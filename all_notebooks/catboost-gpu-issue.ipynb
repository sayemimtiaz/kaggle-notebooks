{"cells":[{"metadata":{},"cell_type":"markdown","source":"As noticed by others [here](https://github.com/catboost/catboost/issues/1408), results from catboost training on GPU can be consistently inferior to results obtained on CPU. Here I try to reproduce the CPU results on the GPU using, where implemented, the same parameters.\n\nThis is just a demo example, the dataset is too small to really benefit from the GPU."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nnp.set_printoptions(precision=4)\nimport catboost\nfrom catboost import datasets\nfrom catboost import *\nprint(\"catboost version:\", catboost.__version__)\n\n# Read data from Amazon.com_Employee Access Challenge\ntrain_df = pd.read_csv('../input/amazoncom-employee-access-challenge/train.csv')\ntest_df = pd.read_csv('../input/amazoncom-employee-access-challenge/test.csv')\n\ny = train_df.ACTION\nX = train_df.drop('ACTION', axis=1)\ncat_features = list(range(0, X.shape[1]))\n\n# train/valid split\ntrain_count = int(X.shape[0] * 0.8)\nX_train = X.iloc[:train_count,:]\ny_train = y[:train_count]\nX_validation = X.iloc[train_count:, :]\ny_validation = y[train_count:]\n\n# Use widely default params to show the difference\nparams = {'learning_rate': 0.05, 'iterations': 500, 'random_seed': 3,\n          'custom_loss': ['Accuracy']}\n\nmod1 = CatBoostClassifier(**params, task_type='GPU')\nmod2 = CatBoostClassifier(**params, task_type='CPU')\n\nargs = (X_train, y_train)\nkwargs = {'eval_set': (X_validation, y_validation), 'cat_features': cat_features, 'verbose': 100}\n\nprint(\"train on GPU (mod1)...\")\nmod1.fit(*args, **kwargs)\n\nprint(\"train on CPU (mod2)...\")\nmod2.fit(*args, **kwargs)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Typical results for some random seeds:\n    model   seed=0  seed=1  seed=2  seed=3  seed=64\n    gpu     0.141   0.143   0.143   0.141   0.144\n    cpu     0.138   0.138   0.137   0.136   0.137"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Compare all params that are different\nparams_gpu = mod1.get_all_params()\nparams_cpu = mod2.get_all_params()\n\nfor k in set(params_cpu.keys())|set(params_gpu.keys()):\n    val_gpu = params_gpu[k] if k in params_gpu.keys() else 'None'\n    val_cpu = params_cpu[k] if k in params_cpu.keys() else 'None'\n    if val_cpu == val_gpu: continue\n    print(f'{k:<30}  {str(val_cpu):<40}  {str(val_gpu):<40}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {'learning_rate': 0.05, 'iterations': 500, 'random_seed': 3,\n          'custom_loss': ['Accuracy']}\n\n# Try to use the same params for both CPU/GPU\nparams['bootstrap_type'] = 'MVS'\nparams['boosting_type'] = 'Plain'         # GPU: much worse (because dataset is small)\nparams['boosting_type'] = 'Ordered'       # CPU: no difference\nparams['model_shrink_mode'] = 'Constant'  # default, ignored by GPU\nparams['model_shrink_rate'] = 0           # default for mode=Constant (should not shrink at all), ignored by GPU\nparams['sampling_frequency'] = 'PerTree'  # doc error: default is 'PerTree' not 'PerTreeLevel'\nparams['posterior_sampling'] = False      # same as None? ignored by GPU\nparams['bagging_temperature'] = 1         # same as None\nparams['border_count'] = 254              # no impact, CPU default: 254, GPU default: 128\nparams['penalties_coefficient'] = 1       # same as None\nparams['fold_permutation_block'] = 64     # 0 ignored by GPU\nparams['subsample'] = 0.8                 # no impact\n\n# ctr: FeatureFreq is not implemented on CPU, Counter not on GPU, use only Border for both.\nparams['simple_ctr'] = ['Borders:CtrBorderCount=15:CtrBorderType=Uniform:TargetBorderCount=1:TargetBorderType=MinEntropy:Prior=0/1:Prior=0.5/1:Prior=1/1']\nparams['combinations_ctr'] = ['Borders:CtrBorderCount=15:CtrBorderType=Uniform:TargetBorderCount=1:TargetBorderType=MinEntropy:Prior=0/1:Prior=0.5/1:Prior=1/1']\n\nparams['ctr_history_unit'] = 'Sample'     # undocumented, ignored by CPU\n#params['fold_size_loss_normalization'] = False  # unexpected keyword argument by GPU\n#params['min_fold_size'] = 100             # undocumented, unexpected keyword argument by GPU\n#params['observations_to_bootstrap'] = 'TestOnly'  # undocumented, unexpected keyword argument for GPU\n\n# Same default for both (but mentioned in Issue report)\nparams['leaf_estimation_method'] = 'Newton'                # same default for both\nparams['leaf_estimation_iterations'] = 10                  # same default for both\nparams['leaf_estimation_backtracking'] = 'AnyImprovement'  # same default for both\n\nmod1 = CatBoostClassifier(task_type='GPU', **params)\nmod2 = CatBoostClassifier(task_type='CPU', **params)\n\nargs = (X_train, y_train)\nkwargs = {'eval_set': (X_validation, y_validation), 'cat_features': cat_features, 'verbose': 100}\n\nprint(\"train on GPU (mod1)...\")\nmod1.fit(*args, **kwargs)  # 1 min setup time\n\nprint(\"train on CPU (mod2)...\")\nmod2.fit(*args, **kwargs)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Still the difference is about the same."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}