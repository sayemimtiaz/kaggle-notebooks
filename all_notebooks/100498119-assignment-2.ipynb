{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nfrom numpy import unique\nfrom numpy import where\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# visualization of data\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn.cluster import KMeans # unsupervised machine learning algorithm \nfrom sklearn.metrics import silhouette_score # Used for the silhouette method for acquiring K\nfrom sklearn.cluster import Birch # Used for birch clustering method\nfrom sklearn.cluster import SpectralClustering # Used for spectral clustering method\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-26T20:09:44.914815Z","iopub.execute_input":"2021-05-26T20:09:44.915241Z","iopub.status.idle":"2021-05-26T20:09:44.933217Z","shell.execute_reply.started":"2021-05-26T20:09:44.915207Z","shell.execute_reply":"2021-05-26T20:09:44.9318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create dataframes for EDA\ncustomer_df = pd.read_csv('../input/customer-segmentation/Cust_Segmentation.csv')\ncustomer_df","metadata":{"execution":{"iopub.status.busy":"2021-05-26T20:09:44.978852Z","iopub.execute_input":"2021-05-26T20:09:44.979257Z","iopub.status.idle":"2021-05-26T20:09:45.010456Z","shell.execute_reply.started":"2021-05-26T20:09:44.979221Z","shell.execute_reply":"2021-05-26T20:09:45.009148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"customer_df.describe()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T20:09:45.041308Z","iopub.execute_input":"2021-05-26T20:09:45.041791Z","iopub.status.idle":"2021-05-26T20:09:45.089422Z","shell.execute_reply.started":"2021-05-26T20:09:45.041739Z","shell.execute_reply":"2021-05-26T20:09:45.088098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# To explore the data, let’s see which columns have the tightest correlation \nsns.pairplot(hue='Edu', data=customer_df, palette=\"husl\")","metadata":{"execution":{"iopub.status.busy":"2021-05-26T20:09:45.091526Z","iopub.execute_input":"2021-05-26T20:09:45.092045Z","iopub.status.idle":"2021-05-26T20:10:09.264688Z","shell.execute_reply.started":"2021-05-26T20:09:45.091992Z","shell.execute_reply":"2021-05-26T20:10:09.263697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Due to the amount of datapoints recorded and the five colour variants for education level it is hard to distinguish any absolute correlation from this graph and further work is needed to make any conclusions.","metadata":{}},{"cell_type":"code","source":"sns.pairplot(hue='Defaulted', data=customer_df, palette=\"bright\")","metadata":{"execution":{"iopub.status.busy":"2021-05-26T20:10:09.266395Z","iopub.execute_input":"2021-05-26T20:10:09.266708Z","iopub.status.idle":"2021-05-26T20:10:28.949842Z","shell.execute_reply.started":"2021-05-26T20:10:09.266679Z","shell.execute_reply":"2021-05-26T20:10:28.946253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In reducing the possible number of colours on the graph from five to two, now reviewing whether an individual has defaulted or not from education may be easier to read. \n\nThere are a lot of clustering occurring in the debt income ratio column which is not surprising if an individual has defaulted. The same degree of clustering applies In the card debt, however other debt is a lot more blended with less correlation to defaults. \n\nThe other columns however are of greater degrees of blended correlation, limiting the possibility for correlations to be visible at this time, without further visualisations being present for those who have defaulted.","metadata":{}},{"cell_type":"code","source":"sns.displot(customer_df, x=\"Edu\", hue=\"Defaulted\")","metadata":{"execution":{"iopub.status.busy":"2021-05-26T20:10:28.951359Z","iopub.execute_input":"2021-05-26T20:10:28.95167Z","iopub.status.idle":"2021-05-26T20:10:29.481909Z","shell.execute_reply.started":"2021-05-26T20:10:28.951641Z","shell.execute_reply":"2021-05-26T20:10:29.480811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The full picture was not painted clearly in previous visualisations, as lower educated people had a higher count as to defaults, but quantity of people who were lower educated was also higher. The ratios of each group would be more telling.","metadata":{}},{"cell_type":"code","source":"edu_1 = len(customer_df.query('Edu == 1'))\nedu_1_defaulted = len(customer_df.query('Edu == 1 and Defaulted == 1'))\nedu_ratio_1 = (round(edu_1_defaulted/edu_1, 2)*100)\n\nedu_2 = len(customer_df.query('Edu == 2'))\nedu_2_defaulted = len(customer_df.query('Edu == 2 and Defaulted == 1'))\nedu_ratio_2 = (round(edu_2_defaulted/edu_2, 2)*100)\n\nedu_3 = len(customer_df.query('Edu == 3'))\nedu_3_defaulted = len(customer_df.query('Edu == 3 and Defaulted == 1'))\nedu_ratio_3 = (round(edu_3_defaulted/edu_3, 2)*100)\n\nedu_4 = len(customer_df.query('Edu == 4'))\nedu_4_defaulted = len(customer_df.query('Edu == 4 and Defaulted == 1'))\nedu_ratio_4 = (round(edu_4_defaulted/edu_4, 2)*100)\n\nedu_5 = len(customer_df.query('Edu == 5'))\nedu_5_defaulted = len(customer_df.query('Edu == 5 and Defaulted == 1'))\nedu_ratio_5 = (round(edu_5_defaulted/edu_5, 2)*100)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T20:10:29.483134Z","iopub.execute_input":"2021-05-26T20:10:29.483414Z","iopub.status.idle":"2021-05-26T20:10:29.521501Z","shell.execute_reply.started":"2021-05-26T20:10:29.483387Z","shell.execute_reply":"2021-05-26T20:10:29.520498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"edu_data = [edu_ratio_1, edu_ratio_2, edu_ratio_3, edu_ratio_4, edu_ratio_5]\nedu_data_df = df = pd.DataFrame({\"Edu\": edu_data})\nplt.bar(['1','2','3','4','5'], edu_data_df.Edu)\nplt.xlabel('Education level')\nplt.ylabel('Ratio of defaults')\nplt.title('Eduction level and ratio of defaults')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T20:10:29.522817Z","iopub.execute_input":"2021-05-26T20:10:29.523138Z","iopub.status.idle":"2021-05-26T20:10:29.66733Z","shell.execute_reply.started":"2021-05-26T20:10:29.523108Z","shell.execute_reply":"2021-05-26T20:10:29.666342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"On average therefore, those in the medium-high range of education (levels 3 and 4) had the highest default rate by the count of individuals in that education level. Which was a surprising result to find.\n\nBelow, lets try and find addition correlations via a heatmap instead to determine areas of correlation. To make the graph easier to read and avoid duplicated results, lets use a triangle heat map to avoid duplication.","metadata":{}},{"cell_type":"code","source":"corr = customer_df.corr()\n\n# Hide the upper half to maintain a triangle\nmask = np.triu(np.ones_like(corr, dtype=bool))\n\n# Create figure\nf, ax = plt.subplots(figsize=(12, 10))\n\n# Create colourmap\ncmap = sns.color_palette(\"coolwarm\", as_cmap=True)\n\n# Display heatmap\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=1, center=0,\n            square=True, annot=True, linewidths=1, cbar_kws={\"shrink\": 1})","metadata":{"execution":{"iopub.status.busy":"2021-05-26T20:10:29.670327Z","iopub.execute_input":"2021-05-26T20:10:29.670633Z","iopub.status.idle":"2021-05-26T20:10:30.207054Z","shell.execute_reply.started":"2021-05-26T20:10:29.670605Z","shell.execute_reply":"2021-05-26T20:10:30.205929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"One of the best visualisations for displaying EDA is a heat map, which is annotated with the correlation between variables. The visualisation can also made easier to read by removing the top half of the graph, thus removing duplicated fields to increase readability.\n\nThe strongest levels of correlation are between card debt and other debt of 64% suggesting poor levels of debt management in the customer segmentation. In second place for highest correlation is income and years employed with a 63% correlation, which we have seen previously in the dataset through other visualisations. In third place is income and other debt, which is strange. One would assume other debt would refer to mortgages potentially, which would make sense as higher earners would have a higher chance of receiving a mortgage. income and other debt also saw a high correlation of 60% which could link years employed to income, income to other debt and other debt to card debt. However, it is important to note that correlation does not imply causation. \n\nAs for the lowest levels of correlations, years employed and defaulted had a correlation of -28%. The lowest correlations are negligible comparatively to the high correlation results, especially considering education and years employed had a -15% correlation and age and defaulted also had a low correlation of -14%.\n","metadata":{}},{"cell_type":"markdown","source":"Lets further expand our findings with a relplot to show the types of debt (other and card) and then compare that with the levels of education. Furthermore, lets use the debt income ratio to evaluate the excessive nature of the debts. It is expected that there will be a larger degree of debt income ratio at the upper bounds of card and other debt.","metadata":{}},{"cell_type":"code","source":"sns.relplot(x=\"Other Debt\", y=\"Card Debt\", hue=\"Edu\", size=\"DebtIncomeRatio\",\n            sizes=(40, 400), alpha=.5, palette=\"muted\",\n            height=6, data=customer_df)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T20:10:30.210676Z","iopub.execute_input":"2021-05-26T20:10:30.211027Z","iopub.status.idle":"2021-05-26T20:10:31.063884Z","shell.execute_reply.started":"2021-05-26T20:10:30.210996Z","shell.execute_reply":"2021-05-26T20:10:31.06289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Rather surprisingly there was not the same degree of debt income distribution at the tail ends of card and other debts, this could be due to individuals with low income, having low debts in pound (£) amounts, because of poor credit scores or not meeting the requirements for larger lending amounts due to financial instability. ","metadata":{}},{"cell_type":"code","source":"sns.jointplot(x=\"Years Employed\", y=\"Income\", data=customer_df, color=\"red\")","metadata":{"execution":{"iopub.status.busy":"2021-05-26T20:10:31.065802Z","iopub.execute_input":"2021-05-26T20:10:31.066112Z","iopub.status.idle":"2021-05-26T20:10:31.706475Z","shell.execute_reply.started":"2021-05-26T20:10:31.066082Z","shell.execute_reply":"2021-05-26T20:10:31.70574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The joint plot shows the general increase in wages as years employed goes up, this can be seen from ten years onwards. We can also see that the highest density of people has only been with the company between 0-2 years with a visible drop off in density as years employed increases. Finally, we can see that the majority of customers have a higher density towards a lower income, reducing in density as income increases.","metadata":{}},{"cell_type":"code","source":"sns.histplot(data=customer_df, x=\"Age\")","metadata":{"execution":{"iopub.status.busy":"2021-05-26T20:10:31.707745Z","iopub.execute_input":"2021-05-26T20:10:31.708209Z","iopub.status.idle":"2021-05-26T20:10:31.899346Z","shell.execute_reply.started":"2021-05-26T20:10:31.708178Z","shell.execute_reply":"2021-05-26T20:10:31.898657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the histogram shown above, the age range of customers with the highest density is in the age range of 25-40 years old. With reductions in density for both younger and old customers than the age range mentioned previously.","metadata":{}},{"cell_type":"markdown","source":"Now we will implement the unsupervised machine learning algoritms K-mean, using the silhouette method to determine K.\n\nThis will test our previous finding from the EDA, in terms of correlation to see the findings from the machine learning algorithm.","metadata":{}},{"cell_type":"code","source":"#Positive correlations tests\ntest1_df = customer_df[[\"Card Debt\", \"Other Debt\"]]\ntest2_df = customer_df[[\"Income\", \"Years Employed\"]]\ntest3_df = customer_df[[\"Income\", \"Other Debt\"]]","metadata":{"execution":{"iopub.status.busy":"2021-05-26T20:10:31.900305Z","iopub.execute_input":"2021-05-26T20:10:31.900715Z","iopub.status.idle":"2021-05-26T20:10:31.907042Z","shell.execute_reply.started":"2021-05-26T20:10:31.900686Z","shell.execute_reply":"2021-05-26T20:10:31.906247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the EDA conducted the following test cases based on the highest correlating datasets will be tested to determine the accuracy of K-mean and how well it can determine patterns in the data.","metadata":{}},{"cell_type":"markdown","source":"**KMEAN TEST 1**","metadata":{}},{"cell_type":"code","source":"sil = []\nmaximum_k = 10\n\n# Find the best value for k, minimum of 2\nfor k in range(2, maximum_k + 1):\n    kmeans = KMeans(n_clusters = k).fit(test1_df)\n    labels = kmeans.labels_\n    sil.append(silhouette_score(test1_df, labels, metric = 'euclidean'))\n\n# Store the value of k and sil scores, to find the best k to use\nk = [*range(2, 11, 1)]\ndic1 = {'k':k,'sil':sil}\nsil1_df = pd.DataFrame(dic1)\nsil1_df","metadata":{"execution":{"iopub.status.busy":"2021-05-26T20:10:31.908053Z","iopub.execute_input":"2021-05-26T20:10:31.908429Z","iopub.status.idle":"2021-05-26T20:10:43.657447Z","shell.execute_reply.started":"2021-05-26T20:10:31.9084Z","shell.execute_reply":"2021-05-26T20:10:43.656404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The code above uses the silhouette method to determine the value of k from the highest silhouette score. The minimum value of k is 2 and the maximum is set to 10.","metadata":{}},{"cell_type":"code","source":"sns.lineplot(data=sil1_df, x=\"k\", y=\"sil\")","metadata":{"execution":{"iopub.status.busy":"2021-05-26T20:10:43.659031Z","iopub.execute_input":"2021-05-26T20:10:43.659619Z","iopub.status.idle":"2021-05-26T20:10:43.87637Z","shell.execute_reply.started":"2021-05-26T20:10:43.659555Z","shell.execute_reply":"2021-05-26T20:10:43.875631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The graph then plots the results of the k iterations and the silhouette score to visualise the best k value.","metadata":{}},{"cell_type":"code","source":"print(labels)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T20:10:43.877698Z","iopub.execute_input":"2021-05-26T20:10:43.878301Z","iopub.status.idle":"2021-05-26T20:10:43.889272Z","shell.execute_reply.started":"2021-05-26T20:10:43.878252Z","shell.execute_reply":"2021-05-26T20:10:43.887779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This array shows the values used to train the model.","metadata":{}},{"cell_type":"code","source":"customer_df['Labelled_Clusters1'] = labels\ntest0 = customer_df[customer_df.Labelled_Clusters1 == 0]\ntest1 = customer_df[customer_df.Labelled_Clusters1 == 1]\n\nsns.scatterplot(x=\"Card Debt\", y=\"Other Debt\", data=test0)\nsns.scatterplot(x=\"Card Debt\", y=\"Other Debt\", data=test1)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T20:10:43.890562Z","iopub.execute_input":"2021-05-26T20:10:43.890879Z","iopub.status.idle":"2021-05-26T20:10:44.127501Z","shell.execute_reply.started":"2021-05-26T20:10:43.89085Z","shell.execute_reply":"2021-05-26T20:10:44.126491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we have all of the data required we can now plot the data for one of the tests, in this case for card debt and other debt. It is clear there is two clear clusters with low other debt being much tighter correlated with low card debt, whereas high other debt bared no relation to other debt.","metadata":{}},{"cell_type":"markdown","source":"**KMEAN TEST 2**","metadata":{}},{"cell_type":"code","source":"sil = []\nmaximum_k = 10\n\n# Find the best value for k, minimum of 2\nfor k in range(2, maximum_k + 1):\n    kmeans = KMeans(n_clusters = k).fit(test2_df)\n    labels = kmeans.labels_\n    sil.append(silhouette_score(test1_df, labels, metric = 'euclidean'))\n\n# Store the value of k and sil scores, to find the best k to use\nk = [*range(2, 11, 1)]\ndic2 = {'k':k,'sil':sil}\nsil1_df = pd.DataFrame(dic2)\n\nsns.lineplot(data=sil1_df, x=\"k\", y=\"sil\")","metadata":{"execution":{"iopub.status.busy":"2021-05-26T20:10:44.128699Z","iopub.execute_input":"2021-05-26T20:10:44.128988Z","iopub.status.idle":"2021-05-26T20:10:53.507504Z","shell.execute_reply.started":"2021-05-26T20:10:44.128959Z","shell.execute_reply":"2021-05-26T20:10:53.506335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"customer_df['Labelled_Clusters2'] = labels\ntest0 = customer_df[customer_df.Labelled_Clusters2 == 0]\ntest1 = customer_df[customer_df.Labelled_Clusters2 == 1]\n\nsns.scatterplot(x=\"Income\", y=\"Years Employed\", data=test0)\nsns.scatterplot(x=\"Income\", y=\"Years Employed\", data=test1)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T20:10:53.509046Z","iopub.execute_input":"2021-05-26T20:10:53.509347Z","iopub.status.idle":"2021-05-26T20:10:53.713981Z","shell.execute_reply.started":"2021-05-26T20:10:53.509317Z","shell.execute_reply":"2021-05-26T20:10:53.712753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For the second scatter plot, the clustering was very strong in proximity, around low income and with years employed between 0-10 and incomes between 10-25. The second cluster has a broad proximity but contained within incomes of 95+, but the years employed was mixed, falling between 5 years and  30 for employment. NOTE: Values used are estimates.","metadata":{}},{"cell_type":"markdown","source":"**KMEAN TEST 3**","metadata":{}},{"cell_type":"code","source":"sil = []\nmaximum_k = 10\n\n# Find the best value for k, minimum of 2\nfor k in range(2, maximum_k + 1):\n    kmeans = KMeans(n_clusters = k).fit(test3_df)\n    labels = kmeans.labels_\n    sil.append(silhouette_score(test1_df, labels, metric = 'euclidean'))\n\n# Store the value of k and sil scores, to find the best k to use\nk = [*range(2, 11, 1)]\ndic3 = {'k':k,'sil':sil}\nsil1_df = pd.DataFrame(dic3)\n\nsns.lineplot(data=sil1_df, x=\"k\", y=\"sil\")","metadata":{"execution":{"iopub.status.busy":"2021-05-26T20:36:07.533089Z","iopub.execute_input":"2021-05-26T20:36:07.533525Z","iopub.status.idle":"2021-05-26T20:36:14.577623Z","shell.execute_reply.started":"2021-05-26T20:36:07.533483Z","shell.execute_reply":"2021-05-26T20:36:14.576526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"customer_df['Labelled_Clusters3'] = labels\ntest0 = customer_df[customer_df.Labelled_Clusters3 == 0]\ntest1 = customer_df[customer_df.Labelled_Clusters3 == 1]\n\nsns.scatterplot(x=\"Income\", y=\"Other Debt\", data=test0)\nsns.scatterplot(x=\"Income\", y=\"Other Debt\", data=test1)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T20:11:01.207977Z","iopub.execute_input":"2021-05-26T20:11:01.208426Z","iopub.status.idle":"2021-05-26T20:11:01.389859Z","shell.execute_reply.started":"2021-05-26T20:11:01.208379Z","shell.execute_reply":"2021-05-26T20:11:01.38915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Similar results were also present within income measured against other debt, with low income showing low other debt, and high income showing a varied degree of other debt, therefore presenting a low proximity structure. This is the opposite to the tight clustering of the low income and low other debt individuals. ","metadata":{}},{"cell_type":"markdown","source":"Next we will use birch clustering method for generating clusters to compare against k mean","metadata":{}},{"cell_type":"markdown","source":"**BIRCH CLUSTERING TEST 1**","metadata":{}},{"cell_type":"code","source":"# birch clustering\nbirch1_array = test1_df.to_numpy() # Convert dataframe to np array for data formatting \nprint(birch1_array)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T20:11:01.390983Z","iopub.execute_input":"2021-05-26T20:11:01.391398Z","iopub.status.idle":"2021-05-26T20:11:01.396588Z","shell.execute_reply.started":"2021-05-26T20:11:01.391354Z","shell.execute_reply":"2021-05-26T20:11:01.395547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"First we need to reformat existing data from a dataframe to a numpy array to first the requirements of the scatter graph, for this applicational use, before it can be used in the Birch method.","metadata":{}},{"cell_type":"code","source":"# Set the parameters for number of clusters. To keep the results comparable number of clusters was set to 2\nmodel = Birch(threshold=0.01, n_clusters=2) \nmodel.fit(birch1_array)\nclust = model.predict(birch1_array)\nclusters = unique(clust)\n# For each cluster create a scatter plot\nfor cluster in clusters:\n    row = where(clust == cluster)\n    plt.scatter(birch1_array[row, 0], birch1_array[row, 1])\n    plt.xlabel(\"Card Debt\")\n    plt.ylabel(\"Other Debt\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T20:11:01.397809Z","iopub.execute_input":"2021-05-26T20:11:01.398076Z","iopub.status.idle":"2021-05-26T20:11:01.761716Z","shell.execute_reply.started":"2021-05-26T20:11:01.398051Z","shell.execute_reply":"2021-05-26T20:11:01.761035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Comparing the two scatter graphs from the kmean example to the birch clustering method is challenging due to not all of the datapoint being plotted by the kmean scatter graph. However, there are distinctions to be made, the kmean visualisations show a higher degree of precision in identifying clusters of data, where as the birch method showed a more inclusive approach to plotting and thus painting broader conclusions as to the relationships within the data.\n\nIn this graph in particular very different classifications were presented, in comparison to kmean. Kmean had two distinct groupings, where as birch was more closely blended. In this instance therefore, kmean is the better approach for identification. `","metadata":{}},{"cell_type":"markdown","source":"**BIRCH CLUSTERING TEST 2**","metadata":{}},{"cell_type":"code","source":"birch2_array = test2_df.to_numpy() # Convert dataframe to np array for data formatting \nmodel = Birch(threshold=0.01, n_clusters=2) \nmodel.fit(birch2_array)\nclust = model.predict(birch2_array)\nclusters = unique(clust)\n# For each cluster create a scatter plot\nfor cluster in clusters:\n    row = where(clust == cluster)\n    plt.scatter(birch2_array[row, 0], birch2_array[row, 1])\n    plt.xlabel(\"Income\")\n    plt.ylabel(\"Years Employed\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T20:11:01.762728Z","iopub.execute_input":"2021-05-26T20:11:01.763138Z","iopub.status.idle":"2021-05-26T20:11:02.103523Z","shell.execute_reply.started":"2021-05-26T20:11:01.763095Z","shell.execute_reply":"2021-05-26T20:11:02.102812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The same results have been repeated here, further reiterating the findings from the first test comparison. ","metadata":{}},{"cell_type":"code","source":"birch3_array = test3_df.to_numpy() # Convert dataframe to np array for data formatting \nmodel = Birch(threshold=0.01, n_clusters=2) \nmodel.fit(birch3_array)\nclust = model.predict(birch3_array)\nclusters = unique(clust)\n# For each cluster create a scatter plot\nfor cluster in clusters:\n    row = where(clust == cluster)\n    plt.scatter(birch3_array[row, 0], birch3_array[row, 1])\n    plt.xlabel(\"Income\")\n    plt.ylabel(\"Other Debt\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T20:11:02.106082Z","iopub.execute_input":"2021-05-26T20:11:02.106535Z","iopub.status.idle":"2021-05-26T20:11:02.47147Z","shell.execute_reply.started":"2021-05-26T20:11:02.106486Z","shell.execute_reply":"2021-05-26T20:11:02.470512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As for the last comparison, the result are similar in their findings. However, the results are more severe in terms of the blended results presented within the birch method with data being closely presented between the two clusters.\n\nBecause the birch models classify the whole dataset this can be problematic as decision lines are blurred for classification, where as the kmean method opts for a higher degree of density within most of its groupings. ","metadata":{}},{"cell_type":"markdown","source":"**SPECTRAL CLUSTERING TEST 1**","metadata":{}},{"cell_type":"code","source":"model = SpectralClustering(n_clusters=2, affinity='nearest_neighbors')\nlabels = model.fit_predict(birch1_array)\nplt.scatter(birch1_array[:, 0], birch1_array[:, 1], c=labels, s=50);\nplt.xlabel(\"Card Debt\")\nplt.ylabel(\"Other Debt\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T20:17:13.390281Z","iopub.execute_input":"2021-05-26T20:17:13.390721Z","iopub.status.idle":"2021-05-26T20:17:13.871355Z","shell.execute_reply.started":"2021-05-26T20:17:13.390681Z","shell.execute_reply":"2021-05-26T20:17:13.870363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For the spectral clustering method, the clustering was broadly in line with that of the birch method but still obscured when compared to the precision of the k-mean approach.","metadata":{}},{"cell_type":"markdown","source":"**SPECTRAL CLUSTERING TEST 2**","metadata":{}},{"cell_type":"code","source":"model = SpectralClustering(n_clusters=2, affinity='nearest_neighbors')\nlabels = model.fit_predict(birch2_array)\nplt.scatter(birch2_array[:, 0], birch2_array[:, 1], c=labels, s=50);\nplt.xlabel(\"Income\")\nplt.ylabel(\"Years Employed\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T20:31:25.438074Z","iopub.execute_input":"2021-05-26T20:31:25.438471Z","iopub.status.idle":"2021-05-26T20:31:26.009706Z","shell.execute_reply.started":"2021-05-26T20:31:25.438434Z","shell.execute_reply":"2021-05-26T20:31:26.008724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Again, the same results were seen in the second test, as with the first.","metadata":{}},{"cell_type":"markdown","source":"**SPECTRAL CLUSTERING TEST 3**","metadata":{}},{"cell_type":"code","source":"model = SpectralClustering(n_clusters=3, affinity='nearest_neighbors')\nlabels = model.fit_predict(birch3_array)\nplt.scatter(birch3_array[:, 0], birch3_array[:, 1], c=labels, s=50);\nplt.xlabel(\"Income\")\nplt.ylabel(\"Other Debt\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T20:38:50.197676Z","iopub.execute_input":"2021-05-26T20:38:50.198044Z","iopub.status.idle":"2021-05-26T20:38:50.887211Z","shell.execute_reply.started":"2021-05-26T20:38:50.198013Z","shell.execute_reply":"2021-05-26T20:38:50.886122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As for this test of the spectral clustering method, an issue with the implementation was found, which did not affect the previous tests. The third test does present a graph, but also accompanied by a warning. This issue was partially fixed when an additional k, from two to three, was added, which allowed for two clusters on the graph to be displayed.","metadata":{}}]}