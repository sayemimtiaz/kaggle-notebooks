{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Chai Time Data Science Show\n***Interviews with Practitioners, Kagglers & Researchers and all things Data Science.***\n<img src='https://chaitimedatascience.com/content/images/2020/07/ctds-1.png' height=200 width=500/>\n\n## <a id='toc'>Table of Contents</a>\n1. [Overview](#1)\n2. [Show Timeline](#2)\n3. [Battle of the Sexes](#3)\n4. [Heroes' Whereabouts](#4)\n5. [The Flavorful Show ‚òï](#5)\n6. [Contribution of the Kagglers](#6)<br>\n    6.1 [The number of Kagglers](#6.1)<br>\n    6.2 [Kaggler Performance Tier](#6.2)<br>\n    6.3 [Know your Kagglers!](#6.3)<br>\n7. [Youtube Analysis](#7)<br>\n    7.1 [Impressions and Views](#7.1)<br>\n    7.2 [What influences the CTR?](#7.2)<br>\n    7.3 [Does the episode duration matter?](#7.3)<br>\n    7.4 [Tracking the User Activity](#7.4)<br>\n8. [Podcasts Analysis](#8)<br>\n    8.1 [Anchor Analysis](#8.1)<br>\n    8.2 [Spotify Analysis](#8.2)<br>\n    8.3 [Apple Podcast Analysis](#8.3)<br>\n9. [Show Analysis](#9)<br>\n    9.1 [Understanding the host: Sanyam Bhutani](#9.1)<br>\n    9.2 [Verbosity of our Heroes](#9.2)<br>\n    9.3 [What's all the talk about?](#9.3)","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport plotly_express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots\nfrom IPython.display import display, HTML\nimport requests\nfrom bs4 import BeautifulSoup\nimport re\nimport json\nimport os\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud, STOPWORDS\n\n\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"subtitle_path = '/kaggle/input/chai-time-data-science/Cleaned Subtitles/'\ndf = pd.read_csv('/kaggle/input/chai-time-data-science/Episodes.csv')\nPLOT_BGCOLOR='#DADEE3'\nPAPER_BGCOLOR='rgb(255,255,255)'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <a id='1'>1. Overview</a>\n<a href='#toc'><span class=\"label label-info\">Go back to the Table of Contents</span></a>\n\nChai Time Data Science show is a Podcast + Video + Blog based show for interviews with Practitioners, Kagglers & Researchers and all things Data Science This is also a ‚Äúre-start‚Äù or continuation of the ‚ÄúInterview with Machine Learning Heroes Series‚Äù by [Sanyam Bhutani](https://www.linkedin.com/in/sanyambhutani/).\nLet us take a look at some of the show statistictics.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig = go.Figure()\n\nfig.add_trace(go.Indicator(\n    title = {'text':'Total Episodes Released','font':{'color': 'white'}},\n    mode = \"number\",\n    number={'font':{'color': 'white'}},\n    value = df.episode_id.nunique(),\n    domain = {'row': 0, 'column': 0}))\n\n\nfig.add_trace(go.Indicator(\n    title = {'text':'Total Heroes Interviewed','font':{'color': 'white'}},\n    mode = \"number\",\n    number={'font':{'color': 'white'}},\n    value = df.heroes.nunique(),\n    domain = {'row': 0, 'column': 1}))\n\n\nfig.add_trace(go.Indicator(\n    title = {'text':'Average Episode Duration<br>(in minutes)','font':{'color': 'white'}},\n    mode = \"number\",\n    number={'font':{'color': 'white'}},\n    value = df.episode_duration.mean()/60,\n    domain = {'row': 1, 'column': 0}))\n\nfig.add_trace(go.Indicator(\n    title = {'text':'Total Youtube<br>Subscribers Earned','font':{'color': 'white'}},\n    mode = \"number\",\n    number={'font':{'color': 'white'}},\n    value = df.youtube_subscribers.sum(),\n    domain = {'row': 1, 'column': 1}))\n\nfig.update_layout(width=700,height=400,\n                  title = {'text':'<b>Chai Time Data Science Stats</b>',\n                           'font':{'size':30,'color': '#762a0c'}},\n                  template='seaborn',margin=dict(t=60,b=10,l=10,r=10),\n                  grid = {'rows': 2, 'columns': 2, 'pattern': \"independent\"},paper_bgcolor='#e87d22')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The show is available on following mediums:-\n- [anchor.fm](https://anchor.fm/chaitimedatascience)\n- [Apple podcasts](https://podcasts.apple.com/us/podcast/chai-time-data-science/id1473685440?ign-mpt=uo%3D4)\n- [Breaker](https://www.breaker.audio/chai-time-data-science)\n- [Spotify](https://open.spotify.com/show/7IbEWJjeimwddhOZqWe0G1)\n- [Google podcasts](https://podcasts.google.com/feed/aHR0cHM6Ly9hbmNob3IuZm0vcy9jMTk3NzJjL3BvZGNhc3QvcnNz)\n- [Pocket Casts](https://pca.st/37LZ)\n- [Overcast](https://overcast.fm/itunes1473685440/chai-time-data-science)\n- [Radio Public](https://radiopublic.com/chai-time-data-science-6VypwX)\n- [Youtube](https://www.youtube.com/playlist?list=PLLvvXm0q8zUbiNdoIazGzlENMXvZ9bd3x)\n- [Stitcher](https://www.stitcher.com/podcast/sanyam-bhutani/chai-time-data-science)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# <a id='2'>2. Show Timeline</a>\n<a href='#toc'><span class=\"label label-info\">Go back to the Table of Contents</span></a>\n\n<img src='https://media.giphy.com/media/10bL6SqRBRfMUU/giphy.gif'/><br>\nThe show first released on 21st July 2019 and since then has released 85 episodes in total. Below gantt chart showcases the entire show's timeline including when a particular episode was recorded and when it was released finally.\n\nOut of the released 85 episodes, 76 are interviews (E0 - E75) and the remaining 9 are lessons(M0 - M8) by fast-ai's founder [Jeremy Howard](https://www.fast.ai/about/#jeremy). The interviews are shown in blue color while lessons are shown in yellow color.\n\nThe y-axis lists down all the episodes and corresponding links to their Youtube and Anchor podcasts for your ready reference. Just click on any of the links to access the episode on youtube/anchor. ","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df_gantt = df.copy()\ndf_gantt = df_gantt[['episode_id','episode_name','recording_date','release_date','youtube_url','anchor_url']]\ndf_gantt['Resource'] = df_gantt['episode_id'].apply(lambda x: 'Episode' if x[0]=='E' else 'Mini-Series')\ndf_gantt['link'] = df_gantt.apply(lambda x: '{}(<a href=\"{}\">Youtube</a>/<a href=\"{}\">Anchor</a>)'\\\n                                  .format(x['episode_id'],x['youtube_url'],x['anchor_url']),axis=1)\ndf_gantt.rename(columns={'link':'Task','recording_date':'Start','release_date':'Finish',\n                         'episode_name':'Description'},inplace=True)\ncolors = {'Episode': '#0080B7',\n          'Mini-Series': '#FDE803'}\nfig = ff.create_gantt(df_gantt,colors=colors,index_col='Resource',bar_width=0.2,showgrid_x=True, showgrid_y=True)\nfig.update_layout(width=700,height=1200,title='Episodes: Recording & Release Dates',template='seaborn',\n                  xaxis=dict(title='Timeline',mirror=True,linewidth=2,linecolor='black',gridcolor='darkgray'),\n                  yaxis=dict(title='Episodes',mirror=True,linewidth=2,linecolor='black',tickfont=dict(size=8),gridcolor='darkgray'),\n                  plot_bgcolor=PLOT_BGCOLOR,paper_bgcolor=PAPER_BGCOLOR,hovermode='closest')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- As can be seen from the show timeline above, it is not necessary that an episode released first is recorded first. For example, have a look at E8 in the above chart. It was recorded the earliest but was released after first eight episodes.\n- The lessons by Jeremy Howard were recorded all at once on 26 Feb 2020 and also released all at once on 7th March 2020.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# youtube_url = 'https://havecamerawilltravel.com/photographer/files/2020/01/youtube-logo-new.jpg'\n# anchor_url = 'https://d12xoj7p9moygp.cloudfront.net/images/anchor-logo-header.png'\n# df_episodes = df[['episode_id','episode_name','release_date','youtube_url','anchor_url']]\n# df_episodes['Youtube Link'] = df_episodes['youtube_url']\\\n#     .apply(lambda x: '<a href=\"{}\" target=\"_blank\" title=\"{}\"><img src=\"{}\" width=\"80\" height=\"10\"></a>'.format(\n#             x, 'Chai Time Data Science', youtube_url))\n# df_episodes['Anchor Link'] = df_episodes['anchor_url']\\\n#     .apply(lambda x: '<a href=\"{}\" target=\"_blank\" title=\"{}\"><img src=\"{}\" width=\"80\" height=\"10\" style=\"background-color:#3C3B6E;\" ></a>'.format(\n#             x, 'Chai Time Data Science', anchor_url))\n# df_episodes.rename(columns={'episode_id':'Episode','episode_name':'Name','release_date':'Released On'},inplace=True)\n# display_html(df_episodes, cols=['Episode','Name', 'Released On','Youtube Link','Anchor Link'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <a id='3'>3. Battle of the Sexes</a>\n<a href='#toc'><span class=\"label label-info\">Go back to the Table of Contents</span></a>\n\n<img src='https://media.giphy.com/media/l4Epgt54FuBUIsdYA/giphy.gif'/>\nData Science is a growing field and over the past few years it has seen exponential growth. Men and Women have contributed equally to this field. By looking at the below plot, it would seem like that there's a gender bias as 88% of the heroes interviewed are males, but I believe it is just a matter of time that we see a rise in the blue bar.\n\n**Eagerly looking forward to it!!**","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"d = dict(df.heroes_gender.value_counts())\ntotal = sum(d.values())\nfig = go.Figure()\ncolors = {'Male':'#FDE803','Female':'#0080B7'}\nannotations=[]\nspace = 0\nfor key, value in d.items():\n    fig.add_trace(go.Bar(name=key,x=[value],y=['Heroes<br>Gender Count'],orientation='h',\n                        marker_line_color='black',marker_line_width=1.5,marker_color=colors[key]))\n    annotations.append(dict(xref='x', yref='y',\n                            x=space + (value/2), y=0,\n                            text=str(int(np.round(value/total,2)*100)) + '%',\n                            font=dict(family='Arial', size=14,\n                                      color='rgb(0, 0, 0)'),\n                                      showarrow=False))\n    space+=value\nfig.update_layout(barmode='stack',width=700,height=150,paper_bgcolor=PAPER_BGCOLOR,plot_bgcolor=PLOT_BGCOLOR,\n                 hovermode='y',xaxis=dict(mirror=True,linewidth=2,linecolor='black',showgrid=False),\n                 yaxis=dict(mirror=True,linewidth=2,linecolor='black',showgrid=False),margin=dict(t=0,b=0,l=0,r=0),\n                 legend=dict(title='Gender',y=0.5),annotations=annotations)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <a id=4>4. Heroes' Whereabouts</a>\n<a href='#toc'><span class=\"label label-info\">Go back to the Table of Contents</span></a>\n\nTo remove the confusion if there's any, the people interviewed on CTDS.show are called Data Science Heroes. I fell its apt owing to the fact that they have contributed so much to the field.\n\nIn this section, I'll be analysing the distribution of Heroes' nationality and the country they are currently working in. In this age of globalization, it is pretty common to move places. So, its not necessary that a person in India will specifically work in India. People switch places for higher education, work and many other reasons.\n<br>\n<img src='https://media.giphy.com/media/3ov9k06VQ0SU6f15rW/giphy.gif'/>\n<br>\nThe horizontal bar chart below has two legends: Nationality & Location.\n<br>\n`Nationality`: The country in which the person is born.\n<br>\n`Location`: The country in which the person is currently working/studying.\n\n> **Please Note:** I have used logarithmic scale for xaxis as there is a huge gap between the first(USA: 22/37) and the second country(France: 8/5).","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"d1 = dict(df.heroes_nationality.value_counts())\nd2 = dict(df.heroes_location.value_counts())\nfig = go.Figure()\nfig.add_trace(go.Bar(name='Nationality',x=list(d1.values()),y=list(d1.keys()),orientation='h',marker_color='#FDE803',\n                    text=list(d1.values()),textposition='outside',marker_line_color='black',marker_line_width=1.5))\nfig.add_trace(go.Bar(name='Location',x=list(d2.values()),y=list(d2.keys()),orientation='h',marker_color='#0080B7',\n                    text=list(d2.values()),textposition='outside',marker_line_color='black',marker_line_width=1.5))\nfig.update_layout(width=700,height=700,template='seaborn',title='Heroes Nationality vs Location',hovermode='y unified',\n                 xaxis=dict(title='Number of Heroes',type='log',mirror=True,linewidth=2,\n                            linecolor='black',gridcolor='darkgray'),\n                 yaxis=dict(mirror=True,linewidth=2,linecolor='black',showgrid=False),margin=dict(t=25,b=0,l=0,r=0),\n                 paper_bgcolor=PAPER_BGCOLOR,plot_bgcolor='#DADEE3',legend=dict(x=0.8,bgcolor='#DADEE3'))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- `USA` is number 1 by a huge margin. One thing to note is that out of the 37 currently working in US, 22 are native americans while the remaining 15 are not orginally from america. I wish Trump had seen this before revoking the visas üòú!!\n- Barring `US`, `UK` & `Canada`, all the other countries have Nationality bar less than or equal to the Location bar. So does this mean that US,UK & Canada have more opportunities when it comes to data science? I believe we need more data before jumping to the  conclusion.\n- Heros born in `Switzerland`, `Africa`, `Vietnam` & `Greece` are currently working in different countries.\n- `Singapore`, `Norway` & `Czech Republic` have in total 4 heroes working there currently. Although, no hero is from there natively.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# <a id='5'>5. The Flavorful Show ‚òï</a>\n<a href='#toc'><span class=\"label label-info\">Go back to the Table of Contents</span></a>\n\nYou all must me thinking that the show is called Chai Time Data Science show and still no talk about Chai(Tea)!!<br>\n<img src='https://media.giphy.com/media/2z0GFIoCNUVY4/giphy.gif' height=300 width=400/>\n<br>\nApparently, the host Sanyam chooses from his collection of 9 different varieties of chai, which he keeps aside him while interviewing. So, let's see which varieties have been used the most and which the least.","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"d = dict(df.flavour_of_tea.value_counts())\ncolors = ['#ED1C22','#FEC907','#FF3D09','#7CBB15', '#92D0FF', '#30ADE5','#1373C7','#ED309C','#3BD5C9']\nfig = go.Figure(data=[go.Pie(labels=list(d.keys()),values=list(d.values()))])\nfig.update_traces(hoverinfo='label+value', textinfo='percent', textfont_size=20,\n                  marker=dict(colors=colors, line=dict(color='#000000', width=1.5)))\nfig.update_layout(title='Different Flavours of Tea‚òï',width=700,height=400,barmode='stack',template='seaborn',\n                 paper_bgcolor=PLOT_BGCOLOR,plot_bgcolor=PLOT_BGCOLOR,hovermode='x unified',\n                 legend=dict(title='<b><i>Type of ‚òï</i></b>',x=0.835,bgcolor=PLOT_BGCOLOR),margin=dict(t=35,b=10,l=10,r=10),\n                 xaxis=dict(title='Number of Heroes',mirror=True,linewidth=2,linecolor='black',showgrid=False),\n                 yaxis=dict(mirror=True,linewidth=2,linecolor='black',gridcolor='darkgray'))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Clearly, `Masala Chai` & `Ginger Chai` are used the most while `Kashmiri Kahwa` the least. I believe the first two are the host's favourites while the latter is the least favourite!!","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# <a id='6'>6. Contribution of the Kagglers</a>\n<a href='#toc'><span class=\"label label-info\">Go back to the Table of Contents</span></a>\n\nKaggle, a subsidiary of Google LLC, is an online community of data scientists and machine learning practitioners. Kaggle allows users to find and publish data sets, explore and build models in a web-based data-science environment, work with other data scientists and machine learning engineers, and enter competitions to solve data science challenges.\n\nIn June 2017, Kaggle announced that it passed 1 million registered users, or Kagglers. The community spans 194 countries. It is the largest and most diverse data community in the world, ranging from those just starting out to many of the world's best known researchers.<br>\n<img src='https://upload.wikimedia.org/wikipedia/commons/7/7c/Kaggle_logo.png'/><br>\nDefinitely, the world's largest Data Science community will make some contribution to a show that's based on Data Science. BTW kaggle is also my favourite plotform. It's an ocean of knowledge where you can learn anything related to Data Science.\n\nIn this section I'll be analysing the relation between the heroes interviewed on CTDS.show and the Kagglers.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## <a id='6.1'>6.1 The number of Kagglers</a>\n<a href='#toc'><span class=\"label label-info\">Go back to the Table of Contents</span></a>\n\nAll the heroes are divided into 4 categories: Kaggle, Industry, Research and Others. Below I have drawn a bar chart showing each category's strength. I have also added gender distrubution as well.","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df.heroes_gender.fillna('NA',inplace=True)\ngroup=df.groupby(['category','heroes_gender'],as_index=False)['episode_id']\\\n        .count().sort_values('episode_id',ascending=False)\nfig = go.Figure()\ncolors={'Male':'#FDE803','Female':'#0080B7','NA':'#FF3D09'}\nfor sex in group.heroes_gender.unique().tolist():\n    df_cat = group[group['heroes_gender']==sex]\n    fig.add_trace(go.Bar(name=sex,x=df_cat['category'],y=df_cat['episode_id'],marker_line_color='black',\n                        marker_line_width=1.5,marker_color=colors[sex],text=df_cat['episode_id'],textposition='auto'))\nfig.update_layout(title='Heroes Category',width=700,height=400,barmode='stack',template='seaborn',\n                 paper_bgcolor=PAPER_BGCOLOR,plot_bgcolor=PLOT_BGCOLOR,hovermode='x unified',\n                 legend=dict(title='Gender',x=0.835,bgcolor=PLOT_BGCOLOR),margin=dict(t=25,b=0,l=0,r=0),\n                 xaxis=dict(title='Number of Heroes',mirror=True,linewidth=2,linecolor='black',showgrid=False),\n                 yaxis=dict(mirror=True,linewidth=2,linecolor='black',gridcolor='darkgray'))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Please Note:** The graph shows out of all the interviewed, 31 are Kagglers and all are males. The actual figure is 43 for Kagglers and they constitute for 50% of those interviewed on CTDS.show. This difference can be attributed to the fact that Kaggle is such a vast community that people working in research, industry or others can also be a part of it. And, only one category has to be assigned to a person.","execution_count":null},{"metadata":{"_kg_hide-input":false},"cell_type":"markdown","source":"## <a id='6.2'>6.2 Kaggler Performance Tier</a>\n<a href='#toc'><span class=\"label label-info\">Go back to the Table of Contents</span></a>\n\nWant to know your probability of featuring on CTDS.show? Maybe the below plot can answer this question. \nFor those of you who are unaware, Kaggle follows a [Progression system](https://www.kaggle.com/progression) that uses performance tiers to track your growth as a data scientist on Kaggle.\n\nThe Progression System is designed around four Kaggle categories of data science expertise: Competitions, Notebooks, Datasets, and Discussion. Advancement through performance tiers is done independently within each category of expertise.\n\nWithin each category of expertise, there are five performance tiers that can be achieved in accordance with the quality and quantity of work you produce: Novice, Contributor, Expert, Master, and Grandmaster.","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df_meta = pd.read_csv('/kaggle/input/meta-kaggle/Users.csv')\ndf_users= df_meta[df_meta['UserName'].isin(list(df.heroes_kaggle_username.unique()[1:]))].copy()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"colors = {0:'#5ac995',1:'#0bf',2:'#95628f',3:'#f96517',4:'#dca917',5:'#008abc'}\nlabels = {0:'Novice',1:'Contributor',2:'Expert',3:'Master',4:'Grandmaster',5:'Kaggle team'}\ngroup = df_users.groupby('PerformanceTier',as_index=False)['Id'].count()\ngroup['labels'] = group['PerformanceTier'].map(labels)\ngroup['colors'] = group['PerformanceTier'].map(colors)\nfig = go.Figure(data=[go.Pie(labels=group.labels,values=group.Id)])\nfig.update_traces(hoverinfo='label+value', textinfo='percent', textfont_size=20,\n                  marker=dict(colors=group.colors, line=dict(color='#000000', width=1.5)))\nfig.update_layout(title=\"Heroes Kaggle Tier Distribution\",width=700,height=400,barmode='stack',template='seaborn',\n                 paper_bgcolor=PLOT_BGCOLOR,plot_bgcolor=PLOT_BGCOLOR,hovermode='x unified',\n                 legend=dict(title='<b><i>Performance Tier</i></b>',x=0.835,bgcolor=PLOT_BGCOLOR),margin=dict(t=35,b=10,l=10,r=10),\n                 xaxis=dict(title='Number of Heroes',mirror=True,linewidth=2,linecolor='black',showgrid=False),\n                 yaxis=dict(mirror=True,linewidth=2,linecolor='black',gridcolor='darkgray'))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- All hail the Grandmasters!! If you are a grandmaster, you deservedly have the highest chances of being featured on the show.\n- As the Tier reduces the chances of being interviewed on the show also decrease.\n- But, don't be disheartened. Your chances of being on the show is more than double than those of the kaggle team atleast. This is something to cheer about :P","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## <a id='6.3'>6.3 Know your Kagglers!</a>\n<a href='#toc'><span class=\"label label-info\">Go back to the Table of Contents</span></a>\n\nI thought that it would be better if I could list all the Kagglers interviewed on the show. I have also added some information about the kagglers. You can click on the kaggler image to access their profile and look at their awesome projects.\nThanks to [Raenish](https://www.kaggle.com/raenish) for his awesome [kernel](https://www.kaggle.com/raenish/become-grandmaster). I have reused some of his code.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"%%javascript\nIPython.OutputArea.prototype._should_scroll = function(lines) {\n    return false;\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def scrape_data(df):\n    for index in df.index:\n        #time.sleep(1)\n        row = df.iloc[index]\n    \n        username = row.UserName\n        profile_url = '{}{}'.format(KAGGLE_BASE_URL, username)\n        displayname = row.DisplayName\n\n        result = requests.get(profile_url)\n        src = result.content\n        soup = BeautifulSoup(src, 'html.parser')\n        soup = soup.find_all(\"div\", id=\"site-body\")[0].find(\"script\")\n\n        user_info = re.search('Kaggle.State.push\\(({.*})', str(soup)).group(1)\n        user_dict = json.loads(user_info)\n    \n        city = user_dict['city']\n        region = user_dict['region']\n        country = user_dict['country']\n        avatar_url = user_dict['userAvatarUrl']\n        occupation = user_dict['occupation']\n        organization = user_dict['organization']\n        github_user = user_dict['gitHubUserName']\n        twitter_user = user_dict['twitterUserName']\n        linkedin_url = user_dict['linkedInUrl']\n        website_url = user_dict['websiteUrl']\n        last_active = user_dict['userLastActive']\n        num_followers = user_dict['followers']['count']\n        num_following = user_dict['following']['count']\n\n        num_posts = user_dict['discussionsSummary']['totalResults']\n        num_datasets = user_dict['datasetsSummary']['totalResults']\n        num_kernels = user_dict['scriptsSummary']['totalResults']\n        num_comps = user_dict['competitionsSummary']['totalResults']\n\n\n        df.loc[index, 'Image'] = '<a href=\"{}\" target=\"_blank\" title=\"{}\"><img src=\"{}\" width=\"100\" height=\"100\"></a>'.format(\n            profile_url, displayname, avatar_url)\n        df.loc[index, 'NumFollowers'] = num_followers\n        df.loc[index, 'NumFollowing'] = num_following\n        df.loc[index, 'NumPosts'] = num_posts\n        df.loc[index, 'NumDatasets'] = num_datasets\n        df.loc[index, 'NumKernels'] = num_kernels\n        df.loc[index, 'NumCompetitions'] = num_comps\n        df.loc[index, 'Country'] = country\n    return df","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def display_html(df, cols=None, index=False, na_rep='', num_rows=0):\n    if num_rows == 0:\n        df_table = df.to_html(columns=cols, index=index, na_rep=na_rep, escape=False, render_links=True)\n        display(HTML(df_table))\n    else:\n        df_table = df.head(num_rows).to_html(columns=cols, index=index, na_rep=na_rep, escape=False, render_links=True)\n        display(HTML(df_table))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"KAGGLE_BASE_URL = \"https://www.kaggle.com/\"\ndf_users['RegisterDate'] = pd.to_datetime(df_users['RegisterDate'],format='%m/%d/%Y')\ndf_users['Joined'] = df_users.RegisterDate.apply(lambda x: str(2020-x.year)+' years ago')\ndf_users.reset_index(drop=True,inplace=True)\ndf_users = scrape_data(df_users)\ndf_users.NumFollowers = df_users.NumFollowers.astype(int)\ndisplay_html(df_users, cols=['Image','UserName', 'DisplayName','Joined','NumFollowers','Country'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 7. Youtube Analysis\n<a href='#toc'><span class=\"label label-info\">Go back to the Table of Contents</span></a>\n\nIn this section, I'll be doing an extensive analysis on the youtube data provided to us. First, just to clarify what all the terms used in this section mean(in the context of online advertising):\n- **Impression: ** It is when an ad is fetched from its source, and is countable. Whether the ad is clicked is not taken into account. Each time an ad is fetched, it is counted as one impression. So, whenever you see a youtube video link on youtube or any other medium it's counted an an impression.\n- **View: ** It is when you click on the link,it's counted as a view. So, if you access the youtube video from a link on youtube webpage/application, it's called an *Impression View*. If you access it from any other webpage/application, it's called an *Non-Impression View*.\n- **CTR: ** It is called the click-through rate and is the ratio between Views and Impressions. By Views here I mean the Impression Views. So, higher the CTR, better the the ad campaign. Therefore, anybody would want a higher CTR.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## <a id='7.1'>7.1 Impressions and Views</a>\n<a href='#toc'><span class=\"label label-info\">Go back to the Table of Contents</span></a>\n\nNow that you know the meanings of these terms, lets see how CTDS.show fared when it comes to campaigning.\n\nIn the plot below I have analysed the impressions per episode. Along with that I have also plotted the mean and median impressions of all the episodes to see how its ditributed.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df_yt = pd.read_csv('/kaggle/input/chai-time-data-science/YouTube Thumbnail Types.csv')\ndf_yt = pd.merge(df,df_yt,on='youtube_thumbnail_type')\ncolors = {0:'#FDE803',1:'#0080B7',2:'#FF3D09',3:'#7CBB15'}\ndf_yt['color'] = df_yt.youtube_thumbnail_type.map(colors)\ndf_yt['ep_no'] = df_yt.episode_id.apply(lambda x: int(x[1:]) if x[0]=='E' else 75+int(x[1:]))\ndf_yt.sort_values('ep_no',inplace=True)\ndf_yt['heroes'] = df_yt['heroes'].fillna('NaN')\ndf_yt['episode'] = df_yt.apply(lambda x: x['episode_id'] + ' | ' + x['heroes'] \n                               if x['heroes']!='NaN' else x['episode_id'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"y_avg = df_yt.youtube_impressions.mean()\ny_med = df_yt.youtube_impressions.median()\nfig = go.Figure()\nfig.add_trace(go.Bar(name='Impressions',x=df_yt.episode_id,y=df_yt.youtube_impressions,\n                     marker_line_width=1,marker_color='rgb(255,255,255)',marker_line_color='black',\n                    text=df_yt['episode'],showlegend=False))\nfig.add_trace(go.Scatter(name='Mean Impressions',x=df_yt.episode_id,\n                         y=[y_avg]*len(df_yt),mode='lines',marker_color='black',\n                        line = dict(dash='dash')))\nfig.add_trace(go.Scatter(name='Median Impressions',x=df_yt.episode_id,\n                         y=[y_med]*len(df_yt),mode='lines',marker_color='black',\n                        line = dict(dash='dot')))\n# Add image\nfig.add_layout_image(\n    dict(\n        source='https://cdn.icon-icons.com/icons2/1584/PNG/512/3721679-youtube_108064.png',\n        xref=\"paper\", yref=\"paper\",\n        x=1, y=1,\n        sizex=0.2, sizey=0.2,\n        xanchor=\"right\", yanchor=\"bottom\"\n    )\n)\nfig.update_layout(title='<b>Youtube Impressions</b> per Episode',\n                width=700,height=300, barmode='stack',\n                paper_bgcolor=PAPER_BGCOLOR,plot_bgcolor=PLOT_BGCOLOR,hovermode='x unified',\n                margin=dict(t=40,b=0,l=0,r=0),legend=dict(x=0.5,y=1,orientation='h',bgcolor=PLOT_BGCOLOR),\n                xaxis=dict(mirror=True,linewidth=2,linecolor='black',\n                showgrid=False,tickfont=dict(size=8)),\n                yaxis=dict(mirror=True,linewidth=2,linecolor='black',gridcolor='darkgray'))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- `Episode 27` with fast.ai founder **Jeremy Howard** as the guest has recorded the highest number of impressions followed by `Episode 1` featuring the world's first 4x kaggle grandmaster **Abhishek Thakur**. Rest all the episodes have recorded less than 20k impressions.\n- Mean of the impressions is greater than its median, meaning a right-skewed distribution.\n- 50% of the episodes have recorded less than 5096 impressions.\n\nLet's also study about the views per episodes. Since, views are of 2 types: Impression and Non-Impression, I have drawn a stacked bar plot based on percentages instead of numbers to get a better understanding of the views distribution. ","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df_yt['view_perc'] = df_yt.apply(lambda x: np.round(x['youtube_impression_views']/x['youtube_views']*100),axis=1)\ndf_yt['non_view_perc'] = df_yt.apply(lambda x: np.round(x['youtube_nonimpression_views']/x['youtube_views']*100),axis=1)\nfig = go.Figure()\nfig.add_trace(go.Bar(name='Youtube Impression Views',x=df_yt.episode_id,y=df_yt.view_perc,\n                    marker_color='#FF3D09',marker_line_width=1))\nfig.add_trace(go.Bar(name='Youtube Non-Impression Views',x=df_yt.episode_id,y=df_yt.non_view_perc,\n                    marker_color='rgb(255,255,255)',marker_line_width=1))\nfig.add_trace(go.Scatter(name='',x=df_yt.episode_id,y=[50]*len(df_yt),mode='lines',marker_color='black',showlegend=False,\n                        line = dict(dash='dash')))\n# Add image\nfig.add_layout_image(\n    dict(\n        source='https://cdn.icon-icons.com/icons2/1584/PNG/512/3721679-youtube_108064.png',\n        xref=\"paper\", yref=\"paper\",\n        x=1, y=1.05,\n        sizex=0.2, sizey=0.2,\n        xanchor=\"right\", yanchor=\"bottom\"\n    )\n)\nannotations=[]\nannotations.append(dict(xref='x', yref='y',\n                        x='E30', y=55,\n                        text=str(50) + '%',\n                        font=dict(family='Arial', size=20,\n                                color='rgb(0, 0, 0)'),\n                                showarrow=False))\nfig.update_layout(title='<b>Youtube Views</b><br>(Impression vs Non-Impression)',\n                width=700,height=400, barmode='stack',\n                paper_bgcolor=PAPER_BGCOLOR,plot_bgcolor=PLOT_BGCOLOR,hovermode='x unified',\n                margin=dict(t=100,b=0,l=0,r=0),\n                xaxis=dict(mirror=True,linewidth=2,linecolor='black',\n                showgrid=False,tickfont=dict(size=8)),\n                legend=dict(x=0.1,y=-0.1,orientation='h'),annotations=annotations,\n                yaxis=dict(title='Percentage',mirror=True,linewidth=2,linecolor='black',gridcolor='darkgray'))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The plot in red signifies that the video was accessed from youtube only and the plot in white signifies that the video was accessed from elsewhere but youtube.\n\nHere are some of the analysis:\n- Episodes in the starting were accessed more from youtube directly but later on the non-impression views came into majority.\n- All Mini Series(M0-M8) episodes by Jeremy Howard had greater number of impression views than non-impresion views.\n- Earlier, we saw that Episode 27 had the highest number of impressions out of all the episodes released. In the above plot we can see that the views from youtube impressions for this episode is just 29% of the total views. This shows the popularity and reach of fast.ai and its founder as well.\n\n> **Please Note: ** A non-impression view can be anything such as a link shared through an email, article, application e.t.c. And it's necessary to click on that link to count as a view.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## <a id='7.2'>7.2 What influences the CTR?</a>\n<a href='#toc'><span class=\"label label-info\">Go back to the Table of Contents</span></a>\n\nTo answer this question first I'll be studying the relation between impressions and CTR and then analysing CTR per episode. Alongside I've have all included the thumbnail type as I feel that it also has some influence on the CTR.\n\nIdeally, CTR should increase with the increase in impressions. Lets see if its true for all the thumbnail types.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df_lr = df_yt.copy()\ndf_lr['youtube_thumbnail_type']=df_lr['youtube_thumbnail_type'].astype(str)\nfig = px.scatter(df_lr, x=\"youtube_impressions\", y=\"youtube_ctr\", trendline=\"ols\",hover_name=\"episode\",\n                 color='description',color_discrete_sequence=['#0080B7','#FDE803','#7CBB15','#FF3D09'])\nfig.update_traces(marker_line_color='black',marker_line_width=1)\n# Add image\nfig.add_layout_image(\n    dict(\n        source='https://cdn.icon-icons.com/icons2/1584/PNG/512/3721679-youtube_108064.png',\n        xref=\"paper\", yref=\"paper\",\n        x=1, y=1.01,\n        sizex=0.2, sizey=0.2,\n        xanchor=\"right\", yanchor=\"bottom\"\n    )\n)\nfig.update_layout(title='<b>Click-through rate VS Impressions</b>',\n                width=700,height=400,\n                paper_bgcolor=PAPER_BGCOLOR,plot_bgcolor=PLOT_BGCOLOR,hovermode='closest',\n                margin=dict(t=60,b=0,l=0,r=0),\n                xaxis=dict(title='Impressions',mirror=True,linewidth=2,linecolor='black',\n                tickfont=dict(size=10),gridcolor='darkgray'),\n                legend=dict(title='<b>Youtube Thumbnail type</b>',x=0.61,y=1,\n                            bgcolor=PLOT_BGCOLOR,font=dict(size=8)),\n                yaxis=dict(title='Click-through Rate',mirror=True,linewidth=2,\n                           linecolor='black',gridcolor='darkgray'))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- As expected, thumbnail types: `Youtube default image with custom annotation`, `youtube default image` & `Mini Series: custom image with annotations` show a positive correlation between impressions and CTR. On the contrary, the thumbnail type `Custom image with CTDS branding, title and tags` shows a high negative correlation.\n- Thumbnail type `Mini Series: custom image with annotations` shows high positive correlation while `Youtube default image with custom annotation` and `youtube default image` show moderate positive correlation.\n- I believe spending on more impressions for episodes with `Custom image with CTDS branding, title and tags` thumbnail is not a good idea. \n- I would recommend to use youtube default image with or without image annotations as thumbnails. Mini Series thumbnail was a series specific thumbail so that's why would not be recommended.\n\nTo further strengthen the conclusions made by me, I have drawn a bubble plot below which shows the CTR per episode with color repesenting the thumbnail type and the size of the bubble representing the youtube impression views.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig = go.Figure()\nfor thumb_type in df_yt.youtube_thumbnail_type.unique().tolist():\n    group = df_yt[df_yt.youtube_thumbnail_type==thumb_type]\n    fig.add_trace(go.Scatter(name=group.description.iloc[0],x=group.episode_id,y=group.youtube_ctr,\n                        marker_color=group.color,mode='markers',marker_size=group.youtube_impression_views/20,\n                        marker_line_color='black',\n                        text='<b>Episode</b>: '+group.episode.astype(str)+'<br>'+\n                             '<b>Impressions</b>: '+group.youtube_impressions.astype(str)+'<br>'+\n                             '<b>Impression Views</b>: '+group.youtube_impression_views.astype(str)+'<br>'+\n                             '<b>CTR</b>: '+group.youtube_ctr.astype(str),\n                        hoverinfo='text'))\n# Add image\nfig.add_layout_image(\n    dict(\n        source='https://cdn.icon-icons.com/icons2/1584/PNG/512/3721679-youtube_108064.png',\n        xref=\"paper\", yref=\"paper\",\n        x=1, y=1.05,\n        sizex=0.2, sizey=0.2,\n        xanchor=\"right\", yanchor=\"bottom\"\n    )\n)\nfig.update_layout(title='<b>Click-through rate per Episode</b><br>(Size of the bubble represents Youtube impression views)',\n                width=700,height=400,\n                paper_bgcolor=PAPER_BGCOLOR,plot_bgcolor=PLOT_BGCOLOR,hovermode='closest',\n                margin=dict(t=100,b=0,l=0,r=0),\n                xaxis=dict(title='Episodes',mirror=True,linewidth=2,linecolor='black',\n                showgrid=False,tickfont=dict(size=10)),\n                legend=dict(title='<b>Youtube Thumbnail type</b>',x=0.61,y=1,\n                            bgcolor=PLOT_BGCOLOR,font=dict(size=8)),\n                yaxis=dict(title='Click-through rate',mirror=True,linewidth=2,\n                           linecolor='black',gridcolor='darkgray'))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- The youtube default image thumbail has been used the most number of times. In between for some episodes the defuault image with annotations was used as the thumbnail. Now, the thumbail with custom image with CTDS branding, title and tags is used.\n- As can be seen the yellow bubble recorded the highest CTR and also the highest Impression views. Although the range of CTR is not changing much barring one outlier i.e. episode 19 with Chip Huyen as the host.\n- So, the thumbnail type has some effect but not that much as the CTR is more or less the same. Higher CTR is what anyone strives for.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## <a id='7.3'>7.3 Does the episode duration matter?</a>\n<a href='#toc'><span class=\"label label-info\">Go back to the Table of Contents</span></a>\n\nI assume that longer the episode, lesser the number of people watching it. Even if someone very popular is featuring on it then also I believe its very difficult to watch the entire episode on youtube at least. Lets see if my assumption is right or wrong?","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"y_avg = df_yt.youtube_watch_hours.mean()\ny_med = df_yt.youtube_watch_hours.median()\nfig = make_subplots(rows=2,cols=1,shared_xaxes=True,vertical_spacing=0.1)\nfig.add_trace(go.Bar(name='Watch hours(h)',x=df_yt['episode_id'],y=df_yt['youtube_watch_hours'],\n                    marker_line_color='black',marker_line_width=1,\n                    text='<b>Episode</b>: '+df_yt.episode.astype(str)+'<br>'+\n                        '<b>Total Watch Hours</b>: '+df_yt.youtube_watch_hours.astype(str),\n                    hoverinfo='text',marker_color='rgb(255,255,255)'),1,1)\nfig.add_trace(go.Scatter(name='Mean watch hours',x=df_yt.episode_id,\n                         y=[y_avg]*len(df_yt),mode='lines',marker_color='black',\n                        line = dict(dash='dash'),showlegend=False),1,1)\nfig.add_trace(go.Scatter(name='Median watch hours',x=df_yt.episode_id,\n                         y=[y_med]*len(df_yt),mode='lines',marker_color='black',\n                        line = dict(dash='dot'),showlegend=False),1,1)\nfig.add_trace(go.Bar(name='Total Duration(s)',x=df_yt['episode_id'],y=df_yt['episode_duration'],\n                    marker_line_color='black',marker_line_width=1,\n                    text='<b>Episode</b>: '+df_yt.episode.astype(str)+'<br>'+\n                        '<b>Total Duration</b>: '+df_yt.episode_duration.astype(str)+' seconds',\n                    hoverinfo='text',marker_color='#0080B7'),2,1)\nfig.add_trace(go.Bar(name='Average Duration watched(s)',x=df_yt['episode_id'],\n                     marker_line_color='black',marker_line_width=1,\n                     y=df_yt['youtube_avg_watch_duration'],\n                     text='<b>Episode</b>: '+df_yt.episode.astype(str)+'<br>'+\n                        '<b>Avg Duration watched</b>: '+df_yt.youtube_avg_watch_duration.astype(str)+' seconds',\n                     hoverinfo='text',marker_color='#FDE803'),2,1)\n#updates axes\nfig.update_xaxes(mirror=True,linecolor='black',linewidth=2,row=1,col=1,showgrid=False,)\nfig.update_yaxes(title_text='Total hours watched',mirror=True,linecolor='black',linewidth=2,\n                 row=1,col=1,gridcolor='darkgray')\nfig.update_xaxes(mirror=True,linecolor='black',linewidth=2,row=2,col=1,showgrid=False)\nfig.update_yaxes(title_text='Episode Duration<br>(in seconds)',mirror=True,linecolor='black',linewidth=2,\n                 row=2,col=1,gridcolor='darkgray')\n# Add image\nfig.add_layout_image(\n    dict(\n        source='https://cdn.icon-icons.com/icons2/1584/PNG/512/3721679-youtube_108064.png',\n        xref=\"paper\", yref=\"paper\",\n        x=1, y=1,\n        sizex=0.15, sizey=0.15,\n        xanchor=\"right\", yanchor=\"bottom\"\n    )\n)\nfig.update_layout(title='Youtube Watch Analysis',width=700,height=500,margin=dict(t=60,b=0,l=0,r=0),\n                  legend=dict(x=0.1,y=0.54,orientation='h'),barmode='overlay',\n                  plot_bgcolor=PLOT_BGCOLOR,paper_bgcolor=PAPER_BGCOLOR)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- The total watch hours per episode is less than 200 hours for all the episodes but E27. It has a staggering watchtime of 704 hours. Jeremy Howard's episode turns out to be the outlier in every department :P.\n- Although the episode duration is varying a lot but the average duration watched per episode remains quite less and consistent. That means users are watching the initial part of the video.\n- Maybe shortening the videos would help as you can see through the mini series the ratio of average duration watched per total episode length is much better than that of other episodes.\n- Episode 23 with Andreas Torrubia was the longest of all episodes with duration of more than 2 hours.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## <a id='7.4'>7.4 Tracking the User Activity</a>\n<a href='#toc'><span class=\"label label-info\">Go back to the Table of Contents</span></a>\n\nI have always noticed that the views of a youtube video don't do justice to the likes, subscribers and the commnets it has. Similar story is with kaggle as well :P. Lot of views but upvotes and commnets are nowhere to be seen.\n\nLet's see if its the same case with CTDS.show. In the below plot I have drawn two plots on top of each other. The first plot represents the numbers and the second plot represents the percentages with respect to the total views the youtube video got\n\n> **Please Note: ** I have taken the total views as the denominator as a user can't like, dislike, subscribe or comment on the video without opening the video. And only when you open the video it's counted as a View.","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df_yt['like_perc'] = df_yt.apply(lambda x: np.round(x['youtube_likes']/x['youtube_views']*100),axis=1)\ndf_yt['dislike_perc'] = df_yt.apply(lambda x: np.round(x['youtube_dislikes']/x['youtube_views']*100),axis=1)\ndf_yt['comment_perc'] = df_yt.apply(lambda x: np.round(x['youtube_comments']/x['youtube_views']*100),axis=1)\ndf_yt['subscribe_perc'] = df_yt.apply(lambda x: np.round(x['youtube_subscribers']/x['youtube_views']*100),axis=1)\nfig = make_subplots(rows=2,cols=1,shared_xaxes=True,vertical_spacing=0.1)\nfig.add_trace(go.Bar(name='Likes',x=df_yt.episode_id,y=df_yt.youtube_likes,\n                    marker_color='#7CBB15',marker_line_width=1,marker_line_color='black',\n                    text='<b>Episode</b>: '+df_yt.episode.astype(str)+'<br>'+\n                        '<b>Likes</b>: '+df_yt.youtube_likes.astype(str),\n                    hoverinfo='text',legendgroup='like'),1,1)\n\nfig.add_trace(go.Bar(name='Dislikes',x=df_yt.episode_id,y=df_yt.youtube_dislikes,\n                    marker_color='#FF3D09',marker_line_width=1,marker_line_color='black',\n                    text='<b>Episode</b>: '+df_yt.episode.astype(str)+'<br>'+\n                        '<b>Dislikes</b>: '+df_yt.youtube_dislikes.astype(str),\n                    hoverinfo='text',legendgroup='dislike'),1,1)\n\nfig.add_trace(go.Bar(name='Comments',x=df_yt.episode_id,y=df_yt.youtube_comments,\n                    marker_color='gold',marker_line_width=1,marker_line_color='black',\n                    text='<b>Episode</b>: '+df_yt.episode.astype(str)+'<br>'+\n                        '<b>Comments</b>: '+df_yt.youtube_comments.astype(str),\n                    hoverinfo='text',legendgroup='comment'),1,1)\n\nfig.add_trace(go.Bar(name='Subscribers',x=df_yt.episode_id,y=df_yt.youtube_subscribers,\n                    marker_color='#0080B7',marker_line_width=1,marker_line_color='black',\n                    text='<b>Episode</b>: '+df_yt.episode.astype(str)+'<br>'+\n                        '<b>Subscribers</b>: '+df_yt.youtube_subscribers.astype(str),\n                    hoverinfo='text',legendgroup='sub'),1,1)\n\nfig.add_trace(go.Bar(name='Likes%',x=df_yt.episode_id,y=df_yt.like_perc,\n                    marker_color='#7CBB15',marker_line_width=1,marker_line_color='black',\n                    text='<b>Episode</b>: '+df_yt.episode.astype(str)+'<br>'+\n                        '<b>Likes</b>: '+df_yt.like_perc.astype(str)+'%',\n                    hoverinfo='text',legendgroup='like',showlegend=False),2,1)\n\nfig.add_trace(go.Bar(name='Dislikes%',x=df_yt.episode_id,y=df_yt.dislike_perc,\n                    marker_color='#FF3D09',marker_line_width=1,marker_line_color='black',\n                    text='<b>Episode</b>: '+df_yt.episode.astype(str)+'<br>'+\n                        '<b>Dislikes</b>: '+df_yt.dislike_perc.astype(str)+'%',\n                    hoverinfo='text',legendgroup='dislike',showlegend=False),2,1)\n\nfig.add_trace(go.Bar(name='Comments%',x=df_yt.episode_id,y=df_yt.comment_perc,\n                    marker_color='gold',marker_line_width=1,marker_line_color='black',\n                    text='<b>Episode</b>: '+df_yt.episode.astype(str)+'<br>'+\n                        '<b>Comments</b>: '+df_yt.comment_perc.astype(str)+'%',\n                    hoverinfo='text',legendgroup='comment',showlegend=False),2,1)\n\nfig.add_trace(go.Bar(name='Subscribers%',x=df_yt.episode_id,y=df_yt.subscribe_perc,\n                    marker_color='#0080B7',marker_line_width=1,marker_line_color='black',\n                    text='<b>Episode</b>: '+df_yt.episode.astype(str)+'<br>'+\n                        '<b>Subscribers</b>: '+df_yt.subscribe_perc.astype(str)+'%',\n                    hoverinfo='text',legendgroup='sub',showlegend=False),2,1)\n#updates axes\nfig.update_xaxes(mirror=True,linecolor='black',linewidth=2,row=1,col=1,showgrid=False,)\nfig.update_yaxes(title_text='Numbers',mirror=True,linecolor='black',linewidth=2,\n                 row=1,col=1,gridcolor='darkgray')\nfig.update_xaxes(mirror=True,linecolor='black',linewidth=2,row=2,col=1,showgrid=False)\nfig.update_yaxes(title_text='Percentages',mirror=True,linecolor='black',linewidth=2,\n                 row=2,col=1,gridcolor='darkgray')\n# Add image\nfig.add_layout_image(\n    dict(\n        source='https://cdn.icon-icons.com/icons2/1584/PNG/512/3721679-youtube_108064.png',\n        xref=\"paper\", yref=\"paper\",\n        x=1, y=1,\n        sizex=0.15, sizey=0.15,\n        xanchor=\"right\", yanchor=\"bottom\"\n    )\n)\nfig.update_layout(title='Youtube User Activity Analysis',width=700,height=500,margin=dict(t=60,b=0,l=0,r=0),\n                  legend=dict(x=0.2,y=0.54,orientation='h'),barmode='stack',\n                  plot_bgcolor=PLOT_BGCOLOR,paper_bgcolor=PAPER_BGCOLOR)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Again Jeremy Howard's interview(E27) turns out to be the outlier. If you look as the numbers plot it has the tallest tower and that too by a huge margin. It can also attribute to the fact that this episode recorded the highest number of views and impressions.\n- In order to remove this bias of number of views and impressions, I have plotted a percentages plot as well. So, episode E55 and E61 recorded the highest activity i.e.13% of the total views(includes likes, dislikes, subscribers and comments).\n- You can play with the legend of the above plot to find the episode with most comments, likes, dislikes, etc.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# <a id='8'>8. Podcast Analysis</a>\n<a href='#toc'><span class=\"label label-info\">Go back to the Table of Contents</span></a>\n\nSince, I have covered the youtube analysis of the show above, why miss out on the podcasts analysis. The show is available on a plethora of podcasts as mentioned in the [overview section](#1). We have data available for anchor, spotify and apple podcasts. I'll cover the analysis for these three podcasts in separate subsections.","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df_anchor = pd.read_csv('/kaggle/input/chai-time-data-science/Anchor Thumbnail Types.csv')\ndf_anchor = pd.merge(df,df_anchor,on='anchor_thumbnail_type')\ncolors = {0:'#FDE803',1:'#0080B7',2:'#FF3D09',3:'#7CBB15'}\ndf_anchor['color'] = df_anchor.anchor_thumbnail_type.map(colors)\ndf_anchor['ep_no'] = df_anchor.episode_id.apply(lambda x: int(x[1:]) if x[0]=='E' else 75+int(x[1:]))\ndf_anchor.sort_values('ep_no',inplace=True)\ndf_anchor['heroes'] = df_anchor['heroes'].fillna('NaN')\ndf_anchor['episode'] = df_anchor.apply(lambda x: x['episode_id'] + ' | ' + x['heroes'] \n                               if x['heroes']!='NaN' else x['episode_id'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id='8.1'>8.1 Anchor Analysis</a>\n<a href='#toc'><span class=\"label label-info\">Go back to the Table of Contents</span></a>\n\nAnchor is an all-in-one platform where you can create, distribute, and monetize your podcast from any device, for free.I have not heard of this podcast service before but let's see to how people the show has reached through this medium. Also, the show creators have used separate thumbnail types just like in youtube so I'll be studying it's affect as well.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig = go.Figure()\nfor anchor_thumb in df_anchor.anchor_thumbnail_type.unique().tolist():\n    group = df_anchor[df_anchor['anchor_thumbnail_type']==anchor_thumb]\n    fig.add_trace(go.Bar(name=group['description'].iloc[0],x=group.episode_id,y=group.anchor_plays,\n                         marker_color=group.color,marker_line_color='black',marker_line_width=1.5,\n                         text='<b>Episode</b>: '+group.episode.astype(str)+'<br>'+\n                        '<b>Plays</b>: '+group.anchor_plays.astype(str),\n                         hoverinfo='text'\n                        ))\nfig.add_trace(go.Scatter(name='Mean Plays',x=df_anchor.episode_id,y=[df_anchor.anchor_plays.mean()]*len(df_yt),mode='lines',\n                         marker_color='black',showlegend=False,line = dict(dash='dot')))\nfig.add_trace(go.Scatter(name='Median Plays',x=df_anchor.episode_id,y=[df_anchor.anchor_plays.median()]*len(df_yt),mode='lines',\n                         marker_color='black',showlegend=False,line = dict(dash='dash')))\n# Add image\nfig.add_layout_image(\n    dict(\n        source='https://cdn-images-1.medium.com/max/552/1*IR4XyosnuJme7tfZJQByuQ@2x.png',\n        xref=\"paper\", yref=\"paper\",\n        x=1, y=1.03,\n        sizex=0.2, sizey=0.15,\n        xanchor=\"right\", yanchor=\"bottom\"\n    )\n)\nfig.update_layout(title='<b>Anchor Plays per Episode</b>',\n                width=700,height=400,\n                paper_bgcolor=PAPER_BGCOLOR,plot_bgcolor=PLOT_BGCOLOR,hovermode='closest',\n                margin=dict(t=50,b=0,l=0,r=0),\n                xaxis=dict(title='Episodes',mirror=True,linewidth=2,linecolor='black',\n                showgrid=False,tickfont=dict(size=10)),\n                legend=dict(title='<b>Anchor Thumbnail type</b>',x=0.61,y=1,\n                            bgcolor=PLOT_BGCOLOR,font=dict(size=8)),\n                yaxis=dict(title='Anchor Plays',mirror=True,linewidth=2,\n                           linecolor='black',gridcolor='darkgray'))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- The dotted line represents the mean plays and the dash line represents the median plays. The anchor plays have a right skewed distribution.\n- Clearly, the thumbnail with `CTDS branding` & `Youtube defualt playlist image` have been the more successful ones. The most recent thumbnail being used is a custom image with CTDS branding, title and tags.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## <a id='8.2'>8.2 Spotify Analysis</a>\n<a href='#toc'><span class=\"label label-info\">Go back to the Table of Contents</span></a>\n\nSpotify is really famous and it was launched in India a few years back. Let's see how the show fares on Spotify.\n\nWhen you start a spotify podcast it is counted as a **spotify start** and if you listen to it more than 60 seconds then it is counted as a **spotify stream**. The number of unique people listening to the podcasts are called **listeners**. I have tried to study these using the bar plot below.","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = go.Figure()\nfig.add_trace(go.Bar(name='Starts',x=df_anchor.episode_id,y=df_anchor.spotify_starts,\n                         marker_color='rgb(255,255,255)',\n                         text='<b>Episode</b>: '+df_anchor.episode.astype(str)+'<br>'+\n                        '<b>Starts</b>: '+df_anchor.spotify_starts.astype(str),\n                         hoverinfo='text'\n                        ))\nfig.add_trace(go.Bar(name='Streams',x=df_anchor.episode_id,y=df_anchor.spotify_streams,\n                         marker_color='#1DB954',\n                         text='<b>Streams</b>: '+df_anchor.spotify_streams.astype(str),\n                         hoverinfo='text'\n                        ))\nfig.add_trace(go.Scatter(name='Listeners',x=df_anchor.episode_id,y=df_anchor.spotify_listeners,mode='lines',\n                         text='<b>Listeners</b>: '+df_anchor.spotify_listeners.astype(str),\n                         hoverinfo='text',marker_color='black',line = dict(dash='dot')))\n# Add image\nfig.add_layout_image(\n    dict(\n        source='https://www.scdn.co/i/_global/open-graph-default.png',\n        xref=\"paper\", yref=\"paper\",\n        x=1, y=1.03,\n        sizex=0.2, sizey=0.15,\n        xanchor=\"right\", yanchor=\"bottom\"\n    )\n)\nfig.update_layout(title='<b>Spotify Statistics per Episode</b>',\n                width=700,height=400,barmode='overlay',\n                paper_bgcolor=PAPER_BGCOLOR,plot_bgcolor=PLOT_BGCOLOR,hovermode='x unified',\n                margin=dict(t=50,b=0,l=0,r=0),\n                xaxis=dict(title='Episodes',mirror=True,linewidth=2,linecolor='black',\n                showgrid=False,tickfont=dict(size=10)),\n                legend=dict(x=0.82,y=1,bgcolor=PLOT_BGCOLOR,font=dict(size=12)),\n                yaxis=dict(title='Starts/Streams/Listeners',mirror=True,linewidth=2,\n                           linecolor='black',gridcolor='darkgray'))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- The number of listeners are in accordance with the number of starts and streams. It's pretty obvious though.\n- CTDS.show seems to be more popular on anchor.fm as compared with spotify as the maximum number of starts recorded is 826 and for anchor it is almost double that is 1527.\n- This is the first plot where I have seen Jeremy Howard's episode(E27) being the undisputed number 1. In spotify paradigm clearly the episode with Abhshek Thakur(E1) tops the list that too convincingly.\n- Almost 20% of people close the podcast before 60 seconds. Still not a bad number. On youtube it's much worse. So, it seems mpre serious audiance is on spotify.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## <a id='8.3'>8.3 Apple Podcast Analysis</a>\n<a href='#toc'><span class=\"label label-info\">Go back to the Table of Contents</span></a>\n\n![](http://)Now, we come to the final podcast for which the data is available. I have with me available the total hours listened, the average duration of the episode listened in seconds and the number of listeners. To accomodate everything into the same plot I have changed the scale of y-axis to logarithmic type. Total hours listened is converted to seconds.","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = go.Figure()\nfig.add_trace(go.Bar(name='Total seconds listened',x=df_anchor.episode_id,y=df_anchor.apple_listened_hours*60*60,\n                         marker_color='rgb(255,255,255)',\n                         text='<b>Episode</b>: '+df_anchor.episode.astype(str)+'<br>'+\n                        '<b>Total listened</b>: '+(df_anchor.apple_listened_hours).astype(str)+' hours',\n                         hoverinfo='text'\n                        ))\nfig.add_trace(go.Bar(name='Average listen duration in seconds',x=df_anchor.episode_id,y=df_anchor.apple_avg_listen_duration,\n                         marker_color='#D56DFB',\n                         text='<b>Average listened</b>: '+df_anchor.apple_avg_listen_duration.astype(str)+' seconds',\n                         hoverinfo='text'\n                        ))\nfig.add_trace(go.Scatter(name='Listeners',x=df_anchor.episode_id,y=df_anchor.apple_listeners,mode='lines',\n                         text='<b>Listeners</b>: '+df_anchor.apple_listeners.astype(str),\n                         hoverinfo='text',marker_color='black',line = dict(dash='dot')))\n# Add image\nfig.add_layout_image(\n    dict(\n        source='https://is1-ssl.mzstatic.com/image/thumb/Purple113/v4/22/8d/49/228d49f8-0798-bfdb-7f4a-59039f7d102f/AppIcon-0-1x_U007emarketing-0-0-GLES2_U002c0-512MB-sRGB-0-0-0-85-220-0-0-0-10.png/246x0w.png',\n        xref=\"paper\", yref=\"paper\",\n        x=1, y=1.02,\n        sizex=0.2, sizey=0.15,\n        xanchor=\"right\", yanchor=\"bottom\"\n    )\n)\nfig.update_layout(title='<b>Apple Podcasts Statistics per Episode</b>',\n                width=700,height=400,barmode='overlay',\n                paper_bgcolor=PAPER_BGCOLOR,plot_bgcolor=PLOT_BGCOLOR,hovermode='x unified',\n                margin=dict(t=50,b=0,l=0,r=0),\n                xaxis=dict(title='Episodes',mirror=True,linewidth=2,linecolor='black',\n                showgrid=False,tickfont=dict(size=10)),\n                legend=dict(x=0.35,y=1,bgcolor=PLOT_BGCOLOR,font=dict(size=8),orientation='h'),\n                yaxis=dict(type='log',title='Total listened/Average Listened/Listeners',mirror=True,linewidth=2,\n                           linecolor='black',gridcolor='darkgray',title_font=dict(size=9)))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Apple podcast seems to be the least popular in front of anchor and spotify as the maximum number of listeners(96) were recorded for Jeremy Howard's episode(E27).\n- One thing that is different from all other mediums is that in case of apple podcasts, the stats are more or less consistent throughout all the episodes. This can also be attributed to the less usage.\n- E53 and E75 had no listeners. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# <a id='9'>9. Show Analysis</a>\n<a href='#toc'><span class=\"label label-info\">Go back to the Table of Contents</span></a>\n\nYou must be thinking that I have covered almost all the aspects of the show from timeline to flavours of the tea, but haven't really laid emphasis on what actually the host Sanyam Bhutani and our heroes talk about. So, this is where I'll be doing the analysis on the show. \n\nThanks to the dataset provider [Rohan Rao](https://www.kaggle.com/rohanrao) for providing the access to all the episode subtitles as well.I will be using the same for my analysis. I plan to first analyse Sanyam's behaviour, then move on to compare the verbosity of our heroes, and finally look into what do they talk about.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## <a id='9.1'>9.1 Understanding the host: Sanyam Bhutani</a>\nI 'll be analysing the behaviour of Sanyam here. I'm taking the speak time into consideration here. Studying the variation in the speak time can help me to decipher the behaviour of the host: whether it changes with respect to the guest or not.  \n\nSince, this is a talk show pertaining to Data Science(ofcourse the name is Chai time data science show), I believe the host will ask the guest speakers(Heroes) about their journey and what motivated them to continue doing whatever they are doing and so on. Therefore, there would be a standard set of questions to be asked. This means that the speak time for the host would more or less be equal for all the episodes. Let's see I'm right or wrong? ","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def get_seconds(x):\n    l = list(map(int,x.split(':')))\n    if len(l) == 3:\n        return l[0]*3600 + l[1]*60 + l[2]\n    else:\n        return l[0]*60 + l[1]\n\ndef get_speaker_data(filename,episode_id,duration):\n    df = pd.read_csv(filename)\n    df['start_time'] = df['Time'].apply(lambda x: get_seconds(x))\n    df['end_time'] = df['start_time'].shift(-1).fillna(duration).astype(int)\n    df['time_spoken'] = df['end_time'] - df['start_time']\n    df['Episode'] = episode_id\n    df = df.groupby(['Episode','Speaker'],as_index=False)['time_spoken'].sum()\n    df['duration'] = duration\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"path = '/kaggle/input/chai-time-data-science/Cleaned Subtitles/'\ndf_durations = pd.DataFrame(columns=['Episode','Speaker','time_spoken','duration'])\nfor idx in range(len(df)):\n    episode_id = df.loc[idx,'episode_id']\n    filename = os.path.join(path,episode_id+'.csv')\n    if os.path.exists(filename):\n        df_sub = get_speaker_data(filename,episode_id,df.loc[idx,'episode_duration'])\n        df_durations = df_durations.append(df_sub)\ndf_durations.reset_index(drop=True,inplace=True)\ndf_durations['time_spoken'] = df_durations['time_spoken'].astype(int)\ndf_durations['duration'] = df_durations['duration'].astype(int)\ndf_durations['spoken%'] = df_durations['time_spoken']/df_durations['duration']\ndf_durations['id'] = df_durations['Episode'].apply(lambda x: int(x[1:]))\nlast_episode = ''\nfor idx in range(len(df_durations)):\n    if df_durations.loc[idx,'Speaker'] == 'Sanyam Bhutani':\n        df_durations.loc[idx,'Host'] = 0\n    else:\n        if last_episode != df_durations.loc[idx,'Episode']:\n            last_episode = df_durations.loc[idx,'Episode']\n            i = 1\n        else:\n            i+=1\n        df_durations.loc[idx,'Host'] = i\ndf_durations['Host'] = df_durations['Host'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df_durations['time_spoken_minutes'] = round(df_durations['time_spoken']/60,1)\ncolors = {0:'#E6774A',1:'#FEE6BA',2:'#EEB534',3:'#5C4F7A',4:'#6486A5'}\nfig = go.Figure()\nfor host in sorted(df_durations.Host.unique().tolist()):\n    if host==0:\n        name='Sanyam Bhutani'\n    else:\n        name='Hero '+str(host)\n    group = df_durations[df_durations['Host']==host]\n    fig.add_trace(go.Bar(name=name,x=group['Episode'],y=group['time_spoken'],\n                        marker_color=colors[host],\n                        #marker_line_color='black',marker_line_width=1.5,\n                        text='<b>Speaker</b>: '+group['Speaker']+'<br>'+\n                        '<b>Time Spoken</b>: '+(group['time_spoken_minutes']).astype(str)+ ' minutes'+'<br>'+\n                        '<b>Total Show Duration</b>: '+round(group['duration']/60,1).astype(str)+ ' minutes'))\nfig.update_layout(title='<b>Time Spoken per Episode</b>',\n                width=700,height=400,barmode='stack',\n                paper_bgcolor=PAPER_BGCOLOR,plot_bgcolor=PLOT_BGCOLOR,hovermode='x unified',\n                margin=dict(t=50,b=0,l=0,r=0),\n                xaxis=dict(title='Episodes',mirror=True,linewidth=2,linecolor='black',\n                showgrid=False,tickfont=dict(size=10)),\n                legend=dict(title='<b>   Who is Speaking?</b>',x=0.1,y=1,orientation='h',\n                            bgcolor=PLOT_BGCOLOR,font=dict(size=8)),\n                yaxis=dict(title='Time Spoken<br>(in seconds)',mirror=True,linewidth=2,\n                           range=[0,9000],linecolor='black',gridcolor='darkgray'))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- I believe I'm somewhat right as the height of orange bars is consistent throughout all the episodes. Non-orange bars are inconsistent(Maybe some heroes speak less and some more :p). The consistent speaktime shows that Sanyam is focussed and doesn't digress from the topic irrespective of whom he's interviewing. Ignore Episode 69 as it was Birthday Special AMA by Sanyam Bhutani.\n- Episode 44 with Radek and Episode 49 with Parul Pandey seem to be 2 anomalies. Here, Sanyam's speak time is quite high.\n- The total bar height is different because of the varying episode duration. Episode 23 was the longest one with duration of more than 2 hours and Episode 65 was the shortest with duration of 33 minutes.\n- Different colors correspond to different guest. Episode 67 saw 4 guests while most of the episodes has a single guest.\n- For some episodes there is some speak time for Unknown Speaker as well. I haven't watched all the episodes. So, assuming maybe some people appear on the show to ask some questions.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## <a id='9.2'> 9.2 Verbosity of our Heroes</a>\n<a href='#toc'><span class=\"label label-info\">Go back to the Table of Contents</span></a>\n\n**Who speaks more and who speaks less? Lets find out!**\nAs we saw in the previous section that the speak time for heroes varied a lot while Sanyam's speak time remained almost consistent, definitely some heroes are more verbose than others. Also, due to different episode durations I wasn't able to put my point forward in the previous section.\n\nHere, I have used percentage spoken into consideration. This removes the bias due to the episode length.","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"colors = {0:'#e87d22',1:'#FEE6BA',2:'#EEB534',3:'#5C4F7A',4:'#6486A5'}\nfig = go.Figure()\nfor host in sorted(df_durations.Host.unique().tolist()):\n    if host==0:\n        name='Sanyam Bhutani'\n    else:\n        name='Hero '+str(host)\n    group = df_durations[df_durations['Host']==host]\n    fig.add_trace(go.Bar(name=name,x=group['Episode'],y=group['spoken%']*100,\n                        marker_color=colors[host],\n                        #marker_line_color='black',marker_line_width=1.5,\n                        text='<b>Speaker</b>: '+group['Speaker']+'<br>'+\n                        '<b>Time Spoken</b>: '+(group['time_spoken_minutes']).astype(str)+ ' minutes'+'<br>'+\n                        '<b>Total Show Duration</b>: '+round(group['duration']/60,1).astype(str)+ ' minutes'+'<br>'+\n                        '<b>Spoken%</b>: '+round(group['spoken%']*100,2).astype(str)+ '%'))\nfig.add_trace(go.Scatter(name='',x=df_durations['Episode'],y=[25]*len(df_durations),mode='lines',\n                         marker_color='black',showlegend=False,line = dict(dash='dash')))\nannotations=[]\nannotations.append(dict(xref='x', yref='y',\n                        x='E25', y=30,\n                        text=str(25) + '%',\n                        font=dict(family='Arial', size=20,\n                                color='rgb(0, 0, 0)'),\n                                showarrow=False))\nfig.update_layout(title='<b>Spoken% per Episode</b>',\n                width=700,height=400,barmode='stack',\n                paper_bgcolor=PAPER_BGCOLOR,plot_bgcolor=PLOT_BGCOLOR,hovermode='x unified',\n                margin=dict(t=50,b=0,l=0,r=0),\n                xaxis=dict(title='Episodes',mirror=True,linewidth=2,linecolor='black',\n                showgrid=False,tickfont=dict(size=10)),annotations=annotations,\n                legend=dict(title='<b>   Who is<br>Speaking?</b>',x=0.35,y=1.15,orientation='h',\n                            bgcolor=PAPER_BGCOLOR,font=dict(size=6)),\n                yaxis=dict(title='Spoken %',mirror=True,linewidth=2\n                           ,linecolor='black',gridcolor='darkgray'))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- The plot above again proves Sanyam's consistency. His speak time is less than 25% for majority of episodes.\n- Dmitry Larko is the most verbose of the lot. He spoke for 94.24% of Episode 74's length(67.2 minutes).\n- Parul Pandey is the least verbose of the lot. She spoke for 38.54% of Episode 49's length(59.5 minutes).\n- So, our heroes showcase a huge range of verbosity. Beauty in Diversity. Rightly said! ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## <a id='9.3'> 9.3 What's all the talk about?</a>\n<a href='#toc'><span class=\"label label-info\">Go back to the Table of Contents</span></a>\n\nI believe best way to judge this is to answer this by looking at the keywords used and the best way to look at and showcase the keywords is by drawing a word cloud.\n\nIt's not feasible for me as well as not that intuitive to show word clouds for each episode as there are 75 in total. In this section, I'll be showing 3 wordclouds.\n\nFirst, showing the keywords used for all the 75 Episodes.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def get_episode_text(episodes=[]):\n    text = ''\n    path = '/kaggle/input/chai-time-data-science/Cleaned Subtitles/'\n    if len(episodes) == 0:\n        episodes = df.episode_id.unique().tolist()\n    for episode in episodes:\n        filepath = os.path.join(path,episode+'.csv')\n        if os.path.exists(filepath):\n            subtitles = pd.read_csv(filepath)\n            text += ' '.join(subtitles.Text.tolist())\n    return text\n\ndef chai_word_cloud(text):\n    # read the mask image\n    url = 'https://www.pngmart.com/files/5/Tea-Cup-PNG-File.png'\n    mask = np.array(Image.open((requests.get(url, stream=True).raw)))\n    #add stopwords\n    stopwords = list(STOPWORDS)\n    stopwords += ['thing','really','something','maybe','right','actually','think','stuff','people']\n    wc = WordCloud(background_color=\"white\",width=1500,height=1000, max_words=2000, mask=mask,\n               stopwords=stopwords, min_word_length=5, contour_width=3, contour_color='steelblue')\n\n    # generate word cloud\n    wc.generate(text)\n    return wc\n\ndef display_wordcloud(wc, title=None, figure_size=(24,16)):\n    plt.figure(figsize=figure_size)\n    plt.imshow(wc);\n    plt.title(title, fontdict={'size': 40, 'color': 'black', \n                                  'verticalalignment': 'bottom'})\n    plt.axis('off');\n    plt.tight_layout()\n\ntext = get_episode_text()\nwc = chai_word_cloud(text)\ndisplay_wordcloud(wc,title='All Episodes')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Second, showing the keywords used in Episode 1 with Abhishek Thakur as the guest.","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"text = get_episode_text(['E1'])\nwc = chai_word_cloud(text)\ndisplay_wordcloud(wc,title='Episode with Abhishek Thakur')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Third, showing the keywords used in Episode 2 with Jeremy Howard as the guest. \nI have chosen these episodes(E1 & E2) as these 2 turned out to be outliers in the analysis done above.","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"text = get_episode_text(['E27'])\nwc = chai_word_cloud(text)\ndisplay_wordcloud(wc,title='Episode with Jeremy Howard')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***So, that's all for now. I hope I was able to provide some helpful insights. Kudos to the show organizers for conducting such an amazing competition. Loved being part of it!!***\n\n<img src='https://st4.depositphotos.com/11223306/24222/v/600/depositphotos_242223232-stock-video-thank-you-handwriting-effect-animation.jpg'/>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Thanks for reading this far. Do leave an upvote in case you liked it. It will motivate me to produce more quality content.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}