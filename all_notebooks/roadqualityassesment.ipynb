{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Road quality assesment based on vehicle speed\n\nCommon sense tells us that whether dirt road conditions are bad, an average driver will slow down in order to avoid damage in his vehicle. In this notebook, I'll try to validate this hypothesis using available data of car speed along dirt roads.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.cluster import DBSCAN\nimport os\n\n\n# Folder\tCar\t\t\t\tDriver\t\tScenario\tDistance\n#----------------------------------------------------------------\n#PVS 1\t\tVW Saveiro\t\tDriver 1\tScenario 1\t13.81 km\n#PVS 2\t\tVW Saveiro\t\tDriver 1\tScenario 2\t11.62 km\n#PVS 3\t\tVW Saveiro\t\tDriver 1\tScenario 3\t10.72 km\n#PVS 4\t\tFiat Bravo\t\tDriver 2\tScenario 1\t13.81 km\n#PVS 5\t\tFiat Bravo\t\tDriver 2\tScenario 2\t11.63 km\n#PVS 6\t\tFiat Bravo\t\tDriver 2\tScenario 3\t10.73 km\n#PVS 7\t\tFiat Palio\t\tDriver 3\tScenario 1\t13.78 km\n#PVS 8\t\tFiat Palio\t\tDriver 3\tScenario 2\t11.63 km\n#PVS 9\t\tFiat Palio\t\tDriver 3\tScenario 3\t10.74 km\n\n### CONSTANTS\n\nroot_dir = '/kaggle/input/pvs-passive-vehicular-sensors-datasets/PVS'        \n\nfilenames = [ # Datasets file names\n    'video_environment_dataset_left.mp4', # 0\n    'video_environment_dataset_right.mp4', # 1\n    'video_environment.mp4', # 2\n    'dataset_gps.csv', # 3 - GPS data, including latitude, longitude, altitude, speed, accuracy, etc.\n    'dataset_labels.csv', # 4 - Data classes for each sample data in the dataset (for both sides).\n    'dataset_gps_mpu_left.csv', # 5 - Inertial sensor data on the left side of the vehicle, combined with GPS data.\n    'dataset_settings_left.csv', # 6\n    'dataset_mpu_right.csv', # 7\n    'video_dataset_left.mp4', # 8\n    'map.html', # 9\n    'dataset_mpu_left.csv', # 10\n    'dataset_settings_right.csv', # 11\n    'dataset_gps_mpu_right.csv', # 12 - Inertial sensor data on the right side of the vehicle, combined with GPS data.\n    'video_dataset_right.mp4' # 13\n]\n\n# List of all columns from file 5 or 12\nall_columns = ['timestamp', 'acc_x_dashboard', 'acc_y_dashboard', 'acc_z_dashboard',\n       'acc_x_above_suspension', 'acc_y_above_suspension',\n       'acc_z_above_suspension', 'acc_x_below_suspension',\n       'acc_y_below_suspension', 'acc_z_below_suspension', 'gyro_x_dashboard',\n       'gyro_y_dashboard', 'gyro_z_dashboard', 'gyro_x_above_suspension',\n       'gyro_y_above_suspension', 'gyro_z_above_suspension',\n       'gyro_x_below_suspension', 'gyro_y_below_suspension',\n       'gyro_z_below_suspension', 'mag_x_dashboard', 'mag_y_dashboard',\n       'mag_z_dashboard', 'mag_x_above_suspension', 'mag_y_above_suspension',\n       'mag_z_above_suspension', 'temp_dashboard', 'temp_above_suspension',\n       'temp_below_suspension', 'timestamp_gps', 'latitude', 'longitude',\n       'speed']\n\ndrivers = ['D1 VW Saveiro','D1 VW Saveiro','D1 VW Saveiro',\n           'D2 Fiat Bravo','D2 Fiat Bravo','D2 Fiat Bravo',\n           'D3 Fiat Palio','D3 Fiat Palio','D3 Fiat Palio']\n\nscenarios = ['Scenario 1', 'Scenario 2', 'Scenario 3',\n             'Scenario 1', 'Scenario 2', 'Scenario 3',\n             'Scenario 1', 'Scenario 2', 'Scenario 3']\n\n# Data tags (from dataset_labels.csv)\nroad_classes = ['dirt_road', 'cobblestone_road', 'asphalt_road']\nquality_left_classes = ['good_road_left', 'regular_road_left', 'bad_road_left']\nquality_right_classes = ['good_road_right', 'regular_road_right', 'bad_road_right']\nother_classes = ['paved_road', 'unpaved_road', 'no_speed_bump', 'speed_bump_asphalt', 'speed_bump_cobblestone']\n\n# Helper functions\ndef list_files(): # For unknown directory content\n    for dirname, _, filenames in os.walk('/kaggle/input'):\n        for filename in filenames:\n            print(os.path.join(dirname, filename))\n\ndef list_files2(fn, filenames): # For known directory content (requires number of folders and filenames)\n    for k in range(1,fn):\n        for f in filenames:\n            print('{} {}/{}'.format(root_dir, k, f))\n            \ndef load_file(k, f, filenames): # Cargar dataset f de experimento k\n    data = pd.read_csv('{} {}/{}'.format(root_dir, k, filenames[f]))\n    return data\n        \ndef save_csv(dataframe, filename): # For export a dataframe to csv file\n    dataframe.to_csv(filename, index = False)\n    \ndef one_hot_to_label(df_in, classes, df_out, class_name): # Convert encoding type\n    conditions = []\n    for r in classes:\n        conditions.append(df_in[r] == 1)\n    df_out[class_name] = np.select(conditions, classes)\n    return df_out\n    \nprint(\"Ready.\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Generate a single dataset containing all the relevant information for the analysis\n\nCombining all nine observations and selecting columns with gps, speed, acceleration and label tags, we build a single dataset.","metadata":{}},{"cell_type":"code","source":"# Columns to use from datasets from file 5 or 12 (both should have same values on these columns)\nuse_columns = [\n    'timestamp',\n    'latitude',\n    'longitude',\n    'speed' # m/s\n]\n# Columns to drop from datasets\ndrop_columns = [c for c in all_columns if c not in use_columns]\n\n# Columns with accelerometer values\nacc_columns = [\n    'acc_x_dashboard', 'acc_y_dashboard', 'acc_z_dashboard',\n    'acc_x_above_suspension', 'acc_y_above_suspension',\n    'acc_z_above_suspension', 'acc_x_below_suspension',\n    'acc_y_below_suspension', 'acc_z_below_suspension'\n]\n\n# If only vertical\n# acc_columns = ['acc_z_dashboard','acc_z_above_suspension', 'acc_z_below_suspension']\n\n\nacc_axis = len(acc_columns)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nall_data = [] # New dataframe containing all data\n\nfor k in range(1,10):\n    # Load labels dataset\n    dataset_labels = load_file(k, 4, filenames)\n    labels_only = pd.DataFrame(columns = ['road', 'quality_right', 'quality_left']) # Convert from one-hot to label\n    \n    # Convert from one-hot encoding to single label encoding\n    labels_only = one_hot_to_label(dataset_labels, road_classes, labels_only, 'road')\n    labels_only = one_hot_to_label(dataset_labels, quality_right_classes, labels_only, 'quality_right')\n    labels_only = one_hot_to_label(dataset_labels, quality_left_classes, labels_only, 'quality_left')\n\n    # Convert road quality labels to numeric values\n    labels_only = labels_only.replace({'quality_right' : { 'good_road_right' : 2, 'regular_road_right' : 1, 'bad_road_right' : 0 }})\n    labels_only = labels_only.replace({'quality_left' : { 'good_road_left' : 2, 'regular_road_left' : 1, 'bad_road_left' : 0 }})\n    \n    # Average road quality\n    labels_only['quality'] = labels_only.loc[: , \"quality_right\":\"quality_left\"].mean(axis=1)\n    \n    # Drop quality columns\n    labels_only = labels_only.drop(columns = [\"quality_right\",\"quality_left\"], axis = 1)\n    \n    # Add columns for driver and scenario\n    labels_only['driver'] = pd.Series([drivers[k-1] for _ in range(len(labels_only.index))])    \n    labels_only['scenario'] = pd.Series([scenarios[k-1] for _ in range(len(labels_only.index))])    \n\n    # Load gps dataset (only left, as should be the same as right side)\n    dataset_gps_left = load_file(k,5, filenames)\n    dataset_gps_right = load_file(k, 12, filenames)\n    \n    # Sum absolute values of all 18 accelerometers and combine in a single column (divided by number of axis (9))\n    sum_left = dataset_gps_left[acc_columns].abs().sum(axis=1).div(acc_axis)\n    sum_right = dataset_gps_right[acc_columns].abs().sum(axis=1).div(acc_axis)\n    \n    dataset_gps = dataset_gps_left.drop(columns = drop_columns, axis = 1)\n    dataset_gps['acceleration'] = pd.concat([sum_left, sum_right], axis=1).mean(axis=1)\n\n    # Add labels and quality labels\n    temp = pd.concat([dataset_gps, labels_only], axis = 1)\n    if len(all_data) == 0: # First create, then concatenate\n        all_data = temp\n    else:\n        all_data = pd.concat([all_data, temp], axis = 0)\n\n# To remove multiple and repeated indexes\nall_data.reset_index(drop = True, inplace = True)\n# Print results\nall_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Export resulting dataset\n#save_csv(all_data, 'road_data.csv')  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Show element counts\nprint('Road types:')\nprint(all_data['road'].value_counts())\nprint('\\nDrivers:')\nprint(all_data['driver'].value_counts())\nprint('\\nScenarios:')\nprint(all_data['scenario'].value_counts())\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display some basic column-wise statistics\nall_data.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploratory Data Analysis","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Road types\nRoad types are classified according to the road surface as 'Asphalt', 'Cobblestone' and 'Dirt'. The pie chart below shows the proportion of data that correspond to each class.\n","metadata":{}},{"cell_type":"code","source":"# Road types proportion\nfig, ax = plt.subplots(1,1)\nfig.set_figheight(10)\nfig.set_figwidth(10)\nfig.set_facecolor((1.0, 1.0, 1.0))\n\ngrouped = all_data['road'].value_counts()\nplt.pie(grouped, labels = grouped.index, autopct = '%1.1f%%');\nplt.axis('equal')\nplt.title('Road types')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Road quality of different road types\n\nData  is labeled according to the road condition. For left and right sides of the car, road quality is labeled as 'Good', 'Regular' or 'Bad'. Values are converted to numeric type and the average between both sides is used. Pie charts below, shows the data proportions that corresponds to each label.","metadata":{}},{"cell_type":"code","source":"# Road quality proportions for each road type\nfig, ax = plt.subplots(1,3)\nfig.set_figheight(10)\nfig.set_figwidth(25)\nfig.suptitle('Road quality proportions')\nfig.set_facecolor((1.0, 1.0, 1.0))\n\t\ndirt_grouped = all_data.loc[all_data['road']=='dirt_road']['quality'].value_counts()\nasphalt_grouped = all_data.loc[all_data['road']=='asphalt_road']['quality'].value_counts()\ncobblestone_grouped = all_data.loc[all_data['road']=='cobblestone_road']['quality'].value_counts()\n\nmap_values = {'0.0':'Bad', '0.5':'Regular bad', '1.0':'Regular', '1.5':'Regular good', '2.0':'Good'}\n\nax[0].pie(dirt_grouped, labels = [map_values[str(k)] for k in dirt_grouped.index], autopct = '%1.1f%%');\nax[0].set_title('Dirt road')\nax[1].pie(asphalt_grouped, labels = [map_values[str(k)] for k in asphalt_grouped.index], autopct = '%1.1f%%');\nax[1].set_title('Asphalt road')\nax[2].pie(cobblestone_grouped, labels = [map_values[str(k)] for k in cobblestone_grouped.index], autopct = '%1.1f%%');\nax[2].set_title('Cobblestone road')\n\nplt.show()\t","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### We can see that 'Dirt road' class have the higher proportion of bad quality. This means that the labels are a general indicator of road condition and are not relative to each road type.","metadata":{}},{"cell_type":"markdown","source":"# Speed vs road quality\nLets check if the acquired speed data has some correlation with road quality for different road types.","metadata":{}},{"cell_type":"code","source":"moving_data = all_data.loc[all_data['speed']>1] # Discard data when car is stopped\nprint('Discarded {:.2f}% of data'.format((1 - len(moving_data)/len(all_data))*100)) # Porcentage of discarded data\n\n# Data distribution for different road types\nfig, ax = plt.subplots(2,1)\nfig.set_figheight(20)\nfig.set_figwidth(15)\n\nplt.subplot(2,1,1)\nsns.boxplot(x=\"quality\", y=\"speed\", hue=\"road\", data=moving_data)\nplt.title('Speed vs road quality')\nplt.grid()\n\nplt.subplot(2,1,2)\nsns.violinplot(x=\"quality\", y=\"speed\", hue=\"road\", data=moving_data)\nplt.title('Speed vs road quality')\nplt.grid()\n\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### We can see that speed recorded is higher for asphalt road, and for cobblestone and dirt road, speed is higher when the quality is better, except for good quality labeled data. This could mean that there are sections traveled at slow speed where road was labeled as good.","metadata":{}},{"cell_type":"markdown","source":"# Acceleration vs road quality\nSame as previous analysis but using acceleration values.","metadata":{}},{"cell_type":"code","source":"# Data distribution for different road types\nfig, ax = plt.subplots(2,1)\nfig.set_figheight(20)\nfig.set_figwidth(15)\nfig.suptitle(\"Acceleration vs road quality\")\n\nplt.subplot(2,1,1)\nsns.boxplot(x=\"quality\", y=\"acceleration\", hue=\"road\", data=moving_data)\nplt.grid()\n\nplt.subplot(2,1,2)\nsns.violinplot(x=\"quality\", y=\"acceleration\", hue=\"road\", data=moving_data)\nplt.grid()\n\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Here we see that for cobblestone and dirt road, acceleration values have a higher amplitude than asphalt roads, which makes sense. The next plot shows acceleration data distribution for each road type, which reaffirms this observation.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,10))\nplt.title('Acceleration distribution on different roads')\nmoving_data.loc[moving_data['road']=='asphalt_road']['acceleration'].hist(bins = 20)    \nmoving_data.loc[moving_data['road']=='dirt_road']['acceleration'].hist(bins = 20)    \nmoving_data.loc[moving_data['road']=='cobblestone_road']['acceleration'].hist(bins = 20)    \nplt.legend(['Asphalt', 'Dirt', 'Cobblestone'])\nplt.xlabel('Acceleration')\nplt.ylabel('Frequency')\nplt.show()\t","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# From now on, lets focus on dirt road only\n","metadata":{}},{"cell_type":"code","source":"dirt_data = moving_data.loc[moving_data['road']=='dirt_road']\ndirt_data.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Trajectory identification\n\nThe goal is to plot speed variations of every driver along a continuous path or trajectory, so first we need to isolate and identify data corresponding to each one.\n","metadata":{}},{"cell_type":"code","source":"# Plot gps data\n\nnot_dirt_data = moving_data.loc[(moving_data[\"road\"] == \"cobblestone_road\") | (moving_data[\"road\"] == \"asphalt_road\")]\n\n# Plot road paths coloring scenarios of dirt road.\nplt.figure(figsize=(10,10))\n# Plot other road types first\nplt.scatter(not_dirt_data['longitude'], not_dirt_data['latitude'], c = \"gray\", label = 'Other roads')\n# Add the dirt road paths\ncolors = {'Scenario 1': 'red', 'Scenario 2': 'blue', 'Scenario 3': 'green'}\nfor c in colors:\n    d = dirt_data.loc[dirt_data['scenario'] == c]\n    plt.scatter(d['longitude'], d['latitude'], c = colors[c], label = c)\n\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Label data based on timestamp discontinuities\n\npd.options.mode.chained_assignment = None  # For using .at for assignment\n\nlast_label = 0\nlast_timestamp = 0\nthres = 120 # 2 minutes\nfor index, row in dirt_data.iterrows():\n    if row[\"timestamp\"]-last_timestamp > thres:\n        last_label = last_label+1\n    dirt_data.at[index, \"label\"] = \"path_{}\".format(last_label)\n    last_timestamp = row[\"timestamp\"]\n\n#print(dirt_data.head())\nprint(\"Total labels = {}\".format(last_label))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Here we have isolated 18 different trajectories. We know that there are three drivers, and each one traveled the same route at least once, so we identify each one based on number of total rows or data observations. \n### The best approach could involve some geospatial data clustering, but for now, lets keep this simple.","metadata":{}},{"cell_type":"code","source":"# Determine trajectories of interest\ngrouped = dirt_data.groupby(\"label\") # Group data according to trajectory label\nsgrouped = sorted(grouped, key = lambda x: len(x[1]), reverse=True) # Sort by number of rows\n\n# Print number of rows of each group\nprint(\"Label\\t\\tSize\")\nfor index, g in sgrouped:\n    print(\"{}\\t\\t{}\".format(index,len(g)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### For determining traveled distance from gps data, we need the Haversine equation:","metadata":{}},{"cell_type":"code","source":"def haversine(lat1, lon1, lat2, lon2): # Vectorized Harvesine equation\n    #from https://stackoverflow.com/questions/40452759/pandas-latitude-longitude-to-distance-between-successive-rows\n    lat1, lon1, lat2, lon2 = np.radians([lat1, lon1, lat2, lon2])\n    a = np.sin((lat2-lat1)/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin((lon2-lon1)/2.0)**2\n    return 12742 * np.arcsin(np.sqrt(a))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Finally we select data from the first 6 labeled groups and combine them in a new dataframe for continue with the analysis","metadata":{}},{"cell_type":"code","source":"# Function for extract a single trajectory subset from dirt road dataframe with speed and distance data\ndef get_trj_data(label_name, new_label):\n    df = dirt_data.loc[dirt_data[\"label\"] == label_name] # Isolate trajectory data\n    \n    df['speed'] = df['speed'].apply(lambda x: x*3600/1000) # Convert to km/h\n\n    # Add column with normalized speed\n    df['speed_norm'] = df['speed'].div(df[\"speed\"].mean()) \n\n    # Add column with distance from start point\n    df['dist'] = haversine(df['latitude'].shift(), df['longitude'].shift(), df.loc[1:, 'latitude'], df.loc[1:, 'longitude'])\n    df['dist'].fillna(df['dist'].iloc[-1])\n    df['dist'] = df['dist'].cumsum() # Cummulative sum of distances between points\n    \n    # Add new label\n    df['trj_label'] = new_label\n\n    return df\n\n# Build dataframe for first trajectory\ntrj_data = []\nfor p in ['path_10', 'path_16', 'path_4']:\n    d = get_trj_data(p, 'trj_1')\n    if len(trj_data) == 0:\n        trj_data = d\n    else:\n        trj_data = pd.concat([trj_data, d], axis=0)\n        \n# Add second trajectory\nfor p in ['path_5', 'path_11', 'path_17']:\n    d = get_trj_data(p, 'trj_2')\n    trj_data = pd.concat([trj_data, d], axis=0)\n\ntrj_data.reset_index(drop = True, inplace = True)\ntrj_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plots of the normalized speed vs linear position for the selected subsets","metadata":{}},{"cell_type":"code","source":"def trj_speed(trj_name):\n    grouped = trj_data.loc[trj_data['trj_label'] == trj_name].groupby('driver')\n    plt.figure(figsize=(15,10))\n    for ind,g in grouped:\n        g.reset_index(inplace=True)\n        plt.plot(g[\"dist\"], g[\"speed_norm\"], '.-', label = g.loc[0,\"driver\"])\n\n    plt.grid()\n    plt.ylabel(\"Norm. speed [avg={:.2f} km/h]\".format(g[\"speed\"].mean()))\n    plt.xlabel(\"Distance traveled [km]\")\n    plt.legend()\n\ntrj_speed('trj_1')\ntrj_speed('trj_2')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Partial conclusions\n\n### As we can see, speed variations are similar between the three different drivers. Now, lets see if we can find a correlation between this speed variations and road conditions\n### For this, we are using a scatter plot where each data point is colored based on the labeled quality","metadata":{}},{"cell_type":"code","source":"temp = trj_data.loc[trj_data['trj_label'] == 'trj_1']\ngrouped = temp.groupby('quality')\nplt.figure(figsize=(15,10))\nfor ind, g in grouped:\n    plt.scatter(g['dist'], g['speed_norm'], label = ind)\nplt.grid()\nplt.title('Norm. speed vs position and road quality')\nplt.xlabel('Position [km]')\nplt.ylabel('Normalized speed')\nplt.legend()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### There are a few low speed data points labeled as 'good', but most of low speed data points corresponds to bad quality labeled data, which makes sense. Lets see how is the speed correlated to the total acceleration indicator","metadata":{}},{"cell_type":"code","source":"temp = trj_data.loc[trj_data['trj_label'] == 'trj_1']\nacc = temp['acceleration'].rolling(30, min_periods = 1).mean() # Acceleration data smoothed with rolling window size=30\n\nplt.figure(figsize=(15,10))\nplt.scatter(temp['dist'], temp['speed'], c = acc, cmap = 'brg')\ncbar = plt.colorbar()\ncbar.set_label('Acceleration', rotation=90)\nplt.title('Velocity through trajectory and acceleration')\nplt.xlabel('Distance [km]')\nplt.ylabel('Speed [km/h]')\nplt.grid()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Here we can see that low velocity data points have small acceleration values. We can say that the faster the car goes, the higher are the values recorded by the accelerometers, but we cannot use this variable as an indicator of the road condition. \n### It would be more appropriate to use the frequency components of the acceleration data instead of the instantaneous values, this is, a vibration analysis might shed some light on measuring the road quality.","metadata":{}},{"cell_type":"markdown","source":"# Car vibration analysis\n\nWork in progress...","metadata":{}}]}