{"cells":[{"metadata":{},"cell_type":"markdown","source":"![](https://media.giphy.com/media/dVuyBgq2z5gVBkFtDc/giphy.gif)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Coronaviruses are a large family of viruses which may cause illness in animals or humans. In humans, several coronaviruses are known to cause respiratory infections ranging from the common cold to more severe diseases such as Middle East Respiratory Syndrome (MERS) and Severe Acute Respiratory Syndrome (SARS). The most recently discovered coronavirus causes coronavirus disease COVID-19.COVID-19 is the infectious disease caused by the most recently discovered coronavirus. This new virus and disease were unknown before the outbreak began in Wuhan, China, in December 2019**\n* [Source](https://www.who.int/news-room/q-a-detail/q-a-coronaviruses)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# **Coronavirus in World**","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"import pandas as pd \ncases = pd.read_csv(\"../input/novel-corona-virus-2019-dataset/covid_19_data.csv\")\nimport plotly.offline as py\nimport plotly.express as px\n\n\npy.init_notebook_mode(connected=True)\n\ngrp = cases.groupby(['ObservationDate', 'Country/Region'])['Confirmed', 'Deaths', 'Recovered'].max()\ngrp = grp.reset_index()\ngrp['Date'] = pd.to_datetime(grp['ObservationDate'])\ngrp['Date'] = grp['Date'].dt.strftime('%m/%d/%Y')\ngrp['Active'] = grp['Confirmed'] - grp['Recovered'] - grp['Deaths']\ngrp['Country'] =  grp['Country/Region']\n\nfig = px.choropleth(grp, locations=\"Country\", locationmode='country names', \n                     color=\"Confirmed\", hover_name=\"Country/Region\",hover_data = [grp.Recovered,grp.Deaths,grp.Active],projection=\"mercator\",\n                     animation_frame=\"Date\",width=800, height=500,\n                     color_continuous_scale='Reds',\n                     range_color=[1000,50000],\n\n                     title='World Map of Coronavirus')\n\nfig.update(layout_coloraxis_showscale=True)\npy.offline.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"from keras import backend as K\nfrom keras.preprocessing.image import ImageDataGenerator,load_img, img_to_array\nfrom keras.models import Sequential, Model\nfrom keras.layers import Conv2D, MaxPooling2D,GlobalAveragePooling2D\nfrom keras.layers import Activation, Dropout, BatchNormalization, Flatten, Dense, AvgPool2D,MaxPool2D\nfrom keras.models import Sequential, Model\nfrom keras.applications.vgg16 import VGG16, preprocess_input\nfrom keras.optimizers import Adam, SGD, RMSprop\n\nimport tensorflow as tf\n\nimport os\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport glob\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n%matplotlib inline\n\nimport plotly.offline as py\nimport plotly.express as px\nfrom fbprophet import Prophet\nfrom fbprophet.plot import plot_plotly, add_changepoints_to_plot","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Symptoms on Covid-19**","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"symptoms={'symptom':['Fever',\n        'Dry cough',\n        'Fatigue',\n        'Sputum production',\n        'Shortness of breath',\n        'Muscle pain',\n        'Sore throat',\n        'Headache',\n        'Chills',\n        'Nausea or vomiting',\n        'Nasal congestion',\n        'Diarrhoea',\n        'Haemoptysis',\n        'Conjunctival congestion'],'percentage':[87.9,67.7,38.1,33.4,18.6,14.8,13.9,13.6,11.4,5.0,4.8,3.7,0.9,0.8]}\n\nsymptoms=pd.DataFrame(data=symptoms,index=range(14))\nsymptoms\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Pie Chart**","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig = px.pie(symptoms,\n            values=\"percentage\",\n             names=\"symptom\",\n             template=\"seaborn\")\nfig.update_traces(rotation=90, pull=0.05, textinfo=\"percent+label\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Reading Data**","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"DATASET_DIR = \"../input/covid-19-x-ray-10000-images/dataset\"\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"os.listdir(DATASET_DIR)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Normal Image**","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"\nnormal_images = []\nfor img_path in glob.glob(DATASET_DIR + '/normal/*'):\n    normal_images.append(mpimg.imread(img_path))\n\nfig = plt.figure()\nfig.suptitle('normal')\nplt.imshow(normal_images[0], cmap='gray') \n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Detection","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Covid Image**","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"covid_images = []\nfor img_path in glob.glob(DATASET_DIR + '/covid/*'):\n    covid_images.append(mpimg.imread(img_path))\n\nfig = plt.figure()\nfig.suptitle('covid')\nplt.imshow(covid_images[0], cmap='gray') ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Length of images**","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print(len(normal_images))\nprint(len(covid_images))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Input Shape, Epochs and Batch Size**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"* **Epochs** - One Epoch is when an ENTIRE dataset is passed forward and backward through the neural network only ONCE\n* **Batch Size** -Total number of training examples present in a single batch.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"IMG_W = 150\nIMG_H = 150\nCHANNELS = 3\n\nINPUT_SHAPE = (IMG_W, IMG_H, CHANNELS)\nNB_CLASSES = 2\nEPOCHS = 48\nBATCH_SIZE = 6","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Model**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Applying Convolutional Neural Network which is a Deep Learning algorithm which can take in an input image, assign importance (learnable weights and biases) to various aspects/objects in the image and be able to differentiate one from the other. Convolution is a mathematical operation to merge two sets of information.In CNN architectures, pooling is typically performed with 2x2 windows, stride 2 and no padding. While convolution is done with 3x3 windows, stride 1 and with padding","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(32, (3, 3), input_shape=INPUT_SHAPE))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(32, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n\nmodel.add(Conv2D(64,(3,3)))\nmodel.add(Activation(\"relu\"))\nmodel.add(Conv2D(250,(3,3)))\nmodel.add(Activation(\"relu\"))\n  \nmodel.add(Conv2D(128,(3,3)))\nmodel.add(Activation(\"relu\"))\nmodel.add(AvgPool2D(2,2))\nmodel.add(Conv2D(64,(3,3)))\nmodel.add(Activation(\"relu\"))\nmodel.add(AvgPool2D(2,2))\n\nmodel.add(Conv2D(256,(2,2)))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPool2D(2,2))\n    \nmodel.add(Flatten())\nmodel.add(Dense(32))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(1))\nmodel.add(Activation(\"sigmoid\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"model.compile(loss='binary_crossentropy',\n              optimizer='rmsprop',\n              metrics=['accuracy'])\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Model Summary**","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"model.summary()\nfrom tensorflow.keras.utils import plot_model\nplot_model(model, to_file='model1.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale=1./255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    validation_split=0.25)\n\ntrain_generator = train_datagen.flow_from_directory(\n    DATASET_DIR,\n    target_size=(IMG_H, IMG_W),\n    batch_size=BATCH_SIZE,\n    class_mode='binary',\n    subset='training')\n\nvalidation_generator = train_datagen.flow_from_directory(\n    DATASET_DIR, \n    target_size=(IMG_H, IMG_W),\n    batch_size=BATCH_SIZE,\n    class_mode='binary',\n    shuffle= False,\n    subset='validation')\n\nhistory = model.fit_generator(\n    train_generator,\n    steps_per_epoch = train_generator.samples // BATCH_SIZE,\n    validation_data = validation_generator, \n    validation_steps = validation_generator.samples // BATCH_SIZE,\n    epochs = EPOCHS)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Plotting Graph - Accuracy and Loss**","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Accuracy**","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print(\"training_accuracy\", history.history['accuracy'][-1])\nprint(\"validation_accuracy\", history.history['val_accuracy'][-1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Labelling and Prediction**","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"label = validation_generator.classes\npred= model.predict(validation_generator)\npredicted_class_indices=np.argmax(pred,axis=1)\nlabels = (validation_generator.class_indices)\nlabels2 = dict((v,k) for k,v in labels.items())\npredictions = [labels2[k] for k in predicted_class_indices]\nprint(predicted_class_indices)\nprint (labels)\nprint (predictions)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Confusion Matrix**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"A confusion matrix is a table that is often used to describe the performance of a classification model (or “classifier”) on a set of test data for which the true values are known. It allows the visualization of the performance of an algorithm.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\ncf = confusion_matrix(predicted_class_indices,label)\ncf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"exp_series = pd.Series(label)\npred_series = pd.Series(predicted_class_indices)\npd.crosstab(exp_series, pred_series, rownames=['Actual'], colnames=['Predicted'],margins=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Plotting Confusion Matrix**","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.matshow(cf)\nplt.title('Confusion Matrix Plot')\nplt.colorbar()\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prediction","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# **Looking into data**","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"pred = pd.read_csv(\"../input/coronavirus-2019ncov/covid-19-all.csv\")\npred = pred.fillna(0)\npredgrp = pred.groupby(\"Date\")[[\"Confirmed\",\"Recovered\",\"Deaths\"]].sum().reset_index()\npredgrp.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Description of Data**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"predgrp.describe().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **State of Person**","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"\nTotal_confirmed = predgrp['Confirmed'].sum()\nTotal_recovered = predgrp['Recovered'].sum()\nTotal_death = predgrp['Deaths'].sum()\ndata = [['Confirmed', Total_confirmed], ['Recovered', Total_recovered], ['Death', Total_death]] \ndf = pd.DataFrame(data, columns = ['state', 'count']) \nfig = px.pie(df,\n             values=\"count\",\n             names=\"state\",\n             title=\"State of Patient\",\n             template=\"seaborn\")\nfig.update_traces(rotation=90, pull=0.05, textinfo=\"percent+label\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Prophet Model**","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"pred_cnfrm = predgrp.loc[:,[\"Date\",\"Confirmed\"]]\npr_data = pred_cnfrm\npr_data.columns = ['ds','y']\nm=Prophet()\nm.fit(pr_data)\nfuture=m.make_future_dataframe(periods=15)\nforecast=m.predict(future)\nforecast","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Graphical representation of Prediction**","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = plot_plotly(m, forecast)\npy.iplot(fig) \n\nfig = m.plot(forecast,xlabel='Date',ylabel='Confirmed Count')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Prediction for next 15 days**","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"cnfrm = forecast.loc[:,['ds','trend']]\ncnfrm = cnfrm[cnfrm['trend']>0]\ncnfrm.columns = ['Date','Confirm']\ncnfrm.tail(15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Prevention**  \n![](http://defiancelibrary.org/images/CoronaVirusInfo.jpg)\n**    To avoid the critical situation people are suggested to do following things** \n*     Avoid contact with people who are sick. \n*     Avoid touching your eyes, nose, and mouth. \n*     Stay home when you are sick. \n*     Cover your cough or sneeze with a tissue, then throw the tissue in the trash. \n*    Clean and disinfect frequently touched objects and surfaces using a regular household  \n*    Wash your hands often with soap and water, especially after going to the bathroom; before eating; and after blowing     your nose, coughing, or sneezing. If soap and water are not readily available, use an alcohol-based hand sanitizer.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}