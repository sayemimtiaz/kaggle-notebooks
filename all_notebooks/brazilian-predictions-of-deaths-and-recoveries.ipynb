{"cells":[{"metadata":{},"cell_type":"markdown","source":"![title](https://raw.githubusercontent.com/emdemor/Covid-Brasil/main/source/title.png)"},{"metadata":{},"cell_type":"markdown","source":"<center> <h2>SUMMARY</h2> </center>\n\n\n*I developed a model to predict the curves of contamination, deaths and recoveries in the cases of COVID-19. Unlike time series analyzes, the model uses regression techniques to predict the rates of change as a function of the current number of contaminations, deaths and recoveries over time. With this, I hope that the model will be able to learn how the time derivatives change as we observe variations (even sudden ones) in the numbers of cases and, after a numerical integration, be able to predict future data with greater precision than simple temporal projection with regressors in time series analysis techniques.*\n\n<img src=\"https://raw.githubusercontent.com/emdemor/Covid-Brasil/main/source/results.png\">"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"toc\"></a>\n  \n  \n  <div  style=\"margin-top: 9px; background-color: #efefef; padding-top:10px; padding-bottom:10px;margin-bottom: 9px;box-shadow: 5px 5px 5px 0px rgba(87, 87, 87, 0.2);\">\n    <center>\n        <h2>Content</h2>\n    </center>\n\n   \n<ol>\n    <li><a href=\"#01\" style=\"color: #37509b;\">Description</a></li>\n    <li><a href=\"#02\" style=\"color: #37509b;\">Introduction</a></li>\n    <li><a href=\"#03\" style=\"color: #37509b;\">Dataset</a></li>\n    <li><a href=\"#04\" style=\"color: #37509b;\">Model</a></li>\n\n</ol>\n\n\n</div>"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"01\" style=\"\n  background-color: #37509b;\n  border: none;\n  color: white;\n  padding: 2px 10px;\n  text-align: center;\n  text-decoration: none;\n  display: inline-block;\n  font-size: 10px;\" href=\"#toc\">TOC ↻</a>\n  \n  \n<div  style=\"margin-top: 9px; background-color: #efefef; padding-left:35px; padding-top:10px; padding-bottom:10px;margin-bottom: 9px;box-shadow: 5px 5px 5px 0px rgba(87, 87, 87, 0.2);\">\n    \n<h1>1. Description</h1>\n\n   \n   \n<ol type=\"i\">\n<!--     <li><a href=\"#0101\" style=\"color: #37509b;\">Inicialização</a></li>\n    <li><a href=\"#0102\" style=\"color: #37509b;\">Pacotes</a></li>\n    <li><a href=\"#0103\" style=\"color: #37509b;\">Funcoes</a></li>\n    <li><a href=\"#0104\" style=\"color: #37509b;\">Dados de Indicadores Sociais</a></li>\n    <li><a href=\"#0105\" style=\"color: #37509b;\">Dados de COVID-19</a></li>\n -->\n</ol>\n\n\n"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"0101\"></a>\n<h2>1.1 Epidemiological Models <a href=\"#01\"\nstyle=\"\n    border-radius: 10px;\n    background-color: #f1f1f1;\n    border: none;\n    color: #37509b;\n    text-align: center;\n    text-decoration: none;\n    display: inline-block;\n    padding: 4px 4px;\n    font-size: 14px;\n\">↻</a></h2>"},{"metadata":{},"cell_type":"markdown","source":">The reader familiar with epidemiological models, can go to <a href=\"#0102\">section 1.2</a>.\n\n\nThe simplest epidemiological models used for modeling SARS-COVID-19 are based on first principles and defined in terms of differential equations on quantities that describe the epidemiological status of the population. In the simplest cases, these quantities are:\n\n* $D(t)$: cumulative number of deaths on time $t$;\n* $C(t)$: cumulative number of confirmed cases on time $t$; \n* $R(t)$: cumulative number of recovered cases on time $t$;\n* $I(t)$: current number infections on time $t$\n\nFixing the number of people constant, only three of these four functions are independent, and, in general, the function $ C(t) $ is eliminated by the relation $ C (t) = I (t) + R (t ) + D (t) $."},{"metadata":{},"cell_type":"markdown","source":"![title](https://raw.githubusercontent.com/emdemor/Covid-Brasil/main/source/Disease-Propagation-Simulation.gif)"},{"metadata":{},"cell_type":"markdown","source":"An additional concept that appears in the models is that of *susceptibility* and takes into account that the entire population cannot, in fact, be subject to infection. It is to be expected that the number of susceptible people will be a dynamic variable, since cases of reinfection are practically non-existent (or certainly very unlikely in relation to cases of first infection). This variable is called:\n\n\n* $S(t)$: number of individuals susceptible to infection over time $t$\n\n\nSusceptible people, when infected, leave the group of $S(t)$ and become $C(t)$. As a consequence:\n\n$\\\\\\\\$\n\n<center>\n$ \\frac{dS}{dt}+\\frac{dC}{dt} = 0, \\tag{1}$\n</center>\n\n$\\\\\\\\$\n\n\nIntuitively, the rate of infection is correlated with the number of susceptible people and the number of people actively infected. A simple model of this relationship is:\n\n<center>\n$ \\frac{dC}{dt} = k_s S(t) I(t) \\label{eq:propC} \\tag{2a} ,$\n</center>\n\n$\\\\\\\\$\n\nwhich, through equation (1), naturally leads to:\n\n$\\\\\\\\$\n\n<center>\n$\\frac{dS}{dt} = - k_s S(t) I(t) \\label{eq:propS} \\tag{2b} ,$\n</center>\n\n$\\\\\\\\$\n\n\nwhere $k_s > 0$. \n\nAnother expected behavior is that both the rate of people recovered and the rate of deaths are proportional in a given time $ t $ to the number of people actively infected:\n\n$\\\\\\\\$\n\n\n<center>\n$ \\frac{dR}{dt} = k_r I(t) \\label{eq:propR} \\tag{3a}$\n</center>\n\n$\\\\\\\\$\n\ne\n\n$\\\\\\\\$\n\n<center>\n$ \\frac{dD}{dt} = k_d I(t) \\label{eq:propD} \\tag{3b}$\n</center>\n\n$\\\\\\\\$\n\nwhere $k_r,k_d > 0$. \n\nAlternatively, you can use the link $ C(t) = I (t) + R (t) + D (t) $ to deduct the differential equation for $ I (t) $:\n\n$\\\\\\\\$\n\n<center>\n$ \\frac{dI}{dt} = \\left( k_s S(t) - k_r - k_d\\right)I(t)  \\label{eq:propI} \\tag{4}$\n</center>\n\n$\\\\\\\\$\n\nThe model described above is well founded, but takes several hypotheses into account. It has been successfully applied to describe the evolution of Covid-19 in different regions. However, these hypotheses are associated with idealized cases and, because of this, the model is not general enough to adapt to the modeling of Covid-19 cases. When this occurs, the authors call for generalizations of the models, generally based on different equations of the type:\n\n$\\\\\\\\$\n\n<center>\n$ \\frac{dS}{dt} = f_s(S(t),I(t),D(t),R(t)), \\tag{5a}$\n</center>\n\n$\\\\\\\\$\n\n<center>\n$ \\frac{dI}{dt} = f_i(S(t),I(t),D(t),R(t)), \\tag{5b}$\n</center>\n\n$\\\\\\\\$\n\n<center>\n$ \\frac{dD}{dt} = f_d(S(t),I(t),D(t),R(t)), \\tag{5c}$\n</center>\n\n$\\\\\\\\$\n\n<center>\n$ \\frac{dR}{dt} = f_r(S(t),I(t),D(t),R(t)), \\tag{5d}$\n</center>\n\n$\\\\\\\\$\n\nwhere the algebraic functions $ f_s $, $ f_i $, $ f_d $ and $ f_r $ are determined according to the problem under study.\n\nIn my opinion, the biggest problem with the application of epidemiological models to Covid-19 modeling is in the human factor. Several times, pathological behaviors were observed in the curves of Covid-19 (as in the case of China and the USA), which are abrupt or even mild changes, but which do not respect the equations in the model. What is wrong in this case is, in general, due to human action. Whether by changing collective behavior (collective abandonment of isolation rules), political influence on social behavior, changes in public policy rules, etc. In such cases, Machine Learning models can be used."},{"metadata":{},"cell_type":"markdown","source":"> [1] Ranjan, R. (2020). *Predictions for COVID-19 outbreak in India using Epidemiological models*. medRxiv.\n\n\n> [2] Hethcote, H. W. (2009). The basic epidemiology models: models, expressions for R0, parameter estimation, and applications. In *Mathematical understanding of infectious disease dynamics* (pp. 1-61)."},{"metadata":{},"cell_type":"markdown","source":"![title](https://raw.githubusercontent.com/emdemor/Covid-Brasil/main/source/211462.gif)"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"0102\"></a>\n<h2>1.2 Machine Learning Models <a href=\"#01\"\nstyle=\"\n    border-radius: 10px;\n    background-color: #f1f1f1;\n    border: none;\n    color: #37509b;\n    text-align: center;\n    text-decoration: none;\n    display: inline-block;\n    padding: 4px 4px;\n    font-size: 14px;\n\">↻</a></h2>"},{"metadata":{},"cell_type":"markdown","source":"Unlike epidemiological models, machine learning models are, in general, structured in a different way. There is a wide range of approaches, but the dynamic variables $ C (t) $, $ D (t) $, $ R (t) $ and $ I (t) $ are generally taken as time series. As this approach is data oriented, there is no reference to the dynamic variable $ S (t) $, since it carries an abstract notion (that of the number of susceptible people) that is something inaccessible. This type of approach, in the short term, is quite satisfactory because it allows forecasts of the evolution of the disease in the coming days. However, in the long run, predictions are more dispersed and inaccurate. The reason for this is that the learning models with this characteristic relate each of the dynamic variables only with time. However, as discussed in the topic of epidemiological models, there are correlations between the variables $ C (t) $, $ D (t) $, $ R (t) $ and $ I (t) $.\n\nThe model proposed here is described as follows: I want to obtain a set of different equations similar to that of Eqs. (5), however, considering $ C (t) $ instead of $ I (t) $.\n\n* Since it is not possible to accurately infer a time series for $ S (t) $, this variable won't be considered.\n* In addition, I want to allow $ f $ functions to depend directly on time to.\n\nIn these considerations, the system will be reduced to:\n\n$\\\\\\\\$\n\n\n<center>\n$ \\frac{dC}{dt} = f_c(t,C(t),D(t),R(t)), \\tag{6a}$\n</center>\n\n$\\\\\\\\$\n\n<center>\n$ \\frac{dD}{dt} = f_d(t,C(t),D(t),R(t)), \\tag{6b}$\n</center>\n\n$\\\\\\\\$\n\n<center>\n$ \\frac{dR}{dt} = f_r(t,C(t),D(t),R(t)), \\tag{6c}$\n</center>\n\n$\\\\\\\\$\n\n* The $ f $ functions will be determined by applying regression models. With this, I will obtain three models of machine learning capable of predicting the variation rates of $ C $, $ D $ and $ R $ receiving data from $ t_ {in} $, $ C (t_ {in}) $, $ D (t_ {in}) $ and $ R (t_ {in}) $ as input.\n\n* With the variation rates model, I can integrate the model in the opposite direction, taking the last data as an initial condition. In this process, the machine learning model will be validated\n\n* As the model validated, future predictions can be performed"},{"metadata":{},"cell_type":"markdown","source":"![title](https://raw.githubusercontent.com/emdemor/Covid-Brasil/main/source/tenor.gif)"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"02\" style=\"\n  background-color: #37509b;\n  border: none;\n  color: white;\n  padding: 2px 10px;\n  text-align: center;\n  text-decoration: none;\n  display: inline-block;\n  font-size: 10px;\" href=\"#toc\">TOC ↻</a>\n  \n  \n<div  style=\"margin-top: 9px; background-color: #efefef; padding-left:35px; padding-top:10px; padding-bottom:10px;margin-bottom: 9px;box-shadow: 5px 5px 5px 0px rgba(87, 87, 87, 0.2);\">\n    \n<h1>2. Introduction</h1>\n\n   \n   \n<ol type=\"i\">\n<!--     <li><a href=\"#0101\" style=\"color: #37509b;\">Inicialização</a></li>\n    <li><a href=\"#0102\" style=\"color: #37509b;\">Pacotes</a></li>\n    <li><a href=\"#0103\" style=\"color: #37509b;\">Funcoes</a></li>\n    <li><a href=\"#0104\" style=\"color: #37509b;\">Dados de Indicadores Sociais</a></li>\n    <li><a href=\"#0105\" style=\"color: #37509b;\">Dados de COVID-19</a></li>\n -->\n</ol>\n\n\n"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"0201\"></a>\n<h2>2.1 Modules e Packages <a href=\"#02\"\nstyle=\"\n    border-radius: 10px;\n    background-color: #f1f1f1;\n    border: none;\n    color: #37509b;\n    text-align: center;\n    text-decoration: none;\n    display: inline-block;\n    padding: 4px 4px;\n    font-size: 14px;\n\">↻</a></h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\n\n\nfrom datetime import datetime,timedelta\nfrom scipy.integrate import odeint\n\n!pip install xtlearn\nfrom xtlearn.feature_selection import FeatureSelector\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import r2_score\nfrom sklearn.base import BaseEstimator,TransformerMixin\nfrom sklearn.metrics import r2_score,mean_squared_log_error,mean_absolute_error\n\nfrom sklearn.base import BaseEstimator,TransformerMixin","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"0202\"></a>\n<h2>2.2 Settings<a href=\"#02\"\nstyle=\"\n    border-radius: 10px;\n    background-color: #f1f1f1;\n    border: none;\n    color: #37509b;\n    text-align: center;\n    text-decoration: none;\n    display: inline-block;\n    padding: 4px 4px;\n    font-size: 14px;\n\">↻</a></h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"warnings.filterwarnings(\"ignore\")\n\n# Setting seaborn style\nsns.set_style(\"darkgrid\")\ncolors = [\"#449353\",\"#ff9999\",\"#4f7cac\", \"#80e4ed\",\"#f8f99e\",\"#b5ddbd\"]\nsns.set_palette(sns.color_palette(colors))\nplt.rcParams[\"figure.figsize\"] = [8,5]\n\n# Setting Pandas float format\npd.options.display.float_format = '{:,.1f}'.format\n\nSEED = 42   #The Answer to the Ultimate Question of Life, The Universe, and Everything\nnp.random.seed(SEED)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"0203\"></a>\n<h2>2.3 Classes e Functions<a href=\"#02\"\nstyle=\"\n    border-radius: 10px;\n    background-color: #f1f1f1;\n    border: none;\n    color: #37509b;\n    text-align: center;\n    text-decoration: none;\n    display: inline-block;\n    padding: 4px 4px;\n    font-size: 14px;\n\">↻</a></h2>"},{"metadata":{},"cell_type":"markdown","source":"The creation of this class was necessary to introduce the possibility of calculating the moving average in the model's pipelines."},{"metadata":{"trusted":true},"cell_type":"code","source":"class RollingMean(BaseEstimator,TransformerMixin):\n    '''\n    Description\n    ----------\n    Provide rolling window calculations.\n   \n    Arguments\n    ----------\n    window: int\n        Size of the moving window. This is the number of observations used for calculating the statistic.\n        \n    min_periods: int, default None\n        Minimum number of observations in window required to have a value \n        (otherwise result is NA). For a window that is specified by an offset, \n        min_periods will default to 1. Otherwise, min_periods will default \n        to the size of the window.\n        \n    center: bool, default False\n        Set the labels at the center of the window.\n        \n\n    active: boolean\n        This parameter controls if the selection will occour. This is useful in hyperparameters searchs to test the contribution\n        in the final score\n        \n    '''\n    \n    def __init__(self,window,\n                 min_periods = None,\n                 center = False,\n                 active=True,\n                 columns = 'all'\n                ):\n        self.columns = columns\n        self.active = active\n        self.window = window\n        self.min_periods = min_periods\n        self.center = center\n\n        \n    def fit(self,X,y=None):\n        return self\n        \n    def transform(self,X):\n        if not self.active:\n            return X\n        else:\n            return self.__transformation(X)\n\n    def __transformation(self,X_in):\n        X = X_in.copy()\n        \n        if type(self.columns) == str:\n            if self.columns == 'all':\n                self.columns = list(X.columns)\n        \n        for col in self.columns:  \n            X[col] = X[col].fillna(0).rolling(window = self.window,\n                                              min_periods = self.min_periods,\n                                              center = self.center\n                                             ).mean()\n        return X.dropna()\n        \n    def inverse_transform(self,X):\n        return X","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This class allows the application of the logarithm in the attributes to be one of the steps in the pipeline."},{"metadata":{"trusted":true},"cell_type":"code","source":"class ApplyLog1p(BaseEstimator,TransformerMixin):\n    '''\n    Description\n    ----------\n    Apply numpy.log1p to specified features.\n   \n    Arguments\n    ----------\n        \n    columns: list, default False\n        Column names to apply numpy.log1p.\n        \n\n    active: boolean\n        This parameter controls if the selection will occour. This is useful in hyperparameters searchs to test the contribution\n        in the final score\n        \n    '''\n    \n    def __init__(self,active=True,columns = 'all'):\n        self.columns = columns\n        self.active = active\n        \n    def fit(self,X,y=None):\n        return self\n        \n    def transform(self,X):\n        if not self.active:\n            return X\n        else:\n            return self.__transformation(X)\n\n    def __transformation(self,X_in):\n        X = X_in.copy()\n        \n        if type(self.columns) == str:\n            if self.columns == 'all':\n                self.columns = list(X.columns)\n        \n        for col in self.columns:  \n            X[col] = np.log1p(X[col])\n            \n        return X\n        \n    def inverse_transform(self,X):\n        if not self.active:\n            return X\n        else:\n            return self.__inverse_transformation(X)\n\n    def __inverse_transformation(self,X_in):\n        X = X_in.copy()\n        \n        if type(self.columns) == str:\n            if self.columns == 'all':\n                self.columns = list(X.columns)\n        \n        for col in self.columns:  \n            X[col] = np.expm1(X[col])\n            \n        return X","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"03\" style=\"\n  background-color: #37509b;\n  border: none;\n  color: white;\n  padding: 2px 10px;\n  text-align: center;\n  text-decoration: none;\n  display: inline-block;\n  font-size: 10px;\" href=\"#toc\">TOC ↻</a>\n  \n  \n<div  style=\"margin-top: 9px; background-color: #efefef; padding-left:35px; padding-top:10px; padding-bottom:10px;margin-bottom: 9px;box-shadow: 5px 5px 5px 0px rgba(87, 87, 87, 0.2);\">\n    \n<h1>3. Dataset</h1>\n\n   \n   \n<ol type=\"i\">\n<!--     <li><a href=\"#0101\" style=\"color: #37509b;\">Inicialização</a></li>\n    <li><a href=\"#0102\" style=\"color: #37509b;\">Pacotes</a></li>\n    <li><a href=\"#0103\" style=\"color: #37509b;\">Funcoes</a></li>\n    <li><a href=\"#0104\" style=\"color: #37509b;\">Dados de Indicadores Sociais</a></li>\n    <li><a href=\"#0105\" style=\"color: #37509b;\">Dados de COVID-19</a></li>\n -->\n</ol>\n\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = pd.read_csv('/kaggle/input/corona-virus-brazil/brazil_covid19_macro.csv',parse_dates=['date']).drop(columns=['monitoring'])\nfirst_day = dataset.iloc[0]['date']\ndataset['days'] = (dataset['date']-first_day).dt.days\n\ndataset['change_cases'] = (dataset['cases']-dataset['cases'].shift())\ndataset['change_deaths'] = (dataset['deaths']-dataset['deaths'].shift())\ndataset['change_recovered'] = (dataset['recovered']-dataset['recovered'].shift())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(dataset['date'],dataset['cases'],linewidth=1,s=5,label='Confirmed Cases')\nplt.scatter(dataset['date'],dataset['deaths'],linewidth=1,s=5, label='Deaths')\nplt.scatter(dataset['date'],dataset['recovered'],linewidth=1,s=5, label='Recovered Cases')\nplt.xticks(rotation=45)\nplt.title('Number of Cases')\nplt.xlabel('Data')\nplt.ylabel('Millions of Cases')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(dataset['date'],dataset['change_cases']/1000,linewidth=1,label='Daily Cases',alpha = 0.4,color = colors[0])\nplt.plot(dataset['date'],0.001*dataset['change_cases'].rolling(window = 14,center=True).mean(),\n         label='Rolling Mean (14 days)',color = colors[0])\n\nplt.xticks(rotation=45)\nplt.title('Daily Cases of Covid-19')\nplt.xlabel('Date')\nplt.ylabel('Thousands of Cases')\nplt.legend(loc = 'upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(dataset['date'],dataset['change_deaths'],linewidth=1,label='Daily Deaths',color = colors[1],alpha=0.4)\nplt.plot(dataset['date'],dataset['change_deaths'].rolling(window = 14,center=True).mean(),\n         label='Rolling Mean (14 days)',color = colors[1])\n\n\nplt.xticks(rotation=45)\nplt.title('Daily Deaths of Covid-19')\nplt.xlabel('Date')\nplt.ylabel('Number of Cases')\nplt.legend(loc = 'upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(dataset['date'],dataset['change_recovered']/1000,linewidth=1,label='Daily Recoveries',color = colors[2],alpha=0.4)\nplt.plot(dataset['date'],0.001*dataset['change_recovered'].rolling(window = 14,center=True).mean(),\n         label='Rolling Mean (14 days)',color = colors[2])\n\n\nplt.xticks(rotation=45)\nplt.title('Daily Recoveries of Covid-19')\nplt.xlabel('Date')\nplt.ylabel('Thousands of Cases')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"04\" style=\"\n  background-color: #37509b;\n  border: none;\n  color: white;\n  padding: 2px 10px;\n  text-align: center;\n  text-decoration: none;\n  display: inline-block;\n  font-size: 10px;\" href=\"#toc\">TOC ↻</a>\n  \n  \n<div  style=\"margin-top: 9px; background-color: #efefef; padding-left:35px; padding-top:10px; padding-bottom:10px;margin-bottom: 9px;box-shadow: 5px 5px 5px 0px rgba(87, 87, 87, 0.2);\">\n    \n<h1>4. Model</h1>\n\n   \n   \n<ol type=\"i\">\n<!--     <li><a href=\"#0101\" style=\"color: #37509b;\">Inicialização</a></li>\n    <li><a href=\"#0102\" style=\"color: #37509b;\">Pacotes</a></li>\n    <li><a href=\"#0103\" style=\"color: #37509b;\">Funcoes</a></li>\n    <li><a href=\"#0104\" style=\"color: #37509b;\">Dados de Indicadores Sociais</a></li>\n    <li><a href=\"#0105\" style=\"color: #37509b;\">Dados de COVID-19</a></li>\n -->\n</ol>\n\n\n"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"0401\"></a>\n<h2>4.1 Pre-Processing Pipelines<a href=\"#02\"\nstyle=\"\n    border-radius: 10px;\n    background-color: #f1f1f1;\n    border: none;\n    color: #37509b;\n    text-align: center;\n    text-decoration: none;\n    display: inline-block;\n    padding: 4px 4px;\n    font-size: 14px;\n\">↻</a></h2>"},{"metadata":{},"cell_type":"markdown","source":"The steps for pre-processing the data consist of:\n1. Apply the 14-day rolling mean\n2. Select only the attributes * ('days', 'cases', 'deaths', 'recovered', 'change_cases', 'change_deaths', 'change_recovered') *\n3. Application of the Logarithmic Scale in the Attributes\n\nTo make the rolling mean and the logarithmic scale, I created two classes in the 'Classes and Functions' Section"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Pipeline for preprocessing\npreproc = Pipeline(steps = [\n    ('rolling_mean',RollingMean(window = 21,columns = [\n        'cases', 'deaths', 'recovered',\n        'change_cases','change_deaths','change_recovered'],center = True)),\n    \n    ('select',FeatureSelector(features = ['days','cases', 'deaths',\n        'recovered','change_cases','change_deaths','change_recovered'])\n    ),\n])\n\n# Log Scalling\nlog_apply = ApplyLog1p(columns = 'all')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"0402\"></a>\n<h2>4.2 Splitting Training and Test Data<a href=\"#04\"\nstyle=\"\n    border-radius: 10px;\n    background-color: #f1f1f1;\n    border: none;\n    color: #37509b;\n    text-align: center;\n    text-decoration: none;\n    display: inline-block;\n    padding: 4px 4px;\n    font-size: 14px;\n\">↻</a></h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Applying pre-processing pipeline\ndf = log_apply.transform(preproc.transform(dataset))\n\n# full dataset\nX = df[['days','cases', 'deaths', 'recovered']]\nyc = df['change_cases']\nyd = df['change_deaths']\nyr = df['change_recovered']\n\ntrain_size = 0.95\nindex_split = int(round(train_size*len(X)))\n\n# training dataset\nX_trn  = X.iloc[:index_split]\nyc_trn = yc.iloc[:index_split]\nyd_trn = yd.iloc[:index_split]\nyr_trn = yr.iloc[:index_split]\n\n#test dataset\nX_tst  = X.iloc[index_split:]\nyc_tst = yc.iloc[index_split:]\nyd_tst = yd.iloc[index_split:]\nyr_tst = yr.iloc[index_split:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"0403\"></a>\n<h2>4.3 Regression of the Time Derivatives of Cases, Deaths and Recovery<a href=\"#04\"\nstyle=\"\n    border-radius: 10px;\n    background-color: #f1f1f1;\n    border: none;\n    color: #37509b;\n    text-align: center;\n    text-decoration: none;\n    display: inline-block;\n    padding: 4px 4px;\n    font-size: 14px;\n\">↻</a></h2>"},{"metadata":{},"cell_type":"markdown","source":"### Pipelines"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Pipeline for regression\nregression_c = Pipeline(steps = [\n    ('polinomial',PolynomialFeatures(degree = 2)),\n    ('regressor',LinearRegression()),\n])\nregression_d = Pipeline(steps = [\n    ('polinomial',PolynomialFeatures(degree = 2)),\n    ('regressor',LinearRegression()),\n])\nregression_r = Pipeline(steps = [\n    ('polinomial',PolynomialFeatures(degree = 2)),\n    ('regressor',LinearRegression()),\n])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Metrics"},{"metadata":{"trusted":true},"cell_type":"code","source":"regression_c.fit(X_trn,yc_trn)\nprint('M.A.E. of cases (train)= %.4f'%mean_absolute_error(yc,regression_c.predict(X)))\nprint('M.A.E. of cases (test) = %.4f'%mean_absolute_error(yc_tst,regression_c.predict(X_tst)))\n\nregression_d.fit(X_trn,yd_trn)\nprint('\\nM.A.E. of deaths (train)= %.4f'%mean_absolute_error(yd,regression_d.predict(X)))\nprint('M.A.E. of deaths (test)= %.4f'%mean_absolute_error(yd_tst,regression_d.predict(X_tst)))\n\nregression_r.fit(X_trn,yr_trn)\nprint('\\nM.A.E. of recovered (train)= %.4f'%mean_absolute_error(yr,regression_r.predict(X)))\nprint('M.A.E. of deaths (test)= %.4f'%mean_absolute_error(yd_tst,regression_d.predict(X_tst)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = log_apply.inverse_transform(pd.concat([\n    X.reset_index(drop=True),\n    pd.DataFrame(regression_c.predict(X),columns = ['change_cases']),\n    pd.DataFrame(regression_d.predict(X),columns = ['change_deaths']),\n    pd.DataFrame(regression_r.predict(X),columns = ['change_recovered']),\n],1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(dataset['days'],dataset['change_cases']/1000,s=5,label='Daily Cases',alpha = 0.3,color = colors[0])\nplt.plot(predictions['days'],0.001*predictions['change_cases'].rolling(window = 14,center=True).mean(),\n         linewidth=2,label='Regression',color = colors[0])\n\n# plt.xticks(rotation=45)\nplt.title('Model for Daily Cases of Covid-19')\nplt.xlabel('Days After First Case')\nplt.ylabel('Thousands of Cases')\nplt.legend(loc = 'upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(dataset['days'],dataset['change_deaths']/1000,s=5,label='Daily Deaths',alpha = 0.3,color = colors[1])\nplt.plot(predictions['days'],0.001*predictions['change_deaths'].rolling(window = 14,center=True).mean(),\n         linewidth=2,label='Regression',color = colors[1])\n\n# plt.xticks(rotation=45)\nplt.title('Model for Daily Deaths by Covid-19')\nplt.xlabel('Days After First Case')\nplt.ylabel('Thousands of Cases')\nplt.legend(loc = 'upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,5))\nplt.scatter(dataset['days'],dataset['change_recovered']/1000,s=5,label='Daily Recoveries',alpha = 0.3,color = colors[2])\nplt.plot(predictions['days'],0.001*predictions['change_recovered'].rolling(window = 14,center=True).mean(),\n         linewidth=2,label='Regression',color = colors[2])\n\n# plt.xticks(rotation=45)\nplt.title('Model for Daily Recoveries of Covid-19')\nplt.xlabel('Days After First Case')\nplt.ylabel('Thousands of Cases')\nplt.legend(loc = 'upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"0404\"></a>\n<h2>4.4 Integration of Differential Equations<a href=\"#04\"\nstyle=\"\n    border-radius: 10px;\n    background-color: #f1f1f1;\n    border: none;\n    color: #37509b;\n    text-align: center;\n    text-decoration: none;\n    display: inline-block;\n    padding: 4px 4px;\n    font-size: 14px;\n\">↻</a></h2>"},{"metadata":{},"cell_type":"markdown","source":"Now that we have used the test dataset to check the model, we can train the model with the entire dataset to make future predictions:"},{"metadata":{"trusted":true},"cell_type":"code","source":"regression_c.fit(X,yc)\nregression_d.fit(X,yd)\nregression_r.fit(X,yr)\n\npredictions = log_apply.inverse_transform(pd.concat([\n    X.reset_index(drop=True),\n    pd.DataFrame(regression_c.predict(X),columns = ['change_cases']),\n    pd.DataFrame(regression_d.predict(X),columns = ['change_deaths']),\n    pd.DataFrame(regression_r.predict(X),columns = ['change_recovered']),\n],1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With regressions, we have a machine learning model for the following system of differential equations:\n\n$\\\\\\\\$\n\n\n<center>\n$ \\frac{dC}{dt} = f_c(t,C(t),D(t),R(t)), $\n</center>\n\n$\\\\\\\\$\n\n<center>\n$ \\frac{dD}{dt} = f_d(t,C(t),D(t),R(t)), $\n</center>\n\n$\\\\\\\\$\n\n<center>\n$ \\frac{dR}{dt} = f_r(t,C(t),D(t),R(t)),$\n</center>\n\n$\\\\\\\\$\nThis can be solved numerically with the `scipy` library.\n\nFirst, the system of differential equations is defined as:"},{"metadata":{"trusted":true},"cell_type":"code","source":"def diff_eq(x,t):\n    \"\"\"\n    Function resturning the differential equations of the model\n\n    \"\"\"\n    # setting the functions\n    c,r,d = x\n    lnt = np.log1p(t)\n    lnx = np.log1p(x)\n    \n    \n    # mathematical equations\n    DiffC = np.expm1(regression_c.predict([[lnt]+list(lnx)]))[0]\n    DiffD = np.expm1(regression_d.predict([[lnt]+list(lnx)]))[0]\n    DiffR = np.expm1(regression_r.predict([[lnt]+list(lnx)]))[0]\n\n    return np.array([DiffC,DiffD,DiffR])\n\ndef neg_diff_eq(x,t):\n    return -diff_eq(x,-t)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Performing the integrations:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# defining the limits\nt_min = 20\nt_max   = 500\nn_points = 500\n\n# initial conditions\nt0,*x0 = np.expm1(list(X.iloc[-50]))\n\n# counting the points\nn_points_right = int(round(n_points*(t_max-t0) / (t_max-t_min)))\nn_points_left = int(round(n_points*(t0-t_min) / (t_max-t_min)))\n\n# right integrate\ndays_list = np.linspace(t0,t_max,n_points_right)\nx = odeint(diff_eq,x0,days_list)\n\n# left integrate\nneg_days_list = np.linspace(-t0,-t_min,n_points_left)\nneg_x = odeint(neg_diff_eq,x0,neg_days_list)\n\n#joinning solution\nt_full = np.concatenate((-neg_days_list[::-1], days_list))\nx_full = np.concatenate((neg_x[::-1], x))\n\nprint('Deaths: %d' % x[-1,1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"0405\"></a>\n<h2>4.5 Comparison between model prediction and data<a href=\"#04\"\nstyle=\"\n    border-radius: 10px;\n    background-color: #f1f1f1;\n    border: none;\n    color: #37509b;\n    text-align: center;\n    text-decoration: none;\n    display: inline-block;\n    padding: 4px 4px;\n    font-size: 14px;\n\">↻</a></h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(dataset['days'],0.000001*dataset['cases'],marker='.',s=80,alpha=0.3,color = colors[0],\n            label='Confirmed Cases')\nplt.plot(t_full,0.000001*x_full[:,0],color='black',linestyle='dashed',linewidth=1.3,label='Model')\n\nplt.title('Model for Confirmed Cases of Covid-19')\nplt.xlabel('Days After First Case')\nplt.ylabel('Millions of Cases')\nplt.legend(loc = 'upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(dataset['days'],0.001*dataset['deaths'],marker='.',s=80,alpha=0.3,color = colors[1],label='Deaths')\nplt.plot(t_full,0.001*x_full[:,1],color='black',linestyle='dashed',linewidth=1.3,label='Model')\n\nplt.title('Model for Deaths by Covid-19')\nplt.xlabel('Days After First Case')\nplt.ylabel('Thousands of Cases')\nplt.legend(loc = 'upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(dataset['days'],0.000001*dataset['recovered'],marker='.',s=80,alpha=0.3,color = colors[2],\n            label='Recoveries')\nplt.plot(t_full,0.000001*x_full[:,2],color='black',linestyle='dashed',linewidth=1.3,label='Model')\n\nplt.title('Model for Recovered Cases of Covid-19')\nplt.xlabel('Days After First Case')\nplt.ylabel('Thousands of Cases')\nplt.legend(loc = 'upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"0406\"></a>\n<h2>4.6 Class for Complete Processing<a href=\"#04\"\nstyle=\"\n    border-radius: 10px;\n    background-color: #f1f1f1;\n    border: none;\n    color: #37509b;\n    text-align: center;\n    text-decoration: none;\n    display: inline-block;\n    padding: 4px 4px;\n    font-size: 14px;\n\">↻</a></h2>"},{"metadata":{},"cell_type":"markdown","source":"In the previous sections, each step of the process was carried out in detail. However, to search for the best hyperparameters of the model, you must run the entire sequence of steps again for each attempt. Instead, it is better to automate the process and the best way to do this is by defining a new class:"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Covid19Regressor(BaseEstimator,TransformerMixin):\n    '''\n    Description\n    ----------\n    Arguments\n    ----------\n    active: boolean\n        This parameter controls if the selection will occour. This is useful in hyperparameters searchs to test the contribution\n        in the final score\n        \n    '''\n    \n    def __init__(self,\n                 confirmed = 'cases', \n                 deaths = 'deaths',\n                 recovered = 'recovered',\n                 \n                 confirmed_rate = 'change_cases', \n                 deaths_rate = 'change_deaths',\n                 recovered_rate = 'change_recovered',\n                 \n                 time = 'days',\n                 window = 7,\n                 min_periods = None,\n                 center = True,\n                 polynomial_degree = 2,\n                 regressor = LinearRegression,\n                 regressor_parameters = {},\n                 t_initial = 'last',\n                 t_min = 20,\n                 t_max = 500,\n                 n_points = 500\n                 \n                ):\n        \n        self.confirmed = confirmed\n        self.confirmed_rate = confirmed_rate\n        self.deaths = deaths\n        self.deaths_rate = deaths_rate\n        self.recovered = recovered\n        self.recovered_rate = recovered_rate\n        self.time = time\n        self.window = window\n        self.min_periods = min_periods\n        self.center = center\n        self.polynomial_degree = polynomial_degree\n        self.regressor = regressor\n        self.regressor_parameters = regressor_parameters\n        self.t_initial = t_initial\n        self.t_min = t_min\n        self.t_max = t_max\n        self.n_points = 1+n_points\n        \n        \n    def fit(self,X,y):\n        \n        # Receiving the data\n        self.X = X[[self.time,self.confirmed,self.deaths,self.recovered]].copy()\n        self.y = y[[self.confirmed_rate,self.deaths_rate,self.recovered_rate]].copy()\n        \n        # Evaluating the rolling mean for X\n        for col in [self.confirmed,self.deaths,self.recovered]:  \n            self.X[col] = self.X[col].fillna(0).rolling(window = self.window,\n                                              min_periods = self.min_periods,\n                                              center = self.center\n                                             ).mean()\n            \n        # Evaluating the rolling mean for y    \n        for col in [self.confirmed_rate,self.deaths_rate,self.recovered_rate]:  \n            self.y[col] = self.y[col].fillna(0).rolling(window = self.window,\n                                              min_periods = self.min_periods,\n                                              center = self.center\n                                             ).mean()\n            \n        # Applying the log scale\n        self.X[self.time] = np.log1p(self.X[self.time])\n\n        for col in [self.confirmed,self.deaths,self.recovered]: \n            self.X[col] = np.log1p(self.X[col])\n            \n        for col in [self.confirmed_rate,self.deaths_rate,self.recovered_rate]: \n            self.y[col] = np.log1p(self.y[col])\n        \n        # Dropping NaN\n        temp = pd.concat([self.X,self.y],1).dropna()\n        self.X = temp[[self.time,self.confirmed,self.deaths,self.recovered]]\n        self.y = temp[[self.confirmed_rate,self.deaths_rate,self.recovered_rate]]\n            \n        # Pipeline for regression\n        regression_c = Pipeline(steps = [\n            ('polinomial',PolynomialFeatures(degree = self.polynomial_degree)),\n            ('regressor',self.regressor(**self.regressor_parameters)),\n        ])\n        regression_d = Pipeline(steps = [\n            ('polinomial',PolynomialFeatures(degree = self.polynomial_degree)),\n            ('regressor',self.regressor(**self.regressor_parameters)),\n        ])\n        regression_r = Pipeline(steps = [\n            ('polinomial',PolynomialFeatures(degree = self.polynomial_degree)),\n            ('regressor',self.regressor(**self.regressor_parameters)),\n        ])\n        \n        # Fitting model\n        regression_c.fit(self.X,self.y[self.confirmed_rate])\n        regression_d.fit(self.X,self.y[self.deaths_rate])\n        regression_r.fit(self.X,self.y[self.recovered_rate])\n        \n        \n        # Predicted Rates\n        self.predicted_rate = pd.concat([\n            self.X.reset_index(drop=True),\n            pd.DataFrame(regression_c.predict(self.X),columns = ['pred_'+self.confirmed_rate]),\n            pd.DataFrame(regression_d.predict(self.X),columns = ['pred_'+self.deaths_rate]),\n            pd.DataFrame(regression_r.predict(self.X),columns = ['pred_'+self.recovered_rate]),\n        ],1)\n        \n        for col in self.predicted_rate.columns:\n            self.predicted_rate[col] = np.expm1(self.predicted_rate[col])\n        \n        \n        # Defining the diferential equations\n        def diff_eq(x,t):\n            \"\"\"\n            Function resturning the differential equations of the model\n\n            \"\"\"\n            # setting the functions\n            c,r,d = x\n            lnt = np.log1p(t)\n            lnx = np.log1p(x)\n\n\n            # mathematical equations\n            DiffC = np.expm1(regression_c.predict([[lnt]+list(lnx)]))[0]\n            DiffD = np.expm1(regression_d.predict([[lnt]+list(lnx)]))[0]\n            DiffR = np.expm1(regression_r.predict([[lnt]+list(lnx)]))[0]\n\n            return np.array([DiffC,DiffD,DiffR])\n\n        def neg_diff_eq(x,t):\n            return -diff_eq(x,-t)\n        \n        if type(self.t_initial) == str:\n            if self.t_initial == 'last':\n                t_initial = int(round(list(self.predicted_rate[self.time])[-1]))\n        else:\n            t_initial = self.t_initial\n        \n        \n        ind_ref = self.predicted_rate[self.time][\n            round(self.predicted_rate[self.time]).astype(int) == t_initial].index[0]\n        \n        # initial conditions\n        t0,*x0 = np.expm1(list(self.X.iloc[ind_ref]))\n\n        n_points_right = int(round(self.n_points*(self.t_max-t0) / (self.t_max-self.t_min)))\n        n_points_left = int(round(self.n_points*(t0-self.t_min) / (self.t_max-self.t_min)))\n\n\n        # right integrate\n        days_list = np.linspace(t0,self.t_max,n_points_right)\n        x = odeint(diff_eq,x0,days_list)\n\n        # left integrate\n        neg_days_list = np.linspace(-t0,-self.t_min,n_points_left)\n        neg_x = odeint(neg_diff_eq,x0,neg_days_list)\n\n        #joinning solution\n        self.t_ode = np.concatenate((-neg_days_list[::-1], days_list))\n        self.x_ode = np.concatenate((neg_x[::-1], x))\n        \n        self.predictions = pd.concat([\n            pd.DataFrame(self.t_ode,columns = [self.time]),\n            pd.DataFrame(self.x_ode,columns = [self.confirmed,self.deaths,self.recovered])]\n        ,1)\n\n        return self\n        \n    def transform(self,X):\n        return X\n    \n    def predict(self,X):\n        \n       \n        return np.array([\n            np.interp(X, self.t_ode, self.x_ode[:,0]),\n            np.interp(X, self.t_ode, self.x_ode[:,1]),\n            np.interp(X, self.t_ode, self.x_ode[:,2]),\n        ])\n        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"0407\"></a>\n<h2>4.7 Size of Training Dataset<a href=\"#04\"\nstyle=\"\n    border-radius: 10px;\n    background-color: #f1f1f1;\n    border: none;\n    color: #37509b;\n    text-align: center;\n    text-decoration: none;\n    display: inline-block;\n    padding: 4px 4px;\n    font-size: 14px;\n\">↻</a></h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import Ridge","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cov19 = Covid19Regressor(window = 14,polynomial_degree = 2,t_initial = 300,t_max=365,regressor = LinearRegression)\ncov19.fit(dataset[['days','cases','deaths','recovered']],\n    dataset[['change_cases','change_deaths','change_recovered']])\n\nt_list = np.arange(20,365,1)\nx_list = cov19.predict(t_list)\n\nplt.figure(figsize=(8,5))\nplt.scatter(dataset['days'],0.000001*dataset['cases'],marker='.',s=80,alpha=0.3,color = colors[0],label='Confirmed Cases')\nplt.plot(t_list,0.000001*x_list[0],color=colors[0],linestyle='dashed',linewidth=1.3,label='Model - Cases')\n\nplt.scatter(dataset['days'],0.000001*dataset['deaths'],marker='.',s=80,alpha=0.3,color = colors[1],label='Deaths')\nplt.plot(t_list,0.000001*x_list[1],color=colors[1],linestyle='dashed',linewidth=1.3,label='Model - Deaths')\n\nplt.scatter(dataset['days'],0.000001*dataset['recovered'],marker='.',s=80,alpha=0.3,color = colors[2],label='Recoveries')\nplt.plot(t_list,0.000001*x_list[2],color=colors[2],linestyle='dashed',linewidth=1.3,label='Model - Recoveries')\n\n\nplt.title('Model for Covid-19')\nplt.xlabel('Days After First Case')\nplt.ylabel('Millions of Cases')\n# plt.legend(loc = 'lower right')\nplt.legend(bbox_to_anchor=(0.02, 0.6), loc=3, borderaxespad=0.)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(dataset['days'],0.000001*dataset['deaths'],marker='.',s=80,alpha=0.3,color = colors[1],label='Deaths')\nplt.plot(t_list,0.000001*x_list[1],color='k',linestyle='dashed',linewidth=1.3,label='Model - Deaths')\n\nplt.title('Model for Covid-19')\nplt.xlabel('Days After First Case')\nplt.ylabel('Millions of Cases')\n# plt.legend(loc = 'lower right')\nplt.legend(bbox_to_anchor=(0.02, 0.6), loc=3, borderaxespad=0.)\nplt.show()\nprint('Deaths after 365 days: %d' % x_list[1][-1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm\ndelta = 10\nnew_list = []\nfor final_index in tqdm(range(110,224,5)):\n    X_train = dataset.fillna(0).iloc[:final_index][['days','cases','deaths','recovered']]\n    y_train = dataset.fillna(0).iloc[:final_index][['change_cases','change_deaths','change_recovered']]\n    X_test = dataset.fillna(0).iloc[final_index:][['days','cases','deaths','recovered']]\n#     X_test = dataset.iloc[final_index:final_index+delta][['days','cases','deaths','recovered']]\n\n    cov19 = Covid19Regressor(window = 10,polynomial_degree = 1)\n    cov19.fit(X_train,y_train)\n\n    pred_tst = cov19.predict(X_test['days'])\n    \n    \n    new_list.append([100*final_index/(len(dataset)),\n        mean_absolute_error(X_test.iloc[:,1].values,np.nan_to_num(pred_tst[0])),\n        mean_absolute_error(X_test.iloc[:,2].values,np.nan_to_num(pred_tst[1])),\n        mean_absolute_error(X_test.iloc[:,3].values,np.nan_to_num(pred_tst[2]))\n    ])\n    \nnp.array(new_list)[:,1].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(np.array(new_list)[:,0],np.array(new_list)[:,1],label = 'Confirmed Cases')\nplt.plot(np.array(new_list)[:,0],np.array(new_list)[:,2],label = 'Deaths')\nplt.plot(np.array(new_list)[:,0],np.array(new_list)[:,3],label = 'Recovered Cases')\n\nplt.title('Absolute Error of Training Dataset')\nplt.xlabel('Training Dataset Size (%)')\nplt.ylabel('M.A.E. for Test Dataset')\nplt.yscale(\"log\")\nplt.legend(loc = 'upper right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}