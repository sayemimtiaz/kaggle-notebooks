{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport os\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn import svm\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import GridSearchCV\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#main_df = pd.read_csv('../input/titanicdataset-traincsv/train.csv')\nmain_df = pd.read_csv('../input/titanic/train.csv')\nunmodified_df = main_df\ntest_df = pd.read_csv('../input/titanic/test.csv')\nmain_df.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#FORMATTING TRAINING SET\nmain_df.columns=['Passengerid', 'survived', 'pclass', 'name', 'sex', 'age', 'sibsp',\n       'parch', 'ticket', 'fare', 'cabin', 'embarked']\n\n#FORMATTING TESTING SET\ntest_df.columns=['Passengerid','pclass', 'name', 'sex', 'age', 'sibsp',\n       'parch', 'ticket', 'fare', 'cabin', 'embarked']\n\nmain_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for dataframe in [main_df, test_df]:\n    label_status = LabelEncoder()\n\n    dataframe.loc[:,'contains_mr'] = dataframe.loc[:,'name'].str.lower().str.contains('|'.join(['mr','mister']))\n    dataframe.loc[:,'contains_mrs'] = dataframe.loc[:,'name'].str.lower().str.contains('|'.join(['mrs']))\n    dataframe.loc[:,'contains_ms'] = dataframe.loc[:,'name'].str.lower().str.contains('|'.join(['ms','miss','mlle','mme']))\n    dataframe.loc[:,'contains_master'] = dataframe.loc[:,'name'].str.lower().str.contains('|'.join(['master']))\n    dataframe.loc[:,'contains_sir'] = dataframe.loc[:,'name'].str.lower().str.contains('|'.join(['sir','jonkheer','col','major','don']))\n    dataframe.loc[:,'contains_rev'] = dataframe.loc[:,'name'].str.lower().str.contains('|'.join(['rev','reverend']))\n    dataframe.loc[:,'contains_lady'] = dataframe.loc[:,'name'].str.lower().str.contains('|'.join(['lady','dona','the countess']))\n    dataframe.loc[:,'contains_dr'] = dataframe.loc[:,'name'].str.lower().str.contains('|'.join(['dr','doctor']))\n    dataframe.loc[:,'contains_col'] = dataframe.loc[:,'name'].str.lower().str.contains('|'.join(['col']))\n\n\n    dataframe['contains_mr'] = label_status.fit_transform(dataframe['contains_mr'])\n    dataframe['contains_mrs'] = label_status.fit_transform(dataframe['contains_mrs'])\n    dataframe['contains_ms'] = label_status.fit_transform(dataframe['contains_ms'])\n    dataframe['contains_master'] = label_status.fit_transform(dataframe['contains_master'])\n    dataframe['contains_sir'] = label_status.fit_transform(dataframe['contains_sir'])\n    dataframe['contains_rev'] = label_status.fit_transform(dataframe['contains_rev'])\n    dataframe['contains_lady'] = label_status.fit_transform(dataframe['contains_lady'])\n    dataframe['contains_dr'] = label_status.fit_transform(dataframe['contains_dr'])\n    dataframe['contains_col'] = label_status.fit_transform(dataframe['contains_col'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"main_df['cabin']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"main_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for dataset in [main_df, test_df]:\n\n    # Feature Engineering\n\n    # Joining all family members together\n    dataset['family'] = dataset.loc[:,'sibsp'] + dataset.loc[:,'parch'] + 1\n\n    # Filling missing fare values and assigning var to missing fare\n    dataset['age'] = dataset.loc[:,'age'].fillna(dataset['age'].median()+.01)\n    dataset['missing_age'] = dataset.loc[:,'age']==28.01\n    dataset['fare'] = dataset.loc[:,'fare'].fillna(dataset['fare'].median())\n    dataset['cabin_pp'] = dataset['cabin'].fillna('x')\n    dataset['cabin_pp'] = dataset.loc[:,'cabin_pp'].apply(lambda x: x[0])\n    dataset['missing_cabin'] = dataset.loc[:,'cabin_pp']=='x'\n    dataset['embarked'] = dataset['embarked'].fillna('S')\n    dataset['age'] = dataset['age'].fillna(dataset['age'].median())\n    dataset['ticket_cn'] = np.where(dataset.ticket != '1601',0,1)\n    \n    dataset.loc[:,'no_fam'] = dataset.loc[:,'family'].astype(int)==1\n    dataset.loc[:,'fam_less_than_4'] = ((dataset.loc[:,'family'].astype(int)>1) & (dataset.loc[:,'family'].astype(int)<4))\n    dataset.loc[:,'fam_greater_than_4'] = dataset.loc[:,'family'].astype(int)>4\n    \n    # converts range into simple encoded 0,1 scalar\n    label_status = LabelEncoder()\n    dataset['sex'] = label_status.fit_transform(dataset['sex'])\n    dataset['embarked'] = label_status.fit_transform(dataset['embarked'])\n    dataset['cabin_pp'] = label_status.fit_transform(dataset['cabin_pp'])\n    dataset['missing_age'] = label_status.fit_transform(dataset['missing_age'])\n    dataset['missing_cabin'] = label_status.fit_transform(dataset['missing_cabin'])\n    dataset['ticket_cn'] = label_status.fit_transform(dataset['ticket_cn'])\n\n    dataset['no_fam'] = label_status.fit_transform(dataset['no_fam'])\n    dataset['fam_less_than_4'] = label_status.fit_transform(dataset['fam_less_than_4'])\n    dataset['fam_greater_than_4'] = label_status.fit_transform(dataset['fam_greater_than_4'])\n    \nmain_df.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = main_df.corr()\ncorr.style.background_gradient(cmap='coolwarm')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for dataset in [main_df, test_df]:\n    dataset = dataset.select_dtypes('number').dropna() \n\ny = main_df['survived']\nX = main_df.drop(['survived','sibsp','parch','name','cabin','ticket',], axis=1)\ntest_df_sample = test_df.drop(['name','sibsp','parch','cabin','ticket',], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# TRAIN TEST SPLIT"},{"metadata":{"trusted":true},"cell_type":"code","source":"#split data into test and train\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=(2**32 - 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#weights of int/floats important\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# DecisionTreeClassifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"dtc = DecisionTreeClassifier(criterion='entropy',max_depth=3,)\ndtc.fit(X_train,y_train)\npred_dtc = dtc.predict(X_test)\n#Lets see how they preformed!\nprint(classification_report(y_test, pred_dtc))\nprint(confusion_matrix(y_test, pred_dtc))\naccuracy = dtc.score(X_test, y_test)\nprint(f'Decision Tree Classifier Accuracy: {accuracy}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Random Forest Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc = RandomForestClassifier(n_estimators=200, criterion='entropy') #best for medium-sized datasets # max_depth=10\nrfc.fit(X_train, y_train)\n\n# TEST THE TRAINING DATA\npred_rfc_train = rfc.predict(X_train)\npred_rfc = rfc.predict(X_test)\npred_rfc_final = rfc.predict(test_df_sample)\n#Lets see how they preformed!\nprint(classification_report(y_test, pred_rfc))\nprint(confusion_matrix(y_test, pred_rfc))\naccuracy = rfc.score(X_test, y_test)\nprint(f'Random Forest Classifier Accuracy: {accuracy}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_rfc_final = rfc.predict(test_df_sample)\nsubmission = pd.DataFrame({'PassengerId':test_df['Passengerid'],'Survived':pred_rfc_final})\nsubmission.to_csv('./horrigan_submission_rfc_v2.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"lrc = LogisticRegression()\nlrc.fit(X_train,y_train)\npred_lrc = lrc.predict(X_test)\npred_lrc_final = lrc.predict(test_df_sample)\n#Lets see how they preformed!\nprint(classification_report(y_test, pred_lrc))\nprint(confusion_matrix(y_test, pred_lrc))\naccuracy = lrc.score(X_test, y_test)\nprint(f'Logistic Regression Classifier Accuracy: {accuracy}')\n\nsubmission = pd.DataFrame({'PassengerId':test_df['Passengerid'],'Survived':pred_lrc_final})\nsubmission.to_csv('./horrigan_submission_lrc.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# SVM Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"svm = svm.SVC() # best on smaller numbers\nsvm.fit(X_train, y_train)\npred_svm=svm.predict(X_test)\n\ntest_df_sample = sc.transform(test_df_sample)\npred_svm_final = svm.predict(test_df_sample)   \n     \nsubmission = pd.DataFrame({'PassengerId':test_df['Passengerid'],'Survived':pred_svm_final})\nsubmission.to_csv('./horrigan_submission_svm.csv')\n\nprint(classification_report(y_test, pred_svm))\nprint(confusion_matrix(y_test, pred_svm))\naccuracy = svm.score(X_test, y_test)\nprint(f'Support Vector Machine Classifier Accuracy: {accuracy}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Neural Networks"},{"metadata":{"trusted":true},"cell_type":"code","source":"mlpc = MLPClassifier(hidden_layer_sizes=(5,5,5),max_iter=500)\nmlpc.fit(X_train, y_train)\npred_mlpc=mlpc.predict(X_test)\nprint(classification_report(y_test, pred_mlpc))\nprint(confusion_matrix(y_test, pred_mlpc))\naccuracy = mlpc.score(X_test, y_test)\nprint(f'Neural Network Classifier Accuracy: {accuracy}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nsvm_score = accuracy_score(y_test, pred_svm)\nrfc_score = accuracy_score(y_test, pred_rfc)\nmlpc_score = accuracy_score(y_test, pred_mlpc)\ndtc_score = accuracy_score(y_test,pred_dtc)\n\nprint(f'Support Vector Machine Classifier: {svm_score}')\nprint(f'Random Forest Classifier: {rfc_score}')\nprint(f'Neural Network Classifier: {mlpc_score}')\nprint(f'Decision Tree Classifier: {dtc_score}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nmodels = [\n    ('Logistic Regression Classifier:', LogisticRegression()),\n    #('Naive Bayes Gaussian NB:', GaussianNB()),\n    ('Support Vector Machine Classifier:', SVC()),\n    ('KNeighbors Classifier:', KNeighborsClassifier()),\n    ('Decision Tree Classifier:', DecisionTreeClassifier()),\n    ('Neural Network Classifier',MLPClassifier(hidden_layer_sizes=(10,10,10),max_iter=600)),\n    ('Random Forest Classifier',RandomForestClassifier(n_estimators=200, criterion='entropy',)),]\n\nfor dataset_name, dataset, label in [('UNMODIFIED',unmodified_df,'survived'),('FEATURE ENGINEERED SET',main_df,'survived')]:\n    dataset=dataset.select_dtypes('number').dropna()\n    y = np.array(dataset[label])\n    X = np.array(dataset.drop(label, axis=1))\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=(2**32 - 1))\n    sc = StandardScaler()\n    X_train = sc.fit_transform(X_train)\n    X_test = sc.transform(X_test)\n    print(dataset_name)\n    for name, model in models:\n        clf = model\n        clf.fit(X_train, y_train)\n        accuracy = clf.score(X_test, y_test)\n        print(name, accuracy)\n    \n    print('------ BREAK -------')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model = RandomForestClassifier(n_estimators=100,)\n\n#n_estim = range(100,1000,100)\n#criterion = ['entropy','gini']\n\n#param_grid = {\"n_estimators\" :n_estim,'criterion':criterion}\n#model_rfc = GridSearchCV(model,param_grid = param_grid, cv=5, scoring=\"accuracy\", n_jobs=4, verbose = 1)\n#model_rfc.fit(X_train,y_train)\n\n# Best score\n#print(model_rfc.best_score_)\n\n#best estimator\n#model_rfc.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model_rfc.best_params_\ndf = pd.read_csv('./horrigan_submission_svm.csv')\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# filled NA = extra column telling it is filled\n# actual OHE\n# tree-based feature engineering can cause more noise","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}