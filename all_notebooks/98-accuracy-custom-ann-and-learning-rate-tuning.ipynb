{"cells":[{"metadata":{"papermill":{"duration":0.040189,"end_time":"2021-02-03T10:33:46.901315","exception":false,"start_time":"2021-02-03T10:33:46.861126","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Breast Cancer predictions using custom ANN "},{"metadata":{"papermill":{"duration":0.037356,"end_time":"2021-02-03T10:33:46.977335","exception":false,"start_time":"2021-02-03T10:33:46.939979","status":"completed"},"tags":[]},"cell_type":"markdown","source":"### A Sample notebook which gives a method to construct a neural network from scratch, that means we are not using any of the predefined libraries like tensorflow, keras etc.\n\nFor this purpose I'm using real life Dataset.\n\nHope you like the work! ðŸ˜Š"},{"metadata":{"papermill":{"duration":0.03713,"end_time":"2021-02-03T10:33:47.052651","exception":false,"start_time":"2021-02-03T10:33:47.015521","status":"completed"},"tags":[]},"cell_type":"markdown","source":"## Importing Libs"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2021-02-03T10:33:47.13907Z","iopub.status.busy":"2021-02-03T10:33:47.138169Z","iopub.status.idle":"2021-02-03T10:33:47.141839Z","shell.execute_reply":"2021-02-03T10:33:47.142568Z"},"papermill":{"duration":0.050412,"end_time":"2021-02-03T10:33:47.142993","exception":false,"start_time":"2021-02-03T10:33:47.092581","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport math","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-02-03T10:33:47.225595Z","iopub.status.busy":"2021-02-03T10:33:47.224708Z","iopub.status.idle":"2021-02-03T10:33:47.329831Z","shell.execute_reply":"2021-02-03T10:33:47.33088Z"},"papermill":{"duration":0.149374,"end_time":"2021-02-03T10:33:47.331103","exception":false,"start_time":"2021-02-03T10:33:47.181729","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"dataset = pd.read_csv('../input/breast-cancer-wisconsin-data/data.csv')\ndataset = dataset.fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-02-03T10:33:47.436493Z","iopub.status.busy":"2021-02-03T10:33:47.425913Z","iopub.status.idle":"2021-02-03T10:33:47.47703Z","shell.execute_reply":"2021-02-03T10:33:47.476118Z"},"papermill":{"duration":0.105968,"end_time":"2021-02-03T10:33:47.477231","exception":false,"start_time":"2021-02-03T10:33:47.371263","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-02-03T10:33:47.567084Z","iopub.status.busy":"2021-02-03T10:33:47.565484Z","iopub.status.idle":"2021-02-03T10:33:47.59276Z","shell.execute_reply":"2021-02-03T10:33:47.59188Z"},"papermill":{"duration":0.075553,"end_time":"2021-02-03T10:33:47.592945","exception":false,"start_time":"2021-02-03T10:33:47.517392","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"dataset.info()","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.041062,"end_time":"2021-02-03T10:33:47.674777","exception":false,"start_time":"2021-02-03T10:33:47.633715","status":"completed"},"tags":[]},"cell_type":"markdown","source":"### no null value found ðŸ‘€"},{"metadata":{"papermill":{"duration":0.386895,"end_time":"2021-02-03T10:34:46.405266","exception":false,"start_time":"2021-02-03T10:34:46.018371","status":"completed"},"tags":[]},"cell_type":"markdown","source":"## It's just a demonstration for building a neural network, so we'll not look for EDA in depth.\n"},{"metadata":{"papermill":{"duration":0.380582,"end_time":"2021-02-03T10:34:47.168251","exception":false,"start_time":"2021-02-03T10:34:46.787669","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Let's get started with our network"},{"metadata":{"execution":{"iopub.execute_input":"2021-02-03T10:34:47.887876Z","iopub.status.busy":"2021-02-03T10:34:47.887065Z","iopub.status.idle":"2021-02-03T10:34:47.893528Z","shell.execute_reply":"2021-02-03T10:34:47.893991Z"},"papermill":{"duration":0.345034,"end_time":"2021-02-03T10:34:47.894163","exception":false,"start_time":"2021-02-03T10:34:47.549129","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"X = dataset.iloc[:,2:-1].values\ny = dataset.iloc[:,1:2].values\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder;\nle =LabelEncoder();\ny = le.fit_transform(y);\ny=y.reshape(569,1)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.386176,"end_time":"2021-02-03T10:34:48.659058","exception":false,"start_time":"2021-02-03T10:34:48.272882","status":"completed"},"tags":[]},"cell_type":"markdown","source":"## Train test split"},{"metadata":{"execution":{"iopub.execute_input":"2021-02-03T10:34:49.431579Z","iopub.status.busy":"2021-02-03T10:34:49.430638Z","iopub.status.idle":"2021-02-03T10:34:49.627191Z","shell.execute_reply":"2021-02-03T10:34:49.627884Z"},"papermill":{"duration":0.585781,"end_time":"2021-02-03T10:34:49.628117","exception":false,"start_time":"2021-02-03T10:34:49.042336","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.380854,"end_time":"2021-02-03T10:34:50.387766","exception":false,"start_time":"2021-02-03T10:34:50.006912","status":"completed"},"tags":[]},"cell_type":"markdown","source":"## Feature Scaling"},{"metadata":{"papermill":{"duration":0.37418,"end_time":"2021-02-03T10:34:51.960544","exception":false,"start_time":"2021-02-03T10:34:51.586364","status":"completed"},"tags":[]},"cell_type":"markdown","source":"### Scaled data will help in training of neural network, i generally speeds up the gradient descent!!"},{"metadata":{"execution":{"iopub.execute_input":"2021-02-03T10:34:51.152304Z","iopub.status.busy":"2021-02-03T10:34:51.151358Z","iopub.status.idle":"2021-02-03T10:34:51.165358Z","shell.execute_reply":"2021-02-03T10:34:51.166093Z"},"papermill":{"duration":0.396672,"end_time":"2021-02-03T10:34:51.166347","exception":false,"start_time":"2021-02-03T10:34:50.769675","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.378798,"end_time":"2021-02-03T10:34:52.722742","exception":false,"start_time":"2021-02-03T10:34:52.343944","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# 1. Intializing Parameters"},{"metadata":{"papermill":{"duration":0.381924,"end_time":"2021-02-03T10:34:53.528725","exception":false,"start_time":"2021-02-03T10:34:53.146801","status":"completed"},"tags":[]},"cell_type":"markdown","source":"## He Initialization\n"},{"metadata":{"execution":{"iopub.execute_input":"2021-02-03T10:34:54.308606Z","iopub.status.busy":"2021-02-03T10:34:54.307439Z","iopub.status.idle":"2021-02-03T10:34:54.320484Z","shell.execute_reply":"2021-02-03T10:34:54.319585Z"},"papermill":{"duration":0.399757,"end_time":"2021-02-03T10:34:54.320666","exception":false,"start_time":"2021-02-03T10:34:53.920909","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"def initialize_params(layer_dims):\n    \n    \"\"\"\n    Arguments:\n    layer_dims -- python array (list) containing the size of each layer.\n    \n    Returns:\n    parameters -- python dictionary containing your parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n                    W1 -- weight matrix of shape (layers_dims[1], layers_dims[0])\n                    b1 -- bias vector of shape (layers_dims[1], 1)\n                    ...\n                    WL -- weight matrix of shape (layers_dims[L], layers_dims[L-1])\n                    bL -- bias vector of shape (layers_dims[L], 1)\n    \"\"\"\n    params = {}\n    np.random.seed(42)\n    L = len(layer_dims)-1\n    for l in range (L):\n        params[\"W\"+str(l+1)] = np.random.randn(layer_dims[l+1],layer_dims[l])*(2/layer_dims[l])**0.5\n        params[\"b\"+str(l+1)] = np.zeros((layer_dims[l+1],1))\n    \n    return params","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.37996,"end_time":"2021-02-03T10:34:55.084563","exception":false,"start_time":"2021-02-03T10:34:54.704603","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# 2. Forward Propagation"},{"metadata":{"papermill":{"duration":0.381363,"end_time":"2021-02-03T10:34:55.845411","exception":false,"start_time":"2021-02-03T10:34:55.464048","status":"completed"},"tags":[]},"cell_type":"markdown","source":"We are using a model with last layer having activation sigmoid and all other layers with ReLu as activation function"},{"metadata":{"execution":{"iopub.execute_input":"2021-02-03T10:34:56.617424Z","iopub.status.busy":"2021-02-03T10:34:56.61656Z","iopub.status.idle":"2021-02-03T10:34:56.622488Z","shell.execute_reply":"2021-02-03T10:34:56.621449Z"},"papermill":{"duration":0.394039,"end_time":"2021-02-03T10:34:56.62267","exception":false,"start_time":"2021-02-03T10:34:56.228631","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"def Linear_forward(A,W,b):\n    Z = np.dot(W,A)+b\n    cache = (A,W,b)\n    return Z,cache","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-02-03T10:34:57.396888Z","iopub.status.busy":"2021-02-03T10:34:57.396018Z","iopub.status.idle":"2021-02-03T10:34:57.399936Z","shell.execute_reply":"2021-02-03T10:34:57.400616Z"},"papermill":{"duration":0.396919,"end_time":"2021-02-03T10:34:57.400844","exception":false,"start_time":"2021-02-03T10:34:57.003925","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"def Activation_forward(A,W,b,Activation):\n    if Activation == \"relu\":\n        Z,Linear_cache = Linear_forward(A,W,b)\n        A  = np.maximum(0,Z)\n        A, activation_cache = A,Z\n    elif Activation == 'sigmoid':\n        Z,Linear_cache = Linear_forward(A,W,b)\n        A,activation_cache = (1/(1+np.exp(-Z)),Z)\n    cache= (Linear_cache,activation_cache)\n    return A,cache","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-02-03T10:34:58.176234Z","iopub.status.busy":"2021-02-03T10:34:58.175343Z","iopub.status.idle":"2021-02-03T10:34:58.180432Z","shell.execute_reply":"2021-02-03T10:34:58.179499Z"},"papermill":{"duration":0.396222,"end_time":"2021-02-03T10:34:58.180613","exception":false,"start_time":"2021-02-03T10:34:57.784391","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"def forward_prop(X,params):\n    A=X\n    caches = []\n    L = len(params)//2\n    for l in range (L-1):\n        A_prev = A\n        A, cache = Activation_forward(A_prev,params[\"W\"+str(l+1)],params[\"b\"+str(l+1)],\"relu\")\n        caches.append(cache)\n    AL,cache = Activation_forward(A,params[\"W\"+str(L)],params[\"b\"+str(L)],\"sigmoid\")\n    caches.append(cache)\n    return AL,caches","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-02-03T10:34:58.952343Z","iopub.status.busy":"2021-02-03T10:34:58.951675Z","iopub.status.idle":"2021-02-03T10:34:58.955987Z","shell.execute_reply":"2021-02-03T10:34:58.956723Z"},"papermill":{"duration":0.397293,"end_time":"2021-02-03T10:34:58.956961","exception":false,"start_time":"2021-02-03T10:34:58.559668","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"def cost(AL,Y) :\n    m = Y.shape[1]\n    cost = -np.sum(Y*np.log(AL)+(1-Y)*np.log(1-AL))/m\n    return np.squeeze(cost)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.382751,"end_time":"2021-02-03T10:34:59.720621","exception":false,"start_time":"2021-02-03T10:34:59.33787","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# 3. Backward Propagation"},{"metadata":{"execution":{"iopub.execute_input":"2021-02-03T10:35:00.491696Z","iopub.status.busy":"2021-02-03T10:35:00.490766Z","iopub.status.idle":"2021-02-03T10:35:00.497542Z","shell.execute_reply":"2021-02-03T10:35:00.498273Z"},"papermill":{"duration":0.396545,"end_time":"2021-02-03T10:35:00.498503","exception":false,"start_time":"2021-02-03T10:35:00.101958","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"def linear_backward(dZ,cache):\n    A_prev,W,b = cache\n    m =A_prev.shape[1]\n    dW = (np.dot(dZ,A_prev.T)/m) \n    db = np.sum(dZ,axis=1,keepdims=True)/m\n    dA_prev = np.dot(W.T,dZ)\n    return dA_prev , dW , db","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-02-03T10:35:01.251064Z","iopub.status.busy":"2021-02-03T10:35:01.250135Z","iopub.status.idle":"2021-02-03T10:35:01.255174Z","shell.execute_reply":"2021-02-03T10:35:01.254234Z"},"papermill":{"duration":0.37578,"end_time":"2021-02-03T10:35:01.255398","exception":false,"start_time":"2021-02-03T10:35:00.879618","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"def activation_backward(dA,cache,activation):\n    linear_cache,activation_cache = cache\n    Z=activation_cache\n    if activation == \"relu\":\n        dZ = (Z>0).astype(int)\n        dZ = dA*dZ\n        dA_prev, dW, db = linear_backward(dZ,linear_cache)\n    elif activation == \"sigmoid\":\n        dZ = np.multiply(dA,(1/(1+np.exp(-Z)))*(1-(1/(1+np.exp(-Z)))))\n        dA_prev, dW, db = linear_backward(dZ,linear_cache)\n    \n    return dA_prev, dW, db","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-02-03T10:35:02.032005Z","iopub.status.busy":"2021-02-03T10:35:02.03113Z","iopub.status.idle":"2021-02-03T10:35:02.044267Z","shell.execute_reply":"2021-02-03T10:35:02.044905Z"},"papermill":{"duration":0.396775,"end_time":"2021-02-03T10:35:02.045117","exception":false,"start_time":"2021-02-03T10:35:01.648342","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"def backward_prop(AL,Y,caches):\n    \n    L = len(caches)\n    m = AL.shape[1]\n    Y = Y.reshape(AL.shape)\n    grads = {}\n    \n    grads[\"dA\"+str(L)] = -(np.divide(Y,AL)-np.divide(1-Y,1-AL))\n    \n    current_cache = caches[L-1]\n    \n    grads[\"dA\" + str(L-1)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] =  activation_backward(grads[\"dA\"+str(L)], current_cache, 'sigmoid')\n    for l in reversed (range(L-1)):\n        current_cache = caches[l]\n        dA_prev_temp, dW_temp, db_temp =  activation_backward(grads['dA'+str(l+1)], current_cache, 'relu')\n        grads[\"dA\" + str(l)] = dA_prev_temp\n        grads[\"dW\" + str(l + 1)] = dW_temp\n        grads[\"db\" + str(l + 1)] = db_temp\n        \n    return grads\n        ","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.38464,"end_time":"2021-02-03T10:35:02.836689","exception":false,"start_time":"2021-02-03T10:35:02.452049","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# 4. Making Mini Batches"},{"metadata":{"execution":{"iopub.execute_input":"2021-02-03T10:35:03.60729Z","iopub.status.busy":"2021-02-03T10:35:03.606431Z","iopub.status.idle":"2021-02-03T10:35:03.619434Z","shell.execute_reply":"2021-02-03T10:35:03.619981Z"},"papermill":{"duration":0.401724,"end_time":"2021-02-03T10:35:03.620172","exception":false,"start_time":"2021-02-03T10:35:03.218448","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"def random_mini_batches(X, Y, mini_batch_size ):\n    \"\"\"\n    Creates a list of random minibatches from (X, Y)\n    \n    Arguments:\n    X -- input data, of shape (input size, number of examples)\n    Y -- true \"label\" vector (1 for blue dot / 0 for red dot), of shape (1, number of examples)\n    mini_batch_size -- size of the mini-batches, integer\n    \n    Returns:\n    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n    \"\"\"\n    \n\n    m = X.shape[1]                  # number of training examples\n    mini_batches = []\n    np.random.seed(42)\n    # Step 1: Shuffle (X, Y)\n    permutation = list(np.random.permutation(m))\n    shuffled_X = X[:, permutation]\n    shuffled_Y = Y[:, permutation].reshape((1,m))\n\n    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n    for k in range(0, num_complete_minibatches):\n        \n        mini_batch_X = shuffled_X[:,k*mini_batch_size:(k+1)*mini_batch_size]\n        mini_batch_Y = shuffled_Y[:,k*mini_batch_size:(k+1)*mini_batch_size]\n     \n        mini_batch = (mini_batch_X, mini_batch_Y)\n        mini_batches.append(mini_batch)\n    \n    # Handling the end case (last mini-batch < mini_batch_size)\n    if m % mini_batch_size != 0:\n        \n        mini_batch_X = shuffled_X[:,num_complete_minibatches*mini_batch_size:m]\n        mini_batch_Y = shuffled_Y[:,num_complete_minibatches*mini_batch_size:m]\n        \n        mini_batch = (mini_batch_X, mini_batch_Y)\n        mini_batches.append(mini_batch)\n    \n    return mini_batches","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.382893,"end_time":"2021-02-03T10:35:04.367854","exception":false,"start_time":"2021-02-03T10:35:03.984961","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# 5. Gradient descent with ADAM optimization"},{"metadata":{"execution":{"iopub.execute_input":"2021-02-03T10:35:05.144701Z","iopub.status.busy":"2021-02-03T10:35:05.143795Z","iopub.status.idle":"2021-02-03T10:35:05.154931Z","shell.execute_reply":"2021-02-03T10:35:05.154187Z"},"papermill":{"duration":0.399166,"end_time":"2021-02-03T10:35:05.155123","exception":false,"start_time":"2021-02-03T10:35:04.755957","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"def initialize_adam(parameters) :\n    L = len(parameters) // 2 # number of layers in the neural networks\n    v = {}\n    s = {}\n    \n    # Initialize v, s. Input: \"parameters\". Outputs: \"v, s\".\n    for l in range(L):\n    \n        v[\"dW\" + str(l+1)] = np.zeros(parameters[\"W\"+str(l+1)].shape)\n        v[\"db\" + str(l+1)] = np.zeros(parameters[\"b\"+str(l+1)].shape)\n        s[\"dW\" + str(l+1)] = np.zeros(parameters[\"W\"+str(l+1)].shape)\n        s[\"db\" + str(l+1)] = np.zeros(parameters[\"b\"+str(l+1)].shape)\n        \n    \n    return v, s","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-02-03T10:35:05.93792Z","iopub.status.busy":"2021-02-03T10:35:05.936934Z","iopub.status.idle":"2021-02-03T10:35:05.957228Z","shell.execute_reply":"2021-02-03T10:35:05.956312Z"},"papermill":{"duration":0.417843,"end_time":"2021-02-03T10:35:05.957407","exception":false,"start_time":"2021-02-03T10:35:05.539564","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"def update_parameters_with_adam(parameters, grads, v, s, t, learning_rate = 0.01, beta1 = 0.9, beta2 = 0.999,  epsilon = 1e-8):\n    L = len(parameters) // 2                 # number of layers in the neural networks\n    v_corrected = {}                         # Initializing first moment estimate, python dictionary\n    s_corrected = {}                         # Initializing second moment estimate, python dictionary\n    \n    # Perform Adam update on all parameters\n    for l in range(L):\n        # Moving average of the gradients. Inputs: \"v, grads, beta1\". Output: \"v\".\n       \n        v[\"dW\" + str(l+1)] = beta1*v[\"dW\"+str(l+1)]+(1-beta1)*grads[\"dW\"+str(l+1)]\n        v[\"db\" + str(l+1)] = beta1*v[\"db\"+str(l+1)]+(1-beta1)*grads[\"db\"+str(l+1)]\n       \n\n        # Compute bias-corrected first moment estimate. Inputs: \"v, beta1, t\". Output: \"v_corrected\".\n        \n        v_corrected[\"dW\" + str(l+1)] = v[\"dW\"+str(l+1)]/(1-beta1**t)\n        v_corrected[\"db\" + str(l+1)] = v[\"db\"+str(l+1)]/(1-beta1**t)\n        \n        # Moving average of the squared gradients. Inputs: \"s, grads, beta2\". Output: \"s\".\n        s[\"dW\" + str(l+1)] = beta2*s[\"dW\"+str(l+1)]+(1-beta2)*grads[\"dW\"+str(l+1)]**2\n        s[\"db\" + str(l+1)] = beta2*s[\"db\"+str(l+1)]+(1-beta2)*grads[\"db\"+str(l+1)]**2\n\n\n        # Compute bias-corrected second raw moment estimate. Inputs: \"s, beta2, t\". Output: \"s_corrected\".\n     \n        s_corrected[\"dW\" + str(l+1)] = s[\"dW\"+str(l+1)]/(1-beta2**t)\n        s_corrected[\"db\" + str(l+1)] = s[\"db\"+str(l+1)]/(1-beta2**t)\n        \n\n        # Update parameters. Inputs: \"parameters, learning_rate, v_corrected, s_corrected, epsilon\". Output: \"parameters\".\n\n        parameters[\"W\" + str(l+1)] = parameters[\"W\"+str(l+1)] - learning_rate*(v_corrected[\"dW\"+str(l+1)]/((s_corrected[\"dW\"+str(l+1)]**0.5)+epsilon))\n        parameters[\"b\" + str(l+1)] = parameters[\"b\"+str(l+1)] - learning_rate*(v_corrected[\"db\"+str(l+1)]/((s_corrected[\"db\"+str(l+1)]**0.5)+epsilon))\n   \n\n    return parameters, v, s","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Gentle Reminder for an Upvote ðŸ˜!!"},{"metadata":{"papermill":{"duration":0.389355,"end_time":"2021-02-03T10:35:06.730605","exception":false,"start_time":"2021-02-03T10:35:06.34125","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# 6. Model code (Combining Every thing) "},{"metadata":{"execution":{"iopub.execute_input":"2021-02-03T10:35:07.517685Z","iopub.status.busy":"2021-02-03T10:35:07.511716Z","iopub.status.idle":"2021-02-03T10:35:07.524409Z","shell.execute_reply":"2021-02-03T10:35:07.52349Z"},"papermill":{"duration":0.407701,"end_time":"2021-02-03T10:35:07.524595","exception":false,"start_time":"2021-02-03T10:35:07.116894","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"def model(X, Y, layers_dims, optimizer, learning_rate = 0.0007, mini_batch_size = 16, beta = 0.9,beta1 = 0.9, beta2 = 0.999,  epsilon = 1e-8, num_epochs = 50, print_cost = True):\n    L = len(layers_dims)             # number of layers in the neural networks\n    costs = []                       # to keep track of the cost\n    t = 0  \n    m =X.shape[1]\n    \n    params = initialize_params(layers_dims)\n    \n    v, s = initialize_adam(params)\n    \n    for i in range(num_epochs):\n        minibatches = random_mini_batches(X, Y, mini_batch_size)\n        cost_total = 0\n        for minibatch in minibatches:\n            \n            (minibatch_X,minibatch_Y) = minibatch\n            AL, caches = forward_prop(minibatch_X, params)\n            \n            cost_total += cost(AL, minibatch_Y)\n            \n            grads = backward_prop(AL, minibatch_Y, caches)\n            t=t+1\n            params, v, s = update_parameters_with_adam(params, grads, v, s, t, learning_rate, beta1, beta2,  epsilon)\n            \n        cost_avg = cost_total / m\n            \n        if print_cost and i %10 == 0:\n            print (\"Cost after epoch %i: %f\" %(i, cost_avg))\n        costs.append(cost_avg)\n                \n    plt.plot(costs)\n    plt.ylabel('cost')\n    plt.xlabel('epochs')\n    plt.title(\"Learning rate = \" + str(learning_rate))\n    plt.show()\n\n    return params","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.364643,"end_time":"2021-02-03T10:35:08.237941","exception":false,"start_time":"2021-02-03T10:35:07.873298","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# 7. Predictions"},{"metadata":{"execution":{"iopub.execute_input":"2021-02-03T10:35:08.979994Z","iopub.status.busy":"2021-02-03T10:35:08.979112Z","iopub.status.idle":"2021-02-03T10:35:08.9851Z","shell.execute_reply":"2021-02-03T10:35:08.98423Z"},"papermill":{"duration":0.363897,"end_time":"2021-02-03T10:35:08.985323","exception":false,"start_time":"2021-02-03T10:35:08.621426","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"def predict(X,y,parameters):\n    \n    pre, cache = forward_prop(X,parameters)\n    predictions = (pre>0.5).astype(int)\n    from sklearn.metrics import accuracy_score\n    \n    print(accuracy_score(predictions[0],y[0]))\n    return predictions\n\n    ","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.390011,"end_time":"2021-02-03T10:35:09.762944","exception":false,"start_time":"2021-02-03T10:35:09.372933","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# 8. Training our model"},{"metadata":{"execution":{"iopub.execute_input":"2021-02-03T10:35:10.546019Z","iopub.status.busy":"2021-02-03T10:35:10.545125Z","iopub.status.idle":"2021-02-03T10:40:10.623957Z","shell.execute_reply":"2021-02-03T10:40:10.624693Z"},"papermill":{"duration":300.475207,"end_time":"2021-02-03T10:40:10.624892","exception":false,"start_time":"2021-02-03T10:35:10.149685","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"layers_dims = [X.shape[1],6,2,1]\nlrates = [1e-4,2e-4,3e-4,5e-4,6e-4,7e-4,8e-4,9e-4,1e-3]\nfor lr in lrates:\n    params = model(X_train.T, y_train.T ,layers_dims, optimizer = \"adam\",learning_rate=lr)\n    print(\"Train Accuracy:\")\n    predictions_train = predict(X_train.T, y_train.T, params)\n    print(\"Test Accuracy:\")  \n    predictions_test = predict(X_test.T, y_test.T, params)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Learning rates 0.0009 - 0.001 works fine!!"},{"metadata":{"papermill":{"duration":0.4028,"end_time":"2021-02-03T10:40:11.392156","exception":false,"start_time":"2021-02-03T10:40:10.989356","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# 9. Making Predictions"},{"metadata":{"execution":{"iopub.execute_input":"2021-02-03T10:40:12.203155Z","iopub.status.busy":"2021-02-03T10:40:12.201891Z","iopub.status.idle":"2021-02-03T10:40:12.216908Z","shell.execute_reply":"2021-02-03T10:40:12.216136Z"},"papermill":{"duration":0.430455,"end_time":"2021-02-03T10:40:12.217079","exception":false,"start_time":"2021-02-03T10:40:11.786624","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"parameters = model(X_train.T, y_train.T ,layers_dims=[X.shape[1],6,2,1], optimizer = \"adam\",learning_rate=0.00095)\nprint(\"Accuracy\")\npredictions = predict(X_test.T, y_test.T, parameters)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nconfusion_matrix(y_test.reshape(1,y_test.shape[0])[0],predictions[0])","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.380185,"end_time":"2021-02-03T10:40:14.592969","exception":false,"start_time":"2021-02-03T10:40:14.212784","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Don't forget to upvote!! ðŸ˜‰"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}