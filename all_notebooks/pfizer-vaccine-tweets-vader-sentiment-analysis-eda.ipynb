{"cells":[{"metadata":{},"cell_type":"markdown","source":"IMPORTING MODULES\n"},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport re\nimport string\nimport nltk\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('darkgrid')\n\npyo.init_notebook_mode()\nnltk.download('vader_lexicon')\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\nfrom wordcloud import WordCloud,STOPWORDS\n\nplt.rc('figure',figsize=(17,13))\nimport plotly.express as px\nimport plotly.graph_objs as go\nimport plotly.offline as pyo\nfrom plotly.subplots import make_subplots\n","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"!pip install vaderSentiment\n!pip install twython","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ****Pfizer and BioNTech Vaccine Tweets Analysis****"},{"metadata":{},"cell_type":"markdown","source":"My first notebook, comments, suggestions  and upvotes are all welcome :)"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data=pd.read_csv('../input/pfizer-vaccine-tweets/vaccination_tweets.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **TEXT PREPROCESSING FOR VADER SENTIMENT ANALYSIS**\n* Here I didn't touch punctuations and case for now as VADER SENTIMENT ANALYSIS SCORES are affected by factors like punctuations,capitalization,preceeding-trigrams,degree modifiers,conjunctions etc.\n* The Sentiments have been classified based on scores according to the VADER convention.\n* A new column 'Sentiment'is thus, added giving sentiment corresponding to each Tweet text."},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean(text):\n    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n    text = re.sub(r'\\s+', ' ', text, flags=re.I)\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    text = re.sub('<.*?>+', '', text)\n    return text\n    \n\n\ndata['text'] = data['text'].apply(lambda x:clean(x))\nfrom vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\nanalyser = SentimentIntensityAnalyzer()\nscores=[]\nfor i in range(len(data['text'])):\n    \n    score = analyser.polarity_scores(data['text'][i])\n    score=score['compound']\n    scores.append(score)\nsentiment=[]\nfor i in scores:\n    if i>=0.05:\n        sentiment.append('Positive')\n    elif i<=(-0.05):\n        sentiment.append('Negative')\n    else:\n        sentiment.append('Neutral')\ndata['sentiment']=pd.Series(np.array(sentiment))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **WORDCLOUD ANALYSIS OF TWEET TEXT**"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud, STOPWORDS , ImageColorGenerator\n\ntweet_All = \" \".join(review for review in data.text)\n\n\nfig, ax = plt.subplots(1, 1, figsize  = (10,10))\n# Create and generate a word cloud image:\nwordcloud_ALL = WordCloud(max_font_size=50, max_words=100, background_color=\"black\").generate(tweet_All)\n\n# Display the generated image:\nax.imshow(wordcloud_ALL, interpolation='bilinear')\n\nax.axis('off')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" **REMOVING PUNCTUATIONS AND MAKING TEXT LOWERCASE**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_text(text):\n    \n    text = str(text).lower()\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    \n    return text\ndata['text'] = data['text'].apply(lambda x:clean_text(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['text']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  **STEMMING AND LEMMATIZATION**"},{"metadata":{},"cell_type":"markdown","source":"* df shows the text at each step of the preprocessing\n* From the dataframe df we can decide which one of the stemming(Porter or Snowball)/lemmatization or both is suitable for our data.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.DataFrame()\ndf['text']=data['text']\ndef tokenization(text):\n    text = re.split('\\W+', text)\n    return text\n\ndf['tokenized'] = df['text'].apply(lambda x: tokenization(x.lower()))\nstopword = nltk.corpus.stopwords.words('english')\ndef remove_stopwords(text):\n    text = [word for word in text if word not in stopword]\n    return text\n    \ndf['No_stopwords'] = df['tokenized'].apply(lambda x: remove_stopwords(x))\n\nps = nltk.PorterStemmer()\n\ndef stemming1(text):\n    text = [ps.stem(word) for word in text]\n    return text\n\ndf['stemmed_porter'] = df['No_stopwords'].apply(lambda x: stemming1(x))\n\nfrom nltk.stem.snowball import SnowballStemmer\ns_stemmer = SnowballStemmer(language='english')\ndef stemming2(text):\n    text = [s_stemmer.stem(word) for word in text]\n    return text\ndf['stemmed_snowball'] = df['No_stopwords'].apply(lambda x: stemming2(x))\n\nwn = nltk.WordNetLemmatizer()\n\ndef lemmatizer(text):\n    text = [wn.lemmatize(word) for word in text]\n    return text\n\ndf['lemmatized'] = df['No_stopwords'].apply(lambda x: lemmatizer(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"IT LOOKS LIKE BOTH THE STEMMING METHODS ARE REDUCING THE TEXT WORDS TO UNUSUAL STEMS WHILE LEMMATIZATION SEEMS TO WORK FINE \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['text']=df['lemmatized']\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **EDA PART:**"},{"metadata":{},"cell_type":"markdown","source":"# SENTIMENT COUNTS"},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = data.groupby('sentiment').count()['text'].reset_index().sort_values(by='text',ascending=False)\ntemp.style.background_gradient(cmap='Purples')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# FUNNEL CHART FOR BETTER VISUALIZATION OF SENTIMENT DISTRIBUTION\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nplt.figure(figsize=(12,6))\nsns.countplot(x='sentiment',data=data)\nfig = go.Figure(go.Funnelarea(\n    text =temp.sentiment,\n    values = temp.text,\n    title = {\"position\": \"top center\", \"text\": \"Funnel-Chart of Sentiment Distribution\"}\n    ))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# RANKING THE SENTIMENTS BASED ON THREE METRICS:\n1. THE FIRST METRIC IS THE SPECIFIC SENTIMENT'S COUNT THROUGHOUT THE TWEET DATA.NEUTRAL TWEETS ARE AT TOP HERE.\n2. THE SECOND METRIC IS THE SUM OF FAVORITES ON A PARTICULAR SENTIMENT'S TWEET.IT CAN BE SEEN THAT THE POSITIVE TWEETS GET THE HIGHEST FAVORITES EVEN THOUGH NEUTRAL TWEETS HAVE THE HIGHEST COUNT.ATLEAST PEOPLE WANT TO BE POSITIVE WHEN IT'S A VACCINE BEING TALKED ABOUT.\n3. THE THIRD METRIC IS THE SUM OF RETWEETS ON A PARTICULAR SENTIMENT'S TWEET.IT CAN BE SEEN THAT THE NEUTRAL TWEETS GET THE HIGHEST RETWEETS \n\nNEGATIVE TWEETS IS AT THE LAST POSITION IN ALL THE THREE METRICS"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":" \ngenre_difference_metric = [data['sentiment'].value_counts().index,data.groupby(['sentiment']).sum()['favorites'].sort_values(ascending=False).index,data.groupby(['sentiment']).sum()['retweets'].sort_values(ascending=False).index]\n\n#Dataframe to be used for plotting.\ngenre_evolution_df = pd.DataFrame(columns=['genre', 'rank_type', 'rank'])\n\n#Populate the dataframe\nfor metric in range(3):\n    for genre in range(len(genre_difference_metric[metric])):\n        genre_evolution_df = genre_evolution_df.append({'genre':genre_difference_metric[metric][genre], 'rank_type': metric, 'rank':genre},\n                                   ignore_index=True)\nplt.style.use('seaborn-bright')       \nfig = plt.figure(figsize=(10,6))\nax = fig.add_subplot(111)\n\n    \n\nax.set_xlim([-2,4])\nxs = [0.0, 1.0, 2.0]\nx_labels = ['sentiment count', 'sum of favorites', 'sum of retweets']\nplt.xticks(range(len(xs)), x_labels)\nplt.xticks(xs, x_labels, rotation='vertical')\nsns.pointplot(x=genre_evolution_df.rank_type,\n              y=3-genre_evolution_df['rank'], \n              hue=genre_evolution_df.genre)\nys = range(1,5)\ny_labels = ['3rd', '2nd', '1st']\nplt.yticks(ys, y_labels)\nax.set_ylabel('Sentiment Category Rank')\n\nplt.legend(bbox_to_anchor=(0.7, 0., 0.5, 0.5),loc='best',ncol=1)\nplt.show();  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ACCOUNT:VERIFIED/NON-VERIFIED"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"\nsns.catplot(data=data, x='user_verified', kind= 'count',height=5,aspect=2)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# DISTRIBUTION OF THE FAVORITES RECIEVED BASED ON TWEET SENTIMENT AND WHETHER THE ACCOUNT IS VERIFIED/NOT"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"sns.barplot(x=\"user_verified\", y=\"favorites\", hue=\"sentiment\", data=data)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# DISTRIBUTION OF THE RETWEETS BASED ON TWEET SENTIMENT AND WHETHER THE ACCOUNT IS VERIFIED/NOT"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"sns.barplot(x=\"user_verified\", y=\"retweets\", hue=\"sentiment\", data=data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **THE TOP 30 MOST FREQUENTLY OCCURING WORDS IN THE TWEET TEXT DATA**\n"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"all_words=[]\nfor i in range(len(data['text'])):\n    a=data['text'][i]\n    for i in a:\n        all_words.append(i)\nall_words=pd.Series(np.array(all_words))\n\ncommon_words=all_words.value_counts()[:30].rename_axis('Common Words').reset_index(name='count')\n\nfig = px.treemap(common_words, path=['Common Words'], values='count',title='30 Most Common Words In Tweets')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **THE TOP 30 MOST FREQUENTLY USED HASHTAGS IN THE TWEET TEXT DATA**"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"data['hashtags']=data['hashtags'].fillna('[]')\nall_hashtags=[]\nfor i in range(len(data['hashtags'])):\n    a=data['hashtags'][i].strip('][').split(', ') \n    for i in a:\n        all_hashtags.append(i)\nall_hashtags=['No Hashtag' if x=='' else x for x in all_hashtags]       \n\nall_hashtags=pd.Series(np.array(all_hashtags))\nprint('There are {} instances of tweets in which No Hashtags were used'.format(all_hashtags.value_counts()[1]))\n\ncommon_hashtags=all_hashtags.value_counts().drop(labels='No Hashtag')[:30].rename_axis('Common Hashtags').reset_index(name='count')\nfig = px.treemap(common_hashtags, path=['Common Hashtags'], values='count',title='30 Most Common Hashtags')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **SENTIMENT WISE ANALYSIS OF HASHTAGS AND WORDS:**"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"Positive_tweet = data[data['sentiment']=='Positive'].reset_index()\nNegative_tweet = data[data['sentiment']=='Negative'].reset_index()\nNeutral_tweet = data[data['sentiment']=='Neutral'].reset_index()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# POSITIVE TWEETS"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"all_positive_words=[]\nall_positive_hashtags=[]\nfor i in range(len(Positive_tweet['text'])):\n    a=Positive_tweet['text'][i]\n    b=Positive_tweet['hashtags'][i].strip('][').split(', ')\n    for i in a:\n        all_positive_words.append(i)\n    for i in b:\n        all_positive_hashtags.append(i)\nall_positive_words=pd.Series(np.array(all_positive_words))\nall_positive_hashtags=pd.Series(np.array(all_positive_hashtags))\ncommon_words=all_positive_words.value_counts().drop(labels='')[:70].rename_axis('Common Positive Words').reset_index(name='count')\nfig = px.treemap(common_words, path=['Common Positive Words'], values='count',title='70 Most Common Words In Positive Tweets')\nfig.show()\ncommon_hashtags=all_positive_hashtags.value_counts()[:70].drop(labels='').rename_axis('Common Positive Hashtags').reset_index(name='count')\nfig = px.treemap(common_hashtags, path=['Common Positive Hashtags'], values='count',title='70 Most Common Hashtags In Positive Tweets')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# NEGATIVE TWEETS"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"all_negative_words=[]\nall_negative_hashtags=[]\nfor i in range(len(Negative_tweet['text'])):\n    a=Negative_tweet['text'][i]\n    b=Negative_tweet['hashtags'][i].strip('][').split(', ')\n    for i in a:\n        all_negative_words.append(i)\n    for i in b:\n        all_negative_hashtags.append(i)\nall_negative_words=pd.Series(np.array(all_negative_words))\nall_negative_hashtags=pd.Series(np.array(all_negative_hashtags))\ncommon_words=all_negative_words.value_counts().drop(labels='')[:70].rename_axis('Common Negative Words').reset_index(name='count')\nfig = px.treemap(common_words, path=['Common Negative Words'], values='count',title='70 Most Common Words In Negative Tweets')\nfig.show()\ncommon_hashtags=all_negative_hashtags.value_counts()[:70].drop(labels='').rename_axis('Common Negative Hashtags').reset_index(name='count')\nfig = px.treemap(common_hashtags, path=['Common Negative Hashtags'], values='count',title='70 Most Common Hashtags In Negative Tweets')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# NEUTRAL TWEETS"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"all_neutral_words=[]\nall_neutral_hashtags=[]\nfor i in range(len(Neutral_tweet['text'])):\n    a=Neutral_tweet['text'][i]\n    b=Neutral_tweet['hashtags'][i].strip('][').split(', ')\n    for i in a:\n        all_neutral_words.append(i)\n    for i in b:\n        all_neutral_hashtags.append(i)\nall_neutral_words=pd.Series(np.array(all_neutral_words))\nall_neutral_hashtags=pd.Series(np.array(all_neutral_hashtags))\ncommon_words=all_neutral_words.value_counts().drop(labels='')[:70].rename_axis('Common Neutral Words').reset_index(name='count')\nfig = px.treemap(common_words, path=['Common Neutral Words'], values='count',title='70 Most Common Words In Neutral Tweets')\nfig.show()\ncommon_hashtags=all_neutral_hashtags.value_counts()[:70].drop(labels='').rename_axis('Common Neutral Hashtags').reset_index(name='count')\nfig = px.treemap(common_hashtags, path=['Common Neutral Hashtags'], values='count',title='70 Most Common Hashtags In Neutral Tweets')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It can be seen that 'PfizerBioNTech','COVID19','vaccine',etc are common in all the sentiments and are not giving a clear distinction in the words used exclusively for a particular sentiment.\nSo,the following plots show the distribution of words that are unique to each sentiment.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"common=set(all_positive_words).intersection(set(all_negative_words)).intersection(set(all_neutral_words))\ncommon_list=list(common)\n\ncommon_words=all_negative_words.value_counts().drop(labels=common_list)[:30].rename_axis('Common Negative Words').reset_index(name='count')\nfig = px.treemap(common_words, path=['Common Negative Words'], values='count',title='Top 30 Unique Words In Negative Tweets')\nfig.show()\ncommon_words=all_positive_words.value_counts().drop(labels=common_list)[:30].rename_axis('Common Positive Words').reset_index(name='count')\nfig = px.treemap(common_words, path=['Common Positive Words'], values='count',title='Top 30 Unique Words In Positive Tweets')\nfig.show()\ncommon_words=all_neutral_words.value_counts().drop(labels=common_list)[:30].rename_axis('Common Neutral Words').reset_index(name='count')\nfig = px.treemap(common_words, path=['Common Neutral Words'], values='count',title='Top 30 Unique Words In Neutral Tweets')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This gave a clearer and better analysis!"},{"metadata":{},"cell_type":"markdown","source":"# SOURCE DISTRIBUTION OF TWEETS"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"data_ = data['source'].value_counts().reset_index()\n\ntrace1 = go.Bar(\n                x = ['Twitter for Android', 'Twitter Web App', 'Twitter for iPhone',\n       'TweetDeck', 'Buffer', 'Twitter for iPad', 'Twitter Media Studio',\n       'ThreadReaderApp', 'Instagram', 'SocialFlow', 'Hootsuite Inc.',\n       'LinkedIn', 'Twitter for Mac', '24liveblog', 'Publer ', 'IFTTT',\n       'Socialbakers', 'Falcon Social Media Management ', 'Echobox',\n       'Microsoft Power Platform', 'Nonli', 'Sendible',\n       'Tweetbot for Mac', 'EastMojo',\n       'Twitter Media Studio - LiveCut'], #temp_df['index'],\n                y = data_['source'],\n                marker = dict(color = 'rgb(250,13,92)',\n                              line=dict(color='rgb(0,0,0)',width=1.5)),\n                text=data_['source'], textposition='outside')\nlayout = go.Layout(template= \"plotly_dark\",title = 'SOURCE DISTRIBUTION OF TWEETS' , xaxis = dict(title = 'SOURCE'), yaxis = dict(title = 'Count'), height=650)\nfig = go.Figure(data = [trace1], layout = layout)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# GLIMPSE AT VERIFIED ACCOUNTS\n"},{"metadata":{},"cell_type":"markdown","source":"# **SOURCE DISTRIBUTION**"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"data_verified=data[(data['user_verified']==True)].reset_index()\ndata_not_verified=data[(data['user_verified']==False)].reset_index()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"\ndata_ = data_verified['source'].value_counts().reset_index()\n\ntrace1 = go.Bar(\n                x = ['Twitter Web App', 'Twitter for iPhone', 'TweetDeck', 'Buffer',\n       'SocialFlow', 'Hootsuite Inc.', 'Twitter for iPad',\n       'Twitter for Android', 'Socialbakers', 'Echobox',\n       'Twitter Media Studio', 'EastMojo',\n       'Twitter Media Studio - LiveCut', 'GT_Backend'], #temp_df['index'],\n                y = data_['source'],\n                marker = dict(color = 'rgb(250,13,92)',\n                              line=dict(color='rgb(0,0,0)',width=1.5)),\n                text=data_['source'], textposition='outside')\nlayout = go.Layout(template= \"plotly_dark\",title = 'SOURCE DISTRIBUTION OF TWEETS FROM VERIFIED ACCOUNTS' , xaxis = dict(title = 'SOURCE'), yaxis = dict(title = 'Count'), height=650)\nfig = go.Figure(data = [trace1], layout = layout)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **HASHTAGS**"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"all_hashtags=[]\nfor i in range(len(data_verified['hashtags'])):\n    a=data_verified['hashtags'][i].strip('][').split(', ') \n    for i in a:\n        all_hashtags.append(i)\nall_hashtags=['No Hashtag' if x=='' else x for x in all_hashtags]       \n\nall_hashtags=pd.Series(np.array(all_hashtags))\ncommon_hashtags=all_hashtags.value_counts()[:30].rename_axis('Common Hashtags').reset_index(name='count')\nfig = px.treemap(common_hashtags, path=['Common Hashtags'], values='count',title='30 Most Common Hashtags by VERIFIED ACCOUNTS')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **SENTIMENT WISE WORD FREQUENCY**"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"\n\nPositive_tweet = data_verified[data_verified['sentiment']=='Positive'].reset_index()\nNegative_tweet = data_verified[data_verified['sentiment']=='Negative'].reset_index()\nNeutral_tweet = data_verified[data_verified['sentiment']=='Neutral'].reset_index()\nall_positive_words=[]\n\nfor i in range(len(Positive_tweet['text'])):\n    a=Positive_tweet['text'][i]\n    \n    for i in a:\n        all_positive_words.append(i)\n    \nall_positive_words=pd.Series(np.array(all_positive_words))\nall_neutral_words=[]\n\nfor i in range(len(Neutral_tweet['text'])):\n    a=Neutral_tweet['text'][i]\n    \n    for i in a:\n        all_neutral_words.append(i)\n    \nall_neutral_words=pd.Series(np.array(all_neutral_words))\nall_negative_words=[]\n\nfor i in range(len(Negative_tweet['text'])):\n    a=Negative_tweet['text'][i]\n   \n    for i in a:\n        all_negative_words.append(i)\n    \nall_negative_words=pd.Series(np.array(all_negative_words))\ncommon=set(all_positive_words).intersection(set(all_negative_words)).intersection(set(all_neutral_words))\ncommon_list=list(common)\n\ncommon_words=all_negative_words.value_counts().drop(labels=common_list)[:30].rename_axis('Common Negative Words').reset_index(name='count')\nfig = px.treemap(common_words, path=['Common Negative Words'], values='count',title='30 Most Common Unique Negative Words by VERIFIED ACCOUNTS')\nfig.show()\ncommon_words=all_positive_words.value_counts().drop(labels=common_list)[:30].rename_axis('Common Positive Words').reset_index(name='count')\nfig = px.treemap(common_words, path=['Common Positive Words'], values='count',title='30 Most Common Unique Positive Words by VERIFIED ACCOUNTS')\nfig.show()\ncommon_words=all_neutral_words.value_counts().drop(labels=common_list)[:30].rename_axis('Common Neutral Words').reset_index(name='count')\nfig = px.treemap(common_words, path=['Common Neutral Words'], values='count',title='30 Most Common Unique Neutral Words by VERIFIED ACCOUNTS')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  TWEET SENTIMENT BASED ANALYSIS OF LOCATION"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"data['user_location'] = data['user_location'].fillna('NaN')\nPositive_tweet = data[data['sentiment']=='Positive'].reset_index()\nNegative_tweet = data[data['sentiment']=='Negative'].reset_index()\nNeutral_tweet = data[data['sentiment']=='Neutral'].reset_index()\npos_location=Positive_tweet['user_location']\nneg_location=Negative_tweet['user_location']\nneu_location=Neutral_tweet['user_location']\n\ncommon=set(pos_location).intersection(set(neg_location)).intersection(set(neu_location))\ncommon_list=list(common)\n\ncommon_words=neg_location.value_counts().drop(labels=common_list)[:10].rename_axis('Common Negative Locations').reset_index(name='count')\nfig = px.treemap(common_words, path=['Common Negative Locations'], values='count',title='10 Top Unique Negative Tweets Locations')\nfig.show()\ncommon_words=pos_location.value_counts().drop(labels=common_list)[:10].rename_axis('Common Positive Locations').reset_index(name='count')\nfig = px.treemap(common_words, path=['Common Positive Locations'], values='count',title='10 Top Unique Positive Tweets Locations')\nfig.show()\ncommon_words=neu_location.value_counts().drop(labels=common_list)[:10].rename_axis('Common Neutral Locations').reset_index(name='count')\nfig = px.treemap(common_words, path=['Common Neutral Locations'], values='count',title='10 Top Unique Neutral Tweets Locations')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 'ACCOUNTS WITH HIGHEST FOLLOWERS' ANALYSIS BASED ON THE TWEET SENTIMENT"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"from matplotlib import rcParams\n","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2, ax3) = plt.subplots(3,1, figsize=(10, 16))\nsns.barplot(x=\"user_followers\", y=\"user_name\", orient=\"h\", ax=ax1, palette=[\"b\"],\n           data=data[(data.sentiment== \"Positive\")]\\\n           .drop_duplicates(subset=[\"user_name\"])\\\n           .sort_values(by=[\"user_followers\"], ascending=False)[[\"user_name\", \"user_followers\"]][:10])\nax1.set_title('Top 10 Accounts with Highest Followers who tweet Positive')\nsns.barplot(x=\"user_followers\", y=\"user_name\", orient=\"h\", ax=ax2, palette=[\"g\"],\n           data=data[(data.sentiment == \"Neutral\")]\n           .drop_duplicates(subset=[\"user_name\"])\\\n           .sort_values(by=[\"user_followers\"], ascending=False)[[\"user_name\", \"user_followers\"]][:10])\nax2.set_title('Top 10 Accounts with Highest Followers who tweet Neutral')\nsns.barplot(x=\"user_followers\", y=\"user_name\", orient=\"h\", ax=ax3, palette=[\"r\"],\n           data=data[(data.sentiment == \"Negative\")]\n           .drop_duplicates(subset=[\"user_name\"])\\\n           .sort_values(by=[\"user_followers\"], ascending=False)[[\"user_name\", \"user_followers\"]][:10])\nax3.set_title('Top 10 Accounts with Highest Followers who tweet Negative')\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# TIME BASED ANALYSIS OF TWEET SENTIMENT:"},{"metadata":{},"cell_type":"markdown","source":"\n* A sudden fall in the positive tweets can be seen around 22-25 Dec.\n* A sudden spike in negative tweets can be seen around 30 Dec 2020."},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"date\"] = pd.to_datetime(data.date) \ntimeline = data.resample('D', on='date')[\"sentiment\"].value_counts().unstack(1)\n\ntimeline.reset_index(inplace=True)\n\ntimeline = timeline.melt(\"date\", var_name='sentiment',  value_name='vals')\n\nsns.set_style(\"whitegrid\")\nsns.lineplot(x=\"date\", y=\"vals\", hue=\"sentiment\", data=timeline, palette=[\"r\", \"g\",\"b\"])\nplt.figure(figsize=(40,10))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**THANKYOU FOR READING MY FIRST NOTEBOOK.\nDO UPVOTE AND GIVE FEEDBACK IF YOU FOUND IT USEFUL!**"},{"metadata":{},"cell_type":"markdown","source":"\n"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}