{"cells":[{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"import re\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import MultipleLocator\n\nimport seaborn as sns\nimport warnings \n\nimport requests\nfrom bs4 import BeautifulSoup\nfrom itertools import product\n\nwarnings.filterwarnings(\"ignore\")\nsns.set(style=\"darkgrid\")\n\ndef read_raw (path):\n    raw = pd.read_csv(path)\n    raw = raw.rename (columns = {\"Province/State\": \"Province_State\", \"Country/Region\":\"Country_Region\"})\n    raw [\"Province_State\"] = raw [\"Province_State\"].fillna(raw [\"Country_Region\"])\n    raw [\"Country_Region\"] = raw [\"Country_Region\"].fillna(\"-\")\n    return raw\n\ndef extract ( df_raw, type_value, date_format='%m/%d/%y' ):\n    df = pd.DataFrame()\n    dates = df_raw.columns[4:]\n\n    for d in dates:    \n        sites = df_raw[[\"Province_State\",\"Country_Region\"]].copy()\n        sites[\"ObservationDate\"]=d\n        sites[type_value]=df_raw[d]\n        df = df.append(sites)\n\n    df [\"ObservationDate\"] = pd.to_datetime(df [\"ObservationDate\"], format=date_format)\n\n    return df\n\n\n\ndef load_data ():\n\n    raw_confirmed = read_raw(\"time_series_covid19_confirmed_global.csv\")\n    raw_recovered = read_raw(\"time_series_covid19_recovered_global.csv\")\n    raw_deaths = read_raw(\"time_series_covid19_deaths_global.csv\")\n\n    anag = raw_confirmed[ [\"Province_State\",\"Country_Region\",\"Lat\",\"Long\"]].copy()\n    confirmed = extract (raw_confirmed, \"Confirmed\")\n    recovered = extract (raw_recovered, \"Recovered\") #,  date_format='%m/%d/%Y')\n    deaths = extract (raw_deaths, \"Death\")\n\n\n    data = anag.merge(confirmed,on=[\"Province_State\",\"Country_Region\"])\n    data = data.merge(recovered,on=[\"Province_State\",\"Country_Region\", \"ObservationDate\"] )\n    data = data.merge(deaths,on=[\"Province_State\",\"Country_Region\", \"ObservationDate\"] )\n\n    data [\"ObservationDate\"] = pd.to_datetime(data [\"ObservationDate\"], format='%m/%d/%y')\n    data = data.sort_values(by=\"ObservationDate\",ascending=True) \n\n    g = data.groupby( [\"Province_State\", \"Country_Region\"])\n\n    data [\"Infected\"] = data[\"Confirmed\"] - data[\"Recovered\"] - data[\"Death\"] \n\n    for f in [\"Confirmed\", \"Infected\", \"Death\", \"Recovered\"]:\n        data [\"Day_\" + f] = data[f]  - g[f].shift()    \n\n    data [\"beta\"] = data[\"Day_Confirmed\"]/(data[\"Infected\"]-data[\"Day_Infected\"])\n    \n    return data\n\n\ndef select_data (data, province = None, country = None):\n    \n    if province is not None:\n        data = data.query ( \"Province_State == @province\" )\n\n    if country is not None:\n        data = data.query ( \"Country_Region == @country\" )\n    \n    return data\n\ndef extract_pcps_by_country ( data, province = None, country = None, confirmed_threshold = 50 ):\n    data = select_data (data, province, country).query (\"Confirmed > @confirmed_threshold\")\n\n    return data ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# The virus spreads\n\n## Facts\n\n* Jan 21: Chinese officials acknowledged the risk of human-to-human transmission for COVID-19.\n* Jan 23: The Chinese authorities locked down Wuhan, and many cities followed in the next few weeks. Travel across China nearly stopped.\n\n* Mar 10: In Italy, a nationwide lockdown went into effect on March 10 that restricts virtually all aspects of life for its 60 million citizens, including retail, leisure, worship, imprisonment, and travel.\n* Mar 11: The World Health Organization (WHO) declared COVID-19 a pandemic\n* Mar 14: Spain became the second European country to impose a nationwide quarantine.\n* Mar 23: The UK went into full coronavirus lockdown on March 23.\n\n* Apr 8: Chinese authorities allowed residents to leave the city of Wuhan for the first time since 23 January.\n\nsources: [1](https://www.nytimes.com/interactive/2020/03/22/world/coronavirus-spread.html), [2](https://www.businessinsider.com/countries-on-lockdown-coronavirus-italy-2020-3?IR=T#germany-announced-a-shut-down-of-shops-churches-sports-facilities-bars-and-clubs-in-16-states-15)\n\nI use data from [Johns Hopkins Github repository](https://github.com/CSSEGISandData/COVID-19) and from [Citymapper](https://citymapper.com/CMI) \n","execution_count":null},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"!wget -N -q https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv\n!wget -N -q https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv    \n!wget -N -q https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv\n!wget -N -q https://cdn.citymapper.com/data/cmi/Citymapper_Mobility_Index_20200809.csv\n!ls","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def infected_plot ( d, p, ax ):\n    ax.set_yscale('log')\n    ax.xaxis.set_major_locator(MultipleLocator(14))\n    chart = sns.lineplot(x=\"ObservationDate\", y=\"Infected\", hue=\"Province_State\",   data = d.query(\"Province_State.isin(@p)\",engine=\"python\"),  ax=ax)\n\ndata = load_data ()\ndata = data.sort_values(by=\"Confirmed\",ascending=False) \ndata = data.drop_duplicates([\"Province_State\",\"Country_Region\"], keep=\"first\")\ntoday =  pd.datetime.now().replace(microsecond=0, second=0, minute=0, hour=0)\ndata [\"Age\"] = today - data [\"ObservationDate\"]\n#data = data [ data [\"Age\"] < '5 days' ]\ndata = data [ (data [\"Age\"] < '5 days') | (data[\"Province_State\"] == \"Hubei\")  ]\n\nprovinces = list(data.head(24)[\"Province_State\"].values)\n\n\ntop=data.query(\"Province_State.isin(@provinces)\",engine='python')  [[\"ObservationDate\", \"Country_Region\",\"Province_State\",\"Confirmed\", \"Infected\", \"Recovered\", \"Death\", \"beta\"]].reset_index(drop=True)\n\n\nd = load_data ()\n\nd = d.sort_values(by=\"Infected\",ascending=False) \n\n\nd[\"ObservationDate\"] = d[\"ObservationDate\"].dt.strftime(\"%m/%d\")\n\n\nd_global = d.groupby([\"ObservationDate\"]).agg({\n    \"Confirmed\":'sum',\n    \"Recovered\": 'sum',\n    \"Infected\": 'sum',\n    \"Death\": 'sum'\n}).reset_index()\nd_global[\"Province_State\"]=\"all countries\"\n\nfig, ax = plt.subplots(1, 1,figsize=(18,4))\nfig.suptitle(\"Infected\")\nax.set_yscale('log')\nax.xaxis.set_major_locator(MultipleLocator(7))\nchart = sns.lineplot(x=\"ObservationDate\", y=\"Infected\", hue=\"Province_State\",  data =d_global,  ax=ax)\n\nplt.ylim(bottom=500)\nplt.tight_layout()\nplt.show()\n\n\nfig, axs = plt.subplots(2, 2,figsize=(18,9), sharey=True, sharex=False )\n\ninfected_plot ( d, provinces[0:5], axs[0,0] )\ninfected_plot ( d, provinces[5:10], axs[0,1] )\ninfected_plot ( d, provinces[10:15], axs[1,0] )\ninfected_plot ( d, provinces[15:20], axs[1,1] )\n\nplt.ylim(bottom=500)\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def death_plot ( d, p, ax ):\n    #ax.set_yscale('log')\n    ax.xaxis.set_major_locator(MultipleLocator(14))\n    chart = sns.lineplot(x=\"ObservationDate\", y=\"Day_Death_Mean\", hue=\"Province_State\",   data = d.query(\"Province_State.isin(@p)\",engine=\"python\"),  ax=ax)\n\ndata = load_data ()\ndata = data.sort_values(by=\"Death\",ascending=False) \ndata = data.drop_duplicates([\"Province_State\",\"Country_Region\"], keep=\"first\")\ntoday =  pd.datetime.now().replace(microsecond=0, second=0, minute=0, hour=0)\ndata [\"Age\"] = today - data [\"ObservationDate\"]\n#data = data [ data [\"Age\"] < '5 days' ]\ndata = data [ (data [\"Age\"] < '5 days') | (data[\"Province_State\"] == \"Hubei\")  ]\n\nprovinces = list(data.head(24)[\"Province_State\"].values)\n\n\ntop=data.query(\"Province_State.isin(@provinces)\",engine='python')  [[\"ObservationDate\", \"Country_Region\",\"Province_State\",\"Confirmed\", \"Infected\", \"Recovered\", \"Death\", \"beta\"]].reset_index(drop=True)\n\n\nd = load_data ()\n\nd = d.sort_values(by=\"Death\",ascending=False) \n\n\nd[\"ObservationDate\"] = d[\"ObservationDate\"].dt.strftime(\"%m/%d\")\n\n\nd_global = d.groupby([\"ObservationDate\"]).agg({\n    \"Confirmed\":'sum',\n    \"Recovered\": 'sum',\n    \"Infected\": 'sum',\n    \"Death\": 'sum',\n    \"Day_Death\": 'sum',\n    \n}).reset_index()\nd_global[\"Province_State\"]=\"all countries\"\n\nd_global[\"Rolling_Mean\"]=d_global[\"Day_Death\"].rolling(7).mean()\n\nfig, ax = plt.subplots(1, 1,figsize=(18,4))\nfig.suptitle(\"Day_Death\")\n#ax.set_yscale('log')\nax.xaxis.set_major_locator(MultipleLocator(7))\nchart = sns.lineplot(x=\"ObservationDate\", y=\"Day_Death\", hue=\"Province_State\",  data =d_global,  ax=ax)\nchart = sns.lineplot(x=\"ObservationDate\", y=\"Rolling_Mean\",  data =d_global,  ax=ax)\n\n\n#plt.ylim(bottom=500)\nplt.tight_layout()\nplt.show()\n\n\nfig, axs = plt.subplots(2, 2,figsize=(18,9), sharey=True, sharex=False )\n\nd[\"Day_Death_Mean\"] = d.groupby(\"Province_State\")[\"Day_Death\"].rolling(7).mean().reset_index(0,drop=True)\n\ndeath_plot ( d, provinces[0:5], axs[0,0] )\ndeath_plot ( d, provinces[5:10], axs[0,1] )\ndeath_plot ( d, provinces[10:15], axs[1,0] )\ndeath_plot ( d, provinces[15:20], axs[1,1] )\n\n#plt.ylim(bottom=500)\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The only way to decrease the spread of the COVID-19 - until a vaccine will be developed - is to take actions to decrease the probability of contact.\n\nIt is important to measure this probability over time to evaluate the validity of those actions.\n\n\nLet's see how - using a simple variation of the [SIR Model](https://mathworld.wolfram.com/Kermack-McKendrickModel.html) - it's possible to track the change of probability of contact over time.\n\n\n### A SIR Model\n\n\\\\(C(t) = I(t) + R(t) + D(t)\\\\)\n\n\\\\(I(t+1) = I(t) + {Pc(t).Ps(t).S(t).I(t)\\over N} - D(t) - R(t) \\\\)\n\nwhere\n\n* \\\\(C(t)\\\\) is the cumulative number of confirmed cases till that date t\n* \\\\(I\\\\) is the cumulative number of infected \n* \\\\(R\\\\) is the cumulative number of recovered cases\n* \\\\(D\\\\) is the cumulative number of deaths \n* \\\\(S\\\\) is the cumulative number of people susceptible to virus\n* \\\\(N\\\\) is the population\n* \\\\(Ps\\\\) is the probability of spreading the virus (if susceptible contacts infected)\n* \\\\(Pc\\\\) is the probability of contact between susceptibles and infected\n\n\n\n### A proxy for the probability of contact over time \n\nAssume that \n\n* \\\\({S(t)\\over N} \\approx 1 \\\\)    that is, the whole population is susceptible to the virus and there are few confirmed cases with respect to the whole population.  \n* \\\\(Ps(t)=Ps\\\\)    that is, the propability of spreading is constant. \n\nwe have that \\\\(\\beta=Pc(t).Ps\\\\) is a good proxy of the probability of contact over time:\n\n\n\\\\(\\beta = Pc(t).Ps={C(t+1)-C(t)\\over I(t)} \\\\)\n\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Current value for \\\\(\\beta\\\\)\n\nFirst of all, let's show the current value of \\\\(\\beta=Pc(t)*Ps\\\\) for countries/provinces with high values of confirmed cases.\n","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"top","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# History of \\\\(\\beta\\\\) for some countries\n\nLet's see the \\\\(\\beta\\\\) trend for some countries/provinces with respect  to applied quarantine policies\n\nI extracted from wikipedia [Coronavirus quarantines](https://en.wikipedia.org/wiki/National_responses_to_the_2019%E2%80%9320_coronavirus_pandemic)  the starting date of lockdown for countries .\n\n* \"L\" is the start of National lockdown for the country\n* \"P\" is the start of Partial lockdown (City, Regional, ...) for the country","execution_count":null},{"metadata":{"_kg_hide-output":true,"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"website_url = requests.get('https://en.wikipedia.org/wiki/National_responses_to_the_2019–20_coronavirus_pandemic').text\nsoup = BeautifulSoup(website_url,'lxml')\n\ntag = soup.find('table',{'class':'wikitable sortable mw-collapsible'})\n\n\ndef clean_country (x):\n    if x == \"United States\":\n        return \"US\"\n    if x == \"Czech Republic\":\n        return \"Czechia\"\n    \n    return x\n\n#https://stackoverflow.com/questions/48393253/how-to-parse-table-with-rowspan-and-colspan\ndef table_to_2d(tag):\n    rowspans = []  # track pending rowspans\n    rows = tag.find_all('tr')\n\n    # first scan, see how many columns we need\n    colcount = 0\n    for r, row in enumerate(rows):\n        cells = row.find_all(['td', 'th'], recursive=False)\n        # count columns (including spanned).\n        # add active rowspans from preceding rows\n        # we *ignore* the colspan value on the last cell, to prevent\n        # creating 'phantom' columns with no actual cells, only extended\n        # colspans. This is achieved by hardcoding the last cell width as 1. \n        # a colspan of 0 means “fill until the end” but can really only apply\n        # to the last cell; ignore it elsewhere. \n        colcount = max(\n            colcount,\n            sum(int(c.get('colspan', 1)) or 1 for c in cells[:-1]) + len(cells[-1:]) + len(rowspans))\n        # update rowspan bookkeeping; 0 is a span to the bottom. \n        rowspans += [int(c.get('rowspan', 1)) or len(rows) - r for c in cells]\n        rowspans = [s - 1 for s in rowspans if s > 1]\n\n    # it doesn't matter if there are still rowspan numbers 'active'; no extra\n    # rows to show in the table means the larger than 1 rowspan numbers in the\n    # last table row are ignored.\n\n    # build an empty matrix for all possible cells\n    table = [[None] * colcount for row in rows]\n\n    # fill matrix from row data\n    rowspans = {}  # track pending rowspans, column number mapping to count\n    for row, row_elem in enumerate(rows):\n        span_offset = 0  # how many columns are skipped due to row and colspans \n        for col, cell in enumerate(row_elem.find_all(['td', 'th'], recursive=False)):\n            # adjust for preceding row and colspans\n            col += span_offset\n            while rowspans.get(col, 0):\n                span_offset += 1\n                col += 1\n\n            # fill table data\n            rowspan = rowspans[col] = int(cell.get('rowspan', 1)) or len(rows) - row\n            colspan = int(cell.get('colspan', 1)) or colcount - col\n            # next column is offset by the colspan\n            span_offset += colspan - 1\n            value = cell.get_text()\n            for drow, dcol in product(range(rowspan), range(colspan)):\n                try:\n                    value =  re.sub(r'\\[\\d+\\]', '',value.replace(\"\\n\",\"\"))\n                    value = re.sub (r'^ +','', value)\n                    value = re.sub (r' +$','', value)\n                    table[row + drow][col + dcol] = value\n                    rowspans[col + dcol] = rowspan\n                except IndexError:\n                    # rowspan or colspan outside the confines of the table\n                    pass\n\n        # update rowspan bookkeeping\n        rowspans = {c: s - 1 for c, s in rowspans.items() if s > 1}\n    \n    \n    df = pd.DataFrame (\n        data = np.array(table) [2:-1,:], \n        columns = [\"Country_Region\", \"Province_State\", \"Start_Date\", \"End_Date\", \"Level\"]\n    )\n    return df\n\ndf_lockdown = table_to_2d (tag)\n\ndf_lockdown[\"Country_Region\"]=df_lockdown[\"Country_Region\"].map ( lambda x: clean_country(x) )\ndf_lockdown[\"Province_State\"]=df_lockdown[\"Province_State\"].map ( lambda x: clean_country(x) )\n\nhubei = pd.DataFrame ({\n    \"Country_Region\" : [\"China\"],\n    \"Province_State\" : [\"Hubei\"],\n    \"Start_Date\" : [\"2020-01-24\"],\n    \"End_Date\" : [\"08-04-2020\"],\n    \"Level\" : [\"National\"]\n})\n\n#df_lockdown = df_lockdown.append ( hubei )\n\n\ndf_lockdown[\"Lockdown\"] = df_lockdown[\"Level\"].map(lambda x: \"Lockdown\" if x == \"National\" else \"Partial\") \n\ndf_lockdown.to_csv(\"wikipedia_lockdown.csv\", index=False)\n\n\n#df_lockdown [\"ObservationDate\"] = pd.to_datetime(df_lockdown [\"Start_Date\"].map(lambda x: str(x).replace(\"[a]\",\"\").replace(\"[b]\",\"\").replace(\"[c]\",\"\").replace(\"[d]\",\"\").replace(\"[e]\",\"\")), format=\"%Y-%m-%d\")\ndf_lockdown [\"ObservationDate\"] = pd.to_datetime(df_lockdown [\"Start_Date\"].map(lambda x: str(x).replace(\"[a]\",\"\").replace(\"[b]\",\"\").replace(\"[c]\",\"\").replace(\"[d]\",\"\").replace(\"[e]\",\"\").replace(\"[f]\",\"\").replace(\"[g]\",\"\").replace(\"[i]\",\"\").replace(\"[j]\",\"\")), format=\"%Y-%m-%d\")\n\n\n\n\ndf_lockdown[\"ObservationDate\"] = df_lockdown[\"ObservationDate\"].dt.strftime(\"%m/%d\")\ndf_lockdown = df_lockdown.drop_duplicates([\"Country_Region\",\"ObservationDate\"])\ndf_lockdown[\"Lockdown\"] = df_lockdown[\"Lockdown\"].fillna(\"\").map(lambda x: x[0] if len(x) > 0 else \"\")\n\ndf_lockdown.to_csv(\"wikipedia_lockdown.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"provinces = top[\"Province_State\"].values\n\ndata = load_data ()\nd = data [ data [\"Confirmed\"] > 500 ]\nd = d [ d[\"Province_State\"].isin(  provinces) ]\n\nd[\"beta\"] = d[\"beta\"].clip(0,0.20)\n\n\nd[\"ObservationDate\"] = d[\"ObservationDate\"].dt.strftime(\"%m/%d\")\nd = d.merge(df_lockdown [[\"Country_Region\",\"ObservationDate\", \"Lockdown\"]] , on=[\"Country_Region\", \"ObservationDate\"], how=\"left\")\n\n#hubei_lockdown = d [(d[\"Province_State\"] == \"Hubei\") & (d[\"ObservationDate\"] == \"01/24\")].index.values[0]\n\n#d.loc[hubei_lockdown,\"Lockdown\"] = \"L\"\n\n\nhmap = d.pivot(index=\"Province_State\", columns=\"ObservationDate\", values=\"beta\")\nannot = d.pivot(index=\"Province_State\", columns=\"ObservationDate\", values=\"Lockdown\").fillna(\"\")\n\n\nfig, ax = plt.subplots(figsize=(20,10))\n\nsns.heatmap(hmap, cmap=\"Blues\", ax=ax, annot = annot.values, fmt = '', annot_kws={\"color\": 'white', 'size': 16, \"weight\": \"bold\"})\nplt.title(\"History of beta for some countries/provinces\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"let's see what happen when max beta is aligned","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"data = load_data ()\nd = data [ data [\"Confirmed\"] > 500 ]\nd = d [ d[\"Province_State\"].isin( provinces ) ]\n\nd[\"ObservationDate\"] = d[\"ObservationDate\"].dt.strftime(\"%m/%d\")\nd = d.merge(df_lockdown [[\"Country_Region\",\"ObservationDate\", \"Lockdown\"]] , on=[\"Country_Region\", \"ObservationDate\"], how=\"left\")\n\n#hubei_lockdown = d [(d[\"Province_State\"] == \"Hubei\") & (d[\"ObservationDate\"] == \"01/24\")].index.values[0]\n#d.loc[hubei_lockdown,\"Lockdown\"] = \"L\"\n\n\n\ndf = d[[\"Province_State\", \"ObservationDate\", \"beta\"]].pivot(index=\"ObservationDate\", columns=\"Province_State\", values=\"beta\").reset_index(drop=\"True\")\n\ndf_annot = d[[\"Province_State\", \"ObservationDate\", \"Lockdown\"]].pivot(index=\"ObservationDate\", columns=\"Province_State\", values=\"Lockdown\").fillna(\"\")\ndf_annot [\"day\"] = df_annot.index\ndf[\"day\"]=df.index\ndf_annot[\"day\"]=df.index\n\n\nidx_max = df.idxmax()\n#hubei_idx = idx_max[\"Hubei\"]\n\n\nfor c in [c for c in provinces if (c != \"day\" and c != \"Hubei\" ) ]:\n    idx = idx_max[c]\n    df[c]=df[c].shift(-idx )\n    df_annot[c] =df_annot[c].shift(-idx) \n\n\n\n\n\nd = pd.melt(df,id_vars=[\"day\"], value_vars=provinces, value_name=\"beta\"   )\nd[\"beta\"] = d[\"beta\"].clip(0,0.20)\n\n\nd_annot = pd.melt(df_annot,id_vars=[\"day\"], value_vars=provinces, value_name=\"Lockdown\"   )\nd = d.query('day < 170')\nd_annot = d_annot.query('day < 170')\n\n\nfig, ax = plt.subplots(figsize=(20,10))\n\n\n\nhmap = d.pivot(index=\"Province_State\", columns=\"day\", values=\"beta\")\nannot = d_annot.pivot(index=\"Province_State\", columns=\"day\", values=\"Lockdown\").fillna(\"\")\n\n\n\nsns.heatmap(hmap, cmap=\"Blues\", ax=ax,  annot = annot.values, fmt = '', annot_kws={\"color\": 'white', 'size': 16, \"weight\": \"bold\"})\n\n\nplt.title(\"Relative History of beta for some countries/provinces\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Citymapper Mobility Index\n\nData from [Citymapper](https://citymapper.com/CMI) ","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"mobility_index= pd.read_csv(\"Citymapper_Mobility_Index_20200809.csv\", header=3)\nmobility_index [\"Date\"] = pd.to_datetime(mobility_index [\"Date\"], format=\"%Y-%m-%d\")\nmobility_index [\"Date\"] = mobility_index [\"Date\"].dt.strftime(\"%m/%d\")\n\nfig, ax = plt.subplots(figsize=(20,10))\n\ndf = mobility_index.transpose()\ndf.columns = df.iloc[0]\ndf = df [1:]\nfor c in df.columns:\n    df[c] = df[c].astype(np.float32)\n\nsns.heatmap(df.clip(upper=1.0), cmap=\"Blues\", ax=ax, )\n\nplt.title(\"Citymapper Mobility Index\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*to be continued*","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}