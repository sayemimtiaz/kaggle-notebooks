{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# â›”ï¸ Deep CNN for Traffic signs Classification","metadata":{}},{"cell_type":"markdown","source":"* **Training** deep CNN on **\"original\"** version of TS for classification\n* **Dataset** with **\"original\"**, **\"light\"** & **\"hard\"** versions:\n[https://www.kaggle.com/valentynsichkar/traffic-signs-1-million-images-for-classification](https://www.kaggle.com/valentynsichkar/traffic-signs-1-million-images-for-classification)\n* **Notebook** with pre-processed **\"original\"** data: [https://www.kaggle.com/valentynsichkar/pre-processing-of-traffic-signs-dataset/](https://www.kaggle.com/valentynsichkar/pre-processing-of-traffic-signs-dataset/)","metadata":{}},{"cell_type":"markdown","source":"# ðŸŽ“ Related course for classification tasks","metadata":{}},{"cell_type":"markdown","source":"**Design**, **Train** & **Test** deep CNN for Image Classification.\n\n**Join** the course & enjoy new opportunities to get deep learning skills:\n\n\n[https://www.udemy.com/course/convolutional-neural-networks-for-image-classification/](https://www.udemy.com/course/convolutional-neural-networks-for-image-classification/?referralCode=12EE0D74A405BF4DDE9B)\n\n\n![](https://github.com/sichkar-valentyn/1-million-images-for-Traffic-Signs-Classification-tasks/blob/main/images/slideshow_classification.gif?raw=true)","metadata":{}},{"cell_type":"markdown","source":"# ðŸ“¥ Importing needed libraries","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n# To create temporary directory, type in following in the Console\n# os.chdir(\"/kaggle/\")\n# !mkdir temp\n# os.listdir()\n\n# Any results we write to the current directory are saved as output in '/kaggle/working/' directory\nprint()\nprint(os.listdir('..'))\nprint(os.listdir('/kaggle/input'))\nprint(os.listdir('/kaggle/working/'))\n# print(os.listdir('/kaggle/temp/'))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-14T14:45:57.890708Z","iopub.execute_input":"2021-06-14T14:45:57.891177Z","iopub.status.idle":"2021-06-14T14:45:57.92233Z","shell.execute_reply.started":"2021-06-14T14:45:57.89107Z","shell.execute_reply":"2021-06-14T14:45:57.921161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Importing needed libraries\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport h5py\nimport cv2\n\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential, load_model\nfrom keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout\nfrom keras.utils import plot_model\nfrom keras.callbacks import LearningRateScheduler, ModelCheckpoint\n\nfrom sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n\nfrom timeit import default_timer as timer\n\n# Check point\nprint('Libraries are imported successfully')\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:46:02.272661Z","iopub.execute_input":"2021-06-14T14:46:02.272982Z","iopub.status.idle":"2021-06-14T14:46:04.220824Z","shell.execute_reply.started":"2021-06-14T14:46:02.272952Z","shell.execute_reply":"2021-06-14T14:46:04.220083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# âž° Designing and Saving Deep CNN model","metadata":{}},{"cell_type":"code","source":"# Building model for RGB datasets\n# RGB --> {128C5-P2-D30} --> {256C5-P2-D30} --> {512C5-P2-D30} --> {1024C3-P2-D30} --> 2048-D30 --> 43\n\n# Initializing model to be as linear stack of layers\nmodel = Sequential()\n\n# Adding first convolutional-pooling pair\nmodel.add(Conv2D(128, kernel_size=5, padding='same', activation='relu', input_shape=(48, 48, 3),\n                 kernel_initializer='random_normal',\n                 bias_initializer='zeros'))\nmodel.add(MaxPool2D())\nmodel.add(Dropout(0.3))\n\n# Adding second convolutional-pooling pair\nmodel.add(Conv2D(256, kernel_size=5, padding='same', activation='relu',\n                 kernel_initializer='random_normal',\n                 bias_initializer='zeros'))\nmodel.add(MaxPool2D())\nmodel.add(Dropout(0.3))\n\n# Adding third convolutional-pooling pair\nmodel.add(Conv2D(512, kernel_size=5, padding='same', activation='relu',\n                 kernel_initializer='random_normal',\n                 bias_initializer='zeros'))\nmodel.add(MaxPool2D())\nmodel.add(Dropout(0.3))\n\n# Adding fourth convolutional-pooling pair\nmodel.add(Conv2D(1024, kernel_size=3, padding='same', activation='relu',\n                 kernel_initializer='random_normal',\n                 bias_initializer='zeros'))\nmodel.add(MaxPool2D())\nmodel.add(Dropout(0.3))\n\n# Adding fully connected layers\nmodel.add(Flatten())\nmodel.add(Dense(2048, activation='relu',\n                kernel_initializer='random_normal',\n                bias_initializer='zeros'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(43, activation='softmax'))\n\n# Compiling created model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Saving model for RGB datasets\nmodel.save('model_ts_rgb_original.h5')\n\n\n\n# Building model for GRAY datasets\n# GRAY --> {128C5-P2-D30} --> {256C5-P2-D30} --> {512C5-P2-D30} --> {1024C3-P2-D30} --> 2048-D30 --> 43\n\n# Initializing model to be as linear stack of layers\nmodel = Sequential()\n\n# Adding first convolutional-pooling pair\nmodel.add(Conv2D(128, kernel_size=5, padding='same', activation='relu', input_shape=(48, 48, 1),\n                 kernel_initializer='random_normal',\n                 bias_initializer='zeros'))\nmodel.add(MaxPool2D())\nmodel.add(Dropout(0.3))\n\n# Adding second convolutional-pooling pair\nmodel.add(Conv2D(256, kernel_size=5, padding='same', activation='relu',\n                 kernel_initializer='random_normal',\n                 bias_initializer='zeros'))\nmodel.add(MaxPool2D())\nmodel.add(Dropout(0.3))\n\n# Adding third convolutional-pooling pair\nmodel.add(Conv2D(512, kernel_size=5, padding='same', activation='relu',\n                 kernel_initializer='random_normal',\n                 bias_initializer='zeros'))\nmodel.add(MaxPool2D())\nmodel.add(Dropout(0.3))\n\n# Adding fourth convolutional-pooling pair\nmodel.add(Conv2D(1024, kernel_size=3, padding='same', activation='relu',\n                 kernel_initializer='random_normal',\n                 bias_initializer='zeros'))\nmodel.add(MaxPool2D())\nmodel.add(Dropout(0.3))\n\n# Adding fully connected layers\nmodel.add(Flatten())\nmodel.add(Dense(2048, activation='relu',\n                kernel_initializer='random_normal',\n                bias_initializer='zeros'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(43, activation='softmax'))\n\n# Compiling created model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Saving 1st model for GRAY datasets\nmodel.save('model_ts_gray_original.h5')\n\n\n# Check point\nprint('2 models are saved successfully')\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:46:14.368849Z","iopub.execute_input":"2021-06-14T14:46:14.369176Z","iopub.status.idle":"2021-06-14T14:46:16.041315Z","shell.execute_reply.started":"2021-06-14T14:46:14.369146Z","shell.execute_reply":"2021-06-14T14:46:16.040321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ðŸ“¥ Loading and Verifying model","metadata":{}},{"cell_type":"code","source":"# Loading model\nmodel_rgb = load_model('/kaggle/working/model_ts_rgb_original.h5')\nmodel_gray = load_model('/kaggle/working/model_ts_gray_original.h5')\n\n# Check point\nprint('2 models are loaded successfully')\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:46:25.349087Z","iopub.execute_input":"2021-06-14T14:46:25.349545Z","iopub.status.idle":"2021-06-14T14:46:25.890188Z","shell.execute_reply.started":"2021-06-14T14:46:25.349505Z","shell.execute_reply":"2021-06-14T14:46:25.889324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting model's layers in form of flowchart\nplot_model(model_rgb,\n           to_file='model_ts_rgb_original.png',\n           show_shapes=True,\n           show_layer_names=False,\n           rankdir='TB',\n           dpi=500)\n\nplot_model(model_gray,\n           to_file='model_ts_gray_original.png',\n           show_shapes=True,\n           show_layer_names=False,\n           rankdir='TB',\n           dpi=500)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:46:31.675328Z","iopub.execute_input":"2021-06-14T14:46:31.675704Z","iopub.status.idle":"2021-06-14T14:46:34.769543Z","shell.execute_reply.started":"2021-06-14T14:46:31.675672Z","shell.execute_reply":"2021-06-14T14:46:34.768389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Showing model's summary in form of table\nmodel_rgb.summary()\nprint()\nmodel_gray.summary()\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:46:44.174747Z","iopub.execute_input":"2021-06-14T14:46:44.1751Z","iopub.status.idle":"2021-06-14T14:46:44.19453Z","shell.execute_reply.started":"2021-06-14T14:46:44.175066Z","shell.execute_reply":"2021-06-14T14:46:44.193763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Showing dropout rate\nprint(model_rgb.layers[2].rate)\nprint(model_gray.layers[2].rate)\n\n# Showing strides for the 1st layer (convolutional)\nprint(model_rgb.layers[0].strides)\nprint(model_gray.layers[0].strides)\n\n# Showing strides for the 2nd layer (max pooling)\nprint(model_rgb.layers[1].strides)\nprint(model_gray.layers[1].strides)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:46:48.653985Z","iopub.execute_input":"2021-06-14T14:46:48.654315Z","iopub.status.idle":"2021-06-14T14:46:48.66285Z","shell.execute_reply.started":"2021-06-14T14:46:48.654284Z","shell.execute_reply":"2021-06-14T14:46:48.662108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ðŸ“‚ Defining separate 4 models for training","metadata":{}},{"cell_type":"code","source":"# Defining lists to collect models in\nmodel_rgb = []\nmodel_gray = []\n\n\n# Loading models and appending them into lists\nfor i in range(2):\n    model_rgb.append(load_model('/kaggle/working/model_ts_rgb_original.h5'))\n    \n    model_gray.append(load_model('/kaggle/working/model_ts_gray_original.h5'))\n\n\n# Check point\nprint('4 separate models are successfully loaded')\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:46:51.363909Z","iopub.execute_input":"2021-06-14T14:46:51.364246Z","iopub.status.idle":"2021-06-14T14:46:52.225491Z","shell.execute_reply.started":"2021-06-14T14:46:51.364215Z","shell.execute_reply":"2021-06-14T14:46:52.224534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Showing models' input shapes\nprint(model_rgb[0].layers[0].input_shape)\nprint()\nprint(model_gray[0].layers[0].input_shape)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:46:57.022228Z","iopub.execute_input":"2021-06-14T14:46:57.02268Z","iopub.status.idle":"2021-06-14T14:46:57.04333Z","shell.execute_reply.started":"2021-06-14T14:46:57.022635Z","shell.execute_reply":"2021-06-14T14:46:57.042444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# âž¿ Training separately defined models","metadata":{}},{"cell_type":"code","source":"# Defining number of epochs\nepochs = 20\n\n\n# Defining schedule to update learning rate\nlearning_rate = LearningRateScheduler(lambda x: 1e-2 * 0.95 ** (x + 50), verbose=1)\n\n\n# Check point\nprint('Number of epochs and schedule for learning rate are set successfully')\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:47:00.126782Z","iopub.execute_input":"2021-06-14T14:47:00.127109Z","iopub.status.idle":"2021-06-14T14:47:00.132826Z","shell.execute_reply.started":"2021-06-14T14:47:00.127079Z","shell.execute_reply":"2021-06-14T14:47:00.1316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preparing list with datasets' names\ndatasets = ['dataset_ts_rgb_255_mean_original.hdf5',\n            'dataset_ts_rgb_255_mean_std_original.hdf5',\n            'dataset_ts_gray_255_mean_original.hdf5',\n            'dataset_ts_gray_255_mean_std_original.hdf5']\n\n\n# Defining list to collect results in\nh = []\n\n\n# Training model with all Traffic Signs datasets in a loop\nfor i in range(4):\n    # Opening saved Traffic Signs dataset from HDF5 binary file\n    # Initiating File object\n    # Opening file in reading mode by 'r'\n    with h5py.File('/kaggle/input/pre-processing-of-traffic-signs-dataset/' + datasets[i], 'r') as f:\n        # Extracting saved arrays for training by appropriate keys\n        # Saving them into new variables\n        x_train = f['x_train']  # HDF5 dataset\n        y_train = f['y_train']  # HDF5 dataset\n        # Converting them into Numpy arrays\n        x_train = np.array(x_train)  # Numpy arrays\n        y_train = np.array(y_train)  # Numpy arrays\n\n        # Extracting saved arrays for validation by appropriate keys\n        # Saving them into new variables\n        x_validation = f['x_validation']  # HDF5 dataset\n        y_validation = f['y_validation']  # HDF5 dataset\n        # Converting them into Numpy arrays\n        x_validation = np.array(x_validation)  # Numpy arrays\n        y_validation = np.array(y_validation)  # Numpy arrays\n    \n    \n    # Check point\n    print('Following dataset is successfully opened:        ', datasets[i])\n    \n    \n    # Preparing classes to be passed into the model\n    # Transforming them from vectors to binary matrices\n    # It is needed to set relationship between classes to be understood by the algorithm\n    # Such format is commonly used in training and predicting\n    y_train = to_categorical(y_train, num_classes = 43)\n    y_validation = to_categorical(y_validation, num_classes = 43)\n    \n    \n    # Check point\n    print('Binary matrices are successfully created:        ', datasets[i])\n \n\n    # Preparing filepath to save best weights\n    best_weights_filepath = 'w' + datasets[i][7:-5] + '.h5'\n       \n    # Defining schedule to save best weights\n    best_weights = ModelCheckpoint(filepath=best_weights_filepath,\n                                   save_weights_only=True,                                   \n                                   monitor='val_accuracy',\n                                   mode='max',\n                                   save_best_only=True,\n                                   period=1,\n                                   verbose=1)\n    \n    \n    # Check point\n    print('Schedule to save best weights is created:        ', datasets[i])\n\n    \n    # Checking if RGB dataset is opened\n    if i <= 1:\n        # Training RGB model with current dataset\n        temp = model_rgb[i].fit(x_train, y_train,\n                                batch_size=50,\n                                epochs=epochs,\n                                validation_data=(x_validation, y_validation),\n                                callbacks=[learning_rate, best_weights],\n                                verbose=1)\n\n        \n        # Adding results of model for current RGB dataset in the list\n        h.append(temp)\n        \n        \n        # Check points\n        print('Model for RGB is successfully trained on:        ', datasets[i])\n        print('Trained weights for RGB are saved successfully:  ', 'w' + datasets[i][7:-5] + '.h5')\n        print()\n    \n    # Checking if GRAY dataset is opened\n    elif i >= 2:\n        # Training GRAY model with current dataset\n        temp = model_gray[i-2].fit(x_train, y_train,\n                                   batch_size=50,\n                                   epochs=epochs,\n                                   validation_data=(x_validation, y_validation),\n                                   callbacks=[learning_rate, best_weights],\n                                   verbose=1)\n\n        \n        # Adding results of 1st model for current GRAY dataset in the list\n        h.append(temp)\n        \n        \n        # Check points\n        print('Model for GRAY is successfully trained on:       ', datasets[i])\n        print('Trained weights for GRAY are saved successfully: ', 'w' + datasets[i][7:-5] + '.h5')\n        print()\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:47:09.720568Z","iopub.execute_input":"2021-06-14T14:47:09.720893Z","iopub.status.idle":"2021-06-14T15:18:07.053684Z","shell.execute_reply.started":"2021-06-14T14:47:09.72086Z","shell.execute_reply":"2021-06-14T15:18:07.052922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Resulted accuracies of all pre-processed Traffic Signs datasets\nfor i in range(4):\n    print('T: {0:.5f},  V: {1:.5f},  D: {2}'.format(max(h[i].history['accuracy']),\n                                                    max(h[i].history['val_accuracy']),\n                                                    datasets[i][8:-5]))\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T15:18:11.268897Z","iopub.execute_input":"2021-06-14T15:18:11.269236Z","iopub.status.idle":"2021-06-14T15:18:11.275376Z","shell.execute_reply.started":"2021-06-14T15:18:11.269204Z","shell.execute_reply":"2021-06-14T15:18:11.274509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Showing other parameters that history holds\nprint(h[0].params)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T15:18:13.927838Z","iopub.execute_input":"2021-06-14T15:18:13.928169Z","iopub.status.idle":"2021-06-14T15:18:13.93278Z","shell.execute_reply.started":"2021-06-14T15:18:13.928137Z","shell.execute_reply":"2021-06-14T15:18:13.93159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Magic function that renders the figure in a jupyter notebook\n# instead of displaying a figure object\n%matplotlib inline\n\n\n# Setting default size of the plot\nplt.rcParams['figure.figsize'] = (12.0, 6.0)\nplt.rcParams['font.family'] = 'Times New Roman'\n\n\n# Plotting accuracies of all Traffic Signs datasets for 1st model\nplt.plot(h[0].history['val_accuracy'], '-o')\nplt.plot(h[1].history['val_accuracy'], '-o')\nplt.plot(h[2].history['val_accuracy'], '-o')\nplt.plot(h[3].history['val_accuracy'], '-o')\n\n\n# Showing legend\nplt.legend(['rgb_255_mean', 'rgb_255_mean_std',\n            'gray_255_mean', 'gray_255_mean_std'],\n           loc='lower right',\n           fontsize='xx-large')\n\n\n# Giving name to axes\nplt.xlabel('Epoch', fontsize=16)\nplt.ylabel('Accuracy', fontsize=16)\n\n\n# Setting limit along Y axis\nplt.ylim(0.97, 0.9992)\n\n\n# Giving name to the plot\nplt.title('Validation accuracies', fontsize=16)\n\n\n# Saving plot\nplt.savefig('validation_model_ts_dataset_original.png', dpi=500)\n\n\n# Showing the plot\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T15:18:18.634907Z","iopub.execute_input":"2021-06-14T15:18:18.635223Z","iopub.status.idle":"2021-06-14T15:18:20.025985Z","shell.execute_reply.started":"2021-06-14T15:18:18.635193Z","shell.execute_reply":"2021-06-14T15:18:20.02526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Magic function that renders the figure in a jupyter notebook\n# instead of displaying a figure object\n%matplotlib inline\n\n\n# Setting default size of the plot\nplt.rcParams['figure.figsize'] = (12.0, 6.0)\nplt.rcParams['font.family'] = 'Times New Roman'\n\n\n# Plotting training and validation losses of all Traffic Signs datasets for 1st model\nplt.plot(h[0].history['loss'], '-ob')\nplt.plot(h[1].history['loss'], '-og')\nplt.plot(h[2].history['loss'], '-or')\nplt.plot(h[3].history['loss'], '-oc')\n\nplt.plot(h[0].history['val_loss'], '-ob')\nplt.plot(h[1].history['val_loss'], '-og')\nplt.plot(h[2].history['val_loss'], '-or')\nplt.plot(h[3].history['val_loss'], '-oc')\n\n\n# Showing legend\nplt.legend(['rgb_255_mean', 'rgb_255_mean_std',\n            'gray_255_mean', 'gray_255_mean_std'],\n           loc='center right',\n           fontsize='large')\n\n\n# Giving name to axes\nplt.xlabel('Epoch', fontsize=16)\nplt.ylabel('Loss', fontsize=16)\n\n\n# Giving name to the plot\nplt.title('Losses', fontsize=16)\n\n\n# Saving plot\nplt.savefig('losses_model_ts_dataset_original.png', dpi=500)\n\n\n# Showing the plot\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T15:18:24.30883Z","iopub.execute_input":"2021-06-14T15:18:24.309161Z","iopub.status.idle":"2021-06-14T15:18:25.605625Z","shell.execute_reply.started":"2021-06-14T15:18:24.309129Z","shell.execute_reply":"2021-06-14T15:18:25.604529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ðŸ§® Calculating testing accuracies","metadata":{}},{"cell_type":"code","source":"# Defining lists to collect models in\nmodel_rgb = []\nmodel_gray = []\n\n\n# Loading 1st model for Traffic Signs dataset\nfor i in range(2):\n    model_rgb.append(load_model('/kaggle/working/model_ts_rgb_original.h5'))\n    model_gray.append(load_model('/kaggle/working/model_ts_gray_original.h5'))\n\n\n# Check point\nprint('4 separate models are successfully loaded')\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T15:18:28.839693Z","iopub.execute_input":"2021-06-14T15:18:28.840017Z","iopub.status.idle":"2021-06-14T15:18:29.738798Z","shell.execute_reply.started":"2021-06-14T15:18:28.839985Z","shell.execute_reply":"2021-06-14T15:18:29.737816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Showing models' input shapes\nprint(model_rgb[0].layers[0].input_shape)\nprint()\nprint(model_gray[0].layers[0].input_shape)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T15:18:33.841033Z","iopub.execute_input":"2021-06-14T15:18:33.841375Z","iopub.status.idle":"2021-06-14T15:18:33.84767Z","shell.execute_reply.started":"2021-06-14T15:18:33.841329Z","shell.execute_reply":"2021-06-14T15:18:33.846578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preparing list with weights' names\nweights = ['w_ts_rgb_255_mean_original.h5',\n           'w_ts_rgb_255_mean_std_original.h5',\n           'w_ts_gray_255_mean_original.h5',\n           'w_ts_gray_255_mean_std_original.h5']\n\n\n# Loading best weights for 1st model\nfor i in range(4):    \n    # Checking if it is RGB model\n    if i <= 1:\n        # loading and assigning best weights\n        model_rgb[i].load_weights('/kaggle/working/' + weights[i])\n        \n        \n        # Check point\n        print('Best weights for RGB model are loaded and assigned  : ', weights[i])\n    \n    # Checking if it is GRAY model\n    elif i >= 2:\n        # loading and assigning best weights\n        model_gray[i-2].load_weights('/kaggle/working/' + weights[i])\n        \n        \n        # Check point\n        print('Best weights for GRAY model are loaded and assigned : ', weights[i])\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T15:18:36.374629Z","iopub.execute_input":"2021-06-14T15:18:36.374968Z","iopub.status.idle":"2021-06-14T15:18:37.005462Z","shell.execute_reply.started":"2021-06-14T15:18:36.37493Z","shell.execute_reply":"2021-06-14T15:18:37.004461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preparing list with datasets' names\ndatasets = ['dataset_ts_rgb_255_mean_original.hdf5',\n            'dataset_ts_rgb_255_mean_std_original.hdf5',\n            'dataset_ts_gray_255_mean_original.hdf5',\n            'dataset_ts_gray_255_mean_std_original.hdf5']\n\n\n# Defining variable to identify the best model\naccuracy_best = 0\n\n\n# Testing 1st model with all Traffic Signs datasets in a loop\nfor i in range(4):    \n    # Opening saved Traffic Signs dataset from HDF5 binary file\n    # Initiating File object\n    # Opening file in reading mode by 'r'\n    with h5py.File('/kaggle/input/pre-processing-of-traffic-signs-dataset/' + datasets[i], 'r') as f:\n        # Extracting saved arrays for testing by appropriate keys\n        # Saving them into new variables\n        x_test = f['x_test']  # HDF5 dataset\n        y_test = f['y_test']  # HDF5 dataset\n        # Converting them into Numpy arrays\n        x_test = np.array(x_test)  # Numpy arrays\n        y_test = np.array(y_test)  # Numpy arrays\n    \n    \n    # Check point\n    print('Dataset is opened :', datasets[i])\n    \n    \n    # Check point\n    # Showing shapes of loaded arrays\n    if i == 0:\n        print('x_test shape      :', x_test.shape)\n        print('y_test shape      :', y_test.shape)\n    \n    \n    # Checking if RGB dataset is opened\n    if i <= 1:\n        # Testing RGB model with current dataset\n        temp = model_rgb[i].predict(x_test)\n        \n        \n        # Check point\n        # Showing prediction shape and scores\n        if i == 0:\n            print('prediction shape  :', temp.shape)  # (3111, 43)\n            print('prediction scores :', temp[0, 0:5])  # 5 score numbers\n      \n    \n        # Getting indexes of maximum values along specified axis\n        temp = np.argmax(temp, axis=1)\n        \n        \n        # Check point\n        # Showing prediction shape after convertion\n        # Showing predicted and correct indexes of classes\n        if i == 0:\n            print('prediction shape  :', temp.shape)  # (3111,)\n            print('predicted indexes :', temp[0:10])\n            print('correct indexes   :', y_test[:10])\n        \n        \n        # Calculating accuracy\n        # We compare predicted class with correct class for all input images\n        # By saying 'temp == y_test' we create Numpy array with True and False values\n        # By function 'np.mean' we calculate mean value:\n        # all_True / (all_True + all_False)\n        accuracy = np.mean(temp == y_test)\n        \n        \n        # Check point\n        # Showing True and False matrix\n        if i == 0:\n            print('T and F matrix    :', (temp == y_test)[0:10])\n        \n        \n        # Check point\n        # Showing calculated accuracy\n        print('Testing accuracy  : {0:.5f}'.format(accuracy))\n        print()\n    \n    # Checking if GRAY dataset is opened\n    elif i >= 2:\n        # Testing GRAY model with current dataset\n        temp = model_gray[i-2].predict(x_test)\n        \n        \n        # Getting indexes of maximum values along specified axis\n        temp = np.argmax(temp, axis=1)\n        \n        \n        # Calculating accuracy\n        # We compare predicted class with correct class for all input images\n        # By saying 'temp == y_test' we create Numpy array with True and False values\n        # By function 'np.mean' we calculate mean value:\n        # all_True / (all_True + all_False)\n        accuracy = np.mean(temp == y_test)\n        \n        \n        # Check point\n        # Showing calculated accuracy\n        print('Testing accuracy  : {0:.5f}'.format(accuracy))\n        print()\n    \n    \n    # Identifying the best model\n    # Saving predicted indexes of the best model\n    if accuracy > accuracy_best:\n        # Updating value of the best accuracy\n        accuracy_best = accuracy\n        \n        # Saving predicted indexes of the best model into array\n        # Updating array with predicted indexes of the best model\n        y_predicted_best = temp\n    ","metadata":{"execution":{"iopub.status.busy":"2021-06-14T15:18:41.14977Z","iopub.execute_input":"2021-06-14T15:18:41.150091Z","iopub.status.idle":"2021-06-14T15:18:48.760456Z","shell.execute_reply.started":"2021-06-14T15:18:41.15006Z","shell.execute_reply":"2021-06-14T15:18:48.75954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# âœ¨ Classification report","metadata":{}},{"cell_type":"code","source":"# Showing the main classification metrics of the best model\nprint(classification_report(y_test, y_predicted_best))\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T15:18:51.419903Z","iopub.execute_input":"2021-06-14T15:18:51.420226Z","iopub.status.idle":"2021-06-14T15:18:51.442501Z","shell.execute_reply.started":"2021-06-14T15:18:51.420194Z","shell.execute_reply":"2021-06-14T15:18:51.441587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# âœ”ï¸ Confusion matrix","metadata":{}},{"cell_type":"code","source":"# Confusion matrix is a two dimensional matrix that visualizes the performance,\n# and makes it easy to see confusion between classes,\n# by providing a picture of interrelation\n\n# Each row represents a number of actual class  \n# Each column represents a number of predicted class  \n\n\n# Computing confusion matrix to evaluate accuracy of classification\nc_m = confusion_matrix(y_test, y_predicted_best)\n\n# Showing confusion matrix in form of Numpy array\nprint(c_m)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T15:18:56.680154Z","iopub.execute_input":"2021-06-14T15:18:56.680506Z","iopub.status.idle":"2021-06-14T15:18:56.701917Z","shell.execute_reply.started":"2021-06-14T15:18:56.68047Z","shell.execute_reply":"2021-06-14T15:18:56.700648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Magic function that renders the figure in a jupyter notebook\n# instead of displaying a figure object\n%matplotlib inline\n\n\n# Setting default size of the plot\n# Setting default fontsize used in the plot\nplt.rcParams['figure.figsize'] = (14.0, 14.0)\nplt.rcParams['font.size'] = 12\n\n\n# Implementing visualization of confusion matrix\ndisplay_c_m = ConfusionMatrixDisplay(c_m)\n\n\n# Plotting confusion matrix\n# Setting colour map to be used\ndisplay_c_m.plot(cmap='PuRd')\n# Other possible options for colour map are:\n# 'OrRd', 'autumn_r', 'Blues', 'cool', 'Greens', 'Greys', 'copper_r'\n\n\n# Setting fontsize for xticks and yticks\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\n\n# Setting fontsize for xlabels and ylabels\nplt.xlabel('Predicted label', fontsize=18)\nplt.ylabel('True label', fontsize=18)\n\n\n# Giving name to the plot\nplt.title('Confusion Matrix: Traffic Signs Dataset', fontsize=18)\n\n\n# Saving plot\nplt.savefig('confusion_matrix_ts_model.png', transparent=True, dpi=500)\n\n\n# Showing the plot\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T15:18:59.543218Z","iopub.execute_input":"2021-06-14T15:18:59.543583Z","iopub.status.idle":"2021-06-14T15:19:10.721319Z","shell.execute_reply.started":"2021-06-14T15:18:59.543551Z","shell.execute_reply":"2021-06-14T15:19:10.72046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ðŸ–¼ï¸ Testing on one image","metadata":{}},{"cell_type":"code","source":"# Opening saved Mean Image for RGB Traffic Signs dataset\n# Initiating File object\n# Opening file in reading mode by 'r'\n# (!) On Windows, it might need to change\n# this: + '/' +\n# to this: + '\\' +\n# or to this: + '\\\\' +\nwith h5py.File('/kaggle/input/pre-processing-of-traffic-signs-dataset' + '/' + \n               'mean_rgb_dataset_ts_original.hdf5', 'r') as f:\n    # Extracting saved array for Mean Image\n    # Saving it into new variable\n    mean_rgb = f['mean']  # HDF5 dataset\n    # Converting it into Numpy array\n    mean_rgb = np.array(mean_rgb)  # Numpy arrays\n\n\n# Opening saved Standard Deviation for RGB Traffic Signs dataset\n# Initiating File object\n# Opening file in reading mode by 'r'\n# (!) On Windows, it might need to change\n# this: + '/' +\n# to this: + '\\' +\n# or to this: + '\\\\' +\nwith h5py.File('/kaggle/input/pre-processing-of-traffic-signs-dataset' + '/' + \n               'std_rgb_dataset_ts_original.hdf5', 'r') as f:\n    # Extracting saved array for Standard Deviation\n    # Saving it into new variable\n    std_rgb = f['std']  # HDF5 dataset\n    # Converting it into Numpy array\n    std_rgb = np.array(std_rgb)  # Numpy arrays\n\n\n# Opening saved Mean Image for GRAY Traffic Signs dataset\n# Initiating File object\n# Opening file in reading mode by 'r'\n# (!) On Windows, it might need to change\n# this: + '/' +\n# to this: + '\\' +\n# or to this: + '\\\\' +\nwith h5py.File('/kaggle/input/pre-processing-of-traffic-signs-dataset' + '/' + \n               'mean_gray_dataset_ts_original.hdf5', 'r') as f:\n    # Extracting saved array for Mean Image\n    # Saving it into new variable\n    mean_gray = f['mean']  # HDF5 dataset\n    # Converting it into Numpy array\n    mean_gray = np.array(mean_gray)  # Numpy arrays\n\n\n# Opening saved Standard Deviation for GRAY Traffic Signs dataset\n# Initiating File object\n# Opening file in reading mode by 'r'\n# (!) On Windows, it might need to change\n# this: + '/' +\n# to this: + '\\' +\n# or to this: + '\\\\' +\nwith h5py.File('/kaggle/input/pre-processing-of-traffic-signs-dataset' + '/' + \n               'std_gray_dataset_ts_original.hdf5', 'r') as f:\n    # Extracting saved array for Standard Deviation\n    # Saving it into new variable\n    std_gray = f['std']  # HDF5 dataset\n    # Converting it into Numpy array\n    std_gray = np.array(std_gray)  # Numpy arrays\n\n\n# Check points\n# Showing shapes of loaded Numpy arrays\nprint('RGB Mean Image          :', mean_rgb.shape)\nprint('RGB Standard Deviation  :', std_rgb.shape)\nprint('GRAY Mean Image         :', mean_gray.shape)\nprint('GRAY Standard Deviation :', std_gray.shape)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T15:19:17.198788Z","iopub.execute_input":"2021-06-14T15:19:17.199106Z","iopub.status.idle":"2021-06-14T15:19:17.238107Z","shell.execute_reply.started":"2021-06-14T15:19:17.199075Z","shell.execute_reply":"2021-06-14T15:19:17.237392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Magic function that renders the figure in a jupyter notebook\n# instead of displaying a figure object\n%matplotlib inline\n\n# Setting default size of the plot\nplt.rcParams['figure.figsize'] = (2.5, 2.5)\n\n\n\n# Reading image by OpenCV library\n# In this way image is opened already as Numpy array\n# (!) OpenCV by default reads images in BGR order of channels\n# (!) On Windows, it might need to change\n# this: + '/' +\n# to this: + '\\' +\n# or to this: + '\\\\' +\nimage_ts_bgr = cv2.imread('/kaggle/input/images-for-testing' + '/' + 'ts_to_test.jpg')\n\n# Swapping channels from BGR to RGB by OpenCV function\nimage_ts_rgb = cv2.cvtColor(image_ts_bgr, cv2.COLOR_BGR2RGB)\n\n# Resizing image to 32 by 32 pixels size\nimage_ts_rgb = cv2.resize(image_ts_rgb,\n                              (48, 48),\n                              interpolation=cv2.INTER_CUBIC)\n\n# Check point\n# Showing loaded and resized image\nplt.imshow(image_ts_rgb)\nplt.show()\n\n\n\n# Implementing normalization by dividing image's pixels on 255.0\nimage_ts_rgb_255 = image_ts_rgb / 255.0\n\n# Implementing normalization by subtracting Mean Image\nimage_ts_rgb_255_mean = image_ts_rgb_255 - mean_rgb\n\n# Implementing preprocessing by dividing on Standard Deviation\nimage_ts_rgb_255_mean_std = image_ts_rgb_255_mean / std_rgb\n\n# Check points\n# Showing shape of Numpy array with RGB image\n# Showing some pixels' values\nprint('Shape of RGB image         :', image_ts_rgb.shape)\nprint('Pixels of RGB image        :', image_ts_rgb[:5, 0, 0])\nprint('RGB /255.0                 :', image_ts_rgb_255[:5, 0, 0])\nprint('RGB /255.0 => mean         :', image_ts_rgb_255_mean[:5, 0, 0])\nprint('RGB /255.0 => mean => std  :', image_ts_rgb_255_mean_std[:5, 0, 0])\nprint()\n\n\n\n# Converting image to GRAY by OpenCV function\nimage_ts_gray = cv2.cvtColor(image_ts_rgb, cv2.COLOR_RGB2GRAY)\n\n# Extending dimension from (height, width) to (height, width, one channel)\nimage_ts_gray = image_ts_gray[:, :, np.newaxis]\n\n# Check point\n# Showing converted into GRAY image\nplt.imshow(image_ts_gray, cmap=plt.get_cmap('gray'))\nplt.show()\n\n\n\n# Implementing normalization by dividing image's pixels on 255.0\nimage_ts_gray_255 = image_ts_gray / 255.0\n\n# Implementing normalization by subtracting Mean Image\nimage_ts_gray_255_mean = image_ts_gray_255 - mean_gray\n\n# Implementing preprocessing by dividing on Standard Deviation\nimage_ts_gray_255_mean_std = image_ts_gray_255_mean / std_gray\n\n# Check points\n# Showing shape of Numpy array with GRAY image\n# Showing some pixels' values\nprint('Shape of GRAY image        :', image_ts_gray.shape)\nprint('Pixels of GRAY image       :', image_ts_gray[:5, 0, 0])\nprint('GRAY /255.0                :', image_ts_gray_255[:5, 0, 0])\nprint('GRAY /255.0 => mean        :', image_ts_gray_255_mean[:5, 0, 0])\nprint('GRAY /255.0 => mean => std :', image_ts_gray_255_mean_std[:5, 0, 0])\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T15:19:22.396163Z","iopub.execute_input":"2021-06-14T15:19:22.396514Z","iopub.status.idle":"2021-06-14T15:19:22.686844Z","shell.execute_reply.started":"2021-06-14T15:19:22.396483Z","shell.execute_reply":"2021-06-14T15:19:22.683531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Extending dimension from (height, width, channels) to (1, height, width, channels)\nimage_ts_rgb_255_mean = image_ts_rgb_255_mean[np.newaxis, :, :, :]\nimage_ts_rgb_255_mean_std = image_ts_rgb_255_mean_std[np.newaxis, :, :, :]\n\nimage_ts_gray_255_mean = image_ts_gray_255_mean[np.newaxis, :, :, :]\nimage_ts_gray_255_mean_std = image_ts_gray_255_mean_std[np.newaxis, :, :, :]\n\n# Check points\n# Showing shapes of extended Numpy arrays\nprint('RGB /255.0 => mean         :', image_ts_rgb_255_mean.shape)\nprint('RGB /255.0 => mean => std  :', image_ts_rgb_255_mean_std.shape)\nprint()\nprint('GRAY /255.0 => mean        :', image_ts_gray_255_mean.shape)\nprint('GRAY /255.0 => mean => std :', image_ts_gray_255_mean_std.shape)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T15:19:27.523677Z","iopub.execute_input":"2021-06-14T15:19:27.524005Z","iopub.status.idle":"2021-06-14T15:19:27.534675Z","shell.execute_reply.started":"2021-06-14T15:19:27.523972Z","shell.execute_reply":"2021-06-14T15:19:27.53394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Defining function to plot bar chart with scores values\ndef bar_chart(scores, bar_title, show_xticks=True, labels=None):\n    # Arranging X axis\n    x_positions = np.arange(scores.size)\n\n    # Creating bar chart\n    barlist = plt.bar(x_positions, scores, align='center', alpha=0.6)\n\n    # Highlighting the highest bar\n    barlist[np.argmax(scores)].set_color('red')\n\n    # Giving labels to bars along X axis\n    if show_xticks:\n        plt.xticks(x_positions, labels, rotation=20, fontsize=15)\n\n    # Giving name to axes\n    plt.xlabel('Class', fontsize=20)\n    plt.ylabel('Value', fontsize=20)\n\n    # Giving name to bar chart\n    plt.title('Classification: ' + bar_title, fontsize=20)\n\n    # Showing bar chart\n    plt.show()\n\n\n# Check point\nprint('Function to plot Bar Chart is successfully defined')\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T15:19:30.95399Z","iopub.execute_input":"2021-06-14T15:19:30.954337Z","iopub.status.idle":"2021-06-14T15:19:30.962524Z","shell.execute_reply.started":"2021-06-14T15:19:30.9543Z","shell.execute_reply":"2021-06-14T15:19:30.961269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preparing labels for Traffic Signs dataset\n# Getting Pandas dataFrame with labels\n# (!) On Windows, it might need to change\n# this: + '/' +\n# to this: + '\\' +\n# or to this: + '\\\\' +\nlabels_ts = pd.read_csv('/kaggle/input/traffic-signs-preprocessed' + '/' + 'label_names.csv', sep=',')\n\n\n# Check point\n# Showing first 5 elements of the dataFrame\nprint(labels_ts.head())\nprint()\n\n\n# Showing class's name of the 1st element\nprint(labels_ts.loc[0, 'SignName'])\nprint()\n\n\n# Converting into Numpy array\nlabels_ts = np.array(labels_ts.loc[:, 'SignName']).flatten()\n\n\n# Check points\n# Showing size of Numpy array\n# Showing all elements of Numpy array\nprint('Total number of labels:', labels_ts.size)\nprint()\nprint(labels_ts)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T15:19:33.710336Z","iopub.execute_input":"2021-06-14T15:19:33.710716Z","iopub.status.idle":"2021-06-14T15:19:33.748239Z","shell.execute_reply.started":"2021-06-14T15:19:33.710683Z","shell.execute_reply":"2021-06-14T15:19:33.747394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Magic function that renders the figure in a jupyter notebook\n# instead of displaying a figure object\n%matplotlib inline\n\n# Setting default size of the plot\nplt.rcParams['figure.figsize'] = (12, 7)\n\n\n\n# Testing RGB model trained on dataset: dataset_ts_rgb_255_mean.hdf5\n# Input image is preprocessed in the same way\n# Measuring classification time\nstart = timer()\nscores = model_rgb[0].predict(image_ts_rgb_255_mean)\nend = timer()\n\n# Scores are given as 43 numbers of predictions for each class\n# Getting only one class with maximum value\nprediction = np.argmax(scores)\n\n# Check points\n# Showing scores shape and values\n# Printing class index, label and time\nprint()\nprint('Scores shape        :', scores.shape)\nprint('Scores values       :', scores[0, 10:15])\nprint('Scores sum          :', scores[0].sum())\nprint('Score of prediction : {0:.5f}'.format(scores[0][prediction]))\nprint('Class index         :', prediction)\nprint('Label               :', labels_ts[prediction])\nprint('Time                : {0:.5f}'.format(end - start))\n\n# Plotting bar chart with scores values\nbar_chart(scores[0],\n          bar_title='1st RGB model, ts_rgb_255_mean',\n          show_xticks=False)\n\n\n\n# Testing RGB model trained on dataset: dataset_ts_rgb_255_mean_std.hdf5\n# Input image is preprocessed in the same way\n# Measuring classification time\nstart = timer()\nscores = model_rgb[1].predict(image_ts_rgb_255_mean_std)\nend = timer()\n\n# Scores are given as 43 numbers of predictions for each class\n# Getting only one class with maximum value\nprediction = np.argmax(scores)\n\n# Check points\n# Showing scores shape and values\n# Printing class index, label and time\nprint()\nprint('Scores shape        :', scores.shape)\nprint('Scores values       :', scores[0, 10:15])\nprint('Scores sum          :', scores[0].sum())\nprint('Score of prediction : {0:.5f}'.format(scores[0][prediction]))\nprint('Class index         :', prediction)\nprint('Label               :', labels_ts[prediction])\nprint('Time                : {0:.5f}'.format(end - start))\n\n# Plotting bar chart with scores values\nbar_chart(scores[0],\n          bar_title='1st RGB model, ts_rgb_255_mean_std',\n          show_xticks=False)\n\n\n\n# Testing GRAY model trained on dataset: dataset_ts_gray_255_mean.hdf5\n# Input image is preprocessed in the same way\n# Measuring classification time\nstart = timer()\nscores = model_gray[0].predict(image_ts_gray_255_mean)\nend = timer()\n\n# Scores are given as 43 numbers of predictions for each class\n# Getting only one class with maximum value\nprediction = np.argmax(scores)\n\n# Check points\n# Showing scores shape and values\n# Printing class index, label and time\nprint()\nprint('Scores shape        :', scores.shape)\nprint('Scores values       :', scores[0, 10:15])\nprint('Scores sum          :', scores[0].sum())\nprint('Score of prediction : {0:.5f}'.format(scores[0][prediction]))\nprint('Class index         :', prediction)\nprint('Label               :', labels_ts[prediction])\nprint('Time                : {0:.5f}'.format(end - start))\n\n# Plotting bar chart with scores values\nbar_chart(scores[0],\n          bar_title='1st GRAY model, ts_gray_255_mean',\n          show_xticks=False)\n\n\n\n# Testing GRAY model trained on dataset: dataset_ts_gray_255_mean_std.hdf5\n# Input image is preprocessed in the same way\n# Measuring classification time\nstart = timer()\nscores = model_gray[1].predict(image_ts_gray_255_mean_std)\nend = timer()\n\n# Scores are given as 43 numbers of predictions for each class\n# Getting only one class with maximum value\nprediction = np.argmax(scores)\n\n# Check points\n# Showing scores shape and values\n# Printing class index, label and time\nprint()\nprint('Scores shape        :', scores.shape)\nprint('Scores values       :', scores[0, 10:15])\nprint('Scores sum          :', scores[0].sum())\nprint('Score of prediction : {0:.5f}'.format(scores[0][prediction]))\nprint('Class index         :', prediction)\nprint('Label               :', labels_ts[prediction])\nprint('Time                : {0:.5f}'.format(end - start))\n\n# Plotting bar chart with scores values\nbar_chart(scores[0],\n          bar_title='1st GRAY model, ts_gray_255_mean_std',\n          show_xticks=False)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T15:19:37.180898Z","iopub.execute_input":"2021-06-14T15:19:37.181218Z","iopub.status.idle":"2021-06-14T15:19:38.207236Z","shell.execute_reply.started":"2021-06-14T15:19:37.181185Z","shell.execute_reply":"2021-06-14T15:19:38.206533Z"},"trusted":true},"execution_count":null,"outputs":[]}]}