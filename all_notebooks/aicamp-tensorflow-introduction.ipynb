{"cells":[{"metadata":{"trusted":false,"collapsed":true,"_uuid":"ad5e3d9aa1b4f9cc022ca21d923417d325660702"},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error as mse\nfrom sklearn.metrics import r2_score","execution_count":2,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"e7c17eed09df55a898d4124fbb7b4b4ca6e360db"},"cell_type":"code","source":"x = tf.Variable(3, name='x')\ny = tf.Variable(4, name='y')\nf = x * x * y + y + 2","execution_count":2,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"a219891a4590138934157cc7e3cd56b5fbdd66f8"},"cell_type":"code","source":"sess = tf.Session()\nsess.run(x.initializer)\nsess.run(y.initializer)\nresult = sess.run(f)\nprint(result)","execution_count":3,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"fdc1becb5d490de5e7c5829e33a40a6b7b549429"},"cell_type":"code","source":"sess.close()","execution_count":4,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"6242a5b0bb7138f484a96fdfa1580a4ec100d2bf"},"cell_type":"code","source":"with tf.Session() as sess:\n    x.initializer.run()\n    y.initializer.run()\n    result = f.eval()","execution_count":5,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"1e9b21480718ec2ed9c09b522bcadde3227cebb3"},"cell_type":"code","source":"print(result)","execution_count":6,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"2eb01a9903d3f14db76e8d9ab9055ad9cdd78b55"},"cell_type":"code","source":"init = tf.global_variables_initializer()\nwith tf.Session() as sess:\n    init.run()\n    result = f.eval()","execution_count":7,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"0b4e542e6e9ba0b1cf03a6029b5fc6deb39c8ea9"},"cell_type":"code","source":"print(result)","execution_count":8,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"cb7c019e70b3447a54f0e58f7c5e99019bd5e019"},"cell_type":"code","source":"init = tf.global_variables_initializer()\nwith tf.Session() as sess:\n    init.run()\n    print(x.eval())\n    print(y.eval())\n    result = sess.run(f, feed_dict={x:1, y:0})","execution_count":12,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"2907d830ca0ecddb72324e8c6360833915902bec"},"cell_type":"code","source":"print(result)","execution_count":13,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"1a76ec0610c027253b1676429afb7f8c30281933"},"cell_type":"markdown","source":"### 用tensorflow 来实现linear regression"},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"0ae375c115b80f77e218be416d7666f09ff2c469"},"cell_type":"code","source":"\ndef plot_decision_boundary(X, model):\n    h = .02 \n\n    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n                       np.arange(y_min, y_max, h))\n\n\n    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n\n    Z = Z.reshape(xx.shape)\n    plt.contour(xx, yy, Z, cmap=plt.cm.Paired)\n\n\ndef f(X):\n    \"\"\"\n    input: x\n    output: y = 3x + 4\n    \"\"\"\n    return 3*X + 4\n\n\n","execution_count":14,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"4cd3bc255e32725609049e39305b65c25f471b64"},"cell_type":"code","source":"N = 40\nnoise_level = 0.8\ntrainX = np.linspace(-4.0, 4.0, N)\nnp.random.shuffle(trainX)\ntrainY = f(trainX) + np.random.randn(N) * noise_level\n\n\nlearning_rate = 0.01\ntraining_epochs = 1000\ndisplay_step = 50","execution_count":17,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"e90666afe12c86841f37eb12b35679866fa87e7f"},"cell_type":"code","source":"plt.scatter(trainX, trainY)","execution_count":18,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"3f0f0c1f681aa03d43f1084507751ce50deef073"},"cell_type":"code","source":"from sklearn.base import BaseEstimator","execution_count":19,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"c089183cbdb0907403b901653ea06715e568c811"},"cell_type":"code","source":"class LinearRegressionTF(BaseEstimator):\n    def __init__(self, learning_rate, training_epochs, display_step, annotate=False):\n        self.annotate = annotate\n        self.sess = tf.Session()\n        self.training_epochs = training_epochs\n        self.learning_rate = learning_rate\n        self.display_step = display_step\n        \n        \n    def fit(self, trainX,trainY):\n        N = trainX.shape[0]\n        # 图的输入\n        self.X = tf.placeholder(\"float\")\n        self.Y = tf.placeholder(\"float\")\n        \n        \n        # 参数的定义\n        self.W = tf.Variable(np.random.randn(), name=\"weight\")\n        self.b = tf.Variable(np.random.randn(), name=\"bias\")\n        \n        # 线性模型\n        self.pred = tf.add(tf.multiply(self.X, self.W), self.b)\n        \n        # mean squre error\n        cost = tf.reduce_sum(tf.pow(self.pred-self.Y, 2))/(2*N)\n        \n        # 优化器\n        optimizer = tf.train.GradientDescentOptimizer(self.learning_rate).minimize(cost)\n        \n        # 初始化所有的参数\n        init = tf.global_variables_initializer()\n        self.sess.run(init)\n\n        \n        if self.annotate:\n            plt.plot(trainX, trainY, 'ro', label='Original data')\n            plt.plot(trainX, self.sess.run(self.W) * trainX + self.sess.run(self.b), label='Fitted line')\n            plt.legend()\n            plt.title(\"This is where model starts to learn!!\")\n            plt.show()\n            \n        # 训练开始\n        for epoch in range(self.training_epochs):\n            for (x, y) in zip(trainX, trainY):\n                self.sess.run(optimizer, feed_dict={self.X: x, self.Y: y})\n\n            #展示训练结果\n            if (epoch+1) % display_step == 0:\n                c = self.sess.run(cost, feed_dict={self.X: trainX, self.Y:trainY})\n                print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(c), \\\n            \"W=\", self.sess.run(self.W), \"b=\", self.sess.run(self.b))\n                \n            #显示拟合的直线\n                if self.annotate:\n                    plt.plot(trainX, trainY, 'ro', label='Original data')\n                    plt.plot(trainX, self.sess.run(self.W) * trainX + self.sess.run(self.b), label='Fitted line')\n                    plt.legend()\n                    plt.show()\n                #plt.pause(0.5)\n\n        print(\"Optimization Finished!\")\n        training_cost = self.sess.run(cost, feed_dict={self.X: trainX, self.Y: trainY})\n        print(\"Training cost=\", training_cost, \"W=\", self.sess.run(self.W), \"b=\", self.sess.run(self.b), '\\n')\n\n        \n    def predict(self, testX):\n        prediction = self.sess.run(self.pred,feed_dict={self.X: testX})\n        return prediction\n    \n    def score(self, testX, testY):\n        result = self.predict(testX)\n        return r2_score(testY, result)\n        \n    ","execution_count":23,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"0d6b61fe1d7c162a2ad758c6775d93ef331acdd1"},"cell_type":"code","source":"lr = LinearRegressionTF(learning_rate, 1000, display_step, annotate=False)\nlr.fit(trainX, trainY)","execution_count":25,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"fe0dbf2cfc47620e3b0d7e742369275e93d70fd1"},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\ncross_val_score(lr, trainX, trainY, cv=5).mean()","execution_count":26,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"188cda93828598ca757633d2baa9b77c5b7128c2"},"cell_type":"code","source":"","execution_count":6,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"3041563fa92a1a5cadb4932657fc94fafc628c83"},"cell_type":"markdown","source":"### 用tensorflow 来实现logistic regression"},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"e90a3afd0ccd8598befebea12c57598c17ad8e40"},"cell_type":"code","source":"tf.reset_default_graph()","execution_count":26,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"f9f8c89ba6083b2bbba9d3d041f9049d60746c77"},"cell_type":"code","source":"N = 100\nD = 2\ntrainX = np.random.randn(N, D)\n\ndelta = 1.75\ntrainX[:N//2] += np.array([delta, delta])\ntrainX[N//2:] += np.array([-delta, -delta])\n\ntrainY = np.array([0] * (N//2) + [1] * (N//2))\nplt.scatter(trainX[:,0], trainX[:,1], s=100, c=trainY, alpha=0.5)\nplt.show()","execution_count":27,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"aeec214e9a265556b6b6d5551dedb1879343f674"},"cell_type":"code","source":"original_label = np.array([0] * (N//2) + [1] * (N//2))","execution_count":28,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"16335c02e85b1073873e72a56e52cbebaafa836d"},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nclass LogisticRegressionTF(BaseEstimator):\n    def __init__(self, learning_rate, training_epochs, display_step, annotate=False):\n        self.annotate = annotate\n        self.sess = tf.Session()\n        self.training_epochs = training_epochs\n        self.learning_rate = learning_rate\n        self.display_step = display_step\n        \n        \n    def fit(self, trainX,trainY):\n        N, D = trainX.shape\n        _, c = trainY.shape\n        # 图的输入\n        self.X = tf.placeholder(tf.float64, shape=[None, D])\n        self.Y = tf.placeholder(tf.float64, shape=[None, c])\n        \n        \n        # 参数的定义\n        self.W = tf.Variable(np.random.randn(D,c), name=\"weight\")\n        self.b = tf.Variable(np.random.randn(c), name=\"bias\")\n        \n        # logistic prediction\n        #self.pred = tf.sigmoid(tf.add(tf.matmul(self.X, self.W), self.b))\n        output_logits = tf.add(tf.matmul(self.X, self.W), self.b)\n        self.pred = tf.sigmoid(output_logits)   # turn logits to probability\n        \n        # 交叉熵loss\n        #cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred), reduction_indices=1))\n        cost= tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=output_logits, labels=self.Y))\n        \n        # 优化器\n        optimizer = tf.train.GradientDescentOptimizer(self.learning_rate).minimize(cost)\n        \n        # 初始化所有的参数\n        init = tf.global_variables_initializer()\n        self.sess.run(init)\n        \n        \n        # 可视化初始化的模型边界\n        if self.annotate:\n            assert len(trainX.shape) == 2, \"Only 2d points are allowed!!\"\n\n            plt.scatter(trainX[:,0], trainX[:,1], s=100, c=original_label, alpha=0.5) \n\n            h = .02 \n            x_min, x_max = trainX[:, 0].min() - 1, trainX[:, 0].max() + 1\n            y_min, y_max = trainX[:, 1].min() - 1, trainX[:, 1].max() + 1\n            xx, yy = np.meshgrid(np.arange(x_min, x_max, h),np.arange(y_min, y_max, h))\n\n            Z = self.predict(np.c_[xx.ravel(), yy.ravel()])\n            Z = Z.reshape(xx.shape)\n            plt.contour(xx, yy, Z, cmap=plt.cm.Paired)\n            plt.title(\"This is where model starts to learn!!\")\n            plt.show()\n\n        \n\n        # 训练开始\n        for epoch in range(self.training_epochs):\n            for (x, y) in zip(trainX, trainY):\n                self.sess.run(optimizer, feed_dict={self.X: np.asmatrix(x), self.Y: np.asmatrix(y)})\n\n            #展示训练结果\n            if (epoch+1) % display_step == 0:\n                c = self.sess.run(cost, feed_dict={self.X: trainX, self.Y:trainY})\n                print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(c), \\\n            \"W=\", self.sess.run(self.W), \"b=\", self.sess.run(self.b))\n                \n            #显示拟合的直线\n                if self.annotate:\n                    assert len(trainX.shape) == 2, \"Only 2d points are allowed!!\"\n\n                    plt.scatter(trainX[:,0], trainX[:,1], s=100, c=original_label, alpha=0.5) \n             \n                    h = .02 \n                    x_min, x_max = trainX[:, 0].min() - 1, trainX[:, 0].max() + 1\n                    y_min, y_max = trainX[:, 1].min() - 1, trainX[:, 1].max() + 1\n                    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),np.arange(y_min, y_max, h))\n\n                    Z = self.predict(np.c_[xx.ravel(), yy.ravel()])\n                    Z = Z.reshape(xx.shape)\n                    plt.contour(xx, yy, Z, cmap=plt.cm.Paired)\n                    plt.show()\n\n\n\n        print(\"Optimization Finished!\")\n        training_cost = self.sess.run(cost, feed_dict={self.X: trainX, self.Y: trainY})\n        print(\"Training cost=\", training_cost, \"W=\", self.sess.run(self.W), \"b=\", self.sess.run(self.b), '\\n')\n\n        \n    def predict(self, testX):\n        prediction = self.sess.run(self.pred,feed_dict={self.X: testX})\n        return np.argmax(prediction, axis=1)\n    \n    def score(self, testX, testY):\n        # suppose the testY has been one hot encoded\n        #eg:#0: [1,0]  -> 0, 0\n            #1: [1,0]  -> 1, 0\n            #2: [0,1]  -> 2, 1\n        _ , true_result = np.where(testY == 1)\n        result = self.predict(testX)\n        return accuracy_score(true_result, result)","execution_count":33,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"6a1900bb8783fffab415239b6324ba4edf84430e"},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder","execution_count":30,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"c9a64d19d82c047512a748e30da0a775d401a25e"},"cell_type":"code","source":"le = OneHotEncoder()\nle.fit(trainY.reshape(N,-1))\ntrainY = le.transform(trainY.reshape(N,-1)).toarray()","execution_count":31,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"b5ebe28caf594994b71570e281a3d32ac2463a3e"},"cell_type":"code","source":"logisticTF = LogisticRegressionTF(learning_rate, 1000, display_step, annotate=False)\nlogisticTF.fit(trainX, trainY)","execution_count":35,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"bca377470fc4b057798c8919f73265622265b40c"},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\ncross_val_score(logisticTF, trainX, trainY, cv=5).mean()","execution_count":37,"outputs":[]},{"metadata":{"_uuid":"9a0cef56531effeecabd924543bdb8b84141395e"},"cell_type":"markdown","source":"### 用tensorflow来实现KNN "},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"bb3747d8baceba10402b08cac9f34a5d1cf134e5"},"cell_type":"code","source":"tf.reset_default_graph()","execution_count":73,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"1eeb09e45a4074a3de195254f10e9035523940c4"},"cell_type":"code","source":"#from tensorflow.examples.tutorials.mnist import input_data\n#mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n#trainX, trainY = mnist.train.next_batch(5000) #5000个数据作为近邻集合\n#testX, testY = mnist.test.next_batch(200) #200个数据用于测试","execution_count":84,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"c14f44b0ef5421cf6eb1b37189a2cd09e87517fc"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"bbdefa17ac0e0055d01dfe8acc0725297365851b"},"cell_type":"code","source":"import os\ndata_folder = \"../input/ninechapterdigitsub\"\n#data_folder = \"data\"\ntrainX = np.genfromtxt(os.path.join(data_folder, \"digit_mnist_trainx.csv\"), delimiter=',')\ntrainY = np.genfromtxt(os.path.join(data_folder, \"digit_mnist_trainy.csv\"), delimiter=',')\ntestX = np.genfromtxt(os.path.join(data_folder, \"digit_mnist_testx.csv\"), delimiter=',')\ntestY = np.genfromtxt(os.path.join(data_folder, \"digit_mnist_testy.csv\"), delimiter=',')","execution_count":5,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"4373a1bc274569a9df6fc54df3c5968500bfd3fa"},"cell_type":"markdown","source":"### define your computing graph"},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"8c4f49419a73a712f13f2a22ecfbd32f0fc15fff"},"cell_type":"code","source":"xtr = tf.placeholder(\"float\", [None, 784])\nxte = tf.placeholder(\"float\", [784])","execution_count":80,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"4ba548544bd8ba4d88807f836d3bce36e9e1ee77"},"cell_type":"code","source":"distance = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(xtr, xte)), reduction_indices=1))\n\n# train 0: [1,...1]\n# train 1: [0,...0]\n# test : [1,...1]\n# tf.subtract(xtr, xte):\n#  0: [0,...0]\n#  1: [-1,...-1]\n# tf.square:\n#  0: [0,...0]\n#  1: [1,...1]\n#  tf.reduce_sum(tf.square(tf.subtract(xtr, xte)), reduction_indices=1):\n#  0: [0]\n#  1: [784]\n\n","execution_count":81,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"860a83a6d46e51d6f135d30fa258ea8572a3485e"},"cell_type":"code","source":"# 因为是topk大的值，这里distance取负号\nKVALUE = 1\npred= tf.nn.top_k(-distance, k=KVALUE)","execution_count":85,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"770f1cb9f04269a9800acda73c6ce216217bb224"},"cell_type":"code","source":"from collections import Counter\naccuracy = 0.\n\n# 初始化参数\ninit = tf.global_variables_initializer()\n\n\n# 开始训练\nwith tf.Session() as sess:\n    sess.run(init)\n\n    # 预测测试数据的标签 (passive learner)\n    for i in range(len(testX)):\n        # 最近邻的序号\n        values, knn_index = sess.run(pred, feed_dict={xtr: trainX, xte: testX[i, :]})\n\n        # 拿到k个邻居后做全民公投，得票最多的为预测标签\n        c = Counter(np.argmax(trainY[knn_index], axis=1))\n        result = c.most_common(KVALUE)[0][0]\n        # 计算最近邻的标签和真实标签值\n        print(\"Test\", i, \"Prediction:\", result, \\\n            \"True Class:\", np.argmax(testY[i]))\n        # 正确率\n        if result == np.argmax(testY[i]):\n\n            accuracy += 1./len(testX)\n    print(\"Done!\")\n    print(\"Accuracy:\", accuracy)","execution_count":86,"outputs":[]},{"metadata":{"_uuid":"df46db7723f3ab4e881233d6ba175078d98ab8d4"},"cell_type":"markdown","source":"### 用tensorflow 实现naive bayes"},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"c77618f3d391f0ba80fe5bcbb4710e2146bbe049"},"cell_type":"code","source":"tf.reset_default_graph()","execution_count":38,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"13e6dff3f4d79326fb6e383e9096ad30c4ec711c"},"cell_type":"code","source":"N = 120\nD = 2\ntrainX = np.random.randn(N, D)\n\ndelta = 2\n#trainX[:N//3] += np.array([delta, delta])\n#trainX[N//3:N*2//3] += np.array([-delta, delta])\n#trainX[N*2//3:] += np.array([0, -delta])\n\n\ndelta = 1.75\ntrainX[:N//2] += np.array([delta, delta])\ntrainX[N//2:] += np.array([-delta, -delta])\n\ntrainY = np.array([0] * (N//2) + [1] * (N//2))\nplt.scatter(trainX[:,0], trainX[:,1], s=100, c=trainY, alpha=0.5)\nplt.show()","execution_count":39,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"67a2139d734d47d85cec0b028f3be82c0c1b6d35"},"cell_type":"code","source":"from sklearn.metrics import accuracy_score","execution_count":40,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"9bb7f9358b55cd9d4f58ecf03af3018d2522fd70"},"cell_type":"code","source":"from matplotlib import colors\nfrom sklearn.utils.fixes import logsumexp\n\n\nclass NaiveBayesTF(BaseEstimator):\n    \n    def __init__(self):\n        self.dist = None\n        self.sess = tf.Session()\n\n    def fit(self, trainX, trainY):\n        # Separate training points by class (nb_classes * nb_samples * nb_features)\n        unique_classes = np.unique(trainY)\n        points_by_class = np.array([\n            [x for x, y in zip(trainX, trainY) if y == c]\n            for c in unique_classes])\n        \n        input_x = tf.placeholder(tf.float64, shape=points_by_class.shape)\n        # 估计每个类底下每一种feature的均值和方差\n        # shape: num_classes * nb_features\n        \n        moments = tf.nn.moments(input_x, axes=[1])\n        mean, var = self.sess.run(moments, feed_dict={input_x:points_by_class})\n        #print(mean.shape)\n        #print(var.shape)\n        \n        # 点集实验里为2类，每个数据点有2个特征 \n        # known mean and variance\n        self.dist = tf.distributions.Normal(loc=mean, scale=tf.sqrt(var))\n        \n\n    def predict(self, testX):\n        assert self.dist is not None\n        num_classes, num_features = map(int, self.dist.scale.shape)\n\n        # 条件概率 log P(x|c)\n        # (nb_samples, nb_classes)\n        cond_probs = tf.reduce_sum(\n            self.dist.log_prob(\n                tf.reshape(\n                    tf.tile(testX, [1, num_classes]), [-1, num_classes, num_features])),\n            axis=2)\n        \n        # 第一个点: 2.0,3.5\n        # 第二个点: 0.5,1.4\n        # tf.tile (num_classes = 2):\n        # 第一个点: 2.0,3.5,2.0,3.5\n        # 第二个点: 0.5,1.4,0.5,1.4\n        # tf.reshape:\n        # 第一个点: 2.0,3.5 \n        #         2.0,3.5\n        # 第二个点：0.5,1.4\n        #         0.5,1.4\n\n        # P(C) 均匀分布\n        priors = np.log(np.array([1. / num_classes] * num_classes))\n\n        # 后验概率取log, log P(C) + log P(x|C)\n        posterior = tf.add(priors, cond_probs)\n        \n        # 取概率最大的那一个\n        result = self.sess.run(tf.argmax(posterior, axis=1))\n\n        return result\n    \n    \n    def score(self, testX, testY):\n        result = self.predict(testX)\n        return accuracy_score(testY, result)\n","execution_count":43,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"69c8fae1921c786d6d68866a6d118e31fecacfa5"},"cell_type":"code","source":"tf_nb = NaiveBayesTF()\ntf_nb.fit(trainX, trainY)","execution_count":44,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"3a92d8f5470066ca99e6d5a12489d73589ea13ec"},"cell_type":"code","source":"x_min, x_max = trainX[:, 0].min() - .5, trainX[:, 0].max() + .5\ny_min, y_max = trainX[:, 1].min() - .5, trainX[:, 1].max() + .5\nxx, yy = np.meshgrid(np.linspace(x_min, x_max, 30),\n                     np.linspace(y_min, y_max, 30))","execution_count":48,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"363a7e31ef97c9eec7cb01efec7a660e8d9472a4"},"cell_type":"code","source":"Z = tf_nb.predict(np.c_[xx.ravel(), yy.ravel()])","execution_count":49,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"1f70b671eb32f72c4a8323cffcc4d7a870042707"},"cell_type":"code","source":"Z = Z.reshape(xx.shape)","execution_count":50,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"27eef12fd8d94d589c74101f1fefe7e9665e875a"},"cell_type":"code","source":"plt.scatter(trainX[:,0], trainX[:,1], s=100, c=trainY, alpha=0.5)\nplt.contour(xx, yy, Z, cmap=plt.cm.Paired)\nplt.show()","execution_count":52,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"c974982897bd5aa898c1057cc31f9d9a12473782"},"cell_type":"code","source":"tf_nb.score(trainX, trainY)","execution_count":45,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"d6742dea4b760221bb21c1fe83b4fefc7c26a7c5"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"5d284b0df80721cf8a098f0092d51cdfa48c4cbc"},"cell_type":"markdown","source":"### Tensorflow实现random forest"},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"c4325553138f896c9f0aac9422872230666e3c5c"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"fb6a5f6d9122cb82db8b4c9084c2f613ef4e0d5e"},"cell_type":"code","source":"from tensorflow.contrib.tensor_forest.python import tensor_forest\nfrom tensorflow.python.ops import resources\nimport pandas as pd\nimport numpy as np\nimport os","execution_count":7,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"970e14bd534de0686d19dab98e29a10405c83d6f"},"cell_type":"code","source":"data_folder = \"../input/fashionmnist\"\n#data_folder = \"./data\"\ntrain_data = pd.read_csv(os.path.join(data_folder, \"fashion-mnist_train.csv\"))\ntest_data = pd.read_csv(os.path.join(data_folder, \"fashion-mnist_test.csv\"))","execution_count":9,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"11677043b47c85766a3702ab42ec4c89f6c4dd36"},"cell_type":"code","source":"trainX = np.array(train_data.iloc[:, 1:])\ntrainY = np.array(train_data.iloc[:, 0])\ntestX = np.array(test_data.iloc[:, 1:])\ntestY = np.array(test_data.iloc[:, 0])","execution_count":48,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"ddfaa0e7c50325de06229a640ca4f838ebaa7b55"},"cell_type":"code","source":"IMAGE_CLASSES = {\n    0: 'T-shirt/top',\n    1: 'Trouser',\n    2: 'Pullover',\n    3: 'Dress',\n    4: 'Coat',\n    5: 'Sandal',\n    6: 'Shirt',\n    7: 'Sneaker',\n    8: 'Bag',\n    9: 'Ankle boot'\n}","execution_count":49,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"351904ee51ca09fcde088b691250e839b1933c7c"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimg_size = 28\nfor img, label in zip(trainX[:10], trainY[:10]):\n    plt.imshow(img.reshape(img_size,img_size),cmap='gray')\n    plt.title(IMAGE_CLASSES[label])\n    plt.show()","execution_count":51,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"af39b7b109c8aea38e01f3366d03a7740cb1b396"},"cell_type":"code","source":"# 参数设定\n#The 10 categories\n#784 Each image is 28x28 pixels\nnum_steps = 100# Total steps to train\nbatch_size = 1024 # The number of samples per batch\nnum_trees = 10\nmax_nodes = 1000","execution_count":52,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"52683c22745ade5fbf0b9dc3f8e58eba41da2150"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"e781afd873e74277d5c7d08322a84ec59a3c8b92"},"cell_type":"code","source":"tf.reset_default_graph()\nclass RandomForestTF(BaseEstimator):\n    \n    def __init__(self, num_trees):\n        self.num_trees = num_trees\n        \n    def fit(self, X, Y, num_steps, batch_size,max_nodes):\n        num_classes = 10   #len(IMAGE_CLASSES)\n        num_data = X.shape[0]\n        num_features = X.shape[1]\n        \n        self.X = tf.placeholder(tf.float32, shape=[None, num_features]) \n        self.Y = tf.placeholder(tf.int32, shape=[None]) \n        \n        \n        # 随机森林的参数\n        hparams = tensor_forest.ForestHParams(num_classes=num_classes,\n                                      num_features=num_features,\n                                      num_trees=self.num_trees,\n                                      max_nodes=max_nodes).fill()\n        \n        \n        # 随机森林的计算图\n        forest_graph = tensor_forest.RandomForestGraphs(hparams)\n        \n        train_operation = forest_graph.training_graph(self.X, self.Y)\n        loss_operation = forest_graph.training_loss(self.X, self.Y)\n        \n        # inference_graph will return probabilities, decision path and variance\n        self.infer_op, _, _ = forest_graph.inference_graph(self.X)\n        correct_prediction = tf.equal(tf.argmax(self.infer_op, 1), tf.cast(self.Y, tf.int64))\n        self.accuracy_op = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n        \n        \n        # 将初始化的操作和树的参数初始化 作为一个整体操作\n        init_vars = tf.group(tf.global_variables_initializer(),\n                   resources.initialize_resources(resources.shared_resources()))\n        #init_vars = tf.global_variables_initializer()\n        \n        self.sess = tf.Session()\n        self.sess.run(init_vars)\n\n        # 开始训练\n        cnt = 0\n        for i in range(1, num_steps + 1):\n            # Prepare Data\n            # 每次学习一个batch的MNIST data\n            #batch_x, batch_y = training_set.next_batch(batch_size)\n            start, end = ((i-1) * batch_size) % num_data, (i * batch_size) % num_data\n            \n            batch_x, batch_y = X[start:end], Y[start:end]\n            _, l = self.sess.run([train_operation, loss_operation], feed_dict={self.X: batch_x, self.Y: batch_y})\n            if i % 50 == 0 or i == 1:\n                acc = self.sess.run(self.accuracy_op, feed_dict={self.X: batch_x, self.Y: batch_y})\n                print('Step %i, Loss: %f, Acc: %f' % (i, l, acc))\n                \n    def predict(self, testX):\n        results = self.sess.run(self.infer_op, feed_dict={self.X:testX})\n        return np.argmax(results, axis=1)\n    \n    def score(self, testX, testY):\n        accuracy = self.sess.run(self.accuracy_op, feed_dict={self.X: testX, self.Y: testY})\n        return accuracy","execution_count":56,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"ce9440c4116c2586e3ae84f9160cae2401793d1a"},"cell_type":"code","source":"rftf = RandomForestTF(num_trees)","execution_count":57,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"3741234913e705ddb4780c7c7c1fe989de5b50f1"},"cell_type":"code","source":"rftf.fit(trainX, trainY, num_steps, batch_size, max_nodes)","execution_count":58,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"04be03cd880f34cb1e51fc0e029e2429596890d0"},"cell_type":"code","source":"rftf.score(testX, testY)","execution_count":59,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"6cf0eb50e27db15dcd256619d012e0fd55866e55"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}