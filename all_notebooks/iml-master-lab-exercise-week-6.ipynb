{"cells":[{"metadata":{},"cell_type":"markdown","source":"#  ** Nonlinear Regression & Tree-based Methods**\nLab Exercises - Week 6\n\n----------"},{"metadata":{},"cell_type":"markdown","source":"## **Notebook Contents:**\n1. Regression Splines.\n2. Generalized Additive Models.  \n    a. Logisitc GAM <br>\n    b. Linear GAM <br>\n3. Classification Trees <br>\n    a. Decision Tree Classifier <br>\n    b. Random Forest Classifier <br>\n4. Regression Trees <br>\n    a. Decision Tree Regressor <br>\n    b. Random Forest Regressor <br>"},{"metadata":{},"cell_type":"markdown","source":"### **Python Libraries:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pygam","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install graphviz","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pydotplus","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport statsmodels.api as sm\nimport statsmodels.formula.api as sam\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom pygam import LogisticGAM,LinearGAM, s, f\nfrom pygam.datasets import default, wage\nfrom sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\nfrom sklearn import datasets\nfrom sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import metrics\nfrom sklearn.tree import export_graphviz\nfrom sklearn.externals.six import StringIO  \nfrom IPython.display import Image  \nimport pydotplus   \nfrom patsy import dmatrix\nimport statsmodels.formula.api as smf\nfrom sklearn import linear_model as lm\nfrom matplotlib import pyplot\n\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **1) Regression Splines **"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/Wage.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfInput = df[['age']]\ndfOutput = df['wage']\n\ntrain_x, test_x, train_y, test_y = train_test_split(dfInput, dfOutput, test_size=0.33, random_state = 1)\n\nplt.scatter(train_x, train_y, facecolor='None', edgecolor='k', alpha=0.3)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Linear Regression\nmodel = LinearRegression()\nmodel.fit(train_x,train_y)\nprint(model.coef_)\nprint(model.intercept_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plot for Linear Regression\npred = model.predict(test_x)\n\nplt.subplots(figsize=(12,5))\nplt.scatter(test_x, test_y, facecolor='None', edgecolor='k', alpha=0.3)\nplt.plot(test_x, pred,  color = 'red')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#RMSE with Linear Regression\nprint(sqrt(mean_squared_error(test_y, pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Polynomial Regression\ndf = pd.read_csv(\"../input/Wage.csv\")\ndfInput = df[['age']]\ndfOutput = df['wage']\n\ntrain_x, test_x, train_y, test_y = train_test_split(dfInput, dfOutput, test_size=0.33, random_state = 1)\n\npoly = PolynomialFeatures(degree = 10) \ninputDF_poly = poly.fit_transform(train_x) \n\npoly.fit(inputDF_poly, train_y) \nlin2 = LinearRegression() \nlin2.fit(inputDF_poly, train_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#RMSE for polynomial regression\nprint(sqrt(mean_squared_error(test_y, lin2.predict(poly.fit_transform(test_x)))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Regression Splines\ndf = pd.read_csv(\"../input/Wage.csv\")\ndfInput = df['age']\ndfOutput = df['wage']\n\ntrain_x, test_x, train_y, test_y = train_test_split(dfInput, dfOutput, test_size=0.33, random_state = 1)\n\ndf_cut, bins = pd.cut(train_x, 4, retbins=True, right=True)\ndf_cut.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Bins value\nbins","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_steps = pd.concat([train_x, df_cut, train_y], keys=['age','age_cuts','wage'], axis=1)\ndf_steps.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Transforming categorical variables\ndf_steps_dummies = pd.get_dummies(df_cut)\ndf_steps_dummies.columns = ['17.938-33.5','33.5-49','49-64.5','64.5-80'] \ndf_steps_dummies.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking for normal distribution\npyplot.hist(df_steps.wage)\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fitting GLM\nfit3 = sm.GLM(df_steps.wage, df_steps_dummies).fit()\n\n#Binning\nbin_mapping = np.digitize(test_x, bins) \nprint(bin_mapping)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#RMSE with Regression Splines\nX_test = pd.get_dummies(bin_mapping).drop([5], axis=1)\npred2 = fit3.predict(X_test)\nprint(sqrt(mean_squared_error(test_y, pred2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotting with Regression Splines\nxp = np.linspace(test_x.min(),test_x.max()-1,70) \nbin_mapping = np.digitize(xp, bins) \nX_valid_2 = pd.get_dummies(bin_mapping) \npred2 = fit3.predict(X_valid_2)\n\nplt.subplots(figsize=(12,5))\nplt.scatter(train_x, train_y,facecolor='None', edgecolor='k', alpha=0.3)   \nplt.plot(xp, pred2, color = 'red')   \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Cubic spline with 3 knots \ntransformed_x = dmatrix(\"bs(train, knots=(25,60), degree=3)\", {\"train\": train_x},return_type='dataframe')\n\nfit1 = sm.GLM(train_y, transformed_x).fit()\n\npred1 = fit1.predict(dmatrix(\"bs(valid, knots=(25,60),degree=3)\", {\"valid\": test_x}, return_type='dataframe'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(sqrt(mean_squared_error(test_y, pred1)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xp = np.linspace(test_x.min(),test_x.max(),70)\npred1 = fit1.predict(dmatrix(\"bs(xp, knots=(25,60), include_intercept=False)\", {\"xp\": xp}, return_type='dataframe'))\n\nplt.subplots(1,1, figsize=(12,5))\nplt.scatter(dfInput, dfOutput, facecolor='None', edgecolor='k', alpha=0.1)\nplt.plot(xp, pred1)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **2) Generalized Additive Models **"},{"metadata":{},"cell_type":"markdown","source":"#### **a) Logistic GAM **"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Logisitic GAM\nX, y = default(return_X_y=True)\ndfInput = pd.DataFrame({'Student':X[:,0],'Balance':X[:,1],'Income':X[:,2]})\ndfInput.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfOutput = pd.DataFrame({'Default': y})\ndfOutput.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"![](https://i.ibb.co/DrYkLrH/Capture.png)"},{"metadata":{"trusted":true},"cell_type":"code","source":"gam = LogisticGAM(f(0) + s(1) + s(2)).gridsearch(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(1, 3)\ntitles = ['student', 'balance', 'income']\n\nfor i, ax in enumerate(axs):\n    XX = gam.generate_X_grid(term=i)\n    pdep, confi = gam.partial_dependence(term=i, width=.95)\n\n    ax.plot(XX[:, i], pdep)\n    ax.plot(XX[:, i], confi, c='r', ls='--')\n    ax.set_title(titles[i]);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gam.accuracy(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gam.predict(X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### **b) Linear GAM **"},{"metadata":{"trusted":true},"cell_type":"code","source":"X, y = wage(return_X_y=True)\ndfInput_Linear = pd.DataFrame({'Year':X[:,0],'Age':X[:,1],'Education':X[:,2]})\ndfInput_Linear.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfOutput_Linear = pd.DataFrame({'Wage': y})\ndfOutput_Linear.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gam = LinearGAM(s(0) + s(1) + f(2))\ngam.gridsearch(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure();\nfig, axs = plt.subplots(1,3);\n\ntitles = ['year', 'age', 'education']\nfor i, ax in enumerate(axs):\n    XX = gam.generate_X_grid(term=i)\n    ax.plot(XX[:, i], gam.partial_dependence(term=i, X=XX))\n    ax.plot(XX[:, i], gam.partial_dependence(term=i, X=XX, width=.95)[1], c='r', ls='--')\n    if i == 0:\n        ax.set_ylim(-30,30)\n    ax.set_title(titles[i]);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gam.predict(X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **3) Decision Tree Classifier**"},{"metadata":{"trusted":true},"cell_type":"code","source":"iris_DC = datasets.load_iris()\nirisDF_DC = pd.DataFrame({\n    'sepal length':iris_DC.data[:,0],\n    'sepal width':iris_DC.data[:,1],\n    'petal length':iris_DC.data[:,2],\n    'petal width':iris_DC.data[:,3],\n    'species':iris_DC.target\n})\nirisDF_DC.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inputDF_DC = irisDF_DC[['sepal length', 'sepal width', 'petal length', 'petal width']]  \noutputDF_DC = irisDF_DC['species']\n\nX_train_DC, X_test_DC, y_train_DC, y_test_DC = train_test_split(inputDF_DC, outputDF_DC, test_size=0.30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clfDC = DecisionTreeClassifier(random_state = 0)\n\nclfDC = clfDC.fit(X_train_DC,y_train_DC)\n\ny_pred_DC = clfDC.predict(X_test_DC)\n\nprint(\"Accuracy:\",metrics.accuracy_score(y_test_DC, y_pred_DC))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_cols = ['sepal length', 'sepal width', 'petal length', 'petal width']\ndot_data = StringIO()\nexport_graphviz(clfDC, out_file=dot_data,  \n                filled=True, rounded=True,\n                special_characters=True,feature_names = feature_cols,class_names=['0','1','2'])\ngraph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \ngraph.write_png('diabetes.png')\nImage(graph.create_png())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **4) Random Forest Classifier **"},{"metadata":{"trusted":true},"cell_type":"code","source":"iris_RF = datasets.load_iris()\nirisDF_RF = pd.DataFrame({\n    'sepal length':iris_RF.data[:,0],\n    'sepal width':iris_RF.data[:,1],\n    'petal length':iris_RF.data[:,2],\n    'petal width':iris_RF.data[:,3],\n    'species':iris_RF.target\n})\ninputDF_RF = irisDF_RF[['sepal length', 'sepal width', 'petal length', 'petal width']]  \noutputDF_RF = irisDF_RF['species']\n\nX_train_RF, X_test_RF, y_train_RF, y_test_RF = train_test_split(inputDF_RF, outputDF_RF, test_size=0.30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clfRF = RandomForestClassifier(n_estimators=50,random_state = 0)\n\nclfRF.fit(X_train_RF,y_train_RF)\n\ny_pred_RF = clfRF.predict(X_test_RF)\n\nprint(\"Accuracy:\",metrics.accuracy_score(y_test_RF, y_pred_RF))\nprint(sqrt(mean_squared_error(y_test_RF, y_pred_RF)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_imp = pd.Series(clfRF.feature_importances_,index=iris_RF.feature_names).sort_values(ascending=False)\nfeature_imp","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **5) Decision Tree Regressor **"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_DCR = pd.read_csv(\"../input/Wage.csv\")\ndf_DCR.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfInput = df_DCR[[\"year\",\"age\",\"sex\",\"education\"]]\ndfInput = pd.get_dummies(dfInput)\ndfOutput = df_DCR[\"wage\"]\n\nX_train, X_test, y_train, y_test = train_test_split(dfInput, dfOutput, test_size=0.30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfInput.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"regressor = DecisionTreeRegressor(random_state = 0, max_depth = 4)  \nregressor.fit(X_train, y_train) \ny_pred = regressor.predict(X_test)\n\nprint(sqrt(mean_squared_error(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dot_data = StringIO()\nexport_graphviz(regressor, out_file =dot_data, \n               feature_names = dfInput.columns.values)\ngraph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \ngraph.write_png('wage.png')\nImage(graph.create_png())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **6) Random Forest Regressor **"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_DCR = pd.read_csv(\"../input/Wage.csv\")\ndfInput = df_DCR[[\"year\",\"age\",\"sex\",\"education\"]]\ndfInput = pd.get_dummies(dfInput)\ndfOutput = df_DCR[\"wage\"]\n\nX_train, X_test, y_train, y_test = train_test_split(dfInput, dfOutput, test_size=0.30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"regr = RandomForestRegressor(random_state=0,\n                            n_estimators=100, max_depth = 4)\nregr.fit(X_train, y_train)\ny_pred = regr.predict(X_test)\n\nprint(sqrt(mean_squared_error(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Voil√†! This is the end of the lab session for week 6. ** <br>\nDo not forget to commit your notebook and set the access to private. Share the notebook with Prof. Karim (Kaggle id: karimshaikh) and Manish Varma (Kaggle id: manishvarma)."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}