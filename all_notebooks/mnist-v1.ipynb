{"cells":[{"metadata":{},"cell_type":"markdown","source":"> This is a classification problem, the aim is to create a model that is able to identify which digit from 0 to 9, based on the images of previous digits. \n\n>https://medium.com/@Mandysidana/machine-learning-types-of-classification-9497bd4f2e14\nHere we have the types of classification algorithms in Machine Learning:\n* Linear Classifiers: Logistic Regression, Naive Bayes Classifier\n* Nearest Neighbor\n* - Support Vector Machines\n* - Decision Trees\n* Boosted Trees\n* - Random Forest\n* - Neural Networks\n\n>Competition https://www.kaggle.com/c/digit-recognizer/overview","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"scrolled":true},"cell_type":"code","source":"file = open(\"/kaggle/input/mnist-in-csv/mnist_train.csv\")\ndata_train = pd.read_csv(file)\n\ny_train = np.array(data_train.iloc[:, 0])\nx_train = np.array(data_train.iloc[:, 1:])\n\nfile = open(\"/kaggle/input/mnist-in-csv/mnist_test.csv\")\ndata_test = pd.read_csv(file)\ny_test = np.array(data_test.iloc[:, 0])\nx_test = np.array(data_test.iloc[:, 1:])\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"SHOW IMAGES","execution_count":null},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"\nsize_img = 28\nthreshold_color = 100 / 255\n# show n_images numbers\ndef show_img(x):\n    plt.figure(figsize=(8,7))\n    if x.shape[0] > 100:\n        print(x.shape)\n        n_imgs = 16\n        n_samples = x.shape[0]\n        x = x.reshape(n_samples, size_img, size_img)\n        for i in range(n_imgs):\n            plt.subplot(4, 4, i+1) #devide figure into 4x4 and choose i+1 to draw\n            plt.imshow(x[i])\n        plt.show()\n    else:\n        plt.imshow(x)\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"show_img(x_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"#plot any image (keep in min 1st row n=0)\nX=x_train.reshape(x_train.shape[0],28,28)\nn=0\nprint(y_train[n])\nplt.imshow(X[n])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Exploratory Data Analysis","execution_count":null},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"data= y_train\ncounts, bins = np.histogram(data)\nplt.hist(bins[:-1], bins, weights=counts)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"data_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"data= x_train\ncounts, bins = np.histogram(data)\nprint(bins)\nplt.hist(bins[:-1], bins, weights=counts)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# PRE - PROCESSAMENTO\n>transformar os valores entre 0 e 1 \n","execution_count":null},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"x_train = np.array(data_train.iloc[:, 1:])\nx_train01=x_train\nn=200\nx_train01[x_train01<n] = 0\nx_train01[x_train01>=n] = 1\n#print(x_train01[0])\nshow_img(x_train01)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"#plot any image (keep in min 1st row n=0)\nX=x_train.reshape(x_train.shape[0],28,28)\nn=0\nprint(y_train[n])\nplt.imshow(X[n])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"transformar dataset de test ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test01=x_test\nn=200\nx_test01[x_test01<n] = 0\nx_test01[x_test01>=n] = 1\n\nX=x_test01.reshape(x_test.shape[0],28,28)\nn=0\nprint(y_test[n])\nplt.imshow(X[n])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dimension selection\n> originally there are 784 features (#columns) its therefore crutial to reduce the number of dimensions to use on the model\n* PCA (unsupervised)\n* LDA (supervised)\n\n","execution_count":null},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"print(x_train01[1:5,:])\ndata_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## PCA","execution_count":null},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\nX=x_train01\npca = PCA(n_components=10)\nX_pca = pca.fit_transform(X)\nprint(pca)\nprint('eigenvectors \\n', pca.components_)\nprint('singular values ', pca.singular_values_)\nprint('normalized cumulative sum of eigenvalues \\n', pca.explained_variance_ratio_)\n#print(' mean vector ', pca.mean_)\n\n#print('Projections of class 0 \\n ', X_pca[y_train==0])\n#print('Projections of class 1 \\n ', X_pca[y_train==1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"eig_vals=  pca.singular_values_\neig_vecs= pca.components_\n# Make a list of (eigenvalue, eigenvector) tuples\neig_pairs = [(np.abs(eig_vals[i]), eig_vecs[:,i]) for i in range(len(eig_vals))]\n\n# Sort the (eigenvalue, eigenvector) tuples from high to low\neig_pairs.sort(key=lambda x: x[0], reverse=True)\n\n# Visually confirm that the list is correctly sorted by decreasing eigenvalues\nprint('Eigenvalues in descending order:')\nfor i in eig_pairs:\n    print(i[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"tot = sum(eig_vals)\nvar_exp = [(i / tot)*100 for i in sorted(eig_vals, reverse=True)]\ncum_var_exp = np.cumsum(var_exp)\nprint(cum_var_exp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"#matplotlib.pyplot.bar(x, height, width=0.8, bottom=None, *, align='center', data=None, **kwargs)\nwith plt.style.context('seaborn-whitegrid'):\n    plt.figure(figsize=(6, 4))\n\n    plt.bar(range(10), var_exp, alpha=0.5, align='center',\n            label='individual explained variance')\n    plt.step(range(10), cum_var_exp, where='mid',\n             label='cumulative explained variance')\n    plt.ylabel('Explained variance ratio')\n    plt.xlabel('Principal components')\n    plt.legend(loc='best')\n    plt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"print(X_pca)\nX_pca.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"PCA test \n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X=x_train01\npca = PCA(n_components=10)\nX_pca = pca.fit_transform(X)\nxtest_pca=pca.fit_transform(x_test01)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## LDA","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n\nX=x_train01\ny=y_train\nlda= LinearDiscriminantAnalysis(n_components=9)\nx_lda=lda.fit(X,y).transform(X)\n\nx_lda","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"LDA test","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"xtest_lda=lda.fit(x_train01,y).transform(x_test01)\nxtest_lda.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## build extra features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train= pd.DataFrame(data=x_train)\ns=X_train.sum(axis=1)\ns=s/784\ns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(y_train,s, 'o')\nplt.ylabel('ratio of ink used')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Models\n* Support Vector Machines (SVM)\n* Decision Tree \n* Random Forest","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Interaction 1: PCA and SVM","execution_count":null},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"X=X_pca\nfrom sklearn import svm\nclf=svm.SVC()\nclf.fit(X, y_train) \nconfidence = clf.score(X, y_train) \nprint(\"Precisão SVM = {}\".format(confidence)) \ny1=clf.predict(X)\ny1_test=clf.predict(xtest_pca)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nX=X_pca\nclassifier=clf\ny_tes=y_train\ny_pred=clf.predict(X)\ncnf_matrix = confusion_matrix(y_tes, y_pred)\ncnf_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"import seaborn as sns \nplt.title(\"Confusion Matrix\")\nsns.heatmap(cnf_matrix,cbar=False,annot=True,cmap=\"Blues\",fmt=\"d\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we can observe that the:\nthe model struggles with distingguish 9 and 4 and 3 and 8 the most\n\n\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_tes=y_test\nX=X_pca\ny_pred=y1_test\n\ncnf_matrix = confusion_matrix(y_tes, y_pred)\ncnf_matrix\n\nfrom sklearn.metrics import precision_score\nconfidence=precision_score(y_tes, y_pred,average='micro')\nprint(\"Precisão pca_svm = {}\".format(confidence)) \n\nimport seaborn as sns \nplt.title(\"Confusion Matrix\")\nsns.heatmap(cnf_matrix,cbar=False,annot=True,cmap=\"Blues\",fmt=\"d\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Interaction 2: LDA and SVM","execution_count":null},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"X=x_lda\nfrom sklearn import svm\nclf=svm.SVC()\nclf.fit(X, y_train) \nconfidence = clf.score(X, y_train) \nprint(\"Precisão SVM_lda = {}\".format(confidence)) \ny2=clf.predict(X)\ny2_test=clf.predict(xtest_lda)\n\nfrom sklearn.metrics import confusion_matrix\nclassifier=clf\ny_tes=y_train\ny_pred=y2\ncnf_matrix = confusion_matrix(y_tes, y_pred)\ncnf_matrix\n\nimport seaborn as sns \nplt.title(\"Confusion Matrix\")\nsns.heatmap(cnf_matrix,cbar=False,annot=True,cmap=\"Blues\",fmt=\"d\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.metrics import confusion_matrix\nclassifier=clf\ny_tes=y_test\ny_pred=y2_test\ncnf_matrix = confusion_matrix(y_tes, y_pred)\ncnf_matrix\n\n\nfrom sklearn.metrics import precision_score\nconfidence=precision_score(y_tes, y_pred,average='micro')\nprint(\"Precisão SVM_lda = {}\".format(confidence)) \n\n\nimport seaborn as sns \nplt.title(\"Confusion Matrix\")\nsns.heatmap(cnf_matrix,cbar=False,annot=True,cmap=\"Blues\",fmt=\"d\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Interaction 3: Lda and Decision Trees","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X=x_lda\nfrom sklearn import tree\nclf= tree.DecisionTreeClassifier()\nclf.fit(X, y_train) \nconfidence = clf.score(X, y_train) \nprint(\"Precisão TREE_lda = {}\".format(confidence)) \ny3=clf.predict(X)\ny3_test=clf.predict(xtest_lda)\nX.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"com precisao de 1 - fazer a matrix de confusao com a info dos dataset de teste\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ny_tes=y_test\ny_pred= y3_test\n\ncnf_matrix = confusion_matrix(y_tes, y_pred)\ncnf_matrix\n\nfrom sklearn.metrics import precision_score\nconfidence=precision_score(y_tes, y_pred,average='micro')\nprint(\"Precisão SVM_lda = {}\".format(confidence)) \n\n\nimport seaborn as sns \nplt.title(\"Confusion Matrix\")\nsns.heatmap(cnf_matrix,cbar=False,annot=True,cmap=\"Blues\",fmt=\"d\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Interaction 4: PCA and Decision Trees","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X=X_pca\nfrom sklearn import tree\nclf= tree.DecisionTreeClassifier()\nclf.fit(X, y_train) \nconfidence = clf.score(X, y_train) \nprint(\"Precisão TREE_pca = {}\".format(confidence)) \ny4=clf.predict(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nclassifier=clf.fit(X_pca, y_train) \ny_tes= y_test\nX=xtest_pca\ny_pred=clf.predict(X)\ny4_test=y_pred\n\ncnf_matrix = confusion_matrix(y_tes, y_pred)\ncnf_matrix\n\nconfidence = clf.score(xtest_pca, y_tes) \nprint(\"Precisão TREE_pca = {}\".format(confidence)) \n\nimport seaborn as sns \nplt.title(\"Confusion Matrix\")\nsns.heatmap(cnf_matrix,cbar=False,annot=True,cmap=\"Blues\",fmt=\"d\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Interaction 5: PCA and random forest","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X=X_pca\nfrom sklearn.ensemble import RandomForestClassifier\nclf= RandomForestClassifier(n_estimators=100)\nclf.fit(X, y_train) \nconfidence = clf.score(X, y_train) \nprint(\"Precisão forest_pca = {}\".format(confidence)) \ny5=clf.predict(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nclassifier=clf.fit(X_pca, y_train) \ny_tes= y_test\nX=xtest_pca\ny_pred=clf.predict(X)\ny5_test=y_pred\n\ncnf_matrix = confusion_matrix(y_tes, y_pred)\ncnf_matrix\n\nconfidence = clf.score(xtest_pca, y_tes) \nprint(\"Precisão forest_pca = {}\".format(confidence)) \n\nimport seaborn as sns \nplt.title(\"Confusion Matrix\")\nsns.heatmap(cnf_matrix,cbar=False,annot=True,cmap=\"Blues\",fmt=\"d\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Interaction 6: LDA and Random Forest","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X=x_lda\nfrom sklearn.ensemble import RandomForestClassifier\nclf= RandomForestClassifier(n_estimators=100)\nclf.fit(X, y_train) \nconfidence = clf.score(X, y_train) \nprint(\"Precisão forest_lda = {}\".format(confidence)) \ny6=clf.predict(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nclassifier=clf.fit(x_lda, y_train) \ny_tes= y_test\nX=xtest_lda\ny_pred=clf.predict(X)\ny6_test=y_pred\n\ncnf_matrix = confusion_matrix(y_tes, y_pred)\ncnf_matrix\n\nconfidence = clf.score(xtest_lda, y_tes) \nprint(\"Precisão forest_lda = {}\".format(confidence)) \n\nimport seaborn as sns \nplt.title(\"Confusion Matrix\")\nsns.heatmap(cnf_matrix,cbar=False,annot=True,cmap=\"Blues\",fmt=\"d\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## evaluate the models\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_results = pd.DataFrame(data = {'ImageId':y_train,'I1':y1,'I2':y2,'I3':y3,'I4':y4,'I5':y5,'I6':y6})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train= pd.DataFrame(data = {'I1':y1,'I2':y2,'I3':y3,'I4':y4,'I5':y5,'I6':y6})\nmode= train.mode(axis='columns', numeric_only=True)\nmode","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"notsure=mode.dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot any image (keep in min 1st row n=0)\nX=x_train.reshape(x_train.shape[0],28,28)\nn=8468\nprint(y_train[n])\nplt.imshow(X[n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot any image (keep in min 1st row n=0)\nX=x_train.reshape(x_train.shape[0],28,28)\nn=19502\nprint(y_train[n])\nprint(train.loc[[19502]])\nplt.imshow(X[n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"na_free = mode.dropna()\nonly_na = mode[~mode.index.isin(na_free.index)]\nonly_na.shape\ny_tes = y_train[~mode.index.isin(na_free.index)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ny_pred=mode\n\ncnf_matrix = confusion_matrix(y_train, y_pred)\ncnf_matrix\n\nfrom sklearn.metrics import precision_score\nconfidence=precision_score(y_train, y_pred,average='micro')\nprint(\"Precisão combo = {}\".format(confidence)) \n\n\nimport seaborn as sns \nplt.title(\"Confusion Matrix\")\nsns.heatmap(cnf_matrix,cbar=False,annot=True,cmap=\"Blues\",fmt=\"d\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Testing complex model\n\n- get all the 6 results\n- calculate mode\n- remove unsure values (without unique mode)\n- confusion matrix\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test= pd.DataFrame(data = {'I1':y1_test,'I2':y2_test,'I3':y3_test,'I4':y4_test,'I5':y5_test,'I6':y6_test})\ntest_mode= test.mode(axis='columns', numeric_only=True)\ntest_mode","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"na_free = test_mode.dropna()\nonly_na = test_mode[~test_mode.index.isin(na_free.index)]\ny_tes = y_test[~test_mode.index.isin(na_free.index)]\nna_free.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ny_pred=only_na[0]\n\ncnf_matrix = confusion_matrix(y_tes, y_pred)\ncnf_matrix\n\nfrom sklearn.metrics import precision_score\nconfidence=precision_score(y_tes, y_pred,average='micro')\nprint(\"Precisão combo = {}\".format(confidence)) \n\n\nimport seaborn as sns \nplt.title(\"Confusion Matrix\")\nsns.heatmap(cnf_matrix,cbar=False,annot=True,cmap=\"Blues\",fmt=\"d\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_mode.dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot any image (keep in min 1st row n=0)\nX=x_test.reshape(x_test.shape[0],28,28)\nn=6569\nprint(y_test[n])\nplt.imshow(X[n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Rede neuronal\n\n* https://www.digitalocean.com/community/tutorials/como-construir-uma-rede-neural-para-reconhecer-digitos-manuscritos-com-o-tensorflow-pt\n* https://itnext.io/classify-hand-written-digits-using-python-and-convolutional-neural-networks-26ccfc06b95c\n- https://www.kaggle.com/yukikitayama/neural-network-classification-to-digit-images\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#import the libraries\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, Flatten\nfrom keras.datasets import mnist\nfrom keras.utils import to_categorical\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nimport numpy as np\nimport tensorflow as tf\nnp.random.seed(1337)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#One-Hot Encoding\ny_train_one_hot = to_categorical(y_train)\ny_test_one_hot = to_categorical(y_test)\n\n#Print the new label\nprint(y_train_one_hot[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# build\nmodel = tf.keras.Sequential()\nmodel.add(tf.keras.layers.Dense(128, activation = tf.nn.relu, input_shape = (28*28,)))\nmodel.add(tf.keras.layers.Dense(10, activation = tf.nn.softmax))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# compile\nmodel.compile(optimizer = 'adam',\n              loss = 'sparse_categorical_crossentropy',\n              metrics = ['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCH = 10\n\nmodel.fit(x_train01, y_train, epochs = EPOCH, verbose = 1, validation_split = 0.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_train = model.predict(x_train01)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_train[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y7=np.argmax(pred_train, axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmax(pred_train[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# true label\ny_train[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\ncnf_matrix = confusion_matrix(y_train, y7)\ncnf_matrix\n\nfrom sklearn.metrics import precision_score\nconfidence=precision_score(y_train, y7,average='micro')\nprint(\"Precisão NN = {}\".format(confidence)) \n\nimport seaborn as sns \nplt.title(\"Confusion Matrix\")\nsns.heatmap(cnf_matrix,cbar=False,annot=True,cmap=\"Blues\",fmt=\"d\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_test = model.predict(x_test01)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_test[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmax(pred_test[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_id = np.arange(1, x_test.shape[0]+1,1)\ntest_id","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = np.argmax(pred_test, axis = 1)\ny7_test=predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\ncnf_matrix = confusion_matrix(y_test, predictions)\ncnf_matrix\n\nfrom sklearn.metrics import precision_score\nconfidence=precision_score(y_test, predictions,average='micro')\nprint(\"Precisão NN = {}\".format(confidence)) \n\nimport seaborn as sns \nplt.title(\"Confusion Matrix\")\nsns.heatmap(cnf_matrix,cbar=False,annot=True,cmap=\"Blues\",fmt=\"d\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Add the neural network result to the complex system","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train01= pd.DataFrame(data = {'I1':y1,'I2':y2,'I3':y3,'I4':y4,'I5':y5,'I6':y6,'I7':y7})\nmode01= train.mode(axis='columns', numeric_only=True)\nmode01","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"notsure=mode01.dropna()\nnotsure\n#the same as before","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"na_free = mode01.dropna()\nonly_na = mode01[~mode01.index.isin(na_free.index)]\ny_train01 = y_train[~mode01.index.isin(na_free.index)]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ny_pred=mode01\n\ncnf_matrix = confusion_matrix(y_train, y_pred)\ncnf_matrix\n\n\nimport seaborn as sns \nplt.title(\"Confusion Matrix\")\nsns.heatmap(cnf_matrix,cbar=False,annot=True,cmap=\"Blues\",fmt=\"d\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### testing","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test01= pd.DataFrame(data = {'I1':y1_test,'I2':y2_test,'I3':y3_test,'I4':y4_test,'I5':y5_test,'I6':y6_test,'I7':y7_test })\ntest_mode01= test01.mode(axis='columns', numeric_only=True)\ntest_mode01","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"na_free = test_mode01.dropna()\nonly_na = test_mode01[~test_mode01.index.isin(na_free.index)]\ny_tes01 = y_test[~test_mode01.index.isin(na_free.index)]\nna_free.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ny_pred=only_na[0]\n\ncnf_matrix = confusion_matrix(y_tes01, y_pred)\ncnf_matrix\n\nfrom sklearn.metrics import precision_score\nconfidence=precision_score(y_tes01, y_pred,average='micro')\nprint(\"Precisão combo_NN = {}\".format(confidence)) \n\n\nimport seaborn as sns \nplt.title(\"Confusion Matrix\")\nsns.heatmap(cnf_matrix,cbar=False,annot=True,cmap=\"Blues\",fmt=\"d\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"comments: better outcomes by adding the neural network results, what creates a worst system than the neural network","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}