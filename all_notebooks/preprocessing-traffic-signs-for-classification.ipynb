{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Preprocessing Traffic Signs for Classification with CNN"},{"metadata":{},"cell_type":"markdown","source":"## Related Paper\nSichkar V. N., Kolyubin S. A. Effect of various dimension convolutional layer filters on traffic sign classification accuracy. *Scientific and Technical Journal of Information Technologies, Mechanics and Optics*, 2019, vol. 19, no. 3, pp. DOI: 10.17586/2226-1494-2019-19-3-546-552 (Full-text available on ResearchGate here: [Effect of various dimension convolutional layer filters on traffic sign classification accuracy](https://www.researchgate.net/publication/334074308_Effect_of_various_dimension_convolutional_layer_filters_on_traffic_sign_classification_accuracy))\n\nâˆ—  Test online with custom Traffic Sign here: https://valentynsichkar.name/traffic_signs.html"},{"metadata":{},"cell_type":"markdown","source":"# Importing needed libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport pickle\nimport matplotlib.pyplot as plt\nfrom timeit import default_timer as timer\n\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, AvgPool2D, BatchNormalization, Reshape\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import LearningRateScheduler\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport os\nfor dirname, _, filenames in os.walk('../input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nprint(os.listdir('../input'))\n\n# Listing all added utility scripts\nprint()\nprint(os.listdir('../usr/lib'))\n\n# Any results you write to the current directory are saved as output.\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Importing utility with custom function"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import utility_scripts_for_traffic_signs\n\n# Showing description of the functions inside utility\nprint(help(utility_scripts_for_traffic_signs))\n\n# Showing module's attributes\nprint(dir(utility_scripts_for_traffic_signs))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading datasets: data2.pickle, data3.pickle, data7.pickle, data8.pickle"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Defining list with numers for the files' datasets to load from\nn = [2, 3, 7, 8]\n\n# Defining list with preprocessed methods for datasets\nm = ['RGB + /255 + Mean', 'RGB + /255 + Mean + STD', 'LHE + /255 + Mean', 'LHE + /255 + Mean + STD']\n\n# Defining dictionary for saving datasets in\ndata = {}\n\n# Going through all of the four datasets' files\nfor i in n:\n    # Opening file for reading in binary mode\n    with open('../input/traffic-signs-preprocessed/data' + str(i) + '.pickle', 'rb') as f:\n        data[i] = pickle.load(f, encoding='latin1')  # dictionary type\n\n    # Preparing y_train and y_validation for using in Keras\n    data[i]['y_train'] = to_categorical(data[i]['y_train'], num_classes=43)\n    data[i]['y_validation'] = to_categorical(data[i]['y_validation'], num_classes=43)\n\n    # Making channels come at the end\n    data[i]['x_train'] = data[i]['x_train'].transpose(0, 2, 3, 1)\n    data[i]['x_validation'] = data[i]['x_validation'].transpose(0, 2, 3, 1)\n    data[i]['x_test'] = data[i]['x_test'].transpose(0, 2, 3, 1)\n\n# Showing loaded datasets from the files\n# All has to be the same\nii = 0  # index of methods' name\nfor i in n:\n    print('data' + str(i) + '.pickle ->', m[ii])\n    for k, j in data[i].items():\n        if k == 'labels':\n            print(k + ':', len(j))\n        else: \n            print(k + ':', j.shape)\n    print()\n    ii += 1\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Showing some training examples"},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\n\n# Visualizing some examples of training data\nsome_examples = data[2]['x_train'][:49, :, :, :]\nprint(some_examples.shape)  # (49, 32, 32, 3)\n\n# Plotting\nfig = plt.figure()\ngrid = utility_scripts_for_traffic_signs.convert_to_grid(some_examples)\nplt.imshow(grid.astype('uint8'))\nplt.axis('off')\nplt.gcf().set_size_inches(15, 15)\nplt.title('Some training examples', fontsize=18)\nplt.show()\nplt.close()\n\n# Saving plot\nfig.savefig('some_training_examples.png')\nplt.close()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Showing one Traffic Sign from different datasets"},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\n\n# Loading original RGB Traffic Sign without any processing\nwith open('../input/traffic-signs-preprocessed/data0.pickle', 'rb') as f:\n        data0 = pickle.load(f, encoding='latin1')  # dictionary type\n\n# Making channels come at the end\ndata0['x_train'] = data0['x_train'].transpose(0, 2, 3, 1)\n\n# Getting example\nexample0 = data0['x_train'][2, :, :, :]\nprint(example0.shape)  # (32, 32, 3)\n\n\n\n# Defining dictionary for saving four examples in\nexample = {}\n\n# Examples with 3-channeled images\nexample[2] = data[2]['x_train'][2, :, :, :]\nexample[3] = data[3]['x_train'][2, :, :, :]\nprint(example[2].shape, example[3].shape)  # (32, 32, 3) (32, 32, 3)\n\n# Examples with 1-channeled images\nexample[7] = data[7]['x_train'][2, :, :, 0]\nexample[8] = data[8]['x_train'][2, :, :, 0]\nprint(example[7].shape, example[8].shape)  # (32, 32) (32, 32)\n\n\n\n# Getting labels' names from the file\n# Defining list for saving labels in order from 0 to 42\nlabels = []\n\n# Reading 'csv' file and getting labels\nr = pd.read_csv('../input/traffic-signs-preprocessed/label_names.csv')\n# Going through all names\nfor name in r['SignName']:\n    # Adding from every row second column with name of the label\n    labels.append(name)\n\n\n\n# Plotting examples of one traffic sign preprocessed in four different ways\nplt.rcParams['figure.figsize'] = (12.0, 12.0) # Setting default size of plots\nplt.rcParams['image.interpolation'] = 'nearest'\nplt.rcParams['font.family'] = 'Times New Roman'\n\nfig = plt.figure()\n\n# Plotting original example\nplt.subplot(2, 4, 1)  # rows, columns, current index of the plot\nplt.imshow(example0)\nplt.xlabel('RGB', fontsize=15)\nplt.ylabel(labels[np.argmax(data[2]['y_train'][2])], fontsize=15)\nplt.xticks([])\nplt.yticks([])\n\n# Going through all of the four examples\nk = 5  # Setting index for the plots\nii = 0  # Setting index for getting method's name\nfor i in n:\n    plt.subplot(2, 4, k)  # rows, columns, current index of the plot\n    if i == 7 or i == 8:\n        plt.imshow(example[i], cmap='gray')\n    else:\n        plt.imshow(example[i])\n    plt.xlabel(m[ii], fontsize=15)\n    plt.ylabel(labels[np.argmax(data[2]['y_train'][2])], fontsize=15)\n    plt.xticks([])\n    plt.yticks([])\n    k += 1\n    ii += 1\n\n# Adjusting height between subplots\nplt.subplots_adjust(hspace=0)\nplt.tight_layout()\n\n# Showing the plot\nplt.show()\n\n# Saving the plot\nfig.savefig('one_ts_from_different_datasets.png')\nplt.close()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Building model of CNN with Keras for RGB dataset[2]"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(32, kernel_size=9, padding='same', activation='relu', input_shape=(32, 32, 3)))\nmodel.add(MaxPool2D(pool_size=2))\n\nmodel.add(Conv2D(64, kernel_size=7, padding='same', activation='relu'))\nmodel.add(MaxPool2D(pool_size=2))\n\nmodel.add(Conv2D(128, kernel_size=3, padding='same', activation='relu'))\nmodel.add(MaxPool2D(pool_size=2))\n\nmodel.add(Flatten())\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(43, activation='softmax'))\n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Overfitting small data for RGB dataset[2]"},{"metadata":{"trusted":true},"cell_type":"code","source":"annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** (x + epochs))\nepochs = 20\n\nh = model.fit(data[2]['x_train'][:100], data[2]['y_train'][:100],\n              batch_size=5, epochs = epochs,\n              validation_data = (data[2]['x_validation'], data[2]['y_validation']),\n              callbacks=[annealer], verbose=1)\n\nprint()\nprint('Epochs={0:d}, Train accuracy={1:.5f}, \\\n      Validation accuracy={2:.5f}'.\\\n      format(epochs, max(h.history['accuracy']), max(h.history['val_accuracy'])))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plotting history results for overfitting small data for RGB dataset[2]"},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nplt.rcParams['figure.figsize'] = (15.0, 5.0) # Setting default size of plots\nplt.rcParams['image.interpolation'] = 'nearest'\n\nfig = plt.figure()\n\nplt.plot(h.history['accuracy'], '-o', linewidth=3.0)\nplt.plot(h.history['val_accuracy'], '-o', linewidth=3.0)\nplt.title('Overfitting small data for RGB dataset[2]', fontsize=22)\nplt.legend(['train', 'validation'], loc='upper left', fontsize='xx-large', borderpad=2)\nplt.xlabel('Epoch', fontsize=22)\nplt.ylabel('Accuracy', fontsize=22)\nplt.tick_params(labelsize=18)\nplt.show()\n\n# Saving the plot\nfig.savefig('Overfitting_dataset_2.png')\nplt.close()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Building set of models of CNN with Keras"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Defining dictionary for models\nmodel = {}\n\n# Building four models\nfor i in n:\n    model[i] = Sequential()\n    \n    if i == 7 or i == 8:\n        model[i].add(Conv2D(32, kernel_size=9, padding='same', activation='relu', input_shape=(32, 32, 1)))\n    else:\n        model[i].add(Conv2D(32, kernel_size=9, padding='same', activation='relu', input_shape=(32, 32, 3)))\n        \n    model[i].add(MaxPool2D(pool_size=2))\n\n    model[i].add(Conv2D(64, kernel_size=7, padding='same', activation='relu'))\n    model[i].add(MaxPool2D(pool_size=2))\n\n    model[i].add(Conv2D(128, kernel_size=3, padding='same', activation='relu'))\n    model[i].add(MaxPool2D(pool_size=2))\n\n    model[i].add(Flatten())\n    model[i].add(Dense(500, activation='relu'))\n    model[i].add(Dense(43, activation='softmax'))\n\n    model[i].compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training with different datasets"},{"metadata":{"trusted":true},"cell_type":"code","source":"annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** (x + epochs))\nepochs = 5\n\n# Defining dictionary for saving history results\nh = {}\n\nfor i in n:\n    h[i] = model[i].fit(data[i]['x_train'], data[i]['y_train'],\n                        batch_size=5, epochs = epochs,\n                        validation_data = (data[i]['x_validation'], data[i]['y_validation']),\n                        callbacks=[annealer], verbose=0)\n    \n    print('Model trained on dataset{0}.pickle, epochs={1:d}, training accuracy={2:.5f}, validation accuracy={3:.5f}'.format(i, epochs, max(h[i].history['accuracy']), max(h[i].history['val_accuracy'])))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Plotting comparison results for accuracy"},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nplt.rcParams['figure.figsize'] = (15.0, 15.0) # Setting default size of plots\nplt.rcParams['image.interpolation'] = 'nearest'\nplt.rcParams[\"font.family\"] = 'Times New Roman'\n\nfig = plt.figure()\n\n# Plotting history of training accuracy\nplt.subplot(2, 1, 1)\nplt.plot(h[2].history['accuracy'], '-o', linewidth=3.0)\nplt.plot(h[3].history['accuracy'], '-s', linewidth=3.0)\nplt.plot(h[7].history['accuracy'], '-D', linewidth=3.0)\nplt.plot(h[8].history['accuracy'], '-D', linewidth=3.0)\nplt.legend(['dataset2', 'dataset3', 'dataset7', 'dataset8'], loc='lower right', fontsize='xx-large', borderpad=2)\nplt.xlabel('Epoch', fontsize=22, fontname='Times New Roman')\nplt.ylabel('Training Accuracy', fontsize=22, fontname='Times New Roman')\nplt.yscale('linear')  # {\"linear\", \"log\", \"symlog\", \"logit\", ...}\nplt.ylim(0.9, 1.0)\nplt.xlim(0.5, 5.3)\nplt.tick_params(labelsize=18)\n# plt.title('Accuracy for different datasets', fontsize=20)\n\n# Plotting history of validation accuracy\nplt.subplot(2, 1, 2)\n# plt.gca().set_title('Validation accuracy')\nplt.plot(h[2].history['val_accuracy'], '-o', linewidth=3.0)\nplt.plot(h[3].history['val_accuracy'], '-s', linewidth=3.0)\nplt.plot(h[7].history['val_accuracy'], '-D', linewidth=3.0)\nplt.plot(h[8].history['val_accuracy'], '-D', linewidth=3.0)\nplt.legend(['dataset2', 'dataset3', 'dataset7', 'dataset8'], loc='lower right', fontsize='xx-large', borderpad=2)\nplt.xlabel('Epoch', fontsize=22, fontname='Times New Roman')\nplt.ylabel('Validation Accuracy', fontsize=22, fontname='Times New Roman')\nplt.yscale('linear')  # {\"linear\", \"log\", \"symlog\", \"logit\", ...}\nplt.ylim(0.75, 1.0)\nplt.xlim(0.5, 5.3)\nplt.tick_params(labelsize=18)\n\n# Showing the plot\nplt.show()\n\n# Saving the plot\nfig.savefig('models_accuracy.png')\nplt.close()\n\n\n# Showing values of training accuracy for different datasets\nfor i in n:\n    print('dataset{0}.pickle training accuracy = {1:.5f}'.\\\n          format(i, np.max(h[i].history['accuracy'])))\n\n# Showing values of validation accuracy for different datasets\nprint()\nfor i in n:\n    print('dataset{0}.pickle validation accuracy = {1:.5f}'.\\\n          format(i, np.max(h[i].history['val_accuracy'])))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Calculating accuracy with testing datasets"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Going through all of the four models\nfor i in n:\n    temp = model[i].predict(data[i]['x_test'])\n    temp = np.argmax(temp, axis=1)\n\n    # We compare predicted class with correct class for all input images\n    # And calculating mean value among all values of following numpy array\n    # By saying 'testing_accuracy == data[i]['y_test']' we create numpy array with True and False values\n    # 'np.mean' function will return average of the array elements\n    # The average is taken over the flattened array by default\n    temp = np.mean(temp == data[i]['y_test'])\n    \n    print('dataset{0}.pickle testing accuracy = {1:.5f}'.format(i, temp))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Calculating time for classification"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting scores from forward pass of one input image\n# Scores is given for each image with 43 numbers of predictions for each class\n# Measuring at the same time execution time\n\n# Going through all of the four models\nfor i in n:\n    start = timer()\n    temp = model[i].predict(data[i]['x_test'][:1, :, :, :])\n    end = timer()\n    \n    print('dataset{0}.pickle classification time = {1:.5f}'.format(i, end - start))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predicting with one image from test dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\n\nplt.rcParams['figure.figsize'] = (15.0, 15.0) # Setting default size of the plots\nplt.rcParams['image.interpolation'] = 'nearest'\nplt.rcParams[\"font.family\"] = 'Times New Roman'\n\n# Going through all of the four models\nk = 1  # Setting index for the plots\nii = 0  # Setting index for getting method's name\nfor i in n:\n    # Preparing image for predicting from test dataset\n    x_input = data[i]['x_test'][100:101, :, :, :]\n    # print(x_input.shape)  # (1, 32, 32, 3) or (1, 32, 32, 1)\n    \n    y_input = data[i]['y_test'][100:101]\n    # print(y_input)  # [3]\n    \n    # Plotting input image\n    plt.subplot(1, 4, k)  # rows, columns, current index of the plot\n    if i == 7 or i == 8:\n        plt.imshow(x_input[0, :, :, 0], cmap='gray')\n    else:\n        plt.imshow(x_input[0])\n    plt.xlabel(m[ii], fontsize=14)\n    plt.ylabel(labels[y_input[0]], fontsize=14)\n    plt.xticks([])\n    plt.yticks([])\n    k += 1\n    ii += 1\n    \n    # Getting scores from forward pass of input image\n    scores = model[i].predict(x_input)\n    # print(scores[0].shape)  # (43,)\n\n    # Scores is given for image with 43 numbers of predictions for each class\n    # Getting only one class with maximum value\n    prediction = np.argmax(scores)\n    print('Predicted classId for model trained on dataset{0}.pickle: {1}'.format(i, prediction))\n\n    # Printing label for classified Traffic Sign\n    print('Predicted label:', labels[prediction])\n    \n    print()\n\n\n# Showing the plot\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Saving models"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in n:\n    name = 'model-dataset' + str(i) + '.h5'\n    model[i].save(name)\n\n# # Saving model locally without committing\n# from IPython.display import FileLink\n\n# FileLink('model-dataset2.h5')\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}