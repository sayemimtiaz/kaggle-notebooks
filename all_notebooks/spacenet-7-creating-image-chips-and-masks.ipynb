{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!ls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!rm -rf chip_dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creating Different Sized Chips for our Satellite Images\nThis notebook is meant to help you create chips out of your satellite images. Chips are basically smaller crops of images that you stitch together to recreate your larger image. To get a better idea take a look at the image below. \n\n\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from PIL import Image\nImage.open('../input/mark-down-images/chips.png')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The helper classes below, allow you to read from the csv files that we created in our earlier notebooks, and use them in tandem with the SpaceNet 7 dataset to create formatted image chips that have your desired dimensions. \n\nThe output directory is structured as follows:\n chip_dataset<br>\n&nbsp;&nbsp;&nbsp;&nbsp;└── change_detection<br>\n    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;└── fname<br>\n        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;├── chips<br>\n        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;│   └── year1_month1_year2_month2<br>\n        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;│&nbsp;&nbsp;&nbsp;&nbsp;       └── global_monthly_year1_month1_year2_month2_chip_x###_y###_fname.tif<br>\n        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;└── masks<br>\n            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;└── year1_month1_year2_month2<br>\n                &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;└── global_monthly_year1_month1_year2_month2_chip_x###_y###_fname_blank.tif<br>\n\n\nThe `_blank` in the mask chips, indicates whether the mask is a blank mask or not."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from __future__ import print_function, division\nimport os\nimport torch\nimport pandas as pd\nfrom skimage import io, transform\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport rasterio as rio\nfrom rasterio import features\nfrom pathlib import Path\nimport pathlib\nimport geopandas as gpd\nfrom descartes import PolygonPatch\nfrom PIL import Image\nimport itertools\nimport re\nfrom tqdm.notebook import tqdm\n\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, utils\n\n\n# Ignore warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nplt.ion()   # interactive mode\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"root_dir = Path('../input/spacenet-7-multitemporal-urban-development/SN7_buildings_train_sample/sample')\ncsv_file = Path('../input/spacenet-7-directory-metadata-extraction/output_csvs/df_sample_untidy.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(csv_file)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class MultiTemporalSatelliteDataset():\n    \"\"\"SpaceNet 7 Multi-Temporal Satellite Imagery Dataset Creater\"\"\"\n    \n    def __init__(self,csv_file, root_dir, no_udm=True, transform=None):\n        \"\"\"\n        Args:\n            csv_file (Path): Path to the csv file with annotations\n            root_dir (Path): Parent directory containing all other directories.\n            no_udm (bool): Specifies whether the dataset will load UDM images or not.\n            transform (callable, optional): Optional transform to be applied on a sample.\n        \"\"\"\n        self.annotations = pd.read_csv(csv_file)\n        self.root_dir = root_dir\n        self.no_udm = no_udm\n        self.transform = transform\n        \n        self.idx_combinations = self.__get_all_idx_combinations()\n        self.max = self.__len__()\n        # for debugging purposes\n        self.empty = []\n    \n    def __len__(self):\n        return len(self.idx_combinations)\n    \n    def __getitem__(self,raster_idx):\n\n            \n        if torch.is_tensor(raster_idx):\n            raster_idx = raster_idx.tolist()\n            \n        # get the indices of the 2 images\n        idx1,idx2 = self.idx_combinations[raster_idx]\n        # paths where the images are stored\n        img1_path = self.root_dir/self.annotations.loc[idx1,'images_masked']\n        img2_path = self.root_dir/self.annotations.loc[idx2,'images_masked']\n        # paths where the corresponding true building footprints \n        labels1_path = self.root_dir/self.annotations.loc[idx1,'labels_match_pix']\n        labels2_path = self.root_dir/self.annotations.loc[idx2,'labels_match_pix']\n        # read rasters using imported rasterio library\n        with rio.open(img1_path) as r1, rio.open(img2_path) as r2:\n            raster1 = r1.read()[0:3]  \n            raster2 = r2.read()[0:3]\n            raster_bounds = r1.bounds\n            rio_transform = r1.transform\n        # get the concatenated array of the 2 images that will be fed into the neural_net\n        raster_diff = np.concatenate((raster1,raster2),axis=0)\n        # get the dates for the images\n        date1 = tuple(self.annotations.loc[idx1,['month','year']])\n        date2 = tuple(self.annotations.loc[idx2,['month','year']])\n        # read geojson files for each of the satellite images into a geodataframe\n        gdf1 = gpd.read_file(labels1_path).set_index('Id').sort_index()\n        gdf2 = gpd.read_file(labels2_path).set_index('Id').sort_index()\n        # get the change between the 2 satellite images by comparing their polygons\n        gdf_diff = self.__geo_difference(labels1_path,labels2_path)\n        # get the corresponding rasterized image of the geodataframes\n        mask_diff = self.__rasterize_gdf(gdf_diff,out_shape=raster1.shape[1:3])\n        \n        sample = {'raster1':raster1,'raster2':raster2,'raster_diff':raster_diff,'raster_bounds':raster_bounds,'rio_transform':rio_transform,\n                  'date1':date1,'date2':date2,'mask_diff':mask_diff,'fname':img1_path.parent.parent.stem}\n        \n        if self.transform:\n            sample = self.transform(sample)\n        \n        return sample\n    \n    def __get_all_idx_combinations(self):\n        all_combinations = []\n        # group by satellite image location\n        location_groups = self.annotations.groupby('image_dir_name')\n        # loop through the groups and get the different index combinations\n        for i,location in enumerate(location_groups):\n            # get the dataframe in the group\n            loc_frame = location[1]\n            # make sure that list does not contain images with unidentified masks\n            condition = (loc_frame['has_udm'] == False)\n            # return a list of the indices in the location dataframe\n            l = list(loc_frame[condition].index)\n            # use itertools to get all the different combinations between 2 in the list\n            combinations = list(itertools.combinations(l,2))\n            all_combinations.extend(combinations)\n        return all_combinations\n        \n    def __geo_difference(self,geojson1,geojson2):\n        # read geojson into geodataframes\n        gdf1 = gpd.read_file(geojson1).set_index('Id').sort_index()\n        gdf2 = gpd.read_file(geojson2).set_index('Id').sort_index()\n\n        # get geodataframe lengths\n        len_1 = len(gdf1)\n        len_2 = len(gdf2)\n        # check which gdf is longer\n        len_diff = abs(len_2-len_1)\n\n        if len_2 > len_1:\n            start_index = len_2-len_diff\n            diff_gdf = gdf2.iloc[start_index:].copy()\n        else:\n            start_index = len_1-len_diff\n            diff_gdf = gdf1.iloc[start_index:].copy()\n\n        # reset the index\n        diff_gdf.reset_index(inplace=True,drop=True)\n\n        return diff_gdf\n\n    \n    def __rasterize_gdf(self,gdf,out_shape):\n        # if geodataframe is empty return empty mask\n        if len(gdf)==0:\n            return np.zeros((1,*out_shape))\n            \n        mask = features.rasterize(((polygon, 255) for polygon in gdf['geometry']),out_shape=out_shape)\n        \n        return np.expand_dims(mask,axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ChipGenerator():   \n    def __init__(self, chip_dimension=256):  \n        self.chip_dimension = chip_dimension\n        self.chip_dict = {'chip':[],'x':[],'y':[], 'blank':[]}\n\n    def __call__(self,image):\n        np_array = self.__read_image(image)\n        # get number of chips per colomn\n        n_rows = (np_array.shape[1] - 1) // self.chip_dimension + 1\n        # get number of chips per row\n        n_cols = (np_array.shape[2] - 1) // self.chip_dimension + 1\n        # segment image into chips and return dict of chips and metadata\n        chip_dict = {'chip':[],'x':[],'y':[], 'blank':[]}\n        for r in range(n_rows):\n            for c in range(n_cols):\n                start_r_idx = r*self.chip_dimension\n                end_r_idx = start_r_idx + self.chip_dimension\n\n                start_c_idx = c*self.chip_dimension\n                end_c_idx = start_c_idx + self.chip_dimension\n                chip = np_array[:,start_r_idx:end_r_idx,start_c_idx:end_c_idx]\n\n                chip_dict['chip'].append(chip)\n                chip_dict['x'].append(start_r_idx)\n                chip_dict['y'].append(start_c_idx)\n                # Check if the chip is an empty chip\n                if chip.mean() == 0 and chip.sum() == 0:\n                    chip_dict['blank'].append('_blank')\n                else:\n                    chip_dict['blank'].append('')\n\n\n        return chip_dict\n\n    def __read_image(self,image):\n        # check whether image is a path or array\n        if isinstance(image,(pathlib.PurePath,str)):\n                with Image.open(image) as img:\n                    # convert image into np array\n                    np_array = np.array(img)\n                return np_array\n\n        elif isinstance(image,np.ndarray):\n            return image\n        else:\n            raise ValueError(f\"Expected Path or Numpy array received: {type(image)}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DatasetCreator():\n    def __init__(self,chip_dimension=256):\n        self.chip_dimension = chip_dimension\n    \n    def __call__(self,dataset):\n        for d in tqdm(dataset):\n            raster_diff = d['raster_diff']\n            mask_diff = d['mask_diff']\n            \n            self.__fname = d['fname']\n            self.__date1= d['date1']\n            self.__date2 = d['date2']\n            self.__raster_bounds = d['raster_bounds']\n            self.__transform = d['rio_transform']\n            self.__raster_shape = raster_diff.shape[1:3]\n            \n            \n            \n            self.__save_chips(image=raster_diff,subdir_name='chips')\n            self.__save_chips(image=mask_diff,subdir_name='masks')\n            \n            \n    def __save_chips(self,image,subdir_name='chips'):\n        \n        month1,year1 = self.__date1\n        month2,year2 = self.__date2\n        \n        chip_generator = ChipGenerator(chip_dimension=self.chip_dimension)\n        chip_dict = chip_generator(image)\n        \n        x_coords = chip_dict['x']\n        y_coords = chip_dict['y']\n        chips = chip_dict['chip']\n        blanks = chip_dict['blank'] \n        \n        im_dir = Path('chip_dataset/change_detection')/Path(self.__fname)/Path(subdir_name)/Path(f'{year1}_{month1}_{year2}_{month2}')\n        im_dir.mkdir(parents=True, exist_ok=True)\n\n        for chip,x,y,blank in zip(chips,x_coords,y_coords,blanks):\n            im_name = f'global_monthly_{year1}_{month1}_{year2}_{month2}_chip_x{x}_y{y}_{self.__fname}{blank}.tif'\n            im_path = im_dir/im_name\n            \n            if subdir_name == 'chips':\n                count = 6\n            else:\n                count = 1\n            \n            # Calculate the new bounds for the raster chips\n            transform = self.__get_geo_transform(x,y)\n            \n            profile = {'driver':'GTiff', 'width':self.chip_dimension,'height':self.chip_dimension,'crs':'EPSG:3857','count':count,'dtype':rio.uint8, 'compress':'zip','transform': transform}\n            \n            with rio.open(im_path, 'w',**profile) as dst:\n                dst.write(chip.astype(rio.uint8))\n                \n    \n    def __get_geo_transform(self,x,y):\n        top = self.__raster_bounds[3]\n        bottom = self.__raster_bounds[1]\n        left = self.__raster_bounds[0]\n        right = self.__raster_bounds[2]\n        \n        raster_height = self.__raster_shape[0]\n        raster_width = self.__raster_shape[1]\n        \n        chip_height = (top-bottom)/(raster_height//self.chip_dimension)\n        chip_width = (left-right)/(raster_width//self.chip_dimension)\n        \n        pixel_height = (top-bottom)/raster_height\n        pixel_width = (left-right)/raster_width\n        \n        chip_top = top + y * pixel_height\n        chip_bottom = chip_top + chip_height\n        \n        chip_left = left + x * pixel_width\n        chip_right = chip_left + chip_width\n        \n        bounds = {'left': chip_left, 'bottom': chip_bottom, 'right': chip_right, 'top': chip_top}\n        \n        return rio.Affine(self.__transform[0], self.__transform[1], chip_left,self.__transform[3], self.__transform[4], chip_top)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In order to generate your chips, replace the chip dimension with your chip dimension of choice, and run the notebook. Make sure that the output does not exceed kaggle's storage restriction of 20gb. If you would like to exceed the limit, then you can download the notebook along with the dataset and run it localy instead."},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = MultiTemporalSatelliteDataset(root_dir=root_dir,csv_file=csv_file)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_creator = DatasetCreator(chip_dimension=64)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_creator(dataset=dataset)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the above example we read our data from our sample satellite imagery directory, we then obained the cartesian product of all the images from the different timestamps. We then looped through the combinations and segmented each combination and saved the corresponding chips and masks in the specified directories. \n\nThis code can be used to generate satellite imagery chips of any kind, and the best part is that the geolocation for each chip is conserved. "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}