{"cells":[{"metadata":{},"cell_type":"markdown","source":"# *Traffic Sign Recognizer - 99% accuracy*"},{"metadata":{},"cell_type":"markdown","source":"## Importing Required Libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport cv2\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.metrics import accuracy_score\nnp.random.seed(42)\n\nfrom matplotlib import style\nstyle.use('fivethirtyeight')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Assigning Path for Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dir = '../input/gtsrb-german-traffic-sign'\ntrain_path = '../input/gtsrb-german-traffic-sign/Train'\ntest_path = '../input/gtsrb-german-traffic-sign/'\n\n# Resizing the images to 30x30x3\nIMG_HEIGHT = 30\nIMG_WIDTH = 30\nchannels = 3","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Finding Total Classes"},{"metadata":{"trusted":true},"cell_type":"code","source":"NUM_CATEGORIES = len(os.listdir(train_path))\nNUM_CATEGORIES","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Label Overview\nclasses = { 0:'Speed limit (20km/h)',\n            1:'Speed limit (30km/h)', \n            2:'Speed limit (50km/h)', \n            3:'Speed limit (60km/h)', \n            4:'Speed limit (70km/h)', \n            5:'Speed limit (80km/h)', \n            6:'End of speed limit (80km/h)', \n            7:'Speed limit (100km/h)', \n            8:'Speed limit (120km/h)', \n            9:'No passing', \n            10:'No passing veh over 3.5 tons', \n            11:'Right-of-way at intersection', \n            12:'Priority road', \n            13:'Yield', \n            14:'Stop', \n            15:'No vehicles', \n            16:'Veh > 3.5 tons prohibited', \n            17:'No entry', \n            18:'General caution', \n            19:'Dangerous curve left', \n            20:'Dangerous curve right', \n            21:'Double curve', \n            22:'Bumpy road', \n            23:'Slippery road', \n            24:'Road narrows on the right', \n            25:'Road work', \n            26:'Traffic signals', \n            27:'Pedestrians', \n            28:'Children crossing', \n            29:'Bicycles crossing', \n            30:'Beware of ice/snow',\n            31:'Wild animals crossing', \n            32:'End speed + passing limits', \n            33:'Turn right ahead', \n            34:'Turn left ahead', \n            35:'Ahead only', \n            36:'Go straight or right', \n            37:'Go straight or left', \n            38:'Keep right', \n            39:'Keep left', \n            40:'Roundabout mandatory', \n            41:'End of no passing', \n            42:'End no passing veh > 3.5 tons' }","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualizing The Dataset"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"folders = os.listdir(train_path)\n\ntrain_number = []\nclass_num = []\n\nfor folder in folders:\n    train_files = os.listdir(train_path + '/' + folder)\n    train_number.append(len(train_files))\n    class_num.append(classes[int(folder)])\n    \n# Sorting the dataset on the basis of number of images in each class\nzipped_lists = zip(train_number, class_num)\nsorted_pairs = sorted(zipped_lists)\ntuples = zip(*sorted_pairs)\ntrain_number, class_num = [ list(tuple) for tuple in  tuples]\n\n# Plotting the number of images in each class\nplt.figure(figsize=(21,10))  \nplt.bar(class_num, train_number)\nplt.xticks(class_num, rotation='vertical')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualizing 25 random images from test data\nimport random\nfrom matplotlib.image import imread\n\ntest = pd.read_csv(data_dir + '/Test.csv')\nimgs = test[\"Path\"].values\n\nplt.figure(figsize=(25,25))\n\nfor i in range(1,26):\n    plt.subplot(5,5,i)\n    random_img_path = data_dir + '/' + random.choice(imgs)\n    rand_img = imread(random_img_path)\n    plt.imshow(rand_img)\n    plt.grid(b=None)\n    plt.xlabel(rand_img.shape[1], fontsize = 20)#width of image\n    plt.ylabel(rand_img.shape[0], fontsize = 20)#height of image","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Collecting the Training Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"image_data = []\nimage_labels = []\n\nfor i in range(NUM_CATEGORIES):\n    path = data_dir + '/Train/' + str(i)\n    images = os.listdir(path)\n\n    for img in images:\n        try:\n            image = cv2.imread(path + '/' + img)\n            image_fromarray = Image.fromarray(image, 'RGB')\n            resize_image = image_fromarray.resize((IMG_HEIGHT, IMG_WIDTH))\n            image_data.append(np.array(resize_image))\n            image_labels.append(i)\n        except:\n            print(\"Error in \" + img)\n\n# Changing the list to numpy array\nimage_data = np.array(image_data)\nimage_labels = np.array(image_labels)\n\nprint(image_data.shape, image_labels.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Shuffling the training data"},{"metadata":{"trusted":true},"cell_type":"code","source":"shuffle_indexes = np.arange(image_data.shape[0])\nnp.random.shuffle(shuffle_indexes)\nimage_data = image_data[shuffle_indexes]\nimage_labels = image_labels[shuffle_indexes]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Splitting the data into train and validation set"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(image_data, image_labels, test_size=0.3, random_state=42, shuffle=True)\n\nX_train = X_train/255 \nX_val = X_val/255\n\nprint(\"X_train.shape\", X_train.shape)\nprint(\"X_valid.shape\", X_val.shape)\nprint(\"y_train.shape\", y_train.shape)\nprint(\"y_valid.shape\", y_val.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## One hot encoding the labels"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = keras.utils.to_categorical(y_train, NUM_CATEGORIES)\ny_val = keras.utils.to_categorical(y_val, NUM_CATEGORIES)\n\nprint(y_train.shape)\nprint(y_val.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Making the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = keras.models.Sequential([    \n    keras.layers.Conv2D(filters=16, kernel_size=(3,3), activation='relu', input_shape=(IMG_HEIGHT,IMG_WIDTH,channels)),\n    keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu'),\n    keras.layers.MaxPool2D(pool_size=(2, 2)),\n    keras.layers.BatchNormalization(axis=-1),\n    \n    keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu'),\n    keras.layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu'),\n    keras.layers.MaxPool2D(pool_size=(2, 2)),\n    keras.layers.BatchNormalization(axis=-1),\n    \n    keras.layers.Flatten(),\n    keras.layers.Dense(512, activation='relu'),\n    keras.layers.BatchNormalization(),\n    keras.layers.Dropout(rate=0.5),\n    \n    keras.layers.Dense(43, activation='softmax')\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = 0.001\nepochs = 30\n\nopt = Adam(lr=lr, decay=lr / (epochs * 0.5))\nmodel.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Augmenting the data and training the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"aug = ImageDataGenerator(\n    rotation_range=10,\n    zoom_range=0.15,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    shear_range=0.15,\n    horizontal_flip=False,\n    vertical_flip=False,\n    fill_mode=\"nearest\")\n\nhistory = model.fit(aug.flow(X_train, y_train, batch_size=32), epochs=epochs, validation_data=(X_val, y_val))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Evaluating the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(history.history).plot(figsize=(8, 5))\nplt.grid(True)\nplt.gca().set_ylim(0, 1)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Loading the test data and running the predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv(data_dir + '/Test.csv')\n\nlabels = test[\"ClassId\"].values\nimgs = test[\"Path\"].values\n\ndata =[]\n\nfor img in imgs:\n    try:\n        image = cv2.imread(data_dir + '/' +img)\n        image_fromarray = Image.fromarray(image, 'RGB')\n        resize_image = image_fromarray.resize((IMG_HEIGHT, IMG_WIDTH))\n        data.append(np.array(resize_image))\n    except:\n        print(\"Error in \" + img)\nX_test = np.array(data)\nX_test = X_test/255\n\npred = model.predict_classes(X_test)\n\n#Accuracy with the test data\nprint('Test Data accuracy: ',accuracy_score(labels, pred)*100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualizing the confusion matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ncf = confusion_matrix(labels, pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\ndf_cm = pd.DataFrame(cf, index = classes,  columns = classes)\nplt.figure(figsize = (20,20))\nsns.heatmap(df_cm, annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Classification report"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nprint(classification_report(labels, pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predictions on Test Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (25, 25))\n\nstart_index = 0\nfor i in range(25):\n    plt.subplot(5, 5, i + 1)\n    plt.grid(False)\n    plt.xticks([])\n    plt.yticks([])\n    prediction = pred[start_index + i]\n    actual = labels[start_index + i]\n    col = 'g'\n    if prediction != actual:\n        col = 'r'\n    plt.xlabel('Actual={} || Pred={}'.format(actual, prediction), color = col)\n    plt.imshow(X_test[start_index + i])\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}