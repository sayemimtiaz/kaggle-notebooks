{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom fbprophet import Prophet\nimport warnings\nimport datetime\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Activation,Flatten\nfrom sklearn.preprocessing import MinMaxScaler\n\n\nwarnings.filterwarnings(action='ignore')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tas = pd.read_csv('../input/chile-temperature-daily-stations-2018/cr2_tasDaily_2018.csv')\ntas.head(15)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for n in range(0,14):\n        print(tas['codigo_estacion'][n],':',tas['330021'][n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def data_processing(df,station):\n    df = df[14:] #drop\n    df=df.replace(float(-9999),np.nan)\n    df=df.replace('-9999',np.nan)\n    print(df['01202012'].isna().sum(),' NaN values of ',df.shape[0])\n    df = df[['codigo_estacion',station]]\n    df['codigo_estacion'] =  pd.to_datetime(df['codigo_estacion'], format='%Y-%m-%d')\n    df=df.dropna().reset_index().drop(columns=['index']).rename(columns={'codigo_estacion':'datetime'}).set_index('datetime')\n    \n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=data_processing(tas,'330021')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.style.use('fivethirtyeight')\n# Color pallete for plotting\ncolor_pal = [\"#F8766D\", \"#D39200\", \"#93AA00\",\n             \"#00BA38\", \"#00C19F\", \"#00B9E3\",\n             \"#619CFF\", \"#DB72FB\"]\ndf.plot(style='.', figsize=(15,15), color=color_pal[0], title='Temperature')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"split_date = datetime.date(2002, 1, 1).isoformat()\nX_train = df.loc[df.index <= split_date].copy()\nX_test = df.loc[df.index > split_date].copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test \\\n.rename(columns={'330021': 'TEST SET'}) \\\n.join(X_train.rename(columns={'330021': 'TRAINING SET'}),how='outer') \\\n.plot(figsize=(15,5), title='Temperature Chile station', style='.')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = X_train.reset_index().rename(columns={'datetime':'ds','330021':'y' })\nX_test = X_test.reset_index().rename(columns={'datetime':'ds','330021':'y' })","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(X_train))\nprint(len(X_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Prophet()\nmodel.fit(X_train)\n\ntas_predict = model.predict(X_test)\ntas_predict.head()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the forecast\nf, ax = plt.subplots(1)\nf.set_figheight(5)\nf.set_figwidth(15)\nfig = model.plot(tas_predict,\n                 ax=ax)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the components of the model\nfig = model.plot_components(tas_predict)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Compare Forecast results with real values of temperature.","metadata":{}},{"cell_type":"code","source":"# Plot the forecast with the actuals\nf, ax = plt.subplots(1)\nf.set_figheight(5)\nf.set_figwidth(15)\nax.scatter(X_test['ds'], X_test['y'], color='r')\nfig = model.plot(tas_predict, ax=ax)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def mean_absolute_percentage_error(y_true, y_pred): \n    \"\"\"Calculates MAPE given y_true and y_pred\"\"\"\n    y_true, y_pred = np.array(y_true), np.array(y_pred)\n    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n\nprint('RMSE '+ str(round(mean_squared_error(y_true=X_test['y'],y_pred=tas_predict['yhat']),3)))\nprint('MAE '+ str(round(mean_absolute_error(y_true=X_test['y'], y_pred=tas_predict['yhat']),3)))\nprint('MAPE ' +str(round(mean_absolute_percentage_error(y_true=X_test['y'], y_pred=tas_predict['yhat']),3))+'%')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Neuronal Network","metadata":{}},{"cell_type":"code","source":"PASOS=7\n\n# convert series to supervised learning\ndef series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n    n_vars = 1 if type(data) is list else data.shape[1]\n    df = pd.DataFrame(data)\n    cols, names = list(), list()\n    # input sequence (t-n, ... t-1)\n    for i in range(n_in, 0, -1):\n        cols.append(df.shift(i))\n        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n    # forecast sequence (t, t+1, ... t+n)\n    for i in range(0, n_out):\n        cols.append(df.shift(-i))\n        if i == 0:\n            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n        else:\n            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n    # put it all together\n    agg = pd.concat(cols, axis=1)\n    agg.columns = names\n    # drop rows with NaN values\n    if dropnan:\n        agg.dropna(inplace=True)\n    return agg\n \n# load dataset\nvalues = df.values\n# ensure all data is float\nvalues = values.astype('float32')\n# normalize features\nscaler = MinMaxScaler(feature_range=(-1, 1))\nvalues=values.reshape(-1, 1) # esto lo hacemos porque tenemos 1 sola dimension\nscaled = scaler.fit_transform(values)\n# frame as supervised learning\nreframed = series_to_supervised(scaled, PASOS, 1)\nreframed.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reframed.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# split into train and test sets\nvalues = reframed.values\nn_train_days = 12612\ntrain = values[:n_train_days, :]\ntest = values[n_train_days:, :]\n# split into input and outputs\nx_train, y_train = train[:, :-1], train[:, -1]\nx_val, y_val = test[:, :-1], test[:, -1]\n# reshape input to be 3D [samples, timesteps, features]\nx_train = x_train.reshape((x_train.shape[0], 1, x_train.shape[1]))\nx_val = x_val.reshape((x_val.shape[0], 1, x_val.shape[1]))\nprint(x_train.shape, y_train.shape, x_val.shape, y_val.shape)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def crear_modeloFF():\n    model = Sequential() \n    model.add(Dense(PASOS, input_shape=(1,PASOS),activation='tanh'))\n    model.add(Flatten())\n    model.add(Dense(1, activation='tanh'))\n    model.compile(loss='mean_absolute_error',optimizer='Adam',metrics=[\"mse\"])\n    model.summary()\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS=40\n \nmodel = crear_modeloFF()\n \nhistory=model.fit(x_train,y_train,epochs=EPOCHS,validation_data=(x_val,y_val),batch_size=PASOS)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test= X_test[7:] #Delete first 7 days of data test.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results=model.predict(x_val)\nf, ax = plt.subplots(1)\nf.set_figheight(5)\nf.set_figwidth(15)\nplt.scatter(X_train['ds'], y_train, c= 'b')\nplt.scatter(X_test['ds'],y_val,c='g')\nplt.scatter(X_test['ds'],results,c='r')\nplt.title('validate')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f, ax = plt.subplots(1)\nf.set_figheight(5)\nf.set_figwidth(15)\n# summarize history for accuracy\nplt.plot(history.history['mse'])\nplt.plot(history.history['val_mse'])\nplt.title('model mse')\nplt.ylabel('mse')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f, ax = plt.subplots(1)\nf.set_figheight(5)\nf.set_figwidth(15)\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}