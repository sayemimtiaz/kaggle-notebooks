{"cells":[{"metadata":{"trusted":false},"cell_type":"code","source":"import os\nimport glob\nimport shutil\nimport json\nimport tensorflow.keras as k\nimport itertools\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom tensorflow.keras import backend as K\nimport tensorflow as tf\nfrom PIL import Image\nfrom tensorflow.keras.preprocessing.image import img_to_array\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import StratifiedKFold\nfrom tensorflow.keras.models import Sequential,Model\nfrom tensorflow.keras.optimizers import RMSprop, Adam\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.applications import ResNet152V2\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.applications import EfficientNetB4\nfrom tensorflow.keras.applications import InceptionResNetV2\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Flatten, Dense, Dropout\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nimport warnings\nfrom tensorflow.keras.applications.nasnet import NASNetLarge\nwarnings.filterwarnings(\"ignore\")\n# !pip install -U efficientnet\n# import efficientnet.tfkeras as efn\nfrom tensorflow.keras.mixed_precision import experimental as mixed_precision\npolicy = mixed_precision.Policy('mixed_float16')\nmixed_precision.set_policy(policy)\n# cwd = os.getcwd()\n# os.chdir('../input/bitempered-logistic-loss-direct-upload/')\n# from tf_bi_tempered_loss import BiTemperedLogisticLoss\n# os.chdir(cwd)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data_path = '../input/hackerearth-deep-learning-challenge-holidayseason/dataset/'\ndata = pd.read_csv(data_path + 'train.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data['Class'].value_counts().plot.pie(figsize=(5,5))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"BATCH_SIZE = 32\nEPOCHS = 10\nn_CLASS = 6\nIMG_SIZE = 150\nsize = (IMG_SIZE,IMG_SIZE)\ntrain_path = data_path + 'train/'\ntest_path = data_path + 'test/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train,val = train_test_split(data, test_size = 0.1, random_state = 7, stratify = data['Class'])\nprint(f\"The train size : {train.shape} \\nThe Validation size : {val.shape}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# ADD rescale=1./255 AFTERWARDS\n# prep_func = tf.keras.applications.resnet50.preprocess_input\n\ndatagen_train = ImageDataGenerator(\n#                     preprocessing_function = prep_func,\n                    rescale=1./255,\n                    rotation_range = 40,\n                    width_shift_range = 0.2,\n                    height_shift_range = 0.2,\n                    shear_range = 0.2,\n                    zoom_range = 0.2,\n                    horizontal_flip = True,\n                    vertical_flip = True,\n                    fill_mode = 'nearest')\n\ndatagen_val = ImageDataGenerator(\n                        rescale=1./255,\n#                         preprocessing_function = prep_func,\n                        )\n\ntrain_set = datagen_train.flow_from_dataframe(train,\n                                 directory = train_path,\n                                 seed=7,\n                                 x_col = 'Image',\n                                 y_col = 'Class',\n                                 target_size = size,\n                                 class_mode = 'categorical',\n#                                  interpolation = 'nearest',\n                                 shuffle = True,\n                                 batch_size = int(BATCH_SIZE))\n\nval_set = datagen_val.flow_from_dataframe(val,\n                                 directory = train_path,\n                                 seed=7,\n                                 x_col = 'Image',\n                                 y_col = 'Class',\n                                 target_size = size,\n                                 #color_mode=\"rgb\",\n                                 class_mode = 'categorical',\n#                                  interpolation = 'nearest',\n                                 shuffle = True,\n                                 batch_size = BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def create_model_efficientnetb0():\n\n        model = Sequential()\n        \n        e = efn.EfficientNetB0(input_shape = (IMG_SIZE, IMG_SIZE, 3), include_top = False, weights = 'imagenet')\n        for l in e.layers[:-5]:\n            l.trainable = False\n        model.add(e)\n        model.add(GlobalAveragePooling2D())\n#         model.add(Flatten())\n#         model.add(Dense(8, activation = 'relu', bias_regularizer=tf.keras.regularizers.L1L2(l1=0.01, l2=0.001)))\n#         model.add(Dropout(0.5))\n        model.add(Dense(n_CLASS, activation = 'softmax',dtype='float32'))\n\n        return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def create_model_efficientnetb4():\n\n        model = Sequential()\n        \n        e = efn.EfficientNetB4(input_shape = (IMG_SIZE, IMG_SIZE, 3), include_top = False, weights = 'imagenet')\n        for l in e.layers[:-5]:\n            l.trainable = False\n        model.add(e)\n        model.add(GlobalAveragePooling2D())\n#         model.add(Flatten())\n#         model.add(Dense(8, activation = 'relu', bias_regularizer=tf.keras.regularizers.L1L2(l1=0.01, l2=0.001)))\n#         model.add(Dropout(0.5))\n        model.add(Dense(n_CLASS, activation = 'softmax',dtype='float32'))\n\n        return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def create_model_resnet50():\n\n        model = Sequential()\n        \n        e = ResNet50(input_shape = (IMG_SIZE, IMG_SIZE, 3), include_top = False, weights = 'imagenet',pooling='avg')\n#         for l in e.layers:\n#             l.trainable = False\n        e.layers[0].trainable = False\n        model.add(e)\n#         model.add(GlobalAveragePooling2D())\n#         model.add(Flatten())\n#         model.add(Dense(8, activation = 'relu', bias_regularizer=tf.keras.regularizers.L1L2(l1=0.01, l2=0.001)))\n#         model.add(Dropout(0.5))\n        model.add(Dense(n_CLASS, activation = 'softmax',dtype='float32'))\n\n        return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def create_model_inceptionresnet():\n\n        model = Sequential()\n        \n        e = InceptionResNetV2(input_shape = (IMG_SIZE, IMG_SIZE, 3), include_top = False, weights = 'imagenet')\n        for layer in e.layers[:-14]:\n    #print(l)\n            layer.trainable = False\n        model.add(e)\n\n        return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def create_model_nasnetL():\n\n        model = Sequential()\n        \n        e = NASNetLarge(input_shape = (IMG_SIZE, IMG_SIZE, 3), include_top = False, weights = 'imagenet')\n        for layer in e.layers[:-14]:\n    #print(l)\n            layer.trainable = False\n        model.add(e)\n\n        return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def create_model_vgg16():\n\n        model = Sequential()\n        \n        e = VGG16(input_shape = (IMG_SIZE, IMG_SIZE, 3), include_top = False, weights = 'imagenet')\n        for layer in e.layers[:-14]:\n    #print(l)\n            layer.trainable = False\n        model.add(e)\n\n        return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model_resnet152v2():\n\n        model = Sequential()\n        \n        e = ResNet152V2(input_shape = (IMG_SIZE, IMG_SIZE, 3), include_top = False, weights = 'imagenet')\n        for layer in e.layers[:-14]:\n    #print(l)\n            layer.trainable = False\n        model.add(e)\n\n        return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"loss = tf.keras.losses.CategoricalCrossentropy(from_logits = False,\n                                                   label_smoothing=0.0001,\n                                                   name='categorical_crossentropy' )\nes = EarlyStopping(monitor='val_loss', mode='min', patience=3,\n                   restore_best_weights=True, verbose=1)\ncheckpoint_cb = ModelCheckpoint(\"INCEPTIONRESNETV2.h5\",\n                                save_best_only=True,\n                                monitor = 'val_loss',\n                                mode='min')\nreduce_lr = ReduceLROnPlateau(monitor = 'val_loss',\n                              factor = 0.2,\n                              patience = 1,\n                              min_lr = 0.0001,\n                              mode = 'min',\n                              verbose = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"e = create_model_inceptionresnet()\nmodel = Sequential()\nmodel.add(e)\nmodel.add(GlobalAveragePooling2D())\nmodel.add(Dense(1024,activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(512,activation='relu'))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(256,activation='relu'))\nmodel.add(Dense(6,activation='softmax',dtype='float32'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model.compile(optimizer = Adam(learning_rate = 1e-3),\n                    loss = loss, #'categorical_crossentropy'\n                    metrics = ['accuracy'])\nhistory = model.fit(x = train_set,\n                         validation_data = val_set,\n                         epochs= EPOCHS,\n                         batch_size = BATCH_SIZE,\n                         #class_weight = d_class_weights,\n#                          steps_per_epoch = STEP_SIZE_TRAIN,\n#                          validation_steps = STEP_SIZE_VALID,\n                         callbacks=[es, checkpoint_cb, reduce_lr]\n                   )","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"classes = (train_set.class_indices)\nclasses = dict((v,k) for k,v in classes.items())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"best_model = k.models.load_model('INCEPTIONRESNETV2.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"predictions = []\nname = []\ns=0\n# classes = list(data['Class'].unique())\n# single_test_path = data_path + 'single_img/'\ntest_images = os.listdir(test_path)\nfor image in test_images:\n    img = Image.open(test_path + image)\n    img = img.convert('RGB')\n    img = img.resize(size)\n    img = img_to_array(img)/255\n    img = np.expand_dims(img, axis=0)\n    pred  = best_model.predict(img)\n    predictions.append(classes[np.argmax(pred[0])])\n    name.append(image)\n    s+=1\n    if s%100==0:\n        print(f\"{s} Images' Prediction Done\")\n    \n\nsub = pd.DataFrame({'Image': test_images, 'Class': predictions})\nsub.to_csv('submission.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Fine- tuning"},{"metadata":{"trusted":false},"cell_type":"code","source":"for i in best_model.layers:\n    i.trainable = True\n    \ncheckpoint_cb = ModelCheckpoint(\"INCEPTIONRESNETV2_ft.h5\",\n                                save_best_only=True,\n                                monitor = 'val_loss',\n                                mode='min')\nbest_model.compile(optimizer = Adam(learning_rate = 1e-4),\n                    loss = loss, #'categorical_crossentropy'\n                    metrics = ['accuracy'])\nhistory = best_model.fit(x = train_set,\n                         validation_data = val_set,\n                         epochs= EPOCHS,\n                         batch_size = BATCH_SIZE,\n                         #class_weight = d_class_weights,\n#                          steps_per_epoch = STEP_SIZE_TRAIN,\n#                          validation_steps = STEP_SIZE_VALID,\n                         callbacks=[es, checkpoint_cb, reduce_lr]\n                   )","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}