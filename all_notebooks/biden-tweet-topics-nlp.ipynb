{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport matplotlib as mp\nimport scipy\nimport scipy.stats\nimport tensorflow as tf\n#import tensorflow_hub as hub\nimport json\nimport pickle\nimport urllib\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelBinarizer\n\nprint(tf.__version__)\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\nfrom wordcloud import WordCloud, STOPWORDS","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"path = os.path.join(dirname, filename)\ndf = pd.read_csv(path) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=df.tweet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wc=WordCloud(width=200,height=100,background_color='black',stopwords=STOPWORDS\n            ).generate(str(data))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Main wordcloud"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig=plt.figure(figsize=(10,10),facecolor='k',edgecolor='w')\nplt.imshow(wc,interpolation='bicubic')\nplt.axis(\"off\")\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig=plt.figure(figsize=(15,15),facecolor='k',edgecolor='w')\nplt.imshow(wc,interpolation='bicubic')\nplt.axis(\"off\")\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.corpus import stopwords\n\nfrom nltk.stem.wordnet import WordNetLemmatizer\n\nimport string\nimport gensim\nfrom gensim import corpora","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Clean and Lemmatize into a document"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stop = set(stopwords.words('english'))\n\nexclude = set(string.punctuation)\n\nlemmma= WordNetLemmatizer() #base word conversion for bbetter tuning and performance\n\ndef clean(doc):\n    stop_free=\" \".join([i for i in doc.lower().split() if i not in stop])\n    punc_free=\"\".join([char for char in stop_free if char not in exclude])\n    normalisation = \" \".join(lemmma.lemmatize(word) for word in punc_free.split(' '))\n    return normalisation\n\ndocument=df.tweet.to_list()\n\n\ndoc_clean=[clean(docu).split() for docu in document ]\n\ndoc_clean[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['tweet_clean']=pd.Series(doc_clean)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dictionary=corpora.Dictionary(doc_clean)\n\nprint(dictionary)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"doc_word_freqcies=[dictionary.doc2bow(term) for term in doc_clean]\ndoc_word_freqcies[:30]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from gensim.models import LdaModel","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Make LDA Model"},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmodel=LdaModel(doc_word_freqcies,num_topics=9,id2word=dictionary,passes=400) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"types= model.show_topics()\nfor t in types:\n    print(t)\n    print('----------------')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diction={}\nfor i in range(6):\n    words=model.show_topic(i,topn=20)\n    #print(words)\n    diction[\"Topic number\" + \"{}\".format(i)]=[i[0] for i in words]\n    \n    \npd.DataFrame(diction)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pyLDAvis.gensim","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Vis=pyLDAvis.gensim.prepare(model,doc_word_freqcies,dictionary,sort_topics=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualize topics"},{"metadata":{"trusted":true},"cell_type":"code","source":"pyLDAvis.display(Vis)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create Corpus: Term Document Frequency\ncorpus = [dictionary.doc2bow(text) for text in doc_clean]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ndef format_topics_sentences(ldamodel=None, corpus=corpus, texts=data):\n    # Init output\n    sent_topics_df = pd.DataFrame()\n\n    # Get main topic in each document\n    for i, row_list in enumerate(ldamodel[corpus]):\n        row = row_list[0] if ldamodel.per_word_topics else row_list            \n        # print(row)\n        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n        # Get the Dominant topic, Perc Contribution and Keywords for each document\n        for j, (topic_num, prop_topic) in enumerate(row):\n            if j == 0:  # => dominant topic\n                wp = ldamodel.show_topic(topic_num)\n                topic_keywords = \", \".join([word for word, prop in wp])\n                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n            else:\n                break\n    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n\n    # Add original text to the end of the output\n    contents = pd.Series(texts)\n    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n    return(sent_topics_df)\n\n\ndf_topic_sents_keywords = format_topics_sentences(ldamodel=model, corpus=corpus, texts=doc_clean)\n\n# Format\ndf_dominant_topic = df_topic_sents_keywords.reset_index()\ndf_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\ndf_dominant_topic.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vc=df_dominant_topic.Dominant_Topic.value_counts()\nvc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#topic 2 and 4  is \n#topic 3 is\n#topic 5 IS \n#topic 1 is\ndic={1.0:\"2\",2.0:\"3\",3.0:\"4\",4.0:\"5\",5.0:\"6\",6.0:'7',0.0:\"1\",8.0:'9',7.0:'8'}\nvc=df_dominant_topic.Dominant_Topic.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dt=df_dominant_topic[[\"Dominant_Topic\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dt.Dominant_Topic=dt.Dominant_Topic.apply(lambda row: dic[row])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(dt.Dominant_Topic.value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## topic classification topic number and its meaning\n\n## 4 racism\n## 6 education\n## 5 gun\n## 8 health care\n## 7 and 2 campaign\n## 3  trump\n## 9 biden\n## 1 positive stuff\n\n\n\n\n## He does talk about stuff related to \n## jobs  too, \n## depending on number of passes \n## and number of topics \n## we might get different results\n## and classifications"},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Topic word cloud"},{"metadata":{"trusted":true},"cell_type":"code","source":"# lda is assumed to be the variable holding the LdaModel object\nimport matplotlib.pyplot as plt\nfor t in range(model.num_topics):\n    plt.figure()\n#   plt.imshow(WordCloud().fit_words(model.show_topic(t, 200)))\n    plt.imshow(WordCloud().fit_words(dict(model.show_topic(t, 200))))\n    plt.axis(\"off\")\n    plt.title(\"Topic #\" + str(t))\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import OrderedDict\n\ndata_lda = {i: OrderedDict(model.show_topic(i,25)) for i in range(6)}\n#data_lda","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\n\ndf_lda = pd.DataFrame(data_lda)\nprint(df_lda.shape)\ndf_lda = df_lda.fillna(0).T\nprint(df_lda.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Word heatmap"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\ng=sns.clustermap(df_lda.corr(), center=0, cmap=\"RdBu\", metric='cosine'\n                 , linewidths=.75, figsize=(10, 10))\nplt.setp(g.ax_heatmap.yaxis.get_majorticklabels(), rotation=0)\nplt.show()\n#plt.setp(ax_heatmap.get_yticklabels(), rotation=0)  # For y axis\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Sentiment analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"from textblob import TextBlob\ndf['pop']=df.tweet_clean.apply(lambda tw: TextBlob(' '.join(tw)).sentiment.polarity)\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['sent']=df['pop'].apply(lambda p: 'positive' if p>0 else  \n                           ( 'negative' if p<0  else 'neutral'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 10))\ndf['Time']=pd.to_datetime(df.timestamp)\nsns.scatterplot(x=df['Time'], y=df['pop'],data=df,hue=df['sent']);\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['year']=df.Time.apply(lambda x:x.year)\ndf.groupby('year')['pop'].describe()['mean'].plot(figsize=(10,10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df.sent.value_counts())\nsns.countplot(x='sent', data = df);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nsns.distplot(df['pop'], bins=30)\nplt.title('Sentiment Distribution',size = 10)\nplt.xlabel('Polarity',size = 10)\nplt.ylabel('Frequency',size = 10)\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count = df.groupby(['year','sent'])['tweet_clean'].count().reset_index().rename(\n    columns={'tweet_clean':'count'})\ncount","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"times = count.year.unique()\nneut=[]\nfor year in count.year.unique():\n    a=count[count['year']==year]\n    if len(list(a[a['sent']=='neutral'].sent))>0:#list(a['sent'].unique()):\n        c=list(a[a['sent']=='neutral']['count'])[0]\n        neut.append(c)\n    else:\n        neut.append(0)\npos = count.loc[count['sent'] == 'positive']['count'].reset_index(drop = True)\n\nneg=[]\nfor year in count.year.unique():\n    a=count[count['year']==year]\n    if len(list(a[a['sent']=='negative'].sent))>0:#list(a['sent'].unique()):\n        c=list(a[a['sent']=='negative']['count'])[0]\n        neg.append(c)\n    else:\n        neg.append(0)                        \nplt.figure(figsize=(10,10))\nplt.xticks(rotation='45')\nlin1=plt.plot(times, pos, 'ro-', label='positive')\nlin2=plt.plot(times, neut, 'g^-', label='neutral')\nlin3=plt.plot(times, neg, 'b--', label='negative')\nplt.legend()\nplt.show","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_dominant_topic.Dominant_Topic.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['topic']=df_dominant_topic.Dominant_Topic","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Make new nlp subset"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_nlp=df[['id','Time','year','topic','pop','sent']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_nlp.topic.value_counts())\nsns.countplot(x='topic', data = df_nlp);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.graph_objs as go\nlabels =['positive stuff','campaign','trump','racism','trump','gun','education','campaign','health care','biden']\nouter_values = df_nlp.topic.value_counts()\ninner_values=pd.Series()\nfor top in df_nlp.topic.unique():\n    df_top=df_nlp[df_nlp['topic']==top]\n    inner_values=inner_values.append(df_top[df_top['sent']=='positive'].value_counts())\n    inner_values=inner_values.append(df_top[df_top['sent']=='negative'].value_counts())\n    inner_values=inner_values.append(df_top[df_top['sent']=='neutral'].value_counts())\ntrace1 = go.Pie(\n    hole=0.5,\n    sort=False,\n    direction='clockwise',\n    domain={'x': [0.15, 0.85], 'y': [0.15, 0.85]},\n    values=inner_values,\n    textinfo='label',\n    textposition='inside',\n    marker={'line': {'color': 'white', 'width': 1}}\n)\ntrace2 = go.Pie(\n    hole=0.7,\n    sort=False,\n    direction='clockwise',\n    values=outer_values,\n    labels=labels,\n    textinfo='label',\n    textposition='outside',\n    marker={'colors': ['green', 'red', 'blue'],\n            'line': {'color': 'white', 'width': 1}}\n)\nfig = go.FigureWidget(data=[trace1, trace2])\nfig\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_nlp.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_nlp['hour']=df_nlp.Time.apply(lambda x:x.hour)\n\n#What time he posts relates with the pop score?\n\ndf_nlp.groupby('hour')['pop'].describe()['mean'].plot(figsize=(10,10))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Time of tweet and topic/sentiment related? i.e is Biden timewise-moody?"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(df_nlp.corr())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Biden ain't timewise-moody hmmm :-(\n## But hey too many posts between 11pm-1am"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_nlp.hour.value_counts()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Now we have dived real deep. What else can we check here?"},{"metadata":{},"cell_type":"markdown","source":"   "},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}