{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Loan Analysis Problem Statement\n\n# 1. Introduction\n\n## What is`LendingClub`? \nA  peer-to-peer lending company, headquartered in San Francisco, California. It was the first peer-to-peer lender to register its offerings as securities with the Securities and Exchange Commission (SEC), and to offer loan trading on a secondary market. `LendingClub` is the world's largest peer-to-peer lending platform.\n\n## How will this case study help you?\n\nSolving this case study can help you in the following ways:\n- Give you an idea about how real business problems are solved using Machine Learning\n- Develop a basic understanding of risk analytics in banking and financial services and understand how data is used to minimise the risk of losing money while lending to customers.\n\n# 2. Business Understanding\n\nYou work for the `LendingClub` company which specialises in lending various types of loans to urban customers. When the company receives a loan application, the company has to make a decision for loan approval based on the applicant’s profile. Two types of risks are associated with the bank’s decision:\n\n- If the applicant is likely to repay the loan, then not approving the loan results in a loss of business to the company\n- If the applicant is not likely to repay the loan, i.e. he/she is likely to default, then approving the loan may lead to a financial loss for the company\n\nThe data given contains the information about past loan applicants and whether they ‘defaulted’ or not. The aim is to identify patterns which indicate if a person is likely to default, which may be used for taking\nactions such as denying the loan, reducing the amount of loan, lending (to risky applicants) at a higher interest rate, etc.\n\nWhen a person applies for a loan, there are two types of decisions that could be taken by the company:\n1. `Loan accepted`: If the company approves the loan, there are 3 possible scenarios described below:\n    - `Fully paid`: Applicant has fully paid the loan (the principal and the interest rate)\n    - `Current`: Applicant is in the process of paying the instalments, i.e. the tenure of the loan is not yet completed. These candidates are not labelled as 'defaulted'.\n    - `Charged-off`: Applicant has not paid the instalments in due time for a long period of time, i.e. he/she has defaulted on the loan\n2. `Loan rejected`: The company had rejected the loan (because the candidate does not meet their requirements etc.). Since the loan was rejected, there is no transactional history of those applicants with the company and so this data is not available with the company (and thus in this dataset)\n\n# 3. Business Objectives\n- `LendingClub` is the largest online loan marketplace, facilitating personal loans, business loans, and financing of medical procedures. Borrowers can easily access lower interest rate loans through a fast online interface. \n- Like most other lending companies, lending loans to ‘`risky`’ applicants is the largest source of financial loss (called `credit loss`). The credit loss is the amount of money lost by the lender when the borrower refuses to pay or runs away with the money owed. In other words, borrowers who defaultcause the largest amount of loss to the lenders. In this case, the customers labelled as '`charged-off`' are the '`defaulters`'. \n- If one is able to identify these risky loan applicants, then such loans can be reduced thereby cutting down the amount of credit loss. Identification of such applicants using EDA and machine learning is the aim of this case study. \n- In other words, the company wants to understand the driving factors (or driver variables) behind loan default, i.e. the variables which are strong indicators of default. The company can utilise this knowledge for its portfolio and risk assessment. \n- To develop your understanding of the domain, you are advised to independently research a little about risk analytics (understanding the types of variables and their significance should be enough).\n\n# 4. Data Description\n\n----\n-----\nHere is the information on this particular data set:\n\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LoanStatNew</th>\n      <th>Description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>loan_amnt</td>\n      <td>The listed amount of the loan applied for by the borrower. If at some point in time, the credit department reduces the loan amount, then it will be reflected in this value.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>term</td>\n      <td>The number of payments on the loan. Values are in months and can be either 36 or 60.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>int_rate</td>\n      <td>Interest Rate on the loan</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>installment</td>\n      <td>The monthly payment owed by the borrower if the loan originates.</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>grade</td>\n      <td>LC assigned loan grade</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>sub_grade</td>\n      <td>LC assigned loan subgrade</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>emp_title</td>\n      <td>The job title supplied by the Borrower when applying for the loan.*</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>emp_length</td>\n      <td>Employment length in years. Possible values are between 0 and 10 where 0 means less than one year and 10 means ten or more years.</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>home_ownership</td>\n      <td>The home ownership status provided by the borrower during registration or obtained from the credit report. Our values are: RENT, OWN, MORTGAGE, OTHER</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>annual_inc</td>\n      <td>The self-reported annual income provided by the borrower during registration.</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>verification_status</td>\n      <td>Indicates if income was verified by LC, not verified, or if the income source was verified</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>issue_d</td>\n      <td>The month which the loan was funded</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>loan_status</td>\n      <td>Current status of the loan</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>purpose</td>\n      <td>A category provided by the borrower for the loan request.</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>title</td>\n      <td>The loan title provided by the borrower</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>zip_code</td>\n      <td>The first 3 numbers of the zip code provided by the borrower in the loan application.</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>addr_state</td>\n      <td>The state provided by the borrower in the loan application</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>dti</td>\n      <td>A ratio calculated using the borrower’s total monthly debt payments on the total debt obligations, excluding mortgage and the requested LC loan, divided by the borrower’s self-reported monthly income.</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>earliest_cr_line</td>\n      <td>The month the borrower's earliest reported credit line was opened</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>open_acc</td>\n      <td>The number of open credit lines in the borrower's credit file.</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>pub_rec</td>\n      <td>Number of derogatory public records</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>revol_bal</td>\n      <td>Total credit revolving balance</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>revol_util</td>\n      <td>Revolving line utilization rate, or the amount of credit the borrower is using relative to all available revolving credit.</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>total_acc</td>\n      <td>The total number of credit lines currently in the borrower's credit file</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>initial_list_status</td>\n      <td>The initial listing status of the loan. Possible values are – W, F</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>application_type</td>\n      <td>Indicates whether the loan is an individual application or a joint application with two co-borrowers</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>mort_acc</td>\n      <td>Number of mortgage accounts.</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>pub_rec_bankruptcies</td>\n      <td>Number of public record bankruptcies</td>\n    </tr>\n  </tbody>\n</table>\n\n---\n----","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nplt.style.use(\"fivethirtyeight\")\nsns.set_style('whitegrid')\n%matplotlib inline\n\npd.set_option('display.float', '{:.2f}'.format)\npd.set_option('display.max_columns', 50)\npd.set_option('display.max_rows', 50)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:51:09.717527Z","iopub.execute_input":"2021-05-25T12:51:09.71791Z","iopub.status.idle":"2021-05-25T12:51:10.749097Z","shell.execute_reply.started":"2021-05-25T12:51:09.717875Z","shell.execute_reply":"2021-05-25T12:51:10.748044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/lending-club-dataset/lending_club_loan_two.csv\")\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:51:12.279848Z","iopub.execute_input":"2021-05-25T12:51:12.280246Z","iopub.status.idle":"2021-05-25T12:51:15.928166Z","shell.execute_reply.started":"2021-05-25T12:51:12.280214Z","shell.execute_reply":"2021-05-25T12:51:15.927079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Exploratory Data Analysis\n\n**OVERALL GOAL:** \n- Get an understanding for which variables are important, view summary statistics, and visualize the data","metadata":{}},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### `loan_status`","metadata":{}},{"cell_type":"code","source":"sns.countplot(data.loan_status)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 8))\nsns.heatmap(data.corr(), annot=True, cmap='viridis')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We noticed almost perfect correlation between \"`loan_amnt`\" the \"`installment`\" feature. We'll explore this features further. Print out their descriptions and perform a scatterplot between them. \n\n- Does this relationship make sense to you? \n- Do we think there is duplicate information here?","metadata":{}},{"cell_type":"markdown","source":"### `loan_amnt` & `installment`","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12, 20))\n\nplt.subplot(4, 2, 1)\ndata[data[\"loan_status\"] == \"Fully Paid\"][\"installment\"].hist(bins=35, color='blue', label='loan_status = Fully Paid', alpha=0.8)\ndata[data[\"loan_status\"] == \"Charged Off\"][\"installment\"].hist(bins=35, color='red', label='loan_status = Charged Off', alpha=0.8)\nplt.legend()\nplt.xlabel(\"installment\")\n\nplt.subplot(4, 2, 2)\ndata[data[\"loan_status\"] == \"Fully Paid\"][\"loan_amnt\"].hist(bins=35, color='blue', label='loan_status = Fully Paid', alpha=0.8)\ndata[data[\"loan_status\"] == \"Charged Off\"][\"loan_amnt\"].hist(bins=35, color='red', label='loan_status = Charged Off', alpha=0.8)\nplt.legend()\nplt.xlabel(\"loan_amnt\")\n\nplt.subplot(4, 2, 3)\nsns.scatterplot(x='installment', y='loan_amnt', data=data)\n\nplt.subplot(4, 2, 4)\nsns.boxplot(x='loan_status', y='loan_amnt', data=data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.groupby(by='loan_status')['loan_amnt'].describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### `grade` & `sub_grade`\nLet's explore the Grade and SubGrade columns that LendingClub attributes to the loans. \n\nWhat are the unique possible `grade` & `sub_grade`?","metadata":{}},{"cell_type":"code","source":"print(f\"GRADE unique: {data.grade.unique()}\")\nprint(f\"SUB_GRADE unique: {data.sub_grade.unique()}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15, 10))\n\nplt.subplot(2, 2, 1)\ngrade = sorted(data.grade.unique().tolist())\nsns.countplot(x='grade', data=data, hue='loan_status', order=grade)\n\nplt.subplot(2, 2, 2)\nsub_grade = sorted(data.sub_grade.unique().tolist())\ng = sns.countplot(x='sub_grade', data=data, hue='loan_status', order=sub_grade)\ng.set_xticklabels(g.get_xticklabels(), rotation=90);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It looks like `F` and `G` subgrades don't get paid back that often. Isloate those and recreate the countplot just for those subgrades.","metadata":{}},{"cell_type":"code","source":"df = data[(data.grade == 'F') | (data.grade == 'G')]\n\nplt.figure(figsize=(15, 10))\n\nplt.subplot(2, 2, 1)\ngrade = sorted(df.grade.unique().tolist())\nsns.countplot(x='grade', data=df, hue='loan_status', order=grade)\n\nplt.subplot(2, 2, 2)\nsub_grade = sorted(df.sub_grade.unique().tolist())\nsns.countplot(x='sub_grade', data=df, hue='loan_status', order=sub_grade)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### `term`, `home_ownership`, `verification_status` & `purpose`","metadata":{}},{"cell_type":"code","source":"data.home_ownership.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.loc[(data.home_ownership == 'ANY') | (data.home_ownership == 'NONE'), 'home_ownership'] = 'OTHER'  \ndata.home_ownership.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15, 20))\n\nplt.subplot(4, 2, 1)\nsns.countplot(x='term', data=data, hue='loan_status')\n\nplt.subplot(4, 2, 2)\nsns.countplot(x='home_ownership', data=data, hue='loan_status')\n\nplt.subplot(4, 2, 3)\nsns.countplot(x='verification_status', data=data, hue='loan_status')\n\nplt.subplot(4, 2, 4)\ng = sns.countplot(x='purpose', data=data, hue='loan_status')\ng.set_xticklabels(g.get_xticklabels(), rotation=90);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### `int_rate` & `annual_inc`","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15, 10))\n\nplt.subplot(2, 2, 1)\ndata[data[\"loan_status\"] == \"Fully Paid\"][\"int_rate\"].hist(bins=35, color='blue', label='loan_status = Fully Paid', alpha=0.6)\ndata[data[\"loan_status\"] == \"Charged Off\"][\"int_rate\"].hist(bins=35, color='red', label='loan_status = Charged Off', alpha=0.6)\nplt.legend()\nplt.xlabel(\"int_rate\")\n\nplt.subplot(2, 2, 2)\ndata[data[\"loan_status\"] == \"Fully Paid\"][\"annual_inc\"].hist(bins=8, color='blue', label='loan_status = Fully Paid', alpha=0.6)\ndata[data[\"loan_status\"] == \"Charged Off\"][\"annual_inc\"].hist(bins=8, color='red', label='loan_status = Charged Off', alpha=0.6)\nplt.legend()\nplt.xlabel(\"annual_inc\")\n\ndf[\"annual_inc\"].head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Extract more info from the annual_inc hist by limiting the range and increasing the bins\n\nplt.figure(figsize=(15, 10))\n\nplt.subplot(2, 2, 2)\ndata[data[\"loan_status\"] == \"Fully Paid\"][\"annual_inc\"].hist(bins=100, color='blue', label='loan_status = Fully Paid', alpha=0.6)\ndata[data[\"loan_status\"] == \"Charged Off\"][\"annual_inc\"].hist(bins=100, color='red', label='loan_status = Charged Off', alpha=0.6)\nplt.legend()\nplt.xlabel(\"annual_inc\")\nplt.xlim([0, 500000])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[data.annual_inc >= 1000000].shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- It seems that loans with high intersest rate are more likely to be unpaid.\n- Only 75 borrowers have an annual income more than 1 million.","metadata":{}},{"cell_type":"markdown","source":"### `emp_title` & `emp_length`","metadata":{}},{"cell_type":"code","source":"data.emp_title.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['emp_title'] = data.emp_title.str.lower()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def manager(string):\n    if type(string) is str:\n        return 'manager' if 'manager' in string else string\n\ndef president(string):\n    if type(string) is str:\n        return 'president' if 'president' in string else string\n    \ndef nurse(string):\n    if type(string) is str:\n        return 'nurse' if 'nurse' in string else string\n    \ndef driver(string):\n    if type(string) is str:\n        return 'driver' if 'driver' in string else string\n    \ndef assistant(string):\n    if type(string) is str:\n        return 'assistant' if 'assistant' in string else string\n\ndef engineer(string):\n    if type(string) is str:\n        return 'engineer' if 'engineer' in string else string    \n\nfunctions = [manager, president, nurse, driver, assistant, engineer]\nfor func in functions:\n    data['emp_title'] = data.emp_title.apply(func)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.emp_title.value_counts()[:30]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15, 12))\n\nplt.subplot(2, 2, 1)\norder = ['< 1 year', '1 year', '2 years', '3 years', '4 years', '5 years', \n          '6 years', '7 years', '8 years', '9 years', '10+ years',]\nsns.countplot(x='emp_length', data=data, hue='loan_status', order=order)\n\nplt.subplot(2, 2, 2)\nplt.barh(data.emp_title.value_counts()[:30].index, data.emp_title.value_counts()[:30])\nplt.title(\"The most 30 jobs title afforded a loan\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### `issue_d`, `earliest_cr_line`","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15, 12))\n\nplt.subplot(2, 2, 1)\ndata.issue_d.value_counts().sort_index().plot()\n\nplt.subplot(2, 2, 2)\ndata.earliest_cr_line.value_counts().sort_index().plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### `title`","metadata":{}},{"cell_type":"code","source":"data.title.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['title'] = data.title.str.lower()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.title.value_counts()[:30]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"`title` will be removed because we have the `purpose` column with is generated from it.","metadata":{}},{"cell_type":"markdown","source":"### `dti`, `open_acc`, `revol_bal`, `revol_util`, & `total_acc`","metadata":{}},{"cell_type":"code","source":"data.dti.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[data.open_acc > 40].shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[data.total_acc > 80].shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[data.revol_bal < 10000].shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[data.revol_util > 200]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15, 30))\n\nplt.subplot(6, 2, 1)\ndata[data[\"loan_status\"] == \"Fully Paid\"][\"dti\"].value_counts().hist(bins=35, color='blue', \n                                                                     label='loan_status = Fully Paid', alpha=0.6)\ndata[data[\"loan_status\"] == \"Charged Off\"][\"dti\"].value_counts().hist(bins=35, color='red', \n                                                                      label='loan_status = Charged Off', alpha=0.6)\nplt.legend()\nplt.xlabel(\"dti\")\n\nplt.subplot(6, 2, 2)\ndata[data[\"loan_status\"] == \"Fully Paid\"][\"open_acc\"].hist(bins=35, color='blue', label='loan_status = Fully Paid', alpha=0.6)\ndata[data[\"loan_status\"] == \"Charged Off\"][\"open_acc\"].hist(bins=35, color='red', label='loan_status = Charged Off', alpha=0.6)\nplt.legend()\nplt.xlabel(\"open_acc\")\n\nplt.subplot(6, 2, 3)\ndf = data[(data.revol_bal <= 10000)]\ndf[df[\"loan_status\"] == \"Fully Paid\"][\"revol_bal\"].hist(bins=35, color='blue', label='loan_status = Fully Paid', alpha=0.6)\ndf[df[\"loan_status\"] == \"Charged Off\"][\"revol_bal\"].hist(bins=35, color='red', label='loan_status = Charged Off', alpha=0.6)\nplt.legend()\nplt.xlabel(\"revol_bal\")\n\nplt.subplot(6, 2, 4)\ndata[data[\"loan_status\"] == \"Fully Paid\"][\"revol_util\"].hist(bins=35, color='blue', label='loan_status = Fully Paid', alpha=0.6)\ndata[data[\"loan_status\"] == \"Charged Off\"][\"revol_util\"].hist(bins=35, color='red', label='loan_status = Charged Off', alpha=0.6)\nplt.legend()\nplt.xlabel(\"revol_util\")\n\nplt.subplot(6, 2, 5)\ndf = data[(data.revol_bal <= 10000)]\ndf[df[\"loan_status\"] == \"Fully Paid\"][\"total_acc\"].hist(bins=35, color='blue', label='loan_status = Fully Paid', alpha=0.6)\ndf[df[\"loan_status\"] == \"Charged Off\"][\"total_acc\"].hist(bins=35, color='red', label='loan_status = Charged Off', alpha=0.6)\nplt.legend()\nplt.xlabel(\"total_acc\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- It seems that the smaller the `dti` the more likely that the loan will not be paid.\n- Only `217` borrower have more than `40` open credit lines.\n- Only `266` borrower have more than `80` credit line in the borrower credit file.","metadata":{}},{"cell_type":"markdown","source":"### `pub_rec`, `initial_list_status`, `application_type`, `mort_acc`, & `pub_rec_bankruptcies`","metadata":{}},{"cell_type":"code","source":"data.pub_rec.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.initial_list_status.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.application_type.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.mort_acc.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.pub_rec_bankruptcies.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pub_rec(number):\n    if number == 0.0:\n        return 0\n    else:\n        return 1\n    \ndef mort_acc(number):\n    if number == 0.0:\n        return 0\n    elif number >= 1.0:\n        return 1\n    else:\n        return number\n    \ndef pub_rec_bankruptcies(number):\n    if number == 0.0:\n        return 0\n    elif number >= 1.0:\n        return 1\n    else:\n        return number","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['pub_rec'] = data.pub_rec.apply(pub_rec)\ndata['mort_acc'] = data.mort_acc.apply(mort_acc)\ndata['pub_rec_bankruptcies'] = data.pub_rec_bankruptcies.apply(pub_rec_bankruptcies)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 30))\n\nplt.subplot(6, 2, 1)\nsns.countplot(x='pub_rec', data=data, hue='loan_status')\n\nplt.subplot(6, 2, 2)\nsns.countplot(x='initial_list_status', data=data, hue='loan_status')\n\nplt.subplot(6, 2, 3)\nsns.countplot(x='application_type', data=data, hue='loan_status')\n\nplt.subplot(6, 2, 4)\nsns.countplot(x='mort_acc', data=data, hue='loan_status')\n\nplt.subplot(6, 2, 5)\nsns.countplot(x='pub_rec_bankruptcies', data=data, hue='loan_status')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## How numeric features correlate with the target variable?","metadata":{}},{"cell_type":"code","source":"data['loan_status'] = data.loan_status.map({'Fully Paid':0, 'Charged Off':1})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8, 5))\ndata.corr()['loan_status'].drop('loan_status').sort_values().plot(kind='barh')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****\n## Conclusion:\n\nWe notice that, there are broadly three types of features: \n- 1. Features related to the applicant (demographic variables such as occupation, employment details etc.), \n- 2. Features related to loan characteristics (amount of loan, interest rate, purpose of loan etc.) \n****","metadata":{}},{"cell_type":"markdown","source":"# 6. Data PreProcessing\n\n**Section Goals:** \n- Remove or fill any missing data. \n- Remove unnecessary or repetitive features. \n- Convert categorical string features to dummy variables.","metadata":{}},{"cell_type":"code","source":"# The length of the data\nprint(f\"The Length of the data: {data.shape}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Missing values\nfor column in data.columns:\n    if data[column].isna().sum() != 0:\n        missing = data[column].isna().sum()\n        portion = (missing / data.shape[0]) * 100\n        print(f\"'{column}': number of missing values '{missing}' ==> '{portion:.3f}%'\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### `emp_title`","metadata":{}},{"cell_type":"code","source":"data.emp_title.nunique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Realistically there are too many unique job titles to try to convert this to a dummy variable feature. Let's remove that emp_title column.","metadata":{}},{"cell_type":"code","source":"data.drop('emp_title', axis=1, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### `emp_length`","metadata":{}},{"cell_type":"code","source":"data.emp_length.unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for year in data.emp_length.unique():\n    print(f\"{year} years in this position:\")\n    print(f\"{data[data.emp_length == year].loan_status.value_counts(normalize=True)}\")\n    print('==========================================')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Charge off rates are extremely similar across all employment lengths. So we are going to drop the `emp_length` column.","metadata":{}},{"cell_type":"code","source":"data.drop('emp_length', axis=1, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### `title`","metadata":{}},{"cell_type":"code","source":"data.title.value_counts().head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.purpose.value_counts().head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The title column is simply a string subcategory/description of the purpose column. So we are going to drop the title column.","metadata":{}},{"cell_type":"code","source":"data.drop('title', axis=1, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### `mort_acc`\n\nThere are many ways we could deal with this missing data. We could attempt to build a simple model to fill it in, such as a linear model, we could just fill it in based on the mean of the other columns, or you could even bin the columns into categories and then set NaN as its own category. There is no 100% correct approach! \n\nLet's review the other columsn to see which most highly correlates to mort_acc","metadata":{}},{"cell_type":"code","source":"data.mort_acc.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.mort_acc.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8, 5))\ndata.corr()['mort_acc'].drop('mort_acc').sort_values().plot(kind='barh')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Looks like the total_acc feature correlates with the mort_acc , this makes sense! Let's try this fillna() approach. We will group the dataframe by the total_acc and calculate the mean value for the mort_acc per total_acc entry. To get the result below:","metadata":{}},{"cell_type":"code","source":"total_acc_avg = data.groupby(by='total_acc').mean().mort_acc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fill_mort_acc(total_acc, mort_acc):\n    if np.isnan(mort_acc):\n        return total_acc_avg[total_acc].round()\n    else:\n        return mort_acc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['mort_acc'] = data.apply(lambda x: fill_mort_acc(x['total_acc'], x['mort_acc']), axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### `revol_util` & `pub_rec_bankruptcies`\nThese two features have missing data points, but they account for less than 0.5% of the total data. So we are going to remove the rows that are missing those values in those columns with dropna().","metadata":{}},{"cell_type":"code","source":"for column in data.columns:\n    if data[column].isna().sum() != 0:\n        missing = data[column].isna().sum()\n        portion = (missing / data.shape[0]) * 100\n        print(f\"'{column}': number of missing values '{missing}' ==> '{portion:.3f}%'\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.dropna(inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Categorical Variables and Dummy Variables","metadata":{}},{"cell_type":"code","source":"print([column for column in data.columns if data[column].dtype == object])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### `term`","metadata":{}},{"cell_type":"code","source":"data.term.unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"term_values = {' 36 months': 36, ' 60 months': 60}\ndata['term'] = data.term.map(term_values)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.term.unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### `grade` & `sub_grade`\n\nWe know that `grade` is just a sub feature of `sub_grade`, So we are goinig to drop it.","metadata":{}},{"cell_type":"code","source":"data.drop('grade', axis=1, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dummies = ['sub_grade', 'verification_status', 'purpose', 'initial_list_status', \n           'application_type', 'home_ownership']\ndata = pd.get_dummies(data, columns=dummies, drop_first=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### `address`\nWe are going to feature engineer a zip code column from the address in the data set. Create a column called 'zip_code' that extracts the zip code from the address column.","metadata":{}},{"cell_type":"code","source":"data.address.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['zip_code'] = data.address.apply(lambda x: x[-5:])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.zip_code.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.get_dummies(data, columns=['zip_code'], drop_first=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.drop('address', axis=1, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### `issue_d` \n\nThis would be data leakage, we wouldn't know beforehand whether or not a loan would be issued when using our model, so in theory we wouldn't have an issue_date, drop this feature.","metadata":{}},{"cell_type":"code","source":"data.drop('issue_d', axis=1, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### `earliest_cr_line`\nThis appears to be a historical time stamp feature. Extract the year from this feature using a `.apply()` function, then convert it to a numeric feature.","metadata":{}},{"cell_type":"code","source":"data['earliest_cr_line'] = data.earliest_cr_line.str.split('-', expand=True)[1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.earliest_cr_line.nunique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Check for duplicates columns & features","metadata":{}},{"cell_type":"code","source":"# print(f\"Data shape: {data.shape}\")\n\n# # Remove duplicate Features\n# data = data.T.drop_duplicates()\n# data = data.T\n\n# # Remove Duplicate Rows\n# data.drop_duplicates(inplace=True)\n\n# print(f\"Data shape: {data.shape}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train Test Split","metadata":{}},{"cell_type":"code","source":"w_p = data.loan_status.value_counts()[0] / data.shape[0]\nw_n = data.loan_status.value_counts()[1] / data.shape[0]\n\nprint(f\"Weight of positive values {w_p}\")\nprint(f\"Weight of negative values {w_n}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.preprocessing import MinMaxScaler\n\n\nX = data.drop('loan_status', axis=1)\ny = data.loan_status\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Normalizing the data","metadata":{}},{"cell_type":"code","source":"scaler = MinMaxScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 7. Models Building","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom sklearn.metrics import roc_auc_score, roc_curve, auc\n\ndef print_score(true, pred, train=True):\n    if train:\n        clf_report = pd.DataFrame(classification_report(true, pred, output_dict=True))\n        print(\"Train Result:\\n================================================\")\n        print(f\"Accuracy Score: {accuracy_score(true, pred) * 100:.2f}%\")\n        print(\"_______________________________________________\")\n        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n        print(\"_______________________________________________\")\n        print(f\"Confusion Matrix: \\n {confusion_matrix(true, pred)}\\n\")\n        \n    elif train==False:\n        clf_report = pd.DataFrame(classification_report(true, pred, output_dict=True))\n        print(\"Test Result:\\n================================================\")        \n        print(f\"Accuracy Score: {accuracy_score(true, pred) * 100:.2f}%\")\n        print(\"_______________________________________________\")\n        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n        print(\"_______________________________________________\")\n        print(f\"Confusion Matrix: \\n {confusion_matrix(true, pred)}\\n\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = np.array(X_train).astype(np.float32)\nX_test = np.array(X_test).astype(np.float32)\ny_train = np.array(y_train).astype(np.float32)\ny_test = np.array(y_test).astype(np.float32)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 7. 1. Artificial Neural Networks (ANNs)","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import AUC","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate_nn(true, pred, train=True):\n    if train:\n        clf_report = pd.DataFrame(classification_report(true, pred, output_dict=True))\n        print(\"Train Result:\\n================================================\")\n        print(f\"Accuracy Score: {accuracy_score(true, pred) * 100:.2f}%\")\n        print(\"_______________________________________________\")\n        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n        print(\"_______________________________________________\")\n        print(f\"Confusion Matrix: \\n {confusion_matrix(true, pred)}\\n\")\n        \n    elif train==False:\n        clf_report = pd.DataFrame(classification_report(true, pred, output_dict=True))\n        print(\"Test Result:\\n================================================\")        \n        print(f\"Accuracy Score: {accuracy_score(true, pred) * 100:.2f}%\")\n        print(\"_______________________________________________\")\n        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n        print(\"_______________________________________________\")\n        print(f\"Confusion Matrix: \\n {confusion_matrix(true, pred)}\\n\")\n        \ndef plot_learning_evolution(r):\n    plt.figure(figsize=(12, 8))\n    \n    plt.subplot(2, 2, 1)\n    plt.plot(r.history['loss'], label='Loss')\n    plt.plot(r.history['val_loss'], label='val_Loss')\n    plt.title('Loss evolution during trainig')\n    plt.legend()\n\n    plt.subplot(2, 2, 2)\n    plt.plot(r.history['AUC'], label='AUC')\n    plt.plot(r.history['val_AUC'], label='val_AUC')\n    plt.title('AUC score evolution during trainig')\n    plt.legend();\n\ndef nn_model(num_columns, num_labels, hidden_units, dropout_rates, learning_rate):\n    inp = tf.keras.layers.Input(shape=(num_columns, ))\n    x = BatchNormalization()(inp)\n    x = Dropout(dropout_rates[0])(x)\n    for i in range(len(hidden_units)):\n        x = Dense(hidden_units[i], activation='relu')(x)\n        x = BatchNormalization()(x)\n        x = Dropout(dropout_rates[i + 1])(x)\n    x = Dense(num_labels, activation='sigmoid')(x)\n  \n    model = Model(inputs=inp, outputs=x)\n    model.compile(optimizer=Adam(learning_rate), loss='binary_crossentropy', metrics=[AUC(name='AUC')])\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_columns = X_train.shape[1]\nnum_labels = 1\nhidden_units = [150, 150, 150]\ndropout_rates = [0.1, 0, 0.1, 0]\nlearning_rate = 1e-3\n\n\nmodel = nn_model(\n    num_columns=num_columns, \n    num_labels=num_labels,\n    hidden_units=hidden_units,\n    dropout_rates=dropout_rates,\n    learning_rate=learning_rate\n)\nr = model.fit(\n    X_train, y_train,\n    validation_data=(X_test, y_test),\n    epochs=150,\n    batch_size=32\n)","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_learning_evolution(r)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train_pred = model.predict(X_train)\nevaluate_nn(y_train, y_train_pred.round(), train=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test_pred = model.predict(X_test)\nevaluate_nn(y_test, y_test_pred.round(), train=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores_dict = {\n    'ANNs': {\n        'Train': roc_auc_score(y_train, model.predict(X_train)),\n        'Test': roc_auc_score(y_test, model.predict(X_test)),\n    },\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 7. 2. XGBoost Classifier","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBClassifier\n\nn_estimators = [50, 100, 200]\nlearning_rate = [0.05, 0.01, 0.5, 0.1, 1]\ntree_method = ['gpu_hist']\n\nparams_grid = {\n    'n_estimators': n_estimators,\n#     'learning_rate': learning_rate,\n}\n\nxgb_clf = XGBClassifier()\nxgb_cv = GridSearchCV(xgb_clf, params_grid, cv=3, scoring='roc_auc', n_jobs=-1, verbose=1)\n# xgb_cv.fit(X_train, y_train)\n# best_params = xgb_cv.best_params_\n# best_params['tree_method'] = 'gpu_hist'\nbest_params = {'n_estimators': 50, 'tree_method': 'gpu_hist'}\nprint(f\"Best Parameters: {best_params}\")\n\nxgb_clf = XGBClassifier(**best_params)\nxgb_clf.fit(X_train, y_train)\n\ny_train_pred = xgb_clf.predict(X_train)\ny_test_pred = xgb_clf.predict(X_test)\n\nprint_score(y_train, y_train_pred, train=True)\nprint_score(y_test, y_test_pred, train=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import plot_confusion_matrix, plot_roc_curve\n\ndisp = plot_confusion_matrix(xgb_clf, X_test, y_test, \n                             cmap='Blues', values_format='d', \n                             display_labels=['Fully-Paid', 'Default'])\n\ndisp = plot_roc_curve(xgb_clf, X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores_dict['XGBoost'] = {\n        'Train': roc_auc_score(y_train, xgb_clf.predict(X_train)),\n        'Test': roc_auc_score(y_test, xgb_clf.predict(X_test)),\n    }","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 7. 3. Random Forest Classifier","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nrf_clf = RandomForestClassifier(n_estimators=100)\nrf_clf.fit(X_train, y_train)\n\ny_train_pred = rf_clf.predict(X_train)\ny_test_pred = rf_clf.predict(X_test)\n\nprint_score(y_train, y_train_pred, train=True)\nprint_score(y_test, y_test_pred, train=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"disp = plot_confusion_matrix(rf_clf, X_test, y_test, \n                             cmap='Blues', values_format='d', \n                             display_labels=['Fully-Paid', 'Default'])\n\ndisp = plot_roc_curve(xgb_clf, X_test, y_test)\nplot_roc_curve(rf_clf, X_test, y_test, ax=disp.ax_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores_dict['Random Forest'] = {\n        'Train': roc_auc_score(y_train, rf_clf.predict(X_train)),\n        'Test': roc_auc_score(y_test, rf_clf.predict(X_test)),\n    }","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 8. Comparing Models Prerformance","metadata":{}},{"cell_type":"code","source":"ml_models = {\n    'Random Forest': rf_clf, \n    'XGBoost': xgb_clf, \n    'ANNs': model\n}\n\nfor model in ml_models:\n    print(f\"{model.upper():{30}} roc_auc_score: {roc_auc_score(y_test, ml_models[model].predict(X_test)):.3f}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores_df = pd.DataFrame(scores_dict)\nscores_df.plot(kind='barh', figsize=(15, 8))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}