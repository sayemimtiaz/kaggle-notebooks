{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.layers import AveragePooling2D\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.applications.mobilenet_v2 import preprocess_input\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom tensorflow.keras.preprocessing.image import load_img\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nimport matplotlib.pyplot as plt\nimport os\nimport cv2\nimport json","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = 1e-4\nepochs = 20\nBS = 16\n\nanno_dir='/kaggle/input/face-mask-detection-dataset/Medical mask/Medical mask/Medical Mask/annotations/'\nimages_dir='/kaggle/input/face-mask-detection-dataset/Medical mask/Medical mask/Medical Mask/images/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images=[]\nlabels=[]\nfor filename in os.listdir(images_dir):\n    num = filename.split('.')[ 0 ]\n    if int(num) > 1800:\n        class_name = None\n        anno = filename + \".json\"\n        with open(os.path.join(anno_dir, anno)) as json_file:\n            json_data = json.load(json_file)\n            no_anno = json_data[\"NumOfAnno\"]\n            k = 0\n            for i in range(0, no_anno):\n                class_nam = json_data['Annotations'][i]['classname']\n                if class_nam in ['face_with_mask',\"gas_mask\", \"face_shield\", \"mask_surgical\", \"mask_colorful\"]:\n                    class_name = 'face_with_mask'\n                    k = i\n                    break\n                elif class_nam in ['face_no_mask,\"hijab_niqab', 'face_other_covering', \"face_with_mask_incorrect\", \"scarf_bandana\", \"balaclava_ski_mask\", \"other\" ]:\n                    class_name = 'face_no_mask'\n                    k = i\n                    break\n                else:\n                    continue\n                    \n            box = json_data[ 'Annotations' ][k][ 'BoundingBox' ]\n            (x1, x2, y1, y2) = box\n        if class_name is not None:\n            image = cv2.imread(os.path.join(images_dir, filename))\n            img = image[x2:y2, x1:y1]\n            img = cv2.resize(img, (224, 224))\n            img = img[...,::-1].astype(np.float32)\n            img = preprocess_input(img)\n            images.append(img)\n            labels.append(class_name)  \n   \nimages = np.array(images, dtype=\"float32\")\nlabels = np.array(labels)\nprint(len(images))\nprint(len(labels))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"lb = LabelBinarizer()\nlabels = lb.fit_transform(labels)\nlabels = to_categorical(labels)\n\n(trainX, testX, trainY, testY) = train_test_split(images, labels,test_size=0.20, stratify=labels, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nimagedata = ImageDataGenerator(rotation_range=20, zoom_range=0.15, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.15,\n                      fill_mode=\"nearest\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"baseModel = MobileNetV2(weights=\"imagenet\", include_top=False,\n    input_tensor=Input(shape=(224, 224, 3)))\n\nheadModel = baseModel.output\nheadModel = AveragePooling2D(pool_size=(7, 7))(headModel)\nheadModel = Flatten(name=\"flatten\")(headModel)\nheadModel = Dense(128, activation=\"relu\")(headModel)\nheadModel = Dropout(0.5)(headModel)\nheadModel = Dense(2, activation=\"softmax\")(headModel)\n\nmodel = Model(inputs=baseModel.input, outputs=headModel)\nmodel.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\nmodel.save('/kaggle/working/model.h5')\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new = model.fit(imagedata.flow(trainX, trainY, batch_size=BS), steps_per_epoch=len(trainX)//BS, validation_data=(testX,testY), \n               validation_steps=len(testX)//BS, epochs=epochs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install mtcnn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.DataFrame(columns=['name', 'x1','x2','y1','y2','classname'])\ndetector = MTCNN()\nfor filename in os.listdir(images_dir):\n    temp = []\n    num = filename.split('.')[0]    \n    if int(num) <= 1800:\n        if int(num) % 100 == 0:\n            print(int(num))\n        image = cv2.imread(os.path.join(images_dir, filename))\n        if image is None:\n            continue\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        (h, w) = image.shape[:2]\n        faces = detector.detect_faces(image)\n        if len(faces)==0:\n            class_curr = 'face_no_mask'\n        else:\n            face = max(faces, key=lambda x:x['confidence'])\n            x,y,w,h = face['box']\n            x, y = abs(x), abs(y)\n            roi = image[y:y+h, x:x+w]            \n            roi = cv2.resize(roi, (224, 224))\n            roi = roi.astype(np.float32)\n            roi = preprocess_input(roi)\n            temp.append(roi)\n            temp = np.asarray(temp)            \n            [(a,b)] = model.predict(temp, batch_size=BS)\n            if a > b:\n                class_curr = 'face_no_mask'\n            else:\n                class_curr = 'face_with_mask'\n        data = {'name': filename,'x1':x,'x2':y,'y1':x+w,'y2':y+h,'classname': class_curr}\n        sub = sub.append(data, ignore_index=True)\n\nprint(len(sub))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.sort_values(by=['name'], inplace=True)\nsub.to_csv('/kaggle/working/submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from mtcnn import MTCNN\nimport cv2\nimport numpy as np\nfrom tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n\nmodel.load_weights('/kaggle/imput/model.h5')\n\ndetector = MTCNN()\ntemp = []\nimage = cv2.imread('/kaggle/input/face-mask-detection-dataset/Medical mask/Medical mask/Medical Mask/images/0004.jpg')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n(h, w) = image.shape[:2]\nfaces = detector.detect_faces(image)\nif len(faces)==0:\n    class_curr = 'face_no_mask'\nelse:\n    face = max(faces, key=lambda x:x['confidence'])\n    x,y,w,h = face['box']\n    x, y = abs(x), abs(y)\n    roi = image[y:y+h, x:x+w]            \n    roi = cv2.resize(roi, (224, 224))\n    roi = roi.astype(np.float32)\n    roi = preprocess_input(roi)\n    temp.append(roi)\n    temp = np.asarray(temp)            \n    [(a,b)] = model.predict(temp, batch_size=16)\n    if a > b:\n        class_curr = 'face_no_mask'\n    else:\n        class_curr = 'face_with_mask'\ncv2.putText(image,class_curr , (10, 30),\n        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 3)\ncv2.rectangle(image, (x, y), (x+w, y+h), (255,0,0), 2)\ncv2.imwrite('/kaggle/working/test.jpg',image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}