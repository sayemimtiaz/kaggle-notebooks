{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem import SnowballStemmer\nfrom wordcloud import WordCloud, STOPWORDS\nimport pandas as pd\nimport numpy as np\nimport re\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport string\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.metrics import precision_recall_fscore_support as score\nfrom sklearn.metrics import accuracy_score as acs\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Warnings\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**SMS Spam Collection dataset**","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/spam-ham-dataset/SMSSpamCollection1.csv\",encoding = 'latin-1')\ndata = data.drop(labels = [\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis = 1)\ndata.columns = [\"label\", \"body_text\"]\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['label'].value_counts().plot(kind = 'pie', explode = [0, 0.15], figsize = (8, 8), autopct = '%1.1f%%', shadow = True)\nplt.xlabel(\"Spam vs Ham\",size=15)\nplt.ylabel(\" \")\nplt.legend([\"ham\", \"spam\"])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Preprocessing**","metadata":{}},{"cell_type":"code","source":"#Extracting spam and ham words from messages\nspam_messages = data[data[\"label\"] == \"spam\"][\"body_text\"]\nham_messages = data[data[\"label\"] == \"ham\"][\"body_text\"]\n\nspam_words = []\nham_words = []\n\ndef extractSpamWords(spamMessages):\n    global spam_words\n    words = [word.lower() for word in word_tokenize(spamMessages) if word.lower() \n             not in stopwords.words(\"english\") and word.lower().isalpha()]\n    spam_words = spam_words + words\n    \ndef extractHamWords(hamMessages):\n    global ham_words\n    words = [word.lower() for word in word_tokenize(hamMessages) if word.lower() \n             not in stopwords.words(\"english\") and word.lower().isalpha()]\n    ham_words = ham_words + words\n    \nspam_messages.apply(extractSpamWords)\nham_messages.apply(extractHamWords)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stopwords = nltk.corpus.stopwords.words('english')\nps = nltk.PorterStemmer() #Stemming\n\ndef count_punct(text):\n    count = sum([1 for char in text if char in string.punctuation])\n    return round(count/(len(text) - text.count(\" \")), 3)*100\n\ndata['body_len'] = data['body_text'].apply(lambda x: len(x) - x.count(\" \"))\ndata['punct%'] = data['body_text'].apply(lambda x: count_punct(x))\n\ndef clean_text(text):\n    text = \"\".join([word.lower() for word in text if word not in string.punctuation])\n    tokens = re.split('\\W+', text)\n    text = [ps.stem(word) for word in tokens if word not in stopwords]\n    return text\ndata.head()\n\n# body_len shows the length of words excluding whitespaces in a message body.\n# punct% shows the percentage of punctuation marks in a message body.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,12))\n\n#Spam Word cloud\nplt.subplot(2,2,2, facecolor='k')\nspam_wordcloud = WordCloud(width=600, height=400,collocations=False,\n                           random_state=1,background_color=\"red\").generate(\" \".join(spam_words))\nplt.imshow(spam_wordcloud)\nplt.title(\"Spam Word Cloud\",size=20)\nplt.axis(\"off\")\n\n#Ham word cloud\nplt.subplot(2,2,1, facecolor='k')\nham_wordcloud = WordCloud(width=600, height=400,collocations=False,\n                          random_state=1,background_color=\"green\").generate(\" \".join(ham_words))\nplt.imshow(ham_wordcloud)\nplt.title(\"Ham Word Cloud\",size=20)\nplt.axis(\"off\")\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Top 10 spam words\nspam_words = np.array(spam_words)\nprint(\"Top 10 Spam words are :\\n\")\ndisplay(pd.Series(spam_words).value_counts().head(n = 10))\n\n# Top 10 Ham words\nham_words = np.array(ham_words)\nprint(\"Top 10 Ham words are :\\n\")\ndisplay(pd.Series(ham_words).value_counts().head(n = 10))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"messageLength\"] = data[\"body_text\"].apply(len)\nf, ax = plt.subplots(1, 2, figsize = (20, 6))\n\nsns.distplot(data[data[\"label\"] == \"spam\"][\"messageLength\"], bins = 20, ax = ax[0],color=\"red\")\nax[0].set_xlabel(\"Spam Message Length\",fontSize=20)\nax[0].grid()\n\nsns.distplot(data[data[\"label\"] == \"ham\"][\"messageLength\"], bins = 20, ax = ax[1],color=\"green\")\nax[1].set_xlabel(\"Ham Message Length\",fontSize=20)\nax[1].grid()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X=data[['body_text', 'body_len', 'punct%']]\nY=data['label']\n\n#Split data into training and testing\nX_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.2, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"__Vectorize Text__","metadata":{}},{"cell_type":"code","source":"tfidf_vect = TfidfVectorizer(analyzer=clean_text)\ntfidf_vect_fit = tfidf_vect.fit(X_train['body_text'])\n\ntfidf_train = tfidf_vect_fit.transform(X_train['body_text'])\ntfidf_test = tfidf_vect_fit.transform(X_test['body_text'])\n\nX_train_vect = pd.concat([X_train[['body_len', 'punct%']].reset_index(drop=True), \n           pd.DataFrame(tfidf_train.toarray())], axis=1)\nX_test_vect = pd.concat([X_test[['body_len', 'punct%']].reset_index(drop=True), \n           pd.DataFrame(tfidf_test.toarray())], axis=1)\n\nX_train_vect.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"__Testing the model__","metadata":{}},{"cell_type":"code","source":"rf = RandomForestClassifier(n_estimators=150, max_depth=None, n_jobs=-1)\nrf_model = rf.fit(X_train_vect, y_train)\n\ny_pred = rf_model.predict(X_test_vect)\n\nprecision, recall, fscore, train_support = score(y_test, y_pred, pos_label=\"spam\", average='binary')\nprint('Precision: {} \\nRecall: {} \\nF1-Score: {} \\nAccuracy: {}'.format(\n    round(precision, 3), round(recall, 3), round(fscore,3), round(acs(y_test,y_pred), 3)*100) +\"% \\n\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\nclass_label = [\"ham\", \"spam\"]\ndf_cm = pd.DataFrame(cm, index=class_label,columns=class_label)\nprint(\"The confusion matrix is:\\n {}\".format(df_cm))\n\n#Plot\nplt.figure(figsize=(10,7))\nsns.heatmap(df_cm, annot=True, fmt='d')\nplt.title(\"Confusion Matrix\",fontsize=15)\nplt.xlabel(\"Predicted Label\",fontsize=15)\nplt.ylabel(\"True Label\",fontsize=15)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}