{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Association Rule Mining\n\nAssociation rule mining finds interesting associations and relationships among large sets of data items. This rule shows how frequently a itemset occurs in a transaction. A typical example is Market Based Analysis.\n\nMarket Based Analysis is one of the key techniques used by large relations to show associations between items.It allows retailers to identify relationships between the items that people buy together frequently.\n\nGiven a set of transactions, we can find rules that will predict the occurrence of an item based on the occurrences of other items in the transaction.","metadata":{}},{"cell_type":"markdown","source":"- **Support(s)** –\nThe number of transactions that include items in the {X} and {Y} parts of the rule as a percentage of the total number of transaction.It is a measure of how frequently the collection of items occur together as a percentage of all transactions.\n\n    ```Support = \\sigma(X+Y) \\div total –```\n\nIt is interpreted as fraction of transactions that contain both X and Y.\n\n- **Confidence(c)** –\nIt is the ratio of the no of transactions that includes all items in {B} as well as the no of transactions that includes all items in {A} to the no of transactions that includes all items in {A}.\n\n    ```Conf(X=>Y) = Supp(X\\cupY) \\div Supp(X) –```\n\nIt measures how often each item in Y appears in transactions that contains items in X also.\n\n- **Lift(l)** –\nThe lift of the rule X=>Y is the confidence of the rule divided by the expected confidence, assuming that the itemsets X and Y are independent of each other.The expected confidence is the confidence divided by the frequency of {Y}.\n\n    ```Lift(X=>Y) = Conf(X=>Y) \\div Supp(Y) –```\n\nLift value near 1 indicates X and Y almost often appear together as expected, greater than 1 means they appear together more than expected and less than 1 means they appear less than expected.Greater lift values indicate stronger association.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport matplotlib as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/market-basket-optimisationcsv/Market_Basket_Optimisation.csv\", header = None)\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"records = []\nfor i in range(0, len(df)):\n    records.append([str(df.values[i,j]) for j in range(0, 20)])\n    records[i] = [x for x in records[i] if x != 'nan']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dict_data = {'items': records}\ndf = pd.DataFrame.from_dict(dict_data)\n\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"items = []\nfor i in range(len(df)):\n    for j in range(len(df['items'][i])):\n        items.append(df['items'][i][j])\n\nitems[0:10]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Creating First Candidate (C1)","metadata":{}},{"cell_type":"code","source":"#Get unique element from list/array\nunique_item = set(items)\nlist_unique_item = list(unique_item)\nlist_unique_item[0:5]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count_unique = []\nfor value in (list_unique_item):\n    count_unique.append((value, items.count(value)))\ncount_unique[0:5]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"candidate1 = pd.DataFrame(count_unique, columns=[\"itemset\", \"sup\"])\ncandidate1.head()\nlen(candidate1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Creating first Frequent Itemset (L1)","metadata":{}},{"cell_type":"code","source":"def filter_sup(candidate):\n    minimum_sup = 50\n    filtering = candidate['sup'] > minimum_sup\n    freq = candidate[filtering]\n    return freq","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"freq_itemset1 = filter_sup(candidate1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"freq_itemset1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"freq_itemset1['itemset'].iloc[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Choose second candidate","metadata":{}},{"cell_type":"code","source":"def self_join(prev_freq_itemset):\n    self_join_candidate = []\n    for i in range(len(prev_freq_itemset['itemset'])):\n        for j in range((i+1), len(prev_freq_itemset['itemset'])):\n            itemset_i = prev_freq_itemset['itemset'].iloc[i]\n            itemset_j = prev_freq_itemset['itemset'].iloc[j]\n            if(type(itemset_i) == np.int64 and type(itemset_j) == np.int64):\n                itemset_i = {itemset_i}\n                itemset_j = {itemset_j}\n            union_candidate = itemset_i + \", \" + itemset_j\n\n            if union_candidate not in self_join_candidate:\n                self_join_candidate.append(union_candidate)\n    return self_join_candidate","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"candidate2_list = self_join(freq_itemset1)\n# candidate2_list","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count_candidate2 = []\n\n#Set the Initial value of Second Count Candidate (C2)\nfor i in range(len(candidate2_list)):\n    count_candidate2.append((candidate2_list[i], 0))\n\ninitial_df_candidate = pd.DataFrame(count_candidate2, columns=['itemset', 'sup'])\nlen(initial_df_candidate)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def count_support(database_dataframe, prev_candidate_list):\n    initial_df_candidate['sup'] = 0 #set All value into 0 only for initial value for consistency value when running this cell everytime.\n    count_prev_candidate = []\n\n    #Set the Initial value of Previous Candidate\n    for i in range(1000): #len(prev_candidate_list)\n        count_prev_candidate.append((prev_candidate_list[i], 0))\n    \n    df_candidate = pd.DataFrame(count_prev_candidate, columns=['itemset', 'sup'])\n    print('Database D dataframe\\n', database_dataframe)\n    print('(Initial) Dataframe from Candidate with All zeros sup\\n', df_candidate)\n    \n    for i in range(len(database_dataframe)):\n        for j in range(1000): #len(count_prev_candidate)\n            #using issubset() function to check whether every itemset is a subset of Database or not\n            if set(list(df_candidate['itemset'][j].split(\", \"))).issubset(set(list(database_dataframe['items'][i]))): \n                df_candidate.loc[j, 'sup'] += 1\n            \n    return df_candidate","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count_candidate2_df = count_support(df, candidate2_list)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count_candidate2_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Creating Second Frequent Itemset (L2)","metadata":{}},{"cell_type":"code","source":"freq_itemset2 = filter_sup(count_candidate2_df)\n\nfreq_itemset2 = freq_itemset2.reset_index(drop=True)\nfreq_itemset2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Creating the Third Candidate (C3) - Using the Candidate Forming Technique","metadata":{}},{"cell_type":"code","source":"print(freq_itemset2[0:10])\nself_join_result = self_join(freq_itemset2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(self_join_result))\nself_join_result[0:10]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"candidate3_list = self_join_result","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count_candidate3_df = count_support(df, candidate3_list)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max(count_candidate3_df['sup'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def filter_sup2(candidate):\n    minimum_sup = 20\n    filtering = candidate['sup'] > minimum_sup\n    freq = candidate[filtering]\n    return freq","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Creating Third frequent Itemset","metadata":{}},{"cell_type":"code","source":"freq_itemset3 = filter_sup2(count_candidate3_df)\nfor i in range(len(freq_itemset3)):\n    print(\"Items: \", set(list(freq_itemset3['itemset'].iloc[i].split(\", \"))), \"\\t Support: \", freq_itemset3['sup'].iloc[i])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"frequent_itemset = pd.concat([freq_itemset1, freq_itemset2, freq_itemset3], axis=0)\nfrequent_itemset_final = frequent_itemset.reset_index(drop=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Combining all the Frequent Itemsets","metadata":{}},{"cell_type":"code","source":"for i in range(len(frequent_itemset_final)):\n    print(frequent_itemset_final['itemset'].iloc[i], \"\\t\", frequent_itemset_final['sup'].iloc[i])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}