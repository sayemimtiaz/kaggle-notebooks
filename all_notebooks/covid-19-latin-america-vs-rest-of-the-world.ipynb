{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In this kernel, the followng question is trying to be answered: **What are the most important measurements (regarding mobility) that must be taken in order to reduce the rate of cases/day in Latin America vs. The rest of the world?**\n\nTo given an answer to this question, the following databases were used:\n* current-data-on-the-geographic-distribution-of-covid-19-cases-worldwide.csv - to obtain the rate of cases/day\n* apple_mobility_trends/mobility-trends.csv - to have information about the different methods of transportation used in the last months\n* google_mobility/regional-mobility - to have information about the distribution of places regarding mobility\n\nTherefore, the first thing to do is to organize and clean up each database. This can be seen in the following cells.","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"sa_countries = ['Belize','Costa_Rica','El_Salvador','Guatemala','Honduras','Mexico','Nicaragua','Panama','Argentina',\n                'Bolivia','Brazil','Chile','Colombia','Ecuador','French_Guiana','Guyana','Paraguay','Peru','Suriname','Uruguay',\n                'Venezuela','Cuba','Dominican_Republic','Haiti','Guadeloupe','Martinique','Puerto_Rico']\n\nsta_1 = pd.read_csv('/kaggle/input/uncover/UNCOVER/ECDC/current-data-on-the-geographic-distribution-of-covid-19-cases-worldwide.csv') #Statistics\nmob_1 = pd.read_csv('/kaggle/input/uncover/UNCOVER/apple_mobility_trends/mobility-trends.csv') #Mobility\nmob_2 = pd.read_csv('/kaggle/input/uncover/UNCOVER/google_mobility/regional-mobility.csv') #Mobility\n\nsta_1 = sta_1.drop(sta_1.columns[[0,7,8,10]], axis=1)\nsta_1 = sta_1.assign(date = pd.to_datetime(sta_1[['year', 'month', 'day']]))\nsta_1 = sta_1.drop(sta_1.columns[[0,1,2]], axis=1)\nsta_1 = sta_1.dropna()\nsta_1['countriesandterritories'].replace({'El Salvador':'El_Salvador', 'French Guiana':'French_Guiana',\n                                          'Dominican Republic':'Dominican_Republic','Puerto Rico':'Puerto_Rico'},inplace=True)\nmob_1 = mob_1.drop(mob_1[mob_1.geo_type == 'city'].index)\nmob_1 = mob_1.drop(mob_1.columns[0], axis=1)\nmob_1 = mob_1.dropna()\nmob_1['region'].replace({'El Salvador':'El_Salvador', 'French Guiana':'French_Guiana',\n                         'Dominican Republic':'Dominican_Republic','Puerto Rico':'Puerto_Rico'},inplace=True)\n\nmob_2 = mob_2.drop(mob_2.columns[1], axis=1)\nmob_2 = mob_2.dropna()\nmob_2['country'].replace({'El Salvador':'El_Salvador', 'French Guiana':'French_Guiana',\n                         'Dominican Republic':'Dominican_Republic','Puerto Rico':'Puerto_Rico'},inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sta1_la = sta_1.loc[sta_1['countriesandterritories'].isin(sa_countries)] #Latin America\nsta1_rw = sta_1.drop(sta1_la['countriesandterritories'].index) #Rest of the world\nsta1_la = sta1_la.drop(sta1_la.columns[[2,3]], axis=1)\nsta1_rw = sta1_rw.drop(sta1_rw.columns[[2,3]], axis=1)\nsta1_la = sta1_la.groupby(['date']).sum().reset_index()\nsta1_rw = sta1_rw.groupby(['date']).sum().reset_index()\n\nmob1_la = mob_1.loc[mob_1['region'].isin(sa_countries)]\nmob1_rw = mob_1.drop(mob1_la['region'].index)\nmob1_la = mob1_la.drop(mob1_la.columns[0], axis=1)\nmob1_rw = mob1_rw.drop(mob1_rw.columns[0], axis=1)\nmob1_la = mob1_la.groupby(['date','transportation_type']).sum().reset_index()\nmob1_rw = mob1_rw.groupby(['date','transportation_type']).sum().reset_index()\n\nmob2_la = mob_2.loc[mob_2['country'].isin(sa_countries)]\nmob2_rw = mob_2.drop(mob2_la['country'].index)\nmob2_la = mob2_la.drop(mob2_la.columns[0], axis=1)\nmob2_rw = mob2_rw.drop(mob2_rw.columns[0], axis=1)\nmob2_la = mob2_la.groupby(['date']).sum().reset_index()\nmob2_rw = mob2_rw.groupby(['date']).sum().reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = mob1_la[mob1_la.transportation_type == 'driving']\ndf2 = mob1_la[mob1_la.transportation_type == 'walking']\ndf3 = mob1_la[mob1_la.transportation_type == 'transit']\ndf1 = df1.rename(columns={'value':'driving'})\ndf1['walking'] = df2.value.values\ndf1['transit'] = df3.value.values\n\nmob1_la = df1.drop(df1.columns[[1]], axis=1)\n\ndf1 = mob1_rw[mob1_rw.transportation_type == 'driving']\ndf2 = mob1_rw[mob1_rw.transportation_type == 'walking']\ndf3 = mob1_rw[mob1_rw.transportation_type == 'transit']\ndf1 = df1.rename(columns={'value':'driving'})\ndf1['walking'] = df2.value.values\ndf1['transit'] = df3.value.values\n\nmob1_rw = df1.drop(df1.columns[[1]], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So as it can be seen in the next print, the three data bases were divided for Latin America and the rest of the world. And, the format of each is consistent, were the columns are: 'date', 'feature1', 'feature2', ...\n\nIt is important to mention that the intial date and the final date in each database is the same. This, to have a consistent time-window for the data analysis.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sta1_la = sta1_la[sta1_la.date >= mob2_la.date[0]]\nsta1_la = sta1_la[sta1_la.date <= mob2_la.date[62]]\nsta1_rw = sta1_rw[sta1_rw.date >= mob2_la.date[0]]\nsta1_rw = sta1_rw[sta1_rw.date <= mob2_la.date[62]]\n\nmob1_la = mob1_la[mob1_la.date >= mob2_la.date[0]]\nmob1_la = mob1_la[mob1_la.date <= mob2_la.date[62]]\nmob1_rw = mob1_rw[mob1_rw.date >= mob2_la.date[0]]\nmob1_rw = mob1_rw[mob1_rw.date <= mob2_la.date[62]]\n\nprint(sta1_la.head(),'\\n')\nprint(mob1_la.head(),'\\n')\nprint(mob2_la.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Having cleaned up the databases, the following graphs show every index that will be studied. This, considering the two different groups mentioned before, Latin America and the rest of the world. The first graph shows the rate of cases/day and deaths/day.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize = (19,3))\nax1 = fig.add_subplot(121)\nax2 = fig.add_subplot(122)\nsta1_la.set_index('date').plot(ax=ax1, title='Latin America')\nsta1_rw.set_index('date').plot(ax=ax2, title='Rest of the world')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The second graph shows the index for different methods of transportation/day used.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize = (19,3))\nax1 = fig.add_subplot(121)\nax2 = fig.add_subplot(122)\nmob1_la.set_index('date').plot(ax=ax1, title='Latin America')\nmob1_rw.set_index('date').plot(ax=ax2, title='Rest of the world')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And the third one shows the index of locations/day.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize = (19,3))\nax1 = fig.add_subplot(121)\nax2 = fig.add_subplot(122)\nmob2_la.set_index('date').plot(ax=ax1, title='Latin America')\nmob2_rw.set_index('date').plot(ax=ax2, title='Rest of the world')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, with the information obtained from cleaning up the databases, a full study can be done. But first, it is important to mention that the amount of data is very limited (only 63 instances - refering to almost 2 full months of data) which is a clear constraint and restriction for the models that will be deployed.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import sklearn.ensemble\nimport sklearn.model_selection\nimport sklearn.metrics\nimport sklearn.neural_network\nfrom sklearn.preprocessing import StandardScaler","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First, the importance and effect of the methods of transportation will be studied. To have consistent results, the data needs to be scaled and normalize as it can be seen.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"total_la = mob1_la\ntotal_la['cases'] = sta1_la.cases.values\n\ntotal_rw = mob1_rw\ntotal_rw['cases'] = sta1_rw.cases.values\n\natributes_name = total_rw.columns\ntotal_la = total_la.to_numpy()\ntotal_rw = total_rw.to_numpy()\n\natributes_la = total_la[:,1:-1].astype(float)\ntarget_la = total_la[:,-1].astype(float)\n\natributes_rw = total_rw[:,1:-1].astype(float)\ntarget_rw = total_rw[:,-1].astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scalerla = StandardScaler()\nxla_train, xla_test, yla_train, yla_test = sklearn.model_selection.train_test_split(atributes_la, target_la, train_size=0.7)\nxla_train = scalerla.fit_transform(xla_train)\nxla_test = scalerla.transform(xla_test)\n\nscalerrw = StandardScaler()\nxrw_train, xrw_test, yrw_train, yrw_test = sklearn.model_selection.train_test_split(atributes_rw, target_rw, train_size=0.7)\nxrw_train = scalerrw.fit_transform(xrw_train)\nxrw_test = scalerrw.transform(xrw_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The following cell implements a method to find the best number of trees in the Random Forest Regressor for each group (Latin America vs. Rest of the world). Here, the variable that is being predicted is the amount of cases/day using the features from the second data base.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"n_trees = np.arange(1,100,1)\nscore_la = []\nscore_rw = []\n\nfor n_tree in n_trees:\n    clf_la = sklearn.ensemble.RandomForestRegressor(n_estimators=n_tree, max_features='sqrt')\n    clf_la.fit(xla_train, yla_train)\n    score_la.append(clf_la.score(xla_test,yla_test))\n    \n    clf_rw = sklearn.ensemble.RandomForestRegressor(n_estimators=n_tree, max_features='sqrt')\n    clf_rw.fit(xrw_train, yrw_train)\n    score_rw.append(clf_rw.score(xrw_test,yrw_test))\n\nbest_Mla = n_trees[np.argmax(score_la)]\nclfla_best = sklearn.ensemble.RandomForestRegressor(n_estimators=best_Mla, max_features='sqrt')\nclfla_best.fit(xla_train,yla_train)\nimportancesla = clfla_best.feature_importances_\n\nbest_Mrw = n_trees[np.argmax(score_rw)]\nclfrw_best = sklearn.ensemble.RandomForestRegressor(n_estimators=best_Mrw, max_features='sqrt')\nclfrw_best.fit(xrw_train,yrw_train)\nimportancesrw = clfrw_best.feature_importances_\n\nfig = plt.figure(figsize = (15,5))\nax1 = fig.add_subplot(121)\nax2 = fig.add_subplot(122)\nala = pd.Series(importancesla, index=atributes_name[1:-1])\nala.nlargest(9).plot(kind='barh', ax=ax1, title='Latin America: $R^2$ = {:.3f} , {:.0f} Trees'.format(clfla_best.score(xla_test,yla_test),best_Mla))\nax1.set_xlabel('Feature Importance')\narw = pd.Series(importancesrw, index=atributes_name[1:-1])\narw.nlargest(9).plot(kind='barh', ax=ax2, title='Rest of the world: $R^2$ = {:.3f} , {:.0f} Trees'.format(clfrw_best.score(xrw_test,yrw_test),best_Mrw))\nax2.set_xlabel('Feature Importance')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As it can be seen from the graphs shown before, it seems as transit, walking and driving are all significant when determining the amount of cases/day for the rest of the world. But, for Latin America, it seems as if the only feature that has a high importance is transit. Considering the score for both models, the results of the rest of the world seem to have a better fit. But, in order to actually confirm the importance of this features LASSO was used. **It is important to mention that LASSO implies a linear regression, meaning that this is a very rough approximation to the data seen when cleaning up the databases.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"n_alpha = 100\nalpha = np.logspace(-5, 5, n_alpha)\n\nscores_la = []\nbetas_la = []\n\nscores_rw = []\nbetas_rw = []\n\nfor a in alpha:\n    lasso_la = sklearn.linear_model.Lasso(alpha=a, max_iter=10000)\n    lasso_la.fit(xla_train, yla_train)\n    scores_la.append(lasso_la.score(xla_test, yla_test))\n    betas_la.append(lasso_la.coef_)\n    \n    lasso_rw = sklearn.linear_model.Lasso(alpha=a, max_iter=10000)\n    lasso_rw.fit(xrw_train, yrw_train)\n    scores_rw.append(lasso_rw.score(xrw_test, yrw_test))\n    betas_rw.append(lasso_rw.coef_)\n\nprint(\"\")\nprint(\"Best model (LASSO): Latin America R^2 = {}\".format(max(scores_la)))\nprint(\"\")\nbest_la = np.argmax(scores_la) \nbeta_la = betas_la[best_la]\nii = np.argsort(-beta_la)\nfor i in ii:\n    if(abs(beta_la[i])>0):\n        print(atributes_name[1:-1][i], beta_la[i])\n        \nprint(\"\")\nprint(\"Best model (LASSO): Rest of the world R^2 = {}\".format(max(scores_rw)))\nprint(\"\")\nbest_rw = np.argmax(scores_rw) \nbeta_rw = betas_rw[best_rw]\nii = np.argsort(-beta_rw)\nfor i in ii:\n    if(abs(beta_rw[i])>0):\n        print(atributes_name[1:-1][i], beta_rw[i])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The results obtained are consistent with those obtained with the Random Forest Regressor. This, since the LASSO linear regression suggests that, for Latin America, t. And, regarding the rest of the world, the significant features in this case are walking and driving. \n\n**So, studying the intersection between the Random Forest Regressor and the LASSO linear regression, it seems as if the most significant feature for Latin America, regarding methods of transportation, when trying to determine the rate of cases/day is transit. While for the rest of the world, are both walking and driving. But, clearly, the lack of data and the rough approximation of using LASSO as a linear regression is a constraint and limits the accuracy of the results.**\n\nNow, to study the effect of the locations, the same process was done, but in this case, considering the third database. Once again the variable to predict is simply the amount of cases/day.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"total_la = mob2_la\ntotal_la['cases'] = sta1_la.cases.values\n\ntotal_rw = mob2_rw\ntotal_rw['cases'] = sta1_rw.cases.values\n\natributes_name = total_rw.columns\ntotal_la = total_la.to_numpy()\ntotal_rw = total_rw.to_numpy()\n\natributes_la = total_la[:,1:-1].astype(float)\ntarget_la = total_la[:,-1].astype(float)\n\natributes_rw = total_rw[:,1:-1].astype(float)\ntarget_rw = total_rw[:,-1].astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scalerla = StandardScaler()\nxla_train, xla_test, yla_train, yla_test = sklearn.model_selection.train_test_split(atributes_la, target_la, train_size=0.7)\nxla_train = scalerla.fit_transform(xla_train)\nxla_test = scalerla.transform(xla_test)\n\nscalerrw = StandardScaler()\nxrw_train, xrw_test, yrw_train, yrw_test = sklearn.model_selection.train_test_split(atributes_rw, target_rw, train_size=0.7)\nxrw_train = scalerrw.fit_transform(xrw_train)\nxrw_test = scalerrw.transform(xrw_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_trees = np.arange(1,100,1)\nscore_la = []\nscore_rw = []\n\nfor n_tree in n_trees:\n    clf_la = sklearn.ensemble.RandomForestRegressor(n_estimators=n_tree, max_features='sqrt')\n    clf_la.fit(xla_train, yla_train)\n    score_la.append(clf_la.score(xla_test,yla_test))\n    \n    clf_rw = sklearn.ensemble.RandomForestRegressor(n_estimators=n_tree, max_features='sqrt')\n    clf_rw.fit(xrw_train, yrw_train)\n    score_rw.append(clf_rw.score(xrw_test,yrw_test))\n\nbest_Mla = n_trees[np.argmax(score_la)]\nclfla_best = sklearn.ensemble.RandomForestRegressor(n_estimators=best_Mla, max_features='sqrt')\nclfla_best.fit(xla_train,yla_train)\nimportancesla = clfla_best.feature_importances_\n\nbest_Mrw = n_trees[np.argmax(score_rw)]\nclfrw_best = sklearn.ensemble.RandomForestRegressor(n_estimators=best_Mrw, max_features='sqrt')\nclfrw_best.fit(xrw_train,yrw_train)\nimportancesrw = clfrw_best.feature_importances_\n\nfig = plt.figure(figsize = (15,5))\nax1 = fig.add_subplot(121)\nax2 = fig.add_subplot(122)\nala = pd.Series(importancesla, index=atributes_name[1:-1])\nala.nlargest(9).plot(kind='barh', ax=ax1, title='Latin America: $R^2$ = {:.3f} , {:.0f} Trees'.format(clfla_best.score(xla_test,yla_test),best_Mla))\nax1.set_xlabel('Feature Importance')\narw = pd.Series(importancesrw, index=atributes_name[1:-1])\narw.nlargest(9).plot(kind='barh', ax=ax2, title='Rest of the world: $R^2$ = {:.3f} , {:.0f} Trees'.format(clfrw_best.score(xrw_test,yrw_test),best_Mrw))\nax2.set_xlabel('Feature Importance')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looking at both of these graphs, there are a lot of differences between Latin America and the rest of the world. It seems as if the most important feature for Latin America is the workplaces, while for the rest of the world are the parks, transit stations, groceries and pharmacies. All of these features seem to have a big importance when trying to determine the amount of cases/day. As well as this, the score for both models is not so high, meaning that there might be a bias and the results should not be taken as a final statement. Once again, to confirm the importance of these features LASSO linear regression was used.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"n_alpha = 100\nalpha = np.logspace(-5, 5, n_alpha)\n\nscores_la = []\nbetas_la = []\n\nscores_rw = []\nbetas_rw = []\n\nfor a in alpha:\n    lasso_la = sklearn.linear_model.Lasso(alpha=a, max_iter=10000)\n    lasso_la.fit(xla_train, yla_train)\n    scores_la.append(lasso_la.score(xla_test, yla_test))\n    betas_la.append(lasso_la.coef_)\n    \n    lasso_rw = sklearn.linear_model.Lasso(alpha=a, max_iter=10000)\n    lasso_rw.fit(xrw_train, yrw_train)\n    scores_rw.append(lasso_rw.score(xrw_test, yrw_test))\n    betas_rw.append(lasso_rw.coef_)\n\nprint(\"\")\nprint(\"Best model (LASSO): Latin America R^2 = {}\".format(max(scores_la)))\nprint(\"\")\nbest_la = np.argmax(scores_la) \nbeta_la = betas_la[best_la]\nii = np.argsort(-beta_la)\nfor i in ii:\n    if(abs(beta_la[i])>0):\n        print(atributes_name[1:-1][i], beta_la[i])\n        \nprint(\"\")\nprint(\"Best model (LASSO): Rest of the world R^2 = {}\".format(max(scores_rw)))\nprint(\"\")\nbest_rw = np.argmax(scores_rw) \nbeta_rw = betas_rw[best_rw]\nii = np.argsort(-beta_rw)\nfor i in ii:\n    if(abs(beta_rw[i])>0):\n        print(atributes_name[1:-1][i], beta_rw[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"In this case, not every feature has a coefficient different from zero, which means that some of the destinations studied do not play an important when trying to predict the number of cases per day in both Latin America and the rest of the world. Considering the results obtained for Latin America, these are consistent with those obtained with the Random Tree Regressor. This, since the features that need to be taken into account when determining the amount of cases/day are transit stations and workplaces. Also, this is consistent with the results from the first data base, since transit was the most significant feature when looking at the methods of transportation. Now, taking into account the results obtained for the rest of the world, they are clearly consistent with those obtained with the Random Forest Regressor. But, it is important to mention that the parks where knocked off when using LASSO. \n\n**So, studying the intersection between the Random Forest Regressor and the LASSO linear regression, it seems as if the most significant feature for Latin America, regarding destinations, when trying to determine the rate of cases/day are transit stations and workplaces. While for the rest of the world, are groceries, pharmacies and transit station. Lastly I cannot stress enough that the lack of data and the rough approximation of using LASSO as a linear regression is a constraint and limits the accuracy of the results.**\n","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}