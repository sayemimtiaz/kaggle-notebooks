{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom matplotlib import cm\nimport seaborn as sns; sns.set()\nimport scipy\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import silhouette_samples\nfrom sklearn import metrics\nfrom sklearn.metrics import silhouette_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import confusion_matrix\nfrom scipy.cluster.hierarchy import linkage, dendrogram, fcluster\nfrom sklearn.metrics.cluster import adjusted_rand_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1. Exploratory Data Analysis\n\nThe dataset GSE45827 was taken from kaggle (https://www.kaggle.com/brunogrisci/breast-cancer-gene-expression-cumida). It represents gene expression data from breast cancer samples curated by the Curated Microarray Database CuMiDa (http://sbcb.inf.ufrgs.br/cumida#). CuMiDa is a repository for machine learning that contains 78 handpicked cancer microarray datasets from 30.000 studies from the Gene Expression Omnibus (GEO), a public functional genomics data repository (https://www.ncbi.nlm.nih.gov/geo/). The data is already in a pre-processed and normalized format ready to be used for experimental ML approaches.","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# load dataset and explore the first rows\ndf = pd.read_csv('/kaggle/input/breast-cancer-gene-expression-cumida/Breast_GSE45827.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# retrieve number of rows and columns in the dataset\nnRow, nCol = df.shape\nprint(f'There are {nRow} rows and {nCol} columns in the breast cancer data set')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check for missing values in dataset\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check for unique ID identifiers\nprint(f\"The total ids are {df['samples'].count()}, from those the unique ids are {df['samples'].value_counts().shape[0]} \")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check for label distribution\nlabel_count = df['type'].value_counts()\nlabel_count","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualize distribution of labels\nfig = plt.figure(figsize=(7, 5))\ndf['type'].value_counts().plot(kind='bar')\nplt.xticks(rotation=45)\nplt.ylabel('Number of occurences', fontsize=12, fontweight='bold')\nplt.xlabel('Sample type', fontsize=12, fontweight='bold')\nplt.title('Distribution of label types in breast cancer data', fontsize=14, fontweight='bold')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Data Preparation for Clustering","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# assign labels to variable y\ny = df['type']\ny","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# select feature data for clustering\ndata = df.iloc[:,2:].values\ndata","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Before applying clustering, we scale our data such that each feature has unit variance. This is necessary because fitting algorithms highly depend on the scaling of the features. Here we use the StandardScaler module for scaling the features individually. StandardScaler subtracts the mean from each feature and then scales to unit variance.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaled_data = scaler.fit_transform(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaled_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Clustering Approaches","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"### k-Means Clustering","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Although the number of classes with 6 for the cancer subtypes is known for this dataset, perform a calculation and plotting of the cluster errors to see whether 6 is really the optimal size for k.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate the cluster errors for clusters from 1 to 15\ncluster_range = range( 1, 20 )\ncluster_errors = []\nfor num_clusters in cluster_range:\n  clusters = KMeans(num_clusters, n_init = 10 )\n  clusters.fit(scaled_data)\n  labels = clusters.labels_\n  centroids = clusters.cluster_centers_\n  cluster_errors.append( clusters.inertia_ )\nclusters_df = pd.DataFrame( { \"num_clusters\":cluster_range, \"cluster_errors\": cluster_errors } )\nclusters_df[0:20]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The total sum of squared distances of every data point from respective centroid is also called inertia. Let us print the inertia value for all k values. That k at which the inertia stop to drop significantly (elbow method) will be the best k.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Elbow plot\nplt.figure(figsize=(12,6))\nplt.plot(clusters_df.num_clusters, clusters_df.cluster_errors, marker = \"o\" )\nplt.xlabel('Number of clusters', fontsize=12, fontweight='bold')\nplt.ylabel('Cluster error', fontsize=12, fontweight='bold')\nplt.title('Elbow plot for determining number of clusters', fontsize=14, fontweight='bold')\nplt.savefig('elbowplot.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# instantiate KMeans object\nkm = KMeans(n_clusters=6, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predict the cluster labels\nlabels = km.fit_predict(scaled_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"km.cluster_centers_.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"centroids = km.cluster_centers_\nprint(centroids)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print cluster labels\nprint(labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## creating a new dataframe only for labels and converting it into categorical variable\ndf_labels = pd.DataFrame(km.labels_ , columns = list(['label']))\n\ndf_labels['label'] = df_labels['label'].astype('category')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Joining the label dataframe with the original data frame. \ndf_labeled = df.join(df_labels)\ndf_labeled.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_labeled['label'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Evaluate k-means Clustering","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"There are several ways to evaluate a clustering. In the following the cluster error, the silhoutte plot and score as well as the accuracy are calculated. Since the data set already has labels assigned to it, it is possible to calculate the amount of correct cluster assignments\nCalculatation of cluster error","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Distortion: %.2f' % km.inertia_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Calculation of accuracy score. Since the k-means algorithm doesn´t have any knowledge on the true cluster labels, the permutations need to be found before comparing to the true labels.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def find_permutation(n_clusters, real_labels, labels):\n    permutation=[]\n    for i in range(n_clusters):\n        idx = labels == i\n        new_label=scipy.stats.mode(real_labels[idx])[0][0]  # Choose the most common label among data points in the cluster\n        permutation.append(new_label)\n    return permutation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"permutation = find_permutation(6, y, km.labels_)\nprint(permutation)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_labels = [ permutation[label] for label in km.labels_]   # permute the labels\nprint(\"Accuracy score is\", accuracy_score(y, new_labels))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot confusion matrix\nmat = confusion_matrix(y, new_labels)\nsns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n            xticklabels=permutation,\n            yticklabels=permutation)\nplt.xlabel('true label')\nplt.ylabel('predicted label');\nplt.savefig('confustion_matrix_1')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create silhouette plot and calculate silhouette score","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# create silhoutte plot\ncluster_labels = np.unique(labels)\nn_clusters = cluster_labels.shape[0]\nsilhouette_vals = silhouette_samples(scaled_data,\n                                      labels,\n                                      metric='euclidean')\ny_ax_lower, y_ax_upper = 0, 0\nyticks = []\nfor i, c in enumerate(cluster_labels):\n     c_silhouette_vals = silhouette_vals[labels == c]\n     c_silhouette_vals.sort()\n     y_ax_upper += len(c_silhouette_vals)\n     color = cm.jet(float(i) / n_clusters)\n     plt.barh(range(y_ax_lower, y_ax_upper),\n              c_silhouette_vals,\n              height=1.0,\n              edgecolor='none',\n              color=color)\n     yticks.append((y_ax_lower + y_ax_upper) / 2.)\n     y_ax_lower += len(c_silhouette_vals)\nsilhouette_avg = np.mean(silhouette_vals)\nplt.axvline(silhouette_avg,\n             color=\"red\",\n             linestyle=\"--\")\nplt.yticks(yticks, cluster_labels + 1)\nplt.ylabel('Cluster')\nplt.xlabel('Silhouette coefficient')\nplt.tight_layout()\n#plt.show()\nplt.savefig('silhoutte_plot_1.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeansSilhouette_Score = metrics.silhouette_score(data, labels, metric='euclidean')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(kmeansSilhouette_Score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rand_index = adjusted_rand_score(labels_true = y, labels_pred = labels)\nprint('The Rand index is', round(rand_index, 2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Apply PCA to data before clustering","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# In order to find the number of dimensions explaining most of the variety in the data, plot cumulative explained variance\npca_plot = PCA().fit(scaled_data)\nplt.plot(np.cumsum(pca_plot.explained_variance_ratio_))\nplt.xlabel('number of components')\nplt.ylabel('cumulative explained variance');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In order to explain 95% of data, one would need 100 principal components.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Apply t-SNE","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"PCA didn´t seem to be a good approach as it would need 100 components to explain most of the data. Try t-SNE instead on original data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"tsne = TSNE(random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tsne_result = tsne.fit_transform(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xi = tsne_result[:, 0]\nyi = tsne_result[:, 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,10))\nsns.scatterplot(\n    x=xi, y=yi,\n    hue=y,\n    legend=\"full\",\n    alpha=1\n)\nplt.savefig('t-SNE_plot.png')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Try t-SNE on scaled data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"tsne_scaled = TSNE(random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tsne_result_scaled = tsne.fit_transform(scaled_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xi_scaled = tsne_result_scaled[:, 0]\nyi_scaled = tsne_result_scaled[:, 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,10))\nsns.scatterplot(\n    x=xi_scaled, y=yi_scaled,\n    hue=y,\n    legend=\"full\",\n    alpha=1\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"t-SNE does better on original data than on scaled data.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Run k-means algorithm on data after t-SNE with original data. t-SNE on scaled data visually doesn´t separate the clusters as well as with the original data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"km_tsne = KMeans(n_clusters = 6, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predict the cluster labels\nlabels_tsne = km_tsne.fit_predict(tsne_result)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels_tsne.size","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels_tsne","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## creating a new dataframe only for labels and converting it into categorical variable\ndf_labels_tsne = pd.DataFrame(km_tsne.labels_ , columns = list(['label']))\ndf_labels_tsne['label'] = df_labels_tsne['label'].astype('category')\ndf_labels_tsne.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_labels_tsne['label'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# silhouette plot\ncluster_labels = np.unique(labels_tsne)\nn_clusters = cluster_labels.shape[0]\nsilhouette_vals = silhouette_samples(tsne_result,\n                                      labels_tsne,\n                                      metric='euclidean')\ny_ax_lower, y_ax_upper = 0, 0\nyticks = []\nfor i, c in enumerate(cluster_labels):\n     c_silhouette_vals = silhouette_vals[labels == c]\n     c_silhouette_vals.sort()\n     y_ax_upper += len(c_silhouette_vals)\n     color = cm.jet(float(i) / n_clusters)\n     plt.barh(range(y_ax_lower, y_ax_upper),\n              c_silhouette_vals,\n              height=1.0,\n              edgecolor='none',\n              color=color)\n     yticks.append((y_ax_lower + y_ax_upper) / 2.)\n     y_ax_lower += len(c_silhouette_vals)\nsilhouette_avg = np.mean(silhouette_vals)\nplt.axvline(silhouette_avg,\n             color=\"red\",\n             linestyle=\"--\")\nplt.yticks(yticks, cluster_labels + 1)\nplt.ylabel('Cluster')\nplt.xlabel('Silhouette coefficient')\nplt.tight_layout()\n#plt.show()\nplt.savefig('silhoutte_plot_2.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeansSilhouette_Score = metrics.silhouette_score(tsne_result, labels_tsne, metric='euclidean')\nkmeansSilhouette_Score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"permutation = find_permutation(6, y, km_tsne.labels_)\nprint(permutation)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_labels = [ permutation[label] for label in km_tsne.labels_]   # permute the labels\nprint(\"Accuracy score is\", accuracy_score(y, new_labels))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This dataset has \"ground truth\" cell type labels available. We can use these to assess our cluster labels a bit more rigorously using the adjusted Rand index. This index is a measure between (0, 1) which indicates the similarity between two sets of categorical labels (e.g., our cell type labels and cluster labels). A value of 1 means the two clusterings are identical, and 0 means the level of similarity expected by random chance.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"rand_index = adjusted_rand_score(labels_true = y, labels_pred = labels_tsne)\nprint('The Rand index is', round(rand_index, 2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### UMAP","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import umap\nimport numba.targets","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clusterable_embedding = umap.UMAP(\n    n_neighbors=30,\n    min_dist=0.0,\n    n_components=2,\n    random_state=42,\n).fit_transform(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,10))\nsns.scatterplot(\n    x=clusterable_embedding[:, 0], y=clusterable_embedding[:, 1],\n    hue=y,\n    legend=\"full\",\n    alpha=1\n)\nplt.savefig('UMAP_plot.png')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Perform k-means clustering after UMAP embedding","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"km_umap = KMeans(n_clusters = 6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predict the cluster labels\nlabels_umap = km_umap.fit_predict(clusterable_embedding)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# silhouette plot\ncluster_labels = np.unique(labels_umap)\nn_clusters = cluster_labels.shape[0]\nsilhouette_vals = silhouette_samples(clusterable_embedding,\n                                      labels_umap,\n                                      metric='euclidean')\ny_ax_lower, y_ax_upper = 0, 0\nyticks = []\nfor i, c in enumerate(cluster_labels):\n     c_silhouette_vals = silhouette_vals[labels == c]\n     c_silhouette_vals.sort()\n     y_ax_upper += len(c_silhouette_vals)\n     color = cm.jet(float(i) / n_clusters)\n     plt.barh(range(y_ax_lower, y_ax_upper),\n              c_silhouette_vals,\n              height=1.0,\n              edgecolor='none',\n              color=color)\n     yticks.append((y_ax_lower + y_ax_upper) / 2.)\n     y_ax_lower += len(c_silhouette_vals)\nsilhouette_avg = np.mean(silhouette_vals)\nplt.axvline(silhouette_avg,\n             color=\"red\",\n             linestyle=\"--\")\nplt.yticks(yticks, cluster_labels + 1)\nplt.ylabel('Cluster')\nplt.xlabel('Silhouette coefficient')\nplt.tight_layout()\n#plt.show()\nplt.savefig('silhoutte_plot_3.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeansSilhouette_Score = metrics.silhouette_score(clusterable_embedding, labels_umap, metric='euclidean')\nkmeansSilhouette_Score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"permutation = find_permutation(6, y, km_umap.labels_)\nprint(permutation)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_labels = [ permutation[label] for label in km_umap.labels_]   # permute the labels\nprint(\"Accuracy score is\", accuracy_score(y, new_labels))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rand_index = adjusted_rand_score(labels_true = y, labels_pred = labels_umap)\nprint('The Rand index is', round(rand_index, 2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}