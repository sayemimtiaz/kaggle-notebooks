{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Poonam Ligade\n7th Feb 2018\n---------------------------------------------------------------------------------\n\n1. [About Yelp](#overview)\n2. [NLP using Keras Pretrained Glove word Embeddings](#keras)\n\n    2.1.  [Preparing text data](#preparation) \n    \n    2.2.  [Converting text into numerical representation i.e Tensors](#numerical)\n    \n    2.2.  [Split train and validation data](#split)\n\n3. [SpaCy Capabilities Demo](#spacy)","metadata":{"_cell_guid":"6aab0b31-6cb9-48cc-9d2c-f9021e7d4b1e","_uuid":"0bf1af1a9ed61f26343269320ac4703a365fad30"}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.utils import to_categorical\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.style.use('fivethirtyeight')\n\nimport spacy;","metadata":{"_cell_guid":"cfd474ce-b6cf-4c47-ae64-fb9700302d11","_uuid":"d86f76f9e0940838802c62f39888b441dc6dcd21","_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='overview'></a>\n\n## About Yelp\n\n**Yelp connects people with great local businesses.**\n\n ![yelp](https://s3-media3.fl.yelpcdn.com/assets/srv0/seo_metadata/f9149736ad8d/assets/img/logos/yelp_og_image.png)\n\nThis dataset is a subset of Yelp's businesses, reviews, and user data.\n\nIn this kernel I'm trying to do Natural Language Processing & Sentiment Analysis\n\nWhat's in a review? Is it positive or negative? Yelp's reviews contain a lot of metadata that can be mined and used to infer meaning, business attributes, and sentiment.\n\nCredits due :\n1. [Jeremy](https://www.kaggle.com/jhoward) [Kernel](https://www.kaggle.com/jhoward/improved-lstm-baseline-glove-dropout)\n2. [Keras](https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html) Blogpost","metadata":{"_cell_guid":"24aa980b-4c8a-4d40-baf1-d83d936fefda","_uuid":"66a3b9a9ae07e640e34c60f93afa755f270e2ca8"}},{"cell_type":"markdown","source":"<a id='keras'></a>\n\n## Bidirectional LSTM using Keras\nHow to use pre-trained word embeddings in a Keras model.\n\nBidirectional LSTMs are an extension of traditional LSTMs that can improve model performance on sequence classification problems.\n\nIn problems where all timesteps of the input sequence are available, Bidirectional LSTMs train two instead of one LSTMs on the input sequence. The first on the input sequence as-is and the second on a reversed copy of the input sequence. This can provide additional context to the network and result in faster and even fuller learning on the problem.\n\nIn this tutorial, you will discover how to develop Bidirectional LSTMs for sequence classification in Python with the Keras deep learning library.\n\ncredits : Jason Brownlee [Blog](https://machinelearningmastery.com/develop-bidirectional-lstm-sequence-classification-python-keras/)","metadata":{"_cell_guid":"55a3967d-bab0-44e0-91f7-22955ed60ea4","_uuid":"969f06b7bf45410d9066abb9adea1ed6c9d7d296"}},{"cell_type":"code","source":"yelp_reviews=pd.read_csv(\"../input/yelp-reviews/yelp.csv\",usecols=[\"stars\",\"text\"])\n","metadata":{"_cell_guid":"891241cd-9725-485c-a2c2-d20e48db541f","_uuid":"d247915d447279f8f779c74cb135b55f9e1df2dc","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yelp_reviews.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#let's check out a sample review\nyelp_reviews.text[5]","metadata":{"_cell_guid":"f1a4b8a6-134f-4707-b314-e576c0896ff7","_uuid":"0d4f6a4d2d3c4b407799e7a6555646362ea05492","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##checking for nulls\nyelp_reviews.isnull().any()","metadata":{"_cell_guid":"4aca08ee-f3c7-4171-bff6-5fb9a89240da","_uuid":"40e81f05e1d3733bc351bd94ae53bb7c273a1f8b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Great we dont have enemies!\n<a id='preparation'></a>\n\n### Preparing Text Data","metadata":{"_cell_guid":"15e017c0-8f89-41e7-8de4-10cf8ab72f76","_uuid":"db2b25add98183abe9166a3b13cecfab063bc12a"}},{"cell_type":"code","source":"yelp_reviews.stars.unique()","metadata":{"_cell_guid":"5867cca1-62f8-4871-8bea-a49871aa8d7b","_uuid":"842fcd53054f0b510dbfc7bf4931f5610607137e","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x=yelp_reviews['stars'].value_counts()\ny=x.sort_index()\n#plot\nplt.figure(figsize=(8,4))\nax= sns.barplot(y.index, x.values, alpha=0.8)\nplt.title(\"Yelp Stars for business\")\nplt.ylabel('Number of businesses', fontsize=12)\nplt.xlabel('Stars acquired ', fontsize=12);","metadata":{"_cell_guid":"4134046e-246a-4134-b2a2-1c7c5ca4b165","_uuid":"d5151aff24f8d06ecfacbbafdf4732623c1c9f9b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Since I wanted to make it simple binary classifcation problem with positive i.e, high polarity(stars= 4 and 5) and negative(stars= 1 and 2) labels I have converted stars column as binary column. We can keep neutral class as stars =3 but right now i am not dealing with that for sake of simplicity.","metadata":{"_cell_guid":"997285e2-9265-45f5-b4c3-0624714230af","_uuid":"03467c3c05ed0191c26d6412f34d3cc9fea33674"}},{"cell_type":"code","source":"reviews=yelp_reviews[:300000]\nreviews=reviews[reviews.stars!=3]\n\nreviews[\"labels\"]= reviews[\"stars\"].apply(lambda x: 1 if x > 3  else 0)\nreviews=reviews.drop(\"stars\",axis=1)\n\nreviews.head()\n","metadata":{"_cell_guid":"06eb3bdc-70e7-4763-9a78-e9c1975fbb46","_uuid":"26ac37d785f5190b7dedfe3e8b7346e1193c3f6f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"texts = reviews[\"text\"].values\nlabels = reviews[\"labels\"].values","metadata":{"_cell_guid":"498f23f1-6450-4fb7-b504-a06c63e3678a","_uuid":"0be5a1ae73dcef7564fefead44c1787588ad3682","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"alice_shelley=b'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'","metadata":{"_cell_guid":"37ff90b9-1adc-4a29-a3c1-e8444b2e4837","_uuid":"1dbf4b6fad21db27eb3b51d15817f167b3948c2e","_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import imageio\nimport codecs\nfrom wordcloud import WordCloud, STOPWORDS\nf2 = open(\"mws.png\", \"wb\")\nf2.write(codecs.decode(alice_shelley,'base64'))\nf2.close()\nimg2 = imageio.imread(\"mws.png\")\nalice_mask = img2\n\nwc = WordCloud(background_color=\"white\", max_words=5000, mask=alice_mask,\n               stopwords=STOPWORDS)\n# generate word cloud\nwc.generate(\" \".join(texts[:10000]))\n\n# show\nplt.figure(figsize=(16,13))\nplt.imshow(wc, interpolation='bilinear')\nplt.title(\"Yelp Reviews (Alice in Wonderland)\", fontsize=14,color='seagreen')\nplt.axis(\"off\");","metadata":{"_cell_guid":"70c778f0-efdb-4066-be9e-7768f117a5bd","_uuid":"e590ebfcd84394895ab537cedb66fd0f8aa14533","_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"What a beautiful wordcloud of theme Alice in wonderland.\nWe can see most popular words users have written in review are food, good , great place, price , drink , delicious etc.\n<a id='numerical'></a>\n\n\n### Converting text into numerical representation i.e Tensors\nThen we can format our text samples and labels into tensors that can be fed into a neural network. \nSome Preprocessing is needed here.\nTokenization - We need to break down the sentence into unique words. For eg, \"The cow jumped over the moon\" will become [\"The\",\"cow\",\"jumped\",\"over\",\"moon\"]\n\nTo do this, we will rely on Keras utilities keras.preprocessing.text.Tokenizer and keras.preprocessing.sequence.pad_sequences.\n\n","metadata":{"_cell_guid":"26ee8605-24cc-4c7b-961d-90ac2dd84ebf","_uuid":"cdaa0fe8658843f098777b489a7aa6056980f108"}},{"cell_type":"code","source":"\nMAX_NUM_WORDS=1000 # how many unique words to use (i.e num rows in embedding vector)\nMAX_SEQUENCE_LENGTH=100 # max number of words in a review to use\n\n\ntokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\ntokenizer.fit_on_texts(texts)\nsequences = tokenizer.texts_to_sequences(texts)\n\nword_index = tokenizer.word_index\nprint('Found %s unique tokens.' % len(word_index))\n\ndata = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n\nlabels = to_categorical(np.asarray(labels))\nprint('Shape of data tensor:', data.shape)\nprint('Shape of label tensor:', labels.shape)\n","metadata":{"_cell_guid":"dd003ff2-d26a-4f47-aa0f-94a0e53f03f4","_uuid":"e5fc665739bc312d370b6148a618ac656b62124c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='split'></a>\n\n###  split the data into a training set and a validation set","metadata":{"_cell_guid":"3c268756-f888-471d-a5c0-78f08df2aa5b","_uuid":"41790705dd7e988bc28cb47a9fbc5c33e9466a8a"}},{"cell_type":"code","source":"VALIDATION_SPLIT=0.2\n\nindices = np.arange(data.shape[0])\nnp.random.shuffle(indices)\ndata = data[indices]\nlabels = labels[indices]\nnb_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n\nx_train = data[:-nb_validation_samples]\ny_train = labels[:-nb_validation_samples]\nx_val = data[-nb_validation_samples:]\ny_val = labels[-nb_validation_samples:]","metadata":{"_cell_guid":"dd74f812-f292-4d4b-9c52-3c10a94874c7","_uuid":"bab24c329c19e62d18054643d7396e394756c7c3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='embedding_layer'></a>\n\n### Preparing the Embedding layer","metadata":{"_cell_guid":"7d6845b8-474e-46b8-9d89-81ddbfac1bfd","_uuid":"d1bd92e445069fcbcc4726ba169037830f2c55b3"}},{"cell_type":"code","source":"GLOVE_DIR='../input/glove-global-vectors-for-word-representation'\n\nimport os\nembeddings_index = {}\nf = open(os.path.join(GLOVE_DIR, 'glove.6B.50d.txt'))\nfor line in f:\n    values = line.split()\n    word = values[0]\n    coefs = np.asarray(values[1:], dtype='float32')\n    embeddings_index[word] = coefs\nf.close()\n\nprint('Found %s word vectors.' % len(embeddings_index))","metadata":{"_cell_guid":"5fbb355e-d6c0-44d5-85f3-15334074bf9c","_uuid":"9a49b3276c58ccb06d8ac532fd1855b5b8e3cdf0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='embedding_matrix'></a>\n\n\n### compute  embedding matrix\nAt this point we can leverage our embedding_index dictionary and our word_index to compute our embedding matrix\n","metadata":{"_cell_guid":"4184a0b8-c569-45df-85c9-b4287f91830a","_uuid":"8ed621c85348f1e0828caae997c94b362d841dd3"}},{"cell_type":"code","source":"EMBEDDING_DIM = 50 # how big is each word vector\n\nembedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\nfor word, i in word_index.items():\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None:\n        # words not found in embedding index will be all-zeros.\n        embedding_matrix[i] = embedding_vector","metadata":{"_cell_guid":"c5c964b6-c5b6-47fa-8370-db3cc0f929b8","_uuid":"976b7859d1bac5f31dd58f08fdca7a16193c02c1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Define Embedding Layer \n We load this embedding matrix into an Embedding layer. Note that we set trainable=False to prevent the weights from being updated during training.\n","metadata":{"_cell_guid":"3159bc0a-353d-4f42-b30b-43445599db46","_uuid":"6e20eb7f40c907c49953d02862fe2c405810ae0f"}},{"cell_type":"code","source":"from keras.layers import Embedding\n\nembedding_layer = Embedding(len(word_index) + 1,\n                            EMBEDDING_DIM,\n                            weights=[embedding_matrix],\n                            input_length=MAX_SEQUENCE_LENGTH,\n                            trainable=False)\n","metadata":{"_cell_guid":"d8633e84-8f8a-4290-9b46-d0955ff787c4","_uuid":"219a73f70bd55c51f35eb38ec9c9f70b46e1354b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training model :)","metadata":{"_cell_guid":"f9960c17-f9b5-41b9-b09d-e80c87cb3e27","_uuid":"f90b6036e77dced3f028d76efad7e9bc1a3ae61d"}},{"cell_type":"code","source":"from keras.layers import Bidirectional, GlobalMaxPool1D,Conv1D\nfrom keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n\nfrom keras.models import Model\n\n\ninp = Input(shape=(MAX_SEQUENCE_LENGTH,))\nx = embedded_sequences = embedding_layer(inp)\nx = Bidirectional(LSTM(50, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))(x)\nx = GlobalMaxPool1D()(x)\nx = Dense(50, activation=\"relu\")(x)\nx = Dropout(0.1)(x)\nx = Dense(2, activation=\"sigmoid\")(x)\nmodel = Model(inputs=inp, outputs=x)\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])","metadata":{"_cell_guid":"382382d7-66a0-4a1c-ba34-f077965d04a0","_uuid":"d8a70e2f13abb66ba977d46f17538152681defa7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(x_train, y_train, validation_data=(x_val, y_val),\n          epochs=2, batch_size=128);","metadata":{"_cell_guid":"cf14d9a6-46a9-4d3d-a47b-31e623c0e235","_uuid":"e63d04b242e8de8d02b147bc1a06b3b574e7d4e1","scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This gives us 93% accuracy. Thats not enough may be we should bring on more data.\n\n\n### Spacy\n\nspaCy is an industrial-strength natural language processing (NLP) library for Python. spaCy's goal is to take recent advancements in natural language processing out of research papers and put them in the hands of users to build production software.\n\nspaCy handles many tasks commonly associated with building an end-to-end natural language processing pipeline:\n\n1. Tokenization\n2. Text normalization, such as lowercasing, stemming/lemmatization\n3. Part-of-speech tagging\n4. Syntactic dependency parsing\n5. Sentence boundary detection\n6. Named entity recognition and annotation\n\nLet's take a sample review","metadata":{"_cell_guid":"331bfe35-3652-4b8d-b065-27f873da3dbd","_uuid":"6c3e48719c3fd8da234ecbaef85381cdcd28f81b"}},{"cell_type":"code","source":"import spacy\nnlp = spacy.load('en')\nsample_review=reviews.text[5]\nsample_review\n","metadata":{"_cell_guid":"b15c3b14-4ae0-42cf-bfb3-86a0c43dfe41","_uuid":"9f6963e349abe841d317f2695197afa6508396f9","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nparsed_review = nlp(sample_review)\nprint(parsed_review)","metadata":{"_cell_guid":"77ec4a5f-ae4f-4240-bdb4-b4c3b02fa85a","_uuid":"05a8389733463eab3b4b9ff8db30b30c7926103a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"looks like nothing changed. \nLet's check againn.\n### Sentence detection and segmentation\n\n","metadata":{"_cell_guid":"814d5754-ed96-4a60-b037-d485ecdcedbd","_uuid":"fd11962fa60a6856d22fe45cce26dbe85d38cd0e"}},{"cell_type":"code","source":"for num, sentence in enumerate(parsed_review.sents):\n    print ('Sentence {}:'.format(num + 1))\n    print (sentence)\n    print ('\\n')","metadata":{"_cell_guid":"8e9715bf-671f-4546-b39a-e99d0a893c19","_uuid":"d7260fbb597279f1761d0357aa673df7045da186","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Named entity detection","metadata":{"_cell_guid":"09391853-d481-41ac-a14d-812384e66c2a","_uuid":"00dd186b219bdac183f5eb26d103d8a584186025"}},{"cell_type":"code","source":"for num, entity in enumerate(parsed_review.ents):\n    print ('Entity {}:'.format(num + 1), entity, '-', entity.label_)\n    print ('\\n')","metadata":{"_cell_guid":"d1f832fb-310c-4083-a5a6-6e56d413825c","_uuid":"06400fb97ac3ad5ce9512d339f5c8716a69b73dc","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Part of speech tagging","metadata":{"_cell_guid":"dbb0640f-33c6-4f54-bafe-6b6034ba0364","_uuid":"0e84d3782bf3bfd381ed1307a0ad5af10d941a5b"}},{"cell_type":"code","source":"token_text = [token.orth_ for token in parsed_review]\ntoken_pos = [token.pos_ for token in parsed_review]\n\nparts_of_speech=pd.DataFrame(data=list(zip(token_text, token_pos)),columns=['token_text', 'part_of_speech'])\nparts_of_speech.head(10)","metadata":{"_cell_guid":"70c43b79-6dd7-4ab1-97ff-6ea8bda0d568","_uuid":"9c0ba69880c4185613f30991489335f24eca987c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Text normalization, like stemming/lemmatization and shape analysis\n\nThe work at this stage attempts to reduce as many different variations of similar words into a single term ( different branches all reduced to single word stem). Therefore if we have \"running\", \"runs\" and \"run\", you would really want these three distinct words to collapse into just the word \"run\". (However of course you lose granularity of the past, present or future tense).\n\n","metadata":{"_cell_guid":"8180485e-f58c-4d31-9139-fb0cd90e5c15","_uuid":"a6f72d5a63ce971802520e26b32bd611114c79f3"}},{"cell_type":"code","source":"token_lemma = [token.lemma_ for token in parsed_review]\ntoken_shape = [token.shape_ for token in parsed_review]\n\ntext_normalized_DF=pd.DataFrame(list(zip(token_text, token_lemma, token_shape)),\n             columns=['token_text', 'token_lemma', 'token_shape'])\ntext_normalized_DF.head()","metadata":{"_cell_guid":"eb83f8c4-055a-4a65-9389-93449b08c56e","_uuid":"a696a191f97a125d662f13a09f5b5271d010839c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Token-level entity analysis\n","metadata":{"_cell_guid":"da8b0505-4bf3-4f7d-8ab9-7cd7f037e1d2","_uuid":"424521ea4cf5ba5bfef4364b49555988de3ed4e2"}},{"cell_type":"code","source":"token_entity_type = [token.ent_type_ for token in parsed_review]\ntoken_entity_iob = [token.ent_iob_ for token in parsed_review]\n\nentity_analysis=pd.DataFrame(list(zip(token_text, token_entity_type, token_entity_iob)),\n             columns=['token_text', 'entity_type', 'inside_outside_begin'])\nentity_analysis.head()","metadata":{"_cell_guid":"c88839ea-e572-4fb4-b086-953ad98ae6c1","_uuid":"bad1c40c4b9f4eedc853c22eaad6bbace8610164","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Token  attributes\n\nsuch as the relative frequency of tokens, and whether or not a token matches any of these categories\n\nstopword\npunctuation\nwhitespace\nrepresents a number\nwhether or not the token is included in spaCy's default vocabulary?","metadata":{"_cell_guid":"8201f321-9770-4d89-a374-bf75d4264531","_uuid":"95083bade5e87d6f418fd4462496ed37ff5ef35f"}},{"cell_type":"code","source":"token_attributes = [(token.orth_,\n                     token.prob,\n                     token.is_stop,\n                     token.is_punct,\n                     token.is_space,\n                     token.like_num,\n                     token.is_oov)\n                    for token in parsed_review]\n\ntoken_attributes = pd.DataFrame(token_attributes,\n                  columns=['text',\n                           'log_probability',\n                           'stop?',\n                           'punctuation?',\n                           'whitespace?',\n                           'number?',\n                           'out of vocab.?'])\n\ntoken_attributes.loc[:, 'stop?':'out of vocab.?'] = (token_attributes.loc[:, 'stop?':'out of vocab.?']\n                                       .applymap(lambda x: u'Yes' if x else u''))\n                                               \ntoken_attributes.head()","metadata":{"_cell_guid":"5759af4e-6173-4d52-9b46-a0eaaee90e36","_uuid":"9503db1f370b3d70438a54471c410794e6d35c7a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}