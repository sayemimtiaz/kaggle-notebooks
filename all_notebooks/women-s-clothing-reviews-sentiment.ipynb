{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Loading Libraries and Data","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport datetime as dt\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\nimport seaborn as sns\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import confusion_matrix\nimport sklearn.metrics as mt\nfrom plotly import tools\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/womens-ecommerce-clothing-reviews/Womens Clothing E-Commerce Reviews.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()\n\n# Extract Necessary columns for analysis in another dataframe\ndf = data[['Review Text','Rating','Class Name','Age']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Analysis and Inputing Features","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Adding the word counts to a dataframe is a very good practice because we might use these counts to reach some useful information.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# fill NA values by space\ndf['Review Text'] = df['Review Text'].fillna('')\n\n# CountVectorizer() converts a collection \n# of text documents to a matrix of token counts\nvectorizer = CountVectorizer()\n\n# assign a shorter name for the analyze\n# which tokenizes the string\nanalyzer = vectorizer.build_analyzer()\n\n\ndef wordcounts(s):\n    c = {}\n    # tokenize the string and continue, if it is not empty\n    if analyzer(s):\n        d = {}\n        # find counts of the vocabularies and transform to array \n        # Returns a list of corresponding count for every word in the string \n        w = vectorizer.fit_transform([s]).toarray()\n        # Eg: \"This is a This is a very very sentence\" --> [[2 1 2 2]]\n        \n        # vocabulary and index (index of w)\n        vc = vectorizer.vocabulary_\n        # Eg: {'is': 2, 'sentence': 1, 'this': 2, 'very': 2}\n\n        # items() transforms the dictionary's (word, index) tuple pairs\n        for k,v in vc.items():\n            d[v]=k # d -> index:word \n            # vc hold information about what each value in w stands for.\n            # Eg:  d -> {2: 'this', 0: 'is', 3: 'very', 1: 'sentence'}\n            # i.e, 2nd item in w stands for 'this', 0th item in w stands for 'is',and so on\n            \n        for index,i in enumerate(w[0]):\n            c[d[index]] = i # c -> word:count\n            #Eg: {'is': 2, 'sentence': 1, 'this': 2, 'very': 2}\n    return  c","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# add new column to the dataframe\ndf['Word Counts'] = df['Review Text'].apply(wordcounts)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# selecting some words to examine detailed \nselectedwords = ['awesome','great','fantastic','extraordinary','amazing','super',\n                 'magnificent','stunning','impressive','wonderful','breathtaking',\n                 'love','content','pleased','happy','glad','satisfied','lucky',\n                 'shocking','cheerful','wow','sad','unhappy','horrible','regret',\n                 'bad','terrible','annoyed','disappointed','upset','awful','hate']\n\ndef selectedcount(dic,word):\n    if word in dic:\n        return dic[word]\n    else:\n        return 0\n    \ndfwc = df.copy()  \nfor word in selectedwords:\n    dfwc[word] = dfwc['Word Counts'].apply(selectedcount,args=(word,))\n    \ndfwc.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"word_sum = dfwc[selectedwords].sum()\nword_sum","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Selected Words')\nprint(word_sum.sort_values(ascending=False).iloc[:5])\n\nprint('\\nClass Names')\nprint(df['Class Name'].fillna(\"Empty\").value_counts().iloc[:5])\n\nfig, ax = plt.subplots(1,2,figsize=(20,10))\nwc0 = WordCloud(background_color='white',\n                      width=450,\n                      height=400 ).generate_from_frequencies(word_sum)\n\ncn = df['Class Name'].fillna(\" \").value_counts()\nwc1 = WordCloud(background_color='white',\n                      width=450,\n                      height=400 \n                     ).generate_from_frequencies(cn)\n\nax[0].imshow(wc0)\nax[0].set_title('Selected Words\\n',size=25)\nax[0].axis('off')\n\nax[1].imshow(wc1)\nax[1].set_title('Class Names\\n',size=25)\nax[1].axis('off')\n\nrt = df['Review Text']\nplt.subplots(figsize=(18,6))\nwordcloud = WordCloud(background_color='white',\n                      width=900,\n                      height=300\n                     ).generate(\" \".join(rt))\nplt.imshow(wordcloud)\nplt.title('All Words in the Reviews\\n',size=25)\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plotting relationship between Age,Class and Rating","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df1=df['Rating'].value_counts().to_frame()\navgdf1 = df.groupby('Class Name').agg({'Rating': np.average})\navgdf2 = df.groupby('Class Name').agg({'Age': np.average})\navgdf3 = df.groupby('Rating').agg({'Age': np.average})\n\ntrace1 = go.Bar(\n    x=avgdf1.index,\n    y=round(avgdf1['Rating'],2),\n    marker=dict(\n        color=avgdf1['Rating'],\n        colorscale = 'RdBu')\n)\n\ntrace2 = go.Bar(\n    x=df1.index,\n    y=df1.Rating,\n    marker=dict(\n        color=df1['Rating'],\n        colorscale = 'RdBu')\n)\n\ntrace3 = go.Bar(\n    x=avgdf2.index,\n    y=round(avgdf2['Age'],2),\n    marker=dict(\n        color=avgdf2['Age'],\n        colorscale = 'RdBu')\n)\n\ntrace4 = go.Bar(\n    x=avgdf3.index,\n    y=round(avgdf3['Age'],2),\n    marker=dict(\n        color=avgdf3['Age'],\n        colorscale = 'Reds')\n)\n\nfig = tools.make_subplots(rows=2, cols=2, print_grid=False)\n\nfig.append_trace(trace1, 1, 1)\nfig.append_trace(trace2, 1, 2)\nfig.append_trace(trace3, 2, 1)\nfig.append_trace(trace4, 2, 2)\n\nfig['layout']['xaxis1'].update(title='Class')\nfig['layout']['yaxis1'].update(title='Average Rating')\nfig['layout']['xaxis2'].update(title='Rating')\nfig['layout']['yaxis2'].update(title='Count')\nfig['layout']['xaxis3'].update(title='Class')\nfig['layout']['yaxis3'].update(title='Average Age of the Reviewers')\nfig['layout']['xaxis4'].update(title='Rating')\nfig['layout']['yaxis4'].update(title='Average Age of the Reviewers')\n\nfig['layout'].update(height=800, width=900,showlegend=False)\nfig.update_layout({'plot_bgcolor':'rgba(0,0,0,0)',\n                   'paper_bgcolor':'rgba(0,0,0,0)'})\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Sentiment Analysis Modelling","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# No Column for sentiment, so we use ratings instead\n# Rating of 4 or higher -> positive, while the ones with \n# Rating of 2 or lower -> negative \n# Rating of 3 -> neutral\ndf = df[df['Rating'] != 3]\ndf['Sentiment'] = df['Rating'] >=4\ndf.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# split data\ntrain_data,test_data = train_test_split(df,train_size=0.8,random_state=0)\n# select the columns and \n# prepare data for the models \nX_train = vectorizer.fit_transform(train_data['Review Text'])\ny_train = train_data['Sentiment']\nX_test = vectorizer.transform(test_data['Review Text'])\ny_test = test_data['Sentiment']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Logistic Regression\nstart=dt.datetime.now()\nlr = LogisticRegression()\nlr.fit(X_train,y_train)\nprint('Logistic Regression Elapsed time: ',str(dt.datetime.now()-start))\n\n# Naive Bayes\nstart=dt.datetime.now()\nnb = MultinomialNB()\nnb.fit(X_train,y_train)\nprint('Naive Bayes Elapsed time: ',str(dt.datetime.now()-start))\n\n#SVM\nstart=dt.datetime.now()\nsvm = SVC()\nsvm.fit(X_train,y_train)\nprint('SVM Elapsed time: ',str(dt.datetime.now()-start))\n\n# Neural Net\nstart=dt.datetime.now()\nnn = MLPClassifier()\nnn.fit(X_train,y_train)\nprint('Neural Net Elapsed time: ',str(dt.datetime.now()-start))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Evaluation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# define a dataframe for the predictions\ndf2 = train_data.copy()\ndf2['Logistic Regression'] = lr.predict(X_train)\ndf2['Naive Bayes'] = nb.predict(X_train)\ndf2['SVM'] = svm.predict(X_train)\ndf2['Neural Network'] = nn.predict(X_train)\ndf2.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ROC Curve and AUC","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_lr = lr.predict_proba(X_test)[:,1]\nfpr_lr,tpr_lr,_ = roc_curve(y_test,pred_lr)\nroc_auc_lr = auc(fpr_lr,tpr_lr)\n\npred_nb = nb.predict_proba(X_test)[:,1]\nfpr_nb,tpr_nb,_ = roc_curve(y_test.values,pred_nb)\nroc_auc_nb = auc(fpr_nb,tpr_nb)\n\npred_svm = svm.decision_function(X_test)\nfpr_svm,tpr_svm,_ = roc_curve(y_test.values,pred_svm)\nroc_auc_svm = auc(fpr_svm,tpr_svm)\n\npred_nn = nn.predict_proba(X_test)[:,1]\nfpr_nn,tpr_nn,_ = roc_curve(y_test.values,pred_nn)\nroc_auc_nn = auc(fpr_nn,tpr_nn)\n\nf, axes = plt.subplots(2, 2,figsize=(15,10))\n\naxes[0,0].plot(fpr_lr, tpr_lr, color='darkred', lw=2, label='ROC curve (area = {:0.2f})'.format(roc_auc_lr))\naxes[0,0].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\naxes[0,0].set(xlim=[-0.01, 1.0], ylim=[-0.01, 1.05])\naxes[0,0].set(xlabel ='False Positive Rate', ylabel = 'True Positive Rate', title = 'Logistic Regression')\naxes[0,0].legend(loc='lower right', fontsize=13)\n\naxes[0,1].plot(fpr_nb, tpr_nb, color='darkred', lw=2, label='ROC curve (area = {:0.2f})'.format(roc_auc_nb))\naxes[0,1].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\naxes[0,1].set(xlim=[-0.01, 1.0], ylim=[-0.01, 1.05])\naxes[0,1].set(xlabel ='False Positive Rate', ylabel = 'True Positive Rate', title = 'Naive Bayes')\naxes[0,1].legend(loc='lower right', fontsize=13)\n\naxes[1,0].plot(fpr_svm, tpr_svm, color='darkred', lw=2, label='ROC curve (area = {:0.2f})'.format(roc_auc_svm))\naxes[1,0].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\naxes[1,0].set(xlim=[-0.01, 1.0], ylim=[-0.01, 1.05])\naxes[1,0].set(xlabel ='False Positive Rate', ylabel = 'True Positive Rate', title = 'Support Vector Machine')\naxes[1,0].legend(loc='lower right', fontsize=13)\n\naxes[1,1].plot(fpr_nn, tpr_nn, color='darkred', lw=2, label='ROC curve (area = {:0.2f})'.format(roc_auc_nn))\naxes[1,1].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\naxes[1,1].set(xlim=[-0.01, 1.0], ylim=[-0.01, 1.05])\naxes[1,1].set(xlabel ='False Positive Rate', ylabel = 'True Positive Rate', title = 'Neural Network')\naxes[1,1].legend(loc='lower right', fontsize=13);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Confusion Matrix","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# preparation for the confusion matrix\nlr_cm=confusion_matrix(y_test.values, lr.predict(X_test))\nnb_cm=confusion_matrix(y_test.values, nb.predict(X_test))\nsvm_cm=confusion_matrix(y_test.values, svm.predict(X_test))\nnn_cm=confusion_matrix(y_test.values, nn.predict(X_test))\n\nplt.figure(figsize=(15,12))\nplt.suptitle(\"Confusion Matrices\",fontsize=24)\n\nplt.subplot(2,2,1)\nplt.title(\"Logistic Regression\")\nsns.heatmap(lr_cm, annot = True, cmap=\"Greens\",cbar=False);\n\nplt.subplot(2,2,2)\nplt.title(\"Naive Bayes\")\nsns.heatmap(nb_cm, annot = True, cmap=\"Greens\",cbar=False);\n\nplt.subplot(2,2,3)\nplt.title(\"Support Vector Machine (SVM)\")\nsns.heatmap(svm_cm, annot = True, cmap=\"Greens\",cbar=False);\n\nplt.subplot(2,2,4)\nplt.title(\"Neural Network\")\nsns.heatmap(nn_cm, annot = True, cmap=\"Greens\",cbar=False);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Precision - Recall - F1-Score","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Logistic Regression\")\nprint(mt.classification_report(y_test, lr.predict(X_test)))\nprint(\"\\n Naive Bayes\")\nprint(mt.classification_report(y_test, nb.predict(X_test)))\nprint(\"\\n Support Vector Machine (SVM)\")\nprint(mt.classification_report(y_test, svm.predict(X_test)))\nprint(\"\\n Neural Network\")\nprint(mt.classification_report(y_test, nn.predict(X_test)))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}