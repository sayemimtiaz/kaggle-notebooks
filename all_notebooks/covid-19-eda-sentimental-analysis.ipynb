{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom plotly.offline import init_notebook_mode, iplot, plot\nimport plotly.express as px\nimport plotly as py\ninit_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport cufflinks as cf\ncf.go_offline()\ncf.set_config_file(offline=False, world_readable=True)\nfrom wordcloud import WordCloud,STOPWORDS\nimport matplotlib.pyplot as plt\n\nimport warnings            \nwarnings.filterwarnings(\"ignore\") ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"covid_data = pd.read_csv('/kaggle/input/covid19-tweets/covid19_tweets.csv')\ncovid_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Total tweets in this data: {}'.format(covid_data.shape[0]))\nprint('Total Unique Users in this data: {}'.format(covid_data['user_name'].nunique()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# info of the data\n\ncovid_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"covid_data['country_name'] = covid_data['user_location'].str.split(',').str[-1]\ncovid_data['only_date'] = pd.to_datetime(covid_data['date']).dt.date","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's see top 15 users by no. of tweets\n\nuser_analysis = pd.DataFrame(covid_data['user_name'].value_counts().sort_values(ascending=False))\nuser_analysis = user_analysis.rename(columns={'user_name':'count'})\n\ntrace = go.Bar(x = user_analysis.index[:15],\n              y = user_analysis['count'][:15],\n              marker = dict(color='rgba(255,155,128,0.5)',\n              line = dict(color='rgb(0,0,0)', width=1.5)))\n\nlayout = go.Layout(title=\"Top 15 user by no. of tweets\",\n                  xaxis=dict(title='User Name',zeroline= False,\n                         gridcolor='rgb(183,183,183)',showline=True),\n                  yaxis=dict(title='Frequency of tweets',zeroline= False,\n                            gridcolor='rgb(183,183,183)',showline=True),\n                  font=dict(family='Courier New, monospace', size=12, color='rgb(0,0,0)')\n)\ndata = [trace]\nfig = go.Figure(data = data, layout = layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's see top 15 users by no. of tweets\n\nlocation_analysis = pd.DataFrame(covid_data['user_location'].value_counts().sort_values(ascending=False))\nlocation_analysis = location_analysis.rename(columns={'user_location':'count'})\n\ntrace = go.Bar(x = location_analysis.index[:15],\n              y = location_analysis['count'][:15],\n              marker = dict(color='rgba(125, 215, 180, 0.5)',\n              line = dict(color='rgb(0,0,0)', width=1.5)))\n\nlayout = go.Layout(title=\"Top 15 Location by no. of tweets\",\n                  xaxis=dict(title='Location Name',zeroline= False,\n                         gridcolor='rgb(183,183,183)',showline=True),\n                  yaxis=dict(title='Frequency of tweets',zeroline= False,\n                            gridcolor='rgb(183,183,183)',showline=True),\n                  font=dict(family='Courier New, monospace', size=12, color='rgb(0,0,0)')\n)\ndata = [trace]\nfig = go.Figure(data = data, layout = layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = {\n   \"values\": location_analysis['count'][:15],\n   \"labels\": location_analysis.index[:15],\n   \"domain\": {\"column\": 0},\n   \"name\": \"Location Name\",\n   \"hoverinfo\":\"label+percent+name\",\n   \"hole\": .4,\n   \"type\": \"pie\"\n}\nlayout = go.Layout(\n   {\n      \"title\":\"Location Ratio\",\n}\n)\n\ndata = [data]\nfig = go.Figure(data = data, layout = layout)\niplot(fig)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweet_analysis = pd.DataFrame(covid_data['only_date'].value_counts())\ntweet_analysis = tweet_analysis.rename(columns={'only_date':'count'})\n\ntrace = go.Bar(x = tweet_analysis.index,\n              y = tweet_analysis['count'],\n              marker = dict(color='rgba(150, 200, 100, 0.5)',\n              line = dict(color='rgb(0,0,0)', width=1.5)))\n\nlayout = go.Layout(barmode='group',\n                  title=\"Date wise no. of tweets\",\n                  xaxis=dict(title='Date',zeroline= False,\n                         gridcolor='rgb(183,183,183)',showline=True),\n                  yaxis=dict(title='Frequency of tweets',zeroline= False,\n                            gridcolor='rgb(183,183,183)',showline=True),\n                  font=dict(family='Courier New, monospace', size=12, color='rgb(0,0,0)')\n)\ndata = [trace]\nfig = go.Figure(data = data, layout = layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# top source \nsource_analysis = pd.DataFrame(covid_data['source'].value_counts().sort_values(ascending=False))\nsource_analysis = source_analysis.rename(columns={'source':'count'})\n\ntrace = go.Bar(x = source_analysis.index[:10],\n              y = source_analysis['count'][:10],\n              marker = dict(color='rgba(150, 125, 180, 0.5)',\n              line = dict(color='rgb(0,0,0)', width=1.5)))\n\nlayout = go.Layout(title=\"Top 10 Sources by no. of tweets\",\n                  xaxis=dict(title='Source Name',zeroline= False,\n                         gridcolor='rgb(183,183,183)',showline=True),\n                  yaxis=dict(title='Frequency of tweets',zeroline= False,\n                            gridcolor='rgb(183,183,183)',showline=True),\n                  font=dict(family='Courier New, monospace', size=12, color='rgb(0,0,0)')\n)\ndata = [trace]\nfig = go.Figure(data = data, layout = layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = {\n   \"values\": source_analysis['count'][:15],\n   \"labels\": source_analysis.index[:15],\n   \"domain\": {\"column\": 0},\n   \"name\": \"Source Name\",\n   \"hoverinfo\":\"label+percent+name\",\n   \"hole\": .4,\n   \"type\": \"pie\"\n}\nlayout = go.Layout(\n   {\n      \"title\":\"Source Ratio of Top 15 sources\",\n}\n)\ndata = [data]\nfig = go.Figure(data = data, layout = layout)\nfig.update_layout(\n    autosize=False,\n    width=1200,\n    height=700,)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def wordcloud(string):\n    wc = WordCloud(width=800,height=500,mask=None,random_state=21, max_font_size=110,stopwords=stop_words).generate(string)\n    fig=plt.figure(figsize=(16,8))\n    plt.axis('off')\n    plt.imshow(wc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stop_words=set(STOPWORDS)\ncountry_string = \" \".join(covid_data['country_name'].astype('str'))\nsource_string = \" \".join(covid_data['source'].astype('str'))\ntext_string = \" \".join(covid_data['text'])\ndescription_string = \" \".join(covid_data['user_description'].astype('str'))\nhastage_string = \" \".join(covid_data['hashtags'].astype('str'))\nlocation_string = \" \".join(covid_data['user_location'].astype('str'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wordcloud(country_string)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wordcloud(source_string)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wordcloud(text_string)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wordcloud(description_string)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wordcloud(hastage_string)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wordcloud(location_string)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentiment_data = pd.read_csv('/kaggle/input/twitterdata/finalSentimentdata2.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentiment_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentiment_data = sentiment_data.drop(columns=['Unnamed: 0'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentiment_data['sentiment'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nimport string\ndef remove_punc(text):\n    # Dealing with Punctuation\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    return text\n\nsentiment_data['text'] = sentiment_data['text'].apply(remove_punc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk import stem\nfrom nltk.corpus import stopwords\nstemmer = stem.SnowballStemmer('english')\nstopwords = set(stopwords.words('english'))\n\ndef alternative_review_messages(msg):\n    # converting messages to lowercase\n    msg = msg.lower()\n    # removing stopwords\n    msg = [word for word in msg.split() if word not in stopwords]\n    # using a stemmer\n    msg = \" \".join([stemmer.stem(word) for word in msg])\n    return msg\n\nsentiment_data['text'] = sentiment_data['text'].apply(alternative_review_messages)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SEED = 2000\nx_train, x_validation, y_train, y_validation = train_test_split(sentiment_data['text'], sentiment_data['sentiment'], \n                                                                test_size=.2, random_state=SEED)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from time import time\ndef prediction(pipeline, x_train, y_train,testtext):\n    t0 = time()\n    sentiment_fit = pipeline.fit(x_train, y_train)\n    y_pred = sentiment_fit.predict(testtext)\n    return y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import RidgeClassifier\n\nvectorizer=TfidfVectorizer()\nchecker_pipeline = Pipeline([\n            ('vectorizer', vectorizer),\n            ('classifier', RidgeClassifier())\n        ])\nvectorizer.set_params(stop_words=None, max_features=10000, ngram_range=(1,4))\nprediction=prediction(checker_pipeline,x_train, y_train,x_validation)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\ndef acc_summary(pipeline, x_train, y_train, x_test, y_test):\n    t0 = time()\n    sentiment_fit = pipeline.fit(x_train, y_train)\n    y_pred = sentiment_fit.predict(x_test)\n    train_test_time = time() - t0\n    accuracy = accuracy_score(y_test, y_pred)\n    print(\"accuracy score: {0:.2f}%\".format(accuracy*100))\n    print(\"train and test time: {0:.2f}s\".format(train_test_time))\n    print(\"-\"*80)\n    return accuracy, train_test_time\nclf_acc = acc_summary(checker_pipeline, x_train, y_train, x_validation, y_validation)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\ndef prediction2(pipeline, x_train, y_train,testtext):\n    t0 = time()\n    sentiment_fit = pipeline.fit(x_train, y_train)\n    y_pred = sentiment_fit.predict(testtext)\n    return y_pred\nchecker_pipeline2 = Pipeline([\n            ('vectorizer', vectorizer),\n            ('classifier', SVC(C=1000))\n        ])\nvectorizer.set_params(stop_words=None, max_features=10000, ngram_range=(1,4))\nprediction=prediction2(checker_pipeline2,x_train, y_train,x_validation)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_acc = acc_summary(checker_pipeline2, x_train, y_train, x_validation, y_validation)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If you found this kernel helpful, please upvote it","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}