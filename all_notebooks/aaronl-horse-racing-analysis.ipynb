{"cells":[{"metadata":{},"cell_type":"markdown","source":"# <center> Analyzing the \"Horses for Courses\" Horse Racing Dataset from Kaggle </center>"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import chisquare, ttest_ind, zscore\n\n%matplotlib inline\n\n#Supresses scientific notation\npd.set_option('display.float_format', lambda x: '%.2f' % x)\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#There are a lot of issues with the 'position_two' column, so I left it out.\n#Furthermore, the 'position_again' column is much more consistent and has all relevant win/place information  \n\nfields = [\"position_again\",\"bf_odds\",\"venue_name\",\"date\",\"market_name\",\"condition\",\n          \"barrier\",\"handicap_weight\",\"last_twenty_starts\",\"prize_money\",\"sex\",\n          \"age\",\"jockey_sex\",\"days_since_last_run\",\"overall_starts\",\"overall_wins\",\n          \"overall_places\",\"track_starts\",\"track_wins\",\"track_places\",\"firm_starts\",\n          \"firm_wins\",\"firm_places\",\"good_starts\",\"good_wins\",\"good_places\",\n          \"slow_starts\",\"slow_wins\",\"slow_places\",\"soft_starts\",\"soft_wins\",\n          \"soft_places\",\"heavy_starts\",\"heavy_wins\",\"heavy_places\",\"distance_starts\",\n          \"distance_wins\",\"distance_places\"]\n\ndf = pd.read_csv('../input/horses 2.csv', usecols=fields, skipinitialspace=True, low_memory=False)\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## I decided not to use any man-made metrics (e.g. odds, field strength, etc.) because these are relative and subject to change.\n\n## Also, jockey and trainer win percentages are not included with this dataset.\n\n## Fixing the format of some features:"},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"df.date = pd.to_datetime(df.date, format='%Y'+'-'+'%m'+'-'+'%d')\n\n#removes numbers from end of 'condition' strings\ndf.condition = df.condition.str.replace('\\d+', '')\n\n#renaming condition values so that they're uniform\ndf.condition = df.condition.replace(['HVY','AWT'], ['HEAVY','GOOD']) \n#AWT equates to a Good surface under some weather conditions\n\n#reverses 'last_five_starts' (originally written right-to-left) \n#so that it's easier to read in the future\ndf.last_twenty_starts = df.last_twenty_starts.str[::-1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Useful Cleaning Functions:"},{"metadata":{"trusted":false},"cell_type":"code","source":"def column_cleaner(cleaned_df, grouped_df, column_name):\n    non_null_indices = grouped_df[column_name].apply(lambda x: all(x.notnull()))\n    \n    non_null_df = cleaned_df[non_null_indices]\n    \n    non_null_grouped = non_null_df.groupby(['date','venue_name','market_name'])\n    \n    clean_indices = non_null_grouped[column_name].value_counts(normalize=True,dropna=False).\\\n        where(lambda x:x != 1).dropna().index.droplevel(column_name)\n    \n    new_cleaned_df = non_null_df.loc[clean_indices].drop_duplicates()\n    return new_cleaned_df\n\ndef cleaned_win_df(cleaned_df):\n    win_indices = cleaned_df.position_again.apply(lambda x:x == 1)\n    \n    df_cleaned_win = cleaned_df[win_indices]\n    return df_cleaned_win","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creating new features and dropping others in order to relate horses in each race to one another while allowing the general input of the dataset into a machine learning model:"},{"metadata":{},"cell_type":"markdown","source":"## Creating a distance column from market_name:"},{"metadata":{"trusted":false},"cell_type":"code","source":"new = df.market_name.str.split(expand=True)\n\ndf['distance'] = new[1].str.rstrip('m')\n\ndf.distance = df.distance.astype(np.int64)\n\ndf.distance.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating general and track, distance, condition-specific 'win_percent' and 'place_percent' columns:"},{"metadata":{"trusted":false},"cell_type":"code","source":"#creates overall, track, and distance win_percent and place_percent columns\n#and drops existing wins and places columns\n\ncolumns_list = [\"overall\",\"track\",\"distance\"]\n\nfor x in columns_list:\n    df[x+\"_win_percent\"] = df[x+\"_wins\"]/df[x+\"_starts\"]\n    \n    df[x+\"_place_percent\"] = df[x+\"_places\"]/df[x+\"_starts\"]\n\n    # dropping various columns, though 'starts' columns will be used later\n    df.drop([x+'_wins', x+'_places'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#creates a condition_starts ,condition_win_percent, and condition_place_percent column\n#for each horse according to the condition of the track for that race\n\ndf.loc[df.condition.isna(), \"condition_win_percent\"] = np.nan\n\ncondition_list = [\"firm\",\"good\",\"slow\",\"soft\",\"heavy\"]\n\nfor x in condition_list: \n    df.loc[df.condition.str.lower() == x, \"condition_starts\"] = df[x+\"_starts\"]\n    \n    df.loc[df.condition.str.lower() == x, \"condition_win_percent\"] = df[x+\"_wins\"]/df[x+\"_starts\"]\n    \n    df.loc[df.condition.str.lower() == x, \"condition_place_percent\"] = df[x+\"_places\"]/df[x+\"_starts\"]\n    \n    df.drop([x+'_starts', x+'_wins', x+'_places'], axis=1, inplace=True)\n\n# Replaces infinity (zero division) with NaN\ndf.replace([np.inf, -np.inf], np.nan, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Find and drop features that are primarily NaN:"},{"metadata":{"trusted":false},"cell_type":"code","source":"df.isnull().sum()\n#The position_again is primarily nan values because it only shows first and place\n#However, track_starts is primarily zeros, so the track_win/place_percent columns are nan","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df.drop(['track_win_percent','track_place_percent'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#position_again unique values\ndf.position_again.unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Splits last_twenty_starts column into 20 separate columns, replaces values, then drops last_twenty_starts:"},{"metadata":{"trusted":false},"cell_type":"code","source":"new = pd.DataFrame()\n\nfor i in range(20):\n    new[i] = df.last_twenty_starts.str[i:i+1]\n\nfor i in range(20):\n    df['last_start'+str(i+1)] = new[i].replace(['0','','x','f'],['ten+','none','scratch','fell'])    \n\ndf.drop('last_twenty_starts',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Cleaning data by removing races with missing win and/or place values in 'position_again' column:"},{"metadata":{"trusted":false},"cell_type":"code","source":"#Used groupby to create indices by which to sort the re-indexed dataframes below, like df_indexed and df_cleaned\ndf_grouped = df.groupby(['date','venue_name','market_name'])\n\n#Drops all groups/races in 'position_again' column where sum of values [1st, 2nd, 3rd] don't add to 3 or 6\n#i.e. 1+2 and 1+2+3\nindex_list1 = df_grouped.position_again.sum(dropna=False).where(lambda x:(x == 3) | (x == 6)).dropna().index\n\ndf_indexed = df.set_index(['date','venue_name','market_name'])\n\ndf_cleaned = df_indexed.loc[index_list1].drop_duplicates()\n\ndf_grouped = df_cleaned.groupby(['date','venue_name','market_name'])\n\n#Eliminates remaining errors in 'position_again' column by making sure that there isn't a single 3rd-place finish\nindex_list2 = df_grouped.position_again.value_counts(normalize=True,dropna=False)\\\n    .where(lambda x:x != 1).dropna().index.droplevel('position_again')\n\ndf_cleaned = df_cleaned.loc[index_list2].drop_duplicates()\n\ndf_grouped = df_cleaned.groupby(['date','venue_name','market_name'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Normalizing each group (race) using z-scores is a good and straightforward way to compare horses across races.\n\n## Here, I am creating several normalized columns in this way."},{"metadata":{},"cell_type":"markdown","source":"## Creating a weight_z column:"},{"metadata":{"trusted":false},"cell_type":"code","source":"df_cleaned['weight_z'] = df_grouped['handicap_weight'].transform(lambda x: zscore(x,ddof=1))\n\ndf_cleaned.drop('handicap_weight',axis=1,inplace=True)\n\ndf_grouped = df_cleaned.groupby(['date','venue_name','market_name'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating a prize_money_per_start_z column:\n\n### This may be one of the best indicators, as prize money is also an indicator of the difficulty of past races. Therefore, the value (meaningfulness) of past wins is taken into consideration."},{"metadata":{"trusted":false},"cell_type":"code","source":"#creates prize_money_per_start column\ndf_cleaned['prize_money_per_start'] = df_cleaned.prize_money/df_cleaned.overall_starts\n\ndf_cleaned['prize_money_per_start_z'] = df_grouped['prize_money_per_start']\\\n    .transform(lambda x: zscore(x,ddof=1))\n\ndf_cleaned.drop(['prize_money','prize_money_per_start'],axis=1,inplace=True)\n\ndf_grouped = df_cleaned.groupby(['date','venue_name','market_name'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating a horse age_z column:"},{"metadata":{"trusted":false},"cell_type":"code","source":"df_cleaned['age_z'] = df_grouped['age'].transform(lambda x: zscore(x,ddof=1))\n\ndf_cleaned.drop('age',axis=1,inplace=True)\n\ndf_grouped = df_cleaned.groupby(['date','venue_name','market_name'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating race-relative z-scores for the remaining continuous features:"},{"metadata":{"trusted":false},"cell_type":"code","source":"z_score_cols = ['days_since_last_run','overall_win_percent','overall_place_percent',\n                'distance_win_percent','distance_place_percent','condition_win_percent',\n                'condition_place_percent','overall_starts','distance_starts','condition_starts',\n                'track_starts']\n\nfor col in z_score_cols:\n    df_cleaned[col+'_z'] = df_grouped[col].transform(lambda x: zscore(x,ddof=1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## I decided to keep the original \"overall_starts,\" \"distance_starts,\" \"condition_starts,\" and \"track_starts\" columns because they may have a meaning irrespective of other races (unnormalized)."},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"#Replaces infinity (zero division) with NaN\ndf_cleaned.replace([np.inf, -np.inf], np.nan, inplace=True)\n\ndf_grouped = df_cleaned.groupby(['date','venue_name','market_name'])\n\ndf_cleaned.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Cleaned Dataframe Details:"},{"metadata":{"trusted":false},"cell_type":"code","source":"df_cleaned.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"len(df_grouped) #Number of remaining races","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Testing and graphing the significance of certain features:"},{"metadata":{},"cell_type":"markdown","source":"## For horse gender:"},{"metadata":{"trusted":false},"cell_type":"code","source":"#Removes races where only one horse gender is represented\nsex_pop_cleaned = column_cleaner(df_cleaned, df_grouped, 'sex')\n\nsex_pop_cleaned_win = cleaned_win_df(sex_pop_cleaned)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#General percentage of horse genders for races where multiple genders are represented  \nsex_pop_cleaned.sex.value_counts(dropna=False,normalize=True).sort_values(ascending=False)\\\n    .drop('Unknown')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sex_pop_cleaned_win.sex.value_counts(dropna=False,normalize=True).sort_values(ascending=False)\\\n    .drop('Unknown')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"horse_sex_pop = sex_pop_cleaned.sex.value_counts(dropna=False,normalize=True)\\\n    .sort_values(ascending=False).drop('Unknown')\n\nhorse_sex_win = sex_pop_cleaned_win.sex.value_counts(dropna=False,normalize=True)\\\n    .sort_values(ascending=False).drop('Unknown')\n\nhorse_sex_percent_difference = (horse_sex_win - horse_sex_pop)/horse_sex_pop\n\nhorse_sex_percent_difference","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"index1 = ['Gelding', 'Mare', 'Filly','Colt', 'Horse']\n\ndf1 = pd.DataFrame({'Total Proportion': horse_sex_pop,'Win Proportion': horse_sex_win ,\n                    'Percent Difference': horse_sex_percent_difference}, index=index1)\n\nax = df1.plot.bar(rot=0,title='The Significance of Horse Gender')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Using the Pearson's chi-squared, I find horse gender is significant:"},{"metadata":{"trusted":false},"cell_type":"code","source":"observed1 = sex_pop_cleaned_win.sex.value_counts().sort_values(ascending=False)\\\n    .drop('Unknown').values\n\nexpected_percentages1 = horse_sex_pop.values\nexpected1 = [x*observed1.sum() for x in expected_percentages1]\n\ntest_stat1, p_value1 = chisquare(observed1, expected1)\n\ntest_stat1, p_value1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## For horse age_z (z-scores):"},{"metadata":{"trusted":false},"cell_type":"code","source":"#Removing races where there is only one age\nage_pop_cleaned = column_cleaner(df_cleaned, df_grouped, 'age_z')\n\nage_pop_cleaned_win = cleaned_win_df(age_pop_cleaned)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"age_pop_cleaned.age_z.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"age_pop_cleaned_win.age_z.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data2a = age_pop_cleaned.age_z.dropna().values\ndata2b = age_pop_cleaned_win.age_z.dropna().values\n\nplt.title(\"Winner and Race Distributions of Age Z-scores\", fontsize=15)\n\nplt.hist(data2a, density=True, bins=24, range=(-3,3), label='Race Average', \n         color='b', alpha=.5, edgecolor='k')\n\nplt.hist(data2b, density=True, bins=24, range=(-3,3), label='Winner Average',\n         color='r', alpha=.5, edgecolor='k')\n\nplt.legend(loc='upper right')\nplt.xlabel('Age Z-scores')\nplt.ylabel('Probability');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Using a 2-sample T-test, I find that Age Z-scores is significant:"},{"metadata":{"trusted":false},"cell_type":"code","source":"test_stat2, p_value2 = ttest_ind(data2a, data2b)\n\ntest_stat2, p_value2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Does condition affect the win distribution of age? Specifically, do older horses perform worse in bad conditions?"},{"metadata":{"trusted":false},"cell_type":"code","source":"condit_age_pop = age_pop_cleaned[age_pop_cleaned.condition == 'HEAVY']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"condit_age_pop_win = cleaned_win_df(condit_age_pop)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data2c = condit_age_pop.age_z.dropna().values\ndata2d = condit_age_pop_win.age_z.dropna().values\n\nplt.title(\"Winner and Race Distributions of Age Z-scores \\n (Condition Specific)\", fontsize=15)\n\nplt.hist(data2c, density=True, bins=24, range=(-3,3), label='Race Average', \n         color='b', alpha=.5, edgecolor='k')\n\nplt.hist(data2d, density=True, bins=24, range=(-3,3), label='Winner Average',\n         color='r', alpha=.5, edgecolor='k')\n\nplt.legend(loc='upper right')\nplt.xlabel('Age Z-scores')\nplt.ylabel('Probability');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Condition depended T-test for Age Z-scores: "},{"metadata":{"trusted":false},"cell_type":"code","source":"test_stat2, p_value2 = ttest_ind(data2c, data2d)\n\ntest_stat2, p_value2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### It appears as though bad track conditions actually level out the age discrepancies, maybe because they have more experience with those bad conditions."},{"metadata":{},"cell_type":"markdown","source":"## For horse handicap weight_z (z-scores):"},{"metadata":{"trusted":false},"cell_type":"code","source":"#Removing races where there is only one age\nweight_pop_cleaned = column_cleaner(df_cleaned, df_grouped, 'weight_z')\n\nweight_pop_cleaned_win = cleaned_win_df(weight_pop_cleaned)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"weight_pop_cleaned.weight_z.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"weight_pop_cleaned_win.weight_z.describe()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"data3a = weight_pop_cleaned.weight_z.dropna().values\ndata3b = weight_pop_cleaned_win.weight_z.dropna().values\n\nplt.title(\"Winner and Race Distributions of Weight Z-scores\", fontsize=15)\n\nplt.hist(data3a, density=True, bins=24, range=(-3,3), label='Race Average', \n         color='b', alpha=.5, edgecolor='k')\n\nplt.hist(data3b, density=True, bins=24, range=(-3,3), label='Winner Average',\n         color='r', alpha=.5, edgecolor='k')\n\nplt.legend(loc='upper right')\nplt.xlabel('Weight Z-scores')\nplt.ylabel('Probability');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Using a 2-sample T-test, again I find that Weight Z-scores is significant:"},{"metadata":{"trusted":false},"cell_type":"code","source":"test_stat3, p_value3 = ttest_ind(data3a, data3b)\n\ntest_stat3, p_value3","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## For prize money, using prize_money_per_start_z (z-scores):"},{"metadata":{"trusted":false},"cell_type":"code","source":"money_pop_cleaned = column_cleaner(df_cleaned, df_grouped, 'prize_money_per_start_z')\n\nmoney_pop_cleaned_win = cleaned_win_df(weight_pop_cleaned)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"money_pop_cleaned.prize_money_per_start_z.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Winner prize money \nmoney_pop_cleaned_win.prize_money_per_start_z.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data4a = money_pop_cleaned.prize_money_per_start_z.dropna().values\ndata4b = money_pop_cleaned_win.prize_money_per_start_z.dropna().values\n\nplt.title(\"Winner and Race Distributions of Prize Money per Start Z-scores\",\n          fontsize=15)\n\nplt.hist(data4a, density=True, bins=24, range=(-3,3), label='Race Average',\n         color='b', alpha=.6, edgecolor='k')\n\nplt.hist(data4b, density=True, bins=24, range=(-3,3), label='Winner Average',\n         color='r', alpha=.5, edgecolor='k')\n\nplt.legend(loc='upper right')\nplt.xlabel('Prize Money per Start Z-scores')\nplt.ylabel('Probability');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Using a 2-sample T-test, I find that Prize Money per Start Z-scores is significant:\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"test_stat4, p_value4 = ttest_ind(data4a, data4b)\n\ntest_stat4, p_value4","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## For overall wins:"},{"metadata":{"trusted":false},"cell_type":"code","source":"overall_win_pop_cleaned = column_cleaner(df_cleaned, df_grouped, 'overall_win_percent_z')\n\noverall_win_pop_cleaned_win = cleaned_win_df(overall_win_pop_cleaned)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"overall_win_pop_cleaned.overall_win_percent_z.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"overall_win_pop_cleaned_win.overall_win_percent_z.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data5a = overall_win_pop_cleaned.overall_win_percent_z.dropna().values\ndata5b = overall_win_pop_cleaned_win.overall_win_percent_z.dropna().values\n\nplt.title(\"Winner and Race Distributions of Overall Win Percent Z-scores\",\n          fontsize=15)\n\nplt.hist(data5a, density=True, bins=24, range=(-3,3), label='Race Average',\n         color='b', alpha=.6, edgecolor='k')\n\nplt.hist(data5b, density=True, bins=24, range=(-3,3), label='Winner Average',\n         color='r', alpha=.5, edgecolor='k')\n\nplt.legend(loc='upper right')\nplt.xlabel('Overall Win Percent Z-scores')\nplt.ylabel('Probability');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Using a 2-sample T-test, I find that Overall Win Percent Z-scores is significant:"},{"metadata":{"trusted":false},"cell_type":"code","source":"test_stat5, p_value5 = ttest_ind(data5a, data5b)\n\ntest_stat5, p_value5","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### There is high variance in the 100% column (aka beginner's luck). How many races before the 100% column is properly represented? That is, how many races is considered statistically significant?\n\n### It seems that a minimum of 5 races for all horses in the race gives the percent difference bar graph an exponential appearance."},{"metadata":{"trusted":false},"cell_type":"code","source":"overall_win_pop_grouped = overall_win_pop_cleaned.groupby(['date','venue_name',\n                                                           'market_name'])\n\noverall_starts_indices = overall_win_pop_grouped.overall_starts.agg('min')\\\n    .where(lambda x:x >= 5).dropna().index\n\noverall_starts_cleaned = overall_win_pop_cleaned.loc[overall_starts_indices].drop_duplicates()\n\noverall_starts_cleaned_win = cleaned_win_df(overall_starts_cleaned)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"overall_starts_cleaned.overall_win_percent_z.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"overall_starts_cleaned_win.overall_win_percent_z.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data6a = overall_starts_cleaned.overall_win_percent_z.dropna().values\ndata6b = overall_starts_cleaned_win.overall_win_percent_z.dropna().values\n\nplt.title(\"Winner and Race Distributions of Overall Win Percent Z-scores \\n (with horses over 5 total races)\",\n          fontsize=15)\n\nplt.hist(data6a, density=True, bins=24, range=(-3,3), label='Race Average',\n         color='b', alpha=.6, edgecolor='k')\n\nplt.hist(data6b, density=True, bins=24, range=(-3,3), label='Winner Average',\n         color='r', alpha=.5, edgecolor='k')\n\nplt.legend(loc='upper right')\nplt.xlabel('Overall Win Percent Z-scores \\n (with horses over 5 total races)')\nplt.ylabel('Probability');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Using a 2-sample T-test, I find that Overall Win Percent Z-scores (with horses over 5 total races) is significant:"},{"metadata":{"trusted":false},"cell_type":"code","source":"test_stat6, p_value6 = ttest_ind(data6a, data6b)\n\ntest_stat6, p_value6","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## For Barrier:"},{"metadata":{"trusted":false},"cell_type":"code","source":"barrier_pop_cleaned = column_cleaner(df_cleaned, df_grouped, 'barrier')\n\nbarrier_grouped = barrier_pop_cleaned.groupby(['date','venue_name','market_name'])\n\nbarrier_indices = barrier_grouped.barrier.value_counts().where(lambda x:x == 1)\\\n    .dropna().index.droplevel('barrier')\n\nbarrier_pop_cleaned = barrier_pop_cleaned.loc[barrier_indices]\n\nbarrier_pop_cleaned_win = cleaned_win_df(barrier_pop_cleaned)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"barrier_pop = barrier_pop_cleaned.barrier.value_counts(normalize=True).sort_index()\\\n    .drop([18.00,19.00,20.00])\n\nbarrier_win = barrier_pop_cleaned_win.barrier.value_counts(normalize=True).sort_index()\\\n    .drop(18.00)\n\nbarrier_percent_difference = (barrier_win - barrier_pop)/barrier_pop\n\nbarrier_percent_difference","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"index7 = barrier_percent_difference.index\n\ndf7 = pd.DataFrame({'Total Proportion': barrier_pop,'Win Proportion': barrier_win,\n                    'Percent Difference': barrier_percent_difference}, index=index7)\n\nax = df7.plot.bar(rot=0, title='The Significance of Barrier')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Why is barrier 1 so overrepresented? Is there a problem with the data? There doesn't appear to be.\n\n### Using the Pearson's chi-squared test, I find that barrier is significant:"},{"metadata":{"trusted":false},"cell_type":"code","source":"observed7 = barrier_pop_cleaned_win.barrier.value_counts().sort_index().drop(18.00).values\nexpected_percentages7 = barrier_pop.values\nexpected7 = [x*observed7.sum() for x in expected_percentages7]\n\ntest_stat7, p_value7 = chisquare(observed7, expected7)\n\ntest_stat7, p_value7","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Does the length of a race negate or alter the effect of starting barrier?"},{"metadata":{"trusted":false},"cell_type":"code","source":"barr_dist_indices = barrier_pop_cleaned.distance.where(lambda x:x>=1800).dropna().index\n\nbarr_dist_cleaned = barrier_pop_cleaned.loc[barr_dist_indices]\n\nbarr_dist_cleaned_win = cleaned_win_df(barr_dist_cleaned)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"barr_dist_pop = barr_dist_cleaned.barrier.value_counts(normalize=True).sort_index()\\\n    .drop(18.00)\n\nbarr_dist_win = barr_dist_cleaned_win.barrier.value_counts(normalize=True).sort_index()\\\n    .drop(18.00)\n\nbarr_dist_percent_difference = (barr_dist_win - barr_dist_pop)/barr_dist_pop\n\nbarr_dist_percent_difference","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"index7a = barr_dist_percent_difference.index\n\ndf7a = pd.DataFrame({'Total Proportion': barr_dist_pop,'Win Proportion': barr_dist_win,\n                    'Percent Difference': barr_dist_percent_difference}, index=index7a)\n\nax = df7a.plot.bar(rot=0, title='The Significance of Barrier for Races Longer than 1800m')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### It appears that there may be an even bigger distinction with barrier 1 with longer race distances. However, the other barriers seem to even out."},{"metadata":{},"cell_type":"markdown","source":"## For jockey gender: "},{"metadata":{},"cell_type":"markdown","source":"#### Overall percentage of men and women in races where both are represented:"},{"metadata":{"trusted":false},"cell_type":"code","source":"#Drops races where there is only one jockey gender, meaning that the other gender can't win\njockey_sex_cleaned = column_cleaner(df_cleaned, df_grouped, 'jockey_sex')\n\njockey_sex_cleaned_win = cleaned_win_df(jockey_sex_cleaned)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Finding the total a different way:"},{"metadata":{"trusted":false},"cell_type":"code","source":"jockey_sex_cleaned.jockey_sex.value_counts(normalize=True)\n#This amount is the sum of all 'male' and 'female' jockeys added together and THEN 'normalized'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Win percentage of those races:"},{"metadata":{"trusted":false},"cell_type":"code","source":"#Isolates wins in races with both jockey genders represented\njockey_sex_cleaned_win.jockey_sex.value_counts(normalize=True, dropna=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Finding the percent difference between win and total\njockey_sex_pop = jockey_sex_cleaned.jockey_sex.value_counts(normalize=True,\n                                                            dropna=False).values\n\njockey_sex_win = jockey_sex_cleaned_win.jockey_sex.value_counts(normalize=True,\n                                                                dropna=False).values\n\njockey_sex_percent_difference = (jockey_sex_win - jockey_sex_pop)/jockey_sex_pop","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"index8 = ['Men','Women']\n\ndf8 = pd.DataFrame({'Total Proportion': jockey_sex_pop,'Win Proportion': jockey_sex_win ,\n                    'Percent Difference': jockey_sex_percent_difference}, index=index8)\n\nax = df8.plot.bar(rot=0, title='The Significance of Jockey Gender')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Using a 2-proportion z-test, I find that jockey gender is significant with a p-value of 2.3E-30\n#### (There is currently a bug with the statsmodels library concering compatibility with scipy, so I used a scientific calculator)"},{"metadata":{},"cell_type":"markdown","source":"## How far back does form (previous finishes) become irrelevant?\n\n### The distribution after 1 start:"},{"metadata":{"trusted":false},"cell_type":"code","source":"last_start_pop_cleaned = column_cleaner(df_cleaned, df_grouped, 'last_start1')\n\nlast_start_pop_cleaned_win = cleaned_win_df(last_start_pop_cleaned)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Finding the percent difference between win and total\nlast_start_pop = last_start_pop_cleaned.last_start1.value_counts(normalize=True,\n                                                                 dropna=False)\n\nlast_start_win = last_start_pop_cleaned_win.last_start1.value_counts(normalize=True,\n                                                                     dropna=False)\n\nlast_start_percent_difference = (last_start_win - last_start_pop)/last_start_pop\n\nlast_start_percent_difference","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"index9 = ['1','2','3','4','5','6','7','8','9','ten+','scratch','fell','none']\n\ndf9 = pd.DataFrame({'Total Proportion': last_start_pop,'Win Proportion': last_start_win,\n                    'Percent Difference': last_start_percent_difference}, index=index9)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### After 5 starts:"},{"metadata":{"trusted":false},"cell_type":"code","source":"last_start_pop_cleaned = column_cleaner(df_cleaned, df_grouped, 'last_start5')\n\nlast_start_pop_cleaned_win = cleaned_win_df(last_start_pop_cleaned)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Finding the percent difference between win and total\nlast_start_pop = last_start_pop_cleaned.last_start5.value_counts(normalize=True,\n                                                                 dropna=False)\n\nlast_start_win = last_start_pop_cleaned_win.last_start5.value_counts(normalize=True,\n                                                                     dropna=False)\n\nlast_start_percent_difference = (last_start_win - last_start_pop)/last_start_pop","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"index10 = ['1','2','3','4','5','6','7','8','9','ten+','scratch','fell','none']\n\ndf10 = pd.DataFrame({'Total Proportion': last_start_pop,'Win Proportion': last_start_win,\n                    'Percent Difference': last_start_percent_difference}, index=index10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### After 10 starts:"},{"metadata":{"trusted":false},"cell_type":"code","source":"last_start_pop_cleaned = column_cleaner(df_cleaned, df_grouped, 'last_start10')\n\nlast_start_pop_cleaned_win = cleaned_win_df(last_start_pop_cleaned)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Finding the percent difference between win and total\nlast_start_pop = last_start_pop_cleaned.last_start10.value_counts(normalize=True,\n                                                                 dropna=False)\n\nlast_start_win = last_start_pop_cleaned_win.last_start10.value_counts(normalize=True,\n                                                                     dropna=False)\n\nlast_start_percent_difference = (last_start_win - last_start_pop)/last_start_pop","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"index11 = ['1','2','3','4','5','6','7','8','9','ten+','scratch','fell','none']\n\ndf11 = pd.DataFrame({'Total Proportion': last_start_pop,'Win Proportion': last_start_win,\n                    'Percent Difference': last_start_percent_difference}, index=index11)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### After 13 starts:"},{"metadata":{"trusted":false},"cell_type":"code","source":"last_start_pop_cleaned = column_cleaner(df_cleaned, df_grouped, 'last_start13')\n\nlast_start_pop_cleaned_win = cleaned_win_df(last_start_pop_cleaned)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Finding the percent difference between win and total\nlast_start_pop = last_start_pop_cleaned.last_start13.value_counts(normalize=True,\n                                                                 dropna=False)\n\nlast_start_win = last_start_pop_cleaned_win.last_start13.value_counts(normalize=True,\n                                                                     dropna=False)\n\nlast_start_percent_difference = (last_start_win - last_start_pop)/last_start_pop\n\nlast_start_percent_difference","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"index12 = ['1','2','3','4','5','6','7','8','9','ten+','scratch','fell','none']\n\ndf12 = pd.DataFrame({'Total Proportion': last_start_pop,'Win Proportion': last_start_win,\n                    'Percent Difference': last_start_percent_difference}, index=index12)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Graphing form data:"},{"metadata":{"trusted":false},"cell_type":"code","source":"fig,ax1 = plt.subplots(2, 2)\n\ndf9.plot.bar(ax=ax1[0,0],figsize=(20, 10)).set_title('The Significance of Previous Result')\ndf10.plot.bar(ax=ax1[0,1],figsize=(20, 10)).set_title('The Significance of 5 Results Ago')\ndf11.plot.bar(ax=ax1[1,0],figsize=(20, 10)).set_title('The Significance of 10 Results Ago')\ndf12.plot.bar(ax=ax1[1,1],figsize=(20, 10)).set_title('The Significance of 13 Results Ago')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# How often would you win and what would be your expected return if you always bet on the favorite?"},{"metadata":{"trusted":false},"cell_type":"code","source":"odds_cleaned = column_cleaner(df_cleaned, df_grouped, 'bf_odds')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#creates dataframe with a unique index\nodds_cleaned['uniq_idx'] = range(len(odds_cleaned))\nodds_cleaned_uniq_idx = odds_cleaned.set_index('uniq_idx',append=True)\nuniq_idx_grouped = odds_cleaned_uniq_idx.groupby(['date','venue_name',\n                                                  'market_name'])\n\nodds_cleaned_uniq_idx.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"bf_min_indices = uniq_idx_grouped.bf_odds.idxmin\n    \nmin_odds_cleaned = odds_cleaned_uniq_idx.loc[bf_min_indices].drop_duplicates()\n\nmin_odds_win = cleaned_win_df(min_odds_cleaned)\n\nodds_pop = len(min_odds_cleaned)\nodds_win = len(min_odds_win)\n\naverage = min_odds_win.bf_odds.agg('min').mean()\n\n#Printing total number of favorite horses (equal to the number of races) and the number of times those horses win:\nprint(len(min_odds_cleaned))\nprint(len(min_odds_win))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### How often the favorite wins:"},{"metadata":{"trusted":false},"cell_type":"code","source":"odds_win/odds_pop","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### The expected return if betting 1 dollar on favorite every race:"},{"metadata":{"trusted":false},"cell_type":"code","source":"-1*(1-odds_win/odds_pop) + average*odds_win/odds_pop","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Beginning the Machine Learning Process:"},{"metadata":{},"cell_type":"markdown","source":"## Dropping null-majority features, creating dummy variables, and replacing null values:"},{"metadata":{"trusted":false},"cell_type":"code","source":"df_cleaned.drop(['condition_place_percent_z','condition_win_percent_z',\n                 'distance_place_percent_z','distance_win_percent_z'],\n                axis=1,inplace=True)\n\n#drops last_start 11 through 20 to match information provided on racing websites\nfor i in range(10,20):\n    df_cleaned.drop('last_start'+str(i+1),axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_cleaned_test = df_cleaned.copy()\n\ndf_cleaned_test.reset_index(drop=True,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Modifying categorical groups\ndf_cleaned_test.position_again = df_cleaned_test.position_again.replace([2,3,np.nan],\n                                                                        [0,0,0])\n\ncategorical_list = ['sex','jockey_sex','condition','barrier']\nfor i in range(10):\n    categorical_list.append('last_start'+str(i+1)) \n\ndf_cleaned_test = pd.get_dummies(df_cleaned_test,columns=categorical_list,drop_first=True,dummy_na=1)\n\nnan_list1 = ['days_since_last_run_z','overall_starts','prize_money_per_start_z',\n             'overall_starts_z','overall_win_percent_z','overall_place_percent_z',\n             'condition_starts_z','distance_starts_z',\"track_starts_z\",\"track_starts\",\n             \"distance_starts\",\"condition_starts\",'weight_z','age_z','days_since_last_run',\n             'overall_win_percent','overall_place_percent','distance_win_percent',\n             'distance_place_percent','condition_win_percent','condition_place_percent']                            \n\nfor column1 in nan_list1:\n    df_cleaned_test[str(column1)].fillna(-99, inplace=True)\n\ndf_cleaned_test = df_cleaned_test.convert_objects(convert_numeric=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_cleaned_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_cleaned_test.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Shuffling and splitting the grouped data:"},{"metadata":{"trusted":false},"cell_type":"code","source":"X = df_cleaned_test.drop(['position_again','bf_odds'],axis=1)\ny = df_cleaned_test['position_again']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#classifiers\nfrom sklearn.ensemble import RandomForestClassifier\n\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.tree import DecisionTreeClassifier\n\nimport xgboost as xgb\n\n#for function below\nfrom sklearn.model_selection import StratifiedKFold\nfrom time import time\nfrom sklearn.metrics import make_scorer,confusion_matrix,accuracy_score,\\\n    precision_score,recall_score,f1_score,roc_auc_score,matthews_corrcoef","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### The dataset is imbalanced and this needs to be accounted for."},{"metadata":{"trusted":false},"cell_type":"code","source":"#for xgboost scale_pos_weight\nnegative = len(df_cleaned_test[df_cleaned_test.position_again ==0])\npositive = len(df_cleaned_test[df_cleaned_test.position_again ==1])\nxgb_weight = negative/positive\n\nxgb_weight","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"clf_B = LogisticRegression(random_state=0,class_weight='balanced')\n\nclf_D = RandomForestClassifier(random_state=0,max_depth=15,class_weight='balanced')\n\nclf_F = DecisionTreeClassifier(random_state=0,max_depth=5,class_weight='balanced')\n\nclf_J = xgb.XGBClassifier(random_state=0,scale_pos_weight=xgb_weight)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Creates a function to split data and fit, predict, and score models:"},{"metadata":{"trusted":false},"cell_type":"code","source":"def metrics_function(target,pred):\n    return accuracy_score(target, pred),precision_score(target, pred),\\\n        recall_score(target, pred),f1_score(target, pred),\\\n        roc_auc_score(target, pred),matthews_corrcoef(target, pred)\n\ndef FOLD_TEST(clf,X_all,y_all,folds_num,row_factor):\n    start=time()\n    \n    KFLD=StratifiedKFold(n_splits=folds_num,random_state=0,shuffle=True)\n    print ('{}:'.format(clf.__class__.__name__),'\\n')\n    \n    acc_list_train=[]\n    acc_list_test=[]\n    prc_list_train=[]\n    prc_list_test=[]\n    rcal_list_train=[]\n    rcal_list_test=[]\n    f1_list_train=[]\n    f1_list_test=[]\n    matt_list_train=[]\n    matt_list_test=[]\n    AUC_list_train=[]\n    AUC_list_test=[]\n    \n    samp_size=X_all.shape[0]//row_factor\n    \n    true_values = []\n    predict_values =[]\n    \n    for fold,(train_index,target_index) in enumerate(KFLD.split(X_all[:samp_size],\n                                                                y_all[:samp_size])):\n        X_train=X_all.iloc[train_index].values\n        y_train=y_all.iloc[train_index].values\n\n        X_test=X_all.iloc[target_index].values\n        y_test=y_all.iloc[target_index].values\n        \n        clf.fit(X_train,y_train)\n        y_pred1=clf.predict(X_train)\n        y_pred2=clf.predict(X_test)\n\n        train_acc,train_prc,train_rcal,train_f1,train_auc,train_matt=metrics_function(y_train,y_pred1)\n        \n        test_acc,test_prc,test_rcal,test_f1,test_auc,test_matt=metrics_function(y_test,y_pred2)\n        \n        acc_list_train.append(train_acc)\n        acc_list_test.append(test_acc)\n        prc_list_train.append(train_prc)\n        prc_list_test.append(test_prc)\n        rcal_list_train.append(train_rcal)\n        rcal_list_test.append(test_rcal)\n        \n        f1_list_train.append(train_f1)\n        f1_list_test.append(test_f1)\n        matt_list_train.append(train_matt)\n        matt_list_test.append(test_matt)\n        AUC_list_train.append(train_auc)\n        AUC_list_test.append(test_auc)\n        \n        true_values = true_values + list(zip(target_index,y_test))\n        predict_values = predict_values + list(zip(target_index,y_pred2))\n        \n    print(\"Averages:\"'\\n')\n    \n    print(\"Train acc: {}, Test acc: {}\".format(np.mean(acc_list_train),\n                                               np.mean(acc_list_test)))\n    print(\"Train prc: {}, Test prc: {}\".format(np.mean(prc_list_train),\n                                               np.mean(prc_list_test)))\n    print(\"Train recall: {}, Test recall: {}\".format(np.mean(rcal_list_train),\n                                                     np.mean(rcal_list_test)),'\\n')\n    \n    print(\"Train f1: {}, Test f1: {}\".format(np.mean(f1_list_train),\n                                             np.mean(f1_list_test)))\n    print(\"Train MattCC: {}, Test MattCC: {}\".format(np.mean(matt_list_train),\n                                                     np.mean(matt_list_test)))\n    print(\"Train AUC: {}, Test AUC: {}\".format(np.mean(AUC_list_train),\n                                               np.mean(AUC_list_test)),'\\n'*2)\n        \n    print(\"Sample Size: {}, Folds Num: {}, Time: {}\".format(samp_size,folds_num,\n                                                            time()-start),'\\n'*2)\n    \n    total_picks = []\n    correct_idx = []\n\n    for ((a,b),(c,d)) in list(zip(true_values,predict_values)):\n        if (b==1)&(d==1):\n            correct_idx.append(a)\n        if d==1:\n            total_picks.append(c)\n\n    win_odds_list=[]\n\n    for a in correct_idx:\n        win_odds_list.append(df_cleaned_test.bf_odds.iloc[a])\n\n    average_win=np.mean(win_odds_list)\n    \n    print(\"Total Picks:\",len(total_picks),\"Average Win Odds:\", average_win)\n    print(\"Total Return:\",average_win*len(correct_idx)-len(total_picks))\n    print(\"Average Expected Return:\",(average_win*len(correct_idx)-len(total_picks))/len(total_picks))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## The meaningful values here are:\n### Test prc (precision), Sample Size, Total Picks, Average Win Odds, Total Return, and Average Expected Return."},{"metadata":{"trusted":false},"cell_type":"code","source":"FOLD_TEST(clf_B, X, y, 5, 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"FOLD_TEST(clf_D, X, y, 5, 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"FOLD_TEST(clf_F, X, y, 5, 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"FOLD_TEST(clf_J, X, y, 5, 2)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}