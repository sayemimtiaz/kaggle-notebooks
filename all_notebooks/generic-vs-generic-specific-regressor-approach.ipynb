{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Aim of the notebook\n\n**'Generic' vs 'Generic+Specific' Regressor approach and performances (BMW dataset)\n\n\n\nI take the chance of this dataset on BMW models to implement and compare the performances of two different approaches:\n\n1) 'generic only': create a generic regressor model on the whole dataset, no matter the price of which car model I am trying to predict.\n\n2) 'generic+specific' create several regressor  models, one per 'car model', to better align to specific characteristics (if any) of each car model: when predicting on test set, for each test item if the generic model performs better than specific, I'll use the generic, otherwise I'll use the specific\n\n3) put together the overall performance ('generic only' vs 'generic+specific') and see what happens.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\nfrom sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nfrom sklearn.model_selection import train_test_split\nfrom itertools import combinations\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# read the dataset\ndf = pd.read_csv('../input/used-car-dataset-ford-and-mercedes/bmw.csv')\n\n# create a copy of the dataset (will be used later when original values are needed but the 'original dataframe has already been encoded)\ndf2=df.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# this plot shows that the price for some models has less variance than other:\n# this might suggest that a specific predict-model for car-model can lead to better overall performance\n# (while the generic model can be used to manage those car-model that do not have many rows in dataset\n# and so the specific model would lead to poor performance)\nsns.catplot(x = 'model', y= 'price', data = df2, kind='point', aspect=4);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# these plots show how much data we can rely on, for any car model\ndf2.groupby('model').count()['year'].values\nplt.figure(figsize=(15, 6))\nplt.bar(df2.groupby('model').count()['year'].index,df2.groupby('model').count()['year'].values,color='#005500', alpha=0.7, label='Number or records')\nplt.xticks(df2.groupby('model').count()['year'].index, (df2.groupby('model').count()['year'].index), rotation = 90);\nplt.xlabel('Car Model')\nplt.ylabel('Number of Records')\nplt.ylim([0,2500])\nplt.suptitle('Number of Records vs Car Model')\nplt.legend();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# STEP 1 CREATE A GENERIC PREDICTION MODELS (BASED ON WHOLE DATASET)\n\n# prepare the 'generic' model to predict those models who doens't have a specific model providing good results\n# also prepare the map of testset for predictions with 'best_model' regressor approach\n\n# create an array of dataset one for each car model (will be used later)\ncar_model_names_list_from_df = df.model.unique();\n\n# encode\ncar_model_le = LabelEncoder()\ndf['model'] = car_model_le.fit_transform(df.model.values)\ntransm_le = LabelEncoder()\ndf['transmission'] = transm_le.fit_transform(df.transmission.values)\nfuelType_le = LabelEncoder()\ndf['fuelType'] = fuelType_le.fit_transform(df.fuelType.values)\n\n# prepare X and Y\nX = df.drop(['price'], axis=1).values\nY = df.price.values\n\n# split\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size= 0.3, random_state=0)\n\n#before predicting, initialize two maps with tests and results: keys are the car model (it will be used later) \n\nmodel_to_x_test_map = {}\nmodel_to_y_test_map = {}\n\nfor car_model_name in car_model_names_list_from_df:\n    model_to_x_test_map[car_model_name] = []\n    model_to_y_test_map[car_model_name] = []\n\nfor test_index, test in enumerate(X_test[:,0]):\n    car_model_to_load = car_model_le.inverse_transform(np.array([int(test)]))\n    model_to_x_test_map[car_model_to_load[0]].append(X_test[test_index])\n    model_to_y_test_map[car_model_to_load[0]].append(Y_test[test_index])\n\n# sanity check on lengths\n#for car_model_name in df.model.values:\n#print(len(model_to_x_test_map[car_model_name]), len(model_to_y_test_map[car_model_name]))\n  \n#scale\nscaler = MinMaxScaler()\nscaler.fit_transform(X_train);\nscaler.transform(X_test);\n\n# prepare the generic model (whole dataset)\ngeneral_rfr = RandomForestRegressor()\n# Fit the model\ngeneral_rfr.fit(X_train,Y_train)\n# Get predictions\nY_pred_train = general_rfr.predict(X_train)\nY_pred_test = general_rfr.predict(X_test)\n# Calculate MAE and r2\nmae_general_train = mean_absolute_error(Y_train,Y_pred_train)\nmae_general_test = mean_absolute_error(Y_test,Y_pred_test)\nr2_general_score_train = r2_score(Y_train,Y_pred_train)\nr2_general_score_test = r2_score(Y_test,Y_pred_test)\nprint(\"'Generic' Approach Mean Absolute Error - Train: %.4f , Test: %.4f\" %(mae_general_train, mae_general_test))\nprint(\"'Generic' Approach r2 score            - Train: %.4f , Test: %.4f\" %(r2_general_score_train, r2_general_score_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# STEP 2 CREATE 'BY CAR MODEL' PREDICTION MODELS (ONE FOR EACH CAR MODEL) and save them\n\ndf_list = []\n\nfor car_model in car_model_names_list_from_df:\n    by_car_model_df = df[df2['model'] == car_model].reindex()\n    by_car_model_df.drop(['model'], inplace=True, axis=1)\n    df_list.append(by_car_model_df)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# for each dataset in the list, do predictions and rate them\n\nresults_map = {}\n\npredict_model_map = {}\n\nfor df_index, df_car_model in enumerate(df_list):\n    # prepare X and Y\n    X = df_car_model.drop(['price'], axis=1).values\n    Y = df_car_model.price.values\n    # split\n    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size= 0.3, random_state=0)\n    #scale\n    scaler = StandardScaler()\n    scaler.fit_transform(X_train);\n    scaler.transform(X_test);\n    # Instanciate the model\n    rfr = RandomForestRegressor()\n    # Fit the model\n    rfr.fit(X_train,Y_train)\n    # Get predictions\n    Y_pred_train = rfr.predict(X_train)\n    Y_pred_test = rfr.predict(X_test)\n    # Calculate MAE and r2\n    mae_train = mean_absolute_error(Y_train,Y_pred_train)\n    mae_test = mean_absolute_error(Y_test,Y_pred_test)\n    r2_score_train = r2_score(Y_train,Y_pred_train)\n    r2_score_test = r2_score(Y_test,Y_pred_test)\n    # put model in the model map\n    predict_model_map[car_model_names_list_from_df[df_index]] = rfr\n    print('Results for \\'%s\\'' %(car_model_names_list_from_df[df_index]))\n    print(\"Mean Absolute Error - Train: %.4f , Test: %.4f\" %(mae_train, mae_test))\n    print(\"r2 score - Train: %.4f , Test: %.4f\" %(r2_score_train, r2_score_test))\n    results_map[car_model_names_list_from_df[df_index]] = (mae_train,mae_test,r2_score_train,r2_score_test);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# collect train/test results in a map\n\ncar_model_names = list(results_map.keys())\nmae_train_values = [] \nmae_test_values =  []\nr2_train_values =  []\nr2_test_values =  []\n\nfor car_model in results_map.keys():\n    results = results_map[car_model]\n    mae_train_values.append(results[0])\n    mae_test_values.append(results[1])\n    r2_train_values.append(results[2])\n    r2_test_values.append(results[3]);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create a dataframe from that result map\nn = pd.DataFrame(results_map)\nn = n.transpose()\nn.columns = ['MAE train','MAE test','R2 train', 'R2 test'];","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot MAE train vs test on 'by car model' models\nplt.figure(figsize=(10, 10))\nplt.subplot(211)\nplt.bar(car_model_names, mae_train_values, color='#550055', alpha=0.7, label=\"Mae Train\")\nplt.xticks(car_model_names, car_model_names, rotation = 90);\nplt.xlabel('Car Model')\nplt.ylabel('Mae Train')\nplt.bar(car_model_names, mae_test_values, color='#005500', alpha=0.7, label=\"Mae Test\")\nplt.xticks(car_model_names, car_model_names, rotation = 90)\nplt.xlabel('Car Model')\nplt.ylabel('Mae Test')\nplt.suptitle('MAE Train vs Test')\nplt.legend()\nplt.show()\n\n# plot R2 train vs test\nplt.figure(figsize=(10, 10))\nplt.subplot(211)\nplt.bar(car_model_names, r2_train_values, color='#550055', alpha=0.7, label='R2 Train')\nplt.xticks(car_model_names, car_model_names, rotation = 90);\nplt.xlabel('Car Model')\nplt.ylabel('R2 Train')\n#plt.subplot(241)\nplt.bar(car_model_names, r2_test_values, color='#005500', alpha=0.7, label='R2 Test')\nplt.xticks(car_model_names, car_model_names, rotation = 90)\nplt.xlabel('Car Model')\nplt.ylabel('R2 Train')\nplt.ylim([-1,1])\nplt.suptitle('R2 Score Train vs Test')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# save those car models whose prices are better predicted with the specific ('by car model') regressor\ncar_models_better_predicted_with_specific_model = n[n['R2 test'] > r2_score_test].index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# STEP3: create a method that predict by using the appropriate regressor depending on car model ('generic' or 'specific' model)\n\ndef predict_with_best_model(single_x_test, car_model_to_predict, predict_model_map):\n    if car_model_to_predict in car_models_better_predicted_with_specific_model:\n        regressor = predict_model_map[car_model_to_predict]\n        reshaped = single_x_test[1:].reshape(1, -1)\n        return regressor.predict(reshaped)\n    else:\n        return general_rfr.predict(single_x_test.reshape(1, -1))\n\n# go over mapped test set and predict each value, measure results\nY_optimized_pred_test = []\nY_expected_value_test = []\nfor car_model_in_map in model_to_x_test_map.keys():\n    all_tests = model_to_x_test_map[car_model_in_map]\n    all_test_results = model_to_y_test_map[car_model_in_map]\n    for test_index, test in enumerate(all_tests):\n        Y_optimized_pred_test.append(predict_with_best_model(test, car_model_in_map, predict_model_map))\n        Y_expected_value_test.append(model_to_y_test_map[car_model_in_map][test_index])\nY_optimized_pred_test = np.array(Y_optimized_pred_test)\n\n# Calculate MAE and r2 on test set with \"by_car_model\" regressor \nmae_optimized_test = mean_absolute_error(Y_expected_value_test,Y_optimized_pred_test)\nr2_optimized_score_test = r2_score(Y_expected_value_test,Y_optimized_pred_test)\nprint(\"'Generic+Specific' Approach -  Mean Absolute Error -  Test: %.4f\" %(mae_optimized_test))\nprint(\"'Generic+Specific' Approach -  R2 score            -  Test: %.4f\" %(r2_optimized_score_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#The comparison of the results on the same test set seems to show that\n# a 'Generic+Speciific' regressor leads to better predictions thant the sole 'Generic' model\n\nprint(\"Mean Absolute Error on test set - 'Generic': %.4f\\t, 'Generic+Specific': %.4f\" %(mae_general_test,mae_optimized_test))\nprint(\"R2 Score            on test set - 'Generic': %.4f\\t, 'Generic+Specific': %.4f\" %(r2_general_score_test,r2_optimized_score_test))\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}