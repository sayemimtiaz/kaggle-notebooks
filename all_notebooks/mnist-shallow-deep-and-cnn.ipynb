{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"pip install -U torch","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def q1_hint():\n    print(\n    \"\"\"\n    trainDataset = MNISTDataset(\"../input/mnist-in-csv/mnist_train.csv\")\n    trainDataloader = torch.utils.data.DataLoader(trainDataset, batch_size=10, shuffle=True)\n    testDataset = MNISTDataset(\"../input/mnist-in-csv/mnist_test.csv\")\n    testDataloader = torch.utils.data.DataLoader(testDataset, batch_size=10000)\n    \"\"\"\n    )\ndef q2_hint():\n    print(\n    \"\"\"\n    def fit(model, epochs):\n    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n    loss_fn = nn.CrossEntropyLoss()\n    for epoch in range(epochs):\n        overall_loss = 0\n        for i, (X, Y) in enumerate(trainDataloader):\n            Y_pred = model(X)S\n            loss = loss_fn(Y_pred, Y)\n            overall_loss += loss.item()\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n            if i % 1000 == 999:\n                print(f'in epoch {epoch}, batch {i+1}, loss = {overall_loss / 1000}')\n                overall_loss = 0.\n    \"\"\"\n    )\n\ndef q3_hint():\n    print(\n    \"\"\"model = nn.Sequential(\n    nn.Flatten(),\n    nn.Linear(784, 64),\n    nn.ReLU(),\n    nn.Linear(64, 10))\nfit(model, 1)\nval(model)\n    \"\"\"\n    )\ndef q4_hint():\n    print(\n    \"\"\"\n    model = nn.Sequential(\n    Preprocess(),\n    nn.Conv2d(1, 32, 3),# 26 * 26 * 32\n    nn.ReLU(),\n    nn.MaxPool2d(2),# 13 * 13 * 32\n    nn.Conv2d(32, 16, 5),# 9 * 9 S* 16\n    nn.ReLU(),\n    nn.MaxPool2d(3),# 3 * 3 * 16\n    nn.Conv2d(16, 10, 3),# 1 * 1 * 10\n    nn.Flatten())\nfit(model, 1)\nval(model)\n    \"\"\"\n    )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Course Body\n* Fill out `None` and `pass` to proceed  \n* Uncomment `qx_hint` to see the answer"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport os\nimport torch\nprint(torch.__version__)\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch.nn as nn\nimport torch.optim as optim\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## One method for loading Data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"mnist_test = pd.read_csv(\"../input/mnist-in-csv/mnist_test.csv\")\nmnist_train = pd.read_csv(\"../input/mnist-in-csv/mnist_train.csv\")\ntrain_Y = mnist_train.iloc[:, 0].values\ntrain_X = mnist_train.iloc[:, 1:].values\ntest_Y = mnist_test.iloc[:, 0].values\ntest_X = mnist_test.iloc[:, 1:].values\nprint(train_X.shape, train_Y.shape)\nprint(test_X.shape, test_Y.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. ## Another method - using torch.Dataset\nyou \nA batch will be `List[Dict]` with keys \"image\", \"label\""},{"metadata":{},"cell_type":"markdown","source":"You will need to use:  \nhttps://pytorch.org/docs/stable/data.html"},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"#create self-defining data\nclass MNISTDataset(torch.utils.data.Dataset):\n    def __init__(self, csv_file, transform=None): #Some initialization\n        \"\"\"\n        Args:\n            csv_file (string): Path to the csv file with annotations.\n            root_dir (string): Directory with all the images.\n            transform (callable, optional): Optional transform to be applied\n                on a sample.\n        \"\"\"\n        self.dataframe = pd.read_csv(csv_file)\n        self.transform = transform\n        \n    def __len__(self): #Returns the amount of all data\n        return len(self.dataframe)\n    \n    def __getitem__(self, index): #Return data and labels\n        if torch.is_tensor(index):\n            index = index.tolist()\n            \n        image = self.dataframe.iloc[index, 1:].values.astype('float32')\n        #print(type(self.dataframe.iloc[index, 0]))\n        label = self.dataframe.iloc[index, 0]\n        image = image.reshape((28, 28))\n        # Normalize TODO:use transform to do it\n        image = (image - image.mean()) / image.std()\n        return image, label\n\n#1.Create dataset for both CtrainDataset and testDataset\n#2.Use torch.utils.data.DataLoader to make some batches. You can think of it as a packaging process.\n#example = torch.utils.data.DataLoader(dataset=trainDataset, batch_size=10,shuffle=True)\ntrainDataset = None\ntrainDataloader = None\ntestDataset = None\ntestDataloader = None\n\n#q1_hint()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Run the code below to inspect your data\nplt.figure(figsize=(3, 3))\ni = 1\nplt.gca().invert_yaxis()\nplt.pcolormesh(trainDataset[i][0])\nprint(trainDataset[i][1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"# Helper Function: fit(), val()"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create a fitting network\ndef fit(model, epochs):\n    pass#Define the optimizer like SGD\n    pass#Define the loss function\n    for epoch in range(epochs):\n        overall_loss = 0\n        for i, (X, Y) in enumerate(trainDataloader):\n            pass#The forward propagation\n            pass#Count the loss\n            pass#Accumulative the loss\n            pass#The back Propagation\n            pass#Update the gradient\n            pass#Don't forget to clear the gradient\n            if i % 1000 == 999:\n                print(f'in epoch {epoch}, batch {i+1}, loss = {overall_loss / 1000}')\n                overall_loss = 0.\n            \ndef val(model):\n    for X, Y in testDataloader:\n        Y_pred = model(X).argmax(dim=1)\n        rightCount = (Y == Y_pred).sum().item()\n        accuracy = rightCount / 10000\n        print(\"accuracy =\", accuracy)\n        \n#q2_hint()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Shallow Network 88%"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = nn.Sequential(\n    nn.Flatten(),\n    nn.Linear(784, 10)\n)\nfit(model, 1)\nval(model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Deep Network 95.24%"},{"metadata":{},"cell_type":"markdown","source":"You will need to use:  \nhttps://pytorch.org/docs/stable/nn.html#sequential  \nhttps://pytorch.org/docs/stable/nn.html#flatten  \nhttps://pytorch.org/docs/stable/nn.html#linear    \nhttps://pytorch.org/docs/stable/nn.html#relu  "},{"metadata":{"trusted":true},"cell_type":"code","source":"model = nn.Sequential(\n    #First you need a flatten layer \n    pass\n    #Then you need to create the linear transformation from the input layer to the hidden layer\n    pass\n    #Then the activation function\n    pass\n    #Then the linear transformation from the hidden layer to the output layer\n    pass\n)\nfit(model, 1)\nval(model)\n\n#q3_hint()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## CNN 97.85%"},{"metadata":{},"cell_type":"markdown","source":"You will need to use:  \nhttps://pytorch.org/docs/stable/nn.html#module  \nhttps://pytorch.org/docs/stable/nn.html#conv2d  \nhttps://pytorch.org/docs/stable/nn.html#adaptivemaxpool2d  "},{"metadata":{},"cell_type":"markdown","source":"A CNN architecture generally consists of the following layers:\n* Convolutional layer: used for feature extraction and feature mapping\n* ReLU layer: used to increase nonlinearity\n* Pooling layer: sampling and sparse processing of feature map to reduce the loss of feature information"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Preprocess(nn.Module):\n    def __init__(self):\n        super(Preprocess, self).__init__()\n        \n    def forward(self, x):\n        return x.unsqueeze(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# A CNN architecture generally consists of the following layers:\n# Convolutional layer: used for feature extraction and feature mapping\n# ReLU layer: used to increase nonlinearity\n# Pooling layer: sampling and sparse processing of feature map to reduce the loss of feature information\n# Fully connected layer\n\npass\n\n#q4_hint()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Well done!\nCheck out our [github repo](https://github.com/AIwaffle/AIwaffle) for more information"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}