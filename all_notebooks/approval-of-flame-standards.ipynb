{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd \nimport seaborn as sns \nimport numpy as np \nfrom sklearn.metrics import accuracy_score\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.model_selection import ShuffleSplit","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-24T00:14:28.590009Z","iopub.execute_input":"2021-07-24T00:14:28.590536Z","iopub.status.idle":"2021-07-24T00:14:28.597469Z","shell.execute_reply.started":"2021-07-24T00:14:28.590499Z","shell.execute_reply":"2021-07-24T00:14:28.595865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Exploratory Analysis - - - - - - - - - - - - Analisis Exploratorio**","metadata":{}},{"cell_type":"markdown","source":"**Loading and inspection   - - - - - - - - -  Carga e Inspección**","metadata":{}},{"cell_type":"code","source":"dataset = pd.read_csv('../input/call-center-metrics-dataset/call_metrics_dataset.csv', delimiter = ';')\ndataset.index = pd.to_datetime(dataset['date'])\ndel(dataset['date'])\ndataset['avg_aht'] = dataset['avg_aht'].str.replace('.', '', regex = True)\ndataset['avg_aht'] = dataset['avg_aht'].str.replace(',', '.', regex = True).astype(float)\ndataset.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-23T23:53:21.120197Z","iopub.execute_input":"2021-07-23T23:53:21.120748Z","iopub.status.idle":"2021-07-23T23:53:21.148032Z","shell.execute_reply.started":"2021-07-23T23:53:21.120706Z","shell.execute_reply":"2021-07-23T23:53:21.146784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Correlation - - - - - - - - - - - - - - Correlación**","metadata":{}},{"cell_type":"code","source":"corr = dataset.astype('float64').corr()\nax = sns.heatmap(corr, annot = True)","metadata":{"execution":{"iopub.status.busy":"2021-07-23T23:54:01.289968Z","iopub.execute_input":"2021-07-23T23:54:01.290388Z","iopub.status.idle":"2021-07-23T23:54:01.864782Z","shell.execute_reply.started":"2021-07-23T23:54:01.29035Z","shell.execute_reply":"2021-07-23T23:54:01.863613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Splitting the dataset      - - - - - - - - - - - - - - -        Dividiendo el dataset**","metadata":{}},{"cell_type":"code","source":"x = dataset.iloc[:, 0:6].values\ny = dataset.iloc[:, -1]. values\nx","metadata":{"execution":{"iopub.status.busy":"2021-07-23T23:57:13.740201Z","iopub.execute_input":"2021-07-23T23:57:13.740733Z","iopub.status.idle":"2021-07-23T23:57:13.750463Z","shell.execute_reply.started":"2021-07-23T23:57:13.740693Z","shell.execute_reply":"2021-07-23T23:57:13.749303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Dividing into training and testing and normalizing the variables - - - - - - - - - - - - - - Dividiendo en entrenamiento y test y normalizando las variables**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)\n\nfrom sklearn.preprocessing import StandardScaler\nsc_x = StandardScaler()\nx_train, x_test = sc_x.fit_transform(x_train), sc_x.transform(x_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T00:00:14.163008Z","iopub.execute_input":"2021-07-24T00:00:14.163426Z","iopub.status.idle":"2021-07-24T00:00:14.171895Z","shell.execute_reply.started":"2021-07-24T00:00:14.163388Z","shell.execute_reply":"2021-07-24T00:00:14.17086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Using variable reduction (PCA) - - - - - - - - - - - Usando reducción de variables (PCA)**","metadata":{}},{"cell_type":"code","source":"from sklearn.decomposition import PCA\npca = PCA(n_components = 3)\nx_train = pca.fit_transform(x_train)\nx_test = pca.transform(x_test)\nexplained_variance = pca.explained_variance_ratio_\nexplained_variance","metadata":{"execution":{"iopub.status.busy":"2021-07-24T00:02:37.64036Z","iopub.execute_input":"2021-07-24T00:02:37.640776Z","iopub.status.idle":"2021-07-24T00:02:38.030218Z","shell.execute_reply.started":"2021-07-24T00:02:37.640742Z","shell.execute_reply":"2021-07-24T00:02:38.028712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Selection Models- - - - - - - - - - - - - - - - - - - Selección de Modelos**","metadata":{}},{"cell_type":"markdown","source":"**XGBOOST CLASSIFIER**","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBClassifier\nclassifier = XGBClassifier(use_label_encoder = False, eval_metric = 'mlogloss').fit(x_train, y_train)\ny_classifier = classifier.predict(x_test)\naccuracy_score(y_test, y_classifier)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T00:14:32.014268Z","iopub.execute_input":"2021-07-24T00:14:32.014676Z","iopub.status.idle":"2021-07-24T00:14:32.060182Z","shell.execute_reply.started":"2021-07-24T00:14:32.014642Z","shell.execute_reply":"2021-07-24T00:14:32.059339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**RANDOM FOREST**","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nclassifier2 = RandomForestClassifier(n_estimators = 10).fit(x_train, y_train)\ny_classifier2 = classifier2.predict(x_test)\naccuracy_score(y_test, y_classifier2)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T00:21:58.112036Z","iopub.execute_input":"2021-07-24T00:21:58.112564Z","iopub.status.idle":"2021-07-24T00:21:58.143781Z","shell.execute_reply.started":"2021-07-24T00:21:58.11253Z","shell.execute_reply":"2021-07-24T00:21:58.142804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**SUPPORT VECTOR MACHINE**","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVC\nclassifier3 = SVC(gamma = 1).fit(x_train, y_train)\ny_classifier3 = classifier3.predict(x_test)\naccuracy_score(y_test, y_classifier3)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T00:22:03.262996Z","iopub.execute_input":"2021-07-24T00:22:03.263389Z","iopub.status.idle":"2021-07-24T00:22:03.272498Z","shell.execute_reply.started":"2021-07-24T00:22:03.263352Z","shell.execute_reply":"2021-07-24T00:22:03.271401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**LOGISTIC REGRESSION**","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nclassifier4 = LogisticRegression(max_iter = 200).fit(x_train, y_train)\ny_classifier4 = classifier4.predict(x_test)\naccuracy_score(y_test, y_classifier4)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T00:22:08.030818Z","iopub.execute_input":"2021-07-24T00:22:08.031187Z","iopub.status.idle":"2021-07-24T00:22:08.045099Z","shell.execute_reply.started":"2021-07-24T00:22:08.031152Z","shell.execute_reply":"2021-07-24T00:22:08.043869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Learning curve**","metadata":{}},{"cell_type":"code","source":"def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n    plt.figure()\n    plt.title(title)\n    if ylim is not None:\n        plt.ylim(*ylim)\n    plt.xlabel(\"Training examples\")\n    plt.ylabel(\"Score\")\n    train_sizes, train_scores, test_scores = learning_curve(\n        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    plt.grid()\n\n    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1,\n                     color=\"r\")\n    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n             label=\"Training score\")\n    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n             label=\"Cross-validation score\")\n\n    plt.legend(loc=\"best\")\n    return plt","metadata":{"execution":{"iopub.status.busy":"2021-07-24T00:17:41.741244Z","iopub.execute_input":"2021-07-24T00:17:41.741669Z","iopub.status.idle":"2021-07-24T00:17:41.75335Z","shell.execute_reply.started":"2021-07-24T00:17:41.741639Z","shell.execute_reply":"2021-07-24T00:17:41.752446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**XGBOOST**","metadata":{}},{"cell_type":"code","source":"title = \"Curva de aprendizaje\"\ncv = ShuffleSplit(n_splits = 10, test_size = 0.3)\nplot_learning_curve(classifier, title, x_train, y_train, ylim = (0.6, 1.0), cv = cv, n_jobs = 1)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T00:19:02.821789Z","iopub.execute_input":"2021-07-24T00:19:02.822302Z","iopub.status.idle":"2021-07-24T00:19:04.60849Z","shell.execute_reply.started":"2021-07-24T00:19:02.822251Z","shell.execute_reply":"2021-07-24T00:19:04.607465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**RANDOM FOREST**","metadata":{}},{"cell_type":"code","source":"plot_learning_curve(classifier2, title, x_train, y_train, ylim = (0.6, 1.0), cv = cv, n_jobs = 1)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T00:19:44.304515Z","iopub.execute_input":"2021-07-24T00:19:44.304978Z","iopub.status.idle":"2021-07-24T00:19:45.661611Z","shell.execute_reply.started":"2021-07-24T00:19:44.304941Z","shell.execute_reply":"2021-07-24T00:19:45.660615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**SVM**","metadata":{}},{"cell_type":"code","source":"plot_learning_curve(classifier3, title, x_train, y_train, ylim = (0.6, 1.0), cv = cv, n_jobs = 1)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T00:20:06.932691Z","iopub.execute_input":"2021-07-24T00:20:06.933102Z","iopub.status.idle":"2021-07-24T00:20:07.267226Z","shell.execute_reply.started":"2021-07-24T00:20:06.933065Z","shell.execute_reply":"2021-07-24T00:20:07.266449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**LOGISTIC REGRESSION**","metadata":{}},{"cell_type":"code","source":"plot_learning_curve(classifier4, title, x_train, y_train, ylim = (0.6, 1.0), cv = cv, n_jobs = 1)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T00:20:10.562229Z","iopub.execute_input":"2021-07-24T00:20:10.562782Z","iopub.status.idle":"2021-07-24T00:20:11.034473Z","shell.execute_reply.started":"2021-07-24T00:20:10.56275Z","shell.execute_reply":"2021-07-24T00:20:11.0337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Conclusions - - - - - - - - - - - - - - - - Conclusiones**","metadata":{}},{"cell_type":"markdown","source":"**Ingles:**\n\n*We can see that within our models a good performance is displayed, however this may be due to the few data we have and although all the models are giving us very similar predictions, we can observe that in the learning curves who is best adapting is XGBOOST, likewise we can highlight the performance that Logistic Regression is giving us although its accuracy is ~ 4% (approximate (~)) below XGBOOST, therefore the recommendation is that if more data were obtained one of the models to consider first will be XGBOOST*\n\n**Español:**\n\n*Podemos observar que dentro de nuestros modelos se visualiza un buen desempeño, sin embargo esto se puede deber a los pocos datos con los que contamos y aunque todos los modelos esten dandonos predicciones muy similares podemos observar que en las curvas de aprendizaje quien mejor se esta adaptando es XGBOOST, así mismo podemos resaltar el desempeño que nos esta dando Logistic Regression aunque su accuracy esta en un ~4% (aproximado(~)) por debajo de XGBOOST, por tanto la recomendación es que si se consiguieran más datos uno de los modelos a considerar primeramente sera XGBOOST*\n","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}