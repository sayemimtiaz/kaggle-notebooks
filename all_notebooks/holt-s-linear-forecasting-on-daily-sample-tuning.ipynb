{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Holt's Linear Forecasting with Hyperparameter Tuning\n### Using Holt's Linear with Hyperparameter tuning to forecast Jetrail traffic for next 7 months for investment purpose. \n\n* Holt's two-parameter model, also known as linear exponential smoothing, is a popular smoothing model for forecasting data with trend. Holt's model has three separate equations that work together to generate a final forecast. The method is also called double exponential smoothing or trend-enhanced exponential smoothing.\n* In this notebook, we will sample data daily, forecast daily data and then transform back to hourly data.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Import all required libraries","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom pandas import Series\nfrom math import sqrt\n\n# metrics\nfrom sklearn.metrics import mean_squared_error\n\nimport statsmodels.api as sm\n\n# forecasting model\nfrom statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\n\n# for analysis\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.tsa.stattools import acf, pacf\nfrom statsmodels.tsa.seasonal import seasonal_decompose\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom matplotlib.pylab import rcParams\nrcParams['figure.figsize'] = 12, 7\n\nfrom IPython.display import display, HTML\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load Jetrail traffic dataset","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_original=pd.read_csv('../input/jetrail-traffic-dataset/Train.csv')\ntest_original=pd.read_csv('../input/jetrail-traffic-dataset/Test.csv')\n\ntrain_original.dropna(inplace=True)\ntest_original.dropna(inplace=True)\ntest_original.drop(test_original.tail(1).index, inplace=True)\n\ntrain_df=train_original.copy()\ntest_df=test_original.copy()\ntest_df.sample(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature engineering","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_original['Datetime']=pd.to_datetime(train_original.Datetime, format='%d-%m-%Y %H:%M')\ntest_original['Datetime']=pd.to_datetime(test_original.Datetime, format='%d-%m-%Y %H:%M')\ntrain_df['Datetime']=pd.to_datetime(train_df.Datetime, format='%d-%m-%Y %H:%M')\ntest_df['Datetime']=pd.to_datetime(test_df.Datetime, format='%d-%m-%Y %H:%M')\n\n# generate day, month, year feature\nfor i in (train_original, test_original, train_df, test_df):\n    i['year']=i.Datetime.dt.year\n    i['month']=i.Datetime.dt.month\n    i['day']=i.Datetime.dt.day\n    i['hour']=i.Datetime.dt.hour","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sampling for daily basis\ntrain_df.index=train_df.Datetime\ntest_df.index=test_df.Datetime","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Helper Functions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_result(train_data, valid_data, pred_data):\n    plt.figure(figsize=(12,7))\n    train_data.plot(label='Train')\n    valid_data.plot(label='Valid')\n    pred_data.plot(label='Prediction')\n    _=plt.legend(loc='best')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Change resample\ndef resample(data, sample_by):\n    data_resample=data.resample(sample_by).mean()\n    return data_resample","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train valid split\ndef train_valid_split(data, train_start_date='2012-08-25', train_end_date='2014-06-24', valid_start_date='2014-06-25', valid_end_date='2014-09-25'):\n    train=data.loc[train_start_date:train_end_date]\n    valid=data.loc[valid_start_date:valid_end_date]\n    return (train, valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# rmse calculation\ndef rmse(valid, pred):\n    # calculate mse\n    rmse=mean_squared_error(valid, pred, squared=False)\n    return rmse","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check for stationary of data with daily basis\ndf=resample(train_df, 'D')\ndftest=adfuller(df.Count, autolag='AIC')\ndfout=pd.Series(dftest[0:4], index=['Test statistics', 'p-value', '#Lags used', 'Number of observation used'])\nfor key, val in dftest[4].items():\n    dfout['Critical value (%s)'%key]=val\nprint(dfout)\n# p-value > 0.05 -> non-stationary data\n# p-value < 0.05 -> stationary data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check rolling mean and std\n# resample data to daily basis\ndf=resample(train_df, 'D')\n# determine rolling stats\nrolmean=df.Count.rolling(window=7).mean() #for 7 days\nrolstd=df.Count.rolling(window=7).std()\nrolmean.dropna(inplace=True)\nrolstd.dropna(inplace=True)\n\nplt.figure(figsize=(12,7))\nrolmean.plot(label='Rolmean', color='black')\nrolstd.plot(label='rolstd')\ndf.Count.plot(label='Train')\n_=plt.legend(loc='best')\nplt.title('Rolling Mean & STD')\nplt.xlabel('Date')\n_=plt.ylabel('Count')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# helper function for grid CV search hyperparameter tuning\ndef grid_search(params, train_data, valid_data):\n    best_rmse=1e10\n    best_param=0\n    for param1 in params['damped']:\n        for param2 in params['exp']:\n            for param3 in params['optim']:\n                for param4 in params['smooth_level_grid']:\n                    for param5 in params['smooth_slope_grid']:\n                        for param6 in params['damping_slope_grid']:\n                            for param7 in params['initial_level_grid']:\n                                for param8 in params['initial_slope_grid']:\n                                    fit1=Holt(train_data, damped=param1, exponential=param2).fit(\n                                        optimized=param3,\n                                        smoothing_level=param4, \n                                        smoothing_slope=param5,\n                                        damping_slope=param6,\n                                        initial_level=param7,\n                                        initial_slope=param8\n                                    )\n                                    pred=fit1.forecast(len(valid_data))\n                                    # check rmse\n                                    pred=np.nan_to_num(pred, nan=0)\n                                    # print(valid_data, pred)\n                                    rmse_err=rmse(pred, valid_data)\n                                    print('params: ',(param1, param2,param3, param4, param5, param6, param7, param8), \n                                          ' rmse: %.4f'%rmse_err)\n                                    if rmse_err<best_rmse:\n                                        best_rmse=rmse_err\n                                        best_param=(param1, param2,param3, param4, param5, param6, param7, param8)\n    print('Best param: ',best_param, ' rmse: %.4f'%best_rmse)\n    return best_param","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def holt_forecast(train_data, valid_data, params):\n    fit1=Holt(np.asarray(train_data), damped=params[0], exponential=params[1]).fit(\n        optimized=params[2],\n        smoothing_level=params[3], \n        smoothing_slope=params[4],\n        damping_slope=params[5],\n        initial_level=params[6],\n        initial_slope=params[7])\n    pred=fit1.forecast(len(valid_data))\n    pred=pd.Series(pred, index=valid_data.index)\n    plot_result(train_data, valid_data, pred)\n    return pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert daily basis to hourly basis using hour traffic ratio\ndef convert_to_hourly(forecast, train_df_hourly, test_df_hourly, train_=1):\n    train_origin=train_df_hourly.copy()\n    test_origin=test_df_hourly.copy()\n    # convert to hourly basis\n    pred_df=pd.DataFrame(forecast, columns=['predict']).reset_index()\n    pred_df['year']=pred_df.Datetime.dt.year\n    pred_df['month']=pred_df.Datetime.dt.month\n    pred_df['day']=pred_df.Datetime.dt.day\n\n    if(train_==1):\n        pred_df=pd.merge(pred_df, train_origin, on=('year', 'month', 'day'), how='left')\n    else:\n        pred_df=pd.merge(pred_df, test_origin, on=('year', 'month', 'day'), how='left')\n\n    # count hour ratio\n    train_origin['ratio']=train_origin.Count/train_origin.Count.sum()\n    grp_ratio=train_origin.groupby('hour')['ratio'].sum().reset_index()\n\n    pred_hour=pd.merge(pred_df, grp_ratio, on='hour', how='left')\n    pred_hour=pd.DataFrame(pred_hour.predict*pred_hour.ratio*24, columns=['Count']).set_index(pred_hour.Datetime_y)\n    return pred_hour.Count","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Hyperparameter tuning","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# split train valid\ntrain, valid=train_valid_split(train_df)\n\n# resample by day\ntrain_sample=resample(train, 'D')\nvalid_sample=resample(valid, 'D')\n\n# grid search for Holt linear\nPARAMS={\n    'damped':[False],\n    'exp':[False],\n    'optim':[True],\n    'smooth_level_grid':np.arange(0,1,0.35),\n    'smooth_slope_grid':np.arange(0,1,0.2),\n    'damping_slope_grid':[None],\n    'initial_level_grid':[None],\n    'initial_slope_grid':np.arange(0.9,1.5,0.2)#[1.2]\n}\nbest_param=grid_search(PARAMS, train_sample.Count.values, valid_sample.Count.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred=holt_forecast(train_sample.Count, valid_sample.Count, best_param)\nplt.title('Forecast on Validation Dataset')\nplt.xlabel('Date')\n_=plt.ylabel('Count')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_hourly=convert_to_hourly(pred, train_df, test_df)\nplot_result(train.Count, valid.Count, pred_hourly)\nplt.title('Forecast on Validation Dataset')\nplt.xlabel('Date')\n_=plt.ylabel('Count')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Test forecasting","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_sample=resample(train_df, 'D')\ntest_sample=resample(test_df, 'D')\n\n# fit1=Holt(np.asarray(train_sample.Count)).fit(smoothing_level=best_param[3], smoothing_slope=best_param[4])\nfit1=Holt(np.asarray(train_sample.Count), damped=best_param[0], exponential=best_param[1]).fit(\n        optimized=best_param[2],\n        smoothing_level=best_param[3], \n        smoothing_slope=best_param[4],\n        damping_slope=best_param[5],\n        initial_level=best_param[6],\n        initial_slope=best_param[7])\npred=fit1.forecast(len(test_sample))\npred=pd.Series(pred, index=test_sample.index)\n\npred_hourly=convert_to_hourly(pred, train_df, test_df, train_=0)\nplot_result(train.Count, valid.Count, pred_hourly)\nplt.title('Forecast on Test Dataset')\nplt.xlabel('Date')\n_=plt.ylabel('Count')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# forecasting result\npred_hourly.index=test_df.ID\npd.DataFrame(pred_hourly).sample(10)\n# score 186.5 on AV Public LB","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Conclusion\n* RMSE validation score: 98.2379\n* RMSE test score: 186.5 still need improvement\n* Daily forecasting with Holt's not fit enough with real values\n\nNext, we will try to improve with Weekly or Monthly forecasting and do some feature engineering.\n\n#### Thank you :D","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}