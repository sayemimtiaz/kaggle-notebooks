{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm # this is a bar for the outputs\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-02T03:28:10.518099Z","iopub.execute_input":"2021-08-02T03:28:10.518544Z","iopub.status.idle":"2021-08-02T03:28:12.849621Z","shell.execute_reply.started":"2021-08-02T03:28:10.518452Z","shell.execute_reply":"2021-08-02T03:28:12.848651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Digit Classifier with PyTorch using Transfer Learning and Data Augmentation","metadata":{}},{"cell_type":"code","source":"dataset = pd.read_csv('../input/digits-mini-dataset-5500/drawings.csv')\ndataset.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-02T03:28:12.851084Z","iopub.execute_input":"2021-08-02T03:28:12.851462Z","iopub.status.idle":"2021-08-02T03:28:13.39361Z","shell.execute_reply.started":"2021-08-02T03:28:12.851424Z","shell.execute_reply":"2021-08-02T03:28:13.392806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# select the feature columns\ndata = dataset.drop(['label'], axis=1).values.astype('float32')\n# select the final column, the labels\nlabels = dataset.values[:,-1].astype('float32')\n\ndata.shape, labels.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-02T03:28:13.395407Z","iopub.execute_input":"2021-08-02T03:28:13.395784Z","iopub.status.idle":"2021-08-02T03:28:13.426485Z","shell.execute_reply.started":"2021-08-02T03:28:13.395746Z","shell.execute_reply":"2021-08-02T03:28:13.425452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# a useful function to plot images\ndef plot_images(imgs, dims, figsize, title_size=22, preds=[]):\n    plt.figure(figsize=figsize)\n    for img, i, in zip(imgs, np.arange(imgs.shape[0])):\n        cmap = 'gray'\n        # if there are not predictions the title is this\n        title = f'Image {i+1}'\n        # if there are predictions\n        if preds != []:\n            title = f'Real: {preds[i][0]}, Pred: {preds[i][1]}'\n            # change the color if the prediction is wrong\n            cmap = ('gray' if preds[i][0] == preds[i][1] else 'magma')\n        # select the plot position\n        plt.subplot(dims[0], dims[1], i+1)\n        # plot the image\n        plt.imshow(np.squeeze(img), cmap=cmap)\n        plt.axis('off')\n        plt.title(title, fontsize=title_size)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-02T03:28:13.42824Z","iopub.execute_input":"2021-08-02T03:28:13.428636Z","iopub.status.idle":"2021-08-02T03:28:13.436352Z","shell.execute_reply.started":"2021-08-02T03:28:13.428593Z","shell.execute_reply":"2021-08-02T03:28:13.435165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Processing and Augmentation","metadata":{}},{"cell_type":"code","source":"from albumentations import Compose, Blur, GridDistortion\n\n# define the transformations function\ntransform = Compose([\n    Blur(always_apply=False, p=1.0, blur_limit=(3, 6)),\n    GridDistortion(always_apply=False, p=1.0, num_steps=5, distort_limit=(-0.3, 0.3), interpolation=0, border_mode=0, value=(0, 0, 0), mask_value=None)\n])\n\n# select an image\nsample_image = data[1].reshape(1,28,28)\naugmented_sample = []\naugmented_sample.append(sample_image)\n\n# transform the image\nfor _ in range(4*4-1):\n    augmented_sample.append(transform(image=sample_image)[\"image\"])\n\nplot_images(np.array(augmented_sample), dims=(4,4), figsize=(15,15))","metadata":{"execution":{"iopub.status.busy":"2021-08-02T03:28:13.437912Z","iopub.execute_input":"2021-08-02T03:28:13.43834Z","iopub.status.idle":"2021-08-02T03:28:15.594535Z","shell.execute_reply.started":"2021-08-02T03:28:13.438283Z","shell.execute_reply":"2021-08-02T03:28:15.593391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Then create more data and more labels\nper_image = 15 # how many transformed images per image\n\nnew_data = []\nnew_labels = []\n\n# a bar for the transformation process\nbar = tqdm(range(1, labels.shape[0]+1))\n\n# iterate the bar, and the data,labels\nfor _, (image, label) in zip(bar, zip(data, labels)):\n    # reshape the image\n    image = image.reshape(1,28,28)\n    # append original the image\n    new_data.append(image)\n    # append the new labels\n    new_labels.append(label)\n    # transform the image in new images\n    for _ in range(per_image):\n        # create the transformed image\n        new_image = transform(image=image)[\"image\"]\n        # append the new image\n        new_data.append(new_image)\n        # append the label\n        new_labels.append(label)\n\n# convert to numpy arays\nnew_data = np.array(new_data)\nnew_labels = np.array(new_labels)\n# see the new shapes\nnew_data.shape, new_labels.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-02T03:28:15.598714Z","iopub.execute_input":"2021-08-02T03:28:15.59983Z","iopub.status.idle":"2021-08-02T03:29:13.244153Z","shell.execute_reply.started":"2021-08-02T03:28:15.59979Z","shell.execute_reply":"2021-08-02T03:29:13.243207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Split the Data","metadata":{}},{"cell_type":"code","source":"# split the data\nx_train, x_test, y_train, y_test = train_test_split(new_data, new_labels, test_size=.1, random_state=13)\nx_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=.1, random_state=13)\n\n# save all the data in a dic\ndata_dic = {\n    'x_train': x_train, 'y_train': y_train,\n    'x_test': x_test, 'y_test': y_test,\n    'x_val': x_val, 'y_val': y_val,\n}\n\ndata_dic['x_train'].shape, data_dic['x_test'].shape, data_dic['x_val'].shape","metadata":{"execution":{"iopub.status.busy":"2021-08-02T03:29:13.245662Z","iopub.execute_input":"2021-08-02T03:29:13.246029Z","iopub.status.idle":"2021-08-02T03:29:13.428982Z","shell.execute_reply.started":"2021-08-02T03:29:13.245991Z","shell.execute_reply":"2021-08-02T03:29:13.427809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create the Dataset Class","metadata":{}},{"cell_type":"code","source":"class DS(Dataset):\n    ############ BASIC FUNCTIONS\n    \n    def __init__(self, data, labels):\n        self.process_data(data)\n        self.process_labels(labels)\n    \n    def __len__(self):\n        return self.labels.shape[0]\n    \n    def __getitem__(self, idx):\n        return self.data[idx], self.labels[idx]\n    \n    ############ PROCESSING FUNCTIONS\n    \n    def process_data(self, data):\n        # convert the data to pytorch tensor\n        self.data = torch.from_numpy(data)\n        # reshape the data\n        batch_dim = self.data.shape[0] # obtain the batch dim\n        self.data = self.data.view(batch_dim, 1, 28, 28)/2 # and normalize\n        # the data is between 1 and 0\n    \n    def process_labels(self, labels):\n        self.labels = torch.from_numpy(labels.astype('int64'))\n        \n\n## USE THE CLASS\ndata_sets = { # not augmented datasets\n    'train': DS(data_dic['x_train'], data_dic['y_train']),\n    'test': DS(data_dic['x_test'], data_dic['y_test']),\n    'val': DS(data_dic['x_val'], data_dic['y_val']),\n}\n\n# how is the shape of the images and labels\ndata_sets['train'][:3][0].shape, data_sets['train'][:3][1].shape","metadata":{"execution":{"iopub.status.busy":"2021-08-02T03:29:13.431807Z","iopub.execute_input":"2021-08-02T03:29:13.432168Z","iopub.status.idle":"2021-08-02T03:29:13.622608Z","shell.execute_reply.started":"2021-08-02T03:29:13.432131Z","shell.execute_reply":"2021-08-02T03:29:13.621463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# and the dtypes\ndata_sets['train'][1][0].dtype, data_sets['train'][1][1].dtype","metadata":{"execution":{"iopub.status.busy":"2021-08-02T03:29:13.624384Z","iopub.execute_input":"2021-08-02T03:29:13.624798Z","iopub.status.idle":"2021-08-02T03:29:13.632881Z","shell.execute_reply.started":"2021-08-02T03:29:13.624755Z","shell.execute_reply":"2021-08-02T03:29:13.632084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# the max value of a sample batch\nmax(list(data_sets['val'][:100][0].reshape(-1)))","metadata":{"execution":{"iopub.status.busy":"2021-08-02T03:29:13.63416Z","iopub.execute_input":"2021-08-02T03:29:13.634643Z","iopub.status.idle":"2021-08-02T03:29:14.450136Z","shell.execute_reply.started":"2021-08-02T03:29:13.634605Z","shell.execute_reply":"2021-08-02T03:29:14.449129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataloaders","metadata":{}},{"cell_type":"code","source":"# now the dataloaders\nbatch_size = 128\n\ndata_loaders = {\n    'train': DataLoader(\n        dataset=data_sets['train'],\n        batch_size=batch_size,\n        shuffle=False, # the datasets are already shuffled\n    ),\n    'test': DataLoader(\n        dataset=data_sets['test'],\n        batch_size=batch_size,\n        shuffle=False\n    ),\n    'val': DataLoader(\n        dataset=data_sets['val'],\n        batch_size=batch_size,\n        shuffle=False\n    ),\n}","metadata":{"execution":{"iopub.status.busy":"2021-08-02T03:29:14.451502Z","iopub.execute_input":"2021-08-02T03:29:14.451983Z","iopub.status.idle":"2021-08-02T03:29:14.458608Z","shell.execute_reply.started":"2021-08-02T03:29:14.451942Z","shell.execute_reply":"2021-08-02T03:29:14.457687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# The Model and Device","metadata":{}},{"cell_type":"code","source":"# define the model class\nclass Network(nn.Module):\n    # all the layers of the model\n    def __init__(self):\n        super(Network, self).__init__()\n        self.conv = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5)\n        self.pool = nn.MaxPool2d(2)\n        # DENSE LAYERS\n        # the first para is like the input_shape, the seccond the number\n        # of outputs, like the number of neurons\n        self.dense1 = nn.Linear(32*12*12, 256)\n        self.dense2 = nn.Linear(256, 256)\n        self.dense3 = nn.Linear(256, 10)\n        # DROPOUT AND BATCH NORM LAYER\n        self.dropout = nn.Dropout(0.2)\n    \n    # define the model data flow with the layers\n    def forward(self, x):\n        # convolutional layer\n        x = self.pool( # third, max pooling\n                F.relu( # seccond, relu function\n                    self.conv(x) # first, convolution\n                ))\n        # apply the flatten process, conserving the batch dim\n        x = torch.flatten(x,1)\n        # dense layers\n        x = self.dropout(F.relu(self.dense1(x)))\n        x = self.dropout(F.relu(self.dense2(x)))\n        x = self.dense3(x)\n        return x\n\n# if the gpu is available use it, if not, use the cpu\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nmodel = Network()\nmodel = model.to(device)\n\n# this is to check if and how the model flow works\n# model(torch.randn(2,1,28,28).to(device))\ndevice","metadata":{"execution":{"iopub.status.busy":"2021-08-02T03:29:14.460268Z","iopub.execute_input":"2021-08-02T03:29:14.460874Z","iopub.status.idle":"2021-08-02T03:29:18.851021Z","shell.execute_reply.started":"2021-08-02T03:29:14.460835Z","shell.execute_reply":"2021-08-02T03:29:18.850215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_train(h, epochs):\n    # get an array with the number of epochs\n    x = np.arange(epochs)\n    plt.figure(figsize=(20,10))\n    # plot the loss\n    plt.subplot(1,2,1)\n    plt.plot(x, h['loss'], label='train loss')\n    plt.plot(x, h['val loss'], label='val loss')\n    plt.grid(True)\n    # plot the accuracy\n    plt.subplot(1,2,2)\n    plt.plot(x, h['accuracy'], label='train accuracy')\n    plt.plot(x, h['val accuracy'], label='val accuracy')\n    plt.grid(True)\n    # \n    plt.legend()\n    plt.show()\n    \n\n# define a metric\ndef check_accuracy(model, loader, criterion, train=True):\n    num_correct = 0\n    num_samples = 0\n    model.eval() # is like swich the model mode, this changes the\n    # behave of layers like Dropouts Layers, BatchNorm Layers\n\n    with torch.no_grad(): # deactivcate the back propagation,\n    # it will reduce memory and speed up computations\n\n        for x,y in loader:\n            # move the data and targets to the device\n            x = x.to(device)\n            y = y.to(device)\n            # obtain the scores\n            scores = model(x)\n            # calculate the loss function\n            loss_ = criterion(scores, y)\n            loss_ = loss_.item()\n            # we ned the max from the second dim\n            _, preds = scores.max(1)\n            # select the correct preds and sum them\n            num_correct += (preds == y).sum()\n            # count the num of samples\n            num_samples += preds.shape[0]\n    \n    # calculate the accuracy, float since numbers are tensors\n    acc_ = float(num_correct) / float(num_samples)\n    if train:\n        print(f'>> loss: {loss_} - accuracy: {acc_}')\n    else:\n        print(f'==>> val loss: {loss_} - val accuracy: {acc_}')\n\n    # switch the model to train mode\n    model.train()\n    return loss_, acc_","metadata":{"execution":{"iopub.status.busy":"2021-08-02T03:29:18.852357Z","iopub.execute_input":"2021-08-02T03:29:18.852707Z","iopub.status.idle":"2021-08-02T03:29:18.862737Z","shell.execute_reply.started":"2021-08-02T03:29:18.852669Z","shell.execute_reply":"2021-08-02T03:29:18.861855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fit(model, loaders, epochs, criterion, optimizer):\n    model.train() # put the model on train mode\n    train_loader, val_loader = loaders\n    hist = { # to save the training data\n        'accuracy': [],\n        'val accuracy': [],\n        'loss': [],\n        'val loss': [],\n    }\n    # define a bar for the train epochs\n    bar = tqdm(range(1, epochs+1))\n    # start the training loop\n    for epoch in bar:\n        # variables for each epoch\n        _loss = []\n        _acc = []\n        for x_batch, y_batch in train_loader:\n            # move the data and labels to the device\n            x_batch = x_batch.to(device)\n            y_batch = y_batch.to(device)\n            # predict\n            y_pred = model(x_batch)\n            # calculate the loss\n            loss = criterion(y_pred, y_batch)\n            # clear the gradient\n            optimizer.zero_grad()\n            # back prop of the loss\n            loss.backward()\n            # update the weights\n            optimizer.step()\n            \n        # evaluate the model on train set\n        l_t, a_t = check_accuracy(model, train_loader, criterion)\n        # evaluate the model on val set, get acc and loss\n        l_v, a_v = check_accuracy(model, val_loader, criterion, train=False)\n        # apped the data\n        hist['accuracy'].append(a_t)\n        hist['loss'].append(l_t)\n        hist['val accuracy'].append(a_v)\n        hist['val loss'].append(l_v)\n        \n        # look for the best model\n        if epoch > 1:\n            past_acc = hist['val accuracy'][epoch-2]\n            actual_acc = hist['val accuracy'][epoch-1]\n            # if the models reach a higher acc\n            if actual_acc > past_acc:\n                # save that accuracy\n                torch.save(model.state_dict(), './model.pth')\n                saved_acc = actual_acc\n        \n    # finally use the best model reached\n    model = Network()\n    model = model.to(device)\n    # load the model\n    model.load_state_dict(torch.load('./model.pth'))\n    print(f'Loaded checkpoint with {saved_acc} acc')\n    return hist\n\n# define the optimizer and the loss functions\noptimizer = optim.Adam(model.parameters(), lr=0.001)\ncriterion = nn.CrossEntropyLoss()\n\nepochs = 25\n\n# train the model\nhistory = fit(\n    model, (data_loaders['train'], data_loaders['val']),\n    epochs, criterion, optimizer\n)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T03:29:18.864113Z","iopub.execute_input":"2021-08-02T03:29:18.864675Z","iopub.status.idle":"2021-08-02T03:30:49.321778Z","shell.execute_reply.started":"2021-08-02T03:29:18.864638Z","shell.execute_reply":"2021-08-02T03:30:49.318972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_train(history, epochs)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T03:30:49.323266Z","iopub.execute_input":"2021-08-02T03:30:49.323681Z","iopub.status.idle":"2021-08-02T03:30:49.799682Z","shell.execute_reply.started":"2021-08-02T03:30:49.323637Z","shell.execute_reply":"2021-08-02T03:30:49.798685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluate the Model","metadata":{}},{"cell_type":"code","source":"results = check_accuracy(model, data_loaders['test'], criterion)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T03:30:49.800781Z","iopub.execute_input":"2021-08-02T03:30:49.801092Z","iopub.status.idle":"2021-08-02T03:30:50.024841Z","shell.execute_reply.started":"2021-08-02T03:30:49.801055Z","shell.execute_reply":"2021-08-02T03:30:50.024017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# to decode from one hot (predictions) to numbers\ndef decode(labels): # recieve a torch tensor, a prediction\n    # select the indexs of the max elements in each label\n    decoded = torch.argmax(labels, dim=1).numpy()\n    return decoded\n\ndef flatten2d(arr):\n    res = []\n    for row in arr:\n        for i in row:\n            res.append(i)\n    return res\n\n# obtain the labels for the confusion matrix\nlabels = []\npreds = []\n\nfor x,y in data_loaders['test']:\n    # move the data for\n    x = x.to(device)\n    # predict and return to cpu\n    p = model(x).to('cpu')\n    # decode and append\n    preds.append(list(decode(p)))\n    # append the labels\n    labels.append(list(y.numpy()))\n\n# flatten the lists\nlabels = flatten2d(labels)\npreds = flatten2d(preds)\n\nlabels[:10], preds[:10]","metadata":{"execution":{"iopub.status.busy":"2021-08-02T03:30:50.0285Z","iopub.execute_input":"2021-08-02T03:30:50.030417Z","iopub.status.idle":"2021-08-02T03:30:50.348132Z","shell.execute_reply.started":"2021-08-02T03:30:50.030377Z","shell.execute_reply":"2021-08-02T03:30:50.347292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define the matrix with the real classes and the predicted\nm = confusion_matrix(labels, preds)\n# the labels for the plot\nlabs = np.arange(10)\nplt.figure(figsize=(20, 8))\n# create the plot\nheatmap = sns.heatmap(m, xticklabels=labs, yticklabels=labs, annot=True, fmt='d', color='blue')\n# labels for the axes\nplt.xlabel('Predicted Label')\nplt.ylabel('Real Label')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-02T03:30:50.349603Z","iopub.execute_input":"2021-08-02T03:30:50.34993Z","iopub.status.idle":"2021-08-02T03:30:50.930125Z","shell.execute_reply.started":"2021-08-02T03:30:50.349892Z","shell.execute_reply":"2021-08-02T03:30:50.929042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion\nThis dataset is pretty useful to practice deep learning. Having 5500 images is a good quantity of data, but using data augmentation it's possible to multiplicate the quantity of data. Also I think that since those augmentations transform the original images in others that are harder to classify, then the model might classify easier the original images, those that has no tranformations. Let's try it :3","metadata":{}},{"cell_type":"code","source":"# these are the original images\ndata = dataset.drop(['label'], axis=1).values.astype('float32')\nlabels = dataset.values[:,-1].astype('float32')\n\ndata.shape, labels.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-02T03:45:09.964569Z","iopub.execute_input":"2021-08-02T03:45:09.964926Z","iopub.status.idle":"2021-08-02T03:45:09.993237Z","shell.execute_reply.started":"2021-08-02T03:45:09.964895Z","shell.execute_reply":"2021-08-02T03:45:09.992229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# then create a new dataset and dataloader\nds = DS(data, labels)\nloader = DataLoader(ds, batch_size=1, shuffle=True)\n# finally check the acuracy\n_ = check_accuracy(model, loader, criterion)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T03:48:27.318033Z","iopub.execute_input":"2021-08-02T03:48:27.318461Z","iopub.status.idle":"2021-08-02T03:48:32.18809Z","shell.execute_reply.started":"2021-08-02T03:48:27.318417Z","shell.execute_reply":"2021-08-02T03:48:32.187151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Yes, it has higher accuracy and lower loss than the test loader. Thanks for the dataset!! :D","metadata":{}}]}