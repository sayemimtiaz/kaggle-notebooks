{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1 style=\"background-color:#ADD8E6; font-family:'Brush Script MT',cursive;color:white;font-size:200%; text-align:center;border-radius: 50% 20% / 10% 40%\">Introduction</h1>","metadata":{}},{"cell_type":"markdown","source":"\nThe dataset contains 116-year rainfall data of Pakistan.To predict the rainfall i'm using the ARIMA and LSTM models. The parameters considered for the evaluation of the performance and the efficiency of the proposed rainfall prediction model are Root Mean Square Error (RMSE).Notebook summary\n* Importing and Data cleaning\n* Exploratory Data Analysis\n* Forecast across the test set using an ARIMA model.\n* Forecast across the test set using an LSTM model and examine\n","metadata":{}},{"cell_type":"markdown","source":"<h1 style=\"background-color:#ADD8E6; font-family:'Brush Script MT',cursive;color:white;font-size:200%; text-align:center;border-radius: 50% 20% / 10% 40%\">Importing and Data cleaning</h1>\n","metadata":{}},{"cell_type":"code","source":"!pip install pmdarima","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Importing Libraries\n\n# linear algebra\nimport numpy as np \nimport math\n\n# data processing\nimport pandas as pd\n\n# data visualization(for EDA)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nplt.style.use('ggplot')\nsns.set(color_codes=True)\nimport plotly.express as px\nimport cufflinks as cf\ncf.go_offline()\ncf.set_config_file(offline=False, world_readable=True)\n\n#ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\n\n#For lstm model\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\n\n#for Arima model\nfrom pmdarima.arima import auto_arima\nfrom statsmodels.tsa.stattools import adfuller\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv('../input/rainfall-in-pakistan/Rainfall_1901_2016_PAK.csv')\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#creating index column\ndf['Date']=pd.to_datetime(df[' Year'].astype(str)  + df['Month'], format='%Y%B').dt.to_period('m')\ndf = df.set_index('Date')\ndf = df.rename(columns = {'Rainfall - (MM)':'Rainfall',' Year':'Year'})\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"background-color:#ADD8E6; font-family:'Brush Script MT',cursive;color:white;font-size:200%; text-align:center;border-radius: 50% 20% / 10% 40%\">Exploratory Data Analysis</h1>\n","metadata":{}},{"cell_type":"markdown","source":"From the graph, we can see that the highest average rainfall in Pakistan was recorded in the year 1944.","metadata":{}},{"cell_type":"code","source":"ax=df.groupby([df.Year]).mean()['Rainfall']\nfig = px.line(ax, x=ax.index, y='Rainfall', title='Annual rainfall in Pakistan from 1901 to 2016')\nfig.update_traces(mode='lines+markers',line=dict(color='Orange'))\nfig.update(layout=dict(title=dict(x=0.5)))\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" To analysis the progression level of rainfall, I took the rolling average of 10 years.","metadata":{}},{"cell_type":"code","source":"ax=df.groupby('Year').mean()['Rainfall'].rolling(10).mean()\nfig = px.line(ax, x=ax.index, y='Rainfall', title='Rolling average of 10 years of Rainfall')\nfig.update_traces(mode='lines+markers',line=dict(color='Black'))\nfig.update(layout=dict(title=dict(x=0.5)))\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the figure we can see that the majority of the rainfall is received in the months of July and August which is the monsoon season while in October and November the least Rainfall is recorded.","metadata":{}},{"cell_type":"code","source":"ax=df.groupby([df.Month]).mean()['Rainfall']\nfig = px.bar(ax,y='Rainfall',title='Monthly Rainfall in Pakistan',category_orders={\"Month\": [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\",\n      \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"]},color_discrete_sequence=px.colors.qualitative.D3)\nfig.update(layout=dict(title=dict(x=0.5)))\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Pakistan has four seasons:  winter from December through February; spring from March through May; the summer rainy season, or southwest monsoon period, from June through September; and the Autumn period is in October and November.\nFrom the graph, it is clear that Pakistan received more rainfall in the summer and spring seasons.\n","metadata":{}},{"cell_type":"code","source":"winter=df.query('Month==\"December\" or Month==\"January\" or Month==\"February\"').groupby([df.Year]).mean()['Rainfall']\nspring=df.query('Month==\"March\"or Month==\"April\"').groupby([df.Year]).mean()['Rainfall']\nsummer=df.query('Month==\"May\" or Month==\"June\" or Month==\"July\" or Month==\"August\"or Month==\"September\"').groupby([df.Year]).mean()['Rainfall']\nAutumn=df.query('Month==\"October\" or Month==\"November\"').groupby([df.Year]).mean()['Rainfall']\ndata=pd.DataFrame({ 'Winter': winter, 'Spring': spring,'Summer': summer, 'Autumn': Autumn })\ndata.plot(figsize=(17,8));\nplt.title('Seasonal Rainfall in Pakistan from 1901 to 2016',fontsize=20);\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y=data.mean()\nx=data.columns\nfig = px.bar(x=x,y=y,color=x,title='Season wise Rainfall in Pakistan')\nfig.update(layout=dict(title=dict(x=0.5)))\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ax=df.groupby([df.index.year]).agg({'Rainfall':sum})\nprint('The largest amount of rain was recorded in the following years')\nax['Rainfall'].nlargest(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"background-color:#ADD8E6; font-family:'Brush Script MT',cursive;color:white;font-size:200%; text-align:center;border-radius: 50% 20% / 10% 40%\">LSTM Model</h1>\n","metadata":{}},{"cell_type":"code","source":"#Data preprcessing\ndataset = df.drop(columns = ['Month','Year'])\n# normalize the dataset\nscaler = MinMaxScaler(feature_range=(0, 1))\ndataset = scaler.fit_transform(dataset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Converting  an array of values into a dataset matrix. The function takes two arguments: the dataset, which is a NumPy array that we want to convert into a dataset, and the look_back, which is the number of previous time steps to use as input variables to predict the next time period and in our case look back is 1.","metadata":{}},{"cell_type":"code","source":"# convert an array of values into a dataset matrix\ndef create_dataset(dataset, look_back=12):\n\tdataX, dataY = [], []\n\tfor i in range(len(dataset)-look_back-1):\n\t\ta = dataset[i:(i+look_back), 0]\n\t\tdataX.append(a)\n\t\tdataY.append(dataset[i + look_back, 0])\n\treturn np.array(dataX), np.array(dataY)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n# split into train and test sets\ntraining_size=int(len(dataset)*0.90)\ntest_size=len(dataset)-training_size\ntrain, test =dataset[0:training_size,:],dataset[training_size:len(dataset),:1]\n\n#reshape into X=t and Y=t+1\nlook_back =12\ntrainX, trainY = create_dataset(train, look_back)\ntestX, testY = create_dataset(test, look_back)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The LSTM network expects the input data (X) to be provided with a specific array structure in the form of: (samples, time steps, features) but Currently, our data is in the form: (samples, features)","metadata":{}},{"cell_type":"code","source":"# reshape input to be [samples, time steps, features]\ntrainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\ntestX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We are now ready to design and fit our LSTM network.","metadata":{}},{"cell_type":"code","source":"\n# create and fit the LSTM network\nmodel=Sequential()\nmodel.add(LSTM(50,return_sequences=True,input_shape=(1,look_back)))\nmodel.add(LSTM(50,return_sequences=True))\nmodel.add(LSTM(50))\nmodel.add(Dense(1))\nmodel.compile(loss='mean_squared_error', optimizer='adam')\nhistory = model.fit(trainX, trainY, epochs=600, batch_size=200, validation_data=(testX, testY), shuffle=False)\n","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"###  A plot of learning curves \nTrain and Validation Learning Curves Showing a Good Fit because The plot of validation loss decreases and has a small gap with the training loss.","metadata":{}},{"cell_type":"code","source":"\n# plot train and validation loss\nimport matplotlib.pyplot as plt\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model train vs validation loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper right')\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The model is fit, now we can estimate the performance of the model on the test datasets.","metadata":{}},{"cell_type":"code","source":"\ntestPredict = model.predict(testX)\n# invert predictions\ntest_Predict = scaler.inverse_transform(testPredict)\ntest_Y = scaler.inverse_transform([testY])\n# calculate root mean squared error\ntestScore = math.sqrt(mean_squared_error(test_Y[0], test_Predict[:,0]))\nprint('Test Score: %.2f RMSE' % (testScore))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndata = df.drop(columns = ['Month','Year'])\ntestindex=data[-(testY.size):]\nfuture_forecast = pd.DataFrame(test_Predict[:,0],index =testindex.index,columns=['Prediction'])\npd.concat([testindex,future_forecast],axis=1).iplot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"background-color:#ADD8E6; font-family:'Brush Script MT',cursive;color:white;font-size:200%; text-align:center;border-radius: 50% 20% / 10% 40%\">ARIMA Model</h1>","metadata":{}},{"cell_type":"markdown","source":"**ARIMA models work on the following assumptions –**\n\n1. The data series is stationary, which means that the mean and variance should not vary with time.\n1. The data provided as input must be a univariate series, since arima uses the past values to predict the future values.\n\n**To identify the nature of data, we will be using the null hypothesis.**\n\n* Ho: It is non-stationary\n* H1: It is stationary\nWe will be considering the null hypothesis that data is not stationary and the alternate hypothesis that data is stationary.\n\n","metadata":{}},{"cell_type":"code","source":"test_result=adfuller(df['Rainfall'])\ndef adfuller_test(sales):\n    result=adfuller(sales)\n    labels = ['ADF Test Statistic','p-value','#Lags Used','Number of Observations']\n    for value,label in zip(result,labels):\n        print(label+' : '+str(value) )\n\n    if result[1] <= 0.05:\n        print(\"strong evidence against the null hypothesis(Ho), reject the null hypothesis. Data is stationary\")\n    else:\n        print(\"weak evidence against null hypothesis,indicating it is non-stationary \")\n\nadfuller_test(df['Rainfall'])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we are working on univariate time series and Data is also stationary.So we can use Arima model.","metadata":{}},{"cell_type":"code","source":"# split into train and test sets\ntraining_size=int(len(df)*0.90)\ntest_size=len(df)-training_size\ntrain,valid=df.iloc[0:training_size,:],df.iloc[training_size:len(df),:1]\ntraining = train['Rainfall']\nvalidation = valid['Rainfall']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"ARIMA has three components – AR (autoregressive term), I (differencing term) and MA (moving average term). \n\n1. AR term refers to the past values used for forecasting the next value and it represented by p.\n1. MA term is used to defines number of past forecast errors used to predict the future values and it represented by q.\n1. Order of differencing  specifies the number of times the differencing operation is performed on series to make it stationary and it represented by d.\n\n**I'm using auto arima in which i don't have to select the combination of p, q, d.Because the model select the best combination of these parameters.**","metadata":{}},{"cell_type":"code","source":"model = auto_arima(training, start_p=0, start_q=0,max_p=3, max_q=3, m=12,start_P=0,start_Q=0,max_P=1,max_Q=1, seasonal=True,d=0, D=1, trace=True,error_action='ignore',suppress_warnings=True)\nmodel.fit(training)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfuture_forecast = model.predict(len(valid))\nfuture_forecast = pd.DataFrame(future_forecast,index =valid.index,columns=['Prediction'])\npd.concat([valid,future_forecast],axis=1).iplot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testScore = math.sqrt(mean_squared_error(valid,future_forecast))\nprint('Test Score: %.2f RMSE' % (testScore))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}