{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# â›”ï¸ CNN trained on \"light\" version of TS","metadata":{}},{"cell_type":"markdown","source":"* **Training** deep CNN on **\"light\"** version of TS for classification\n* Dataset with **\"original\"**, **\"light\"** & **\"hard\"** versions: [https://www.kaggle.com/valentynsichkar/traffic-signs-1-million-images-for-classification](https://www.kaggle.com/valentynsichkar/traffic-signs-1-million-images-for-classification)\n* Dataset with preprocessed **\"light\"** version: [https://www.kaggle.com/valentynsichkar/preprocessed-light-version-of-traffic-signs](https://www.kaggle.com/valentynsichkar/preprocessed-light-version-of-traffic-signs)","metadata":{}},{"cell_type":"markdown","source":"# ðŸŽ“ Related course for classification tasks","metadata":{}},{"cell_type":"markdown","source":"**Design**, **Train** & **Test** deep CNN for Image Classification.\n\n**Join** the course & enjoy new opportunities to get deep learning skills:\n\n\n[https://www.udemy.com/course/convolutional-neural-networks-for-image-classification/](https://www.udemy.com/course/convolutional-neural-networks-for-image-classification/?referralCode=12EE0D74A405BF4DDE9B)\n\n\n![](https://github.com/sichkar-valentyn/1-million-images-for-Traffic-Signs-Classification-tasks/blob/main/images/slideshow_classification.gif?raw=true)","metadata":{}},{"cell_type":"markdown","source":"# ðŸ“¥ Importing needed libraries","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n# To create temporary directory, type in following in the Console\n# os.chdir(\"/kaggle/\")\n# !mkdir temp\n# os.listdir()\n\n# Any results we write to the current directory are saved as output in '/kaggle/working/' directory\nprint()\nprint(os.listdir('..'))\nprint(os.listdir('/kaggle/input'))\nprint(os.listdir('/kaggle/working/'))\n# print(os.listdir('/kaggle/temp/'))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-14T15:28:57.641007Z","iopub.execute_input":"2021-06-14T15:28:57.641466Z","iopub.status.idle":"2021-06-14T15:28:57.686701Z","shell.execute_reply.started":"2021-06-14T15:28:57.641362Z","shell.execute_reply":"2021-06-14T15:28:57.686052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Importing needed libraries\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport h5py\nimport cv2\n\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential, load_model\nfrom keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout\nfrom keras.utils import plot_model\nfrom keras.callbacks import LearningRateScheduler, ModelCheckpoint\n\nfrom sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n\nfrom timeit import default_timer as timer\n\n# Check point\nprint('Libraries are imported successfully')\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T15:29:05.952346Z","iopub.execute_input":"2021-06-14T15:29:05.952675Z","iopub.status.idle":"2021-06-14T15:29:11.686497Z","shell.execute_reply.started":"2021-06-14T15:29:05.952644Z","shell.execute_reply":"2021-06-14T15:29:11.685607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# âž° Designing and Saving Deep CNN model","metadata":{}},{"cell_type":"code","source":"# Building model for RGB datasets\n# RGB --> {128C5-P2-D30} --> {256C5-P2-D30} --> {512C5-P2-D30} --> {1024C3-P2-D30} --> 2048-D30 --> 43\n\n# Initializing model to be as linear stack of layers\nmodel = Sequential()\n\n# Adding first convolutional-pooling pair\nmodel.add(Conv2D(128, kernel_size=5, padding='same', activation='relu', input_shape=(48, 48, 3),\n                 kernel_initializer='random_normal',\n                 bias_initializer='zeros'))\nmodel.add(MaxPool2D())\nmodel.add(Dropout(0.3))\n\n# Adding second convolutional-pooling pair\nmodel.add(Conv2D(256, kernel_size=5, padding='same', activation='relu',\n                 kernel_initializer='random_normal',\n                 bias_initializer='zeros'))\nmodel.add(MaxPool2D())\nmodel.add(Dropout(0.3))\n\n# Adding third convolutional-pooling pair\nmodel.add(Conv2D(512, kernel_size=5, padding='same', activation='relu',\n                 kernel_initializer='random_normal',\n                 bias_initializer='zeros'))\nmodel.add(MaxPool2D())\nmodel.add(Dropout(0.3))\n\n# Adding fourth convolutional-pooling pair\nmodel.add(Conv2D(1024, kernel_size=3, padding='same', activation='relu',\n                 kernel_initializer='random_normal',\n                 bias_initializer='zeros'))\nmodel.add(MaxPool2D())\nmodel.add(Dropout(0.3))\n\n# Adding fully connected layers\nmodel.add(Flatten())\nmodel.add(Dense(2048, activation='relu',\n                kernel_initializer='random_normal',\n                bias_initializer='zeros'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(43, activation='softmax'))\n\n# Compiling created model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Saving model for RGB datasets\nmodel.save('model_ts_rgb_light.h5')\n\n\n\n\n# Building model for GRAY datasets\n# GRAY --> {128C5-P2-D30} --> {256C5-P2-D30} --> {512C5-P2-D30} --> {1024C3-P2-D30} --> 2048-D30 --> 43\n\n# Initializing model to be as linear stack of layers\nmodel = Sequential()\n\n# Adding first convolutional-pooling pair\nmodel.add(Conv2D(128, kernel_size=5, padding='same', activation='relu', input_shape=(48, 48, 1),\n                 kernel_initializer='random_normal',\n                 bias_initializer='zeros'))\nmodel.add(MaxPool2D())\nmodel.add(Dropout(0.3))\n\n# Adding second convolutional-pooling pair\nmodel.add(Conv2D(256, kernel_size=5, padding='same', activation='relu',\n                 kernel_initializer='random_normal',\n                 bias_initializer='zeros'))\nmodel.add(MaxPool2D())\nmodel.add(Dropout(0.3))\n\n# Adding third convolutional-pooling pair\nmodel.add(Conv2D(512, kernel_size=5, padding='same', activation='relu',\n                 kernel_initializer='random_normal',\n                 bias_initializer='zeros'))\nmodel.add(MaxPool2D())\nmodel.add(Dropout(0.3))\n\n# Adding fourth convolutional-pooling pair\nmodel.add(Conv2D(1024, kernel_size=3, padding='same', activation='relu',\n                 kernel_initializer='random_normal',\n                 bias_initializer='zeros'))\nmodel.add(MaxPool2D())\nmodel.add(Dropout(0.3))\n\n# Adding fully connected layers\nmodel.add(Flatten())\nmodel.add(Dense(2048, activation='relu',\n                kernel_initializer='random_normal',\n                bias_initializer='zeros'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(43, activation='softmax'))\n\n# Compiling created model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Saving 1st model for GRAY datasets\nmodel.save('model_ts_gray_light.h5')\n\n\n# Check point\nprint('2 models are saved successfully')\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T15:29:14.624953Z","iopub.execute_input":"2021-06-14T15:29:14.625286Z","iopub.status.idle":"2021-06-14T15:29:17.801155Z","shell.execute_reply.started":"2021-06-14T15:29:14.625252Z","shell.execute_reply":"2021-06-14T15:29:17.800199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ðŸ“¥ Loading and Verifying model","metadata":{}},{"cell_type":"code","source":"# Loading model\nmodel_rgb = load_model('/kaggle/working/model_ts_rgb_light.h5')\nmodel_gray = load_model('/kaggle/working/model_ts_gray_light.h5')\n\n# Check point\nprint('2 models are loaded successfully')\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T15:29:22.038203Z","iopub.execute_input":"2021-06-14T15:29:22.038532Z","iopub.status.idle":"2021-06-14T15:29:22.478887Z","shell.execute_reply.started":"2021-06-14T15:29:22.038501Z","shell.execute_reply":"2021-06-14T15:29:22.477961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Showing model's summary in form of table\nmodel_rgb.summary()\nprint()\nmodel_gray.summary()\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T15:29:24.813713Z","iopub.execute_input":"2021-06-14T15:29:24.814029Z","iopub.status.idle":"2021-06-14T15:29:24.832706Z","shell.execute_reply.started":"2021-06-14T15:29:24.813999Z","shell.execute_reply":"2021-06-14T15:29:24.831945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Showing dropout rate\nprint(model_rgb.layers[2].rate)\nprint(model_gray.layers[2].rate)\n\n# Showing strides for the 1st layer (convolutional)\nprint(model_rgb.layers[0].strides)\nprint(model_gray.layers[0].strides)\n\n# Showing strides for the 2nd layer (max pooling)\nprint(model_rgb.layers[1].strides)\nprint(model_gray.layers[1].strides)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T15:29:29.720143Z","iopub.execute_input":"2021-06-14T15:29:29.720474Z","iopub.status.idle":"2021-06-14T15:29:29.729981Z","shell.execute_reply.started":"2021-06-14T15:29:29.720442Z","shell.execute_reply":"2021-06-14T15:29:29.728732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ðŸ“‚ Defining separate 4 models for training","metadata":{}},{"cell_type":"code","source":"# Defining lists to collect models in\nmodel_rgb = []\nmodel_gray = []\n\n\n# Loading models and appending them into lists\nfor i in range(2):\n    model_rgb.append(load_model('/kaggle/working/model_ts_rgb_light.h5'))\n    \n    model_gray.append(load_model('/kaggle/working/model_ts_gray_light.h5'))\n\n\n# Check point\nprint('4 separate models are successfully loaded')\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T15:29:32.175569Z","iopub.execute_input":"2021-06-14T15:29:32.175887Z","iopub.status.idle":"2021-06-14T15:29:33.068948Z","shell.execute_reply.started":"2021-06-14T15:29:32.175855Z","shell.execute_reply":"2021-06-14T15:29:33.067921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Showing models' input shapes\nprint(model_rgb[0].layers[0].input_shape)\nprint()\nprint(model_gray[0].layers[0].input_shape)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T15:29:35.896845Z","iopub.execute_input":"2021-06-14T15:29:35.89716Z","iopub.status.idle":"2021-06-14T15:29:35.903465Z","shell.execute_reply.started":"2021-06-14T15:29:35.897128Z","shell.execute_reply":"2021-06-14T15:29:35.902568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# âž¿ Training separately defined models","metadata":{}},{"cell_type":"code","source":"# Defining number of epochs\nepochs = 10\n\n\n# Defining schedule to update learning rate\nlearning_rate = LearningRateScheduler(lambda x: 1e-2 * 0.95 ** (x + 50), verbose=1)\n\n\n# Check point\nprint('Number of epochs and schedule for learning rate are set successfully')\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T15:29:38.142856Z","iopub.execute_input":"2021-06-14T15:29:38.143174Z","iopub.status.idle":"2021-06-14T15:29:38.148321Z","shell.execute_reply.started":"2021-06-14T15:29:38.143142Z","shell.execute_reply":"2021-06-14T15:29:38.14744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preparing list with datasets' names\ndatasets = ['dataset_ts_rgb_255_mean_light.hdf5',\n            'dataset_ts_rgb_255_mean_std_light.hdf5',\n            'dataset_ts_gray_255_mean_light.hdf5',\n            'dataset_ts_gray_255_mean_std_light.hdf5']\n\n\n# Defining list to collect results in\nh = []\n\n\n# Training model with all Traffic Signs datasets in a loop\nfor i in range(4):\n    # Opening saved Traffic Signs dataset from HDF5 binary file\n    # Initiating File object\n    # Opening file in reading mode by 'r'\n    with h5py.File('/kaggle/input/preprocessed-light-version-of-traffic-signs/' + datasets[i], 'r') as f:\n        # Extracting saved arrays for training by appropriate keys\n        # Saving them into new variables\n        x_train = f['x_train']  # HDF5 dataset\n        y_train = f['y_train']  # HDF5 dataset\n        # Converting them into Numpy arrays\n        x_train = np.array(x_train)  # Numpy arrays\n        y_train = np.array(y_train)  # Numpy arrays\n\n        # Extracting saved arrays for validation by appropriate keys\n        # Saving them into new variables\n        x_validation = f['x_validation']  # HDF5 dataset\n        y_validation = f['y_validation']  # HDF5 dataset\n        # Converting them into Numpy arrays\n        x_validation = np.array(x_validation)  # Numpy arrays\n        y_validation = np.array(y_validation)  # Numpy arrays\n    \n    \n    # Check point\n    print('Following dataset is successfully opened:        ', datasets[i])\n    \n    \n    # Preparing classes to be passed into the model\n    # Transforming them from vectors to binary matrices\n    # It is needed to set relationship between classes to be understood by the algorithm\n    # Such format is commonly used in training and predicting\n    y_train = to_categorical(y_train, num_classes = 43)\n    y_validation = to_categorical(y_validation, num_classes = 43)\n    \n    \n    # Check point\n    print('Binary matrices are successfully created:        ', datasets[i])\n \n\n    # Preparing filepath to save best weights\n    best_weights_filepath = 'w' + datasets[i][7:-5] + '.h5'\n       \n    # Defining schedule to save best weights\n    best_weights = ModelCheckpoint(filepath=best_weights_filepath,\n                                   save_weights_only=True,                                   \n                                   monitor='val_accuracy',\n                                   mode='max',\n                                   save_best_only=True,\n                                   period=1,\n                                   verbose=1)\n    \n    \n    # Check point\n    print('Schedule to save best weights is created:        ', datasets[i])\n\n    \n    # Checking if RGB dataset is opened\n    if i <= 1:\n        # Training RGB model with current dataset\n        temp = model_rgb[i].fit(x_train, y_train,\n                                batch_size=50,\n                                epochs=epochs,\n                                validation_data=(x_validation, y_validation),\n                                callbacks=[learning_rate, best_weights],\n                                verbose=1)\n\n        \n        # Adding results of model for current RGB dataset in the list\n        h.append(temp)\n        \n        \n        # Check points\n        print('Model for RGB is successfully trained on:        ', datasets[i])\n        print('Trained weights for RGB are saved successfully:  ', 'w' + datasets[i][7:-5] + '.h5')\n        print()\n    \n    # Checking if GRAY dataset is opened\n    elif i >= 2:\n        # Training GRAY model with current dataset\n        temp = model_gray[i-2].fit(x_train, y_train,\n                                   batch_size=50,\n                                   epochs=epochs,\n                                   validation_data=(x_validation, y_validation),\n                                   callbacks=[learning_rate, best_weights],\n                                   verbose=1)\n\n        \n        # Adding results of 1st model for current GRAY dataset in the list\n        h.append(temp)\n        \n        \n        # Check points\n        print('Model for GRAY is successfully trained on:       ', datasets[i])\n        print('Trained weights for GRAY are saved successfully: ', 'w' + datasets[i][7:-5] + '.h5')\n        print()\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T15:29:40.504204Z","iopub.execute_input":"2021-06-14T15:29:40.504552Z","iopub.status.idle":"2021-06-14T16:09:06.27377Z","shell.execute_reply.started":"2021-06-14T15:29:40.504522Z","shell.execute_reply":"2021-06-14T16:09:06.272812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Resulted accuracies of all pre-processed Traffic Signs datasets\nfor i in range(4):\n    print('T: {0:.5f},  V: {1:.5f},  D: {2}'.format(max(h[i].history['accuracy']),\n                                                    max(h[i].history['val_accuracy']),\n                                                    datasets[i][8:-5]))\n    ","metadata":{"execution":{"iopub.status.busy":"2021-06-14T16:09:09.902131Z","iopub.execute_input":"2021-06-14T16:09:09.902459Z","iopub.status.idle":"2021-06-14T16:09:09.908724Z","shell.execute_reply.started":"2021-06-14T16:09:09.90243Z","shell.execute_reply":"2021-06-14T16:09:09.907546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Showing other parameters that history holds\nprint(h[0].params)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T16:09:12.388981Z","iopub.execute_input":"2021-06-14T16:09:12.389317Z","iopub.status.idle":"2021-06-14T16:09:12.393881Z","shell.execute_reply.started":"2021-06-14T16:09:12.389281Z","shell.execute_reply":"2021-06-14T16:09:12.393033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Magic function that renders the figure in a jupyter notebook\n# instead of displaying a figure object\n%matplotlib inline\n\n\n# Setting default size of the plot\nplt.rcParams['figure.figsize'] = (12.0, 6.0)\nplt.rcParams['font.family'] = 'Times New Roman'\n\n\n# Plotting accuracies of all Traffic Signs datasets for 1st model\nplt.plot(h[0].history['val_accuracy'], '-o')\nplt.plot(h[1].history['val_accuracy'], '-o')\nplt.plot(h[2].history['val_accuracy'], '-o')\nplt.plot(h[3].history['val_accuracy'], '-o')\n\n\n# Showing legend\nplt.legend(['rgb_255_mean', 'rgb_255_mean_std',\n            'gray_255_mean', 'gray_255_mean_std'],\n           loc='lower right',\n           fontsize='xx-large')\n\n\n# Giving name to axes\nplt.xlabel('Epoch', fontsize=16)\nplt.ylabel('Accuracy', fontsize=16)\n\n\n# Setting limit along Y axis\nplt.ylim(0.88, 0.9992)\n\n\n# Giving name to the plot\nplt.title('Validation accuracies', fontsize=16)\n\n\n# Saving plot\nplt.savefig('validation_model_ts_dataset_light.png', dpi=500)\n\n\n# Showing the plot\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T16:10:04.475108Z","iopub.execute_input":"2021-06-14T16:10:04.475444Z","iopub.status.idle":"2021-06-14T16:10:05.784239Z","shell.execute_reply.started":"2021-06-14T16:10:04.475412Z","shell.execute_reply":"2021-06-14T16:10:05.783153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Magic function that renders the figure in a jupyter notebook\n# instead of displaying a figure object\n%matplotlib inline\n\n\n# Setting default size of the plot\nplt.rcParams['figure.figsize'] = (12.0, 6.0)\nplt.rcParams['font.family'] = 'Times New Roman'\n\n\n# Plotting training and validation losses of all Traffic Signs datasets for 1st model\nplt.plot(h[0].history['loss'], '-ob')\nplt.plot(h[1].history['loss'], '-og')\nplt.plot(h[2].history['loss'], '-or')\nplt.plot(h[3].history['loss'], '-oc')\n\nplt.plot(h[0].history['val_loss'], '-ob')\nplt.plot(h[1].history['val_loss'], '-og')\nplt.plot(h[2].history['val_loss'], '-or')\nplt.plot(h[3].history['val_loss'], '-oc')\n\n\n# Showing legend\nplt.legend(['rgb_255_mean', 'rgb_255_mean_std',\n            'gray_255_mean', 'gray_255_mean_std'],\n           loc='center right',\n           fontsize='large')\n\n\n# Giving name to axes\nplt.xlabel('Epoch', fontsize=16)\nplt.ylabel('Loss', fontsize=16)\n\n\n# Giving name to the plot\nplt.title('Losses', fontsize=16)\n\n\n# Saving plot\nplt.savefig('losses_model_ts_dataset_light.png', dpi=500)\n\n\n# Showing the plot\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T16:10:11.757693Z","iopub.execute_input":"2021-06-14T16:10:11.758009Z","iopub.status.idle":"2021-06-14T16:10:13.264841Z","shell.execute_reply.started":"2021-06-14T16:10:11.757978Z","shell.execute_reply":"2021-06-14T16:10:13.264026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ðŸ§® Calculating testing accuracies","metadata":{}},{"cell_type":"code","source":"# Defining lists to collect models in\nmodel_rgb = []\nmodel_gray = []\n\n\n# Loading 1st model for Traffic Signs dataset\nfor i in range(2):\n    model_rgb.append(load_model('/kaggle/working/model_ts_rgb_light.h5'))\n    model_gray.append(load_model('/kaggle/working/model_ts_gray_light.h5'))\n\n\n# Check point\nprint('4 separate models are successfully loaded')\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T16:10:16.731716Z","iopub.execute_input":"2021-06-14T16:10:16.732036Z","iopub.status.idle":"2021-06-14T16:10:17.676595Z","shell.execute_reply.started":"2021-06-14T16:10:16.732004Z","shell.execute_reply":"2021-06-14T16:10:17.675673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Showing models' input shapes\nprint(model_rgb[0].layers[0].input_shape)\nprint()\nprint(model_gray[0].layers[0].input_shape)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T16:10:20.996979Z","iopub.execute_input":"2021-06-14T16:10:20.997321Z","iopub.status.idle":"2021-06-14T16:10:21.003392Z","shell.execute_reply.started":"2021-06-14T16:10:20.997283Z","shell.execute_reply":"2021-06-14T16:10:21.002402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preparing list with weights' names\nweights = ['w_ts_rgb_255_mean_light.h5',\n           'w_ts_rgb_255_mean_std_light.h5',\n           'w_ts_gray_255_mean_light.h5',\n           'w_ts_gray_255_mean_std_light.h5']\n\n\n# Loading best weights for 1st model\nfor i in range(4):    \n    # Checking if it is RGB model\n    if i <= 1:\n        # loading and assigning best weights\n        model_rgb[i].load_weights('/kaggle/working/' + weights[i])\n        \n        \n        # Check point\n        print('Best weights for RGB model are loaded and assigned  : ', weights[i])\n    \n    # Checking if it is GRAY model\n    elif i >= 2:\n        # loading and assigning best weights\n        model_gray[i-2].load_weights('/kaggle/working/' + weights[i])\n        \n        \n        # Check point\n        print('Best weights for GRAY model are loaded and assigned : ', weights[i])\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T16:10:22.965193Z","iopub.execute_input":"2021-06-14T16:10:22.966475Z","iopub.status.idle":"2021-06-14T16:10:24.178678Z","shell.execute_reply.started":"2021-06-14T16:10:22.966423Z","shell.execute_reply":"2021-06-14T16:10:24.177682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preparing list with datasets' names\ndatasets = ['dataset_ts_rgb_255_mean_light.hdf5',\n            'dataset_ts_rgb_255_mean_std_light.hdf5',\n            'dataset_ts_gray_255_mean_light.hdf5',\n            'dataset_ts_gray_255_mean_std_light.hdf5']\n\n\n# Defining variable to identify the best model\naccuracy_best = 0\n\n\n# Testing 1st model with all Traffic Signs datasets in a loop\nfor i in range(4):    \n    # Opening saved Traffic Signs dataset from HDF5 binary file\n    # Initiating File object\n    # Opening file in reading mode by 'r'\n    with h5py.File('/kaggle/input/preprocessed-light-version-of-traffic-signs/' + datasets[i], 'r') as f:\n        # Extracting saved arrays for testing by appropriate keys\n        # Saving them into new variables\n        x_test = f['x_test']  # HDF5 dataset\n        y_test = f['y_test']  # HDF5 dataset\n        # Converting them into Numpy arrays\n        x_test = np.array(x_test)  # Numpy arrays\n        y_test = np.array(y_test)  # Numpy arrays\n    \n    \n    # Check point\n    print('Dataset is opened :', datasets[i])\n    \n    \n    # Check point\n    # Showing shapes of loaded arrays\n    if i == 0:\n        print('x_test shape      :', x_test.shape)\n        print('y_test shape      :', y_test.shape)\n    \n    \n    # Checking if RGB dataset is opened\n    if i <= 1:\n        # Testing RGB model with current dataset\n        temp = model_rgb[i].predict(x_test)\n        \n        \n        # Check point\n        # Showing prediction shape and scores\n        if i == 0:\n            print('prediction shape  :', temp.shape)  # (3111, 43)\n            print('prediction scores :', temp[0, 0:5])  # 5 score numbers\n      \n    \n        # Getting indexes of maximum values along specified axis\n        temp = np.argmax(temp, axis=1)\n        \n        \n        # Check point\n        # Showing prediction shape after convertion\n        # Showing predicted and correct indexes of classes\n        if i == 0:\n            print('prediction shape  :', temp.shape)  # (3111,)\n            print('predicted indexes :', temp[0:10])\n            print('correct indexes   :', y_test[:10])\n        \n        \n        # Calculating accuracy\n        # We compare predicted class with correct class for all input images\n        # By saying 'temp == y_test' we create Numpy array with True and False values\n        # By function 'np.mean' we calculate mean value:\n        # all_True / (all_True + all_False)\n        accuracy = np.mean(temp == y_test)\n        \n        \n        # Check point\n        # Showing True and False matrix\n        if i == 0:\n            print('T and F matrix    :', (temp == y_test)[0:10])\n        \n        \n        # Check point\n        # Showing calculated accuracy\n        print('Testing accuracy  : {0:.5f}'.format(accuracy))\n        print()\n    \n    # Checking if GRAY dataset is opened\n    elif i >= 2:\n        # Testing GRAY model with current dataset\n        temp = model_gray[i-2].predict(x_test)\n        \n        \n        # Getting indexes of maximum values along specified axis\n        temp = np.argmax(temp, axis=1)\n        \n        \n        # Calculating accuracy\n        # We compare predicted class with correct class for all input images\n        # By saying 'temp == y_test' we create Numpy array with True and False values\n        # By function 'np.mean' we calculate mean value:\n        # all_True / (all_True + all_False)\n        accuracy = np.mean(temp == y_test)\n        \n        \n        # Check point\n        # Showing calculated accuracy\n        print('Testing accuracy  : {0:.5f}'.format(accuracy))\n        print()\n    \n    \n    # Identifying the best model\n    # Saving predicted indexes of the best model\n    if accuracy > accuracy_best:\n        # Updating value of the best accuracy\n        accuracy_best = accuracy\n        \n        # Saving predicted indexes of the best model into array\n        # Updating array with predicted indexes of the best model\n        y_predicted_best = temp\n    ","metadata":{"execution":{"iopub.status.busy":"2021-06-14T16:10:26.531126Z","iopub.execute_input":"2021-06-14T16:10:26.531455Z","iopub.status.idle":"2021-06-14T16:10:42.139103Z","shell.execute_reply.started":"2021-06-14T16:10:26.531426Z","shell.execute_reply":"2021-06-14T16:10:42.138246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# âœ¨ Classification report","metadata":{}},{"cell_type":"code","source":"# Showing the main classification metrics of the best model\nprint(classification_report(y_test, y_predicted_best))\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T16:10:45.344954Z","iopub.execute_input":"2021-06-14T16:10:45.345308Z","iopub.status.idle":"2021-06-14T16:10:45.378377Z","shell.execute_reply.started":"2021-06-14T16:10:45.345274Z","shell.execute_reply":"2021-06-14T16:10:45.377508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# âœ”ï¸ Confusion matrix","metadata":{}},{"cell_type":"code","source":"# Confusion matrix is a two dimensional matrix that visualizes the performance,\n# and makes it easy to see confusion between classes,\n# by providing a picture of interrelation\n\n# Each row represents a number of actual class  \n# Each column represents a number of predicted class  \n\n\n# Computing confusion matrix to evaluate accuracy of classification\nc_m = confusion_matrix(y_test, y_predicted_best)\n\n# Showing confusion matrix in form of Numpy array\nprint(c_m)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T16:10:48.498397Z","iopub.execute_input":"2021-06-14T16:10:48.498715Z","iopub.status.idle":"2021-06-14T16:10:48.53731Z","shell.execute_reply.started":"2021-06-14T16:10:48.498683Z","shell.execute_reply":"2021-06-14T16:10:48.536341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Magic function that renders the figure in a jupyter notebook\n# instead of displaying a figure object\n%matplotlib inline\n\n\n# Setting default size of the plot\n# Setting default fontsize used in the plot\nplt.rcParams['figure.figsize'] = (14.0, 14.0)\nplt.rcParams['font.size'] = 12\n\n\n# Implementing visualization of confusion matrix\ndisplay_c_m = ConfusionMatrixDisplay(c_m)\n\n\n# Plotting confusion matrix\n# Setting colour map to be used\ndisplay_c_m.plot(cmap='PuRd')\n# Other possible options for colour map are:\n# 'OrRd', 'autumn_r', 'Blues', 'cool', 'Greens', 'Greys', 'copper_r'\n\n\n# Setting fontsize for xticks and yticks\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\n\n# Setting fontsize for xlabels and ylabels\nplt.xlabel('Predicted label', fontsize=18)\nplt.ylabel('True label', fontsize=18)\n\n\n# Giving name to the plot\nplt.title('Confusion Matrix: Traffic Signs Dataset', fontsize=18)\n\n\n# Saving plot\nplt.savefig('confusion_matrix_ts_model.png', transparent=True, dpi=500)\n\n\n# Showing the plot\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T16:10:50.816552Z","iopub.execute_input":"2021-06-14T16:10:50.816874Z","iopub.status.idle":"2021-06-14T16:11:02.063074Z","shell.execute_reply.started":"2021-06-14T16:10:50.816843Z","shell.execute_reply":"2021-06-14T16:11:02.062159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ðŸ–¼ï¸ Testing on one image","metadata":{}},{"cell_type":"code","source":"# Preparing list with datasets' names\ndatasets = ['dataset_ts_rgb_255_mean_light.hdf5',\n            'dataset_ts_rgb_255_mean_std_light.hdf5',\n            'dataset_ts_gray_255_mean_light.hdf5',\n            'dataset_ts_gray_255_mean_std_light.hdf5']\n\n\n# Opening saved Traffic Signs dataset from HDF5 binary file\n# Initiating File object\n# Opening file in reading mode by 'r'\nwith h5py.File('/kaggle/input/preprocessed-light-version-of-traffic-signs/' + datasets[0], 'r') as f:\n    # Extracting saved arrays for testing by appropriate keys\n    # Saving them into new variables\n    x_test_rgb_255_mean_light = f['x_test']  # HDF5 dataset\n    # Converting them into Numpy arrays\n    x_test_rgb_255_mean_light = np.array(x_test_rgb_255_mean_light)  # Numpy arrays\n\n\n# Opening saved Traffic Signs dataset from HDF5 binary file\n# Initiating File object\n# Opening file in reading mode by 'r'\nwith h5py.File('/kaggle/input/preprocessed-light-version-of-traffic-signs/' + datasets[1], 'r') as f:\n    # Extracting saved arrays for testing by appropriate keys\n    # Saving them into new variables\n    x_test_rgb_255_mean_std_light = f['x_test']  # HDF5 dataset\n    # Converting them into Numpy arrays\n    x_test_rgb_255_mean_std_light = np.array(x_test_rgb_255_mean_std_light)  # Numpy arrays\n\n# Opening saved Traffic Signs dataset from HDF5 binary file\n# Initiating File object\n# Opening file in reading mode by 'r'\nwith h5py.File('/kaggle/input/preprocessed-light-version-of-traffic-signs/' + datasets[2], 'r') as f:\n    # Extracting saved arrays for testing by appropriate keys\n    # Saving them into new variables\n    x_test_gray_255_mean_light = f['x_test']  # HDF5 dataset\n    # Converting them into Numpy arrays\n    x_test_gray_255_mean_light = np.array(x_test_gray_255_mean_light)  # Numpy arrays\n\n\n# Opening saved Traffic Signs dataset from HDF5 binary file\n# Initiating File object\n# Opening file in reading mode by 'r'\nwith h5py.File('/kaggle/input/preprocessed-light-version-of-traffic-signs/' + datasets[3], 'r') as f:\n    # Extracting saved arrays for testing by appropriate keys\n    # Saving them into new variables\n    x_test_gray_255_mean_std_light = f['x_test']  # HDF5 dataset\n    # Converting them into Numpy arrays\n    x_test_gray_255_mean_std_light = np.array(x_test_gray_255_mean_std_light)  # Numpy arrays\n\n\n# Check points\n# Showing shapes of loaded Numpy arrays\nprint('RGB Mean                :', x_test_rgb_255_mean_light.shape)\nprint('RGB Standard Deviation  :', x_test_rgb_255_mean_std_light.shape)\nprint('GRAY Mean               :', x_test_gray_255_mean_light.shape)\nprint('GRAY Standard Deviation :', x_test_gray_255_mean_std_light.shape)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T16:23:33.216661Z","iopub.execute_input":"2021-06-14T16:23:33.216996Z","iopub.status.idle":"2021-06-14T16:23:39.827859Z","shell.execute_reply.started":"2021-06-14T16:23:33.216963Z","shell.execute_reply":"2021-06-14T16:23:39.826722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Magic function that renders the figure in a jupyter notebook\n# instead of displaying a figure object\n%matplotlib inline\n\n# Setting default size of the plot\nplt.rcParams['figure.figsize'] = (2.5, 2.5)\n\n\n# Check point\n# Showing RGB image\nplt.imshow(x_test_rgb_255_mean_light[0])\nplt.show()\n\n\n# Check point\n# Showing GRAY image\nplt.imshow(x_test_gray_255_mean_light[0], cmap=plt.get_cmap('gray'))\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T16:25:31.820275Z","iopub.execute_input":"2021-06-14T16:25:31.820591Z","iopub.status.idle":"2021-06-14T16:25:32.028142Z","shell.execute_reply.started":"2021-06-14T16:25:31.82056Z","shell.execute_reply":"2021-06-14T16:25:32.027479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Extending dimension from (height, width, channels) to (1, height, width, channels)\nimage_ts_rgb_255_mean = x_test_rgb_255_mean_light[0][np.newaxis, :, :, :]\nimage_ts_rgb_255_mean_std = x_test_rgb_255_mean_std_light[0][np.newaxis, :, :, :]\n\nimage_ts_gray_255_mean = x_test_gray_255_mean_light[0][np.newaxis, :, :, :]\nimage_ts_gray_255_mean_std = x_test_gray_255_mean_std_light[0][np.newaxis, :, :, :]\n\n# Check points\n# Showing shapes of extended Numpy arrays\nprint('RGB /255.0 => mean         :', image_ts_rgb_255_mean.shape)\nprint('RGB /255.0 => mean => std  :', image_ts_rgb_255_mean_std.shape)\nprint()\nprint('GRAY /255.0 => mean        :', image_ts_gray_255_mean.shape)\nprint('GRAY /255.0 => mean => std :', image_ts_gray_255_mean_std.shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T16:30:03.108821Z","iopub.execute_input":"2021-06-14T16:30:03.109192Z","iopub.status.idle":"2021-06-14T16:30:03.117126Z","shell.execute_reply.started":"2021-06-14T16:30:03.109157Z","shell.execute_reply":"2021-06-14T16:30:03.116084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Defining function to plot bar chart with scores values\ndef bar_chart(scores, bar_title, show_xticks=True, labels=None):\n    # Arranging X axis\n    x_positions = np.arange(scores.size)\n\n    # Creating bar chart\n    barlist = plt.bar(x_positions, scores, align='center', alpha=0.6)\n\n    # Highlighting the highest bar\n    barlist[np.argmax(scores)].set_color('red')\n\n    # Giving labels to bars along X axis\n    if show_xticks:\n        plt.xticks(x_positions, labels, rotation=20, fontsize=15)\n\n    # Giving name to axes\n    plt.xlabel('Class', fontsize=20)\n    plt.ylabel('Value', fontsize=20)\n\n    # Giving name to bar chart\n    plt.title('Classification: ' + bar_title, fontsize=20)\n\n    # Showing bar chart\n    plt.show()\n\n\n# Check point\nprint('Function to plot Bar Chart is successfully defined')\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T16:30:15.01139Z","iopub.execute_input":"2021-06-14T16:30:15.011712Z","iopub.status.idle":"2021-06-14T16:30:15.019087Z","shell.execute_reply.started":"2021-06-14T16:30:15.01168Z","shell.execute_reply":"2021-06-14T16:30:15.017945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preparing labels for Traffic Signs dataset\n# Getting Pandas dataFrame with labels\n# (!) On Windows, it might need to change\n# this: + '/' +\n# to this: + '\\' +\n# or to this: + '\\\\' +\nlabels_ts = pd.read_csv('/kaggle/input/traffic-signs-preprocessed' + '/' + 'label_names.csv', sep=',')\n\n\n# Check point\n# Showing first 5 elements of the dataFrame\nprint(labels_ts.head())\nprint()\n\n\n# Showing class's name of the 1st element\nprint(labels_ts.loc[0, 'SignName'])\nprint()\n\n\n# Converting into Numpy array\nlabels_ts = np.array(labels_ts.loc[:, 'SignName']).flatten()\n\n\n# Check points\n# Showing size of Numpy array\n# Showing all elements of Numpy array\nprint('Total number of labels:', labels_ts.size)\nprint()\nprint(labels_ts)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T16:30:17.14562Z","iopub.execute_input":"2021-06-14T16:30:17.145957Z","iopub.status.idle":"2021-06-14T16:30:17.161951Z","shell.execute_reply.started":"2021-06-14T16:30:17.145925Z","shell.execute_reply":"2021-06-14T16:30:17.160955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Magic function that renders the figure in a jupyter notebook\n# instead of displaying a figure object\n%matplotlib inline\n\n# Setting default size of the plot\nplt.rcParams['figure.figsize'] = (12, 7)\n\n\n\n# Testing RGB model trained on dataset: dataset_ts_rgb_255_mean.hdf5\n# Input image is preprocessed in the same way\n# Measuring classification time\nstart = timer()\nscores = model_rgb[0].predict(image_ts_rgb_255_mean)\nend = timer()\n\n# Scores are given as 43 numbers of predictions for each class\n# Getting only one class with maximum value\nprediction = np.argmax(scores)\n\n# Check points\n# Showing scores shape and values\n# Printing class index, label and time\nprint()\nprint('Scores shape        :', scores.shape)\nprint('Scores values       :', scores[0, 10:15])\nprint('Scores sum          :', scores[0].sum())\nprint('Score of prediction : {0:.5f}'.format(scores[0][prediction]))\nprint('Class index         :', prediction)\nprint('Label               :', labels_ts[prediction])\nprint('Time                : {0:.5f}'.format(end - start))\n\n# Plotting bar chart with scores values\nbar_chart(scores[0],\n          bar_title='1st RGB model, ts_rgb_255_mean',\n          show_xticks=False)\n\n\n\n# Testing RGB model trained on dataset: dataset_ts_rgb_255_mean_std.hdf5\n# Input image is preprocessed in the same way\n# Measuring classification time\nstart = timer()\nscores = model_rgb[1].predict(image_ts_rgb_255_mean_std)\nend = timer()\n\n# Scores are given as 43 numbers of predictions for each class\n# Getting only one class with maximum value\nprediction = np.argmax(scores)\n\n# Check points\n# Showing scores shape and values\n# Printing class index, label and time\nprint()\nprint('Scores shape        :', scores.shape)\nprint('Scores values       :', scores[0, 10:15])\nprint('Scores sum          :', scores[0].sum())\nprint('Score of prediction : {0:.5f}'.format(scores[0][prediction]))\nprint('Class index         :', prediction)\nprint('Label               :', labels_ts[prediction])\nprint('Time                : {0:.5f}'.format(end - start))\n\n# Plotting bar chart with scores values\nbar_chart(scores[0],\n          bar_title='1st RGB model, ts_rgb_255_mean_std',\n          show_xticks=False)\n\n\n\n# Testing GRAY model trained on dataset: dataset_ts_gray_255_mean.hdf5\n# Input image is preprocessed in the same way\n# Measuring classification time\nstart = timer()\nscores = model_gray[0].predict(image_ts_gray_255_mean)\nend = timer()\n\n# Scores are given as 43 numbers of predictions for each class\n# Getting only one class with maximum value\nprediction = np.argmax(scores)\n\n# Check points\n# Showing scores shape and values\n# Printing class index, label and time\nprint()\nprint('Scores shape        :', scores.shape)\nprint('Scores values       :', scores[0, 10:15])\nprint('Scores sum          :', scores[0].sum())\nprint('Score of prediction : {0:.5f}'.format(scores[0][prediction]))\nprint('Class index         :', prediction)\nprint('Label               :', labels_ts[prediction])\nprint('Time                : {0:.5f}'.format(end - start))\n\n# Plotting bar chart with scores values\nbar_chart(scores[0],\n          bar_title='1st GRAY model, ts_gray_255_mean',\n          show_xticks=False)\n\n\n\n# Testing GRAY model trained on dataset: dataset_ts_gray_255_mean_std.hdf5\n# Input image is preprocessed in the same way\n# Measuring classification time\nstart = timer()\nscores = model_gray[1].predict(image_ts_gray_255_mean_std)\nend = timer()\n\n# Scores are given as 43 numbers of predictions for each class\n# Getting only one class with maximum value\nprediction = np.argmax(scores)\n\n# Check points\n# Showing scores shape and values\n# Printing class index, label and time\nprint()\nprint('Scores shape        :', scores.shape)\nprint('Scores values       :', scores[0, 10:15])\nprint('Scores sum          :', scores[0].sum())\nprint('Score of prediction : {0:.5f}'.format(scores[0][prediction]))\nprint('Class index         :', prediction)\nprint('Label               :', labels_ts[prediction])\nprint('Time                : {0:.5f}'.format(end - start))\n\n# Plotting bar chart with scores values\nbar_chart(scores[0],\n          bar_title='1st GRAY model, ts_gray_255_mean_std',\n          show_xticks=False)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T16:30:19.62336Z","iopub.execute_input":"2021-06-14T16:30:19.623679Z","iopub.status.idle":"2021-06-14T16:30:20.616998Z","shell.execute_reply.started":"2021-06-14T16:30:19.623651Z","shell.execute_reply":"2021-06-14T16:30:20.616307Z"},"trusted":true},"execution_count":null,"outputs":[]}]}