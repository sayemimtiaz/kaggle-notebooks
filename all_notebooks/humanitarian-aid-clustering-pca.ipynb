{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-23T06:35:18.807528Z","iopub.execute_input":"2021-07-23T06:35:18.807915Z","iopub.status.idle":"2021-07-23T06:35:18.821198Z","shell.execute_reply.started":"2021-07-23T06:35:18.807881Z","shell.execute_reply":"2021-07-23T06:35:18.820327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Importing the libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Import the StandardScaler()\nfrom sklearn.preprocessing import StandardScaler\n\n#Improting the PCA module\nfrom sklearn.decomposition import PCA\nfrom sklearn.decomposition import IncrementalPCA\n\nfrom sklearn.neighbors import NearestNeighbors\nfrom random import sample\nfrom numpy.random import uniform\nfrom math import isnan\n\n# To perform KMeans clustering \nfrom sklearn.cluster import KMeans\nfrom scipy.cluster.hierarchy import linkage\nfrom scipy.cluster.hierarchy import dendrogram\nfrom scipy.cluster.hierarchy import cut_tree\n\n#Let's check the silhouette score first to identify the ideal number of clusters\nfrom sklearn.metrics import silhouette_score","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:35:18.822608Z","iopub.execute_input":"2021-07-23T06:35:18.823052Z","iopub.status.idle":"2021-07-23T06:35:18.835921Z","shell.execute_reply.started":"2021-07-23T06:35:18.823008Z","shell.execute_reply":"2021-07-23T06:35:18.834806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Read and Understand the data","metadata":{}},{"cell_type":"code","source":"# reading datasets\ncountry_data = pd.read_csv('../input/pca-kmeans-hierarchical-clustering/Country-data.csv')\ncountry_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:35:18.838159Z","iopub.execute_input":"2021-07-23T06:35:18.838649Z","iopub.status.idle":"2021-07-23T06:35:18.886179Z","shell.execute_reply.started":"2021-07-23T06:35:18.838607Z","shell.execute_reply":"2021-07-23T06:35:18.885387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"country_data.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:35:18.887943Z","iopub.execute_input":"2021-07-23T06:35:18.888385Z","iopub.status.idle":"2021-07-23T06:35:18.894996Z","shell.execute_reply.started":"2021-07-23T06:35:18.88832Z","shell.execute_reply":"2021-07-23T06:35:18.894257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"country_data.columns","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:35:18.896213Z","iopub.execute_input":"2021-07-23T06:35:18.896664Z","iopub.status.idle":"2021-07-23T06:35:18.910044Z","shell.execute_reply.started":"2021-07-23T06:35:18.896626Z","shell.execute_reply":"2021-07-23T06:35:18.909046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"country_data.info()","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:35:18.911322Z","iopub.execute_input":"2021-07-23T06:35:18.911608Z","iopub.status.idle":"2021-07-23T06:35:18.937274Z","shell.execute_reply.started":"2021-07-23T06:35:18.911581Z","shell.execute_reply":"2021-07-23T06:35:18.936074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Cleaning\n- Identifying Missing data\n- Identifying wrong data type\n- Removing duplicates","metadata":{}},{"cell_type":"code","source":"#Identifying Missing data\ntotal_null = country_data.isnull().sum().sort_values(ascending = False)\npercent = ((country_data.isnull().sum()/country_data.isnull().count())*100).sort_values(ascending = False)\nprint(\"Total records (country_data Data) = \", country_data.shape[0])\n\nmissing_data = pd.concat([total_null,percent.round(2)],axis=1,keys=['Total Missing','In Percent'])\nmissing_data.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:35:18.938897Z","iopub.execute_input":"2021-07-23T06:35:18.939596Z","iopub.status.idle":"2021-07-23T06:35:18.976291Z","shell.execute_reply.started":"2021-07-23T06:35:18.939555Z","shell.execute_reply":"2021-07-23T06:35:18.97537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inference\n- None of the columns have null values hence no drop required.","metadata":{}},{"cell_type":"code","source":"country_data.dtypes","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:35:18.97874Z","iopub.execute_input":"2021-07-23T06:35:18.97932Z","iopub.status.idle":"2021-07-23T06:35:18.987665Z","shell.execute_reply.started":"2021-07-23T06:35:18.979277Z","shell.execute_reply":"2021-07-23T06:35:18.986652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inference\nNone of the columns have inconsistent datatype, hence no conversion is required.","metadata":{}},{"cell_type":"markdown","source":"## Data Preparation\n* Derived Metrices\n* Exploratary Data analysis\n    * Visualize the data (Undertanding top or bottom 10 countries) on various factors\n* Correlation between different variables. How they co-related\n* Scaling the Data\n* PCA (Principal Component Analysis) on the data to remove redundancies.","metadata":{"execution":{"iopub.status.busy":"2021-07-23T05:48:50.103761Z","iopub.execute_input":"2021-07-23T05:48:50.104577Z","iopub.status.idle":"2021-07-23T05:48:50.111727Z","shell.execute_reply.started":"2021-07-23T05:48:50.104507Z","shell.execute_reply":"2021-07-23T05:48:50.110199Z"}}},{"cell_type":"code","source":"country_data.describe()","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:35:18.989057Z","iopub.execute_input":"2021-07-23T06:35:18.989495Z","iopub.status.idle":"2021-07-23T06:35:19.037607Z","shell.execute_reply.started":"2021-07-23T06:35:18.989466Z","shell.execute_reply":"2021-07-23T06:35:19.036597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Derived Metrices\n* The variables export, health & imports are percentage values and hence wouldn't give the clear picture of spending by the country. For example two countries (Afghanistan & Albina) have similar import % but not necessarily have the same gdpp which doesn't give accurate of idea of country being develop or under develop. Hence we need to derive the actual value of this variable.","metadata":{}},{"cell_type":"code","source":"# Converting exports,imports & health spending percentages to absolute values.\ncountry_data['exports'] = country_data['exports'] * country_data['gdpp']/100\ncountry_data['imports'] = country_data['imports'] * country_data['gdpp']/100\ncountry_data['health'] = country_data['health'] * country_data['gdpp']/100\n\ncountry_data.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:35:19.038785Z","iopub.execute_input":"2021-07-23T06:35:19.039058Z","iopub.status.idle":"2021-07-23T06:35:19.063053Z","shell.execute_reply.started":"2021-07-23T06:35:19.039033Z","shell.execute_reply":"2021-07-23T06:35:19.062369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exploratory Data Analytics\n* With the new derived variables let's visualise the top/bottom countries on different socio-economic and health factors","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(14,6))\nfig.set_facecolor(\"lightgrey\")\n\nplt.subplot(2,3,1)\n# Health :Total health spending as %age of Total GDP.\nbottom10_health = country_data[['country','health']].sort_values('health', ascending = True).head(10)\nsns.barplot(x='country',y='health',data=bottom10_health,palette=\"BuGn_r\")\nplt.title(\"Top 10 Countries with lowest spent on Health overall gdp\",fontsize=9)\nplt.xticks(rotation = 90,fontsize=10,family = \"Comic Sans MS\")\n\n# Exports: Exports of goods and services. Given as %age of the Total GDP\nplt.subplot(2,3,2)\nbottom10_export = country_data[['country','exports']].sort_values('exports', ascending = True).head(10)\nsns.barplot(x='country',y='exports',data=bottom10_export,palette=\"Blues\")\nplt.title(\"Top 10 Countries with lowest exports\",fontsize=9)\nplt.xticks(rotation = 90,fontsize=10,family = \"Comic Sans MS\")\n\n# Imports: Imports of goods and services. Given as %age of the Total GDP\nplt.subplot(2,3,3)\nbottom10_import = country_data[['country','imports']].sort_values('imports', ascending = True).head(10)\nsns.barplot(x='country',y='imports',data=bottom10_import,palette=\"Reds\")\nplt.title(\"Top 10 Countries with lowest imports\",fontsize=9)\nplt.xticks(rotation = 90,fontsize=10,family = \"Comic Sans MS\")\n\n\nfig = plt.figure(figsize=(14,6))\nfig.set_facecolor(\"lightgrey\")\n\nplt.subplot(2,3,1)\n# Child Death Rate : Death of children under 5 years of age per 1000 live births\ntop10_deathrate = country_data[['country','child_mort']].sort_values('child_mort',ascending=False).head(10)\nsns.barplot(x='country',y='child_mort',data=top10_deathrate,palette=\"BuGn_r\")\nplt.title(\"Top 10 Countries with highest child Death Rate\",fontsize=9)\nplt.xticks(rotation = 90,fontsize=10,family=\"Comic Sans MS\")\n\nplt.subplot(2,3,2)\n# Fertility Rate: The number of children that would be born to each woman if the current age-fertility rates remain the same\ntop10_tot_fer = country_data[['country','total_fer']].sort_values('total_fer', ascending = False).head(10)\nsns.barplot(x='country',y='total_fer',data=top10_tot_fer,palette=\"Blues\")\nplt.title(\"Top 10 Countries with highest Fertility Rate\",fontsize=9)\nplt.xticks(rotation = 90,fontsize=10,family = \"Comic Sans MS\")\n\n# Life Expectancy: The average number of years a new born child would live if the current mortality patterns are to remain same\nplt.subplot(2,3,3)\ntop10_lowest_life_expec = country_data[['country','life_expec']].sort_values('life_expec', ascending = True).head(10)\nsns.barplot(x='country',y='life_expec',data=top10_lowest_life_expec,palette=\"Reds\")\nplt.title(\"Top 10 Countries with lowest life Expectancy\",fontsize=9)\nplt.xticks(rotation = 90,fontsize=10,family = \"Comic Sans MS\")\n\nfig = plt.figure(figsize=(14,6))\nfig.set_facecolor(\"lightgrey\")\n\nplt.subplot(2,3,1)\n# The GDP per capita : Calculated as the Total GDP divided by the total population.\nbottom10_gdpp = country_data[['country','gdpp']].sort_values('gdpp',ascending=True).head(10)\nsns.barplot(x='country',y='gdpp',data=bottom10_gdpp,palette=\"BuGn_r\")\nplt.title(\"Bottom 10 Countries with overall gdpp\",fontsize=9)\nplt.xticks(rotation = 90,fontsize=10,family=\"Comic Sans MS\")\n\nplt.subplot(2,3,2)\n# Per capita Income : Net income per person\nbottom10_net_income = country_data[['country','income']].sort_values('income', ascending = True).head(10)\nsns.barplot(x='country',y='income',data=bottom10_net_income,palette=\"Blues\")\nplt.title(\"Bottom 10 Countries with net income per person\",fontsize=9)\nplt.xticks(rotation = 90,fontsize=10,family = \"Comic Sans MS\")\n\n# Inflation: The measurement of the annual growth rate of the Total GDP\nplt.subplot(2,3,3)\nbottom10_inflation = country_data[['country','inflation']].sort_values('inflation', ascending = False).head(10)\nsns.barplot(x='country',y='inflation',data=bottom10_inflation,palette=\"Reds\")\nplt.title(\"Bottom 10 Countries with inflation rate\",fontsize=9)\nplt.xticks(rotation = 90,fontsize=10,family = \"Comic Sans MS\")\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:35:19.064108Z","iopub.execute_input":"2021-07-23T06:35:19.064513Z","iopub.status.idle":"2021-07-23T06:35:20.788542Z","shell.execute_reply.started":"2021-07-23T06:35:19.064485Z","shell.execute_reply":"2021-07-23T06:35:20.787867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Correlation coefficients\n- We have a lot of variables, creating and visualising proper clusters will be a difficulty.Let's see if we can apply PCA to do dimensional reduction first let's plot the correlation matrix and check if the data is indeed highly correlated so that the usage of PCA in this scenario is justified","metadata":{}},{"cell_type":"code","source":"# Correlation coefficients to see which variables are highly correlated\n\nplt.figure(figsize = (16, 10))\nsns.heatmap(country_data.corr(),annot=True,cmap=\"Greens\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:36:00.442362Z","iopub.execute_input":"2021-07-23T06:36:00.44275Z","iopub.status.idle":"2021-07-23T06:36:01.155782Z","shell.execute_reply.started":"2021-07-23T06:36:00.442718Z","shell.execute_reply":"2021-07-23T06:36:01.154757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inference\n- child_mortality and life_expentency are highly correlated with correlation of -0.89\n- child_mortality and total_fertility are highly correlated with correlation of 0.85\n- imports and exports are highly correlated with correlation of 0.99\n- life_expentency and total_fertility are highly correlated with correlation of -0.76","metadata":{}},{"cell_type":"code","source":"# Pairplot of all numeric columns\nsns.pairplot(country_data)","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:37:59.72898Z","iopub.execute_input":"2021-07-23T06:37:59.729626Z","iopub.status.idle":"2021-07-23T06:38:15.882108Z","shell.execute_reply.started":"2021-07-23T06:37:59.729575Z","shell.execute_reply":"2021-07-23T06:38:15.881476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inferences\n- A lot of highly correlated variables exist, hence the usage of PCA is justified. Now let's proceed to doing it on the dataset","metadata":{}},{"cell_type":"code","source":"country_data_tmp = country_data.copy()\ncountry_data_tmp.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:38:31.511134Z","iopub.execute_input":"2021-07-23T06:38:31.511548Z","iopub.status.idle":"2021-07-23T06:38:31.530921Z","shell.execute_reply.started":"2021-07-23T06:38:31.511518Z","shell.execute_reply":"2021-07-23T06:38:31.529885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Rescaling the features\n\n- Most software packages use SVD to compute the principal components and assume that the data is scaled and centred, so it is important to do standardisation/normalisation.","metadata":{}},{"cell_type":"code","source":"# Create a scaling object\nscaler = StandardScaler()\n\n# Create a list of the variables that you need to scale\ncol_list = ['child_mort', 'exports', 'health', 'imports', 'income', 'inflation', 'life_expec', 'total_fer', 'gdpp']\n\n# Scale these variables using 'fit_transform'\ncountry_data_tmp[col_list] = scaler.fit_transform(country_data_tmp[col_list])\n\ncountry_data_tmp.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:38:58.81819Z","iopub.execute_input":"2021-07-23T06:38:58.818748Z","iopub.status.idle":"2021-07-23T06:38:58.84443Z","shell.execute_reply.started":"2021-07-23T06:38:58.818699Z","shell.execute_reply":"2021-07-23T06:38:58.843431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Separate out the Feature variable and response variable","metadata":{}},{"cell_type":"code","source":"# Putting feature variable to x\nx = country_data_tmp.drop(['country'],axis=1)\n\n# Putting response variable to country\ncountry = country_data_tmp['country']","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:39:26.084847Z","iopub.execute_input":"2021-07-23T06:39:26.085204Z","iopub.status.idle":"2021-07-23T06:39:26.090547Z","shell.execute_reply.started":"2021-07-23T06:39:26.085174Z","shell.execute_reply":"2021-07-23T06:39:26.089824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x.shape\nx.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:39:32.039361Z","iopub.execute_input":"2021-07-23T06:39:32.039769Z","iopub.status.idle":"2021-07-23T06:39:32.056854Z","shell.execute_reply.started":"2021-07-23T06:39:32.039735Z","shell.execute_reply":"2021-07-23T06:39:32.055669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"country.shape\ncountry.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:39:40.698395Z","iopub.execute_input":"2021-07-23T06:39:40.698968Z","iopub.status.idle":"2021-07-23T06:39:40.705851Z","shell.execute_reply.started":"2021-07-23T06:39:40.698918Z","shell.execute_reply":"2021-07-23T06:39:40.704839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Applying PCA on data","metadata":{}},{"cell_type":"markdown","source":"### PCA\n- Principal component analysis (PCA) is one of the most commonly used dimensionality reduction techniques to improve model performance","metadata":{}},{"cell_type":"code","source":"pca = PCA(svd_solver='randomized',random_state=42)\npca.fit(x)","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:40:18.498954Z","iopub.execute_input":"2021-07-23T06:40:18.49931Z","iopub.status.idle":"2021-07-23T06:40:18.701448Z","shell.execute_reply.started":"2021-07-23T06:40:18.499279Z","shell.execute_reply":"2021-07-23T06:40:18.700655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pca.components_","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:40:25.167Z","iopub.execute_input":"2021-07-23T06:40:25.167437Z","iopub.status.idle":"2021-07-23T06:40:25.176328Z","shell.execute_reply.started":"2021-07-23T06:40:25.167398Z","shell.execute_reply":"2021-07-23T06:40:25.17501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Variance Ratio\npca.explained_variance_ratio_","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:40:33.558062Z","iopub.execute_input":"2021-07-23T06:40:33.558666Z","iopub.status.idle":"2021-07-23T06:40:33.566182Z","shell.execute_reply.started":"2021-07-23T06:40:33.558618Z","shell.execute_reply":"2021-07-23T06:40:33.565324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Variance Ratio bar plot for each PCA components.\nfig = plt.figure(figsize = (8,6))\nplt.bar(range(1,len(pca.explained_variance_ratio_)+1), pca.explained_variance_ratio_)\nplt.xlabel(\"PCA Components\",fontsize=10,family = \"Comic Sans MS\")\nplt.ylabel(\"Variance Ratio\",fontsize=10,family = \"Comic Sans MS\")\nplt.title(\"Variance Ratio for each PCA component\",fontsize=14,family = \"Comic Sans MS\")","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:40:41.245748Z","iopub.execute_input":"2021-07-23T06:40:41.246112Z","iopub.status.idle":"2021-07-23T06:40:41.436952Z","shell.execute_reply.started":"2021-07-23T06:40:41.246081Z","shell.execute_reply":"2021-07-23T06:40:41.435977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inference\n* With first component variance explained is almost 60%.\n* For second component variance explained is almost 20%.\n* For third component variance explained is around 10%","metadata":{}},{"cell_type":"markdown","source":"## Making Scree plot","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:41:23.18255Z","iopub.execute_input":"2021-07-23T06:41:23.183032Z","iopub.status.idle":"2021-07-23T06:41:23.185999Z","shell.execute_reply.started":"2021-07-23T06:41:23.183002Z","shell.execute_reply":"2021-07-23T06:41:23.185313Z"}}},{"cell_type":"code","source":"fig = plt.figure(figsize = (8,6))\nfig.set_facecolor(\"lightgrey\")\nvar_cumu = np.cumsum(pca.explained_variance_ratio_)\nplt.plot(range(1,len(var_cumu)+1), var_cumu)\nplt.vlines(x=3,ymax=1,ymin=0.0,color=\"g\",linestyles=\"--\")\nplt.hlines(y=0.88,xmax=8,xmin=0.0,color=\"b\",linestyles=\"--\")\n\nplt.xlabel('Number of PCA Components',fontsize=12,family = \"Comic Sans MS\")\nplt.ylabel('Cumulative Explained Variance',fontsize=12,family = \"Comic Sans MS\")\nplt.title(\"Sree plot to Visualize Cumulative Variance\",fontsize=14,family = \"Comic Sans MS\")","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:41:36.540945Z","iopub.execute_input":"2021-07-23T06:41:36.541285Z","iopub.status.idle":"2021-07-23T06:41:36.720436Z","shell.execute_reply.started":"2021-07-23T06:41:36.541257Z","shell.execute_reply":"2021-07-23T06:41:36.719374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inference\n\n- From the above it is clear that first 3 principal components can well explain around 90% varaiance. Hence we will use them clustering process.","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:41:49.50274Z","iopub.execute_input":"2021-07-23T06:41:49.503092Z","iopub.status.idle":"2021-07-23T06:41:49.509054Z","shell.execute_reply.started":"2021-07-23T06:41:49.503062Z","shell.execute_reply":"2021-07-23T06:41:49.507928Z"}}},{"cell_type":"code","source":"# Checking which attributes are well explained by the pca components\ncolnames = list(x.columns)\npca_attr = pd.DataFrame({'Attribute':colnames,'PC1':pca.components_[0],'PC2':pca.components_[1],'PC3':pca.components_[2]})\npca_attr","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:42:02.109008Z","iopub.execute_input":"2021-07-23T06:42:02.109424Z","iopub.status.idle":"2021-07-23T06:42:02.124172Z","shell.execute_reply.started":"2021-07-23T06:42:02.109389Z","shell.execute_reply":"2021-07-23T06:42:02.123177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting the above dataframe for better visualization with PC1 and PC2\nsns.set(style='darkgrid')\nsns.pairplot(data=pca_attr, x_vars=[\"PC1\"], y_vars=[\"PC2\"], hue = \"Attribute\" ,height=8)\nplt.xlabel(\"Principal Component 1\",fontsize=12,family = \"Comic Sans MS\")\nplt.ylabel(\"Principal Component 2\",fontsize=12,family = \"Comic Sans MS\")\n\nfor i,txt in enumerate(pca_attr.Attribute):\n    plt.annotate(txt, (pca_attr.PC1[i],pca_attr.PC2[i]))","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:42:11.056302Z","iopub.execute_input":"2021-07-23T06:42:11.056782Z","iopub.status.idle":"2021-07-23T06:42:12.150925Z","shell.execute_reply.started":"2021-07-23T06:42:11.056748Z","shell.execute_reply":"2021-07-23T06:42:12.149948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inference\n- life expectency, income, gdpp and health are very well explained by PC1.\n- imports and exports are well explained by both the components PC1 and PC2.\n- child mortality,inflation and total fertility are well explained by PC2.\n","metadata":{}},{"cell_type":"code","source":"# Building the dataframe using Incremental PCA for better efficiency.\ninc_pca = IncrementalPCA(n_components=3)","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:42:30.656925Z","iopub.execute_input":"2021-07-23T06:42:30.657359Z","iopub.status.idle":"2021-07-23T06:42:30.661369Z","shell.execute_reply.started":"2021-07-23T06:42:30.657307Z","shell.execute_reply":"2021-07-23T06:42:30.660446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pca_final = inc_pca.fit_transform(x)\npca_final.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:42:36.274599Z","iopub.execute_input":"2021-07-23T06:42:36.274972Z","iopub.status.idle":"2021-07-23T06:42:36.296524Z","shell.execute_reply.started":"2021-07-23T06:42:36.274936Z","shell.execute_reply":"2021-07-23T06:42:36.295449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pca_final = pd.DataFrame(pca_final, columns=[\"PC1\", \"PC2\",\"PC3\"])\ndf = pd.concat([country, pca_final], axis=1)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:42:43.011637Z","iopub.execute_input":"2021-07-23T06:42:43.011982Z","iopub.status.idle":"2021-07-23T06:42:43.026362Z","shell.execute_reply.started":"2021-07-23T06:42:43.011952Z","shell.execute_reply":"2021-07-23T06:42:43.025643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting Heatmap to check is there still dependency in the dataset.\n\nplt.figure(figsize = (8,6))        \nax = sns.heatmap(df.corr(),annot = True,cmap=\"Blues\")","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:42:49.933214Z","iopub.execute_input":"2021-07-23T06:42:49.933771Z","iopub.status.idle":"2021-07-23T06:42:50.231993Z","shell.execute_reply.started":"2021-07-23T06:42:49.933722Z","shell.execute_reply":"2021-07-23T06:42:50.231179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inference:\n\nFrom above heatmap  - Correlation among the attributes is almost 0, we can proceed with this dataframe","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:42:58.868911Z","iopub.execute_input":"2021-07-23T06:42:58.869495Z","iopub.status.idle":"2021-07-23T06:42:58.874811Z","shell.execute_reply.started":"2021-07-23T06:42:58.869447Z","shell.execute_reply":"2021-07-23T06:42:58.873405Z"}}},{"cell_type":"code","source":"sns.set(style='white')\nfig.set_facecolor(\"lightgrey\")\n\nplt.figure(figsize=(20, 8))\nplt.subplot(2,3,1)\nsns.scatterplot(data=df, x='PC1', y='PC2')\nplt.subplot(2,3,2)\nsns.scatterplot(data=df, x='PC1', y='PC3')\nplt.subplot(2,3,3)\nsns.scatterplot(data=df, x='PC3', y='PC2')","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:43:12.18748Z","iopub.execute_input":"2021-07-23T06:43:12.187839Z","iopub.status.idle":"2021-07-23T06:43:12.844123Z","shell.execute_reply.started":"2021-07-23T06:43:12.187808Z","shell.execute_reply":"2021-07-23T06:43:12.843172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Outlier Analysis and Treatment","metadata":{}},{"cell_type":"code","source":"#Function to plot a list of categorical variables together\ndef box_plot(colname):\n    plt.figure(figsize=(15, 4))\n    for var in colname:\n        plt.subplot(1,3,colname.index(var)+1)\n        sns.boxplot(x = var, data = df)\n        plt.xlabel(var, fontsize=12,family = \"Comic Sans MS\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:43:32.470603Z","iopub.execute_input":"2021-07-23T06:43:32.471023Z","iopub.status.idle":"2021-07-23T06:43:32.477701Z","shell.execute_reply.started":"2021-07-23T06:43:32.47098Z","shell.execute_reply":"2021-07-23T06:43:32.476446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"colnames = ['PC1', 'PC2', 'PC3']\nbox_plot(colnames[:])","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:43:38.952167Z","iopub.execute_input":"2021-07-23T06:43:38.952572Z","iopub.status.idle":"2021-07-23T06:43:39.365414Z","shell.execute_reply.started":"2021-07-23T06:43:38.952536Z","shell.execute_reply":"2021-07-23T06:43:39.364634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Statstical Outlier treatment for PC1\n\nQ1 = df.PC1.quantile(0.05)\nQ3 = df.PC1.quantile(0.95)\nIQR = Q3 - Q1\ndf = df[(df.PC1 >= Q1) & (df.PC1 <= Q3)]\n\n# Statstical Outlier treatment for PC2\n\nQ1 = df.PC2.quantile(0.05)\nQ3 = df.PC2.quantile(0.95)\nIQR = Q3 - Q1\ndf = df[(df.PC2 >= Q1) & (df.PC2 <= Q3)]\n\n# Statstical Outlier treatment for PC3\nQ1 = df.PC3.quantile(0.05)\nQ3 = df.PC3.quantile(0.95)\nIQR = Q3 - Q1\ndf = df[(df.PC3 >= Q1) & (df.PC3 <= Q3)]","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:43:49.491958Z","iopub.execute_input":"2021-07-23T06:43:49.49254Z","iopub.status.idle":"2021-07-23T06:43:49.508551Z","shell.execute_reply.started":"2021-07-23T06:43:49.49249Z","shell.execute_reply":"2021-07-23T06:43:49.507538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"colnames = ['PC1', 'PC2', 'PC3']\nbox_plot(colnames[:])","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:43:55.946371Z","iopub.execute_input":"2021-07-23T06:43:55.946747Z","iopub.status.idle":"2021-07-23T06:43:56.353324Z","shell.execute_reply.started":"2021-07-23T06:43:55.946714Z","shell.execute_reply":"2021-07-23T06:43:56.352156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reindexing the df after outlier removal\ndf = df.reset_index(drop=True)\ndf_final = df.drop(['country'],axis=1)\ndf.head()\ndf_final.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:44:03.887719Z","iopub.execute_input":"2021-07-23T06:44:03.888099Z","iopub.status.idle":"2021-07-23T06:44:03.897191Z","shell.execute_reply.started":"2021-07-23T06:44:03.888049Z","shell.execute_reply":"2021-07-23T06:44:03.896106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Hopkins Statistics Test\n\n- A way of measuring the cluster tendency of a data set.\n- A value close to 1 tends to indicate the data is highly clustered, random data will tend to result in values around 0.5, and uniformly distributed data will tend to result in values close to 0","metadata":{}},{"cell_type":"code","source":"def hopkins(X):\n    d = X.shape[1]\n    n = len(X)\n    m = int(0.1 * n) \n    nbrs = NearestNeighbors(n_neighbors=1).fit(X.values)\n \n    rand_X = sample(range(0, n, 1), m)\n \n    ujd = []\n    wjd = []\n    for j in range(0, m):\n        u_dist, _ = nbrs.kneighbors(uniform(np.amin(X,axis=0),np.amax(X,axis=0),d).reshape(1, -1), 2, return_distance=True)\n        ujd.append(u_dist[0][1])\n        w_dist, _ = nbrs.kneighbors(X.iloc[rand_X[j]].values.reshape(1, -1), 2, return_distance=True)\n        wjd.append(w_dist[0][1])\n \n    HS = sum(ujd) / (sum(ujd) + sum(wjd))\n    if isnan(HS):\n        print(ujd, wjd)\n        HS = 0\n \n    return HS","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:44:28.016206Z","iopub.execute_input":"2021-07-23T06:44:28.016604Z","iopub.status.idle":"2021-07-23T06:44:28.026264Z","shell.execute_reply.started":"2021-07-23T06:44:28.01657Z","shell.execute_reply":"2021-07-23T06:44:28.025244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Let's check the Hopkins measure\nhopkins(df_final)","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:44:35.137679Z","iopub.execute_input":"2021-07-23T06:44:35.138018Z","iopub.status.idle":"2021-07-23T06:44:35.173344Z","shell.execute_reply.started":"2021-07-23T06:44:35.13799Z","shell.execute_reply":"2021-07-23T06:44:35.172692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n## Inference\n\n- 0.75 is a good Hopkins score for Clustering.","metadata":{}},{"cell_type":"markdown","source":"## Building Model\n\n- K Means Clustering\n\nK-means clustering is one of the simplest and popular unsupervised machine learning algorithms.\n\nThe algorithm works as follows:\n\nFirst we initialize k points, called means, randomly. We categorize each item to its closest mean and we update the meanâ€™s coordinates, which are the averages of the items categorized in that mean so far. We repeat the process for a given number of iterations and at the end, we have our clusters.","metadata":{}},{"cell_type":"markdown","source":"### Finding the Optimal Number of Clusters\n\nElbow Curve to get the right number of Clusters\n\nA fundamental step for any unsupervised algorithm is to determine the optimal number of clusters into which the data may be clustered. The Elbow Method is one of the most popular methods to determine this optimal value of k.","metadata":{}},{"cell_type":"code","source":"# Elbow curve method to find the ideal number of clusters.\nssd = []\nfor num_clusters in list(range(1,10)):\n    kmeans = KMeans(n_clusters = num_clusters, max_iter=50,random_state= 100)\n    kmeans.fit(df_final)\n    ssd.append(kmeans.inertia_)\n\nplt.plot(ssd)","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:45:29.539688Z","iopub.execute_input":"2021-07-23T06:45:29.540371Z","iopub.status.idle":"2021-07-23T06:45:30.250282Z","shell.execute_reply.started":"2021-07-23T06:45:29.540306Z","shell.execute_reply":"2021-07-23T06:45:30.249246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inference\n* Looking at the above elbow curve it looks good to proceed with either 4 or 5 clusters.","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:45:38.203166Z","iopub.execute_input":"2021-07-23T06:45:38.203549Z","iopub.status.idle":"2021-07-23T06:45:38.209983Z","shell.execute_reply.started":"2021-07-23T06:45:38.203515Z","shell.execute_reply":"2021-07-23T06:45:38.2087Z"}}},{"cell_type":"code","source":"# Silhouette score analysis to find the ideal number of clusters for K-means clustering\nrange_n_clusters = [2, 3, 4, 5, 6, 7, 8]\n\nfor num_clusters in range_n_clusters:    \n    # intialise kmeans\n    kmeans = KMeans(n_clusters=num_clusters, max_iter=50,random_state= 100)\n    kmeans.fit(df_final)\n    cluster_labels = kmeans.labels_\n    \n    # silhouette score\n    silhouette_avg = silhouette_score(df_final, cluster_labels)\n    print(\"For n_clusters={0}, the silhouette score is {1}\".format(num_clusters, silhouette_avg))","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:46:04.275203Z","iopub.execute_input":"2021-07-23T06:46:04.275645Z","iopub.status.idle":"2021-07-23T06:46:04.722765Z","shell.execute_reply.started":"2021-07-23T06:46:04.275612Z","shell.execute_reply":"2021-07-23T06:46:04.721709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#K-means with k=4 clusters\n\ncluster5 = KMeans(n_clusters=5, max_iter=50, random_state= 100)\ncluster5.fit(df_final)\n\n# Cluster labels\ncluster5.labels_","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:46:11.176822Z","iopub.execute_input":"2021-07-23T06:46:11.177165Z","iopub.status.idle":"2021-07-23T06:46:11.232524Z","shell.execute_reply.started":"2021-07-23T06:46:11.177137Z","shell.execute_reply":"2021-07-23T06:46:11.231451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assign the label\ndf['Cluster_Id'] = cluster5.labels_\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:46:21.313257Z","iopub.execute_input":"2021-07-23T06:46:21.313743Z","iopub.status.idle":"2021-07-23T06:46:21.329109Z","shell.execute_reply.started":"2021-07-23T06:46:21.313699Z","shell.execute_reply":"2021-07-23T06:46:21.328131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Number of countries in each cluster\ndf['Cluster_Id'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:46:29.604688Z","iopub.execute_input":"2021-07-23T06:46:29.605083Z","iopub.status.idle":"2021-07-23T06:46:29.614176Z","shell.execute_reply.started":"2021-07-23T06:46:29.605039Z","shell.execute_reply":"2021-07-23T06:46:29.613091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n## Inference:\n\n- It seems there are good number of countries in each clusters.","metadata":{}},{"cell_type":"code","source":"# Scatter plot on Principal components to visualize the spread of the data\n\nfig, axes = plt.subplots(1,3, figsize=(15,7))\n\nsns.scatterplot(x='PC1',y='PC2',hue='Cluster_Id',legend='full',palette=\"Set1\",data=df,ax=axes[0])\nsns.scatterplot(x='PC1',y='PC3',hue='Cluster_Id',legend='full',palette=\"Set1\",data=df,ax=axes[1])\nsns.scatterplot(x='PC2',y='PC3',hue='Cluster_Id',legend='full',palette=\"Set1\",data=df,ax=axes[2])","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:46:51.144699Z","iopub.execute_input":"2021-07-23T06:46:51.145075Z","iopub.status.idle":"2021-07-23T06:46:52.595617Z","shell.execute_reply.started":"2021-07-23T06:46:51.145042Z","shell.execute_reply":"2021-07-23T06:46:52.594452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inference:\n* We have visualized the data on the principal components and saw some good clusters were formed but some were not so good hence let's now visualize the data on the original attributes.","metadata":{}},{"cell_type":"code","source":"# Merging the df with PCA with original df\n\ndf_merge = pd.merge(country_data,df,on='country')\ndf_merge_col = df_merge[['country','child_mort','exports','imports','health','income','inflation','life_expec','total_fer','gdpp','Cluster_Id']]\n\n# Creating df with mean values\ncluster_child = pd.DataFrame(df_merge_col.groupby([\"Cluster_Id\"]).child_mort.mean())\ncluster_export = pd.DataFrame(df_merge_col.groupby([\"Cluster_Id\"]).exports.mean())\ncluster_import = pd.DataFrame(df_merge_col.groupby([\"Cluster_Id\"]).imports.mean())\ncluster_health = pd.DataFrame(df_merge_col.groupby([\"Cluster_Id\"]).health.mean())\ncluster_income = pd.DataFrame(df_merge_col.groupby([\"Cluster_Id\"]).income.mean())\ncluster_inflation = pd.DataFrame(df_merge_col.groupby([\"Cluster_Id\"]).inflation.mean())         \ncluster_lifeexpec = pd.DataFrame(df_merge_col.groupby([\"Cluster_Id\"]).life_expec.mean())\ncluster_totalfer = pd.DataFrame(df_merge_col.groupby([\"Cluster_Id\"]).total_fer.mean())\ncluster_gdpp = pd.DataFrame(df_merge_col.groupby([\"Cluster_Id\"]).gdpp.mean())\n\ndf_concat = pd.concat([pd.Series([0,1,2,3,4]),cluster_child,cluster_export,cluster_import,cluster_health,cluster_income\n                       ,cluster_inflation,cluster_lifeexpec,cluster_totalfer,cluster_gdpp], axis=1)\ndf_concat.columns = [\"Cluster_Id\", \"Child_Mortality\", \"Exports\", \"Imports\",\"Health_Spending\",\"Income\",\"Inflation\",\"Life_Expectancy\",\"Total_Fertility\",\"GDPpcapita\"]\ndf_concat.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:47:19.683822Z","iopub.execute_input":"2021-07-23T06:47:19.684214Z","iopub.status.idle":"2021-07-23T06:47:19.738285Z","shell.execute_reply.started":"2021-07-23T06:47:19.684179Z","shell.execute_reply":"2021-07-23T06:47:19.737466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inferences\n- From the business understanding we have learnt that Child_Mortality, Income, Gdpp are some important factors which decides the development of any country. We have also cross checked with Principal components and found that these variables have good score in PCA. Hence, we will proceed with analyzing these 3 components to build some meaningful clusters.","metadata":{}},{"cell_type":"code","source":"df_merge_col.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:47:46.938669Z","iopub.execute_input":"2021-07-23T06:47:46.939025Z","iopub.status.idle":"2021-07-23T06:47:46.957363Z","shell.execute_reply.started":"2021-07-23T06:47:46.938993Z","shell.execute_reply":"2021-07-23T06:47:46.956418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"figsize=(15,12)\nsns.scatterplot(x='income',y='child_mort',hue='Cluster_Id',data = df_merge_col,legend='full',palette=\"Set1\")","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:47:54.808621Z","iopub.execute_input":"2021-07-23T06:47:54.809011Z","iopub.status.idle":"2021-07-23T06:47:55.231786Z","shell.execute_reply.started":"2021-07-23T06:47:54.80898Z","shell.execute_reply":"2021-07-23T06:47:55.23073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"figsize=(15,12)\nsns.scatterplot(x='child_mort',y='gdpp',hue='Cluster_Id',data=df_merge_col,legend='full',palette=\"Set1\")","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:48:02.640613Z","iopub.execute_input":"2021-07-23T06:48:02.640981Z","iopub.status.idle":"2021-07-23T06:48:03.049247Z","shell.execute_reply.started":"2021-07-23T06:48:02.640951Z","shell.execute_reply":"2021-07-23T06:48:03.048228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"figsize=(15,12)\nsns.scatterplot(x='gdpp',y='income',hue='Cluster_Id',data=df_merge_col,legend='full',palette=\"Set1\")","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:48:13.410268Z","iopub.execute_input":"2021-07-23T06:48:13.410692Z","iopub.status.idle":"2021-07-23T06:48:13.825507Z","shell.execute_reply.started":"2021-07-23T06:48:13.410639Z","shell.execute_reply":"2021-07-23T06:48:13.824431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Box plot on Original attributes to visualize the spread of the data\nfig, axes = plt.subplots(2,2, figsize=(15,12))\n\nsns.boxplot(x = 'Cluster_Id', y = 'child_mort', data = df_merge_col,ax=axes[0][0])\nsns.boxplot(x = 'Cluster_Id', y = 'income', data = df_merge_col,ax=axes[0][1])\nsns.boxplot(x = 'Cluster_Id', y = 'inflation', data=df_merge_col,ax=axes[1][0])\nsns.boxplot(x = 'Cluster_Id', y = 'gdpp', data=df_merge_col,ax=axes[1][1])\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:48:20.696889Z","iopub.execute_input":"2021-07-23T06:48:20.697316Z","iopub.status.idle":"2021-07-23T06:48:21.603732Z","shell.execute_reply.started":"2021-07-23T06:48:20.697283Z","shell.execute_reply":"2021-07-23T06:48:21.602717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inference:\n\n- Child Mortality is highest for Cluster 0 and Cluster 3.These clusters need some aid.\n- Income and Gdpp are measures of development. Higher the per capita income and gdpp better is the country's development. Income per capita and gdpp seems lowest for countries in clusters 0 and 3. Hence, these countries need some help.\n\n","metadata":{}},{"cell_type":"code","source":"# Box plot to visualise the mean value of few original attributes.\n\nfig, axes = plt.subplots(2,2, figsize=(15,12))\n\nsns.boxplot(x = 'Cluster_Id', y = 'Child_Mortality', data = df_concat,ax=axes[0][0])\nsns.boxplot(x = 'Cluster_Id', y = 'Income', data = df_concat,ax=axes[0][1])\nsns.boxplot(x = 'Cluster_Id', y = 'Inflation', data=df_concat,ax=axes[1][0])\nsns.boxplot(x = 'Cluster_Id', y = 'GDPpcapita', data=df_concat,ax=axes[1][1])","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:48:44.500949Z","iopub.execute_input":"2021-07-23T06:48:44.501303Z","iopub.status.idle":"2021-07-23T06:48:45.404303Z","shell.execute_reply.started":"2021-07-23T06:48:44.501271Z","shell.execute_reply":"2021-07-23T06:48:45.403556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inferences\n - Mean values also suggests same trends as above.","metadata":{}},{"cell_type":"code","source":"# List of countries in Cluster 0\ndf_merge_col[df_merge_col['Cluster_Id']==0]","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:49:10.981532Z","iopub.execute_input":"2021-07-23T06:49:10.982045Z","iopub.status.idle":"2021-07-23T06:49:11.023818Z","shell.execute_reply.started":"2021-07-23T06:49:10.981996Z","shell.execute_reply":"2021-07-23T06:49:11.023109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# List of countries in Cluster 3\ndf_merge_col[df_merge_col['Cluster_Id']==3]","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:49:20.921777Z","iopub.execute_input":"2021-07-23T06:49:20.922306Z","iopub.status.idle":"2021-07-23T06:49:20.95229Z","shell.execute_reply.started":"2021-07-23T06:49:20.92226Z","shell.execute_reply":"2021-07-23T06:49:20.951161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Hierarchical Clustering","metadata":{}},{"cell_type":"markdown","source":"Hierarchical clustering involves creating clusters that have a predetermined ordering from top to bottom. For example, all files and folders on the hard disk are organized in a hierarchy. There are two types of hierarchical clustering,\n\n- Divisive\n- Agglomerative.","metadata":{}},{"cell_type":"code","source":"df_final.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:49:56.155452Z","iopub.execute_input":"2021-07-23T06:49:56.155823Z","iopub.status.idle":"2021-07-23T06:49:56.167359Z","shell.execute_reply.started":"2021-07-23T06:49:56.155792Z","shell.execute_reply":"2021-07-23T06:49:56.166354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Single linkage\nsingle_link = linkage(df_final, method='single',metric='euclidean')\ndendrogram(single_link)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:50:02.452276Z","iopub.execute_input":"2021-07-23T06:50:02.452668Z","iopub.status.idle":"2021-07-23T06:50:04.929599Z","shell.execute_reply.started":"2021-07-23T06:50:02.452637Z","shell.execute_reply":"2021-07-23T06:50:04.928442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inference \n- No Good results. Let's try Complete linkage Method.","metadata":{}},{"cell_type":"code","source":"# Complete Linkage\n\ncomplete_link = linkage(df_final, method='complete',metric='euclidean')\ndendrogram(complete_link)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:50:19.984063Z","iopub.execute_input":"2021-07-23T06:50:19.9845Z","iopub.status.idle":"2021-07-23T06:50:22.462597Z","shell.execute_reply.started":"2021-07-23T06:50:19.984457Z","shell.execute_reply":"2021-07-23T06:50:22.461499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_hc = df.copy()\ndf_hc = df_hc.drop('Cluster_Id',axis=1)\ndf_hc.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:50:28.547794Z","iopub.execute_input":"2021-07-23T06:50:28.548155Z","iopub.status.idle":"2021-07-23T06:50:28.562771Z","shell.execute_reply.started":"2021-07-23T06:50:28.548125Z","shell.execute_reply":"2021-07-23T06:50:28.561747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let cut the tree at height of approx 3 to get 4 clusters &\n# see if it get any better cluster formation.\n\nclusterCut = pd.Series(cut_tree(complete_link, n_clusters = 4).reshape(-1,))\ndf_hc_cut = pd.concat([df_hc, clusterCut], axis=1)\ndf_hc_cut.columns = ['country', 'PC1', 'PC2','PC3','Cluster_Id']\ndf_hc_cut.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:50:35.376055Z","iopub.execute_input":"2021-07-23T06:50:35.376685Z","iopub.status.idle":"2021-07-23T06:50:35.402595Z","shell.execute_reply.started":"2021-07-23T06:50:35.376619Z","shell.execute_reply":"2021-07-23T06:50:35.401677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Scatter plot on Principal components to visualize the spread of the data\n\nfig, axes = plt.subplots(1,2, figsize=(15,8))\n\nsns.scatterplot(x='PC1',y='PC2',hue='Cluster_Id',legend='full',palette=\"Set1\",data=df_hc_cut,ax=axes[0])\nsns.scatterplot(x='PC1',y='PC3',hue='Cluster_Id',legend='full',palette=\"Set1\",data=df_hc_cut,ax=axes[1])","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:50:42.342992Z","iopub.execute_input":"2021-07-23T06:50:42.343407Z","iopub.status.idle":"2021-07-23T06:50:43.109718Z","shell.execute_reply.started":"2021-07-23T06:50:42.343369Z","shell.execute_reply":"2021-07-23T06:50:43.108579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Merging the df with PCA with original df\n\ndf_merge_hc=pd.merge(country_data,df_hc_cut,on='country')\ndf_merge_hc_col=df_merge_hc[['country','child_mort','exports','imports','health','income','inflation','life_expec','total_fer','gdpp','Cluster_Id']]\ndf_merge_hc_col.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:50:51.189848Z","iopub.execute_input":"2021-07-23T06:50:51.190199Z","iopub.status.idle":"2021-07-23T06:50:51.217117Z","shell.execute_reply.started":"2021-07-23T06:50:51.190168Z","shell.execute_reply":"2021-07-23T06:50:51.21563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_merge_hc_col['Cluster_Id'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:50:59.447787Z","iopub.execute_input":"2021-07-23T06:50:59.448193Z","iopub.status.idle":"2021-07-23T06:50:59.456525Z","shell.execute_reply.started":"2021-07-23T06:50:59.448151Z","shell.execute_reply":"2021-07-23T06:50:59.455555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inference\n- The no. of Countries in Cluster =0 using Hierarihical clustering is same as the no. of countries for Cluster = 0 in K-Means clustering.","metadata":{}},{"cell_type":"code","source":"figsize=(15,12)\nsns.scatterplot(x='income',y='child_mort',hue='Cluster_Id',data = df_merge_hc_col,legend='full',palette=\"Set1\")","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:51:15.917692Z","iopub.execute_input":"2021-07-23T06:51:15.918095Z","iopub.status.idle":"2021-07-23T06:51:16.317136Z","shell.execute_reply.started":"2021-07-23T06:51:15.918058Z","shell.execute_reply":"2021-07-23T06:51:16.315968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"figsize=(15,12)\nsns.scatterplot(x='child_mort',y='gdpp',hue='Cluster_Id',data=df_merge_hc_col,legend='full',palette=\"Set1\")","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:51:25.368569Z","iopub.execute_input":"2021-07-23T06:51:25.368971Z","iopub.status.idle":"2021-07-23T06:51:25.757653Z","shell.execute_reply.started":"2021-07-23T06:51:25.368936Z","shell.execute_reply":"2021-07-23T06:51:25.756461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"figsize=(15,12)\nsns.scatterplot(x='gdpp',y='income',hue='Cluster_Id',data=df_merge_hc_col,legend='full',palette=\"Set1\")","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:51:33.179605Z","iopub.execute_input":"2021-07-23T06:51:33.179988Z","iopub.status.idle":"2021-07-23T06:51:33.566924Z","shell.execute_reply.started":"2021-07-23T06:51:33.179945Z","shell.execute_reply":"2021-07-23T06:51:33.565969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Box plot on Original attributes to visualize the spread of the data\nfig, axes = plt.subplots(2,2, figsize=(15,12))\n\nsns.boxplot(x = 'Cluster_Id', y = 'child_mort', data = df_merge_hc_col,ax=axes[0][0])\nsns.boxplot(x = 'Cluster_Id', y = 'income', data = df_merge_hc_col,ax=axes[0][1])\nsns.boxplot(x = 'Cluster_Id', y = 'inflation', data=df_merge_hc_col,ax=axes[1][0])\nsns.boxplot(x = 'Cluster_Id', y = 'gdpp', data=df_merge_hc_col,ax=axes[1][1])\n","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:51:40.150165Z","iopub.execute_input":"2021-07-23T06:51:40.150618Z","iopub.status.idle":"2021-07-23T06:51:40.9688Z","shell.execute_reply.started":"2021-07-23T06:51:40.150579Z","shell.execute_reply":"2021-07-23T06:51:40.967636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inference\n- We have analyzed both K-means and Hierarchial clustering and found clusters formed are identical. The clusters formed in both the cases are not that great but gives some idea about countries which need of aid.","metadata":{}},{"cell_type":"code","source":"# List of countries in Cluster 0\ndf_merge_hc_col[df_merge_hc_col['Cluster_Id']==0]","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:52:03.17496Z","iopub.execute_input":"2021-07-23T06:52:03.175614Z","iopub.status.idle":"2021-07-23T06:52:03.207585Z","shell.execute_reply.started":"2021-07-23T06:52:03.175553Z","shell.execute_reply":"2021-07-23T06:52:03.206591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inference \n - The country list for cluster =0 using Hierarchical and K-Means are same. ","metadata":{}},{"cell_type":"code","source":"country_list = df_merge_hc_col[df_merge_hc_col['Cluster_Id']==0]\ncountry_list.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:52:20.506651Z","iopub.execute_input":"2021-07-23T06:52:20.507039Z","iopub.status.idle":"2021-07-23T06:52:20.527033Z","shell.execute_reply.started":"2021-07-23T06:52:20.506984Z","shell.execute_reply":"2021-07-23T06:52:20.5261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"country_list['country']","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:52:27.440895Z","iopub.execute_input":"2021-07-23T06:52:27.441433Z","iopub.status.idle":"2021-07-23T06:52:27.450926Z","shell.execute_reply.started":"2021-07-23T06:52:27.441397Z","shell.execute_reply":"2021-07-23T06:52:27.449957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"country_childmort = pd.DataFrame(country_list.groupby(['country'])['child_mort'].mean().sort_values(ascending = False))\ncountry_childmort.plot.bar(figsize=(15,10),facecolor='g')\nplt.title('Country vs Child Mortality',fontsize=16,family = \"Comic Sans MS\")\nplt.xlabel(\"Country\",fontweight = 'bold')\nplt.ylabel(\"Child Mortality\", fontsize = 12, fontweight = 'bold')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:52:34.105366Z","iopub.execute_input":"2021-07-23T06:52:34.105863Z","iopub.status.idle":"2021-07-23T06:52:34.808917Z","shell.execute_reply.started":"2021-07-23T06:52:34.10583Z","shell.execute_reply":"2021-07-23T06:52:34.80792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# BarPlot for Per Capita Income of countries which are in need of aid\n\ncountry_income = pd.DataFrame(country_list.groupby(['country'])['income'].mean().sort_values(ascending = True))\ncountry_income.plot.bar(figsize=(15,10),facecolor='b')\nplt.title('Country vs Per Capita Income',fontsize=16,family = \"Comic Sans MS\")\nplt.xlabel(\"Country\",fontweight = 'bold')\nplt.ylabel(\"Per Capita Income\", fontsize = 12, fontweight = 'bold')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:52:45.596777Z","iopub.execute_input":"2021-07-23T06:52:45.597276Z","iopub.status.idle":"2021-07-23T06:52:46.007826Z","shell.execute_reply.started":"2021-07-23T06:52:45.597244Z","shell.execute_reply":"2021-07-23T06:52:46.006968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# BarPlot for Per Capita Income of countries which are in need of aid\n\ncountry_gdp = pd.DataFrame(country_list.groupby(['country'])['gdpp'].mean().sort_values(ascending = True))\ncountry_gdp.plot.bar(figsize=(15,10),facecolor='r')\nplt.title('Country vs GDP per capita',fontsize=16,family = \"Comic Sans MS\")\nplt.xlabel(\"Country\",fontweight = 'bold')\nplt.ylabel(\"GDP per capita\", fontsize = 12, fontweight = 'bold')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:52:59.158113Z","iopub.execute_input":"2021-07-23T06:52:59.158503Z","iopub.status.idle":"2021-07-23T06:52:59.549244Z","shell.execute_reply.started":"2021-07-23T06:52:59.158468Z","shell.execute_reply":"2021-07-23T06:52:59.548184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Closing Statement\n\n- We have used PCA above to reduce the variables involved and then done the clustering of countries based on those Principal components and then later we identified few factors like child mortality, income etc which plays a vital role in deciding the development status of the country and builded clusters of countries based on that. Based on those clusters we have identified the below list of countries which are in dire need of aid. The list of countries are subject to change as it is based on the few factors like Number of components chosen, Number of Clusters chosen, Clustering method used etc.which we have used to build the model.","metadata":{}},{"cell_type":"code","source":"# Final countries list\ncountry_list.reset_index(drop=True).country","metadata":{"execution":{"iopub.status.busy":"2021-07-23T06:53:22.782218Z","iopub.execute_input":"2021-07-23T06:53:22.782615Z","iopub.status.idle":"2021-07-23T06:53:22.790852Z","shell.execute_reply.started":"2021-07-23T06:53:22.782581Z","shell.execute_reply":"2021-07-23T06:53:22.789952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}