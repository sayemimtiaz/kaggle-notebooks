{"cells":[{"metadata":{},"cell_type":"markdown","source":"## <font color=\"#00bfff\">1.Cookie Cats and Project Goal</font>\n<p><a href=\"https://www.facebook.com/cookiecatsgame\">Cookie Cats</a> is a hugely popular mobile puzzle game developed by <a href=\"http://tactile.dk\">Tactile Entertainment</a>. It's a classic \"connect three\"-style puzzle game where the player must connect tiles of the same color to clear the board and win the level. \n    <p><img src=\"https://i.ytimg.com/vi/LkvnfULq8yQ/maxresdefault.jpg\" style=\"max-width:350px\"></p>\n<p>As players progress through the levels of the game, they will occasionally encounter gates that force them to wait a non-trivial amount of time or make an in-app purchase to progress. In addition to driving in-app purchases, these gates serve the important purpose of giving players an enforced break from playing the game, hopefully resulting in that the player's enjoyment of the game being increased and prolonged.</p>\n<p><img src=\"https://assets.datacamp.com/production/project_184/img/cc_gates.png\" style=\"max-width:350px\"></p>\n<p>But where should the gates be placed? Initially the first gate was placed at level 30, but in this notebook we're going to analyze an AB-test where we moved the first gate in Cookie Cats from level 30 to level 40. In particular, we will look at the impact on player retention. But before we get to that, a key step before undertaking any analysis is understanding the data.</p>\n"},{"metadata":{},"cell_type":"markdown","source":"## <font color=\"#00bfff\">2. Dataset and Variables</font>\nThe data we have is from 90,189 players that installed the game while the AB-test was running. The variables are:\n\n<li><code>userid</code> - a unique number that identifies each player.</li>\n<li><code>version</code> - whether the player was put in the control group (<code>gate_30</code> - a gate at level 30) or the group with the moved gate (<code>gate_40</code> - a gate at level 40).</li>\n<li><code>sum_gamerounds</code> - the number of game rounds played by the player during the first 14 days after install.</li>\n<li><code>retention_1</code> - did the player come back and play <strong>1 day</strong> after installing?</li>\n<li><code>retention_7</code> - did the player come back and play <strong>7 days</strong> after installing?</li>\n\n<p>When a player installed the game, he or she was randomly assigned to either <code>gate_30</code> or <code>gate_40</code>.\n\n So let's load it in and take a look!"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing pandas\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Reading the data set\ndf = pd.read_csv(\"../input/mobile-games-ab-testing-cookie-cats/cookie_cats.csv\")\n\n# Showing the first few rows\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <font color=\"#00bfff\">3. Descriptive Statistics</font>\n\n\n<p><img src=\"https://assets.datacamp.com/production/project_184/img/mr_waffles_smiling.png\" style=\"width:150px; float:right;margin: -15px 20px 1px 15px;\"> </p>\n\nLet's deep dive into dataset and try to observe the differences between A/B group in terms of given variables. \n\nFirst, look at how many players we have."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Number of unique player\ndf[\"userid\"].nunique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As a sanity check, let's see if there are roughly the same number of players in each A/B group."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Counting the number of players in each A/B group.\ndf.groupby(\"version\")[[\"userid\"]].nunique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It looks like there is roughly the same number of players in each group, nice! \n\nThe focus of this analysis will be on how the gate placement affects player retention, but just for fun: Let's plot the distribution of the number of game rounds players played during their first week playing the game."},{"metadata":{"trusted":true},"cell_type":"code","source":"# The distribution of game rounds\n\n# Counting the number of players for each number of gamerounds \nplot_df = df.groupby(\"sum_gamerounds\")[\"userid\"].count()\n\n# Plotting the distribution of players that played 0 to 100 game rounds\nax = plot_df.head(100).plot()\nplt.title(\"The distribution of players\", fontweight=\"bold\", size=14)\nplt.xlabel(\"total gamerounds\", size=12)\nplt.ylabel(\"number of player\", size=12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the plot above we can see that some players install the game but then never play it (0 game rounds). Let's find there are how many of them."},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df[\"sum_gamerounds\"]== 0][\"userid\"].count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p><img src=\"https://assets.datacamp.com/production/project_184/img/belle_cookie.png\" style=\"width:150px; float:right\"> </p>\n\n3994 players never played the game, just installed it. Is it too much? \n\nA common metric in the video gaming industry for how fun and engaging a game is retention: The percentage of players that come back and play the game 1-day and 7-days after they have installed it. The higher retention is, the easier it is to retain players and build a large player base.\n\nAs a first step, let's look at what 1-day and 7-days retentions are overall."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_retention = df[[\"retention_1\",\"retention_7\"]].mean()*100\nprint(f\"1-day retention ratio: {round(df_retention[0],2)}% \\\n      \\n7-days retention ratio: {round(df_retention[1],2)}%\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, a little less than half of the players come back one day after installing the game. 18 percent of the players come back 7 day after installing the game. \n\nNow that we have a benchmark, let's look at how retention rates differs between the two A/B groups."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculating 1-day and 7-days retention for each A/B group\ndf_retention_ab = df.groupby(\"version\").agg({\"userid\":\"count\", \"retention_1\":\"mean\",\"retention_7\":\"mean\", \"sum_gamerounds\":\"sum\"})\ndf_retention_ab","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p><img src=\"https://assets.datacamp.com/production/project_184/img/ziggy_smiling.png\" style=\"width:150px; float:left;margin:20px 10px 5px 5px;\"> </p>\n\n* There was a slight decrease in 1-day retention when the gate was moved to level 40 (44.2%) compared to the control group when it was at level 30 (44.8%). \n\n* Again,a decrease in 7-day retention when the gate was moved to level 40 (18.2%) compared to the control group when it was at level 30 (19.8%). \n\n* It's a small change, but even small changes in retention can have a large impact. But while we are certain of the difference in the data, how certain should we be that a gate at level 40 will be worse in the future?\n\nThere are a couple of ways we can get at the certainty of these retention numbers. Here we will use **bootstrapping.**"},{"metadata":{},"cell_type":"markdown","source":"## <font color=\"#00bfff\"> 4. A/B Testing: Bootstrapping </font>\n\n**Definiton of Method**\n\n<p><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/f/fa/Stratified_sampling.PNG/300px-Stratified_sampling.PNG\" style=\" float: right;margin:5px 20px 5px 1px; max-width:250px\"></p>\n\nWe'll use **bootstrapping** for A/B testing. The basic idea of bootstrapping is that inference about a population from sample data (sample → population) can be modelled by resampling the sample data and performing inference about a sample from resampled data (resampled → sample). As the population is unknown, the true error in a sample statistic against its population value is unknown. In bootstrap-resamples, the 'population' is in fact the sample, and this is known; hence the quality of inference of the 'true' sample from resampled data (resampled → sample) is measurable. [This information retrieved from Wikipedia](https://en.wikipedia.org/wiki/Bootstrapping_(statistics)\n\n**Testing Steps:**\n1. Creating 500 samples of dataset **(bootstraping)**\n2. Calculating 1-day & 7-days retentions for A/B groups\n3. Plotting the bootstrap distributions\n4. Calculating retention rate difference between the two A/B groups\n5. Calculating the probability that 1-day & 7-days retentions are greater when the gate is at level 30\n6. Evaluating results and making recommendation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating an list with bootstrapped means for each A/B group\nboot_1d = []\nboot_7d = []\nfor i in range(500):\n    boot_mean_1 = df.sample(frac=1, replace=True).groupby('version')['retention_1'].mean()\n    boot_mean_7 = df.sample(frac=1, replace=True).groupby('version')['retention_7'].mean()\n    boot_1d.append(boot_mean_1)\n    boot_7d.append(boot_mean_7)\n    \n# Transforming the list to a DataFrame\nboot_1d = pd.DataFrame(boot_1d)\nboot_7d = pd.DataFrame(boot_7d)\n\n# Kernel Density Estimate plot of the bootstrap distributions\nfig, (ax1,ax2) = plt.subplots(1, 2, sharey=True, figsize=(13,5))\n\nboot_1d.plot.kde(ax=ax1)\nax1.set_xlabel(\"retantion rate\",size=12)\nax1.set_ylabel(\"number of sample\",size=12)\nax1.set_title(\"1 day retention rate distribution\", fontweight=\"bold\",size=14)\n\nboot_7d.plot.kde(ax=ax2)\nax2.set_xlabel(\"retantion rate\",size=12)\nax2.set_title(\"7 days retention rate distribution\", fontweight=\"bold\",size=14)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p>These two distributions above represent the bootstrap uncertainty over what the underlying 1-day & 7-days retention could be for the two A/B groups. Just eyeballing this plot, we can see that there seems to be some evidence of a difference, albeit small. Let's zoom in on the differences.</p>\n<p>(<em>Note that in this notebook we have limited the number of bootstrap replication to 500 to keep the calculations quick. In \"production\" we would likely increase this to a much larger number, say, 10 000.</em>)</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Adding a column with the % difference between the two A/B groups\nboot_1d['diff'] = ((boot_1d['gate_30'] - boot_1d['gate_40']) / boot_1d['gate_40'] * 100)\nboot_7d['diff'] = ((boot_7d['gate_30'] - boot_7d['gate_40']) / boot_7d['gate_40'] * 100)\n\n# Ploting the bootstrap % difference\nfig, (ax1) = plt.subplots(1, 1,figsize=(6,5))\n\nboot_1d['diff'].plot.kde(ax=ax1, c=\"#ff99ff\", label = \"1 day retention\")\nboot_7d['diff'].plot.kde(ax=ax1, c= \"#00bfff\", label = \"7 days retention\")\nax1.set_xlabel(\"% difference\",size=12)\nax1.set_ylabel(\"% density\",size=12)\nax1.set_title(\"Difference in retention \\n between the two A/B groups\", fontweight=\"bold\", size=14)\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p><img src=\"https://assets.datacamp.com/production/project_184/img/ziggy_smiling.png\" style=\"width:100px; float:left; margin:10px 10px 5px 5px;\"> </p>\n<p>From these chart, we can see that the most likely % difference is around 1% - 2% for 1-day retention. For 7-days retention the most likely % difference is around 2% - 5%. Moreover, the most of the distribution is above 0%, in favor of a gate at level 30. But what is the probability that the difference is above 0%? Let's calculate that as well.</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculating the probability that 1-day retention is greater when the gate is at level 30\nprob_1 = (boot_1d['diff']>0).sum()/len(boot_1d['diff'])\n\n# Calculating the probability that 7-days retention is greater when the gate is at level 30\nprob_7 = (boot_7d['diff']>0).sum()/len(boot_7d['diff'])\n\n# Pretty printing the probability\nprint(f\"The probability that 1-day retention is greater when the gate is at level 30: {round(prob_1,2)*100}% \\\n      \\nThe probability that 7-days retention is greater when the gate is at level 30: {(prob_7)*100}% \")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <font color=\"00bfff\">5. The conclusion</font>\n\n<p><img src=\"https://assets.datacamp.com/production/project_184/img/cookie_yellow.png\" style=\"width:150px; float:right\"> </p>\n\nThe bootstrap result tells us that there is strong evidence **99.8% probability** that 7-day retention is higher when the gate is at level 30 than when it is at level 40.\n\nThe conclusion is: If we want to keep retention high — both 1-day and 7-day retention — we should <strong>not</strong> move the gate from level 30 to level 40. There are, of course, other metrics we could look at, like the number of game rounds played or how much in-game purchases are made by the two AB-groups. But retention <em>is</em> one of the most important metrics.\n\nYou can reach the case study from [DataCamp](https://www.datacamp.com/projects/184) ❤️"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}