{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Exploratory Analysis"},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"# Import all the libraries\nimport pandas as pd\nimport numpy as np\nfrom numpy import set_printoptions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import dataset\ntimes = pd.read_csv(\"../input/world-university-rankings/timesData.csv\")\ntimes.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('dtypes of times dataset:')\ntimes.dtypes\n\n# mix between float, string and integer.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('number of NaNs per column:')\ntimes.isna().sum()\n\n# 4 columns have missing values. Female male ratio has the most with 233. ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Pre-processing"},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop university name and country because they're strings\n# drop female male ratio because 233 rows are missing\n# drop total score because it's too similar to world rank\ntimes.drop(columns=['university_name', 'country', 'female_male_ratio', 'total_score'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"times.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# converting string values to numeric\n# world rank values are numeric from 1 to 100 afterwards they're string like 100-150\n# convert world rank to numeric and rest is converted to NaN\n# we're only interested in top 100, top 50, top 10 so we only care about the first 100 for the binarizer\n\ntimes['world_rank'] = pd.to_numeric(times['world_rank'], errors='coerce')\n\n# fill with 101 so it's below the binarize threshold of 100\ntimes['world_rank'].fillna(101, inplace=True)\n\n# binarizer converts value to 1 if it's above the threshold\n# so we need to invert world rank i.e. make negative\ntimes['world_rank'] = (times['world_rank'] * -1)\n\n# prepare object or string columns for numeric conversion\n# Few columns had \"-\" for missing value, replace with 0\n# num students has \",\", replace with nothing \"\"\n# international students has \"%\", replace with nothing \"\"\nstr_cols = times.select_dtypes(['object']).columns\ntimes[str_cols] = times[str_cols].replace('-', 0)\ntimes['num_students'] = times['num_students'].str.replace(',', '')\ntimes['international_students'] = times['international_students'].str.replace('%', '')\n\n# convert object or string columns to numeric\ntimes[str_cols] = times[str_cols].apply(pd.to_numeric, errors='coerce', axis=1)\n\n# convert international students percentage to decimal\ntimes['international_students'] = times['international_students'] / 100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# determine number of NaNs\ntimes.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop remaining NaNs \ntimes.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check dataframe, dtypes and NaNs\nprint(times.dtypes)\nprint(times.isna().sum())\ntimes.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert times dataframe to array\ntimes_array = times.values\nX = times_array[:,1:]\ny_ = times_array[:,[0]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"set_printoptions(precision=3, suppress=True)\nX[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop world_rank, not needed\ntimes.drop(columns='world_rank', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create binary variable\nfrom sklearn.preprocessing import Binarizer\n\ntop_n = -50 + (-1)\n\nbinarizer=Binarizer(threshold=top_n).fit(y_)\ny_binary=binarizer.transform(y_)\n\ny_binary[:5]\n\ny_reshaped = np.ravel(y_binary)\ny_reshaped","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# reshape using ravel() so that it works with LogisticRegression\ny_reshaped = np.ravel(y_binary)\ny_reshaped","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Univariate selection using Chi-squared"},{"metadata":{"trusted":true},"cell_type":"code","source":"times.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Univariate selection using Chi-squared \nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2 \n\n# feature selection (we select the 3 best)\ntest = SelectKBest(score_func=chi2, k=3)\nfit = test.fit(X,y_reshaped)\nprint(\"Scores\")\n\nprint(fit.scores_)\n\nprint(\"The 3 attributes with the highest scores are: teaching, research and num_students \")\nprint()\nprint('teaching: university score for teaching')\nprint('reserach: university score for research (volume, income and reputation)')\nprint('num_students: number of students at the university')\n\nfeatures=fit.transform(X)\nfeatures[0:5,:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Recursive Feature Elimination using LogisticRegression"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Recursive Feature Elimiantion\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LogisticRegression\n\n#Logistic regression\nmodel = LogisticRegression(solver='liblinear')\n\nrfe = RFE(model, 3) #  we want to find the 3 top features\nfit = rfe.fit(X, y_reshaped)\n\nprint(f'Number of features {fit.n_features_:d}')\nprint(f'Selected features {fit.support_}')\nprint(f'Ranking of features {fit.ranking_}')\nprint()\nprint(\"Top features seem to be teaching, research and citations\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Ranking feature importance using ExtraTreeClassifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import ExtraTreesClassifier\n\nmodel = ExtraTreesClassifier(n_estimators=100)\nmodel.fit(X,y_reshaped)\n\nprint(model.feature_importances_)\nprint()\nprint(\"Top features seem to be citations, research and teaching\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Univariate, Recursive Feature Elimination and ExtraTreeClassifier for Top 10, Top 50 and Top 100"},{"metadata":{"trusted":true},"cell_type":"code","source":"top_unis = [10, 50, 100]\nunivariate = []\nrfe_ranking = []\netc_features = []\n\nfor n in top_unis:\n\n    top_n = (n + 1) * (-1)\n\n    binarizer=Binarizer(threshold=top_n).fit(y_)\n    y_binary=binarizer.transform(y_)\n\n    y_reshaped = np.ravel(y_binary)\n\n    print('*************************************************************')\n    print('Univariate Selection using Chi-Squared: top', n)\n\n    #set_printoptions(precision=3, suppress)\n\n    # feature selection (we select the 3 best)\n    test = SelectKBest(score_func=chi2, k=3)\n    fit = test.fit(X,y_reshaped)\n    print(\"Scores\")\n\n    univariate.append(fit.scores_)\n\n    features=fit.transform(X)\n    print(features[0:5,:])\n\n    print('*************************************************************')\n    print('Recursive Feature Elimination: top', n)\n    print()\n\n    model = LogisticRegression(solver='liblinear')\n\n    rfe = RFE(model, 3) #  we want to find the 3 top features\n    fit = rfe.fit(X, y_reshaped)\n\n    print(f'Number of features {fit.n_features_:d}')\n    print(f'Selected features {fit.support_}')\n    print(f'Ranking of features {fit.ranking_}')\n\n    rfe_ranking.append(fit.ranking_)\n    print()\n\n    print('*************************************************************')\n    print('ExtraTreeClassifier: top', n)\n\n    model = ExtraTreesClassifier(n_estimators=100, random_state=7)\n    model.fit(X,y_reshaped)\n\n    print(model.feature_importances_)\n    etc_features.append(model.feature_importances_)\n\nprint(times.head())\n    \nprint('top unis:', top_unis)\nprint(univariate)\nprint(rfe_ranking)\nprint(etc_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"times.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Answer for Univariate Selection. \n# First row is top 10, then top 50, then top 100\nunivariate","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Answer for Recursive Feature Selection.\n# First row is top 10, then top 50, then top 100\nrfe_ranking","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Answer for ExtraTreeClassifier\n# First row is top 10, then top 50, then top 100\netc_features","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model evaluation "},{"metadata":{},"cell_type":"markdown","source":"##Â train-test-split and k-fold-10 validation for top 10, top 50 and top 100"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_unis = [10, 50, 100]\ntrain_test_split_accuracy = []\nk_fold_accuracy = []\n\nfor n in top_unis:\n\n    top_n = (n + 1) * (-1)\n\n    binarizer=Binarizer(threshold=top_n).fit(y_)\n    y_binary=binarizer.transform(y_)\n\n    y_reshaped = np.ravel(y_binary)\n    \n    print('*************************************************************')\n    print('train-test-split: top', n)\n    \n    # we need to make it reproducible, so we use a seed for the pseudo-random\n    test_size = 0.3\n    seed = 7\n\n    # the actual split\n    X_train, X_test, y_train, y_test = train_test_split(X, y_reshaped, test_size=test_size, random_state=seed)\n\n    # Let's do the log regresssion\n    model = LogisticRegression(solver='liblinear')\n    model.fit(X_train,y_train)\n\n    # Now let's find the accurary with the test split\n    result = model.score(X_test, y_test)\n    train_test_split_accuracy.append(result)\n\n    print(f'Accuracy {result*100:5.3f}')\n    print()\n    \n    print('*************************************************************')\n    print('k-fold-10 validation: top', n)\n    print()\n    \n    # KFold\n    splits = 10\n    kfold = KFold(n_splits=splits, random_state=seed)\n\n    #Logistic regression\n    model = LogisticRegression(solver='liblinear')\n\n    # Obtain the performance measure - accuracy\n    results = cross_val_score(model, X, y_reshaped, cv=kfold)\n    k_fold_accuracy.append(results.mean())\n    \n    print(f'Logistic regression, k-fold {splits:d} - Accuracy {results.mean()*100:5.3f}% ({results.std()*100:5.3f}%)')\n    print()\n    \n    \ntrain_test_accuracy = [ '%.3f' % elem for elem in train_test_split_accuracy]\nkfold_accuracy = [ '%.3f' % elem for elem in k_fold_accuracy]\n\nprint('Top unis: ', top_unis)\nprint(train_test_accuracy)\nprint(kfold_accuracy)\nprint('Accuracy decreases as the number of universities to be classified increases')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Metrics evaluation using StratifiedKFold"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_unis = [10, 50, 100]\nscoring = ['accuracy', 'neg_log_loss', 'roc_auc']\nk_fold_accuracy = []\n\nfor n in top_unis:\n\n    top_n = (n + 1) * (-1)\n\n    binarizer=Binarizer(threshold=top_n).fit(y_)\n    y_binary=binarizer.transform(y_)\n\n    y_reshaped = np.ravel(y_binary)\n\n    print('*************************************************************')\n    \n    for score in scoring:\n        \n        print('*************************************************************')\n        print(score, ', top', n)\n\n        # StratifiedKFold because top10 with kfold causes an error (bug)\n        splits = 10\n        skfold = StratifiedKFold(n_splits=splits, random_state=7)\n\n\n        #Logistic regression\n        model = LogisticRegression(solver='liblinear')\n\n        # Obtain the performance measure - accuracy\n        results = cross_val_score(model, X, y_reshaped, scoring=score, cv=skfold)\n\n        print(score, f': {results.mean():.3f}')\n        print()\n\n    print('*************************************************************')\n    print('Confusion Matrix, top', n)\n    \n    test_size=0.3\n    seed=7\n\n    X_train, X_test, Y_train, Y_test = train_test_split(X, y_reshaped, test_size=test_size, random_state=seed)\n\n    model = LogisticRegression(solver='liblinear')\n    log_reg = model.fit(X_train, Y_train)\n\n    Y_predicted = log_reg.predict(X_test)\n\n    c_matrix=confusion_matrix(Y_test, Y_predicted)\n\n    print(c_matrix)\n\n    print()\n    print(f'Accuracy {model.score(X_test, Y_test)*100:.3f}')\n    print(f'Accuracy check with conf. matrix {(c_matrix[0,0]+c_matrix[1,1])/c_matrix.sum()*100:.3f}')\n    print()\n    \n    print('*************************************************************')\n    print('Classification Report, top', n)    \n    \n    report = classification_report(Y_test, Y_predicted, digits=3)\n    \n    print(f'Accuracy {model.score(X_test, Y_test)*100:.3f}')\n    print()\n    print(report)\n\nprint('All the scores decrease as the number of universities in the group to predict increases')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}