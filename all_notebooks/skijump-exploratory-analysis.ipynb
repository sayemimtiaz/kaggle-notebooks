{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Exploratory Analysis of FIS Ski Jumping Data","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-25T17:27:09.450347Z","iopub.execute_input":"2021-06-25T17:27:09.450753Z","iopub.status.idle":"2021-06-25T17:27:10.354226Z","shell.execute_reply.started":"2021-06-25T17:27:09.450718Z","shell.execute_reply":"2021-06-25T17:27:10.353382Z"}}},{"cell_type":"markdown","source":"# Introduction","metadata":{}},{"cell_type":"markdown","source":"The sport of ski jumping is characterized by a discrepancy in performance of individuals from different countries. Athletes from a set of countries (mostly european countries and japan) consistently outperform those from the other countries. The ultimate purpose of this project is to determine the root causes of this discrepancy by analyzing ski jumping data. ","metadata":{}},{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"markdown","source":"**Data Collection**\n\nThe data for this project was all collected from the FIS website. The majority of the data, information containing competition results and hill specs, was collected and made publically available by kaggle user wrotki8778 by dowlnloading and scrapping the competition results pdfs. The remaining  data on the athletes was scrapped directly off the FIS site by me. \n\n**Data Cleaning/Feature Engineering**\n\nThe following steps are taken in the next code cell to edit the data and make it more usable for the purpose of this project:\n\n* A singe dataframe is created by combining columns from competition, results, and athletes datasets.\n* Rows containing Nan values are dropped from the dataset.\n* date-time values are parsed so that birthdate contains only birth year and comp date contains only the month (year is already stated in the *season* column)\n* Fuzzy matching between club names is minimized by creating a *club-id* column, giving clubs with sufficiently similar names the same club id. Matching is likely imperfect and somewhat up to interpretation.\n* columns containing strings representing numerical values are converted to numerical data type.\n* flying hill and regular hill results are differentiated by creating *is_flying* column. True for flying hill, False otherwise.\n* the distance travelled by an athlete is measured as a percent of the k point of the hill in column *percent_k*. Ths allows comparison of distance across the different hill sizes.\n* The approximate age of the athlete is stored in the column *age*\n* Whether the athlete is jumping in their home country is stored as a bool value in the column *home_comp*\n* Whether the athlete is from one of the aformentioned top performing countries is stored in the column *is_euro* (also contains japanese athletes and excludes european athletes from european countries that are not consistently out-performing others, eg. britain, russia etc.)\n* A rough approximation of the experience of an athlete is stored in the *years_seen* column. This contains the number of different seasons in which the athlete appears in the dataset.\n* The size of a club (number of different athletes with the same club id) is contained in the *club_size* column\n* The size of a nation (number of different athletes with the same nationality) is contained in the *nation_size* column.\n\n","metadata":{}},{"cell_type":"code","source":"# package imports\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns; sns.set_theme(color_codes=True)\nimport os\nfrom sklearn.feature_selection import mutual_info_regression\nfrom sklearn.cluster import KMeans\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import LabelEncoder\nfrom fuzzywuzzy import process\nfrom fuzzywuzzy import fuzz\nimport time\n\n\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n #   for filename in filenames:\n  #      print(os.path.join(dirname, filename))     \n\n# data imports\nratings = pd.read_csv('../input/ski-jumping-results-database-2009now/all_ratings.csv')\nnames = pd.read_csv('../input/ski-jumping-results-database-2009now/all_names.csv')\ncomps = pd.read_csv('../input/ski-jumping-results-database-2009now/all_comps_r.csv')\nresults = pd.read_csv('../input/ski-jumping-results-database-2009now/all_results.csv')\nstats = pd.read_csv('../input/ski-jumping-results-database-2009now/all_stats_r.csv')\nathletes = pd.read_csv('../input/fis-ski-jumpers/all_athlete_data.csv')\nathletes.drop(columns=['Unnamed: 0'], inplace=True)\n\n#merge data into single dataset containing athlete, comp, hill, and results data\nathletes_results = pd.merge(left = results, right = athletes, left_on='codex', right_on='xcode')\nathletes_comp_results = pd.merge(left=comps, right=athletes_results, left_on = 'id', right_on = 'id')\n#show all columns when visalizing \npd.set_option('max_columns', None)\n#drop repeat columns\nathletes_comp_results.rename(columns={'codex_x': 'comp_codex', 'hill_size_x': 'hill_size', 'xcode': 'athlete_codex', 'gender_y': 'gender','points':'total_points', 'loc': 'ranking'}, inplace=True)\nathletes_comp_results.drop(columns=['gender_x', 'hill_size_y', 'codex_y'], inplace=True)\n\n#drop individual judge scores\nathletes_comp_results.drop(columns=['note_1', 'note_2', 'note_3', 'note_4', 'note_5'], inplace=True)\n\n#drop missing values\nacr = athletes_comp_results.dropna()\n\n\n### Data Cleaning ###\n\n#fix birthdate to contain only year\ndef dtstring_year(bd):\n    try:\n        return int(pd.to_datetime(bd).year)\n    except ValueError:\n        return np.nan\n    except:\n        return int(bd)\n\n#fix comp date to only month\ndef dtstring_month(date):\n    try:\n        return int(pd.to_datetime(date).month)\n    except:\n        return np.nan\n\n#replace whitespace character wih Nan\ndef replace_nan(item):\n    if len(item) == 1:\n        return np.nan\n    else:\n        return item\n\n#acr.club = acr.club.map(lambda c: replace_nan(c))\nacr.birthdate = acr.birthdate.map(lambda bd: dtstring_year(bd))\nacr.date = acr.date.map(lambda d: dtstring_month(d))\n#acr.dropna(inplace=True)\nacr.club = acr.club.map(lambda c: c.lower().strip())\n\n#fix fuzzy matching for club names\n#make a 'club id' column for similar enough club names \n\nclubs = acr[['club', 'nationality']]\nclub_names = np.sort(clubs.club.unique())\n\ndef matchscore(s1, s2, limit=1):\n    return fuzz.partial_ratio(s1,s2)\n\ndef make_id(names, minscore):\n    ids = [1]\n    idnum = 1\n    for i in range(len(names)-1):\n        if matchscore(names[i+1], names[i]) > minscore:\n            ids.append(idnum)\n        else:\n            idnum += 1\n            ids.append(idnum)\n    return ids\n\nclub_ids = make_id(club_names, 70)\n\nclub_id_df = pd.DataFrame({'club': club_names, 'club_id': club_ids})\n\nacr = pd.merge(left = acr, right = club_id_df, left_on='club', right_on='club')\n\n\n#change cols to numerical values where necessary\nacr = acr.apply(pd.to_numeric, errors='ignore')\n\n\n### Some Feature Engineering ###\n\ndef check_top_country(val):\n    return val in ['GER', 'NOR', 'AUT', 'POL', 'SLO', 'JPN']\n\n# seperate flying hills as k-point > 160\nacr.loc[:,'flying_hill'] = acr['k.point'] > 160\nacr.loc[:,'percent_k'] = acr.dist/acr['k.point']\n# age\nacr['age'] = acr.season - acr.birthdate\n# home_comp\nacr['home_comp'] = acr['country'] == acr['nationality']\n# is from a top competing country\nis_top_li = [check_top_country(val) for val in acr['nationality']]\nacr['is_euro'] = is_top_li\n# num_years_seen\nacr['years_seen'] = acr.groupby('athlete_codex').season.transform('nunique')\n# club size\nacr['club_size'] = acr.groupby('club_id').athlete_codex.transform('nunique')\n# nation_size (number of individuals from a particular nation)\nacr['nation_size'] = acr.groupby('nationality').athlete_codex.transform('nunique')\n\nacr.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-03T22:44:14.330722Z","iopub.execute_input":"2021-07-03T22:44:14.331668Z","iopub.status.idle":"2021-07-03T22:44:33.668663Z","shell.execute_reply.started":"2021-07-03T22:44:14.331541Z","shell.execute_reply":"2021-07-03T22:44:33.667694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Analysis","metadata":{}},{"cell_type":"markdown","source":"the following was determined by analyzing a table of correlations:\n\n* hill size and k point can probably be reduced to a single column\n* points gained due to distance is strongly correlated with the size of the hill. This will need to be taken into account when analyzing points.\n* performance columns as expected show some correlation with is_euro and nation_size\n* club_size has little to no impact on athlete performance\n* nation_size and club_size are negatively correlated\n\nThe interesting correlations with the club_size column should be taken with a grain of salt. Club size was calculated using club_id, an imperfect fix to the club name fuzzy matching. ","metadata":{}},{"cell_type":"code","source":"# look at correlations\n\nMcorr = acr.drop(columns=['training']).corr()\nMcorr","metadata":{"execution":{"iopub.status.busy":"2021-07-03T22:44:33.670259Z","iopub.execute_input":"2021-07-03T22:44:33.670546Z","iopub.status.idle":"2021-07-03T22:44:34.00568Z","shell.execute_reply.started":"2021-07-03T22:44:33.670516Z","shell.execute_reply":"2021-07-03T22:44:34.004767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Importance","metadata":{}},{"cell_type":"markdown","source":"The correlation table showed a few notable relationships but I want to get a list of features reanked by their ability to predict the performance. Mutual information scores show the amount of information gained about a target from the feature. 0 is low, 2 is very high. his will be a useful metric. I will also train a random forest with the dataframe and list the feature importances. Ranking makes the most sense as a target, it will correct for the points discrepancies in hill size found earlier, and we wont have to worry about the different scoring system for ski flying competitions. Other useful festures to look at will be total points and distance, for a finer grain target. These will hold a little more information than the rank.","metadata":{}},{"cell_type":"markdown","source":"**Mutual Information between features and rank**\n\nThe following cell plots the mutual information scores of features using rank as the target. Aside from target leakage columns (points, distnce, etc.) we see that the features that provide the most information about rank are athletes, clubs, and then nations. It is interesting to see that the club an athlete is from gives more information than the nationality. Is_euro and years_seen have a little less information about the target, and club size interestingly has very little information. Home_comp, whether an athlete is jumping in their home country, holds virtually no information about the target, implying that athletes do not tend to jump any better in their home country than away at other countries.\n\nIt is interesting to me that club holds more information than nationality. Further analysis should be conducted in this area.","metadata":{}},{"cell_type":"code","source":"## get feat. importance with mutual information\n\ndef make_mi_scores(X, y):\n    X = X.copy()\n    for colname in X.select_dtypes([\"object\", \"category\"]):\n        X[colname], _ = X[colname].factorize()\n    # All discrete features should now have integer dtypes\n    discrete_features = [pd.api.types.is_integer_dtype(t) for t in X.dtypes]\n    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features, random_state=0)\n    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n    mi_scores = mi_scores.sort_values(ascending=False)\n    return mi_scores\n\n\ndef plot_mi_scores(scores):\n    scores = scores.sort_values(ascending=True)\n    width = np.arange(len(scores))\n    ticks = list(scores.index)\n    plt.barh(width, scores)\n    plt.yticks(width, ticks)\n    plt.title(\"Mutual Information Scores\")\n    return 0\n\nX = acr.dropna()\ny = X.pop('ranking')\n\nmi_scores = make_mi_scores(X, y)\n\nplt.figure(dpi=100, figsize=(10, 10))\nplot_mi_scores(mi_scores)","metadata":{"execution":{"iopub.status.busy":"2021-07-03T22:44:34.007421Z","iopub.execute_input":"2021-07-03T22:44:34.007708Z","iopub.status.idle":"2021-07-03T22:45:14.505261Z","shell.execute_reply.started":"2021-07-03T22:44:34.007679Z","shell.execute_reply":"2021-07-03T22:45:14.504534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Feature importance using points as the target**\n\nIt is necessary to seperate flying hill data from regular hill data when looking at total_points as the target because flying hill competitions score the distance differently. Hill size will also have a big impact on the total points, as we saw from the correlation table. The following cell shows the impact of flying hill on points, and seperatess flying and regular jumps into two datasets.","metadata":{}},{"cell_type":"code","source":"# demonstration of flying hill impact \nsns.scatterplot(x=acr.type, y=acr.total_points, hue=acr.flying_hill)\nsns.lmplot(x='total_points', y='percent_k', hue='flying_hill', data=acr)\n\n# seperate the two\nflying_df = acr[acr['flying_hill'] == True]\nregular_df = acr[acr['flying_hill'] == False]","metadata":{"execution":{"iopub.status.busy":"2021-07-03T22:45:14.506545Z","iopub.execute_input":"2021-07-03T22:45:14.506997Z","iopub.status.idle":"2021-07-03T22:45:26.249979Z","shell.execute_reply.started":"2021-07-03T22:45:14.506951Z","shell.execute_reply":"2021-07-03T22:45:26.249009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Feature importance with mutual information**\n\nThis time I will get rid of the target leakage columns before getting the feature importance. The following shows similar results to when rank was used as a target, this time the importance of the individual (athlete name and codex) is especially obvious. Place also seems to share a lot of information about the total points, this may reflect that points are awarded differently in diffrerent cities. Factors related to hill size (including wind/gate factor) populate the higher end of the list as expected. Wind seems to affect the score of an athlete in some way, perhaps indicating that wind factors are not always properly calibrated. Is_euro ranks far lower than nationality, indicating that maybe the distinction made in is_euro does not perfectly reflect the higher and lower ranking countries. Club size, again, ranks far lower than club id. Home_comp again seems to share little to no information with total_points. ","metadata":{}},{"cell_type":"code","source":"## get feat. importance with mutual information\n\n#drop irrelevent/target-leakage columns\ntotal_points_prediction_set = regular_df.drop(columns=['comp_codex','id','speed','dist','dist_points',\n                                                       'note_points', 'wind_comp', 'gate_points', 'ranking'])\n\n#drop NaNs\ntp_reg = total_points_prediction_set.dropna()\n\nX = tp_reg.drop(columns=['percent_k'])\ny = X.pop('total_points')\n\nmi_scores = make_mi_scores(X, y)\n\nplt.figure(dpi=100, figsize=(10, 10))\nplot_mi_scores(mi_scores)","metadata":{"execution":{"iopub.status.busy":"2021-07-03T22:45:26.251469Z","iopub.execute_input":"2021-07-03T22:45:26.252042Z","iopub.status.idle":"2021-07-03T22:45:53.090217Z","shell.execute_reply.started":"2021-07-03T22:45:26.251997Z","shell.execute_reply":"2021-07-03T22:45:53.089483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Feature importance with random forest**\n\n","metadata":{}},{"cell_type":"code","source":"\n#get categorical and numerical columns\nnumerical_cols = [col for col in X.columns if X[col].dtype in ['float64', 'int64']]\ncategorical_cols = [col for col in X.columns if X[col].dtype == 'object']\n\n## shorten the number of nationalities by combining the less-common nationalities into 'other' - \n## necessary for encoding nationality information for numerical random forest implementation\n\nacrn = acr.nationality\nacrv = acr.nationality.value_counts()\nnationalities = []\nfor n in acrn:\n    if acrv[n] < 2500:\n        nationalities.append('other')\n    else:\n        nationalities.append(n)\nacr.nationality = nationalities\n\n## Label Encode\n\n# Make copy to avoid changing original data \nlabel_X = X.copy()\n\n# Apply label encoder to each column with categorical data\nlabel_encoder = LabelEncoder()\nfor col in categorical_cols:\n    label_X[col] = label_encoder.fit_transform(X[col])\n\nXtrain_L, Xval_L, ytrain, yval = train_test_split(label_X, y, train_size = 0.8, test_size = 0.2)\n\n#random forest dat bish\n#### get feature importance\n\nplt.rcParams[\"figure.figsize\"] = (20,20)\n\n\n# Function for comparing different models\ndef score_model(X_t, X_v, y_t, y_v):\n    model = RandomForestRegressor(n_estimators=200, random_state=0)\n    model.fit(X_t, y_t)\n    preds = model.predict(X_v)\n    print (mean_absolute_error(y_v, preds))\n    return model\n\ndef plot_features(model, X_t, title):\n    feature_importances = model.feature_importances_\n\n    imp = pd.Series(feature_importances, index = X_t.columns).sort_values(ascending=True)\n    width = np.arange(len(imp))\n    ticks = list(imp.index)\n    plt.barh(width, imp)\n    plt.yticks(width, ticks)\n    plt.title(\"RF feature importance {}\".format(title))\n    return 0\n\nLabel_model = score_model(Xtrain_L, Xval_L, ytrain, yval)\n\n\nplot_features(Label_model, Xtrain_L, 'Label Encoding')","metadata":{"execution":{"iopub.status.busy":"2021-07-03T22:45:53.091382Z","iopub.execute_input":"2021-07-03T22:45:53.091861Z","iopub.status.idle":"2021-07-03T22:48:12.323226Z","shell.execute_reply.started":"2021-07-03T22:45:53.091778Z","shell.execute_reply":"2021-07-03T22:48:12.322378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Feature importance using distance as the target**\n\n","metadata":{}},{"cell_type":"code","source":"dist_target_set = acr[acr.flying_hill == False].copy()\n\n##drop irrelevent/target leakage cols\ndist_target_set.drop(columns=['id', 'speed', 'dist', 'dist_points', 'gate', 'gate_points', 'bib', 'comp_codex', 'flying_hill'], inplace=True)\n\n#change date-time vals to numerical\ndist_target_set.birthdate = dist_target_set.birthdate.map(lambda bd: dtstring_year(bd))\ndist_target_set.date = dist_target_set.date.map(lambda bd: dtstring_month(bd))\ntotal_points_prediction_set = total_points_prediction_set.apply(pd.to_numeric, errors='ignore')\n\ndist_target_set.dropna(inplace=True)\n\ndist_target_set.head(10)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## mutual information scores\n\nX = dist_target_set.drop(columns=['total_points']).copy()\ny = X.pop('percent_k')\n\nmi_scores = make_mi_scores(X, y)\n\nplt.figure(dpi=100, figsize=(8, 5))\nplot_mi_scores(mi_scores)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Label Encode\n\n#get categorical and numerical columns\nnumerical_cols = [col for col in X.columns if X[col].dtype in ['float64', 'int64']]\ncategorical_cols = [col for col in X.columns if X[col].dtype == 'object']\n\n# Make copy to avoid changing original data \nlabel_X = X.drop(columns=['note_points']).copy()\n\n# Apply label encoder to each column with categorical data\nlabel_encoder = LabelEncoder()\nfor col in categorical_cols:\n    label_X[col] = label_encoder.fit_transform(X[col])\n\nXtrain_L, Xval_L, ytrain, yval = train_test_split(label_X, y, train_size = 0.8, test_size = 0.2)\n\nplt.rcParams[\"figure.figsize\"] = (20,20)\n\nLabel_model = score_model(Xtrain_L, Xval_L, ytrain, yval)\n\nplot_features(Label_model, Xtrain_L, 'Label Encoding')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Further analysis with data visualization","metadata":{}},{"cell_type":"markdown","source":"**Investigation of club performance in relation to rank**\n\n","metadata":{}},{"cell_type":"code","source":"def mode(series):\n    return series.value_counts().idxmax()\n\nstatcols = ['club_id', 'nationality', 'nation_size', 'ranking', 'club_size', 'club']\nstats = ['mean', 'median', 'std']\n\nstats_df = acr[statcols].dropna()\nstats_df['season'] = acr.season\n\nfor col in statcols[:-2]:\n    stats_df[col + '_rank_mode'] = stats_df.groupby(col).ranking.transform(mode)\n    for stat in stats:\n        stats_df[col + '_rank_' + stat] = stats_df.groupby(col).ranking.transform(stat)\n        \n#look a top 50 clubs by mean and by median ranking \ntop_50 = stats_df.groupby('club_id').apply(lambda df: df.loc[df.club_id_rank_mean.idxmin()]).sort_values(by='club_id_rank_mean').head(50)\nbottom_50 = stats_df.groupby('club_id').apply(lambda df: df.loc[df.club_id_rank_mean.idxmin()]).sort_values(by='club_id_rank_mean', ascending=False).head(50)\n\ntop_50.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-03T22:48:53.172121Z","iopub.execute_input":"2021-07-03T22:48:53.172408Z","iopub.status.idle":"2021-07-03T22:48:54.150479Z","shell.execute_reply.started":"2021-07-03T22:48:53.172379Z","shell.execute_reply":"2021-07-03T22:48:54.149457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Clubs performance over time ","metadata":{}},{"cell_type":"code","source":"top_50_clubs = top_50.club_id\n\nclub50 = acr.loc[acr.club_id.isin(top_50_clubs)]\n\nseasons = np.sort(acr.season.unique())\n\nclub50['cmr_season'] = club50.groupby(['season', 'club_id']).ranking.transform('mean')\n\n#drop small clubs as the mean values will tend to be more extreme and less useful\nclub50 = club50.drop(club50[club50.club_size < 3].index)\n\n#fig, ax = plt.subplots(figsize=(15,10))\n#sns.lineplot(x=club50.season, y=club50.cmr_season, hue=club50.club)\n\n#sort by nation\nnations = club50.nationality.unique()\nfor nation in nations:\n    df = club50.loc[club50.nationality == nation]\n    fig, ax = plt.subplots(figsize=(10,7))\n    sns.lineplot(ax=ax, x=df.season, y=df.cmr_season, hue=df.club_id)\n    ax.set_title(nation)\n    ","metadata":{"execution":{"iopub.status.busy":"2021-07-03T22:48:54.151807Z","iopub.execute_input":"2021-07-03T22:48:54.152122Z","iopub.status.idle":"2021-07-03T22:49:01.698642Z","shell.execute_reply.started":"2021-07-03T22:48:54.152093Z","shell.execute_reply":"2021-07-03T22:49:01.697713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that clubs with id 308, 297, and 129 have shown quite dramatic improvement over the last 10 years.","metadata":{}},{"cell_type":"code","source":"##### look at some features\n\ntp_flying = total_points_prediction_set[total_points_prediction_set['flying_hill'] == True]\ntp_reg = total_points_prediction_set[total_points_prediction_set['flying_hill'] == False]\n\nfeatures = [\"hill_size\", 'place', 'club', \"nationality\"]\nsns.relplot(\n    x=\"value\", y=\"total_points\", col=\"variable\", data=tp_reg.melt(id_vars=\"total_points\", value_vars=features), facet_kws=dict(sharex=False),\n);\n\nfeatures = ['wind', 'age', 'years_seen']\nsns.relplot(\n    x=\"value\", y=\"total_points\", col=\"variable\", data=tp_reg.melt(id_vars=\"total_points\", value_vars=features), facet_kws=dict(sharex=False),\n);\n\nfeatures = ['home_comp', 'is_euro', 'club_size', 'nation_size']\nsns.relplot(\n    x=\"value\", y=\"total_points\", col=\"variable\", data=tp_reg.melt(id_vars=\"total_points\", value_vars=features), facet_kws=dict(sharex=False),\n);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# look at relationship between hill size/k point, wind factor, gate factor, metre value\n\nfeatures = ['gate.factor', 'wind.factor', \"meter.value\"]\nsns.relplot(\n    x=\"value\", y=\"hill_size\", col=\"variable\", data=tp_reg.melt(id_vars=\"hill_size\", value_vars=features), facet_kws=dict(sharex=False),\n);\n","metadata":{"execution":{"iopub.status.busy":"2021-07-03T22:49:01.699851Z","iopub.execute_input":"2021-07-03T22:49:01.700134Z","iopub.status.idle":"2021-07-03T22:49:03.417381Z","shell.execute_reply.started":"2021-07-03T22:49:01.700106Z","shell.execute_reply":"2021-07-03T22:49:03.416394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(1,2, figsize=(15., 7.))\n\nax1.scatter(tp_reg['gate.factor'], tp_reg['wind.factor'])\nax1.set_xlabel('gate factor')\nax1.set_ylabel('wind factor')\nax1.set_title('wind-gate factor correlation')\n\nax2.scatter(tp_reg['meter.value'], tp_reg.hill_size)\nax2.set_xlabel('meter value')\nax2.set_ylabel('hill size')\nax2.set_title('meter-value - hill size correlation')","metadata":{"execution":{"iopub.status.busy":"2021-07-03T22:49:03.418527Z","iopub.execute_input":"2021-07-03T22:49:03.418811Z","iopub.status.idle":"2021-07-03T22:49:04.101735Z","shell.execute_reply.started":"2021-07-03T22:49:03.418784Z","shell.execute_reply":"2021-07-03T22:49:04.100492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10., 7.))\nsns.scatterplot(x=tp_reg['gate.factor'], y=tp_reg['wind.factor'], hue=tp_reg.country)","metadata":{"execution":{"iopub.status.busy":"2021-07-03T22:49:04.103338Z","iopub.execute_input":"2021-07-03T22:49:04.103735Z","iopub.status.idle":"2021-07-03T22:49:07.801994Z","shell.execute_reply.started":"2021-07-03T22:49:04.103691Z","shell.execute_reply":"2021-07-03T22:49:07.801098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lets make some clusters and see if they correlate with points/distance\n\ncluster_features = ['gate.factor', 'wind.factor']\nscaled_cluster_df = tp_reg[cluster_features]\nfor feat in cluster_features:\n    scaled_cluster_df[feat] = (scaled_cluster_df[feat])/scaled_cluster_df[feat].std()\n\nkmeans = KMeans(n_clusters=2)\nscaled_cluster_df[\"cluster\"] = kmeans.fit_predict(scaled_cluster_df[cluster_features])\n\nfig, ax = plt.subplots(figsize=(10., 7.))\nsns.scatterplot(y=scaled_cluster_df['wind.factor'], x=scaled_cluster_df['gate.factor'], hue=scaled_cluster_df['cluster'])\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-03T22:49:07.803399Z","iopub.execute_input":"2021-07-03T22:49:07.803955Z","iopub.status.idle":"2021-07-03T22:49:11.900364Z","shell.execute_reply.started":"2021-07-03T22:49:07.803907Z","shell.execute_reply":"2021-07-03T22:49:11.899593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#try and isolate the outliers\n\nscaled_cluster_df['wind_gate_outlier'] = scaled_cluster_df['wind.factor'] > scaled_cluster_df['gate.factor']*2 - 7\n\nfig, ax = plt.subplots(figsize=(10., 7.))\nsns.scatterplot(y=scaled_cluster_df['wind.factor'], x=scaled_cluster_df['gate.factor'], hue=scaled_cluster_df['wind_gate_outlier'])\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-03T22:49:11.901409Z","iopub.execute_input":"2021-07-03T22:49:11.901885Z","iopub.status.idle":"2021-07-03T22:49:14.622919Z","shell.execute_reply.started":"2021-07-03T22:49:11.90184Z","shell.execute_reply":"2021-07-03T22:49:14.621838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tp_reg['wind_gate_outlier'] = scaled_cluster_df['wind_gate_outlier']\n\n#see what it affects\nfig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10., 10.))\nsns.scatterplot(ax=ax1, x=tp_reg['wind.factor'], y=tp_reg['gate.factor'], hue=tp_reg.wind_gate_outlier)\nsns.kdeplot(ax = ax2, x='total_points', hue='wind_gate_outlier', data=tp_reg)\nfig2, ax = plt.subplots(figsize = (10., 7.))\nsns.kdeplot(ax = ax, x='hill_size', hue='wind_gate_outlier', data=tp_reg)","metadata":{"execution":{"iopub.status.busy":"2021-07-03T22:49:14.624518Z","iopub.execute_input":"2021-07-03T22:49:14.625Z","iopub.status.idle":"2021-07-03T22:49:18.895764Z","shell.execute_reply.started":"2021-07-03T22:49:14.624876Z","shell.execute_reply":"2021-07-03T22:49:18.894815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (15,10)\n#wind is slightly negatively correlated\nsns.regplot(x=tp_reg.wind, y=tp_reg.total_points)","metadata":{"execution":{"iopub.status.busy":"2021-07-03T22:49:19.021009Z","iopub.status.idle":"2021-07-03T22:49:19.02185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#maybe some correlation with age\n\nage_df = tp_reg[[\"age\", \"total_points\"]]\nage_df['mean_points_age'] = age_df.groupby('age').total_points.transform('mean')\n\nage_plot = sns.regplot(x=age_df.age, y=age_df.mean_points_age, logx=True)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-03T22:49:19.02313Z","iopub.status.idle":"2021-07-03T22:49:19.023925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.kdeplot(data=tp_reg, x='age', shade=True)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-03T22:49:19.025093Z","iopub.status.idle":"2021-07-03T22:49:19.025905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"years_df = tp_reg[[\"years_seen\", \"total_points\"]]\nyears_df['mean_points_years'] = years_df.groupby('years_seen').total_points.transform('mean')\nyears_df['var_points_years'] = years_df.groupby('years_seen').total_points.transform('std')\n\n\nax = sns.regplot(x=years_df.years_seen, y=years_df.mean_points_years)\nax.errorbar(x=years_df.years_seen, y=years_df.mean_points_years, yerr = years_df.var_points_years, fmt='none', capsize=5, zorder=1, color='C0')","metadata":{"execution":{"iopub.status.busy":"2021-07-03T22:49:19.027163Z","iopub.status.idle":"2021-07-03T22:49:19.027976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.distplot(x=tp_reg.years_seen)","metadata":{"execution":{"iopub.status.busy":"2021-07-03T22:49:19.028867Z","iopub.status.idle":"2021-07-03T22:49:19.02941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.catplot(x='is_euro', y='total_points', data=tp_reg, kind='violin')","metadata":{"execution":{"iopub.status.busy":"2021-07-03T22:49:19.030161Z","iopub.status.idle":"2021-07-03T22:49:19.030659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.kdeplot(data=tp_reg, x=\"total_points\", hue='is_euro', multiple=\"fill\")","metadata":{"execution":{"iopub.status.busy":"2021-07-03T22:49:19.031398Z","iopub.status.idle":"2021-07-03T22:49:19.031875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.catplot(x='home_comp', y='total_points', data=tp_reg, kind='violin')","metadata":{"execution":{"iopub.status.busy":"2021-07-03T22:49:19.032711Z","iopub.status.idle":"2021-07-03T22:49:19.03314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.kdeplot(data=tp_reg, x=\"total_points\", hue='home_comp', multiple=\"fill\")","metadata":{"execution":{"iopub.status.busy":"2021-07-03T22:49:19.034018Z","iopub.status.idle":"2021-07-03T22:49:19.03443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# look for correlation between club size and club mean performance\n\ntp_reg['club_points_mean'] = tp_reg.groupby('club').total_points.transform('mean')\n\nclub_df = tp_reg[['club', 'club_size', 'club_points_mean', 'is_euro', 'nation_size']]\n\nx = sns.catplot(x='club_size', y='club_points_mean', data=club_df, kind='box')\nx.fig.set_figheight(10)\nx.fig.set_figwidth(15)","metadata":{"execution":{"iopub.status.busy":"2021-07-03T22:49:19.035267Z","iopub.status.idle":"2021-07-03T22:49:19.035672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"club_df.sort_values(by='club_points_mean', inplace=True)\nc = sns.distplot(x=club_df.club_points_mean)","metadata":{"execution":{"iopub.status.busy":"2021-07-03T22:49:19.036628Z","iopub.status.idle":"2021-07-03T22:49:19.037094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nprint(tp_reg.club.nunique())\nprint(tp_reg.club_size.nunique())\n\nsns.scatterplot(x=club_df.club_size, y=club_df.nation_size)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-03T22:49:19.037999Z","iopub.status.idle":"2021-07-03T22:49:19.038416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.kdeplot(data=dist_target_set, x=\"percent_k\", hue='is_euro', multiple=\"fill\")","metadata":{"execution":{"iopub.status.busy":"2021-07-03T22:49:19.043813Z","iopub.status.idle":"2021-07-03T22:49:19.044309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.kdeplot(data=dist_target_set, x=\"percent_k\", hue='home_comp', multiple=\"fill\")","metadata":{"execution":{"iopub.status.busy":"2021-07-03T22:49:19.045131Z","iopub.status.idle":"2021-07-03T22:49:19.045541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.lmplot(x=\"note_points\", y=\"percent_k\", hue=\"gender\", data=dist_target_set)\nsns.lmplot(x=\"note_points\", y=\"percent_k\", hue=\"is_euro\", data=dist_target_set)","metadata":{"execution":{"iopub.status.busy":"2021-07-03T22:49:19.046483Z","iopub.status.idle":"2021-07-03T22:49:19.04691Z"},"trusted":true},"execution_count":null,"outputs":[]}]}