{"cells":[{"metadata":{},"cell_type":"markdown","source":"1. [Introduction](#1)\n2. [Load and Preprocessing](#2)\n3. [Supervised Models](#3)\n      * [Random Forest](#4)\n      * [Decision Tree](#5)\n      * [K-Nearest Neighbours](#6)\n      * [Support Vector Machines](#7)\n      * [Naive Bayes](#8)\n4. [Compare Model's Accuracy with Graph](#9)\n5. [Conclusion](#10)"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"1\" >\n    \n# Introduction"},{"metadata":{},"cell_type":"markdown","source":"* Supervised learning is used for datas which have labels(class). We can find the class of our data with supervised learning.\n \n![image.png](https://i.ibb.co/4pKMSNq/Machine-Learning-Classification-Algorithms-1280x720.jpg)\n\n* In this picture, we can say that all of foods have some features(their size,weight, etc.) and every foods have labels(ice cream, cake, etc.). Thanks to this features, we can find their labels with our model.\n\n* In supervised learning, we use our provided labels and features as a teacher of model. For this example, we will split our data as train and test datas. We will use our train data to train our model. We can train our model with this data because we know its label. After that we will use our test data to determine our accuracy. \n\n* In this notebook, we will use Naive Bayes, Decision Tree, Support Vector Machines, Random Forest and K-Nearest Neighbours. All of them will be explained before its code."},{"metadata":{},"cell_type":"markdown","source":"<a id=\"2\" >\n    \n# Load and Preprocessing"},{"metadata":{},"cell_type":"markdown","source":"* First we import our libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nfrom collections import Counter\nimport seaborn as sns\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load Data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/glass/glass.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Check data\n* We see that we don't have null data. Our number of data is 214 and their type is float64. Our type(it will be our label) is int64"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* We can see our first 5 row of our dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Our columns name"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* In this part, we determine our features and labels. Our labels are our type of glasses. It has 6 type(1,2,3,5,6,7). It calls it in our code as a Y and\nX is our features"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.iloc[:,:-1]\nY = df.iloc[:,9]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* We can see that how many types we have"},{"metadata":{"trusted":true},"cell_type":"code","source":"Counter(Y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Normalize Data\n\n* In this part we normalize our data. It means all of features have value between 0 and 1. Thanks to normalization, all of our data's values change to common scale, without distorting differences in the ranges of values. "},{"metadata":{"trusted":true},"cell_type":"code","source":"X_n = (X-np.min(X))/(np.max(X)-np.min(X))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* In this part we split our data as train and test. This code means our %80 of data will be used to train our model. %20 of data will be used to test our model. Random state means it takes same values for every run"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(X_n,Y,test_size=0.2,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"3\" >\n    \n# Supervised Models"},{"metadata":{},"cell_type":"markdown","source":"<a id = \"4\" >\n\n## Random Forest"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"![randomforest.png](https://i.ibb.co/THj4n51/Random-Forest-Algorithm.jpg)\n\n* Random forest is using this type of algorithm. It uses yes/no. It ask a yes-no question to our data for a specific value. If it is correct, it selects yes road, if it isn't correct, it selects no road. \n* For an example, our data is [1,5,6,8,10,7]. For 6, it asks your value >2? and it is correct. It is going yes road and random forest asks your value<5? and it is wrong and it is going to false road. With these questions, our figure looks like tree and thanks to it, we can class our data\n\n* Random forest is using a lot of tree and it classifies our data with voting system. Each tree vote for one class and the winner will be our class."},{"metadata":{},"cell_type":"markdown","source":"* We will use this parameters for our graphs."},{"metadata":{"trusted":true},"cell_type":"code","source":"score_list = []\nmodel = []\ncross_val_score_list=[]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tuning= [100,200,300,400,500,600,700,800]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* For all model, first we import our model's library. After that we can use it.\n* For all model, we find our train's accuracy with k-fold cross validation. We split our train data and use them for train and validation. \n![](https://i.ibb.co/ZcdQJLq/8uEci.png)\n\n* For this picture cv=5. It means it uses %80 of data for train and %20 data to determine accuracy of train data. Their mean will be our accuracy of our train data. If we don't use it, our train's accuracy can misguide us. For an example, our accuracy is %86 without k-fold cross validation. Hovewer,our accuracies are %90,%99,%65,%91,%85 with k-fold cross validation. We can say that for this model there can be some problems because it is unstable.\n\n* For our models we will our cv=3 and we check std to understand our model stable or not."},{"metadata":{},"cell_type":"markdown","source":"* To find the best n_estimators, we use this code. (We can use grid searh cv, but in this notebook we didn't use it) It means how many estimators will vote to class our data."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier \nscore=[]\na=0\nc=0\nfor i in tuning:\n    rf = RandomForestClassifier(n_estimators=i, random_state=42)\n\n    rf.fit(x_train,y_train)\n    accuracies = cross_val_score(estimator=rf,X = x_train,y = y_train,cv=3)\n#%%\n    score.append(np.mean(accuracies))\n    if np.mean(accuracies)>a:\n        a=np.mean(accuracies)\n        c=i\nprint(\"acc = \",a,\" best number of estimator = \",c)\nprint(\"std= \",np.std(accuracies))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(tuning,score)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* For all of models first we introduce one variable which is equal to our model(their parameters can change with model). After that we fit it with our train datas. After that we check our test results with our model which is fitted by our train datas."},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier(n_estimators=100, random_state=42) #variable = our model\n\nrf.fit(x_train,y_train) #fit our model with our train datas\nprint(rf.score(x_test,y_test)) #check score with our test datas\nmodel.append(\"Random Forest Classifier\") #store our models name for our graph\nscore_list.append(rf.score(x_test,y_test)) #store our test score for our graph","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* We use confusion matrix to compare our predicted and real value. For an example we have dog and cat labels. We have 30 dog and 20 cat. With confusion matrix, we can see that how many dogs we predicted right.\n* For an example, our data have 10 dogs and 90 cats. We saw that our accuracy is %90 and we can say that it is good. However, we use confusion matrix and we saw that our model predicted dogs for all features. It means our model isn't good because we have two classes and our predicted data don't have one of them."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ny_pred= rf.predict(x_test) #we use this code to predict our labels with our model\n#confusion matrix part\ncategories = [1,2,3,5,6,7] \ncm = confusion_matrix(y_test,y_pred)\nf , ax = plt.subplots(figsize=(5,5))\n\nsns.heatmap(cm,annot = True,linewidths =0.5,linecolor =\"Red\",fmt=\".0f\",ax=ax)\nax.set_xticklabels(categories)\nax.set_yticklabels(categories)\nplt.xlabel(\"y_pred\")\nplt.ylabel(\"y_true\")\n\n\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"5\" >\n\n## Decision Tree"},{"metadata":{},"cell_type":"markdown","source":"* It is like random forest, but it uses only one tree. Random forest is essentially collection of decision tree"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\ndt = DecisionTreeClassifier()\naccuracies = cross_val_score(estimator=rf,X = x_train,y = y_train,cv=3)\n#%%\nprint(\"acc = \", np.mean(accuracies))\nprint(\"std= \",np.std(accuracies))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dt.fit(x_train,y_train)\nprint(\"acc = \", dt.score(x_test,y_test))\nmodel.append(\"Decision Tree Classifier\")\nscore_list.append(dt.score(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred= dt.predict(x_test)\n\ncategories = [1,2,3,5,6,7]\ncm = confusion_matrix(y_test,y_pred)\nf , ax = plt.subplots(figsize=(5,5))\n\nsns.heatmap(cm,annot = True,linewidths =0.5,linecolor =\"Red\",fmt=\".0f\",ax=ax)\nax.set_xticklabels(categories)\nax.set_yticklabels(categories)\nplt.xlabel(\"y_pred\")\nplt.ylabel(\"y_true\")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"6\" >\n    \n## K-Nearest Neighbors"},{"metadata":{},"cell_type":"markdown","source":"![knn](https://i.ibb.co/K5Z6345/knn.png)\n* K-Nearest Neighbors determines nearest neighbors. It looks nearest neighbors class and specify your data's class. \n* For this model, you have to determine number of neighbors. For this picture, in small circle n_neighbors is 3, for big circle n_neighbors is 6"},{"metadata":{},"cell_type":"markdown","source":"* To find the best n_neighbors, we use this code. (We can use grid searh cv, but in this notebook we didn't use it)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nscore =[]\na=0\nc=0\nfor i in range(2,20):\n    knn = KNeighborsClassifier(n_neighbors = i)\n    accuracies = cross_val_score(estimator=knn,X = x_train,y = y_train,cv=3)\n    score.append(np.mean(accuracies))\n    if np.mean(accuracies)>a:\n        a=np.mean(accuracies)\n        c=i\n    \nprint(\"acc = \",a,\" best number of neighbors = \",c)\nprint(\"std= \",np.std(accuracies))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(range(2,20),score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(x_train,y_train)\nprint(\"acc = \", knn.score(x_test,y_test))\nmodel.append(\"K-Nearest Neighbors\")\nscore_list.append(knn.score(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred= knn.predict(x_test)\n\ncategories = [1,2,3,5,6,7]\ncm = confusion_matrix(y_test,y_pred)\nf , ax = plt.subplots(figsize=(5,5))\n\nsns.heatmap(cm,annot = True,linewidths =0.5,linecolor =\"Red\",fmt=\".0f\",ax=ax)\nax.set_xticklabels(categories)\nax.set_yticklabels(categories)\nplt.xlabel(\"y_pred\")\nplt.ylabel(\"y_true\")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"7\" >\n    \n## Support Vector Machines"},{"metadata":{},"cell_type":"markdown","source":"![support](https://i.ibb.co/2SpcZ3M/SVM.jpg)\n\n* It uses vector to separate our data and says that left of this vector will be class a, right of this vector will be class. By looking p, svm optimizes for best hyper-plane"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\n\nsvm = SVC(random_state=1)\naccuracies = cross_val_score(estimator=knn,X = x_train,y = y_train,cv=3)\nprint(\"acc = \" ,np.mean(accuracies))\nprint(\"std= \",np.std(accuracies))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nsvm.fit(x_train,y_train)\nprint(\"acc = \" ,svm.score(x_test,y_test))\nmodel.append(\"Support Vector Machines\")\nscore_list.append(svm.score(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred= svm.predict(x_test)\n\ncategories = [1,2,3,5,6,7]\ncm = confusion_matrix(y_test,y_pred)\nf , ax = plt.subplots(figsize=(5,5))\n\nsns.heatmap(cm,annot = True,linewidths =0.5,linecolor =\"Red\",fmt=\".0f\",ax=ax)\nax.set_xticklabels(categories)\nax.set_yticklabels(categories)\nplt.xlabel(\"y_pred\")\nplt.ylabel(\"y_true\")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"8\" >\n\n## Navie Bayes"},{"metadata":{},"cell_type":"markdown","source":"* It is a classification technique based on Bayesâ€™ Theorem with an assumption of independence among predictors. In simple terms, a Naive Bayes classifier assumes that the presence of a particular feature in a class is unrelated to the presence of any other feature.\n* Navie bayes formula is :\n![navie](https://i.ibb.co/N25cdqS/Siniflandirma-Notlari-10-Bayes-Teoremi-Formul-e1504212839936.png)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\n\nnb=GaussianNB()\n\naccuracies = cross_val_score(estimator=nb,X = x_train,y = y_train,cv=3)\nprint(\"acc = \", np.mean(accuracies))\nprint(\"std= \",np.std(accuracies))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nb.fit(x_train,y_train)\nprint(\"acc = \" ,nb.score(x_test,y_test))\nmodel.append(\"Naive Bayes\")\nscore_list.append(nb.score(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred= nb.predict(x_test)\n\ncategories = [1,2,3,5,6,7]\ncm = confusion_matrix(y_test,y_pred)\nf , ax = plt.subplots(figsize=(5,5))\n\nsns.heatmap(cm,annot = True,linewidths =0.5,linecolor =\"Red\",fmt=\".0f\",ax=ax)\nax.set_xticklabels(categories)\nax.set_yticklabels(categories)\nplt.xlabel(\"y_pred\")\nplt.ylabel(\"y_true\")\nlabels = [\"True Neg\",\"False Pos\",\"False Neg\",\"True Pos\"]\n\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"9\" >\n# Compare Model's Accuracy with Graph"},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_result = pd.DataFrame({\"Scores\":score_list, \"ML Models\":model})\ng = sns.barplot(\"Scores\", \"ML Models\",data=cv_result)\ng.set_xlabel(\"Test Name\")\ng.set_title(\"Test Scores\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"10\" >\n       \n# Conclusion"},{"metadata":{},"cell_type":"markdown","source":"* For this data random forest classifier is the best choice for us. Its accuracy is higher than others.\n* We saw all models' basic, what they are and how we can write them in python.\n* To increase our model's accuracy, we can use other hyperparameters with grid search cv and we can make some changes for our data to increase our accuracy. We have to try them to see they work or not.\n* I hope you will like it, if you like it don't forget to upvote.\n\nThank you"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}