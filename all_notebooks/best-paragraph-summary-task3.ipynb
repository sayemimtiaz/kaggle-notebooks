{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Installing and testing sentence embedding extraction modules. Testing For GPU and setting up device. \n### Using Pytorch based Bio-Bert download via biobert-embedding\n\n### **Testing below package to generate embedding** \n[Biobert Reference](https://github.com/Overfitter/biobert_embedding)\n**This package main code is modified to run it on GPU**\n\n[sentence-transformers](https://github.com/UKPLab/sentence-transformers)\n\n#### Reserch paper for the search is selected based on Clustering Via Citation and other networks \n\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\nimport os\nimport pandas as pd\nimport numpy as np\nfrom scipy.spatial.distance import cdist\nimport subprocess\nimport pickle\nimport numpy as np\nimport io\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport re\nimport networkx as nx\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport pprint\nimport matplotlib.pyplot as plt\nimport pickle as pkl\n!pip install biobert-embedding\nimport torch\n\n# If there's a GPU available...\nif torch.cuda.is_available():    \n\n    # Tell PyTorch to use the GPU.    \n    device = torch.device(\"cuda\")\n\n    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n\n    print('We will use the GPU:', torch.cuda.get_device_name(0))\n\n# If not...\nelse:\n    print('No GPU available, using the CPU instead.')\n    device = torch.device(\"cpu\")\nfrom nltk import word_tokenize\nfrom nltk.corpus import stopwords\nfrom string import punctuation\nfrom scipy.spatial import distance\nimport nltk\nnltk.download('stopwords')\nnltk.download('punkt')\nstop_words = set(stopwords.words('english'))\ndef preprocess_sentence(text):\n    text = text.replace('/', ' / ')\n    text = text.replace('.-', ' .- ')\n    text = text.replace('.', ' . ')\n    text = text.replace('\\'', ' \\' ')\n    text = text.lower()\n\n    tokens = [token for token in word_tokenize(text) if token not in punctuation and token not in stop_words]\n\n    return ' '.join(tokens)\nfrom nltk import tokenize\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Import package and change code to run on GPU\n\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from biobert_embedding.embedding import BiobertEmbedding\nimport os\nimport torch\nimport logging\nimport tensorflow as tf\nfrom pathlib import Path\nfrom biobert_embedding import downloader\nfrom pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\nlogging.basicConfig(filename='app.log', filemode='w',format='%(asctime)s %(message)s', level=logging.INFO)\n\nlogger = logging.getLogger(__name__)\nclass BiobertEmbedding(object):\n    \"\"\"\n    Encoding from BioBERT model (BERT finetuned on PubMed articles).\n    Parameters\n    ----------\n    model : str, default Biobert.\n            pre-trained BERT model\n    \"\"\"\n\n    def __init__(self, model_path=None):\n\n        if model_path is not None:\n            self.model_path = model_path\n        else:\n            self.model_path = downloader.get_BioBert(\"google drive\")\n\n        self.tokens = \"\"\n        self.sentence_tokens = \"\"\n        self.tokenizer = BertTokenizer.from_pretrained(self.model_path)\n        # Load pre-trained model (weights)\n        self.model = BertModel.from_pretrained(self.model_path)\n        self.model.to(device)\n        logger.info(\"Initialization Done !!\")\n\n    def process_text(self, text):\n\n        marked_text = \"[CLS] \" + text + \" [SEP]\"\n        # Tokenize our sentence with the BERT tokenizer.\n        tokenized_text = self.tokenizer.tokenize(marked_text)\n        return tokenized_text\n\n\n    def handle_oov(self, tokenized_text, word_embeddings):\n        embeddings = []\n        tokens = []\n        oov_len = 1\n        for token,word_embedding in zip(tokenized_text, word_embeddings):\n            if token.startswith('##'):\n                token = token[2:]\n                tokens[-1] += token\n                oov_len += 1\n                embeddings[-1] += word_embedding\n            else:\n                if oov_len > 1:\n                    embeddings[-1] /= oov_len\n                tokens.append(token)\n                embeddings.append(word_embedding)\n        return tokens,embeddings\n\n\n    def eval_fwdprop_biobert(self, tokenized_text):\n\n        # Mark each of the tokens as belonging to sentence \"1\".\n        segments_ids = [1] * len(tokenized_text)\n        # Map the token strings to their vocabulary indeces.\n        indexed_tokens = self.tokenizer.convert_tokens_to_ids(tokenized_text)\n\n        # Convert inputs to PyTorch tensors\n        tokens_tensor = torch.tensor([indexed_tokens]).to(device)\n        segments_tensors = torch.tensor([segments_ids]).to(device)\n\n        # Put the model in \"evaluation\" mode, meaning feed-forward operation.\n        self.model.eval()\n        # Predict hidden states features for each layer\n        with torch.no_grad():\n            encoded_layers, _ = self.model(tokens_tensor, segments_tensors)\n\n        return encoded_layers\n\n\n    def word_vector(self, text, handle_oov=True, filter_extra_tokens=True):\n\n        tokenized_text = self.process_text(text)\n\n        encoded_layers = self.eval_fwdprop_biobert(tokenized_text)\n\n        # Concatenate the tensors for all layers. We use `stack` here to\n        # create a new dimension in the tensor.\n        token_embeddings = torch.stack(encoded_layers, dim=0)\n        token_embeddings = torch.squeeze(token_embeddings, dim=1)\n        # Swap dimensions 0 and 1.\n        token_embeddings = token_embeddings.permute(1,0,2)\n\n        # Stores the token vectors, with shape [22 x 768]\n        word_embeddings = []\n        logger.info(\"Summing last 4 layers for each token\")\n        # For each token in the sentence...\n        for token in token_embeddings:\n\n            # `token` is a [12 x 768] tensor\n            # Sum the vectors from the last four layers.\n            sum_vec = torch.sum(token[-4:], dim=0)\n\n            # Use `sum_vec` to represent `token`.\n            word_embeddings.append(sum_vec)\n\n        self.tokens = tokenized_text\n        if filter_extra_tokens:\n            # filter_spec_tokens: filter [CLS], [SEP] tokens.\n            word_embeddings = word_embeddings[1:-1]\n            self.tokens = tokenized_text[1:-1]\n\n        if handle_oov:\n            self.tokens, word_embeddings = self.handle_oov(self.tokens,word_embeddings)\n        logger.info(self.tokens)\n        logger.info(\"Shape of Word Embeddings = %s\",str(len(word_embeddings)))\n        return word_embeddings\n\n\n\n    def sentence_vector(self,text):\n\n        logger.info(\"Taking last layer embedding of each word.\")\n        logger.info(\"Mean of all words for sentence embedding.\")\n        tokenized_text = self.process_text(text)\n        self.sentence_tokens = tokenized_text\n        encoded_layers = self.eval_fwdprop_biobert(tokenized_text)\n\n        # `encoded_layers` has shape [12 x 1 x 22 x 768]\n        # `token_vecs` is a tensor with shape [22 x 768]\n        token_vecs = encoded_layers[11][0]\n\n        # Calculate the average of all 22 token vectors.\n        sentence_embedding = torch.mean(token_vecs, dim=0)\n        logger.info(\"Shape of Sentence Embeddings = %s\",str(len(sentence_embedding)))\n        return sentence_embedding\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Check GPU"},{"metadata":{"trusted":true},"cell_type":"code","source":"device.type","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Sentence transformer"},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install -U sentence-transformers","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Download BioBert"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_path = downloader.get_BioBert(\"google drive\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# setting SentenceTransformer"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Use BERT for mapping tokens to embeddings\nfrom sentence_transformers import models\nfrom sentence_transformers import SentenceTransformer\nword_embedding_model = models.BERT('/kaggle/working/'+model_path.name)\n\n# Apply mean pooling to get one fixed sized sentence vector\npooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(),\n                               pooling_mode_mean_tokens=True,\n                               pooling_mode_cls_token=False,\n                               pooling_mode_max_tokens=True)\n\nmodel = SentenceTransformer(modules=[word_embedding_model, pooling_model])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Read papers Selected for Task3 "},{"metadata":{"trusted":true},"cell_type":"code","source":"data=pd.read_excel(\"/kaggle/input/task3covid/task3_results_summary.xlsx\",index=False).dropna()\nselected_papers_task3=pd.read_csv('/kaggle/input/task3-results/task3_results.csv')\n\n# Select query or subtask field\nquery_subtask=\"Queries\"\n# query_subtask=\"Subtask mapping\"\n\n# Select summary or original text field\n# summary_field=\"summary\"\nsummary_field=\"Text\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data preparation"},{"metadata":{"trusted":true},"cell_type":"code","source":"selected_papers_task3=selected_papers_task3.drop_duplicates(subset=[query_subtask,'cord_uid'])\nselected_papers_task3[query_subtask]=selected_papers_task3[query_subtask].apply(lambda x:preprocess_sentence(x))\n\ndata=data[~data['Name'].isin(['TITLE','ABSTRACT'])]\ndata=data.drop_duplicates(subset =summary_field)\nmeta_df_title_abstract=data\nlen1=meta_df_title_abstract.shape[0]\nlist1=list(range(len1))\nmeta_df_title_abstract['pid']=list1\nmeta_df_title_abstract.head()\n# meta_df_title_abstract['summary_preprocessed']=meta_df_title_abstract['Text'].apply(lambda x:tokenize.sent_tokenize(x))\n# new_data_sent=meta_df_title_abstract['summary_preprocessed'].apply(pd.Series).reset_index().melt(id_vars='index').dropna()[['index', 'value']].set_index('index')\n# new_data_sent=new_data_sent.merge(meta_df_title_abstract[['cord_uid', 'lsid', 'gsid', 'Name', 'Text', 'Subtype', 'summary', 'pid']],right_index=True,left_index=True,how='left')\nmeta_df_title_abstract['wrd_cnt']=meta_df_title_abstract[summary_field].str.split().str.len()\nnew_data_sent_strip=meta_df_title_abstract[meta_df_title_abstract['wrd_cnt']>30]\nprint(\"wrd cnt > 30 \" + str(new_data_sent_strip.shape))\nnew_data_sent_strip=new_data_sent_strip[new_data_sent_strip['wrd_cnt']<550]\nprint(\"wrd cnt < 600 \" + str(new_data_sent_strip.shape))\n# new_data_sent_strip['value_edit']=new_data_sent_strip[summary_field].apply(lambda x:preprocess_sentence(x))\nnew_data_sent_strip[summary_field]=new_data_sent_strip[summary_field].apply(lambda x:preprocess_sentence(x))\n\nquery_list=selected_papers_task3[query_subtask].unique().tolist()\nnew_data_sent_strip=new_data_sent_strip.reset_index()\nsummaries=new_data_sent_strip[summary_field].tolist()\nComp_reserch_data=pd.read_csv('/kaggle/input/CORD-19-research-challenge/metadata.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create embedding for queries and summaries "},{"metadata":{"trusted":true},"cell_type":"code","source":"# query_text=['What is known about transmission, incubation, and environmental stability? What do we know about natural history, transmission, and diagnostics for the virus? What have we learned about infection prevention and control?',\n# 'Range of incubation periods for the disease in humans (and how this varies across age and health status) and how long individuals are contagious, even after recovery.',\n# 'Prevalence of asymptomatic shedding and transmission',\n# 'Seasonality of transmission of covid corona virus.',\n# 'Physical science of the coronavirus (e.g., charge distribution, adhesion to hydrophilic/phobic surfaces, environmental survival to inform decontamination efforts for affected areas and provide information about viral shedding)',\n# 'Disease models, including animal models for infection, disease and transmission',\n# 'Immune response and immunity',\n# 'Role of the environment in transmission',\n# 'Effectiveness of personal protective equipment (PPE) and its usefulness to reduce risk of transmission in health care and community settings',\n# 'Effectiveness of movement control strategies to prevent secondary transmission in health care and community settings',\n# 'Persistence of virus on surfaces of different materials (e,g., copper, stainless steel, plastic).']\n\nimport pickle\n\nquery_embedding=model.encode(query_list,show_progress_bar=False)\nsumm_embedding=model.encode(summaries,show_progress_bar=False)\n\nwith open('/kaggle/working/query_embedding_sent.pickle', 'wb') as handle:\n    pickle.dump(query_embedding, handle)\nprint(len(query_embedding))\nprint(query_embedding[0].shape)\n\nwith open('/kaggle/working/embeddings37912.pickle', 'wb') as handle:\n    pickle.dump(summ_embedding, handle)\nprint(len(summ_embedding))\nprint(summ_embedding[0].shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Run Similarity test"},{"metadata":{"trusted":true},"cell_type":"code","source":"import scipy.spatial\nnew_frame=pd.DataFrame(columns=['query','cord_uid','cord_uid_index','summary','similarity'])\n\nfor k in range(len(query_list)):\n    query=query_list[k]\n    query_emb=list(query_embedding[k])\n    cord_id_index=selected_papers_task3.index[selected_papers_task3[query_subtask]==query].tolist()\n    cord_id_list=[]\n    for j in cord_id_index:\n        cid=selected_papers_task3.loc[j,'cord_uid']\n        cord_id_list.append(cid)\n    cord_id_list_summ=[]\n    cord_id_list_emb=[]\n    for j in cord_id_list:\n        ind_list=new_data_sent_strip.index[new_data_sent_strip['cord_uid']==j].tolist()\n        for p in ind_list:\n            text=new_data_sent_strip.loc[p,'summary']\n            cord_id_list_summ.append(text)\n            summm_embed=list(summ_embedding[p])\n            cord_id_list_emb.append(summm_embed)\n    distances = scipy.spatial.distance.cdist([query_emb], cord_id_list_emb, \"cosine\")[0]\n    results = zip(range(len(distances)), distances)\n    results = sorted(results, key=lambda x: x[1])\n    closest_n = min(len(cord_id_list_emb),5)       \n    for idx, distance in results[0:closest_n]:\n        text1=cord_id_list_summ[idx]\n        cord_uid1=new_data_sent_strip.index[new_data_sent_strip['summary']==text1].tolist()[0]\n        cid=new_data_sent_strip.loc[cord_uid1,'cord_uid']\n        val=1-distance\n        new_frame=new_frame.append({'query':query,'cord_uid':cid,'cord_uid_index':cord_uid1,'summary':text1,'similarity':val},ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Display results"},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import display, HTML\n#display(HTML(all_search.to_html()))\nfor query_id in range(len(query_list)):\n    display(HTML('<font size=\"5\" color=\"blue\"> <b> Query Searched : </b> </font><p> <font size=\"4\">'+query_list[query_id]+'</font><p>'))\n    new_frame1=new_frame[new_frame['query']==query_list[query_id]].drop(columns=['query'])\n    new_frame1=new_frame1.merge(Comp_reserch_data[['cord_uid',  'title', 'license', 'publish_time', 'authors', 'journal']],on=['cord_uid'],how='inner')\n    new_frame1=new_frame1[['similarity','summary','cord_uid','title', 'license', 'publish_time', 'authors', 'journal']]\n    display(HTML(new_frame1.style.set_properties(subset=['summary'], \\\n                                             **{'font-weight': 'bold','font-size': '9pt','text-align':\"left\",'background-color': 'lightgrey','color': 'black'}).set_table_styles(\\\n                                             [dict(selector='th', props=[('text-align', 'left'),('font-size', '12pt'),('background-color', 'skyblue'),('border-style','solid'),('border-width','1px')])]).hide_index().render()))\n\n    display(HTML(\"-------End-----\"*15))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Done\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}