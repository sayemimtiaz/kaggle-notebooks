{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom IPython.display import display\n\nimport matplotlib.pyplot as plt \nimport re\nimport string\n\nimport nltk\nfrom nltk.tokenize import sent_tokenize\nfrom nltk.corpus import words\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.stem import PorterStemmer\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nfrom nltk.sentiment.util import *\nnltk.download('stopwords')\nnltk.download('vader_lexicon')\nfrom collections import Counter\n\nfrom matplotlib import pyplot as plt\nfrom matplotlib import ticker\nimport seaborn as sns\nimport plotly.express as px\n\nsns.set(style=\"darkgrid\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Importing the Dataset**\n","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import os\nos.listdir('/kaggle/input/')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/nigeria-endsars-tweets/NigeriaEndSars data.csv\")\ndf.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"let's check the shape of the dataframe","metadata":{}},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"let's streamline the needed columns","metadata":{}},{"cell_type":"code","source":"needed_columns=['username','date','content']\ndf=df[needed_columns]\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Picking out the tweet texts","metadata":{}},{"cell_type":"code","source":"contents=df.content\ncontents","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Removing URLs from tweets","metadata":{}},{"cell_type":"code","source":"remove_url=lambda x:re.sub(r'http\\S+','',str(x))\ncontents_lr=contents.apply(remove_url)\ncontents_lr","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Converting all tweets to lowercase","metadata":{}},{"cell_type":"code","source":"to_lower=lambda x: x.lower()\ncontents_lr_lc=contents_lr.apply(to_lower)\ncontents_lr_lc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Removing punctuations","metadata":{}},{"cell_type":"code","source":"remove_puncs= lambda x:x.translate(str.maketrans('','',string.punctuation))\ncontents_lr_lc_np=contents_lr_lc.apply(remove_puncs)\ncontents_lr_lc_np","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"Removing stopwords","metadata":{}},{"cell_type":"code","source":"more_words=['say','going','like','U','u','hey','#epitwitter','amp',]\nstop_words=set(stopwords.words('english')) \nstop_words.update(more_words)\nremove_words=lambda x: ' '.join([word for word in x.split() if word not in stop_words]) \ncontents_lr_lc_np_ns=r=contents_lr_lc_np.apply(remove_words)\ncontents_lr_lc_np_ns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"words_list=[word for line in contents_lr_lc_np_ns for word in line.split()]\nwords_list[:5]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"word_counts=Counter(words_list).most_common(50)\nword_df=pd.DataFrame(word_counts)\nword_df.columns=['word','frq']\ndisplay(word_df.head(5))\n# px=import plotly.express\npx.bar(word_df,x='word',y='frq',title='Most common words')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"put the Cleaned text in main dataframe","metadata":{}},{"cell_type":"code","source":"display(df.head(5))\ndf.content=contents_lr_lc_np_ns\ndisplay(df.head(5))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"addtional cleaning","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"def clean_content(content):\n    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n    and remove words containing numbers.'''\n    content = re.sub('\\[.*?\\]', '', content)\n    content = re.sub('https?://\\S+|www\\.\\S+', '', content)\n    content = re.sub('<.*?>+', '', content)\n    content = re.sub('[%s]' % re.escape(string.punctuation), '', content)\n    content = re.sub('\\n', '', content)\n    content = re.sub('\\w*\\d\\w*', '', content)\n    return content\ndf['content'] = df['content'].apply(lambda x: clean_content(x))\ndisplay(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove_emoji(content):\n    emoji_pattern = re.compile(\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                           u\"\\U00002702-\\U000027B0\"\n                           u\"\\U000024C2-\\U0001F251\"\n                           \"]+\", flags=re.UNICODE)\n    return emoji_pattern.sub(r'', content)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['content']=df['content'].apply(lambda x: remove_emoji(x))\ndisplay(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Sentiment Analysis**","metadata":{}},{"cell_type":"markdown","source":"Getting the polarity scores for each tweet","metadata":{}},{"cell_type":"code","source":"sid=SentimentIntensityAnalyzer()\nps=lambda x:sid.polarity_scores(x)\nsentiment_scores=df.content.apply(ps)\nsentiment_scores","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentiment_df=pd.DataFrame(data=list(sentiment_scores))\ndisplay(sentiment_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Labeling the scores based on the compound polarity value","metadata":{}},{"cell_type":"code","source":"labelize=lambda x:'neutral' if x==0 else('positive' if x>0 else 'negative')\nsentiment_df['label']=sentiment_df.compound.apply(labelize)\ndisplay(sentiment_df.head(10))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"join the two data frames","metadata":{}},{"cell_type":"code","source":"display(df.head(5))\ndata=df.join(sentiment_df.label)\ndisplay(data.head(5))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Plotting the sentiment score counts","metadata":{}},{"cell_type":"code","source":"counts_df=data.label.value_counts().reset_index()\ndisplay(counts_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8,5)) \nsns.barplot(x='index',y='label',data=counts_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"group number of counts by\n* date\n* positive,neutral,negative","metadata":{}},{"cell_type":"code","source":"data_agg=data[['username','date','label']]\ndisplay(data_agg.head(5))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_agg.columns=['date','label','counts']\ndisplay(data_agg.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_agg=data_agg.reset_index()\ndisplay(data_agg.head(5))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from wordcloud import WordCloud","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cut_content = \" \".join(df.content)\nmax_words=100\nword_cloud = WordCloud(\n                    background_color='white',\n                    stopwords=set(stop_words),\n                    max_words=max_words,\n                    max_font_size=30,\n                    scale=5,\n    colormap='magma',\n                    random_state=1).generate(cut_content)\nfig = plt.figure(1, figsize=(50,50))\nplt.axis('off')\nplt.title('Word Cloud for Top '+str(max_words)+' words with # ENDSars on Twitter\\n', fontsize=100,color='blue')\nfig.subplots_adjust(top=2.3)\nplt.imshow(word_cloud)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}