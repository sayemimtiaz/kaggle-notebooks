{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.over_sampling import RandomOverSampler\n\nfrom sklearn.pipeline import Pipeline\nfrom imblearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder, MinMaxScaler\nfrom sklearn.compose import ColumnTransformer\n\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, RandomizedSearchCV\n\nfrom sklearn.metrics import recall_score\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"att = pd.read_csv('../input/ibm-hr-analytics-attrition-dataset/WA_Fn-UseC_-HR-Employee-Attrition.csv')\natt.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"att.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"attFeatures = []\nfor i in att.columns:\n    attFeatures.append([i, att[i].nunique(), att[i].drop_duplicates().values])\npd.DataFrame(attFeatures, columns = ['Features', 'Unique Number', 'Values'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Preprocessing Scheme**\n* OneHotEncoding: BusinessTravel, Department, EducationField, Gender, JobRole, MaritalStatus, OverTime\n* The rest will be pass through."},{"metadata":{"trusted":true},"cell_type":"code","source":"att['Attrition'] = np.where(att['Attrition'] == 'Yes', 1, 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*I define number **1 is Yes, means resign** and number **0 is No, means stay**.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"att.drop(columns=['EmployeeCount', 'Over18', 'StandardHours'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*I drop these columns because it's only has one value for all rows.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"transformer = ColumnTransformer([\n    ('one hot', OneHotEncoder(drop = 'first'), ['BusinessTravel', 'Department', 'EducationField', 'Gender',\n                                                'JobRole', 'MaritalStatus', 'OverTime']),\n], remainder = 'passthrough')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"att['Attrition'].value_counts()/att.shape[0]*100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Indicated imbalance data*"},{"metadata":{},"cell_type":"markdown","source":"* *0 = Stay*\n* *1 = Resign*\n\n        - TN: Predicted: Stay and Actual: Stay\n        - TP: Predicted: Resign and Actual: Resign\n        - FP: Predicted: Resign and Actual: Stay\n        - FN: Predicted: Stay and Actual: Resign\n\n*From this matrix, I choose to push the FN or recall score to anticipate the employees not to resign because of the prediction is wrong.*"},{"metadata":{},"cell_type":"markdown","source":"**Splitting Data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = att.drop('Attrition', axis = 1)\ny = att['Attrition']\n\nX.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X,y,\n                                                   stratify = y,\n                                                   test_size = 0.3,\n                                                   random_state = 3131)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*I use 0.3 as default score for test_size and X.shape for random_state so the data will be devided equally.*"},{"metadata":{},"cell_type":"markdown","source":"# Modeling"},{"metadata":{},"cell_type":"markdown","source":"**Define Model**\n- I test with 4 models to find the best model:\n\n    * Logistic Regression\n    * Decision Tree Classifier\n    * K-Nearest Neighbor\n    * Random Forest Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"logreg = LogisticRegression()\ntree = DecisionTreeClassifier(random_state = 3131)\nknn = KNeighborsClassifier()\nrf = RandomForestClassifier(random_state = 3131)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Cross Validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"logreg_pipe = Pipeline([('transformer', transformer), ('logreg', logreg)])\ntree_pipe = Pipeline([('transformer', transformer), ('tree', tree)])\nknn_pipe = Pipeline([('transformer', transformer), ('scale', MinMaxScaler()), ('knn', knn)])\nrf_pipe = Pipeline([('transformer', transformer), ('rf', rf)])\n\ndef model_evaluation(model, metric):\n    skfold = StratifiedKFold(n_splits = 5)\n    model_cv = cross_val_score(model, X_train, y_train, cv = skfold, scoring = metric)\n    return model_cv\n\nlogreg_pipe_cv = model_evaluation(logreg_pipe, 'recall')\ntree_pipe_cv = model_evaluation(tree_pipe, 'recall')\nknn_pipe_cv = model_evaluation(knn_pipe, 'recall')\nrf_pipe_cv = model_evaluation(rf_pipe, 'recall')\n\nfor model in [logreg_pipe, tree_pipe, knn_pipe, rf_pipe]:\n    model.fit(X_train, y_train)\n    \nscore_mean = [logreg_pipe_cv.mean(), tree_pipe_cv.mean(), knn_pipe_cv.mean(), rf_pipe_cv.mean()]\nscore_std = [logreg_pipe_cv.std(), tree_pipe_cv.std(), knn_pipe_cv.std(), rf_pipe_cv.std()]\nscore_recall_score = [recall_score(y_test, logreg_pipe.predict(X_test)),\n            recall_score(y_test, tree_pipe.predict(X_test)), \n            recall_score(y_test, knn_pipe.predict(X_test)), \n            recall_score(y_test, rf_pipe.predict(X_test))]\nmethod_name = ['Logistic Regression', 'Decision Tree Classifier', 'KNN Classifier', 'Random Forest Classifier']\ncv_summary = pd.DataFrame({\n    'method': method_name,\n    'mean score': score_mean,\n    'std score': score_std,\n    'recall score': score_recall_score\n})\ncv_summary","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*From this method, I will choose Decision Tree Classifier because it has the highest recall score. But overall, the score still not good enough to do a prediction. While I process the data, it already indicates that the data is imbalanced. I decide to handle it using Under Sampling and Over Sampling.*"},{"metadata":{},"cell_type":"markdown","source":"# Handling Imbalance"},{"metadata":{},"cell_type":"markdown","source":"### UnderSampling"},{"metadata":{},"cell_type":"markdown","source":"**RandomUnderSampler Model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"rus = RandomUnderSampler(random_state = 3131)\nX_under, y_under = rus.fit_resample(X_train, y_train) \n\nlogreg_pipe_under = Pipeline([('transformer', transformer), ('rus', rus), ('logreg', logreg)])\ntree_pipe_under = Pipeline([('transformer', transformer), ('rus', rus), ('tree', tree)])\nknn_pipe_under = Pipeline([('transformer', transformer), ('scale', MinMaxScaler()), ('rus', rus), ('knn', knn)])\nrf_pipe_under = Pipeline([('transformer', transformer), ('rus', rus), ('rf', rf)])\n\ndef model_evaluation(model, metric):\n    skfold = StratifiedKFold(n_splits = 5)\n    model_cv = cross_val_score(model, X_train, y_train, cv = skfold, scoring = metric)\n    return model_cv\n\nlogreg_under_cv = model_evaluation(logreg_pipe_under, 'recall') \ntree_under_cv = model_evaluation(tree_pipe_under, 'recall')\nknn_under_cv = model_evaluation(knn_pipe_under, 'recall')\nrf_under_cv = model_evaluation(rf_pipe_under, 'recall')\n\nfor model in [logreg_pipe_under, tree_pipe_under, knn_pipe_under, rf_pipe_under]:\n    model.fit(X_train, y_train)\n    \nscore_mean = [logreg_under_cv.mean(), tree_under_cv.mean(), knn_under_cv.mean(),\n              rf_under_cv.mean()]\nscore_std = [logreg_under_cv.std(), tree_under_cv.std(), knn_under_cv.std(),\n             rf_under_cv.std()]\nscore_recall_score = [recall_score(y_test, logreg_pipe_under.predict(X_test)),\n            recall_score(y_test, tree_pipe_under.predict(X_test)), \n            recall_score(y_test, knn_pipe_under.predict(X_test)), \n            recall_score(y_test, rf_pipe_under.predict(X_test))]\nmethod_name = ['Logistic Regression UnderSampling', 'Decision Tree Classifier UnderSampling',\n              'KNN Classifier UnderSampling', 'Random Forest Classifier UnderSampling']\nunder_summary = pd.DataFrame({\n    'method': method_name,\n    'mean score': score_mean,\n    'std score': score_std,\n    'recall score': score_recall_score\n})\nunder_summary","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*The score looks good rather than before. From this Under Sampling, I will choose Decision Tree Classifier because it has the highest recall score.*"},{"metadata":{},"cell_type":"markdown","source":"### OverSampling"},{"metadata":{},"cell_type":"markdown","source":"**RandomOverSampler Model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"ros = RandomOverSampler(random_state = 3131)\nX_over, y_over = ros.fit_resample(X_train, y_train) \n\nlogreg_pipe_over = Pipeline([('transformer', transformer), ('ros', ros), ('logreg', logreg)])\ntree_pipe_over = Pipeline([('transformer', transformer), ('ros', ros), ('tree', tree)])\nknn_pipe_over = Pipeline([('transformer', transformer), ('scale', MinMaxScaler()), ('ros', ros), ('knn', knn)])\nrf_pipe_over = Pipeline([('transformer', transformer), ('ros', ros), ('rf', rf)])\n\ndef model_evaluation(model, metric):\n    skfold = StratifiedKFold(n_splits = 5)\n    model_cv = cross_val_score(model, X_train, y_train, cv = skfold, scoring = metric)\n    return model_cv\n\nlogreg_over_cv = model_evaluation(logreg_pipe_over, 'recall') \ntree_over_cv = model_evaluation(tree_pipe_over, 'recall')\nknn_over_cv = model_evaluation(knn_pipe_over, 'recall')\nrf_over_cv = model_evaluation(rf_pipe_over, 'recall')\n\nfor model in [logreg_pipe_over, tree_pipe_over, knn_pipe_over, rf_pipe_over]:\n    model.fit(X_train, y_train)\n    \nscore_mean = [logreg_over_cv.mean(), tree_over_cv.mean(), knn_over_cv.mean(),\n              rf_over_cv.mean()]\nscore_std = [logreg_over_cv.std(), tree_over_cv.std(), knn_over_cv.std(),\n             rf_over_cv.std()]\nscore_recall_score = [recall_score(y_test, logreg_pipe_over.predict(X_test)),\n            recall_score(y_test, tree_pipe_over.predict(X_test)), \n            recall_score(y_test, knn_pipe_over.predict(X_test)), \n            recall_score(y_test, rf_pipe_over.predict(X_test))]\nmethod_name = ['Logistic Regression OverSampling', 'Decision Tree Classifier OverSampling',\n              'KNN Classifier OverSampling', 'Random Forest Classifier OverSampling']\nover_summary = pd.DataFrame({\n    'method': method_name,\n    'mean score': score_mean,\n    'std score': score_std,\n    'recall score': score_recall_score\n})\nover_summary","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Now, the score getting worse again. The only one who stands out from the others. It's Logistic Regression using Over Sampling method. The recall score is the highest of other models. The rest models indicates underfitting.*"},{"metadata":{},"cell_type":"markdown","source":"*Based on 3 methods, Cross Validation, Under Sampling, and Over Sampling, I pick Logistic Regression as the most stable model and using Over Sampling method, and continue to HyperParameter Tuning process.*"},{"metadata":{},"cell_type":"markdown","source":"# HyperParam Tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"estimator = Pipeline([\n    ('transformer', transformer),\n    ('ros', ros),\n    ('model', logreg)\n])\n\nhyperparam_space = {\n    'model__C': [100, 10, 1, 0.1, 0.01, 0.001],\n    'model__solver': ['liblinear', 'newton-cg', 'lbfgs'],\n    'model__max_iter': [50, 100, 150, 200],\n    'model__random_state': [3131]\n}\n\nrandom = RandomizedSearchCV(\n                estimator,\n                param_distributions = hyperparam_space,\n                cv = StratifiedKFold(n_splits = 5),\n                scoring = 'recall',\n                n_iter = 10,\n                n_jobs = -1)\n\nrandom.fit(X_train, y_train)\n\nprint('best score', random.best_score_)\nprint('best param', random.best_params_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After HyperParameter Tuning process, the score is getting higher, it means that tuning process can improve the model."},{"metadata":{},"cell_type":"markdown","source":"# Compairing Result"},{"metadata":{"trusted":true},"cell_type":"code","source":"estimator.fit(X_train, y_train)\ny_pred_estimator = estimator.predict(X_test)\nrecall_estimator = recall_score(y_test, y_pred_estimator)\n\nrandom.best_estimator_.fit(X_train, y_train)\ny_pred_random = random.best_estimator_.predict(X_test)\nrecall_best_estimator = recall_score(y_test, y_pred_random)\n\nscore_list = [recall_estimator, recall_best_estimator]\nmethod_name = ['Logistic Regression OverSampling Before Tuning', 'Logistic Regression OverSampling After Tuning']\nbest_summary = pd.DataFrame({\n    'method': method_name,\n    'score': score_list\n})\nbest_summary","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So far, this is the best model that I got for predicting attrition in this case."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}