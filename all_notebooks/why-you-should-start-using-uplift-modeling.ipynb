{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"![](https://i.ibb.co/4PFKrfw/cover-03.jpg)","metadata":{}},{"cell_type":"markdown","source":"# I. Intro:\n- üí°You can also make your own experiment/research with this project, simply search for **'XGBClassifier()'**, and modify it with other algorithms available out there, or take a look at the **'future research'** section in the end of this project.\n- üëâThis project is an experiment for this research http://ijair.id/index.php/ijair/article/view/169/pdf\n- üëâPublished in the International Journal of Artificial Inteligence.\n- üëâRanked 2 in Science & Technology Index Indonesia.\n- üëâIn a nutshell, this project compares the [predictive & prescriptive](https://insights.principa.co.za/4-types-of-data-analytics-descriptive-diagnostic-predictive-prescriptive) capabilities of a mainstream [Employee Turnover Prediction (ETP)](https://www.researchgate.net/publication/328796091_Employee_Turnover_Prediction_with_Machine_Learning_A_Reliable_Approach) VS Employee Uplift Modeling (ETU) with the XGBoost algorithm.\n\n\n## Abstract:\n\n**i. ‚ùìBackground:** Employee turnover is the loss of talent in the workforce that can be costly for a company. Uplift modeling is one of several prescriptive methods available in machine learning models that not only predict an outcome but also prescribe a solution. Recent studies are focusing on the conventional predictive models (binary classification) to predict employee turnover rather than uplift modeling.\n\n**ii. üéØAim:** In this research, we analyze whether the Uplift Modeling has better performance than the conventional predictive model in solving employee turnover.\n\n**iii. ‚öôÔ∏èMethodology:** Performance comparison between the two methods was carried out by experimentation using two synthetic datasets and one real dataset. XGBoost is used as the machine learning algorithm for both models in this experiment.\n\n**iv. ‚úîÔ∏èResults:** After observing the 6 Qini curves, the results show that despite the ETP model yields an average prediction accuracy of 84%; it only yields a success rate of 50% to target the right employee with a retention program on the three datasets. By contrast, the uplift model only yields an average accuracy of 67% but yields a consistent success rate of 100% in targeting the right employee with a retention program.\n\n## Step by step\n1. üìäThree datasets are used in this project: [Dataset-1](https://www.kaggle.com/giripujar/hr-analytics), [Dataset-2](https://www.kaggle.com/pavansubhasht/ibm-hr-analytics-attrition-dataset), and [Dataset-3](https://www.kaggle.com/davinwijaya/employee-turnover)\n2. üé∞[XGBoost](https://machinelearningmastery.com/gentle-introduction-xgboost-applied-machine-learning/) is used in this project as the machine learning algorithm for both models (ETP & ETU)\n3. ü§ñETP Model just predict [employee's turnover](https://smallbusiness.chron.com/employee-turnover-definitions-calculations-11611.html#:~:text=Employee%20turnover%20refers%20to%20the,to%2Dhire%20for%20budget%20purposes.) (turnover or stay)\n4. ü§ñETU model predicts  employee's [uplift category](https://www.predictiveanalyticsworld.com/machinelearningtimes/uplift-modeling-making-predictive-models-actionable/8578/) (Sure things, persuadables, lost causes, or sleeping dogs/do-not-disturbs)\n5. üîéPredictive performances of both models are evaluated with the [Accuracy package from Sci-kit Learn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)\n6. üèÉETP Model gives prescription by ranking the employee based on its risk of quitting (predicted probability)\n7. üìàETU Model gives prescription by ranking the employee based on its uplift score (in this case I use [LGWUM](https://www.worldscientific.com/doi/abs/10.1142/S0219622019500172)'s formulation)\n8. üìâPrescriptive performances of both models are evaluated with [Qini Curve](https://pdfs.semanticscholar.org/147b/32f3d56566c8654a9999c5477dded233328e.pdf?_ga=2.266187788.2072205534.1599377562-943609542.1599377562)\n\n## Acknowledgement\nüôè I also thank Giri Pujar, Pavan Subhash, and Eduard Babushkin for sharing the datasets used in this project.\nMoreover, this project is made by [me](linkedin.com/in/wijayadavin/) under [CC BY-NC-SA 4.0 common license](https://creativecommons.org/licenses/by-nc-sa/4.0/). Feel free to use or modify it for your personal use.\n\nü§ì If you write an article, please cite with the citation file from [this page](https://ijair.id/index.php/ijair/rt/captureCite/169/0) with your [Mendeley](https://www.mendeley.com/guides/desktop/02-adding-documents) or as shown below (for IEEE style):\n\n#### [1] D. Wijaya, J. H. DS, S. Barus, B. Pasaribu, L. I. Sirbu, and A. Dharma, ‚ÄúUplift modeling VS conventional predictive model: A reliable machine learning model to solve employee turnover,‚Äù Int. J. Artif. Intell. Res. Vol 5, No 1 Artic. Press, 2021, doi: 10.29099/ijair.v4i2.169.\n","metadata":{}},{"cell_type":"markdown","source":"# II. Employee Turnover Uplift (ETU):\nEmployee Turnover Uplift is simply a model to predict and solve employee turnover by using the [Uplift Modeling](https://en.wikipedia.org/wiki/Uplift_modelling) technique.\n![](https://storage.googleapis.com/kagglesdsdata/datasets%2F507628%2F1467607%2FUplift%20framework-15.jpg?GoogleAccessId=databundle-worker-v2@kaggle-161607.iam.gserviceaccount.com&Expires=1599849266&Signature=mXR4h60oO9jOW7FhrFYT%2FovpRjRJtNRiAGpyJftCX5UA%2Fcw972L4JTxSzqElFliGc5HH8%2BqzRBmKLDKWxUlvLkQVPnhS4OQbI5Yjt6xaO233qdDagKAbao%2BDtlMo%2FmNiIqN1rhBWmlYnOzXQHsB83kLNPA0yy4eYy5baGd0t3jOzLoflNc341XQo3dZWLebkJiYb9IUQAO3qT8Q0nhh%2FIInm6FGDzZoJdw6EJHjRPd2nhglJH3E4KAoNQNBvl4KtYxNhI2P8%2BVIB%2Bey7qX4VDGNPvVFaTVAcTxLodgeS0gYod%2Bi86H3M14GT2uO38NFnHA%2BhfevQ49WeZPQZdo9%2Bmw%3D%3D)","metadata":{}},{"cell_type":"markdown","source":"![](https://i.ibb.co/XJp4Kwh/Uplift-framework-15.jpg)","metadata":{}},{"cell_type":"markdown","source":"Four target classes are generated by fitting the treatment status and employee turnover status as visualized in the left part of the image above:\n1. Control Non‚Äìresponders (CN): Employees who have not been treated with the retention program and left. We want to find the persuadables in this group.\n2. Control Responders (CR): Employees who have not been treated with the retention program and stay. We want to avoid targeting this group because we do not need to treat them to make them stay, and there is a possibility that some of them are Do-Not-Disturbs.\n3. Treated Non‚ÄìResponders (TN): Employees who have been treated with the retention program but left. We want to avoid treating this group because they will leave if treated, and there is a possibility that some of them are Do-Not-Disturbs that will stay if left untreated.\n4. Treated Responders (TR): Employees who have been treated with the retention program and stayed. We also want to find the persuadables in this group.\n\nTherefore, by combining CN with CR and TN with TR will result in C, and T, respectively. Thus by fitting the treated and control group from those four target classes as visualized in the right table will yield four possible theoretical uplift classes (also known as the four quadrants):\n\n1. Do-Not-Disturb (CRTN): Sometimes referred to as sleeping dogs, employees who will be driven away if treated.\n2. Lost Causes (CNTN): Employees who will leave whether treated or not.\n3. Sure Things (CRTR): Employees who will stay whether treated or not.\n4. Persuadables (CNTR): Employees who are willing to leave but will stay if treated. We want to target this group to reduce overall employee turnover in the company.\n\nAfter predicting the four target classes which are visualized with XGBoost, four probability results are generated. Where P is the probability result, thus uplift score is calculated with LGWUM (Lai's Generalized Weighted Uplift Method) as: \n> ## Uplift Score = P(CN/C)+ P(TR/T) ‚Äì P(CR/C) ‚Äì P(TN/T)","metadata":{}},{"cell_type":"markdown","source":"# III. Experimental Analysis\nThe workflow of this project will follow the machine-learning-pipeline below:","metadata":{}},{"cell_type":"markdown","source":"![](https://i.ibb.co/mFS1V74/pipeline-english-Artboard-53-01.jpg)","metadata":{}},{"cell_type":"markdown","source":"# 1. Setup\nFirst let's set up the environment and datasets","metadata":{}},{"cell_type":"code","source":"# Import the packages and libraries needed for this project\nimport matplotlib as mpl, matplotlib.pyplot as plt, \\\npandas as pd, seaborn as sns, xgboost as xgb, sklearn as sk\nfrom sklearn.metrics import accuracy_score, \\\nconfusion_matrix, multilabel_confusion_matrix\nfrom sklearn.model_selection import train_test_split","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking for package version\nprint(\"Matplotlib Version\", mpl.__version__)\nprint(\"Pandas Version\", pd.__version__)\nprint(\"Xgboost Version\", xgb.__version__)\nprint(\"Seaborn Version\", sns.__version__)\nprint(\"Sci-kit learn Version\", sk.__version__)","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import the three datasets\ndf_data_1 = pd.read_csv('/kaggle/input/hr-analytics/HR_comma_sep.csv')\ndf_data_2 = pd.read_csv('/kaggle/input/ibm-hr-analytics-attrition-dataset/WA_Fn-UseC_-HR-Employee-Attrition.csv')\ndf_data_3 = pd.read_csv('/kaggle/input/employee-turnover/turnover.csv', encoding = 'ISO-8859-1')\ndf_model_1 = df_data_1.copy()\ndf_model_2 = df_data_2.copy()\ndf_model_3 = df_data_3.copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Data Exploration","metadata":{}},{"cell_type":"markdown","source":"Now we've the datasets ready, let's check for null data.","metadata":{}},{"cell_type":"code","source":"# Explore dataset 1\ndf_data_1.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Explore dataset 2\ndf_data_2.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Explore dataset 3\ndf_data_3.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check for null.\ndisplay(df_data_1.isnull().values.any())\ndisplay(df_data_2.isnull().values.any())\ndisplay(df_data_3.isnull().values.any())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Good, there is no null data.","metadata":{}},{"cell_type":"markdown","source":"# 3. Data preprocessing","metadata":{}},{"cell_type":"code","source":"# Drop unwanted features (i.e. columns) that will be dropped.\ndrop_2 = ['EmployeeCount', 'EmployeeNumber', 'StandardHours', 'Over18']\ndf_model_2 = df_model_2.drop(drop_2,axis=1)\n\nprint('Deleting unwanted features...')\nprint(drop_2)\nprint('‚úîÔ∏èDeleted')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Rename all target features.\ndf_model_1 = df_model_1.rename(columns={'left': 'churn'})\ndf_model_2 = df_model_2.rename(columns={'Attrition': 'churn'})\ndf_model_3 = df_model_3.rename(columns={'event': 'churn'})\nprint(\"‚úîÔ∏è Rename target column names to 'churn'\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Rename all treatment features.\ndf_model_1 = df_model_1.rename(columns={'promotion_last_5years': 'treatment'})\ndf_model_2 = df_model_2.rename(columns={'OverTime': 'treatment'})\ndf_model_3 = df_model_3.rename(columns={'coach': 'treatment'})\nprint(\"‚úîÔ∏è Rename treatment column names to 'treatment'\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Explore the unique data in the 'selected features' (for the label encoding):\")\nstring1, string2, string3 = ['salary'], ['churn',\n                                         'treatment',\n                                         'BusinessTravel'], ['treatment']\n\nprint('\\nDataset 1:')\nfor col in string1:\n    print(col, df_model_1[col].unique())\n\nprint('\\nDataset 2:')\nfor col in string2:\n    print(col, df_model_2[col].unique())\n    \nprint('\\nDataset 3:')\nfor col in string3:\n    print(col, df_model_3[col].unique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Manually label encode the target (i.e. dependent variable) for dataset 1\ndf_model_1.salary = df_model_1.salary.map({'low': 0, 'medium': 1, 'high':2})\nprint(\"‚úîÔ∏è Label encoding the 'salary' feature in dataset 1\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Manually label encode the target and identified treatment (i.e. employee retention program) for dataset 2\ndf_model_2.churn = df_model_2.churn.map({'Yes': 1, 'No': 0})\ndf_model_2.treatment = df_model_2.treatment.map({'Yes': 0, 'No': 1})\n# Declaration BusinessTravel\ndf_model_2.BusinessTravel = df_model_2.BusinessTravel.map({'Non-Travel': 0,\n                                                           'Travel_Rarely': 1,\n                                                           'Travel_Frequently':2})\nprint(\"‚úîÔ∏è Label encoding the 'churn, treatment, & BusinessTravel' features in dataset 2\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Manually label encode the target and treatment for dataset 3\ndf_model_3.treatment = df_model_3.treatment.map({'yes': 0, 'no': 1, 'my head':2})\ndf_model_3 = df_model_3.loc[df_model_3.treatment <=1].reset_index(drop=True)\nprint(\"‚úîÔ∏è Label encoding the 'treatment' feature in dataset 3\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Secondly, let's turn the rest of the string/object data into integer with the magical get_dummies function (One hot encoding) from Pandas package, so we can feed the data into XGBoost. Moreover, I add another dataframe df_model_inverse that will be useful for later:","metadata":{}},{"cell_type":"code","source":"# One-Hot Encoding:\ndf_model_1, df_model_inverse_1 = pd.get_dummies(df_model_1), pd.get_dummies(df_model_1)\ndf_model_2, df_model_inverse_2 = pd.get_dummies(df_model_2), pd.get_dummies(df_model_2)\ndf_model_3, df_model_inverse_3 = pd.get_dummies(df_model_3), pd.get_dummies(df_model_3)\nprint(\"‚úîÔ∏è One-hot encoding\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's check the treatment's correlation to employee turnover:","metadata":{}},{"cell_type":"code","source":"def correlation_treatment(df:pd.DataFrame):\n    \"\"\"Function to calculate the treatment's correlation\n    \"\"\"\n    correlation = df[['treatment','churn']].corr(method ='pearson') \n    return(pd.DataFrame(round(correlation.loc['churn'] * 100,2)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"‚úîÔ∏èTreatment correlation in dataset 1:\", correlation_treatment(df_model_1).iloc[0,0])\nprint(\"\\n‚úîÔ∏èTreatment correlation in dataset 2:\", correlation_treatment(df_model_2).iloc[0,0])\nprint(\"\\n‚úîÔ∏èTreatment correlation in dataset 3:\", correlation_treatment(df_model_3).iloc[0,0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Good, now all of the treatment features are negatively correlated. For instance, when the treatment in dataset 1 (promotion last 5 years) is true, the employee churn tend to be reduced.\n\nWe will use the positive ones later at the end of this project. For now, let's add the four uplift category for each datasets:","metadata":{}},{"cell_type":"code","source":"def declare_target_class(df:pd.DataFrame):\n    \"\"\"Function for declare the target class\n    \"\"\"\n    #CN:\n    df['target_class'] = 0 \n    #CR:\n    df.loc[(df.treatment == 0) & (df.churn == 0),'target_class'] = 1 \n    #TN:\n    df.loc[(df.treatment == 1) & (df.churn == 1),'target_class'] = 2 \n    #TR:\n    df.loc[(df.treatment == 1) & (df.churn == 0),'target_class'] = 3 \n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Add the four target classes\ndf_model_1, df_model_2, df_model_3 = declare_target_class(df_model_1), \\\ndeclare_target_class(df_model_2), declare_target_class(df_model_3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Machine Learning Modeling","metadata":{}},{"cell_type":"markdown","source":"Finally we're ready to start the machine learning process:","metadata":{}},{"cell_type":"code","source":"def split_data(df_model:pd.DataFrame):\n    \"\"\"Split data into training data and testing data\n    \"\"\"\n    X = df_model.drop(['churn','target_class'],axis=1)\n    y = df_model.churn\n    z = df_model.target_class\n    X_train, X_test, \\\n    y_train, y_test, \\\n    z_train, z_test = train_test_split(X,\n                                       y,\n                                       z,\n                                       test_size=0.3,\n                                       random_state=42,\n                                       stratify=df_model['treatment'])\n    return X_train,X_test, y_train, y_test, z_train, z_test\n\n\ndef machine_learning(X_train:pd.DataFrame,\n                     X_test:pd.DataFrame,\n                     y_train:pd.DataFrame,\n                     y_test:pd.DataFrame,\n                     z_train:pd.DataFrame,\n                     z_test:pd.DataFrame):\n    \"\"\"Machine learning process consists of \n    data training, and data testing process (i.e. prediction) with XGBoost (XGB) Algorithm\n    \"\"\"\n    # prepare a new DataFrame\n    prediction_results = pd.DataFrame(X_test).copy()\n    \n    \n    # train the ETP model\n    model_tp \\\n    = xgb.XGBClassifier().fit(X_train.drop('treatment', axis=1), y_train)  \n    # prediction Process for ETP model \n    prediction_tp \\\n    = model_tp.predict(X_test.drop('treatment',axis=1))\n    probability__tp \\\n    = model_tp.predict_proba(X_test.drop('treatment', axis=1))\n    prediction_results['prediction_churn'] = prediction_tp\n    prediction_results['proba_churn'] = probability__tp[:,1]\n    \n    \n    # train the ETU model\n    model_etu \\\n    = xgb.XGBClassifier().fit(X_train.drop('treatment', axis=1), z_train)\n    # prediction Process for ETU model \n    prediction_etu \\\n    = model_etu.predict(X_test.drop('treatment', axis=1))\n    probability__etu \\\n    = model_etu.predict_proba(X_test.drop('treatment', axis=1))\n    prediction_results['prediction_target_class'] = prediction_etu\n    prediction_results['proba_CN'] = probability__etu[:,0] \n    prediction_results['proba_CR'] = probability__etu[:,1] \n    prediction_results['proba_TN'] = probability__etu[:,2] \n    prediction_results['proba_TR'] = probability__etu[:,3]\n    prediction_results['score_etu'] = prediction_results.eval('\\\n    proba_CN/(proba_CN+proba_CR) \\\n    + proba_TR/(proba_TN+proba_TR) \\\n    - proba_TN/(proba_TN+proba_TR) \\\n    - proba_CR/(proba_CN+proba_CR)')  \n    \n    # add the churn and target class into dataframe as validation data\n    prediction_results['churn'] = y_test\n    prediction_results['target_class'] = z_test\n    return prediction_results\n\n\ndef predict(df_model:pd.DataFrame):\n    \"\"\"Combining data split and machine learning process with XGB\n    \"\"\"\n    X_train, X_test, y_train, y_test, z_train, z_test = split_data(df_model)\n    prediction_results = machine_learning(X_train,\n                                          X_test,\n                                          y_train,\n                                          y_test,\n                                          z_train,\n                                          z_test)\n    print(\"‚úîÔ∏èPrediction succeeded\")\n    return prediction_results","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Machine Learning Modelling Process\nprint(\"Predicting dataset 1 ...\")\nprediction_results_1 = predict(df_model_1)\nprint(\"\\nPredicting dataset 2 ...\")\nprediction_results_2 = predict(df_model_2)\nprint(\"\\nPredicting dataset 3 ...\")\nprediction_results_3 = predict(df_model_3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Prediction results are stored in prediction_results_1, prediction_results_2, and prediction_results_3 for dataset 1, dataset 2, and dataset 3, respectively.","metadata":{}},{"cell_type":"code","source":"# Uncomment this line below to save the prediction result into an Excel file.\n# prediction_results_3.to_excel(\"output_prediction3.xlsx\")  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Evaluating predictive performance","metadata":{}},{"cell_type":"markdown","source":"Now let's evaluate the predictive performance:","metadata":{}},{"cell_type":"code","source":"def cm_evaluation(df:pd.DataFrame):\n    \"\"\"Confusion matrix evaluation\n    \"\"\"  \n    print(\"===================================\")\n    print(\"1. ETP's confusion matrix result:\")\n    confusion_etp = confusion_matrix(df['churn'], df['prediction_churn'])\n    df_confusion_etp = pd.DataFrame(confusion_etp, columns = ['True','False'], index = ['Positive','Negative'])\n    print(df_confusion_etp)\n    \n    print(\"-----------------------------------\")\n    \n    print(\"2. ETU's confusion matrix result:\")   \n    confusion_etu = multilabel_confusion_matrix(df['target_class'], df['prediction_target_class'])\n    print(\"a. CN's confusion matrix:\")  \n    df_cn = pd.DataFrame(confusion_etu[0], columns = ['True','False'], index = ['Positive','Negative'])\n    print(df_cn)\n    print(\"b. CR's confusion matrix:\") \n    df_cr = pd.DataFrame(confusion_etu[1], columns = ['True','False'], index = ['Positive','Negative'])\n    print(df_cr) \n    print(\"c. TN's confusion matrix:\")\n    df_tn = pd.DataFrame(confusion_etu[2], columns = ['True','False'], index = ['Positive','Negative'])\n    print(df_tn) \n    print(\"d. TR's confusion matrix:\") \n    df_tr = pd.DataFrame(confusion_etu[3], columns = ['True','False'], index = ['Positive','Negative'])\n    print(df_tr)\n    \n    print(\"===================================\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In [Confusion Matrix](https://towardsdatascience.com/understanding-confusion-matrix-a9ad42dcfd62), the True Positive and False Negative are the amount of successful predictions and the True Negative and False Positive are the amount of failed predictions. Therefore, let's generate the confusion matrices:","metadata":{}},{"cell_type":"code","source":"# Confusion Matrix Evaluation\nprint(\"‚úîÔ∏èDataset 1\")\ncm_evaluation(prediction_results_1)\nprint(\"\\n\\n‚úîÔ∏èDataset 2\")\ncm_evaluation(prediction_results_2)\nprint(\"\\n\\n‚úîÔ∏èDataset 3\")\ncm_evaluation(prediction_results_3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, let's calculate the accuracy result:","metadata":{}},{"cell_type":"code","source":"def accuracy_evaluation(df:pd.DataFrame):\n    \"\"\"Accuracy evaluation\n    \"\"\"\n    akurasi_cp = accuracy_score(df['churn'],\n                                df['prediction_churn'])\n    print('‚úîÔ∏èETP model accuracy: %.2f%%' % (akurasi_cp * 100.0))\n    \n    \n    akurasi_uplift = accuracy_score(df['target_class'],\n                                    df['prediction_target_class'])\n    print('‚úîÔ∏èETU model accuracy: %.2f%%' % (akurasi_uplift * 100.0))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Accuracy Evaluation Process.\nprint(\"Dataset 1\")\naccuracy_evaluation(prediction_results_1)\nprint(\"\\nDataset 2\")\naccuracy_evaluation(prediction_results_2)\nprint(\"\\nDataset 3\")\naccuracy_evaluation(prediction_results_3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Wow, seems like ETP models are much better than ETU models in terms of prediction accuracy. That makes sense anyway, because ETP models only predict two possible outcomes (The employee is turnover or stay), where ETU models predict four possible outcomes (Persuadables, Sure Things, Lost Causes, and Sleeping Dogs/Do-not-disturbs). But will ETP will also have a better performance in solving the employee turnover (prescriptive performance)? Let's find out.","metadata":{}},{"cell_type":"markdown","source":"# 6. Evaluating prescriptive performance","metadata":{}},{"cell_type":"markdown","source":"Now let's use the prediction results to solve the problem. As explained before, for ETP model employees are ranked by their turnover probability. Employees with the highest turnover probability will be targeted with a retention campaign (the treatment features declared before). On the other side, the ETU models are ranked by its uplift score with LGWUM's formulation.","metadata":{}},{"cell_type":"code","source":"def sorting_data(df:pd.DataFrame):\n    \"\"\"Function to sort data\n    \"\"\"\n    # Set up new DataFrames for ETP model and ETU model\n    df_c = pd.DataFrame({'n':[], 'target_class':[]})\n    df_u = df_c.copy()\n    df_c['target_class'] = df['target_class']\n    df_u['target_class'] = df['target_class']\n    \n    \n    # Add quantiles\n    df_c['n'] = df.proba_churn.rank(pct=True, ascending=False)\n    df_u['n'] = df.score_etu.rank(pct=True, ascending=False)\n    df_c['score'] = df['proba_churn']\n    df_u['score'] = df['score_etu']\n    \n    \n    # Ranking the data by deciles\n    df_c = df_c.sort_values(by='n').reset_index(drop=True)\n    df_u = df_u.sort_values(by='n').reset_index(drop=True)\n    df_c['model'], df_u['model'] = 'CP', 'Uplift'\n    return df_c, df_u\n\n\ndef calculating_qini(df:pd.DataFrame):\n    \"\"\"Function to measure the Qini value\n    \"\"\"\n    # Calculate the C, T, CR, and TR\n    C, T = sum(df['target_class'] <= 1), sum(df['target_class'] >= 2)\n    df['cr'] = 0\n    df['tr'] = 0\n    df.loc[df.target_class  == 1,'cr'] = 1\n    df.loc[df.target_class  == 3,'tr'] = 1\n    df['cr/c'] = df.cr.cumsum() / C\n    df['tr/t'] = df.tr.cumsum() / T\n    \n\n    # Calculate & add the qini value into the Dataframe\n    df['uplift'] = df['tr/t'] - df['cr/c']\n    df['random'] = df['n'] * df['uplift'].iloc[-1]\n    qini_coef= df['uplift'].sum(skipna = True) - df['random'].sum(skipna = True)\n    \n    # Print the Qini coefficient\n    print('‚úîÔ∏èQini coefficient = {} {}'.format(round(qini_coef, 2), '%'))\n    \n    # Add q0 into the Dataframe\n    q0 = pd.DataFrame({'n':0, 'uplift':0, 'target_class': None}, index =[0])\n    qini = pd.concat([q0, df]).reset_index(drop = True)\n    return qini\n\n\ndef merging_data(df_c:pd.DataFrame, df_u:pd.DataFrame):\n    \"\"\"Function to add the 'Model' column and merge the dataframe into one\n    \"\"\"\n    df_u['model'] = 'ETU'\n    df_c['model'] = 'ETP'\n    df = pd.concat([df_u, df_c]).sort_values(by='n').reset_index(drop = True)\n    return df\n\n\ndef plot_qini(df:pd.DataFrame):\n    \"\"\"Function to plot the qini curve\n    \"\"\"\n    print('\\nPlotting the qini curve...')\n    \n    # Define the data that will be plotted\n    order = ['ETU','ETP']\n    ax = sns.lineplot(x='n', y=df.uplift, hue='model', data=df,\n                      style='model', palette=['red','deepskyblue'],\n                      style_order=order, hue_order = order)\n    \n    \n    # Additional plot display settings\n    handles, labels = ax.get_legend_handles_labels()\n    plt.xlabel('Proportion targeted',fontsize=30)\n    plt.ylabel('Uplift',fontsize=30)\n    plt.subplots_adjust(right=1)\n    plt.subplots_adjust(top=1)\n    plt.legend(fontsize=30)\n    ax.tick_params(labelsize=24)\n    ax.legend(handles=handles[1:], labels=labels[1:])\n    ax.plot([0,1], [0,df.loc[len(df) - 1,'uplift']],'--', color='grey')\n    print('‚úîÔ∏èSuccessfully plot the qini curve')\n    return ax\n\n\ndef evaluation_qini(prediction_results:pd.DataFrame):\n    \"\"\"Function to combine all qini evaluation processes\n    \"\"\"\n    df_c, df_u = sorting_data(prediction_results)\n    print('ETP model (previous model):')\n    qini_c = calculating_qini(df_c)\n    print('\\nETU model (our proposed model):')\n    qini_u = calculating_qini(df_u)\n    qini = merging_data(qini_c, qini_u)\n    ax = plot_qini(qini)\n    return ax, qini","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Which model is successful or failed?\n\n### üî¢Quantitative measurement:\nNow let's calculate the Qini coefficient to measure which model is successful and failed.The higher the coefficient is, indicating a better benefit (in this case, the benefit is preventing employee turnover).But in this project we won't find which model is better or not, we just want to know which one is more reliable (i.e. consistently returning a good result). A successful model has a Qini coefficient above 0 (Give a benefit).\n\n### üìàQualitative measurement:\nAnother method to measure the performance qualitatively is by measuring the Qini curve (the red or blue line) in comparison with the random curve (the grey line). The higher the uplift value is and the smaller the proportion is, indicating a good performance. But again, in this project we just want to know which model yields a good result consistently.","metadata":{}},{"cell_type":"code","source":"# Qini evaluation results for DataSet 1 with negative treatment correlation\nax, qini_1 = evaluation_qini(prediction_results_1)\nplt.title('Qini Curve - Dataset 1',fontsize=20)\n\n\n# save into pdf:\n# plt.savefig('qini_1_n.pdf', bbox_inches='tight')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The Qini curve above shows that the ETU has a better uplift value than the random model. The random model is a straight line from 0 to 100% proportion targeted, this may  indicate the value of the uplift without using any model. By contrast, the ETP model failed to shows a good result above the random mode, therefore we could say that in this case ETP model failed to target the right employees.\n\nMoreover, the Qini coefficient is just the Gini coefficient version of Qini to compare A Model's Qini curve with the random model (i.e. without model). A positive Qini coefficient indicates that the model has succeeded to give a significant benefit.","metadata":{}},{"cell_type":"code","source":"# Qini evaluation results for DataSet 2 with negative treatment correlation\nax, qini_2 = evaluation_qini(prediction_results_2)\nplt.title('Qini Curve - Dataset 2',fontsize=20)\n\n\n# save into pdf:\n# plt.savefig('qini_2_n.pdf', bbox_inches='tight'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Well, now the ETP model is catching up and give a good result.","metadata":{}},{"cell_type":"code","source":"# Qini evaluation results for DataSet 3 with negative treatment correlation\nax, qini_3 = evaluation_qini(prediction_results_3)\nplt.title('Qini Curve - Dataset 3',fontsize=20)\n\n\n# save into pdf:\n# plt.savefig('qini_3_n.pdf', bbox_inches='tight')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In the Qini curve above, the ETP model even gives a worse result than not using any model (random model).\n\nSo far the success result are: ETU = 3 and ETP = 1.\n\nFurthermore, now we can use the df_model_inverse dataframes we prepared before, we will inverse the value (from 0 to 1, and 1 to 0):","metadata":{}},{"cell_type":"code","source":"# The process to inverse treatment's parameter\n# Thus also inverse the treatment's correlation from negative to positive\ndf_model_inverse_1.treatment = df_model_inverse_1.treatment.replace({0: 1, 1: 0})\ndf_model_inverse_2.treatment = df_model_inverse_2.treatment.replace({0: 1, 1: 0})\ndf_model_inverse_3.treatment = df_model_inverse_3.treatment.replace({0: 1, 1: 0})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Recalculate the treatment correlation\nprint(\"‚úîÔ∏èTreatment correlation in dataset 1 (inverted):\", correlation_treatment(df_model_inverse_1).iloc[0,0])\nprint(\"\\n‚úîÔ∏èTreatment correlation in dataset 2 (inverted):\", correlation_treatment(df_model_inverse_2).iloc[0,0])\nprint(\"\\n‚úîÔ∏èTreatment correlation in dataset 3 (inverted):\", correlation_treatment(df_model_inverse_3).iloc[0,0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Good, now the treatment features are positively correlated with employee turnover. This means, if we target the employees with this treatment, it's more likely that the employee turnover rate will be increased. So it'll be wise to use this treatment carefully. Okay, now let's repeat the prediction procedure once again:","metadata":{}},{"cell_type":"code","source":"# Add the target class feature to all three datasets\ndf_model_inverse_1, df_model_inverse_2, df_model_inverse_3 = declare_target_class(df_model_inverse_1), \\\ndeclare_target_class(df_model_inverse_2), declare_target_class(df_model_inverse_3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Do the prediction process once more time\nprediction_results_inverse_1 = predict(df_model_inverse_1)\nprediction_results_inverse_2 = predict(df_model_inverse_2)\nprediction_results_inverse_3 = predict(df_model_inverse_3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Qini evaluation results for DataSet 1 with positive treatment correlation\nax, qini_inverse_1 = evaluation_qini(prediction_results_inverse_1)\nplt.title('Qini Curve - Dataset 1',fontsize=20)\n\n\n# save into pdf:\n# plt.savefig('qini_1_p.pdf', bbox_inches='tight')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The Qini curve above shows that ETP and ETU are succeeded.","metadata":{}},{"cell_type":"code","source":"# qini evaluation results for DataSet 2 with positive treatment correlation\nax, qini_inverse_2 = evaluation_qini(prediction_results_inverse_2)\nplt.title('Qini Curve - Dataset 2',fontsize=20)\n\n\n# save into pdf:\n# plt.savefig('qini_2_p.pdf', bbox_inches='tight')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The Qini curve above shows that ETP is failed.","metadata":{}},{"cell_type":"code","source":"# Qini evaluation results for DataSet 3 with positive treatment correlation\nax, qini_inverse_3 = evaluation_qini(prediction_results_inverse_3)\nplt.title('Qini Curve - Dataset 3',fontsize=20)\n\n\n# save into pdf:\n# plt.savefig('qini_3_p.pdf', bbox_inches='tight')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The last Qini curve above shows that both Employee Turnover Uplift (ETU) and Employee Turnover Prediction (ETP) are succeeded.","metadata":{}},{"cell_type":"markdown","source":"# Conclusion\nEmployees with a high [turnover](https://en.wikipedia.org/wiki/Turnover_employment) risk do not necessarily need to be targeted with a retention program. The ETP model tends to target the wrong type of employees (e.g. Do-not-disturbs employees) that will leave the company if targeted and could be [costly](https://builtin.com/recruiting/cost-of-turnover) for the company/employeers. On the other side, the ETU model tends to target the right employees (Persuadables) and prevent unnecessary costs. The Qini curves show that the ETU model yields better uplift value than the ETP model in overall. In other words, the ETU model is more effective as a prescriptive analytics model than the ETP model.\n\nIn other words, despite the low prediction accuracy, the Uplift Modeling yields better results than the conventional Churn Prediction Model.\n\n# Future Research\nFuture research is needed to validate this research with:\n- other machine learning algorithms (e.g. Logistic Regression, Neural Network, ADA Boost, etc.),\n- other uplift strategies (e.g. Two-model Uplift, LWUM, Pessimistic Uplift, etc.),\n- other datasets (Student Performance, Customer, Promotion, etc.), and evaluation methods (e.g. Uplift values instead of Qini Curve).","metadata":{}}]}