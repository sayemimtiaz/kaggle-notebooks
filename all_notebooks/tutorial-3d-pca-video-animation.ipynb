{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":false,"_kg_hide-input":true},"cell_type":"code","source":"import os\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nfrom matplotlib import animation\nfrom sklearn.decomposition import PCA\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom mpl_toolkits.mplot3d import proj3d\nimport matplotlib.animation as animation\nfrom matplotlib.patches import FancyArrowPatch\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n\nurl = '../input/breast-cancer-wisconsin-data/data.csv'\ndf = pd.read_csv( url )\n\nrndperm = np.random.permutation(df.shape[0])\nD = df.iloc[rndperm, :]\n\n## Print the number of rows in the data set\ndf_rows, df_cols = df.shape\nprint('Table size : {} x {}'.format(df_rows, df_cols) )\n\nix_mn = [*range(0, 10, 1)]\n\ndef arr_shift(arr, shift):\n    return [i+shift for i in arr]\n\nclass_feat = ['Radius', 'Texture', 'Perimeter', 'Area', 'Smoothness', 'Compactness', 'Concavity', 'Concave points', 'Symmetry', 'Fractal dim.']\n\nle = LabelEncoder()                 # label encoding\nX, y = D.iloc[:, 2:], D[['diagnosis']]\ny = y.rename(columns={'diagnosis': 'Diagnosis'})\ny = le.fit_transform( y['Diagnosis'].values )\nif isinstance(y, pd.DataFrame):\n    y = y.values.ravel()\n    \nX_mn = X.iloc[:, ix_mn]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### $\\text{Table of Contents}$\n\n* [Introduction](#Introduction)\n* [Principal Components Analysis](#PCA)\n* [3D Visualization](#3D-data)\n* [Explanation](#Closure)\n\n### ${\\text{Abstract}} \\ :$\n\nThe notebook proposes a simple method for turning any boring presentation of data into a lively animation,\nusing **proj3d** and **Axes3D** from the [*mplot3d*](https://matplotlib.org/mpl_toolkits/mplot3d/api.html) library.\nSamples are taken from the Wisconsin Breast Cancer Dataset ([WBCD]( https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic) )).\n\nConsider the following 2d [biplot](https://en.wikipedia.org/wiki/Biplot#:~:text=Biplots%20are%20a%20type%20of,matrix%20to%20be%20displayed%20graphically.) which shows the PCA projection of the samples onto a 2D PC plane ($PCA: \\mathbb{R}^{10} \\rightarrow \\mathbb{R}^{2}$) :"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":false},"cell_type":"code","source":"# **************************************************************** #\n# ------------------------ 2D PCA scatter ------------------------ #\n# **************************************************************** #\n\nfrom sklearn.preprocessing import StandardScaler\n\n# In general, it's a good idea to scale the data prior to PCA.\nscaler = StandardScaler()\nscaler.fit(X_mn)\nX_mn = scaler.transform(X_mn)\npca = PCA()\nx_new = pca.fit_transform(X_mn)\n\ndef PCA_scatter(X, coeff, y_M, labels):\n    \n    n = coeff.shape[0]\n    xs, ys = X[:,0], X[:,1]             # zs = X[:,2]\n    scalex, scaley = 1.0/(xs.max() - xs.min()) , 1.0/(ys.max() - ys.min())\n    # scalez = 1.0/(zs.max() - zs.min()) <-- 3D of Z\n    \n    # ---------- Scatter color by class ----------- #\n    plt.scatter(xs[y_M] * scalex, ys[y_M] * scaley, c = 'orange', alpha=0.5) \n    plt.scatter(xs[1-y_M==True] * scalex, ys[1-y_M==True] * scaley, c = 'blue', alpha=0.5)\n    # plt.scatter(xs * scalex, ys * scaley, c = 'blue')\n\n    for i in range(n):\n        plt.arrow(0, 0, coeff[i,0], coeff[i,1], color = 'r',alpha = 0.5)\n        if labels is None:\n            plt.text(coeff[i,0]* 1.15, coeff[i,1] * 1.15, \"Var\"+str(i+1), color = 'g', ha = 'center', va = 'center')\n        else:\n            plt.text(coeff[i,0]* 1.15, coeff[i,1] * 1.15, labels[i], color = 'g', fontsize=12, ha = 'center', va = 'center')\n    \n    plt.xlabel(\"PC{}\".format(1))\n    plt.ylabel(\"PC{}\".format(2))\n    plt.grid(linestyle='-', linewidth=0.5)\n\n#Call the function. Use only the 2 PCs\ny_M, y_B = y==1, y==0           # Logical statement for Benign indication\n\npca_i = 2\n\nPCA_scatter(x_new[:, 0:pca_i], np.transpose(pca.components_[0:pca_i, :]), y_M, class_feat)\nplt.rcParams['figure.figsize'] = (12, 6)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The red **lines** denote the 10 original features (variables) projected after rescaling. Each feature lies in a direction that maximizes the original data's variance. Thereby, it can be seen that the *Concave points* feature maximizes the **1st PC** while the *Fractal dimension* contributes poorly to the **2nd PC**.\n\n* Consider the same procedure, but this time : $PCA: \\mathbb{R}^{10} \\rightarrow \\mathbb{R}^{3}$\n\n<img src=\"https://github.com/Daniboy370/Machine-Learning/blob/master/Misc/Animation/PCA_vid.gif?raw=true\" width=\"700px\">"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"section-one\"></a>\n### $\\text{Introduction}$\n\nThe original dataset was composed of $n=569 \\,$  digitized images of a fine needle aspirate ([FNA](https://en.wikipedia.org/wiki/Fine-needle_aspiration)), which later were engnireed by researchers, and concentrated as a tabular feature space of $X \\in \\mathbb{R}^{n \\times 30}$ . The instances are differed by labelled **diagnosis** (=$y$ / target variable), challanging the user to train a classifier that will be able to discriminate between unseen samples.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"D.iloc[:, 2:].head(10)        # Show ten first samples (after random shuffling)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All good, but such high dimensionality (of extracted feartues) still imposes difficulties for classic ML algorithms. To that end, a great friend of us is the principal component analysis (PCA).\n\n<a id=\"PCA\"></a>\n### $\\text{Principal Component Analysis (PCA)}$\n\n**PCA** can be done in many techniques (covariance, correlation, SVD etc.), for further theoretical development [[Wiki](https://en.wikipedia.org/wiki/Principal_component_analysis)]."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"# ******************************************************** #\n# ------------- PCA : Utilization functions -------------- #\n# ******************************************************** #\n\n# --------------- Dimensionality Reduction --------------- #\ndef PCA_reduction(X, PC_num):\n    scaler = StandardScaler()\n    scaler.fit(X)\n    X = scaler.transform(X)\n    pca = PCA()                                            # Perform PCA transformation\n    X_pca = pca.fit_transform(X)[:, 0:PC_num]              # Low dim : Projected  instances\n    max_Var = np.transpose(pca.components_[0:PC_num, :])   # Direction of maximum variance\n    return X_pca, max_Var\n\n\nclass Arrow3D(FancyArrowPatch):\n    def __init__(self, xs, ys, zs, *args, **kwargs):\n        FancyArrowPatch.__init__(self, (0,0), (0,0), *args, **kwargs)\n        self._verts3d = xs, ys, zs\n\n    def draw(self, renderer):\n        xs3d, ys3d, zs3d = self._verts3d\n        xs, ys, zs = proj3d.proj_transform(xs3d, ys3d, zs3d, renderer.M)\n        self.set_positions((xs[0],ys[0]),(xs[1],ys[1]))\n        FancyArrowPatch.draw(self, renderer)\n\n# ------------------- PCA Visualization ------------------ #\ndef Scatter_3D(X_pca, max_Var, y, labels):\n    \n    y_M, y_B = y==1, y==0           # Logical statement for Benign indication\n    xs, ys, zs = X_pca[:,0], X_pca[:,1], X_pca[:,2]\n    s_x, s_y, s_z = 1.0/(xs.max() - xs.min()), 1.0/(ys.max() - ys.min()), 1.0/(zs.max() - zs.min())\n    \n    # -------------- Scatter color by class -------------- #\n    \n    ax.scatter(xs[y_M]*s_x, ys[y_M]*s_y, zs[y_M]*s_z, s=42, c='orange', alpha=0.35) \n    ax.scatter(xs[y_B]*s_x, ys[y_B]*s_y, zs[y_B]*s_z, s=42, c='blue',   alpha=0.35)\n    n = max_Var.shape[0]\n\n    for i in range(n):\n        mean_x, mean_y, mean_z = max_Var[i,0], max_Var[i,1], max_Var[i,2]\n        a = Arrow3D([mean_x, 0.0], [mean_y, 0.0], [mean_z, 0.0], mutation_scale=15, lw=3, arrowstyle=\"<|-\", color=\"r\")\n        ax.add_artist(a)\n\n        if labels is None:\n            ax.text(max_Var[i,0]* 1.15, max_Var[i,1] * 1.15, max_Var[i,2] * 1.15, \"Var\"+str(i+1), color = 'g', fontsize=14, ha = 'center', va = 'center')\n        else:\n            ax.text(max_Var[i,0]* 1.15, max_Var[i,1] * 1.15, max_Var[i,2] * 1.15, labels[i],      color = 'g', fontsize=14, ha = 'center', va = 'center')\n\n\n# --------------- Normalize data structure --------------- #\ndef self_Normalize( X ):\n    X_n = (X-X.mean())/(X.max(axis=0)-X.min(axis=0))\n    return X_n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"3D-data\"></a>\n### $\\text{3D Visualization}$\n\nIn this notebook I utilize the [*FuncAnimation*](https://matplotlib.org/api/_as_gen/matplotlib.animation.FuncAnimation.html) library for a simple rotated motion footage :"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# ******************************************************** #\n# ----------------- Data Visualization ------------------- #\n# ******************************************************** #\n\n\n# ---------- Static : Setting of the figure -------------- #\ndef initialize_figure(pca_exp_mn):\n    fig = plt.figure(figsize=(10, 6))\n    ax = Axes3D(fig)\n    ax.xaxis.pane.fill, ax.yaxis.pane.fill, ax.zaxis.pane.fill = False, False, False\n    ax.legend(['Malignant', 'Benign'], fontsize=15, loc='best')\n    ax.set_xlabel('PC-1 : %.2f [%%]'%pca_1, fontsize=13)\n    ax.set_ylabel('PC-2 : %.2f [%%]'%pca_2, fontsize=13)\n    ax.set_zlabel('PC-3 : %.2f [%%]'%pca_3, fontsize=13)\n    return ax, fig\n\n\n\n# --------- Static : points at constant location --------- #\ndef init():\n    Scatter_3D(X_pca, max_Var, y, class_feat)\n    return fig,\n\n\n# ----------- Dynamic : define desired motion ------------ #\ndef animate(i):\n    ''' \n    input i : number of frames \n    Total_frame : defines length of footage\n    [elev, azim] : parameters of 3D point of view\n    '''\n    thres = 200\n    if i > thres:\n        j = i-thres\n    else:\n        j = 0\n\n    # Explain on motion preferences\n    Elev = 45 - i/6 + 2*j/6\n    Azim = -120+i/2\n    ax.view_init(elev=Elev, azim=Azim)\n    \n    frame_freq = 20\n    if (i%frame_freq - Total_frame%10) == 0:\n        print('Remaining frames : ', Total_frame-i)\n    return fig,\n\n\n# -------------- Implement PCA on the data --------------- #\nPC_num = 3                     # Dimensionallity reduction to 3D\npca_mn = PCA()\nX_mn = self_Normalize(X_mn)\npca_mn.fit( X_mn )\npca_exp_mn = pca_mn.explained_variance_ratio_\npca_1, pca_2, pca_3 = pca_exp_mn[0]*100, pca_exp_mn[1]*100, pca_exp_mn[2]*100\nX_pca, max_Var = PCA_reduction(X_mn, PC_num)\n\n\n# ------------- Processing of data before PCA ------------ #\ny_M, y_B = y==1, y==0      # Logical statement for Benign indication\nxs, ys, zs = X_pca[:,0], X_pca[:,1], X_pca[:,2]\ns_x, s_y, s_z = 1.0/(xs.max() - xs.min()), 1.0/(ys.max() - ys.min()), 1.0/(zs.max() - zs.min())\nax, fig = initialize_figure(pca_exp_mn)\n\n\n# ------------- Parameter for video footage -------------- #\nTotal_frame = 101\nanim = animation.FuncAnimation(fig, animate, init_func=init, frames=Total_frame, interval=20, blit=True)\nanim.save('PCA_vid.mp4', fps=30, extra_args=['-vcodec', 'libx264'])\nprint('Finished ! Download video from : \"../input/output/\"')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### $\\text{Download video :}$\n\n<img src=\"https://i.imgur.com/Pw5fDa2.png\" width=\"650px\">\n\n<a id=\"Closure\"></a>\n### ${\\text{Explanation}} \\ :$\n\nThe major contribution of the PCA, is the transform capability to reveal the data's internal structure, in a manner that explains most the variance (EVR) :"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# @title\n\nplt.rcParams['figure.figsize'] = (9, 5)\nclass_full =  class_feat + ['Diagnosis']\n\n# Initialize the PCA method\npca_mn = PCA()\n\n# Mean Dataset\npca_mn.fit(X_mn)\npca_exp_mn = pca_mn.explained_variance_ratio_\nt_solo = [*range(1, X_mn.shape[1]+1)]\n\n\ndef PCA_plot(t, pca_exp):\n    # ---------------------------------------------- #\n    # Instantiate the prinicipal (LHS) plot\n    pca_cum = np.cumsum(pca_exp)\n    fig, ax1 = plt.subplots()\n    color = 'tab:blue'\n\n    ax1.grid(color='b', ls = '-.', lw = 0.25)\n    ax1.set_xlabel('n-th component', fontsize=16)\n    ax1.set_ylabel('Explained Variance Ratio (EVR)', color=color, fontsize=17)\n    ax1.plot(t, pca_exp, 'bo', color=color, markersize=7)\n    ax1.plot(t, pca_exp, '--', color=color, linewidth=2.5)\n    ax1.tick_params(axis=\"x\", labelsize=12)\n    ax1.tick_params(axis=\"y\", labelsize=12)\n\n    # ---------------------------------------------- #\n    # Instantiate a second axes that shares the same x-axis\n    ax2 = ax1.twinx()  \n    color = 'tab:green'\n\n    ax2.set_ylabel('Cumulative EVR', color=color, fontsize=17)  # we already handled the x-label with ax1\n    ax2.plot(t, pca_cum, 'go', color=color, markersize=7)\n    ax2.plot(t, pca_cum, '--', color=color, linewidth=2.5)\n    ax2.tick_params(axis=\"y\", labelsize=12)\n    t_score, t_loc = pca_cum[2], pca_cum[2]*1.025\n    ax2.annotate('%.2f '%(t_score*100)+'[%]', fontsize=18, xy =(3, t_loc), xytext =(3, t_loc*1.06), arrowprops = dict(facecolor ='green', shrink = 0.05),) \n\n    fig.tight_layout()  # otherwise the right y-label is slightly clipped\n    plt.xticks(t)\n    plt.show()\n\nPCA_plot(t_solo, pca_exp_mn)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Such that instead of using the full feature space $\\mathbb{R}^{10}$, we can capture more than $90\\%$ of it, using only 3 principal components."},{"metadata":{},"cell_type":"markdown","source":"### $\\text{Points in Motion :}$\n\nAnother study case for animation, is when the observer point of view is frozen and the points are in motion.\n\n* Consider the amazing work of on *Pierre Segonne* on [Medium](https://medium.com/@pnpsegonne/animating-a-3d-scatterplot-with-matplotlib-ca4b676d4b55) :\n\n<img src=\"https://miro.medium.com/max/600/1*jF7UplHE94z59ihR3ZD5uw.gif\" width=\"550px\" style=\"vertical-align:middle;margin:0px 150px\">\n"},{"metadata":{},"cell_type":"markdown","source":"$$\n\\circ \\quad \\text{Comments (üí¨) , feedback (ü§î) and upvotes (üëç) are much welcome !} \\quad \\circ \\\\[1cm]\n$$"},{"metadata":{},"cell_type":"markdown","source":"$$\n- \\, fin \\, -\n$$"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}