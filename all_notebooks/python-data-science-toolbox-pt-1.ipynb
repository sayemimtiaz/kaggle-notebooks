{"cells":[{"metadata":{},"cell_type":"markdown","source":"# NumPy - Numeric Python\nDocs  \nhttps://www.numpy.org/  \n  \n**Numpy is the core library for scientific computing in Python. It provides a high-performance multidimensional array object, and tools for working with these arrays.**  \n### Main advantages of NumPy arrays over python lists\n1. Computations are faster\n2. NumPy provides a set of practical and very easy to use tools for performing calculations over entire arrays"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom random import randint\nfrom datetime import datetime\n\n# testing performance difference between python lists and numpy array\ndef get_list_with_x_random_elements(x):\n    return [randint(1, 9) for i in range(x)]\n\nlist_a = get_list_with_x_random_elements(1000000)\nlist_b = get_list_with_x_random_elements(1000000)\nnp_array_a = np.array(list_a)\nnp_array_b = np.array(list_b)\n\ndef calculate_performance_for_python_list():\n    dt1 = datetime.now()\n    result = [(a / b) ** 2 for a, b in zip(list_a, list_b)]\n    dt2 = datetime.now()\n    return (dt2 - dt1).microseconds\n\ndef calculate_performance_for_numpy_array():\n    dt1 = datetime.now()\n    result = (np_array_a / np_array_b) ** 2\n    dt2 = datetime.now()\n    return (dt2 - dt1).microseconds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"python_list_result = [calculate_performance_for_python_list() for i in range(20)]\nnumpy_array_result = [calculate_performance_for_numpy_array() for i in range(20)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculating mean for both results\nprint(\"Python list performance:\", np.array(python_list_result).mean())\nprint(\"NumPy array performance:\", np.array(numpy_array_result).mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ###  Opposed to python lists, NumPy arrays can contain only values of single type"},{"metadata":{"trusted":true},"cell_type":"code","source":"np.array([1, 2.4, \"string\", False])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Bolean subsetting is very useful for quick value search"},{"metadata":{"trusted":true},"cell_type":"code","source":"a = np.array([1, 2, 4, 8, 11])\nbolean_filter = a > 10\nbolean_filter","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a[bolean_filter]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Replacing values based on logical operations\nnp.where(a > 10, 1, 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Basic statistics with NumPy"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Generating random normal distribution \nnormal_dist = np.random.normal(100, 5, 10)\n# arguments in order: mean, stadard deviation and number of samples\nnormal_dist","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"normal_dist = np.round(normal_dist, 2)\nnormal_dist","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Mean:\", np.mean(normal_dist))\nprint(\"Median:\", np.median(normal_dist))\nprint(\"Standard deviation:\", np.std(normal_dist))\nprint(\"Variance:\", np.var(normal_dist))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Relation between two sets\nnormal_dist2 = np.random.normal(200, 10, 10)\nprint(\"Correlation coefficients:\")\nprint(np.corrcoef(normal_dist, normal_dist2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Methods which are also avialable for standard python lists, but work much faster\nprint(\"Max value:\", np.max(normal_dist))\nprint(\"Min value:\", np.min(normal_dist))\nprint(\"Index of min value:\", np.argmin(normal_dist))\nprint(\"Index of max value:\", np.argmax(normal_dist))\nprint(\"Sum:\", np.sum(normal_dist))\nprint(\"Product:\", np.prod(normal_dist))\nprint(\"Sorted:\", np.sort(normal_dist))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Mathematical operations on NumPy arrays - it works element wise!"},{"metadata":{"trusted":true},"cell_type":"code","source":"array_1 = np.array([11,12,13,14,15,16,17,18,19])\narray_2 = np.array([10,20,30,40,50,60,70,80,90])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Addition:\", array_1 + array_2)\nprint(\"Subtraction:\", array_2 - array_1)\nprint(\"Multiplication:\", array_1 * array_2)\nprint(\"Division:\", array_1 / array_2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"array_1 + 100 ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Other useful NumPy features"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Generating NumPy arrays with zeros or ones\nzeros = np.zeros(10)\nones = np.ones(10)\n\nprint(zeros)\nprint(ones)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ones.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ones.shape = 10, 1\nones","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Generasting array with constant step\nnp.linspace(2, 100, 8)\n# arguments: start, end, number of elements","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dot product (iloczyn skalarny)\narray_1 @ array_2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Exercise - perform following tasks\n**Given two lists created below (list_A and list_B) do following**  \n  \n1. Transform both lists to NumPy arrays\n2. Multiply each element of array A by 37. Assing the result back to array A\n3. Add 38 to each element of array B. Assing the result back to array B\n4. Calculate standard deviation from array B and round the result to 1 digit after a comma. Save the result to variable x\n5. Divide each element from array A by variable x. Assign the result back to array A\n6. Calculate the mean from array A and round the result to 2 digits after a comma. Save the result to variable y\n7. Create array C only from those elements of array A which are smaller than y. Round all elements of array C to 1 digit after a comma\n8. Sum all elements of array C, multiply the result by x and divide by y. Round to two digits after a comma\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"list_A = [100, 46, 45, 82, 90]\nlist_B = [404, 24, 87, 99, 12]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Pandas - Python Data Analysis Library\n\nDocs  \nhttps://pandas.pydata.org/  \n  \n**Pandas is an open source library providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language**  \n###  In Pandas we store data in so called Data Frame  \n**Data Frame is a two-dimensional, size-mutable, potentially heterogeneous tabular data structure with labeled axes (rows and columns).**  \n**ROWS = OBSERVATIONS**  \n**COLUMNS = VARIABLES**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\n\n# Creating Data Frame from python dictionary\ndict_data = {\n    \"country\": [\"Poland\", \"Germany\", \"Spain\", \"Denmark\"],\n    \"capital\": [\"Warsaw\", \"Berlin\", \"Madrid\", \"Copenhagen\"],\n    \"area\": [312679, 357386, 505990, 42933],\n    \"population\": [38.4, 82.8, 46.7, 5.7]\n}\n\ndf = pd.DataFrame(dict_data)\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Pandas assigns index (0,1,2,3) automatically but we can set index manually\ndf.set_index('country')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing data from a CSV file\ndf = pd.read_csv('../input/otomoto.csv')\n\ndf = df[df.make == 'Tesla'].head(10).reset_index()\n# remove column 'index'\ndel df['index']\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Selecting specific column\nprice_column = df[\"price\"]\nprice_column","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(price_column)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Series is a one dimensional array where each row is labelled"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Syntax for selecting specific column but in a format of a DataFrame\nprice_column_df = df[[\"price\"]]\nprice_column_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(price_column_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Selecting multiple columns\nprice_year_df = df[['price', 'year']]\nprice_year_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Selecting rows from a data frame where car is less expensive than 200 000 PLN\ncheap_tesla = df[df.price < 200000]\ncheap_tesla","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using logical AND when filtering\nfiltering_mask = np.logical_and(df.price < 200000, df.year == 2015)\ndf[filtering_mask]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using logical OR when filtering\nfiltering_mask = np.logical_or(df.price < 200000, df.mileage < 10000)\ndf[filtering_mask]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Iteratig over data frame with a for loop\nfor label, row in cheap_tesla.iterrows():\n    print(\"Label:\", label)\n    print(\"Row values:\")\n    print(row)\n    \n# Remember! This is not very efficient","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Assuming we want to create new column which would be a price in EUR\ndf[\"price_EUR\"] = np.round(df[\"price\"] / 3.9, 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We can apply any user defined function for each element with 'apply'\ndef my_func(x):\n    return np.round(x / 3.9, 2)\n\ndf[\"price_EUR\"] = df[\"price\"].apply(my_func)\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Collecting basic info about a DataFrame\ndf = pd.read_csv('../input/otomoto.csv')\npd.options.display.float_format = '{:.2f}'.format","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Basic info about each column\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Basic statistical information about numerical columns\ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# See top rows of a DataFrame\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# See bottom rows of a DataFrame\ndf.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sort DataFrame\ndf = df.sort_values(\"price\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting rid of currency column - converting all rows to PLN currency\neur_pln_ratio = 4.31\ndf['price'] = df.apply(lambda x: int(x['price'] * eur_pln_ratio) if x['currency'] == 'EUR' else x['price'], axis=1)\ndf.loc[70123]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# remove currency column\ndel df['currency']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Explore prices distribution\ndf.price.plot('hist')\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 7,7","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.sort_values(\"price\", ascending=False).head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reading standard deviation\nnp.std(df.price)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# delete all rows where price is bigger than 200 000 PLN\ndf = df[df.price < 200000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting the histogram once again\ndf.price.plot('hist')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# delete all rows where price is lower than 2000 PLN\ndf = df[df.price > 2000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting the histogram once again\ndf.price.plot('hist')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exploring makes\nlen(df.make.value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_rows', 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.make.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df.make == \"Samoch贸d\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# delete all rows where make is equal to 'Samoch贸d'\ndf = df[df.make != 'Samoch贸d']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# delete all rows with make that has less than 500 occurances\nv = df[['make']]\ndf = df[v.replace(v.apply(pd.Series.value_counts)).gt(500).all(1)]\nlen(df.make.value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exploring fuel column\ndf.fuel.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df[np.logical_and(df.fuel != \"Wod贸r\", df.fuel != 'Etanol')]\ndf.fuel.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n# correlation between year and price\n_ = plt.scatter(df['price'], df['year'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# remove all rows where year is below 1970\ndf = df[df.year > 1970]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_ = plt.scatter(df['price'], df['year'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# correlation between price and mileage\n_ = plt.scatter(df['price'], df['mileage'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# remove all rows where mileage is above 700 000\ndf = df[df.mileage < 700000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# correlation between price and mileage\n_ = plt.scatter(df['price'], df['mileage'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# correlation between year and mileage\n_ = plt.scatter(df['year'], df['mileage'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# year distribution\n_ = plt.hist(df['year'], bins=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# mileage distribution\n_ = plt.hist(df['mileage'], bins=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# relation between price and engine volume\n_ = plt.scatter(df.price, df.engine)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# remove outliner with extremaly high engine volume\ndf = df[df.engine < 15000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# relation between price and engine volume\n_ = plt.scatter(df.price, df.engine)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# How much our DataFrame was reduced\nlen(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# how fast car prices go down with each year of usage?\n\n# mean price for each year\nunique_years = list(set(df.year.values))\nmean_prices = []\nfor year in unique_years:\n    temp_df = df[df[\"year\"] == year]\n    mean_prices.append(int(temp_df.price.mean()))\n\nmean_prices = np.array(mean_prices)\n_ = plt.scatter(mean_prices, unique_years)\nplt.show()\n_ = plt.plot(mean_prices, unique_years)\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}