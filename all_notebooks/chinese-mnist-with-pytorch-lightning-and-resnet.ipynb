{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Overview\n\nThis notebook will demonstrates solving Chinese MNIST classification task using:\n\n1. `torch` and `torchvision` with pretrained resnet 18\n2. `pytorch-lightning` for code formation (you can see easily setup GPU training and half precision flag)\n3. `albumentations` for augmentations\n4. sklearn's stratified k-fold cross-validation for equally distribute labels (`code`s) amongst different folds\n\nAlthought it can achieve 1.0 or at least 0.98 accuracy, there is still room for improvement, _for which I don't have more time_."},{"metadata":{},"cell_type":"markdown","source":"## Install dependencies"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install -U -q --use-feature=2020-resolver \"pytorch_lightning==0.10.0rc1\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Define dataset and dataloader via pytorch-lightning datamodule"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfrom pathlib import Path\n\nimport albumentations as A\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport pytorch_lightning as pl\nimport torch\nfrom albumentations.pytorch import ToTensorV2\nfrom albumentations.augmentations.transforms import Blur, RandomBrightness\nfrom torch.utils.data import DataLoader, Dataset\n\n\nclass ChineseMNISTDataset(Dataset):\n    def __init__(\n        self,\n        df: pd.DataFrame,\n        image_root: Path,\n        transform: A.BasicTransform = None,\n    ) -> None:\n        super().__init__()\n        self.df = df\n        self.image_root = image_root\n        self.transform = transform\n\n    def __getitem__(self, idx: int):\n        row = self.df.loc[idx, :]\n        suite_id, code, sample_id = row.suite_id, row.code, row.sample_id\n        filename = self.image_root / f\"input_{suite_id}_{sample_id}_{code}.jpg\"\n        assert os.path.isfile(filename), f\"{filename} is not a file\"\n        image = cv2.imread(str(filename))\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n        image = image[:, np.newaxis]\n        if self.transform is not None:\n            image = self.transform(image=image)[\"image\"]\n        return image, code - 1\n\n    def __len__(self):\n        return len(self.df)\n\n\nclass ChineseMNISTDataModule(pl.LightningDataModule):\n    def __init__(\n        self,\n        data_root: Path,\n        all_df: pd.DataFrame,\n        train_indices: pd.Index,\n        val_indices: pd.Index,\n    ) -> None:\n        super().__init__()\n        self.data_root = data_root\n        self.df = all_df\n        self.image_root = self.data_root / \"data\" / \"data\"\n        self.train_df = self.df.loc[train_indices, :].copy().reset_index()\n        self.train_transform = A.Compose(\n            [\n                Blur(),\n                RandomBrightness(),\n                ToTensorV2(),\n            ]\n        )\n        self.val_df = self.df.loc[val_indices, :].copy().reset_index()\n        self.val_transform = A.Compose(\n            [\n                ToTensorV2(),\n            ]\n        )\n\n    def train_dataloader(self):\n        ds = ChineseMNISTDataset(self.train_df, self.image_root, self.train_transform)\n        return DataLoader(\n            ds,\n            batch_size=64,\n            shuffle=True,\n            num_workers=4,\n            pin_memory=True,\n        )\n\n    def val_dataloader(self):\n        ds = ChineseMNISTDataset(self.val_df, self.image_root, self.val_transform)\n        return DataLoader(\n            ds,\n            batch_size=64,\n            shuffle=False,\n            num_workers=4,\n            pin_memory=True,\n        )\n\n\nif __name__ == \"__main__\":\n    is_kaggle = os.path.isdir(\"/kaggle\")\n    data_root = Path(\"/kaggle/input/chinese-mnist\" if is_kaggle else \"archive\")\n    assert os.path.isdir(data_root), f\"{data_root} is not a dir\"\n    df = pd.read_csv(data_root / \"chinese_mnist.csv\")\n\n    data_module = ChineseMNISTDataModule(data_root, df, df.index[:20], df.index[20:30])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model definition"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfrom pathlib import Path\n\nimport pandas as pd\nimport pytorch_lightning as pl\nfrom pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint\nfrom pytorch_lightning.metrics import Accuracy\nfrom sklearn.model_selection import StratifiedKFold\nfrom torch import nn, optim\nfrom torchvision.models import resnet18\n\ntry:\n    from dataset import ChineseMNISTDataModule, ChineseMNISTDataset\nexcept:\n    pass\n\n\nclass ChineseMNISTResnetModel(pl.LightningModule):\n    def __init__(self, learning_rate=1e-3):\n        super().__init__()\n        self.learning_rate = learning_rate\n        self.num_classes = 15\n        resnet = resnet18(pretrained=True, progress=True)\n        resnet.conv1 = nn.Conv2d(\n            in_channels=1,\n            out_channels=resnet.conv1.out_channels,\n            kernel_size=resnet.conv1.kernel_size,\n            stride=resnet.conv1.stride,\n            dilation=resnet.conv1.dilation,\n            bias=resnet.conv1.bias,\n        )\n        resnet.fc = nn.Linear(512, self.num_classes)\n        self.resnet = resnet\n        self.accuracy = Accuracy(num_classes=self.num_classes)\n        self.criterion = nn.CrossEntropyLoss()\n\n    def forward(self, image):\n        image = image.permute(0, 3, 1, 2).contiguous().float()\n        return self.resnet(image)\n\n    def training_step(self, batch, batch_idx: int):\n        image, y = batch\n        yhat = self(image)\n        loss = self.criterion(yhat, y)\n        acc = self.accuracy(yhat, y)\n        return {\"loss\": loss, \"acc\": acc}\n\n    def validation_step(self, batch, batch_idx: int):\n        image, y = batch\n        yhat = self(image)\n        loss = self.criterion(yhat, y)\n        acc = self.accuracy(yhat, y)\n        return {\"val_loss\": loss, \"val_acc\": acc, \"progress_bar\": {\"val_acc\": acc}}\n\n    def test_step(self, batch, batch_idx):\n        metrics = self.validation_step(batch, batch_idx)\n        return {\"test_acc\": metrics[\"val_acc\"], \"test_loss\": metrics[\"val_loss\"]}\n\n    def configure_optimizers(self):\n        optimizer = optim.Adam(self.parameters(), lr=self.learning_rate)\n        return optimizer\n\n\ndef training(k_folds: int = 5):\n    is_kaggle = os.path.isdir(\"/kaggle\")\n    data_root = Path(\"/kaggle/input/chinese-mnist\" if is_kaggle else \"archive\")\n    all_df = pd.read_csv(data_root / \"chinese_mnist.csv\")\n\n    skf = StratifiedKFold(n_splits=k_folds, shuffle=True)\n\n    checkpoint_callback = ModelCheckpoint(\n        filepath=os.getcwd(),\n        save_top_k=1,\n        verbose=True,\n        monitor=\"val_loss\",\n        mode=\"min\",\n    )\n    trainer = pl.Trainer(\n        gpus=1,\n        max_epochs=4,\n        precision=16,\n        val_check_interval=0.2,\n        checkpoint_callback=checkpoint_callback,\n    )\n\n    for train_indices, val_indices in skf.split(all_df, all_df.code):\n        data_module = ChineseMNISTDataModule(\n            data_root=data_root,\n            all_df=all_df,\n            train_indices=train_indices,\n            val_indices=val_indices,\n        )\n        model = ChineseMNISTResnetModel()\n        trainer.fit(model, data_module)\n\n\nif __name__ == \"__main__\":\n    training()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}