{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport torch\nimport torch.nn as nn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nimport transformers\nfrom transformers import AutoModel, BertTokenizerFast\n\n# specify GPU\ndevice = torch.device(\"cuda\")\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-25T21:52:34.133194Z","iopub.execute_input":"2021-05-25T21:52:34.13375Z","iopub.status.idle":"2021-05-25T21:52:36.970543Z","shell.execute_reply.started":"2021-05-25T21:52:34.133667Z","shell.execute_reply":"2021-05-25T21:52:36.969445Z"},"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"background-color:#001f3f; font-family:'Brush Script MT',cursive;color:#FFD700;font-size:200%; text-align:center;border-radius: 50% 20% / 10% 40%\">Robert Frost</h1>\n\n\"Robert Lee Frost (March 26, 1874 – January 29, 1963) was an American poet. His work was initially published in England before it was published in the United States. Known for his realistic depictions of rural life and his command of American colloquial speech, Frost frequently wrote about settings from rural life in New England in the early 20th century, using them to examine complex social and philosophical themes.\"\n\n\"Frost was honored frequently during his lifetime and is the only poet to receive four Pulitzer Prizes for Poetry. He became one of America's rare \"public literary figures, almost an artistic institution.\" He was awarded the Congressional Gold Medal in 1960 for his poetic works. On July 22, 1961, Frost was named poet laureate of Vermont.\"\n\nhttps://en.wikipedia.org/wiki/Robert_Frost","metadata":{}},{"cell_type":"markdown","source":"![](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQ2HE-uDLvOoiRdNw810jMvODPrc24976bALg&usqp=CAU)slideshare.net","metadata":{}},{"cell_type":"code","source":"\ndf = pd.read_csv(\"/kaggle/input/robert-frost-collection/robert_frost_collection.csv\", low_memory=False)\nprint(df.shape)\ndf.head().style.set_properties(**{'background-color':'gold',\n                                     'color': 'purple'})","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-05-25T23:33:34.216691Z","iopub.execute_input":"2021-05-25T23:33:34.217065Z","iopub.status.idle":"2021-05-25T23:33:34.250336Z","shell.execute_reply.started":"2021-05-25T23:33:34.217033Z","shell.execute_reply":"2021-05-25T23:33:34.249286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T21:52:52.899918Z","iopub.execute_input":"2021-05-25T21:52:52.90029Z","iopub.status.idle":"2021-05-25T21:52:52.909806Z","shell.execute_reply.started":"2021-05-25T21:52:52.900257Z","shell.execute_reply":"2021-05-25T21:52:52.908636Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"![](https://i.redd.it/m721qo3ywsk31.jpg)reddit.com","metadata":{}},{"cell_type":"code","source":"# categorical features with missing values\ncategorical_nan = [feature for feature in df.columns if df[feature].isna().sum()>0 and df[feature].dtypes=='O']\nprint(categorical_nan)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T21:58:05.929564Z","iopub.execute_input":"2021-05-25T21:58:05.930022Z","iopub.status.idle":"2021-05-25T21:58:05.938796Z","shell.execute_reply.started":"2021-05-25T21:58:05.929972Z","shell.execute_reply":"2021-05-25T21:58:05.937669Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# replacing missing values in categorical features\nfor feature in categorical_nan:\n    df[feature] = df[feature].fillna('None')","metadata":{"execution":{"iopub.status.busy":"2021-05-25T21:58:23.798339Z","iopub.execute_input":"2021-05-25T21:58:23.798973Z","iopub.status.idle":"2021-05-25T21:58:23.805714Z","shell.execute_reply.started":"2021-05-25T21:58:23.798928Z","shell.execute_reply":"2021-05-25T21:58:23.804938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[categorical_nan].isna().sum()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T21:58:38.587517Z","iopub.execute_input":"2021-05-25T21:58:38.588046Z","iopub.status.idle":"2021-05-25T21:58:38.597565Z","shell.execute_reply.started":"2021-05-25T21:58:38.588013Z","shell.execute_reply":"2021-05-25T21:58:38.596607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Handle numerical features with nan value\nnumerical_nan = [feature for feature in df.columns if df[feature].isna().sum()>1 and df[feature].dtypes!='O']\nnumerical_nan","metadata":{"execution":{"iopub.status.busy":"2021-05-25T21:59:09.87699Z","iopub.execute_input":"2021-05-25T21:59:09.877512Z","iopub.status.idle":"2021-05-25T21:59:09.886344Z","shell.execute_reply.started":"2021-05-25T21:59:09.877471Z","shell.execute_reply":"2021-05-25T21:59:09.885464Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[numerical_nan].isna().sum()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T21:59:34.640914Z","iopub.execute_input":"2021-05-25T21:59:34.641267Z","iopub.status.idle":"2021-05-25T21:59:34.652003Z","shell.execute_reply.started":"2021-05-25T21:59:34.641237Z","shell.execute_reply":"2021-05-25T21:59:34.650978Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Replacing the numerical Missing Values\n\nfor feature in numerical_nan:\n    ## We will replace by using median since there are outliers\n    median_value=df[feature].median()\n    \n    df[feature].fillna(median_value,inplace=True)\n    \ndf[numerical_nan].isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T21:59:53.098967Z","iopub.execute_input":"2021-05-25T21:59:53.09943Z","iopub.status.idle":"2021-05-25T21:59:53.114767Z","shell.execute_reply.started":"2021-05-25T21:59:53.099381Z","shell.execute_reply":"2021-05-25T21:59:53.113424Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.rename(columns={'Name':'name', 'Content': 'content', 'Collection':'collection', 'Year of Publication': 'year'})","metadata":{"execution":{"iopub.status.busy":"2021-05-25T22:42:48.382276Z","iopub.execute_input":"2021-05-25T22:42:48.382639Z","iopub.status.idle":"2021-05-25T22:42:48.388534Z","shell.execute_reply.started":"2021-05-25T22:42:48.382607Z","shell.execute_reply":"2021-05-25T22:42:48.387723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Code by Debanjan Sarkar  https://www.kaggle.com/deb009/commonlit-readability-prize-using-bert","metadata":{}},{"cell_type":"code","source":"# split train dataset into train, validation sets\ndf_content, valid_content, df_year, valid_year = train_test_split(df['content'], df['year'], \n                                                                    random_state=2018, \n                                                                    test_size=0.3)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T22:11:06.179058Z","iopub.execute_input":"2021-05-25T22:11:06.179624Z","iopub.status.idle":"2021-05-25T22:11:06.188334Z","shell.execute_reply.started":"2021-05-25T22:11:06.179584Z","shell.execute_reply":"2021-05-25T22:11:06.187338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Import BERT Model and BERT Tokenizer","metadata":{}},{"cell_type":"code","source":"# import BERT-base pretrained model\nbert = AutoModel.from_pretrained('bert-base-uncased')\n\n# Load the BERT tokenizer\ntokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')","metadata":{"execution":{"iopub.status.busy":"2021-05-25T22:11:40.032205Z","iopub.execute_input":"2021-05-25T22:11:40.032599Z","iopub.status.idle":"2021-05-25T22:12:02.292972Z","shell.execute_reply.started":"2021-05-25T22:11:40.032561Z","shell.execute_reply":"2021-05-25T22:12:02.292205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Third Row. Second column: content. \n\ndf.iloc[3,1]","metadata":{"execution":{"iopub.status.busy":"2021-05-25T22:29:28.987622Z","iopub.execute_input":"2021-05-25T22:29:28.988007Z","iopub.status.idle":"2021-05-25T22:29:28.994856Z","shell.execute_reply.started":"2021-05-25T22:29:28.987973Z","shell.execute_reply":"2021-05-25T22:29:28.993762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#See how BERT Tokenizer works, We will try to encode a couple of sentences using the tokenizer.","metadata":{}},{"cell_type":"code","source":"#sample data\ntext_list = [\"Before man came to blow it right The wind once blew itself untaught, And did its loudest day and night In any rough place where it caught. Man came to tell it what was wrong: It hadn’t found the place to blow; It blew too hard the aim was song. And listen how it ought to go! He took a little in his mouth, And held it long enough for north To be converted into south, And then by measure blew it forth. By measure. It was word and note, The wind the wind had meant to be A little through the lips and throat. The aim was song the wind could see\"]\n\n\nprint(text_list)\n# encode text\nsent_id = tokenizer.batch_encode_plus(text_list, padding=True)\n\n# output\nprint(sent_id)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T22:23:39.560946Z","iopub.execute_input":"2021-05-25T22:23:39.5613Z","iopub.status.idle":"2021-05-25T22:23:39.577547Z","shell.execute_reply.started":"2021-05-25T22:23:39.561264Z","shell.execute_reply":"2021-05-25T22:23:39.576511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#I was not sure if the rename worked since I was receiving errors with the column's names. ","metadata":{}},{"cell_type":"code","source":"df.columns.tolist()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T22:42:59.911115Z","iopub.execute_input":"2021-05-25T22:42:59.911679Z","iopub.status.idle":"2021-05-25T22:42:59.917523Z","shell.execute_reply.started":"2021-05-25T22:42:59.911644Z","shell.execute_reply":"2021-05-25T22:42:59.916361Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['content'].astype(str)#Trying to avoid str error float' object has no attribute 'split'","metadata":{"execution":{"iopub.status.busy":"2021-05-25T22:49:20.170107Z","iopub.execute_input":"2021-05-25T22:49:20.170542Z","iopub.status.idle":"2021-05-25T22:49:20.182117Z","shell.execute_reply.started":"2021-05-25T22:49:20.170502Z","shell.execute_reply":"2021-05-25T22:49:20.181133Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Tokenize the Sentences","metadata":{}},{"cell_type":"markdown","source":"#Below the original snippet was:\n\nseq_len = [len(i.split()) for i in train['excerpt']] \n\nWhich resulted in AttributeError: 'float' object has no attribute 'split'\n\nThen I introduced str().split  Instead of i.split\n\nhttps://github.com/lingualytics/py-lingualytics/issues/1 By argoniteXD ","metadata":{}},{"cell_type":"code","source":"#https://github.com/lingualytics/py-lingualytics/issues/1 By argoniteXD \n\n# get length of all the messages in the train set\nseq_len = [len(str(i).split()) for i in df['content']]\n\npd.Series(seq_len).hist(bins = 30)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T22:54:59.279702Z","iopub.execute_input":"2021-05-25T22:54:59.280075Z","iopub.status.idle":"2021-05-25T22:54:59.57303Z","shell.execute_reply.started":"2021-05-25T22:54:59.280044Z","shell.execute_reply":"2021-05-25T22:54:59.572125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#We will set the padding length as 2000. See chart above. There is very few at 3000.","metadata":{}},{"cell_type":"code","source":"# tokenize and encode sequences in the training set\ntokens_df = tokenizer.batch_encode_plus(\n    df_content.tolist(),\n    max_length = 2000,\n    pad_to_max_length=True,\n    truncation=True\n)\n\n# tokenize and encode sequences in the validation set\ntokens_val = tokenizer.batch_encode_plus(\n    valid_content.tolist(),\n    max_length = 2000,\n    pad_to_max_length=True,\n    truncation=True\n)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T23:00:43.763882Z","iopub.execute_input":"2021-05-25T23:00:43.764274Z","iopub.status.idle":"2021-05-25T23:00:43.873745Z","shell.execute_reply.started":"2021-05-25T23:00:43.764242Z","shell.execute_reply":"2021-05-25T23:00:43.87263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Converting the integer sequences to tensors.","metadata":{}},{"cell_type":"code","source":"## convert lists to tensors\n\ndf_seq = torch.tensor(tokens_df['input_ids'])\ndf_mask = torch.tensor(tokens_df['attention_mask'])\ndf_y = torch.tensor(df_year.tolist())\n\nval_seq = torch.tensor(tokens_val['input_ids'])\nval_mask = torch.tensor(tokens_val['attention_mask'])\nval_y = torch.tensor(valid_year.tolist())","metadata":{"execution":{"iopub.status.busy":"2021-05-25T23:02:13.214653Z","iopub.execute_input":"2021-05-25T23:02:13.215156Z","iopub.status.idle":"2021-05-25T23:02:13.273601Z","shell.execute_reply.started":"2021-05-25T23:02:13.215109Z","shell.execute_reply":"2021-05-25T23:02:13.272616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n\n#define a batch size\nbatch_size = 32\n\n# wrap tensors\ndf_data = TensorDataset(df_seq, df_mask, df_y)\n\n# sampler for sampling the data during training\ndf_sampler = RandomSampler(df_data)\n\n# dataLoader for train set\ndf_dataloader = DataLoader(df_data, sampler=df_sampler, batch_size=batch_size)\n\n# wrap tensors\nval_data = TensorDataset(val_seq, val_mask, val_y)\n\n# sampler for sampling the data during training\nval_sampler = SequentialSampler(val_data)\n\n# dataLoader for validation set\nval_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T23:04:32.971171Z","iopub.execute_input":"2021-05-25T23:04:32.971597Z","iopub.status.idle":"2021-05-25T23:04:32.979245Z","shell.execute_reply.started":"2021-05-25T23:04:32.971559Z","shell.execute_reply":"2021-05-25T23:04:32.978075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#At this point the author (Debanjan Sarkar) wrote: WIP and I don't know if he will keep coding or not. ","metadata":{}},{"cell_type":"markdown","source":"![](http://2.bp.blogspot.com/-iPpPd6ErybU/U1dKbD4LksI/AAAAAAAAAF4/8JKu956uzqE/s1600/gold.gif)outsiders2014.blogspot.com","metadata":{}},{"cell_type":"code","source":"#sample data\ntext_gold = [\"Nature’s first green is gold, Her hardest hue to hold. Her early leaf’s a flower; But only so an hour. Then leaf subsides to leaf. So Eden sank to grief, So dawn goes down to day. Nothing gold can stay.\"]\n\n\nprint(text_gold)\n# encode text\nsent_gold = tokenizer.batch_encode_plus(text_gold, padding=True)\n\n# output\nprint(sent_gold)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T23:24:17.416466Z","iopub.execute_input":"2021-05-25T23:24:17.416904Z","iopub.status.idle":"2021-05-25T23:24:17.425358Z","shell.execute_reply.started":"2021-05-25T23:24:17.416863Z","shell.execute_reply":"2021-05-25T23:24:17.424336Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"![](https://www.biography.com/.image/c_fit%2Ccs_srgb%2Cfl_progressive%2Cq_auto:good%2Cw_620/MTY2Nzk4OTY5ODAyODU5NjQx/robertfrost_facts_desktop.jpg)biography.com","metadata":{}},{"cell_type":"code","source":"#Code by Olga Belitskaya https://www.kaggle.com/olgabelitskaya/sequential-data/comments\nfrom IPython.display import display,HTML\nc1,c2,f1,f2,fs1,fs2=\\\n'#eb3434','#eb3446','Akronim','Smokum',30,15\ndef dhtml(string,fontcolor=c1,font=f1,fontsize=fs1):\n    display(HTML(\"\"\"<style>\n    @import 'https://fonts.googleapis.com/css?family=\"\"\"\\\n    +font+\"\"\"&effect=3d-float';</style>\n    <h1 class='font-effect-3d-float' style='font-family:\"\"\"+\\\n    font+\"\"\"; color:\"\"\"+fontcolor+\"\"\"; font-size:\"\"\"+\\\n    str(fontsize)+\"\"\"px;'>%s</h1>\"\"\"%string))\n    \n    \ndhtml('In 3 words, I can sum up everything I ve learned about life: it goes on.' )","metadata":{"execution":{"iopub.status.busy":"2021-05-25T23:47:32.539271Z","iopub.execute_input":"2021-05-25T23:47:32.539894Z","iopub.status.idle":"2021-05-25T23:47:32.550292Z","shell.execute_reply.started":"2021-05-25T23:47:32.539852Z","shell.execute_reply":"2021-05-25T23:47:32.54903Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]}]}