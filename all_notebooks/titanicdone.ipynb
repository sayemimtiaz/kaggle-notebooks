{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\ndata_train = pd.read_csv('../input/train.csv')\ndata_test = pd.read_csv('../input/test.csv')\n\ndata_train.sample(3)\n\n\nsns.barplot(x=\"Embarked\",y=\"Survived\",hue=\"Sex\",data=data_train)\n\nsns.pointplot(x=\"Pclass\", y=\"Survived\", hue=\"Sex\", data=data_train,\n              palette={\"male\": \"blue\", \"female\": \"pink\"},\n              markers=[\"*\", \"o\"]);\n\ndef simplify_ages(df):\n    df.Age=df.Age.fillna(0.5)\n    bins=(-1,0,5,12,18,25,35,60,100)\n    group_names=['Unknown','Baby','Child','Teenager','Student','Adult','Senior','Old']\n    categories=pd.cut(df.Age,bins,labels=group_names)\n    df.Age=categories\n    return df\n\n\ndef simplify_cabins(df):\n    df.Cabin = df.Cabin.fillna('N')\n    df.Cabin = df.Cabin.apply(lambda x: x[0])\n    return df\n\n\ndef simplify_fares(df):\n    df.Fare = df.Fare.fillna(-0.5)\n    bins = (-1, 0, 8, 15, 31, 1000)\n    group_names = ['Unknown', '1$', '2$', '3_$', '4$']\n    categories = pd.cut(df.Fare, bins, labels=group_names)\n    df.Fare = categories\n    return df\n\n\ndef format_name(df):\n    df['NamePrefix'] = df.Name.apply(lambda x: x.split(' ')[1])\n    df['Lname'] = df.Name.apply(lambda x: x.split(' ')[-1])\n    \n    return df\n\n\n\ndef drop_features(df):\n    return df.drop(['Ticket', 'Name', 'Embarked'], axis=1)\n\ndef transform_features(df):\n    df = simplify_ages(df)\n    df = simplify_cabins(df)\n    df = format_name(df)\n    df = simplify_fares(df)\n    df = drop_features(df)\n    return df\n\n\ndata_train = transform_features(data_train)\ndata_test = transform_features(data_test)\ndata_train.head()\n\nsns.barplot(x=\"Age\", y=\"Survived\", hue=\"Sex\", data=data_train);\"\"\n\n\n\nfrom sklearn import preprocessing\ndef encode_features(df_train, df_test):\n    features = ['Fare', 'Cabin', 'Age', 'Sex', 'Lname', 'NamePrefix']\n    df_combined = pd.concat([df_train[features], df_test[features]])\n    \n    for feature in features:\n        le = preprocessing.LabelEncoder()\n        le = le.fit(df_combined[feature])\n        df_train[feature] = le.transform(df_train[feature])\n        df_test[feature] = le.transform(df_test[feature])\n    return df_train, df_test\n    \ndata_train, data_test = encode_features(data_train, data_test)\ndata_train.head()\n    \n    \n    \nfrom sklearn.model_selection import train_test_split\n\nX_all = data_train.drop(['Survived', 'PassengerId'], axis=1)\ny_all = data_train['Survived']\n\nnum_test = 0.30\nX_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=num_test, random_state=23)\n\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import make_scorer, accuracy_score\nfrom sklearn.model_selection import GridSearchCV\n\n# Choose the type of classifier. \nclf = RandomForestClassifier()\n\n# Choose some parameter combinations to try\nparameters = {'n_estimators': [4, 6, 9], \n              'max_features': ['log2', 'sqrt','auto'], \n              'criterion': ['entropy', 'gini'],\n              'max_depth': [2, 3, 5, 10], \n              'min_samples_split': [2, 3, 5],\n              'min_samples_leaf': [1,5,8]\n             }\n\n\n# Type of scoring used to compare parameter combinations\nacc_scorer = make_scorer(accuracy_score)\n# Run the grid search\ngrid_obj = GridSearchCV(clf, parameters, scoring=acc_scorer)\ngrid_obj = grid_obj.fit(X_train, y_train)\n\n# Set the clf to the best combination of parameters\nclf = grid_obj.best_estimator_\n\n# Fit the best algorithm to the data. \nclf.fit(X_train, y_train)\n\npredictions = clf.predict(X_test)\nprint(accuracy_score(y_test, predictions))\n\n\nids = data_test['PassengerId']\npredictions = clf.predict(data_test.drop('PassengerId', axis=1))\n\n\noutput = pd.DataFrame({ 'PassengerId' : ids, 'Survived': predictions })\noutput.to_csv('titanic-predictions.csv', index = False)\n#output.head()\nprint(output)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false,"_kg_hide-output":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}