{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport cv2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load the dataset\ndb_face_images = np.load('../input/face-images-with-marked-landmark-points/face_images.npz')['face_images']\nprint(db_face_images.shape)\ndf_facial_keypoints = pd.read_csv('../input/face-images-with-marked-landmark-points/facial_keypoints.csv')\npd.set_option('display.max_columns', None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#visualising the dataframe\ndf_facial_keypoints.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking for the number of NAN values row wise\nnan_value = df_facial_keypoints.isnull().sum(axis = 1)\nprint (nan_value)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Getting the indices with 15 keypoints of all non null rows\nindices = np.nonzero(nan_value == 0)[0] \nprint(indices)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Showing Random subset of images with keypoints overlaid"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig_row = 6\nfig_col = 5\n\nnum_plot = fig_row * fig_col\nrandom_indices_vector = np.random.choice(db_face_images.shape[2], num_plot, replace = False)\nrandom_indices_mat = random_indices_vector.reshape(fig_row, fig_col)\nplt.close('all')\n\nfig, ax = plt.subplots(nrows = fig_row, ncols =fig_col, figsize = (14, 18))\n\nfor i in range(fig_row):\n    for j in range(fig_col):\n        curr_indice = random_indices_mat[i][j]\n        curr_img = db_face_images[:,:,curr_indice]\n        \n        x_feature_cord = np.array(df_facial_keypoints.iloc[curr_indice, 0::2].tolist())\n        y_feature_cord = np.array(df_facial_keypoints.iloc[curr_indice, 1::2].tolist())\n        \n        ax[i][j].imshow(curr_img, cmap = 'gray')\n        ax[i][j].scatter(x_feature_cord,y_feature_cord,c='b',s=15)\n        ax[i][j].set_axis_off()\n        ax[i][j].set_title('image_index = %d' %(curr_indice),fontsize=10)\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Getting the modifed image database with 15 keypoints \ndb_face_images = db_face_images[:,:,indices]\ndb_face_images.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Reseting the index of keypoits as per indices\ndf_facial_keypoints = df_facial_keypoints.iloc[indices,:].reset_index(drop=True)\ndf_facial_keypoints.shape\ndf_facial_keypoints.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Now we have our modified dataset and keypoints with all images having 15 keypoints"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Converting both dataset and dataframe into array for further modification\n\ndb_face_images = np.moveaxis(db_face_images, -1, 0)\ndb_face_images.shape\n\n# Images are gray scale\ndb_images = np.asarray(db_face_images).reshape(db_face_images.shape[0],96,96,1)\nprint(db_images.shape)\n\ndf_keypoints = np.array(df_facial_keypoints)\nprint(df_keypoints.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's create a function to plot the image\ndef plot_sample(image, keypoint, axis, title):\n    image = image.reshape(96,96)\n    axis.imshow(image, cmap='gray')\n    axis.scatter(keypoint[0::2], keypoint[1::2], marker='*', s=20)\n    plt.title(title)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's create a new label for images and keypoints\ndb_images_modify = db_images\ndf_keypoints_modify = df_keypoints\nfig, axis = plt.subplots()\nplot_sample(db_images[50], df_keypoints[50], axis, \"Sample Image & Keypoints\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Various Image Agumentation choices\nsample = 50\nhorizontal_flip = True\nrotation_augmentation = True\nbrightness_augmentation = True\nshift_augmentation = True\nrandom_noise_augmentation = True","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Horizontal Flipping"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Function for flipping of images horizontally\ndef flip(images, keypoints):\n    flipped_keypoints = []\n    flipped_images = np.flip(images, axis=2)   # Flip column-wise (axis=2)\n    for idx, sample_keypoints in enumerate(keypoints):\n        flipped_keypoints.append([96.-coor if idx%2==0 else coor for idx,coor in enumerate(sample_keypoints)])    # Subtract only X co-ordinates of keypoints from 96 for horizontal flipping\n    return flipped_images, flipped_keypoints\n\nif horizontal_flip:\n    db_images_flipped, df_keypoints_flipped = flip(db_images, df_keypoints)\n    print(\"Shape of flipped_images:\",np.shape(db_images_flipped))\n    print(\"Shape of flipped_keypoints:\",np.shape(df_keypoints_flipped))\n    \n    #Adding flipped images and keypoints to my modified dataset and dataframe\n    db_images_modify = np.concatenate((db_images_modify, db_images_flipped))\n    df_keypoints_modify = np.concatenate((df_keypoints_modify, df_keypoints_flipped))\n    fig, axis = plt.subplots()\n    plot_sample(db_images_flipped[sample], df_keypoints_flipped[sample], axis, \"Horizontally Flipped\")\n    \n    \nprint(\"Shape of images database after shifting:\",db_images_modify.shape)\nprint(\"Shape of keypoints dataframe after shifting:\",df_keypoints_modify.shape)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Translation/shifting on images(pixels) and keypoints"},{"metadata":{"trusted":true},"cell_type":"code","source":"pixel_shift = [12]    # shift amount in pixels (includes shift from all 4 corners)\n\n#Function fot translation\ndef shift(images, keypoints):\n    shifted_images = []\n    shifted_keypoints = []\n    for shift in pixel_shift:    # Augmenting over several pixel shift values\n        for (shift_x,shift_y) in [(-shift,-shift),(-shift,shift),(shift,-shift),(shift,shift)]:\n            M = np.float32([[1,0,shift_x],[0,1,shift_y]])\n            for image, keypoint in zip(images, keypoints):\n                shifted_image = cv2.warpAffine(image, M, (96,96), flags=cv2.INTER_CUBIC)\n                shifted_keypoint = np.array([(point+shift_x) if idx%2==0 else (point+shift_y) for idx, point in enumerate(keypoint)])\n                if np.all(0.0<shifted_keypoint) and np.all(shifted_keypoint<96.0):\n                    shifted_images.append(shifted_image.reshape(96,96,1))\n                    shifted_keypoints.append(shifted_keypoint)\n    shifted_keypoints = np.clip(shifted_keypoints,0.0,96.0)\n    return shifted_images, shifted_keypoints\n\nif shift_augmentation:\n    db_images_shifted, df_keypoints_shifted = shift(db_images, df_keypoints)\n    print(f\"Shape of shifted_images:\",np.shape(db_images_shifted))\n    print(f\"Shape of shifted_keypoints:\",np.shape(df_keypoints_shifted))\n    \n    db_images_modify = np.concatenate((db_images_modify, db_images_shifted))\n    df_keypoints_modify = np.concatenate((df_keypoints_modify, df_keypoints_shifted))\n    fig, axis = plt.subplots()\n    plot_sample(db_images_shifted[sample], df_keypoints_shifted[sample], axis, \"Shift Augmentation\")\n    \nprint(\"Shape of images database after shifting:\",np.shape(db_images_modify))\nprint(\"Shape of keypoints dataframe after shifting:\",np.shape(df_keypoints_modify))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Rotation on images and keypoints"},{"metadata":{"trusted":true},"cell_type":"code","source":"from math import sin, cos, pi\n\n\nrotation_angles = [12]    # Rotation angle in degrees (includes both clockwise & anti-clockwise rotations)\n\n#Function for Rotation of the Images\ndef rotate(images, keypoints):\n    rotated_images = []\n    rotated_keypoints = []\n    print(\"Augmenting for angles (in degrees): \")\n    \n    for angle in rotation_angles:    # Rotation augmentation for a list of angle values\n        for angle in [angle,-angle]:\n            print(f'{angle}', end='  ')\n            M = cv2.getRotationMatrix2D((48,48), angle, 1.0)\n            angle_rad = -angle*pi/180.     # Obtain angle in radians from angle in degrees (notice negative sign for change in clockwise vs anti-clockwise directions from conventional rotation to cv2's image rotation)\n            \n            # For train_images\n            for image in images:\n                rotated_image = cv2.warpAffine(image, M, (96,96), flags=cv2.INTER_CUBIC)\n                rotated_images.append(rotated_image)\n            \n            # For train_keypoints\n            for keypoint in keypoints:\n                rotated_keypoint = keypoint - 48.    # Subtract the middle value of the image dimension\n                for idx in range(0,len(rotated_keypoint),2):\n                    # https://in.mathworks.com/matlabcentral/answers/93554-how-can-i-rotate-a-set-of-points-in-a-plane-by-a-certain-angle-about-an-arbitrary-point\n                    rotated_keypoint[idx] = rotated_keypoint[idx]*cos(angle_rad)-rotated_keypoint[idx+1]*sin(angle_rad)\n                    rotated_keypoint[idx+1] = rotated_keypoint[idx]*sin(angle_rad)+rotated_keypoint[idx+1]*cos(angle_rad)\n                rotated_keypoint += 48.   # Add the earlier subtracted value\n                rotated_keypoints.append(rotated_keypoint)\n            \n    return np.reshape(rotated_images,(-1,96,96,1)), rotated_keypoints\n\n#For more details on the transformation of the images below is the link.\n#https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_geometric_transformations/py_geometric_transformations.html\n\nif rotation_augmentation:\n    db_images_rotated, df_keypoints_rotated = rotate(db_images, df_keypoints)\n    print(\"\\nShape of rotated_images:\",np.shape(db_images_rotated))\n    print(\"Shape of rotated_keypoints:\\n\",np.shape(df_keypoints_rotated))\n    \n    #Concatenating the train images with rotated image & train keypoints with rotated train points\n    db_images_modify = np.concatenate((db_images_modify, db_images_rotated))\n    df_keypoints_modify = np.concatenate((df_keypoints_modify, df_keypoints_rotated))\n    fig, axis = plt.subplots()\n    plot_sample(db_images_rotated[sample], df_keypoints_rotated[sample], axis, \"Rotation Augmentation\")\n    \nprint(\"Shape of images database after shifting:\",np.shape(db_images_modify))\nprint(\"Shape of keypoints dataframe after shifting:\",np.shape(df_keypoints_modify))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Adding Noise to image"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Writing a function to add noise\ndef add_noise(images):\n    noisy_images = []\n    for image in images:\n        noisy_image = cv2.add(image, 0.009*np.random.randn(96,96,1))    # Adding random normal noise to the input image & clip the resulting noisy image between [-1,1]\n        noisy_images.append(noisy_image.reshape(96,96,1))\n    return noisy_images\n\nif random_noise_augmentation:\n    db_images_noisy = add_noise(db_images)\n    print(\"Shape of noisy_train_images:\",np.shape(db_images_noisy))\n    \n    db_images_modify = np.concatenate((db_images_modify, db_images_noisy))\n    df_keypoints_modify = np.concatenate((df_keypoints_modify, df_keypoints))\n    fig, axis = plt.subplots()\n    plot_sample(db_images_noisy[sample], df_keypoints[sample], axis, \"Random Noise Augmentation\")\n    \nprint(\"Shape of images database after shifting:\",np.shape(db_images_modify))\nprint(\"Shape of keypoints dataframe after shifting:\",np.shape(df_keypoints_modify))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualizing our final dataset with all augmentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Shape of final train_images: {}\".format(np.shape(db_images_modify)))\nprint(\"Shape of final train_keypoints: {}\".format(np.shape(df_keypoints_modify)))\n\nif horizontal_flip:\n    print(\"Horizontal Flip Augmentation: \")\n    fig = plt.figure(figsize=(20,8))\n    for i in range(10):\n        axis = fig.add_subplot(2, 5, i+1, xticks=[], yticks=[])\n        plot_sample(db_images_flipped[i], df_keypoints_flipped[i], axis, \"\")\n    plt.show()\n\nif shift_augmentation:\n    print(\"Shift Augmentation: \")\n    fig = plt.figure(figsize=(20,8))\n    for i in range(10):\n        axis = fig.add_subplot(2, 5, i+1, xticks=[], yticks=[])\n        plot_sample(db_images_shifted[i], df_keypoints_shifted[i], axis, \"\")\n    plt.show()\n    \nif rotation_augmentation:\n    print(\"Rotation Augmentation: \")\n    fig = plt.figure(figsize=(20,8))\n    for i in range(10):\n        axis = fig.add_subplot(2, 5, i+1, xticks=[], yticks=[])\n        plot_sample(db_images_rotated[i], df_keypoints_rotated[i], axis, \"\")\n    plt.show()\n    \nif random_noise_augmentation:\n    print(\"Random Noise Augmentation: \")\n    fig = plt.figure(figsize=(20,8))\n    for i in range(10):\n        axis = fig.add_subplot(2, 5, i+1, xticks=[], yticks=[])\n        plot_sample(db_images_noisy[i], df_keypoints[i], axis, \"\")\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = np.array(db_images_modify)\nprint(X.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = np.array(df_keypoints_modify)\nprint(y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking the type of both X and y dataset\ntype(X), type(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test,y_train, y_test = train_test_split(X, y, test_size=0.20)\n\nprint(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert from int to float\nX_train = X_train.astype('float32')\nX_test = X_test.astype('float32')\ny_train = y_train.astype('float32')\ny_test = y_test.astype('float32')\n\n#Normalize the input image\nX_train = X_train / 255\nX_test = X_test / 255\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers.advanced_activations import ReLU\nfrom keras.layers import Dense, Conv2D, Flatten, AvgPool2D, BatchNormalization, Dropout, Activation, MaxPooling2D\nfrom keras.models import Model\n\nmodel = Sequential()\n\nmodel.add(Conv2D(32, (3, 3),use_bias=False, input_shape = (96, 96, 1)))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size = (2,2)))\n\nmodel.add(Conv2D(64,(3,3), use_bias=False))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size = (2,2)))\n    \nmodel.add(Conv2D(128,(3,3), use_bias=False))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\nmodel.add(Conv2D(256,(3,3), use_bias=False))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = 'relu'))\nmodel.add(Dropout(0.1))  \nmodel.add(Dense(30))\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import optimizers\n\nopt = optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\nmodel.compile(loss=\"mean_squared_error\",optimizer= opt, metrics = ['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(x = X_train, y = y_train, epochs = 100, batch_size = 128)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nmodel.save('model_facial_landmark.hdf5', overwrite = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Evaluating and predicting the test dataset\npredicted = model.evaluate(x = X_test, y = y_test)\n\nprint(\"Loss = \" + str(predicted[0]))\nprint(\"Test Accuracy = \" + str(predicted[1]))\n\ny_test_pred = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Showing test images\nfrom keras.preprocessing.image import img_to_array, array_to_img\nplt.imshow(array_to_img(X_test[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test_pred[0][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(20,18))\nfor i in range(20):\n    axis = fig.add_subplot(4, 5, i+1, xticks=[], yticks=[])\n    plot_sample(X_test[i], y_test_pred[i], axis, \"\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}