{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Bike Ads -- Starting kernel: CNN + brief EDA\nThe purpose of this kernel is to provide a starting point for working with this dataset. In the future, I may make a more complete kernel demonstrating my model results."},{"metadata":{},"cell_type":"markdown","source":"# Import libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport json\nimport os\nimport re\nimport seaborn as sns\nfrom collections import Counter\nimport random\n\n# -- Modeling --\nimport tensorflow as tf\nimport keras\nfrom keras import optimizers\nfrom keras.preprocessing.image import ImageDataGenerator\n\n# install Keras-Applications\n!pip install Keras-Applications\nfrom keras_applications.imagenet_utils import _obtain_input_shape\nfrom keras import backend as K\nfrom keras.layers import Input, Convolution2D, MaxPooling2D, Activation, concatenate, Dropout, Dense\nfrom keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D\nfrom keras.models import Model, Sequential\nfrom keras.engine.topology import get_source_inputs\nfrom keras.utils import get_file\nfrom keras.utils import layer_utils\n\nimport warnings  \nwarnings.filterwarnings('ignore')\n\ndef seed_everything(seed = 42):\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    tf.random.set_seed(seed)\n    \nseed_everything()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. Predicting bike prices from ad images using CNN"},{"metadata":{},"cell_type":"markdown","source":"## Making a train-test split"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/bike-ads-images-prices-specifications/combined_price-only.csv\")\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# choose indices for train-test split\nn = len(data)\ntrain_idx = np.random.choice(range(n), size=int(0.8*n), replace=False)\ntest_idx = [i for i in range(n) if i not in train_idx]\n\n\nprint(\"Number of training examples:\", len(train_idx)) \nprint(\"Number of testing examples:\", len(test_idx))\nprint(\"Number of examples that appear in both (should be zero):\", len(set(train_idx).intersection(set(test_idx))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# make train-test split\ntrain_label_df = data.loc[train_idx,:]\ntest_label_df = data.loc[test_idx,:]\n\n# save as csv (optional)\ntrain_label_df.to_csv(\"./df_train.csv\", index=False)\ntest_label_df.to_csv(\"./df_test.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Defining a CNN architecture\nThe architecture chosen below is taken from the work on a similar project: [AI Blue Book: Vehicle Price Prediction using Visual Features\n](https://arxiv.org/abs/1803.11227) by Richard R. Yang, Steven Chen, and Edward Chou. Their model is based on the SqueezeNet architecture, which is a lightweight architecture that is known for outperforming AlexNet\n\nThe code for the architecture is mostly copied from their [Github](https://github.com/richardyang/AI-blue-book)."},{"metadata":{"trusted":true},"cell_type":"code","source":"sq1x1 = \"squeeze1x1\"\nexp1x1 = \"expand1x1\"\nexp3x3 = \"expand3x3\"\nrelu = \"relu_\"\n\nWEIGHTS_PATH = \"https://github.com/rcmalli/keras-squeezenet/releases/download/v1.0/squeezenet_weights_tf_dim_ordering_tf_kernels.h5\"\nWEIGHTS_PATH_NO_TOP = \"https://github.com/rcmalli/keras-squeezenet/releases/download/v1.0/squeezenet_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n\n# Modular function for Fire Node\n\ndef fire_module(x, fire_id, squeeze=16, expand=64):\n    s_id = 'fire' + str(fire_id) + '/'\n\n    if K.image_data_format() == 'channels_first':\n        channel_axis = 1\n    else:\n        channel_axis = 3\n    \n    x = Convolution2D(squeeze, (1, 1), padding='valid', name=s_id + sq1x1)(x)\n    x = Activation('relu', name=s_id + relu + sq1x1)(x)\n\n    left = Convolution2D(expand, (1, 1), padding='valid', name=s_id + exp1x1)(x)\n    left = Activation('relu', name=s_id + relu + exp1x1)(left)\n\n    right = Convolution2D(expand, (3, 3), padding='same', name=s_id + exp3x3)(x)\n    right = Activation('relu', name=s_id + relu + exp3x3)(right)\n\n    x = concatenate([left, right], axis=channel_axis, name=s_id + 'concat')\n    return x\n\n\n# Original SqueezeNet from paper.\n\ndef SqueezeNet(include_top=True, weights='imagenet',\n               input_tensor=None, input_shape=None,\n               pooling=None,\n               classes=1000):\n    \"\"\"Instantiates the SqueezeNet architecture.\n    \"\"\"\n        \n    if weights not in {'imagenet', None}:\n        raise ValueError('The `weights` argument should be either '\n                         '`None` (random initialization) or `imagenet` '\n                         '(pre-training on ImageNet).')\n\n    if weights == 'imagenet' and classes != 1000:\n        raise ValueError('If using `weights` as imagenet with `include_top`'\n                         ' as true, `classes` should be 1000')\n\n\n    input_shape = _obtain_input_shape(input_shape,\n                                      default_size=227,\n                                      min_size=48,\n                                      data_format=K.image_data_format(),\n                                      require_flatten=include_top)\n\n    if input_tensor is None:\n        img_input = Input(shape=input_shape)\n    else:\n        if not K.is_keras_tensor(input_tensor):\n            img_input = Input(tensor=input_tensor, shape=input_shape)\n        else:\n            img_input = input_tensor\n\n\n    x = Convolution2D(64, (3, 3), strides=(2, 2), padding='valid', name='conv1')(img_input)\n    x = Activation('relu', name='relu_conv1')(x)\n    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool1')(x)\n\n    x = fire_module(x, fire_id=2, squeeze=16, expand=64)\n    x = fire_module(x, fire_id=3, squeeze=16, expand=64)\n    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool3')(x)\n\n    x = fire_module(x, fire_id=4, squeeze=32, expand=128)\n    x = fire_module(x, fire_id=5, squeeze=32, expand=128)\n    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool5')(x)\n\n    x = fire_module(x, fire_id=6, squeeze=48, expand=192)\n    x = fire_module(x, fire_id=7, squeeze=48, expand=192)\n    x = fire_module(x, fire_id=8, squeeze=64, expand=256)\n    x = fire_module(x, fire_id=9, squeeze=64, expand=256)\n    \n    if include_top:\n        # It's not obvious where to cut the network... \n        # Could do the 8th or 9th layer... some work recommends cutting earlier layers.\n    \n        x = Dropout(0.5, name='drop9')(x)\n\n        x = Convolution2D(classes, (1, 1), padding='valid', name='conv10')(x)\n        x = Activation('relu', name='relu_conv10')(x)\n        x = GlobalAveragePooling2D()(x)\n        x = Activation('softmax', name='loss')(x)\n    else:\n        if pooling == 'avg':\n            x = GlobalAveragePooling2D()(x)\n        elif pooling=='max':\n            x = GlobalMaxPooling2D()(x)\n        elif pooling==None:\n            pass\n        else:\n            raise ValueError(\"Unknown argument for 'pooling'=\" + pooling)\n\n    # Ensure that the model takes into account\n    # any potential predecessors of `input_tensor`.\n    if input_tensor is not None:\n        inputs = get_source_inputs(input_tensor)\n    else:\n        inputs = img_input\n\n    model = Model(inputs, x, name='squeezenet')\n\n    # load weights\n    if weights == 'imagenet':\n        if include_top:\n            weights_path = get_file('squeezenet_weights_tf_dim_ordering_tf_kernels.h5',\n                                    WEIGHTS_PATH,\n                                    cache_subdir='models')\n        else:\n            weights_path = get_file('squeezenet_weights_tf_dim_ordering_tf_kernels_notop.h5',\n                                    WEIGHTS_PATH_NO_TOP,\n                                    cache_subdir='models')\n            \n        model.load_weights(weights_path)\n        if K.backend() == 'theano':\n            layer_utils.convert_all_kernels_in_model(model)\n\n    return model\n\nimg_width = 227\nimg_height = 227\n\nmodel = Sequential()\nsqueezenet = SqueezeNet(weights='imagenet', include_top=False, input_shape = (img_width, img_height, 3), pooling=None)\nmodel.add(squeezenet)\n\n# \"Top layer\" adapted for regression\nmodel.add(Dropout(0.5))\nmodel.add(Convolution2D(1000, (1, 1), padding='valid'))\nmodel.add(Activation('relu'))\nmodel.add(GlobalAveragePooling2D())\nmodel.add(Dense(1, activation='linear'))\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training the model\nHere we train our CNN. We use mean squared error (MSE) as our loss function and report MSE and MAE for evaluation. The optimizer chosen is RMSprop.\nNote, we're mixing up the terms test and validation. Eventually, I think we should split the training set into train/validation -- but for a starter kernel we'll just use the testing set as \"validation.\""},{"metadata":{"trusted":true},"cell_type":"code","source":"# path to images\nimg_dir = \"../input/bike-ads-images-prices-specifications/images\"\n\n# append .jpg to id\ndef append_ext(fn):\n    return str(fn) + \".jpg\"\ntrain_label_df[\"ID\"] = train_label_df[\"ID\"].apply(append_ext)\ntest_label_df[\"ID\"] = test_label_df[\"ID\"].apply(append_ext)\n\n# parameters -- increase these to improve performance\nbs = 32 # batch size\nepochs = 8 \nsteps_per_epoch = 50 \nvalidation_steps = 50\n\n# ------------ DATA GENERATORS ------------\n# All images will be rescaled by 1./255\n\n# Training set: no data augmentation\n# train_datagen = ImageDataGenerator(rescale=1./255) \n\n# Training set: with data augmentation\ntrain_datagen = ImageDataGenerator(rescale = 1./255, \n                                   rotation_range=30, \n                                   width_shift_range = 0.2, \n                                   height_shift_range=0.2,\n                                   shear_range=0.2,\n                                   zoom_range = 0.2,\n                                   horizontal_flip = True)\n\ntrain_generator = train_datagen.flow_from_dataframe(dataframe=train_label_df, \n                                                    directory=img_dir, \n                                                    x_col=\"ID\", # id\n                                                    y_col=\"Price\", # score\n                                                    class_mode=\"raw\", \n                                                    target_size=(img_width, img_height), \n                                                    batch_size=bs)\n\n# Testing set\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\nvalidation_generator = test_datagen.flow_from_dataframe(dataframe=test_label_df, \n                                                    directory=img_dir, \n                                                    x_col=\"ID\", # id\n                                                    y_col=\"Price\", # score\n                                                    class_mode=\"raw\", \n                                                    target_size=(img_width, img_height), \n                                                    batch_size=bs)\n\n# Amount+dimensions of generated data\nfor data_batch, labels_batch in train_generator:\n    print('data batch shape:', data_batch.shape)\n    print('labels batch shape:', labels_batch.shape)\n    break\n# ----------------------------------------\n\n# Train the model\nmodel.compile(loss='mse', optimizer=optimizers.RMSprop(lr=0.0001), metrics=['mae', 'mse']) # lr=0.001 to 0.01 seem to work well \nhistory = model.fit_generator(train_generator,\n                              steps_per_epoch=steps_per_epoch,\n                              epochs=epochs,\n                              validation_data=validation_generator,\n                              validation_steps=validation_steps)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model diagnostics"},{"metadata":{"trusted":true},"cell_type":"code","source":"hist_dict = model.history.history\n\nfig, ax = plt.subplots(1,2,figsize=(10,4))\n\n# MAE\nplt.sca(ax[0])\nplt.plot(hist_dict[\"mae\"], label=\"training\")\nplt.plot(hist_dict[\"val_mae\"], label=\"validation\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Mean Absolute Error\")\nplt.legend()\n\n# MSE\nplt.sca(ax[1])\nplt.plot(hist_dict[\"mse\"], label=\"training\")\nplt.plot(hist_dict[\"val_mse\"], label=\"validation\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Mean Squared Error\")\nplt.legend()\n\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Considerations: a baseline regressor\nThis task does not seem easy. Likely reasons are: (i) people are inherently very hard to predict and we're trying to predict asking price rather than \"true\" price (ii) important bike features are very small or not visible (i.e. frame material) and may not be picked up by ebay's lower resolution images.\n\nA naive predictor would be to predict the median price in the training dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"(test_label_df[\"Price\"]-train_label_df[\"Price\"].median()).abs().mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"That is, with the baseline predictor, we are on average off by over $\\$1400$. I've found that even with training this CNN for ~30 epochs it still does not perform much better than $\\$1300$. This is not good; personally I would not buy a bike $\\$1300$ off my ideal price! A couple things to consider: (i) MAPE might be a better metric here; for a $\\$10000$ bike people would be more likely to pay another $\\$1300$, (ii) outliers might be skewing this performance -- see the following EDA. "},{"metadata":{},"cell_type":"markdown","source":"# 2. Brief EDA (ebay only)\nHow many unique specifications are there?"},{"metadata":{"trusted":true},"cell_type":"code","source":"site = \"ebay\"\n\nignore = [\"Price now\", \"Price was\", \"Price\", \"ID\", \"Condition\", \"Seller notes\", \"Title\", \"Product URL\", \"Photo URL\", \"UPC\", \"MPN\"]\nfile = \"../input/bike-ads-images-prices-specifications/data_%s.json\" % site\nattributes = []\nwith open(file,\"r\") as f:\n    for line in f:\n        x = json.loads(line)\n        attributes.extend([y for y in x.keys() if y not in ignore])\n\nlen(set(attributes))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"What are the most common specifications?"},{"metadata":{"trusted":true},"cell_type":"code","source":"common_attributes = Counter(attributes).most_common(25) # top 25 most common \nxy = list(zip(*common_attributes)) # getting ready to plot\nfig = plt.figure(figsize=(16,4))\nchart = sns.barplot(x=list(xy[0]), y=list(xy[1]))\nchart.set_xticklabels(chart.get_xticklabels(), rotation=60, horizontalalignment='right', fontsize=14)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Brand is almost always listed. Frame size, wheel size, bike type, and vintage are listed in over half the data. We see differences in \"Color\" and \"Colour\" between US and UK listings. We suspect brand would be an incredibly useful predictor to combine with the CNN model and improve predictions.\n\nNow let's take a look at the price data. We could look at `price.csv`, but I've included a script below to extract & convert prices from the raw JSON data. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# sites = [\"ebay\",\"bike_exchange\"] # uncomment this to loop over both sites\nsites = [\"ebay\"]\n\nPOUND_TO_DOLLAR_RATIO = 1.25 # as of June 2020\n\nIDs = []\nprices = []\nfor site in sites:\n    file = \"../input/bike-ads-images-prices-specifications/data_%s.json\" % site\n    \n    with open(file,\"r\") as f:\n        for line in f:\n            x = json.loads(line)\n            \n            if site == \"bike_exchange\":\n                price_key = \"Price now\" \n            else:\n                price_key = \"Price\"\n            \n            price_US = re.findall(\"[\\$]{1}[\\d,]+\\.?\\d{0,2}\",x[price_key])\n            price_UK = re.findall(\"[\\u00a3]{1}[\\d,]+\\.?\\d{0,2}\",x[price_key])\n\n            if price_US:\n                float_price = float(price_US[0].replace(\"$\",\"\").replace(\",\",\"\"))\n            elif price_UK:\n                float_price = POUND_TO_DOLLAR_RATIO * float(price_UK[0].replace(\"\\u00a3\",\"\").replace(\",\",\"\"))\n\n            IDs.append(int(x[\"ID\"]))\n            prices.append(round(float_price, 2))\n\n# plotting\nplt.hist(prices, bins=\"auto\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The prices are highly skewed right! Most bikes cost around $\\$1000$, but some bikes cost (are listed for sale at) over $\\$15000$.\n\n# Wrapping up\nThere is a lot more we can do with this data, but I hope this kernel is a useful starting point! Future work should try other CNN architectures, experiment with parameter choices, and train for a larger number of epochs. Another modeling approach would be to take a pretrained CNN (i.e. ResNet50) and extract features from the top level (before the dense layer). Then traditional regression models could be applied to these features.\n\nI'm relatively new to data science, and especially new to these sort of deep learning/computer vision tasks. Any suggestions are welcome. ðŸ˜Š"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}