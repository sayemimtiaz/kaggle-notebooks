{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Detect counterfeit Banknotes with machine learning","metadata":{}},{"cell_type":"markdown","source":"<strong>Original Data Source:</strong> \nFlury, B. and Riedwyl, H. (1988). Multivariate Statistics: A practical approach. London: Chapman & Hall, Tables 1.1 and 1.2, pp. 5-8.   \n","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://i.imgur.com/vzYAmpP.png\" alt=\"search Conterfeit\">","metadata":{}},{"cell_type":"markdown","source":"### ==> Goal: Detect counterfeit banknotes based on their size. ","metadata":{}},{"cell_type":"markdown","source":"# Table of contents\n\n\n[<h3>1. Content of the dataset</h3>](#1)\n[<h3>2. Predictions</h3>](#2)\n.... [2.1. Logistic Regression](#21)<br>\n.... [2.2. Random Forrest](#22)<br>\n.... [2.3. Decision Tree](#23)<br>\n.... [2.4. Neural Network](#24)<br>\n.... [2.5. SVC](#25)<br><br>\n[<h3>3. Clustering</h3>](#3)\n.... [3.1. KMeans with SVD](#31)<br>\n.... [3.2. KMeans with PCA](#32)<br><br>\n[<h3>4. Comparison of the models</h3>](#4)","metadata":{}},{"cell_type":"markdown","source":"# 1. Content of the dataset<a class=\"anchor\" id=\"1\"></a>\n","metadata":{}},{"cell_type":"markdown","source":"The dataset includes information about the shape of the bill, as well as the label. It is made up of 200 banknotes in total, 100 for genuine/counterfeit each.<br/>\n\n<strong>Attributes:</strong>\n- conterfeit: Whether a banknote is counterfeit (1) or genuine (0)\n- Length: Length of bill (mm)\n- Left: Width of left edge (mm)\n- Right: Width of right edge (mm)\n- Bottom: Bottom margin width (mm)\n- Top: Top margin width (mm)\n- Diagonal: Length of diagonal (mm)","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ndf = pd.read_csv(\"../input/swiss-banknote-conterfeit-detection/banknotes.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(df.isnull())\nplt.title(\"Missing values?\", fontsize = 18)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There is no missing value in the dataset.","metadata":{}},{"cell_type":"code","source":"# Pairwise relationships depending on counterfeit\nsns.pairplot(df, hue = \"conterfeit\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(df.corr(), annot = True, cmap=\"RdBu\")\nplt.title(\"Pairwise correlation of the columns\", fontsize = 18)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Predictions<a class=\"anchor\" id=\"2\"></a>","metadata":{}},{"cell_type":"markdown","source":"In the part, we will first separate the dataset in a training-set and a test-set. With the train-set, we will train the model and later we will the accuracy of the predictions of different models on the test-set.","metadata":{}},{"cell_type":"code","source":"# Shuffle the dataset\ndf = df.reindex(np.random.permutation(df.index))\n\nX = df.drop(columns = \"conterfeit\")\ny = df[\"conterfeit\"]\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n\nfrom sklearn.preprocessing import StandardScaler\nst = StandardScaler()\nX_train = st.fit_transform(X_train)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.1. Logistic Regression<a class=\"anchor\" id=\"21\"></a>","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression()\nmodel.fit(X_train,y_train)\n\npred = model.predict(st.transform(X_test))\n\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n\nclass_report = classification_report(y_test, pred)\nconf_matrix = confusion_matrix(y_test,pred)\nacc = accuracy_score(y_test,pred)\n\nprint(\"Classification report:\\n\\n\", class_report)\nprint(\"Confusion Matrix\\n\",conf_matrix)\nprint(\"\\nAccuracy\\n\",acc)\n\nresults = []\nresults.append((\"LogisticRegression\",class_report, conf_matrix, acc))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.2. Random Forrest<a class=\"anchor\" id=\"22\"></a>","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nrfc = RandomForestClassifier()\n\nrfc.fit(X_train, y_train)\n\npred = rfc.predict(st.transform(X_test))\n\nclass_report = classification_report(y_test, pred)\nconf_matrix = confusion_matrix(y_test,pred)\nacc = accuracy_score(y_test,pred)\n\nprint(\"Classification report:\\n\\n\", class_report)\nprint(\"Confusion Matrix\\n\",conf_matrix)\nprint(\"\\nAccuracy\\n\",acc)\n\nresults.append((\"RandomForestClassifier\",class_report, conf_matrix, acc))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.3. Decision Tree<a class=\"anchor\" id=\"23\"></a>","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\ndtc = DecisionTreeClassifier()\n\ndtc.fit(X_train, y_train)\n\npred = dtc.predict(st.transform(X_test))\n\nclass_report = classification_report(y_test, pred)\nconf_matrix = confusion_matrix(y_test,pred)\nacc = accuracy_score(y_test,pred)\n\nprint(\"Classification report:\\n\\n\", class_report)\nprint(\"Confusion Matrix\\n\",conf_matrix)\nprint(\"\\nAccuracy\\n\",acc)\n\nresults.append((\"DecisionTreeClassifier\",class_report, conf_matrix, acc))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.4. Neural Network<a class=\"anchor\" id=\"24\"></a>","metadata":{}},{"cell_type":"code","source":"import tensorflow.keras\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Dense, Activation\n\nmodel = Sequential()\nmodel.add(Dense(6))\nmodel.add(Dense(10))\nmodel.add(Dense(10))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.fit(X_train,y_train.values, epochs = 50, verbose = 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = model.predict(st.transform(X_test))\npred = [int(round(t)) for t in pred.reshape(1,-1)[0]]\n\nclass_report = classification_report(y_test, pred)\nconf_matrix = confusion_matrix(y_test,pred)\nacc = accuracy_score(y_test,pred)\n\nprint(\"Classification report:\\n\\n\", class_report)\nprint(\"Confusion Matrix\\n\",conf_matrix)\nprint(\"\\nAccuracy\\n\",acc)\n\nresults.append((\"Neural Network\",class_report, conf_matrix, acc))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2.5. SVC<a class=\"anchor\" id=\"25\"></a>","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVC\nsvc = SVC()\n\nsvc.fit(X_train, y_train)\n\npred = svc.predict(st.transform(X_test))\n\nclass_report = classification_report(y_test, pred)\nconf_matrix = confusion_matrix(y_test,pred)\nacc = accuracy_score(y_test,pred)\n\nprint(\"Classification report:\\n\\n\", class_report)\nprint(\"Confusion Matrix\\n\",conf_matrix)\nprint(\"\\nAccuracy\\n\",acc)\n\nresults.append((\"SVC\",class_report, conf_matrix, acc))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Clustering<a class=\"anchor\" id=\"3\"></a>","metadata":{}},{"cell_type":"markdown","source":"Now we'll use the unsupervised learning algorithm KMeans to find clusters in the dataset without using the counterfeit column to see if it will be capable to separate well the dataset in two clusters.\n","metadata":{}},{"cell_type":"markdown","source":"## 3.1. KMeans with SVD<a class=\"anchor\" id=\"31\"></a>","metadata":{}},{"cell_type":"code","source":"from sklearn.decomposition import TruncatedSVD\nsvd = TruncatedSVD(n_components = 2, random_state = 0)\n\ntransf = svd.fit_transform(X)\n\nplt.scatter(x = transf[:,0], y = transf[:,1])\nplt.title(\"Dataset after transformation with SVD\", fontsize = 18)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.cluster import KMeans\n\nkm = KMeans(n_clusters = 2)\nc = km.fit_predict(transf)\n\nplt.scatter(x = transf[:,0], y = transf[:,1], c = c)\nplt.title(\"Clustering with Kmeans after SVD\", fontsize = 18)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.scatter(x = transf[:,0], y = transf[:,1], c = y)\nplt.title(\"Original labels after SVD\", fontsize = 18)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.2. KMeans with PCA<a class=\"anchor\" id=\"32\"></a>","metadata":{}},{"cell_type":"code","source":"from sklearn.decomposition import PCA\npca = PCA(n_components = 2, random_state = 0)\n\ntransf = pca.fit_transform(X)\n\nplt.scatter(x = transf[:,0], y = transf[:,1])\nplt.title(\"Dataset after transformation with PCA\", fontsize = 18)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"km = KMeans(n_clusters = 2)\nc = km.fit_predict(transf)\n\nplt.scatter(x = transf[:,0], y = transf[:,1], c = c)\nplt.title(\"Clustering with Kmeans after PCA\", fontsize = 18)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.scatter(x = transf[:,0], y = transf[:,1], c = y)\nplt.title(\"Original labels after PCA\", fontsize = 18)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Comparison of the models<a class=\"anchor\" id=\"4\"></a>","metadata":{}},{"cell_type":"code","source":"labels  = []\nheight = []\nfor i in range(len(results)):\n    labels.append(results[i][0])\n    height.append(results[i][-1])\n    \nplt.figure(figsize = (12,6))    \nax = sns.barplot(labels,height)\nax.set_xticklabels(labels, fontsize = 18, rotation = 90)\nplt.title(\"Comparison of the models\", fontsize = 18)\nplt.ylabel(\"Prediction accuracy\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<strong>==> All of the models give good predictions.</strong>","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://i.imgur.com/5VIHT6R.png\" alt = \"good\">","metadata":{}}]}