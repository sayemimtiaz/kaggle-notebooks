{"cells":[{"metadata":{"id":"oOxsIvJtD1PK","colab_type":"text","_uuid":"866f6dca507ec3c16544f7cc6e49b359d0cb1b4f"},"cell_type":"markdown","source":"#How Good Is This Wine?  - Using A.I For Quality Control\n\nHello everyone, and a warm welcome to this interactive tutorial where we´ll be exploring how we can use some pretty simple A.I to automate our Quality Control process, saving us time and money.\n\nAs always, our mission here is to show people in all types of business, that these A.I  tools are available to them and that they can use them without any technical knowledge. You don´t need to know the code behind Microsoft Word in order to use it, right? I hope to convince you that the same applies here.\n\n##Introducing the data\n\nSo, for today, say here hello to our dataset: a list of 5,000 white wines with information about their chemical attributes, things like sulphates, chlorides, PH levels, etc. (you can have a look at the complete spreadsheet [here](https://docs.google.com/spreadsheets/d/1YU2sqcuG4_DAzYvD-uLbp5NHg21S51CxILCq9xPaOsE/edit#gid=1916199166))\n\nRight, so why on earth would that be of any use to us?\n\nImagine the following scenario: Let´s say we are medium-sized wine distributor, we receive wines from producers, store them and then supply them to liquor stores around the country or even sell them online.  Let´s say that we carry out on a daily basis random quality control tests on samples of wines we receive from the producers. The spreadsheet we are going to be working with today is comprised from all these past tests that we have carried out. Let´s have a look."},{"metadata":{"trusted":true,"_uuid":"bea5a2a8a6f00f2608f6289be0b1f60b0eb5aea9"},"cell_type":"code","source":"import os\n\nprint(os.listdir(\"../input\"))\n","execution_count":null,"outputs":[]},{"metadata":{"id":"lMVQJYqtr95Q","colab_type":"code","outputId":"3745b397-2d96-40e0-c6d1-d5b521e3da1b","colab":{"base_uri":"https://localhost:8080/","height":700},"trusted":true,"_uuid":"435c38c71e9b40b9181128c919b1a79089b27a67"},"cell_type":"code","source":"#We import the library of pandas ( remember pandas is like Excel, but after having taken some sort of illegal steroids)\nimport pandas as pd\n#I previously uploaded our data to this link\n#data_url=(\"https://github.com/busyML/Wine-Quality-Control/blob/master/winewhite.xlsx?raw=true\")\n\n#We load our data from that link to Pandas \ndata = pd.read_csv(\"../input/wineQualityWhites.csv\")\n\ndata.drop(columns=[\"quality\",\"Unnamed: 0\"], inplace=True)\n#We print out the first 20 rows of our data to visualize what we are working with here\ndata.head(21)","execution_count":null,"outputs":[]},{"metadata":{"id":"bn-TVgvVudEk","colab_type":"text","_uuid":"7afbacad5f5066ca3f3bcc7b899b4ac788a1ba70"},"cell_type":"markdown","source":"This dataset, I have to admit, doesn´t look particularly interesting. This is probably because this is just a set of features **without** any conclusions made. For example, in many datasets, we would have a set of columns like this but also an additional column that would maybe give some sort of judgment about the wine (for example, a column that says \"good wine/bad wine\"). The name of the game in those cases is to create a model that is able to classify the wines as good or bad, based on the past labels. These sort of predictions are possible when we have previously collected **answers**  .\n\nHowever, no such luck with this dataset here. We have no indication we could even try to predict. More often than not, datasets in the real world are like this. So what can we use this datasheet for? Well, as we go through step by step, we will still be able to do some very interesting things like:\n\n\n*   **Anomaly Detection**: Our model will be able to detect if something seems to be wrong (for example if it has been corked or the wine has gone off) with a new given wine.\n\n*   **Categorize and order our data for us**: Our model will find categories within our dataset and then tell us which category a new wine belongs to. This can be extremely useful for pricing for example.\n\nSo, first things first, we need to clean our data, let´s get mopping.\n\n"},{"metadata":{"id":"5HBdWiCl0jFe","colab_type":"text","_uuid":"ecba44a04fd8d821d3dbc029423ccb1ef3cdc7e5"},"cell_type":"markdown","source":"####Step 0 -Importing libraries\n\nFirst of all, as always we need to pre-load the libraries to make our lives a hundred times easier. This is always the first thing for us to do. Consider it as our **Step 0**.\n\nWithout these libraries, we wouldn't be able to use any of the easy commands. These libraries use open source code created by other people, allowing us to execute complex operations with commands that are only a few words long. I always import all common libraries whether I end up using them or not just so that I don't need to worry about any of this later on. \n\n*To execute the code and follow along, simply press the *\"Play\"* button at the top left-hand side of the code.*\n"},{"metadata":{"id":"8ma3OslK0pz-","colab_type":"code","colab":{},"trusted":true,"_uuid":"9594ea3b5123a353446e1a84ab020a6ea918a96c"},"cell_type":"code","source":"import numpy as np # This library allows to easily carry out simple and complex mathematical operations.\nimport matplotlib.pyplot as plt #Allows us to plot data, create graphs and visualize data. Perfect for your Powerpoint slides ;)\nimport sklearn #The one and only. This amazing library holds all the secrets. Containing powerful algorithms packed in a single line of code, this is where the magic will happen.\nimport sklearn.model_selection # more of sklearn. It is a big library, but trust me it is worth it.\nimport sklearn.preprocessing \nfrom sklearn.preprocessing import LabelEncoder,OneHotEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score, explained_variance_score,mean_absolute_error,mean_squared_error,precision_score,recall_score, accuracy_score,f1_score\nfrom sklearn.utils import shuffle\nimport pandas as pd\nfrom pandas.plotting import radviz\n\n\nimport random # Allows us to call random numbers, occasionally very useful.\n#from google.colab import files #Allows to upload and download files directly from the browser.\nimport pprint#Allows us to neatly display text\nfrom collections import OrderedDict\n\n\n\n#Unsupervised Learning\nfrom sklearn.neighbors import NearestNeighbors,LocalOutlierFactor\nfrom sklearn.cluster import KMeans\n","execution_count":null,"outputs":[]},{"metadata":{"id":"uf_onLlDw2JF","colab_type":"text","_uuid":"d4b71feb8f256a44b6d0c3ddb6249cfaa27b889e"},"cell_type":"markdown","source":"## I - Data cleaning\n\nSo it looks like we´ve been blessed with a relatively clean dataset. First of all, we can see that we are purely dealing with numerical values, which is fantastic news for our algorithms. If we had any texts or categories in our columns, we would have to convert these to some sort of number encoding.\n\nThere is one thing that we need to take care of however...\n\n"},{"metadata":{"id":"093pEFLBzL1N","colab_type":"text","_uuid":"7e1b35723806803a371e66702d62906bf5bdb72b"},"cell_type":"markdown","source":"###Step 1- Everyday I´m shuffling...\n\nSo this is extremely simple. We want to shuffle our data. Why is this? Because if the data is not shuffled, then some unwanted bias might slip in. The most common, for instance, would be if the data was entered in chronologically. Now imagine that we were buying cheaper and less palatable wines 5 years simply because our company was smaller and we had less resources. The model might pick up on this and could think that the year we purchased the wine in could be indicator of how good the wine is, and if we gave it a new wine to sample, it might overestimate its quality simply because we purchased it in 2019.\n\nIt is always a best practice to shuffle our data, and there is no excuses in not doing, especially when it takes only one line of code:\n"},{"metadata":{"id":"4TkTKAfJ0dUH","colab_type":"code","outputId":"4dfe2c43-26db-47f3-972a-6a9eab0a776f","colab":{"base_uri":"https://localhost:8080/","height":700},"trusted":true,"_uuid":"26c7ca72f0fc97f972e07e975236ed44841692e1"},"cell_type":"code","source":"#we use the \"sample\" command of pandas to shuffle our data, the random state means that we will always shuffle the data the same way so that when different people load this code, they will all get the same results.\ndata= data.sample(frac=1, random_state=85)\n\n#we print out the first 20 rows of our data to check that it has indeed been shuffled, on the left we have the index number which we can also think of as an ID number.\ndata.head(21)","execution_count":null,"outputs":[]},{"metadata":{"id":"IVjvTWUC1qgp","colab_type":"text","_uuid":"9de4705d94f6e62de5ac15615fa60703e72d432f"},"cell_type":"markdown","source":"## II- Data Learning\n\n###Anomaly Detection\n\nSo the first thing we can do with our data, is to create an anomaly detection model. Put as simply as possible, we will use an algorithm to scan through all the wines of our current dataset so that it can learn what a \"normal\" white wine is like. This way, when we give it the data for a test on a new wine we receive in the warehouse, it will be able to detect whether this wine is normal or if there is something \"abnormal\", or in everyday language, \"fishy\" about it.\n\nThe algorithm is called **\"Local Outlier Factor\"**, and here is a visualization of how it works:\n\n\n![alt text](https://github.com/busyML/Wine-Quality-Control/raw/master/anomaly_comparison_0011.png)\n\n\nThe yellow dots are \"normal\" samples whereas the blue dots on the edge have been identified as \"abnormal\"\n\nLet's first load and train our algorithm in a couple of lines of code:"},{"metadata":{"id":"0CYFlfJwu1I9","colab_type":"code","outputId":"18ccada7-e332-473b-ce40-e817f08a2c40","colab":{"base_uri":"https://localhost:8080/","height":88},"trusted":true,"_uuid":"f13bb8a136466ac32e2fad87551aff37f10e3df4"},"cell_type":"code","source":"#From The SKlearn library, we can load this handy algorithm called \"Local Outlier Factor\", we'll call it lof for short from now on.\nlof = LocalOutlierFactor(novelty=True)\n\n#Using the \".fit\" command, we are ordering our algorithm to learn from our data what a normal white wine should be\nlof.fit(data)\n\nprint(\"Learning Done!\")\n\n","execution_count":null,"outputs":[]},{"metadata":{"id":"vYvNxKkqo86L","colab_type":"text","_uuid":"a4d3a2525ea42b98233fe8437c903af4deadec7c"},"cell_type":"markdown","source":"There you go! In half a second, our model learnt what a good wine should look like. Now let's put it to the test by giving it three new wines it has not seen before, we'll name them **Wine_1**, **Wine_2** and  **Wine_3**. \nSo imagine the scene, it's* 5:30 AM* and you are receiving the first order of the day. You take out three bottles of white wine and take a chemical test for quality control. Once you have their data, you can very easily use our algorithm to see if everything is ok with this batch. You run the test."},{"metadata":{"id":"AEgi5vyHo-cl","colab_type":"code","outputId":"b8ee5a75-e85f-4433-8ecb-80fca853a04e","colab":{"base_uri":"https://localhost:8080/","height":119},"trusted":true,"_uuid":"e49844982ceec069d888d82847e35b223f2ce7d7"},"cell_type":"code","source":"#Chemical Data for Wine 1\nwine_1= [[6.8,0.32,0.16,7,0.045,30,145,0.9949,3.18,0.47,9.6]]\n\n#Chemical Data for Wine 2\nwine_2 = [[7.6,1.58,0.0,2.1,0.136,5.0,9.0,0.99476,3.5,0.4,10.9]]\n\n#Chemical Data for Wine 3\nwine_3=[[5.2,0.37,0.2,7.6,0.046,35,110,0.9954,3.29,0.58,9.6]]\n\n\n#We can use the \".predict\" command to ask the algorithm to detect an anomaly, if it outputs \"1\", the wine is normal, if not it will output a \"-1\"\n\n\n#We can then create a simple \"if/else\" condition that will give us the outcome in plain English.\nprint('for wine 1 :')\nif lof.predict(wine_1)==1:\n  print(\"This wine is normal, it passes quality control.\")\nelse:\n  print(\"Abnormal wine detected! Human checking is needed on this one!\")\n  \nprint('for wine 2 :')\nif lof.predict(wine_2)==1:\n  print(\"This wine is normal, it passes quality control.\")\nelse:\n  print(\"Abnormal wine detected! Human checking needed !\")\n  \nprint('for wine 3 :')\nif lof.predict(wine_3)==1:\n  print(\"This wine is normal, it passes quality control.\")\nelse:\n  print(\"Abnormal wine detected! Human checking is needed on this one!\")\n  \n  \n  \n  \n","execution_count":null,"outputs":[]},{"metadata":{"id":"18JKDwe1tyn8","colab_type":"text","_uuid":"c849fb044f3948cd09580afb698b97fb34c9e36e"},"cell_type":"markdown","source":"Ok, so two of our three wines passed. So what is going with wine #2 ? As the machine tells you to, you decide to pick up the bottle and give up it a closer look... and you realize you accidentally grabbed a bottle of red wine. A clear brain fart on your part, but you console yourself that it is 5:30 AM after all and you are happy that nobody was around to  see you. You quietly bless the algorithm that saved you from that an embarrassing moment where you have to aplogize to a customer and go off to make yourself a well-earned coffee.\n\n\n---\n\nSo, in summary, this algorithm was able to flag up anything strange in our test samples. In this case, the data for wine #2 is genuinely taken from red wine (as any oenologist will be quick to attest) so we would expect that the algorithm detects it as an abnormal white wine!\n\nA final point, it is important to understand that the algorithm is not saying that the wines are \"good\" or \"bad\", but simply \"common\" or \"very uncommon\". Say we had an exceptionally high quality wine, our algorithm might flag it up as an abnormal, as in “abnormally delicious”. Whenever the algorithm finds an anomaly, it is down to the human to double check that anomaly and investigate as too what is so strange about it.\n\nSo that was anomaly testing, but what else can be done with our data?\n"},{"metadata":{"id":"xg569tkXwJHL","colab_type":"text","_uuid":"f1de7e4858dfbf5e3d26b950fc449a30ae1fb37c"},"cell_type":"markdown","source":"###Categorization\n\nAs we mentioned at the beginning, our data is not categorized in anyway. However, we can use an algorithm to delve into the data for us and find commonalities between different wines in order to form categories  (this is also known as clustering). This is incredibly useful since it means we can transform big bulks of unsorted data in a neat set of categories. We can then use those categorizes for lots of things, like market research (finding different groups of customers of our business), for technical support (what are the different sort of queries received), or for re-organizing our stock of products (like in our case with wine). I could go on and on with the use cases.\n\nSo the algorithm we will use for this is called **K-means**, and here is a picture for you to visualize what it actually does: \n\n![texto alternativo](https://github.com/busyML/Wine-Quality-Control/raw/master/clustering_image.jpg)\n\nAs you can see above, the algorithm takes the data from the left and on the right finds three distinct groups, represented by the different colors. Each point is a different sample however when two points are the same color, we can think of them as being similar and thus belonging to the same category. This is how we can categorize our data!\n\nThe great thing here is that we can choose how many categories  we want. We could ask our algorithm to separate our data into 20 categories  or just 2. This decision will be based on our business context. As our dataset is not that large and all wines are not different from one another anyway (sorry if I´ve offended anyone), I´m going to ask our algorithm to divide our wine data into **three categories**\n\nSo as always, we´ll use just a few lines of code to load and use this algorithm on our data:"},{"metadata":{"id":"o2IQNVUy1sA-","colab_type":"code","outputId":"d28109f2-349b-4a11-a196-1618098a796a","colab":{"base_uri":"https://localhost:8080/","height":85},"trusted":true,"_uuid":"cadc097066f5145f1f14bf4ac1688a1d18a08e35"},"cell_type":"code","source":"\n#we import the kmeans algorithm from sklearn\nkmeans= KMeans(n_clusters=3)\n\n#we use the \".fit\" command to use the kmeans algorithm on our data\nkmeans.fit(data)\n\n#We create a new column in a data spreadsheet that records for each wine the category it was given\ndata['category']= kmeans.fit_predict(data)\n\n#prints out the different categories we have and the number of wines that were assigned to it\ndata['category'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"id":"O_XWRrCuXgh5","colab_type":"text","_uuid":"4ec930f427f195833d8c288d29e010aa03493823"},"cell_type":"markdown","source":"Ok, done, so our data has been separated into three distinct groups! For now, the name of these categories is pretty boring:\n\n* **Category 0:** has 1977 wines.\n* **Category 1:** has 1796 wines.\n* **Category 2:** has 1125 wines.\n\nWe’ve also added this categorization to our original datasheet in an extra column, as you can see below:"},{"metadata":{"id":"K6rW3zTkW5p6","colab_type":"code","outputId":"b55be530-93fe-4241-8112-776b209b486b","colab":{"base_uri":"https://localhost:8080/","height":717},"trusted":true,"_uuid":"df0e6feb489f666a829b8235f309c321ec18cd8f"},"cell_type":"code","source":"data.head(21)","execution_count":null,"outputs":[]},{"metadata":{"id":"r7rwqiIKZW2h","colab_type":"text","_uuid":"52ff23c3aa7a5f231fff31073c12b89ed2b5ce49"},"cell_type":"markdown","source":"####Naming the categories\nRight, so here comes the **crucial** part, the human added value. The **Kmeans** algorithm grouped these data points for us into three groups but it is unable to tell us why! All that we know is that there is some sort of similarity between the wines within each group, but it is down to us to figure out what this similarity actually is. What we can do for now is to display the ID number of 20-30 wines of each category and find out for ourselves what they all seem to have in common:"},{"metadata":{"id":"pGBn6Cw8U28o","colab_type":"code","outputId":"36a62674-d7da-4a44-dd39-cd5e83ff451c","colab":{"base_uri":"https://localhost:8080/","height":88},"trusted":true,"_uuid":"b8165f8b6444554056157690be687e237edf9955"},"cell_type":"code","source":"#We initialize a list of empty lists that will later contain the wines of each category\ncategory_0=[]\ncategory_1=[]\ncategory_2=[]\n\n#this function will sort the first 100 wines of our spreadsheet based on what category they belong to.\nfor i in range (100):\n  if (data.iloc[i]['category'])==0:\n    category_0.append(data.index[i])\n  if (data.iloc[i]['category'])==1:\n    category_1.append(data.index[i])\n  if (data.iloc[i]['category'])==2:\n    category_2.append(data.index[i])\n\n#Let´s print out the id number numbers belonging to each category.    \nprint(len(category_0),\"wines in category 0:\",category_0)\n\nprint(len(category_1),\"wines in category 1:\",category_1)\n\nprint(len(category_2),\"wines in category 2:\",category_2)\n                      ","execution_count":null,"outputs":[]},{"metadata":{"id":"8Wf33tY9a719","colab_type":"text","_uuid":"adacfbdfe96c975a4a4b15d89c27ed5fdffb99c0"},"cell_type":"markdown","source":"Great, so from the first 100 wines of our list, we what we have above are the id numbers for each wine and in which category they are. \n\n\nSo now this is the fun part. Now that we have this list of wines that supposedly share something common, we let’s physically go to our warehouse and pull out the wines print it out for each category and see what they all have in common. It could be all sorts of things, maybe the wines from each category are from a different type of grape (*Chablis*, *Chardonnay*, etc.), or maybe they come from a different region (*South America*, *North America*, *Europe*) or maybe they are from large producers or small producers. Whatever it is, there should be some sort of commonality that jumps out at you straight away and that explains why the algorithm separated the data in this way.\n\nNow let´s imagine that in our case, after a rather fun tasting session that dragged on late into the night (and of which the resulting hangover explains why you previously tested red white by mistake), it becomes clear to us that the algorithm separated our data in terms of quality. Rather impressive, and this is fantastic, because quality is related to price. Which means that our algorithm is able, in our fictional example, to discriminate by taste quality and we can use this to set our pricing for our wine. So we can now automate our pricing process!\n\nSo after the hours of tasting, we are able to give the following labels to our wine categories:\n\n\n* **Category 0**: Average, mid-range wine, usually priced between $30-50\n\n* **Category 1:**  Low range wine usually priced under $30\n\n* **Category 2:** High-end, great quality wines, usually priced over $50\n\n\n\nSo now that we´ve figured that out, let´s just update our spreadsheet to change the category number we have for each wine from \"0, 1, 2\" to something a bit more meaningful like ** \"Low price\", \"Medium price\", \"High price\"**.\n\n\nWe can quickly do so  with the following code:"},{"metadata":{"id":"duR5AXmxk5zK","colab_type":"code","outputId":"51f26497-11a3-4d92-b39d-b748225467ae","colab":{"base_uri":"https://localhost:8080/","height":955},"trusted":true,"_uuid":"0fd7b95e74f92014fc9efc0e3ca8a0e58e4fed83"},"cell_type":"code","source":"#Here we use a short function to convert the categories numbers to plain English labels that we´ll be able to understand.\n\ndata['category'] = data['category'].apply(lambda x:\"High Price\" if x==2 else x)\ndata['category'] = data['category'].apply(lambda x:\"Medium Price\" if x==0 else x)\ndata['category'] = data['category'].apply(lambda x:\"Low Price\" if x==1 else x)\n\n#We print the top part of our dataset to observe the changes\ndata.head(21)","execution_count":null,"outputs":[]},{"metadata":{"id":"YBfJWYAnrqTs","colab_type":"text","_uuid":"899763966024ebb1b06dd637a5421cadb9ad1399"},"cell_type":"markdown","source":"Looking good. Just for safe keeping, now that we have categorized our wines and given them labels, this is now a pretty handy spreadsheet to have for our employees.\n\n\nWe can download it to our hard drive with the following code:\n"},{"metadata":{"id":"-GnJvMEyl-Wa","colab_type":"code","colab":{},"trusted":false,"_uuid":"fab755e68a39c3ea50866396a7c4abc007410bcb"},"cell_type":"code","source":"#We create an excel file that contains the wine with their new categories\ndata.to_csv(\"wines with price categories.csv\")\n\n#We use the \".download\" command to download the new excel file to our browser\n#files.download(\"wines with price categories.xlsx\")","execution_count":null,"outputs":[]},{"metadata":{"id":"CLE3wldjsw2_","colab_type":"text","_uuid":"6065005d25837471f296563b9b974c7b194a8be1"},"cell_type":"markdown","source":"### Classifying new wines.\n\nSo what´s even better, is that now when we receive new wines into our warehouse, we can ask our algorithm to classify them based on our previous data. So let´s take **Wine 1** and **Wine 3** (not **wine 2** because it failed the anomaly test, remember), and let´s see what our **Kmeans** algorithm categorizes them as:"},{"metadata":{"id":"toC2E0XqmeEF","colab_type":"code","outputId":"3a111268-af3c-4438-e54c-f9d6d6823505","colab":{"base_uri":"https://localhost:8080/","height":231},"trusted":true,"_uuid":"7a9f1e2f75219b0eccddbfa53f80cca2a0e66b5e"},"cell_type":"code","source":"#We can use the \".predict\" command for this\n\n#A simple condition to interpret the output in plain english\nif kmeans.predict(wine_1)==2:\n        print(\"Wine 1 should be high priced (more than $50)\")\nif kmeans.predict(wine_1)==0:\n        print(\"Wine 1 should be medium priced ($30-50)\")\nif kmeans.predict(wine_1)==1:\n        print(\"Wine 1 should be low priced (less than $30)\")\n\n\nif kmeans.predict(wine_3)==2:\n        print(\"Wine 3 should be high priced (more than $50)\")\nif kmeans.predict(wine_3)==0:\n        print(\"Wine 3 should be medium priced ($30-$50)\")\nif kmeans.predict(wine_3)==1:\n        print(\"Wine 3 should be low priced (less than $30)\")\n  \n  \n","execution_count":null,"outputs":[]},{"metadata":{"id":"4tGH6qysvtF7","colab_type":"text","_uuid":"65f097cce01f7306de08ebddaa184da255ac402a"},"cell_type":"markdown","source":"There we have it, for the two wines we inputted, the algorithm has judged **wine** 1 to be average quality wine and therefore it should be put in the medium price bracket.\n\nMeanwhile, **Wine 3** is apparently of higher quality and so should be priced accordingly.\n\nWhat we have here is now an automated price setting system, something that can tangibly speed up the ops at our wine warehouse.\n\n\n####Visualization\nSo we´ve dealt with a lot of numbers so far, now perhaps it´s time for a bit pretty visualization. Let´s try to actually visualize how our algorithm has separated our different wines and see what insights we can draw from it:\n\nFor this, we´ll use a graph called a \"**Radviz**\" plot, which allows us to visualize all our wines (each dot being one of our wines) and see how they relate to our different features and other wines:\n\n\n![texto alternativo](https://github.com/busyML/Wine-Quality-Control/raw/master/radviz.png)"},{"metadata":{"id":"JLj7gbwA0DlD","colab_type":"text","_uuid":"39ea863ed3686890c0008a8ee847d50e9575e7f1"},"cell_type":"markdown","source":"\nSo, what are we looking at here? Each dot represents a wine from our dataset and they have been color-coded as per the price bracket that our algorithm assigned to them. \n\nA few things jump out just from skimming over this plot:\n\n\n* **The high priced wines seem to have higher levels of alcohol and sulphates**\n*  **Low priced wines have more residual sugar and chlorides**\n*  **Medium priced wines seem to have an average level of pH ( which makes sense)**\n\n\nSo those are a few inferences we can make, and we could use this for some business intelligence; i.e if we wanted to avoid receiving low-quality wines from our suppliers, we could tell them that we will not be accepting wines that have over a certain level of *residual sugar*.\n\nFinally, as I´m sure you agree, this plot is not perfect. There seems to be a lot of overlap between the categories for instance. The reason for this despite this being a 2D plot, you should actually think of it as 3D. Imagine that it is in fact a hill and that we are looking down at it from above. When our data is multi-dimensional it is always hard to visualize. For example our spreadsheet has 11 columns, which means it needs to be represented in ***11-D***. This is impossible for our feeble human brain but thankfully, it is something that computers find very easy to do. As such, the sorts of visualizations like the one above is probably as close as we´ll ever be able to get to visualizing complex datasets like the one we have today.\n\nWe have trained our models to **1) detect anomalies** and **2) Sort our wines into price categories** and these were the most important methodologies and concepts I wanted to share with you today.\n\nOur final task will be to implement these models into a short program through which any employee could use with in order to obtain from our models useful predictions to speed up their job.\n\n#Data Predicting\n\nSo let´s now build a simple and easy to use program that allows our employees at the wine warehouse to input the chemical data of a new wine and obtain some useful information about it.\n\nUnless you are a web developer or programmer, feel free skip the technical explanation, however , I do recommend that you try to use it for yourself and see how the predictions can be carried out in real time. Please press the \"*play*\" button on the top left-hand side and follow the instructions. This will allow you to start forming an idea of how we can integrate these tools into our everyday office lives."},{"metadata":{"id":"JstZswhAApQi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":221},"outputId":"0cfb7227-b852-46dd-da76-741d330ae600","trusted":true,"_uuid":"ec68ea22cd90e0ad516b4040ab985d1772da8a7c"},"cell_type":"code","source":"#We create a program called \"wine_categorizer\"\n\ndef wine_categorizer():\n  \n  #The first prompt asks the user whether they have data correctly formatted. If not, they will have to enter it manually.\n  \n  prompt1=input(\"Do you have the wine data in the following format:[fixed acidity,volatile acidity,citric acid....]? (yes/no)\")\n  #if that is the case....\n  if prompt1==\"yes\" or prompt1==\"Yes\" or prompt1==\"y\" or prompt1==\"YES\":\n    #...we ask the user to simply copy and paste the line of data\n    print(\"ok great! just copy and paste the data below\")\n    \n    inputted_data=(input(\":\"))\n    #This variable changes the user´s input from a string to a numerical list, that we can compute it\n    formatted_data=[list(map(float,inputted_data.split(',')))]\n  #if not we get the user to input the data manually, one variable at a time\n  else:\n    \n    print(\"Ok, no problem, let´s do it manually:\")\n    \n    entered_fixed_acidity=float(input(\"the wine´s fixed acidity:\"))\n    entered_volatile_acidity=float(input(\"volatile acidity:\"))\n    entered_citric_acid=float(input(\"citric acid:\"))\n    entered_residual_sugar=float(input(\"residual sugar:\"))\n    entered_chlorides=float(input(\"chloride levels:\"))\n    entered_free_sulfur_dioxide=float(input(\"free sulfur dioxide level:\"))\n    entered_total_sulfur_dioxide=float(input(\"total sulfur dioxide :\"))\n    entered_density=float(input(\"density:\"))\n    entered_pH=float(input(\"pH level :\"))\n    entered_sulphates=float(input(\"sulphates :\"))\n    entered_alcohol=float(input(\"alcohol% :\"))\n    #formatting the data so it can computed by our algorithms\n    formatted_data=[[entered_fixed_acidity,entered_volatile_acidity,entered_citric_acid,entered_residual_sugar,entered_chlorides,entered_free_sulfur_dioxide,entered_total_sulfur_dioxide,entered_density,entered_pH,entered_sulphates,entered_alcohol]]\n  #perform anomaly detection on the entered data and save it the variable \"anomaly_check\"\n  anomaly_check=lof.predict(formatted_data)\n  \n  #if the anomaly check returns a 1, our data is not an anomaly\n  if anomaly_check==1:\n    print(\"This wine is normal, it passes quality control.\")\n    \n     #if the anomaly check returns a -1, our data is an anomaly\n\n  else:\n    print(\"Abnormal wine detected! Human checking needed !\")\n  #If the wine is an anomaly, then we terminate the program early ( no need to proceed to the price categorization.)\n  if anomaly_check==-1:\n  #Asking the user whether they want to check a new wine. If the answer is \"Yes\", the program restarts  \n    prompt2=input(\"Would you like to restart program to check another wine?(Yes/No)\")\n    if prompt2==\"yes\" or prompt2==\"Yes\" or prompt2==\"y\" or prompt2==\"YES\":\n      wine_categorizer()\n    else:\n      quit()\n #If the wine is deemed normal by the wine, the program moves onto the price category algorithm \n  if anomaly_check==1:\n      print(\"We will now proceed to the price categorization\")\n      \n      #we use the \".predict\" to what the price category the inputted wine would be\n      price_category_check=kmeans.predict(formatted_data)\n      if price_category_check==2:\n        print(\"This wine should be high priced (more than $50)\")\n      if price_category_check==0:\n        print(\"This wine should be medium priced ($30-50)\")\n      if price_category_check==1:\n        print(\"This wine should be low priced (less than $30)\")\n      prompt2=input(\"Would you like to restart program to check another wine?(Yes/No)\")\n      if prompt2==\"yes\" or prompt2==\"Yes\" or prompt2==\"y\" or prompt2==\"YES\":\n        wine_categorizer()\n      else:\n        quit()\n  \nwine_categorizer()","execution_count":null,"outputs":[]},{"metadata":{"id":"zmJ2CPCKZG4m","colab_type":"text","_uuid":"87bb131f2e41aa3e8b399c7ed209d795ba8a9b44"},"cell_type":"markdown","source":"#Conclusion\n\nI hope you were able to follow this tutorial. The point that I wish to make here is that even when we have a dataset that is just a jumbled mess of observations, we can still find plenty of ways to extract value from it and use it accelerate our work. I used here quality control and categorization because these take up a lot of time, and yet they are relatively easy to automate. Go find out what old spreadsheets you have may have sitting on your hard drive and have a think at how you could implement the methodology and techniques we discussed above for yourself.\n\nAs always, I hope to have convinced you that Machine Learning is a tool available to everyone and that we can all use it to make our lives more convenient.\n\nAnd for any questions or help, feel free to drop me an email at [conrad.w.s@gmail](mailto:conrad.w.s@gmail.com).\n\nI'm off to drink some more high priced wine. "}],"metadata":{"colab":{"name":"Wine Quality Control.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}