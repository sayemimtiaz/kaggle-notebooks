{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Objective : In this notebook we will play around with the spotify datasets and do the following things\n                \n    1. Read the pickle file of summarised datasets\n    2. Train a word 2 vec model using skip gram with window size as a hyperparameters\n    3. Play around with the vectors received from this excercise \n    4. Try creating two function which return most similar songs to particular songs\n    5. Take 3 songs as list and return a playlist of 10 words"},{"metadata":{},"cell_type":"markdown","source":"Results : \n    \nFind Similar Songs using Word2vec\n    \nSearching for songs similar to : kashmir\n    Similar songs are as follow\n    \n    kashmir - live: o2 arena, london - december 10, 2007\n    \n    killing in the name\n    \n    keep talking - 2011 remastered version\n    \n    immigrant song\n    \n    kickstart my heart - international\n    \nSearching for songs similar to : ['wonderwall', 'paradise', 'yellow', 'let her go', 'fireflies']\n    Playlist based on your list is as follows\n    won't go home without you\n    \n    you and your heart\n    \n    wherever you will go\n    \n    white houses\n    \n    wouldn't it be nice - 1999 - remaster\n    \n    you found me\n    \n    you give me something\n    \n    you and i both\n    \n    yellow - live\n    \n    where is the love?"},{"metadata":{},"cell_type":"markdown","source":"### Load the required packages in the required format"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport pandas as pd\nimport os\nimport warnings\n\n%matplotlib notebook\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pickle\nplt.style.use('ggplot')\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport gensim, logging\nlogging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n%matplotlib notebook\n\nplt.style.use('ggplot')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Read the datasets from the given locations and do following\npath = \"../input/spotify-playlist/\"\nfilename = \"spotify_dataset.csv\"\n### While Loading datasets we say error_bad_lines = false which drops rows with errors \n### As it is experimental project and we have huge datasets, dropping 100-200 Bad rows will not impact any results\nprint (\"Reading the data\")\nspotify_data = pd.read_csv(os.path.join(path,filename),escapechar= '.',error_bad_lines = False,warn_bad_lines=False)\nprint (\"Read Succesful with shape {}\".format(spotify_data.shape))\n### Columns names were not very clean give them manual names\nspotify_data.columns = ['user_id','artistname','trackname','playlistname']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Lets look at the few stats about the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"print (\"Some General statistics about data are as follows:\",spotify_data.info())\nprint (\"Lets look at the summary stats about the data :\",spotify_data.describe(include ='object'))\nprint (\"The number of rows in the datasets are as follows :\",spotify_data.shape[0])\nprint (\" The columns in the data are as follows :\",spotify_data.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Now lets define function which creates a dictionary and convert songs names to dictionary\n\ntracklist = spotify_data['trackname'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"spotify_data.dropna(inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Create a function which takes a dataset name and column name \n\ndef create_dict(dataset, column):\n    ''' Takes two input from user column name and dataset name and return dictionary with hash map '''\n    unique_list = dataset[column].unique()\n    out_dict = {}\n    out_dict1 = {}\n    \n    for j,i in enumerate(unique_list):\n        out_dict[i.lower()] = str(j)\n        out_dict1[str(j)] = i.lower()\n        \n    print (\"Number of distinct in vocab is :\",j)\n    return (out_dict,out_dict1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### call the dict functions on track names and artistname\ntrack_map, track_map_comp= create_dict(spotify_data,'trackname')\nartist_map,artist_map_comp = create_dict(spotify_data,'artistname')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### We created two dicts as will first need to convert songs to numeric mapping and after we have trained the model we will return numeric to song mapping"},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('track_map_dict.pickle','wb') as track_file:\n    pickle.dump(track_map,track_file)\nwith open('track_map_comp_dict.pickle','wb') as track_file_comp:\n    pickle.dump(track_map_comp,track_file_comp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('artist_map_dict.pickle','wb') as artist_file:\n    pickle.dump(artist_map,artist_file)\nwith open('artist_map_comp_dict.pickle','wb') as artist_file_comp:\n    pickle.dump(artist_map_comp,artist_file_comp)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Processing For Word2vec models \n##### 1. Convert each artist name & song name to numeric using the dictionary first\n##### 2. Roll up the data at User_id and Playlist level, and store songss in a playlist as list. Before doing that we will like to shuffle the datasets\n##### 3. Train a word 2 vector model, and see how it works "},{"metadata":{"trusted":true},"cell_type":"code","source":"### Lets shuffle the data first\nprint (\"Shape of data before sampling is:\", spotify_data.shape)\nspotify_data.sample(frac = 1,  random_state = 10000).reset_index(drop=True)\nprint (\"Shape of data after sampling is :\", spotify_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Load the pickle files stored for song to numeric \nwith open('track_map_dict.pickle','rb') as dict1:\n    track_dict= pickle.load( dict1)\nprint (\"Track dict has {} observations\".format(len(track_dict)))\n#### Load the prcikle file for artist to numeric\nwith open('artist_map_dict.pickle','rb') as dict2:\n    artist_dict = pickle.load(dict2)\nprint (\"Track dict has {} observations\".format(len(artist_dict)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Now we will use this mapping to convert names to numeric\nprint (\"Data before mapping dict :\", spotify_data.head(5))\nspotify_data['trackname'] = spotify_data['trackname'].str.lower().map(track_dict)\nspotify_data['artistname'] = spotify_data['artistname'].str.lower().map(artist_dict)\nprint (\"Data after mapping dict :\")\nprint (spotify_data.head(5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### We want to create a list of songs in zip file \ndef zip_list(x):\n    return ([str(z) for z in x])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Lets group by data based on the user id and playlist and zip it as a list"},{"metadata":{"trusted":true},"cell_type":"code","source":"spotify_summary = spotify_data.groupby(['user_id','playlistname'])['trackname'].apply(zip_list).reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (\" Distinct playlist after summarizing the data is :\",spotify_summary.shape[0])\nprint (\" The data looks like this :\")\nprint (spotify_summary.head(5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### We will Dump this data in the pickle file and work in it later\nwith open(\"spotify_summary.pickle\",'wb') as pick_data:\n    pickle.dump(spotify_summary,pick_data)\n    print (\"The dataset is pickled at \",os.getcwd())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Load the pickled datasets \nwith open('spotify_summary.pickle','rb') as dataset:\n    spotify_summary = pickle.load(dataset)\n    print (\" The dataset is loaded succesfully\")\n    print (\" The shape of the dataset is as follows\",spotify_summary.shape)\n    print (spotify_summary.head(5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Gensim takes input as a list of list. Our tracknames are already a list convert them to list of list\nspotify_wrd2vec_input = [ x for x in spotify_summary['trackname']]\nprint (\"Input data is ready for gensim models\")\nprint (\"The number of input playlists we have are as follows :\",len(spotify_wrd2vec_input))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Define traing the word 2 vec model we will use Skip Gram using negative sampling as oftmax can be slow\n# seed = 1000, hs = 0,negative = 10,workers=10,iter = 100)\n### Skip Gram : Predict Context given the middle word works well with infrequent datasets.\n### Good idea for songs as some songs may ne liked by a few users oly\nprint (\"Model Training has started\")\nmodel = gensim.models.Word2Vec(spotify_wrd2vec_input, size = 200 , window = 4 , min_count = 15,\n                               seed = 1000, hs = 0,negative = 10,workers=16,iter = 100)\nprint (\"Model Trainin Finished\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Pickle the model datasets and save it to a pickle file \n\nwith open('model_spotify_word2vec.pickle','wb') as model_file:\n    pickle.dump(model,model_file)\n    print (\" Dumping the model succesful \")\n    print (\" The model is dumped at this location :\",os.getcwd())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### From the dump load the model dictionary and model pickle files\nwith open('model_spotify_word2vec.pickle','rb') as model_file:\n    model_spotify = pickle.load(model_file)\n\n### Load the pickle files stored for song to numeric \nwith open('track_map_dict.pickle','rb') as dict1:\n    track_dict= pickle.load( dict1)\nprint (\"Track dict has {} observations\".format(len(track_dict)))\n#### Load the prcikle file for artist to numeric\nwith open('track_map_comp_dict.pickle','rb') as dict2:\n    track_map_comp_dict = pickle.load(dict2)\nprint (\"Track dict has {} observations\".format(len(track_map_comp_dict)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Define a function which return similar songs to a particular songs"},{"metadata":{"trusted":true},"cell_type":"code","source":"#### Define a function which takes as input songs from list and returns similar songs\ndef similar_songs(songname,n):\n    ''' Gets the songname from user and return the n songs similar'''\n    song_id = track_dict[songname]\n    print (\"Searching for songs similar to :\",songname)\n    \n    similar = model_spotify.most_similar(song_id,topn = n)\n    print (\"Similar songs are as follow\")\n    for i in similar[:]:\n        print (track_map_comp_dict[i[0]])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Define a function which takes list of songs and creates playlist for the users"},{"metadata":{"trusted":true},"cell_type":"code","source":"#### Define a function which takes as input songs from list and returns similar songs\ndef create_play_list(list_songs,n):\n    ''' Gets the songname from user and return the 5 songs similar'''  \n    list1 = []\n    for i in list_songs:\n        list1.append(track_dict[i])      \n        \n    print (\"Searching for songs similar to :\",list_songs)\n    \n    similar = model_spotify.most_similar(positive = list1,topn = n)\n    print (\"Playlist based on your list is as follows\")\n    for i in similar[:]:\n        print (track_map_comp_dict[i[0]])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Lets check out results for my favourite songs list "},{"metadata":{"trusted":true},"cell_type":"code","source":"create_play_list(['wonderwall','paradise','yellow','let her go','fireflies'],10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Lets check the results for a different music taste - Classic Metal | Rock","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"create_play_list(['enter sandman','fade to black','kashmir'],15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Try a different list of songs"},{"metadata":{"trusted":true},"cell_type":"code","source":"create_play_list(['hey you','time','hypnotised','fix you'],10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###  find out similar songs Kashmir by Led Zepplin"},{"metadata":{"trusted":true},"cell_type":"code","source":"similar_songs('kashmir',5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Highlighting the Problems with current datasets and next steps for further \n\n1. Training Data is not clean and has lot of similar songs with different names. We could try to restrict the version of songs to 1 or 2 max based on frequency for example\n   SOngs :  kashmir , kashmir - live: o2 arena, london - december 10, 2007\n   \n2. Songs with similar names can be of different taste based on the artist names. We should create vocab by combining strings of tracknames with the artist names"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}