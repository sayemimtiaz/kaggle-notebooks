{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-22T00:04:11.620915Z","iopub.execute_input":"2021-07-22T00:04:11.621342Z","iopub.status.idle":"2021-07-22T00:04:11.646252Z","shell.execute_reply.started":"2021-07-22T00:04:11.621247Z","shell.execute_reply":"2021-07-22T00:04:11.645004Z"},"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"![](https://warehouse-camo.ingress.cmh1.psfhosted.org/072e5a48a57a57f8c239cd3fb717f1c9def7f2bd/68747470733a2f2f6576616c6d6c2d7765622d696d616765732e73332e616d617a6f6e6177732e636f6d2f6576616c6d6c5f686f72697a6f6e74616c2e737667)pypi.org","metadata":{}},{"cell_type":"markdown","source":"#EvalML \n\nhttps://github.com/alteryx/evalml\n\nEvalML is an AutoML library which builds, optimizes, and evaluates machine learning pipelines using domain-specific objective functions.\n\nKey Functionality\n\nAutomation - Makes machine learning easier. Avoid training and tuning models by hand. Includes data quality checks, cross-validation and more.\n\nData Checks - Catches and warns of problems with your data and problem setup before modeling.\n\nEnd-to-end - Constructs and optimizes pipelines that include state-of-the-art preprocessing, feature engineering, feature selection, and a variety of modeling techniques.\n\nModel Understanding - Provides tools to understand and introspect on models, to learn how they'll behave in your problem domain.\n\nDomain-specific - Includes repository of domain-specific objective functions and an interface to define your own.\n\nFollow along by cloning the demo repository: https://github.com/alteryx/open_sourc...\n\nFor more information on EvalML, visit our GitHub page at https://github.com/alteryx/evalml and our documentation at https://evalml.alteryx.com\n\nhttps://github.com/alteryx/evalml","metadata":{}},{"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/cusersmarildownloadsgermancsv/german.csv',encoding ='ISO-8859-1',sep=\";\")\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-22T00:04:28.682195Z","iopub.execute_input":"2021-07-22T00:04:28.68261Z","iopub.status.idle":"2021-07-22T00:04:28.865494Z","shell.execute_reply.started":"2021-07-22T00:04:28.682572Z","shell.execute_reply":"2021-07-22T00:04:28.864413Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Code by Homayoon Khadivi https://www.kaggle.com/homayoonkhadivi/creative-automation-ml-evalml-model-understanding/comments","metadata":{}},{"cell_type":"code","source":"!pip install evalml","metadata":{"execution":{"iopub.status.busy":"2021-07-22T00:04:42.843975Z","iopub.execute_input":"2021-07-22T00:04:42.844401Z","iopub.status.idle":"2021-07-22T00:05:49.78838Z","shell.execute_reply.started":"2021-07-22T00:04:42.844366Z","shell.execute_reply":"2021-07-22T00:05:49.785706Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df.drop(columns=['Creditability'])\ny = df['Creditability']","metadata":{"execution":{"iopub.status.busy":"2021-07-22T00:14:24.046827Z","iopub.execute_input":"2021-07-22T00:14:24.04718Z","iopub.status.idle":"2021-07-22T00:14:24.052473Z","shell.execute_reply.started":"2021-07-22T00:14:24.04715Z","shell.execute_reply":"2021-07-22T00:14:24.051753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import evalml\nfrom evalml.pipelines import BinaryClassificationPipeline\n\n#X,y = evalml.demos.load_breast_cancer()\n\npipeline = BinaryClassificationPipeline([\"Simple Imputer\", \"Random Forest Classifier\"])\npipeline.fit(X,y)\n\nprint(pipeline.score(X,y, objectives = ['log loss binary']))","metadata":{"execution":{"iopub.status.busy":"2021-07-22T00:14:41.609467Z","iopub.execute_input":"2021-07-22T00:14:41.610047Z","iopub.status.idle":"2021-07-22T00:14:54.623671Z","shell.execute_reply.started":"2021-07-22T00:14:41.609986Z","shell.execute_reply":"2021-07-22T00:14:54.622463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Feature Importance\n\nWe can get the importance associated with each feature of the resulting pipeline","metadata":{}},{"cell_type":"code","source":"pipeline.feature_importance","metadata":{"execution":{"iopub.status.busy":"2021-07-22T00:17:05.449092Z","iopub.execute_input":"2021-07-22T00:17:05.449497Z","iopub.status.idle":"2021-07-22T00:17:05.573097Z","shell.execute_reply.started":"2021-07-22T00:17:05.449464Z","shell.execute_reply":"2021-07-22T00:17:05.572035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Create a bar plot of the feature importances","metadata":{}},{"cell_type":"code","source":"pipeline.graph_feature_importance()","metadata":{"execution":{"iopub.status.busy":"2021-07-22T00:17:56.279794Z","iopub.execute_input":"2021-07-22T00:17:56.280192Z","iopub.status.idle":"2021-07-22T00:17:56.513335Z","shell.execute_reply.started":"2021-07-22T00:17:56.280159Z","shell.execute_reply":"2021-07-22T00:17:56.512655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Permutation Importance\n\nCompute and plot the permutation importance of the pipeline.","metadata":{}},{"cell_type":"code","source":"from evalml.model_understanding import calculate_permutation_importance\ncalculate_permutation_importance(pipeline, X, y, \"log loss binary\")","metadata":{"execution":{"iopub.status.busy":"2021-07-22T00:19:13.015471Z","iopub.execute_input":"2021-07-22T00:19:13.015935Z","iopub.status.idle":"2021-07-22T00:19:25.218515Z","shell.execute_reply.started":"2021-07-22T00:19:13.015896Z","shell.execute_reply":"2021-07-22T00:19:25.217497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from evalml.model_understanding import graph_permutation_importance\ngraph_permutation_importance(pipeline, X, y, 'log loss binary')","metadata":{"execution":{"iopub.status.busy":"2021-07-22T00:20:28.670347Z","iopub.execute_input":"2021-07-22T00:20:28.670779Z","iopub.status.idle":"2021-07-22T00:20:40.828721Z","shell.execute_reply.started":"2021-07-22T00:20:28.670741Z","shell.execute_reply":"2021-07-22T00:20:40.827733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Partial Dependence Plots\n\nCalculate the one-way partial dependence plots for a feature. Here, I chose Credit amount.","metadata":{}},{"cell_type":"code","source":"from evalml.model_understanding.graphs import partial_dependence\npartial_dependence(pipeline, X, features='Credit_Amount')","metadata":{"execution":{"iopub.status.busy":"2021-07-22T00:23:07.953436Z","iopub.execute_input":"2021-07-22T00:23:07.953951Z","iopub.status.idle":"2021-07-22T00:23:23.567043Z","shell.execute_reply.started":"2021-07-22T00:23:07.953911Z","shell.execute_reply":"2021-07-22T00:23:23.56629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from evalml.model_understanding.graphs import graph_partial_dependence\ngraph_partial_dependence(pipeline, X, features='Credit_Amount')","metadata":{"execution":{"iopub.status.busy":"2021-07-22T00:25:51.416924Z","iopub.execute_input":"2021-07-22T00:25:51.417686Z","iopub.status.idle":"2021-07-22T00:26:07.017015Z","shell.execute_reply.started":"2021-07-22T00:25:51.41761Z","shell.execute_reply":"2021-07-22T00:26:07.01604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Compute the partial dependence for a categorical feature. We don't have categorical, hence I used Demos Load fraud, which has nothing to do with my Creditability Dataset. I saved that snippet to apply when I have Categorical features. ","metadata":{}},{"cell_type":"code","source":"X_fraud, y_fraud = evalml.demos.load_fraud(100, verbose=False)\nX_fraud.ww.init(logical_types={\"provider\": \"Categorical\", 'region': \"Categorical\"})\nfraud_pipeline = BinaryClassificationPipeline([\"DateTime Featurization Component\",\"One Hot Encoder\", \"Random Forest Classifier\"])\nfraud_pipeline.fit(X_fraud, y_fraud)\n\ngraph_partial_dependence(fraud_pipeline, X_fraud, features='provider')","metadata":{"execution":{"iopub.status.busy":"2021-07-22T00:28:45.179446Z","iopub.execute_input":"2021-07-22T00:28:45.179982Z","iopub.status.idle":"2021-07-22T00:28:50.582133Z","shell.execute_reply.started":"2021-07-22T00:28:45.179941Z","shell.execute_reply":"2021-07-22T00:28:50.5813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Two-way partial dependence plots are also possible and invoke the same API.","metadata":{}},{"cell_type":"code","source":"partial_dependence(pipeline, X, features=('Account_Balance', 'Duration_of_Credit_monthly'), grid_resolution=10)","metadata":{"execution":{"iopub.status.busy":"2021-07-22T00:33:39.853553Z","iopub.execute_input":"2021-07-22T00:33:39.854061Z","iopub.status.idle":"2021-07-22T00:33:45.774388Z","shell.execute_reply.started":"2021-07-22T00:33:39.854013Z","shell.execute_reply":"2021-07-22T00:33:45.773215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"graph_partial_dependence(pipeline, X, features=('Account_Balance', 'Duration_of_Credit_monthly'), grid_resolution=10)","metadata":{"execution":{"iopub.status.busy":"2021-07-22T00:35:30.933935Z","iopub.execute_input":"2021-07-22T00:35:30.934341Z","iopub.status.idle":"2021-07-22T00:35:36.844563Z","shell.execute_reply.started":"2021-07-22T00:35:30.934308Z","shell.execute_reply":"2021-07-22T00:35:36.843879Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Confusion Matrix\n\nFor binary or multiclass classification, we can view a confusion matrix of the classifierâ€™s predictions. In the DataFrame output of confusion_matrix(), the column header represents the predicted labels while row header represents the actual labels.","metadata":{}},{"cell_type":"code","source":"from evalml.model_understanding.graphs import confusion_matrix\ny_pred = pipeline.predict(X)\nconfusion_matrix(y, y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-07-22T00:36:20.043513Z","iopub.execute_input":"2021-07-22T00:36:20.044073Z","iopub.status.idle":"2021-07-22T00:36:20.193596Z","shell.execute_reply.started":"2021-07-22T00:36:20.044037Z","shell.execute_reply":"2021-07-22T00:36:20.192853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from evalml.model_understanding.graphs import graph_confusion_matrix\ny_pred = pipeline.predict(X)\ngraph_confusion_matrix(y, y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-07-22T00:36:42.646191Z","iopub.execute_input":"2021-07-22T00:36:42.646741Z","iopub.status.idle":"2021-07-22T00:36:45.108752Z","shell.execute_reply.started":"2021-07-22T00:36:42.646695Z","shell.execute_reply":"2021-07-22T00:36:45.107571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Predicted Vs Actual Values Graph for Regression Problems\n\nCreate a scatterplot comparing predicted vs actual values for regression problems. Specify an outlier_threshold to color values differently if the absolute difference between the actual and predicted values are outside of a given threshold.","metadata":{}},{"cell_type":"code","source":"from evalml.model_understanding.graphs import graph_prediction_vs_actual\nfrom evalml.pipelines import RegressionPipeline\n\n#X_regress, y_regress = evalml.demos.load_diabetes()\nX_train, X_test, y_train, y_test = evalml.preprocessing.split_data(X, y, problem_type='regression')\n\npipeline_regress = RegressionPipeline(['One Hot Encoder', 'Linear Regressor'])\npipeline_regress.fit(X_train, y_train)\n\ny_pred = pipeline_regress.predict(X_test)\ngraph_prediction_vs_actual(y_test, y_pred, outlier_threshold=50)","metadata":{"execution":{"iopub.status.busy":"2021-07-22T00:54:45.522534Z","iopub.execute_input":"2021-07-22T00:54:45.522941Z","iopub.status.idle":"2021-07-22T00:54:45.692805Z","shell.execute_reply.started":"2021-07-22T00:54:45.522904Z","shell.execute_reply":"2021-07-22T00:54:45.691831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipeline_dt = BinaryClassificationPipeline(['Simple Imputer', 'Decision Tree Classifier'])\npipeline_dt.fit(X, y)","metadata":{"execution":{"iopub.status.busy":"2021-07-22T00:56:38.972024Z","iopub.execute_input":"2021-07-22T00:56:38.972487Z","iopub.status.idle":"2021-07-22T00:56:39.102157Z","shell.execute_reply.started":"2021-07-22T00:56:38.972443Z","shell.execute_reply":"2021-07-22T00:56:39.101176Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Tree Visualization\n\nVisualize the structure of the Decision Tree that was fit to that data, and save it if necessary.","metadata":{}},{"cell_type":"code","source":"from evalml.model_understanding.graphs import visualize_decision_tree\n\nvisualize_decision_tree(pipeline_dt.estimator, max_depth=2, rotate=False, filled=True, filepath=None)","metadata":{"execution":{"iopub.status.busy":"2021-07-22T00:57:03.566229Z","iopub.execute_input":"2021-07-22T00:57:03.566597Z","iopub.status.idle":"2021-07-22T00:57:03.956198Z","shell.execute_reply.started":"2021-07-22T00:57:03.566564Z","shell.execute_reply":"2021-07-22T00:57:03.954791Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Why the parenthesis above are empty?","metadata":{}},{"cell_type":"markdown","source":"#Explaining Predictions\n\nExplain why the model made certain predictions with the explain_predictions function. This will use the Shapley Additive Explanations (SHAP) algorithm to identify the top features that explain the predicted value.\n\nThis function can explain both classification and regression models - all you need to do is provide the pipeline, the input features, and a list of rows corresponding to the indices of the input features you want to explain. The function will return a table that you can print summarizing the top 3 most positive and negative contributing features to the predicted value.","metadata":{}},{"cell_type":"code","source":"from evalml.model_understanding.prediction_explanations import explain_predictions\n\ntable = explain_predictions(pipeline=pipeline, input_features=X, y=None, indices_to_explain=[3],\n                           top_k_features=6, include_shap_values=True)\nprint(table)","metadata":{"execution":{"iopub.status.busy":"2021-07-22T00:58:47.636925Z","iopub.execute_input":"2021-07-22T00:58:47.637371Z","iopub.status.idle":"2021-07-22T00:58:47.7035Z","shell.execute_reply.started":"2021-07-22T00:58:47.637332Z","shell.execute_reply":"2021-07-22T00:58:47.702774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#The interpretation of the table\n\nThe interpretation of the table is the same for regression problems - but the SHAP value now corresponds to the change in the estimated value of the dependent variable rather than a change in probability. For multiclass classification problems, a table will be output for each possible class.\n\nBelow is an example of how you would explain three predictions with explain_predictions.","metadata":{}},{"cell_type":"code","source":"from evalml.model_understanding.prediction_explanations import explain_predictions\n\nreport = explain_predictions(pipeline=pipeline, input_features=X, y=y, indices_to_explain=[0, 4, 9], include_shap_values=True,\n                            output_format='text')\nprint(report)","metadata":{"execution":{"iopub.status.busy":"2021-07-22T01:01:51.213552Z","iopub.execute_input":"2021-07-22T01:01:51.214256Z","iopub.status.idle":"2021-07-22T01:01:51.306295Z","shell.execute_reply.started":"2021-07-22T01:01:51.214213Z","shell.execute_reply":"2021-07-22T01:01:51.305447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Explaining Best and Worst Predictions\n\nWhen debugging machine learning models, it is often useful to analyze the best and worst predictions the model made. The explain_predictions_best_worst function can help us with this.\n\nThis function will display the output of explain_predictions for the best 2 and worst 2 predictions. By default, the best and worst predictions are determined by the absolute error for regression problems and cross entropy for classification problems.\n\nWe can specify our own ranking function by passing in a function to the metric parameter. This function will be called on y_true and y_pred. By convention, lower scores are better.\n\nAt the top of each table, we can see the predicted probabilities, target value, error, and row index for that prediction. For a regression problem, we would see the predicted value instead of predicted probabilities.","metadata":{}},{"cell_type":"code","source":"from evalml.model_understanding.prediction_explanations import explain_predictions_best_worst\n\nreport = explain_predictions_best_worst(pipeline=pipeline, input_features=X, y_true=y,\n                                        include_shap_values=True, top_k_features=6, num_to_explain=2)\n\nprint(report)","metadata":{"execution":{"iopub.status.busy":"2021-07-22T01:03:01.735807Z","iopub.execute_input":"2021-07-22T01:03:01.736487Z","iopub.status.idle":"2021-07-22T01:03:02.118476Z","shell.execute_reply.started":"2021-07-22T01:03:01.736446Z","shell.execute_reply":"2021-07-22T01:03:02.117538Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Hinge Loss\n\nUse a custom metric (hinge loss) for selecting the best and worst predictions. See this example:","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\ndef hinge_loss(y_true, y_pred_proba):\n\n    probabilities = np.clip(y_pred_proba.iloc[:, 1], 0.001, 0.999)\n    y_true[y_true == 0] = -1\n\n    return np.clip(1 - y_true * np.log(probabilities / (1 - probabilities)), a_min=0, a_max=None)\n\nreport = explain_predictions_best_worst(pipeline=pipeline, input_features=X, y_true=y,\n                                        include_shap_values=True, num_to_explain=5, metric=hinge_loss)\n\nprint(report)","metadata":{"execution":{"iopub.status.busy":"2021-07-22T01:04:24.318389Z","iopub.execute_input":"2021-07-22T01:04:24.319088Z","iopub.status.idle":"2021-07-22T01:04:24.764409Z","shell.execute_reply.started":"2021-07-22T01:04:24.319044Z","shell.execute_reply":"2021-07-22T01:04:24.763291Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Single prediction as a dataframe","metadata":{}},{"cell_type":"code","source":"single_prediction_report = explain_predictions(pipeline=pipeline, input_features=X, indices_to_explain=[3],\n                                              y=y, top_k_features=6, include_shap_values=True,\n                                              output_format=\"dataframe\")\nsingle_prediction_report","metadata":{"execution":{"iopub.status.busy":"2021-07-22T01:06:35.343318Z","iopub.execute_input":"2021-07-22T01:06:35.343844Z","iopub.status.idle":"2021-07-22T01:06:35.420967Z","shell.execute_reply.started":"2021-07-22T01:06:35.343803Z","shell.execute_reply":"2021-07-22T01:06:35.419778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Best and worst predictions as a dataframe","metadata":{}},{"cell_type":"code","source":"report = explain_predictions_best_worst(pipeline=pipeline, input_features=X, y_true=y,\n                                        num_to_explain=1, top_k_features=6,\n                                        include_shap_values=True, output_format=\"dataframe\")\nreport","metadata":{"execution":{"iopub.status.busy":"2021-07-22T01:07:57.348667Z","iopub.execute_input":"2021-07-22T01:07:57.349132Z","iopub.status.idle":"2021-07-22T01:07:57.731592Z","shell.execute_reply.started":"2021-07-22T01:07:57.349092Z","shell.execute_reply":"2021-07-22T01:07:57.730477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Code by Homayoon Khadivi https://www.kaggle.com/homayoonkhadivi/creative-automation-ml-evalml-model-understanding/comments","metadata":{}}]}