{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Introduction\n\n### In this notebook we use [Feature Fusion Attention Network (FFA-Net)](https://arxiv.org/abs/1911.07559v2) to perform Single Image Dehazing on [RESIDE Dataset](https://sites.google.com/view/reside-dehaze-datasets/reside-standard?authuser=0)."},{"metadata":{},"cell_type":"markdown","source":"<h3><center>Image Dehazing with FFA-Net</center></h3>\n<img src=\"https://storage.googleapis.com/groundai-web-prod/media%2Fusers%2Fuser_297673%2Fproject_398618%2Fimages%2Ffig1.jpg\" width=\"500\" height=\"500\"/>\n<h4></h4>\n<h4><center><a href=\"https://arxiv.org/abs/1911.07559v2\">Source: FFA-Net [Xu Qin & Zhilin Wang et. al.]</a></center></h4>"},{"metadata":{},"cell_type":"markdown","source":"## Acknowledgements\n\n### This work was inspired by and borrows code from the authors' [original FFA-Net implementation](https://github.com/zhilin007/FFA-Net)."},{"metadata":{},"cell_type":"markdown","source":"### Libraries üìö‚¨á"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os, sys\nimport time, math\nimport argparse, random\nfrom math import exp\nimport numpy as np\n\nimport torch\nfrom torch import nn, optim\nimport torch.nn.functional as F\nimport torch.utils.data as data\nfrom torch.utils.data import DataLoader\nfrom torch.backends import cudnn\nfrom torch.autograd import Variable\n\nimport torchvision\nimport torchvision.transforms as tfs\nfrom torchvision.transforms import ToPILImage\nfrom torchvision.transforms import functional as FF\nimport torchvision.utils as vutils\nfrom torchvision.utils import make_grid\nfrom torchvision.models import vgg16\n\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Settings ‚öôÔ∏è"},{"metadata":{"trusted":true},"cell_type":"code","source":"# number of training steps\nsteps = 20000\n# Device name\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n# resume Training\nresume = False\n# number of evaluation steps\neval_step = 5000\n# learning rate\nlearning_rate = 0.0001\n# pre-trained model directory\npretrained_model_dir = '../input/ffa-net-for-single-image-dehazing-pytorch/trained_models/'\n# directory to save models to\nmodel_dir = './trained_models/'\n# train data\ntrainset = 'its_train'\n# test data\ntestset = 'its_test'\n# model to be used\nnetwork = 'ffa'\n# residual_groups\ngps = 3\n# residual_blocks\nblocks = 12\n# batch size\nbs = 1\n# crop image\ncrop = True\n# Takes effect when crop = True\ncrop_size = 240\n# No lr cos schedule\nno_lr_sche = True\n# perceptual loss\nperloss = True\n\nmodel_name = trainset + '_' + network.split('.')[0] + '_' + str(gps) + '_' + str(blocks)\npretrained_model_dir = pretrained_model_dir + model_name + '.pk'\nmodel_dir = model_dir + model_name + '.pk'\nlog_dir = 'logs/' + model_name\n\nif not os.path.exists('trained_models'):\n    os.mkdir('trained_models')\nif not os.path.exists('numpy_files'):\n    os.mkdir('numpy_files')\nif not os.path.exists('logs'):\n    os.mkdir('logs')\nif not os.path.exists('samples'):\n    os.mkdir('samples')\nif not os.path.exists(f\"samples/{model_name}\"):\n    os.mkdir(f'samples/{model_name}')\nif not os.path.exists(log_dir):\n    os.mkdir(log_dir)\n    \ncrop_size='whole_img'\nif crop:\n    crop_size = crop_size\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Utility Functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def tensorShow(tensors,titles=None):\n    '''t:BCWH'''\n    fig=plt.figure()\n    for tensor, title, i in zip(tensors, titles, range(len(tensors))):\n        img = make_grid(tensor)\n        npimg = img.numpy()\n        ax = fig.add_subplot(211+i)\n        ax.imshow(np.transpose(npimg, (1, 2, 0)))\n        ax.set_title(title)\n    plt.show()\n    \ndef lr_schedule_cosdecay(t, T, init_lr=learning_rate):\n    lr=0.5*(1+math.cos(t*math.pi/T))*init_lr\n    return lr","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3><center>FFA-Net Model Architecture</center></h3>\n<img src=\"https://storage.googleapis.com/groundai-web-prod/media%2Fusers%2Fuser_297673%2Fproject_398618%2Fimages%2Ffig2.jpg\" width=\"750\" height=\"750\"/>\n<h4></h4>\n<h4><center><a href=\"https://arxiv.org/abs/1911.07559v2\">Source: FFA-Net [Xu Qin & Zhilin Wang et. al.]</a></center></h4>"},{"metadata":{},"cell_type":"markdown","source":"### Model Definition"},{"metadata":{"trusted":true},"cell_type":"code","source":"def default_conv(in_channels, out_channels, kernel_size, bias=True):\n    return nn.Conv2d(in_channels, out_channels, kernel_size, padding=(kernel_size//2), bias=bias)\n    \n    \nclass PALayer(nn.Module):\n    def __init__(self, channel):\n        super(PALayer, self).__init__()\n        self.pa = nn.Sequential(\n                nn.Conv2d(channel, channel // 8, 1, padding=0, bias=True),\n                nn.ReLU(inplace=True),\n                nn.Conv2d(channel // 8, 1, 1, padding=0, bias=True),\n                nn.Sigmoid()\n        )\n    def forward(self, x):\n        y = self.pa(x)\n        return x * y\n\n    \nclass CALayer(nn.Module):\n    def __init__(self, channel):\n        super(CALayer, self).__init__()\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.ca = nn.Sequential(\n                nn.Conv2d(channel, channel // 8, 1, padding=0, bias=True),\n                nn.ReLU(inplace=True),\n                nn.Conv2d(channel // 8, channel, 1, padding=0, bias=True),\n                nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        y = self.avg_pool(x)\n        y = self.ca(y)\n        return x * y\n\n    \nclass Block(nn.Module):\n    def __init__(self, conv, dim, kernel_size,):\n        super(Block, self).__init__()\n        self.conv1 = conv(dim, dim, kernel_size, bias=True)\n        self.act1 = nn.ReLU(inplace=True)\n        self.conv2 = conv(dim, dim, kernel_size, bias=True)\n        self.calayer = CALayer(dim)\n        self.palayer = PALayer(dim)\n\n    def forward(self, x):\n        res = self.act1(self.conv1(x))\n        res = res+x \n        res = self.conv2(res)\n        res = self.calayer(res)\n        res = self.palayer(res)\n        res += x \n        return res\n\n    \nclass Group(nn.Module):\n    def __init__(self, conv, dim, kernel_size, blocks):\n        super(Group, self).__init__()\n        modules = [Block(conv, dim, kernel_size)  for _ in range(blocks)]\n        modules.append(conv(dim, dim, kernel_size))\n        self.gp = nn.Sequential(*modules)\n\n    def forward(self, x):\n        res = self.gp(x)\n        res += x\n        return res\n\n    \nclass FFA(nn.Module):\n    def __init__(self,gps,blocks,conv=default_conv):\n        super(FFA, self).__init__()\n        self.gps = gps\n        self.dim = 64\n        kernel_size = 3\n        pre_process = [conv(3, self.dim, kernel_size)]\n        assert self.gps==3\n        self.g1 = Group(conv, self.dim, kernel_size,blocks=blocks)\n        self.g2 = Group(conv, self.dim, kernel_size,blocks=blocks)\n        self.g3 = Group(conv, self.dim, kernel_size,blocks=blocks)\n        self.ca = nn.Sequential(*[\n            nn.AdaptiveAvgPool2d(1),\n            nn.Conv2d(self.dim*self.gps,self.dim//16,1,padding=0),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(self.dim//16, self.dim*self.gps, 1, padding=0, bias=True),\n            nn.Sigmoid()\n            ])\n        self.palayer = PALayer(self.dim)\n\n        post_process = [\n            conv(self.dim, self.dim, kernel_size),\n            conv(self.dim, 3, kernel_size)]\n\n        self.pre = nn.Sequential(*pre_process)\n        self.post = nn.Sequential(*post_process)\n\n    def forward(self, x1):\n        x = self.pre(x1)\n        res1 = self.g1(x)\n        res2 = self.g2(res1)\n        res3 = self.g3(res2)\n        w = self.ca(torch.cat([res1,res2,res3],dim=1))\n        w = w.view(-1,self.gps, self.dim)[:,:,:,None,None]\n        out = w[:,0,::] * res1 + w[:,1,::] * res2+w[:,2,::] * res3\n        out = self.palayer(out)\n        x = self.post(out)\n        return x + x1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Perceptual Loss"},{"metadata":{"trusted":true},"cell_type":"code","source":"# --- Perceptual loss network  --- #\nclass PerLoss(torch.nn.Module):\n    def __init__(self, vgg_model):\n        super(PerLoss, self).__init__()\n        self.vgg_layers = vgg_model\n        self.layer_name_mapping = {\n            '3': \"relu1_2\",\n            '8': \"relu2_2\",\n            '15': \"relu3_3\"\n        }\n\n    def output_features(self, x):\n        output = {}\n        for name, module in self.vgg_layers._modules.items():\n            x = module(x)\n            if name in self.layer_name_mapping:\n                output[self.layer_name_mapping[name]] = x\n        return list(output.values())\n\n    def forward(self, dehaze, gt):\n        loss = []\n        dehaze_features = self.output_features(dehaze)\n        gt_features = self.output_features(gt)\n        for dehaze_feature, gt_feature in zip(dehaze_features, gt_features):\n            loss.append(F.mse_loss(dehaze_feature, gt_feature))\n\n        return sum(loss)/len(loss)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### SSIM / PSNR Metrics"},{"metadata":{"trusted":true},"cell_type":"code","source":"def gaussian(window_size, sigma):\n    gauss = torch.Tensor([exp(-(x - window_size // 2) ** 2 / float(2 * sigma ** 2)) for x in range(window_size)])\n    return gauss / gauss.sum()\n\ndef create_window(window_size, channel):\n    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n    window = Variable(_2D_window.expand(channel, 1, window_size, window_size).contiguous())\n    return window\n\ndef _ssim(img1, img2, window, window_size, channel, size_average=True):\n    mu1 = F.conv2d(img1, window, padding=window_size // 2, groups=channel)\n    mu2 = F.conv2d(img2, window, padding=window_size // 2, groups=channel)\n    mu1_sq = mu1.pow(2)\n    mu2_sq = mu2.pow(2)\n    mu1_mu2 = mu1 * mu2\n    sigma1_sq = F.conv2d(img1 * img1, window, padding=window_size // 2, groups=channel) - mu1_sq\n    sigma2_sq = F.conv2d(img2 * img2, window, padding=window_size // 2, groups=channel) - mu2_sq\n    sigma12 = F.conv2d(img1 * img2, window, padding=window_size // 2, groups=channel) - mu1_mu2\n    C1 = 0.01 ** 2\n    C2 = 0.03 ** 2\n    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n\n    if size_average:\n        return ssim_map.mean()\n    else:\n        return ssim_map.mean(1).mean(1).mean(1)\n\ndef ssim(img1, img2, window_size=11, size_average=True):\n    img1=torch.clamp(img1,min=0,max=1)\n    img2=torch.clamp(img2,min=0,max=1)\n    (_, channel, _, _) = img1.size()\n    window = create_window(window_size, channel)\n    if img1.is_cuda:\n        window = window.cuda(img1.get_device())\n    window = window.type_as(img1)\n    return _ssim(img1, img2, window, window_size, channel, size_average)\n\ndef psnr(pred, gt):\n    pred=pred.clamp(0,1).cpu().numpy()\n    gt=gt.clamp(0,1).cpu().numpy()\n    imdff = pred - gt\n    rmse = math.sqrt(np.mean(imdff ** 2))\n    if rmse == 0:\n        return 100\n    return 20 * math.log10( 1.0 / rmse)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Get Dataloaders"},{"metadata":{"trusted":true},"cell_type":"code","source":"class RESIDE_Dataset(data.Dataset):\n    def __init__(self, path, train, size=crop_size, format='.png'):\n        super(RESIDE_Dataset, self).__init__()\n        self.size = size\n        self.train = train\n        self.format = format\n        self.haze_imgs_dir = os.listdir(os.path.join(path,'hazy'))\n        self.haze_imgs = [os.path.join(path, 'hazy', img) for img in self.haze_imgs_dir]\n        self.clear_dir = os.path.join(path,'clear')\n        \n    def __getitem__(self, index):\n        haze = Image.open(self.haze_imgs[index])\n        if isinstance(self.size, int):\n            while haze.size[0] < self.size or haze.size[1] < self.size :\n                index = random.randint(0, 20000)\n                haze = Image.open(self.haze_imgs[index])\n        img = self.haze_imgs[index]\n        id = img.split('/')[-1].split('_')[0]\n        clear_name = id + self.format\n        clear = Image.open(os.path.join(self.clear_dir, clear_name))\n        clear = tfs.CenterCrop(haze.size[::-1])(clear)\n        if not isinstance(self.size, str):\n            i, j, h, w = tfs.RandomCrop.get_params(haze, output_size=(self.size, self.size))\n            haze = FF.crop(haze, i, j, h, w)\n            clear = FF.crop(clear, i, j, h, w)\n        haze, clear = self.augData(haze.convert(\"RGB\"), clear.convert(\"RGB\") )\n        return haze, clear\n    \n    def augData(self, data, target):\n        if self.train:\n            rand_hor = random.randint(0,1)\n            rand_rot = random.randint(0,3)\n            data = tfs.RandomHorizontalFlip(rand_hor)(data)\n            target = tfs.RandomHorizontalFlip(rand_hor)(target)\n            if rand_rot:\n                data = FF.rotate(data, 90*rand_rot)\n                target = FF.rotate(target, 90*rand_rot)\n        data = tfs.ToTensor()(data)\n        data = tfs.Normalize(mean=[0.64,0.6,0.58], std=[0.14,0.15,0.152])(data)\n        target = tfs.ToTensor()(target)\n        return data, target\n\n    def __len__(self):\n        return len(self.haze_imgs)\n\n\n# path to your 'data' folder\nits_train_path = '../input/indoor-training-set-its-residestandard'\nits_test_path = '../input/synthetic-objective-testing-set-sots-reside/indoor'\n\nITS_train_loader = DataLoader(dataset=RESIDE_Dataset(its_train_path, train=True, size=crop_size), batch_size=bs, shuffle=True)\nITS_test_loader = DataLoader(dataset=RESIDE_Dataset(its_test_path, train=False, size='whole img'), batch_size=1, shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Define Train / Test Functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('log_dir :', log_dir)\nprint('model_name:', model_name)\n\nmodels_ = {'ffa': FFA(gps = gps, blocks = blocks)}\nloaders_ = {'its_train': ITS_train_loader, 'its_test': ITS_test_loader}\n# loaders_ = {'its_train': ITS_train_loader, 'its_test': ITS_test_loader, 'ots_train': OTS_train_loader, 'ots_test': OTS_test_loader}\nstart_time = time.time()\nT = steps\n\ndef train(net, loader_train, loader_test, optim, criterion):\n    losses = []\n    start_step = 0\n    max_ssim = max_psnr = 0\n    ssims, psnrs = [], []\n    if resume and os.path.exists(pretrained_model_dir):\n        print(f'resume from {pretrained_model_dir}')\n        ckp = torch.load(pretrained_model_dir)\n        losses = ckp['losses']\n        net.load_state_dict(ckp['model'])\n        start_step = ckp['step']\n        max_ssim = ckp['max_ssim']\n        max_psnr = ckp['max_psnr']\n        psnrs = ckp['psnrs']\n        ssims = ckp['ssims']\n        print(f'Resuming training from step: {start_step} ***')\n    else :\n        print('Training from scratch *** ')\n    for step in range(start_step+1, steps+1):\n        net.train()\n        lr = learning_rate\n        if not no_lr_sche:\n            lr = lr_schedule_cosdecay(step,T)\n            for param_group in optim.param_groups:\n                param_group[\"lr\"] = lr\n        x, y = next(iter(loader_train))\n        x = x.to(device); y = y.to(device)\n        out = net(x)\n        loss = criterion[0](out,y)\n        if perloss:\n            loss2 = criterion[1](out,y)\n            loss = loss + 0.04*loss2\n\n        loss.backward()\n\n        optim.step()\n        optim.zero_grad()\n        losses.append(loss.item())\n        print(f'\\rtrain loss: {loss.item():.5f} | step: {step}/{steps} | lr: {lr :.7f} | time_used: {(time.time()-start_time)/60 :.1f}',end='',flush=True)\n\n        if step % eval_step ==0 :\n            with torch.no_grad():\n                ssim_eval, psnr_eval = test(net, loader_test, max_psnr, max_ssim, step)\n            print(f'\\nstep: {step} | ssim: {ssim_eval:.4f} | psnr: {psnr_eval:.4f}')\n\n            ssims.append(ssim_eval)\n            psnrs.append(psnr_eval)\n            if ssim_eval > max_ssim and psnr_eval > max_psnr :\n                max_ssim = max(max_ssim,ssim_eval)\n                max_psnr = max(max_psnr,psnr_eval)\n                torch.save({\n                            'step': step,\n                            'max_psnr': max_psnr,\n                            'max_ssim': max_ssim,\n                            'ssims': ssims,\n                            'psnrs': psnrs,\n                            'losses': losses,\n                            'model': net.state_dict()\n                }, model_dir)\n                print(f'\\n model saved at step : {step} | max_psnr: {max_psnr:.4f} | max_ssim: {max_ssim:.4f}')\n\n    np.save(f'./numpy_files/{model_name}_{steps}_losses.npy',losses)\n    np.save(f'./numpy_files/{model_name}_{steps}_ssims.npy',ssims)\n    np.save(f'./numpy_files/{model_name}_{steps}_psnrs.npy',psnrs)\n\ndef test(net, loader_test, max_psnr, max_ssim, step):\n    net.eval()\n    torch.cuda.empty_cache()\n    ssims, psnrs = [], []\n    for i, (inputs, targets) in enumerate(loader_test):\n        inputs = inputs.to(device); targets = targets.to(device)\n        pred = net(inputs)\n        # # print(pred)\n        # tfs.ToPILImage()(torch.squeeze(targets.cpu())).save('111.png')\n        # vutils.save_image(targets.cpu(),'target.png')\n        # vutils.save_image(pred.cpu(),'pred.png')\n        ssim1 = ssim(pred, targets).item()\n        psnr1 = psnr(pred, targets)\n        ssims.append(ssim1)\n        psnrs.append(psnr1)\n        #if (psnr1>max_psnr or ssim1 > max_ssim) and s :\n#             ts=vutils.make_grid([torch.squeeze(inputs.cpu()),torch.squeeze(targets.cpu()),torch.squeeze(pred.clamp(0,1).cpu())])\n#             vutils.save_image(ts,f'samples/{model_name}/{step}_{psnr1:.4}_{ssim1:.4}.png')\n#             s=False\n    return np.mean(ssims) ,np.mean(psnrs)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train FFA-Net"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nloader_train = loaders_[trainset]\nloader_test = loaders_[testset]\nnet = models_[network]\nnet = net.to(device)\nif device == 'cuda':\n    net = torch.nn.DataParallel(net)\n    cudnn.benchmark = True\ncriterion = []\ncriterion.append(nn.L1Loss().to(device))\nif perloss:\n    vgg_model = vgg16(pretrained=True).features[:16]\n    vgg_model = vgg_model.to(device)\n    for param in vgg_model.parameters():\n        param.requires_grad = False\n    criterion.append(PerLoss(vgg_model).to(device))\noptimizer = optim.Adam(params = filter(lambda x: x.requires_grad, net.parameters()), lr=learning_rate, betas=(0.9,0.999), eps=1e-08)\noptimizer.zero_grad()\ntrain(net, loader_train, loader_test, optimizer, criterion)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Test FFA-Net"},{"metadata":{"trusted":true},"cell_type":"code","source":"# its or ots\ntask = 'its'\n# test imgs folder\ntest_imgs = '../input/synthetic-objective-testing-set-sots-reside/indoor/hazy/'\n\ndataset = task\nimg_dir = test_imgs\n\noutput_dir = f'pred_FFA_{dataset}/'\nprint(\"pred_dir:\",output_dir)\n\nif not os.path.exists(output_dir):\n    os.mkdir(output_dir)\n\nckp = torch.load(model_dir, map_location=device)\nnet = FFA(gps=gps, blocks=blocks)\nnet = nn.DataParallel(net)\nnet.load_state_dict(ckp['model'])\nnet.eval()\n\nfor im in os.listdir(img_dir):\n    haze = Image.open(img_dir+im)\n    haze1 = tfs.Compose([\n        tfs.ToTensor(),\n        tfs.Normalize(mean=[0.64, 0.6, 0.58],std=[0.14,0.15, 0.152])\n    ])(haze)[None,::]\n    haze_no = tfs.ToTensor()(haze)[None,::]\n    with torch.no_grad():\n        pred = net(haze1)\n    ts = torch.squeeze(pred.clamp(0,1).cpu())\n    # tensorShow([haze_no, pred.clamp(0,1).cpu()],['haze', 'pred'])\n    \n    haze_no = make_grid(haze_no, nrow=1, normalize=True)\n    ts = make_grid(ts, nrow=1, normalize=True)\n    image_grid = torch.cat((haze_no, ts), -1)\n    vutils.save_image(image_grid, output_dir+im.split('.')[0]+'_FFA.png')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}