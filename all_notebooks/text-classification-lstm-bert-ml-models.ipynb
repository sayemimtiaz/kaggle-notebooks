{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Text classification is the task of assigning a set of predefined categories to open-ended text. Text classifiers can be used to organize, structure, and categorize pretty much any kind of text – from documents, medical studies and files, and all over the web.We will classify the text into 9 categories.The 9 categories are:\n- computer       \n- science        \n- politics       \n- sport          \n- automobile     \n- religion        \n- medicine       \n- sales           \n- alt.atheism","metadata":{}},{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"markdown","source":"Let's first import all the required libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport random\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.graph_objects as go\nimport re\nimport string\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.datasets import fetch_20newsgroups\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn import svm\nfrom time import time\nfrom sklearn import linear_model\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import StratifiedKFold\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import model_selection\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, plot_confusion_matrix, confusion_matrix, f1_score\nfrom statistics import mean\nimport pickle\nfrom tensorflow import keras\nfrom keras import layers\nfrom keras import losses\nfrom keras import utils\nfrom keras.layers.experimental.preprocessing import TextVectorization\nfrom keras.callbacks import EarlyStopping\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, Bidirectional, Dropout\nfrom tensorflow.keras.models import load_model\nimport torch\nfrom tqdm.notebook import tqdm\nfrom transformers import BertTokenizer\nfrom torch.utils.data import TensorDataset\nfrom transformers import BertForSequenceClassification\nfrom torch.utils.data import DataLoader, RandomSampler, SequentialSampler\nfrom transformers import AdamW, get_linear_schedule_with_warmup","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Dataset","metadata":{}},{"cell_type":"markdown","source":"We will going to use the 20 news group dataset.Let's load the dataset in dataframe","metadata":{}},{"cell_type":"code","source":"dataset = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'), shuffle=True, random_state=42)\ndf = pd.DataFrame()\ndf['text'] = dataset.data\ndf['source'] = dataset.target\nlabel=[]\nfor i in df['source']:\n    label.append(dataset.target_names[i])\ndf['label']=label","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# first few rows of the dataset\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will later use the label enocder to convert the labels (categorical value) into numeric value.So now, we will drop that column","metadata":{}},{"cell_type":"code","source":"# drop source column\ndf.drop(['source'],axis=1,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's see the count of each label","metadata":{}},{"cell_type":"code","source":"# value count\ndf['label'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In our dataset we have very less data in a each categorical label and there are 20 categories which are too much.We will combine the sub-categories","metadata":{}},{"cell_type":"markdown","source":"- So in politics we have mideast, guns and misc sub-topics we will replace all to politics\n- We have sub-categories in sports, we will going to replace this also into sports\n- We have two sub categories in religion, we will replace them to one\n- We are going to make 9 categories in all","metadata":{}},{"cell_type":"code","source":"# replace to politics\ndf['label'].replace({'talk.politics.misc':'politics','talk.politics.guns':'politics',\n                     'talk.politics.mideast':'politics'},inplace=True)\n                    \n# replace to sport\ndf['label'].replace({'rec.sport.hockey':'sport','rec.sport.baseball':'sport'},inplace=True)\n                    \n# replace to religion\ndf['label'].replace({'soc.religion.christian':'religion','talk.religion.misc':'religion'},inplace=True)\n                    \n# replace to computer\ndf['label'].replace({'comp.windows.x':'computer','comp.sys.ibm.pc.hardware':'computer',\n                    'comp.os.ms-windows.misc':'computer','comp.graphics':'computer',\n                    'comp.sys.mac.hardware':'computer'},inplace=True)  \n# replace to sales\ndf['label'].replace({'misc.forsale':'sales'},inplace=True)\n\n# replace to automobile\ndf['label'].replace({'rec.autos':'automobile','rec.motorcycles':'automobile'},inplace=True)\n\n# replace to science\ndf['label'].replace({'sci.crypt':'science','sci.electronics':'science','sci.space':'science'},inplace=True)\n\n# replace to medicine\ndf['label'].replace({'sci.med':'medicine'},inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's see the number of unique targets ","metadata":{}},{"cell_type":"code","source":"# number of targets\ndf['label'].nunique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# value count\ndf['label'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We are going to make a number of words column in which there is the number of words in a particular text","metadata":{}},{"cell_type":"code","source":"df['Number_of_words'] = df['text'].apply(lambda x:len(str(x).split()))\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Check the basic stats of number of words, like maximum, minimum, average number of words","metadata":{}},{"cell_type":"code","source":"# basic stats\ndf['Number_of_words'].describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So the maximum number of words in our dataset is 11,765.Let's have a look at it","metadata":{}},{"cell_type":"code","source":"df[df['Number_of_words']==11765]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So maximu number of words text is belongs to electronics category.In our dataset we have some rows where there are no text at all i.e. the number of words is 0.We will drop those rows","metadata":{}},{"cell_type":"code","source":"no_text = df[df['Number_of_words']==0]\nprint(len(no_text))\n\n# drop these rows\ndf.drop(no_text.index,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.style.use('ggplot')\nplt.figure(figsize=(12,6))\nsns.distplot(df['Number_of_words'],kde = False,color=\"red\",bins=200)\nplt.title(\"Frequency distribution of number of words for each text extracted\", size=20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Pre-Processing","metadata":{}},{"cell_type":"markdown","source":"Now it's time to clean our dataset, we will lower the text, remove the text in square brackets, remove links and remove words containing numbers","metadata":{}},{"cell_type":"code","source":"# cleaning the text\n\ndef clean_text(text):\n    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n    and remove words containing numbers.'''\n    text = text.lower()\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    return text\n\n# Applying the cleaning function to  datasets\ndf['cleaned_text'] = df['text'].apply(lambda x: clean_text(x))\n\n# updated text\ndf['cleaned_text'].head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's convert our cleaned text into tokens","metadata":{}},{"cell_type":"code","source":"tokenizer=nltk.tokenize.RegexpTokenizer(r'\\w+')\ndf['tokens'] = df['cleaned_text'].apply(lambda x:tokenizer.tokenize(x))\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Stopwords are those english words which do not add much meaning to a sentence.They are very commonly used words and we do not required those words. So we can remove those stopwords","metadata":{}},{"cell_type":"code","source":"# stopwords\nstopwords.words('english')[0:5]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's check number of stopwords in nltk library","metadata":{}},{"cell_type":"code","source":"len(stopwords.words('english'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we are going to remome the stopwords from the sentences","metadata":{}},{"cell_type":"code","source":"# removing stopwords\ndef remove_stopwords(text):\n    words = [w for w in text if w not in stopwords.words('english')]\n    return words \ndf['stopwordremove_tokens'] = df['tokens'].apply(lambda x : remove_stopwords(x))\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It's time to do lemmatization","metadata":{}},{"cell_type":"code","source":"# lemmatization\nlem = WordNetLemmatizer()\ndef lem_word(x):\n    return [lem.lemmatize(w) for w in x]\n\ndf['lemmatized_text'] = df['stopwordremove_tokens'].apply(lem_word)\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we are going to combine our text, this is our final text","metadata":{}},{"cell_type":"code","source":"def combine_text(list_of_text):\n    '''Takes a list of text and combines them into one large chunk of text.'''\n    combined_text = ' '.join(list_of_text)\n    return combined_text\n\ndf['final_text'] = df['lemmatized_text'].apply(lambda x : combine_text(x))\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So we have cleaned the dataset and remove stopwords, it's possible that there are rows in which the text length is 0.We will find those rows and remove them","metadata":{}},{"cell_type":"code","source":"df['Final_no_of_words'] = df['final_text'].apply(lambda x:len(str(x).split()))\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# basic stats\ndf['Final_no_of_words'].describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# number of rows with text lenth = 0\nprint(len(df[df['Final_no_of_words']==0]))\n\n# drop those rows\ndf.drop(df[df['Final_no_of_words']==0].index,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now our text has been cleaned, we will convert the labels into numeric values using LableEncoder()","metadata":{}},{"cell_type":"code","source":"# label_encoder object knows how to understand word labels.\nlabel_encoder = preprocessing.LabelEncoder()\n  \n# Encode labels in column 'species'.\ndf['target']= label_encoder.fit_transform(df['label'])\n  \ndf['target'].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dependent and Independent Variable","metadata":{}},{"cell_type":"code","source":"# dependent and independent variable\nX = df['final_text']\ny = df['target']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.shape,y.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Bag-of-Words","metadata":{}},{"cell_type":"markdown","source":"CountVectorizer is used to transform a given text into a vector on the basis of the frequency(count) of each word that occurs in the entire text.It involves counting the number of occurences each words appears in a document(text)","metadata":{}},{"cell_type":"code","source":"count_vectorizer = CountVectorizer()\ncount_vector = count_vectorizer.fit_transform(X)\nprint(count_vector[0].todense())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Tf-Idf","metadata":{}},{"cell_type":"markdown","source":"Tf-Idf stands for Term Frequency-Inverse document frequency.It is a techinque to quantify a word in documents,we generally compute a weight to each word which signifies the importance of the word which signifies the importance of the word in the document and corpus","metadata":{}},{"cell_type":"code","source":"tfidf_vectorizer = TfidfVectorizer(min_df = 2,max_df = 0.5,ngram_range = (1,2))\ntfidf = tfidf_vectorizer.fit_transform(X)\nprint(tfidf[0].todense())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SMOTE technique to balance the dataset","metadata":{}},{"cell_type":"markdown","source":"So we can clearly see that our dataset is imbalanced dataset.We will use SMOTE technique to balance the dataset.SMOTE is an oversampling technique where the synthetic samples are generated for the minority class.The algorithm helps to overcome the overfitting problem posed by random sampling. ","metadata":{}},{"cell_type":"code","source":"# count vector\nsmote = SMOTE(random_state = 402)\nX_smote, Y_smote = smote.fit_resample(count_vector,y)\n\n\nsns.countplot(Y_smote)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tfidf\nsmote = SMOTE(random_state = 402)\nX_smote_tfidf, Y_smote_tfidf = smote.fit_resample(tfidf,y)\n\nsns.countplot(Y_smote_tfidf)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train-Test Split","metadata":{}},{"cell_type":"code","source":"# train-test split countvector\nX_train, X_test, y_train, y_test = train_test_split(X_smote, Y_smote, test_size = 0.20, random_state = 0)\nX_train.shape, X_test.shape,y_train.shape, y_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train-test split tfidf\nX_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(X_smote_tfidf, Y_smote_tfidf , test_size = 0.20, random_state = 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_time_container = {'linear_svm_tfidf':0,'linear_svm':0,'mnb_naive_bayes_tfidf':0,\n                         'mnb_naive_bayes':0,'random_forest_tfidf':0,'random_forest':0,\n                          'logistic_reg':0,'logistic_reg_tfidf':0}\nprediction_time_container = {'linear_svm_tfidf':0,'linear_svm':0,'mnb_naive_bayes_tfidf':0,\n                         'mnb_naive_bayes':0,'random_forest_tfidf':0,'random_forest':0,\n                            'logistic_reg':0,'logistic_reg_tfidf':0}\naccuracy_container = {'linear_svm_tfidf':0,'linear_svm':0,'mnb_naive_bayes_tfidf':0,\n                         'mnb_naive_bayes':0,'random_forest_tfidf':0,'random_forest':0,\n                     'logistic_reg':0,'logistic_reg_tfidf':0}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Logistic Regression","metadata":{}},{"cell_type":"code","source":"# on countvector\nlg = LogisticRegression(C = 1.0)\n#Fitting the model \nt0=time()\nlg.fit(X_train,y_train)\ntraining_time_container['logistic_reg']=time()-t0\n\n\n# Predicting the Test set results\nt0 = time()\ny_pred_lg = lg.predict(X_test)\nprediction_time_container['logistic_reg']=time()-t0\n\nlg_test_accuracy =  accuracy_score(y_test,y_pred_lg)\naccuracy_container['logistic_reg'] = lg_test_accuracy\n\nprint('Training Accuracy : ', accuracy_score(y_train,lg.predict(X_train)))\nprint('Testing Accuracy: ',lg_test_accuracy)\nprint(\"Training Time: \",training_time_container['logistic_reg'])\nprint(\"Prediction Time: \",prediction_time_container['logistic_reg'])\nprint(confusion_matrix(y_test,y_pred_lg))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# on tfidf\nlg = LogisticRegression(C = 1.0)\n#Fitting the model \nt0=time()\nlg.fit(X_train_tfidf,y_train_tfidf)\ntraining_time_container['logistic_reg_tfidf']=time()-t0\n\n# Predicting the Test set results\nt0=time()\nypred_lg_tf = lg.predict(X_test_tfidf)\nprediction_time_container['logistic_reg_tfidf']=time()-t0\n\nlg_test_accuracy_tf  = accuracy_score(y_test_tfidf,ypred_lg_tf)\naccuracy_container['logistic_reg_tfidf'] = lg_test_accuracy_tf\n\nprint('Training Accuracy: ', accuracy_score(y_train_tfidf,lg.predict(X_train_tfidf)))\nprint('Testing Accuracy: ', lg_test_accuracy_tf)\nprint(\"Training Time: \",training_time_container['logistic_reg_tfidf'])\nprint(\"Prediction Time: \",prediction_time_container['logistic_reg_tfidf'])\nprint(confusion_matrix(y_test,ypred_lg_tf))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Multinomial Naive Bayes","metadata":{}},{"cell_type":"code","source":"# on countvector\nnb = MultinomialNB()\n#Fitting the model \nt0=time()\nnb.fit(X_train,y_train)\ntraining_time_container['mnb_naive_bayes']=time()-t0\n\n\n# Predicting the Test set results\nt0 = time()\ny_pred_nb = nb.predict(X_test)\nprediction_time_container['mnb_naive_bayes']=time()-t0\n\nmnb_test_accuracy =  accuracy_score(y_test,y_pred_nb)\naccuracy_container['mnb_naive_bayes'] = mnb_test_accuracy\n\nprint('Training Accuracy : ', accuracy_score(y_train,nb.predict(X_train)))\nprint('Testing Accuracy: ',mnb_test_accuracy)\nprint(\"Training Time: \",training_time_container['mnb_naive_bayes'])\nprint(\"Prediction Time: \",prediction_time_container['mnb_naive_bayes'])\nprint(confusion_matrix(y_test,y_pred_nb))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# on tfidf\nnb = MultinomialNB()\n#Fitting the model \nt0=time()\nnb.fit(X_train_tfidf,y_train_tfidf)\ntraining_time_container['mnb_naive_bayes_tfidf']=time()-t0\n\n# Predicting the Test set results\nt0=time()\nypred_nb_tf = nb.predict(X_test_tfidf)\nprediction_time_container['mnb_naive_bayes_tfidf']=time()-t0\n\nmnb_tfidf_test_accuracy = accuracy_score(y_test_tfidf,ypred_nb_tf)\naccuracy_container['mnb_naive_bayes_tfidf'] = mnb_tfidf_test_accuracy \n\n\nprint('Training Accuracy: ', accuracy_score(y_train_tfidf,nb.predict(X_train_tfidf)))\nprint('Testing Accuracy: ',mnb_tfidf_test_accuracy )\nprint(\"Training Time: \",training_time_container['mnb_naive_bayes_tfidf'])\nprint(\"Prediction Time: \",prediction_time_container['mnb_naive_bayes_tfidf'])\nprint(confusion_matrix(y_test,ypred_nb_tf))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## SVM using Stochastic Gradient Descent","metadata":{}},{"cell_type":"code","source":"# Used hinge loss which gives linear Support Vector Machine. Also set the learning rate to 0.0001 (also the default value)\n# which is a constant that's gets multiplied with the regularization term. For penalty, I've used L2 which is the standard\n#regularizer for linear SVMs\n\n\n# on countvector\nsvm_classifier = linear_model.SGDClassifier(loss='hinge',alpha=0.0001)\nt0=time()\nsvm_classifier.fit(X_train,y_train)\ntraining_time_container['linear_svm']=time()-t0\n\n# Predicting the Test set results\nt0=time()\ny_pred_svm = svm_classifier.predict(X_test)\nprediction_time_container['linear_svm']=time()-t0\n\nsvm_test_accuracy  = accuracy_score(y_test,y_pred_svm)\naccuracy_container['linear_svm'] = svm_test_accuracy \n\nprint('Training Accuracy : ', accuracy_score(y_train,svm_classifier.predict(X_train)))\nprint('Testing Accuracy: ',svm_test_accuracy )\nprint(\"Training Time: \",training_time_container['linear_svm'])\nprint(\"Prediction Time: \",prediction_time_container['linear_svm'])\nprint(confusion_matrix(y_test,y_pred_svm))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# on tfidf\nsvm_classifier = linear_model.SGDClassifier(loss='hinge',alpha=0.0001)\n#Fitting the model \nt0=time()\nsvm_classifier.fit(X_train_tfidf,y_train_tfidf)\ntraining_time_container['linear_svm_tfidf']=time()-t0\n\n# Predicting the Test set results\nt0=time()\nypred_svm_tf = svm_classifier.predict(X_test_tfidf)\nprediction_time_container['linear_svm_tfidf']=time()-t0\n\nsvm_test_accuracy_tf  = accuracy_score(y_test_tfidf,ypred_svm_tf)\naccuracy_container['linear_svm_tfdif'] = svm_test_accuracy_tf \n\nprint('Training Accuracy: ', accuracy_score(y_train_tfidf,svm_classifier.predict(X_train_tfidf)))\nprint('Testing Accuracy: ', svm_test_accuracy_tf)\nprint(\"Training Time: \",training_time_container['linear_svm_tfidf'])\nprint(\"Prediction Time: \",prediction_time_container['linear_svm_tfidf'])\nprint(confusion_matrix(y_test,ypred_svm_tf))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## RandomForest ","metadata":{}},{"cell_type":"code","source":"# on count vectorizer\nrf = RandomForestClassifier(n_estimators=50)\nt0=time()\nrf.fit(X_train,y_train)\ntraining_time_container['random_forest']=time()-t0\n\n# Predicting the Test set results\nt0=time()\ny_pred_rf = rf.predict(X_test)\nprediction_time_container['random_forest']=time()-t0\n\nrf_test_accuracy  = accuracy_score(y_test,y_pred_rf)\naccuracy_container['random_forest'] = rf_test_accuracy \n\n\nprint('Training Accuracy : ', accuracy_score(y_train,rf.predict(X_train)))\nprint('Testing Accuracy: ',rf_test_accuracy )\nprint(\"Training Time: \",training_time_container['random_forest'])\nprint(\"Prediction Time: \",prediction_time_container['random_forest'])\nprint(confusion_matrix(y_test,y_pred_rf))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# on tfidf\nrf = RandomForestClassifier(n_estimators=50)\n#Fitting the model \nt0=time()\nrf.fit(X_train_tfidf,y_train_tfidf)\ntraining_time_container['random_forest_tfidf']=time()-t0\n\n# Predicting the Test set results\nt0=time()\nypred_rf_tf = rf.predict(X_test_tfidf)\nprediction_time_container['random_forest_tfidf']=time()-t0\n\nrf_test_accuracy_tf  = accuracy_score(y_test_tfidf,ypred_rf_tf)\naccuracy_container['random_forest_tfidf'] = rf_test_accuracy_tf\n\nprint('Training Accuracy: ', accuracy_score(y_train_tfidf,rf.predict(X_train_tfidf)))\nprint('Testing Accuracy: ',rf_test_accuracy_tf )\nprint(\"Training Time: \",training_time_container['random_forest_tfidf'])\nprint(\"Prediction Time: \",prediction_time_container['random_forest_tfidf'])\nprint(confusion_matrix(y_test,ypred_rf_tf ))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig=go.Figure(data=[go.Bar(y=list(training_time_container.values()),x=list(training_time_container.keys()),\n                           marker={'color':np.arange(len(list(training_time_container.values())))}\n                          ,text=list(training_time_container.values()), textposition='auto' )])\n\nfig.update_layout(autosize=True ,plot_bgcolor='rgb(275, 275, 275)',\n                  title=\"Comparison of Training Time of different classifiers\",\n                    xaxis_title=\"Machine Learning Models\",\n                    yaxis_title=\"Training time in seconds\" )\n\nfig.data[0].marker.line.width = 3\nfig.data[0].marker.line.color = \"black\"  \nfig","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig=go.Figure(data=[go.Bar(y=list(prediction_time_container.values()),x=list(prediction_time_container.keys()),\n                           marker={'color':np.arange(len(list(prediction_time_container.values())))}\n                          ,text=list(prediction_time_container.values()), textposition='auto' )])\n\nfig.update_layout(autosize=True ,plot_bgcolor='rgb(275, 275, 275)',\n                  title=\"Comparison of Prediction Time of different classifiers\",\n                    xaxis_title=\"Machine Learning Models\",\n                    yaxis_title=\"Prediction time in seconds\" )\n\nfig.data[0].marker.line.width = 3\nfig.data[0].marker.line.color = \"black\"  \nfig","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig=go.Figure(data=[go.Bar(y=list(accuracy_container.values()),x=list(accuracy_container.keys()),\n                           marker={'color':np.arange(len(list(accuracy_container.values())))}\n                          ,text=list(accuracy_container.values()), textposition='auto' )])\n\nfig.update_layout(autosize=True ,plot_bgcolor='rgb(275, 275, 275)',\n                  title=\"Comparison of Accuracy Scores of different classifiers\",\n                    xaxis_title=\"Machine Learning Models\",\n                    yaxis_title=\"Accuracy Scores\" )\n\nfig.data[0].marker.line.width = 3\nfig.data[0].marker.line.color = \"black\"  \nfig","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Stratified K-fold CV","metadata":{}},{"cell_type":"markdown","source":"In machine learning, when we want to train our ML model we split our entire dataset into train set and test set using train test split class present in sklearn.Then we train our model on train set and test our model on test set. The problems that we face are, whenever we change the random_state parameter present in train_test_split(), we get different accuracy for different random_state and hence we can’t exactly point out the accuracy for our model.<br>\nThe solution for the this problem is to use K-Fold Cross-Validation. But K-Fold Cross Validation also suffer from second problem i.e. random sampling.<br>\nThe solution for both first and second problem is to use Stratified K-Fold Cross-Validation.Stratified k-fold cross-validation is same as just k-fold cross-validation, But in Stratified k-fold cross-validation, it does stratified sampling instead of random sampling.","metadata":{}},{"cell_type":"markdown","source":"## SVM","metadata":{}},{"cell_type":"code","source":"svm_skcv = linear_model.SGDClassifier(loss='hinge',alpha=0.0001)\n\n# StratifiedKFold object.\nskf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\nlst_accu_stratified_svm = []\n   \nfor train_index, test_index in skf.split(X_smote_tfidf,Y_smote_tfidf):\n    x_train_fold, x_test_fold = X_smote_tfidf[train_index], X_smote_tfidf[test_index]\n    y_train_fold, y_test_fold = Y_smote_tfidf[train_index], Y_smote_tfidf[test_index]\n    svm_skcv.fit(x_train_fold, y_train_fold)\n    lst_accu_stratified_svm.append(svm_skcv.score(x_test_fold, y_test_fold))\n   \n# Print the output.\nprint('List of possible accuracy:', lst_accu_stratified_svm)\nprint('\\nMaximum Accuracy That can be obtained from this model is:',max(lst_accu_stratified_svm)*100, '%')\nprint('\\nMinimum Accuracy:', min(lst_accu_stratified_svm)*100, '%')\nprint('\\nOverall Accuracy:',mean(lst_accu_stratified_svm)*100, '%')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## RandomForest","metadata":{}},{"cell_type":"code","source":"rf_skcv = RandomForestClassifier(n_estimators=50)\n\n# StratifiedKFold object.\nskf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\nlst_accu_stratified_rf = []\n   \nfor train_index, test_index in skf.split(X_smote_tfidf,Y_smote_tfidf):\n    x_train_fold, x_test_fold = X_smote_tfidf[train_index], X_smote_tfidf[test_index]\n    y_train_fold, y_test_fold = Y_smote_tfidf[train_index], Y_smote_tfidf[test_index]\n    rf_skcv.fit(x_train_fold, y_train_fold)\n    lst_accu_stratified_rf.append(rf_skcv.score(x_test_fold, y_test_fold))\n   \n# Print the output.\nprint('List of possible accuracy:', lst_accu_stratified_rf)\nprint('\\nMaximum Accuracy That can be obtained from this model is:', max(lst_accu_stratified_rf)*100, '%')\nprint('\\nMinimum Accuracy:', min(lst_accu_stratified_rf)*100, '%')\nprint('\\nOverall Accuracy:', mean(lst_accu_stratified_rf)*100, '%')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Multinomial Naive Bayes","metadata":{}},{"cell_type":"code","source":"nb_skcv = MultinomialNB()\n\n# StratifiedKFold object.\nskf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\nlst_accu_stratified_nb = []\n   \nfor train_index, test_index in skf.split(X_smote_tfidf,Y_smote_tfidf):\n    x_train_fold, x_test_fold = X_smote_tfidf[train_index], X_smote_tfidf[test_index]\n    y_train_fold, y_test_fold = Y_smote_tfidf[train_index], Y_smote_tfidf[test_index]\n    nb_skcv.fit(x_train_fold, y_train_fold)\n    lst_accu_stratified_nb.append(nb_skcv.score(x_test_fold, y_test_fold))\n   \n# Print the output.\nprint('List of possible accuracy:', lst_accu_stratified_nb)\nprint('\\nMaximum Accuracy That can be obtained from this model is:', max(lst_accu_stratified_nb)*100, '%')\nprint('\\nMinimum Accuracy:', min(lst_accu_stratified_nb)*100, '%')\nprint('\\nOverall Accuracy:', mean(lst_accu_stratified_nb)*100, '%')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Save the models","metadata":{}},{"cell_type":"code","source":"import joblib","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cv and tfidf\njoblib.dump(count_vectorizer, open('cv.pkl', 'wb'),8)\njoblib.dump(tfidf_vectorizer, open('tfidf.pkl', 'wb'),8)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# mnb \njoblib.dump(nb, open('mnb.pkl', 'wb'),8)\n\n# svm\njoblib.dump(svm_classifier, open('svm.pkl', 'wb'),8)\n\n# randomforest\njoblib.dump(rf , open('rf.pkl', 'wb'),8)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LSTM","metadata":{}},{"cell_type":"markdown","source":"We will not going to create RNN model due to its vanishing gradient problem instead of that we will going to create LSTM model.LSTMs have an additional state called ‘cell state’ through which the network makes adjustments in the information flow. The advantage of this state is that the model can remember or forget the leanings more selectively.\nFirst of all we are going to do tokenization then we will generate sequence of n-grams.After that we will going to do padding.Padding is required because all the sentences are of different length so we need to make them of same length.We will going to do this by adding 0 in the end of the text with the help of pad_sequences function of keras","metadata":{}},{"cell_type":"code","source":"max_features = 6433     # the maximum number of words to keep, based on word frequency\ntokenizer = Tokenizer(num_words=max_features )\ntokenizer.fit_on_texts(df['cleaned_text'].values)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = tokenizer.texts_to_sequences(df['cleaned_text'].values)\nX = pad_sequences(X, padding = 'post', maxlen = 6433 )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.shape[1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y = pd.get_dummies(df['label']).values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.25, random_state = 42,stratify = Y)\nprint(X_train.shape,Y_train.shape)\nprint(X_test.shape,Y_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embid_dim = 300\nlstm_out = 32\n\n\nmodel = keras.Sequential()\nmodel.add(Embedding(max_features, embid_dim, input_length = X.shape[1] ))\nmodel.add(Bidirectional(LSTM(lstm_out)))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(32, activation = 'relu'))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(9,activation = 'softmax'))\n\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So our model is created now it's time to train our model, we will going to use 10 epochs","metadata":{}},{"cell_type":"code","source":"batch_size = 128\nearlystop = EarlyStopping(monitor='loss', min_delta=0, patience=3, verbose=0, mode='auto')\nmodel.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\nhistory = model.fit(X_train, Y_train, epochs = 10, batch_size=batch_size, verbose = 1, validation_data= (X_test, Y_test),callbacks=[earlystop])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Plot Accuracy and Loss","metadata":{}},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\n\nplt.plot(epochs, loss, 'r', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Save LSTM model","metadata":{}},{"cell_type":"code","source":"model.save('lstm.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# BERT","metadata":{}},{"cell_type":"markdown","source":"So now we will going to make the bert model.In our kernel we have less memory so we will going to take 50% of our dataset","metadata":{}},{"cell_type":"code","source":"df_bert = df.sample(frac=0.5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_bert.reset_index(inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_bert['target'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So our dataset is imbalanced, we split the dataset in a stratified way","metadata":{}},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(df_bert.index.values, \n                                                  df_bert.target.values, \n                                                  test_size=0.15, \n                                                  random_state=42, \n                                                  stratify=df_bert.target.values)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_bert['data_type'] = ['not_set']*df_bert.shape[0]\n\ndf_bert.loc[X_train, 'data_type'] = 'train'\ndf_bert.loc[X_val, 'data_type'] = 'val'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we will construct the BERT Tokenizer.Based on wordpiece.We will intantiate a pre-trained model configuration to encode our data","metadata":{}},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', \n                                          do_lower_case=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- To convert all the titles from text into encoded form, we use a function called *batch_encode_plus* and we will proceed train and test data seperately.The first parameter inside the function is the text.\n- *add_special_tokens = True* means the sequences will encoded with the special tokens realtive to their model\n- *return_attention_mask=True* returns the attention mask according to the special tokenizer defined by *max_length* attribute","metadata":{}},{"cell_type":"code","source":"encoded_data_train = tokenizer.batch_encode_plus(\n    df_bert[df_bert.data_type=='train'].final_text.values, \n    add_special_tokens=True, \n    return_attention_mask=True, \n    pad_to_max_length=True, \n    max_length=256, \n    return_tensors='pt'\n)\n\nencoded_data_val = tokenizer.batch_encode_plus(\n    df_bert[df_bert.data_type=='val'].final_text.values, \n    add_special_tokens=True, \n    return_attention_mask=True, \n    pad_to_max_length=True, \n    max_length=256, \n    return_tensors='pt'\n)\n\n\ninput_ids_train = encoded_data_train['input_ids']\nattention_masks_train = encoded_data_train['attention_mask']\nlabels_train = torch.tensor(df_bert[df_bert.data_type=='train'].target.values)\n\ninput_ids_val = encoded_data_val['input_ids']\nattention_masks_val = encoded_data_val['attention_mask']\nlabels_val = torch.tensor(df_bert[df_bert.data_type=='val'].target.values)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we got encoded dataset, we can create training data and validation data","metadata":{}},{"cell_type":"code","source":"dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\ndataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# length of training and validation data \nlen(dataset_train), len(dataset_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We are treating each title as its unique sequence, so one sequence will be classified into one of the 12 labels","metadata":{}},{"cell_type":"code","source":"model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n                                                      num_labels=12,\n                                                      output_attentions=False,\n                                                      output_hidden_states=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"DataLoader combines a dataset and a sampler and provides an iterable over the given dataset.","metadata":{}},{"cell_type":"code","source":"batch_size = 3\n\ndataloader_train = DataLoader(dataset_train, \n                              sampler=RandomSampler(dataset_train), \n                              batch_size=batch_size)\n\ndataloader_validation = DataLoader(dataset_val, \n                                   sampler=SequentialSampler(dataset_val), \n                                   batch_size=batch_size)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = AdamW(model.parameters(),\n                  lr=1e-5, \n                  eps=1e-8)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 3\n\nscheduler = get_linear_schedule_with_warmup(optimizer, \n                                            num_warmup_steps=0,\n                                            num_training_steps=len(dataloader_train)*epochs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will use f1 score as a performance metrics","metadata":{}},{"cell_type":"code","source":"def f1_score_func(preds, labels):\n    preds_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n    return f1_score(labels_flat, preds_flat, average='weighted')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed_val = 17\nrandom.seed(seed_val)\nnp.random.seed(seed_val)\ntorch.manual_seed(seed_val)\ntorch.cuda.manual_seed_all(seed_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)\n\nprint(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training loop","metadata":{}},{"cell_type":"code","source":"def evaluate(dataloader_val):\n\n    model.eval()\n    \n    loss_val_total = 0\n    predictions, true_vals = [], []\n    \n    for batch in dataloader_val:\n        \n        batch = tuple(b.to(device) for b in batch)\n        \n        inputs = {'input_ids':      batch[0],\n                  'attention_mask': batch[1],\n                  'labels':         batch[2],\n                 }\n\n        with torch.no_grad():        \n            outputs = model(**inputs)\n            \n        loss = outputs[0]\n        logits = outputs[1]\n        loss_val_total += loss.item()\n\n        logits = logits.detach().cpu().numpy()\n        label_ids = inputs['labels'].cpu().numpy()\n        predictions.append(logits)\n        true_vals.append(label_ids)\n    \n    loss_val_avg = loss_val_total/len(dataloader_val) \n    \n    predictions = np.concatenate(predictions, axis=0)\n    true_vals = np.concatenate(true_vals, axis=0)\n            \n    return loss_val_avg, predictions, true_vals","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in tqdm(range(1, epochs+1)):\n    \n    #model.train()\n    \n    loss_train_total = 0\n\n    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n    for batch in progress_bar:\n\n        model.zero_grad()\n        \n        batch = tuple(b.to(device) for b in batch)\n        \n        inputs = {'input_ids':      batch[0],\n                  'attention_mask': batch[1],\n                  'labels':         batch[2],\n                 }       \n\n        outputs = model(**inputs)\n        \n        loss = outputs[0]\n        loss_train_total += loss.item()\n        loss.backward()\n\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n\n        optimizer.step()\n        scheduler.step()\n        \n        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n        \n        \n    tqdm.write(f'\\nEpoch {epoch}')\n    \n    loss_train_avg = loss_train_total/len(dataloader_train)            \n    tqdm.write(f'Training loss: {loss_train_avg}')\n    \n    val_loss, predictions, true_vals = evaluate(dataloader_validation)\n    val_f1 = f1_score_func(predictions, true_vals)\n    tqdm.write(f'Validation loss: {val_loss}')\n    tqdm.write(f'F1 Score (Weighted): {val_f1}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}