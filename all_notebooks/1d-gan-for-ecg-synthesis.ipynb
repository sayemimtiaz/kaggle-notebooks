{"cells":[{"metadata":{"id":"PWdS5fYXo2s9"},"cell_type":"markdown","source":"# Generative Adversarial Network for ECG synthesis\nThis notebook is an addition to this [notebook](https://www.kaggle.com/polomarco/ecg-classification-cnn-lstm-attention-mechanism)."},{"metadata":{"_kg_hide-input":true,"trusted":true,"id":"Bcd8t2P4o2tH","outputId":"07922392-b41f-4b7b-8e96-86c1dc5e9b2b"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport cv2\nimport imageio as io\n\nlat_D = 'max[log(D(x))+log(1-D(G(x))]'\nlat_G = 'min[log(D(x))+log(1-D(G(x))]'\n\nplt.figure(figsize=(12, 10))\nplt.imshow(io.imread(\"https://i.pinimg.com/originals/97/c8/0e/97c80e536a8b8712a8299dddb9f14e07.jpg\"))\nplt.axis('off');\n\nplt.text(80, 220, \"Generator\", \n         fontdict={\n             \"fontsize\":15,\n             \"color\":\"#FF033E\",\n             \"weight\": \"bold\"\n             }\n         );\nplt.text(38, 230, r\"$%s$\" % lat_G, \n         fontdict={\n             \"fontsize\":13,\n             \"color\":\"black\",\n             \"weight\": \"bold\"\n             }\n         );\n                                                                                               \nplt.text(300, 120, r\"Discriminator\", \n         fontdict={\n             \"fontsize\":15,\n             \"color\":\"lime\",\n             \"weight\": \"bold\"\n             }\n         );\n         \nplt.text(260, 130, r\"$%s$\" % lat_D,\n         fontdict=\n         {\"fontsize\":13,\n          \"color\":\"white\",\n          \"weight\": \"bold\"\n          }\n         );","execution_count":null,"outputs":[]},{"metadata":{"id":"w1B4aDB5o2tK"},"cell_type":"markdown","source":"![](https://64.media.tumblr.com/66dc00e688f72af4d7b5d768005359c4/094fefb7e60b17ee-9c/s500x750/3060385c5fdcb38f3a716d8a309a40e69e598a5f.png)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"id":"mU-LH25oo2tL"},"cell_type":"code","source":"import os\nimport time\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim import AdamW, Adam\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"FUN6yAu7o2tM"},"cell_type":"code","source":"class Config:\n    csv_path = ''\n    seed = 2021\n    device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n\ndef seed_everything(seed: int):\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n    \nconfig = Config()\nseed_everything(config.seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"ORrVrvbJo2tM"},"cell_type":"code","source":"df_ptbdb = pd.read_csv('/kaggle/input/heartbeat/ptbdb_abnormal.csv')\ndf_mitbih = pd.read_csv('/kaggle/input/heartbeat/mitbih_train.csv')\ndf_ptbdb.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"mgHScVqlo2tN","outputId":"40fd6a61-cbb1-49b7-865e-729f83759a01"},"cell_type":"code","source":"df_mitbih_train = pd.read_csv('/kaggle/input/heartbeat/mitbih_train.csv', header=None)\ndf_mitbih_test = pd.read_csv('/kaggle/input/heartbeat/mitbih_test.csv', header=None)\ndf_mitbih = pd.concat([df_mitbih_train, df_mitbih_test], axis=0)\ndf_mitbih.rename(columns={187: 'class'}, inplace=True)\n\nid_to_label = {\n    0: \"Normal\",\n    1: \"Artial Premature\",\n    2: \"Premature ventricular contraction\",\n    3: \"Fusion of ventricular and normal\",\n    4: \"Fusion of paced and normal\"\n}\ndf_mitbih['label'] = df_mitbih.iloc[:, -1].map(id_to_label)\nprint(df_mitbih.info())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"cFK-v-3Ho2tN"},"cell_type":"code","source":"df_mitbih.to_csv('data.csv', index=False)\nconfig.csv_path = 'data.csv'","execution_count":null,"outputs":[]},{"metadata":{"id":"hv3xX7FWo2tO"},"cell_type":"markdown","source":"# Basic EDA"},{"metadata":{"trusted":true,"id":"29vCaKCNo2tO","outputId":"cf113e7d-5083-43ef-a2dc-aee7fe734ed0"},"cell_type":"code","source":"df_mitbih['label'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"id":"CvgGtV3Jo2tP","outputId":"848f29bc-e513-405c-eb26-ed0045d68bf3"},"cell_type":"code","source":"percentages = [count / df_mitbih.shape[0] * 100 for count in df_mitbih['label'].value_counts()]\n\nfig, ax = plt.subplots(figsize=(12, 6))\nsns.countplot(\n    x=df_mitbih['label'],\n    ax=ax,\n    palette=\"bright\",\n    order=df_mitbih['label'].value_counts().index\n)\nax.set_xticklabels(ax.get_xticklabels(), rotation=15);\n\nfor percentage, count, p in zip(\n    percentages,\n    df_mitbih['label'].value_counts(sort=True).values,\n    ax.patches):\n    \n    percentage = f'{np.round(percentage, 2)}%'\n    x = p.get_x() + p.get_width() / 2 - 0.4\n    y = p.get_y() + p.get_height()\n    ax.annotate(str(percentage)+\" / \"+str(count), (x, y), fontsize=12, fontweight='bold')\n    \nplt.savefig('data_dist.png', facecolor='w', edgecolor='w', format='png',\n        transparent=False, bbox_inches='tight', pad_inches=0.1)\nplt.savefig('data_dist.svg', facecolor='w', edgecolor='w', format='svg',\n        transparent=False, bbox_inches='tight', pad_inches=0.1)","execution_count":null,"outputs":[]},{"metadata":{"id":"GsHjXM9po2tQ"},"cell_type":"markdown","source":"# Dataset"},{"metadata":{"trusted":true,"id":"-36cguDho2tQ"},"cell_type":"code","source":"class ECGDataset(Dataset):\n\n    def __init__(self, df):\n        self.df = df\n        self.data_columns = self.df.columns[:-2].tolist()\n\n    def __getitem__(self, idx):\n        signal = self.df.loc[idx, self.data_columns].astype('float32')\n        signal = torch.FloatTensor([signal.values])                 \n        target = torch.LongTensor(np.array(self.df.loc[idx, 'class']))\n        return signal, target\n\n    def __len__(self):\n        return len(self.df)\n\ndef get_dataloader(label_name, batch_size):\n    df = pd.read_csv(config.csv_path)\n    df = df.loc[df['label'] == label_name]\n    df.reset_index(drop=True, inplace=True)\n    dataset = ECGDataset(df)\n    dataloader = DataLoader(dataset=dataset, batch_size=batch_size, num_workers=0)\n    return dataloader\n    \n    \ndataloader = get_dataloader(label_name='Artial Premature', batch_size=96)\n\nprint(len(dataloader))\nx,y = next(iter(dataloader))\nx.shape, y.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Models"},{"metadata":{"trusted":true,"id":"0nhtdB6Vo2tQ"},"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass Generator(nn.Module):\n    def __init__(self):\n        super(Generator, self).__init__()\n        self.fc1 = nn.Linear(256, 256)\n        self.fc2 = nn.Linear(256, 256)\n        self.fc3 = nn.Linear(256, 187)\n        self.rnn_layer = nn.LSTM(\n                input_size=187,\n                hidden_size=128,\n                num_layers=1,\n                bidirectional=True,\n                batch_first=True,\n            )\n    def forward(self, x):\n        x,_ = self.rnn_layer(x)\n        x = x.view(-1,256)\n        x = F.leaky_relu(self.fc1(x))\n        x = F.leaky_relu(self.fc2(x))\n        x = F.dropout(x, p=0.2)\n        x = self.fc3(x)\n        return x.unsqueeze(1)\n\n\nclass Discriminator(nn.Module):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n        \n        self.rnn_layer = nn.LSTM(\n                input_size=187,\n                hidden_size=256,\n                num_layers=1,\n                bidirectional=True,\n                batch_first=True,\n            )\n        self.fc1 = nn.Linear(512, 512)\n        self.fc2 = nn.Linear(512, 256) \n        self.fc3 = nn.Linear(256, 1)\n\n    def forward(self, x):\n        x,_ = self.rnn_layer(x)\n        x = x.view(-1, 512)\n        x = F.leaky_relu(self.fc1(x))\n        x = F.leaky_relu(self.fc2(x))\n        x = F.dropout(x, p=0.2)\n        x = torch.sigmoid(self.fc3(x))\n        return x","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training stage"},{"metadata":{"trusted":true,"id":"NUd86RQBo2tS"},"cell_type":"code","source":"class Trainer:\n    def __init__(\n        self,\n        generator,\n        discriminator,\n        batch_size,\n        num_epochs,\n        label\n    ):\n        self.device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n        self.netG = generator.to(self.device)\n        self.netD = discriminator.to(self.device)\n        \n        self.optimizerD = Adam(self.netD.parameters(), lr=0.0002)\n        self.optimizerG = Adam(self.netG.parameters(), lr=0.0002)\n        self.criterion = nn.BCELoss()\n        \n        self.batch_size = batch_size\n        self.signal_dim = [self.batch_size, 1, 187]\n        self.num_epochs = num_epochs\n        self.dataloader = get_dataloader(\n            label_name=label, batch_size=self.batch_size\n        )\n        self.fixed_noise = torch.randn(self.batch_size, 1, 187,\n                                       device=self.device)\n        self.g_errors = []\n        self.d_errors = []\n        \n    def _one_epoch(self):\n        real_label = 1\n        fake_label = 0\n        \n        for i, data in enumerate(self.dataloader, 0):\n            ##### Update Discriminator: maximize log(D(x)) + log(1 - D(G(z))) #####\n            ## train with real data\n            self.netD.zero_grad()\n            real_data = data[0].to(self.device)\n            # dim for noise\n            batch_size = real_data.size(0)\n            self.signal_dim[0] = batch_size\n            \n            label = torch.full((batch_size,), real_label,\n                           dtype=real_data.dtype, device=self.device)\n            \n            output = self.netD(real_data)\n            output = output.view(-1)\n       \n            errD_real = self.criterion(output, label)\n            errD_real.backward()\n            D_x = output.mean().item()\n            \n            ## train with fake data\n            noise = torch.randn(self.signal_dim, device=self.device)\n            fake = self.netG(noise)\n            label.fill_(fake_label)\n            \n            output = self.netD(fake.detach())\n            output = output.view(-1)\n            \n            errD_fake = self.criterion(output, label)\n            errD_fake.backward()\n            D_G_z1 = output.mean().item()\n            errD = errD_real + errD_fake \n            self.optimizerD.step()\n            \n            ##### Update Generator: maximaze log(D(G(z)))  \n            self.netG.zero_grad()\n            label.fill_(real_label) \n            output = self.netD(fake)\n            output = output.view(-1)\n            \n            errG = self.criterion(output, label)\n            errG.backward()\n            D_G_z2 = output.mean().item()\n            self.optimizerG.step()\n            \n        return errD.item(), errG.item()\n        \n    def run(self):\n        for epoch in range(self.num_epochs):\n            errD_, errG_ = self._one_epoch()\n            self.d_errors.append(errD_)\n            self.g_errors.append(errG_)\n            if epoch % 300 == 0:\n                print(f\"Epoch: {epoch} | Loss_D: {errD_} | Loss_G: {errG_} | Time: {time.strftime('%H:%M:%S')}\")\n   \n                fake = self.netG(self.fixed_noise)\n                plt.plot(fake.detach().cpu().squeeze(1).numpy()[:].transpose())\n                plt.show()\n            \n        torch.save(self.netG.state_dict(), f\"generator.pth\")\n        torch.save(self.netG.state_dict(), f\"discriminator.pth\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g = Generator()\nd = Discriminator()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"vbsXrltbo2tT"},"cell_type":"code","source":"trainer = Trainer(\n    generator=g,\n    discriminator=d,\n    batch_size=96,\n    num_epochs=3000,\n    label='Fusion of ventricular and normal'\n)\ntrainer.run()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"id":"V9ONlQ8-o2tW","outputId":"0cd32f2b-9ffe-4d76-d39e-de3a130d6ed4"},"cell_type":"code","source":"plt.figure(figsize=(12, 5))\nplt.title(\"GAN Errors in Training\")\nplt.plot(trainer.d_errors, label='Generator Error', c='#1CD3A2')\nplt.plot(trainer.g_errors, label='Discriminator Error', c='#FF0033')\nplt.xlabel(\"Epochs\")\nplt.ylabel('Error')\n_ = plt.legend()\nplt.savefig('Gan_Losses.png', facecolor='w', edgecolor='w', format='png',\n        transparent=False, bbox_inches='tight', pad_inches=0.1)\nplt.savefig('Gan_Losses.svg', facecolor='w', edgecolor='w', format='svg',\n        transparent=False, bbox_inches='tight', pad_inches=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"id":"THQDcRKYo2tX","outputId":"552cb67e-b7e9-4390-ce25-289ddc60048b"},"cell_type":"code","source":"df = pd.read_csv(config.csv_path)\ndf = df.loc[df['label'] == 'Fusion of ventricular and normal']\n\n# real signal\nN = 1\nreal_samples =  df.sample(N).values[:, :-2].transpose()\n\nsynthetic signal\nfake = trainer.netG(trainer.fixed_noise)\nindex = np.random.choice(fake.shape[0], N, replace=False) \nsynthetic_samples = fake.detach().cpu().squeeze(1).numpy()[index].transpose()\n\nfig, axs = plt.subplots(1, 2, figsize=(15, 4))\n\n\naxs[0].plot(real_samples, c='#007FFF')\naxs[0].set_title(\"Real\", fontsize= 12, weight=\"bold\")\n\n\naxs[1].plot(synthetic_samples, c=\"crimson\")\naxs[1].set_title(\"Synthetic\", fontsize= 12, weight=\"bold\")\n\nplt.suptitle('class \"Fusion of ventricular and normal\"', fontsize=18, y=1.05, weight=\"bold\")\nplt.tight_layout()\nplt.savefig('Fusion_of_ventricular_and_normal.png', facecolor='w', edgecolor='w', format='png',\n        transparent=False, bbox_inches='tight', pad_inches=0.1)\nplt.savefig('Fusion_of_ventricular_and_normal.svg', facecolor='w', edgecolor='w', format='svg',\n        transparent=False, bbox_inches='tight', pad_inches=0.1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusion\nSince this is a standard process for training a GAN model, we can observe that the Generator produces predominantly dominant signal types.\nMore specifically, we have a total of 803 signals of the '\"Fusion of ventricular and normal\"' class, most of which are very similar, and that's what GAN model learned to generate."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}