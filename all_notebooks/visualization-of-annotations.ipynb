{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction\nWelcome to this kernel about the Brackish dataset from AAU.\nIn this kernel we will come by the following steps:\n\n* Loading annotations using Pandas.\n* Specifying video and frame of interest.\n* Extracting relevant annotations for video and frame.\n* How to plot the annotated frame\n"},{"metadata":{},"cell_type":"markdown","source":"# Loading annotations using Pandas\nThe annotation files will be loaded using pandas, since pandas is a great library for data analsys and provide an easy method for loading comma separated file (CSV), however, in this case the files are seperated by semicolons."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport cv2 # For loading the videofile and plotting bounding boxes\nimport os # For loading datafiles\nfrom matplotlib import pyplot as plt # For plotting the annotations\n\n# Input data files are available in the \"../input/\" directory.\n# Loading data, the data is semicolon seperated.\n\nValid = pd.read_csv(\"../input/brackish-dataset/annotations/annotations_AAU/valid.csv\", sep=\";\")\nTrain = pd.read_csv(\"../input/brackish-dataset/annotations/annotations_AAU/train.csv\", sep=\";\")\nTest = pd.read_csv(\"../input/brackish-dataset/annotations/annotations_AAU/test.csv\", sep=\";\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Specifying video and frame of interest\n\nThe only thing needed to be specified, is which videofile to use, and the corresponding frame number.\nIt is possible to plot the annotation for all the frames in the video, by iterating all frame in a for loop,\nbut in the kernel, we are only allowed to plot single frames and thereby we have chosen to allow for choosing a specific frame instead."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Specify which video and frame to plot annotations for\nVideo_File = \"../input/brackish-dataset/dataset/videos/jellyfish/2019-03-20_15-15-12to2019-03-20_15-15-19_1.avi\"\nFrame_Num = 52\n\n# Get basename, since the annotation is sorted by the filename\nFilename = os.path.basename(Video_File).replace(\".avi\",\"\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Extracting relevant annotations for video\nOne method do reduce the complexity of sorting out which annotating is important for the given videofile, is to get pandas to sort out annotations where the column ***\"Filename\"*** contains the video's filename.\nThen a new array is created consisting of all the annotations for the given videofile. By doing so, we do not have to browse all the annotations when we change frame number, but only needs to browse the annotations for the given video.\nThis is indeed relavent, when you want to plot the annotations for all frame in the video."},{"metadata":{"trusted":true},"cell_type":"code","source":"### Extracting all annotations for the video file using Pandas\n\n# All annotations where the column filename contains the video filename.\nAnnoV = Valid[Valid[\"Filename\"].str.contains(Filename)]\nAnnoT = Test[Test[\"Filename\"].str.contains(Filename)]\nAnnoTr = Train[Train[\"Filename\"].str.contains(Filename)]\n\n# Append annotations from validation, training and test set into one single array named Anno.\nAnno = AnnoV\nAnno = Anno.append(AnnoT)\nAnno = Anno.append(AnnoTr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Extracting relevant annotations for frame\nAgain, here we use pandas to sort out the annotations, which contains the frame number in the ***\"Filename\"*** column."},{"metadata":{"trusted":true},"cell_type":"code","source":"### Script for extracting all annotations for the given frame using Pandas\n\nFrame_Anno = Anno[Anno[\"Filename\"].str.contains(\"%04d\" % Frame_Num)]  # \"%04d\" is for making 1 = 0001 to fit annotations.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Drawing bounding boxes and plotting frame\nIn this script we load the videofile, and iterate through the frames one by one, and store them in a list called ***Images***. The frames are resized to the (960, 540) pixel resolution in order to fit the resolution at which the annotations are made.\nAfterwards, we iterate through the array containing annotations for the given frame, drawing bounding boxes on the frame.\nLastly, we plot the frame with the annotations drawn."},{"metadata":{"trusted":true},"cell_type":"code","source":"### Script for loading video and drawing bounding boxes\ncap = cv2.VideoCapture(Video_File)\n\n# Create a empty list, in which all the images from the video will be stored \nImages = []\n\nwhile(True):\n    ret, frame = cap.read()\n    if ret == True:\n        # Resizing the image to fit the resolution of the annotations (960 x 540) pixels.\n        Images.append(cv2.resize(frame, (960, 540)))\n    else:\n        break\n\nfor idx, row in Frame_Anno.iterrows():\n    \n    # Extracting position of bounding boxes\n    UX, UY, LX, LY = row[\"Upper left corner X\"], row[\"Upper left corner Y\"], row[\"Lower right corner X\"], row[\"Lower right corner Y\"]\n    cv2.rectangle(Images[Frame_Num], (UX,UY), (LX, LY), (0, 255, 0), 5) # Drawing bounding boxes\n\n# Plot the annotated image\nplt.imshow(Images[Frame_Num])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Annotate all frames in a video\nThis script does annotate all the frames in a given video, by iterating through the annotation file called ***Anno***. In this example we just choose a random image (55) and plot this image, however, one could be interest in see the entire video. And this can be carried out by iterating the ***Images*** list in a loop."},{"metadata":{"trusted":true},"cell_type":"code","source":"### Script for annotating all frames in a video.\nfor idx, row in Anno.iterrows():\n    \n    # Extracting the frame number for the annotation.\n    # Kinda hardcode though, but it works.\n    framenum = int(row[\"Filename\"].replace(Filename + \"-\",\"\").replace(\".png\",\"\"))\n    \n    # Again extracting needed information about the bounding box.\n    UX, UY, LX, LY = row[\"Upper left corner X\"], row[\"Upper left corner Y\"], row[\"Lower right corner X\"], row[\"Lower right corner Y\"]\n    cv2.rectangle(Images[framenum], (UX,UY), (LX, LY), (0, 255, 0), 5) # Drawing bounding boxes\n\n# Plot the annotated frames, can be inserted into a for loop to show all images.\nplt.imshow(Images[55])\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Ending\nThis was all for now, more will come later on."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}