{"cells":[{"metadata":{},"cell_type":"markdown","source":"![](https://www.scubadiving.com/sites/scubadiving.com/files/styles/opengraph_1_91x1/public/images/2015/10/darth-vader.jpg?itok=fW9Tvc0i)\n([Image Source](https://www.google.com/search?q=Vader&client=safari&rls=en&sxsrf=ALeKk02vuMaylLazNndJ2sffmpnux3uErA:1612409404732&source=lnms&tbm=isch&sa=X&ved=2ahUKEwjBwLSOpc_uAhXvwzgGHX6oBOwQ_AUoAnoECAIQBA&biw=1920&bih=1000&dpr=1#imgrc=ni-aeMdeIhzgFM))"},{"metadata":{},"cell_type":"markdown","source":"# Introduction \n\nTwo popular libraries for peforming unsupervised Sentiment Classification are Vader and TextBlob.Both of these libraries are able to assign a numeric value to a sentence without having any labels to compare with. However, we need to decide on how to assign these numbers to categories such as Negative, Positive, Neutral etc. \n\nIn this notebook, we perform grid search to find the optimum split points for doing extactly this. \nOnce we find these optimal splits for both VADER and TextBlob, we compare the best accuracies of both. "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# imports \nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\nfrom sklearn.model_selection import train_test_split\n\nfrom tqdm.notebook import tqdm\nimport textblob\n\nimport pandas as pd \nimport numpy as np \nimport os ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# generate sentiment scores using VADER and TextBlob\nsia = SIA()\n\ndata = pd.read_csv(\"/kaggle/input/twitter-airline-sentiment/Tweets.csv\")\n\n# Balance the dataset by choosing 2363 from each class\n# This is becayse there are only 2363 samples in Positive.\n\ng = data.groupby('airline_sentiment')\ndata = g.apply(lambda x: x.sample(g.size().min()).reset_index(drop=True))\n\nvader = [sia.polarity_scores(x) for x in data['text']] \n\nblob_sentiments = [textblob.TextBlob(x).sentiment[0] for x in data['text']]\nvader_sentiments = [x['compound'] for x in vader]\ntargets = data['airline_sentiment'].replace({ \"negative\": -1, \"neutral\": 0, \"positive\": 1})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert float to labels based on threshold\ndef get_sign(x, p, n):\n    if x > p:\n        return 1\n    if x < n:\n        return -1 \n    return 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# gridsearch to get the best split points for positive,negative and neutral\ndef get_best_threshold(sentiments, targets):\n\n    neg_thresh =np.arange(-1,1, 0.05)\n    pos_thresh = np.arange(-1,1, 0.05)\n\n    best_params = []\n    best_acc = 0 \n    i = 0\n    total = len(pos_thresh) * len(neg_thresh)\n\n\n    for p in pos_thresh:\n        for n in neg_thresh:\n            i += 1 \n            print(f\"Processing: {i/total*100:.2f}%\", end=\"\\r\")\n\n            params = (p,n)\n            res = [get_sign(x, p, n) for x in sentiments]\n            acc = sum(res == targets)/len(targets)\n\n            if acc > best_acc:\n                best_acc= acc\n                best_params = params\n\n    \n    return best_acc, best_params","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train-test-split to check for overfitting\n(\n    vader_train, \n    vader_test,  \n    blob_train, \n    blob_test, \n    y_train, \n    y_test \n) = train_test_split(\n    vader_sentiments, \n    blob_sentiments, \n    targets, \n    stratify=targets,\n    test_size=0.1,\n    random_state=42\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Best split points and max accuracy for TextBlob\nbest_acc, best_params = get_best_threshold(blob_train, y_train)\nprint(\"\\nTextBlob Results: \")\nprint(\"\\nBest Accuracy: \", best_acc)\nprint(\"Best (pos, neg) threshold values: \", best_params)\n\npreds = [get_sign(x, *best_params) for x in blob_test]\nval_acc = sum(preds == y_test)/len(y_test)\nprint(\"\\nValid Accuracy for selected params: \", val_acc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Best split points and max accuracy for VADER\nbest_acc, best_params = get_best_threshold(vader_train, y_train)\n\nprint(\"\\nVADER Results: \")\nprint(\"\\nBest Accuracy: \", best_acc)\nprint(\"Best (pos, neg) threshold values: \", best_params)\n\npreds = [get_sign(x, *best_params) for x in vader_test]\nval_acc = sum(preds == y_test)/len(y_test)\nprint(\"\\nValid Accuracy for selected params: \", val_acc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusions:\n1. Vader significantly outperforms TextBlob for twitter sentiments \n2. Best accuracy when using Vader:  ~62%\n\nBest Thresholds for splitting Vader tweet [](http://)sentiments:\n* sentiment['compound'] < -0.05 => Negative\n* sentiment['compound'] > 0.35 => Positive\n* -0.05 <= sentiment['compound'] <= 0.35 => Neutral"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}