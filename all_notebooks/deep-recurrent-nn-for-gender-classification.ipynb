{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Task for Today  \n\n***\n\n## Twitter User Gender Prediction  \n\nGiven *data about users on Twitter*, let's try to predict the **gender** of a given user.  \n  \nWe will use a deep recurrent neural network with multiple inputs to make our predictions."},{"metadata":{},"cell_type":"markdown","source":"# Getting Started"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\n\nfrom sklearn.metrics import confusion_matrix, classification_report","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/twitter-user-gender-classification/gender-classifier-DFE-791531.csv', encoding='latin-1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isna().mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_sequences(texts, vocab_length):\n    tokenizer = Tokenizer(num_words=vocab_length)\n    tokenizer.fit_on_texts(texts)\n    \n    sequences = tokenizer.texts_to_sequences(texts)\n    \n    max_seq_length = np.max([len(sequence) for sequence in sequences])\n    \n    sequences = pad_sequences(sequences, maxlen=max_seq_length, padding='post')\n    \n    return sequences","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.int('ED', 16)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def hex_to_decimal(x):\n    try:\n        return np.int(x, 16)\n    except:\n        return 0\n\ndef get_rgb(colors):\n    r = colors.apply(lambda x: hex_to_decimal(x[0:2]))\n    g = colors.apply(lambda x: hex_to_decimal(x[2:4]))\n    b = colors.apply(lambda x: hex_to_decimal(x[4:6]))\n    return r, g, b","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_inputs(df):\n    df = df.copy()\n    \n    # Drop unnecessary columns\n    df = df.drop(['_unit_id', 'name', 'profileimage', 'tweet_id'], axis=1)\n    \n    # Encode unknown values in the target column as np.NaN\n    df['gender'] = df['gender'].replace('unknown', np.NaN)\n    \n    # Drop rows with missing target values\n    gender_nas = df[df['gender'].isna()].index\n    df = df.drop(gender_nas, axis=0).reset_index(drop=True)\n    \n    # Drop columns with over 30% missing values\n    missing_cols = df.columns[df.isna().mean() > 0.3]\n    df = df.drop(missing_cols, axis=1)\n    \n    # There are only 50 remaining missing values in the _last_judgment_at columns, so let's drop those rows\n    judgment_nas = df[df['_last_judgment_at'].isna()].index\n    df = df.drop(judgment_nas, axis=0).reset_index(drop=True)\n    \n    # Let's encode the missing values in the description column as empty strings\n    df['description'] = df['description'].fillna('')\n    \n    # Create date/time columns\n    for column in ['_last_judgment_at', 'created', 'tweet_created']:\n        df[column] = pd.to_datetime(df[column])\n    \n    df['judgment_day'] = df['_last_judgment_at'].apply(lambda x: x.day)\n    df['judgment_hour'] = df['_last_judgment_at'].apply(lambda x: x.hour)\n    \n    df['created_year'] = df['created'].apply(lambda x: x.year)\n    df['created_month'] = df['created'].apply(lambda x: x.month)\n    df['created_day'] = df['created'].apply(lambda x: x.day)\n    df['created_hour'] = df['created'].apply(lambda x: x.hour)\n    \n    df['tweet_hour'] = df['tweet_created'].apply(lambda x: x.hour)\n    \n    df = df.drop(['_last_judgment_at', 'created', 'tweet_created'], axis=1)\n    \n    # Get sequence data for description and text columns\n    desc = get_sequences(df['description'], vocab_length=20000)\n    tweets = get_sequences(df['text'], vocab_length=20000)\n    \n    df = df.drop(['description', 'text'], axis=1)\n    \n    # Drop columns with only one value\n    df = df.drop(['_golden', '_unit_state', '_trusted_judgments', 'profile_yn'], axis=1)\n    \n    # Encode color columns as RGB values\n    df['link_red'], df['link_green'], df['link_blue'] = get_rgb(df['link_color'])\n    df['side_red'], df['side_green'], df['side_blue'] = get_rgb(df['sidebar_color'])\n    \n    df = df.drop(['link_color', 'sidebar_color'], axis=1)\n    \n    # Encode label column\n    label_mapping = {'female': 0, 'male': 1, 'brand': 2}\n    df['gender'] = df['gender'].replace(label_mapping)\n    \n    # Split df into X and y\n    y = df['gender'].copy()\n    X = df.drop('gender', axis=1).copy()\n    \n    # Scale X with a standard scaler\n    scaler = StandardScaler()\n    X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n    \n    return X, desc, tweets, y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X, desc, tweets, y = preprocess_inputs(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"{column: len(X[column].unique()) for column in X.columns}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"desc.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train-Test Split"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, desc_train, desc_test, tweets_train, tweets_test, y_train, y_test = \\\n    train_test_split(X, desc, tweets, y, train_size=0.7, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modeling"},{"metadata":{"trusted":true},"cell_type":"code","source":"desc.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model():\n\n    X_inputs = tf.keras.Input(shape=(X.shape[1],))\n    desc_inputs = tf.keras.Input(shape=(desc.shape[1],))\n    tweet_inputs = tf.keras.Input(shape=(tweets.shape[1],))\n\n    # X\n    X_dense1 = tf.keras.layers.Dense(256, activation='relu')(X_inputs)\n    X_dense2 = tf.keras.layers.Dense(256, activation='relu')(X_dense1)\n\n    # desc\n    desc_embedding = tf.keras.layers.Embedding(\n        input_dim=20000,\n        output_dim=256,\n        input_length=desc.shape[1]\n    )(desc_inputs)\n    desc_gru = tf.keras.layers.GRU(256, return_sequences=False)(desc_embedding)\n    desc_flatten = tf.keras.layers.Flatten()(desc_embedding)\n    desc_concat = tf.keras.layers.concatenate([desc_gru, desc_flatten])\n\n    # tweets\n    tweet_embedding = tf.keras.layers.Embedding(\n        input_dim=20000,\n        output_dim=256,\n        input_length=tweets.shape[1]\n    )(tweet_inputs)\n    tweet_gru = tf.keras.layers.GRU(256, return_sequences=False)(tweet_embedding)\n    tweet_flatten = tf.keras.layers.Flatten()(tweet_embedding)\n    tweet_concat = tf.keras.layers.concatenate([tweet_gru, tweet_flatten])\n\n    concat = tf.keras.layers.concatenate([X_dense2, desc_concat, tweet_concat])\n\n    outputs = tf.keras.layers.Dense(3, activation='softmax')(concat)\n\n\n    model = tf.keras.Model(inputs=[X_inputs, desc_inputs, tweet_inputs], outputs=outputs)\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = build_model()\n\nprint(model.summary())\ntf.keras.utils.plot_model(model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(\n    optimizer='adam',\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nbatch_size = 32\nepochs = 3\n\nhistory = model.fit(\n    [X_train, desc_train, tweets_train],\n    y_train,\n    validation_split=0.2,\n    batch_size=batch_size,\n    epochs=epochs,\n    callbacks=[\n        tf.keras.callbacks.ModelCheckpoint('./model.h5', save_best_only=True, save_weights_only=True),\n        tf.keras.callbacks.ReduceLROnPlateau()\n    ]\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_weights('./model.h5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Results"},{"metadata":{"trusted":true},"cell_type":"code","source":"results = model.evaluate([X_test, desc_test, tweets_test], y_test, verbose=0)\nprint(\"Model Accuracy: {:.2f}%\".format(results[1] * 100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_true = np.array(y_test)\n\ny_pred = model.predict([X_test, desc_test, tweets_test])\ny_pred = map(lambda x: np.argmax(x), y_pred)\ny_pred = np.array(list(y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(y_true, y_pred)\nclr = classification_report(y_true, y_pred, target_names=['Female', 'Male', 'Brand'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(6, 6))\nsns.heatmap(cm, annot=True, fmt='g', cbar=False, cmap='Blues')\nplt.xticks(np.arange(3) + 0.5, ['Female', 'Male', 'Brand'])\nplt.yticks(np.arange(3) + 0.5, ['Female', 'Male', 'Brand'])\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.title(\"Confusion Matrix\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Classification Report:\\n\\n\", clr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps://youtu.be/0Jb0ywwLQgI"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}