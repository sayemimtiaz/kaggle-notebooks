{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"### Questions to Answer:\n1. What is the best time so sell?\n\n2. What are the popular items?\n\n3. What items are usually bought together? (Association Mining Rule) \n\n4. What is the trend?"},{"metadata":{},"cell_type":"markdown","source":"# Data Auditing"},{"metadata":{"trusted":true},"cell_type":"code","source":"#pip install apriori\n#pip install mlxtend\n#pip install seaborn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom mlxtend.frequent_patterns import apriori, association_rules","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#to check the directory of the file\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# read csv \ndf = pd.read_csv('/kaggle/input/the-bread-basket/bread basket.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# first look\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check for null values\nprint(df.shape)\nprint('----------------------------')\nprint('There are no NULL values:')\nprint(df.isna().sum())\nprint('----------------------------')\nprint(df.info())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# look at figures from categorical data\ndf.describe(include = ['O'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Item.unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preparing data for analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Quantity'] = 1 #assign quantity bought for each row\ndf1 = df.copy() # create a copy of original data\ndf1 = df.groupby(['Transaction','Item','date_time','period_day','weekday_weekend']).sum()\n\n#pivot Items to columns to run Apriori Algorithm later. The new dataframe has 98 columns now.\ndf1 = df1.pivot_table('Quantity',['Transaction','date_time','period_day','weekday_weekend'],'Item').reset_index().rename_axis(None, axis=1).fillna(0)\ndf1.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# looks like customers will only buy maximum 3 items at once\nbought = df1['date_time'].value_counts()\nbought = pd.DataFrame(bought).reset_index().rename(columns = {'index': 'datetime', 'date_time':'number'})\n\n# items bought in 1 transaction\n# it looks like only less than 4% of people will buy more than 1 item\nprint(\"3 items:\", round(len(bought[bought['number'] == 3])/len(bought['number'])*100,2),'%',sep='')\nprint(\"2 items:\", round(len(bought[bought['number'] == 2])/len(bought['number'])*100,2),'%',sep='')\nprint(\"1 items:\", round(len(bought[bought['number'] == 1])/len(bought['number'])*100,2),'%',sep='')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# split the date_time into Date, Time, Month, Year and Date for easier analysis later\ndf1['date_time'] = pd.to_datetime(df['date_time'])\ndf1['Date'] = df1['date_time'].dt.strftime('%d-%m-%Y')\ndf1['Time'] = df1['date_time'].dt.strftime('%H:%M:%S')\ndf1['Month'] = df1['date_time'].dt.strftime('%b')\ndf1['Year'] = df1['date_time'].dt.strftime('%Y')\ndf1['Day'] = df1['date_time'].dt.strftime('%a')\n\n# drop date_time column as we don't need it anymore\n#df1 = df1.drop(columns='date_time') \n\n# move the date time columns to the front so that it is easier to visualise\ncol = df1.pop('Date')\ndf1.insert(1, col.name, col)\ncol = df1.pop('Time')\ndf1.insert(2, col.name, col)\ncol = df1.pop('Day')\ndf1.insert(3, col.name, col)\ncol = df1.pop('Month')\ndf1.insert(4, col.name, col)\ncol = df1.pop('Year')\ndf1.insert(5, col.name, col)\ndf1.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## The number of transactions by day: Friday, Saturday and Monday are the busiest."},{"metadata":{"trusted":true},"cell_type":"code","source":"df1['Day'] = pd.Categorical(df1['Day'], categories= ['Mon','Tue','Wed','Thu','Fri','Sat', 'Sun'], ordered=True)\nday = df1['Day'].value_counts()\nday = day.sort_index().reset_index().rename(columns={'index':'Day','Day':'Transactions'})\nax = sns.barplot(x=\"Day\", y=\"Transactions\", data=day)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## The number of transactions by month: November and December are the busiest."},{"metadata":{"trusted":true},"cell_type":"code","source":"df1['Month'] = pd.Categorical(df1['Month'], categories= ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'], ordered=True)\nmonth = df1['Month'].value_counts()\nmonth = month.sort_index().reset_index().rename(columns={'index':'Month','Month':'Transactions'})\nax = sns.barplot(x=\"Month\", y=\"Transactions\", data=month)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## The number of transactions by period of day: Morning and Afternoon are the busiest."},{"metadata":{"trusted":true},"cell_type":"code","source":"df1['period_day'] = pd.Categorical(df1['period_day'], categories= ['morning','afternoon','evening','night'], ordered=True)\nperiod_day = df1['period_day'].value_counts()\nperiod_day = period_day.sort_index().reset_index().rename(columns={'index':'period_day','period_day':'Transactions'})\nax = sns.barplot(x=\"period_day\", y=\"Transactions\", data=period_day)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## The number of transactions by year: Sales in 2017 seems to have plunged compared to 2016."},{"metadata":{"trusted":true},"cell_type":"code","source":"year = pd.DataFrame(df1.Year.value_counts())\nyear = year.reset_index().rename(columns={'index':'Year','Year':'Transactions'})\nax = sns.barplot(x=\"Year\", y=\"Transactions\", data=year)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## % change compared to previous year:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# select data by year to for a new dataframe\ndf_2016 = df1[df1['Year'] == '2016']\ndf_2017 = df1[df1['Year'] == '2017']\n\n# extract number of transactions by month\nmonthly_sales_2016 = pd.DataFrame(df_2016['Month'].value_counts().reset_index().rename(columns = {'index': 'Month', 'Month':'2016'}))\nmonthly_sales_2017 = pd.DataFrame(df_2017['Month'].value_counts()).reset_index().rename(columns = {'index': 'Month', 'Month':'2017'})\n\n# merge sales data for both years\nmonthly_sales = pd.merge(monthly_sales_2016,monthly_sales_2017)\n\n# sort by month\nmonthly_sales['Month'] = pd.Categorical(monthly_sales['Month'], categories= ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'], ordered=True)\nmonthly_sales.sort_values(inplace=True, by='Month')\nmonthly_sales = monthly_sales.reset_index().drop('index', axis=1)\n\n# % change compared to previous year\nprint('% change compared to previous year:')\nmonthly_sales['% Change'] = round(((monthly_sales['2017']-monthly_sales['2016'])/monthly_sales['2016']*100),2).astype(str) + '%'\nmonthly_sales","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Compare month-by-month for 2016 & 2017"},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot grouped bar plot to compare month-by-month for 2016 & 2017\nlabels = monthly_sales['Month']\nsales_2016 = monthly_sales['2016']\nsales_2017 = monthly_sales['2017']\n\nx = np.arange(len(monthly_sales['Month']))  # the label locations\nwidth = 0.35  # the width of the bars\n\nfig, ax = plt.subplots()\nrects1 = ax.bar(x - width/2, sales_2016, width, label='2016')\nrects2 = ax.bar(x + width/2, sales_2017, width, label='2017')\n\n# Add some text for labels, title and custom x-axis tick labels, etc.\nax.set_ylabel('No. of Transactions')\nax.set_title('No. of Transactions by Month')\nax.set_xticks(x)\nax.set_xticklabels(labels)\nax.legend()\n\nfig.tight_layout()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## What are the popular items?"},{"metadata":{"trusted":true},"cell_type":"code","source":"total_transactions = len(df1)\nsupport = 0.02\nmin_items = total_transactions*support\n\nitemset_1 = pd.DataFrame(df.Item.value_counts()).reset_index().rename(columns = {'index':'Item','Item':'Count'})\nitemset_1 = itemset_1[itemset_1['Count'] >= min_items]\nitemset_1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualise popular items on a barplot"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initialize the matplotlib figure\n#f, ax = plt.subplots(figsize=(6, 15))\n\n# Plot the total crashes\nsns.set_color_codes(\"pastel\")\nt = sns.barplot(x=\"Item\", y=\"Count\", data=itemset_1,\n            label=\"Item\", color=\"b\")\n\n# Add a legend and informative axis label\nax.legend(ncol=2, loc=\"lower right\", frameon=True)\n#ax.set(xlim=(0, 24), ylabel=\"\", xlabel=\"Popular Items Sold\")\nsns.despine(left=True, bottom=True)\nt.set_xticklabels(itemset_1['Item'],rotation=90)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Frequent Pattern Mining via Apriori Algorithm"},{"metadata":{},"cell_type":"markdown","source":"### Although there is only a small amount of customers that would buy more than 1 item. However, it is still worthwhile to find any Associations on multiple items bought to upsell. Another benefit is to possibly create a 'deal' say, Coffee + Scone at a cheaper price. This will encourage customers to buy multiple items instead of just 1 item only.\n\n#### Apriori Algorithm reference: https://www.geeksforgeeks.org/implementing-apriori-algorithm-in-python/"},{"metadata":{"trusted":true},"cell_type":"code","source":"def hot_encode(x): \n    if(x<= 0): \n        return 0\n    if(x>= 1): \n        return 1\n\nbasket = df1.iloc[:,9:]\nbasket_encoded = basket.applymap(hot_encode)\nbasket_encoded.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Building the model \nfrequent_items = apriori(basket_encoded, min_support = 0.01, use_colnames = True) \n  \n# Collecting the inferred rules in a dataframe \nrules = association_rules(frequent_items, metric =\"lift\", min_threshold = 1) \nrules = rules.sort_values(['confidence', 'lift'], ascending =[True, True]) \nprint(pd.DataFrame(rules))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rules = association_rules(frequent_items, metric = \"lift\", min_threshold = 1)\nrules.sort_values('confidence', ascending = False, inplace = True)\nrules","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Drawing from the fact that only about 3% of customers buy more than 1 item, the association between items purchased are not expected to be high as shown in the lift, support and confidence figures. However, they are still worth noting for every opportunity to upsell to increase revenue. "},{"metadata":{},"cell_type":"markdown","source":"## Visualisation on number of transactions over time"},{"metadata":{"trusted":true},"cell_type":"code","source":"# prepare data for 2016\n# sorting Month\nmonthly_sales_2016['Month'] = pd.Categorical(monthly_sales_2016['Month'], categories= ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'], ordered=True)\nmonthly_sales_2016 = monthly_sales_2016.rename(columns={'2016':'Transactions'})\nmonthly_sales_2016.sort_values(inplace=True, by='Month')\nmonthly_sales_2016['Month'] = monthly_sales_2016['Month'].astype(str) + '_2016'\n\n# prepare data for 2017\n# sorting Month\nmonthly_sales_2017['Month'] = pd.Categorical(monthly_sales_2017['Month'], categories= ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'], ordered=True)\nmonthly_sales_2017 = monthly_sales_2017.rename(columns={'2017':'Transactions'})\nmonthly_sales_2017.sort_values(inplace=True, by='Month')\nmonthly_sales_2017['Month'] = monthly_sales_2017['Month'].astype(str) + '_2017'\n\n# merge both datasets\nmerged = monthly_sales_2016.append([monthly_sales_2017])\nmerged = merged.reset_index().drop(['index'], axis=1)\nmerged","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot bargraph\nsns.set_style(style=\"whitegrid\")\ns = sns.barplot(x='Month',y='Transactions', data=merged)\ns.set_xticklabels(merged['Month'],rotation=90)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### In 2016, business seemed to be pretty good and peaked at the end of the year. However, starting Feb 2017, number of transactions plunged to zero. There were some transactions in the subsequent months but never recovered to the level in 2016."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}