{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# What is about \n\nStudy degree distribution of KNN graphs for model data clouds - Gauss, uniform, sphere.\nFor high dimensions it seems to be  power law like. We also see drastical difference between sphere-torus vs Gauss-Uniform.\nSee discussion in : \nhttps://cstheory.stackexchange.com/questions/47957/power-law-for-degree-distribution-of-random-knn-graphs\nsee also https://stats.stackexchange.com/questions/500250/recognize-distribution-on-integers-0-mean-5-median-2-percentiles-75-5\n\nV20 - same as 18,19 - but simulate Gauss, Uniform, Sphere, Torus \n\nV19 - same as 18, but trials increase to 100, and dim 1000 repeated twice with n_sample 1e4,1e5,\n\nV18 - high dims explore: dim 100,1000,10000, K =5 n_sample = 1e4, Gauss \n\nV17 uniform , dim = 50, K = 10 \n\nV16 same with , dim = 10, K = 20  strange thing  - mean sometimes not K for big sample size - is not a bug in cuml ? \nfor dim 10 we see mean equals to median , while for dim 50 we saw mean was = percentile 75 \n\nV15 same with , dim = 10, K = 10\n\nV14 same with , dim = 10, K = 5\n\nV13: K = 20\n\nV12: repeat V11 for K = 10\n\nV11 - study distribution in details for particular case - K=5, dim = 50 , change n_samples, look at percentiles, power law etc..  Findings summarized here: https://stats.stackexchange.com/questions/500250/recognize-distribution-on-integers-0-mean-5-median-2-percentiles-75-5\n\nV10 - same as V9 - increase samples to 10_000_000 - crashed by memory after processing first case \n\nV9 - same as V8 - increase samples to 1_000_000 - 150 seconds \n\nV8 - simulations for Sphere and Torus added. See drastical difference for sphere-torus VS Gauss-uniform. 100_000 samples - 7 seconds \n\n\nV7 - same as V6 , but n_sample = 1e6 - run out of time 9 hours\n\n\nV6 - linear interplotation of loglog plot - estimate exponent of power law of the distibution \n\nV5 - same as V4 but compare GPU and sklearn implementations - should coincide - indeed coincide \n\n\nV4 - pdf of degrees K=5, various dimensions , n_sample = 1e4\n\nV3: plot pdf for :\n\nGauss dim50 n_neighbors3 n_sample100000 2276.7 2276.7 seconds passed trial, total\n\nGauss dim50 n_neighbors10 n_sample100000 2294.3 4571.1 seconds passed trial, total\n\nV2: plot pdf for :\n\nGauss dim10 n_neighbors5 n_sample100000 73.2 73.2 seconds passed trial, total\n\nGauss dim50 n_neighbors5 n_sample100000 2313.5 2386.7 seconds passed trial, total\n\nV1 - fast calculation:\n\nGauss dim10 n_neighbors5 n_sample10000 1.5 1.5 seconds passed trial, total\n\nGauss dim50 n_neighbors5 n_sample10000 11.9 13.4 seconds passed trial, total\n","metadata":{}},{"cell_type":"markdown","source":"dim10 n_neighbors5 n_sample1000 0.1 0.1 seconds passed trial, total\n\ndim10 n_neighbors5 n_sample10000 1.5 1.6 seconds passed trial, total\n\ndim10 n_neighbors5 n_sample100000 66.1 67.7 seconds passed trial, total","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport plotly.graph_objs as go\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-01T09:43:27.293229Z","iopub.execute_input":"2021-07-01T09:43:27.293547Z","iopub.status.idle":"2021-07-01T09:43:27.323067Z","shell.execute_reply.started":"2021-07-01T09:43:27.293519Z","shell.execute_reply":"2021-07-01T09:43:27.322134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.neighbors import kneighbors_graph\nimport time\nimport matplotlib.pyplot as plt\nimport plotly\n_t00 = time.time()\n\n","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2021-07-01T07:19:50.691963Z","iopub.execute_input":"2021-07-01T07:19:50.692304Z","iopub.status.idle":"2021-07-01T07:19:50.699913Z","shell.execute_reply.started":"2021-07-01T07:19:50.692272Z","shell.execute_reply":"2021-07-01T07:19:50.698955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom scipy.stats import rv_continuous\nimport scipy.integrate as integrate\nimport scipy.special as special\n\n\nclass CustomDistribution(rv_continuous):\n    def __init__(self, momtype = 'pdf', a=0, b=1):\n        super().__init__(a=a, b=b)\n    \n    def _get_support(*args, **kwargs):\n        return 0, 1\n    \n    def _pdf(self, x):\n        if x < 0 or x > 1:\n             return 0\n            \n        integral = integrate.quad(lambda t: np.sinh(t), 0, 1)[0]\n        res = (np.sinh(x)) / integral\n        return res\n\n\nn_sample = 10000\nt0 = CustomDistribution().rvs(size=n_sample)\nt1 = np.random.rand(n_sample) * 2 * np.pi\nX0 = np.cosh(t0)\nX1 = np.sinh(t0) * np.cos(t1)\nX2 = np.sinh(t0) * np.sin(t1)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-01T10:33:20.249542Z","iopub.execute_input":"2021-07-01T10:33:20.24987Z","iopub.status.idle":"2021-07-01T10:34:44.513564Z","shell.execute_reply.started":"2021-07-01T10:33:20.249838Z","shell.execute_reply":"2021-07-01T10:34:44.5128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nx = X0\ny = X1\nz = X2\ntrace = go.Scatter3d(\n   x = x, y = y, z = z,mode = 'markers', marker = dict(\n      size = 6,\n      color = z, # set color to an array/list of desired values\n      colorscale = 'Viridis'\n      )\n   )\nlayout = go.Layout(title = '3D Scatter plot')\nfig = go.Figure(data = [trace], layout = layout)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-01T10:35:27.789063Z","iopub.execute_input":"2021-07-01T10:35:27.789381Z","iopub.status.idle":"2021-07-01T10:35:27.898912Z","shell.execute_reply.started":"2021-07-01T10:35:27.789352Z","shell.execute_reply":"2021-07-01T10:35:27.897962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"V_1/V_2 = {np.sinh(1/4) ** 2 / np.sinh(1/2) ** 2}\")\nprint(f\"N_1/N_2 = {X0[X0 < np.cosh(1/2)].size / X0.size}\")","metadata":{"execution":{"iopub.status.busy":"2021-07-01T10:34:52.645738Z","iopub.execute_input":"2021-07-01T10:34:52.646079Z","iopub.status.idle":"2021-07-01T10:34:52.651623Z","shell.execute_reply.started":"2021-07-01T10:34:52.646047Z","shell.execute_reply":"2021-07-01T10:34:52.650596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    import cudf\n    from cuml.neighbors import NearestNeighbors\n    #from cuml.datasets import make_blobs    \nexcept:\n    print('GPU library cannot be imported. Turn ON GPU')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#distribution_type = 'Gauss' # 'uniform'\nverbose = 0\n\n\nplt.style.use('ggplot')\n\nfig = plt.figure(figsize=(20,12))\n\n#ax2 =     fig.add_subplot(2,1,2)\n\nt00=time.time()\n\ndf_stat = pd.DataFrame()\ndf_stat2 = pd.DataFrame()\n\nlist_save_results = []\nn_sample0 = 1e4\ni = 0\n#for dim , n_neighbors, n_sample  in [(2,5,1e4), (5,5,1e4),   (8,5,1e4),   (10,5,1e4), (50,5,1e4), (500,5,1e4)]: #  , (100,10,1e4)  , (10,5,1e4) , (10,5,1e5) ]:  \nfor distribution_type in ['Gauss', 'Uniform', 'Sphere', 'Torus' ]: #  ['Gauss']: # \n    i += 1\n    #ax1 =     \n    #fig.add_subplot(2,1,i)\n    fig = plt.figure(figsize=(20,8))\n    configs = [(x, 5, n_sample0) for x in [100, 1000, 10000]]\n    \n#     for dim , n_neighbors, n_sample  in [(100,5,n_sample0), (1000,5,n_sample0), (1000,5,10*n_sample0),  (10000,5,n_sample0),  ]: # , (50,10,10*n_sample0) , (50,10,100*n_sample0) ]: # ,(500,5,n_sample0),]:# [(2,5,n_sample0),     (10,5,n_sample0), (50,5,n_sample0),(500,5,n_sample0)]: \n#                                           #  , (5,5,n_sample0) , (100,10,1e4)  , (10,5,1e4) , (10,5,1e5) ]:  \n    \n    for dim , n_neighbors, n_sample  in configs:\n        n_sample = int(n_sample)\n        df_stat_over_trials = pd.DataFrame()\n        \n        for trial in range(100):    \n            if distribution_type == 'Gauss':\n                X = np.random.randn(n_sample,dim)\n                if verbose >= 100:\n                    print('Gauss')\n            elif distribution_type == 'Sphere':\n                X = np.random.randn(n_sample,dim+1)\n                s = np.sqrt( (X*X).sum(axis=1))\n                X = X / s[:,np.newaxis]\n                if verbose >= 100:\n                    print('Sphere')\n            elif distribution_type == 'Torus':\n                X = ( np.random.rand(n_sample,dim) )\n                X1 = np.sin(2*np.pi*X)\n                X2 = np.cos(2*np.pi*X)\n                X = np.concatenate((X1,X2),axis=1)\n                if verbose >= 100:\n                    print('Torus')\n            elif distribution_type == 'Parabolic':\n                t0 = np.random.rand(n_sample)\n                t1 = np.random.rand(n_sample) * 2 * np.pi\n                X0 = np.cosh(t0)\n                X1 = np.sinh(t0) * np.cos(t1)\n                X2 = np.sinh(t0) * np.sin(t1)\n                if verbose >= 100:\n                    print('Parabolic')\n            else:\n                X = np.random.uniform(-1,1, size = (n_sample,dim) )\n                if verbose >= 100:\n                    print('Uniform')    \n\n            for method in ['GPU']: # 'sklearn',  'GPU'\n\n                t0=time.time()\n\n                if method in ['GPU']:\n                    X_cudf = cudf.DataFrame(X)\n                    model = NearestNeighbors(n_neighbors=n_neighbors+1)\n                    model.fit(X)\n                    # get 3 nearest neighbors\n                    m = model.kneighbors_graph(X_cudf)#, include_self=False) #  no include_self\n                    vec_degs = np.sum(m,axis = 0 )\n                    vec_degs = vec_degs.get()\n\n                    vec_degs = np.squeeze(np.array(vec_degs.ravel()))\n                    vec_degs -= np.ones_like(vec_degs ) # no include_self - so that is a way round\n\n                else: #if method in ['sklearn']:\n                    m = kneighbors_graph(X, n_neighbors=n_neighbors, mode='connectivity' , include_self=False) #'distance' mode=  'connectivity'\n                    vec_degs = np.sum(m,axis = 0 )\n                    vec_degs = np.squeeze(np.array(vec_degs.ravel()))\n\n                #print(m.toarray())\n\n                bins = np.arange(200)# np.max(vec_degs))\n                h = np.histogram(vec_degs,bins = bins, density= True)\n\n                #label = method +' '+ distribution_type + ' dim'+str(dim) +' n_neighbors'+str(n_neighbors) + ' n_sample'+str(n_sample)\n                label = distribution_type + ' dim'+str(dim) +' n_neighbors'+str(n_neighbors) + ' n_sample'+str(n_sample)\n\n                list_save_results.append( (label, h) )\n\n                #plt.plot(h[0],'*-',label = label)\n                #plt.loglog(h[0],'*-',label = label)\n                #plt.legend(fontsize = 13)\n                #plt.xlabel('Degree')\n                #plt.ylabel('Probability')\n\n                degs = bins[:-1]\n                probs = h[0]\n                # Cut suitable subset to make linear interpolation (i.e. avoid noisy part) and take logs:   \n                m = (degs > 2*n_neighbors ) # & (degs < 90)\n                y = (probs[m])\n                x = (degs[m])\n                for t in range(len(y) ):\n                    if y[t] == 0:\n                        break\n                t = t-1\n                y = y[:t]\n                x = x[:t]\n                y = np.log10(y)\n                x = np.log10(x)\n\n                coefs_polyfit = np.polyfit(x, y, 1)\n                x2 =  np.log10(degs[degs > 0])\n                vec_line_intepolation_result = np.poly1d(coefs_polyfit)(x2)\n                if verbose >= 100:\n                    print(label, 'coefficients of line interpolation: ', coefs_polyfit )\n                m = h[0] > 1e-12\n                if trial <= 1:\n                    #plt.loglog(h[1][:-1][m], h[0][m],'*-', label = label, linewidth=4)\n                    plt.loglog( h[0][m],'*-', label = label, linewidth=4)\n                    plt.loglog(np.power(10,x2), np.power(10, vec_line_intepolation_result ), label = 'linear approx' )#  ,  label = label+' Approx', linewidth=4)\n                    plt.title('LogLog plot')\n                    plt.xlabel('degree')\n                    #plt.ylabel('Node count')\n                    plt.legend( fontsize = 12 )\n                    #plt.show()\n\n                    #ax1.grid()\n\n                    #ax2.loglog(h[0],'*-',label = label)\n                    #ax2.legend()\n                    #ax2.grid()\n\n                st = pd.Series(vec_degs).describe( percentiles = [0.05,0.1, .25, .5, .75, 0.9,0.95,0.99 ])\n                st.name = label + ' trial' + str(trial)\n                st['Linear slope'] = coefs_polyfit[0]\n                st['Linear constant'] = coefs_polyfit[1]\n                st['Seconds passed'] = np.round( time.time()-t0, 2)\n                df_stat = df_stat.join( st, how = 'outer'  )\n                df_stat_over_trials = df_stat_over_trials.join( st, how = 'outer'  )\n                \n                if verbose >= 100:\n                    print(label,  np.round(time.time()-t0,1),  np.round(time.time()-t00,1),'seconds passed trial, total')\n                \n        label = distribution_type + ' dim'+str(dim) +' n_neighbors'+str(n_neighbors) + ' n_sample'+str(n_sample)\n        st = df_stat_over_trials.mean(axis = 1)\n        st.name = label \n        df_stat2 = df_stat2.join( st, how = 'outer'  ) \n        st = df_stat_over_trials.std(axis = 1)\n        st.name = label + ' std' \n        df_stat2 = df_stat2.join( st, how = 'outer'  ) \n\nplt.show()\n    \nseconds_passed_total = time.time()-t00\nprint( np.round(seconds_passed_total,1),  np.round(seconds_passed_total/60,1), np.round(seconds_passed_total/3600,1), \n      'seconds, minutes, hours passed')\n\n#print(df_stat)\ndf_stat2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print( np.round(seconds_passed_total,1),  np.round(seconds_passed_total/60,1), np.round(seconds_passed_total/3600,1), \n      'seconds, minutes, hours passed')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_stat2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_stat","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_stat2.to_csv('df_stat2.csv')\ndf_stat.to_csv('df_stat.csv')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 0:\n    fig = plt.figure(figsize=(20,12))\n\n    for label,h in list_save_results:\n        plt.plot(h[0][h[0]>0],'*-', label = label)\n\n    plt.legend()\n    #plt.grid()\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 0:\n    fig = plt.figure(figsize=(20,12))\n\n    for label,h in list_save_results:\n        plt.loglog(h[0][h[0]>1e-12],'*-', label = label)\n\n    plt.legend()\n    #plt.grid()\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(np.round(time.time()- _t00,1), np.round( (time.time()-_t00)/60,1),  np.round( (time.time()-_t00)/3600,1), 'seconds minutes hours total passed')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}