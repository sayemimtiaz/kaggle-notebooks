{"cells":[{"metadata":{},"cell_type":"markdown","source":"#### If you Like My Work **Please UpVote**"},{"metadata":{},"cell_type":"markdown","source":"Heart Disease UCI dataset is been created from the Cleveland database with the subset of 14 attributes. \n\nIn this kernel I am going to visualize few variables **with respect to the target data** and predict the target variable using different classification algorithms.\n"},{"metadata":{},"cell_type":"markdown","source":"This dataset is a classification type datset with two classifications 0 or 1. \nThe target variable is angiographic disease status => \nValue 0: < 50% diameter narrowing  \nValue 1: > 50% diameter narrowing in any major vessel.  \n\nLets import the dataset and analyse the data"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from warnings import simplefilter\n# ignore all future warnings\nsimplefilter(action='ignore', category=FutureWarning)\n\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\n\n\nimport os\nprint(os.listdir(\"../input\"))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"heart_dataset = pd.read_csv('../input/heart.csv')\nheart_dataset.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Description of the Columns in the dataset\n1. Age - Age of the person in Years\n\n1. Sex - Gender of the person (1-> male, 0 -> female)\n\n1. CP - Chest pain type (1 = typical angina, 2 = atypical angina, 3 = non-anginal pain, 4 = asymptomatic)\n\n1. trestbps - Resting Blood Pressure in mm Hg on admission to the hospital\n\n1. chol - Serum Cholestrol in mg/dl \n\n1. fbs - Fasting Blood Sugar > 120 mg/dl (1 = true \"> 120 mg/dl”, 0 = false \"< 120 mg/dl\")\n\n1. restecg - Resting electrocardiographic results (0 = normal, 1 = having ST-T wave abnormality \"T wave inversions and/or ST elevation or depression of > 0.05 mV”, 2 = showing probable or definite left ventricular hypertrophy by Estes' criteria)\n\n1. thalach - maximum heart rate achieved\n\n1. exang - exercise induced angina (1 = yes, 0 = no)\n\n1. oldpeak - ST depression induced by exercise relative to rest\n\n1. slope - the slope of the peak exercise ST segment (1 = up sloping, 2 = flat, 3 = down sloping)\n\n1. ca - number of major vessels colored by flourosopy (0-3)\n\n1. thal - (1 = normal, 2 = fixed defect, 3 = reversable defect)\n\n1. target - diagnosis of heart disease (angiographic disease status 0 = < 50% diameter narrowing,              1 = > 50% diameter narrowing in any major vessel attributes)  \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"heart_dataset.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"from the count we can see that there are no missing data. Lets analyse variables like Age, Gender, ChestPain type and Thal with respect to the target varaible."},{"metadata":{},"cell_type":"markdown","source":"Lets split the dataset into two parts for analysis purpose. data with target = 1 and target = 0"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_with_disease = heart_dataset[heart_dataset['target'] == 1]\ndata_without_disease = heart_dataset[heart_dataset['target'] == 0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 1: relation between age and target variable\nwhich age group had suffered from heart disease"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_with_disease['age'] = ((data_with_disease['age']-(data_with_disease['age']%10))/10)\ndata_without_disease['age'] = ((data_without_disease['age']-(data_without_disease['age']%10))/10) \n\nN=8\nind =np.arange(N)\n\ndisease_data = [0]*8\nno_disease_data = [0]*8\n\nfor i in range(0,len(data_with_disease)):\n    disease_data[int(data_with_disease['age'][i])] += 1\nfor i in range(165,165+len(data_without_disease)):\n    no_disease_data[int(data_without_disease['age'][i])] += 1 \n\nplt.figure(figsize = (6,6))\np1 = plt.bar(ind,no_disease_data)\np2 = plt.bar(ind,disease_data,bottom = no_disease_data)\nplt.xticks(ind, ('0-10','10-20','20-30','30-40','40-50','50-60','60-70','70-80'))\nplt.yticks(np.arange(0,150,10))\nplt.xlabel('age_groups')\nplt.ylabel('count of people')\nplt.legend((p1[0], p2[0]), ('not_suffered', 'Suffered'))\nplt.title('age group wise data comparision between  suffered and un-suffered people in dataset')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"it is significant that most of suffered people are between 40 to 70.\n\nFrom suffered people which age group is highest"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (9,9))\nlables = ['0-10','10-20','20-30','30-40','40-50','50-60','60-70','70-80']\nsizes = disease_data\nexplode = [0, 0, 0, 0, 0, 0, 0, 0]\nplt.pie(sizes, labels = lables, explode = explode, shadow = True, startangle=90, autopct='%1.1f%%')\nplt.legend()\nplt.title('percent of different age groups who are suffered in dataset')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"from the pie chart we can see that people who have angiographic disease status =1 are most from the age group 50-60. Large percent are between age 40-70.  "},{"metadata":{},"cell_type":"markdown","source":"#### 2: relation between gender and target variable\nwhat is the count of people in dataset who have the status = 1 and who have status = 0 from the gender perspective."},{"metadata":{"trusted":true},"cell_type":"code","source":"suffered_data = [0]*2\nun_suffered_data = [0]*2  \nfor i in range(0,len(data_with_disease)):\n    suffered_data[int(data_with_disease['sex'][i])] += 1\n    \nfor i in range(165,165+len(data_without_disease)):\n    un_suffered_data[int(data_without_disease['sex'][i])] += 1 \n\nN=2\nind=np.arange(N)\n\np1 = plt.bar(ind,suffered_data)\np2 = plt.bar(ind,un_suffered_data,bottom = suffered_data)\nplt.xticks(ind, ('female','male'))\nplt.yticks(np.arange(0,210,20))\nplt.xlabel('gender')\nplt.ylabel('count of people')\nplt.legend((p1[0], p2[0]), ('suffered', 'not-suffered'))\nplt.title('gender wise data comparision in dataset')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 3: relation between Chestpaintype, Gender and target-\n\n spread of chest pain types and relation with Gender"},{"metadata":{"trusted":true},"cell_type":"code","source":"chest_pains_count=[0]*4\nchest_pains_count_suffered=[0]*4\nchest_pains_count_unsuffered=[0]*4\nchest_pains_with_gender = [0]*8\ntypes = ['typical angina', 'atypical angina', 'non-anginal pain', 'asymptomatic']\ngender_with_types = ['female','male','female','male','female','male','female','male']\n\n#make data\nfor i in range(0,len(heart_dataset)):\n    chest_pains_count[heart_dataset['cp'][i]]+= 1\n    if(heart_dataset['sex'][i] == 0):\n        chest_pains_with_gender[heart_dataset['cp'][i]*2]+=1\n    else:\n        chest_pains_with_gender[(heart_dataset['cp'][i]*2)+1]+=1\n#choose colors\na, b, c ,d = [plt.cm.Blues, plt.cm.Reds, plt.cm.Greens, plt.cm.Oranges]\n\n#outer ring\n\nfig, ax = plt.subplots()\nax.axis('equal')\nout_pie, _ =ax.pie(chest_pains_count, radius =2, labels =types, colors = [a(0.8), b(0.8), c(0.8), d(0.8)])\nplt.setp(out_pie, width= 1.2)\n\n#inner ring\nin_pie, _ =ax.pie(chest_pains_with_gender, radius =1.4, labels = gender_with_types, labeldistance=0.7,\n                  colors = [a(0.4),a(0.6),b(0.4),b(0.6),c(0.4),c(0.6),d(0.4),d(0.6)]) \nplt.setp(in_pie, width = 1)\nplt.show() \n\nfor i in range(0,len(data_with_disease)):\n    chest_pains_count_suffered[data_with_disease['cp'][i]]+= 1\nfor i in range(165,165+len(data_without_disease)):\n    chest_pains_count_unsuffered[data_without_disease['cp'][i]]+= 1  \n\n    types = ['typical', 'atypical', 'non-anginal', 'asymptomatic']\nplt.figure(figsize = (12,6))\nplt.subplot(1,2,1)\nplt.bar(types,chest_pains_count_suffered,width =0.8)\nplt.ylabel('count of different chest pain types who are suffered')\n\nplt.subplot(1,2,2)\nplt.bar(types,chest_pains_count_unsuffered,width =0.8)\nplt.ylabel('count of different chest pain types who are unsuffered')\nplt.show()   \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Pie chart above defines the spread of different types of chest pains in the dataset and split of chest pains Gender. The bar graphs show spread of the chest pain types in both suffered and unsuffered data"},{"metadata":{},"cell_type":"markdown","source":"#### 4: relation between thal and target variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"thal_types_suffered = [0]*4\nthal_types_unsuffered = [0]*4\n\nN =4\nind = np.arange(N)\nfor i in range(0,len(heart_dataset)):\n    if(heart_dataset['target'][i] == 1):thal_types_suffered[heart_dataset['thal'][i]] +=1\n    else:thal_types_unsuffered[heart_dataset['thal'][i]] += 1\n\nplt.figure(figsize = (7,7))\np1 = plt.bar(ind,thal_types_suffered)\np2 = plt.bar(ind,thal_types_unsuffered,bottom = thal_types_suffered)\nplt.xticks(ind, ('None', 'normal', 'fixed defect', 'reversable defect'))\nplt.yticks(np.arange(0,175,30))\nplt.xlabel('thal types in suffered and un-suffered data')\nplt.ylabel('count of different thal types who are suffering and not suffering')\nplt.legend((p1[0], p2[0]), ('suffered', 'not_suffered'))\nplt.title('Thal type wise data comparision between  suffered and un-suffered people in dataset')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All the data are in numbers but few are categorical data replace them with categories\n\nThe features which are categories are sex, chestpain type(cp 0,1,2,3),fasting blood sugar(>120 yes or no),\nresting ecg(restecg  0,1,2),excercise angina(yes or no),slope(0,1,2),thal(1:normal,2:fixed,3:reversable)\n\nwe replace categorical data with dummy variables and avoid dummy variable trap by considering\nonly (n-1) categories in ecah categoricla data field. \n\nreplacing data is not requried for sex, fasting bp, excercise angina\n\nreplace rest of fields with categorical data"},{"metadata":{"trusted":true},"cell_type":"code","source":"heart_dataset['cp'][heart_dataset['cp'] == 0] = 'typical angina'\nheart_dataset['cp'][heart_dataset['cp'] == 1] = 'atypical angina'\nheart_dataset['cp'][heart_dataset['cp'] == 2] = 'non-anginal pain'\nheart_dataset['cp'][heart_dataset['cp'] == 3] = 'asymptomatic'\n\nheart_dataset['restecg'][heart_dataset['restecg'] == 0] = 'ecg1'\nheart_dataset['restecg'][heart_dataset['restecg'] == 1] = 'ecg2'\nheart_dataset['restecg'][heart_dataset['restecg'] == 2] = 'ecg3'\n\nheart_dataset['slope'][heart_dataset['slope'] == 0] = 'slope1'\nheart_dataset['slope'][heart_dataset['slope'] == 1] = 'slope2'\nheart_dataset['slope'][heart_dataset['slope'] == 2] = 'slope3'\n\nheart_dataset['thal'][heart_dataset['thal'] == 0] = 'None'\nheart_dataset['thal'][heart_dataset['thal'] == 1] = 'normal'\nheart_dataset['thal'][heart_dataset['thal'] == 2] = 'fixed'\nheart_dataset['thal'][heart_dataset['thal'] == 3] = 'reversable'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### delimiting outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (18,18))\nplt.subplot(2,3,1)\nplt.boxplot('age', data = heart_dataset)\nplt.ylabel('age')\nplt.subplot(2,3,2)\nplt.boxplot('chol', data = heart_dataset) \nplt.ylabel('chol')\nplt.subplot(2,3,3)\nplt.boxplot('trestbps', data = heart_dataset )\nplt.ylabel('trestbps')\nplt.subplot(2,3,4)\nplt.boxplot('thalach', data = heart_dataset)\nplt.ylabel('thalach')\nplt.subplot(2,3,5)\nplt.boxplot('oldpeak', data = heart_dataset)\nplt.ylabel('oldpeak')\nplt.subplot(2,3,6)\nplt.boxplot('exang', data = heart_dataset)\nplt.ylabel('exang')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"remove the row with extreme outlier. Impute the other outliers such that the mean and median values before and after imputing doesn't change much."},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(0,len(heart_dataset)):\n    if(heart_dataset['chol'][i] > 360):\n        heart_dataset['chol'][i] = int(heart_dataset['chol'][i] + heart_dataset['chol'].median())/2    \n    if(heart_dataset['trestbps'][i] > 170):\n        heart_dataset['trestbps'][i] = int(heart_dataset['trestbps'][i] + heart_dataset['trestbps'].median())/2    \n    if(heart_dataset['oldpeak'][i] > 4):\n        heart_dataset['oldpeak'][i] = int(heart_dataset['oldpeak'][i] + heart_dataset['oldpeak'].median())/2 \n\nheart_dataset = heart_dataset.drop(85) # chol value is extremely outside the range\nheart_dataset = heart_dataset.drop(48)  # thal is none\nheart_dataset = heart_dataset.drop(281) # thal is none\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"dummy variables for categorical data. train test split and feature scaling"},{"metadata":{"trusted":true},"cell_type":"code","source":"heart_dataset = pd.get_dummies(heart_dataset, drop_first=True)\n\nX = heart_dataset\nX=X.drop(['target'],axis =1)\ny = heart_dataset['target']\n\n# train test split\nfrom sklearn.model_selection import train_test_split\n\ntrain_x, test_x, train_y, test_y = train_test_split(X,y,test_size = 0.15, random_state =0)\n\n# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc_X = StandardScaler()\ntrain_x = sc_X.fit_transform(train_x)\ntest_x = sc_X.transform(test_x)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### model selection \n\nLets compare the classification prediction algorithms on the dataset "},{"metadata":{"trusted":true},"cell_type":"code","source":"#1. logistic regression----------------------------------------------------------------------------------\n\nfrom sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression(random_state =0)\nclassifier.fit(train_x,train_y)\ny_pred = classifier.predict(test_x)\n\nfrom sklearn.metrics import confusion_matrix\ncm_logistic = confusion_matrix(test_y,y_pred)\nprint(cm_logistic)\n\nfrom sklearn.model_selection import cross_val_score\naccuracies = cross_val_score(estimator = classifier, X = train_x, y = train_y, cv=10)\nprint(' ')\nprint('accuracy')\nprint(accuracies.mean())\nprint(' ')\nprint('standard deviation')\nprint(accuracies.std())\n\nfrom sklearn.metrics import f1_score\nf1_score(test_y,y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#2.K-Nearest Neighbours----------------------------------------------------------------------------\n\nfrom sklearn.neighbors import KNeighborsClassifier\nclassifier = KNeighborsClassifier(n_neighbors = 6, metric = 'minkowski', p=2)\nclassifier.fit(train_x,train_y)\ny_pred = classifier.predict(test_x)\n\n\ncm_knn = confusion_matrix(test_y,y_pred)\nprint(cm_knn)\n\n\naccuracies = cross_val_score(estimator = classifier, X = train_x, y = train_y, cv=10)\nprint(' ')\nprint('accuracy')\nprint(accuracies.mean())\nprint(' ')\nprint('standard deviation')\nprint(accuracies.std())\n\nf1_score(test_y,y_pred)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"find the best parameters for KNN. GridSearch is a method where it runs the specified classifier on different parameters and returns the best parameter fit based on the scoring method specified."},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.model_selection import GridSearchCV\nparameters = [{'n_neighbors':[2,3,4,5,6,7,8], 'metric':['minkowski'],'p':[2]}]\ngridsearch = GridSearchCV(estimator = classifier,\n                          param_grid = parameters,\n                          scoring = 'f1',\n                          cv=10)\ngridsearch = gridsearch.fit(train_x,train_y)\nbest_params_knn = gridsearch.best_params_\nprint(best_params_knn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#3.SVM-------------------------------------------------------------------------------------------\n\nfrom sklearn.svm import SVC\nclassifier = SVC(C=10,kernel = 'rbf',\n                 gamma=0.01,\n                 random_state = 0)\nclassifier.fit(train_x,train_y)\ny_pred = classifier.predict(test_x)\n\ncm_svm = confusion_matrix(test_y,y_pred)\nprint(cm_svm)\n\naccuracies = cross_val_score(estimator = classifier, X = train_x, y = train_y, cv=10)\nprint(' ')\nprint('accuracy')\nprint(accuracies.mean())\nprint(' ')\nprint('standard deviation')\nprint(accuracies.std())\n\n\nf1_score(test_y,y_pred)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"find best parameters for the SVM through gridsearch"},{"metadata":{"trusted":true},"cell_type":"code","source":"parameters = [ {'C':[1, 10, 100], 'kernel':['linear']},\n               {'C':[1, 10, 100],'kernel' : ['rbf'], 'gamma':[0.1,0.01,0.05,0.005]},\n               {'C':[1, 10, 100], 'kernel' :['poly'], 'degree' :[1,2,3,4]}]\ngridsearch = GridSearchCV(estimator = classifier,\n                          param_grid = parameters,\n                          scoring = 'f1',\n                          cv=10)\ngridsearch = gridsearch.fit(train_x,train_y)\nbest_accuracy_SVM = gridsearch.best_score_\nbest_params_SVM = gridsearch.best_params_\nprint(best_params_SVM)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#4.Decision Tree --------------------------------------------------------------------------------------\n\nfrom sklearn.tree import DecisionTreeClassifier\nclassifier = DecisionTreeClassifier(criterion ='entropy', random_state =0)\nclassifier.fit(train_x,train_y)\ny_pred = classifier.predict(test_x)\n\n\ncm_DecisionTree = confusion_matrix(test_y,y_pred)\nprint(cm_DecisionTree)\n\naccuracies = cross_val_score(estimator = classifier, X = train_x, y = train_y, cv=10)\nprint(' ')\nprint('accuracy')\nprint(accuracies.mean())\nprint(' ')\nprint('standard deviation')\nprint(accuracies.std())\n\n\nf1_score(test_y,y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#5.Random Forest-------------------------------------------------------------------------------------------------\n\nfrom sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(n_estimators =100, criterion ='gini', random_state = 0)\nclassifier.fit(train_x,train_y)\ny_pred = classifier.predict(test_x)\n\n\ncm_RandomForest = confusion_matrix(test_y,y_pred)\nprint(cm_RandomForest)\n\naccuracies = cross_val_score(estimator = classifier, X = train_x, y = train_y, cv=10)\nprint(' ')\nprint('accuracy')\nprint(accuracies.mean())\nprint(' ')\nprint('standard deviation')\nprint(accuracies.std())\n\nf1_score(test_y,y_pred)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"parameters = [ {'n_estimators':[10,100,200,300,400,500,600,700], 'criterion':['entropy']},\n                {'n_estimators':[10,100,200,300,400,500,600,700], 'criterion':['gini']}]\ngridsearch = GridSearchCV(estimator = classifier,\n                          param_grid = parameters,\n                          scoring = 'f1',\n                          cv=10)\ngridsearch = gridsearch.fit(train_x,train_y)\nbest_accuracy_forest = gridsearch.best_score_\nbest_params_forest = gridsearch.best_params_\nprint(best_params_forest)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"from the models SVM has shown better results with f1-score of 84.4% and accuracy 84.3% and std 7.46%. This doesn't mean that SVM is the best. Because of the low no of samples in dataset other algorithms didn't perform well but if samples were more then this results might change. "}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}