{"cells":[{"metadata":{},"cell_type":"markdown","source":"<hr/>\n[**Tolgahan Cepel**](https://www.kaggle.com/tolgahancepel)\n<hr/>\n<font color=green>\n1. [Overview](#1)\n1. [Importing Libraries and Reading the Dataset](#2)\n1. [Data Visualization and Preprocessing](#3)\n1. [Classification Models](#4) \n    * [Logistic Regression](#5) \n    * [K-Nearest Neighbors(K-NN)](#6)\n    * [Support Vector Machine (SVM - Linear)](#7)\n    * [Support Vector Machine (SVM - Kernel)](#8)\n    * [Naive Bayes](#9) \n    * [Decision Tree Classification](#10) \n    * [Random Forest Classification](#11)\n    * [Artificial Neural Network (ANN)](#12) \n1. [Comparing the Results](#13)\n    * [Visualizing Models Performance](#14) \n1. [Conclusion](#15)\n<hr/>"},{"metadata":{},"cell_type":"markdown","source":"## <span id=\"1\"></span> ** 1. Overview **"},{"metadata":{},"cell_type":"markdown","source":"Columns:\n- <b> RI: </b> refractive index \n- <b> NA: </b> Sodium (unit measurement: weight percent in corresponding oxide, as are attributes 4-10)\n- <b> Mg: </b> Magnesium\n- <b> Al: </b> Aluminum\n- <b> K: </b> Potassium\n- <b> Ca: </b> Calcium\n- <b> Ba: </b> Barium\n- <b> Fe: </b> Iron\n- <b> Type of glass: </b> 1 building_windows_float_processed -- 2 building_windows_non_float_processed -- 3 vehicle_windows_float_processed -- 4 vehicle_windows_non_float_processed (none in this database) -- 5 containers -- 6 tableware -- 7 headlamps"},{"metadata":{},"cell_type":"markdown","source":"## <span id=\"2\"></span> ** 2. Importing Libraries and Reading the Dataset **"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import cross_val_score\nfrom collections import Counter\nfrom IPython.core.display import display, HTML\nsns.set_style('darkgrid')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = pd.read_csv('/kaggle/input/glass/glass.csv')\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <span id=\"3\"></span> ** 3. Data Visualization and Preprocessing **"},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = dataset.corr()\n#Plot figsize\nfig, ax = plt.subplots(figsize=(10, 8))\n#Generate Heat Map, allow annotations and place floats in map\nsns.heatmap(corr, cmap='coolwarm', annot=True, fmt=\".2f\")\n#Apply xticks\nplt.xticks(range(len(corr.columns)), corr.columns);\n#Apply yticks\nplt.yticks(range(len(corr.columns)), corr.columns)\n#show plot\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"f, axes = plt.subplots(1,2,figsize=(14,4))\n\nsns.distplot(dataset['RI'], ax = axes[0])\naxes[0].set_xlabel('Refractive Index', fontsize=14)\naxes[0].set_ylabel('Count', fontsize=14)\naxes[0].yaxis.tick_left()\n\nsns.violinplot(x = 'Type', y = 'RI', data = dataset, hue = 'Type', dodge = False, ax = axes[1])\naxes[1].set_xlabel('Type of glass', fontsize=14)\naxes[1].set_ylabel('Refractive Index', fontsize=14)\naxes[1].yaxis.set_label_position(\"right\")\naxes[1].yaxis.tick_right()\naxes[1].legend(bbox_to_anchor=(1.15, 1), loc=2, borderaxespad=0.)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"f, axes = plt.subplots(1,2,figsize=(14,4))\n\nsns.distplot(dataset['Na'], ax = axes[0])\naxes[0].set_xlabel('Sodium', fontsize=14)\naxes[0].set_ylabel('Count', fontsize=14)\naxes[0].yaxis.tick_left()\n\nsns.boxplot(x = 'Type', y = 'Na', data = dataset, hue = 'Type', dodge = False, ax = axes[1])\naxes[1].set_xlabel('Type of glass', fontsize=14)\naxes[1].set_ylabel('Sodium', fontsize=14)\naxes[1].yaxis.set_label_position(\"right\")\naxes[1].yaxis.tick_right()\naxes[1].legend(bbox_to_anchor=(1.15, 1), loc=2, borderaxespad=0.)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"f, axes = plt.subplots(1,2,figsize=(14,4))\n\nsns.distplot(dataset['Mg'], ax = axes[0])\naxes[0].set_xlabel('Magnesium', fontsize=14)\naxes[0].set_ylabel('Count', fontsize=14)\naxes[0].yaxis.tick_left()\n\nsns.violinplot(x = 'Type', y = 'Mg', data = dataset, hue = 'Type', dodge = False, ax = axes[1])\naxes[1].set_xlabel('Type of glass', fontsize=14)\naxes[1].set_ylabel('Magnesium', fontsize=14)\naxes[1].yaxis.set_label_position(\"right\")\naxes[1].yaxis.tick_right()\naxes[1].legend(bbox_to_anchor=(1.15, 1), loc=2, borderaxespad=0.)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"f, axes = plt.subplots(1,2,figsize=(14,4))\n\nsns.distplot(dataset['Al'], ax = axes[0])\naxes[0].set_xlabel('Aluminum', fontsize=14)\naxes[0].set_ylabel('Count', fontsize=14)\naxes[0].yaxis.tick_left()\n\nsns.violinplot(x = 'Type', y = 'Al', data = dataset, hue = 'Type', dodge = False, ax = axes[1])\naxes[1].set_xlabel('Type of glass', fontsize=14)\naxes[1].set_ylabel('Aluminum', fontsize=14)\naxes[1].yaxis.set_label_position(\"right\")\naxes[1].yaxis.tick_right()\naxes[1].legend(bbox_to_anchor=(1.15, 1), loc=2, borderaxespad=0.)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"f, axes = plt.subplots(1,2,figsize=(14,4))\n\nsns.distplot(dataset['Si'], ax = axes[0])\naxes[0].set_xlabel('Silicon', fontsize=14)\naxes[0].set_ylabel('Count', fontsize=14)\naxes[0].yaxis.tick_left()\n\nsns.violinplot(x = 'Type', y = 'Si', data = dataset, hue = 'Type', dodge = False, ax = axes[1])\naxes[1].set_xlabel('Type of glass', fontsize=14)\naxes[1].set_ylabel('Silicon', fontsize=14)\naxes[1].yaxis.set_label_position(\"right\")\naxes[1].yaxis.tick_right()\naxes[1].legend(bbox_to_anchor=(1.15, 1), loc=2, borderaxespad=0.)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"f, axes = plt.subplots(1,2,figsize=(14,4))\n\nsns.distplot(dataset['K'], ax = axes[0])\naxes[0].set_xlabel('Potassium', fontsize=14)\naxes[0].set_ylabel('Count', fontsize=14)\naxes[0].yaxis.tick_left()\n\nsns.violinplot(x = 'Type', y = 'K', data = dataset, hue = 'Type', dodge = False, ax = axes[1])\naxes[1].set_xlabel('Type of glass', fontsize=14)\naxes[1].set_ylabel('Potassium', fontsize=14)\naxes[1].yaxis.set_label_position(\"right\")\naxes[1].yaxis.tick_right()\naxes[1].legend(bbox_to_anchor=(1.15, 1), loc=2, borderaxespad=0.)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"f, axes = plt.subplots(1,2,figsize=(14,4))\n\nsns.distplot(dataset['Ca'], ax = axes[0])\naxes[0].set_xlabel('Calcium', fontsize=14)\naxes[0].set_ylabel('Count', fontsize=14)\naxes[0].yaxis.tick_left()\n\nsns.violinplot(x = 'Type', y = 'Ca', data = dataset, hue = 'Type', dodge = False, ax = axes[1])\naxes[1].set_xlabel('Type of glass', fontsize=14)\naxes[1].set_ylabel('Calcium', fontsize=14)\naxes[1].yaxis.set_label_position(\"right\")\naxes[1].yaxis.tick_right()\naxes[1].legend(bbox_to_anchor=(1.15, 1), loc=2, borderaxespad=0.)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"f, axes = plt.subplots(1,2,figsize=(14,4))\n\nsns.distplot(dataset['Ca'], ax = axes[0])\naxes[0].set_xlabel('Barium', fontsize=14)\naxes[0].set_ylabel('Count', fontsize=14)\naxes[0].yaxis.tick_left()\n\nsns.violinplot(x = 'Type', y = 'Ca', data = dataset, hue = 'Type', dodge = False, ax = axes[1])\naxes[1].set_xlabel('Type of glass', fontsize=14)\naxes[1].set_ylabel('Barium', fontsize=14)\naxes[1].yaxis.set_label_position(\"right\")\naxes[1].yaxis.tick_right()\naxes[1].legend(bbox_to_anchor=(1.15, 1), loc=2, borderaxespad=0.)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"f, axes = plt.subplots(1,2,figsize=(14,4))\n\nsns.distplot(dataset['Fe'], ax = axes[0])\naxes[0].set_xlabel('Iron', fontsize=14)\naxes[0].set_ylabel('Count', fontsize=14)\naxes[0].yaxis.tick_left()\n\nsns.violinplot(x = 'Type', y = 'Fe', data = dataset, hue = 'Type', dodge = False, ax = axes[1])\naxes[1].set_xlabel('Type of glass', fontsize=14)\naxes[1].set_ylabel('Iron', fontsize=14)\naxes[1].yaxis.set_label_position(\"right\")\naxes[1].yaxis.tick_right()\naxes[1].legend(bbox_to_anchor=(1.15, 1), loc=2, borderaxespad=0.)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = dataset.drop('Type', axis = 1).values\ny = dataset['Type'].values.reshape(-1,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Shape of X_train: \",X_train.shape)\nprint(\"Shape of X_test: \", X_test.shape)\nprint(\"Shape of y_train: \",y_train.shape)\nprint(\"Shape of y_test\",y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <span id=\"4\"></span> ** 4. Classification Models **"},{"metadata":{},"cell_type":"markdown","source":"### <span id=\"5\"></span> ** Logistic Regression **"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fitting Logistic Regression to the Training set\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\n\nclassifier_lr = LogisticRegression()\nsteps = [\n    ('scalar', StandardScaler()),\n    ('model', LogisticRegression())\n]\n\nlr_pipe = Pipeline(steps)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"parameters = { 'model__C' : [1,10,100,1000,10000],\n               'model__fit_intercept' : [True],\n               'model__multi_class' : ['auto'],\n               'model__tol' : [0.0001],\n               'model__solver' : ['newton-cg', 'lbfgs', 'sag', 'saga'],\n               'model__n_jobs' : [-1],\n               'model__max_iter' : [5000],\n               'model__random_state': [42] \n}\nclassifier_lr = GridSearchCV(lr_pipe, parameters, iid=False, cv = 3)\nclassifier_lr = classifier_lr.fit(X_train, y_train.ravel())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\ny_pred_lr_train = classifier_lr.predict(X_train)\naccuracy_lr_train = accuracy_score(y_train, y_pred_lr_train)\nprint(\"Training set: \", accuracy_lr_train)\n\ny_pred_lr_test = classifier_lr.predict(X_test)\naccuracy_lr_test = accuracy_score(y_test, y_pred_lr_test)\nprint(\"Test set: \", accuracy_lr_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nsns.heatmap(confusion_matrix(y_test, y_pred_lr_test), annot=True, cmap = 'viridis', fmt='.0f')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <span id=\"6\"></span> ** K-Nearest Neighbors (K-NN) **"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fitting classifier to the Training set\nfrom sklearn.neighbors import KNeighborsClassifier\nclassifier_knn = KNeighborsClassifier()\nsteps = [\n    ('scalar', StandardScaler()),\n    ('model', KNeighborsClassifier())\n]\nknn_pipe = Pipeline(steps)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"parameters = { 'model__algorithm' : ['brute'],\n               'model__leaf_size' : [30,50,70,90,110],\n               'model__metric' : ['minkowski'],\n               'model__p' : [1],\n               'model__n_neighbors' : [3,5,11,19],\n               'model__weights' : ['uniform', 'distance'],\n               'model__n_jobs' : [-1]\n}\nclassifier_knn = GridSearchCV(knn_pipe, parameters, iid=False, cv = 3)\nclassifier_knn = classifier_knn.fit(X_train, y_train.ravel())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_knn_train = classifier_knn.predict(X_train)\naccuracy_knn_train = accuracy_score(y_train, y_pred_knn_train)\nprint(\"Training set: \", accuracy_knn_train)\n\ny_pred_knn_test = classifier_knn.predict(X_test)\naccuracy_knn_test = accuracy_score(y_test, y_pred_knn_test)\nprint(\"Test set: \", accuracy_knn_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nsns.heatmap(confusion_matrix(y_test, y_pred_knn_test), annot=True, cmap = 'viridis', fmt='.0f')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <span id=\"7\"></span> ** Support Vector Machine (SVM - Linear) **"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nclassifier_svm = SVC()\nsteps = [\n    ('scalar', StandardScaler()),\n    ('model', SVC())\n]\nsvm_linear_pipe = Pipeline(steps)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"parameters = { 'model__kernel' : ['linear'],\n               'model__C' : [1,10,100,1000,10000],\n               'model__random_state' : [42]\n}\nclassifier_svm_linear = GridSearchCV(svm_linear_pipe, parameters, iid=False, cv = 3)\nclassifier_svm_linear = classifier_svm_linear.fit(X_train, y_train.ravel())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_svm_linear_train = classifier_svm_linear.predict(X_train)\naccuracy_svm_linear_train = accuracy_score(y_train, y_pred_svm_linear_train)\nprint(\"Training set: \", accuracy_svm_linear_train)\n\ny_pred_svm_linear_test = classifier_svm_linear.predict(X_test)\naccuracy_svm_linear_test = accuracy_score(y_test, y_pred_svm_linear_test)\nprint(\"Test set: \", accuracy_svm_linear_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nsns.heatmap(confusion_matrix(y_test, y_pred_svm_linear_test), annot=True, cmap = 'viridis', fmt='.0f')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <span id=\"8\"></span> ** Support Vector Machine (SVM - Kernel) **"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fitting classifier to the Training set\nfrom sklearn.svm import SVC\nclassifier_svm_kernel = SVC()\nsteps = [\n    ('scalar', StandardScaler()),\n    ('model', SVC())\n]\nsvm_kernel_pipe = Pipeline(steps)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"parameters = { 'model__kernel' : ['rbf', 'poly', 'sigmoid'],\n               'model__C' : [1,10,100,1000,10000],\n               'model__gamma' : [0.001, 0.01, 0.1, 1, 'scale'],\n               'model__random_state' : [42],\n               'model__degree' : [1,2,3]\n}\nclassifier_svm_kernel = GridSearchCV(svm_kernel_pipe, parameters, iid=False, cv = 3)\nclassifier_svm_kernel = classifier_svm_kernel.fit(X_train, y_train.ravel())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_svm_kernel_train = classifier_svm_kernel.predict(X_train)\naccuracy_svm_kernel_train = accuracy_score(y_train, y_pred_svm_kernel_train)\nprint(\"Training set: \", accuracy_svm_kernel_train)\n\ny_pred_svm_kernel_test = classifier_svm_kernel.predict(X_test)\naccuracy_svm_kernel_test = accuracy_score(y_test, y_pred_svm_kernel_test)\nprint(\"Test set: \", accuracy_svm_kernel_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nsns.heatmap(confusion_matrix(y_test, y_pred_svm_kernel_test), annot=True, cmap = 'viridis', fmt='.0f')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <span id=\"9\"></span> ** Naive Bayes **"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fitting classifier to the Training set\nfrom sklearn.naive_bayes import GaussianNB\nclassifier_nb = GaussianNB()\nclassifier_nb.fit(X_train, y_train.ravel())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_nb_train = classifier_nb.predict(X_train)\naccuracy_nb_train = accuracy_score(y_train, y_pred_nb_train)\nprint(\"Training set: \", accuracy_nb_train)\n\ny_pred_nb_test = classifier_nb.predict(X_test)\naccuracy_nb_test = accuracy_score(y_test, y_pred_nb_test)\nprint(\"Test set: \", accuracy_nb_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nsns.heatmap(confusion_matrix(y_test, y_pred_nb_test), annot=True, cmap = 'viridis', fmt='.0f')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <span id=\"10\"></span> ** Decision Tree Classification **"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fitting classifier to the Training set\nfrom sklearn.tree import DecisionTreeClassifier\nclassifier_dt = DecisionTreeClassifier()\n\nsteps = [\n    ('scalar', StandardScaler()),\n    ('model', DecisionTreeClassifier())\n]\ndt_pipe = Pipeline(steps)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Applying Grid Search to find the best model and the best parameters\nparameters = [ { \"model__max_depth\": np.arange(1,21),\n                 \"model__min_samples_leaf\": [1, 5, 10, 20, 50, 100],\n                 \"model__min_samples_split\": np.arange(2, 11),\n                 \"model__criterion\": [\"gini\"],\n                 \"model__random_state\" : [42]}\n            ]\nclassifier_dt = GridSearchCV(estimator = dt_pipe,\n                           param_grid  = parameters,\n                           cv = 3,\n                           iid = False,\n                           n_jobs = -1)\nclassifier_dt = classifier_dt.fit(X_train, y_train.ravel())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_dt_train = classifier_dt.predict(X_train)\naccuracy_dt_train = accuracy_score(y_train, y_pred_dt_train)\nprint(\"Training set: \", accuracy_dt_train)\n\ny_pred_dt_test = classifier_dt.predict(X_test)\naccuracy_dt_test = accuracy_score(y_test, y_pred_dt_test)\nprint(\"Test set: \", accuracy_dt_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nsns.heatmap(confusion_matrix(y_test, y_pred_dt_test), annot=True, cmap = 'viridis', fmt='.0f')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <span id=\"11\"></span> ** Random Forest Classification **"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fitting Random Forest Classification to the Training set\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\nclassifier_rf = RandomForestClassifier()\n\nsteps = [\n    ('scalar', StandardScaler()),\n    ('model', RandomForestClassifier())\n]\nrf_pipe = Pipeline(steps)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"parameters =  { \"model__n_estimators\": [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)],\n                \"model__max_features\": [\"auto\", \"sqrt\"],\n                \"model__max_depth\": np.linspace(10, 110, num = 11),\n                \"model__min_samples_split\": [2, 5, 10],\n                \"model__min_samples_leaf\": [1, 2, 4],\n                \"model__bootstrap\": [True, False],\n                \"model__criterion\": [\"gini\"],\n                \"model__random_state\" : [42] }\n            \nclassifier_rf = RandomizedSearchCV(estimator = rf_pipe,\n                                  param_distributions = parameters,\n                                  n_iter = 100,\n                                  cv = 3,\n                                  random_state=42,\n                                  verbose = 4,\n                                  n_jobs = -1)\nclassifier_rf = classifier_rf.fit(X_train, y_train.ravel())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_rf_train = classifier_rf.predict(X_train)\naccuracy_rf_train = accuracy_score(y_train, y_pred_rf_train)\nprint(\"Training set: \", accuracy_rf_train)\n\ny_pred_rf_test = classifier_rf.predict(X_test)\naccuracy_rf_test = accuracy_score(y_test, y_pred_rf_test)\nprint(\"Test set: \", accuracy_rf_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nsns.heatmap(confusion_matrix(y_test, y_pred_rf_test), annot=True, cmap = 'viridis', fmt='.0f')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <span id=\"12\"></span> ** Artificial Neural Network (ANN) **"},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# Importing the Keras libraries and packages\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature Scaling\nsc_X = StandardScaler()\nX_train_scaled = sc_X.fit_transform(X_train)\nX_test_scaled = sc_X.fit_transform(X_test)\nprint(X_train_scaled.shape)\nprint(X_test_scaled.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Defining a function to encode output column\nfrom keras.utils import to_categorical\ndef encode(data):\n    print('Shape of data (BEFORE encode): %s' % str(data.shape))\n    encoded = to_categorical(data)\n    print('Shape of data (AFTER  encode): %s\\n' % str(encoded.shape))\n    return encoded","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_encoded = encode(y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test_encoded = encode(y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_encoded = np.delete(y_train_encoded, [0,4], axis = 1)\ny_test_encoded = np.delete(y_test_encoded, [0,4], axis = 1)\nprint(y_train_encoded[2])\nprint(y_test_encoded[2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# Initialising the ANN\nclassifier = Sequential()\n\n# Adding the input layer and the first hidden layer\nclassifier.add(Dense(units = 9, kernel_initializer = 'uniform', activation = 'relu'))\n\n# Adding the second hidden layer\nclassifier.add(Dense(units = 5, kernel_initializer = 'uniform', activation = 'relu'))\n\n# Adding the output layer\nclassifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'softmax'))\n\n# Compiling the ANN\nclassifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n\n# Fitting the ANN to the Training set\nhistory = classifier.fit(X_train_scaled, y_train_encoded, validation_data=(X_test_scaled, y_test_encoded), batch_size = 100, epochs = 1150)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(1,2,figsize=(14,4))\n\naxes[0].plot(history.history['loss'])\naxes[0].plot(history.history['val_loss'])\naxes[0].set_xlabel('Loss', fontsize=14)\naxes[0].set_ylabel('Epuch', fontsize=14)\naxes[0].yaxis.tick_left()\naxes[0].legend(['Train', 'Test'], loc='upper left')\n\naxes[1].plot(history.history['acc'])\naxes[1].plot(history.history['val_acc'])\naxes[1].set_xlabel('Accuracy', fontsize=14)\naxes[1].set_ylabel('Epoch', fontsize=14)\naxes[1].yaxis.set_label_position(\"right\")\naxes[1].yaxis.tick_right()\naxes[1].legend(['Train', 'Test'], loc='upper left')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Training set: \", history.history.get('acc')[-1])\nprint(\"Test set: \", history.history.get('val_acc')[-1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <span id=\"13\"></span> ** 5. Comparing the Results **"},{"metadata":{"trusted":true},"cell_type":"code","source":"models = [('Logistic Regression', accuracy_lr_train, accuracy_lr_test),\n          ('KNN', accuracy_knn_train, accuracy_knn_test),\n          ('SVM (Linear)', accuracy_svm_linear_train, accuracy_svm_linear_test),\n          ('SVM (Kernel)', accuracy_svm_kernel_train, accuracy_svm_kernel_test),\n          ('Naive Bayes', accuracy_nb_train, accuracy_nb_test),\n          ('Decision Tree Classification', accuracy_dt_train, accuracy_dt_test),\n          ('Random Forest Classification', accuracy_rf_train, accuracy_rf_test),\n          ('ANN', history.history.get('acc')[-1], history.history.get('val_acc')[-1]),\n         ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict = pd.DataFrame(data = models, columns=['Model', 'Training Accuracy', 'Test Accuracy'])\npredict","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <span id=\"14\"></span> ** Visualizing Models Performance **"},{"metadata":{"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(2,1, figsize=(14,10))\n\npredict.sort_values(by=['Training Accuracy'], ascending=False, inplace=True)\n\nsns.barplot(x='Training Accuracy', y='Model', data = predict, palette='Blues_d', ax = axes[0])\n#axes[0].set(xlabel='Region', ylabel='Charges')\naxes[0].set_xlabel('Training Accuracy', size=16)\naxes[0].set_ylabel('Model')\naxes[0].set_xlim(0,1.0)\naxes[0].set_xticks(np.arange(0, 1.1, 0.1))\n\npredict.sort_values(by=['Test Accuracy'], ascending=False, inplace=True)\n\nsns.barplot(x='Test Accuracy', y='Model', data = predict, palette='Greens_d', ax = axes[1])\n#axes[0].set(xlabel='Region', ylabel='Charges')\naxes[1].set_xlabel('Test Accuracy', size=16)\naxes[1].set_ylabel('Model')\naxes[1].set_xlim(0,1.0)\naxes[1].set_xticks(np.arange(0, 1.1, 0.1))\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <span id=\"15\"></span> ** 6. Conclusion **"},{"metadata":{},"cell_type":"markdown","source":"In this kernel, I have built 8 classification models using Glass Identification Dataset. These are logistic, k-nn, svm(linear), svm(kernel), naive bayes, decision tree, random forest and artificial neural network. Then measured and visualized the performance of the models. Please make a comment and let me know how to improve model performance, visualization or something in this kernel. This will also help me on my future works.\n\n<b><font color=\"red\">Don't forget to </font></b> <b><font color=\"green\">UPVOTE </font></b> if you liked this kernel, thank you. üôÇüëç"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}