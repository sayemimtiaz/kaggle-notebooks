{"cells":[{"metadata":{},"cell_type":"markdown","source":"<div style=\"height:200px; width:100%;\">\n    <img style=\"height:200px; width:100%;\" src=\"http://csc.lsu.edu/~saikat/deepsat/images/sat_img.png\"/>\n</div>"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import numpy as np\nfrom tqdm import tqdm\n\nimport pandas as pd\nimport sys\n\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib.pyplot as plt\nimport matplotlib","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 id=\"dataset\" style=\"color:blue; border: 1px dotted green;\"> \n    <center>Dataset\n        <a class=\"anchor-link\" href=\"#dataset\" target=\"_self\">¶</a>\n    </center>\n</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"features = pd.read_csv('../input/deepsat-sat4/X_test_sat4.csv', skiprows=lambda i: i % 50 != 0).values\nfeatures = features / 255.\nlabels = pd.read_csv('../input/deepsat-sat4/y_test_sat4.csv', skiprows=lambda i: i % 50 != 0).values\nlabels = np.max(labels, axis=1)\n\nfeatures, labels = shuffle(features, labels)\n\nX_train, X_test, y_train, y_test = train_test_split(\n                                        features, labels, test_size=0.33, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 id=\"activation\" style=\"color:blue; border: 1px dotted green;\"> \n    <center>Activation Functions\n        <a class=\"anchor-link\" href=\"#activation\" target=\"_self\">¶</a>\n    </center>\n</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"def log(x):\n    return 1 / (1 + np.exp(-1 * x))\n\ndef d_log(x):\n    return log(x) * ( 1 - log(x))\n\ndef tanh(x):\n    return np.tanh(x)\n\ndef d_tanh(x):\n    return 1 - np.tanh(x) ** 2 \n\ndef ReLu(x):\n    mask = (x > 0.0) * 1.0\n    return x * mask\n\ndef d_ReLu(x):\n    mask = (x > 0.0) * 1.0\n    return mask    \n\ndef elu(matrix):\n    mask = (matrix<=0) * 1.0\n    less_zero = matrix * mask\n    safe =  (matrix>0) * 1.0\n    greater_zero = matrix * safe\n    final = 3.0 * (np.exp(less_zero) - 1) * less_zero\n    return greater_zero + final\n\ndef d_elu(matrix):\n    safe = (matrix>0) * 1.0\n    mask2 = (matrix<=0) * 1.0\n    temp = matrix * mask2\n    final = (3.0 * np.exp(temp))*mask2\n    return (matrix * safe) + final","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 id=\"weights\" style=\"color:blue; border: 1px dotted green;\"> \n    <center>Weights\n        <a class=\"anchor-link\" href=\"#weights\" target=\"_self\">¶</a>\n    </center>\n</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 1. Declare Weights\nnp.random.seed(1234)\n\nw1 = np.random.randn(3136,256) * 0.2\nw2 =np.random.randn(256,128) * 0.2\nw3 =np.random.randn(128,1) * 0.2\n\nw1_sgd,w2_sgd ,w3_sgd = w1,w2,w3\nw1_m,w2_m ,w3_m = w1,w2,w3\nw1_ng,w2_ng,w3_ng =  w1,w2,w3\nw1_adagrad,w2_adagrad,w3_adagrad =  w1,w2,w3\nw1_adadelta,w2_adadelta,w3_adadelta =  w1,w2,w3\nw1_RSMprop,w2_RSMprop,w3_RSMprop =  w1,w2,w3\nw1_adam,w2_adam,w3_adam =  w1,w2,w3\nw1_nadam,w2_nadam,w3_nadam =  w1,w2,w3\n\nw1_sgd_noise,w2_sgd_noise ,w3_sgd_noise = w1,w2,w3\nw1_noise,w2_noise,w3_noise  = w1,w2,w3\nw1_noise_noise,w2_noise_noise,w3_noise_noise  = w1,w2,w3\nw1_noise_adam,w2_noise_adam,w3_noise_adam  = w1,w2,w3","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 id=\"sgd\" style=\"color:blue; border: 1px dotted green;\"> \n    <center>SGD\n        <a class=\"anchor-link\" href=\"#sgd\" target=\"_self\">¶</a>\n    </center>\n</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"num_epoch = 10\ntotal_cost = 0\nlearn_rate = 0.0003\ncost_array =[]\ncost_temp_array = []\n\nfor e in range(num_epoch):\n    for i in range(len(X_train)):\n        \n        X = np.expand_dims(X_train[i],axis=0)\n        y = np.expand_dims(np.array([y_train[i]]), axis=1)\n\n        l1 = X.dot(w1_sgd)\n        l1A = elu(l1)\n\n        l2 = l1A.dot(w2_sgd)\n        l2A = tanh(l2)       \n\n        l3 = l2A.dot(w3_sgd)\n        l3A = log(l3)   \n\n        cost = np.square(l3A - y).sum() * 0.5\n        total_cost = total_cost + cost\n\n        grad_3_part_1 = l3A - y\n        grad_3_part_2 = d_log(l3)\n        grad_3_part_3 = l2A\n        grad_3 =    grad_3_part_3.T.dot(grad_3_part_1 * grad_3_part_2)    \n\n        grad_2_part_1 = (grad_3_part_1 * grad_3_part_2).dot(w3_sgd.T)\n        grad_2_part_2 = d_tanh(l2)\n        grad_2_part_3 = l1A\n        grad_2 =    grad_2_part_3.T.dot(grad_2_part_1 * grad_2_part_2)\n\n        grad_1_part_1 = (grad_2_part_1 * grad_2_part_2).dot(w2_sgd.T)\n        grad_1_part_2 = d_elu(l1)\n        grad_1_part_3 = X\n        grad_1 =    grad_1_part_3.T.dot(grad_1_part_1 *grad_1_part_2)\n\n        w3_sgd = w3_sgd - learn_rate * grad_3\n        w2_sgd = w2_sgd - learn_rate * grad_2\n        w1_sgd = w1_sgd - learn_rate * grad_1\n        \n    if e % 1 == 0 :\n        print(\"e:{:2d}. SGD - Cost:{:1.3}\".format(e + 1, total_cost))\n        \n    cost_temp_array.append(total_cost)\n    total_cost = 0\n    \ncost_array.append(cost_temp_array)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 id=\"momentum\" style=\"color:blue; border: 1px dotted green;\"> \n    <center>Momentum\n        <a class=\"anchor-link\" href=\"#momentum\" target=\"_self\">¶</a>\n    </center>\n</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"v1,v2,v3 = 0,0,0\nalpha = 0.001\ntotal_cost = 0\ncost_temp_array = []\n\nfor e in range(num_epoch):\n    for i in range(len(X_train)):\n        \n        X = np.expand_dims(X_train[i],axis=0)\n        y = np.expand_dims(np.array([y_train[i]]), axis=1)\n\n        l1 = X.dot(w1_m)\n        l1A = elu(l1)\n\n        l2 = l1A.dot(w2_m)\n        l2A = tanh(l2)       \n\n        l3 = l2A.dot(w3_m)\n        l3A = log(l3)   \n\n        cost = np.square(l3A - y).sum() * 0.5\n        total_cost = total_cost + cost\n\n        grad_3_part_1 = l3A - y\n        grad_3_part_2 = d_log(l3)\n        grad_3_part_3 = l2A\n        grad_3 =    grad_3_part_3.T.dot(grad_3_part_1 * grad_3_part_2)    \n\n        grad_2_part_1 = (grad_3_part_1 * grad_3_part_2).dot(w3_m.T)\n        grad_2_part_2 = d_tanh(l2)\n        grad_2_part_3 = l1A\n        grad_2 =    grad_2_part_3.T.dot(grad_2_part_1 * grad_2_part_2)\n\n        grad_1_part_1 = (grad_2_part_1 * grad_2_part_2).dot(w2_m.T)\n        grad_1_part_2 = d_elu(l1)\n        grad_1_part_3 = X\n        grad_1 =   grad_1_part_3.T.dot(grad_1_part_1 *grad_1_part_2)\n\n        v3 = v3 * alpha + learn_rate * grad_3\n        v2 = v2 * alpha + learn_rate * grad_2\n        v1 = v1 * alpha + learn_rate * grad_1\n\n        w3_m = w3_m - v3\n        w2_m = w2_m - v2\n        w1_m = w1_m - v1\n        \n    if e % 1 == 0 :\n        print(\"e:{:2d}. Momentum - Cost:{:1.3}\".format(e + 1, total_cost))\n        \n    cost_temp_array.append(total_cost)\n    total_cost = 0\n    \ncost_array.append(cost_temp_array)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 id=\"nesterov\" style=\"color:blue; border: 1px dotted green;\"> \n    <center>Nesterov\n        <a class=\"anchor-link\" href=\"#nesterov\" target=\"_self\">¶</a>\n    </center>\n</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"v1,v2,v3 = 0,0,0\nalpha = 0.001\ntotal_cost = 0\ncost_temp_array = []\n\nfor e in range(num_epoch):\n    for i in range(len(X_train)):\n        \n        X = np.expand_dims(X_train[i],axis=0)\n        y = np.expand_dims(np.array([y_train[i]]), axis=1)\n\n        l1 = X.dot(w1_ng)\n        l1A = elu(l1)\n\n        l2 = l1A.dot(w2_ng)\n        l2A = tanh(l2)       \n\n        l3 = l2A.dot(w3_ng)\n        l3A = log(l3)   \n\n        cost = np.square(l3A - y).sum() * 0.5\n        total_cost = total_cost + cost\n\n        grad_3_part_1 = l3A - y\n        grad_3_part_2 = d_log(l3)\n        grad_3_part_3 = l2A\n        grad_3 =    grad_3_part_3.T.dot(grad_3_part_1 * grad_3_part_2)    \n\n        grad_2_part_1 = (grad_3_part_1 * grad_3_part_2).dot(w3_ng.T)\n        grad_2_part_2 = d_tanh(l2)\n        grad_2_part_3 = l1A\n        grad_2 =    grad_2_part_3.T.dot(grad_2_part_1 * grad_2_part_2)\n\n        grad_1_part_1 = (grad_2_part_1 * grad_2_part_2).dot(w2_ng.T)\n        grad_1_part_2 = d_elu(l1)\n        grad_1_part_3 = X\n        grad_1 =   grad_1_part_3.T.dot(grad_1_part_1 *grad_1_part_2)\n\n        # ------- FAKE GRADIENT --------\n        fake_w3_ng = w3_ng - alpha * v3\n        fake_w2_ng = w2_ng - alpha * v2\n        fake_w1_ng = w1_ng - alpha * v1\n        \n        l1 = X.dot(fake_w1_ng)\n        l1A = elu(l1)\n\n        l2 = l1A.dot(fake_w2_ng)\n        l2A = tanh(l2)       \n\n        l3 = l2A.dot(fake_w3_ng)\n        l3A = log(l3)   \n\n        grad_3_part_1 = l3A - y\n        grad_3_part_2 = d_log(l3)\n        grad_3_part_3 = l2A\n        grad_3_fake =     grad_3_part_3.T.dot(grad_3_part_1 * grad_3_part_2)    \n\n        grad_2_part_1 = (grad_3_part_1 * grad_3_part_2).dot(fake_w3_ng.T)\n        grad_2_part_2 = d_tanh(l2)\n        grad_2_part_3 = l1A\n        grad_2_fake =    grad_2_part_3.T.dot(grad_2_part_1 * grad_2_part_2)\n\n        grad_1_part_1 = (grad_2_part_1 * grad_2_part_2).dot(fake_w2_ng.T)\n        grad_1_part_2 = d_elu(l1)\n        grad_1_part_3 = X\n        grad_1_fake =   grad_1_part_3.T.dot(grad_1_part_1 *grad_1_part_2)\n        # ------- FAKE GRADIENT --------\n\n        v3 = v3 * alpha + learn_rate * grad_3_fake\n        v2 = v2 * alpha + learn_rate * grad_2_fake\n        v1 = v1 * alpha + learn_rate * grad_1_fake\n\n        w3_ng = w3_ng - v3\n        w2_ng = w2_ng - v2\n        w1_ng = w1_ng - v1\n        \n    if e % 1 == 0 :\n        print(\"e:{:2d}. Nesterov - Cost:{:1.3}\".format(e + 1, total_cost))\n        \n    cost_temp_array.append(total_cost)\n    total_cost = 0\n    \ncost_array.append(cost_temp_array)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 id=\"adagrad\" style=\"color:blue; border: 1px dotted green;\"> \n    <center>Adagrad\n        <a class=\"anchor-link\" href=\"#adagrad\" target=\"_self\">¶</a>\n    </center>\n</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"Adagrad_lr_1,Adagrad_lr_2,Adagrad_lr_3 = 0,0,0\nAdagrad_e = 0.00000001\ntotal_cost = 0\ncost_temp_array = []\n\nfor e in range(num_epoch):\n    for i in range(len(X_train)):\n        \n        X = np.expand_dims(X_train[i],axis=0)\n        y = np.expand_dims(np.array([y_train[i]]), axis=1)\n\n        l1 = X.dot(w1_adagrad)\n        l1A = elu(l1)\n\n        l2 = l1A.dot(w2_adagrad)\n        l2A = tanh(l2)       \n\n        l3 = l2A.dot(w3_adagrad)\n        l3A = log(l3)   \n\n        cost = np.square(l3A - y).sum() * 0.5\n        total_cost = total_cost + cost\n\n        grad_3_part_1 = l3A - y\n        grad_3_part_2 = d_log(l3)\n        grad_3_part_3 = l2A\n        grad_3 =     grad_3_part_3.T.dot(grad_3_part_1 * grad_3_part_2)    \n\n        grad_2_part_1 = (grad_3_part_1 * grad_3_part_2).dot(w3_adagrad.T)\n        grad_2_part_2 = d_tanh(l2)\n        grad_2_part_3 = l1A\n        grad_2 =    grad_2_part_3.T.dot(grad_2_part_1 * grad_2_part_2)\n\n        grad_1_part_1 = (grad_2_part_1 * grad_2_part_2).dot(w2_adagrad.T)\n        grad_1_part_2 = d_elu(l1)\n        grad_1_part_3 = X\n        grad_1 =   grad_1_part_3.T.dot(grad_1_part_1 *grad_1_part_2)\n\n        Adagrad_lr_3 = Adagrad_lr_3 + grad_3 ** 2\n        Adagrad_lr_2 = Adagrad_lr_2 + grad_2 ** 2\n        Adagrad_lr_1 = Adagrad_lr_1 + grad_1 ** 2\n\n        w3_adagrad = w3_adagrad - (learn_rate/np.sqrt(Adagrad_lr_3 + Adagrad_e)) *grad_3\n        w2_adagrad = w2_adagrad - (learn_rate/np.sqrt(Adagrad_lr_2 + Adagrad_e)) *grad_2\n        w1_adagrad = w1_adagrad - (learn_rate/np.sqrt(Adagrad_lr_1 + Adagrad_e)) *grad_1\n    \n    if e % 1 == 0 :\n        print(\"e:{:2d}. Adagrad - Cost:{:1.3}\".format(e + 1, total_cost))\n        \n    cost_temp_array.append(total_cost)\n    total_cost = 0\n    \ncost_array.append(cost_temp_array)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 id=\"adadelta\" style=\"color:blue; border: 1px dotted green;\"> \n    <center>Adadelta\n        <a class=\"anchor-link\" href=\"#adadelta\" target=\"_self\">¶</a>\n    </center>\n</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"AdaDelta_e,AdaDelta_v = 0.000001,0.001\nAdaDelta_1,AdaDelta_2,AdaDelta_3 = 0,0,0\nAdaDelta_1_v,AdaDelta_2_v,AdaDelta_3_v = 0,0,0\ntotal_cost = 0\ncost_temp_array = []\n\nfor e in range(num_epoch):\n    for i in range(len(X_train)):\n        \n        X = np.expand_dims(X_train[i],axis=0)\n        y = np.expand_dims(np.array([y_train[i]]), axis=1)\n        \n        l1 = X.dot(w1_adadelta)\n        l1A = elu(l1)\n\n        l2 = l1A.dot(w2_adadelta)\n        l2A = tanh(l2)       \n\n        l3 = l2A.dot(w3_adadelta)\n        l3A = log(l3)   \n\n        cost = np.square(l3A - y).sum() * 0.5\n        total_cost = total_cost + cost\n\n        grad_3_part_1 = l3A - y\n        grad_3_part_2 = d_log(l3)\n        grad_3_part_3 = l2A\n        grad_3 =     grad_3_part_3.T.dot(grad_3_part_1 * grad_3_part_2)    \n\n        grad_2_part_1 = (grad_3_part_1 * grad_3_part_2).dot(w3_adadelta.T)\n        grad_2_part_2 = d_tanh(l2)\n        grad_2_part_3 = l1A\n        grad_2 =    grad_2_part_3.T.dot(grad_2_part_1 * grad_2_part_2)\n\n        grad_1_part_1 = (grad_2_part_1 * grad_2_part_2).dot(w2_adadelta.T)\n        grad_1_part_2 = d_elu(l1)\n        grad_1_part_3 = X\n        grad_1 =   grad_1_part_3.T.dot(grad_1_part_1 *grad_1_part_2)\n\n        AdaDelta_3 = AdaDelta_v * AdaDelta_3 + (1-AdaDelta_v) * grad_3 ** 2\n        AdaDelta_2 = AdaDelta_v * AdaDelta_2 + (1-AdaDelta_v) * grad_2 ** 2\n        AdaDelta_1 = AdaDelta_v * AdaDelta_1 + (1-AdaDelta_v) * grad_1 ** 2\n\n        mid_grad_3 = - ( np.sqrt(AdaDelta_3_v + AdaDelta_e) / np.sqrt(AdaDelta_3 + AdaDelta_e) ) * grad_3\n        mid_grad_2 = - ( np.sqrt(AdaDelta_2_v + AdaDelta_e) / np.sqrt(AdaDelta_2 + AdaDelta_e) ) * grad_2\n        mid_grad_1 = - ( np.sqrt(AdaDelta_1_v + AdaDelta_e) / np.sqrt(AdaDelta_1 + AdaDelta_e) ) * grad_1\n\n        AdaDelta_3_v = AdaDelta_v * AdaDelta_3_v + (1-AdaDelta_v) * mid_grad_3 ** 2\n        AdaDelta_2_v = AdaDelta_v * AdaDelta_2_v + (1-AdaDelta_v) * mid_grad_2 ** 2\n        AdaDelta_1_v = AdaDelta_v * AdaDelta_1_v + (1-AdaDelta_v) * mid_grad_1 ** 2\n\n        w3_adadelta = w3_adadelta - mid_grad_3\n        w2_adadelta = w2_adadelta - mid_grad_2\n        w1_adadelta = w1_adadelta - mid_grad_1\n        \n    if e % 1 == 0 :\n        print(\"e:{:2d}. Adadelta - Cost:{:1.3}\".format(e + 1, total_cost))\n\n    cost_temp_array.append(total_cost)\n    total_cost = 0\n    \n# exclude from cost_array due to high cost\n# cost_array.append(cost_temp_array)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 id=\"rmsprop\" style=\"color:blue; border: 1px dotted green;\"> \n    <center>RMSprop\n        <a class=\"anchor-link\" href=\"#rmsprop\" target=\"_self\">¶</a>\n    </center>\n</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"RMSprop_1,RMSprop_2,RMSprop_3 = 0,0,0\nRMSprop_v,RMSprop_e= 0.9,0.00000001\ntotal_cost = 0\ncost_temp_array = []\n\nfor e in range(num_epoch):\n    for i in range(len(X_train)):\n        \n        X = np.expand_dims(X_train[i],axis=0)\n        y = np.expand_dims(np.array([y_train[i]]), axis=1)\n\n        l1 = X.dot(w1_RSMprop)\n        l1A = elu(l1)\n\n        l2 = l1A.dot(w2_RSMprop)\n        l2A = tanh(l2)       \n\n        l3 = l2A.dot(w3_RSMprop)\n        l3A = log(l3)   \n\n        cost = np.square(l3A - y).sum() * 0.5\n        total_cost = total_cost + cost\n\n        grad_3_part_1 = l3A - y\n        grad_3_part_2 = d_log(l3)\n        grad_3_part_3 = l2A\n        grad_3 =     grad_3_part_3.T.dot(grad_3_part_1 * grad_3_part_2)    \n\n        grad_2_part_1 = (grad_3_part_1 * grad_3_part_2).dot(w3_RSMprop.T)\n        grad_2_part_2 = d_tanh(l2)\n        grad_2_part_3 = l1A\n        grad_2 =    grad_2_part_3.T.dot(grad_2_part_1 * grad_2_part_2)\n\n        grad_1_part_1 = (grad_2_part_1 * grad_2_part_2).dot(w2_RSMprop.T)\n        grad_1_part_2 = d_elu(l1)\n        grad_1_part_3 = X\n        grad_1 =   grad_1_part_3.T.dot(grad_1_part_1 *grad_1_part_2)\n\n        RMSprop_3 = RMSprop_v*RMSprop_3 + (1- RMSprop_v)*grad_3**2\n        RMSprop_2 = RMSprop_v*RMSprop_2 + (1- RMSprop_v)*grad_2**2\n        RMSprop_1 = RMSprop_v*RMSprop_1 + (1- RMSprop_v)*grad_1**2\n\n        w3_RSMprop = w3_RSMprop - (learn_rate/np.sqrt(RMSprop_3 + RMSprop_e)) * grad_3\n        w2_RSMprop = w2_RSMprop - (learn_rate/np.sqrt(RMSprop_2 + RMSprop_e)) * grad_2\n        w1_RSMprop = w1_RSMprop - (learn_rate/np.sqrt(RMSprop_1 + RMSprop_e)) * grad_1\n        \n    if e % 1 == 0 :\n        print(\"e:{:2d}. RMSprop - Cost:{:1.3}\".format(e + 1, total_cost))\n        \n    cost_temp_array.append(total_cost)\n    total_cost = 0\n    \ncost_array.append(cost_temp_array)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 id=\"adam\" style=\"color:blue; border: 1px dotted green;\"> \n    <center>Adam\n        <a class=\"anchor-link\" href=\"#adam\" target=\"_self\">¶</a>\n    </center>\n</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"Adam_m_1,Adam_m_2,Adam_m_3 = 0,0,0\nAdam_v_1,Adam_v_2,Adam_v_3 = 0,0,0\nAdam_Beta_1,Adam_Beta_2 = 0.9,0.999\nAdam_e = 0.00000001\ntotal_cost = 0\ncost_temp_array = []\n\nfor e in range(num_epoch):\n    for i in range(len(X_train)):\n        \n        X = np.expand_dims(X_train[i],axis=0)\n        y = np.expand_dims(np.array([y_train[i]]), axis=1)\n\n        l1 = X.dot(w1_adam)\n        l1A = elu(l1)\n\n        l2 = l1A.dot(w2_adam)\n        l2A = tanh(l2)       \n\n        l3 = l2A.dot(w3_adam)\n        l3A = log(l3)   \n\n        cost = np.square(l3A - y).sum() * 0.5\n        total_cost = total_cost + cost\n\n        grad_3_part_1 = l3A - y\n        grad_3_part_2 = d_log(l3)\n        grad_3_part_3 = l2A\n        grad_3 =     grad_3_part_3.T.dot(grad_3_part_1 * grad_3_part_2)    \n\n        grad_2_part_1 = (grad_3_part_1 * grad_3_part_2).dot(w3_adam.T)\n        grad_2_part_2 = d_tanh(l2)\n        grad_2_part_3 = l1A\n        grad_2 =    grad_2_part_3.T.dot(grad_2_part_1 * grad_2_part_2)\n\n        grad_1_part_1 = (grad_2_part_1 * grad_2_part_2).dot(w2_adam.T)\n        grad_1_part_2 = d_elu(l1)\n        grad_1_part_3 = X\n        grad_1 =   grad_1_part_3.T.dot(grad_1_part_1 *grad_1_part_2)\n\n        Adam_m_3 = Adam_Beta_1 * Adam_m_3 + ( 1-Adam_Beta_1 ) *grad_3\n        Adam_m_2 = Adam_Beta_1 * Adam_m_2 + ( 1-Adam_Beta_1 ) *grad_2\n        Adam_m_1 = Adam_Beta_1 * Adam_m_1 + ( 1-Adam_Beta_1 ) *grad_1\n\n        Adam_v_3 = Adam_Beta_2 * Adam_v_3 + ( 1-Adam_Beta_2 ) *grad_3 **2 \n        Adam_v_2 = Adam_Beta_2 * Adam_v_2 + ( 1-Adam_Beta_2 ) *grad_2 **2 \n        Adam_v_1 = Adam_Beta_2 * Adam_v_1 + ( 1-Adam_Beta_2 ) *grad_1 **2 \n        \n        Adam_m_3_hat = Adam_m_3/(1-Adam_Beta_1)\n        Adam_m_2_hat = Adam_m_2/(1-Adam_Beta_1)\n        Adam_m_1_hat = Adam_m_1/(1-Adam_Beta_1)\n        \n        Adam_v_3_hat = Adam_v_3/(1-Adam_Beta_2)\n        Adam_v_2_hat = Adam_v_2/(1-Adam_Beta_2)\n        Adam_v_1_hat = Adam_v_1/(1-Adam_Beta_2)\n        \n        w3_adam = w3_adam - (learn_rate/(np.sqrt(Adam_v_3_hat) + Adam_e)) * Adam_m_3_hat\n        w2_adam = w2_adam - (learn_rate/(np.sqrt(Adam_v_2_hat) + Adam_e)) * Adam_m_2_hat\n        w1_adam = w1_adam - (learn_rate/(np.sqrt(Adam_v_1_hat) + Adam_e)) * Adam_m_1_hat\n        \n    if e % 1 == 0 :\n        print(\"e:{:2d}. Adam - Cost:{:1.3}\".format(e + 1, total_cost))\n        \n    cost_temp_array.append(total_cost)\n    total_cost = 0\n    \ncost_array.append(cost_temp_array)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 id=\"nadam\" style=\"color:blue; border: 1px dotted green;\"> \n    <center>Nadam\n        <a class=\"anchor-link\" href=\"#nadam\" target=\"_self\">¶</a>\n    </center>\n</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"Nadam_m_1,Nadam_m_2,Nadam_m_3 = 0,0,0\nNadam_v_1,Nadam_v_2,Nadam_v_3 = 0,0,0\nNadam_Beta_1,Nadam_Beta_2 = 0.9,0.999\nNadam_e = 0.00000001\ntotal_cost = 0\ncost_temp_array = []\n\nfor e in range(num_epoch):\n    for i in range(len(X_train)):\n        \n        X = np.expand_dims(X_train[i],axis=0)\n        y = np.expand_dims(np.array([y_train[i]]), axis=1)\n\n        l1 = X.dot(w1_nadam)\n        l1A = elu(l1)\n\n        l2 = l1A.dot(w2_nadam)\n        l2A = tanh(l2)       \n\n        l3 = l2A.dot(w3_nadam)\n        l3A = log(l3)   \n\n        cost = np.square(l3A - y).sum() * 0.5\n        total_cost = total_cost + cost\n\n        grad_3_part_1 = l3A - y\n        grad_3_part_2 = d_log(l3)\n        grad_3_part_3 = l2A\n        grad_3 =     grad_3_part_3.T.dot(grad_3_part_1 * grad_3_part_2)    \n\n        grad_2_part_1 = (grad_3_part_1 * grad_3_part_2).dot(w3_nadam.T)\n        grad_2_part_2 = d_tanh(l2)\n        grad_2_part_3 = l1A\n        grad_2 =    grad_2_part_3.T.dot(grad_2_part_1 * grad_2_part_2)\n\n        grad_1_part_1 = (grad_2_part_1 * grad_2_part_2).dot(w2_nadam.T)\n        grad_1_part_2 = d_elu(l1)\n        grad_1_part_3 = X\n        grad_1 =   grad_1_part_3.T.dot(grad_1_part_1 *grad_1_part_2)\n\n        Nadam_m_3 = Nadam_Beta_1 * Nadam_m_3 + (1 - Nadam_Beta_1) * grad_3\n        Nadam_m_2 = Nadam_Beta_1 * Nadam_m_2 + (1 - Nadam_Beta_1) * grad_2\n        Nadam_m_1 = Nadam_Beta_1 * Nadam_m_1 + (1 - Nadam_Beta_1) * grad_1\n        \n        Nadam_v_3 = Nadam_Beta_2 * Nadam_v_3 + (1- Nadam_Beta_2) * grad_3 ** 2\n        Nadam_v_2 = Nadam_Beta_2 * Nadam_v_2 + (1- Nadam_Beta_2) * grad_2 ** 2\n        Nadam_v_1 = Nadam_Beta_2 * Nadam_v_1 + (1- Nadam_Beta_2) * grad_1 ** 2\n\n        Nadam_m_3_hat = Nadam_m_3/ (1 - Nadam_Beta_1)\n        Nadam_m_2_hat = Nadam_m_2/ (1 - Nadam_Beta_1)\n        Nadam_m_1_hat = Nadam_m_1/ (1 - Nadam_Beta_1)\n\n        Nadam_v_3_hat = Nadam_v_3/ (1 - Nadam_Beta_2)\n        Nadam_v_2_hat = Nadam_v_2/ (1 - Nadam_Beta_2)\n        Nadam_v_1_hat = Nadam_v_1/ (1 - Nadam_Beta_2)\n         \n        w3_nadam = w3_nadam - (learn_rate/( np.sqrt(Nadam_v_3_hat) + Nadam_e )) * ( Nadam_Beta_1  * Nadam_m_3_hat + ( ( (1-Nadam_Beta_1) * grad_3 ) / (1 - Nadam_Beta_1)  ) )\n        w2_nadam = w2_nadam - (learn_rate/( np.sqrt(Nadam_v_2_hat) + Nadam_e )) * ( Nadam_Beta_1  * Nadam_m_2_hat + ( ( (1-Nadam_Beta_1) * grad_2 ) / (1 - Nadam_Beta_1)  ) )\n        w1_nadam = w1_nadam - (learn_rate/( np.sqrt(Nadam_v_1_hat) + Nadam_e )) * ( Nadam_Beta_1  * Nadam_m_1_hat + ( ( (1-Nadam_Beta_1) * grad_1 ) / (1 - Nadam_Beta_1)  ) )\n    \n    if e % 1 == 0 :\n        print(\"e:{:2d}. Nadam - Cost:{:1.3}\".format(e + 1, total_cost))\n        \n    cost_temp_array.append(total_cost)\n    total_cost = 0\n    \ncost_array.append(cost_temp_array)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 id=\"sgdnoise\" style=\"color:blue; border: 1px dotted green;\"> \n    <center>SGD with Gaussian Noise\n        <a class=\"anchor-link\" href=\"#sgdnoise\" target=\"_self\">¶</a>\n    </center>\n</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"total_cost = 0\nn_value = 0.001\ncost_temp_array = []\n\nfor e in range(num_epoch):\n    for i in range(len(X_train)):\n        \n        X = np.expand_dims(X_train[i],axis=0)\n        y = np.expand_dims(np.array([y_train[i]]), axis=1)\n\n        l1 = X.dot(w1_sgd_noise)\n        l1A = elu(l1)\n\n        l2 = l1A.dot(w2_sgd_noise)\n        l2A = tanh(l2)       \n\n        l3 = l2A.dot(w3_sgd_noise)\n        l3A = log(l3)   \n\n        cost = np.square(l3A - y).sum() * 0.5\n        total_cost = total_cost + cost\n\n        grad_3_part_1 = l3A - y\n        grad_3_part_2 = d_log(l3)\n        grad_3_part_3 = l2A\n        grad_3 =     grad_3_part_3.T.dot(grad_3_part_1 * grad_3_part_2)    \n\n        grad_2_part_1 = (grad_3_part_1 * grad_3_part_2).dot(w3_sgd_noise.T)\n        grad_2_part_2 = d_tanh(l2)\n        grad_2_part_3 = l1A\n        grad_2 =    grad_2_part_3.T.dot(grad_2_part_1 * grad_2_part_2)\n\n        grad_1_part_1 = (grad_2_part_1 * grad_2_part_2).dot(w2_sgd_noise.T)\n        grad_1_part_2 = d_elu(l1)\n        grad_1_part_3 = X\n        grad_1 =   grad_1_part_3.T.dot(grad_1_part_1 *grad_1_part_2)\n\n        # ------ Calculate The Additive Noise -------\n        ADDITIVE_NOISE_STD = n_value / (np.power((1 + e), 0.55))\n        ADDITIVE_GAUSSIAN_NOISE = np.random.normal(loc=0,scale=ADDITIVE_NOISE_STD)\n        # ------ Calculate The Additive Noise -------\n\n        w3_sgd_noise = w3_sgd_noise - learn_rate* (grad_3 + ADDITIVE_GAUSSIAN_NOISE)\n        w2_sgd_noise = w2_sgd_noise - learn_rate* (grad_2 + ADDITIVE_GAUSSIAN_NOISE)\n        w1_sgd_noise = w1_sgd_noise - learn_rate* (grad_1 + ADDITIVE_GAUSSIAN_NOISE)\n        \n    if e % 1 == 0 :\n        print(\"e:{:2d}. SGD with Gaussian Noise - Cost:{:1.3}\".format(e + 1, total_cost))    \n        \n    cost_temp_array.append(total_cost)\n    total_cost = 0\n    \ncost_array.append(cost_temp_array)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 id=\"noise\" style=\"color:blue; border: 1px dotted green;\"> \n    <center>Noise\n        <a class=\"anchor-link\" href=\"#noise\" target=\"_self\">¶</a>\n    </center>\n</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"total_cost = 0\nn, p = 1, .5 \ncost_temp_array = []\n\nfor e in range(num_epoch):\n    for i in range(len(X_train)):\n        \n        X = np.expand_dims(X_train[i],axis=0)\n        y = np.expand_dims(np.array([y_train[i]]), axis=1)\n\n        l1 = X.dot(w1_noise)\n        l1A = elu(l1)\n\n        l2 = l1A.dot(w2_noise)\n        l2A = tanh(l2)       \n\n        l3 = l2A.dot(w3_noise)\n        l3A = log(l3)   \n\n        cost = np.square(l3A - y).sum() * 0.5\n        total_cost = total_cost + cost\n\n        gradient_weight_3 = np.random.gumbel(size=w3.shape)\n        gradient_weight_2 = np.random.gumbel(size=w2.shape)\n        gradient_weight_1 = np.random.gumbel(size=w1.shape)\n\n        w3_noise = w3_noise - learn_rate* gradient_weight_3\n        w2_noise = w2_noise - learn_rate* gradient_weight_2\n        w1_noise = w1_noise - learn_rate* gradient_weight_1\n    \n    if e % 1 == 0 :\n        print(\"e:{:2d}. Noise - Cost:{:1.3}\".format(e + 1, total_cost))\n        \n    cost_temp_array.append(total_cost)\n    total_cost = 0\n        \ncost_array.append(cost_temp_array)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 id=\"noisenoise\" style=\"color:blue; border: 1px dotted green;\"> \n    <center>Noise + Gaussian Additive Noise\n        <a class=\"anchor-link\" href=\"#noisenoise\" target=\"_self\">¶</a>\n    </center>\n</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"total_cost = 0\ncost_temp_array = []\n\nfor e in range(num_epoch):\n    for i in range(len(X_train)):\n        \n        X = np.expand_dims(X_train[i],axis=0)\n        y = np.expand_dims(np.array([y_train[i]]), axis=1)\n\n        l1 = X.dot(w1_noise_noise)\n        l1A = elu(l1)\n\n        l2 = l1A.dot(w2_noise_noise)\n        l2A = tanh(l2)       \n\n        l3 = l2A.dot(w3_noise_noise)\n        l3A = log(l3)   \n\n        cost = np.square(l3A - y).sum() * 0.5\n        total_cost = total_cost + cost\n\n        gradient_weight_3 = np.random.gumbel(size=w3.shape)\n        gradient_weight_2 = np.random.gumbel(size=w2.shape)\n        gradient_weight_1 = np.random.gumbel(size=w1.shape)\n\n        # ------ Calculate The Additive Noise -------\n        ADDITIVE_NOISE_STD = n_value / (np.power((1 + e), 0.55))\n        ADDITIVE_GAUSSIAN_NOISE = np.random.normal(loc=0,scale=ADDITIVE_NOISE_STD)\n        # ------ Calculate The Additive Noise -------\n\n        w3_noise_noise = w3_noise_noise - learn_rate* (gradient_weight_3 + ADDITIVE_GAUSSIAN_NOISE)\n        w2_noise_noise = w2_noise_noise - learn_rate* (gradient_weight_2 + ADDITIVE_GAUSSIAN_NOISE)\n        w1_noise_noise = w1_noise_noise - learn_rate* (gradient_weight_1 + ADDITIVE_GAUSSIAN_NOISE)\n    \n    if e % 1 == 0 :\n        print(\"e:{:2d}. Noise + Gaussian Noise - Cost:{:1.3}\".format(e + 1, total_cost))\n        \n    cost_temp_array.append(total_cost)\n    total_cost = 0\n\ncost_array.append(cost_temp_array)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 id=\"noiseadam\" style=\"color:blue; border: 1px dotted green;\"> \n    <center>Noise Adam\n        <a class=\"anchor-link\" href=\"#noiseadam\" target=\"_self\">¶</a>\n    </center>\n</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"total_cost = 0\ncost_temp_array = []\nnoise_adam_m1,noise_adam_m2,noise_adam_m3 = 0,0,0\nnoise_adam_v1,noise_adam_v2,noise_adam_v3 = 0,0,0\nnoise_Adam_Beta_1,noise_Adam_Beta_2 = 0.9,0.999\nnoise_Adam_e = 0.00000001\n\nfor e in range(num_epoch):\n    for i in range(len(X_train)):\n        \n        X = np.expand_dims(X_train[i],axis=0)\n        y = np.expand_dims(np.array([y_train[i]]), axis=1)\n\n        l1 = X.dot(w1_noise_adam)\n        l1A = elu(l1)\n\n        l2 = l1A.dot(w2_noise_adam)\n        l2A = tanh(l2)       \n\n        l3 = l2A.dot(w3_noise_adam)\n        l3A = log(l3)   \n\n        cost = np.square(l3A - y).sum() * 0.5\n        total_cost = total_cost + cost\n\n        gradient_weight_3 = np.random.gumbel(size=w3.shape)\n        gradient_weight_2 = np.random.gumbel(size=w2.shape)\n        gradient_weight_1 = np.random.gumbel(size=w1.shape)\n\n        noise_adam_m3 = noise_Adam_Beta_1 * noise_adam_m3 + (1 - noise_Adam_Beta_1) * gradient_weight_3\n        noise_adam_m2 = noise_Adam_Beta_1 * noise_adam_m2 + (1 - noise_Adam_Beta_1) * gradient_weight_2\n        noise_adam_m1 = noise_Adam_Beta_1 * noise_adam_m1 + (1 - noise_Adam_Beta_1) * gradient_weight_1\n        \n        noise_adam_v3 = noise_Adam_Beta_2 * noise_adam_v3 + (1 - noise_Adam_Beta_2) * gradient_weight_3 ** 2\n        noise_adam_v2 = noise_Adam_Beta_2 * noise_adam_v2 + (1 - noise_Adam_Beta_2) * gradient_weight_2 ** 2\n        noise_adam_v1 = noise_Adam_Beta_2 * noise_adam_v1 + (1 - noise_Adam_Beta_2) * gradient_weight_1 ** 2\n\n        noise_adam_m3_hat = noise_adam_m3/(1 -noise_Adam_Beta_1 )\n        noise_adam_m2_hat = noise_adam_m2/(1 -noise_Adam_Beta_1 )\n        noise_adam_m1_hat = noise_adam_m1/(1 -noise_Adam_Beta_1 )\n\n        noise_adam_v3_hat = noise_adam_v3/(1 -noise_Adam_Beta_2 )\n        noise_adam_v2_hat = noise_adam_v2/(1 -noise_Adam_Beta_2 )\n        noise_adam_v1_hat = noise_adam_v1/(1 -noise_Adam_Beta_2 )\n\n        w3_noise_adam = w3_noise_adam - (learn_rate / ( np.sqrt(noise_adam_v3_hat)  +noise_Adam_e )) * noise_adam_m3_hat\n        w2_noise_adam = w2_noise_adam - (learn_rate / ( np.sqrt(noise_adam_v2_hat)  +noise_Adam_e )) * noise_adam_m2_hat\n        w1_noise_adam = w1_noise_adam - (learn_rate / ( np.sqrt(noise_adam_v1_hat)  +noise_Adam_e )) * noise_adam_m1_hat\n\n    if e % 1 == 0 :\n        print(\"e:{:2d}. Noise Adam - Cost:{:1.3}\".format(e + 1, total_cost))\n        \n    cost_temp_array.append(total_cost)\n    total_cost = 0\n    \ncost_array.append(cost_temp_array)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 id=\"analyze\" style=\"color:blue; border: 1px dotted green;\"> \n    <center>Analyze\n        <a class=\"anchor-link\" href=\"#analyze\" target=\"_self\">¶</a>\n    </center>\n</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"bar_color = ['b', 'g', 'saddlebrown', 'steelblue', \n            'orangered', 'y', 'paleturquoise', 'royalblue',\n            'salmon','silver','skyblue','slateblue','peru','plum']\nlabels_z = ['SGD', 'Momentum', 'Nesterov', 'Adagrad', 'RMSprop',\n            'Adam', 'Nadam', 'SGD with Gaussian Noise', 'Noise',\n            'Noise + Gaussian Additive Noise', 'Noise Adam']\n\nplt.figure(figsize=(12, 8))\nfor i in range(len(cost_array)):\n    plt.plot(np.arange(num_epoch), cost_array[i],color=bar_color[i],linewidth=3,label=str(labels_z[i]) )\nplt.title(\"Total Cost per Training\")\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 id=\"reference\" style=\"color:blue; border: 1px dotted green;\"> \n    <center>Reference\n        <a class=\"anchor-link\" href=\"#reference\" target=\"_self\">¶</a>\n    </center>\n</h1>"},{"metadata":{},"cell_type":"markdown","source":"Full credits goes to Jae Duk Seo and his [Medium](https://towardsdatascience.com/only-numpy-implementing-and-comparing-gradient-descent-optimization-algorithms-google-brains-8870b133102b)"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}