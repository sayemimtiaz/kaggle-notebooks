{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"#!/usr/bin/env python3 ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Author: Mbonu Chinedum Endurance \n# Project Name: Hole Deviation Prediction \n# Universty: Nnamdi Azikiwe University \n# Faculty: Engineering \n# Department: Chemical Engineering \n# Date Created: 18/01/2020 ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n## Hole Deviation:\nHole Deviation is the unintentional departure of the drill bit from a preselected borehole trajactory. Whether it involves drilling a straight or curved-hole section. \nThe tendency of the drill bit to walk away from the desired path can lead to drilling problems such as higher drilling costs and also lease-boundary legal problems. \n\n### Causes of hole deviation: \nIt is not exactly known what causes a drill bit to deviate from its uninteded path. it is generally agreed that one or a combination of the following factors may be responsible for    deviation. \n1.  Heterogeneous nature of formation and dip angle \n2.  Drill string characteristics, specifically the bottomehole assemble makeup (BHA) \n3. Applied weight on bit (WOB) \n4. Stabilizers (location, number, clearances) \n5. Hole-inclination angle from the vertical \n6. Hydraulics at the bit \n7. Improper hole cleaning \n\nN/B; It is known that some resultand force acting on a drill bit causes hole deviation to occur. \nThe machanics of this resultand force is complex and it is governed mainly by the mechanics of the bottomhole assemble makeup (BHA). "},{"metadata":{},"cell_type":"markdown","source":"## Exploratory Analysis\nTo begin this exploratory analysis, first use `matplotlib` to import libraries and define functions for plotting the data. Depending on the data, not all plots will be made"},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"# Importing the necessary packages\nimport os \nimport pandas as pd \nimport numpy as np \nimport seaborn as sns \nimport matplotlib.pyplot as plt \nimport plotly.express as px \nimport matplotlib.patches as pathes \nimport plotly.graph_objects as go \nfrom matplotlib.patches import Circle, Wedge, Polygon, Rectangle \nfrom IPython.display import Image \nfrom matplotlib.collections import PathCollection \nfrom matplotlib.ticker import (MultipleLocator, FormatStrFormatter, AutoMinorLocator)\nfrom matplotlib.colors import ListedColormap \nfrom sklearn.preprocessing import StandardScaler \nfrom scipy.cluster.hierarchy import fcluster \nfrom sklearn.pipeline import make_pipeline \nfrom sklearn.cluster import KMeans \nfrom sklearn import preprocessing \nfrom plotly.subplots import make_subplots \nfrom imblearn.over_sampling import SMOTE \nfrom tensorflow.keras.models import Sequential \nfrom tensorflow.keras.layers import Dense \nfrom mpl_toolkits.mplot3d import Axes3D\nfrom sklearn.preprocessing import StandardScaler\n\n# Setting some basic parameters for the analysis \nsmote = SMOTE(random_state = 33)\n%matplotlib inline ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"# Loading the dataset into memory \n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# Specifying the path to the well log dataset \ndataset_path = '/kaggle/input/well_log.csv'\n\n# Reading the well log dataset into memroy \ndf = pd.read_csv(dataset_path)\ndf = df.drop('Unnamed: 0', axis = 1)\n# viewing the head of the dataset \ndf.head() ","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# # Distribution graphs (histogram/bar graph) of column data\n# def plotPerColumnDistribution(df, nGraphShown, nGraphPerRow):\n#     nunique = df.nunique()\n#     df = df[[col for col in df if nunique[col] > 1 and nunique[col] < 50]] # For displaying purposes, pick columns that have between 1 and 50 unique values\n#     nRow, nCol = df.shape\n#     columnNames = list(df)\n#     nGraphRow = (nCol + nGraphPerRow - 1) / nGraphPerRow\n#     plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * nGraphRow), dpi = 80, facecolor = 'w', edgecolor = 'k')\n#     for i in range(min(nCol, nGraphShown)):\n#         plt.subplot(nGraphRow, nGraphPerRow, i + 1)\n#         columnDf = df.iloc[:, i]\n#         if (not np.issubdtype(type(columnDf.iloc[0]), np.number)):\n#             valueCounts = columnDf.value_counts()\n#             valueCounts.plot.bar()\n#         else:\n#             columnDf.hist()\n#         plt.ylabel('counts')\n#         plt.xticks(rotation = 90)\n#         plt.title(f'{columnNames[i]} (column {i})')\n#     plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)\n#     plt.show()\n\n# plotPerColumnDistribution(df, 100, 100)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Correlation matrix\ndef plotCorrelationMatrix(df, graphWidth):\n    filename = df.columns\n    df = df.dropna('columns') # drop columns with NaN\n    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values\n    if df.shape[1] < 2:\n        print(f'No correlation plots shown: The number of non-NaN or constant columns ({df.shape[1]}) is less than 2')\n        return\n    corr = df.corr()\n    plt.figure(num=None, figsize=(graphWidth, graphWidth), dpi=80, facecolor='w', edgecolor='k')\n    corrMat = plt.matshow(corr, fignum = 1)\n    plt.xticks(range(len(corr.columns)), corr.columns, rotation=90)\n    plt.yticks(range(len(corr.columns)), corr.columns)\n    plt.gca().xaxis.tick_bottom()\n    plt.colorbar(corrMat)\n    plt.title(f'Correlation Matrix for {filename}', fontsize=15)\n    plt.show()\n\nplotCorrelationMatrix(df, 20)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Scatter and density plots\ndef plotScatterMatrix(df, plotSize, textSize):\n    df = df.select_dtypes(include =[np.number]) # keep only numerical columns\n    # Remove rows and columns that would lead to df being singular\n    df = df.dropna('columns')\n    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values\n    columnNames = list(df)\n    if len(columnNames) > 10: # reduce the number of columns for matrix inversion of kernel density plots\n        columnNames = columnNames[:10]\n    df = df[columnNames]\n    ax = pd.plotting.scatter_matrix(df, alpha=0.75, figsize=[plotSize, plotSize], diagonal='kde')\n    corrs = df.corr().values\n    for i, j in zip(*plt.np.triu_indices_from(ax, k = 1)):\n        ax[i, j].annotate('Corr. coef = %.3f' % corrs[i, j], (0.8, 0.2), xycoords='axes fraction', ha='center', va='center', size=textSize)\n    plt.suptitle('Scatter and Density Plot')\n    plt.show()\n\nplotScatterMatrix(df, 20, 7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Displaying the unique values for the classification class  \n# Here, 0 stands for Non-deviated class, while 1 stands for Deviated class \nclassified_label = df['Classification'].unique()\nprint('The labels are: {}'.format(classified_label))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converting the columns into numpy arrays \ndepth = df['Depth'].values \ngamma_ray = df['Gamma-ray'].values \nshale_volume = df['Shale_Volume'].values\nrestivity = df['Restivity'].values \nDelta_t = df['Delta T'].values \nvp = df['Vp'].values \nvs = df['Vs'].values \ndensity = df['Density'].values \ndensity_calculated = df['Density_Calculated'].values \nneuron_porosity = df['Neuron_Porosity'].values \ndensity_porosity = df['Density_Porosity'].values \npossion_ratio = df['Possions_Ratio'].values \nclassification = df['Classification'].values \n\n# making 11 column and only 1 row \nfig = make_subplots(rows=1, cols=9)\n\n# plotting the graph of Gamma ray against depth \nfig.append_trace(go.Scatter(\n    x=gamma_ray,\n    y=depth,\n    name='Gamma-Ray',\n), row=1, col=1)\n# plotting the graph of shale volume against depth \nfig.append_trace(go.Scatter(\n    x=shale_volume,\n    y=depth,\n    name='Shale_Volume',\n), row=1, col=2)\n# plotting the graph of resitivity against depth \nfig.append_trace(go.Scatter(\n    x=restivity,\n    y=depth, \n    name='Restivity', \n), row=1, col=3)\n# plotting the graph of temperature against depth \nfig.append_trace(go.Scatter(\n    x=Delta_t, \n    y=depth,\n    name='Temperature', \n), row=1, col=4)\n# plotting the graph of velocity against depth \nfig.append_trace(go.Scatter(\n    x=vp, \n    y=depth,\n    name='Velocity', \n), row=1, col=5)\n# plotting the graph of density against depth \nfig.append_trace(go.Scatter(\n    x=density, \n    y=depth,\n    name='Density', \n), row=1, col=6)\n# plotting the graph of neuron_porosity against depth \nfig.append_trace(go.Scatter(\n    x=neuron_porosity, \n    y=depth, \n    name='Neuron Porosity',\n),  row=1, col=7)\n# plotting the graph of possion_ratio against depth \nfig.append_trace(go.Scatter(\n    x=possion_ratio, \n    y=depth, \n    name='Possion Ratio',\n),  row=1, col=8)\n# plotting the graph of classification against depth \nfig.append_trace(go.Scatter(\n    x=classification, \n    y=depth, \n    name='Hole Deviation',\n),  row=1, col=9)\n\n# showing the plots in a horizontal order\nfig.update_layout(height=1000, width=1300, title_text=\"Well Log Exploratory Data Analysis\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Displaying the count for the Deviated class \nmajority_class = df.loc[df['Classification'] == 1].count()[0]\n\n# Showing the count for Non Hole Deviation \nminority_class = df.loc[df['Classification'] == 0].count()[0]\n\n# Printing the classes for the deviated and non-deviated class \nprint('Deviated Class: {}'.format(majority_class))\nprint('Non Deviated Class: {}'.format(minority_class))\n\n# Plotting a graph of the total count for the deviated and Non deviated class \ndegree_count = df['Classification'].value_counts() \nplt.figure(figsize = (20, 8)) \ndegree_count.plot(kind='bar') \nplt.xlabel('0 : Non-Deviated,  1 : Deviated')\nplt.ylabel('Counts')\nplt.title('Imbalanced Classification of Hole Deviation')\nplt.grid(True) \nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# specifying the input variable as the input features X and converting \n# it into a numpy array \nX = df[['Depth', 'Gamma-ray', 'Shale_Volume', 'Restivity', 'Delta T', 'Vs', 'Density', 'Density_Porosity', 'Possions_Ratio']]\nX = X.values \n# specifying the output variable as an output feature y and converting  \n# it into a numpy array \ny = df.iloc[:, -1]\n\n# standardize the data \nfrom sklearn.preprocessing import StandardScaler \nscaler = StandardScaler() \nX = scaler.fit_transform(X)\n\n# Using SMOTE to Balance the imbalanced data \nX, y = smote.fit_sample(X, y.ravel())\n\nfrom sklearn.model_selection import train_test_split \nX_train, X_test, y_train, y_test = train_test_split(X, y)\n\n# showing a plot of the Balanced dataset \nplt.figure(figsize = (20, 8)) \npd.Series(y).value_counts().plot.bar() \nplt.grid(True)\nplt.title('Balanced Dataset')\nplt.xlabel('0 = Non-deviated, 1 = Deviated')\nplt.ylabel('Counts')\nplt.show() \n\n# Prining the counts of the Balanced Data \nprint('Deviated Class: {}'.format(pd.Series(y).value_counts()[0]))\nprint('Non-Deviated Class: {}'.format(pd.Series(y).value_counts()[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Displaying the shape of the input and output data   \nprint('Input Shape: {}'.format(X.shape))\nprint('Output Shape: {}'.format(y.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Model Building\nA multilayer perceptron (MLP) is a class of feedforward artificial neural network (ANN). The term MLP is used ambiguously, sometimes loosely to refer to any feedforward artifical neural network, sometimes strictly to refer to networks composed of multiple layers of perceptrons also with a threshold activation."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Building An MLP \nmodel = Sequential() \nmodel.add(Dense(32, input_dim = X_train.shape[1], activation = 'relu'))\nmodel.add(Dense(8, activation = 'relu'))\nmodel.add(Dense(1, activation = 'sigmoid'))\nmodel.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n\n# Model summary \nmodel.summary() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training the model \nhist = model.fit(X_train, y_train, epochs = 100, batch_size = 4, validation_data = (X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaulating the model accuracy  \naccuracy = model.evaluate(X_test, y_test)[1] * 100 \naccuracy = str(accuracy)[:5]\n!echo \nprint('The model is {}% Accurate.'.format(accuracy))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# showing a plot of how Accurate the model is against the \n# test dataset\nplt.figure(figsize=(20, 8))\nplt.grid(True)\nplt.plot(hist.history['accuracy'])\nplt.plot(hist.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Val'], loc='lower right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# showing a plot of the loss with respect to the number of epochs \nplt.figure(figsize=(20, 8))\nplt.grid(True)\nplt.plot(hist.history['loss'])\nplt.plot(hist.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Val'], loc='upper right')\nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Making Predictions "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Viewing the tail of the well log datast \ndf.tail() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Specifying the input parameters to be fed into the neural net trained model \n# for accurate predictions. \n['Depth', 'Gamma-ray', 'Shale_Volume', 'Restivity', 'Delta T',\n'Vs', 'Density', 'Density_Porosity', 'Possions_Ratio']\n\n# Creating the input features for predictions \nnew_input = ['4300', '38.885', '0.2750', '0.70', '111.28', '4320.6076', \n            '2.1866', '0.2687', '0.3497']\n\n# Reshaping and converting into a numpy array \nnew_input = np.array(new_input).reshape(1, -1)\n\n# Using the min max scalar to fit the new input feature and printing its input shape \nnew_input = scaler.transform(new_input)\nprint('Shape of Input Data: {}'.format(new_input.shape))\n\n# Performing prediction on the new input dataset and displaying the predicted target variable \npredicted = model.predict(new_input)[0][0]\nprint('The Predicted Classification is : {}'.format(predicted))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}