{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport PIL\nimport tensorflow as tf\nimport pathlib\nimport ipywidgets as widgets\nimport io\n\nfrom IPython.display import Javascript\nfrom PIL import Image\nfrom ipywidgets import interact\nfrom PIL import ImageShow\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Download Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_path = \"../input/bee-images-separated/bee_imgs\"\ndata_dir = pathlib.Path(dataset_path)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create Dataset\nValidation split splits the images into 80% for training and 20% for validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 32\nimg_height = 180\nimg_width = 180\n\ntrain_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    data_dir,\n    validation_split=0.2,\n    subset=\"training\",\n    seed=123,\n    image_size=(img_height, img_width),\n    batch_size=batch_size\n)\n\nval_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    data_dir,\n    validation_split=0.2,\n    subset=\"validation\",\n    seed=123,\n    image_size=(img_height, img_width),\n    batch_size=batch_size\n)\n\nclass_names = train_ds.class_names","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Configure Dataset\ndataset.cache(): keeps images in memory after they're loaded off the disk for the first epoch\n<br>dataset.prefetch(): overlaps data preprocessing and model execution while training"},{"metadata":{"trusted":true},"cell_type":"code","source":"AUTOTUNE = tf.data.experimental.AUTOTUNE\n\ntrain_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\nval_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Standardize Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"normalization_layer = layers.experimental.preprocessing.Rescaling(1./255)\n\nnormalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\nimage_batch, labels_batch = next(iter(normalized_ds))\nfirst_image = image_batch[0]\nprint(np.min(first_image), np.max(first_image))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create Model\nConsists of three convolutional blocks with each having a max pooling layer\n<br>The fully connected layer is activated by the ReLU function"},{"metadata":{"trusted":true},"cell_type":"code","source":"num_classes = 6\n\nmodel = Sequential([\n  layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n  layers.Conv2D(16, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Conv2D(32, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Conv2D(64, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Flatten(),\n  layers.Dense(128, activation='relu'),\n  layers.Dense(num_classes)\n])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Compile Data\nUse Adam optimizer and the Sparse Categorical Croessentropy loss function"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs=10\nhistory = model.fit(\n  train_ds,\n  validation_data=val_ds,\n  epochs=epochs\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Save Model\nSave in output to be saved for later allowing for overwriting and to use an optimizer."},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save(\"./\", True, True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predict on New Data"},{"metadata":{},"cell_type":"markdown","source":"Upload a new image to be analyzed"},{"metadata":{"trusted":true},"cell_type":"code","source":"uploader = widgets.FileUpload(\n    accept='.png, .jpg',  # Accepted file extension e.g. '.txt', '.pdf', 'image/*', 'image/*,.pdf'\n    multiple=False  # True to accept multiple files upload else False\n)\ndisplay(uploader)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def run_all(ev):\n    display(Javascript('IPython.notebook.execute_cells_below()'))\n\nbutton = widgets.Button(description=\"Analyze Next Image\")\nbutton.on_click(run_all)\ndisplay(button)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After the image has been uploaded, save it to output directory and display image back to user"},{"metadata":{"trusted":true},"cell_type":"code","source":"img_name=\"\"\n#save the uploaded image to a folder\nfor name, file_info in uploader.value.items():\n    img = Image.open(io.BytesIO(file_info['content']))\n    img_name = name\n    with open(name, 'wb') as fp:\n        fp.write(file_info['content'])\n\nbee_img = './' + img_name\n\n\n#display chosen image back to user\n#PIL.Image.open(bee_img)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Display Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"if img_name == \"\":\n    bee_img = \"../input/bee-images-separated/bee_imgs/ants/013_008.png\"\n\nimg = keras.preprocessing.image.load_img(\n    bee_img, target_size=(img_height, img_width)\n)\n\nimg_array = keras.preprocessing.image.img_to_array(img)\nimg_array = tf.expand_dims(img_array, 0) # Create a batch\n\npredictions = model.predict(img_array)\nscore = tf.nn.softmax(predictions[0])\n\nprint(\n    \"This image most likely belongs to the category {} with a {:.2f} percent confidence.\"\n    .format(class_names[np.argmax(score)], 100 * np.max(score))\n)\n\n\n\nPIL.Image.open(bee_img)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}