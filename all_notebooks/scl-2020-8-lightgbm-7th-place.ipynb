{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Changelog\n\n## Version 23\n\n* Final hyperparameter tuning\n* Use 3, 5 & 10 StratifiedKFold\n\n## Version 21\n\n* Tuning LightGBM parameter from version 20 result\n    * lambda pair : [0.0, 0.0], [0.001, 0.01], [0.01, 0.1], [0.01, 1.0], [1.0, 0.01]\n* Try different boosting_type\n* Change formula for weighted ensemble mean\n* Use 3 & 5 StratifiedKFold\n\n## Version 20\n\n* Tuning LightGBM parameter from version 18 result\n* Stop using validation data\n\n## Version 18\n\n* Tuning LightGBM parameter from version 16 result\n    * num_leaves : 63\n    * min_data_in_leaf : 20, 50\n    * bagging_fraction : **no diff**\n    * feature_fraction : 0.9, 1.0\n    * max_bin : 16, 102, 255\n    * min_data_per_group : 1\n* Use validation data to reduce overfit\n\n## Version 16\n\n* Tuning LightGBM parameter from version 15 result\n    * boosting_type : gbdt\n    * n_estimators : 100\n    * LR : 0.01\n    * num_leaves : 31, 63\n    * min_data_in_leaf : 20, 50\n\n## Version 15\n\n* Make submission for all mode\n* Fix dump `df_model`\n* Remove `age` from category feature\n\n## Version 13\n\n* Tuning LightGBM parameter\n* Add additional preprocessing\n* Add EDA\n\n## Version 10\n\n* Add additional preprocessing\n\n## Version 9\n\n* Use StratifiedKFold 3, 5, 10\n* Combine parameter from verison 4 & 5\n* Use mean and mode to predict data\n\n## Version 5\n\n* Use MCC score\n* Visualize LightGBM tree\n* Use different processed dataset\n* Specify categorical feature\n* Tweak parameter\n\n## Version 4\n\n* Attempt fix overfit\n* Tweak class weight\n\n## Version 2\n\n* Fix wrong row\n* Lower `max_bin` 255 -> 64\n* Increase `num_iterations` 5000 -> 10000\n\n## Version 1\n\n* Initial Code","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Library","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport random\nimport platform\nimport itertools\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport sklearn\nimport lightgbm as lgbm\nimport scipy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip freeze > requirements.txt","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"print('Python version:', platform.python_version())\nprint('Numpy version:', np.__version__)\nprint('Pandas version:', pd.__version__)\nprint('Matplotlib version:', matplotlib.__version__)\nprint('Seaborn version:', sns.__version__)\nprint('Scikit-Learn version:', sklearn.__version__)\nprint('LightGBM version:', lgbm.__version__)\nprint('Scipy version:', scipy.__version__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SEED = 42\n\nos.environ['PYTHONHASHSEED']=str(SEED)\nrandom.seed(SEED)\nnp.random.seed(SEED)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.width', None)\npd.set_option('display.max_column', None)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_parquet('/kaggle/input/shopee-marketing-data/train_processed.parquet')\ndf_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = pd.read_parquet('/kaggle/input/shopee-marketing-data/test_processed.parquet')\ndf_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# preprocessing","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 1. Timedate","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['day'] = pd.to_datetime(df_train['grass_date']).dt.dayofweek.astype('category')\ndf_test['day'] = pd.to_datetime(df_test['grass_date']).dt.dayofweek.astype('category')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del df_train['grass_date']\ndel df_test['grass_date']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Anomaly","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def fix_age(age):\n    if age < 18 or age >= 100:\n        return np.nan\n    else:\n        return age\n    \ndf_train['age'] = df_train['age'].apply(fix_age)\ndf_test['age'] = df_test['age'].apply(fix_age)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. NaN","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# # last_open_day\n# df_train['last_open_day_nan'] = df_train['last_open_day'].isnull()\n# df_train['last_open_day'] = df_train['last_open_day'].fillna(-1)\n\n# df_test['last_open_day_nan'] = df_test['last_open_day'].isnull()\n# df_test['last_open_day'] = df_test['last_open_day'].fillna(-1)\n\n# # last_login_day\n# df_train['last_login_day_nan'] = df_train['last_login_day'].isnull()\n# df_train['last_login_day'] = df_train['last_login_day'].fillna(-1)\n\n# df_test['last_login_day_nan'] = df_test['last_login_day'].isnull()\n# df_test['last_login_day'] = df_test['last_login_day'].fillna(-1)\n\n# # last_checkout_day\n# df_train['last_checkout_day_nan'] = df_train['last_checkout_day'].isnull()\n# df_train['last_checkout_day'] = df_train['last_checkout_day'].fillna(-1)\n\n# df_test['last_checkout_day_nan'] = df_test['last_checkout_day'].isnull()\n# df_test['last_checkout_day'] = df_test['last_checkout_day'].fillna(-1)\n\n# # attr_1\n# df_train['attr_1_nan'] = df_train['attr_1'].isnull()\n# df_train['attr_1'] = df_train['attr_1'].fillna(-1)\n\n# df_test['attr_1_nan'] = df_test['attr_1'].isnull()\n# df_test['attr_1'] = df_test['attr_1'].fillna(-1)\n\n# # attr_2\n# df_train['attr_2_nan'] = df_train['attr_2'].isnull()\n# df_train['attr_2'] = df_train['attr_2'].fillna(-1)\n\n# df_test['attr_2_nan'] = df_test['attr_2'].isnull()\n# df_test['attr_2'] = df_test['attr_2'].fillna(-1)\n\n# # attr_3\n# df_train['attr_3_nan'] = df_train['attr_3'].isnull()\n# df_train['attr_3'] = df_train['attr_3'].fillna(-1)\n\n# df_test['attr_3_nan'] = df_test['attr_3'].isnull()\n# df_test['attr_3'] = df_test['attr_3'].fillna(-1)\n\n# # age\n# df_train['age_nan'] = df_train['age'].isnull()\n# df_train['age'] = df_train['age'].fillna(-1)\n\n# df_test['age_nan'] = df_test['age'].isnull()\n# df_test['age'] = df_test['age'].fillna(-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# domain\n# 1 -> 'other' domain from previous preprocessing\n# df_train['domain_nan'] = df_train['domain'].isnull()\ndf_train['domain'] = df_train['domain'].fillna(1)\n\n# df_test['domain_nan'] = df_test['domain'].isnull()\ndf_test['domain'] = df_test['domain'].fillna(1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4. Misc","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df_train.copy()\ndel X['open_flag']\n\nX_test = df_test.copy()\n\ny = df_train['open_flag'].to_numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_feature = [\n    'country_code','attr_1', 'attr_2', 'attr_3',\n    'domain','day',\n#     'last_open_day_nan', 'last_login_day_nan',\n#     'last_checkout_day_nan', 'attr_1_nan', 'attr_2_nan',\n#     'attr_3_nan', 'age_nan', 'domain_nan',\n    \n]\ncat_feature_idx = [X.columns.get_loc(ct) for ct in cat_feature]\ncat_feature_idx","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import matthews_corrcoef\n\nK = [3, 5, 10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"param_dict = {\n    'learning_rate': [0.0075, 0.01, 0.0125],\n    'min_data_in_leaf': [20, 50],\n    'max_bin': [16, 102, 255],\n    'lambda': [\n        # l1, l2\n        [0.0, 0.0],\n        [0.001, 0.01],\n        [0.01, 0.1],\n        [1.0, 0.01],\n    ],\n    'n_estimators': [100, 125, 150]\n}\nparam_key = list(param_dict.keys())\nparam_item = list(param_dict.values())\nparam_item","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"param_list = list(itertools.product(*param_item))\nparam_list[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(param_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_model = pd.DataFrame(columns=[*param_key, *[f'model_{i}' for i in range(sum(K))], *[f'model_{i}_mcc' for i in range(sum(K))], 'average_mcc'])\ndf_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"skf_list = [StratifiedKFold(n_splits=k, shuffle=True, random_state=SEED) for k in K]\n\nfor param in param_list:\n    ctr = 0\n    model = []\n    mcc_score = []\n    for skf in skf_list:\n        for train_idx, val_idx in skf.split(X, y):\n            X_train, X_val = X.loc[train_idx], X.loc[val_idx]\n            y_train, y_val = y[train_idx], y[val_idx]\n\n            model.append(\n                lgbm.LGBMClassifier(\n                    # fixed\n                    is_unbalance=True,\n                    seed=SEED,\n                    extra_trees=True,\n\n                    min_data_per_group=1,\n                    boosting_type='goss',\n                    num_leaves=63,\n                    feature_fraction=0.9,\n                    # variable\n                    learning_rate=param[0],\n                    min_data_in_leaf=param[1],\n                    max_bin=param[2], \n                    lambda_l1=param[3][0],\n                    lambda_l2=param[3][1],\n                    n_estimators=param[4],\n                )\n            )\n            model[ctr].fit(\n                X_train, y_train,\n                categorical_feature=cat_feature_idx\n            )\n\n            y_val_pred = model[ctr].predict(X_val)\n            mcc_score.append(matthews_corrcoef(y_val, y_val_pred))\n\n            ctr += 1\n    df_model.loc[ df_model.shape[0] ] = [\n        *param,\n        *model,\n        *mcc_score,\n        sum(mcc_score) / len(mcc_score)\n    ]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluate","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_model = df_model.sort_values(by=['average_mcc', 'learning_rate'], ascending=[False, True]).reset_index(drop=True)\ndf_model.loc[:1000].to_pickle('model.pkl')\n!ls -lah","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_row', df_model.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_row', 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report, f1_score, confusion_matrix, precision_score, matthews_corrcoef\n\ndef predict(X, mode='best_mean'):\n    if mode == 'best_mode':\n        y_preds = []\n        for i in range(sum(K)):\n            y_preds.append(df_model.loc[0, f'model_{i}'].predict(X))\n        y_preds = np.array(y_preds)\n        y_preds = scipy.stats.mode(y_preds)\n        y_preds = y_preds[0]\n        y_preds = y_preds.reshape(-1)\n    elif mode == 'best_mean':\n        y_preds = []\n        for i in range(sum(K)):\n            y_preds.append(df_model.loc[0, f'model_{i}'].predict_proba(X))\n        y_preds = np.mean(np.array(y_preds), axis=0)\n        y_preds = np.argmax(y_preds, axis=-1)\n    elif mode == 'ensemble_mode':\n        y_preds = []\n        for i in df_model.index:\n            for j in range(sum(K)):\n                y_preds.append(df_model.loc[i, f'model_{j}'].predict(X))\n        y_preds = np.array(y_preds)\n        y_preds = scipy.stats.mode(y_preds)\n        y_preds = y_preds[0]\n        y_preds = y_preds.reshape(-1)\n    elif mode == 'ensemble_mean':\n        y_preds = []\n        for i in df_model.index:\n            for j in range(sum(K)):\n                y_preds.append(df_model.loc[i, f'model_{j}'].predict_proba(X))\n        y_preds = np.mean(np.array(y_preds), axis=0)\n        y_preds = np.argmax(y_preds, axis=-1)\n    elif mode == 'weighted_ensemble_mean':\n        y_preds = []\n#         model_weight = df_model['average_mcc'].apply(lambda a: a/df_model['average_mcc'].sum())\n        model_weight = []\n        for i in df_model.index:\n            model_weight.append(1 + np.log10(df_model.shape[0] - i + 1))\n        print(model_weight[:10])\n        for i in df_model.index:\n            for j in range(sum(K)):\n                y_preds.append(\n                    df_model.loc[i, f'model_{j}'].predict_proba(X) *\n                    model_weight[i]\n                )\n        y_preds = np.array(y_preds)\n        y_preds = np.mean(y_preds, axis=0)\n        y_preds = np.argmax(y_preds, axis=-1)\n    else:\n        raise ValueError(\"Mode isn't supported\")\n    \n    return y_preds\n\ndef metrics(y_true, y_pred):\n    print('Weighted F1 Score :', f1_score(y_true, y_pred, average='weighted'))\n    print('MCC Score :', matthews_corrcoef(y_true, y_pred))\n    cm = confusion_matrix(y_true, y_pred)\n    cm = pd.DataFrame(cm, [0, 1], [0, 1])\n\n    sns.heatmap(cm, annot=True, cmap=\"YlGnBu\", fmt=\"d\")\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred = predict(X_train, mode='best_mode')\nmetrics(y_train, y_train_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred2 = predict(X_train, mode='best_mean')\nmetrics(y_train, y_train_pred2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred3 = predict(X_train, mode='ensemble_mode')\nmetrics(y_train, y_train_pred3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred4 = predict(X_train, mode='ensemble_mean')\nmetrics(y_train, y_train_pred4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred5 = predict(X_train, mode='weighted_ensemble_mean')\nmetrics(y_train, y_train_pred5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Test","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test_pred = predict(X_test, mode='best_mode')\n\ndf_submission = pd.concat([pd.Series(list(range(0, len(X_test))), name='row_id', dtype=np.int32), pd.Series(y_test_pred, name='open_flag')], axis=1)\ndf_submission.to_csv('submission_best_mode.csv', index=False)\n\ndf_submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test_pred2 = predict(X_test, mode='best_mean')\n\ndf_submission = pd.concat([pd.Series(list(range(0, len(X_test))), name='row_id', dtype=np.int32), pd.Series(y_test_pred2, name='open_flag')], axis=1)\ndf_submission.to_csv('submission_best_mean.csv', index=False)\n\ndf_submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test_pred3 = predict(X_test, mode='ensemble_mode')\n\ndf_submission = pd.concat([pd.Series(list(range(0, len(X_test))), name='row_id', dtype=np.int32), pd.Series(y_test_pred3, name='open_flag')], axis=1)\ndf_submission.to_csv('submission_ensemble_mode.csv', index=False)\n\ndf_submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test_pred4 = predict(X_test, mode='ensemble_mean')\n\ndf_submission = pd.concat([pd.Series(list(range(0, len(X_test))), name='row_id', dtype=np.int32), pd.Series(y_test_pred4, name='open_flag')], axis=1)\ndf_submission.to_csv('submission_ensemble_mean.csv', index=False)\n\ndf_submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test_pred5 = predict(X_test, mode='weighted_ensemble_mean')\n\ndf_submission = pd.concat([pd.Series(list(range(0, len(X_test))), name='row_id', dtype=np.int32), pd.Series(y_test_pred5, name='open_flag')], axis=1)\ndf_submission.to_csv('submission_weighted_ensemble_mean.csv', index=False)\n\ndf_submission","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualize","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"lgbm.plot_importance(df_model.loc[0, 'model_0'], ignore_zero=False, figsize=(16,9))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgbm.plot_split_value_histogram(df_model.loc[0, 'model_0'], 2)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}