{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<footer id=\"footer\"></footer>","metadata":{"id":"QNOxZAMC75AD"}},{"cell_type":"markdown","source":"# Cleaned Toxic Comments with stacking","metadata":{"id":"npH1wChQ75AE"}},{"cell_type":"markdown","source":"![](https://i.ibb.co/pjcBRMR/bbc87fcc-3bb9-422a-a925-60ae8f17b019.jpg)","metadata":{"id":"5XGMByv475AE"}},{"cell_type":"markdown","source":"Discussing things you care about can be difficult. The threat of abuse and harassment online means that many people stop expressing themselves and give up on seeking different opinions. Platforms struggle to effectively facilitate conversations, leading many communities to limit or completely shut down user comments.\n\nWe have several target features, but let us work only with toxic in this data because of kernel limits.\n\n\n**It is just a baseline for beginners, thank you for reading and also you can see the stacking technique for classification and downsampling**\n\nNote: Dataset contains toxic vocabulary","metadata":{"id":"2m_9qEJs75AF"}},{"cell_type":"markdown","source":"## Preprocessing","metadata":{"id":"yO9SRKYY75AJ"}},{"cell_type":"markdown","source":"### Imports","metadata":{"id":"EECiPmEg75AJ"}},{"cell_type":"code","source":"%%capture\n!pip install transformers;","metadata":{"id":"k0xzyIPoj4qd","execution":{"iopub.status.busy":"2021-08-05T00:24:07.851204Z","iopub.execute_input":"2021-08-05T00:24:07.851953Z","iopub.status.idle":"2021-08-05T00:24:16.981873Z","shell.execute_reply.started":"2021-08-05T00:24:07.851829Z","shell.execute_reply":"2021-08-05T00:24:16.98048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%capture\n!pip install wordcloud;","metadata":{"id":"YK5OK1rL75AK","scrolled":true,"execution":{"iopub.status.busy":"2021-08-05T00:24:16.983902Z","iopub.execute_input":"2021-08-05T00:24:16.984258Z","iopub.status.idle":"2021-08-05T00:24:24.216138Z","shell.execute_reply.started":"2021-08-05T00:24:16.98422Z","shell.execute_reply":"2021-08-05T00:24:24.214212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%capture\n!pip install tqdm;","metadata":{"id":"zSO7mtzw75AK","execution":{"iopub.status.busy":"2021-08-05T00:24:24.218851Z","iopub.execute_input":"2021-08-05T00:24:24.219741Z","iopub.status.idle":"2021-08-05T00:24:31.396791Z","shell.execute_reply.started":"2021-08-05T00:24:24.219647Z","shell.execute_reply":"2021-08-05T00:24:31.395433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport re\n\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.linear_model import SGDClassifier, LogisticRegression\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import f1_score, accuracy_score\nfrom sklearn.utils import shuffle\n\n\nimport torch\nimport transformers\nfrom wordcloud import WordCloud\n\n\nimport warnings\nimport seaborn as sns\nfrom tqdm import notebook\nfrom tqdm import tqdm\n\nsns.set_style('darkgrid')\nnltk.download('punkt')\nnltk.download('wordnet')\nwarnings.filterwarnings('ignore')\nnltk.download('stopwords')\nstopwords = set(stopwords.words('english'))\n\nnp.random.seed(42)","metadata":{"id":"WJFNN90HOvyj","outputId":"f32ed9ff-7016-43a6-fea1-e1ec36bd9758","execution":{"iopub.status.busy":"2021-08-05T00:24:31.399163Z","iopub.execute_input":"2021-08-05T00:24:31.399552Z","iopub.status.idle":"2021-08-05T00:24:35.207108Z","shell.execute_reply.started":"2021-08-05T00:24:31.399516Z","shell.execute_reply":"2021-08-05T00:24:35.20574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Downloading data and review","metadata":{"id":"aUTVMeFRozE2"}},{"cell_type":"code","source":"train = pd.read_csv('../input/cleaned-toxic-comments/train_preprocessed.csv')\ntrain.drop(['set', 'id', 'toxicity'], axis=1, inplace=True)\ndisplay(train.head())\ndisplay(train.columns)","metadata":{"id":"NZ3aAMkUPGv6","outputId":"91cdbb3a-175a-464c-e82c-96d5b661a7de","execution":{"iopub.status.busy":"2021-08-05T00:24:35.20892Z","iopub.execute_input":"2021-08-05T00:24:35.209401Z","iopub.status.idle":"2021-08-05T00:24:36.914448Z","shell.execute_reply.started":"2021-08-05T00:24:35.20935Z","shell.execute_reply":"2021-08-05T00:24:36.91333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"the column `comment_text` contains the text of the comment, and `identity_hate`, `insult`, `obscene`, `severe_toxic`, `threat`, `toxic` — target features\n\nCheck the gaps","metadata":{"id":"YvXdSs9P75AN"}},{"cell_type":"code","source":"train.isna().mean()","metadata":{"id":"MM0f8_c5PLQL","outputId":"4f925254-f3c7-4696-b8de-fb9bbbcb132e","execution":{"iopub.status.busy":"2021-08-05T00:24:36.916099Z","iopub.execute_input":"2021-08-05T00:24:36.91653Z","iopub.status.idle":"2021-08-05T00:24:36.952419Z","shell.execute_reply.started":"2021-08-05T00:24:36.916483Z","shell.execute_reply":"2021-08-05T00:24:36.951052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"id":"-e-SKCb-Pc_m","outputId":"2ba4bc3d-79b5-48e1-a2f5-e4457e227032","execution":{"iopub.status.busy":"2021-08-05T00:24:36.953872Z","iopub.execute_input":"2021-08-05T00:24:36.954194Z","iopub.status.idle":"2021-08-05T00:24:37.000611Z","shell.execute_reply.started":"2021-08-05T00:24:36.954163Z","shell.execute_reply":"2021-08-05T00:24:36.999511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The dataset contains 159571 lines, the data types correspond to the desired ones","metadata":{"id":"1iuaPCiC75AN"}},{"cell_type":"code","source":"train.duplicated().sum()","metadata":{"id":"iM1UB8H7PgzJ","outputId":"bb6387d8-6888-4bca-a960-3af0b134c267","execution":{"iopub.status.busy":"2021-08-05T00:24:37.004244Z","iopub.execute_input":"2021-08-05T00:24:37.004744Z","iopub.status.idle":"2021-08-05T00:24:37.235023Z","shell.execute_reply.started":"2021-08-05T00:24:37.004693Z","shell.execute_reply":"2021-08-05T00:24:37.233981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For convenience, we will convert the text to lower case","metadata":{"id":"13L1grbg75AO"}},{"cell_type":"code","source":"train['comment_text'] = train['comment_text'].str.lower()","metadata":{"id":"4Uyay4hHVn1V","execution":{"iopub.status.busy":"2021-08-05T00:24:37.237174Z","iopub.execute_input":"2021-08-05T00:24:37.237478Z","iopub.status.idle":"2021-08-05T00:24:37.451812Z","shell.execute_reply.started":"2021-08-05T00:24:37.237449Z","shell.execute_reply":"2021-08-05T00:24:37.450816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"id":"WkTQPpGvVtSa","outputId":"544a1577-2af3-4ca0-c0f6-42bbd138ce73","execution":{"iopub.status.busy":"2021-08-05T00:24:37.453354Z","iopub.execute_input":"2021-08-05T00:24:37.453877Z","iopub.status.idle":"2021-08-05T00:24:37.472886Z","shell.execute_reply.started":"2021-08-05T00:24:37.453819Z","shell.execute_reply":"2021-08-05T00:24:37.471463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols = ['identity_hate', 'insult', 'obscene', 'severe_toxic', 'threat', 'toxic']\nfor col in cols:\n  display(train[col].value_counts(normalize=True))","metadata":{"id":"OJG72ZHA0FAE","outputId":"aab5b77b-d61e-417f-b001-86d437fa03c7","execution":{"iopub.status.busy":"2021-08-05T00:24:37.474599Z","iopub.execute_input":"2021-08-05T00:24:37.474987Z","iopub.status.idle":"2021-08-05T00:24:37.539579Z","shell.execute_reply.started":"2021-08-05T00:24:37.474951Z","shell.execute_reply":"2021-08-05T00:24:37.53864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Conclusion:** Primary transformations were made, checked for gaps and duplicates. we observe an imbalance in the target class","metadata":{"id":"eehu7ukH75AO"}},{"cell_type":"markdown","source":"We need to transform the text, get tokens, and also clear lines of characters. We will make the transformations through the function and library `nltk` and` re`","metadata":{"id":"t-J6hyjQ75AP"}},{"cell_type":"code","source":"def text_preprocessing(text):\n    tokenized = nltk.word_tokenize(text)\n    joined = ' '.join(tokenized)\n    text_only = re.sub(r\"[^a-z0-9!@#\\$%\\^\\&\\*_\\-,\\.' ]\", ' ', joined)\n    final = ' '.join(text_only.split())\n    return final","metadata":{"id":"2WEGEIgLQlo9","execution":{"iopub.status.busy":"2021-08-05T00:24:37.540973Z","iopub.execute_input":"2021-08-05T00:24:37.541269Z","iopub.status.idle":"2021-08-05T00:24:37.545887Z","shell.execute_reply.started":"2021-08-05T00:24:37.541242Z","shell.execute_reply":"2021-08-05T00:24:37.545039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tqdm.pandas() \ntrain['token_text'] = train['comment_text'].progress_apply(text_preprocessing)","metadata":{"id":"HKk-CzzDPxES","outputId":"320139a8-bc99-4449-b621-c0a8519424b6","execution":{"iopub.status.busy":"2021-08-05T00:24:37.547176Z","iopub.execute_input":"2021-08-05T00:24:37.547481Z","iopub.status.idle":"2021-08-05T00:26:25.320887Z","shell.execute_reply.started":"2021-08-05T00:24:37.547451Z","shell.execute_reply":"2021-08-05T00:26:25.319754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We got tokens of words, we can continue working with the set","metadata":{"id":"yO2XdUvI75AP"}},{"cell_type":"code","source":"corpus_lemm = train['token_text']","metadata":{"id":"4Fzp5rb9VU-K","execution":{"iopub.status.busy":"2021-08-05T00:26:25.322465Z","iopub.execute_input":"2021-08-05T00:26:25.322804Z","iopub.status.idle":"2021-08-05T00:26:25.327349Z","shell.execute_reply.started":"2021-08-05T00:26:25.322771Z","shell.execute_reply":"2021-08-05T00:26:25.326295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corpus_lemm[0]","metadata":{"id":"v1fFoUTW3m7X","outputId":"1d8c4ce6-5c9f-4fc7-9565-f5c5a2957a7c","execution":{"iopub.status.busy":"2021-08-05T00:26:25.328699Z","iopub.execute_input":"2021-08-05T00:26:25.328996Z","iopub.status.idle":"2021-08-05T00:26:25.342358Z","shell.execute_reply.started":"2021-08-05T00:26:25.328968Z","shell.execute_reply":"2021-08-05T00:26:25.341415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Received a body for further processing","metadata":{"id":"e6UytlON75AQ"}},{"cell_type":"code","source":"x, y = np.ogrid[:300, :300]\n\nmask = (x - 150) ** 2 + (y - 150) ** 2 > 150 ** 2\nmask = 255 * mask.astype(int)\n\nwc = WordCloud(background_color=\"white\", \n               random_state=42, mask=mask, repeat=True,\n               stopwords=stopwords).generate(corpus_lemm[0])\n\nplt.figure(figsize=(15, 10), dpi=42)\nplt.imshow(wc, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","metadata":{"id":"vnVbv8A-YnWt","outputId":"af80731f-61aa-41a5-f8d1-a23ee484c9b8","execution":{"iopub.status.busy":"2021-08-05T00:26:25.343796Z","iopub.execute_input":"2021-08-05T00:26:25.344116Z","iopub.status.idle":"2021-08-05T00:26:26.054727Z","shell.execute_reply.started":"2021-08-05T00:26:25.344085Z","shell.execute_reply":"2021-08-05T00:26:26.053505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Conclusion:** Transformed the dataset and got word lemmas. In the word cloud, the most common words are explanation, dolls, edits - let's try to train the models to predict the toxicity of the text.\n\nWe going to use an Random Forest and SGD classifier, and we will also use the Distilbert to obtain and predict embeddings - perhaps we will be able to improve the results of the basic models and also we will try stacking\n\nTo speed up the DistillBERT learning process without GPU, only a part of the dataset will be transmitted, which should have a definite effect on the result. Also we will use only toxic target","metadata":{"id":"z9I5szAM75AR"}},{"cell_type":"markdown","source":"## Model training","metadata":{"id":"R8Zjje-k75AR"}},{"cell_type":"markdown","source":"there is a strong class imbalance. Let's try to go in two ways:\n\n- train the model on the network using **downsampling**\n- train the model with the parameter **class_weight = 'balanced'**","metadata":{"id":"tG-viHtA75AS"}},{"cell_type":"markdown","source":"### Preparing characteristics","metadata":{"id":"xbViK1Tz75AS"}},{"cell_type":"markdown","source":"\nLet's select from the set date the target feature and the training feature - the text","metadata":{"id":"HFv9LQda75AS"}},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-05T00:26:26.056289Z","iopub.execute_input":"2021-08-05T00:26:26.056941Z","iopub.status.idle":"2021-08-05T00:26:26.077868Z","shell.execute_reply.started":"2021-08-05T00:26:26.05689Z","shell.execute_reply":"2021-08-05T00:26:26.076828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = train['token_text']\ntarget = train['toxic']","metadata":{"id":"MPS77C2z3RtM","execution":{"iopub.status.busy":"2021-08-05T00:26:26.0795Z","iopub.execute_input":"2021-08-05T00:26:26.079952Z","iopub.status.idle":"2021-08-05T00:26:26.09065Z","shell.execute_reply.started":"2021-08-05T00:26:26.079906Z","shell.execute_reply":"2021-08-05T00:26:26.089613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Divide our set to test and train","metadata":{"id":"g7QekrSr75AS"}},{"cell_type":"code","source":"features_train, features_test, target_train, target_test = train_test_split(\n    features, target, test_size=0.25, random_state=42)","metadata":{"id":"zQLb1IO875AS","execution":{"iopub.status.busy":"2021-08-05T00:26:26.092082Z","iopub.execute_input":"2021-08-05T00:26:26.092704Z","iopub.status.idle":"2021-08-05T00:26:26.135607Z","shell.execute_reply.started":"2021-08-05T00:26:26.092643Z","shell.execute_reply":"2021-08-05T00:26:26.134602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's write a function that allows you to achieve a balance of the class, through downsampling","metadata":{"id":"tP9ljJ2o75AS"}},{"cell_type":"code","source":"def downsample(features, target, fraction):\n    features_zeros = features[target == 0]\n    features_ones = features[target == 1]\n    target_zeros = target[target == 0]\n    target_ones = target[target == 1]\n\n    features_sample = features_zeros.sample(frac=0.1, random_state=42)\n    target_sample = target_zeros.sample(frac=0.1, random_state=42)\n    \n    features_downsampled = pd.concat([features_sample] + [features_ones])\n    target_downsampled = pd.concat([target_sample] + [target_ones])\n    \n    features_downsampled = shuffle(features_downsampled, random_state=42)\n    target_downsampled = shuffle(target_downsampled, random_state=42)\n    \n    return features_downsampled, target_downsampled","metadata":{"id":"6Ye3NjeV28lK","execution":{"iopub.status.busy":"2021-08-05T00:26:26.137099Z","iopub.execute_input":"2021-08-05T00:26:26.137538Z","iopub.status.idle":"2021-08-05T00:26:26.145246Z","shell.execute_reply.started":"2021-08-05T00:26:26.137496Z","shell.execute_reply":"2021-08-05T00:26:26.144423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will receive new sets","metadata":{"id":"fViK2yED75AT"}},{"cell_type":"code","source":"features_downsampled, target_downsampled = downsample(features_train, target_train, 0.1)\n\nprint(features_downsampled.shape)\nprint(target_downsampled.shape)","metadata":{"id":"LmxocO7075AT","execution":{"iopub.status.busy":"2021-08-05T00:26:26.14644Z","iopub.execute_input":"2021-08-05T00:26:26.146986Z","iopub.status.idle":"2021-08-05T00:26:26.196865Z","shell.execute_reply.started":"2021-08-05T00:26:26.146951Z","shell.execute_reply":"2021-08-05T00:26:26.195879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_downsampled.value_counts(normalize=True)","metadata":{"id":"nIycaavL3ki0","execution":{"iopub.status.busy":"2021-08-05T00:26:26.198325Z","iopub.execute_input":"2021-08-05T00:26:26.198766Z","iopub.status.idle":"2021-08-05T00:26:26.208103Z","shell.execute_reply.started":"2021-08-05T00:26:26.198719Z","shell.execute_reply":"2021-08-05T00:26:26.20718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The imbalance is insignificant, with such a set, you can try to train the model. First, let's get the TD-IDF measure for the new set.","metadata":{"id":"H_ud_lkU75AT"}},{"cell_type":"code","source":"count_tf_idf = TfidfVectorizer(stop_words=stopwords)\ntf_idf = count_tf_idf.fit_transform(features_downsampled)\n\nprint(\"Learning Matrix Size:\", tf_idf.shape)","metadata":{"id":"yRhVwfSL4hXI","execution":{"iopub.status.busy":"2021-08-05T00:26:26.213309Z","iopub.execute_input":"2021-08-05T00:26:26.213785Z","iopub.status.idle":"2021-08-05T00:26:27.820197Z","shell.execute_reply.started":"2021-08-05T00:26:26.213733Z","shell.execute_reply":"2021-08-05T00:26:27.818876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name = []\nfscore = []","metadata":{"id":"2k_6e8jj75AT","execution":{"iopub.status.busy":"2021-08-05T00:26:27.823644Z","iopub.execute_input":"2021-08-05T00:26:27.824064Z","iopub.status.idle":"2021-08-05T00:26:27.827897Z","shell.execute_reply.started":"2021-08-05T00:26:27.824028Z","shell.execute_reply":"2021-08-05T00:26:27.82713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training a random forest with downsampling","metadata":{"id":"jQcOR6qw75AT"}},{"cell_type":"markdown","source":"\nTrain an ensemble of models using the downsampling technique","metadata":{"id":"QKNJvEI775AT"}},{"cell_type":"code","source":"X_train_ans = tf_idf\ny_train_ans = target_downsampled","metadata":{"id":"PhUuCQWg4zbz","execution":{"iopub.status.busy":"2021-08-05T00:26:27.828922Z","iopub.execute_input":"2021-08-05T00:26:27.829346Z","iopub.status.idle":"2021-08-05T00:26:27.842695Z","shell.execute_reply.started":"2021-08-05T00:26:27.829313Z","shell.execute_reply":"2021-08-05T00:26:27.841618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nrnd_clf = RandomForestClassifier(n_estimators=10, random_state=42)\n\n\n\nX_test_ans = count_tf_idf.transform(features_test)\n\nrnd_clf.fit(X_train_ans, y_train_ans)\npredict = rnd_clf.predict(X_test_ans)\nf_score = f1_score(predict, target_test)\n\nprint('{}'.format(f_score))","metadata":{"id":"R_iiOfls4nnY","execution":{"iopub.status.busy":"2021-08-05T00:26:27.844168Z","iopub.execute_input":"2021-08-05T00:26:27.844504Z","iopub.status.idle":"2021-08-05T00:26:37.122943Z","shell.execute_reply.started":"2021-08-05T00:26:27.844474Z","shell.execute_reply":"2021-08-05T00:26:37.121878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"F1 measure is not good, the model converges poorly on the test - let's try learning without downsampling with class balance and SGD\n","metadata":{"id":"G5XOiM8j75AU"}},{"cell_type":"code","source":"model_name.append(str(rnd_clf.__class__.__name__)+str(' ')+str('downsampling)'))\nfscore.append(round(f_score, 2))","metadata":{"id":"geeZRRgM75AU","execution":{"iopub.status.busy":"2021-08-05T00:26:37.124314Z","iopub.execute_input":"2021-08-05T00:26:37.124662Z","iopub.status.idle":"2021-08-05T00:26:37.129664Z","shell.execute_reply.started":"2021-08-05T00:26:37.124629Z","shell.execute_reply":"2021-08-05T00:26:37.128569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training a random forest without downsampling","metadata":{"id":"GZCu9ecGA7T7"}},{"cell_type":"markdown","source":"Let's train a model based on the same ensemble, but instead of a balanced set, we use the basic lemmatized one and set the class weight as balanced and set mode estimators","metadata":{"id":"R63Gm_HI75AU"}},{"cell_type":"code","source":"count_tf = TfidfVectorizer(stop_words=stopwords)\ntf_idf_new = count_tf.fit_transform(features_train)","metadata":{"id":"p8dQ-Zmq75AU","execution":{"iopub.status.busy":"2021-08-05T00:26:37.131222Z","iopub.execute_input":"2021-08-05T00:26:37.131865Z","iopub.status.idle":"2021-08-05T00:26:46.47044Z","shell.execute_reply.started":"2021-08-05T00:26:37.131817Z","shell.execute_reply":"2021-08-05T00:26:46.469468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nX_train = tf_idf_new\ny_train = target_train\n\nX_test = count_tf.transform(features_test)\n\n\nrnd_clf = RandomForestClassifier(n_estimators=10, random_state=42, \n                            class_weight='balanced')\n\n\n\nrnd_clf.fit(X_train, y_train)\npredict_new = rnd_clf.predict(X_test)","metadata":{"id":"pfx3oeqSBYHU","execution":{"iopub.status.busy":"2021-08-05T00:26:46.471837Z","iopub.execute_input":"2021-08-05T00:26:46.472142Z","iopub.status.idle":"2021-08-05T00:28:23.491444Z","shell.execute_reply.started":"2021-08-05T00:26:46.472112Z","shell.execute_reply":"2021-08-05T00:28:23.490345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f_score = f1_score(predict_new, target_test)\nprint(f_score)","metadata":{"id":"qvnnTLQzIeUr","execution":{"iopub.status.busy":"2021-08-05T00:28:23.493013Z","iopub.execute_input":"2021-08-05T00:28:23.49342Z","iopub.status.idle":"2021-08-05T00:28:23.521489Z","shell.execute_reply.started":"2021-08-05T00:28:23.493376Z","shell.execute_reply":"2021-08-05T00:28:23.520274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\nWith this approach, we have decreased F1-measure","metadata":{"id":"Rw7x_5zV75AU"}},{"cell_type":"code","source":"model_name.append(str(rnd_clf.__class__.__name__)+str(' ')+str('class_weight balanced'))\nfscore.append(round(f_score, 2))","metadata":{"id":"R3CYcgTS75AU","execution":{"iopub.status.busy":"2021-08-05T00:28:23.522969Z","iopub.execute_input":"2021-08-05T00:28:23.523341Z","iopub.status.idle":"2021-08-05T00:28:23.529194Z","shell.execute_reply.started":"2021-08-05T00:28:23.523306Z","shell.execute_reply":"2021-08-05T00:28:23.527812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train SGD model with downsampling","metadata":{"id":"8IpXZhrsItBF"}},{"cell_type":"markdown","source":"Let's try the stochastic gradient descent model with downsampling","metadata":{"id":"_APhmliP75AU"}},{"cell_type":"code","source":"count_tf_idf = TfidfVectorizer(stop_words=stopwords)\ntf_idf = count_tf_idf.fit_transform(features_downsampled)\n\nprint(\"Matrix size:\", tf_idf.shape)","metadata":{"id":"LIZDKPqNDxCJ","execution":{"iopub.status.busy":"2021-08-05T00:28:23.53084Z","iopub.execute_input":"2021-08-05T00:28:23.531281Z","iopub.status.idle":"2021-08-05T00:28:25.12599Z","shell.execute_reply.started":"2021-08-05T00:28:23.53123Z","shell.execute_reply":"2021-08-05T00:28:25.124859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = tf_idf\ny_train = target_downsampled","metadata":{"id":"wM2wK4MoDxCN","execution":{"iopub.status.busy":"2021-08-05T00:28:25.127446Z","iopub.execute_input":"2021-08-05T00:28:25.128083Z","iopub.status.idle":"2021-08-05T00:28:25.132857Z","shell.execute_reply.started":"2021-08-05T00:28:25.128039Z","shell.execute_reply":"2021-08-05T00:28:25.131616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sgb_clf = SGDClassifier(l1_ratio=0.1, random_state=42,\n                            class_weight='balanced')","metadata":{"id":"sO6LJj0hECQE","execution":{"iopub.status.busy":"2021-08-05T00:28:25.13418Z","iopub.execute_input":"2021-08-05T00:28:25.134482Z","iopub.status.idle":"2021-08-05T00:28:25.145961Z","shell.execute_reply.started":"2021-08-05T00:28:25.134454Z","shell.execute_reply":"2021-08-05T00:28:25.144577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nsgb_clf.fit(X_train, y_train)\n\nX_test = count_tf_idf.transform(features_test)\n\npredict = sgb_clf.predict(X_test)\nf_score = f1_score(predict, target_test)\nprint(f_score)","metadata":{"id":"Q9Mg6BDEEErl","execution":{"iopub.status.busy":"2021-08-05T00:28:25.147469Z","iopub.execute_input":"2021-08-05T00:28:25.147988Z","iopub.status.idle":"2021-08-05T00:28:28.095351Z","shell.execute_reply.started":"2021-08-05T00:28:25.147938Z","shell.execute_reply":"2021-08-05T00:28:28.094173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The result is better then forest (but in forest we use only 10 estimators)","metadata":{"id":"3Cp7Lw1P75AV"}},{"cell_type":"code","source":"model_name.append(str(sgb_clf.__class__.__name__)+str(' ')+str('class_weight balanced'))\nfscore.append(round(f_score, 2))","metadata":{"id":"9oEEngY575AV","execution":{"iopub.status.busy":"2021-08-05T00:28:28.09658Z","iopub.execute_input":"2021-08-05T00:28:28.096896Z","iopub.status.idle":"2021-08-05T00:28:28.10251Z","shell.execute_reply.started":"2021-08-05T00:28:28.096865Z","shell.execute_reply":"2021-08-05T00:28:28.101178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Stacking with Random forest","metadata":{}},{"cell_type":"markdown","source":"Let us try stacking via Sklearn models - RandomForestClassifier, SGDClassifier and MLP  \nWe need validation set","metadata":{}},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(\n    features_train, target_train, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-08-05T00:28:28.103585Z","iopub.execute_input":"2021-08-05T00:28:28.103931Z","iopub.status.idle":"2021-08-05T00:28:28.13624Z","shell.execute_reply.started":"2021-08-05T00:28:28.103898Z","shell.execute_reply":"2021-08-05T00:28:28.135188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now use TD-IDF for all three sets","metadata":{}},{"cell_type":"code","source":"count_tf = TfidfVectorizer(stop_words=stopwords)\nX_train_idf = count_tf.fit_transform(X_train)\nX_val_idf = count_tf.transform(X_val)\nX_test = count_tf.transform(features_test)","metadata":{"execution":{"iopub.status.busy":"2021-08-05T00:28:28.137614Z","iopub.execute_input":"2021-08-05T00:28:28.137937Z","iopub.status.idle":"2021-08-05T00:28:40.193576Z","shell.execute_reply.started":"2021-08-05T00:28:28.137906Z","shell.execute_reply":"2021-08-05T00:28:40.192679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will use three base models - RandomForestClassifier, SGDClassifier and MLP, then we will blend our predictions with RandomForestClassifier","metadata":{}},{"cell_type":"code","source":"random_forest_clf = RandomForestClassifier(n_estimators=10, random_state=42, \n                                           class_weight='balanced')\nsgd_clf = SGDClassifier(l1_ratio=0.1, random_state=42,\n                            class_weight='balanced')\nmlp_clf = MLPClassifier(random_state=42, early_stopping=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-05T00:28:40.19501Z","iopub.execute_input":"2021-08-05T00:28:40.195422Z","iopub.status.idle":"2021-08-05T00:28:40.201044Z","shell.execute_reply.started":"2021-08-05T00:28:40.195379Z","shell.execute_reply":"2021-08-05T00:28:40.200249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"estimators = [random_forest_clf, sgd_clf, mlp_clf]\nfor estimator in estimators:\n    print('Training', estimator)\n    estimator.fit(X_train_idf, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-08-05T00:28:40.202052Z","iopub.execute_input":"2021-08-05T00:28:40.202388Z","iopub.status.idle":"2021-08-05T00:47:56.131114Z","shell.execute_reply.started":"2021-08-05T00:28:40.202358Z","shell.execute_reply":"2021-08-05T00:47:56.130246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the predictions let us make new trainig set for our meta model - blender","metadata":{}},{"cell_type":"code","source":"X_val_predictions = np.empty((X_val_idf.shape[0], len(estimators)), dtype=np.float32)\n\nfor index, estimator in enumerate(estimators):\n    X_val_predictions[:, index] = estimator.predict(X_val_idf)\nX_val_predictions","metadata":{"execution":{"iopub.status.busy":"2021-08-05T00:47:56.132106Z","iopub.execute_input":"2021-08-05T00:47:56.132506Z","iopub.status.idle":"2021-08-05T00:47:56.510972Z","shell.execute_reply.started":"2021-08-05T00:47:56.132476Z","shell.execute_reply":"2021-08-05T00:47:56.509898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rnd_forest_blender = RandomForestClassifier(n_estimators=50, oob_score=True, random_state=42)\nrnd_forest_blender.fit(X_val_predictions, y_val)","metadata":{"execution":{"iopub.status.busy":"2021-08-05T00:47:56.512533Z","iopub.execute_input":"2021-08-05T00:47:56.513148Z","iopub.status.idle":"2021-08-05T00:47:56.898309Z","shell.execute_reply.started":"2021-08-05T00:47:56.513103Z","shell.execute_reply":"2021-08-05T00:47:56.897249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rnd_forest_blender.oob_score_","metadata":{"execution":{"iopub.status.busy":"2021-08-05T00:47:56.899592Z","iopub.execute_input":"2021-08-05T00:47:56.899941Z","iopub.status.idle":"2021-08-05T00:47:56.906094Z","shell.execute_reply.started":"2021-08-05T00:47:56.89991Z","shell.execute_reply":"2021-08-05T00:47:56.905285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we can predict our test and see the F1-measure","metadata":{}},{"cell_type":"code","source":"X_test_predictions = np.empty((X_test.shape[0], len(estimators)), dtype=np.float32)\n\nfor index, estimator in enumerate(estimators):\n    X_test_predictions[:, index] = estimator.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-08-05T00:47:56.907284Z","iopub.execute_input":"2021-08-05T00:47:56.907762Z","iopub.status.idle":"2021-08-05T00:47:57.578473Z","shell.execute_reply.started":"2021-08-05T00:47:56.907726Z","shell.execute_reply":"2021-08-05T00:47:57.577321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\ny_pred = rnd_forest_blender.predict(X_test_predictions)\nf_score = f1_score(y_pred, target_test)\nprint(f_score)","metadata":{"execution":{"iopub.status.busy":"2021-08-05T00:47:57.580202Z","iopub.execute_input":"2021-08-05T00:47:57.580699Z","iopub.status.idle":"2021-08-05T00:47:57.750299Z","shell.execute_reply.started":"2021-08-05T00:47:57.580642Z","shell.execute_reply":"2021-08-05T00:47:57.749278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"we have an improvement here with stacking","metadata":{}},{"cell_type":"code","source":"model_name.append(str(rnd_forest_blender.__class__.__name__)+str(' ')+str('Stacking Ensemble'))\nfscore.append(round(f_score, 2))","metadata":{"execution":{"iopub.status.busy":"2021-08-05T00:47:57.751521Z","iopub.execute_input":"2021-08-05T00:47:57.751848Z","iopub.status.idle":"2021-08-05T00:47:57.757149Z","shell.execute_reply.started":"2021-08-05T00:47:57.751816Z","shell.execute_reply":"2021-08-05T00:47:57.756075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train DistillBert","metadata":{"id":"Eaw-LDsHIxyp"}},{"cell_type":"markdown","source":"To train the model with pretraining using DistillBERT, we will build a new set, balanced, since we will have to transfer an order of magnitude fewer rows for training, which is not an entirely adequate performance estimate","metadata":{"id":"CRIIFtS075AV"}},{"cell_type":"markdown","source":"Let's create samples for DistillBERT and remove the class imbalance in the training sample. ","metadata":{"id":"4mBm9RYa75AV"}},{"cell_type":"code","source":"features = train['comment_text']\ntarget = train['toxic']\n\nfeatures_train, features_test, target_train, target_test = train_test_split(\n    features, target, test_size=0.25, random_state=42)\n\nfeatures_downsampled, target_downsampled = downsample(features_train, target_train, 0.1)\n\ntarget_downsampled.value_counts(normalize=True).to_frame()","metadata":{"id":"27qLXxvF75AV","execution":{"iopub.status.busy":"2021-08-05T00:47:57.758374Z","iopub.execute_input":"2021-08-05T00:47:57.75871Z","iopub.status.idle":"2021-08-05T00:47:57.927132Z","shell.execute_reply.started":"2021-08-05T00:47:57.758629Z","shell.execute_reply":"2021-08-05T00:47:57.926096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's create a set from the training balanced sample, remove duplicates from it and take a sample of 1000 values","metadata":{"id":"0b8HFvjB75AW"}},{"cell_type":"code","source":"df_bert = features_downsampled.to_frame().join(\n    target_downsampled.to_frame())\ndf_bert.head()","metadata":{"id":"pAuPX9Ek75AW","execution":{"iopub.status.busy":"2021-08-05T00:47:57.92857Z","iopub.execute_input":"2021-08-05T00:47:57.928907Z","iopub.status.idle":"2021-08-05T00:47:57.953999Z","shell.execute_reply.started":"2021-08-05T00:47:57.928877Z","shell.execute_reply":"2021-08-05T00:47:57.953224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_bert.duplicated().sum()","metadata":{"id":"SttaL8wU75AW","execution":{"iopub.status.busy":"2021-08-05T00:47:57.955178Z","iopub.execute_input":"2021-08-05T00:47:57.955712Z","iopub.status.idle":"2021-08-05T00:47:57.993751Z","shell.execute_reply.started":"2021-08-05T00:47:57.955664Z","shell.execute_reply":"2021-08-05T00:47:57.992764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_bert.drop_duplicates(inplace=True)\ndf_bert.duplicated().sum()","metadata":{"id":"sABdyIms75AW","execution":{"iopub.status.busy":"2021-08-05T00:47:57.99686Z","iopub.execute_input":"2021-08-05T00:47:57.997171Z","iopub.status.idle":"2021-08-05T00:47:58.063938Z","shell.execute_reply.started":"2021-08-05T00:47:57.997139Z","shell.execute_reply":"2021-08-05T00:47:58.062936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_bert[df_bert.index == 115222]","metadata":{"id":"ZpRQweWs75AW","execution":{"iopub.status.busy":"2021-08-05T00:47:58.06533Z","iopub.execute_input":"2021-08-05T00:47:58.06568Z","iopub.status.idle":"2021-08-05T00:47:58.077199Z","shell.execute_reply.started":"2021-08-05T00:47:58.06563Z","shell.execute_reply":"2021-08-05T00:47:58.076091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Thus, we got a new set, from which we will take slices, while deleting all duplicates, checking one index in order to make sure that the set was assembled adequately","metadata":{"id":"bJuuid8q75AW"}},{"cell_type":"code","source":"df_comm = df_bert.sample(1000).reset_index(\n    drop=True)\ndf_comm.head()","metadata":{"id":"R-6R0DkBgTdt","execution":{"iopub.status.busy":"2021-08-05T00:47:58.078423Z","iopub.execute_input":"2021-08-05T00:47:58.07882Z","iopub.status.idle":"2021-08-05T00:47:58.097073Z","shell.execute_reply.started":"2021-08-05T00:47:58.078786Z","shell.execute_reply":"2021-08-05T00:47:58.095681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_comm['toxic'].value_counts(normalize=True).to_frame()","metadata":{"id":"x9ZSqLbA2oY3","execution":{"iopub.status.busy":"2021-08-05T00:47:58.098383Z","iopub.execute_input":"2021-08-05T00:47:58.098731Z","iopub.status.idle":"2021-08-05T00:47:58.111622Z","shell.execute_reply.started":"2021-08-05T00:47:58.098699Z","shell.execute_reply":"2021-08-05T00:47:58.110518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We got a fairly balanced sample.\n\nWe transform our signs in order to obtain embeddings","metadata":{"id":"LtDW9Fo175AW"}},{"cell_type":"code","source":"configuration = transformers.DistilBertConfig()\nmodel = transformers.DistilBertModel(configuration)\nconfiguration = model.config\n\npretrained_weights = 'distilbert-base-uncased'\n\ntokenizer_class = transformers.DistilBertTokenizer","metadata":{"id":"z0D7ND_-75AW","execution":{"iopub.status.busy":"2021-08-05T00:47:58.112929Z","iopub.execute_input":"2021-08-05T00:47:58.113259Z","iopub.status.idle":"2021-08-05T00:48:04.996397Z","shell.execute_reply.started":"2021-08-05T00:47:58.113227Z","shell.execute_reply":"2021-08-05T00:48:04.995337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It is worth noting that the model is trained to work with sentences up to 512 characters. It is necessary to cut our offers if they exceed this limit. It can also affect the results","metadata":{"id":"Z0cvSYtB75AW"}},{"cell_type":"code","source":"tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n\ntokenized = df_comm['comment_text'].apply(\n    lambda x: tokenizer.encode(x[:512], add_special_tokens=True))\n\npadded = np.array([i + [0]*(512 - len(i)) for i in tokenized.values])\n\nattention_mask = np.where(padded != 0, 1, 0)","metadata":{"id":"UAXwdVosgvVt","execution":{"iopub.status.busy":"2021-08-05T00:48:04.997759Z","iopub.execute_input":"2021-08-05T00:48:04.998071Z","iopub.status.idle":"2021-08-05T00:48:14.652436Z","shell.execute_reply.started":"2021-08-05T00:48:04.998042Z","shell.execute_reply":"2021-08-05T00:48:14.651684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(padded[0])","metadata":{"id":"V6Aa2uBY36XP","execution":{"iopub.status.busy":"2021-08-05T00:48:14.653564Z","iopub.execute_input":"2021-08-05T00:48:14.653938Z","iopub.status.idle":"2021-08-05T00:48:14.659957Z","shell.execute_reply.started":"2021-08-05T00:48:14.653904Z","shell.execute_reply":"2021-08-05T00:48:14.658753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"padded.shape, attention_mask.shape","metadata":{"id":"fsULiGD675AX","execution":{"iopub.status.busy":"2021-08-05T00:48:14.661302Z","iopub.execute_input":"2021-08-05T00:48:14.661604Z","iopub.status.idle":"2021-08-05T00:48:14.679317Z","shell.execute_reply.started":"2021-08-05T00:48:14.661574Z","shell.execute_reply":"2021-08-05T00:48:14.67816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 100\nembeddings = []\nfor i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n        batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)]) \n        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n        \n        with torch.no_grad():\n            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n        \n        \n        embeddings.append(batch_embeddings[0][:,0,:].numpy())","metadata":{"id":"iMb8tYYfg1D-","execution":{"iopub.status.busy":"2021-08-05T00:48:14.682615Z","iopub.execute_input":"2021-08-05T00:48:14.682956Z","iopub.status.idle":"2021-08-05T01:00:07.428451Z","shell.execute_reply.started":"2021-08-05T00:48:14.682925Z","shell.execute_reply":"2021-08-05T01:00:07.426945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create training and target datasets for our model","metadata":{"id":"zEL6I1So75AX"}},{"cell_type":"code","source":"X_train = np.concatenate(embeddings)\ny_train = df_comm['toxic'][:padded.shape[0]]","metadata":{"id":"98jIov54g2Yf","execution":{"iopub.status.busy":"2021-08-05T01:00:07.430438Z","iopub.execute_input":"2021-08-05T01:00:07.430842Z","iopub.status.idle":"2021-08-05T01:00:07.463459Z","shell.execute_reply.started":"2021-08-05T01:00:07.430799Z","shell.execute_reply":"2021-08-05T01:00:07.462296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will check visually whether the target classes were selected correctly","metadata":{"id":"KGDfMIv_75AX"}},{"cell_type":"code","source":"y_train.values[:50]","metadata":{"id":"PZbtiewN75AX","execution":{"iopub.status.busy":"2021-08-05T01:00:07.46452Z","iopub.execute_input":"2021-08-05T01:00:07.464855Z","iopub.status.idle":"2021-08-05T01:00:07.473819Z","shell.execute_reply.started":"2021-08-05T01:00:07.464822Z","shell.execute_reply":"2021-08-05T01:00:07.472804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_comm['toxic'].values[:50]","metadata":{"id":"qy_4v61m75AX","execution":{"iopub.status.busy":"2021-08-05T01:00:07.475306Z","iopub.execute_input":"2021-08-05T01:00:07.475646Z","iopub.status.idle":"2021-08-05T01:00:07.491633Z","shell.execute_reply.started":"2021-08-05T01:00:07.475592Z","shell.execute_reply":"2021-08-05T01:00:07.490249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Check the sets for the form","metadata":{"id":"WYU9LMRG75AX"}},{"cell_type":"code","source":"X_train.shape, y_train.shape","metadata":{"id":"zqX87lQNg3zQ","execution":{"iopub.status.busy":"2021-08-05T01:00:07.493247Z","iopub.execute_input":"2021-08-05T01:00:07.493635Z","iopub.status.idle":"2021-08-05T01:00:07.507074Z","shell.execute_reply.started":"2021-08-05T01:00:07.493596Z","shell.execute_reply":"2021-08-05T01:00:07.505937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train.value_counts(normalize=True).to_frame()","metadata":{"id":"oTTMTTfi75AX","execution":{"iopub.status.busy":"2021-08-05T01:00:07.508594Z","iopub.execute_input":"2021-08-05T01:00:07.509033Z","iopub.status.idle":"2021-08-05T01:00:07.531523Z","shell.execute_reply.started":"2021-08-05T01:00:07.508998Z","shell.execute_reply":"2021-08-05T01:00:07.530387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The target feature is balanced on the training sample","metadata":{"id":"L-QxZBRl75AZ"}},{"cell_type":"markdown","source":"Let's prepare a test sample. Let's take 200 random values ​​and get embeddings for the test","metadata":{"id":"1Tb8ZqPX75AZ"}},{"cell_type":"code","source":"test = features_test.to_frame().join(\n    target_test.to_frame()).sample(200).reset_index(\n    drop=True)\ntest.head()","metadata":{"id":"UYwSe7jr75AZ","execution":{"iopub.status.busy":"2021-08-05T01:00:07.532959Z","iopub.execute_input":"2021-08-05T01:00:07.533405Z","iopub.status.idle":"2021-08-05T01:00:07.593962Z","shell.execute_reply.started":"2021-08-05T01:00:07.533351Z","shell.execute_reply":"2021-08-05T01:00:07.593087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n\ntokenized = test['comment_text'].apply(\n    lambda x: tokenizer.encode(x[:512], add_special_tokens=True))\n\npadded = np.array([i + [0]*(512 - len(i)) for i in tokenized.values])\n\nattention_mask = np.where(padded != 0, 1, 0)","metadata":{"id":"cmkx8dkd75AZ","execution":{"iopub.status.busy":"2021-08-05T01:00:07.595355Z","iopub.execute_input":"2021-08-05T01:00:07.59565Z","iopub.status.idle":"2021-08-05T01:00:13.019985Z","shell.execute_reply.started":"2021-08-05T01:00:07.595622Z","shell.execute_reply":"2021-08-05T01:00:13.019008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 100\nembeddings = []\nfor i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n        batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)]) \n        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n        \n        with torch.no_grad():\n            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n        \n        \n        embeddings.append(batch_embeddings[0][:,0,:].numpy())","metadata":{"id":"1hE7XwUo75AZ","execution":{"iopub.status.busy":"2021-08-05T01:00:13.021337Z","iopub.execute_input":"2021-08-05T01:00:13.021978Z","iopub.status.idle":"2021-08-05T01:02:33.029959Z","shell.execute_reply.started":"2021-08-05T01:00:13.021934Z","shell.execute_reply":"2021-08-05T01:02:33.028589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test = np.concatenate(embeddings)\ny_test = test['toxic'][:X_test.shape[0]]","metadata":{"id":"lgzIk96p75AZ","execution":{"iopub.status.busy":"2021-08-05T01:02:33.031892Z","iopub.execute_input":"2021-08-05T01:02:33.032377Z","iopub.status.idle":"2021-08-05T01:02:33.039936Z","shell.execute_reply.started":"2021-08-05T01:02:33.032321Z","shell.execute_reply":"2021-08-05T01:02:33.038413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test.value_counts(normalize=True).to_frame()","metadata":{"id":"R2SXVI3E75AZ","execution":{"iopub.status.busy":"2021-08-05T01:02:33.04783Z","iopub.execute_input":"2021-08-05T01:02:33.048238Z","iopub.status.idle":"2021-08-05T01:02:33.066062Z","shell.execute_reply.started":"2021-08-05T01:02:33.048203Z","shell.execute_reply":"2021-08-05T01:02:33.065103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There is an imbalance of classes in the test sample. Let's train a logistic regression model, with a balance","metadata":{"id":"TgPwAnIh75AZ"}},{"cell_type":"code","source":"%%time\nlog_clf = LogisticRegression(solver=\"liblinear\", random_state=42,\n                             class_weight='balanced')\n\nlog_clf.fit(X_train, y_train)","metadata":{"id":"yTfYAIwS75AZ","execution":{"iopub.status.busy":"2021-08-05T01:02:33.068062Z","iopub.execute_input":"2021-08-05T01:02:33.068779Z","iopub.status.idle":"2021-08-05T01:02:33.600368Z","shell.execute_reply.started":"2021-08-05T01:02:33.068715Z","shell.execute_reply":"2021-08-05T01:02:33.59907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict = log_clf.predict(X_test)","metadata":{"id":"Nub6hm0O75AZ","execution":{"iopub.status.busy":"2021-08-05T01:02:33.601953Z","iopub.execute_input":"2021-08-05T01:02:33.602309Z","iopub.status.idle":"2021-08-05T01:02:33.615652Z","shell.execute_reply.started":"2021-08-05T01:02:33.602276Z","shell.execute_reply":"2021-08-05T01:02:33.61406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f_score = f1_score(predict, y_test)\nprint(f_score)","metadata":{"id":"8TN7wB0y75AZ","execution":{"iopub.status.busy":"2021-08-05T01:02:33.617689Z","iopub.execute_input":"2021-08-05T01:02:33.618851Z","iopub.status.idle":"2021-08-05T01:02:33.631224Z","shell.execute_reply.started":"2021-08-05T01:02:33.61874Z","shell.execute_reply":"2021-08-05T01:02:33.629587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Unfortunately, we got a rather low result. But this fact is due to the fact that in order to reduce the training time, we had to transfer not the entire set for training, and we had to cut off the sentences that the model could work with them, which could affect the context","metadata":{"id":"pArGGIR875AZ"}},{"cell_type":"code","source":"model_name.append(str(log_clf.__class__.__name__)+str(' ')+str('BERT'))\nfscore.append(round(f_score, 2))","metadata":{"id":"_9PrQ5W075AZ","execution":{"iopub.status.busy":"2021-08-05T01:02:33.63339Z","iopub.execute_input":"2021-08-05T01:02:33.634204Z","iopub.status.idle":"2021-08-05T01:02:33.642378Z","shell.execute_reply.started":"2021-08-05T01:02:33.634145Z","shell.execute_reply":"2021-08-05T01:02:33.640276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Sanity check","metadata":{"id":"VKAQhnZE75Aa"}},{"cell_type":"markdown","source":"Let's build a constant model. It will predict 1 - toxic comment everywhere, since our goal is to identify them.","metadata":{"id":"2jyaXHJD75Aa"}},{"cell_type":"code","source":"dummy = DummyClassifier(random_state=42, strategy='constant', constant=1)","metadata":{"id":"HI5ec3uF75Aa","execution":{"iopub.status.busy":"2021-08-05T01:02:33.644746Z","iopub.execute_input":"2021-08-05T01:02:33.64566Z","iopub.status.idle":"2021-08-05T01:02:33.660304Z","shell.execute_reply.started":"2021-08-05T01:02:33.64559Z","shell.execute_reply":"2021-08-05T01:02:33.65858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dummy.fit(features_train, target_train)\ndummy_pred = dummy.predict(features_test)","metadata":{"id":"O0B2YaJU75Aa","execution":{"iopub.status.busy":"2021-08-05T01:02:33.662355Z","iopub.execute_input":"2021-08-05T01:02:33.663662Z","iopub.status.idle":"2021-08-05T01:02:33.690658Z","shell.execute_reply.started":"2021-08-05T01:02:33.663582Z","shell.execute_reply":"2021-08-05T01:02:33.689177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f1_const = f1_score(target_test, dummy_pred)\n\nprint(\"Const:\", f1_const)","metadata":{"id":"FpNh-I7i75Aa","execution":{"iopub.status.busy":"2021-08-05T01:02:33.692659Z","iopub.execute_input":"2021-08-05T01:02:33.693572Z","iopub.status.idle":"2021-08-05T01:02:33.736309Z","shell.execute_reply.started":"2021-08-05T01:02:33.693514Z","shell.execute_reply":"2021-08-05T01:02:33.735012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name.append(str(dummy.__class__.__name__)+str(' ')+str('const 1'))\nfscore.append(round(f1_const, 2))","metadata":{"id":"bDmRtARp75Aa","execution":{"iopub.status.busy":"2021-08-05T01:02:33.737983Z","iopub.execute_input":"2021-08-05T01:02:33.738461Z","iopub.status.idle":"2021-08-05T01:02:33.744197Z","shell.execute_reply.started":"2021-08-05T01:02:33.738412Z","shell.execute_reply":"2021-08-05T01:02:33.743124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Summary","metadata":{"id":"scP1Q6jR75Aa"}},{"cell_type":"code","source":"summary = pd.DataFrame(\n    { 'model' : model_name , 'F1' : fscore }\n    ).sort_values(by='F1', ascending=False).reset_index( drop = True )\n\nsummary.style.highlight_max( 'F1' , color = 'green' , axis = 0 )\n","metadata":{"id":"wTKvqrwm75Aa","execution":{"iopub.status.busy":"2021-08-05T01:02:33.745827Z","iopub.execute_input":"2021-08-05T01:02:33.746561Z","iopub.status.idle":"2021-08-05T01:02:33.818235Z","shell.execute_reply.started":"2021-08-05T01:02:33.746503Z","shell.execute_reply":"2021-08-05T01:02:33.816789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Acceptable results were obtained on a model based on the SGB algorithm and we have **better score on stacking**\n\nLogistic regression based on DistillBERT to classify long texts such as comments for these purposes is not worth it - you have to truncate the text, which can affect the context, you have to limit the amount of data for training and prediction.\n\nThank you for reading","metadata":{"id":"yw7_Ny-975Aa"}},{"cell_type":"markdown","source":"\n---\n<font size=\"1\">\nArtyKraftyy\n</font>     \n","metadata":{"id":"NYrtd7WMANIV"}}]}