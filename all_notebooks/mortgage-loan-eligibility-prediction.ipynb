{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# THE KEY REQUIREMENTS OF GETTING A MORTGAGE LOAN IN WASHINGTON,DC\n\n","metadata":{"id":"uoF9PlzdRJGv"}},{"cell_type":"markdown","source":"# Context\n\n* The Home Mortgage Disclosure Act (HMDA) requires many financial institutions to maintain, report, and publicly disclose information about mortgages. These public data are important because they help show whether lenders are serving the housing needs of their communities; or help authourities to determine and fish out all predatory act of lending; they give public officials information that helps them make decisions and policies; and they shed light on lending patterns that could be discriminatory.  \n* Eg. a reported increase in mortgage borrowing by blacks and Hispanics as of 1993.","metadata":{"id":"TVOjLUx6RJGw"}},{"cell_type":"markdown","source":"# content\nThis project will generally consist of there main parts:  \n1) **Exploratory data analysis and recommendations**   \n2)**Feature Engineering**   \n3) **Prediction**    \n**we will try as much as possible to keep things simple and concise**","metadata":{"id":"dEap9uNpRJGx"}},{"cell_type":"markdown","source":"# 1.0.0) EXPLORATORY DATA ANALYSIS SECTION","metadata":{"id":"qw9pcWf5RJGy"}},{"cell_type":"markdown","source":"We will start off by importing various libraries for our analysis.\nThe css code below will create border lines around our dataframes","metadata":{"id":"G0vKARJLRJGz"}},{"cell_type":"code","source":"%%HTML\n<style type='text/css'>\ntable.dataframe td,table.dataframe th{\n    border: 1px solid black !important;\n    color: solid black !important\n}\n</style>","metadata":{"id":"-pPjfo33RJG0","outputId":"dfb05b4c-16a3-4d51-a6bd-81f99a9eaaba","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create a class to print different font properties in python\nclass color:\n   PURPLE = '\\033[95m'\n   CYAN = '\\033[96m'\n   DARKCYAN = '\\033[36m'\n   BLUE = '\\033[94m'\n   GREEN = '\\033[92m'\n   YELLOW = '\\033[93m'\n   RED = '\\033[91m'\n   BOLD = '\\033[1m'\n   UNDERLINE = '\\033[4m'\n   END = '\\033[0m'","metadata":{"id":"czBIz0-pRJG7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Importing various libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nimport matplotlib as mpl\nmpl.rcParams['agg.path.chunksize'] = 10000\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.model_selection import StratifiedKFold,train_test_split\n\nimport string\nimport warnings\nwarnings.filterwarnings('ignore')\n\nSEED = 42\n\nle = LabelEncoder()","metadata":{"id":"mTW9aUCBRJG_","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.set_style('whitegrid')","metadata":{"id":"9APwcK7LRJHE","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_main = pd.read_csv('/kaggle/input/washington-state-home-mortgage-hdma2016/Washington_State_HDMA-2016.csv',low_memory=False)\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))","metadata":{"id":"1LPZz_gaRJHI","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**1.0.1)**\n### An Overview\n* The shape of the data is (466565,47) which means it contains 466,566 unique data entries and 47 attribute/features/columns.\n* Dataset has 34 features with object datatype, 9 with float datatype and 4 with integer datatype.","metadata":{"id":"J1A7Gf5ORJHM"}},{"cell_type":"code","source":"df_main.info()","metadata":{"id":"dj-R_EZyRJHN","outputId":"a985ec59-ae90-4c4d-a024-dd618a9ad9d4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.0.2) This is the overall description of some numerical features of the dataset","metadata":{"id":"XgqaScMHRJHS"}},{"cell_type":"markdown","source":">`Loan amount`: Is the amount of money the applicant applied for.  \n>`as_of_year`: Is the the reporting year of the HMDA record.\n\n* The Average loan amount received by applicants is `$`$298.26k$ and the average income of applicants is `$`$112.98k$ which is slightly lower than the loan receives by applicants.  \n\n* The minimum loan amount received by applicants is `$`$1k$ USD(United States Dollars) which is proportional to the minimum annual gross income of applicants thus `$`$1k$.\n* The median `tract_to_msamd_income`(The percentage of the median family income for the tract compared to the median family income for the MSA/MD) is `$`$104.530k$.  \n> * Tract or Census Tract: Is an area equivalent to a noughborhood consisting of a population between 2,800 and 8,000.  \n> * Metropolitan statistical areas (MSA): are delineated by the U.S. Office of Management and Budget (OMB) as having at least one urbanized area with a minimum population of 50,000.  \n* The minimum,average and maximum interest `rate_spread` is 1.50, 1.72 and 13.66 respectively.\n>The interest rate spread is what the company charges on a loan compared to its cost of money.\n* The average `hud_median_family_income` is `$`$76797.148$ \n> * hud_median_family_income is median family income in dollars for the MSA/MD in which the tract is located.\n* `as_of_year` is the year the HDMA data was given to the federal agency.","metadata":{"id":"cC48UARVRJHS"}},{"cell_type":"code","source":"df_main.describe()","metadata":{"id":"eaNdu5PTRJHT","outputId":"f7aef6bb-faef-4d4d-a8a1-98a2bdacb8de","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.0.3) Describing the non-numerical features","metadata":{"id":"x-Wqpx96RJHZ"}},{"cell_type":"markdown","source":"* Most of the mortgage applicants are male representing $60.76$% and female of $23.61$%. The remaining $15.63$% applicants didn't provide their gender status.\n* All the properties are located in the Washington state from which this entire Mortgage data was collected.\n* The `loan_type_name` provide information of the institutions or individuals that guaranteed the loan:Government programs offered by Federal Housing Administration (FHA), the Department of Veterans Affairs (VA), or the Department of Agriculture's Rural Housing Service (RHS) or Farm Service Agency (FSA). All other loans are classified as conventional. For this data, most loans were guaranted Convetionally representing %$71.30$ and the rest %$29.70$.\n* In the loan process %$99.997$ percent of it was not subjected to the Home Ownership and Equity Protection Act(HOEPA).\n    >The Home Ownership and Equity Protection Act is a federal law that discourages banks and other financial institutions from predatory lending when they fund mortgages and home equity loans.\n    \n* Per this data set, the top-most reasons of being denied of loan is because of `Debt_to_income ratio`.","metadata":{"id":"CPuepljsRJHa"}},{"cell_type":"code","source":"df_main.describe(include='O').iloc[:,20:]","metadata":{"id":"PA2NFjFRRJHa","outputId":"f5aeeb7e-ea75-4b97-9036-72ea9528a378","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_corr = df_main.corr().abs().unstack().sort_values(ascending=False)\ndf_corr = df_corr.reset_index() \ndf_corr.columns = ['feat_one','feat_two','count']\ndf_corr = df_corr[df_corr['count'] != 1.0][1::2]\ndf_corr[df_corr['count'] > 0.3]","metadata":{"id":"jcnFPuR5RJHe","outputId":"6fe13c15-1063-41bc-d3d2-1541799638e3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.0.4) `action_taken_name`\nLoan origination is the process by which a borrower applies for a new loan, and a lender processes that application. This process ends when the loan is approved or denied. In this case `loan originated` means the loan has been approved for disbursement in our case.\n\nwhat is `loan purchased by institution`: Most lenders sell loans to **Secondary market** due to liquidity reasons, meaning they either don’t want the loans in their balance sheet or they sell loans so they can lend to more borrowers.\n\n**Secondary Market** is basically an institution willing to buy loans from the primary lenders. When this happens, either the secondary market will resume the service right(means consumers have to make payment to the secondary market) or the service right is retained by the original lender.\n\n**NB:** In our case, we will remove all loans that were sold to secondary institutions since we want to deal directly to primary lenders.  \nWe will also take-out loans that were withdrawn by applicants `Application withdrawn by applicant`.","metadata":{"id":"kwJfnP2mRJHh"}},{"cell_type":"code","source":"print(df_main['action_taken_name'].unique())\n\ndf_main = df_main[(df_main['action_taken_name'] != 'Loan purchased by the institution') & (df_main['action_taken_name'] != 'Application withdrawn by applicant')]","metadata":{"id":"pB1e2rQZRJHi","outputId":"1405c2db-a708-49d8-8545-a9a5957fe131","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will also drop some selected columns that have too much missing values and are not really of much importance to this project.","metadata":{"id":"5_5gOwOeRJHn"}},{"cell_type":"markdown","source":"### 1.0.5) What is the main reason why applicants are denied of loans.","metadata":{"id":"7sMjROHARJHp"}},{"cell_type":"markdown","source":"* The `denial_reason_name_1`,`denial_reason_name_2` and `denial_reason_name_3` columns contain the various reason why an applicant loan application is denied. Each applicant has atmost three reasons to be denied of a loan.  \n> **NB:**There is a huge number of missing data: a total of **42491** out of **1031065** is missing accross the three columns. Decision about it would be made a the Feature engineering section.\n* Since we want the overall reasons that cuts accross all the three columns,the three features would be joined together into one column.\n* After that we find the percentage of each reason compared to the others.  \n\n\n  \n* From the graph below, the significant reason why applicants are denied of loans is `Debt-to-income` ratio and bad `Credit History` having $23$% and $22$% respectively.\n > The debt-to-income ratio is the percentage of your gross monthly income that goes to paying your monthly debt payments.\n Most lenders don't want it to be above 36%.\n \n > Credit history is a record of a consumer's ability to repay debts and demonstrated responsibility in repaying debts.\n \n* The most avoidable one is the incomplete loan application. A number of $6,184$ representing $1.73$ `%` of the total loan applications were denied because of incompleted application.","metadata":{"id":"v2-51MyERJHq"}},{"cell_type":"code","source":"print(df_main[['denial_reason_name_1',\n               'denial_reason_name_2',\n               'denial_reason_name_3']].isna().sum(),'\\n\\n')\n\nprint('Total available values = {}'.format(df_main[['denial_reason_name_1',\n                                                    'denial_reason_name_2',\n                                                    'denial_reason_name_3']].notna().sum().sum()))\n\nprint('Total missing values = {}'.format(df_main[['denial_reason_name_1',\n                                                  'denial_reason_name_2',\n                                                  'denial_reason_name_3']].isna().sum().sum()))\n","metadata":{"id":"PWm0k-miRJHq","outputId":"c8f06cc8-ec7d-4bb0-817f-3837f2f5ff9a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_loan_denial = df_main[['denial_reason_name_1','denial_reason_name_2','denial_reason_name_3']]\n\ndf_loan_denial = pd.DataFrame(pd.concat([df_loan_denial['denial_reason_name_1'],\n                                         df_loan_denial['denial_reason_name_2'],\n                                         df_loan_denial['denial_reason_name_3']],\n                                         ignore_index=True).value_counts(normalize=True),\n                                         columns=['denial_reason_count'])","metadata":{"id":"RcmOa_y3RJHu","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig,ax  = plt.subplots(figsize=(10,5))\n\nsns.barplot(y=df_loan_denial.index,x=df_loan_denial.denial_reason_count,orient='h');\n\nplt.ylabel('Denial Reasons',fontdict={'fontsize':15,'fontstyle':'italic','fontweight':'bold'})\n\nplt.xlabel('Reasons Count(%)',fontdict={'fontsize':15,'fontstyle':'italic','fontweight':'bold'})\n\nplt.tick_params(axis='both',labelsize=15)\n\nplt.subplots_adjust(left=0.3)\n\nplt.title('Various reasons why applicants loan are denied(%)',\n          fontdict={'fontsize':16,'fontstyle':'italic','fontweight':'bold'});","metadata":{"id":"Be9VH0GSRJHx","outputId":"7a3f62fc-23de-467c-cc62-c0b93e540cef","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.0.6) Does applicants gross income play role in his/her loan attainment?\n\nIn figure **1.0.5,** it shows clearly that debt-to-income ratio is the main reason why applicants are denied of loans.\nThis brings up the question, is  high income applicants having an edge over the lower income groups?\nThis turned out be true!.\n\nWe will create a new column called `loan_approved` which will consist of binary, `1` means loan was approved and `0` means denied. The we will divide the entire dataset into two groups of dataframes `loan_approved` and `loan_denied` and then print out the mean and median income of both categories.\n\n* The bar plot shows that the mean and median income of those with their loans approved is slightly higher than those with their loans denied.","metadata":{"id":"aUwjCnwVRJH2"}},{"cell_type":"code","source":"# creating loan_approved column from the action_taken_name columns\ndf_main['loan_approved'] = df_main['action_taken_name'].apply(lambda x: 1 if x == 'Loan originated' else 0)\n\nloan_approved,loan_denied = df_main[df_main['loan_approved'] == 1],df_main[df_main['loan_approved'] == 0]\n\nprint('Approved mean {} and median {}'.format(loan_approved['applicant_income_000s'].mean(),\n                                              loan_approved['applicant_income_000s'].median()))\n\nprint('Denied mean {} and median {}'.format(loan_denied['applicant_income_000s'].mean(),\n                                            loan_denied['applicant_income_000s'].median()))","metadata":{"id":"gf-WZYy7RJH3","outputId":"8aba14c5-b3a2-43e5-da15-860e2166a2d2","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"app_loan_mean,app_loan_med = loan_approved['applicant_income_000s'].mean(),loan_approved['applicant_income_000s'].median()\n\nden_loan_mean,den_loan_med = loan_denied['applicant_income_000s'].mean(),loan_denied['applicant_income_000s'].median()\n\nfig,ax = plt.subplots(1,1,sharey=True,figsize=(10,6))\nax.bar(x=['mean income','median income'],height=(app_loan_mean,app_loan_med),color='b',alpha=1,width=0.1)\nax.bar(x=['mean income','median income'],height=(den_loan_mean,den_loan_med),color='red',width=0.1)\n\nplt.legend(['Loan Approved: mean = {} median = {}'.format(np.round(app_loan_mean,2),app_loan_med),\n            'Loan Denied: mean= {} median = {}'.format(np.round(den_loan_mean,2),den_loan_med)],\n           fontsize=13,title='Loan Status',title_fontsize=15)\n\nax.tick_params(axis='x',labelsize=20)\nplt.title('Bar plot shows the mean and median income of the approved and denied loan status',fontsize=20,pad=20);","metadata":{"id":"1D45bgFeRJH7","outputId":"45fb19d3-9983-4401-a120-3549bdba6d3d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.0.7) CAN LOW OR HIGH NEIGHBOURHOOD FAMILY INCOME OF WHERE THE PROPERTY IS LOCATED AFFECT APPLICANTS CHANCES OF GETTING A LOAN?","metadata":{"id":"1hjkKXvtRJH-"}},{"cell_type":"markdown","source":"From the HMDA dataset, lenders disclose the census tract of applicants instead of making their addressess public, which is part of the community where the property is located.Each census tract is located in a Metropolitian Statistical Area/Metropolitian Division (MSA/MD). \nThe `hud_median_family_income` is the median family income in dollars for the MSA/MD in which the tract is located.\n\nBasically,you must be expecting that for a loan to be approved the applicant's income must be quite similar or above the neighbourhood median family income.  \nwell, this is in some sense true! but wait,we will see how applicants with their average income LOWER,EQUAL or HIGHER than the mean neighborhood median income of where the property is located are affected.\n\n**NOTE ON THE PLOT**  \n    1) md = msamd/md  \n    2) st=mean_status  \n    3) st = $-1$ (applicants with their income lower),  $0$ ( applicants with their income equal) and  $1$  (applicants with their income higher)  \n    4) On the x-axis, `0` and `1` means `loan_approved` and `loan_denied` respectively\n\n**FINDINGS**\n* In all  Metropolitian Statistical Area/Metropolitian Division (MSA/MD),it is obvious that number of applicants with their loans approved is significantly higher than those that were denied.\n* As you view from **right to left** each row, you could see a slight increase in the number of `loan_denied` for almost all the plots.\nApplicants whose median_income is lower than the median neigbhorhood income of the census tract, have got their `loan_denied bar (0)` comparatively taller to the rest on the right especially msamd **Yakima-WA**.\n\n`loan_denied`:\n  - -1 > 0 > 1","metadata":{"id":"Ph83kACtRJH_"}},{"cell_type":"code","source":"# make a copy of the main dataframe\ndf_hud_appincome = df_main.copy()\n\n#The trailing zeros in the column name indicates that the actual amount must be multiply by 1000 to the actual values\ndf_hud_appincome['applicant_income_000s'] = df_hud_appincome['applicant_income_000s']*1000\n\n# This column will hold either applicant is below, equal or above the average mean income of its neighbors\ndf_hud_appincome['mean_status'] = 0\n","metadata":{"id":"u5Fqbw1CRJIA","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# list of msamd names\nmsamd = list(df_hud_appincome['msamd_name'].unique())\n\n# function to indicate each applicants mean_status\n# Running this can take significant amount of time.\n# You can skip this cell and run the next and you will get the exact data this function will produce\n\ndef mean_sort(df,msamd):\n    for msamd_name in msamd:\n        df_batch = df[df['msamd_name'] == msamd_name]\n        avg_hud_income = df_batch['hud_median_family_income'].mean()\n        for row in range(df_batch.shape[0]):\n            indx_val = df_batch.iloc[[row]]['applicant_income_000s']\n            indx,val= indx_val.index[0],indx_val.values[0]\n            if val > avg_hud_income:\n                df.loc[indx,'mean_status'] = 1\n            elif val < avg_hud_income:\n                df.loc[indx,'mean_status'] = -1\n            else:\n                pass\n    return df\n\n# The resulting dataframe\n# df_trans = mean_sort(df_hud_appincome,msamd)\n\n# Convert the transformed dataframe into Commas Separated Files \n# NB: This is optional\n\n# df_trans.to_csv('df_transformed',index=False)","metadata":{"scrolled":true,"id":"KFljR9BoRJIE","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_trans = pd.read_csv('/kaggle/input/transformed-dataframe/df_transformed',low_memory=False)\n# grouping by msamd name, mean status and loan_approved \ndf_grouped = (df_trans.reset_index().groupby(['msamd_name','mean_status','loan_approved']).count()['index']).reset_index()","metadata":{"id":"E_xmH6NPRJIH","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nperc_list = []\n# This will basically calculate all the percentage of its corresponding\nfor indx in range(0,df_grouped.shape[0],2):\n    curr_val,next_val = df_grouped.loc[indx,'index'],df_grouped.loc[indx+1,'index']\n    curr_next_val = curr_val + next_val\n    curr_perc,next_perc = (curr_val/curr_next_val)*100,(next_val/curr_next_val)*100\n    perc_list.append(np.round(curr_perc,2)),perc_list.append(np.round(next_perc,2))\n\ndf_grouped = pd.concat([df_grouped,pd.Series(perc_list,name='percentage %')],axis=1)","metadata":{"scrolled":true,"id":"QGMHTqdMRJIL","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Because the plots are many, we shorten the names to allow space\ndf_grouped.rename({'msamd_name':'md','mean_status':'st'},axis=1,inplace=True)","metadata":{"id":"-2dezrklRJIO","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**NOTE ON THE PLOT**  \n    1) md = msamd/md  \n    2) st=mean_status  \n    3) st = $-1$ (applicants with their income lower),  $0$ ( applicants with their income equal) and  $1$  (applicants with their income higher)  \n    4) On the x-axis, `0` and `1` means `loan_approved` and `loan_denied` respectively\n\n**INSIGHT**\n* In all  Metropolitian Statistical Area/Metropolitian Division (MSA/MD),it is obvious that number of applicants with their loans approved is significantly higher than those that were denied.\n* As you view from right to left each row, you could see a slight increase in the number of `loan_denied` for almost all the plots.\nApplicants whose median_income is lower than the average neigbhorhood income of the census tract, have got their `loan_denied bar (0)` comparatively taller to the rest on the right especially msamd **Yakima-WA**.\n\n`loan_denied`:\n  - -1 > 0 > 1","metadata":{"id":"PGZ0Er2XRJIR"}},{"cell_type":"code","source":"# creating a facetgrid with MSA/MD, Mean Status,loan_approved, percentage %\nsns.set(font_scale=1.2)\ngrid = sns.FacetGrid(df_grouped, row='md', col='st', height=2.2, aspect=2)\ngrid.map(sns.barplot, 'loan_approved', 'percentage %', alpha=.5, ci=None,order=[0,1],palette='deep')\ngrid.add_legend();\n\naxes = plt.gca()\n\nfrom matplotlib.lines import Line2D\ncmap = plt.cm.coolwarm\n\ncustom_lines = [Line2D([0], [0], color='#dab9aa', lw=10),\n                Line2D([0], [0], color='#a1afca', lw=10)]\n\n\naxes.legend(custom_lines, ['Loan Approved', 'Loan Denied'],title='Loan Approval Status',\n           loc='best', bbox_to_anchor=(0.85, 0.5, 0.9, 18));","metadata":{"id":"fWcyV4FsRJIR","outputId":"c97d5c0e-c740-40b6-8496-8866744bf8cf","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='property'></a>\n### 1.0.8) WHAT KIND OF PROPERTY HAS THE HIGHEST LOAN APPROVAL RATE?","metadata":{"id":"jM2RtWKQRJIU"}},{"cell_type":"markdown","source":"**1-4 family dwelling, multifamily dwelling and manufactured housing are the three property types.**  \n\n**Manufactured homes**: are housing that is esentially ready for occupancy upon leaving the factory and being transported to a building site.  \n\n**Multifamily dwelling:** means any housing unit where two (2) or more dwellings are separated by a common wall, floor or ceiling, including but not limited to apartments, condominiums and townhouses.\n\n**Results**:\n\n* Applicants for multifamily dwelling housing property has the highest percentage of qualifying for loans.\n\n    >This result is obvious because some lenders want to be sure that you will have enough money to start making payment at the earlier stage since such property can produce a cashflow of decent rental income. \n    \n    >Most applicants of multifamily dwelling are mostly investors and they obviously have good credit-score history and they also provide decent down payment.\n\n\nIt's tougher to get a loan for manufactured housing.\n\n> Many manufactured home loan programs have strict guidelines about the property condition and age. That’s because manufactured housing tends to depreciate, while traditional home values tend to increase over time.","metadata":{"id":"fkLMOe-9RJIV"}},{"cell_type":"code","source":"# creating a dataframe with `loan_approved` grouped by property_type_name as index\ndf_cross = pd.crosstab(df_main['property_type_name'],df_main['loan_approved'])\n\n# creating a dictionary of property_type_name and its percentage\nperc_dict = {}\n\nfor indx in range(df_cross.shape[0]):\n#     calculate percentage\n    percentage = df_cross.loc[df_cross.index[indx],1]/(df_cross.loc[df_cross.index[indx],0] + df_cross.loc[df_cross.index[indx],1])\n    \n    perc_dict[df_cross.index[indx]] = np.round(percentage*100,2)\n","metadata":{"id":"ydT4hVVYRJIY","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# getting the x and y values for the plot\nx = list(perc_dict.keys())\ny = list(perc_dict.values())\n\n# creating a barplot of a property type and its rate of approval\nsns.barplot(y,x,orient='h',order=sorted(perc_dict,key=lambda x: x[1],reverse=True),palette='Accent');\n\nplt.xlabel('Rate of Approval (%)',fontstyle='italic')\nplt.ylabel('Property Type',fontstyle='italic')\nplt.xlim([0,100])\n\n# title\nplt.title('Types of Properties and its Rate (%) of approval',pad=20,fontweight='bold');","metadata":{"id":"yy8VZkeqRJIc","outputId":"8ba3fbe1-bc92-4cc6-b8f3-e776e37c32f1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.0.9) Which type of loans have a better chance of being approved?  ","metadata":{"id":"hoANkpsiRJIg"}},{"cell_type":"markdown","source":"There are loans that are insured or guaranteed by government programs offered by:  \n    1) Federal Housing Administration (FHA)   \n    2). Department of Veterans Affairs (VA)  \n    3) Department of Agriculture's Rural Housing Service (RHS) or Farm Service Agency (FSA).  \n    All other loans are classified as conventional.\n    \n* It turned out that,FSA/RHS has the highest rate of loan approval whiles FHA stands the highest risk of getting their loans denied.  \n* The FSA/RHS are basically Agencies set to help low-income rural residence and farmers to get loans. Applicants guaranteed under this agency needs not to worry about credit history or present income since they are pardoned from such criteria but they should be able make payment for their loan,taxes and insurance.  \n* FSA takes up to 95% percent of loss.","metadata":{"id":"Oy7bXSNbRJIh"}},{"cell_type":"code","source":"# creating a dataframe with loan_type_name and loan approval_approved\ndf_main['loan_type_name'].unique()\n\ndf_loan_type = pd.crosstab(df_main['loan_type_name'],df_main['loan_approved'],normalize='index')","metadata":{"id":"_jnpTtPfRJIh","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_loan_type","metadata":{"id":"81wlPT67RJIk","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rate_barplot(df,label1=None,label2=None,title=None,x_label=None,y_label=None):\n    \"\"\"This return a barplot with a well labelled axis\"\"\"\n#     getting the x values from the length of the dataframe\n    x = np.arange(df.shape[0])\n    \n#     index of the df as a label\n    labels = list(df.index)\n    fig  = plt.figure()\n    ax = fig.add_axes([0,0,1,1])\n\n    width = 0.35\n\n    ret1 = ax.bar(x-width/2,df[0],width=width,label=label1)\n    ret2 = ax.bar(x+width/2,df[1],width=width,label=label2)\n\n    ax.set_xticks(x)\n    ax.set_xticklabels(labels)\n    ax.set_ylim([0,1])\n    ax.set_title(title,fontsize=15,fontweight='bold')\n    ax.set_ylabel(y_label,fontstyle='italic')\n    ax.set_xlabel(x_label,fontstyle='italic')\n\n    ax.grid(True,which='minor',axis='y')\n\n    def autolabel(rects):\n        \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n        for rect in rects:\n            height = rect.get_height()\n            ax.annotate('{}%'.format(np.round(height*100,2)),\n                        xy=(rect.get_x() + rect.get_width() / 2, height),\n                        xytext=(0, 3),  # 3 points vertical offset\n                        textcoords=\"offset points\",\n                        ha='center', va='bottom')\n\n    autolabel(ret1)\n    autolabel(ret2)\n#     position the legend outside the main axis\n    plt.legend(loc='best', bbox_to_anchor=(0.85, 0.5, 0.5, 0.5))\n\n    plt.setp(ax.get_xticklabels(),rotation=45,ha='right');\n    plt.show()","metadata":{"id":"VAM43KpBRJIn","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creating barplot with the `rate_barplot` function\n\nrate_barplot(df_loan_type,'Loan Denied','Loan Approved','Loan-Type Rate % of Approval','Loan Type','Rate(%)')","metadata":{"id":"JPGf2RBDRJIq","outputId":"94eea1e9-9eed-4d01-bbcd-0c31ce41855f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.1.0) WHICH COUNTY HAS THE HIGHEST NUMBER OF LOAN APPLICANTS AND HIGHEST RATE OF LOAN APPROVAL?","metadata":{"id":"eAYUx9EcRJIu"}},{"cell_type":"markdown","source":"**King County has the highest number of loan applicants**\n\n* King County according to the 2019 us population and housing census is having a whooping number 2,252,782 residents which makes it the most populous county in Washington and the 13th most populous county in America.\n\n* The second highest is Pierce County, also having a population of 904,980 residents making it the second and 61st most populous county in Washington and United States respectively.\n\n* Atleat this two give a clear indication of how the number of applicants correlate with the population of that county.\n* `King County` has the highest rate of loan approval followed by snohomish County.","metadata":{"id":"2eeP1sxvRJIu"}},{"cell_type":"code","source":"df_main['county_name'].value_counts().head()","metadata":{"scrolled":true,"id":"W4fRNLnNRJIv","outputId":"2d1ab444-8bf2-472d-cb67-f81d8119cc7d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.crosstab(df_main['county_name'],df_main['loan_approved'],normalize='index').sort_values(by=[1],ascending=False).head(5)[1]","metadata":{"id":"REqL_jrhRJIx","outputId":"3657f935-50d1-44ed-f29d-8099e925d6af","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.1.1) CAN THE PURPOSE OF THE LOAN ALSO HELP YOU GET IT?","metadata":{"id":"KnWucYSoRJIz"}},{"cell_type":"markdown","source":"Loan applicantions are intended for `Refinancing`, `Home Purchase` and `Home Improvement`.  \nHome Purchase and Home Improvement is self explainatory.  \n\n`Refinancing:`Refinancing means getting a new mortgage to replace the original. Refinancing is done to allow a borrower to obtain a better interest term and rate.\n* From our graph, applying for a loan to purchase a home has significant rate over the other two.","metadata":{"id":"5Srjs5fMRJI0"}},{"cell_type":"code","source":"df_main['loan_purpose_name'].unique()","metadata":{"id":"vUE7BjR4RJI0","outputId":"16fe9d08-44d6-4af1-ba08-e2e1a144e4e8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_purpose = pd.crosstab(df_main['loan_purpose_name'],df_main['loan_approved'],normalize='index')\n\nrate_barplot(df_purpose,'Loan Denied','Loan Approved','Loan Purpose vs Rate (%) of Approval',\n             'Loan Purpose','Purpose Rate(%)')","metadata":{"id":"kKNlDfbWRJI3","outputId":"86eccf2d-5817-4ced-e830-6138082d02a1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='hoepa_owner'></a>\n### 1.1.2) HOW DOES THE `OWNER_OCCUPANCY_NAME` AND `HOEPA_STATUS_NAME` AFFECT LOAN APPLICATION?\n","metadata":{"id":"0xJ3pHj4RJI5"}},{"cell_type":"markdown","source":"`HOEPA:` The Home Ownership and Equity Protection Act (HOEPA) was enacted in 1994 as an amendment to the Truth in Lending Act (TILA) to address abusive practices in refinances and closed-end home equity loans with high interest rates or high fees. So `HOEPA_STATUS_NAME` shows whether or not a loan was subjected to heopa regulations.\n\n`Owner_occupancy_name:` Basically shows the owner-occupancy status of the property. Second homes, vacation homes, and rental properties are classified as \"not owner-occupied as a principal dwelling\".\n\nFor multifamily dwellings (housing five or more families), and any dwellings located outside MSA/MDs, or in MSA/MDs where an institution does not have home or branch offices, an institution may either enter`not applicable`. Most of these properties are for investment purposes.\n\n* None of the loans that were indicated as ` Non_applicable` were subjected to hoepa status\n* All the loans subjected to hoepa status stands $100$% rate of approval\n* multifamily dwellings (housing five or more families)  that is once indicated as `not_applicable` also have comparatively higher rate of approval.\n* The Owner occupied houses have a slight chance over the not_owner occupied homes","metadata":{"id":"MWvRmvvMRJI6"}},{"cell_type":"code","source":"# grouping the dataframe with three columns being the index and loan_approved values\ndf_hoepa_grp = pd.crosstab([df_main['owner_occupancy_name'],\n             df_main['hoepa_status_name']],df_main['loan_approved'],\n            normalize='index').reset_index()\n\n# create loan_approved columns filled with zeros indicating loan denied\ndf_hoepa_grp['loan_approved'] = 0\ndf_hoepa_grp_0 = df_hoepa_grp.drop(1,axis=1).rename(columns={0:'percentage'})\n\n# Create loan_approved columns filled with ones indicating loan approved\ndf_hoepa_grp['loan_approved'] = 1\ndf_hoepa_grp_1 = df_hoepa_grp.drop(0,axis=1).rename(columns={1:'percentage'})\n\n# combine the dataframes\ndf_hoepa_grp_combine = pd.concat([df_hoepa_grp_0,df_hoepa_grp_1],axis=0,ignore_index=True,sort=False)\n","metadata":{"scrolled":true,"id":"ro77SkMhRJI7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# In order to have a well layed out plot, lets shorten the name the columns and the owner_occupancy_name\n\ndf_hoepa_grp_combine.rename(columns={'owner_occupancy_name':'owner_occupy',\n                                     'hoepa_status_name':'hoepa_st','percentage':'rate(%)'},inplace=True)\n\ndf_hoepa_grp_combine['owner_occupy'] = df_hoepa_grp_combine['owner_occupy'].map({'Not owner-occupied as a principal dwelling':'not_prin_dweller',\n                               'Owner-occupied as a principal dwelling':'prin_dweller',\n                                 'Not applicable':'not_applic'})\ndf_hoepa_grp_combine","metadata":{"id":"Lihlm0v6RJI_","outputId":"7a25eb52-0693-40d0-c934-b9be717f85f4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.set(font_scale=1.2)\ngrid = sns.FacetGrid(df_hoepa_grp_combine, row='owner_occupy', col='hoepa_st',height=2.95, aspect=2,margin_titles=False)\ngrid.map(sns.barplot,'loan_approved', 'rate(%)', alpha=.5, ci=None,order=[0,1],palette='deep')\ngrid.add_legend()\n\naxes = plt.gca()\n\nfrom matplotlib.lines import Line2D\ncmap = plt.cm.coolwarm\n\ncustom_lines = [Line2D([0], [0], color='#dab9aa', lw=10),\n                Line2D([0], [0], color='#a1afca', lw=10)]\n\n\naxes.legend(custom_lines, ['Loan Approved', 'Loan Denied'],title='Loan Approval Status',\n           loc='best', bbox_to_anchor=(0.85, 0.5, 0.6, 3));","metadata":{"id":"xwIgqr63RJJB","outputId":"00913457-0e73-4667-db75-6f8f4efb4f44","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.1.3) DOES THE LIEN STATUS PLAY A ROLE IN THE LOAN APPROVAL?","metadata":{"id":"-CCOdzPKRJJD"}},{"cell_type":"markdown","source":"* A lien is a claim or legal right against assets that are typically used as collateral to satisfy a debt.  A lien serves to guarantee an underlying obligation, such as the repayment of a loan.  \n\n* Typical example is a payment agreement for a home loan. The documents includes provisions that allow the lender to keep you from selling the house until you pay what you(debter) owe.\n* Let say that an investor is seeking for a loan to buy a real estate with an assessed value of `$`2,000,000\nlender(first lien) approved a loan of `$` 1,500,000 the rest of the `$` 500,000 amount was approved by second lender(subordinate lien).\n\n**Results:**\n* Loan secured by a `first lien` has the highest rate of approval($74$%). This because loan subjected to this binds the debtor from not being allowed to sell the property untill the full loan repayment is been made. In this case there is relatively lower risk for lenders.  \n* Loan secured by a `second lien` has the second highest rate of approval and this is clear because when the debtor defaults and there is a force liquidation of asset, the subordinate lien will only be paid if and only when the first lien( the primary lien's)  money is paid fully. In this case the second lien stands a degree of risk.\n* `Not secured by a lien` has the lowest rate of approval ($0.55$%). Remember, the higher the risk of you paying the loan, the lower your chances of getting the loan","metadata":{"id":"cVKE9OpkRJJE"}},{"cell_type":"code","source":"pd.crosstab(df_main['lien_status_name'],df_main['loan_approved'],normalize='index')","metadata":{"id":"qNaHUiJBRJJE","outputId":"137eae16-0b40-4d7a-8ff0-85850a3c4661","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ax = sns.pointplot(x='lien_status_name',y='loan_approved',data=df_main)\nplt.setp(ax.get_xticklabels(),rotation=20,ha='right');\nplt.ylim([0,1]);\nplt.title('How lien status affects the approval rate',fontsize=15,fontweight='bold');","metadata":{"id":"0fm4CDnCRJJK","outputId":"eb4e3dce-f578-44ce-a856-0e9d3e805bb4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1.1.4) IS THE LENDING PROCESS DESCRIMINATORY???","metadata":{"id":"QvMjpEcSRJJS"}},{"cell_type":"markdown","source":"### i) We will start by comparing how county with certain percentage of minority and county above or below the overall median county approval rate affects loan approval.\n\n* The United States is the third-most populous country in the world, with an estimated population of 329,227,746 as of January 28, 2020.\n\n* White people constitute the majority of the U.S. population, with a total of about 234,370,202 or 73%.\"Non-Hispanic Whites\" make up 60.7% of the country's population.\n\n* Hispanic,Latino Americans and African/Black-Americans are the minority in USA.\n\n\n* Properties that are located in the census_tract having a minority population between 13-32%, recorded the highest rate of loan approval for both above and below the overall median approval rate of all counties. Such counties are mixed-racial.\n\n* Applying for a loan to purchase a property located in county that have HIGHER minority population and also below the overall median approval rate of all counties ,have lower rate of loan approval than the LOWER minority populated areas.This can be basically the fact that, people in those counties have low income which makes lenders think that taking loan to invest in those areas may be more riskier so they tend not to approve.\n\nIn all the four categories,counties that are below the `median approval rate of all counties` have lower rate of loan approval.","metadata":{"id":"Tuljdi5WRJJS"}},{"cell_type":"code","source":"# make a copy of the main. Name the new df as df_county_population\ndf_county_population = df_main.copy()\n\n# Take out all nan counties\ndf_county_population = df_county_population[df_county_population['county_name'].notna()]\n\n# make a dataframe of county name as index and loan_approved as values. get the median approval rate for all the counties\nmed_county_appr_rate = np.round((pd.crosstab(df_county_population['county_name'],\n                    df_county_population['loan_approved'],normalize='index')[1]).median(),2)\n\ndf_county_rate = pd.crosstab(df_county_population['county_name'],df_county_population['loan_approved'],normalize='index')\n\n# Get names of all counties above the median county approval rate\ncount_name_above_roa = df_county_rate.loc[df_county_rate[1] >= med_county_appr_rate].index.tolist()\n\n# create 'Aboveall_county_median_appr_rate' column to hold whether the county is above or below the overall median county rate of\n# approval. above=1 and below=0\ndf_county_population['Aboveall_county_median_appr_rate'] = df_county_population['county_name'].isin(count_name_above_roa).astype(int)\n\n# list of all county names\ncounty_name_list = df_county_population['county_name'].unique().tolist()\n\n# county names with its respective average minority population rate\navg_popu_dict = df_county_population.groupby('county_name').mean()['minority_population'].to_dict()\n\n# Fillin the null values in the minority_population with the average minority_population percentage of its particular county\nfor county_name in county_name_list:\n    df_county_population.loc[(df_county_population['county_name'] == county_name) & (df_county_population['minority_population'].isna()),\n                         'minority_population'] = avg_popu_dict[county_name]\n    \n# Break the minority_population into four quantiles\ndf_county_population['minority_population'] = pd.qcut(df_county_population['minority_population'],4)","metadata":{"id":"6jaK8sSmRJJT","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make a dataframe of loan approval rate\ndf_county_pop = pd.crosstab([df_county_population['Aboveall_county_median_appr_rate'],\n                             df_county_population['minority_population']],df_county_population['loan_approved'],\n                            normalize='index').reset_index()","metadata":{"scrolled":true,"id":"7hlc9arBRJJX","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig,ax = plt.subplots(figsize=(12,6))\nsns.barplot(x='minority_population',y=1,data=df_county_pop,hue='Aboveall_county_median_appr_rate')\n\nplt.ylim([0,1])\nplt.legend(title='Aboveall_county_median_appr_rate',loc='best', bbox_to_anchor=(0.85, 0.5, 0.52, 0.52))\n\nax.set_xlabel('Minority population range(%)')\nax.set_ylabel('Loan approval rate(%)')\nax.set_title('Minority population categories VS Rate of loan approval',fontweight='bold');","metadata":{"id":"z1mqWSWLRJJc","outputId":"7065a1d7-b8e6-4f04-cfa1-4141f98545fe","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ii) Can applicant gender influence his/her loan?\n**NB:** Because our main focus is on the two gender status `male` and `female`, we will take all others out of the `applicant_sex_name` column and `co_applicant_sex_name` column.\n* It's recorded that, Male main applicants and Female co-applicants have a better chance of qualifying for a loan than all the remaining combination. This makes me think that couples have better chance over single applicants.\nThis is confirmed in a research article published by forbes. [You can get the details here](https://www.forbes.com/sites/trulia/2016/08/31/how-your-relationship-status-affects-mortgage-worthiness/#27b17b7e6114). \n * As a single applicant,you have to be earning good income on your own in other to maintain good debt-to-income ratio and nice credit score(which is the main reason applicants loans are denied).\n * Couples can raise this income easily if they join their money, this gives them good debt-to-income ratio and nice credit score to make a hedge over single applicants.\n* The heatmap also shows that main and co-applicants of the same-sex have slightly lower chances than the other way round.","metadata":{"id":"oSXVl08-RJJg"}},{"cell_type":"markdown","source":"minority_population,msamd_name,co_applicant_sex_name,co_applicant_race_name_5,co_applicant_race_name_4,co_applicant_race_name_3,co_applicant_race_name_2,co_applicant_race_name_1,co_applicant_ethnicity_name,applicant_sex_name,applicant_race_name_5,applicant_race_name_4,applicant_race_name_3,applicant_race_name_2,applicant_race_name_1,loan_approved","metadata":{"id":"n0LJQbWlRJJg"}},{"cell_type":"code","source":"# Make a copy of the main df into another called df_sex_grouped\ndf_sex_grouped = df_main.copy()\n\n# Take only male and female sex from both main applicants and co-applicants columns\ndf_sex_grouped = df_sex_grouped[((df_sex_grouped['applicant_sex_name'] == 'Female') | (df_sex_grouped['applicant_sex_name'] == 'Male')) & ((df_sex_grouped['co_applicant_sex_name'] == 'Female') | (df_sex_grouped['co_applicant_sex_name'] == 'Male'))]","metadata":{"id":"wdaXHpELRJJh","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create a pivot table with the dataframe\ndf_sex_grouped_pivot = pd.pivot_table(df_sex_grouped,values='loan_approved',index='applicant_sex_name',\n                                      columns='co_applicant_sex_name',aggfunc='mean')","metadata":{"id":"0WCovFptRJJj","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot a heatmap\nax = sns.heatmap(df_sex_grouped_pivot,annot=True,center=0,cbar=False)\n# add title to the plot\nplt.title('Main applicants and Co-applicants gender influence over loan approval',pad=20,fontweight='bold');\nbottom,top = ax.get_ylim()\n# add 1/2 each to make the edge full\nax.set_ylim(bottom+0.5,top-0.5);","metadata":{"scrolled":true,"id":"AiXpnOVgRJJm","outputId":"e112c1fe-809c-4285-d273-fffe91e0a10d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{"id":"-aOuYfkVRJJp"}},{"cell_type":"markdown","source":"### iii) Can applicant loan be denied because of his/her race?\nThe issue of racism has been a problem in the United States since the foundation of the nation. \n`Not applicable` is the name given to institutions as applicants and co_applicants.\n* The heatmap shows the rate of loan approval from the various race combination.\nA more summarized version is a shown the tables.\nWe take a particular race of a main or co-applicants and combined it with the approval rate of the rest of the races and find the average.  \n\n**Table 1**: Each column value is the mean value of race(column name) vs all other race. Example.\nAssume the main applicant race is `WHITE` therefore as shown on the heatmap,we compare it with all the co-applicants race values then find the average.\nafter doing this calculation,`Black or African American` happens to have the lowest average rate of loan approval $65$% compared to the `white` race(majority) $75$%.\n\n**Table 2**: Each column value is the mean value of co-applicant race(column name) vs all other race. Example.\nAssume the co_applicant race is `WHITE` therefore as shown on the heatmap,we compare it with all the main applicants race values then find the average.\nAgain after doing this calculation,`Black or African American` happens to have the lowest average rate of loan approval $66$% compared to the `white` race(majority) $78$%.\n\n* `Asian americans` a minority group, happens to be having the highest rate of loan approval $76$% and $79$% in both table 1 and 2 respectively.\n\nA research article published by Pew Research Center shows that Blacks and Hispanics face extra challenges in getting home loans than the rest of the race in america.\n\nThe reasons lenders cite for turning down mortgage applications show different patterns depending on racial or ethnic group. Among whites, Hispanics and Asians rejected for conventional home loans, for instance, the most frequently cited reason was that their debt-to-income ratio was too high (25%, 26% and 29%, respectively). Among blacks, the most often cited reason was a poor credit history (31%).  \nAccording to the research,Blacks and Hispanics generally put less money down on houses relative to total value than other groups. This makes lenders denied them of loan since it reflect the income status of the applicant and their ability to make repayments.\n[click to read more on this interesting findings](https://www.pewresearch.org/fact-tank/2017/01/10/blacks-and-hispanics-face-extra-challenges-in-getting-home-loans/)","metadata":{"id":"v-vlCxadRJJp"}},{"cell_type":"code","source":"# make a pivot table with various features of the main dataframe.\ndf_applicants_pivot = pd.pivot_table(df_main,values='loan_approved',\n                                     index='co_applicant_race_name_1',columns='applicant_race_name_1')\n# create a figure\nfig,ax = plt.subplots(figsize=(12,6))\n# draw a heatmap\nsns.heatmap(df_applicants_pivot,annot=True,annot_kws={\"size\": 15},linewidths=2, linecolor='yellow')\n# get the bottom and top size of the map\nbottom,top = ax.get_ylim()\n# add 1/2 each to make the edge full\nax.set_ylim(bottom+0.5,top+0.5)\n\nplt.setp(ax.get_xticklabels(), rotation=30, ha=\"right\",\n         rotation_mode=\"anchor\");\n\nplt.ylabel('Co-applicant race')\nplt.xlabel('Main applicant race');\nplt.show()\n\n","metadata":{"id":"ln7UXEtBRJJq","outputId":"29644acc-6d40-458b-8cef-1c18a8ea30ce","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"column_names = df_applicants_pivot.columns.tolist()\ndf = pd.DataFrame({column_name:np.round(df_applicants_pivot[column_name].mean(),2) for column_name in column_names},\n            index=['All_other_race'])\n# set seaborn color map\ncm = sns.light_palette(\"green\", as_cmap=True)\n\ndef highlight(s):\n    return 'background-color: yellow'\n# add highlight and caption to the table\ndf.style.applymap(highlight,subset=['Black or African American','White'])\\\n    .set_caption('MEAN VALUE OF MAIN APPLICANT RACE NAME VS ALL OTHER RACE')\n","metadata":{"id":"47cyaOdsRJJv","outputId":"b4366df6-5d3a-4f74-a5b3-e3feb50311f2","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"column_names = df_applicants_pivot.columns.tolist()\ndf = pd.DataFrame({column_name:np.round(df_applicants_pivot.loc[column_name,:].mean(),2) for column_name in column_names},\n            index=['All_other_race'])\n\ncm = sns.light_palette(\"green\", as_cmap=True)\n\ndef highlight(s):\n    return 'background-color: yellow'\n\ndf.style.applymap(highlight,subset=['Black or African American','White'])\\\n    .set_caption('MEAN OF CO-APPLICANT RACE VS ALL OTHER RACE')\n","metadata":{"id":"dAdqeNpIRJJx","outputId":"2990a2b6-fb62-4a14-b75d-e0cdcd2a5b35","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n<br>\n<br>\n   \n<h3 'style=text-align:center';>RECOMMENDATIONS</h3>\n<br>","metadata":{"id":"fnOhF3tbRJJ1"}},{"cell_type":"markdown","source":" \n **Recommendations:**\n The following Nuggets will comparatively increase your chances in getting your loan approved in Washington DC:\n   - Build good credit score. Even if you don't need loan now, for the sake of the future it is advisable to build good score.\n   - Maintain good Debt-to-Income ratio.\n   - Unfortunately, it turned out that high income earners have an edge over the lower income group. So you may consider taking high income job though its not a major requirement.\n   - Make sure your median income is equal or higher than the median neigbhorhood income of where the property is located.\n   - Choose to buy multifamily dwelling. Don't apply for loan to buy manufactured housing.\n   - Apply for FSA/RHS loans. It has relatively high chance of loan approval.\n   - Consider getting a Home loan in King County\n   - Apply for a loan to purchase a house(`Home Purchase loan`) it has a significant approval rate.\n   - If you want $100$% rate of approval for your loan, then, apply for HOEPA loans.\n   - Secure your loan through first lien.","metadata":{"id":"SKa_je61RJJ2"}},{"cell_type":"markdown","source":"<br>\n<br>\n<h1'style=text-align:center';>2.0.0) FEATURE ENGINEERING SECTION<h1>\n<br>","metadata":{"id":"O5ITYSCCRJJ3"}},{"cell_type":"markdown","source":"* Lets start by selecting features that are likely to be used in the model and drop the rest.It advisable to take out irrelevant features to simplify the dataset.\n* Some of the  features too contain huge number of missing values which may lead to wrong predictions if not taken out.\n* The `county_name` contains 209 missing values. You could see that most columns have missing values in that rows as well so it is logical to drop those rows.","metadata":{"id":"qFME42LARJJ3"}},{"cell_type":"code","source":"df_main.isna().sum()","metadata":{"scrolled":true,"id":"ZfHprG96RJJ3","outputId":"8654dc02-caf9-40a0-adc3-2df1dfd099e7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# list of selected features to maintain\nsel_feat = ['tract_to_msamd_income','population','minority_population','number_of_owner_occupied_units',\n'number_of_1_to_4_family_units','loan_amount_000s','hud_median_family_income',\n 'property_type_name', 'owner_occupancy_name', 'loan_type_name', 'loan_purpose_name', 'lien_status_name',\n 'hoepa_status_name', 'county_name','co_applicant_sex_name','co_applicant_race_name_1',\n 'co_applicant_ethnicity_name', 'census_tract_number', 'applicant_sex_name',\n 'applicant_race_name_1', 'applicant_ethnicity_name', 'agency_name', 'action_taken_name', 'loan_approved']\n\n# Dropping all null values from county_names\ndf_selected = df_main[sel_feat].dropna(subset=['county_name'])","metadata":{"id":"axSWjn9kRJJ9","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.0.1) CREATING NEW FEATURES\n* we will create some new features from existing ones","metadata":{"id":"O4rZUGljRJKA"}},{"cell_type":"markdown","source":"### Co_Applicants Sex\n* We will create one additional feature out of this column then we label encode the as-is data\n\n* The `Male` and `Female` gender has quite similar rate so we will create a binary feature called `co_appl_gender_vs_na` which consist of the two gender vs the other categories.\n","metadata":{"id":"M67T_wMyRJKA"}},{"cell_type":"code","source":"df_selected.loc[:,'co_appl_sex_vs_NA_cat'] = df_selected.loc[:,'co_applicant_sex_name']\\\n           .apply(lambda x:1 if ((x == 'Female')| ( x == 'Male')) else 0)","metadata":{"id":"WHzMFCQGRJKA","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Applicant Sex name\n**NB:** As we did to the co-applicant, so as we will do to the main applicants\n* We will create one additional feature out of this column then we label encode the as-is data\n\n* The `Male` and `Female` gender has quite similar rate so we will create a binary feature called `appl_gender_vs_na` which consist of the two gender vs the other categories.\n","metadata":{"id":"qvHfL7-YRJKC"}},{"cell_type":"code","source":"df_selected.loc[:,'appl_gender_vs_NA'] = df_selected.loc[:,'applicant_sex_name']\\\n           .apply(lambda x:1 if ((x == 'Female')| ( x == 'Male')) else 0)","metadata":{"id":"I3JdyWF3RJKD","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Co_Applicant ethnicity\n* we will create a feature `is_majority` to determine if applicant is minority or majoriy or none=2\n* No_applicant has the least rate of approval\n* We then encode the feature with integer values\n","metadata":{"id":"4OJT7fEERJKF"}},{"cell_type":"code","source":"df_selected.loc[:,'is_majority'] = df_selected.loc[:,'co_applicant_ethnicity_name']\\\n                             .apply(lambda x: 1 if (x == 'Not Hispanic or Latino') else 0 if (x == 'Hispanic or Latino') else 2)\n","metadata":{"id":"kPiX7W7DRJKF","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Applicant Race \n*  We will create a feature `is_black`: a binary feature showing if applicant is black or not.","metadata":{"id":"EixMI4EjRJKH"}},{"cell_type":"code","source":"\ndf_selected.loc[:,'is_black'] = df_selected.loc[:,'applicant_race_name_1']\\\n                             .apply(lambda x: 1 if (x == 'Black or African American') else 0)","metadata":{"id":"XmGJrIwgRJKH","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.0.2) PREPROCESSING OF CATEGORICAL FEATURES.\n\n* Most machine learning models do recognize only numerical data so we will encode all non-numeric categorical features to numeric.  \n* We will also demonstrate how the feature also correlate with the target variable","metadata":{"id":"zIK4RNlkRJKN"}},{"cell_type":"code","source":"# define a function to encode all the categorical variables\ndef cat_encoder(df,exist_cols,new_cols):\n    for exist,new in zip(exist_cols,new_cols):\n        df.loc[:,new] = le.fit_transform(df.loc[:,exist])\n    return df","metadata":{"id":"8kuJLybrRJKN","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# new columns to create\nnew_cols =['prop_type_cat','owner_occu_cat','loan_type_cat','loan_purp_cat','lien_status_cat',\n           'hoepa_status_cat','appl_ethnicity_cat','agency_cat','county_cat']\n\n# existing columns to create from\nexist_cols =['property_type_name','owner_occupancy_name','loan_type_name','loan_purpose_name',\n             'lien_status_name','hoepa_status_name','applicant_ethnicity_name','agency_name','county_name']\n\n# encode all non-numeric categorical variables using label encoder\ndf_selected = cat_encoder(df_selected,exist_cols,new_cols)","metadata":{"id":"O948AxnERJKQ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define function to correlate all the categorical variables with the target\ndef correlator(df,col_names):\n    for col_n in col_names:\n        print('\\n\\n'+color.BOLD+col_n.upper()+color.END+'\\n\\n',df[[col_n,'loan_approved']].groupby(col_n).mean())\n\n# print correlation\ncorrelator(df_selected,new_cols)","metadata":{"id":"K45zT6Z1RJKS","outputId":"7e2c0854-73b2-4705-f67b-5a72d32d4595","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.0.3) COMBINING TWO FEATURES\n### Hoepa status and Owner occupancy\nHoepa status and Owner occupancy name combination [as shown here](#hoepa_owner) has different approval rates. So we will create a feature called `hoepa_owner` to have this combination.","metadata":{"id":"NqRtJbj_RJKU"}},{"cell_type":"code","source":"# df_selected.loc[:,'hoepa_owner'] = (df_selected['hoepa_status_name'].astype(str) + df_selected['owner_occupancy_name'].astype(str))\n\n# get list of owner occupancy status name\nowner_occup = df_selected['owner_occu_cat'].unique().tolist()\n\n# get list of hoepa status name\nhoepa  = df_selected['hoepa_status_cat'].unique().tolist()\n\n# create feature initialize with `0`\ndf_selected.loc[:,'hoepa_owner'] = 0\n\nfor owner_st in owner_occup:\n    for hoepa_st in hoepa:\n#         get the index of the row in the two-feature combination\n        indx = df_selected[(df_selected.loc[:,'owner_occu_cat'] == owner_st)\\\n        & (df_selected.loc[:,'hoepa_status_cat'] == hoepa_st)].index.tolist()\n        \n#         insert into a selected rows\n        df_selected.loc[indx,'hoepa_owner'] = int(str(owner_st)+str(hoepa_st))\n    \n# plot\ndf_selected[['hoepa_owner','loan_approved']].groupby('hoepa_owner').mean().plot(kind='bar')\nplt.ylabel('Rate');\n","metadata":{"id":"yZOv2uuKRJKV","outputId":"c11ca504-93f4-4237-a2c6-38289a9d86e0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.0.4) NUMERICAL FEATURES","metadata":{"id":"UF756tpNRJKX"}},{"cell_type":"markdown","source":"### Tract_to_msamd\n\n`Tract_to_msamd` is the median family income for the tract compared to the median family income for the `MSA/MD`.\n* The min,max and mean values of the `Tract_to_msamd` varies in the various counties.\n* From the **boxplot**, counties also have various degree of outliers and they have minimal standard deviation.  \n**Decision: We will fill in the null values in `Tract_to_msamd` with the mean value of each respective county  \n<br>\n\n* we will divide the `tract-to-income` feature into $20$ equal groups.\n* It is observed from the **line plot** that, the higher the `tract-to-income` of the property location, the higher the chances of `loan approval`.\n\n<br>  \n* Lets then create a heatmap of `tract-to-income` and `type of property` and study its relationship aswell.\n* The approval rate of all the `Property types` increases as the `tract-to-income` increase in exception of `Multi dwelling home` which is higher no matter the tract income. We will create new feature called `tract_to_prop` to hold the product of these two features.\n\n  - At the far right side of the `barplot` you could see a smooth bar increasing towards the right-end. From the middle to the left-end has spike and bumps.","metadata":{"id":"l9TUwPrNRJKX"}},{"cell_type":"code","source":"# create boxplot\nfig,ax = plt.subplots(nrows=4,ncols=1,figsize=(16,25))\nsns.boxplot(x='county_name',y='tract_to_msamd_income',data=df_selected,ax=ax[0])\n\n# make the x_tick labels invisible\nax[0].set_title('tract_to_msamd_income VS county_name')\nax[0].axes.xaxis.set_ticks([]);\n\n# fill tract_to_msamd_income with it average county tract_to_msamd_income value\ndf_selected['tract_to_msamd_income'] = df_selected[['county_name','tract_to_msamd_income']]\\\n                                       .groupby('county_name').transform(lambda x: x.fillna(x.mean()))\n\n\n# group tract_to_msamd_income into 20 quantiles\ndf_selected.loc[:,'tract_to_msamd_cat'] = pd.qcut(df_selected['tract_to_msamd_income'],q=20,labels=np.arange(1,21,1))\n\n# Finally let transform\ndf_selected.loc[:,'tract_to_msamd_cat'] = le.fit_transform(df_selected['tract_to_msamd_cat'])\n\ndf_selected[['tract_to_msamd_cat','loan_approved']].groupby('tract_to_msamd_cat').mean().plot(ax=ax[1])\n\nax[1].set_title('Tract to msamd income categories VS Approval rate')\nax[1].set_xlabel('Tract to msamd income categories')\nax[1].set_ylabel('Approval rate')\n\n\n\n\n# make a pivot table with various features of the main dataframe.\ndf_pivot = pd.pivot_table(df_selected,values='loan_approved',\n                                     index='tract_to_msamd_cat',columns='property_type_name')\n\n# draw a heatmap\nsns.heatmap(df_pivot,annot=True,annot_kws={\"size\": 15},linewidths=2, linecolor='yellow',ax=ax[2])\n\n# get the bottom and top size of the map\nbottom,top = ax[2].get_ylim()\n\n# add 1/2 each to make the edge full\nax[2].set_ylim(bottom+0.5,top-0.5)\n\n# providing x and y labels\nax[2].axes.xaxis.set_ticklabels(['Manufactured housing','Multifamily dwelling','one-to-four family dwelling'])\nax[2].axes.yaxis.set_ticklabels(['Min']+['']*18+['max'])\n\n# rotate the xtick labels\nplt.setp(ax[2].get_xticklabels(), rotation=10, ha=\"right\",\n         rotation_mode=\"anchor\");\n\nax[2].set_title('Property Type name VS Tract-to-msamd income ')\nax[2].set_ylabel('Tract-to-msamd income')\nax[2].set_xlabel('Property Type name');\n\n\n\n# create `tract_to_prop` from 'tract_to_msamd_cat' * 'prop_type_cat'\ndf_selected.loc[:,'tract_to_prop'] = df_selected[['tract_to_msamd_cat','prop_type_cat']].product(axis=1).astype(int)\n\n# create a lineplot with tract_to_prop vs loan_approved\ndf_selected[['tract_to_prop','loan_approved']].groupby('tract_to_prop').mean().plot(kind='bar',ax=ax[3])\n\nax[3].set_title('tract-income-to-property vs Approval rate')\nax[3].set_ylabel('Approval Rate');\n\nplt.tight_layout();\n","metadata":{"id":"FhZxBmbmRJKY","outputId":"c8a8ed34-e21e-4be8-fd15-0abf85fe4bb1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Number of Owner Occupied Units\n* This has $151$ missing values.\n* `number_of_owner_occupied_units` correlates with the `tract_to_prop` as shown on the box plot.\n* There is high standard deviation between the `Number of Owner Occupied Units`  in each respective county.\n* we will then fill the missing values by the median values groupby the county.","metadata":{"id":"6qcApUagRJKa"}},{"cell_type":"code","source":"print(df_selected[['tract_to_prop','number_of_owner_occupied_units']]\\\n            .groupby('tract_to_prop',sort=False).agg(['max','mean','min','std']).head())\n\nprint('\\n\\n')\n\n# create boxplot\nfig,ax = plt.subplots(figsize=(16,6))\nsns.boxplot(x='tract_to_prop',y='number_of_owner_occupied_units',data=df_selected);\nplt.show()\n\n# fill NaN values with the median value of each group\n\ndf_selected['number_of_owner_occupied_units'] = df_selected[['tract_to_prop','number_of_owner_occupied_units']]\\\n            .groupby('tract_to_prop').transform(lambda x:x.fillna(x.median()))","metadata":{"id":"W5aaDlcVRJKa","outputId":"00c116e5-8743-44cd-f23f-909918cbf41a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.0.5) LETS PREPROCESS THE FOLLOWING CONTINOUS FEATURES TOGETHER\n\n### `population`,`minority_population`,`number_of_1_to_4_family_units`\n### `hud_median_family_income`,`census_tract_number`","metadata":{"id":"4zPTFcE2RJKd"}},{"cell_type":"markdown","source":"* Lets fill the remaining missing values in the continuous variables with the median value grouped by the county_name.\n\n* As we can see,the features have various degree of skewness. High skewed feature can lead to overweigth very high values in the model, even if it is scaled. We can apply two solutions here: either we use `log function` or group it into `bins`.  \n* After the log transformation, it is crystal clear that the data is normalized and therefore the skewness too was reduced.\n\n\nLogarithm transformation (or log transform) is one of the most commonly used mathematical transformations in feature engineering.It helps to handle skewed data and after transformation, the distribution becomes more approximate to normal","metadata":{"id":"2oZIcoT2RJKd"}},{"cell_type":"code","source":"# list of continuous varible names\ncont_vars = ['population','minority_population','number_of_1_to_4_family_units',\n             'hud_median_family_income','census_tract_number']\n\n# iterate over the list and fill in with the median value\nfor var in cont_vars:\n    df_selected[var] = df_selected[['county_cat',var]].groupby('county_cat')\\\n                         .transform(lambda x: x.fillna(x.median()))","metadata":{"id":"ez6gr2d3RJKe","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_selected['minority_population'].hist()","metadata":{"id":"wBKeQKOkRJKg","outputId":"ce01fc18-9999-4f03-9e8e-14e01a121c74","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create a figure with a width=16 and height=10\nplt.figure(figsize=(16,10))\n\n# assign axis to a variable\nax1,ax2,ax3,ax4,ax5 = plt.subplot(3,2,1),plt.subplot(3,2,2),plt.subplot(3,2,3),plt.subplot(3,2,4),plt.subplot(3,2,5)\n\nfor axes in enumerate((ax1,ax2,ax3,ax4,ax5)):\n#   Iterate throught axis and do the plotting\n    axes[1].hist(df_selected[cont_vars[axes[0]]],bins='auto',color=\"m\", \n                 label=\"Skewness : %.2f\"%(df_selected[cont_vars[axes[0]]].skew()))\n    \n    axes[1].legend(loc=\"best\")\n    axes[1].set_title(cont_vars[axes[0]],fontdict={'fontweight':'bold'})\nplt.tight_layout();","metadata":{"id":"ZTKg3MV-RJKi","outputId":"8c502b1d-a067-4c5c-86ec-41f49b6ce852","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lets apply the `log` funtion to each feature\nfor cont in cont_vars:\n    df_selected.loc[:,cont] = df_selected[cont].transform(np.log)","metadata":{"id":"Ph91PxlYRJKk","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# AFTER LOG TRANSFORMATION\n# create a figure with a width=16 and height=10\nplt.figure(figsize=(16,10))\n\n# assign axis to a variable\nax1,ax2,ax3,ax4,ax5 = plt.subplot(3,2,1),plt.subplot(3,2,2),plt.subplot(3,2,3),plt.subplot(3,2,4),plt.subplot(3,2,5)\n\nfor axes in enumerate((ax1,ax2,ax3,ax4,ax5)):\n#   Iterate throught axis and do the plotting\n    axes[1].hist(df_selected[cont_vars[axes[0]]],bins='auto',color=\"m\", \n                 label=\"Skewness : %.2f\"%(df_selected[cont_vars[axes[0]]].skew()))\n    \n    axes[1].legend(loc=\"best\")\n    axes[1].set_title(cont_vars[axes[0]],fontdict={'fontweight':'bold'})\nplt.tight_layout();","metadata":{"id":"u_vPREeiRJKm","outputId":"e7b22e59-9ba4-4bb5-955f-528d5c81bc80","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now lets check some info about the data\ndf_selected.info()","metadata":{"id":"9o45SpxSRJKq","outputId":"59138cbb-7613-4a25-eda5-ccec1e8325a9","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we will drop all object type data column from the dataset\ndf_selected.drop(df_selected.select_dtypes('object').columns.tolist(),axis=1,inplace=True)","metadata":{"id":"1HsyvEZURJKs","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_selected.info()","metadata":{"id":"nYGJOg0sRJKt","outputId":"7803b695-3b33-4dcc-f802-8121e0fe8fe3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* The following categorical features and converted to one-hot-encoded features using the `OneHotEncoder()`   \n(`prop_type_ca`',`owner_occu_ca`',`loan_type_cat`,`loan_purp_cat`,`lien_status_cat`,`hoepa_status_cat`,    `appl_ethnicity_cat`,`agency_cat`,`county_cat`,`tract_to_prop`,`co_appl_sex_vs_NA_cat`,  \n`appl_gender_vs_NA`,`is_majority`,`is_black`,`hoepa_owner`) the rest of the features are not converted because they are ordinal unlike the previous ones.\n\n* All the unwanted features are dropped afterwards","metadata":{"id":"JK7Ggt5CRJKx"}},{"cell_type":"code","source":"# Get all the column names with `int32` and `int64` datatype\nto_hot_encode = df_selected.select_dtypes('int32').columns.tolist() + df_selected.select_dtypes('int64')\\\n                           .drop(['loan_amount_000s','loan_approved','tract_to_msamd_cat'],axis=1).columns.tolist() ","metadata":{"id":"PsitEXkoRJKy","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoded_features = []\nfor feature in to_hot_encode:\n    encoded_feat = OneHotEncoder(categories='auto').fit_transform(df_selected[feature].values.reshape(-1, 1)).toarray()\n    n = df_selected[feature].nunique()\n    cols = ['{}_{}'.format(feature, n) for n in range(1, n + 1)]\n    encoded_df = pd.DataFrame(encoded_feat, columns=cols)\n    encoded_df.index = df_selected.index\n    encoded_features.append(encoded_df)\n\n# concatenate the encoded features to the dataframe and drop the previous features\ndf_X_y_train_test = pd.concat([df_selected, *encoded_features], axis=1).drop(to_hot_encode,axis=1)","metadata":{"id":"wvW6vdbKRJKz","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<br>\n<h1'style=text-align:center';>3.0.0) PREDICTION SECTION<h1>\n<br>","metadata":{"id":"AAdl2zsQRJK2"}},{"cell_type":"code","source":"df_X_y_train_test.head()","metadata":{"id":"jDZUhh-DRJK2","outputId":"d494b4db-760a-4161-e281-da7d854cdb81","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### The entire dataset is being divided into train and test set and normalized","metadata":{"id":"8nEj6Kd7RJK4"}},{"cell_type":"code","source":"# Split the dataset into train and test with 75% and 25% respectively\nX_train, X_test, y_train, y_test = train_test_split(df_X_y_train_test.drop('loan_approved',axis=1),\n                                                    df_X_y_train_test['loan_approved'], test_size=0.25, random_state=42)\n\n# reset the indices\nfor data in [X_train, X_test, y_train, y_test]:\n    data.reset_index(drop=True,inplace=True)","metadata":{"id":"Ag0yXIv7RJK4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Normalization\nscaler = StandardScaler()\n\nX_train_norm = scaler.fit_transform(X_train)\n\nX_test_norm = scaler.transform(X_test)\n\n# print current shapes\nprint('X_train shape = {} \\n y_train shape = {}\\n'.format(X_train_norm.shape,y_train.shape))\nprint('X_test shape = {} \\n y_test shape = {}'.format(X_test_norm.shape,y_test.shape))","metadata":{"id":"_pXLw1dTRJK6","outputId":"d2318516-3b89-4d56-e533-f6c27a05f31d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"single_best_model = RandomForestClassifier(criterion='gini', \n                                           n_estimators=1100,\n                                           max_depth=5,\n                                           min_samples_split=4,\n                                           min_samples_leaf=5,\n                                           max_features='auto',\n                                           oob_score=True,\n                                           random_state=SEED,\n                                           n_jobs=-1,\n                                           verbose=1)\n","metadata":{"id":"CoxCaxUFRJK8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nleaderboard_model = RandomForestClassifier(criterion='gini',\n                                           n_estimators=1750,\n                                           max_depth=7,\n                                           min_samples_split=6,\n                                           min_samples_leaf=6,\n                                           max_features='auto',\n                                           oob_score=True,\n                                           random_state=SEED,\n                                           n_jobs=-1,\n                                           verbose=1) ","metadata":{"id":"7HXcWUn3RJK-","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets Intantiate our classifier\nrc = RandomForestClassifier(oob_score=True)\n# We can get the defaults parameters with this function\nrc.get_params()","metadata":{"id":"F0qpXO1LRJLD","outputId":"e8176805-4768-44a8-ab55-d767f07dd2e4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"n_estimators = number of trees in the foreset   \nmax_features = max number of features considered for splitting a node  \nmax_depth = max number of levels in each decision tree  \nmin_samples_split = min number of data points placed in a node before the node is split  \nmin_samples_leaf = min number of data points allowed in a leaf node  \nbootstrap = method for sampling data points (with or without replacement)  ","metadata":{"id":"Ig7wg0zyRJLJ"}},{"cell_type":"code","source":"N = 5\noob = 0\nprobs = pd.DataFrame(np.zeros((len(X_test_norm), N * 2)), \n                     columns=['Fold_{}_Prob_{}'.format(i, j) for i in range(1, N + 1) for j in range(2)])\n\nimportances = pd.DataFrame(np.zeros((X_train_norm.shape[1], N)),\n    columns=['Fold_{}'.format(i) for i in range(1, N + 1)], index=df_X_y_train_test.drop('loan_approved',axis=1).columns)\nimportances\n\nfprs, tprs, scores = [], [], []\n\nskf = StratifiedKFold(n_splits=N, random_state=N, shuffle=True)\ny_train = y_train.reset_index(drop=True)\nfor fold, (trn_idx, val_idx) in enumerate(skf.split(X_train_norm, y_train), 1):\n    print('Fold {}\\n'.format(fold))\n    # Fitting the model\n    leaderboard_model.fit(X_train_norm[trn_idx], y_train[trn_idx])\n    \n    # Computing Train AUC score\n    trn_fpr, trn_tpr, trn_thresholds = roc_curve(y_train[trn_idx], leaderboard_model.predict_proba(X_train_norm[trn_idx])[:, 1])\n    trn_auc_score = auc(trn_fpr, trn_tpr)\n#     Computing Validation AUC score\n    val_fpr, val_tpr, val_thresholds = roc_curve(y_train[val_idx], leaderboard_model.predict_proba(X_train_norm[val_idx])[:, 1])\n    val_auc_score = auc(val_fpr, val_tpr)  \n      \n    scores.append((trn_auc_score, val_auc_score))\n    fprs.append(val_fpr)\n    tprs.append(val_tpr)\n    \n    # X_test_norm probabilities\n    probs.loc[:, 'Fold_{}_Prob_0'.format(fold)] = leaderboard_model.predict_proba(X_test_norm)[:, 0]\n    probs.loc[:, 'Fold_{}_Prob_1'.format(fold)] = leaderboard_model.predict_proba(X_test_norm)[:, 1]\n    importances.iloc[:, fold - 1] = leaderboard_model.feature_importances_\n        \n    oob += leaderboard_model.oob_score_ / N\n    print('Fold {} OOB Score: {}\\n'.format(fold, leaderboard_model.oob_score_))   \n    \nprint('Average OOB Score: {}'.format(oob))","metadata":{"id":"5AqJnu_JRJLK","outputId":"9f376b73-9f20-42d9-9ae2-8a2b359defaf","trusted":true},"execution_count":null,"outputs":[]}]}