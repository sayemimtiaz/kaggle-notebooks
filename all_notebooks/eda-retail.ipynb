{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Exploratory Data Analysis - Retail\n> TSF:GRIP Data Science & Business Analytics Task By: Aimen Baig\n\n**task:** As a business manager, try to find out the weak areas where you can work to make more profit? What all business problems you can derive by exploring the data?\n ","metadata":{"editable":false}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This task will extractdata. Appropriate preprocessing will be done and data exploration will be performed on the data. \nFollowing the purpose of this task, the primary focus will be on profit-related factors, which are the attributes 'Sales' and 'Profit' in American Dollars (USD) measurements, as well as the integer value of 'Quantity' and percentage values of 'Discount' for each sales transaction. Analysing these will help to identify and assess concern areas.","metadata":{"editable":false}},{"cell_type":"markdown","source":"","metadata":{"editable":false}},{"cell_type":"markdown","source":"# 1. Data Collection\nWe will import the data look into it's type, and dive into the meaning of every attribute","metadata":{"editable":false}},{"cell_type":"code","source":"# import data\ndf = pd.read_csv('../input/sample-supermarket-dataset/SampleSuperstore.csv')\ndf.head()\n# show first 5 records","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{"editable":false}},{"cell_type":"code","source":"# checking the type of data\ntype(df)","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# column names\ndf.columns","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" Regarding the attributes included in SampleSuperstore dataset\n*  'Ship Mode' is the method of shipping the physical goods and products to the intended customers\n*  'Segment' specifies the customer segment or marketing groups according to their interests and demographics\n*  'Country' is all in the United States of America (USA), \n*  'City' refers to the cities in USA\n* 'State' is made up of the states in USA,\n*  'Postal Code' denotes the postal destination address sorted by the regions in USA \n* 'Region' Country region\n* 'Category' consists of the named groups of similar and defined physical products\n* 'Sub-Category' lists the subdivisions with respect to a given category\n* 'Sales' are the monetary value of transactions between the Superstore and its customers of physical goods in American Dollars (USD$) measurements\n* 'Quantity' records the number of such products in each sales transaction\n* 'Discount' states the percentage of monetary deduction from the usual product price\n* 'Profit' is the financial gains in USD from each transaction.","metadata":{"editable":false}},{"cell_type":"markdown","source":"# Data Preprocessing\n","metadata":{"editable":false}},{"cell_type":"markdown","source":"Now we will convert the raw data into understandable format and we'll focus on 4 steps:\n1. Data cleaning: null values within the dataset will be identified, and appropriately replaced if possible,then we will check for typos or inconsistent capitalization of records in columns\n","metadata":{"editable":false}},{"cell_type":"code","source":"#checking for null values and attribute type\ndf.info()","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#representing missing values\nsns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='viridis')","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From above output, we can see that:\n* there are no null values.\n* We have 8 categorical attributes\n* We have two quantitative discrete integers attributes i.e. Postal Code and Quantity \n* 3 quantitative continuous numerical floats with 64 digit placings","metadata":{"editable":false}},{"cell_type":"code","source":"","metadata":{"editable":false},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking for unique categories in object type attributes (categorical)\ncatagorical_features = [i for i in df.columns if df.dtypes[i] == 'object']\nfor j in catagorical_features:\n    print('\\033[1m' + j + '\\033[0m')\n    print(sorted(df[j].unique())) # sort in alphabetical order","metadata":{"editable":false,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#df.apply(pd.Series.value_counts)\n","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"By looking at the  above output,there are no Typos, Repetitive entries or any structural errors(inconsistent capitalization or mislabeled columns) in the data.","metadata":{"editable":false}},{"cell_type":"markdown","source":"Now we shall observe the unique value counts ahead","metadata":{"editable":false}},{"cell_type":"code","source":"# count of unique values\ndf.nunique()","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{"editable":false}},{"cell_type":"markdown","source":"above we also see that the \"Country\" column has only one category, this is not gonna take any parts in generating patterns therefore, we'll consider to drop it in future in our data reduction step","metadata":{"editable":false}},{"cell_type":"markdown","source":"Up next, we are gonna try to detect the outliers in the dataset by looking in to the histograms of the numerical attributes.","metadata":{"editable":false}},{"cell_type":"code","source":"#matplotlib inline # only in a Jupyter notebook\nimport matplotlib.pyplot as plt\ndf.hist(bins=50, figsize=(20,15))\nplt.show()\n","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The values are resonable and lie within an expected range hence there are no outliers to connsider specifically","metadata":{"editable":false}},{"cell_type":"markdown","source":"Now we are going to handle the duplicate entries in our data set.\n> Duplicated rows or records can now by dropped from the dataset, as this redundancy may cause inaccurate results and outcomes (an assumption on the dataset).","metadata":{"editable":false}},{"cell_type":"code","source":"# detect duplicated records\ndf[df.duplicated(subset = None, keep = False)]","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# drop duplicated records, retain only one copy for each\ndf = pd.DataFrame.drop_duplicates(df)\ndf.shape\n# 9977 unique records for 12 attributes shown below\n","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Data reduction:** Data reduction involves dropping the attribute ‘Country’ through attribute dimensionality reduction, since it is containing 100% exact same values of \"United States\" for all records. 'Postal Code' is also dropped since this attribute is useless when we're interested in profit.","metadata":{"editable":false}},{"cell_type":"code","source":"# drop Country\ndf = df.drop(['Country'], axis = 1)\ndf = df.drop(['Postal Code'], axis = 1)","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Up next, we're going to observe some correlations ahead\n> A correlation heatmap is used to list all the correlation coefficients in order to identify multicollinearity, in other words high intercorrelation above an absolute value of 0.5 between the a pair of attributes. For a pair of attributes with multicollinearity, one of them will be dropped since it would be redudant to include both of them with almost mirroring values. Another reason is to prevent overfitting.\n\nThe correlation will compare and describe the linear connection and relationship between pairs of features, through the type of correlation and its strength. A positive correlation indicates that both features will change their values in the same direction, while a negative correlation indicates that both will change in opposite directions. The larger the correlation strength, the stronger the connection and relationship.","metadata":{"editable":false}},{"cell_type":"code","source":"sns.heatmap(df.corr(), cmap = 'PuBu', annot = True)\nplt.show()","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In this case, the only predictors i will consider to  drop will be if their intercorrelations are above 0.95 and almost perfect descriptions of each other. It would be a cause of \"redundancy\" to include both of them. Therefore, no attributes were removed. no multicollinearity was found.","metadata":{"editable":false}},{"cell_type":"markdown","source":"finally the preprocessing is complete :","metadata":{"editable":false}},{"cell_type":"code","source":"# display the number of entries, the number and names of the column attributes, the data type \ndf.info()","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA\nNow after complete preprocessing, we will analyse the data ","metadata":{"editable":false}},{"cell_type":"markdown","source":"The Summary statistics:","metadata":{"editable":false}},{"cell_type":"code","source":"df.describe()","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# total Sales\nround(sum(df['Sales']), 2)\n","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# total Quantity sold\nsum(df['Quantity'])","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# total Profit\nround(sum(df['Profit']), 2)","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Firstly, the total sales is USD2296195.59 ,  USD230.148902 average for every transaction. it's minimum value is USD0.4444000 and maximum is USD22638.48.\nThe total Quantity sold was 37820 of products, with an average of 4 being sold throughout the individual transactions. the range of product sold starts from 1 to 14\nAverage discount was 16% for each transaction. This can range from no discount to a  highest discount of 80% for an individual transaction.\n\nThe Superstore made a total profit of USD28,6241.42, and USD28.69 on average for each transaction. However, this can range from a loss of USD6,599.98 to a profit of USD8,399.98 for an individual transaction.\n\n","metadata":{"editable":false}},{"cell_type":"markdown","source":"Now, we're gong to use kernel density curves for visualising the distributions of both sales and profit in a form of continous probability density curve. ","metadata":{"editable":false}},{"cell_type":"markdown","source":"","metadata":{"editable":false}},{"cell_type":"code","source":"plt.figure(figsize = (15, 5))\n# plot Sales and Profit for comparisons\nsns.kdeplot(df['Sales'], color = 'Teal', label = 'Sales', shade = True, bw = 25)\nsns.kdeplot(df['Profit'], color = 'Cornflowerblue', label = 'Profit', shade = True, bw = 25)\nplt.xlim([0, 13000])\nplt.ylim([0, 0.00007])\nplt.ylabel('Density')\nplt.xlabel('Monetary Value in USD$')\nplt.title('Sales and Profit', fontsize = 20)\nplt.legend(loc = 'upper right', frameon = False) \nplt.show()","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (15, 5))\n# plot Sales and Profit for comparisons\nsns.kdeplot(df['Sales'], color = 'Teal', label = 'Sales', shade = True, bw = 25)\nsns.kdeplot(df['Profit'], color = 'Cornflowerblue', label = 'Profit', shade = True, bw = 25)\nplt.xlim([13000, 22640])\nplt.ylim([0, 0.00002])\nplt.ylabel('Density')\nplt.xlabel('Monetary Value in USD$')\nplt.title('Sales and Profit', fontsize = 20)\nplt.legend(loc = 'upper right', frameon = False) \nplt.show()","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In above plots, the profit values are mostly above than the sales. Which shows good business of the superstore. But sales above USD 8500 are having decreased profits and they are the areas where the improvement is needed.","metadata":{"editable":false}},{"cell_type":"markdown","source":"next, we're going to observe some Pearson correlations","metadata":{"editable":false}},{"cell_type":"code","source":" # correlation matrix\nsns.heatmap(df.corr(), cmap = 'PuBu', annot = True)\nplt.show()","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Sales and Profit have a moderate positive linear correlation indicating good business. Discount and Profit have a weak negative linear correlation which means the discounts that were given to increase the profits were causing a negative impact on the profit( it might be bacause of the bad quality products etc or maybe the consumers  find it suspicious that the discounts are given ). Quantity and Profit have little to no linear correlation i.e when increasing quantity it has little to no effect on the profit maybe because superstore might have promotional strageties of buy one get one etc. similarly with increasing discounts the customers were not likely to buy the product hence resulting in a negative correlation. ","metadata":{"editable":false}},{"cell_type":"markdown","source":"","metadata":{"editable":false}},{"cell_type":"markdown","source":"now for the categorical attributes:","metadata":{"editable":false}},{"cell_type":"code","source":"# count of each Category, Segment, Ship Mode, and Region\nfig, axs = plt.subplots(nrows = 2, ncols = 2, figsize=(10, 7));\nsns.countplot(df['Category'], ax = axs[0][0], palette = 'PuBu')\nsns.countplot(df['Segment'], ax = axs[0][1], palette = 'PuBu')\nsns.countplot(df['Ship Mode'], ax = axs[1][0], palette = 'PuBu')\nsns.countplot(df['Region'], ax = axs[1][1], palette = 'PuBu')\naxs[0][0].set_title('Category', fontsize = 20)\naxs[0][1].set_title('Segment', fontsize = 20)\naxs[1][0].set_title('Ship Mode', fontsize = 20)\naxs[1][1].set_title('Region', fontsize = 20)\nplt.tight_layout()","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"now we're going to make a scatterplot to observe the spread of datapoints betwen sales and profit.","metadata":{"editable":false}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (10, 6))\n# scatterplot of Sales and Profit\nax.scatter(df[\"Sales\"] , df[\"Profit\"], color = 'Teal')\nax.set_xlabel('Sales in USD$')\nax.set_ylabel('Profit/Loss in USD$')\nplt.title('Sales and Profit', fontsize = 20)\nplt.show()","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Most of the sales were made under 5k, individuals who were from the \"consumer segment\" as we seen above were likely to buy goods that were less in making profits. \n\nSales under USD2500 were in loss maybe because of the discounted products which decreased the overall revenue.\n\nSales above USD5000 were hugely profitable. ","metadata":{"editable":false}},{"cell_type":"markdown","source":"Now We're going to dive into the state wise analysis: \n1. We're going to see the sales in every state\n2. We're going to see the profits generated in every state\n3. We're going to give the discounts given off in every state","metadata":{"editable":false}},{"cell_type":"code","source":"# total Sales for each State\ndf_state_sales = df.groupby('State')['Sales'].sum().sort_values(ascending = False).plot.bar(figsize = (15, 5), \n                                                                                            color = 'Cornflowerblue')\nplt.ylabel('Total Sales in USD$')\nplt.xlabel('American States')\nplt.title('Total State-Wise Sales', fontsize = 20)\nplt.show()","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# total Profit for each State\ndf_state_profit = df.groupby('State')['Profit'].sum().sort_values(ascending = False).plot.bar(figsize = (15, 5), \n                                                                                              color = 'Cornflowerblue')\nplt.ylabel('Total Profit/Loss in USD$')\nplt.xlabel('American States')\nplt.title('Total State-Wise Profit/Loss', fontsize = 20)\nplt.show()","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# average Discount for each State\ndf_state_profit = df.groupby('State')['Discount'].mean().sort_values(ascending = False).plot.bar(figsize = (15, 5), \n                                                                                                 color = 'Cornflowerblue')\nplt.ylabel('Average Discount')\nplt.xlabel('American States')\nplt.title('Average State-Wise Discount', fontsize = 20)\nplt.show()","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"California and New York are the top 2 places, with higher  profits of around USD 75k.\n\n\nTexas, despite having the third highest sales, suffered the highest loss of around USD25k. This may be because it has the second highest discount level. Superstore is advised to reduce discount levels in Texas, and instead switch to other promotional strategies, in order to minimise losses.\n\nPennsylvania, Illinois, and Ohio are the third, first, and fourth state offering larger discounts respectively, and this may be the reason behind them resulting in the third, fourth, and second biggest loss of around USD15k. Superstore is advised to switch to giving less discounts.\n\nCalifornia gives out considerably lower discounts, which may be one of the reasons behind it being top in sales and profit. This is indicative that the promotional strategy of offering less discounts is highly effective in the state of California.\n\nMore than half the states make little to no profit, and a significant number of these even suffer from loss.\n\nA majority of states offer  discounts under 10%.","metadata":{"editable":false}},{"cell_type":"markdown","source":"now we're going to see some subcategories and their profit/loss","metadata":{"editable":false}},{"cell_type":"markdown","source":"","metadata":{"editable":false}},{"cell_type":"code","source":"# total Profit for each State\ndf_state_profit = df.groupby('Sub-Category')['Profit'].sum().sort_values(ascending = False).plot.bar(figsize = (15, 5), \n                                                                                              color = 'Cornflowerblue')\nplt.ylabel('Total Profit/Loss in USD$')\nplt.xlabel('Sub-categories')\nplt.title('Total Sub-category wise Profit/Loss', fontsize = 20)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"editable":false},"execution_count":null,"outputs":[]}]}