{"cells":[{"metadata":{},"cell_type":"markdown","source":"# GTSRB Classification with VGG-19"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport cv2\nimport csv\nimport numpy as np\nfrom time import time\nfrom tensorflow.keras import utils\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, BatchNormalization\nfrom tensorflow.keras.applications import VGG19\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## The data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"dir = '../input/gtsrb-german-traffic-sign'\n    \nplt.figure(figsize=(10, 10))\nfor i in range (0,43):\n    plt.subplot(7,7,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    path = dir + \"/meta/{0}.png\".format(i)\n    img = plt.imread(path)\n    plt.imshow(img)\n    plt.xlabel(i)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Loading"},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess(image, out_side):\n    height, width = image.shape[:2]\n    scale = out_side / max(height, width)\n    dx = (out_side - scale * width) / 2\n    dy = (out_side - scale * height) / 2\n    trans = np.array([[scale, 0, dx], [0, scale, dy]], dtype=np.float32)\n    image = cv2.warpAffine(image, trans, (out_side, out_side), flags=cv2.INTER_AREA)\n    image = cv2.resize(image, (out_side, out_side))\n    return image\n\ndef mixing(images, labels):\n    images = np.array(images)\n    labels = np.array(labels)\n    s = np.arange(images.shape[0])\n    np.random.seed(43)\n    np.random.shuffle(s)\n    images=images[s]\n    labels=labels[s]\n    return images, labels\n\ndef load_train(path, out_side):\n    images = []\n    labels = []\n    for folder in os.listdir(os.path.join(path, 'Train')):\n        cur_path = os.path.join(path, 'Train', folder)\n        for file_name in os.listdir(cur_path):\n            image = cv2.imread(os.path.join(cur_path, file_name))\n            images.append(preprocess(image, out_side))\n            labels.append(int(folder))\n\n    return mixing(images, labels)\n\ndef load_test(path, out_side):\n    images = []\n    labels = []\n    with open(os.path.join(path, 'Test.csv'), 'r') as f:\n        reader = csv.reader(f)\n        for rows in reader:\n            name = rows[7]\n            if (name == 'Path'):\n                continue\n            image = cv2.imread(os.path.join(path, rows[7]))\n            images.append(preprocess(image, out_side))\n            labels.append(int(rows[6]))\n\n    return mixing(images, labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"start = time()\n\ntrain_images, train_labels = load_train(dir + \"/\", 50)\ntest_images, test_labels = load_test(dir + \"/\", 50)\nshape = train_images[0].shape\nprint(shape)\n\ntrain_images = train_images.astype('float32') / 255.\ntest_images = test_images.astype('float32') / 255.\n\ntrain_labels = utils.to_categorical(train_labels, 43)\ntest_labels = utils.to_categorical(test_labels, 43)\n\nprint('Loading: ', time() - start)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Network"},{"metadata":{"trusted":true},"cell_type":"code","source":"classes = 43\nbatch = 256\nepochs = 3\nlearning_rate = 0.0001\n\ndef results(model):\n  adam = Adam(lr=learning_rate)\n\n  model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n\n  start = time()\n  history = model.fit(train_images, train_labels, batch_size=batch, epochs=epochs, validation_split=0.2, shuffle = True, verbose=1)\n  train_time = time() - start\n\n  model.summary()\n\n  plt.figure(figsize=(12, 12))\n  plt.subplot(3, 2, 1)\n  plt.plot(history.history['accuracy'], label = 'train_accuracy')\n  plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n  plt.xlabel('epoch')\n  plt.ylabel('accuracy')\n  plt.legend()\n  plt.subplot(3, 2, 2)\n  plt.plot(history.history['loss'], label = 'train_loss')\n  plt.plot(history.history['val_loss'], label = 'val_loss')\n  plt.xlabel('epoch')\n  plt.ylabel('accuracy')\n  plt.legend()\n  plt.show()\n\n  start = time()\n  test_loss, test_acc = model.evaluate(test_images, test_labels)\n  test_time = time() - start\n  print('\\nTrain time: ', train_time)\n  print('Test accuracy:', test_acc)\n  print('Test loss:', test_loss)\n  print('Test time: ', test_time)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Configuration"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(VGG19(weights='imagenet', include_top=False, input_shape=(50,50,3)))\nmodel.add(BatchNormalization())\nmodel.add(Flatten())\nmodel.add(Dense(1024, activation='sigmoid'))\nmodel.add(Dense(43, activation='softmax'))\n\nresults(model)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}