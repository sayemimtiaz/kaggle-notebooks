{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nimport cv2\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n!pip install imutils\nimport os\nimport keras.backend as K\nimport imutils\nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Reading Files","metadata":{}},{"cell_type":"code","source":"import glob\nfiles=[]\nfiles=[]\nfor file in glob.glob(\"../input/brain-tumor/Brain Tumor/Brain Tumor/*.jpg\"):\n    files.append(file)\n        ","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def crop_brain_contour(image, plot=False):\n    \n    # Convert the image to grayscale, and blur it slightly\n    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n    \n    thresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]\n    thresh = cv2.erode(thresh, None, iterations=2)\n    thresh = cv2.dilate(thresh, None, iterations=2)\n\n    # Find contours in thresholded image, then grab the largest one\n    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n    cnts = imutils.grab_contours(cnts)\n    c = max(cnts, key=cv2.contourArea)\n    # extreme points\n    extLeft = tuple(c[c[:, :, 0].argmin()][0])\n    extRight = tuple(c[c[:, :, 0].argmax()][0])\n    extTop = tuple(c[c[:, :, 1].argmin()][0])\n    extBot = tuple(c[c[:, :, 1].argmax()][0])\n    \n    # crop new image out of the original image using the four extreme points (left, right, top, bottom)\n    new_image = image[extTop[1]:extBot[1], extLeft[0]:extRight[0]]            \n\n    if plot:\n        plt.figure()\n        plt.subplot(1, 2, 1)\n        plt.imshow(image)\n        plt.tick_params(axis='both', which='both', top=False, bottom=False, left=False, right=False,labelbottom=False, labeltop=False, labelleft=False, labelright=False)\n        plt.title('Original Image')\n        plt.subplot(1, 2, 2)\n        plt.imshow(new_image)\n        plt.tick_params(axis='both', which='both',top=False, bottom=False, left=False, right=False,labelbottom=False, labeltop=False, labelleft=False, labelright=False)\n        plt.title('Cropped Image')\n        plt.show()\n    \n    return new_image","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\ntry:\n    os.rmdir('./crop/')\n   \nexcept:\n    pass\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Crop Image","metadata":{}},{"cell_type":"code","source":"\n#os.mkdir('./crop/')\n\n\nfor file in files:\n    #print(file)\n    ex_img = cv2.imread(file)\n    ex_crop_img = crop_brain_contour(ex_img, False)\n    filename='./crop/'+os.path.basename(file)\n    #print(filename)\n    cv2.imwrite(filename,ex_crop_img)\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Class Balance","metadata":{}},{"cell_type":"code","source":"import pandas as pd\ndf_train=pd.read_csv('../input/brain-tumor/Brain Tumor.csv')\ndf_train\ndf_train_=df_train[['Image','Class']]\ndf_train_.columns=['filename','class']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.unique(df_train_['class'])\ndf_train_.filename=[filename+'.jpg' for filename in df_train_.filename.values ]\n\ndf_train_=df_train_.sample(frac=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(df_train_[df_train_['class']==0]))\nprint(len(df_train_[df_train_['class']==1]))\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train,X_=train_test_split(df_train_,test_size=0.2,random_state=0)\n\nX_test,X_val=train_test_split(X_,test_size=0.2,random_state=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimg_generator=ImageDataGenerator(rescale=1/255)\n\ntrain_it = img_generator.flow_from_dataframe(X_train,directory='./crop/', class_mode='raw',\n                                             featurewise_std_normalization=True,\n                                             image_size=(256, 256))\ntest_it = img_generator.flow_from_dataframe(X_test,directory='./crop/', class_mode='raw',image_size=(256, 256),featurewise_std_normalization=True,batch_size=602)\nval_it = img_generator.flow_from_dataframe(X_val,directory='./crop/', class_mode='raw',image_size=(256, 256),featurewise_std_normalization=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Show images","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfig,ax=plt.subplots(2,2,figsize=(6,6))\n\nimages,labels = train_it.next()\nx=0\ny=0\nfor i in range(0,16):\n    image = images[i]\n    if y<2 and x<2:\n        ax[y][x].imshow(image)\n    if x>2:\n        y=y+1\n        x=0\n    x=x+1\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# example of tending the vgg16 model\nfrom keras.applications.vgg16 import VGG16\nfrom keras.models import Model\nfrom keras.layers import Dense\nfrom keras.layers import Flatten\nfrom keras.layers import BatchNormalization\nfrom keras.layers import Dropout\n\n# load model without classifier layers\nvgg = VGG16(include_top=False, input_shape=(256, 256, 3))\n# add new classifier layers\nflat1 = Flatten()(vgg.output)\ndropout = Dropout(0.5)(flat1)\ndense1 = Dense(1024, activation='relu')(flat1)\nbatch =  BatchNormalization()(dense1)\ndense2 = Dense(1024, activation='relu')(batch)\ndropout = Dropout(0.5)(dense2)\noutput = Dense(1, activation='sigmoid')(dropout)\n# define new model\nmodel = Model(inputs=vgg.inputs, outputs=output)\n# summarize\nmodel.summary()\n\nfor layer in vgg.layers:\n    layer.trainable=False\n\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow\nes=tensorflow.keras.callbacks.EarlyStopping(\n    monitor=\"val_loss\",\n    min_delta=0,\n    patience=8,\n    verbose=0,\n    mode=\"auto\",\n    baseline=None,\n    restore_best_weights=True,\n)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ReduceLROnPlateau\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n                              patience=2)\ncallbacks=[reduce_lr,es]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train model","metadata":{}},{"cell_type":"code","source":"model.fit_generator(train_it, epochs=30,steps_per_epoch=5, \n                    validation_data=val_it, validation_steps=3,callbacks=callbacks)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if os.path.isfile('/kaggle/working/model.h5'):\n    model.load_weights(\"/kaggle/working/model.h5\")\nelse:\n    model.fit_generator(train_it, epochs=180,steps_per_epoch=5, \n                    validation_data=val_it, validation_steps=3,callbacks=callbacks)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save_weights('/kaggle/working/model.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores=model.evaluate_generator(generator=test_it,steps=10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Test Accuracy","metadata":{}},{"cell_type":"code","source":"print(\"Accuracy = \", scores[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_shuffle=X_test\ndf_shuffle.filename=['./crop/'+filename for filename in df_shuffle.filename]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_yes=df_shuffle[df_shuffle['class']==1]\ndf_yes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Test Predictions","metadata":{}},{"cell_type":"code","source":"df_yes=df_shuffle[df_shuffle['class']==1]\nname=list(df_yes.iloc[1:2,:]['filename'])[0]\nprint(name)\nex_img = cv2.imread(name)\nex_img = cv2.resize(ex_img,(256,256))\nplt.imshow(ex_img)\n\nfrom tensorflow.keras.preprocessing import image\nfrom keras.applications.vgg16 import preprocess_input\n\nx_reshape = ex_img.reshape((1, ex_img.shape[0],ex_img.shape[1], ex_img.shape[2]))\n\nimage = preprocess_input(x_reshape)\n\nmodel.predict(image)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_no=df_shuffle[df_shuffle['class']==0]\nname=list(df_no.iloc[1:2,:]['filename'])[0]\nprint(name)\nex_img = cv2.imread(name)\nex_img = cv2.resize(ex_img,(256,256))\nplt.imshow(ex_img)\n\nfrom tensorflow.keras.preprocessing import image\nfrom keras.applications.vgg16 import preprocess_input\n\nx_reshape = ex_img.reshape((1, ex_img.shape[0],ex_img.shape[1], ex_img.shape[2]))\n\nimage = preprocess_input(x_reshape)\n\nmodel.predict(image)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred=[]\ny_true=[]\nimages,y_true=test_it.next()\n\nfor image in images:\n    \n    pred=model.predict(np.array([image]))\n    \n\n    \n\n    \n \n    y_pred.extend(pred[0])\n   ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_=[int(y>0.5) for y in y_pred]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_true","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test=y_true","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(y_test,y_pred_))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nconfusion_matrix(y_test,y_pred_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Machine Learning Explainable","metadata":{}},{"cell_type":"code","source":"def get_xai(x):\n    \n    \n    x=x/255\n    x_ = np.expand_dims(x, axis=0)\n        \n\n    y_pred = model.predict(x_)\n    \n    print('pred',y_pred)\n    last_conv_layer = model.get_layer('block5_conv3')\n    argmax = np.argmax(y_pred[0])\n    print(argmax)\n    output = model.output[:, argmax]\n    print(output)\n    print(last_conv_layer.output)\n    grads = K.gradients(output, last_conv_layer.output)[0]\n\n    #tf.print(grads)\n    pooled_grads = K.mean(grads, axis=(0, 1, 2))\n\n\n\n\n    iterate = K.function([model.input], [pooled_grads, last_conv_layer.output[0]])\n\n\n\n    from keras.applications.vgg16 import preprocess_input\n    #x = preprocess_input(x)\n    #print( pooled_grads_value[pooled_grads_value>0])\n\n    pooled_grads_value, conv_layer_output_value = iterate([x_])\n\n\n    for i in range(512):\n        conv_layer_output_value[:, :, i] *= pooled_grads_value[i]\n\n    heatmap = np.mean(conv_layer_output_value, axis=-1)\n    heatmap = np.maximum(heatmap, 0)\n    heatmap /= np.max(heatmap)\n    #plt.matshow(heatmap)\n    #plt.show()\n    import cv2\n    heatmap = cv2.resize(heatmap, (x.shape[1], x.shape[0]))\n    heatmap = np.uint8(255 * heatmap)\n    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n    hif = .05\n    superimposed_img = heatmap * hif + x\n    from matplotlib.pyplot import figure\n    plt.figure(figsize=(5, 5))\n    #fig, ax =figure(figsize=(10, 2))\n    #ax.imshow(random.rand(8, 90), interpolation='nearest')\n    plt.imshow(superimposed_img)\n    #plt.axis('off')\n    plt.show()\n    \ndef get_heatmap(x):\n    \n    \n    x=x/255\n    x_ = np.expand_dims(x, axis=0)\n        \n\n    y_pred = model.predict(x_)\n    \n   \n    last_conv_layer = model.get_layer('block5_conv3')\n    argmax = np.argmax(y_pred[0])\n    \n    output = model.output[:, argmax]\n   \n    grads = K.gradients(output, last_conv_layer.output)[0]\n\n    #tf.print(grads)\n    pooled_grads = K.mean(grads, axis=(0, 1, 2))\n\n\n\n\n    iterate = K.function([model.input], [pooled_grads, last_conv_layer.output[0]])\n\n\n\n    from keras.applications.vgg16 import preprocess_input\n    #x = preprocess_input(x)\n    #print( pooled_grads_value[pooled_grads_value>0])\n\n    pooled_grads_value, conv_layer_output_value = iterate([x_])\n\n\n    for i in range(512):\n        conv_layer_output_value[:, :, i] *= pooled_grads_value[i]\n\n    heatmap = np.mean(conv_layer_output_value, axis=-1)\n    heatmap = np.maximum(heatmap, 0)\n    heatmap /= np.max(heatmap)\n    #plt.matshow(heatmap)\n    #plt.show()\n    import cv2\n    heatmap = cv2.resize(heatmap, (x.shape[1], x.shape[0]))\n    heatmap = np.uint8(255 * heatmap)\n    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n    return heatmap","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_yes=df_shuffle[df_shuffle['class']=='yes']\nname=list(df_yes.iloc[1:2,:]['filename'])[0]\nprint(name)\nex_img = cv2.imread(name)\nex_img = cv2.resize(ex_img,(256,256))\nplt.imshow(ex_img)\nget_xai(ex_img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Saving maps","metadata":{}},{"cell_type":"code","source":"###from tqdm import tqdm\n\n###images=[]\n###predictions=[]\n\n\n###for i,r in tqdm(df_shuffle.iterrows()):\n###    ex_img = cv2.imread(r['filename'])\n###    ex_img = cv2.resize(ex_img,(256,256))\n###    plt.imshow(ex_img)\n\n###    from tensorflow.keras.preprocessing import image\n###    from keras.applications.vgg16 import preprocess_input\n\n###    x_reshape = ex_img.reshape((1, ex_img.shape[0],ex_img.shape[1], ex_img.shape[2]))\n\n###    image = preprocess_input(x_reshape)\n    \n###    pred=model.predict(image)\n###    images.append(get_heatmap(ex_img).flatten())\n###    predictions.extend(pred[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### import csv\n\n### df_shuffle.to_csv('/kaggle/working/df.csv')\n\n### with open('/kaggle/working/maps.csv', 'wb') as images:\n###    wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n###    wr.writerow(mylist)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}