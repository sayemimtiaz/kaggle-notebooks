{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":false,"_kg_hide-output":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport cv2\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Sharpening"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"image = cv2.imread('/kaggle/input/chinese-fine-art/Dataset/Ai_Xuan_艾軒/Ai_Xuan_05.jpg')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\nplt.figure(figsize=(20, 20))\nplt.subplot(1, 2, 1)\nplt.title(\"Original\")\nplt.imshow(image)\n\n# Create our shapening kernel, we don't normalize since the \n# the values in the matrix sum to 1\nkernel_sharpening = np.array([[-1,-1,-1], \n                              [-1,9,-1], \n                              [-1,-1,-1]])\n\n# applying different kernels to the input image\nsharpened = cv2.filter2D(image, -1, kernel_sharpening)\n\n\nplt.subplot(1, 2, 2)\nplt.title(\"Image Sharpening\")\nplt.imshow(sharpened)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thresholding, Binarization & Adaptive Thresholding"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Load our new image\nimage = cv2.imread('/kaggle/input/chinese-fine-art/Dataset/Ai_Xuan_艾軒/Ai_Xuan_05.jpg', 0)\n\nplt.figure(figsize=(30, 30))\nplt.subplot(3, 2, 1)\nplt.title(\"Original\")\nplt.imshow(image)\n\n# Values below 127 goes to 0 (black, everything above goes to 255 (white)\nret,thresh1 = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n\nplt.subplot(3, 2, 2)\nplt.title(\"Threshold Binary\")\nplt.imshow(thresh1)\n\n# It's good practice to blur images as it removes noise\nimage = cv2.GaussianBlur(image, (3, 3), 0)\n\n# Using adaptiveThreshold\nthresh = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 3, 5) \n\nplt.subplot(3, 2, 3)\nplt.title(\"Adaptive Mean Thresholding\")\nplt.imshow(thresh)\n\n\n_, th2 = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n\nplt.subplot(3, 2, 4)\nplt.title(\"Otsu's Thresholding\")\nplt.imshow(th2)\n\n\nplt.subplot(3, 2, 5)\n# Otsu's thresholding after Gaussian filtering\nblur = cv2.GaussianBlur(image, (5,5), 0)\n_, th3 = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\nplt.title(\"Guassian Otsu's Thresholding\")\nplt.imshow(th3)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dilation, Erosion, Opening and Closing"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"image = cv2.imread('/kaggle/input/chinese-fine-art/Dataset/Ai_Xuan_艾軒/Ai_Xuan_07.jpg')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\nplt.figure(figsize=(20, 20))\nplt.subplot(3, 2, 1)\nplt.title(\"Original\")\nplt.imshow(image)\n\n# Let's define our kernel size\nkernel = np.ones((5,5), np.uint8)\n\n# Now we erode\nerosion = cv2.erode(image, kernel, iterations = 1)\n\nplt.subplot(3, 2, 2)\nplt.title(\"Erosion\")\nplt.imshow(erosion)\n\n# \ndilation = cv2.dilate(image, kernel, iterations = 1)\nplt.subplot(3, 2, 3)\nplt.title(\"Dilation\")\nplt.imshow(dilation)\n\n\n# Opening - Good for removing noise\nopening = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\nplt.subplot(3, 2, 4)\nplt.title(\"Opening\")\nplt.imshow(opening)\n\n# Closing - Good for removing noise\nclosing = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\nplt.subplot(3, 2, 5)\nplt.title(\"Closing\")\nplt.imshow(closing)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Edge Detection & Image Gradients"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"image = cv2.imread('/kaggle/input/chinese-fine-art/Dataset/Ai_Xuan_艾軒/Ai_Xuan_08.jpg')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\nheight, width,_ = image.shape\n\n# Extract Sobel Edges\nsobel_x = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=5)\nsobel_y = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=5)\n\nplt.figure(figsize=(20, 20))\n\nplt.subplot(3, 2, 1)\nplt.title(\"Original\")\nplt.imshow(image)\n\nplt.subplot(3, 2, 2)\nplt.title(\"Sobel X\")\nplt.imshow(sobel_x)\n\nplt.subplot(3, 2, 3)\nplt.title(\"Sobel Y\")\nplt.imshow(sobel_y)\n\nsobel_OR = cv2.bitwise_or(sobel_x, sobel_y)\n\nplt.subplot(3, 2, 4)\nplt.title(\"sobel_OR\")\nplt.imshow(sobel_OR)\n\nlaplacian = cv2.Laplacian(image, cv2.CV_64F)\n\nplt.subplot(3, 2, 5)\nplt.title(\"Laplacian\")\nplt.imshow(laplacian)\n\n# Canny Edge Detection uses gradient values as thresholds\n# The first threshold gradient\ncanny = cv2.Canny(image, 50, 120)\n\nplt.subplot(3, 2, 6)\nplt.title(\"Canny\")\nplt.imshow(canny)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Perpsective Transform"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"image = cv2.imread('/kaggle/input/chinese-fine-art/Dataset/Ai_Xuan_艾軒/Ai_Xuan_17.jpg')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\nplt.figure(figsize=(20, 20))\n\nplt.subplot(1, 2, 1)\nplt.title(\"Original\")\nplt.imshow(image)\n\n# Cordinates of the 4 corners of the original image\npoints_A = np.float32([[320,15], [700,215], [85,610], [530,780]])\n\n# Cordinates of the 4 corners of the desired output\n# We use a ratio of an A4 Paper 1 : 1.41\npoints_B = np.float32([[0,0], [420,0], [0,594], [420,594]])\n \n# Use the two sets of four points to compute \n# the Perspective Transformation matrix, M    \nM = cv2.getPerspectiveTransform(points_A, points_B)\n\n\nwarped = cv2.warpPerspective(image, M, (420,594))\n\nplt.subplot(1, 2, 2)\nplt.title(\"warpPerspective\")\nplt.imshow(warped)\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Scaling, re-sizing and interpolations"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"image = cv2.imread('/kaggle/input/chinese-fine-art/Dataset/Ai_Xuan_艾軒/Ai_Xuan_13.jpg')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\nplt.figure(figsize=(20, 20))\n\nplt.subplot(2, 2, 1)\nplt.title(\"Original\")\nplt.imshow(image)\n\n# Let's make our image 3/4 of it's original size\nimage_scaled = cv2.resize(image, None, fx=0.75, fy=0.75)\n\nplt.subplot(2, 2, 2)\nplt.title(\"Scaling - Linear Interpolation\")\nplt.imshow(image_scaled)\n\n# Let's double the size of our image\nimg_scaled = cv2.resize(image, None, fx=2, fy=2, interpolation = cv2.INTER_CUBIC)\n\nplt.subplot(2, 2, 3)\nplt.title(\"Scaling - Cubic Interpolation\")\nplt.imshow(img_scaled)\n\n# Let's skew the re-sizing by setting exact dimensions\nimg_scaled = cv2.resize(image, (900, 400), interpolation = cv2.INTER_AREA)\n\nplt.subplot(2, 2, 4)\nplt.title(\"Scaling - Skewed Size\")\nplt.imshow(img_scaled)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Cropping"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"image = cv2.imread('/kaggle/input/chinese-fine-art/Dataset/Ai_Xuan_艾軒/Ai_Xuan_11.jpg')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\nplt.figure(figsize=(20, 20))\n\nplt.subplot(2, 2, 1)\nplt.title(\"Original\")\nplt.imshow(image)\n\nheight, width = image.shape[:2]\n\n# Let's get the starting pixel coordiantes (top  left of cropping rectangle)\nstart_row, start_col = int(height * .25), int(width * .25)\n\n# Let's get the ending pixel coordinates (bottom right)\nend_row, end_col = int(height * .75), int(width * .75)\n\n# Simply use indexing to crop out the rectangle we desire\ncropped = image[start_row:end_row , start_col:end_col]\n\n\nplt.subplot(2, 2, 2)\nplt.title(\"Cropped\")\nplt.imshow(cropped)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Blurring"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"image = cv2.imread('/kaggle/input/chinese-fine-art/Dataset/Ai_Xuan_艾軒/Ai_Xuan_16.jpg')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\nplt.figure(figsize=(20, 20))\n\nplt.subplot(2, 2, 1)\nplt.title(\"Original\")\nplt.imshow(image)\n\n# Creating our 3 x 3 kernel\nkernel_3x3 = np.ones((3, 3), np.float32) / 9\n\n# We use the cv2.fitler2D to conovlve the kernal with an image \nblurred = cv2.filter2D(image, -1, kernel_3x3)\n\nplt.subplot(2, 2, 2)\nplt.title(\"3x3 Kernel Blurring\")\nplt.imshow(blurred)\n\n# Creating our 7 x 7 kernel\nkernel_7x7 = np.ones((7, 7), np.float32) / 49\n\nblurred2 = cv2.filter2D(image, -1, kernel_7x7)\n\nplt.subplot(2, 2, 3)\nplt.title(\"7x7 Kernel Blurring\")\nplt.imshow(blurred2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Contours"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Let's load a simple image with 3 black squares\nimage = cv2.imread('/kaggle/input/chinese-fine-art/Dataset/Ai_Xuan_艾軒/Ai_Xuan_02.jpg')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\nplt.figure(figsize=(20, 20))\n\nplt.subplot(2, 2, 1)\nplt.title(\"Original\")\nplt.imshow(image)\n\n\n# Grayscale\ngray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n\n# Find Canny edges\nedged = cv2.Canny(gray, 30, 200)\n\nplt.subplot(2, 2, 2)\nplt.title(\"Canny Edges\")\nplt.imshow(edged)\n\n# Finding Contours\n# Use a copy of your image e.g. edged.copy(), since findContours alters the image\ncontours, hierarchy = cv2.findContours(edged, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n\nplt.subplot(2, 2, 3)\nplt.title(\"Canny Edges After Contouring\")\nplt.imshow(edged)\n\nprint(\"Number of Contours found = \" + str(len(contours)))\n\n# Draw all contours\n# Use '-1' as the 3rd parameter to draw all\ncv2.drawContours(image, contours, -1, (0,255,0), 3)\n\nplt.subplot(2, 2, 4)\nplt.title(\"Contours\")\nplt.imshow(image)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Approximating Contours and Convex Hull"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Load image and keep a copy\nimage = cv2.imread('/kaggle/input/chinese-fine-art/Dataset/Ai_Xuan_艾軒/Ai_Xuan_02.jpg')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\nplt.figure(figsize=(20, 20))\n\nplt.subplot(2, 2, 1)\nplt.title(\"Original\")\nplt.imshow(image)\n\norig_image = image.copy()\n\n\n# Grayscale and binarize\ngray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\nret, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV)\n\n# Find contours \ncontours, hierarchy = cv2.findContours(thresh.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n\n# Iterate through each contour and compute the bounding rectangle\nfor c in contours:\n    x,y,w,h = cv2.boundingRect(c)\n    cv2.rectangle(orig_image,(x,y),(x+w,y+h),(0,0,255),2)    \n    plt.subplot(2, 2, 2)\n    plt.title(\"Bounding Rectangle\")\n    plt.imshow(orig_image)\n    \ncv2.waitKey(0) \n    \n# Iterate through each contour and compute the approx contour\nfor c in contours:\n    # Calculate accuracy as a percent of the contour perimeter\n    accuracy = 0.03 * cv2.arcLength(c, True)\n    approx = cv2.approxPolyDP(c, accuracy, True)\n    cv2.drawContours(image, [approx], 0, (0, 255, 0), 2)\n    \n    plt.subplot(2, 2, 3)\n    plt.title(\"Approx Poly DP\")\n    plt.imshow(image)\n\nplt.show()\n    \n# Convex Hull\n\n\nimage = cv2.imread('/kaggle/input/chinese-fine-art/Dataset/Ai_Xuan_艾軒/Ai_Xuan_02.jpg')\ngray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n\nplt.figure(figsize=(20, 20))\n\nplt.subplot(1, 2, 1)\nplt.title(\"Original Image\")\nplt.imshow(image)\n\n\n# Threshold the image\nret, thresh = cv2.threshold(gray, 176, 255, 0)\n\n# Find contours \ncontours, hierarchy = cv2.findContours(thresh.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n    \n# Sort Contors by area and then remove the largest frame contour\nn = len(contours) - 1\ncontours = sorted(contours, key=cv2.contourArea, reverse=False)[:n]\n\n# Iterate through contours and draw the convex hull\nfor c in contours:\n    hull = cv2.convexHull(c)\n    cv2.drawContours(image, [hull], 0, (0, 255, 0), 2)\n\n    plt.subplot(1, 2, 2)\n    plt.title(\"Convex Hull\")\n    plt.imshow(image)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#codes from Endi Niu @niuddd\nimg = cv2.imread('/kaggle/input/chinese-fine-art/Dataset/Ai_Xuan_艾軒/Ai_Xuan_015.jpg')\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nfig = plt.figure(figsize=(8,8))\nplt.imshow(img)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Kaggle Notebook Runner: Marília Prata @mpwolke"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}