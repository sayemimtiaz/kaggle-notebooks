{"cells":[{"metadata":{"_uuid":"d6576d078c298c71f783ae570d9e1941be2924ed","_cell_guid":"690f98f7-648f-4146-8aa4-6a47fbb72883"},"cell_type":"markdown","source":"# Análise de Sentimentos em língua portuguesa do Brasil\n\nExemplo didático de análise de sentimentos a partir de uma base de dados de tweets classificados como positivo, negativo e neutro. Baseado no trabalho do Minerando Dados (https://github.com/minerandodados)."},{"metadata":{},"cell_type":"markdown","source":"### Configurações"},{"metadata":{"trusted":true},"cell_type":"code","source":"tune_hyparams = False\n# num trials for hyperparameter tuning\nnum_evals = 15\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Carregar pacotes e dados"},{"metadata":{"_uuid":"2840dd041b764e287b641cc8308c68c520796d9b","_cell_guid":"6f03ca1a-3c0e-4e33-9ba6-91a9d640185f","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n\nimport nltk\nimport re\nimport pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn import metrics\nfrom sklearn.model_selection import cross_val_predict\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"-l\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"af447214f6b3b7791f19e4a17488198659a5e6ab","_cell_guid":"a9cdc1e8-0e19-4f98-a377-1a8efa50331c"},"cell_type":"markdown","source":"## 1. O Dataset de Tweets\nVamos começar inspecionando nosso dataset."},{"metadata":{"_uuid":"7b761277e1b96610ba67f19b27b52d6658acd2bb","_cell_guid":"f1f48f72-4db1-4734-8723-9ef52aedc7b0","trusted":true},"cell_type":"code","source":"# Primeiro, vamos contar a quantidade total de registros\ndataset = pd.read_csv('../input/Tweets_Mg.csv',encoding='utf-8')\ndataset.count()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cf33f8ba0a1faf5aced6cb0769d39407ac08ee76","_cell_guid":"f2cfc532-207d-4d45-9110-bfefafa97b2a","trusted":true},"cell_type":"code","source":"# Agora, apenas os classificados como neutro\ndataset[dataset.Classificacao == 'Neutro'].count()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ab681c0af0991060c8b176adf95d0438097715f9","_cell_guid":"e3d854fb-edab-4a8c-a22a-c41782f1db5a","trusted":true},"cell_type":"code","source":"# Os classificados como positivo\ndataset[dataset.Classificacao == 'Positivo'].count()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d8c95fe8a2ff1114161f3af20a87dfabb80d3048","_cell_guid":"1241d7f5-12c6-4f4f-9c0f-4355f1195d8f","trusted":true},"cell_type":"code","source":"# E finalmente, os classificados como negativo\ndataset[dataset.Classificacao == 'Negativo'].count()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7c04a528851a3fa57b89a1ad33826456a423e7f0","_cell_guid":"978a0209-71be-443d-8748-88f7c1cef6c5","trusted":true},"cell_type":"code","source":"# OK, vamos dar uma olhada rápida no conteúdo do dataset para finalizar esse passo\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"73de912a022494b152d915d3ea31ca18c14d718b","_cell_guid":"f39fe03f-981f-4629-b79a-50098dd59924"},"cell_type":"markdown","source":"## 2. Construindo o Modelo"},{"metadata":{"_uuid":"0b90c933012a38041e975f66a60f377915b92112","_cell_guid":"eca2a77a-f355-41c5-ad4a-dfbe32af62f4","trusted":true},"cell_type":"code","source":"# Próximo passo, vamos separar os tweets e suas classes\ntweets = dataset[\"Text\"].values\ntweets","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"866709548dc8dabc53c1c758f0bfdf410182a19d","_cell_guid":"69e04867-3f0f-47d2-88f5-df2127042d1b","trusted":true},"cell_type":"code","source":"classes = dataset[\"Classificacao\"].values\nclasses","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a376262987475125694411ecb7e129f07e84e8f3","_cell_guid":"007fbaef-b5d0-4fd7-92cc-2583ba668179","trusted":true},"cell_type":"code","source":"# Agora, vamos treinar o modelo usando a abordagem Bag of Words e o algoritmo Naive Bayes Multinomial\n#    - Bag of Words, na prática, cria um vetor com cada uma das palavras do texto completo da base,\n#      depois, calcula a frequência em que essas palavras ocorrem em uma data sentença, para então\n#      classificar/treinar o modelo\n#    - Exemplo HIPOTÉTICO de três sentenças vetorizadas \"por palavra\" e classificadas baseada na\n#      frequência de suas palavras:\n#         {0,3,2,0,0,1,0,0,0,1, Positivo}\n#         {0,0,1,0,0,1,0,1,0,0, Negativo}\n#         {0,1,1,0,0,1,0,0,0,0, Neutro}\n#    - Olhando para esses vetores, meu palpite é que as palavras nas posições 2 e 3 são as com maior\n#      peso na determinação de a que classe pertence cada uma das três sentenças avaliadas\n#    - A função fit_transform faz exatamente esse processo: ajusta o modelo, aprende o vocabulário,\n#      e transforma os dados de treinamento em feature vectors, a.k.a. vetor com frequêcia das palavras\n\nvectorizer = CountVectorizer(analyzer = \"word\")\nfreq_tweets = vectorizer.fit_transform(tweets)\n\nmodelo = MultinomialNB()\nmodelo.fit(freq_tweets, classes)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f55fb6c880a34170862eaf35be8f594d9e280460","_cell_guid":"466d7f29-032e-4dec-9602-94dd38109d3a"},"cell_type":"markdown","source":"## 3. Testando o modelo"},{"metadata":{"_uuid":"68bc8d6fc38abf056dca0a39b687d1c381f8fd25","_cell_guid":"455dcddd-6b44-4a28-97c3-fa08f0fee171","trusted":true},"cell_type":"code","source":"# Vamos usar algumas frases de teste para fazer a classificação com o modelo treinado\ntestes = [\"Esse governo está no início, vamos ver o que vai dar\",\n          \"Estou muito feliz com o governo de São Paulo esse ano\",\n          \"O estado de Minas Gerais decretou calamidade financeira!!!\",\n          \"A segurança desse país está deixando a desejar\",\n          \"O governador de Minas é do PT\",\n          \"O prefeito de São Paulo está fazendo um ótimo trabalho\"]\n\nfreq_testes = vectorizer.transform(testes)\nmodelo.predict(freq_testes)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"170c7c69f73a7433a0554d44a98a62308e08fc9f","_cell_guid":"179b67d3-0050-4188-a605-b70907e14336"},"cell_type":"markdown","source":"## 4. Avaliando o modelo"},{"metadata":{"_uuid":"7cff21dfc9bb07fbce32ab78ed3073b13bdc021b","_cell_guid":"6afb7e0c-ce1c-497b-8f2f-02b75587954e","trusted":true},"cell_type":"code","source":"# Validação cruzada do modelo. Neste caso, o modelo é dividido em 10 partes, treinado em 9 e testado em 1\nresultados = cross_val_predict(modelo, freq_tweets, classes, cv = 10)\nresultados","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e8eb430cb4d6449c8f173c27fbac4fc4ec711bb3","_cell_guid":"b6b63681-0961-4da4-bd40-3c73cf0884cd","trusted":true},"cell_type":"code","source":"# Quão acurada é a média do modelo?\nmetrics.accuracy_score(classes, resultados)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1fb21da856cc6c4ee65f7daa95137dcdfbb51c0d","_cell_guid":"a2b917b7-da10-4403-b0a7-f6f88897e29d","trusted":true},"cell_type":"code","source":"# Medidas de validação do modelo\nsentimentos = [\"Positivo\", \"Negativo\", \"Neutro\"]\nprint(metrics.classification_report(classes, resultados, sentimentos))\n\n# Lembrando que:\n#    : precision = true positive / (true positive + false positive)\n#    : recall    = true positive / (true positive + false negative)\n#    : f1-score  = 2 * ((precision * recall) / (precision + recall))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aaa2cc41ea529a09c8a3c8fe504457b02769ea59","_cell_guid":"ffda64a4-e0cf-443c-bb53-a1a6f2024ae1","trusted":true},"cell_type":"code","source":"# Vamos fazer uma matriz de confusão -- What?!?!\nprint(pd.crosstab(classes, resultados, rownames = [\"Real\"], colnames=[\"Predito\"], margins=True))\n\n# Lembrando que:\n#    - Predito = O que o programa classificou como Negativo, Neutro, Positivo e All\n#    - Real    = O que é de fato Negativo, Neutro, Positivo e All\n#\n# Ou seja, somente 9 tweets eram de fato negativos e o programa classificou como positivos. Já os\n# positivos que o programa classificou como negativos foram 45, muito mais","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0c355e4fb76bd97a114473c71a49872dcd5b5c75","_cell_guid":"0354f18c-b26d-42e9-b5b8-945b931cc2a0"},"cell_type":"markdown","source":"## 5. Melhorando o modelo"},{"metadata":{"_uuid":"c4db254fe1fa38a0d05067708d37e65f007eb118","_cell_guid":"8dfc7e26-78fe-4233-89db-3795d4c360bd","trusted":true},"cell_type":"code","source":"# Com o modelo de Bigrams, em lugar de vetorizar o texto \"por palavra\", vamos vetoriza-lo por cada\n# \"duas palavras\", tipo: Eu gosto de São Paulo => { eu gosto, gosto de, de são, são paulo }\nvectorizer = CountVectorizer(ngram_range = (1, 2))\nfreq_tweets = vectorizer.fit_transform(tweets)\n\nmodelo = MultinomialNB()\nmodelo.fit(freq_tweets, classes)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a6b6fe306e4a46b24150f858d88fa9b49bb58575","_cell_guid":"e918cdc1-a49c-4868-9218-047af413b4c5","trusted":true},"cell_type":"code","source":"# Nova predição bigramada\nresultados = cross_val_predict(modelo, freq_tweets, classes, cv = 10)\nresultados","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"89647d6fedfb0d600c4d32bda31a95a4b7e6c83a","_cell_guid":"eeac7ad5-01ee-495b-b014-a3cbeda59abc","trusted":true},"cell_type":"code","source":"# Qual foi a acuracidade desse novo modelo?\nmetrics.accuracy_score(classes, resultados)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3ae3973a12114a23096b0d35dfa298c36340a901","_cell_guid":"ac06ba72-6bd4-41c7-8175-e1604f179ee5","trusted":true},"cell_type":"code","source":"# As novas medidas de validação do modelo, um pouquinho melhor que o anterior\nprint(metrics.classification_report(classes, resultados, sentimentos))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fcddb076247e620c096b02b7d5562a63d14c79ec","_cell_guid":"6ba7bd8e-30ea-42dc-929e-39bfc54ed323","trusted":true},"cell_type":"code","source":"# E a nova matriz de confusão\nprint(pd.crosstab(classes, resultados, rownames = [\"Real\"], colnames = [\"Predito\"], margins = True))\n\n# Mudanças em relação ao modelo anterior:\n#\n#    - Negativo-negativo = 2275 vs 2265 (piorou)\n#    - Negativo-neutro   = 162  vs 179  (piorou)\n#    - Negativo-positivo = 9    vs 2    (melhorou)\n#\n#    - Positivo-positivo = 2899 vs 2900 (melhorou)\n#    - Positivo-neutro   = 356  vs 357  (piorou)\n#    - Positivo-negativo = 45   vs 43   (melhorou)\n#\n#    - Neutro-neutro     = 2067 vs 2177 (melhorou)\n#    - Neutro-negativo   = 240  vs 181  (melhorou)\n#    - Neutro-positivo   = 146  vs 95   (melhorou)\n#\n# Tabela anterior para referência:\n#\n#    Predito   Negativo  Neutro  Positivo   All\n#    Real                                      \n#    Negativo      2275     162         9  2446\n#    Neutro         240    2067       146  2453\n#    Positivo        45     356      2899  3300\n#    All           2560    2585      3054  8199","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"23667044df7fc4bc823e300200974a489d4fe80d","_cell_guid":"e110fa95-d680-4be2-9eda-1270ef26b46c"},"cell_type":"markdown","source":"# Bônus"},{"metadata":{"_uuid":"8da2509f419ffdfcfc0441af686d91a6b9eb90fa","_cell_guid":"37a22b03-e440-4ad4-8281-de61479ab563","trusted":true},"cell_type":"code","source":"# Vamos reinicializar nosso bag of words com um parâmetro de máximo de features\nvectorizer = CountVectorizer(analyzer = \"word\", tokenizer = None, preprocessor = None,\n                             stop_words = None, max_features = 5000)\n\n# Treinar o modelo, aprender o vocabulário e transformar nossos dados de treinamento em feature vectors\ntrain_data_features = vectorizer.fit_transform(tweets)\ntrain_data_features","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5b5372b7009069ca8dff959ae95137033cb3b25e","_cell_guid":"85de9639-ac4a-4934-a572-949001f190bd","trusted":true},"cell_type":"code","source":"# Hora de iniciar um classificador Random Forest\nfrom sklearn.ensemble import RandomForestClassifier\nforest = RandomForestClassifier(n_estimators = 100)\nforest","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"99f6f55b07fbac58fb42206feb8ef3526a21981d","_cell_guid":"7d9c25be-4942-4bf0-8cb0-f018a38edb09","trusted":true},"cell_type":"code","source":"# Separar os sentimentos do dataset de tweets\nclass_sentimentos = dataset[\"Classificacao\"].values\nclass_sentimentos","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e65add0e8b5bbd16f5e819f4794ff728539551a2","_cell_guid":"ff88013f-fbd2-4ec4-8ec6-cc7e45b4957a","trusted":true},"cell_type":"code","source":"# Ajusta a forest ao dataset de treinamento usando a bag of words como feature e os sentimentos\n# como a resposta variável\nforest = forest.fit(train_data_features, class_sentimentos)\nforest","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"20aa2583db7ecf91e02bc945c6cdadde568abd63","_cell_guid":"a05bc498-14b4-4f7f-b7a7-d308d0067ccd","trusted":true},"cell_type":"code","source":"# Criar a bag of words de teste\ntest_data_features = vectorizer.transform(testes)\ntest_data_features","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"de46ae32c3eeb3fd1fc1388d7573146516541100","_cell_guid":"9e4a1300-7b5a-4f3d-ab27-d3c8f5f265ab","trusted":true},"cell_type":"code","source":"# Fazer um predição\nresultados = forest.predict(test_data_features)\nresultados\n\n# Resultado que tivemos com o primeiro modelo:\n# array(['Neutro', 'Neutro', 'Negativo', 'Negativo', 'Neutro', 'Positivo'], dtype='<U8')\n#\n# Meh.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e824df8f567108ab50f2f39aba588612bfed3dd3","_cell_guid":"05e502f3-c4ad-44e1-9480-eb7ce21202f0","trusted":true},"cell_type":"code","source":"# Que tal gerar uma tabelinha Pandas?\ntestes_id = [1, 2, 3, 4, 5, 6]\n\ndata_frame = pd.DataFrame(data = { \"id\": testes_id, \"texto\": testes, \"sentimento\": resultados })\ndata_frame","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"507f81f018ac63e1c7f46ac5140d178b0f3d8297","_cell_guid":"b2f278ac-2ff5-49dc-9461-b4b62d45c30a","trusted":true},"cell_type":"code","source":"# E finalmente, vamos salvar nossa predição em um .csv\ndata_frame.to_csv(\"tweets_classificados_por_forest.csv\", index = False, quoting = 3, escapechar = \"\\\\\")\nprint(check_output([\"ls\", \"-l\", \".\"]).decode(\"utf8\"))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c4675aedf2a2e46b5642fbe8fd9f78c74a26cc74","_cell_guid":"5d1e2db8-a0b7-49de-ba13-f501cfc9d86d","trusted":true},"cell_type":"code","source":"# OK, ok, vamos dar só mais uma espiada para ver se deu tudo certo\nprint(check_output([\"cat\", \"tweets_classificados_por_forest.csv\"]).decode(\"utf8\"))","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"codemirror_mode":{"version":3,"name":"ipython"},"mimetype":"text/x-python","name":"python","file_extension":".py","nbconvert_exporter":"python","version":"3.6.4","pygments_lexer":"ipython3"},"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"}},"nbformat":4,"nbformat_minor":1}