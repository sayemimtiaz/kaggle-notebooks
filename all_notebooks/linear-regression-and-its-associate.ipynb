{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\ndataset = pd.read_csv('../input/red-wine-quality-cortez-et-al-2009/winequality-red.csv')\nX = dataset.iloc[:,:-1].values\nY = dataset.iloc[:,-1].values\n\ncorrelation = dataset.corr()\nfig = plt.subplots(figsize=(10,10))\nsns.heatmap(correlation,vmax=1,square=True,annot=True,cmap='Reds')\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Although correlation predicts that certain features(alcohol and pH) have a relationship with quality. The data does not establish a linear relationship between any of the features.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"features = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n       'pH', 'sulphates', 'alcohol']\nfor feature in features:\n    sns.set()\n    sns.relplot(data = dataset,x = feature,y = Y, kind = 'line', height = 7, aspect = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As shown in the above graphs no feature has a correlation with the quality of the wine. Hence the Linear regression model would not fair well in making predictions."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\n\nx_train,x_test,y_train,y_test=train_test_split(X,Y,random_state=4)\nlinear_regressor = LinearRegression()\nlinear_regressor.fit(x_train,y_train)\ny_pred = linear_regressor.predict(x_test)\n\naccuracy = linear_regressor.score(x_test,y_test)\nprint(\"Linear Accuracy: {}\".format(accuracy))\n\nrmse_linear = mean_squared_error(y_test,y_pred)\nprint(\"Linear RMSE: {} \".format(rmse_linear))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We estimated the linear regression model using the equation y = a0 + x1a1 + x2a2 + x3a3+...+x11a11 where x- feature values a- model parameter. In this model, a0 is bias term and a1,...a11 are feature weights. "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import Lasso\n\nmodel2 = Lasso()\nmodel2.fit(X=x_train, y=y_train)\ny_pred2 = model2.predict(x_test)\nrmse_lasso = mean_squared_error(y_pred2, y_test)\nprint(\"Lasso RMSE: {}\".format(rmse_lasso))\naccuracy_lasso = model2.score(x_test,y_test)\nprint(\"Accuracy Lasso: {}\".format(accuracy_lasso))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lasso(Least Absolute Shrinkage and Selection Operator) Regression involves regularization of data by typically constraining weights. It is used when data is overfitted.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import Ridge\n\nmodel3 = Ridge(alpha = 1 , solver = \"cholesky\")\nmodel3.fit(X=x_train, y=y_train)\ny_pred3 = model3.predict(x_test)\nrmse_ridge = mean_squared_error(y_pred3, y_test)\nprint(\"Ridge RMSE: {}\".format(rmse_ridge))\naccuracy_ridge = model3.score(x_test,y_test)\nprint(\"Accuracy Ridge: {}\".format(accuracy_ridge))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Summary:\nAs estimated by the correlation plot of this model, it can be established that the model does not have any linear relationship between input features and quality of wine. Although 'Alcohol' has a stron relationship with the quality of wine, it cannot be concluded that the relationship between them is linear. This model is clearly a classification model. Classifiers like K-Means and Random Forest would do well with this data.\n\nNote:\nAs the model is already scaled no scaling was needed for regularization. Regularization is to be performed when using Lasso, Ridge and other regularization models."},{"metadata":{},"cell_type":"markdown","source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}