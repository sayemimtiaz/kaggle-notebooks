{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom keras.preprocessing.image import ImageDataGenerator     # for images\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n%config Completer.use_jedi = False\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-15T11:34:56.921925Z","iopub.execute_input":"2021-07-15T11:34:56.922508Z","iopub.status.idle":"2021-07-15T11:35:04.578769Z","shell.execute_reply.started":"2021-07-15T11:34:56.922384Z","shell.execute_reply":"2021-07-15T11:35:04.577964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Part 1 : Importing Data set\n\nwe will only import trainnig set","metadata":{}},{"cell_type":"code","source":"data_train = pd.read_csv(\"/kaggle/input/google-stock-price/Google_Stock_Price_Train.csv\")\ndata_train.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-15T11:35:04.579935Z","iopub.execute_input":"2021-07-15T11:35:04.580321Z","iopub.status.idle":"2021-07-15T11:35:04.633222Z","shell.execute_reply.started":"2021-07-15T11:35:04.580293Z","shell.execute_reply":"2021-07-15T11:35:04.632396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#training set through which we train the RNN\ntraining_set = data_train.iloc[:,1:2].values\ntraining_set","metadata":{"execution":{"iopub.status.busy":"2021-07-15T11:35:04.634574Z","iopub.execute_input":"2021-07-15T11:35:04.634981Z","iopub.status.idle":"2021-07-15T11:35:04.642392Z","shell.execute_reply.started":"2021-07-15T11:35:04.634951Z","shell.execute_reply":"2021-07-15T11:35:04.641601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Feature Scaling\nwe will use Normalisation, for this we use min max saclaer class\n\nIt will convert all stock price in between 0 and 1","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nsc = MinMaxScaler(feature_range=(0,1))\n#dataset with scaled value\ntraining_set_scaled = sc.fit_transform(training_set)","metadata":{"execution":{"iopub.status.busy":"2021-07-15T11:35:04.643849Z","iopub.execute_input":"2021-07-15T11:35:04.644343Z","iopub.status.idle":"2021-07-15T11:35:05.475685Z","shell.execute_reply.started":"2021-07-15T11:35:04.644312Z","shell.execute_reply":"2021-07-15T11:35:05.474504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_set_scaled    #all is between 0 and 1","metadata":{"execution":{"iopub.status.busy":"2021-07-15T11:35:05.477232Z","iopub.execute_input":"2021-07-15T11:35:05.477551Z","iopub.status.idle":"2021-07-15T11:35:05.487676Z","shell.execute_reply.started":"2021-07-15T11:35:05.477515Z","shell.execute_reply":"2021-07-15T11:35:05.486519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Creating a data structure with 60 timesteps and 1 output  \n\n- ` 60 timesteps means at each time t the rnn will lookat 60 stock prices before time t and based on trends it will predict the next output. `\n\n- ` it will use the preivous 60 information to predict the output`\n\n- `60 timesteps means stock price of 3 months (20 timesteps each month)`","metadata":{}},{"cell_type":"code","source":"#input 60 previous timesteps\nX_train = [] \n#y_train contain stock price at time T+1\ny_train = []\n\nfor i in range(60, 1258):\n    X_train.append(training_set_scaled[i-60:i,0])  #60 previous stock price from i\n    y_train.append(training_set_scaled[i, 0])\n    \n# make them numpy array\nX_train, y_train = np.array(X_train), np.array(y_train)\n    \n    \nprint(\"X_TRAIN \" ,X_train)\nprint(\"Y_TRAIN \" ,y_train)","metadata":{"execution":{"iopub.status.busy":"2021-07-15T11:35:05.489117Z","iopub.execute_input":"2021-07-15T11:35:05.489429Z","iopub.status.idle":"2021-07-15T11:35:05.508892Z","shell.execute_reply.started":"2021-07-15T11:35:05.489397Z","shell.execute_reply":"2021-07-15T11:35:05.507663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4 Reshaping the X_train to 3 Dimension","metadata":{}},{"cell_type":"code","source":"print(\"SHAPE BEFORE RESHAPING: X_Train is \", X_train.shape)\n\nprint(\"\\n\\nRESHAPING to 3D........\\n\\n\")\nX_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n\nprint(\"SHAPE AFTER RESHAPING: X_Train is \", X_train.shape)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-15T11:35:05.510584Z","iopub.execute_input":"2021-07-15T11:35:05.510965Z","iopub.status.idle":"2021-07-15T11:35:05.521975Z","shell.execute_reply.started":"2021-07-15T11:35:05.510927Z","shell.execute_reply":"2021-07-15T11:35:05.521102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PART 5: Building RNN","metadata":{}},{"cell_type":"code","source":"#import LIbraries\nfrom keras.models import Sequential #for seqntial model\nfrom keras.layers import LSTM, Dropout, Dense","metadata":{"execution":{"iopub.status.busy":"2021-07-15T11:35:05.524585Z","iopub.execute_input":"2021-07-15T11:35:05.524921Z","iopub.status.idle":"2021-07-15T11:35:05.540448Z","shell.execute_reply.started":"2021-07-15T11:35:05.52488Z","shell.execute_reply":"2021-07-15T11:35:05.539135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#initialize RNN\nmodel = Sequential()\n\n#adding First LSTM LAYER AND SOME DROPOUT REgularisation\nmodel.add(LSTM(units = 50, return_sequences=True, input_shape = (X_train.shape[1],1)))\n#dropout 20% of neuron during each epoch of traiing\nmodel.add(Dropout(0.2))\n\n#adding Second LSTM Layer with dropout Regularisation\nmodel.add(LSTM(units = 50, return_sequences=True)) #in next layers we dont need input shape\nmodel.add(Dropout(0.2))\n\n#adding Third LSTM Layer\nmodel.add(LSTM(units = 50, return_sequences=True))\nmodel.add(Dropout(0.2))\n\n#adding Fourth LSTM Layer  --> return seq == False(no more layers now)\nmodel.add(LSTM(units = 50, return_sequences=False))\nmodel.add(Dropout(0.2))\n\n#adding output layer\nmodel.add(Dense(units=1))\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-07-15T11:35:05.542266Z","iopub.execute_input":"2021-07-15T11:35:05.54257Z","iopub.status.idle":"2021-07-15T11:35:06.909718Z","shell.execute_reply.started":"2021-07-15T11:35:05.542539Z","shell.execute_reply":"2021-07-15T11:35:06.908695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Compiling the RNN\nmodel.compile(optimizer='adam', loss='mean_squared_error')\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-15T11:35:06.911426Z","iopub.execute_input":"2021-07-15T11:35:06.91185Z","iopub.status.idle":"2021-07-15T11:35:06.928754Z","shell.execute_reply.started":"2021-07-15T11:35:06.911788Z","shell.execute_reply":"2021-07-15T11:35:06.927945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#fitting the RNN to traiing set\nmodel.fit(X_train, y_train,epochs=100, batch_size=32)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-07-15T11:35:06.930093Z","iopub.execute_input":"2021-07-15T11:35:06.930667Z","iopub.status.idle":"2021-07-15T11:42:20.629085Z","shell.execute_reply.started":"2021-07-15T11:35:06.930634Z","shell.execute_reply":"2021-07-15T11:42:20.627964Z"},"jupyter":{"outputs_hidden":true},"collapsed":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. Predicting and Visualising Result","metadata":{}},{"cell_type":"code","source":"data_test = pd.read_csv(\"/kaggle/input/google-stock-price/Google_Stock_Price_Test.csv\")\nreal_stock_price = data_test.iloc[:,1:2].values\nprint(real_stock_price)\nprint(data_test.head())","metadata":{"execution":{"iopub.status.busy":"2021-07-15T11:42:20.630546Z","iopub.execute_input":"2021-07-15T11:42:20.630879Z","iopub.status.idle":"2021-07-15T11:42:20.658399Z","shell.execute_reply.started":"2021-07-15T11:42:20.630818Z","shell.execute_reply":"2021-07-15T11:42:20.657265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Predict Stock Price of 2017\ndataset_total = pd.concat((data_train['Open'], data_test['Open']), axis=0)\ninputs =  dataset_total[len(dataset_total) - len(data_test) -60: ].values\ninputs = inputs.reshape(-1,1)\ninputs = sc.transform(inputs)\n\nX_test = [] \n\nfor i in range(60, 80):\n    X_test.append(inputs[i-60:i,0])      \n\nX_test = np.array(X_test)\nX_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n\npredicted_stock_price = model.predict(X_test)\npredicted_stock_price = sc.inverse_transform(predicted_stock_price)","metadata":{"execution":{"iopub.status.busy":"2021-07-15T11:42:49.031711Z","iopub.execute_input":"2021-07-15T11:42:49.032128Z","iopub.status.idle":"2021-07-15T11:42:50.722116Z","shell.execute_reply.started":"2021-07-15T11:42:49.032087Z","shell.execute_reply":"2021-07-15T11:42:50.72098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visulaize the Result","metadata":{}},{"cell_type":"code","source":"plt.plot(real_stock_price, color = 'red', label = 'Real Google Stock Price')\nplt.plot(predicted_stock_price, color = 'blue', label = 'Predicted Google Stock Price')\nplt.title(\"Google Stock Price Prediction\")\nplt.xlabel(\"Time\")\nplt.ylabel(\"Stock Price\")\n\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-15T11:46:10.801842Z","iopub.execute_input":"2021-07-15T11:46:10.802246Z","iopub.status.idle":"2021-07-15T11:46:11.00362Z","shell.execute_reply.started":"2021-07-15T11:46:10.802208Z","shell.execute_reply":"2021-07-15T11:46:11.002311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluate the RNN","metadata":{}},{"cell_type":"code","source":"import math\nfrom sklearn.metrics import mean_squared_error\nrmse = math.sqrt(mean_squared_error(real_stock_price, predicted_stock_price))\nrmse","metadata":{"execution":{"iopub.status.busy":"2021-07-15T11:51:40.581179Z","iopub.execute_input":"2021-07-15T11:51:40.581577Z","iopub.status.idle":"2021-07-15T11:51:40.592241Z","shell.execute_reply.started":"2021-07-15T11:51:40.581544Z","shell.execute_reply":"2021-07-15T11:51:40.59087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Imporving RNN\n\nHi guys,\n\nhere are different ways to improve the RNN model:\n\n1. Getting more training data: we trained our model on the past 5 years of the Google Stock Price but it would be even better to train it on the past 10 years.\n2. Increasing the number of timesteps: the model remembered the stock prices from the 60 previous financial days to predict the stock price of the next day. Thatâ€™s because we chose a number of 60 timesteps (3 months). You could try to increase the number of timesteps, by choosing for example 120 timesteps (6 months).\n3. Adding some other indicators: if you have the financial instinct that the stock price of some other companies might be correlated to the one of Google, you could add this other stock price as a new indicator in the training data.\n4. Adding more LSTM layers: we built a RNN with four LSTM layers but you could try with even more.\n5. Adding more neurones in the LSTM layers: we highlighted the fact that we needed a high number of neurones in the LSTM layers to respond better to the complexity of the problem and we chose to include 50 neurones in each of our 4 LSTM layers. You could try an architecture with even more neurones in each of the 4 (or more) LSTM layers.\n\n\nEnjoy Deep Learning!","metadata":{}}]}