{"cells":[{"metadata":{},"cell_type":"markdown","source":"**It's time to EXPLORE**\n\n# Exploration : Prediction\n\n<font color=\"Green\">  Date: 17-07-2020 - 18-07-2020 KaggleStreak </font>\n\nSo, here I start my **Exploration Series**:\n *\" It will consists of Data Pre-processing, Data Visualization, EDA, Feature Engg., Model build and finally Evaluation of model. \"*\n\nComing to the present dataset I a using **Campus Recruitment** dataset (link:[https://www.kaggle.com/benroshan/factors-affecting-campus-placement](http://))\n\nThis dataset was developed by *Ben Roshan D*\n\nAnd according to him, *This data set consists of Placement data of students in our campus. It includes secondary and higher secondary school percentage and specialization. It also includes degree specialization, type and Work experience and salary offers to the placed students*\n\nSo, here I start my first exploration to the saame dataset.\n\nDo give <font color=\"Red\"> UPVOTE </font>\n\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Data Preprocessing","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Importing necessary libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reading the dataset\ntrain_data = pd.read_csv('../input/factors-affecting-campus-placement/Placement_Data_Full_Class.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Let's have a detailed look over dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**So, we have a useless column 'sl_no, let's just drop it first**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = train_data.iloc[:,1:]\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Shape of data: \",train_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Looking ate the unique values of Categorical Features\nprint(train_data['ssc_b'].unique())\nprint(train_data['hsc_b'].unique())\nprint(train_data['hsc_s'].unique())\nprint(train_data['degree_t'].unique())\nprint(train_data['workex'].unique())\nprint(train_data['specialisation'].unique())\nprint(train_data['status'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have 67 null values in *salary* column, so I had made a separate dataframe for not null values in all columns for Exploration of data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"null_salary_data = train_data[train_data['salary'].notna()]\nnull_salary_data = null_salary_data.reset_index(drop = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Visualization\n### Let's have some Plots for a user-friendly look over data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 1) Salary","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"var = 'salary'\nfig, ax = plt.subplots()\nfig.set_size_inches(20, 8)\nplt.xticks(rotation=90);\nsns.countplot(x = var,palette=\"ch:.4\", data = null_salary_data)\nax.set_xlabel('Salary', fontsize=15)\nax.set_ylabel('Count', fontsize=15)\nax.set_title('Salary Count Distribution', fontsize=15)\nsns.despine()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2) Status","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_data['status'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"var = 'status'\nfig, ax = plt.subplots()\nfig.set_size_inches(5,5)\nsns.countplot(x = var, data = train_data)\nax.set_xlabel('Status', fontsize=15)\nax.set_ylabel('Count', fontsize=15)\nax.set_title('Status Count Distribution', fontsize=15)\nax.tick_params(labelsize=15)\nsns.despine()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Not placed data are less than half of Placed one.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 3) Senior Secondary Board","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Senior Secondary Board: ',train_data['ssc_b'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"var = 'ssc_b'\nfig, ax = plt.subplots()\nfig.set_size_inches(5,5)\nsns.countplot(x = var, data = train_data)\nax.set_xlabel('Senior Secondary', fontsize=15)\nax.set_ylabel('Count', fontsize=15)\nax.set_title('Senior Secondary Count Distribution', fontsize=15)\nax.tick_params(labelsize=15)\nsns.despine()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4) Higher Secondary Boards","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Higher Secondary Boards: ',train_data['hsc_b'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"var = 'hsc_b'\nfig, ax = plt.subplots()\nfig.set_size_inches(5,5)\nsns.countplot(x = var, data = train_data)\nax.set_xlabel('Higher Secondary', fontsize=15)\nax.set_ylabel('Count', fontsize=15)\nax.set_title('Higher Secondary Count Distribution', fontsize=15)\nax.tick_params(labelsize=15)\nsns.despine()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 5) Higher Secondary Subjects","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Higher Secondary Subjects: ',train_data['hsc_s'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"var = 'hsc_s'\nfig, ax = plt.subplots()\nfig.set_size_inches(5,5)\nsns.countplot(x = var, data = train_data)\nax.set_xlabel('Higher Secondary Subjects', fontsize=15)\nax.set_ylabel('Count', fontsize=15)\nax.set_title('Higher Secondary Count Distribution', fontsize=15)\nax.tick_params(labelsize=15)\nsns.despine()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Commerce* is the most popular Subjects in dataset followed by *Science*. But, *Arts* is having a very low popularity when compared to other ones","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 6) Work experience","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Work Experience: ',train_data['workex'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"var = 'workex'\nfig, ax = plt.subplots()\nfig.set_size_inches(5,5)\nsns.countplot(x = var, data = train_data)\nax.set_xlabel('Work Experience', fontsize=15)\nax.set_ylabel('Count', fontsize=15)\nax.set_title('Work Experience Count Distribution', fontsize=15)\nax.tick_params(labelsize=15)\nsns.despine()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 7) Specialisation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"var = 'specialisation'\nfig, ax = plt.subplots()\nfig.set_size_inches(5,5)\nsns.countplot(x = var, data = train_data)\nax.set_xlabel('Specialisation', fontsize=15)\nax.set_ylabel('Count', fontsize=15)\nax.set_title('Specialisation Count Distribution', fontsize=15)\nax.tick_params(labelsize=15)\nsns.despine()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Now after having some Count Visualization let's visualize some related one**\n\n### First I started with 'Senior Secondary Board Salary On basis of Gender'","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots()\nfig.set_size_inches(5,5)\nsns.barplot(x='ssc_b', y='salary',hue='gender', data=train_data)\nax.set_xlabel('Senior Secondary Board', fontsize=15)\nax.set_ylabel('Salary', fontsize=15)\nax.set_title('Senior Secondary Board Salary On basis of Gender', fontsize=10)\nax.tick_params(labelsize=15)\nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**As our target feature is *Status*, So let's compare other features w.r.t. status**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Status vs feature count","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(nrows = 2, ncols = 2, figsize = (10,10))\n\nsns.countplot(x = 'gender', hue = 'status', palette=\"ch:2.5,-.2,dark=.3\",data = train_data, ax = ax1)\nax1.set_title('Status on basis of Gender', fontsize=15)\nax1.tick_params(labelsize=15)\n\nsns.countplot(x = 'specialisation', hue = 'status', palette=\"ch:5,-.6,dark=.3\", data = train_data, ax = ax2)\nax2.set_title('Status on basis of Specialisation', fontsize=15)\nax2.tick_params(labelsize=15)\n\nsns.countplot(x = 'workex', hue = 'status', palette=\"ch:10.5,-8.2,dark=.3\", data = train_data, ax = ax3)\nax3.set_title('Status on basis of Work Exp.', fontsize=15)\nax3.tick_params(labelsize=15)\n\nsns.countplot(x = 'degree_t', hue = 'status', palette=\"ch:12.5,-11.2,dark=.3\", data = train_data, ax = ax4)\nax4.set_title('Status on basis of Degree', fontsize=15)\nax4.tick_params(labelsize=15)\n\nplt.subplots_adjust(wspace=0.5)\nplt.tight_layout() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Working with Categorical Data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"As discussed in many earlier notebooks, we have 2 popular ways to handle Categorical data:\n1. OneHotEncoder\n2. LabelEncoder\n\n### First we will start with Gender \n**We will be applying One-hot Encding here**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Gender = train_data[['gender']]\nGender = pd.get_dummies(Gender,drop_first=True)\nGender.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Followed we are modifing all others columns","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"ssc_b = train_data[['ssc_b']]\nssc_b = pd.get_dummies(ssc_b,drop_first=True)\nhsc_b = train_data[['hsc_b']]\nhsc_b = pd.get_dummies(hsc_b,drop_first=True)\nhsc_s = train_data[['hsc_s']]\nhsc_s = pd.get_dummies(hsc_s,drop_first=True)\ndegree_t = train_data[['degree_t']]\ndegree_t = pd.get_dummies(degree_t,drop_first=True)\nworkex = train_data[['workex']]\nworkex = pd.get_dummies(workex,drop_first=True)\nspecialisation = train_data[['specialisation']]\nspecialisation = pd.get_dummies(specialisation,drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**For Status Column I am using Label Encoding, as we need only one column for Y(target feature)**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.replace({\"Placed\":1,\"Not Placed\":0},inplace=True)\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I will be droping *salary* column as it has a large null values when compared to whole size of data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.drop([\"salary\"],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**And, then we will add up all One-Hot Encoded DF to final one, followed by droping the useless.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"final_train= pd.concat([train_data,Gender,ssc_b,hsc_b,hsc_s,degree_t,workex,specialisation],axis=1)\nfinal_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_train.drop([\"gender\",\"ssc_b\",\"hsc_b\",\"hsc_s\",\"degree_t\",\"workex\",\"specialisation\"],axis=1,inplace=True)\nfinal_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Final Shape of data: \",final_train.shape)\nprint(\"\\nFinal Columns of data:\\n\",final_train.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preparation of final data \n### and checking for any other Useless Features (here Heat Map will help us)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = final_train.loc[:,['ssc_p', 'hsc_p', 'degree_p', 'etest_p', 'mba_p', 'gender_M',\n       'ssc_b_Others', 'hsc_b_Others', 'hsc_s_Commerce', 'hsc_s_Science',\n       'degree_t_Others', 'degree_t_Sci&Tech', 'workex_Yes',\n       'specialisation_Mkt&HR']]\ny = final_train.loc[:,['status']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(18,18))\nsns.heatmap(X.corr(),annot=True,cmap='RdYlGn')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Build it (Model)\n\nFirst we are spliting the data to train and test for the model\n\n**We will using following 3 models for our dataset:**\n1. Logistic Regression\n2. XGB Classifier\n3. GradientBoosting Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 25)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1) Logistic Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nsc_X = StandardScaler()\nX_train = sc_X.fit_transform(X_train)\nX_test = sc_X.transform(X_test)\nlog_reg = LogisticRegression() \nlog_reg.fit(X_train,y_train)\nlog_pred = log_reg.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import scikitplot as skplt\nskplt.metrics.plot_confusion_matrix(y_test,log_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\nprint(\"Logistic Model Accuracy is: \",metrics.accuracy_score(y_test, log_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3) XGB Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\nxgb = XGBClassifier()\nxgb.fit(X_train, y_train)\nxgb_pred = xgb.predict(X_test)\n\nprint(\"XGBClassifier Accuracy is: \",metrics.accuracy_score(y_test, xgb_pred))\nskplt.metrics.plot_confusion_matrix(y_test,xgb_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3) Gradient-Boosting Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\ngbk = GradientBoostingClassifier()\ngbk.fit(X_train, y_train)\ngbk_pred = gbk.predict(X_test)\n\nprint(\"GradientBoostingClassifier Accuracy is: \",metrics.accuracy_score(y_test, gbk_pred))\nskplt.metrics.plot_confusion_matrix(y_test,gbk_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### ROC of XGB and GradientBoost","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\n\nfig, (ax, ax1) = plt.subplots(nrows = 1, ncols = 2, figsize = (15,5))\n\nprobs = xgb.predict_proba(X_test)\npreds = probs[:,1]\nfprxgb, tprxgb, thresholdxgb = metrics.roc_curve(y_test, preds)\nroc_aucxgb = metrics.auc(fprxgb, tprxgb)\n\nax.plot(fprxgb, tprxgb, 'b', label = 'AUC = %0.2f' % roc_aucxgb)\nax.plot([0, 1], [0, 1],'r--')\nax.set_title('Receiver Operating Characteristic XGBOOST ',fontsize=10)\nax.set_ylabel('True Positive Rate',fontsize=20)\nax.set_xlabel('False Positive Rate',fontsize=15)\nax.legend(loc = 'lower right', prop={'size': 16})\n\nprobs = gbk.predict_proba(X_test)\npreds = probs[:,1]\nfprgbk, tprgbk, thresholdgbk = metrics.roc_curve(y_test, preds)\nroc_aucgbk = metrics.auc(fprgbk, tprgbk)\n\nax1.plot(fprgbk, tprgbk, 'b', label = 'AUC = %0.2f' % roc_aucgbk)\nax1.plot([0, 1], [0, 1],'r--')\nax1.set_title('Receiver Operating Characteristic GRADIENT BOOST ',fontsize=10)\nax1.set_ylabel('True Positive Rate',fontsize=20)\nax1.set_xlabel('False Positive Rate',fontsize=15)\nax1.legend(loc = 'lower right', prop={'size': 16})\n\nplt.subplots_adjust(wspace=1)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**DO look My Classification Model Evaluation for more evaluation works :**\n\n[https://www.kaggle.com/iabhishekmaurya/classification-model-evaluation](http://)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":" So, Finally this NoteBook End here ü§µüèª\n \n One could go even further by using more different models to try upon this data. But, for now I left it  over you all\n \n Before going a humble request if you liked the notebook the \n <font color=\"Red\">Please Upvote ( It motivates me ) </font>\n \n And Stay Tuned... \n \n Till then Happy Coding\n ","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}