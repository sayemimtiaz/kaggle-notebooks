{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nimport datetime as dt\nfrom datetime import timedelta\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/data.csv\", encoding=\"ISO-8859-1\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()/df.shape[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"25% of CustomerID values are missing. It might be people who are not registered so they are buying without account. That's what I think at the first glance. But for purpose of this analysis I'm about to drop these rows."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dropna(subset=['CustomerID'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Number of rows', df.shape[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 406829 rows but as you can see 1 row is not equal to 1 transactions. Every row means 1 listing on the invoice."},{"metadata":{"trusted":true},"cell_type":"code","source":"#types\nfor c in ['InvoiceNo', 'StockCode', 'Description', 'CustomerID', 'Country']:\n    df[c] = df[c].astype('category')\n#dates    \ndf['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\ndf['Year'] = df['InvoiceDate'].dt.year\ndf['Month'] = df['InvoiceDate'].dt.month\ndf['Day'] = df['InvoiceDate'].dt.day\ndf['DayOfWeek'] = df['InvoiceDate'].dt.dayofweek\ndf['DayOfWeek'] = df['DayOfWeek'].map({0: 'Monday', 1: 'Tuesday', 2: 'Wednesday', 3: 'Thursday', 4: 'Friday', 5: 'Saturday', 6: 'Sunday'})\ndf['Hour'] = df['InvoiceDate'].dt.hour\n\n#invoice\ndf['StockValue'] = df['Quantity']*df['UnitPrice']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df['InvoiceDate'].min())\nprint(df['InvoiceDate'].max())\nprint(df['InvoiceDate'].max() - df['InvoiceDate'].min())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Period of analysis is 1 year with additional couple days."},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"def column_statistic(column):\n    plt.figure(figsize=(20,10))\n    sns.boxplot(df[column])\n    print(df[column].describe())\n    print('-'*10)\n    print('Variation coefficient {}'.format(df[column].std()/df[column].mean()))\n    print('-'*10)\n    print('Minimum values')\n    print(df[column].sort_values().head(5))\n    print('Maximum values')\n    print(df[column].sort_values(ascending=False).head(5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"column_statistic('Quantity')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['Quantity'] < 0].sample(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are invoices which have negative number of quantity of some listings. As you can see those invoices have letter \"C\" at the beggining of invoice number. I suppose these are credit notes. Let's mark them. 2 listings with highest value of quantity have been turned back."},{"metadata":{"trusted":true},"cell_type":"code","source":"df['InvoiceType'] = df['InvoiceNo'].apply(lambda x: 'FK' if x[:1] == 'C' else 'FV')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"column_statistic('UnitPrice')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['UnitPrice'] == 0].sample(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some of the listings on invoices have 0 unit prices. It must be some kind of discounts or promotions."},{"metadata":{},"cell_type":"markdown","source":"# Sales over time"},{"metadata":{"trusted":true},"cell_type":"code","source":"group_type = df.groupby('InvoiceType')['InvoiceNo'].nunique()\nprint('We have got {0} invoices and {1} correcting invoices'.format(group_type[1],\n                                                                    group_type[0]))\nprint('Its about {0} invoices and {1} correcting invoices per day'.format(group_type[1]/373,\n                                                                        group_type[0]/373))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Total number of invoices is 22190, which 83,5% are sales invoices and the rest are credit notes."},{"metadata":{"trusted":true},"cell_type":"code","source":"date_group = df.groupby('Month')['Day'].nunique()\nplt.figure(figsize=(20,10))\nsns.barplot(date_group.index, date_group.values)\nplt.ylabel('Number of working days')\nplt.xlabel('Month')\nplt.title('Number of days in each month that transactions were made', fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dayweek_group = df.groupby('DayOfWeek')['InvoiceNo'].nunique()\nplt.figure(figsize=(20,10))\nsns.barplot(dayweek_group.index, dayweek_group.values, order=['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Sunday'])\nplt.ylabel('Number of invoices')\nplt.xlabel('Day')\nplt.title('Number of invoices for every day', fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The working days are on more or less on the same level through the year. Interesting fact is that there are no transactions on Saturday at all and day with highest number of invoices is Thursday"},{"metadata":{},"cell_type":"markdown","source":"# Customers"},{"metadata":{"trusted":true},"cell_type":"code","source":"index = df['CustomerID'].drop_duplicates().index\ndf_unique_customer = df.loc[index, :]\nunique_customer_count = df_unique_customer['Country'].value_counts()\n#############\nplt.figure(figsize=(20,15))\nsns.barplot(y=unique_customer_count.index, x=unique_customer_count.values,\n            order=unique_customer_count.index)\nplt.yticks(size=15)\nplt.ylabel('Country', fontsize=15)\nplt.xlabel('Invoices', fontsize=15)\nplt.title('Number of invoices per each country', fontsize=15)\nprint('There are {} customers who made {} transactions'.format(len(df['CustomerID'].unique()),\n                                                             len(df['InvoiceNo'].unique())))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##data\ncustomer_value = df.groupby('CustomerID')['StockValue'].sum().sort_values(ascending=False)\n##plot\nplt.figure(figsize=(20,15))\nplt.barh(y=np.linspace(0,19,20), width=customer_value[:20][::-1].values, align='center', linewidth=10)\nplt.yticks(np.linspace(0,19,20), customer_value[:20][::-1].index, size=15)\nplt.title('Most profitable customers', fontsize=15)\nplt.xlabel('Stock value', fontsize=15)\nplt.ylabel('Customer ID', fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"customer_20 = customer_value[:20].reset_index()\n\nfor i, customer in enumerate(customer_20['CustomerID']):\n    value_for_customer = df[df['CustomerID'] == customer]['Country'].unique()[0]\n    customer_20.loc[i, 'Country'] = value_for_customer\nprint('Top 20 most profitable customers are from: ')\ncustomer_20['Country'].value_counts()\n                                       ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Over 90% percent of customers are from United Kingdom. The highest income is generated from client with ID 14646. Stock value of that client is equal to 279 489.02$. Out of 20 top profitable client 16 are from UK, 2 from Ireland and each one from Australia and Netherlands."},{"metadata":{},"cell_type":"markdown","source":"# Stock codes and items"},{"metadata":{"trusted":true},"cell_type":"code","source":"stock_code_count = len(df['StockCode'].unique())\nprint('There are {} different stock codes'.format(stock_code_count))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text = \" \".join(review for review in df['Description'])\nwordcloud = WordCloud(background_color=\"white\").generate(text)\nplt.figure(figsize=(15,15))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.title('Most frequent words in description of item', fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#stock_code_v_counts = df['StockCode'].value_counts(normalize=True)[:20]\nstock_code_v_counts = df.groupby('StockCode')['StockValue'].sum().sort_values(ascending=False)[:20]\nstock_code_v_counts = stock_code_v_counts/df['StockValue'].sum()\nplt.figure(figsize=(20,10))\nsns.barplot(y=stock_code_v_counts.index, x=stock_code_v_counts.values,\n            order=stock_code_v_counts.index, color='blue')\nplt.title('Most profitable stock codes', fontsize=15)\nplt.xlabel('Percent of total stock value', fontsize=15)\nplt.ylabel('Stock code', fontsize=15)\nplt.yticks(size=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"description_stock_code = stock_code_v_counts.reset_index()\nfor i, stockcode in enumerate(description_stock_code['StockCode']):\n    value_for_stockcode = df[df['StockCode'] == stockcode]['Description'].value_counts().index[0]\n    description_stock_code.loc[i, 'Description'] = value_for_stockcode\nprint('What are these 20 top profitable stock codes?')    \ndescription_stock_code['Description']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"digit = df['StockCode'].apply(lambda x: 'char' if x.isalpha() else 'number')\nchar_index = digit[digit == 'char'].index\n\ndf_char_stock = df.loc[char_index, :]\nprint('Unusual stock codes: {}'.format([x for x in df_char_stock['StockCode'].unique()])) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for stockcode in df_char_stock['StockCode'].unique():\n    print('Stock code: {} has {} unique values  - Description {}'.format(stockcode,\n                                                                        df[df['StockCode'] == stockcode]['Description'].nunique(),\n                                                                       df[df['StockCode'] == stockcode]['Description'].unique()[0]))\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most of the stock codes are just numbers which describe the product but some of them are some kind of text. It seems that there is **POST** service available. Code **D** is assigned to discounted transactions which occurs only in FK invoices. **PADS** are some kind of gifts. **DOTCOM** is as well post service I suppose. **CRUK** is a charged fee to the customer with ID 14096. Not sure about **M**."},{"metadata":{},"cell_type":"markdown","source":"For the purpose of further analysis I will only include the sales invoices to avoid observations with negative quantity and huge value of transactions whic are counted as outliers."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_low = df[df['InvoiceType'] == 'FV']\noutlier_drop = df_low['StockValue'].quantile(0.95)\ndf_low = df_low[df_low['StockValue'] < outlier_drop]\nprint(df_low.shape[0]/df.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_low['CustomerID'].nunique()/df['CustomerID'].nunique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After dropping 5% of data we lost a little more than 7% of observations and less than 3,5% of customers."},{"metadata":{"trusted":true},"cell_type":"code","source":"stock_value_group_mean = df_low['StockValue'].groupby(df_low['Month']).mean()\nstock_value_group_std = df_low['StockValue'].groupby(df_low['Month']).std()\nplt.figure(figsize=(20,10))\nplt.plot(stock_value_group_mean, marker=\"o\", label='Mean stock value')\nplt.fill_between(stock_value_group_mean.index, stock_value_group_mean.values - stock_value_group_std.values, stock_value_group_mean.values + stock_value_group_std.values,\n                 color='gray', alpha=0.4, label='Standard deviation')\nplt.xticks(np.linspace(1,12,12))\nplt.xlabel('Month', fontsize=15)\nplt.ylabel('Stock value', fontsize=15)\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_low['StockValue'].std()/df_low['StockValue'].mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The mean stock value over the year is constant. The variation coefficient is 0,86. Just to reminder in the not filtered data it was about 20~. In that case filtering data seems needed"},{"metadata":{},"cell_type":"markdown","source":"****RFM segmentation****"},{"metadata":{},"cell_type":"markdown","source":"Next step is to cluster clients by RFM analysis (Recency, Frequency, Monetary). It groups customers based on their transaction history â€“ how recently, how often and how much did they buy."},{"metadata":{"trusted":true},"cell_type":"code","source":"date = df_low['InvoiceDate'].max() + timedelta(days=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfm = df_low.groupby(['CustomerID']).agg({'StockValue': lambda x: x.sum(),\n                                'CustomerID': 'count',\n                               'InvoiceDate': lambda x: (date-x.max()).days})\nrfm.rename(columns={'StockValue': 'TotalMonetary',\n                    'CustomerID': 'TotalTransactions',\n                    'InvoiceDate': 'LastPurchase'}, inplace=True)\nrfm.dropna(inplace=True)\n\n\nprint(rfm.shape[0])\nrfm.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We still have 4224 unique customers to cluster. Table above shows 3 attribute that every customer will be clustered on.\n\nTotalMonetary = total amount of cash that customer has spend\n\nTotalTransactions = number of transactions for each customer\n\nLastPurchase = number of days when was the last transaction"},{"metadata":{},"cell_type":"markdown","source":"Right now every attribute get a score from 1 to 5 (the scale is dependent on the author) where 1 is best and 5 the worst. I'm about to get this score by dividing values into quantilies for each attribute. "},{"metadata":{"trusted":true},"cell_type":"code","source":"quantile = rfm.quantile(np.linspace(0,1,5))\nquantile","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_bins_monetary(x):\n    if x <= quantile.loc[0, 'TotalMonetary']:\n        return 5\n    elif x <= quantile.loc[0.25, 'TotalMonetary']:\n        return 4\n    elif x <= quantile.loc[0.5, 'TotalMonetary']:\n        return 3\n    elif x <= quantile.loc[0.75, 'TotalMonetary']:\n        return 2\n    else:\n        return 1\n    \ndef get_bins_transactions(x):\n    if x <= quantile.loc[0, 'TotalTransactions']:\n        return 5\n    elif x <= quantile.loc[0.25, 'TotalTransactions']:\n        return 4\n    elif x <= quantile.loc[0.5, 'TotalTransactions']:\n        return 3\n    elif x <= quantile.loc[0.75, 'TotalTransactions']:\n        return 2\n    else:\n        return 1\n    \ndef get_bins_purchase(x):\n    if x <= quantile.loc[0, 'LastPurchase']:\n        return 1\n    elif x <= quantile.loc[0.25, 'LastPurchase']:\n        return 2\n    elif x <= quantile.loc[0.5, 'LastPurchase']:\n        return 3\n    elif x <= quantile.loc[0.75, 'LastPurchase']:\n        return 4\n    else:\n        return 5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfm['m_rate'] = rfm['TotalMonetary'].apply(get_bins_monetary)\nrfm['f_rate'] = rfm['TotalTransactions'].apply(get_bins_transactions)\nrfm['r_rate'] = rfm['LastPurchase'].apply(get_bins_purchase)\nrfm['RFM'] = rfm['m_rate'].map(str) + rfm['f_rate'].map(str) + rfm['r_rate'].map(str)\nrfm['RFM_value'] = rfm['m_rate'] + rfm['f_rate'] + rfm['r_rate']\nrfm.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"That's how the table looks like after signing every score"},{"metadata":{"trusted":true},"cell_type":"code","source":"cross_table1 = pd.crosstab(index=rfm['m_rate'], columns=rfm['f_rate'])\ncross_table2 = pd.crosstab(index=rfm['m_rate'], columns=rfm['r_rate'])\ncross_table3 = pd.crosstab(index=rfm['f_rate'], columns=rfm['r_rate'])\nplt.figure(figsize=(20,15))\nplt.subplot(311)\nax1 = sns.heatmap(cross_table1, cmap='viridis', annot=True, fmt=\".0f\")\nax1.invert_yaxis()\nax1.set_ylabel('Monetary')\nax1.set_xlabel('Frequency')\nplt.subplot(312)\nax2 = sns.heatmap(cross_table2, cmap='viridis', annot=True, fmt=\".0f\")\nax2.invert_yaxis()\nax2.set_ylabel('Monetary')\nax2.set_xlabel('Recency')\nplt.subplot(313)\nax3 = sns.heatmap(cross_table3, cmap='viridis', annot=True, fmt=\".0f\")\nax3.invert_yaxis()\nax3.set_ylabel('Frequency')\nax3.set_xlabel('Recency')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Correlation monetary - frequency: ', rfm[['m_rate', 'f_rate']].corr().iloc[1,0])\nprint('Correlation monetary - recency: ', rfm[['m_rate', 'r_rate']].corr().iloc[1,0])\nprint('Correlation frequency - recency: ', rfm[['f_rate', 'r_rate']].corr().iloc[1,0])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}