{"cells":[{"metadata":{},"cell_type":"markdown","source":"# My first try at Data analytics"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Loading dependencies"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Libraries for data preparation, mathematics and os related tasks\nimport numpy as np\nimport os\nimport pandas as pd\n\n# Libraries for visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# For use in Jupyter notebook visualizations\n%matplotlib inline\nplt.style.use('seaborn-notebook')\n\n# machine learning\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Loading datasets and basic overview"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Important disclaimer:\n\n# The following code is almost entirely based and/or copied from work by Manav Sehgal and PandaBrenda published in Kaggle. \n# I have done only minor tweeks to suit the code to my purposes. \n# All credit goes to them. Check out their work here:\n# Manav Sehgal: https://www.kaggle.com/startupsci/titanic-data-science-solutions\n# PandaBrenda: https://www.kaggle.com/brendan45774\n\n# Current version: 1.00\n# Accuracy: 77%\n# Model: Linear Regression\n\n# There will be a lot of bugs - all suggestions are welcome!","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_path = '/kaggle/input/titanic/'\n\ndataset_file = 'train.csv'\ndataset_test_file = 'test.csv'\n\n# Combine train and test datasets to one for ease of use (for performing the same operations on both datasets - preventing\n# mismatch):\n\n# Function for loading the dataset\ndef load_dataset(dataset_path, dataset_file):\n    csv_path = os.path.join(dataset_path, dataset_file)\n    return pd.read_csv(csv_path)\n\n# Load train dataset\ntitanic = load_dataset(dataset_path, dataset_file)\n\n# Load test dataset\ntitanic_test = load_dataset(dataset_path, dataset_test_file)\n\n# Combine datasets\ncombine = [titanic, titanic_test]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's review the Titanic dataset features - data types, null or empty values etc.\ntitanic.info()\nprint('_'*40) # Print a line to separate the two tables\ntitanic_test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Basic statistical description of the training Titanic dataset\ntitanic.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"titanic.describe(include=['O']) # Returns distribution of categorical features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop \"Ticket\" and \"Cabin\" features from the dataset because of too many missing values. Also drop \"PassengerId\" because I won't use it.\nfor i in range(len(combine)):\n    combine[i] = combine[i].drop([\"Ticket\", \"Cabin\", \"PassengerId\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Analysis, visualization and data cleaning"},{"metadata":{},"cell_type":"markdown","source":"## What percentage of people survived based on age"},{"metadata":{"trusted":true},"cell_type":"code","source":"# What percentage of men and women survived?\nwomen = titanic.loc[titanic.Sex == 'female'][\"Survived\"]\nrate_women = sum(women)/len(women)\n\nprint(\"% of women who survived:\", round(rate_women * 100, 2))\n\nmen = titanic.loc[titanic.Sex == 'male'][\"Survived\"]\nrate_men = sum(men)/len(men)\n\nprint(\"% of men who survived:\", round(rate_men * 100, 2))\n\n# Better solution to the same thing above by Manav Sehgal:\ntitanic[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Clean and analyze age data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Round age data in Titanic dataset to the nearest integer.\n# Note: Numpy uses a specific type of rounding where for example: 1.5 rounds up to 2 and 10.5 rounds down to 10!\n\ntitanic[\"Age\"] = titanic[\"Age\"].apply(lambda x: np.rint(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create age brackets and count how many of those people survived:\n# Brackets: 0-5, 6-15, 16-21, 22-30, 31-40, 41-50, 51-60, 61-70, 71-80\n\nage_brackets = [[0,5], [6,15], [16,21], [22,30], [31,40], [41,50], [51,60], [61,70], [71,80]]\n\nfor bracket in age_brackets:\n    \n    # Divide the dataset to age brackets:\n    age_group = titanic.loc[(titanic.Age >= bracket[0]) & (titanic.Age <= bracket[1])]\n    print(\"There are:\", age_group[\"Survived\"].count(), \"people in the\", bracket ,\"age group.\") # \"Survived\" index is there just to get the number 891, i.e. the number of total rows. This should be done by some better code in the future.\n    \n    # Create a dataframe of people who survived from the age bracket\n    survived = age_group.loc[age_group[\"Survived\"] == 1].count()\n    \n    # Percentage of people who survived from the age bracket\n    survival_rate = survived[\"Survived\"] / age_group[\"Survived\"].count() # Divide the number of people who survived by the total number of rows in the age bracket for \"Survived\"\n    print(\"Survival for this age group is {}%\".format(round(survival_rate * 100, 2)))\n    #print(\"In this group the survival rate for females was:\")\n    #print(\"In this group the survival rate for males was:\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Transpose survival by age groups"},{"metadata":{"trusted":true},"cell_type":"code","source":"survived = 'survived'\nnot_survived = 'not survived'\nfig, axes = plt.subplots(nrows=1, ncols=2,figsize=(16, 8))\nwomen = titanic[titanic['Sex']=='female']\nmen = titanic[titanic['Sex']=='male']\nax = sns.histplot(women[women['Survived']==1].Age.dropna(), bins=40, label = survived, ax = axes[0], kde =False, color=\"green\")\nax = sns.histplot(women[women['Survived']==0].Age.dropna(), bins=40, label = not_survived, ax = axes[0], kde =False, color=\"red\")\nax.legend()\nax.set_title('Female')\nax = sns.histplot(men[men['Survived']==1].Age.dropna(), bins=40, label = survived, ax = axes[1], kde = False, color=\"green\")\nax = sns.histplot(men[men['Survived']==0].Age.dropna(), bins=40, label = not_survived, ax = axes[1], kde = False, color=\"red\")\nax.legend()\n_ = ax.set_title('Male');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Correlation matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a correlation matrix:\ncorr_matrix = titanic.corr()\nsns.heatmap(corr_matrix, annot=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dataset state so far"},{"metadata":{"trusted":true},"cell_type":"code","source":"combine[0].info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"combine[1].info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Fix missing Age, Embarked and Fare data, and transform them into integers"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's start with the Embarked data column\n\n# Load both datasets column for Embarked into one dataset and find out which port of embarkation is the most frequent\ncomplete_dataset = combine[0].append(combine[1])\ncomplete_dataset.info()\n\nfreq_port = titanic.Embarked.dropna().mode()[0] # find most frequent port of embarkating. Dropping NaN values is needed\nprint(40*\"_\")\nprint (\"Most frequent port is: {}\".format(freq_port))\n\ncombine[0][\"Embarked\"] = combine[0][\"Embarked\"].fillna(freq_port)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Change the \"Embarked\" data from string to integers. 0 = Southampton, 1 = Cherbourg, 2 = Queenstown\nfor i in range(len(combine)):\n    combine[i][\"Embarked\"] = combine[i][\"Embarked\"].map({'S': 0, 'C': 1, 'Q': 2}).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"combine[0].info() # Check if data type changed to integer and all missing values have been filled\ncombine[1].info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Change \"Sex\" data points to integers instead of strings. Female = 0, Male = 1\n\nfor i in range(len(combine)):\n    combine[i][\"Sex\"] = combine[i][\"Sex\"].apply(lambda x: 0 if x == \"female\" else 1) # We can use \"apply\" method with lambda or \"map\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fill missing age data\n\n# Get the age mean and standard deviation of the whole age dataset\nage_mean = complete_dataset[\"Age\"].mean() # Titanic ages mean\nage_std = complete_dataset[\"Age\"].std() # Standard deviation\n\nprint(\"The mean of the population is: {}\".format(age_mean))\nprint(\"The standard deviation of the titanic population age is: {}\".format(age_std))\n\nfor i in range(len(combine)):\n    # Get count of missing age data for each dataset\n    missing_age_values = combine[i]['Age'].isna().sum()\n    print(\"Number of missing age values is: {}\".format(missing_age_values))\n    \n    # Generate random ages in the first standard deviation from the mean\n    rand_age = np.random.randint(age_mean - age_std, age_mean + age_std, missing_age_values) # This is OK but not sure what \"discrete uniform\" distribution is - more research is needed.\n    print(\"The ages generated are: {}\".format(rand_age))\n    \n    # Add random ages to the missing values for age:\n    age_slice = combine[i][\"Age\"].copy()\n    age_slice[np.isnan(age_slice)] = rand_age # Get all NaN values from the age_slice series and replace them with our random ages\n    combine[i][\"Age\"] = age_slice # Assign our modified age_slice series back to the full dataset\n    combine[i][\"Age\"] = combine[i][\"Age\"].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fill missing value for fare\nfare_mean = complete_dataset[\"Fare\"].mean() # Titanic fare mean\nprint(\"The fare mean of the whole dataset is {}:\".format(fare_mean))\n\ncombine[1][\"Fare\"] = combine[1][\"Fare\"].fillna(fare_mean)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Drop \"Name\" data and distribute datasets back to original variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(len(combine)):\n    combine[i] = combine[i].drop([\"Name\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"titanic = combine[0]\ntitanic_test = combine[1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create machine learning models and predict survival"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = titanic.drop(\"Survived\", axis=1)\nY_train = titanic[\"Survived\"]\nX_test  = titanic_test.copy()\nX_train.shape, Y_train.shape, X_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Linear Regression\n\nlin_reg = LinearRegression()\nlin_reg.fit(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = lin_reg.predict(titanic_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(results)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Example of the linear regression model prediction:\n\nprint(\"Will the following passenger of the Titanic survive: \\n{}\".format(titanic_test.loc[0]))\nprint(\"The model predicts the following survival chance: \\n{}\".format(results[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Another example from the linear regression model prediction\n\nprint(\"Will the following passenger of the Titanic survive: \\n{}\".format(titanic_test.loc[22]))\nprint(\"The model predicts the following survival chance: \\n{}\".format(results[22]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This is experimental - it is too ambiguous for values around 0.4 to 0.6 - should be revisited\n# Round numbers to the nearest integer (either 0 or 1), 0 = dead, 1 = survived\n\nrounded_results = np.rint(results).astype(int) # numpy.rint method works for rounding elements of numpy arrays\n\nprint(rounded_results)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compare our rounded integers to the original floats from model prediction\n\ndef compare(float_number, integer_number):\n    for i in range(len(results)):\n        print(\"The float result number {} compares to: {}\".format(float_number[i], integer_number[i]))\n    \ncompare(results, rounded_results)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Count the number of survived and dead passengers\n\ndef count_dead_survived(rounded_result_array):\n    unique, counts = np.unique(rounded_result_array, return_counts=True)\n    for i in range(len(unique)):\n        print(\"The value of {} repeats this many times: {}\".format(unique[i], counts[i]))\n    \ncount_dead_survived(rounded_results)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create submission file\n\nsubmission_file = 'gender_submission.csv'\nsubmission = load_dataset(dataset_path, submission_file)\n\nsubmission['Survived'] = rounded_results\nsubmission.to_csv('submission_titanic.csv', index=False) # Save submission dataset to a csv file in the folder where the program is running\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}