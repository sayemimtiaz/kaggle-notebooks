{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport re\nfrom datetime import datetime\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly\nimport plotly.plotly as py\nimport plotly.graph_objs as go\nimport colorlover as cl\nplotly.offline.init_notebook_mode() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Load Data"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"twitter_files = os.listdir(\"../input/twitter\")\ntwitter_users_files = os.listdir(\"../input/twitter_users\")\npic_files = os.listdir(\"../input/pics\")\nmetadata = pd.read_csv(\"../input/candidates_info.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Define functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean(text):\n\n    text = re.sub(r'#\\S*', ' ', text)  \n    text = re.sub(r'http\\S*', ' ', text)\n    for ch in ['\\\\','`','*','_','{','}','[',']','(',')','>','+','-','.','!','\\'',\"\\”\",'\\\"', '\\“', \"\\’\", \"?\", \":\",\n               \"-\",\",\", \"//t\", \"&amp;\", \"/\", \"'\", \"'\", \"…\",\"-\", \"’\", \"\\—\", \"—\", \"–\", \"“\", \"”\"]:\n        if ch in text:\n            text = text.replace(ch,\" \")\n    \n    return(text)  \n\ndef pair_words(text):\n    text = text.replace(\"climate change\", \"climate_change\")\n    text = text.replace(\"health care\", \"health_care\")\n    text = text.replace(\"we need\", \"we_need\")\n    text = text.replace(\"we must\", \"we_must\")\n    text = text.replace(\"we can t\", \"we_can_t\")\n    text = text.replace(\"we can\", \"we_can\")\n    text = text.replace(\"we have\", \"we_have\")\n    text = text.replace(\"we are\", \"we_are\")\n    text = text.replace(\"we re\", \"we_are\")\n    text = text.replace(\"thank you\", \"thank_you\")\n    text = text.replace(\"united states\", \"united_states\")\n    text = text.replace(\"american people\", \"american_people\")\n    text = text.replace(\"town hall\", \"town_hall\")\n    text = text.replace(\"gun violence\", \"gun_violence\")\n    text = text.replace(\"join us\", \"join_us\")\n    text = text.replace(\"looking forward\", \"looking_forward\")\n    text = text.replace(\"white house\", \"white_house\")\n    text = text.replace(\"right now\", \"right_now\")\n    text = text.replace(\"supreme court\", \"supreme_court\")\n    text = text.replace(\"new york\", \"new_york\")\n    text = text.replace(\"middle class\", \"middle_class\")\n    text = text.replace(\"south bend\", \"south_bend\")\n    text = text.replace(\"don t\", \"don_t\")\n    text = text.replace(\"for all\", \"for_all\")\n    text = text.replace(\"we will\", \"we_will\")\n    text = text.replace(\"join me\", \"join_me\")\n    text = text.replace(\"national security\", \"national_security\")\n    text = text.replace(\"bill weld\", \"bill_weld\")\n    text = text.replace(\"de blasio\", \"de_blasio\")\n    \n    \n    return(text)    \n\n\ndef clean_tweet(tweet):\n    return ' '.join(pair_words(clean(tweet.lower())).split())\n\n\ndef print_table(header_values, content, colors):\n    data = go.Table(\n    \n      header = dict(\n        values = header_values ,\n        line = dict(color = \"rgb(70,130,180)\"),\n        fill = dict(color = \"rgb(70,130,180)\"),\n        align = 'center',\n        font = dict(color = 'black', size = 12)\n      ),\n      cells = dict(\n        values = content,\n        fill = colors,  \n        align = 'center',\n        font = dict(color = 'black', size = 9),\n        height = 40\n        ))\n\n    plotly.offline.iplot([data])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Clean Tweets, calculate stats for candidates and for the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"metadata[\"filename\"] = metadata[\"handle\"].apply(lambda x: x[1:])\nmetadata[\"age\"] = ((datetime.today() - pd.to_datetime(metadata[\"born\"])).dt.days/365).astype(int)\ndems = (metadata[metadata[\"party\"] == \"D\"]).copy()\n\ndic = dict()\nfor index, row in metadata.iterrows():\n    \n    dic[row[\"filename\"]] = pd.read_csv(\"../input/twitter/%s.csv\"%row[\"filename\"])\n    \n    df = dic[row[\"filename\"]]\n\n    df[\"clean tweet\"] = df['Text'].apply(clean_tweet)\n    \n    df = df[df[\"Language\"] == \"English\"]\n    metadata.loc[index,\"first tweet in dataset\"] = df[\"Created At\"].astype(\"datetime64\").min()\n    metadata.loc[index,\"number of tweets and retweets in dataset\"] = df.shape[0]\n    metadata.loc[index,\"number of tweets in dataset\"] = df[df[\"Tweet Type\"] == \"Tweet\"].shape[0]\n    metadata.loc[index,\"average likes all time\"] = int(df[df[\"Tweet Type\"] == \"Tweet\"][\"Favorites\"].mean()+0.5)\n    metadata.loc[index,\"average retweets all time\"] = int(df[df[\"Tweet Type\"] == \"Tweet\"][\"Retweets\"].mean()+0.5)\n    \n    df = df[df[\"Created At\"].astype(\"datetime64\").dt.year > 2018]\n    metadata.loc[index,\"number of tweets in 2019\"] = df[df[\"Tweet Type\"] == \"Tweet\"].shape[0]\n    metadata.loc[index,\"average likes in 2019\"] = int(df[df[\"Tweet Type\"] == \"Tweet\"][\"Favorites\"].mean()+0.5)\n    metadata.loc[index,\"average retweets in 2019\"] = int(df[df[\"Tweet Type\"] == \"Tweet\"][\"Retweets\"].mean()+0.5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Candidates Info"},{"metadata":{"trusted":true},"cell_type":"code","source":"columns =  [\"name\", \"sex\", \"born\", \"age\",\"announcement\", \"party\", \"city of residence\", \"state of residence\", \"children\"]\n\nheader_values = ['<b>%s</b>'%x for x in columns]\ncontent = metadata[columns].T\ncolors = dict()\nprint_table(header_values, content, colors)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Age of Democratic primaries candidates"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(dems[\"age\"], bins=6, kde=False, rug=True, color=\"#3498db\" )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Number of children for Democratic candidates"},{"metadata":{"trusted":true},"cell_type":"code","source":"children_counts = dems[\"children\"].value_counts()\nsns.barplot(children_counts.index, children_counts.values, color=\"#3498db\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Where are the Democratic Candidates coming from"},{"metadata":{"trusted":true},"cell_type":"code","source":"states_count = dems['state of residence'].value_counts()\n\ntext = []\nfor state in states_count.index:\n    text.append(\"<br>\".join(dems[dems['state of residence'] == state][\"name\"]))\n    \nscl = [\n    [0.0, 'rgb(174, 214, 241)'],\n    [0.5, 'rgb(52, 152, 219)'],\n    [1.0, 'rgb(33, 97, 140)'],\n]\n    \n\n    \n\ndata = [go.Choropleth(\n    colorscale = scl,\n    autocolorscale = False,\n    locations = states_count.index,\n    z = states_count,\n    locationmode = 'USA-states',\n    text = text,\n    marker = go.choropleth.Marker(\n        line = go.choropleth.marker.Line(\n            color = 'rgb(0,0,0)',\n            width = 1\n        )),\n    colorbar = go.choropleth.ColorBar(\n        title = \"\")\n)]\n\nlayout = go.Layout(\n    title = go.layout.Title(\n        text = 'Where are the Democratic Candidates coming from (mouseover for candidate names)'\n    ),\n    geo = go.layout.Geo(\n        scope = 'usa',\n        projection = go.layout.geo.Projection(type = 'albers usa'),\n        showlakes = True,\n        lakecolor = 'rgb(255, 255, 255)'),\n)\n\nfig = go.Figure(data = data, layout = layout)\nplotly.offline.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Twitter Engagement, likes and retweets\n\nAverage engagement barchart for each candidate. Since the candidacy announcements started in January of 2019, I charted the likes and retweets, before and after 2019."},{"metadata":{"trusted":true},"cell_type":"code","source":"sorted_data = metadata.sort_values(\"average likes in 2019\", ascending=False)\ncol = [\"name\", \"average likes all time\", \"average likes in 2019\",\n               \"average retweets all time\", \"average retweets in 2019\"]\ntidy = sorted_data[col].melt(id_vars='name')\n\n\nf, ax = plt.subplots(figsize=(10, 16))\nsns.barplot(x='value', y='name', hue='variable', data = tidy, orient = \"h\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Buzzwords for each candidate\n\nI cleaned the tweets of @user, #tags and links. Then I ignored, with a few exceptions, the most popular 100 words between all of the candidates. With what was left I ranked the most popular buzzwords for each candidate, together with it's relative frequency in percentage"},{"metadata":{"trusted":true},"cell_type":"code","source":"#pair_of_words_list =[]\nwords_list =[]\n\nfor index, row in metadata.iterrows():\n    df = dic[row[\"filename\"]]\n    df = df[df[\"Tweet Type\"] == \"Tweet\"]\n    df = df[df[\"Created At\"].astype(\"datetime64\").dt.year > 2018]\n    df = df[df[\"Language\"] == \"English\"]\n    words = ' '.join(df[\"clean tweet\"]).split(\" \")\n    words_list.extend(words)\n#    pair_of_words = []\n#    for i in range(len(words)-1):\n#        pair_of_words.append(words[i]+ \" \" + words[i+1])\n#    pair_of_words_list.extend(pair_of_words)\n#pair_of_words_list = pd.Series(pair_of_words_list)\n\ncommon_words = pd.Series(words_list).value_counts()[:100].index.tolist()\nadd_to_common = []\ncommon_words.extend(add_to_common)\nexceptions = [\"first\", \"right\", \"campaign\", \"work\", 'people','country','president','we_are','trump','great','we_need','thank_you','vote','fight','america','women','state','thanks','help','support','americans']\n\ncommon_words = [x for x in common_words if x not in exceptions]\n\nbuzz_words = pd.DataFrame()\nbuzz_value = pd.DataFrame()\n\nfor index, row in metadata.iterrows():\n\n    df = dic[row[\"filename\"]]\n    df = df[df[\"Created At\"].astype(\"datetime64\").dt.year > 2018]\n    df = df[df[\"Tweet Type\"] == \"Tweet\"]\n    df = df[df[\"Language\"] == \"English\"]\n    name = row[\"name\"]\n    words = pd.Series(' '.join(df[\"clean tweet\"]).split(\" \"))\n    words = (words[~words.isin(common_words)])\n    words_count = words.value_counts()*100/len(words)\n    if \"women\" in words_count.index:\n        metadata.loc[index,\"women mention\"] = int(words_count[\"women\"]*1000+0.5)/1000\n    else:\n        metadata.loc[index,\"women mention\"] = 0\n    if \"country\" in words_count.index:\n        metadata.loc[index,\"country mention\"] = int(words_count[\"country\"]*1000+0.5)/1000\n    else:\n        metadata.loc[index,\"country mention\"] = 0\n    buzz_words[row[\"name\"]] = [x[0] + \"<br>\" + str(int(x[1]*10+0.5)/10) for x in zip(words_count[:10].index, words_count[:10].values)]\n    buzz_value[row[\"name\"]] = words_count[:10].values\n\ncolors = cl.scales['9']['seq']['YlOrRd']\nbuzz_value = (buzz_value / buzz_value.max().max()*9-0.01).astype(int)\nbuzz_value = buzz_value.applymap(lambda x: colors[x])\n\nheader_values = ['<b>Name</b>']\ncontent = np.concatenate((np.expand_dims(buzz_words.columns,0), buzz_words))\ncolors = dict(color = np.concatenate((np.expand_dims([\"rgb(135,206,235)\"]* buzz_value.shape[1],0), buzz_value)))\nprint_table(header_values, content, colors)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Women\n\nFor some candidates it is very important to mention Women, but not for all. Added Country for reference."},{"metadata":{"trusted":true},"cell_type":"code","source":"sorted_data = metadata.sort_values(\"women mention\", ascending=False)\ncol = [\"name\", \"women mention\", \"country mention\"]\ntidy = sorted_data[col].melt(id_vars='name')\n\npalette = ['#e74c3c','#3498db']\n\nf, ax = plt.subplots(figsize=(8, 10))\nsns.barplot(x='value', y='name', hue='variable', palette=palette, data = tidy, orient = \"h\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}