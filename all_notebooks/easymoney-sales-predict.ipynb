{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Cargamos las funciones necesarias","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport calendar\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport squarify\nimport gc\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\n\nimport time\nimport datetime\nfrom datetime import datetime\nimport calendar\n\nfrom sklearn import model_selection # model assesment and model selection strategies\nfrom sklearn import metrics # model evaluation metrics\nfrom sklearn.tree import DecisionTreeClassifier, plot_tree\nfrom sklearn.tree import export_graphviz\nimport graphviz\nfrom sklearn.preprocessing import LabelEncoder,MinMaxScaler, StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import tree\nfrom sklearn.ensemble import RandomForestClassifier\nimport xgboost as xgb\n\n\nsns.set_style('white')\n\npd.options.display.float_format = '{:,.2f}'.format","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Definimos la funcion que nos hara las diferencias mensuales entre los productos EasyMoney","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def calcula_diferencias_mensuales (dataset, variable):\n    dataset[variable+'_pm']  = dataset.groupby('pk_cid')[variable].shift(1)\n    dataset['dif_'+variable] = dataset[variable] - dataset[variable+'_pm']\n    #dataset['dif_'+variable]  = dataset.groupby('pk_cid')[variable].diff()\n    dataset.drop(variable+'_pm',axis=1,inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Cargamos los tres dataset Necesarios","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"products_file = '/kaggle/input/easymoney/products_df.csv'\nproducts = pd.read_csv(products_file)\nproducts.drop('Unnamed: 0', axis=1, inplace=True)\n\nsd_file = '/kaggle/input/easymoney/sociodemographic_df.csv'\nsociodemographic = pd.read_csv(sd_file)\nsociodemographic.drop('Unnamed: 0',axis=1, inplace=True)\n\nca_file = '/kaggle/input/easymoney/commercial_activity_df.csv'\ncommercial = pd.read_csv(ca_file)\ncommercial.drop('Unnamed: 0',axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Los unimos de forma adecuada:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_= pd.merge(products,commercial, how=\"inner\",on=['pk_cid','pk_partition' ])\ndf=pd.merge(df_,sociodemographic, how=\"inner\",on=['pk_cid','pk_partition'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_sorted = pd.read_pickle('/kaggle/input/easymoney/EasyMoney_base.pkl',compression='zip')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Obtenemos las diferencias por meses:","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Ordenamos el Dataset y llamamos a la funci칩n calcula_diferencias_mensuales","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sorted = df.sort_values(by=['pk_cid', 'pk_partition'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del products, sociodemographic, commercial, df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"productos_easymoney=['loans',\n 'mortgage',\n 'funds',\n 'securities',\n 'long_term_deposit',\n 'em_account_pp',\n 'credit_card',\n 'payroll',\n 'pension_plan',\n 'payroll_account',\n 'emc_account',\n 'debit_card',\n 'em_account_p',\n 'em_acount']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for x in productos_easymoney:\n    calcula_diferencias_mensuales (df_sorted, x)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creamos campo es usuario nuevo:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# las ponemos a 2019-02-28\ndf_sorted.loc[ (df_sorted['entry_date']=='2019-02-29'), \n              'entry_date']='2019-02-28'\ndf_sorted.loc[ (df_sorted['entry_date']=='2015-02-29'), \n              'entry_date']='2015-02-28'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Vamos a ponerlos como fechas\nfor i in [\"pk_partition\",\"entry_date\"]:\n    df_sorted[i]=pd.to_datetime(df_sorted[i], format='%Y-%m-%d')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Vamos a restar las dos y lo ponemos en mesess:\ndf_sorted['mesesAlta']=(df_sorted['pk_partition']-df_sorted['entry_date'])/np.timedelta64(1,'M')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creamos el campo isNewClient\ndf_sorted['isNewClient']=((df_sorted['mesesAlta'] < 1) & \n                          (df_sorted['mesesAlta'] > 0)).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cuando es usuario nuevo todos los campos diff de ses mes estan a 0. Pero el puede haber contratado \n# algo en ese mismo mes y no estaria recogido en el campo diff. \n# Para las altas nuevas igualamos los dif con los contadores del producto\nfor x in productos_easymoney:\n    df_sorted.loc[ (df_sorted['isNewClient']==1) &\n                   (df_sorted['dif_'+x].isnull()==True), \n                  'dif_'+x]=df_sorted[x]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creamos campo es usuario activo:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sorted['isActive']=((df_sorted['loans']==0) &\n                        (df_sorted['mortgage']==0) &\n                        (df_sorted['funds']==0) &\n                        (df_sorted['securities']==0) &\n                        (df_sorted['long_term_deposit']==0) &\n                        (df_sorted['em_account_pp']==0) &\n                        (df_sorted['credit_card']==0) &\n                        (df_sorted['payroll']==0) &\n                        (df_sorted['pension_plan']==0) &\n                        (df_sorted['payroll_account']==0) &\n                        (df_sorted['emc_account']==0) &\n                        (df_sorted['debit_card']==0) &\n                        (df_sorted['em_account_p']==0) &\n                        (df_sorted['em_acount']==0)).astype(int)\n# pero nos queda al reves, hacemos la negacion\ndf_sorted['isActive']=(df_sorted['isActive']!=1).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_sorted.to_pickle('./dataset_base.pkl')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_sorted =pd.read_pickle('./dataset_base.pkl')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sorted.info(verbose=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Variable totalAssest","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Easymoney product list\nproductos_easymoney=['loans',\n 'mortgage',\n 'funds',\n 'securities',\n 'long_term_deposit',\n 'em_account_pp',\n 'credit_card',\n 'payroll',\n 'pension_plan',\n 'payroll_account',\n 'emc_account',\n 'debit_card',\n 'em_account_p',\n 'em_acount']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_assets=df_sorted.melt(id_vars=['pk_partition','pk_cid'],\n              value_vars=productos_easymoney,\n              var_name='Product',\n              value_name='Count')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_assets=df_assets.groupby(['pk_partition','pk_cid']).agg({'Count':np.sum}).reset_index(drop=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_assets.rename(columns={'Count':'totalAssets'}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df_sorted),len(df_assets)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sorted=pd.merge(df_sorted,df_assets, how=\"inner\",on=['pk_cid','pk_partition'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del df_assets","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Cargamos directamente el dataset anterior del pickle","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Leememos directamente todo lo anterior del pickle generado en el notebook: Easymoney_first_steps:\ndf_sorted = pd.read_pickle('/kaggle/input/easymoney/EasyMoney_base.pkl',compression='zip')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sorted.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sorted['payroll'].fillna(0,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sorted['pension_plan'].fillna(0,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sorted","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Para poder hacer predicciones para el mes 06/2019 del que no tenemos datos, vamos a cambiar de forma al dataset. Vamos a pasar todas las columnas dif_ con los incrementos mensuales a solo dos columnas \"producto\" y \"count\" mediante un melt del dataset. Dejamos em_acount y el debit_card para luego poder sacar mejor las variables LAG. Hacemos el melt solo para dos productos por limitaciones de memoria","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"vars_colums=['pk_cid','pk_partition',\n'entry_date',             \n'entry_channel',                 \n'active_customer',              \n'segment',                     \n'country_id',                  \n'region_code',                  \n'gender',                         \n'age',                            \n'deceased',              \n'salary',  \n'mesesAlta',                   \n'isNewClient',                    \n'isActive',\n'em_acount',\n'totalAssets']\n#'debit_card'] ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\ndelta_productos_easymoney=['dif_loans',\n 'dif_mortgage',\n 'dif_funds',\n 'dif_securities',\n 'dif_long_term_deposit',\n 'dif_em_account_pp',\n 'dif_credit_card',\n 'dif_payroll',\n 'dif_pension_plan',\n 'dif_payroll_account',\n 'dif_emc_account',\n 'dif_debit_card',\n 'dif_em_account_p',\n 'dif_em_acount']","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"delta_productos_easymoney=[\n 'dif_em_acount']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_altas=df_sorted.melt(id_vars=vars_colums,\n              value_vars=delta_productos_easymoney,\n              var_name='Product',\n              value_name='Count')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_altas.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del df_sorted","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Vamos a hacer el producto cartesiano para predecir\nSolo clientes activos(Con producto) el ultimo mes","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Vamos a tratar de hacer la prediccion de altas/bajas solo para los clientes activos en el ultimo mes del que tenemos datos y solo para el producto em_acount por limitaciones de memoria. A침adimos el mes 2019-06-28 a la lista de fechas para tener datos de ese mes","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"lista_fechas=['2018-01-28',\n'2018-02-28',\n'2018-03-28',\n'2018-04-28',\n'2018-05-28',\n'2018-06-28',\n'2018-07-28',\n'2018-08-28',\n'2018-09-28',\n'2018-10-28',\n'2018-11-28',\n'2018-12-28',\n'2019-01-28',\n'2019-02-28',\n'2019-03-28',\n'2019-04-28',\n'2019-05-28',             \n'2019-06-28']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Solo clientes activos el ultimo mes:\nlista_clientes=df_altas[(df_altas['isActive']==1) & \n                        (df_altas['pk_partition']=='2019-05-28')][\"pk_cid\"].unique().tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Solo uno por razones de memoria del Kernel\nlista_productos=['dif_em_acount']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hacemos el producto cartesiano:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cartesian_product = pd.MultiIndex.from_product([lista_fechas, \n                                                lista_clientes , \n                                                lista_productos], names = [\"pk_partition\", \"pk_cid\", \"Product\"])\nlen(cartesian_product)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cartesian_product","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_df = pd.DataFrame(index = cartesian_product).reset_index()\nfull_df.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Ponemos el campo pk_partition a tipo fecha\nfull_df['pk_partition']=pd.to_datetime(full_df['pk_partition'], format='%Y-%m-%d')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_df.groupby('pk_partition')['pk_cid'].size()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Vemos que esta OK, con 331588 clientes en cada mes. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Hace:mos el merge de los datos ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"full_df = pd.merge(full_df, df_altas, on = [\"pk_partition\", \"pk_cid\", \"Product\"], how = 'left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del df_altas","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_df.groupby('pk_partition')['pk_cid'].size()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Debido al producto cartesiano se nos generra muchos clientes inactivos en las fechas posteriores. Asi que procedo a borrar los clientes de \"relleno\" en los meses que no existian y que no nos aportan informacion. De hecho sin hacer este paso, el desempe침o del modelo es muy, muy malo. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Borramos todos los nulos que se generan por el producto cartesiano:\nfull_df.drop (full_df[ (full_df['pk_partition']!='2019-06-28') &\n                       (full_df['entry_date'].isnull()) ].index, axis=0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Comprobamos el borrado:\nfull_df.groupby('pk_partition')['pk_cid'].size()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(full_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Borramos los meses en que no pasa nada, para que el modleo aprenda emjor los cambios:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"full_df.drop(full_df[(full_df['isNewClient']==0) &\n                        (full_df['isActive']==0) & \n                       (full_df['em_acount']==0) &\n                       (full_df['Count']==0) ].index ,axis=0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Comprobamos que se han borado clientes en los meses antiguos","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"full_df.groupby('pk_partition')['pk_cid'].size()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_df[(full_df['pk_cid']==1231342)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_df.info(verbose=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"En el mes a predecir la informaci칩n relativa al cliente esta toda a NAN, como es logico. La repoblamos en la medida de  lo posible con los datos de meses anteriores:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"lista_actualizar=['entry_date',\n #'entry_channel',\n 'active_customer',\n #'segment',\n #'country_id',\n 'region_code',\n #'gender',\n 'age',\n #'deceased',\n 'salary']\n #'mesesAlta']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Rellenamos entry_date y los campos anteriores para el ultimo mes 06/2019:\nfor x in lista_actualizar:\n    print(x)\n    full_df.loc[(full_df['pk_partition']=='2019-06-28'),\n                x]=full_df[full_df['pk_partition']=='2019-06-28']['pk_cid'].map(full_df[['pk_cid',x]].groupby('pk_cid')[x].max())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_df[(full_df['pk_cid']==1231342) & (full_df['pk_partition']=='2019-06-28')]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hay que volver sobre este punto porque podemos poblar mas campos, con datos antiguos. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Solo hay nulos en el ultimo mes ,el mes a predecir:\nfull_df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#full_df.to_pickle('./full_df_antesFe.pkl')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#full_df =pd.read_pickle('./full_df_antesFe.pkl')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature engeniering","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Vamos a sacar variables LAG con los valores de los meses anteriores que son las que deberemos de usar de forma mayoritaria para entrenar al modelo","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Solo 5 meses hacia atras por razones de memoria del kernel\nfor x in [1,2,3,4,5]:\n    full_df['Count_shift_'+str(x)]=full_df.groupby(['pk_cid','Product'])['Count'].shift(x)\n    full_df['em_acount_shift_'+str(x)]=full_df.groupby(['pk_cid','Product'])['em_acount'].shift(x)\n    full_df['isActive_shift_'+str(x)]=full_df.groupby(['pk_cid','Product'])['isActive'].shift(x)\n    full_df['isNewClient_shift_'+str(x)]=full_df.groupby(['pk_cid','Product'])['isNewClient'].shift(x)\n    full_df['active_customer_shift_'+str(x)]=full_df.groupby(['pk_cid','Product'])['active_customer'].shift(x)\n    full_df['totalAssets_shift_'+str(x)]=full_df.groupby(['pk_cid','Product'])['totalAssets'].shift(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# La borro xq no aporta mucho y hacemos espacio:\nfull_df.drop('country_id',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_df.fillna(-999, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Sacos variables de la fecha del mes en curso","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"full_df[\"year\"] = full_df[\"pk_partition\"].dt.year\nfull_df[\"month\"] = full_df[\"pk_partition\"].dt.month","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_df[\"entry_date_year\"] = full_df[\"entry_date\"].dt.year\nfull_df[\"entry_date_month\"] = full_df[\"entry_date\"].dt.month","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hot encoding con el genero","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dummy_dataset = pd.get_dummies(full_df['gender'],prefix='gender')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dummy_dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_df = pd.concat([full_df,dummy_dataset],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del dummy_dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_df.isnull().sum().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#full_df.to_pickle('./full_df_antesFe.pkl')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Entrenar modelo","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Vamos a entrenar con todos los meses excepto los dos ultimos. Validamos con el penultimo y test en el ultimo. Todavia nos quedaria el del mes 06/2019 que seria del que ya realmente no tenemos datos. Quito los primeros meses del entrenamiento donde las variables lags son nulas (-999)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_index = sorted(list(full_df[\"pk_partition\"].unique()))[6:-3]\n\nvalida_index = [sorted(list(full_df[\"pk_partition\"].unique()))[-3]]\n\ntest_index = [sorted(list(full_df[\"pk_partition\"].unique()))[-2]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Borramos las variables que hacen referencia al mes en curso y solo entrenamos el modelo con las LAGS y con las propias del cliente","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"variables_borrar= ['Count' ,\n\"pk_partition\",\n'pk_cid',\n'Product',\n'segment',\n'gender', \n'deceased',\n'mesesAlta',\n'entry_date',\n#'country_id',\n'entry_channel',\n'em_acount',\n#'debit_card',\n'isNewClient',\n'isActive',\n'active_customer',\n'totalAssets']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = full_df[full_df[\"pk_partition\"].isin(train_index)].drop(variables_borrar, axis=1)\nY_train = full_df[full_df[\"pk_partition\"].isin(train_index)]['Count']\n\nX_valida = full_df[full_df[\"pk_partition\"].isin(valida_index)].drop(variables_borrar, axis=1)\nY_valida = full_df[full_df[\"pk_partition\"].isin(valida_index)]['Count']\n\nX_test = full_df[full_df[\"pk_partition\"].isin(test_index)].drop(variables_borrar, axis=1)\nY_test = full_df[full_df[\"pk_partition\"].isin(test_index)]['Count']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del full_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dt = DecisionTreeClassifier(max_depth=7,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dt.fit(X_train,Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score_train=dt.score(X_train, Y_train)\nscore_test=dt.score(X_valida, Y_valida)\nprint('Resultados para: Train: {} - Test: {}'.format(score_train,score_test))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Parece un Score muy bueno, pero si lo vemos en detalle es muy pobre","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_valida_pred = pd.DataFrame(dt.predict(X_valida), index=Y_valida.index, columns=['CountPrediction'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results_df = Y_valida.to_frame().join(y_valida_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results_df[results_df['Count']!=0].sample(40)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Vemos que el modelo parece cazar bien los 0 y los 1, pero no las bajas. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"results_df['error']=results_df['Count']-results_df['CountPrediction']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results_df['error'].hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results_df[results_df['Count']==0]['error'].hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results_df[results_df['Count']==-1]['error'].hist()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Caza muy pocas bajas!!!!!!!!!!!!!!!!!!!!! Solo unas pocas mas de 200","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"results_df[results_df['Count']==1]['error'].hist()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ![](http://)Las altas mucho mejor. Cazamos 3475 altas y fallamos 552. Lo que nos da un 84% de acierto en las altas. [](http://)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"results_df[results_df['Count']!=0]['error'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_features = pd.Series(dt.feature_importances_, index=X_train.columns).sort_values(ascending=False).head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(results_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results_df[results_df['Count']==0]['error'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"De los casos que son 0 (Se queda como esta), se aciertan 321419 y se fallan 1369","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"results_df[results_df['Count']==-1]['error'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Se los casos que son baja, se aciertan 272 y se fallan 1707","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"results_df[results_df['Count']==1]['error'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"De los que son altas de una nueva cuenta se aciertan 3379 y se fallan 552.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}