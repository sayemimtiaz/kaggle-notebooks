{"cells":[{"metadata":{},"cell_type":"markdown","source":"# TFIDF - BERT Question Answer Model\n\nOur submission answers all the task questions by utilising a pretrained BERT Question Answer model - [bert-large-uncased-whole-word-masking-finetuned-squad](https://huggingface.co/bert-large-uncased-whole-word-masking-finetuned-squad).\n\nThis work is a collaborative effort between [Nick Sorros](https://www.kaggle.com/nsorros), [Antonio Campello](https://www.kaggle.com/campello) and [Liz Gallagher](https://www.kaggle.com/lizgal).\n\n\n## Methodology\n\nFor each question in the task list we find the 5 more relevant 2020 papers to the question text using TFIDF vectors. Next we split up the text from these papers and apply the pretrained model to predict the answer to the question in each of the text chunks. We output the highest scoring answer found. Thus for each question we output the top answer found for each of the 5 most relevant papers.\n\n### Data Filters\n\n1. We only use papers which are from 2020.\n2. We only use English language papers. Languages were predicted by applying the [langdetect](https://pypi.org/project/langdetect/) language detection library to the abstract text in the metadata.\n3. We deduplicate any papers which had the same pmcid.\n\n### Evaluation Data\n\nWe have tagged 150 answers (5 from each question) as to whether we though they were the best answer or not the best answer from this paper, or whether the paper was not relevant to this question.\n\nUsing this data we can calculate 2 metrics of how well the model performs on the answers - the relevance and the good answer ratio:\n\nrelevance = `(best_answer + not_best_answer) / (best_answer + not_best_answer + not_relevant)`\n\nand\n\nGood answer ratio = `best_answer / (best_answer + not_best_answer)`\n\n\n## Results\n\n### Results version 1\n\nData: The data wasn't filtered.\n\nModel: Predictions were made by separating chunks of text by fullstops.\n\n| Task | Number of questions | Relevance | Good answer ratio | \n| --- | --- | --- | --- |\n| What is known about transmission, incubation, and environmental stability? | 5 | 65.22% | 40.00 |\n| What do we know about COVID-19 risk factors? | 8 | 85.00% | 52.94 |\n| What do we know about virus genetics, origin, and evolution? | 5 | 52.63% | 10.00 |\n| What do we know about vaccines and therapeutics? | 2 | 70.00% | 57.14 |\n| What do we know about non-pharmaceutical interventions? | 2 | 85.71% | 66.67 |\n| What has been published about medical care? | 4 | 66.67% | 30.00 |\n| What do we know about diagnostics and surveillance? | 1 | 75.00% | 100.00 |\n| Other interesting questions | 3 | 18.18% | 0.00 |\n\n\n"},{"metadata":{},"cell_type":"markdown","source":"%%bash\npip install -q transformers**"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install spacy==2.2.1\n!pip install scispacy\n!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.4/en_core_sci_sm-0.2.4.tar.gz\n!pip install langdetect","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load all the 2020 publication texts\n\n- For any JSON file found in the data location collate all the body text found\n- Create a dictionary of the paper ID and its body text\n- Only include publications in the data which are from 2020 (this has to be done by linking to the metadata.csv file)\n- Create key dictionaries of the index to the paper ID (index2paperID), and the index to publication file pathway (index2paperPath)"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom langdetect import detect\n\nimport json\nimport os\n\nmeta_path = '/kaggle/input/CORD-19-research-challenge/metadata.csv'\n\ndef get_data_texts():\n    \n    def get_abstract_language(abstract):\n        try:\n            language = detect(abstract)\n        except:\n            language = None\n        return language\n\n    # Create dict of paper_id and publication year\n    meta_data = pd.read_csv(meta_path, low_memory=True)\n    paperID2year = {}\n    paperID2lang = {}\n    sha2pmcid = {}\n    for _, meta_row in meta_data.iterrows():\n        # Only save information for meta data with parsed text\n        if meta_row['has_pmc_xml_parse'] or meta_row['has_pdf_parse']:\n            # The paper ID will either be the pmcid or sha\n            if pd.notnull(meta_row['pmcid']):\n                paperID2year[meta_row['pmcid']] = meta_row['publish_time']\n                if pd.notnull(meta_row['abstract']):\n                    lang = get_abstract_language(meta_row['abstract'])\n                    if lang:\n                        paperID2lang[meta_row['pmcid']] = lang\n            # There can be muliple sha IDs in the rows\n            if pd.notnull(meta_row['sha']):\n                lang = None\n                if pd.notnull(meta_row['abstract']):\n                    lang = get_abstract_language(meta_row['abstract'])\n                paper_ids = meta_row['sha'].split('; ')\n                for paper_id in paper_ids:\n                    if pd.notnull(meta_row['pmcid']):\n                        sha2pmcid[paper_id] = meta_row['pmcid']\n                    paperID2year[paper_id] = meta_row['publish_time']\n                    if lang:\n                        paperID2lang[paper_id] = lang\n                                \n    data_text = {}\n    index2paperID = {}\n    index2paperPath = {}\n    paperpmcids = set()\n    i = 0\n    for dirname, _, filenames in os.walk('/kaggle/input/CORD-19-research-challenge'):\n        for filename in filenames:\n            paper_path = os.path.join(dirname, filename)\n            if paper_path[-4:] != 'json':\n                continue\n            with open(paper_path) as json_file:\n                article_data = json.load(json_file)\n                # Don't include duplicates (defined from pmcid - if given) in data_text\n                if article_data['paper_id'][0:3] == 'PMC':\n                    pmcid = article_data['paper_id']\n                else:\n                    pmcid = sha2pmcid.get(article_data['paper_id'], None)\n                if (not pmcid) or (pmcid not in paperpmcids):\n                    if pmcid:\n                        paperpmcids.add(pmcid)\n                    paper_date = paperID2year.get(article_data['paper_id'], None)\n                    paper_language = paperID2lang.get(article_data['paper_id'], None)\n                    if paper_date:\n                        # Only include papers from 2020 and papers in English (or no language given)\n                        if (paper_date[0:4] == '2020') and (paper_language == 'en' or not paper_language):\n                            data_text[article_data['paper_id']] = ' '.join([d['text'] for d in article_data['body_text']])\n                            index2paperID[i] = article_data['paper_id']\n                            index2paperPath[i] = paper_path\n                            i += 1\n\n    return data_text, index2paperID, index2paperPath\n\n\ndata_text, index2paperID, index2paperPath = get_data_texts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('/kaggle/working/data_text.jsonl', \"w\") as f:\n    json.dump(data_text, f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('/kaggle/working/index2paperID.jsonl', \"w\") as f:\n    json.dump(index2paperID, f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('/kaggle/working/index2paperPath.jsonl', \"w\") as f:\n    json.dump(index2paperPath, f)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create the QuestionCovid class\n```\nArguments:\n    TOKENIZER: A pretrained BertTokenizer\n    MODEL: A pretrained BertForQuestionAnswering model\n    index2paperID: A dictionary of indexes to the paper id as found from get_data_texts\n    index2paperPath: A dictionary of indexes to the paper pathway as found from get_data_texts\n    data_text: A dictionary of paper ids and the collated body text from them\n    question: A single question to ask the papers\n    \nAttributes:\n    fit: Vectorize the body text from data_text using TFIDF\n    predict: Load the text of the top 5 closest TFIDF vectors of the papers to the question.\n        Split the texts for each of these papers up into chunks of 3 sentences, and predict the\n        answers to the question for each chunk of text using the pretrained BERT QA model.\n        Output the answer with the highest score for each of the 5 closest papers.\n        For each of the 5 closest papers using TFIDF, 'predict' yields:\n        1. the paper id,\n        2. the best answer,\n        3. the BERT QA score,\n        4. the text chunk the answer came from,\n        5. and the cosine similarity between the question and the paper TFIDF vectors. \n```\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from transformers import BertTokenizer, BertForQuestionAnswering\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport torch\nimport spacy\n\nfrom wasabi import msg\nimport time\n\nclass QuestionCovid:\n\n    def __init__(\n            self,\n            TOKENIZER,\n            MODEL,\n            index2paperID,\n            index2paperPath\n            ):\n        self.TOKENIZER = TOKENIZER\n        self.MODEL = MODEL\n        self.index2paperID = index2paperID\n        self.index2paperPath = index2paperPath\n        self.scispacy = spacy.load(\"en_core_sci_sm\")\n\n    def fit(self, data_text):\n\n        self.TFIDF_VECTORIZER = TfidfVectorizer()\n        with msg.loading(\"   Fitting TFIDF\"):\n            start = time.time()\n            self.TFIDF_VECTORIZER.fit(data_text.values())\n        msg.good(\"   TFIDF fitted - Took {:.2f}s\".format(time.time()-start))\n        with msg.loading(\"   Creating Articles matrix\"):\n            start = time.time()\n            self.ARTICLES_MATRIX = self.TFIDF_VECTORIZER.transform(data_text.values())\n        msg.good(\"   Article matrix created - Took {:.2f}s\".format(time.time()-start))\n\n    def get_answer(self, text, question):\n\n        input_text = \"[CLS] \" + question + \" [SEP] \" + text + \" [SEP]\"\n        input_ids = self.TOKENIZER.encode(input_text)\n        token_type_ids = [0 if i <= input_ids.index(102) else 1 for i in range(len(input_ids))]\n        start_scores, end_scores = self.MODEL(torch.tensor([input_ids]), token_type_ids=torch.tensor([token_type_ids]))\n        all_tokens = self.TOKENIZER.convert_ids_to_tokens(input_ids)\n        answer = ' '.join(all_tokens[torch.argmax(start_scores) : torch.argmax(end_scores)+1])\n        score = round(start_scores.max().item(), 2)\n\n        return answer, score\n\n    def predict(self, question):\n\n        query = self.TFIDF_VECTORIZER.transform([question + ' covid'])\n        best_matches = sorted([(i,c) for i, c in enumerate(cosine_similarity(query, self.ARTICLES_MATRIX).ravel())], key=lambda x: x[1], reverse=True)\n\n        for i, tfidf_score in best_matches[:5]:\n            best_score = 0 # if score is negative, i consider the answer wrong\n            best_answer = \"No answer\"\n            best_text = \"No snippet\"\n            \n            paper_path = self.index2paperPath[i]\n            with open(paper_path) as json_file:\n                article_data = json.load(json_file)\n                text = ' '.join([d['text'] for d in article_data['body_text']])\n            sentences = [s.text for s in self.scispacy(text).sents]\n\n            def yield_subtext(sentences):\n                subtext = ''\n                for i in range(len(sentences)):\n                    sent = sentences[i]\n                    if len(sent) + len(subtext) > 400:\n                        yield subtext\n                        subtext = sent\n                    else:\n                        subtext += sent\n            #sentences_grouped = ['.'.join(sentences[i:i+n]) for i in range(0, len(sentences), n)]\n            for subtext in yield_subtext(sentences):\n                answer, score = self.get_answer(subtext, question)\n                if score > best_score:\n                    best_score = score\n                    best_answer = answer\n                    best_text = subtext\n            yield (self.index2paperID[i], best_answer, best_score, best_text, tfidf_score)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load the BERT model and fit the QuestionCovid model with the publication texts"},{"metadata":{"trusted":true},"cell_type":"code","source":"TOKENIZER = BertTokenizer.from_pretrained('bert-base-uncased')\nMODEL = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"covid_q = QuestionCovid(TOKENIZER, MODEL, index2paperID, index2paperPath)\ncovid_q.fit(data_text)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Add each question from the Kaggle competition tasks list\nhttps://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge/tasks"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Credit to https://www.kaggle.com/jonathanbesomi\nchallenge_tasks = [\n  {\n      \"task\": \"What is known about transmission, incubation, and environmental stability?\",\n      \"questions\": [\n          \"Is the virus transmitted by aerosol, droplets, food, close contact, fecal matter, or water?\",\n          \"How long is the incubation period for the virus?\",\n          \"Can the virus be transmitted asymptomatically or during the incubation period?\",\n          \"How does weather, heat, and humidity affect the tramsmission of 2019-nCoV?\",\n          \"How long can the 2019-nCoV virus remain viable on common surfaces?\"\n      ]\n  },\n  {\n      \"task\": \"What do we know about COVID-19 risk factors?\",\n      \"questions\": [\n          \"What risk factors contribute to the severity of 2019-nCoV?\",\n          \"How does hypertension affect patients?\",\n          \"How does heart disease affect patients?\",\n          \"How does copd affect patients?\",\n          \"How does smoking affect patients?\",\n          \"How does pregnancy affect patients?\",\n          \"What is the fatality rate of 2019-nCoV?\",\n          \"What public health policies prevent or control the spread of 2019-nCoV?\"\n      ]\n  },\n  {\n      \"task\": \"What do we know about virus genetics, origin, and evolution?\",\n      \"questions\": [\n          \"Can animals transmit 2019-nCoV?\",\n          \"What animal did 2019-nCoV come from?\",\n          \"What real-time genomic tracking tools exist?\",\n          \"What geographic variations are there in the genome of 2019-nCoV?\",\n          \"What effors are being done in asia to prevent further outbreaks?\"\n      ]\n  },\n  {\n      \"task\": \"What do we know about vaccines and therapeutics?\",\n      \"questions\": [\n          \"What drugs or therapies are being investigated?\",\n          \"Are anti-inflammatory drugs recommended?\"\n      ]\n  },\n  {\n      \"task\": \"What do we know about non-pharmaceutical interventions?\",\n      \"questions\": [\n          \"Which non-pharmaceutical interventions limit tramsission?\",\n          \"What are most important barriers to compliance?\"\n      ]\n  },\n  {\n      \"task\": \"What has been published about medical care?\",\n      \"questions\": [\n          \"How does extracorporeal membrane oxygenation affect 2019-nCoV patients?\",\n          \"What telemedicine and cybercare methods are most effective?\",\n          \"How is artificial intelligence being used in real time health delivery?\",\n          \"What adjunctive or supportive methods can help patients?\"\n      ]\n  },\n  {\n      \"task\": \"What do we know about diagnostics and surveillance?\",\n      \"questions\": [\n          \"What diagnostic tests (tools) exist or are being developed to detect 2019-nCoV?\"\n      ]\n  },\n  {\n      \"task\": \"Other interesting questions\",\n      \"questions\": [\n          \"What is the immune system response to 2019-nCoV?\",\n          \"Can personal protective equipment prevent the transmission of 2019-nCoV?\",\n          \"Can 2019-nCoV infect patients a second time?\"\n      ]\n  }\n]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predict the answer to one question using the most relevant paper"},{"metadata":{"trusted":true},"cell_type":"code","source":"question = \"How long is the incubation period for the virus?\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, (paper_id, answer, score, snippet, tfidf_score) in enumerate(covid_q.predict(question)):\n    print(f\"Answer {i}: {answer}\")\n    print(f\"Text segment: {snippet}\")\n    print(f\"Paper id: {paper_id}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predict and save the answers to all the task questions\nThis takes up to an hour and will save the answers in '/kaggle/working/answers.jsonl'."},{"metadata":{"trusted":true},"cell_type":"code","source":"# possibly better to write as csv\nwith open('/kaggle/working/answers.jsonl', \"w\") as f:\n    for task_id, task in enumerate(challenge_tasks):\n        task_question = task['task']\n        msg.text(f\"Task {task_id}: {task_question}\")\n\n        questions = task['questions']\n        for question_id, question in enumerate(questions):\n            with msg.loading(f\"Answering question: {question}\"):\n                start = time.time()\n                for i, (paper_id, answer, score, snippet, tfidf_score) in enumerate(covid_q.predict(question)):\n                    chunk = json.dumps({\n                        'task_id': task_id,\n                        'task': task_question,\n                        'question_id': question_id,\n                        'question': question,\n                        'paper_id': paper_id,\n                        'answer': answer,\n                        'snippet': snippet,\n                        'bert_score': score,\n                        'tfidf_score': tfidf_score\n                    })\n                    f.write(chunk + '\\n')\n                    msg.text(\"\\n\")\n                    msg.text(f\"Answer {i}: {answer}\")\n            time_elapsed = time.time()-start\n            msg.good(f\"Question {question_id} answered - Took {time_elapsed}s\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}