{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Mexico COVID-19 clinical data\n<p>This daset contains the results of real-time PCR testing for COVID-19 from the [General Directorate of Epidemiology](https://www.gob.mx/salud/documentos/datos-abiertos-152127) (more details [here](href=\"https://datos.gob.mx/busca/dataset/informacion-referente-a-casos-covid-19-en-mexico/resource/e8c7079c-dc2a-4b6e-8035-08042ed37165)).The data was gathered using a \"sentinel model\" that samples 10% of the patients that present a viral respiratory diagnosis to test for COVID-19, and consists of data reported by 475 viral respiratory disease monitoring units (hospitals) named USMER (Unidades Monitoras de Enfermedad Respiratoria Viral) throughout the country in the entire health sector (IMSS, ISSSTE, SEDENA, SEMAR, and others).</p>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 1. Load the data üìà","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport warnings\n\npd.set_option('display.max_columns', None) # shows all columns\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read file into memory\n\n# It's best to try first with the lastest remote file from repository\ndata = pd.read_csv('https://raw.githubusercontent.com/marianarf/covid19_mexico_analysis/master/mexico_covid19.csv')\n\n# Local data\n# data = pd.read_csv('../input/mexico-covid19-clinical-data/mexico_covid19.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show first 5 rows\ndata.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Quick glance at the data\ndata.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. Features üñºÔ∏è\n<p>We are aiming to predict whether a patient with pending COVID-19 results will get a positive or a negative result. We will use columns already factored with numeric values and will remove variables not relevant to the analysis.<p>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make a copy of the data frame so that we don't override the original dataframe\ndf = data.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Take a glance at the variables\ndf.keys()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check dtypes for each column\n# df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exclude features as described above\ndf = df[df.columns[~df.columns.isin(\n    ['id', 'ID_REGISTRO',\n     'FECHA_ARCHIVO', 'FECHA_ACTUALIZACION', 'FECHA_DEF', 'FECHA_INGRESO','FECHA_SINTOMAS',\n     'ABR_ENT', 'ENTIDAD', 'MIGRANTE', 'NACIONALIDAD', 'ORIGEN', 'PAIS_NACIONALIDAD', 'PAIS_ORIGEN',\n     'INTUBADO', 'UCI'] # remove features that are only available while hospitalized\n)]]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Show the number of missing (NAN, NaN, na) data for each column\n# data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Various ways to check for NaN, NA and NULL\n# df.isnull()\n# df.isnull().sum()\n# df.isnull().values.any()\n# df.isnull().values.sum()\n# df.isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# There are a few rows without the city code attribute - so let's remove them\ndf = df[~df.isnull().any(axis=1)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We have data that contains either negative or positive results (i.e, excludes tests that are in process)\nprint(df['RESULTADO'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The original data has different codes, but let's follow convention and refactor them (0=negative, 1=positive)\ndf['RESULTADO'] = df['RESULTADO'].astype(str).str.replace('2','0') # negative\ndf['RESULTADO'] = df['RESULTADO'].astype(str).str.replace('1','1') # positive","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert whole df to numeric\ndf = df.apply(pd.to_numeric, errors='ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We want every remaining column to be of numeric type\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3. Model ü§ñ\n<p>We are aiming to predict whether a patient with pending COVID-19 results will get a positive or a negative result:</p>\n\n<ul>\n<li>As laboratory results are processed, each pending patient record leaves a time window when it's uncertain whether a result will return positive or negative (so we can validate almost daily if predictions are wrong or right, as laboratory results are reported in the new reports).</li>\n<li>Also, this could help predict for similar symptoms e.g. from a survey or an app that checks for similar data (ideally, containing most of the parameters that can be assessed without coming into the hospital, like e.g. age of the patient)</li>\n</ul>\n\n<p>The value of the lab result comes from a RT-PCR, and is stored in <code>RESULTADO</code>, where <code>0 = NEGATIVE</code> and <code>1 = POSITIVE</code>. Let's rename this to <code>target</code> so that it's more convenient to work with.</p>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Rename target column as 'target' for clarity\ndf.rename(\n    columns={'RESULTADO': 'target'},\n    inplace=True\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove target variable to move it to the first position of dataframe\ncol_name = 'target'\nfirst_col = df.pop(col_name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now we can use Pandas insert() function and insert the opped column into first position of the dataframe\n# The first argument of insert() function is the location we want to insert, here it is 0\ndf.insert(0, col_name, first_col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now response variable is at the start of the data frame\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's see how many observations and features we have\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.1 Explore features üî¨","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 3.1.1 Correlation Matrix üìê","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns \nimport matplotlib.pyplot as plt\n\ncorrmat = df.corr() \n  \nf, ax = plt.subplots(figsize =(9, 8)) \nsns.heatmap(corrmat, ax=ax, cmap='viridis', linewidths = 0.1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### 3.1.2 Target incidence üéØ\n<p>Target incidence is the number of cases of each individual target value in the data. It represents the proportion of categorical variable in a target column. Target incidence gives us an idea of how balanced (imbalanced) is our data.</p>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print target incidence proportions and round to 3 decimal places\ndf.target.value_counts(normalize=True).round(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize = (15,6))\n\nplt.rcParams['axes.titlesize'] = 20\nplt.rcParams['axes.labelsize'] = 16\nplt.rcParams['axes.titlesize'] = 16\n\nfive_thirty_eight = [\n    '#30a2da',\n    '#fc4f30',\n    '#e5ae38',\n    '#6d904f',\n    '#8b8b8b',\n]\n\nsns.set_palette(sns.color_palette(five_thirty_eight))\n\ntotal = float(len(data))\nresults = ['Negative', 'Positive']  \nax = sns.countplot(x='target', data=df)\nax.set_xticklabels(results)\n\n# add percentages above each bar\nfor p in ax.patches:\n    height = p.get_height()\n    ax.text(p.get_x() + p.get_width()/2.,\n            p.get_height(),\n            '{:1.2f}'.format(height/total),\n            ha='center')\n    \nplt.title('Incidence of COVID-19 in Mexico', fontsize=20)\nplt.xlabel('Result')\nplt.ylabel('Patients')\n\nsns.set(style='ticks')\nsns.despine()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.1.3 Age distribution of cases for each category üïµÔ∏è","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\ndf_positive = df.loc[df['target'] == 0]\ndf_negative = df.loc[df['target'] == 1]\n\nfive_thirty_eight = [\n    '#30a2da',\n    '#fc4f30',\n    '#e5ae38',\n    '#6d904f',\n    '#8b8b8b',\n]\n\nplt.figure(figsize = (15,6))\nplt.rcParams['axes.titlesize'] = 20\nplt.rcParams['axes.labelsize'] = 16\nplt.rcParams['axes.titlesize'] = 16\n\nsns.set_palette(sns.color_palette(five_thirty_eight))\n\nsns.distplot(df_positive['EDAD'])\nsns.distplot(df_negative['EDAD'])\n\nsns.set(style='ticks')\nsns.despine()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.1.4 Class imbalance for each feature üìä","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nfive_thirty_eight = [\n    '#30a2da',\n    '#fc4f30',\n    '#e5ae38',\n    '#6d904f',\n    '#8b8b8b',\n]\n    \nvar = df.columns.values\n\ni = 0\nt0 = df.loc[df['target'] == 0]\nt1 = df.loc[df['target'] == 1]\n\nplt.figure()\nfig, ax = plt.subplots(8,4,figsize=(16,28))\nplt.title('Class imbalance for features in data')\n\nfor feature in var:\n    i += 1\n    plt.subplot(8,4,i)\n    sns.kdeplot(t0[feature], bw=0.5, label=\"Negative = 0\")\n    sns.kdeplot(t1[feature], bw=0.5, label=\"Positive = 1\")\n    sns.set_palette(sns.color_palette(five_thirty_eight))\n    sns.set(style='ticks')\n    sns.despine()\n    plt.xlabel(feature, fontsize=12)\n    locs, labels = plt.xticks()\n    plt.tick_params(axis='both', which='major', labelsize=12)\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###¬†3.2 Binary classification\n<p>We want to predict whether or not a person with a certain clinical profile may result COVID-19 positive when tested for a real-time PCR. The model for this is a binary classifier, meaning that there are only 2 possible outcomes:</p>\n\n<ul>\n    <li><code>0</code> - the lab result is COVID-19 negative</li>\n    <li><code>1</code> - the lab result is COVID-19 positive</li>\n</ul>\n\n<p>1. As laboratory results are processed, each pending patient record leaves a time window when it's uncertain whether a result will return positive or negative (so we can validate almost daily if predictions are wrong or right, as laboratory results are reported in the new reports).</p>\n\n<p>2. Also, this could help predict for similar symptoms e.g. from a survey or an app that checks for similar data (ideally, containing most of the parameters that can be assessed without coming into the hospital, like e.g. age of the patient).</p>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 3.2.1 Split the dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX = df.drop('target',axis=1)\ny = df.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.2.2 Models and hyperparameters\n<p>This section is adapted from [this post by Gabriel Naya](https://towardsdatascience.com/available-hyperparameter-optimization-techniques-dc60fb836264) on hyperparameter optimization with the following optimization techniques:<p>\n    \n<ul>\n    <li>Default hyperparameters</li>\n    <li>Sklearn GridSearchCV</li>\n    <li>Sklearn RandomizedSearchCV</li>\n    <li>Hyperopt for Python</li>\n</ul>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# First create dataframe to store the results\ncols = ['Case','RndForest','LogReg','LGB']\nresult_tbl = pd.DataFrame(columns=cols)\nresult_tbl.set_index('Case',inplace=True)\nresult_tbl.loc['Standard'] = [0,0,0]\nresult_tbl.loc['GridSearch'] = [0,0,0]\nresult_tbl.loc['RandomSearch'] = [0,0,0]\nresult_tbl.loc['Hyperopt'] = [0,0,0]\nresult_tbl.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nimport lightgbm as lgb\n\n# Instantiate models with default parameters\n\nrf    = RandomForestClassifier(n_estimators=10)\nlr    =  LogisticRegression(solver='liblinear')\nlgg   = lgb.LGBMClassifier()\nmodels = [rf,lr,lgg]\n\ncol = 0\n\nfor model in models:\n    model.fit(X_train,y_train.values.ravel())\n    result_tbl.iloc[0,col] = model.score(X_test,y_test)\n    col += 1\nresult_tbl.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Parameters for GridSearchCV\n\n# Random Forest\nn_estimators = [10, 100, 1000,10000]\nmax_features = ['sqrt', 'log2']\nrf_grid = dict(n_estimators=n_estimators, max_features=max_features)\n\n# Logistic Regrresion\nsolvers = ['newton-cg', 'lbfgs', 'liblinear']\npenalty = ['l2']\nc_values = [100, 10, 1.0, 0.1, 0.01]\nlr_grid = dict(solver=solvers, penalty=penalty, C=c_values)\n\n# LGB\nscale_pos_weight = (161217/103095) # change this to not-manual input -_- pls\nboosting_type = ['gbdt', 'goss', 'dart']\nnum_leaves = [30,50,100,150] #list(range(30, 150)),\nlearning_rate = list(np.logspace(np.log(0.005), np.log(0.2), base = np.exp(1), num = 10)) #1000\nlgg_grid = dict(scale_pos_weight=scale_pos_weight, boosting_type=boosting_type, num_leaves=num_leaves, learning_rate=learning_rate)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RepeatedStratifiedKFold\n\n# This configuration depends on one's computing capacity and scope of time.\n# The parameters in the previous cell are only some parameters available for the models.\n# I haven't figured how to use GPU for the following optimization techniques, so I will use LightXGB.\n\nmodels = [rf,lr,lgg]\ngrids = [rf_grid,lr_grid,lgg_grid]\n\ncol = 0\nfor ind in range(0,len(models)):\n    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, \n                                 random_state=1)\n    grid_search = GridSearchCV(estimator=models[col], \n                  param_grid=grids[col], n_jobs=-1, cv=cv,  \n                  scoring='accuracy',error_score=0)\n    grid_clf_acc = grid_search.fit(X_train, y_train)\n    result_tbl.iloc[1,col] = grid_clf_acc.score(X_test,y_test)\n    col += 1\nresult_tbl.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import randint as sp_randint\nfrom sklearn.model_selection import RandomizedSearchCV\n\n# This configuration depends on one's computing capacity and scope of time.\n# The parameters in the previous cell are only some parameters available for the models.\n# I haven't figured how to use GPU for the following optimization techniques, so I will use LightXGB.\n\nmodels = [rf,lr,lgg]\ngrids = [rf_grid,lr_grid,lgg_grid]\n\ncol = 0\nfor ind in range(0,len(models)):\n    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, \n                                 random_state=1)\n    n_iter_search = 3\n    random_search = RandomizedSearchCV(models[col],\n    param_distributions=grids[col],n_iter=n_iter_search, cv=cv)\n    random_search.fit(X_train,y_train)\n    result_tbl.iloc[2,col] = random_search.score(X_test, y_test)\n    col += 1\nresult_tbl.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4. LightXGB model\n<p>Since I couldn't use the GPU and it will take a long time to perform the hyperparameter optimization, I opted to use LightXGB with the base parameters. Imo there's no much use in performing these steps before having a good baseline model with the correct feature engineering but I will leave the code if someone wants to try it out with different algorithms!</p>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 4.1 Train","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb\n\n# Instantiate model\n\nlgg = lgb.LGBMClassifier()\nlgg.fit(X_train,y_train.values.ravel())\nprint(lgg.score(X_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predict the results\ny_hat = lgg.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4.2 Performance metrics","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\n# View accuracy\naccuracy = accuracy_score(y_hat, y_test)\nprint('LightGBM Model accuracy score: {0:0.4f}'.format(accuracy_score(y_test, y_hat)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compare train and test set accuracy\ny_hat_train = lgg.predict(X_train)\nprint('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_hat_train)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check for overfitting\nprint('Training set score: {:.4f}'.format(lgg.score(X_train, y_train)))\nprint('Test set score: {:.4f}'.format(lgg.score(X_test, y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\n\n# Classification metrics\nprint(classification_report(y_test, y_hat))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\n# Confussion matrix\ncm = confusion_matrix(y_test, y_hat)\nprint('Confusion matrix\\n\\n', cm)\nprint('\\nTrue Positives(TP) = ', cm[0,0])\nprint('\\nTrue Negatives(TN) = ', cm[1,1])\nprint('\\nFalse Positives(FP) = ', cm[0,1])\nprint('\\nFalse Negatives(FN) = ', cm[1,0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4.3 Too many false negatives! ü§î\n<p>Since this model is meant to build for diagnostic, it's very dangerous to have that many false negatives. Let's explore ROC metrics to have a better understanding of what's going on.</p>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate probability again\ny_hat = lgg.predict_proba(X_test) # Use this instead of `predict()`so that we can retrieve probabilities\npos_probs = y_hat[:,1] # Retrieve just the probabilities for the positive class","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4.3.1 ROC Curve","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve\n\n# Plot No Skill ROC Curve\nplt.plot([0, 1], [0, 1], linestyle='--', label='No Skill')\n\n# Calculate ROC Curve for model\nfpr, tpr, _ = roc_curve(y_test, pos_probs)\n\n# Plot model ROC Curve\nplt.plot(fpr, tpr, marker='.', label='LightGBM')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###¬†4.3.2 ROC AUC Curve","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.dummy import DummyClassifier\nfrom sklearn.metrics import roc_auc_score\n\n# Create No Skill classifier\ndummy_model = DummyClassifier(strategy='stratified')\ndummy_model.fit(X_train, y_train)\ny_hat_dummy = dummy_model.predict_proba(X_test)\npos_probs_dummy = y_hat_dummy[:, 1]\n\n# Calculate ROC AUC for No Skill\nroc_auc = roc_auc_score(y_test, pos_probs_dummy)\nprint('No Skill ROC AUC %.3f' % roc_auc)\n\n# Calculate ROC AUC for our model\nroc_auc = roc_auc_score(y_test, pos_probs)\nprint('LightGBM ROC AUC %.3f' % roc_auc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###¬†4.3.3 Precision-Recall Curve","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import precision_recall_curve\n\n# Calculate the no skill line as the proportion of the positive class\nno_skill = len(y[y==1])/len(y)\n\n# Plot the no skill precision-recall curve\nplt.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n\n# Calculate model precision-recall curve\nprecision, recall, _ = precision_recall_curve(y_test, pos_probs)\n\n# Plot the model precision-recall curve\nplt.plot(recall, precision, marker='.', label='LightGBM')\n\n# Calculate model precision-recall curve\nprecision, recall, _ = precision_recall_curve(y_test, pos_probs)\n\n# Call the plot\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import auc\n\n# Calculate the Precision-Recall AUC\nprecision, recall, _ = precision_recall_curve(y_test, pos_probs_dummy)\nauc_score = auc(recall, precision)\nprint('No Skill PR AUC: %.3f' % auc_score)\n\n# Calculate the Precision-Recall AUC for our model\nprecision, recall, _ = precision_recall_curve(y_test, pos_probs)\nauc_score = auc(recall, precision)\nprint('LightGBM PR AUC: %.3f' % auc_score)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###¬†5. Conclusion and notes for further analysis\n<p>We have explored the data, plotted some features and tried a binary classification model. While the preliminary performance scores aren't all that discouraging, this is meant to be only a starting point to expand upon the model. Further analysis may add features most importantly to optimize for the confusion matrix, crucially, in regards for the false negative results, which in this case is at the most center of improvement.</p>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<center>Stay safe and I hope this effort is helpful! üôã‚Äç‚ôÄÔ∏èüåé</center>","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}