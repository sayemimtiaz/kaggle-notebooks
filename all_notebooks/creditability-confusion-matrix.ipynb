{"cells":[{"metadata":{},"cell_type":"markdown","source":"![](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQutKA-oYIBw8OtYhNsrZ9uGr87_j_t4QXx-g&usqp=CAU)youtube.com"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Code by Shashwat Tiwari  https://www.kaggle.com/shashwatwork/insurance-company-complaint-prediction/notebook"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.compose import make_column_transformer,ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import KFold,cross_val_score,RepeatedStratifiedKFold,train_test_split\nfrom sklearn.preprocessing import RobustScaler,StandardScaler,LabelEncoder,LabelBinarizer\nfrom sklearn.linear_model import LogisticRegression,LogisticRegressionCV\nfrom numpy import absolute,mean,std\nfrom imblearn.over_sampling import SMOTE,ADASYN\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import confusion_matrix,accuracy_score,auc\nfrom imblearn.ensemble import BalancedRandomForestClassifier,EasyEnsembleClassifier,BalancedBaggingClassifier\nfrom sklearn.metrics import classification_report,f1_score,roc_auc_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import RepeatedStratifiedKFold,GridSearchCV,RandomizedSearchCV,StratifiedKFold,cross_val_score\nfrom sklearn.svm import LinearSVC\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier,BaggingClassifier,AdaBoostClassifier,GradientBoostingClassifier\nfrom sklearn.naive_bayes import GaussianNB,BernoulliNB\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom xgboost import XGBClassifier\n\n# for model explanation\nimport shap \nimport eli5\nfrom eli5.sklearn import PermutationImportance","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"nRowsRead = 1000 # specify 'None' if want to read whole file\ndf = pd.read_csv('../input/cusersmarildownloadsgermancsv/german.csv', delimiter=';', encoding = \"ISO-8859-2\", nrows = nRowsRead)\ndf.dataframeName = 'german.csv'\nnRow, nCol = df.shape\nprint(f'There are {nRow} rows and {nCol} columns')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = df.copy()\nscores = pd.DataFrame(columns=['Model', 'Score'])\nscores_ohe = pd.DataFrame(columns=['Model', 'Score'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = df1.drop(['Creditability'], axis = 1)\ny = df1['Creditability']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold,cross_val_score,RepeatedStratifiedKFold,train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_cols_list = X_train.columns.values.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import Counter\nprint('Classes and number of values in trainset',Counter(y_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fixing up Imbalance Classes with AdaSyn\n\nfrom imblearn.over_sampling import SMOTE,ADASYN\n\noversample = ADASYN()\nX_train,y_train = oversample.fit_resample(X_train,y_train)\nprint('Classes and number of values in trainset after ADSYN:',Counter(y_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import RobustScaler,StandardScaler,LabelEncoder,LabelBinarizer\n\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n    lb = LabelBinarizer()\n    lb.fit(y_test)\n    y_test = lb.transform(y_test)\n    y_pred = lb.transform(y_pred)\n    return roc_auc_score(y_test, y_pred, average=average)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_lr = LogisticRegression()\nmodel_lr.fit(X_train, y_train)\n\nlrpred = model_lr.predict(X_test)\n\nprint(\"Training Accuracy: \", model_lr.score(X_train, y_train))\nprint('Testing Accuarcy: ', model_lr.score(X_test, y_test))\nprint('F1 Score',f1_score(y_test, lrpred,average = 'weighted'))\nroc_score = multiclass_roc_auc_score(y_test,lrpred)\nprint(\"ROC AUC Score - \",roc_score)\n\n\n# confusion matrix\ncm = confusion_matrix(y_test, lrpred)\nplt.rcParams['figure.figsize'] = (5, 5)\nsns.heatmap(cm, annot = True, cmap = 'rainbow')\nplt.show()\n\n# classification report\ncr = classification_report(y_test, lrpred)\nprint(cr)\nscores = scores.append({'Model': 'Logistic Regression', 'Score': roc_score}, ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_lr_cv = LogisticRegressionCV(cv=10)\nmodel_lr_cv.fit(X_train, y_train)\n\nlrpred_cv = model_lr_cv.predict(X_test)\n\nprint(\"Training Accuracy: \", model_lr_cv.score(X_train, y_train))\nprint('Testing Accuarcy: ', model_lr_cv.score(X_test, y_test))\nprint('F1 Score',f1_score(y_test, lrpred_cv,average = 'weighted'))\nroc_score = multiclass_roc_auc_score(y_test,lrpred_cv)\nprint(\"ROC AUC Score - \",roc_score)\n\n\n# confusion matrix\ncm = confusion_matrix(y_test, lrpred_cv)\nplt.rcParams['figure.figsize'] = (5, 5)\nsns.heatmap(cm, annot = True, cmap = 'viridis')\nplt.show()\n\n# classification report\ncr = classification_report(y_test, lrpred_cv)\nprint(cr)\nscores = scores.append({'Model': 'Logistic RegressionCV', 'Score': roc_score}, ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_nb = GaussianNB()\nmodel_nb.fit(X_train, y_train)\n\nnbpred = model_nb.predict(X_test)\n\nprint('F1 Score',f1_score(y_test, nbpred,average = 'weighted'))\nroc_score = multiclass_roc_auc_score(y_test,nbpred)\nprint(\"ROC AUC Score - \",roc_score)\n\n\n# confusion matrix\ncm = confusion_matrix(y_test, nbpred)\nplt.rcParams['figure.figsize'] = (5, 5)\nsns.heatmap(cm, annot = True, cmap = 'twilight')\nplt.show()\n\n# classification report\ncr = classification_report(y_test, nbpred)\nprint(cr)\nscores = scores.append({'Model': 'GaussianNB', 'Score': roc_score}, ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_u = RandomForestClassifier(n_estimators=100, class_weight='balanced',random_state=0)\nmodel_u.fit(X_train, y_train)\n\ny_pred_rf = model_u.predict(X_test)\n\nprint(\"Training Accuracy: \", model_u.score(X_train, y_train))\nprint('Testing Accuarcy: ', model_u.score(X_test, y_test))\nprint('F1 Score',f1_score(y_test, y_pred_rf,average = 'weighted'))\nroc_score = multiclass_roc_auc_score(y_test,y_pred_rf)\nprint(\"ROC AUC Score - \",roc_score)\n\n# confusion matrix\ncm = confusion_matrix(y_test, y_pred_rf)\nplt.rcParams['figure.figsize'] = (5, 5)\nsns.heatmap(cm, annot = True, cmap = 'winter')\nplt.show()\n\n# classification report\ncr = classification_report(y_test, y_pred_rf)\nprint(cr)\nscores = scores.append({'Model': 'Random-Forest', 'Score': roc_score}, ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_gb = GradientBoostingClassifier()\nmodel_gb.fit(X_train, y_train)\n\ny_pred_rf = model_gb.predict(X_test)\n\nprint(\"Training Accuracy: \", model_gb.score(X_train, y_train))\nprint('Testing Accuarcy: ', model_gb.score(X_test, y_test))\nprint('F1 Score',f1_score(y_test, y_pred_rf,average = 'weighted'))\nroc_score = multiclass_roc_auc_score(y_test,y_pred_rf)\nprint(\"ROC AUC Score - \",roc_score)\n\n# confusion matrix\ncm = confusion_matrix(y_test, y_pred_rf)\nplt.rcParams['figure.figsize'] = (5, 5)\nsns.heatmap(cm, annot = True, cmap = 'vlag')\nplt.show()\n\n# classification report\ncr = classification_report(y_test, y_pred_rf)\nprint(cr)\nscores = scores.append({'Model': 'Gradient Boosting', 'Score': roc_score}, ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_xgb = XGBClassifier()\nmodel_xgb.fit(X_train, y_train)\n\ny_pred_rf = model_xgb.predict(X_test)\n\nprint(\"Training Accuracy: \", model_xgb.score(X_train, y_train))\nprint('Testing Accuarcy: ', model_xgb.score(X_test, y_test))\nprint('F1 Score',f1_score(y_test, y_pred_rf,average = 'weighted'))\nroc_score = multiclass_roc_auc_score(y_test,y_pred_rf)\nprint(\"ROC AUC Score - \",roc_score)\n\n# confusion matrix\ncm = confusion_matrix(y_test, y_pred_rf)\nplt.rcParams['figure.figsize'] = (5, 5)\nsns.heatmap(cm, annot = True, cmap = 'vlag_r')\nplt.show()\n\n# classification report\ncr = classification_report(y_test, y_pred_rf)\nprint(cr)\nscores = scores.append({'Model': 'XGradient Boosting', 'Score': roc_score}, ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Snippet for imbalanced Data Using Imblearn Balanced Classifiers.  I don't know if this data is imbalanced or not. I copied the snippet, just in case I need it in the future."},{"metadata":{"trusted":true},"cell_type":"code","source":"model_brf = BalancedRandomForestClassifier(n_estimators = 100,max_depth=8, random_state = 0)\n\nmodel_brf.fit(X_train, y_train)\ny_pred_brf = model_brf.predict(X_test)\n\nprint(\"Training Accuracy: \", model_brf.score(X_train, y_train))\nprint('Testing Accuarcy: ', model_brf.score(X_test, y_test))\nprint('F1 Score',f1_score(y_test, y_pred_brf,average = 'weighted'))\nroc_score = multiclass_roc_auc_score(y_test,y_pred_brf)\nprint(\"ROC AUC Score - \",roc_score)\n\n\n# making a classification report\ncr = classification_report(y_test,  y_pred_brf)\nprint(cr)\n\n# making a confusion matrix\nplt.rcParams['figure.figsize'] = (5, 5)\ncm = confusion_matrix(y_test, y_pred_brf)\nsns.heatmap(cm, annot = True, cmap = 'magma')\nplt.show()\nscores = scores.append({'Model': 'Balanced RF', 'Score': roc_score}, ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model1 = EasyEnsembleClassifier(n_estimators = 100, random_state = 0)\n\nmodel1.fit(X_train, y_train)\ny_pred_ef = model1.predict(X_test)\n\nprint(\"Training Accuracy: \", model1.score(X_train, y_train))\nprint('Testing Accuarcy: ', model1.score(X_test, y_test))\nprint('F1 Score',f1_score(y_test, y_pred_ef,average = 'weighted'))\nroc_score = multiclass_roc_auc_score(y_test,y_pred_ef)\nprint(\"ROC AUC Score - \",roc_score)\n\n\n\n# making a classification report\ncr = classification_report(y_test,  y_pred_ef)\nprint(cr)\n\n# making a confusion matrix\ncm = confusion_matrix(y_test, y_pred_ef)\nsns.heatmap(cm, annot = True, cmap = 'copper')\nplt.show()\nscores = scores.append({'Model': 'Easy-Ensemble CLF', 'Score': roc_score}, ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model2 = BalancedBaggingClassifier(base_estimator = RandomForestClassifier(),\n                                 sampling_strategy = 'auto',\n                                 replacement = False,\n                                 random_state = 0)\n\nmodel2.fit(X_train, y_train)\ny_pred_bc = model2.predict(X_test)\n\nprint(\"Training Accuracy: \", model2.score(X_train, y_train))\nprint('Testing Accuarcy: ', model2.score(X_test, y_test))\nprint('F1 Score',f1_score(y_test, y_pred_bc,average = 'weighted'))\nroc_score = multiclass_roc_auc_score(y_test,y_pred_bc)\nprint(\"ROC AUC Score - \",roc_score)\n\n\n# making a classification report\ncr = classification_report(y_test,  y_pred_bc)\nprint(cr)\n\n# making a confusion matrix\ncm = confusion_matrix(y_test, y_pred_bc)\nsns.heatmap(cm, annot = True, cmap = 'Purples')\nplt.show()\nscores = scores.append({'Model': 'Balanced Bagging Classifier', 'Score': roc_score}, ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores.sort_values(by='Score', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Hyper Parameter Tuning for Random Forest Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"n_estimators = [int(x) for x in np.linspace(start = 100, stop = 2000, num = 10)]\nmax_depth = [int(x) for x in np.linspace(1, 10, num = 10)]\nmax_depth.append(None)\nmin_samples_split = [2, 5, 10]\nmin_samples_leaf = [1, 2, 4]\nbootstrap = [True, False]\nrandom_grid = {'n_estimators': n_estimators,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}\n\nprint(random_grid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_random = RandomizedSearchCV(estimator=model_u, param_distributions=random_grid,\n                              n_iter = 100, scoring='f1_weighted', \n                              cv = 3, verbose=2, random_state=42, n_jobs=-1,\n                              return_train_score=True)\n\nrf_random.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_random.best_params_","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true,"collapsed":true},"cell_type":"code","source":"rf_random.cv_results_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fitting up tuned model param.\nmodel_tuned = RandomForestClassifier(n_estimators =  944,min_samples_split = 10,min_samples_leaf= 1,max_depth = None,bootstrap= False)\nmodel_tuned.fit(X_train, y_train)\n\ny_pred_rf = model_tuned.predict(X_test)\n\nprint(\"Training Accuracy: \", model_tuned.score(X_train, y_train))\nprint('Testing Accuarcy: ', model_tuned.score(X_test, y_test))\nprint('F1 Score',f1_score(y_test, y_pred_rf,average = 'weighted'))\nroc_score = multiclass_roc_auc_score(y_test,y_pred_rf)\nprint(\"ROC AUC Score - \",roc_score)\n\n# confusion matrix\ncm = confusion_matrix(y_test, y_pred_rf)\nplt.rcParams['figure.figsize'] = (5, 5)\nsns.heatmap(cm, annot = True, cmap = 'YlOrBr')\nplt.show()\n\n# classification report\ncr = classification_report(y_test, y_pred_rf)\nprint(cr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Setting up ML Pipeline\n\nValidation of Pipeline created"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_pipeline = Pipeline(steps=[('scaling',StandardScaler()),\n                                 ('RFTuned', RandomForestClassifier(n_estimators =  944,min_samples_split = 10,min_samples_leaf= 1,max_depth = None,bootstrap= False))])\nmodel_pipeline.fit(X_train, y_train)\n\nmodel_pipeline_pred = model_pipeline.predict(X_test)\n\nprint(\"Training Accuracy: \", model_pipeline.score(X_train, y_train))\nprint('Testing Accuarcy: ', model_pipeline.score(X_test, y_test))\nprint('F1 Score',f1_score(y_test, model_pipeline_pred,average = 'weighted'))\nroc_score = multiclass_roc_auc_score(y_test,model_pipeline_pred)\nprint(\"ROC AUC Score - \",roc_score)\n\n# confusion matrix\ncm = confusion_matrix(y_test, model_pipeline_pred)\nplt.rcParams['figure.figsize'] = (5, 5)\nsns.heatmap(cm, annot = True, cmap = 'RdGy')\nplt.show()\n\n# classification report\ncr = classification_report(y_test, model_pipeline_pred)\nprint(cr)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"!pip install dexplot -q","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import dexplot as dxp\n\ndxp.bar(x = 'Model',y = 'Score',data = scores,cmap='geyser',figsize=(10,5),title='Model Score without OHE')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Using Random Forest Model For Interpretation\nshap_values = shap.TreeExplainer(model_u).shap_values(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shap.summary_plot(shap_values, train_cols_list, plot_type=\"bar\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It's a multi class classification stacked bar plot shows impact of classes on model performance.\nI don't know even if this is MultiClass classification or not."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}