{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Customer Churn Prediction with XGBoost and SMOTE-ENN"},{"metadata":{},"cell_type":"markdown","source":"- Customer churn prediction is a binary classification problem to be solved by supervised learning.\n- Let's use major supervised learning algorithm and compare the results.\n  - Logistic regression\n  - KNN\n  - SVM\n  - Decision Tree\n  - Random Forest\n  - AdaBoost\n  - XGBoost\n- The data is imbalanced, so apply rebalancing methods and compare their results  with those of baseline models.\n  - Baseline models: Imbalanced data\n  - SMOTE\n  - SMOTE-ENN\n- Performance measure\n  - Accuracy\n  - Recall\n  - F1 score\n  - AUC score"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. Load and Explore Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import the necessary packages\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom xgboost import XGBClassifier\n\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.metrics import confusion_matrix,accuracy_score,classification_report\nfrom sklearn.metrics import roc_auc_score,roc_curve,scorer\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import precision_score,recall_score\n\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)\nsns.set(color_codes=True)\n%matplotlib inline\n%config InlineBackend.figure_formats = {'png', 'retina'}\n\n# Suppressing Warnings\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load the dataset\ndf=pd.read_csv('../input/credit-card-customers/BankChurners.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# According to the data details, \"The PLEASE IGNORE THE LAST 2 COLUMNS (NAIVE BAYES CLASâ€¦)\" so we should delete the last 2 columns.\n# First display the column names\ndf.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Delete the last two columns\n# \"CLIENTNUM\" is not needed for prediction. So, let's delete it.\ndf=df.drop([\"CLIENTNUM\",\n            \"Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1\",\n            \"Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2\"],\n           axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display first five rows\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display dataset shape\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display descriptive statistics\ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display data information\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- There are no missing values in this dataset. \n- Some are categorical variables. So we need to encode them.\n  - They are \"Attrition_Flag\",\"Gender\",\"Education_Level\",\"Marital_Status\",\"Income_Category\",\"Card_Category\""},{"metadata":{},"cell_type":"markdown","source":"# 2. Data preprocessing"},{"metadata":{},"cell_type":"markdown","source":"# 2.1. Convert categorical variables to numerical"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show the unique values of categorical variables\nprint(\"Attrition_Flag :\",df[\"Attrition_Flag\"].unique())\nprint(\"Gender         :\",df[\"Gender\"].unique())\nprint(\"Education_Level:\",df[\"Education_Level\"].unique())\nprint(\"Marital_Status :\",df[\"Marital_Status\"].unique())\nprint(\"Income_Category:\",df[\"Income_Category\"].unique())\nprint(\"Card_Category  :\",df[\"Card_Category\"].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert variables with two categories into binary variables\ndf.loc[df[\"Attrition_Flag\"] == \"Existing Customer\", \"Attrition_Flag\"] = 0\ndf.loc[df[\"Attrition_Flag\"] == \"Attrited Customer\", \"Attrition_Flag\"] = 1\ndf[\"Attrition_Flag\"] = df[\"Attrition_Flag\"].astype(int)\n\ndf.loc[df[\"Gender\"] == \"F\", \"Gender\"] = 0\ndf.loc[df[\"Gender\"] == \"M\", \"Gender\"] = 1\ndf[\"Gender\"] = df[\"Gender\"].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#One hot encoding for Categorical variables\ndf = pd.get_dummies(df)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.2. Train-Test split"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split data into train and test Datasets\n\n# Separate the dataset into features and target\nX = df.drop([\"Attrition_Flag\"],axis=1)\ny = df[\"Attrition_Flag\"]\n\n# Splitting the data into train and test\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.30, stratify=y, random_state=101)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scale the data\n\n# Standardize the columns the values of which are out of 0-1 range\nscaler = StandardScaler().fit(X_train)\n\nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check the data balance\n\n# Count the number of churn (=1)\ny.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Check the churn rate\nchurn_rate = (sum(df['Attrition_Flag'])/len(df['Attrition_Flag'].index))*100\nchurn_rate","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The employee churn rate is 23.8. We can say that it is an imbalanced dataset."},{"metadata":{},"cell_type":"markdown","source":"## 3. Prediction with Imbalanced Data: Baseline models"},{"metadata":{},"cell_type":"markdown","source":"## 3.1.Logistic Regression with Imbalanced Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initiate the model\nbase_lm = LogisticRegression()\n# Fit the model\nbase_lm_model = base_lm.fit(X_train, y_train.ravel())\n# Make Predictions\nbase_lm_pred=base_lm_model.predict(X_test)\n\n# Calculate Accuracy, Precision, Recall, and F1 score\nbase_lm_accuracy = accuracy_score(y_test, base_lm_pred)\nbase_lm_precision = precision_score(y_test, base_lm_pred)\nbase_lm_recall = recall_score(y_test, base_lm_pred)\nbase_lm_f1 = 2 * (base_lm_precision * base_lm_recall) / (base_lm_precision + base_lm_recall)\n\n# Calculate AUC score\nbase_lm_probs = base_lm.predict_proba(X_test)\nbase_lm_probs = base_lm_probs[:,1]\nbase_lm_auc = roc_auc_score(y_test, base_lm_probs)\n\n# Display the metrics\nprint(\"Logistic Regression: Imbalanced Data\")\nprint(\" - Accuracy : \",'{:.3f}'.format(base_lm_accuracy))\nprint(\" - Precision: \",'{:.3f}'.format(base_lm_precision))\nprint(\" - Recall   : \",'{:.3f}'.format(base_lm_recall))\nprint(\" - F1 score : \",'{:.3f}'.format(base_lm_f1))\nprint(\" - AUC score: \",'{:.3f}'.format(base_lm_auc))\n\n# Display the confusion matrix\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_test,base_lm_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.2. KNN with Imbalanced Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initiate the model\nbase_knn = KNeighborsClassifier()\n# Fit the model\nbase_knn_model = base_knn.fit(X_train, y_train.ravel())\n# Make Predictions\nbase_knn_pred=base_knn_model.predict(X_test)\n\n# Calculate Accuracy, Precision, Recall, and F1 score\nbase_knn_accuracy = accuracy_score(y_test, base_knn_pred)\nbase_knn_precision = precision_score(y_test, base_knn_pred)\nbase_knn_recall = recall_score(y_test, base_knn_pred)\nbase_knn_f1 = 2 * (base_knn_precision * base_knn_recall) / (base_knn_precision + base_knn_recall)\n\n# Calculate AUC score\nbase_knn_probs = base_knn.predict_proba(X_test)\nbase_knn_probs = base_knn_probs[:,1]\nbase_knn_auc = roc_auc_score(y_test, base_knn_probs)\n\n# Display the metrics\nprint(\"KNN Classifier: Imbalanced Data\")\nprint(\" - Accuracy : \",'{:.3f}'.format(base_knn_accuracy))\nprint(\" - Precision: \",'{:.3f}'.format(base_knn_precision))\nprint(\" - Recall   : \",'{:.3f}'.format(base_knn_recall))\nprint(\" - F1 score : \",'{:.3f}'.format(base_knn_f1))\nprint(\" - AUC score: \",'{:.3f}'.format(base_knn_auc))\n\n# Display the confusion matrix\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_test,base_knn_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.3. SVM with Imbalanced Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initiate the model\nbase_svc = SVC(kernel='rbf',probability=True)\n# Fit the model\nbase_svc_model = base_svc.fit(X_train, y_train.ravel())\n# Make Predictions\nbase_svc_pred = base_svc_model.predict(X_test)\n\n# Calculate Accuracy, Precision, Recall, and F1 score\nbase_svc_accuracy = accuracy_score(y_test, base_svc_pred)\nbase_svc_precision = precision_score(y_test, base_svc_pred)\nbase_svc_recall = recall_score(y_test, base_svc_pred)\nbase_svc_f1 = 2 * (base_svc_precision * base_svc_recall) / (base_svc_precision + base_svc_recall)\n\n# Calculate AUC score\nbase_svc_probs = base_svc.predict_proba(X_test)\nbase_svc_probs = base_svc_probs[:,1]\nbase_svc_auc = roc_auc_score(y_test, base_svc_probs)\n\n# Display the metrics\nprint(\"SVM Classifier: Imbalanced Data\")\nprint(\" - Accuracy : \",'{:.3f}'.format(base_svc_accuracy))\nprint(\" - Precision: \",'{:.3f}'.format(base_svc_precision))\nprint(\" - Recall   : \",'{:.3f}'.format(base_svc_recall))\nprint(\" - F1 score : \",'{:.3f}'.format(base_svc_f1))\nprint(\" - AUC score: \",'{:.3f}'.format(base_svc_auc))\n\n# Display the confusion matrix\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_test,base_svc_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.4. Decision Tree with Imbalanced Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initiate the model\nbase_tree = DecisionTreeClassifier()\n# Fit the model\nbase_tree_model = base_tree.fit(X_train, y_train.ravel())\n# Make Predictions\nbase_tree_pred=base_tree_model.predict(X_test)\n\n# Calculate Accuracy, Precision, Recall, and F1 score\nbase_tree_accuracy = accuracy_score(y_test, base_tree_pred)\nbase_tree_precision = precision_score(y_test, base_tree_pred)\nbase_tree_recall = recall_score(y_test, base_tree_pred)\nbase_tree_f1 = 2 * (base_tree_precision * base_tree_recall) / (base_tree_precision + base_tree_recall)\n\n# Calculate AUC score\nbase_tree_probs = base_tree.predict_proba(X_test)\nbase_tree_probs = base_tree_probs[:,1]\nbase_tree_auc = roc_auc_score(y_test, base_tree_probs)\n\n# Display the metrics\nprint(\"Decision Tree Classifier: Imbalanced Data\")\nprint(\" - Accuracy : \",'{:.3f}'.format(base_tree_accuracy))\nprint(\" - Precision: \",'{:.3f}'.format(base_tree_precision))\nprint(\" - Recall   : \",'{:.3f}'.format(base_tree_recall))\nprint(\" - F1 score : \",'{:.3f}'.format(base_tree_f1))\nprint(\" - AUC score: \",'{:.3f}'.format(base_tree_auc))\n\n# Display the confusion matrix\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_test,base_tree_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.5. Random Forest with Imbalanced Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initiate the model\nbase_rfc = RandomForestClassifier()\n# Fit the model\nbase_rfc_model = base_rfc.fit(X_train, y_train.ravel())\n# Make Predictions\nbase_rfc_pred=base_rfc_model.predict(X_test)\n\n# Calculate Accuracy, Precision, Recall, and F1 score\nbase_rfc_accuracy = accuracy_score(y_test, base_rfc_pred)\nbase_rfc_precision = precision_score(y_test, base_rfc_pred)\nbase_rfc_recall = recall_score(y_test, base_rfc_pred)\nbase_rfc_f1 = 2 * (base_rfc_precision * base_rfc_recall) / (base_rfc_precision + base_rfc_recall)\n\n# Calculate AUC score\nbase_rfc_probs = base_rfc.predict_proba(X_test)\nbase_rfc_probs = base_rfc_probs[:,1]\nbase_rfc_auc = roc_auc_score(y_test, base_rfc_probs)\n\n# Display the metrics\nprint(\"Random Forest Classifier: Imbalanced Data\")\nprint(\" - Accuracy : \",'{:.3f}'.format(base_rfc_accuracy))\nprint(\" - Precision: \",'{:.3f}'.format(base_rfc_precision))\nprint(\" - Recall   : \",'{:.3f}'.format(base_rfc_recall))\nprint(\" - F1 score : \",'{:.3f}'.format(base_rfc_f1))\nprint(\" - AUC score: \",'{:.3f}'.format(base_rfc_auc))\n\n# Display the confusion matrix\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_test,base_rfc_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.6. AdaBoost with Imbalanced Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initiate the model\nbase_adb = AdaBoostClassifier()\n# Fit the model\nbase_adb_model = base_adb.fit(X_train, y_train.ravel())\n# Make Predictions\nbase_adb_pred=base_adb_model.predict(X_test)\n\n# Calculate Accuracy, Precision, Recall, and F1 score\nbase_adb_accuracy = accuracy_score(y_test, base_adb_pred)\nbase_adb_precision = precision_score(y_test, base_adb_pred)\nbase_adb_recall = recall_score(y_test, base_adb_pred)\nbase_adb_f1 = 2 * (base_adb_precision * base_adb_recall) / (base_adb_precision + base_adb_recall)\n\n# Calculate AUC score\nbase_adb_probs = base_adb.predict_proba(X_test)\nbase_adb_probs = base_adb_probs[:,1]\nbase_adb_auc = roc_auc_score(y_test, base_adb_probs)\n\n# Display the metrics\nprint(\"AdaBoost Classifier: Imbalanced Data\")\nprint(\" - Accuracy : \",'{:.3f}'.format(base_adb_accuracy))\nprint(\" - Precision: \",'{:.3f}'.format(base_adb_precision))\nprint(\" - Recall   : \",'{:.3f}'.format(base_adb_recall))\nprint(\" - F1 score : \",'{:.3f}'.format(base_adb_f1))\nprint(\" - AUC score: \",'{:.3f}'.format(base_adb_auc))\n\n# Display the confusion matrix\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_test,base_adb_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.7. XGBoost with Imbalance Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initiate the model\nbase_xgb = XGBClassifier()\n# Fit the model\nbase_xgb_model = base_xgb.fit(X_train, y_train.ravel())\n# Make Predictions\nbase_xgb_pred = base_xgb_model.predict(X_test)\n\n# Calculate Accuracy, Precision, Recall, and F1 score\nbase_xgb_accuracy = accuracy_score(y_test, base_xgb_pred)\nbase_xgb_precision = precision_score(y_test, base_xgb_pred)\nbase_xgb_recall = recall_score(y_test, base_xgb_pred)\nbase_xgb_f1 = 2 * (base_xgb_precision * base_xgb_recall) / (base_xgb_precision + base_xgb_recall)\n\n# Calculate AUC score\nbase_xgb_probs = base_xgb.predict_proba(X_test)\nbase_xgb_probs = base_xgb_probs[:,1]\nbase_xgb_auc = roc_auc_score(y_test, base_xgb_probs)\n\n# Display the metrics\nprint(\"XGBoost Classifier: Imbalanced Data\")\nprint(\" - Accuracy : \",'{:.3f}'.format(base_xgb_accuracy))\nprint(\" - Precision: \",'{:.3f}'.format(base_xgb_precision))\nprint(\" - Recall   : \",'{:.3f}'.format(base_xgb_recall))\nprint(\" - F1 score : \",'{:.3f}'.format(base_xgb_f1))\nprint(\" - AUC score: \",'{:.3f}'.format(base_xgb_auc))\n\n# Display the confusion matrix\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_test,base_xgb_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4. Prediction with SMOTE"},{"metadata":{},"cell_type":"markdown","source":"## Perform SMOTE"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Since this is an imbalanced data, apply SMOTE to the training set\nfrom imblearn.over_sampling import SMOTE\nsmote=SMOTE()\nsmote_X_train, smote_y_train = smote.fit_sample(X_train,y_train)\n\n# Check if SMOTE were properly applied\nsmote_y_train.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"SMOTE successfully made the dataset balanced"},{"metadata":{},"cell_type":"markdown","source":"## 4.1. Logisgic Regression with SMOTE"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initiate the model\nsmote_lm = LogisticRegression()\n\n# Fit the model\nsmote_lm_model = smote_lm.fit(smote_X_train, smote_y_train.ravel())\n\n# Make Predictions\nsmote_lm_pred=smote_lm_model.predict(X_test)\n\n# Calculate Accuracy, Precision, Recall, and F1 score\nsmote_lm_accuracy = accuracy_score(y_test, smote_lm_pred)\nsmote_lm_precision = precision_score(y_test, smote_lm_pred)\nsmote_lm_recall = recall_score(y_test, smote_lm_pred)\nsmote_lm_f1 = 2 * (smote_lm_precision * smote_lm_recall) / (smote_lm_precision + smote_lm_recall)\n\n# Calculate AUC score\nsmote_lm_probs = smote_lm.predict_proba(X_test)\nsmote_lm_probs = smote_lm_probs[:,1]\nsmote_lm_auc = roc_auc_score(y_test, smote_lm_probs)\n\n# Display the metrics\nprint(\"Logistic Regression: SMOTE\")\nprint(\" - Accuracy : \",'{:.3f}'.format(smote_lm_accuracy))\nprint(\" - Precision: \",'{:.3f}'.format(smote_lm_precision))\nprint(\" - Recall   : \",'{:.3f}'.format(smote_lm_recall))\nprint(\" - F1 score : \",'{:.3f}'.format(smote_lm_f1))\nprint(\" - AUC score: \",'{:.3f}'.format(smote_lm_auc))\n\n# Display the confusion matrix\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_test,smote_lm_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4.2. KNN with SMOTE"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initiate the model\nsmote_knn = KNeighborsClassifier()\n\n# Fit the model\nsmote_knn_model = smote_knn.fit(smote_X_train, smote_y_train.ravel())\n\n# Make Predictions\nsmote_knn_pred=smote_knn_model.predict(X_test)\n\n# Calculate Accuracy, Precision, Recall, and F1 score\nsmote_knn_accuracy = accuracy_score(y_test, smote_knn_pred)\nsmote_knn_precision = precision_score(y_test, smote_knn_pred)\nsmote_knn_recall = recall_score(y_test, smote_knn_pred)\nsmote_knn_f1 = 2 * (smote_knn_precision * smote_knn_recall) / (smote_knn_precision + smote_knn_recall)\n\n# Calculate AUC score\nsmote_knn_probs = smote_knn.predict_proba(X_test)\nsmote_knn_probs = smote_knn_probs[:,1]\nsmote_knn_auc = roc_auc_score(y_test, smote_knn_probs)\n\n# Display the metrics\nprint(\"KNN Classifier: SMOTE\")\nprint(\" - Accuracy : \",'{:.3f}'.format(smote_knn_accuracy))\nprint(\" - Precision: \",'{:.3f}'.format(smote_knn_precision))\nprint(\" - Recall   : \",'{:.3f}'.format(smote_knn_recall))\nprint(\" - F1 score : \",'{:.3f}'.format(smote_knn_f1))\nprint(\" - AUC score: \",'{:.3f}'.format(smote_knn_auc))\n\n# Display the confusion matrix\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_test,smote_knn_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4.3. SVM with SMOTE"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initiate the model\nsmote_svc = SVC(kernel='rbf',probability=True)\n\n# Fit the model\nsmote_svc_model = smote_svc.fit(smote_X_train, smote_y_train.ravel())\n\n# Make Predictions\nsmote_svc_pred=smote_svc_model.predict(X_test)\n\n# Calculate Accuracy, Precision, Recall, and F1 score\nsmote_svc_accuracy = accuracy_score(y_test, smote_svc_pred)\nsmote_svc_precision = precision_score(y_test, smote_svc_pred)\nsmote_svc_recall = recall_score(y_test, smote_svc_pred)\nsmote_svc_f1 = 2 * (smote_svc_precision * smote_svc_recall) / (smote_svc_precision + smote_svc_recall)\n\n# Calculate AUC score\nsmote_svc_probs = smote_svc.predict_proba(X_test)\nsmote_svc_probs = smote_svc_probs[:,1]\nsmote_svc_auc = roc_auc_score(y_test, smote_svc_probs)\n\n# Display the metrics\nprint(\"SVM Classifier: SMOTE\")\nprint(\" - Accuracy : \",'{:.3f}'.format(smote_svc_accuracy))\nprint(\" - Precision: \",'{:.3f}'.format(smote_svc_precision))\nprint(\" - Recall   : \",'{:.3f}'.format(smote_svc_recall))\nprint(\" - F1 score : \",'{:.3f}'.format(smote_svc_f1))\nprint(\" - AUC score: \",'{:.3f}'.format(smote_svc_auc))\n\n# Display the confusion matrix\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_test,smote_svc_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4.4. Decision Tree Classifier with SMOTE"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initiate the model\nsmote_tree = DecisionTreeClassifier()\n\n# Fit the model\nsmote_tree_model = smote_tree.fit(smote_X_train, smote_y_train.ravel())\n\n# Make Predictions\nsmote_tree_pred=smote_tree_model.predict(X_test)\n\n# Calculate Accuracy, Precision, Recall, and F1 score\nsmote_tree_accuracy = accuracy_score(y_test, smote_tree_pred)\nsmote_tree_precision = precision_score(y_test, smote_tree_pred)\nsmote_tree_recall = recall_score(y_test, smote_tree_pred)\nsmote_tree_f1 = 2 * (smote_tree_precision * smote_tree_recall) / (smote_tree_precision + smote_tree_recall)\n\n# Calculate AUC score\nsmote_tree_probs = smote_tree.predict_proba(X_test)\nsmote_tree_probs = smote_tree_probs[:,1]\nsmote_tree_auc = roc_auc_score(y_test, smote_tree_probs)\n\n# Display the metrics\nprint(\"Decision Tree Classifier: SMOTE\")\nprint(\" - Accuracy : \",'{:.3f}'.format(smote_tree_accuracy))\nprint(\" - Precision: \",'{:.3f}'.format(smote_tree_precision))\nprint(\" - Recall   : \",'{:.3f}'.format(smote_tree_recall))\nprint(\" - F1 score : \",'{:.3f}'.format(smote_tree_f1))\nprint(\" - AUC score: \",'{:.3f}'.format(smote_tree_auc))\n\n# Display the confusion matrix\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_test,smote_tree_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4.5. Random Forest Classifier with SMOTE"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initiate the model\nsmote_rfc = RandomForestClassifier()\n\n# Fit the model\nsmote_rfc_model = smote_rfc.fit(smote_X_train, smote_y_train.ravel())\n\n# Make Predictions\nsmote_rfc_pred = smote_rfc_model.predict(X_test)\n\n# Calculate Accuracy, Precision, Recall, and F1 score\nsmote_rfc_accuracy = accuracy_score(y_test, smote_rfc_pred)\nsmote_rfc_precision = precision_score(y_test, smote_rfc_pred)\nsmote_rfc_recall = recall_score(y_test, smote_rfc_pred)\nsmote_rfc_f1 = 2 * (smote_rfc_precision * smote_rfc_recall) / (smote_rfc_precision + smote_rfc_recall)\n\n# Calculate AUC score\nsmote_rfc_probs = smote_rfc.predict_proba(X_test)\nsmote_rfc_probs = smote_rfc_probs[:,1]\nsmote_rfc_auc = roc_auc_score(y_test, smote_rfc_probs)\n\n# Display the metrics\nprint(\"Random Forest Classifier: SMOTE\")\nprint(\" - Accuracy : \",'{:.3f}'.format(smote_rfc_accuracy))\nprint(\" - Precision: \",'{:.3f}'.format(smote_rfc_precision))\nprint(\" - Recall   : \",'{:.3f}'.format(smote_rfc_recall))\nprint(\" - F1 score : \",'{:.3f}'.format(smote_rfc_f1))\nprint(\" - AUC score: \",'{:.3f}'.format(smote_rfc_auc))\n\n# Display the confusion matrix\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_test,smote_rfc_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4.6. AdaBoost Classifier with SMOTE"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initiate the model\nsmote_adb = AdaBoostClassifier()\n\n# Fit the model\nsmote_adb_model = smote_adb.fit(smote_X_train, smote_y_train.ravel())\n\n# Make Predictions\nsmote_adb_pred = smote_adb_model.predict(X_test)\n\n# Calculate Accuracy, Precision, Recall, and F1 score\nsmote_adb_accuracy = accuracy_score(y_test, smote_adb_pred)\nsmote_adb_precision = precision_score(y_test, smote_adb_pred)\nsmote_adb_recall = recall_score(y_test, smote_adb_pred)\nsmote_adb_f1 = 2 * (smote_adb_precision * smote_adb_recall) / (smote_adb_precision + smote_adb_recall)\n\n# Calculate AUC score\nsmote_adb_probs = smote_adb.predict_proba(X_test)\nsmote_adb_probs = smote_adb_probs[:,1]\nsmote_adb_auc = roc_auc_score(y_test, smote_adb_probs)\n\n# Display the metrics\nprint(\"AdaBoost Classifier: SMOTE\")\nprint(\" - Accuracy : \",'{:.3f}'.format(smote_adb_accuracy))\nprint(\" - Precision: \",'{:.3f}'.format(smote_adb_precision))\nprint(\" - Recall   : \",'{:.3f}'.format(smote_adb_recall))\nprint(\" - F1 score : \",'{:.3f}'.format(smote_adb_f1))\nprint(\" - AUC score: \",'{:.3f}'.format(smote_adb_auc))\n\n# Display the confusion matrix\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_test,smote_adb_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4.7. XGBoost Classifier with SMOTE"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initiate the model\nsmote_xgb = XGBClassifier()\n\n# Fit the model\nsmote_xgb_model = smote_xgb.fit(smote_X_train, smote_y_train.ravel())\n\n# Make Predictions\nsmote_xgb_pred = smote_xgb_model.predict(X_test)\n\n# Calculate Accuracy, Precision, Recall, and F1 score\nsmote_xgb_accuracy = accuracy_score(y_test, smote_xgb_pred)\nsmote_xgb_precision = precision_score(y_test, smote_xgb_pred)\nsmote_xgb_recall = recall_score(y_test, smote_xgb_pred)\nsmote_xgb_f1 = 2 * (smote_xgb_precision * smote_xgb_recall) / (smote_xgb_precision + smote_xgb_recall)\n\n# Calculate AUC score\nsmote_xgb_probs = smote_xgb.predict_proba(X_test)\nsmote_xgb_probs = smote_xgb_probs[:,1]\nsmote_xgb_auc = roc_auc_score(y_test, smote_xgb_probs)\n\n# Display the metrics\nprint(\"XGBClassifier: SMOTE\")\nprint(\" - Accuracy : \",'{:.3f}'.format(smote_xgb_accuracy))\nprint(\" - Precision: \",'{:.3f}'.format(smote_xgb_precision))\nprint(\" - Recall   : \",'{:.3f}'.format(smote_xgb_recall))\nprint(\" - F1 score : \",'{:.3f}'.format(smote_xgb_f1))\nprint(\" - AUC score: \",'{:.3f}'.format(smote_xgb_auc))\n\n# Display the confusion matrix\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_test,smote_xgb_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Prediction with SMOTE-ENN"},{"metadata":{},"cell_type":"markdown","source":"## Perform SMOTE-ENN"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Combined SMOTE and Edited Nearest Neighbors sampling for imbalanced classification\nfrom imblearn.combine import SMOTEENN\nfrom imblearn.under_sampling import EditedNearestNeighbours\n\n# define sampling\nsmoteenn_X_train, smoteenn_y_train=SMOTEENN(\n    enn=EditedNearestNeighbours(sampling_strategy='majority')).fit_sample(X_train,y_train)\n\n# Check if SMOTE-ENN were properly applied\nsmoteenn_y_train.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5.1. Logistic Regression with SMOTE-ENN"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initiate the model\nsmoteenn_lm = LogisticRegression()\n\n# Fit the model\nsmoteenn_lm_model = smoteenn_lm.fit(smoteenn_X_train, smoteenn_y_train.ravel())\n\n# Make Predictions\nsmoteenn_lm_pred=smoteenn_lm_model.predict(X_test)\n\n# Calculate Accuracy, Precision, Recall, and F1 score\nsmoteenn_lm_accuracy = accuracy_score(y_test, smoteenn_lm_pred)\nsmoteenn_lm_precision = precision_score(y_test, smoteenn_lm_pred)\nsmoteenn_lm_recall = recall_score(y_test, smoteenn_lm_pred)\nsmoteenn_lm_f1 = 2 * (smoteenn_lm_precision * smoteenn_lm_recall) / (smoteenn_lm_precision + smoteenn_lm_recall)\n\n# Calculate AUC score\nsmoteenn_lm_probs = smoteenn_lm.predict_proba(X_test)\nsmoteenn_lm_probs = smoteenn_lm_probs[:,1]\nsmoteenn_lm_auc = roc_auc_score(y_test, smoteenn_lm_probs)\n\n# Display the metrics\nprint(\"Logistic Regression: SMOTE-ENN\")\nprint(\" - Accuracy : \",'{:.3f}'.format(smoteenn_lm_accuracy))\nprint(\" - Precision: \",'{:.3f}'.format(smoteenn_lm_precision))\nprint(\" - Recall   : \",'{:.3f}'.format(smoteenn_lm_recall))\nprint(\" - F1 score : \",'{:.3f}'.format(smoteenn_lm_f1))\nprint(\" - AUC score: \",'{:.3f}'.format(smoteenn_lm_auc))\n\n# Display the confusion matrix\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_test,smoteenn_lm_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5.2. KNN with SMOTE-ENN"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initiate the model\nsmoteenn_knn = KNeighborsClassifier()\n\n# Fit the model\nsmoteenn_knn_model = smoteenn_knn.fit(smoteenn_X_train, smoteenn_y_train.ravel())\n\n# Make Predictions\nsmoteenn_knn_pred=smoteenn_knn_model.predict(X_test)\n\n# Calculate Accuracy, Precision, Recall, and F1 score\nsmoteenn_knn_accuracy = accuracy_score(y_test, smoteenn_knn_pred)\nsmoteenn_knn_precision = precision_score(y_test, smoteenn_knn_pred)\nsmoteenn_knn_recall = recall_score(y_test, smoteenn_knn_pred)\nsmoteenn_knn_f1 = 2 * (smoteenn_knn_precision * smoteenn_knn_recall) / (smoteenn_knn_precision + smoteenn_knn_recall)\n\n# Calculate AUC score\nsmoteenn_knn_probs = smoteenn_knn.predict_proba(X_test)\nsmoteenn_knn_probs = smoteenn_knn_probs[:,1]\nsmoteenn_knn_auc = roc_auc_score(y_test, smoteenn_knn_probs)\n\n# Display the metrics\nprint(\"KNN Classifier: SMOTE-ENN\")\nprint(\" - Accuracy : \",'{:.3f}'.format(smoteenn_knn_accuracy))\nprint(\" - Precision: \",'{:.3f}'.format(smoteenn_knn_precision))\nprint(\" - Recall   : \",'{:.3f}'.format(smoteenn_knn_recall))\nprint(\" - F1 score : \",'{:.3f}'.format(smoteenn_knn_f1))\nprint(\" - AUC score: \",'{:.3f}'.format(smoteenn_knn_auc))\n\n# Display the confusion matrix\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_test,smoteenn_knn_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5.3. SVM Classifier with SMOTE-ENN"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initiate the model\nsmoteenn_svc = SVC(kernel='rbf',probability=True)\n\n# Fit the model\nsmoteenn_svc_model = smoteenn_svc.fit(smoteenn_X_train, smoteenn_y_train.ravel())\n\n# Make Predictions\nsmoteenn_svc_pred=smoteenn_svc_model.predict(X_test)\n\n# Calculate Accuracy, Precision, Recall, and F1 score\nsmoteenn_svc_accuracy = accuracy_score(y_test, smoteenn_svc_pred)\nsmoteenn_svc_precision = precision_score(y_test, smoteenn_svc_pred)\nsmoteenn_svc_recall = recall_score(y_test, smoteenn_svc_pred)\nsmoteenn_svc_f1 = 2 * (smoteenn_svc_precision * smoteenn_svc_recall) / (smoteenn_svc_precision + smoteenn_svc_recall)\n\n# Calculate AUC score\nsmoteenn_svc_probs = smoteenn_svc.predict_proba(X_test)\nsmoteenn_svc_probs = smoteenn_svc_probs[:,1]\nsmoteenn_svc_auc = roc_auc_score(y_test, smoteenn_svc_probs)\n\n# Display the metrics\nprint(\"SVM Classifier: SMOTE-ENN\")\nprint(\" - Accuracy : \",'{:.3f}'.format(smoteenn_svc_accuracy))\nprint(\" - Precision: \",'{:.3f}'.format(smoteenn_svc_precision))\nprint(\" - Recall   : \",'{:.3f}'.format(smoteenn_svc_recall))\nprint(\" - F1 score : \",'{:.3f}'.format(smoteenn_svc_f1))\nprint(\" - AUC score: \",'{:.3f}'.format(smoteenn_svc_auc))\n\n# Display the confusion matrix\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_test,smoteenn_svc_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5.4. Decision Tree Classifier with SMOTE-ENN"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initiate the model\nsmoteenn_tree = DecisionTreeClassifier()\n\n# Fit the model\nsmoteenn_tree_model = smoteenn_tree.fit(smoteenn_X_train, smoteenn_y_train.ravel())\n\n# Make Predictions\nsmoteenn_tree_pred=smoteenn_tree_model.predict(X_test)\n\n# Calculate Accuracy, Precision, Recall, and F1 score\nsmoteenn_tree_accuracy = accuracy_score(y_test, smoteenn_tree_pred)\nsmoteenn_tree_precision = precision_score(y_test, smoteenn_tree_pred)\nsmoteenn_tree_recall = recall_score(y_test, smoteenn_tree_pred)\nsmoteenn_tree_f1 = 2 * (smoteenn_tree_precision * smoteenn_tree_recall) / (smoteenn_tree_precision + smoteenn_tree_recall)\n\n# Calculate AUC score\nsmoteenn_tree_probs = smoteenn_tree.predict_proba(X_test)\nsmoteenn_tree_probs = smoteenn_tree_probs[:,1]\nsmoteenn_tree_auc = roc_auc_score(y_test, smoteenn_tree_probs)\n\n# Display the metrics\nprint(\"Decision Tree Classifier: SMOTE-ENN\")\nprint(\" - Accuracy : \",'{:.3f}'.format(smoteenn_tree_accuracy))\nprint(\" - Precision: \",'{:.3f}'.format(smoteenn_tree_precision))\nprint(\" - Recall   : \",'{:.3f}'.format(smoteenn_tree_recall))\nprint(\" - F1 score : \",'{:.3f}'.format(smoteenn_tree_f1))\nprint(\" - AUC score: \",'{:.3f}'.format(smoteenn_tree_auc))\n\n# Display the confusion matrix\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_test,smoteenn_tree_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5.5. Random Forest Classifier with SMOTE-ENN"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initiate the model\nsmoteenn_rfc = RandomForestClassifier()\n\n# Fit the model\nsmoteenn_rfc_model = smoteenn_rfc.fit(smoteenn_X_train, smoteenn_y_train.ravel())\n\n# Make Predictions\nsmoteenn_rfc_pred = smoteenn_rfc_model.predict(X_test)\n\n# Calculate Accuracy, Precision, Recall, and F1 score\nsmoteenn_rfc_accuracy = accuracy_score(y_test, smoteenn_rfc_pred)\nsmoteenn_rfc_precision = precision_score(y_test, smoteenn_rfc_pred)\nsmoteenn_rfc_recall = recall_score(y_test, smoteenn_rfc_pred)\nsmoteenn_rfc_f1 = 2 * (smoteenn_rfc_precision * smoteenn_rfc_recall) / (smoteenn_rfc_precision + smoteenn_rfc_recall)\n\n# Calculate AUC score\nsmoteenn_rfc_probs = smoteenn_rfc.predict_proba(X_test)\nsmoteenn_rfc_probs = smoteenn_rfc_probs[:,1]\nsmoteenn_rfc_auc = roc_auc_score(y_test, smoteenn_rfc_probs)\n\n# Display the metrics\nprint(\"Random Forest Classifier: SMOTE-ENN\")\nprint(\" - Accuracy : \",'{:.3f}'.format(smoteenn_rfc_accuracy))\nprint(\" - Precision: \",'{:.3f}'.format(smoteenn_rfc_precision))\nprint(\" - Recall   : \",'{:.3f}'.format(smoteenn_rfc_recall))\nprint(\" - F1 score : \",'{:.3f}'.format(smoteenn_rfc_f1))\nprint(\" - AUC score: \",'{:.3f}'.format(smoteenn_rfc_auc))\n\n# Display the confusion matrix\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_test,smoteenn_rfc_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5.6. AdaBoost with SMOTE-ENN"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initiate the model\nsmoteenn_adb = AdaBoostClassifier()\n\n# Fit the model\nsmoteenn_adb_model = smoteenn_adb.fit(smoteenn_X_train, smoteenn_y_train.ravel())\n\n# Make Predictions\nsmoteenn_adb_pred = smoteenn_adb_model.predict(X_test)\n\n# Calculate Accuracy, Precision, Recall, and F1 score\nsmoteenn_adb_accuracy = accuracy_score(y_test, smoteenn_adb_pred)\nsmoteenn_adb_precision = precision_score(y_test, smoteenn_adb_pred)\nsmoteenn_adb_recall = recall_score(y_test, smoteenn_adb_pred)\nsmoteenn_adb_f1 = 2 * (smoteenn_adb_precision * smoteenn_adb_recall) / (smoteenn_adb_precision + smoteenn_adb_recall)\n\n# Calculate AUC score\nsmoteenn_adb_probs = smoteenn_adb.predict_proba(X_test)\nsmoteenn_adb_probs = smoteenn_adb_probs[:,1]\nsmoteenn_adb_auc = roc_auc_score(y_test, smoteenn_adb_probs)\n\n# Display the metrics\nprint(\"AdaBoost Classifier: SMOTE-ENN\")\nprint(\" - Accuracy : \",'{:.3f}'.format(smoteenn_adb_accuracy))\nprint(\" - Precision: \",'{:.3f}'.format(smoteenn_adb_precision))\nprint(\" - Recall   : \",'{:.3f}'.format(smoteenn_adb_recall))\nprint(\" - F1 score : \",'{:.3f}'.format(smoteenn_adb_f1))\nprint(\" - AUC score: \",'{:.3f}'.format(smoteenn_adb_auc))\n\n# Display the confusion matrix\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_test,smoteenn_adb_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5.7. XGBoost Classifier with SMOTE-ENN"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initiate the model\nsmoteenn_xgb = XGBClassifier()\n# Fit the model\nsmoteenn_xgb_model =smoteenn_xgb.fit(smoteenn_X_train, smoteenn_y_train.ravel())\n# Make Predictions\nsmoteenn_xgb_pred = smoteenn_xgb_model.predict(X_test)\n\n# Calculate Accuracy, Precision, Recall, and F1 score\nsmoteenn_xgb_accuracy = accuracy_score(y_test, smoteenn_xgb_pred)\nsmoteenn_xgb_precision = precision_score(y_test, smoteenn_xgb_pred)\nsmoteenn_xgb_recall = recall_score(y_test, smoteenn_xgb_pred)\nsmoteenn_xgb_f1 = 2 * (smoteenn_xgb_precision * smoteenn_xgb_recall) / (smoteenn_xgb_precision + smoteenn_xgb_recall)\n\n# Calculate AUC score\nsmoteenn_xgb_probs = smoteenn_xgb.predict_proba(X_test)\nsmoteenn_xgb_probs = smoteenn_xgb_probs[:,1]\nsmoteenn_xgb_auc = roc_auc_score(y_test, smoteenn_xgb_probs)\n\n# Display the metrics\nprint(\"XGB Classifier: SMOTEENN\")\nprint(\" - Accuracy: \", smoteenn_xgb_accuracy)\nprint(\" - Precision: \", smoteenn_xgb_precision)\nprint(\" - Recall: \", smoteenn_xgb_recall)\nprint(\" - F1 score: \", smoteenn_xgb_f1)\nprint(\" - AUC score: \", smoteenn_xgb_auc)\n\n# Display the confusion matrix\nprint(confusion_matrix(y_test,smoteenn_xgb_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6. Summary of Results"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create Results Table: Accuracy \npd.options.display.float_format = '{:.3f}'.format\n\nacc_list = [\n    [base_lm_accuracy, base_knn_accuracy, base_svc_accuracy, base_tree_accuracy, base_rfc_accuracy,\n     base_adb_accuracy, base_xgb_accuracy],\n    [smote_lm_accuracy, smote_knn_accuracy, smote_svc_accuracy, smote_tree_accuracy, smote_rfc_accuracy,\n     smote_adb_accuracy, smote_xgb_accuracy],\n    [smoteenn_lm_accuracy, smoteenn_knn_accuracy, smoteenn_svc_accuracy, smoteenn_tree_accuracy, \n     smoteenn_rfc_accuracy,smoteenn_adb_accuracy, smoteenn_xgb_accuracy]]\n\nacc_df = pd.DataFrame(acc_list)\nacc_df.index = ['BASE','SMOTE','SMOTE-ENN']\nacc_df.columns = ['Logistic Regression','KNN','SVM','Decision Tree','Random Forest','AdaBoost','XGBoost']   \n\n# Create Results Table: Recall\nrec_list = [\n    [base_lm_recall, base_knn_recall, base_svc_recall, base_tree_recall, base_rfc_recall,\n     base_adb_recall, base_xgb_recall],\n    [smote_lm_recall, smote_knn_recall, smote_svc_recall, smote_tree_recall, smote_rfc_recall,\n     smote_adb_recall, smote_xgb_recall],\n    [smoteenn_lm_recall, smoteenn_knn_recall, smoteenn_svc_recall, smoteenn_tree_recall, \n     smoteenn_rfc_recall,smoteenn_adb_recall, smoteenn_xgb_recall]]\n\nrec_df = pd.DataFrame(rec_list)\nrec_df.index = ['BASE','SMOTE','SMOTE-ENN']\nrec_df.columns = ['Logistic Regression','KNN','SVM','Decision Tree','Random Forest','AdaBoost','XGBoost']\n\n# Create Results Table: F1\nf1_list = [\n    [base_lm_f1, base_knn_f1, base_svc_f1, base_tree_f1, base_rfc_f1,base_adb_f1, base_xgb_f1],\n    [smote_lm_f1, smote_knn_f1, smote_svc_f1, smote_tree_f1, smote_rfc_f1,smote_adb_f1, smote_xgb_f1],\n    [smoteenn_lm_f1, smoteenn_knn_f1, smoteenn_svc_f1, smoteenn_tree_f1,smoteenn_rfc_f1,smoteenn_adb_f1, \n     smoteenn_xgb_f1]]\n\nf1_df = pd.DataFrame(f1_list)\nf1_df.index = ['BASE','SMOTE','SMOTE-ENN']\nf1_df.columns = ['Logistic Regression','KNN','SVM','Decision Tree','Random Forest','AdaBoost','XGBoost']\n\n# Create Results Table: AUC\nauc_list = [\n    [base_lm_auc, base_knn_auc, base_svc_auc, base_tree_auc, base_rfc_auc,base_adb_auc, base_xgb_auc],\n    [smote_lm_auc, smote_knn_auc, smote_svc_auc, smote_tree_auc, smote_rfc_auc,smote_adb_auc, smote_xgb_auc],\n    [smoteenn_lm_auc, smoteenn_knn_auc, smoteenn_svc_auc, smoteenn_tree_auc,smoteenn_rfc_auc,smoteenn_adb_auc, \n     smoteenn_xgb_auc]]\n\nauc_df = pd.DataFrame(auc_list)\nauc_df.index = ['BASE','SMOTE','SMOTE-ENN']\nauc_df.columns = ['Logistic Regression','KNN','SVM','Decision Tree','Random Forest','AdaBoost','XGBoost']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Accuracy\")\nacc_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Recall\")\nrec_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"F1 score\")\nf1_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"AUC\")\nauc_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Baseline model achieved the highest performance.\n- Among them, XGBoost achieve the highest performance. AUC score = 0.994"},{"metadata":{},"cell_type":"markdown","source":"## ROC Curve"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import the library for ROC curve.\nfrom sklearn.metrics import roc_curve, roc_auc_score\n\nns_probs = [0 for _ in range(len(y_test))]\n\nprob_lm = base_lm_model.predict_proba(X_test)\nprob_lm = prob_lm[:,1]\n\nprob_knn = base_knn_model.predict_proba(X_test)\nprob_knn = prob_knn[:,1]\n\nprob_svc = base_svc_model.predict_proba(X_test)\nprob_svc = prob_svc[:,1]\n\nprob_tree = base_tree_model.predict_proba(X_test)\nprob_tree = prob_tree[:,1]\n\nprob_rfc = base_rfc_model.predict_proba(X_test)\nprob_rfc = prob_rfc[:,1]\n\nprob_adb = base_adb_model.predict_proba(X_test)\nprob_adb = prob_adb[:,1]\n\nprob_xgb = base_xgb_model.predict_proba(X_test)\nprob_xgb = prob_xgb[:,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\nlm_fpr, lm_tpr, _ = roc_curve(y_test, prob_lm)\nknn_fpr, knn_tpr, _ = roc_curve(y_test, prob_knn)\nsvc_fpr, svc_tpr, _ = roc_curve(y_test, prob_svc)\ntree_fpr, tree_tpr, _ = roc_curve(y_test, prob_tree)\nrfc_fpr, rfc_tpr, _ = roc_curve(y_test, prob_rfc)\nadb_fpr, adb_tpr, _ = roc_curve(y_test, prob_adb)\nxgb_fpr, xgb_tpr, _ = roc_curve(y_test, prob_xgb)\n\nplt.figure(figsize=(8, 6))\nplt.plot(ns_fpr, ns_tpr, linestyle='--', label='Based on Majority')\nplt.plot(lm_fpr, lm_tpr, marker='.', label='Logistic')\nplt.plot(knn_fpr, knn_tpr, marker='.', label='KNN')\nplt.plot(svc_fpr, svc_tpr, marker='.', label='SVM')\nplt.plot(tree_fpr, tree_tpr, marker='.', label='Decision Tree')\nplt.plot(rfc_fpr, rfc_tpr, marker='.', label='Random Forest')\nplt.plot(adb_fpr, adb_tpr, marker='.', label='AdaBoost')\nplt.plot(xgb_fpr, xgb_tpr, marker='.', label='XGBoost')\n\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\n\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}