{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Deep Art Challenge - part 1 - The Bob Ross DCGAN\nAI Impact Lab, Ã–rebro University\n\n## This is a Jupyter Notebook\n\nA Jupyter Notebook is a great tool for creating interactive code tutorials. Runnable code is mixed with instructive text and explanations of what's going on. Put the mouse cursor in a code cell and press the play button to the left, or Ctrl-Enter, to execute it. An asterisc will be shown to the left of the cell when it is running. When finished it will show a sequenced number. If the code generates any output it will be shown below the code cell. Output can be anything from text and error reports to images, movies, and other media.\n\n## Enable GPU support\n\nTraining a neural network involves heavy matrix computation. Using a GPU for this will speed up the process compared to using a regular CPU. On Kaggle you have 30 hours free GPU access per month. This is how you enable it:\n\n* Find *Settings* in the sidebar.\n* Select GPU as *Accelerator*. (Requires phone verification by SMS.)\n* Wait for Kaggle to reconfigure and restart your session.\n\n## Train your DCGAN\n\nCompleting this part of the challange is as easy as to run all code cells one by one. You can stop execution at any time by clicking *Cancel run* in the upper toolbar. If you get errors complaining about full disc space, you can start fresh by restarting the session by clicking the rotating arrows button in the toolbar. Don't be afraid to changing hyperparameters or tweaking the code to try and improve your results. You can always start anew by saving a new copy of the project template if you end up with lots of errors and can't find your way back to a working application.\n\nGood luck!","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 1. Application setup\n\nTo make this notebook easier to read, most code has been put in a module called *dcgan*, that we import to the project. Implementation details has been abstracted away since they are beyond the scope of this challenge. But if you know a little Python you are more than welcome to take a look at the code to see what's going on under the hood. The implementation is far from optimal and you are more than welcome to improve it.\n\nWe also define a file path to where our image data is. You can find this folder in the sidebar.","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from dcgan import DCGAN\n\nIMAGE_DIR = \"../input/segmented-bob-ross-images/train/images\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. Define hyperparameters\n\nIn machine learning we separate parameters from hyperparameters. Hyperparameters are all parameters that are set before starting the training process. The other parameters or weights are learnt automatically in the training process. Different settings of the hyperparameters can make a huge effect on the outcome of the training.","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"hyperparameters = {\n    \"leaky_relu_slope\": 0.0,\n    \"dropout_rate\": 0.0,\n    \"weight_init_std\": 0.5,\n    \"weight_init_mean\": 0.0,\n    \"learning_rate_initial_discriminator\": 0.0,\n    \"learning_rate_initial_generator\": 0.0,\n    \"noise_array_dimensions\": 50,\n    \"batch_size\": 16,\n    \"label_smoothing\": False,\n    \"label_noise\": False\n}\ndcgan = DCGAN(hyperparameters)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3. Create training dataset\n\nThe images in the input folder are preprocessed and stored in a binary format that the training algorithm can work efficiently with. Each image is also downsampled to 64 by 64 pixels to reduce the training time. This code cell should output a few example images from the training dataset. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = dcgan.create_dataset(IMAGE_DIR)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4. Generator and Discriminator\n\nThe DCGAN architecture is basically two neural networks competing against each other in the training process. The discriminator takes an image as input and is trained to predict if the image is real or fake. Real in this case means being part of the dataset we trained the model on. The generator takes some noise as input and is trained to fool the discriminator by generating images that resemble the images of the training dataset to a level that the discriminator can not tell them apart from real images.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"generator = dcgan.build_generator()\ndiscriminator = dcgan.build_discriminator()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 5. The training process\n\nTo start training we pass the dataset, generator and discriminator to the *train* function. We also specify how many epochs we want the process to repeat, and we tell it to plot and display generated images for every x epoch. Doing this at every iteration would soon fill the disc space we are allowed to use on Kaggle.\n\nWhen training starts both networks are equally bad. The discriminator predictions will be random and the generator will produce random noise images. As the training goes on both networks should become better at their tasks because the results are fed back in the training loop and progress in the generator should trigger progress in the discriminator and vice versa.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dcgan.train(\n    dataset,\n    generator, \n    discriminator,\n    epochs=5000,\n    save_every_x_results=100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 6. Evaluating trainging progress\n\nAs you can see in the output above, each training epoch runs for a few seconds (at least for the initial configuration). For each epoch a *loss* value is computed for both the generator and discriminator. This value is a measure of how far off from the truth the network is when making a prediction. A lower value means the prediction is better. The loss value is what is fed back from one iteration to the next to enable learning of the neural network weights. The loss value is fed into an *optimizer* function that calculates how the weights should be adjusted for the network to improve. How the optimizer works is beyond the scope of this excercise. The loss values are easier to reason about here. If you are able to run a successfull training session for long enough, you will see in the *All epochs loss* graph how the loss values go up and down all the time but starts stabilizing at different levels after some number of iterations. When training for example an image object detection network for detecting different animals, you will see the loss value decrease to a more stable low number, with less variance. But when training a GAN the loss values will keep fluctuating. This is because the generator and discriminator keep competing and influencing each others loss function.\n\nHow do you know training is complete? You don't! You'll have to watch the output and decide when you think the results stop improving. You should also interupt training if the DCGAN doesn't seem to learn anything and the generator keeps generating random noise images.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 7. Try different hyperparameters\n\nNow go back to the code cell where we defined hyperparameters. Change some values, run all code cells again, and see if you can improve the results. There are plenty articles on the web that can guide you to hyperparameter settings for stable training of a DCGAN. If you know Python programming you can make a copy of the dcgan utility script and see if you can do any changes to the code to improve your results.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}