{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Gender recognition using Tensorflow v2 and InceptionV3 on entire dataset\n### Inspiration\nI have copied this notebook from [Marcos Alvarado's notebook](https://www.kaggle.com/bmarcos/image-recognition-gender-detection-inceptionv3) and adapted it to work on the entire dataset, and tensorflow v2. \n**Note:** I've removed some of the details from the original notebook, so I recommend the read. \n\n### Dataset\nThe dataset is available [here](https://www.kaggle.com/jessicali9530/celeba-dataset) and contains:\n- 202,599 number of face images of various celebrities\n- 10,177 unique identities, but names of identities are not given\n- 40 binary attribute annotations per image\n- 5 landmark locations\n\n### Modelling and structure\n\n#### Transfer learning with InceptionV3\nI am using a pretrained Inception V3 model for which I will retrain some layers and fix the first layers. I will also attach new output layers to perform the new classification task. \n\n#### Target variable\nAs my target variable, I only use the gender feature available in the dataset and detect if the image shows a man or a woman.\n\n#### Training on the entire dataset\nI use keras' ImageDataGenerator and flow_from_dataframe to avoid loading all images in memory and fit the model on the entire dataset. The process goes this way:\n##### Training\nI augment data using the image generator and then fit the model using the generator:\n```python\ntrain_datagen =  ImageDataGenerator(\n  preprocessing_function=preprocess_input,\n  rotation_range=30,\n  width_shift_range=0.2,\n  height_shift_range=0.2,\n  shear_range=0.2,\n  zoom_range=0.2,\n  horizontal_flip=True,\n  #brightness_range=[0.4,1.5],\n  rescale=1./255,\n)\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    df_train,\n    batch_size=20,\n    x_col=\"image_id\", \n    y_col=\"gender\",\n    class_mode=\"binary\",\n    image_size=(IMG_WIDTH, IMG_HEIGHT),\n    validate_filenames=False)\n```\nThe model can then be fitted on the generator:\n```python\nmodel.fit(train_generator,\n          validation_data=valid_generator,\n          steps_per_epoch=len(df_train)//BATCH_SIZE,\n          validation_steps=len(df_valid) // BATCH_SIZE,\n          epochs=NUM_EPOCHS,\n          callbacks=[checkpointer],\n          verbose=1)\n```\n##### Testing\nThe same process takes place, but I do not augment data, and **make sure suffle is set to False**. I also set validate_filenames to False to save some time.\n```python\ntest_datagen =  ImageDataGenerator(\n  preprocessing_function=preprocess_input,\n  rescale=1./255,\n)\n\ntest_generator = test_datagen.flow_from_dataframe(\n    df_test,\n    batch_size=20,\n    x_col=\"image_id\", \n    y_col=\"gender\",\n    class_mode=\"raw\",\n    image_size=(IMG_WIDTH, IMG_HEIGHT),\n    validate_filenames=False,\n    shuffle=False)\n```\nPredictions can then be generated using this generator:\n```python\nmodel_predictions = model_.predict(test_generator, steps=len(df_test))\n```\n\n##### Generating new predictions\nWe could make batch predictions using the testing generator that I defined previously (and I include a function for this in this notebook). However, it can also be useful to re-create the same preprocessing to generate predictions without it. I have recreated the behavior this way:\n```python\nimg = image.load_img(path, target_size=(256, 256))  # Keras function\nimg = image.img_to_array(img)\nimg = np.expand_dims(img, axis=0)\nimg = np.vstack([img])\nimg = preprocess_input(img) # Keras function \nimg = img / 255\n```\nThis is the same preprocessing the generator performs and will yield the same results when making the predictions. \n\n### Inception V3\nThe inception model is available from Keras ([here](https://keras.io/api/applications/inceptionv3/)) and its pre-trained version is either available for download when initializing:\n```python\ninc_model = InceptionV3(weights=\"imagenet\",\n                        include_top=False,\n                        input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n```\nOr by connecting the notebook to [this Kaggle dataset](https://www.kaggle.com/keras/inceptionv3) containing the weights:\n```python\ninc_model = InceptionV3(weights=\"../input/inceptionv3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\",\n                        include_top=False,\n                        input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n```\n\n## The code\n\n ### Required libraries:\n - cv2\n - sklearn\n - tensorflow (v2)\n - keras\n - PIL\n - pandas\n - numpy\n - matplotlib\n - seaborn\n \n #### Imports"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\n\nimport pandas as pd\nimport numpy as np\nimport cv2    \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import accuracy_score\n\nfrom keras.applications.inception_v3 import InceptionV3, preprocess_input\nfrom keras import optimizers\nfrom keras.models import Sequential, Model \nfrom keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\nfrom keras.utils import np_utils\nfrom keras.preprocessing import image\n\nfrom IPython.core.display import display, HTML\nfrom PIL import Image\nfrom io import BytesIO\nimport base64\n\nimport tensorflow as tf\nprint(f\"Built using tensorflow version {tf.__version__}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Variables\nSetting the image folder, image properties and training parameters."},{"metadata":{"trusted":true},"cell_type":"code","source":"# set variables \nmain_folder = \"../input/celeba-dataset\"\nimages_folder = os.path.join(main_folder, 'img_align_celeba', 'img_align_celeba')\n\nIMG_WIDTH = 178\nIMG_HEIGHT = 218\nBATCH_SIZE = 128\nNUM_EPOCHS = 10","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Importing the data\nHere I read and process the dataframe containing the features and the filename they correspond to. Note that it does not contain the image, and actually reading the image will be handled by the keras generator (flow_from_dataframe). "},{"metadata":{"trusted":true},"cell_type":"code","source":"df_imgs = pd.read_csv(os.path.join(main_folder, 'list_attr_celeba.csv'), usecols=[\"image_id\", \"Male\"])  \ndf_imgs.replace(to_replace={\"Male\": -1}, value=\"Female\", inplace=True)\ndf_imgs.replace(to_replace={\"Male\": 1}, value=\"Male\", inplace=True)\ndf_imgs.rename(columns={\"Male\": \"gender\"}, inplace=True)\ndf_imgs.head() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Partitioning data into train, valid and test\nI will use:\n- train: training data, will be augmented \n- valid: validation data during training. We will save the model that performs the best on the valid dataset\n- test: once I have the best model according to train and valid, I verify the results on the test dataset.\n\n#### Class distribution\nThe dataset is slightly imbalanced."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Female or Male?\nplt.title('Female or Male')\nsns.countplot(y='gender', data=df_imgs, color=\"c\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Dataset recommended partition\nThe dataset provides us with the following partition:\n- 0: train\n- 1: valid\n- 2: test"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_partition = pd.read_csv(os.path.join(main_folder, 'list_eval_partition.csv'))\ndf_partition.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_partition['partition'].value_counts().sort_index()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Joining the partition with the dataframe containing the labels\nAnd changing image_id to be the image path, so flow_from_dataframe will read the images from there. We could skip that path appending step and provide a directory when flowing from dataframe."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_imgs = df_imgs.merge(df_partition, on=\"image_id\")\ndf_imgs.loc[:, \"image_id\"] = df_imgs.loc[:, \"image_id\"].apply(lambda x: os.path.join(images_folder, x))\ndf_imgs.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Creating the train, valid and test dataframes \nThey will all point to the relevant image and contain the label (\"Male\" or \"Female\")."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = df_imgs.loc[df_imgs.loc[:, \"partition\"] == 0, \n                      [\"image_id\", \"gender\"]]\ndf_valid = df_imgs.loc[df_imgs.loc[:, \"partition\"] == 1, \n                      [\"image_id\", \"gender\"]]\ndf_test = df_imgs.loc[df_imgs.loc[:, \"partition\"] == 2, \n                      [\"image_id\", \"gender\"]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Augmentation\n#### Demonstration \nThe following code uses the image generator and flow_from_dataframe methods to load images from a dataframe (I recommend loading only one though) and displays 10 generated images.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Generate image generator for data augmentation\ndatagen =  ImageDataGenerator(\n  rotation_range=30,\n  width_shift_range=0.2,\n  height_shift_range=0.2,\n  shear_range=0.2,\n  zoom_range=0.2,\n  horizontal_flip=True,\n  rescale=1./255,\n    \n)\n\n# load one image and reshape\ndef display_image(img: pd.DataFrame) -> None:\n    \"\"\"\"\"\"\n\n    # plot 10 augmented images of the loaded image\n    plt.figure(figsize=(20,10))\n    plt.suptitle('Data Augmentation', fontsize=28)\n\n    i = 0\n    for batch in datagen.flow_from_dataframe(img,\n                                             batch_size=1,\n                                             x_col=\"image_id\", \n                                             y_col=\"gender\",\n                                             class_mode=\"raw\",\n                                             image_size=(IMG_WIDTH, IMG_HEIGHT)):\n        batch_image = batch[0]\n        batch_label = batch[1]\n        plt.subplot(3, 5, i+1)\n        plt.grid(False)\n        plt.imshow(batch_image.reshape(256,256, 3))\n        \n        if i == 9:\n            break\n        i += 1\n    print(f\"Label: {batch_label}\")\n    plt.show()\n\ndisplay_image(df_imgs.loc[:0, :])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Create the train and valid data generators\n\n#### The training data needs to be augmented"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train - Data Preparation - Data Augmentation with generators\ntrain_datagen =  ImageDataGenerator(\n  preprocessing_function=preprocess_input,\n  rotation_range=30,\n  width_shift_range=0.2,\n  height_shift_range=0.2,\n  shear_range=0.2,\n  zoom_range=0.2,\n  horizontal_flip=True,\n  #brightness_range=[0.4,1.5],\n  rescale=1./255,\n)\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    df_train,\n    batch_size=20,\n    x_col=\"image_id\", \n    y_col=\"gender\",\n    class_mode=\"binary\",\n    image_size=(IMG_WIDTH, IMG_HEIGHT),\n    validate_filenames=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Test data isn't augmented \nWe don't need to provide suffle=False as labels will match the image during training. If we were using this for prediction, we would only pass the images (no labels) and the model would not output the images im the same order. So make sure shuffle is set to False when generating predictions."},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_datagen =  ImageDataGenerator(\n  preprocessing_function=preprocess_input,\n  rescale=1./255,\n)\n\nvalid_generator = valid_datagen.flow_from_dataframe(\n    df_valid,\n    batch_size=20,\n    x_col=\"image_id\", \n    y_col=\"gender\",\n    class_mode=\"binary\",\n    image_size=(IMG_WIDTH, IMG_HEIGHT),\n    validate_filenames=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Creating the model\n#### Pretrained model\nI'm using InceptionV3 pretrained on the imagenet dataset. This code will automatically download the weights. \n\n#### Setting the initial layers to be non trainable\nTraining all layers could lead to overfitting, and training none will result in underfitting (as the image representation will not be tuned). Training 52 layers seems to work well.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import InceptionV3 Model\ninc_model = InceptionV3(weights=\"imagenet\",\n                        include_top=False,\n                        input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n\nprint(\"number of layers:\", len(inc_model.layers))\n# Lock initial layers to do not be trained\nfor layer in inc_model.layers[:52]:\n    layer.trainable = False","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Connecting the representation layers to the classification layers"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Adding custom Layers\nx = inc_model.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(1024, activation=\"relu\")(x)\nx = Dropout(0.5)(x)\nx = Dense(512, activation=\"relu\")(x)\npredictions = Dense(1, activation=\"sigmoid\")(x)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Final model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating the final model \nmodel_ = Model(inputs=inc_model.input, outputs=predictions)\n\n# compile the model\nmodel_.compile(optimizer=\"adam\", \n               loss='binary_crossentropy', \n               metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Making sure we use the best model from training according to its performance on the valid set"},{"metadata":{"trusted":true},"cell_type":"code","source":"#https://keras.io/models/sequential/ fit generator\ncheckpointer = ModelCheckpoint(filepath='weights.best.inc.male.hdf5', \n                               verbose=1, save_best_only=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Fit the model and plot training performance over time"},{"metadata":{"trusted":true},"cell_type":"code","source":"hist = model_.fit(train_generator,\n                  validation_data=valid_generator,\n                  steps_per_epoch=len(df_train)//BATCH_SIZE,\n                  validation_steps=len(df_valid) // BATCH_SIZE,\n                  epochs=NUM_EPOCHS,\n                  callbacks=[checkpointer],\n                  verbose=1\n                    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot loss function value through epochs\nplt.figure(figsize=(18, 4))\nplt.plot(hist.history['loss'], label = 'train')\nplt.plot(hist.history['val_loss'], label = 'valid')\nplt.legend()\nplt.title('Loss Function')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot accuracy through epochs\nplt.figure(figsize=(18, 4))\nplt.plot(hist.history['accuracy'], label = 'train')\nplt.plot(hist.history['val_accuracy'], label = 'valid')\nplt.legend()\nplt.title('Accuracy')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Select and use the best model from training according to the validation set"},{"metadata":{"trusted":true},"cell_type":"code","source":"#load the best model\nmodel_.load_weights('weights.best.inc.male.hdf5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Generating predictions\n#### Batch generating: using a generator\nNote that suffle is set to False. Sorry for insisting, I lost some time on that!"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_datagen =  ImageDataGenerator(\n  preprocessing_function=preprocess_input,\n  rescale=1./255,\n)\n\ntest_generator = test_datagen.flow_from_dataframe(\n    df_test,\n    batch_size=20,\n    x_col=\"image_id\", \n    y_col=\"gender\",\n    class_mode=\"raw\",\n    image_size=(IMG_WIDTH, IMG_HEIGHT),\n    validate_filenames=False,\n    shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# generate prediction\nmodel_predictions = model_.predict(test_generator, steps=len(df_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# report test accuracy\npreds = np.array(model_predictions > 0.5).astype(int)\ntest_accuracy = 100 * accuracy_score(preds, df_test.loc[:, \"gender\"].replace({\"Male\": 1, \"Female\": 0}).values)\nprint('Model Evaluation')\nprint('Test accuracy: %.4f%%' % test_accuracy)\nprint('f1_score:', f1_score(df_test.loc[:, \"gender\"].replace({\"Male\": 1, \"Female\": 0}).values, preds))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##Â Generating new predictions\nThis is highly inspired by Marcos' notebook\n- read_image: recreates the preprocessing done by the data generator (reads the image and preprocesses it)\n- display_result: displays the output nicely using html"},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_image(path: str) -> np.ndarray:\n    \"\"\"Replicates the image preprocessing from the data generator\"\"\"\n    # predicting images\n    img = image.load_img(path, target_size=(256, 256))\n    img = image.img_to_array(img)\n    img = np.expand_dims(img, axis=0)\n    img = np.vstack([img])\n    img = preprocess_input(img) # preprocess for our model input\n    return img / 255.\n\n\ndef img_to_display(filename: str):\n    \"\"\"\n    Reads a jpeg image. Goal is to display it nicely using html in the function below.\n    \n    (Copied from Marco's notebook, this is his note :) )\n    # inspired on this kernel:\n    # https://www.kaggle.com/stassl/displaying-inline-images-in-pandas-dataframe\n    # credits to stassl :)\n    \"\"\"\n    \n    i = Image.open(filename)\n    i.thumbnail((200, 200), Image.LANCZOS)\n    \n    with BytesIO() as buffer:\n        i.save(buffer, 'jpeg')\n        return base64.b64encode(buffer.getvalue()).decode()\n    \n\ndef display_result(filename: str, target: str) -> None:\n    \"\"\"\n    Display the results in HTML\n    \n    :param filename: path to the image\n    :param target: real label from that image\n    \"\"\"\n    gender = 'Male'\n    gender_icon = \"https://i.imgur.com/nxWan2u.png\"\n    \n    prediction = model_.predict(read_image(filename), steps=1).reshape(-1)\n    \n        \n    if prediction <= 0.5:\n        gender_icon = \"https://i.imgur.com/oAAb8rd.png\"\n        gender = 'Female'\n        prediction = 1 - prediction\n            \n    display_html = '''\n    <div style=\"overflow: auto;  border: 2px solid #D8D8D8;\n        padding: 5px; width: 420px;\" >\n        <img src=\"data:image/jpeg;base64,{}\" style=\"float: left;\" width=\"200\" height=\"200\">\n        <div style=\"padding: 10px 0px 0px 20px; overflow: auto;\">\n            <img src=\"{}\" style=\"float: left;\" width=\"40\" height=\"40\">\n            <h3 style=\"margin-left: 50px; margin-top: 2px;\">{}</h3>\n            <p style=\"margin-left: 50px; margin-top: -6px; font-size: 12px\">{} prob.</p>\n            <p style=\"margin-left: 50px; margin-top: -16px; font-size: 12px\">Real Target: {}</p>\n            <p style=\"margin-left: 50px; margin-top: -16px; font-size: 12px\">Filename: {}</p>\n        </div>\n    </div>\n    '''.format(img_to_display(filename)\n               , gender_icon\n               , gender\n               , \"{0:.2f}%\".format(np.round(max(prediction)*100,2))\n               , target\n               , filename.split('/')[-1]\n               )\n\n    display(HTML(display_html))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#select random images of the test partition\ndf_to_test = df_test.iloc[: 10, :]\n\nfor _, row in df_to_test.iterrows():\n    display_result(row[\"image_id\"], row[\"gender\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_.save(\"test_model_save.h5\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Additional code: batch prediction with flow from dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict(img: pd.DataFrame) -> np.ndarray:\n    \"\"\"\n    @param img: pandas DataFrame containing the image paths under image_id\n    \n    :return: numpy array with boolean predictions.\n    \"\"\"\n    datagen =  ImageDataGenerator(\n      rescale=1./255,\n      preprocessing_function=preprocess_input,\n\n    )\n\n    generator = datagen.flow_from_dataframe(img,\n                                            suffle=False,\n                                            batch_size=len(img),\n                                            x_col=\"image_id\", \n                                            class_mode=None,\n                                            image_size=(IMG_WIDTH, IMG_HEIGHT))\n    return model_.predict(generator, steps=len(img))\n\npredict(df_imgs.loc[:10]) >= 0.5","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}