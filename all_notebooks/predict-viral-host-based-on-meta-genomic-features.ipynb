{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Predicting Viral Host based on Metagenomic Features\n\nIn this notebook, metagenomic features taken from a viral genome are used to predict the type of virus host. The efficacy of these features is then evaluated. Genome size, GC%, and count of CDS from viral genomes are used as features to predict the viral host (target). SVM techniques are used to create a classifier that achieves 86% accuracy across this dataset. This notebook was created by Jeffrey Jeyachandren (github: JeffinWithYa) as the capstone project for the Udacity Machine Learning Engineer nanodegree. \n\nYou should note two things:\n* The dataset is taken from the viruses.csv file, please make sure it is in your directory.\n* The data contains metagenomic info from 7362 unique viral genomes and their known characteristics"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\nvirus_csv_file = '../input/genome-information-for-sequenced-organisms/viruses.csv'\nviruses_df = pd.read_csv(virus_csv_file)\nviruses_df.head(5)\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# clean up column names i.e. remove the erroneous characters from the column names (spaces, percent sign, etc.)\n\n# clean up column names https://stackoverflow.com/a/11346337/6542644 \nviruses_df.columns = ['organism_name', 'organism_groups', 'BioSample', 'Bioproject', 'Assembly', 'Level', 'size_mb', 'gc_percent', 'replicons', 'host', 'cds', 'neighbours', 'release_date', 'genbank_ftp', 'refseq_ftp', 'replicons1']\n\n# verify column names have been changed\nviruses_df.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Explore the data\n\n# .shape[0] gives the number of rows in the dataframe, which is the number of viral species in the dataset\nprint('Number of viruses: ', viruses_df.shape[0])\n\n# .unique gives the number of unique items in a specified column, in this case the number of viral hosts\nprint('Number of unique viral host types: ', (len(viruses_df['host'].unique())))\n\nviruses_df['host'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ohe_df = pd.get_dummies(viruses_df['host'], prefix='host')\nohe_df.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop columns we don't need \nvirus_feats_only = viruses_df.drop(['organism_name', 'organism_groups', 'BioSample', \n                                    'Bioproject', 'Assembly', 'Level', 'replicons', \n                                    'neighbours', 'release_date', 'genbank_ftp', 'refseq_ftp',\n                                   'replicons1'], axis=1)\n\n\n# create dict to map strings to numerical values, also combines overlapping hosts: vertebrates/human and human\nviruses_host_dict = {'bacteria': 0, 'fungi': 1, 'plants': 2, 'vertebrates': 3,\n                    'invertebrates': 4, 'protozoa': 5, 'vertebrates, invertebrates, human': 6,\n                    'invertebrates, plants': 7, 'algae': 8, 'vertebrates, invertebrates': 9,\n                    'vertebrates, human': 10, 'archaea': 11, 'human': 10}\n\n# replace method use cited from: https://stackoverflow.com/a/20250996/6542644 \nvirus_feats_cleanhost = virus_feats_only.replace({'host':viruses_host_dict})\n\nfirst_col = virus_feats_cleanhost.pop('host')\nvirus_feats_cleanhost.insert(0, 'host', first_col)\nvirus_feats_cleanhost.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check for NaN values in data\n\nprint(\"Count of NaN in host: \", virus_feats_cleanhost['host'].isnull().sum())\nprint(\"Count of NaN in Size_Mb: \", virus_feats_cleanhost['size_mb'].isnull().sum())\nprint(\"Count of NaN in GC_percent: \", virus_feats_cleanhost['gc_percent'].isnull().sum())\nprint(\"Count of NaN in cds: \", virus_feats_cleanhost['cds'].isnull().sum())\n\nviruses_dropped_nan = virus_feats_cleanhost.dropna()\n\n# count of NaN values in a column cited from: https://datatofish.com/check-nan-pandas-dataframe/\n\nprint(\"Count of NaN after dropna(): \", viruses_dropped_nan['host'].isnull().sum())\n\nviruses_dropped_nan.head(5)\ndisplay(viruses_dropped_nan)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Distribution of Data\n\nWe will look at the distribution of our viral hosts (target) and our features. Class imbalances may affect our results. Here we ask: **How evenly is our data distributed among different meta-genomic features and viral hosts?**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check distribution of viral hosts\ncounts_host2 = viruses_dropped_nan.copy()\ncounts_host_unique = counts_host2.groupby(['host']).size().reset_index(name='Counts')\n\ncounts_host_unique","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot distribution of viral hosts\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\ngroup = ['host']\ncounts = viruses_dropped_nan.groupby(group).size().reset_index(name=\"Counts\")\n\n# use of plt cited from: https://python-graph-gallery.com/4-add-title-and-axis-label/\nbars = ('bact', 'fungi', 'plants', 'verts', 'inverts',\n        'pro', 'v/i/hum',\n        'i/plants', 'algae', 'v/i',\n        'v/hum', 'archaea')\ny_pos = np.arange(len(bars))\n\n#plt.title('Distribution of Unique Host Types')\nplt.figure(figsize=(10,8))\nplt.bar(range(len(counts)), counts['Counts'], color = 'blue')\nplt.title('Distribution of Viral Hosts')\nplt.xlabel('Viral Hosts')\nplt.ylabel('Count')\nplt.xticks(y_pos, bars)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get stats for viral genome size (size_mb) and plot distribution\n\nprint('Number of unique size values: ', (len(viruses_dropped_nan['size_mb'].unique())))\n\nprint(viruses_dropped_nan.size_mb.describe())\n\nprint(\"mode of Size_Mb is: \", viruses_dropped_nan['size_mb'].mode())\n\n# replace values of 0 with the mean cited from: https://stackoverflow.com/a/11455375/6542644\nfrom sklearn.impute import SimpleImputer\nimp = SimpleImputer(missing_values=0, strategy = 'mean')\n\ncleaned_sizemb_df = viruses_dropped_nan['size_mb']\n\ndrop_host = viruses_dropped_nan.drop(['host'], axis=1)\n\nimp.fit(drop_host)\n\ncleaned_df = imp.transform(drop_host)\n\ncleaned_df = pd.DataFrame(data=cleaned_df, columns=[\"size_mb\", \"gc_percent\", \"cds\"])\n\ncleaned_size = cleaned_df['size_mb']\n\nprint(\"count zeroes is: \", cleaned_size.isin([0]).sum())\n\ncleaned_size = cleaned_size.sort_values()\ncleaned_size.hist(bins = 100)\nplt.title('Distribution of Size of Genome Mb')\nplt.xlabel('Size of genome in Mb')\nplt.ylabel('Count')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get stats for GC% (gc_percent) and plot distribution\n\nprint('Number of unique GC% values: ', (len(viruses_df['gc_percent'].unique())))\n\nprint(viruses_df.gc_percent.describe())\n\ngc_sorted_df = viruses_df['gc_percent']\ngc_sorted_df = gc_sorted_df.sort_values()\n\nprint('Most frequent value is ', gc_sorted_df.mode() )\ngc_sorted_df.hist(bins = 50)\nplt.title('Distribution of GC% of Viral Genomes')\nplt.xlabel('GC% of Viral Genomes')\nplt.ylabel('Count')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get stats for CDS (cds) and plot distribution\n\nprint('Number of unique CDS values: ', (len(viruses_df['cds'].unique())))\n\nprint(viruses_df.cds.describe())\n\ncds_sorted_df = viruses_df['cds']\ncds_sorted_df = cds_sorted_df.sort_values()\n\nprint('Most frequent value is ', cds_sorted_df.mode() )\n\nprint('count zeroes is ', cds_sorted_df.isin([0]).sum() )\n\ncds_sorted_df.hist(bins = 50)\nplt.title('Distribution of CDS of Viral Genomes')\nplt.xlabel('CDS of Viral Genomes')\nplt.ylabel('Count')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Pre-process Data\n\nfrom sklearn import preprocessing\n\nnew_viral_df = viruses_dropped_nan.copy()\n\ntargets_host = new_viral_df.pop('host')\n\nx = new_viral_df.values\n\nmin_max_scaler = preprocessing.MinMaxScaler()\nx_scaled = min_max_scaler.fit_transform(x)\n\nunclean_viral_df = pd.DataFrame(x_scaled)\n\nunclean_viral_df.insert(0, 'host', targets_host)\n\n# remove the NaN values!\nnew_df_clean = unclean_viral_df.dropna()\n\nnew_df_clean.columns = ['host', 'size_mb', 'gc_percent', 'cds']\nnew_df_clean.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prep the data: generate X and y\n\n# create features and labels\ny = new_df_clean['host']\nX = new_df_clean.drop(['host'], axis=1)\ny.columns = ['host']\n\n# X.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# SVM usage cited from: https://towardsdatascience.com/multiclass-classification-with-support-vector-machines-svm-kernel-trick-kernel-functions-f9d5377d6f02\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import svm, datasets\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=0)\n\n# start with linear kernel\n\nlinear = svm.SVC(kernel='linear', C=1, decision_function_shape='ovo').fit(X_train, y_train)\n                                            \nlinear_pred = linear.predict(X_test)\n\n# retrieve accuracy\naccuracy_lin = linear.score(X_test, y_test)\n\nprint(\"acc linear kernel: \", accuracy_lin)\n\ncm_lin = confusion_matrix(y_test, linear_pred)\nprint(cm_lin)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# now try rbf kernel\n\nrbf = svm.SVC(kernel='rbf', C=1, decision_function_shape='ovo', probability=True).fit(X_train, y_train)\nrbf_pred = rbf.predict(X_test)\n\naccuracy_rbf = rbf.score(X_test, y_test)\nprint(\"acc rbf kernel: \", accuracy_rbf)\n\ncm_rbf = confusion_matrix(y_test, linear_pred)\nprint(cm_rbf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# now try with cross validation!\n\nfrom sklearn.model_selection import cross_val_score\n\nclf_cross_val = svm.SVC(kernel='rbf', C=1, decision_function_shape='ovo')\n\n# use of cross_val_score cited from: https://scikit-learn.org/stable/modules/cross_validation.html\n\nscores = cross_val_score(clf_cross_val, X, y, cv=10)\nprint(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}