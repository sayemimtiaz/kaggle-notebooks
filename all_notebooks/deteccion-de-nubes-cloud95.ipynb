{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Librerias\nimport numpy as np\nfrom pathlib import Path\nfrom PIL import Image\nimport util_func as fc\nimport time\n\n#Librerías de PyTorch\nimport torch  #PyTorch library\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn #Neural networks library\nimport torch.nn.functional as F\n\n#Librerias utiles para plotear\nimport matplotlib.pyplot as plt\n%matplotlib inline \n#plots in the line below the code, inside the notebook \n\n#Nombre del proyecto\nproject_name = 'Deteccion de nubes'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preparando los datos\n\nPara empezar, cargo en la lista a la que denomino *'total_list'* los nombres de todos los archivos. Esta lista contiene tres sub-listas, cada una de ellas contiene los nombres de los archivos que van a pertenecer al conjunto de datos de entrenamiento(*training*), validacion y prueba(*test*) respectivamente. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"total_list = fc.data_split('../input/95cloud-cloud-segmentation-on-satellite-images/95-cloud_training_only_additional_to38-cloud/train_red_additional_to38cloud', 15000, 5000)\nlen(total_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Cargo la direccion de la carpeta que contiene todos los canales en una variable, como objeto 'Path'\npath_ppal = Path('../input/95cloud-cloud-segmentation-on-satellite-images/95-cloud_training_only_additional_to38-cloud')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Cargo el dataset de entrenamiento, es el primer objeto de la lista total_lista\ntrain_dataset = fc.CloudDataset(path_ppal/'train_red_additional_to38cloud', \n                    path_ppal/'train_green_additional_to38cloud', \n                    path_ppal/'train_blue_additional_to38cloud', \n                    path_ppal/'train_nir_additional_to38cloud',\n                    path_ppal/'train_gt_additional_to38cloud',\n                    total_list[0])\nlen(train_dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Cargo el dataset de validación, es el segundo objeto de la lista total_list\nval_dataset = fc.CloudDataset(path_ppal/'train_red_additional_to38cloud', \n                    path_ppal/'train_green_additional_to38cloud', \n                    path_ppal/'train_blue_additional_to38cloud', \n                    path_ppal/'train_nir_additional_to38cloud',\n                    path_ppal/'train_gt_additional_to38cloud',\n                    total_list[1])\nlen(val_dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Cargo el dataset de validación, es el tercer objeto de la lista total_list\ntest_dataset = fc.CloudDataset(path_ppal/'train_red_additional_to38cloud', \n                    path_ppal/'train_green_additional_to38cloud', \n                    path_ppal/'train_blue_additional_to38cloud', \n                    path_ppal/'train_nir_additional_to38cloud',\n                    path_ppal/'train_gt_additional_to38cloud',\n                    total_list[2])\nlen(test_dataset)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creo los *dataloaders* donde cargo los *datasets* y defino el tamaño del lote (*batch*) para cargar el conjunto de datos en lotes al entrenarlo. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 6","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dl = DataLoader(train_dataset, batch_size, shuffle=True, num_workers=4, pin_memory=True)\nval_dl = DataLoader(val_dataset, batch_size*2, shuffle=True, num_workers=4, pin_memory=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Mover los datos al GPU\nA continuación defino una serie de funciones cuyo objetivo es mover los datos al GPU para poder utilizarlo y entrenar la red con este dispositivo. Si utilizara sólo el CPU tardaria mucho tiempo, incluso es probable que no sea posible. \n[Fuente](https://jovian.ml/forum/c/pytorch-zero-to-gans/18)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.cuda.is_available() #Detecta si hay un GPU disponible","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Elige un GPU si hay uno disponible. Si no, elige un CPU.\ndevice = fc.get_default_device()\ndevice","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def to_device(data, device):\n    \"\"\"Mueve tensor(es) al dispositivo (CPU O GPU) elegido\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Cantidad de batches o lotes\"\"\"\n        return len(self.dl)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Cargo los datos con un Dataloader en el dispositivo correspondiente\ntrain_loader = DeviceDataLoader(train_dl, device)\nval_loader = DeviceDataLoader(val_dl, device)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Modelo","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#The accuracy we will define our own, that will be basically \n#the number of matched pixels (mask == prediction) divided by the total number of pixels in a batch\ndef accuracy(predb, yb):\n    return (predb.argmax(dim=1) == yb).float().mean()\n\nclass ImageClassificationBase(nn.Module):\n    \n    def training_step(self, batch):\n        loss_fn = nn.CrossEntropyLoss()\n        images, masks = batch \n        #input, targets Carga un lote de datos, cada imagen con su respectiva máscara de nubes\n        out = self(images)     # output Genera las predicciones\n        loss = loss_fn(out, masks) # Calcula las perdidas para cada prediccion (diferencia entre predicción y mascara)        \n        return loss\n    \n    def validation_step(self, batch):\n        loss_fn = nn.CrossEntropyLoss()\n        images, masks = batch      # Carga un lote de datos, cada imagen con su respectiva máscara\n        out = self(images)          # Generate predictions\n        loss = loss_fn(out, masks.long()) # Calculate loss\n        acc = accuracy(out, masks) # Calculate accuracy\n        return {'val_loss': loss.detach(), 'val_acc': acc}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs] # Lista de las perdidas de cada batch\n        epoch_loss = torch.stack(batch_losses).mean()   # Junta las losses de todos los lotes\n        batch_accs = [x['val_acc'] for x in outputs]    # Lista de las exctitudes de cada batch\n        epoch_acc = torch.stack(batch_accs).mean()      # Junta las accuracies de todos los lotes\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result): #Imprime los resultados al terminar de correr cada epoch\n        print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n            epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_acc']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### CNN","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class SimpleCNN(ImageClassificationBase):\n    \n    def __init__(self):\n        super().__init__() \n        \n        self.encod = nn.Sequential(\n            nn.Conv2d(4,32, kernel_size=5, stride=1, padding=2), #out = 32x384x384 cambie 16 por 32\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2), #out = 32x192x192, acum = 1/2\n\n            nn.Conv2d(32,64, kernel_size=5, stride=1, padding=2), #out = 64x192x192\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2), #out = 64x96x96, acum = 1/4\n        \n        \n            nn.Conv2d(64,128, kernel_size=5, stride=1, padding=2), #out=128x96x96\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2), #out = 128x48x48, acum = 1/8\n        \n            nn.Conv2d(128, 256, kernel_size=5, stride=1, padding=2), #out = 256x48x48\n            nn.BatchNorm2d(256),\n            nn.ReLU(),    \n            nn.MaxPool2d(kernel_size=2, stride=2), #out = 256x24x24, acum = 1/16\n        \n            nn.Conv2d(256, 512, kernel_size=5, stride=1, padding=2), #out = 256x24x24\n            nn.BatchNorm2d(512),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2), #out = 512x12x12, acum = 1/32\n            \n            nn.Conv2d(512, 1024, kernel_size=3, stride=1, padding=1), #out = 1024x24x24\n            nn.BatchNorm2d(1024),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2), #out = 1024x6x6, acum = 1/64\n            \n            nn.Conv2d(1024, 1024, kernel_size=5, stride=1, padding=2), #out = 2048x12x12\n            nn.BatchNorm2d(1024),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2) #out = 1024x3x3, acum = 1/128\n            \n        )\n        \n        self.decod = nn.Sequential(\n            nn.ConvTranspose2d(in_channels=1024,out_channels=512,kernel_size=3,stride=1, padding=2), #out = 512x3x3\n            nn.BatchNorm2d(512),\n            nn.ReLU(),\n            nn.UpsamplingNearest2d([6,6], scale_factor=None), #out=128x6x6 \n            \n            nn.ConvTranspose2d(in_channels=512,out_channels=256,kernel_size=3,stride=1, padding=2), #out = 256x6x6\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.UpsamplingNearest2d([12,12], scale_factor=None), #out=128x6x6 \n            \n            nn.ConvTranspose2d(in_channels=256,out_channels=128,kernel_size=5,stride=1, padding=2), #out=128x12x12\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.UpsamplingNearest2d([24,24], scale_factor=None), #out=128x24x24\n        \n            nn.ConvTranspose2d(in_channels=128,out_channels=64,kernel_size=5,stride=1, padding=2),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.UpsamplingNearest2d([48,48], scale_factor=None), #out=64x48x48\n           \n            nn.ConvTranspose2d(in_channels=64,out_channels=32,kernel_size=5,stride=1, padding=2),\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.UpsamplingNearest2d([96,96], scale_factor=None), #out=32x96x96\n        \n            nn.ConvTranspose2d(in_channels=32,out_channels=16,kernel_size=5,stride=1, padding=2),\n            nn.BatchNorm2d(16),\n            nn.ReLU(),\n            nn.UpsamplingNearest2d([192,192], scale_factor=None),#out=16x192x192\n        \n            nn.ConvTranspose2d(in_channels=16,out_channels=2,kernel_size=5,stride=1, padding=2),\n            nn.BatchNorm2d(2),\n            nn.Sigmoid(), \n            nn.UpsamplingNearest2d([384,384], scale_factor=None),#out=4x384x384\n        )\n            \n    \n    def forward(self, xb):\n        out = self.encod(xb) #out = 512x12x12\n        out = self.decod(out)\n        return out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class VanillaCNN(ImageClassificationBase):\n    def __init__(self):\n        super().__init__() #pad = k-1/2\n        \n        self.convnet = nn.Sequential(\n            nn.Conv2d(4,16, kernel_size=5, stride=1, padding=2), #out = 16x384x384\n            nn.BatchNorm2d(16),\n            nn.GELU(),\n            nn.MaxPool2d(kernel_size=2, stride=2), #out = 16x192x192\n\n            nn.Conv2d(16,32, kernel_size=5, stride=1, padding=2), #out = 32x96x96\n            nn.BatchNorm2d(32),\n            nn.GELU(),\n            nn.MaxPool2d(kernel_size=2, stride=2), #out = 32x96x96\n        \n        \n            nn.Conv2d(32,64, kernel_size=5, stride=1, padding=2), #out=64x96x96\n            nn.BatchNorm2d(64),\n            nn.GELU(),\n            nn.MaxPool2d(kernel_size=2, stride=2), #out = 64x48x48\n        \n            nn.Conv2d(64, 128, kernel_size=5, stride=1, padding=2), #out = 128x48x48\n            nn.BatchNorm2d(128),\n            nn.GELU(),     \n            nn.MaxPool2d(kernel_size=2, stride=2), #out = 128x24x24\n        \n        \n            nn.Conv2d(128, 256, kernel_size=5, stride=1, padding=2), #out = 256x24x24\n            nn.BatchNorm2d(256),\n            nn.GELU(),\n            nn.MaxPool2d(kernel_size=2, stride=2), #out = 256x12x12\n        \n            nn.Conv2d(256, 512, kernel_size=5, stride=1, padding=2), #out = 512x12x12\n            nn.BatchNorm2d(512),\n            nn.GELU(),\n            nn.MaxPool2d(kernel_size=2, stride=2), #out = 512x6x6\n        \n            nn.Conv2d(512, 1024, kernel_size=3, stride=1, padding=1), #out = 1024x6x6\n            nn.BatchNorm2d(1024),\n            nn.Sigmoid(),\n            nn.MaxPool2d(kernel_size=2, stride=1) #out = 1024x3x3\n        )\n        \n            #Deconvolution layers\n        self.deconvnet = nn.Sequential(\n            nn.ConvTranspose2d(in_channels=1024,out_channels=512,kernel_size=5, stride=1, padding=2), #1024x3x3\n            nn.GELU(),\n            nn.UpsamplingNearest2d([6,6], scale_factor=None), #out=512x6x6\n        \n            nn.ConvTranspose2d(in_channels=512,out_channels=256,kernel_size=5, stride=1, padding=2),\n            nn.GELU(),\n            nn.UpsamplingNearest2d([12,12], scale_factor=None), #out=256x12x12\n        \n            nn.ConvTranspose2d(in_channels=256,out_channels=128,kernel_size=5,stride=1, padding=2),\n            nn.GELU(),\n            nn.UpsamplingNearest2d([24,24], scale_factor=None), #out=128x24x24\n        \n            nn.ConvTranspose2d(in_channels=128,out_channels=64,kernel_size=5,stride=1, padding=2),\n            nn.GELU(),\n            nn.UpsamplingNearest2d([48,48], scale_factor=None), #out=64x48x48\n           \n            nn.ConvTranspose2d(in_channels=64,out_channels=32,kernel_size=5,stride=1, padding=2),\n            nn.GELU(),\n            nn.UpsamplingNearest2d([96,96], scale_factor=None), #out=32x96x96\n        \n            nn.ConvTranspose2d(in_channels=32,out_channels=16,kernel_size=5,stride=1, padding=2),\n            nn.GELU(),\n            nn.UpsamplingNearest2d([192,192], scale_factor=None),#out=16x192x192\n        \n            nn.ConvTranspose2d(in_channels=16,out_channels=2,kernel_size=3,stride=1, padding=2),\n            nn.Sigmoid(), #out=4x384x384\n            nn.UpsamplingNearest2d([384,384], scale_factor=None),#out=4x384x384\n            \n            #nn.ConvTranspose2d(in_channels=4, out_channels=2, kernel_size=3, stride=2, padding=1)\n        )\n          \n    def forward(self, x):\n        \n        out = self.convnet(x) #out = 16x384x384\n        out = self.deconvnet(out) #out=4x384x384\n        return out","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### U-Net\n![Esquema](https://miro.medium.com/max/700/1*XvJffq5FAdDS4FoCqUb76g.png)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class UNET(ImageClassificationBase):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n\n        self.conv1 = self.contract_block(in_channels, 32, 7, 3)\n        self.conv2 = self.contract_block(32, 64, 3, 1)\n        self.conv3 = self.contract_block(64, 128, 3, 1)\n\n        self.upconv3 = self.expand_block(128, 64, 3, 1)\n        self.upconv2 = self.expand_block(64*2, 32, 3, 1)\n        self.upconv1 = self.expand_block(32*2, out_channels, 3, 1)\n\n    def __call__(self, x):\n\n        # downsampling part\n        conv1 = self.conv1(x)\n        conv2 = self.conv2(conv1)\n        conv3 = self.conv3(conv2)\n\n        upconv3 = self.upconv3(conv3)\n        upconv2 = self.upconv2(torch.cat([upconv3, conv2], 1))\n        upconv1 = self.upconv1(torch.cat([upconv2, conv1], 1))\n\n        return upconv1\n\n    def contract_block(self, in_channels, out_channels, kernel_size, padding):\n\n        contract = nn.Sequential(\n            torch.nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=1, padding=padding),\n            torch.nn.BatchNorm2d(out_channels),\n            nn.ReLU(),\n            torch.nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size, stride=1, padding=padding),\n            torch.nn.BatchNorm2d(out_channels),\n            nn.ReLU(),\n            torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n                                 )\n        return contract\n\n    def expand_block(self, in_channels, out_channels, kernel_size, padding):\n\n        expand = nn.Sequential(torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=padding),\n                            torch.nn.BatchNorm2d(out_channels),\n                            nn.ReLU(),\n                            torch.nn.Conv2d(out_channels, out_channels, kernel_size, stride=1, padding=padding),\n                            torch.nn.BatchNorm2d(out_channels),\n                            nn.ReLU(),\n                            torch.nn.ConvTranspose2d(out_channels, out_channels, kernel_size=3, stride=2, padding=1, output_padding=1) \n                            )\n        return expand","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Entrenamiento\n\nLo voy a hacer con política de un ciclo del learning rate, weight decay y gradient clipping\n\nProceso para implementar gradient descent:\n\n1. Generar predicciones a través del modelo.\n\n2. Calcular las perdidas (*loss*), es decir la diferencia entre la prediccion y la máscara.\n\n3. Calcular los gradientes respecto a los pesos y biases.\n\n4. Adjust los pesos by subtracting a small quantity proportional to the gradient.\n\n5. Resetear los gradientes a 0 y repetir el proceso.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"@torch.no_grad()\ndef evaluate(model, val_loader):\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef get_lr(optimizer):\n    for param_group in optimizer.param_groups:\n        return param_group['lr']\n\ndef fit_one_cycle(epochs, max_lr, model, train_loader, val_loader, weight_decay=0, grad_clip=None, opt_func=torch.optim.ASGD): #Averege SGD\n    '''Función que entrena el modelo para un dado numero de epochs con la política de un ciclo de learning rates'''\n    \n    torch.cuda.empty_cache()\n    history = [] \n    \n    # Seteo una funcion de optimizacion con weight decay\n    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n    # Set up one-cycle learning rate scheduler\n    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, \n                                                steps_per_epoch=len(train_loader))\n    torch.optim.lr_scheduler.OneCycleLR(optimizer, \n                                        max_lr, \n                                        total_steps=None, \n                                        epochs=epochs, \n                                        steps_per_epoch=len(train_loader), \n                                        pct_start=0.3,\n                                        anneal_strategy='cos', \n                                        cycle_momentum=True, \n                                        base_momentum=0.85,\n                                        max_momentum=0.95)\n    for epoch in range(epochs):\n        # Training Phase \n        model.train()\n        train_losses = [] #Lista donde guardo las losses del train dataset\n        lrs = [] #Lista donde guardo los learning rates\n        \n        for batch in train_loader: #para cada lote de datos \n            loss = model.training_step(batch) #calculo la loss para el batch\n            train_losses.append(loss) #agrego a la lista de train_losses\n            loss.backward() #calulo el gradiente respecto a los pesos y biasses\n            \n            # Gradient clipping\n            if grad_clip: \n                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n            \n            optimizer.step()\n            optimizer.zero_grad() #Reset gradient to 0 ?\n            \n            # Record & update learning rate\n            lrs.append(get_lr(optimizer))\n            sched.step()\n        \n        # Validation phase\n        result = evaluate(model, val_loader) #Genera predicciones\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        result['lrs'] = lrs\n        model.epoch_end(epoch, result) #imprime los resultados\n        history.append(result) #Agrega a lista history\n        \n    return history","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Elijo el modelo y lo imprimo","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":" def init_all(model, init_func, *params, **kwargs):\n    for p in model.parameters():\n        init_func(p, *params, **kwargs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ModelCNN\n#model = to_device(VanillaCNN(), device)\n\n#model = to_device(VanillaFCN32(4,2), device)\n\n#model = to_device(SimpleCNN(), device)\n \n\n#Modelo U-Net\nmodel = to_device(UNET(4,2), device)\n\n#init_all(model, torch.nn.init.normal_, mean=0., std=1) #inicializo los pesos\nmodel","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Defino una lista denominada 'history' donde voy a guardar los parámetros de los entrenamientos y los resultados. Ademas, con la función evaluate() voy a elegir los parametros iniciales.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"history = [evaluate(model, val_loader)]\nhistory","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Elijo los parámetros y entreno. Además, voy a registrar el tiempo que lleva cada entrenamiento.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 10 #cantidad de iteraciones\nmax_lr = 0.001 #learning rate maximo para el ciclo\ngrad_clip = 0.1 \nweight_decay = 1e-4\nopt_func = torch.optim.Adam #función de optimización\n\nstart = time.time()\nhistory += fit_one_cycle(epochs, max_lr, model, train_loader, val_loader, \n                             grad_clip=grad_clip, \n                             weight_decay=weight_decay, \n                             opt_func=opt_func) #entreno y agrego a la historia","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Tiempo de entrenamiento en horas en sistema decimal\ntime = ((time.time() - start)/60)/60\ntime","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_lrs(history):\n    lrs = np.concatenate([x.get('lrs', []) for x in history])\n    plt.plot(lrs)\n    plt.xlabel('Batch no.')\n    plt.ylabel('Learning rate')\n    plt.title('Learning Rate vs. Batch no.');\n    \nplot_lrs(history)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Evaluación de los resultados","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_accuracies(history):\n    accuracies = [x['val_acc'] for x in history]\n    plt.plot(accuracies, '-x')\n    plt.xlabel('epoch')\n    plt.ylabel('accuracy')\n    plt.title('Accuracy vs. No. of epochs');\n    \nplot_accuracies(history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_losses(history):\n    train_losses = [x.get('train_loss') for x in history]\n    val_losses = [x['val_loss'] for x in history]\n    plt.plot(train_losses, '-bx')\n    plt.plot(val_losses, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend(['Training', 'Validation'])\n    plt.title('Loss vs. No. of epochs');\n    \nplot_losses(history)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ahora voy a utilizar el dataset 'test' para ver qué tan bien está etiquetando el modelo. Siguiendo el mismo procedimiento, cargo el dataset, muevo los datos al GPU y luego con la función *predict_image* puedo pasarle una imagen y el modelo que elegi y obtener la prediccion. Luego la comparo con la máscara correpondiente. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dl = DataLoader(test_dataset, batch_size*2, num_workers=4, pin_memory=True)\n#Muevo los datos al GPU.\ntest_loader = DeviceDataLoader(test_dl, device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Test\ndef predict_image(img, model):\n    xb = to_device(img.unsqueeze(0), device)  # Convert to a batch of 1\n    yb = model(xb) # Get predictions from model\n    return yb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img, label = test_dataset[1209]\npred = predict_image(img, model).cpu().detach().numpy()\nprint(pred.shape)\nmask_pred = np.zeros([384,384,2])\nmask_pred[:,:,0] = pred[:,1,:,:] #rojo = 1 = nubes\nmask_pred[:,:,1] = pred[:,0,:,:] #verde = 0 = no nubes\nprint(mask_pred.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from skimage import data\nfrom skimage.filters import threshold_otsu\n\n# Load image\nimage = mask_pred\n\n# Threshold image to binary\nthresh = threshold_otsu(image)\nbinary = image > thresh\n\n# Make 3 channel RGB image same dimensions\nRGB = np.zeros((binary.shape[0],binary.shape[1],3), dtype=np.uint8)\n\n# Make True pixels red\nRGB[binary]  = [255,0,0]\n# Make False pixels blue\nRGB[~binary] = [0,0,255]\n\n# Display result\nImage.fromarray(RGB).show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef test_plot(num, test_dataset):\n    \n    img, label = test_dataset[num]\n    pred = predict_image(img, model).cpu().detach().numpy()\n    mask_pred = np.zeros([384,384,3])\n    mask_pred[:,:,0] = pred[:,0,:,:]*255 #no nubes = 0 = rojo\n    mask_pred[:,:,1] = pred[:,1,:,:]*255 #nubes = 1 = verde\n    \n    plt.figure(num, figsize=(15,15))\n    \n    plt.subplot(131)\n    plt.title('Imagen RGB')\n    plt.imshow(test_dataset.open_as_array(num))\n\n    plt.subplot(132)\n    plt.title('Máscara predicha')\n    plt.imshow(mask_pred)\n#plt.cm.binary_\n    plt.subplot(133)\n    plt.title('Máscara real')\n    plt.imshow(test_dataset.open_mask(num))\n\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_plot(296,test_dataset)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finalmente, podemos ver la perdida y la exactitud del modelo sobre todo el conjunto de datos de testeo. Se espera que estos valores sean similares para este conjunto de datos y para el de validación. Si no lo son, puede ser un indicador de que es necesario un mejor conjunto de datos de validación, que contenga imágenes similares y con la misma distribución que el conjunto de datos de testeo.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_loader = DeviceDataLoader(DataLoader(test_dataset, batch_size*2), device)\nresult = evaluate(model, test_loader)\nresult","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Como ultimo paso, grabo las mediciones en Jovian. Esto me permite tener un registro de los valores que obtuve y con qué hiperparámetros y modelos lo logre. De esta forma puedo entender cual fue el 'mejor modelo' y por qué.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plataforma para guardar los resultados \n!pip install jovian --upgrade -q\nimport jovian \n\ntorch.save(model.state_dict(), 'Deteccion de nubes')\n\njovian.reset()\n\njovian.log_hyperparams(Modelo='UNET',\n                       Loss_fn = 'nn.CrossEntropyLoss',\n                       batch_size = batch_size,\n                       epochs = epochs, \n                       lr = max_lr, \n                       scheduler='one-cycle', \n                       weight_decay = weight_decay, \n                       grad_clip = grad_clip,\n                       opt = opt_func.__name__, \n                       time = time)\n\njovian.log_metrics(best_acc=0.9133, test_loss=result.get('val_loss'), test_acc=result.get('val_acc') )\n\njovian.commit(project=project_name, outputs=['Deteccion de nubes.pth'], environment=None)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Este código puede encontrarse en Kaggle y Github.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Fuentes y bibliografía\n* Código para la creacion del dataset original no ampliado, 38Cloud: https://github.com/SorourMo/38-Cloud-A-Cloud-Segmentation-Dataset\n* Clase CloudDataset: https://medium.com/analytics-vidhya/how-to-create-a-custom-dataset-loader-in-pytorch-from-scratch-for-multi-band-satellite-images-c5924e908edf\n* S. Mohajerani and P. Saeedi. \"Cloud-Net: An End-to-end Cloud Detection Algorithm for Landsat 8 Imagery\". (forthcoming) 2019. to appear at IEEE International Geoscience and Remote Sensing Symposium (IGARSS). URL: https://arxiv.org/pdf/1901.10077.pdf\n* Modelo U-Net: https://medium.com/analytics-vidhya/creating-a-very-simple-u-net-model-with-pytorch-for-semantic-segmentation-of-satellite-images-223aa216e705\n* Funciones varias: curso de Deep Learnig https://jovian.ml/forum/c/pytorch-zero-to-gans/18\n* Explicación detallada sobre las redes neuronales convolucionales: https://cs231n.github.io/convolutional-networks/\n* Explicación detallada sobre el modelo U-Net: https://towardsdatascience.com/understanding-semantic-segmentation-with-unet-6be4f42d4b47\n* Explicación detallada de las funciones de optimización\n* Dive into Deep Learning (libro): https://d2l.ai/index.html\n* Towards Data Science (post explicativos, tomé varias imágenes de esta cuenta): \nhttp://deeplearning.net/tutorial/fcn_2D_segm.html\n\nSemantic segmentation\nhttps://la.mathworks.com/help/vision/ug/semantic-segmentation-with-deep-learning.html#mw_6ab02754-d2fa-4330-8bea-3eeec77279da\n\nhttps://www.kite.com/blog/python/image-segmentation-tutorial/#confusion-matrix","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}