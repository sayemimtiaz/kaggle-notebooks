{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Startup Success Prediction Model","metadata":{}},{"cell_type":"markdown","source":"## Problem Statement\n\n**Startup** is a business that has just been established and grown supported by digital services and has also become an important element of innovation systems and economies around the world. The **Startup** ecosystem is growing very rapidly and still needs a lot of funding to operate with a minimalist working group. So it is very important for VC to monitor the performance and performance of **Startup**, so that it can be used as a consideration to decide whether to fund a Startup to drive its growth or refuse to take part in funding. To monitor startup performance, it is important to analyze what makes a Startup successful and how to determine its success.\n\n## Goals\nThe goal to be achieved is to determine whether a StartUp will be successful or not.\n\n## Objective\nThe objective is to analyze startup behavior based on several variables, determine what variables affect startup success the most, then build a model that can predict the success of a StartUp.","metadata":{}},{"cell_type":"markdown","source":"# Data Exploration","metadata":{}},{"cell_type":"markdown","source":"## Import Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib as mpl\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nfrom datetime import date\nfrom scipy import stats\nfrom scipy.stats import norm, skew #for some statistics\n\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nfrom plotly.colors import n_colors\nfrom plotly.subplots import make_subplots\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n%matplotlib inline\npd.set_option(\"display.max_columns\",None)\npd.set_option(\"display.max_rows\",None)\nplt.style.use('seaborn')\n\nfrom collections import Counter\nimport datetime\nimport wordcloud\nimport json","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Dataset","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/startup-success-prediction/startup data.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(10)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Description","metadata":{}},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data type identification","metadata":{}},{"cell_type":"code","source":"df.columns","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data numeric","metadata":{}},{"cell_type":"code","source":"numeric=['int8', 'int16', 'int32', 'int64', 'float16', 'float32', 'float64']\ndf_num=df.select_dtypes(include=numeric)\ndf_num.head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data categorical","metadata":{"code_folding":[]}},{"cell_type":"code","source":"df_cat=df.select_dtypes(include='object')\ndf_cat.head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Changing 'status' data value","metadata":{}},{"cell_type":"code","source":"df['status'] = df.status.map({'acquired':1, 'closed':0})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Handling 'status' data type to int ","metadata":{}},{"cell_type":"code","source":"#Tipe data status diganti dari object ke int\ndf['status'].astype(int)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Drop column labels","metadata":{}},{"cell_type":"code","source":"#labels dan status check similarity\nfor index, row in df.iterrows():\n    if row['labels']!=row['status']:\n        print(index, row['labels'], row['status'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#drop feature\ndf.drop([\"labels\"], axis=1, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploratory Data Analysis","metadata":{}},{"cell_type":"markdown","source":"## Numerical Approach","metadata":{}},{"cell_type":"markdown","source":"### Statistical Summary","metadata":{}},{"cell_type":"code","source":"describeNum = df.describe(include =['float64', 'int64', 'float', 'int'])\ndescribeNum.T.style.background_gradient(cmap='viridis',low=0.2,high=0.1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"describeNumCat = df.describe(include=[\"O\"])\ndescribeNumCat.T.style.background_gradient(cmap='viridis',low=0.2,high=0.1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Does the value listed on each column make sense?\n- age_first_funding_year and age_last_funding_year have the same min,max data, need to be checked again \n- Is the maximum/minimum value still within the reasonable limit? \n- Min/max that is too far from the mean/median may be an indication of data input error \n- Is there a column with a significant difference between the mean and the median?\n- Differences between mean/median indicate outlier or skewed distribution","metadata":{}},{"cell_type":"markdown","source":"### Categorical Value Counting","metadata":{}},{"cell_type":"code","source":"cats = ['state_code','zip_code','id','city','Unnamed: 6','name','founded_at','closed_at','first_funding_at','last_funding_at','state_code.1','category_code','object_id','status'] \nfor col in cats:\n    print(f'''Value count kolom {col}:''')\n    print(df[col].value_counts())\n    print()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Missing Value ","metadata":{}},{"cell_type":"code","source":"null=pd.DataFrame(df.isnull().sum(),columns=[\"Null Values\"])\nnull[\"% Missing Values\"]=(df.isna().sum()/len(df)*100)\nnull = null[null[\"% Missing Values\"] > 0]\nnull.style.background_gradient(cmap='viridis',low =0.2,high=0.1) ","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **Analysis results in the dataset used there are Missing Values among them are**\n    - **Total Missing Values i.e. 1386**\n    - **Columns that have more than 50% of missing values**\n        - Variable 'closed_at' with a total percentage of 63.70% or a total of 588 columns.\n        - Variable 'Unnamed: 6' with a total percentage of 53.41% or a total of 493 columns.\n    - **Columns that have less than 50% of missing values** \n        - Variable 'age_first_milestone_year' with a total percentage of 16.46% or a total of 152 columns.\n        - Variable 'age_last_milestone_year' with a total percentage of 16.46% or a total of 152 columns.","metadata":{}},{"cell_type":"code","source":"# Checking Missing Values Column \ndf[[\"Unnamed: 6\", \"closed_at\", \"age_first_milestone_year\", \"age_last_milestone_year\", \"state_code.1\", \"status\"]].head(4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **Analysis results in the column contained Missing Values among them are** \n    - **Column \"Unnamed: 6\"** is a column of information from a combination of several tables including \n        - Column \"city\", \"state_code\", and \"zip_code\" \n    - **Column \"closed_at\"** is a column where StartUp **\"Closed\"** so that the empty data should be a StarUp whose status is still **\"Acquired\"** \n    - **Column age_first_milestone_year** is information on when milestones were first performed in units of the year \n        - This column has a total of 771 rows of data with a Mean of 3.055353 and a median of 2.520500 showing abnormal data distribution \n    - **Column age_Last_milestone_year** is information when the last milestone was done in units of years \n        - This column has a total of 771 rows of data with a Mean of 4.754423 and a median of 4.476700 that shows the distribution of data is abnormal","metadata":{}},{"cell_type":"markdown","source":"###  Handling Missing Value Unnamed: 6","metadata":{}},{"cell_type":"markdown","source":"Based on the results of the analysis obtained that the column **Unnamed: 6** is a combination of several other columns including columns **city, state_code, and zip_code**, then we decided that remove the contents of the column **Unnamed: 6** first and then fill in the data based on a combination of several related columns.","metadata":{}},{"cell_type":"code","source":"df['Unnamed: 6'] = df.apply(lambda row: (row.city) + \" \" + (row.state_code) + \" \" +(row.zip_code)  , axis = 1)\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Total Missing Values kolom \"Unnamed: 6\"\ntotalNull = df['Unnamed: 6'].isnull().sum()\n\nprint('Total Missing Values Kolom \"Unnamed: 6\": ', totalNull)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Handling Missing Value closed_at","metadata":{}},{"cell_type":"code","source":"df['closed_at'] = df['closed_at'].fillna(value=\"31/12/2013\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"totalNull = df['closed_at'].isnull().sum()\n\nprint('Total Missing Values Kolom \"closed_at\": ', totalNull)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Handling Missing Value age_first_milestone_year and age_last_milestone_year","metadata":{}},{"cell_type":"code","source":"df[['age_first_milestone_year','age_last_milestone_year','milestones']].head()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Based on the results of the analysis obtained that the columns 'age_first_milestone_year' and 'age_last_milestone_year' have null values because the startup does not have milestones. this can be confirmed by looking at the 'milestones' column containing the data 0 must be accompanied by the null 'age_first_milestone_year' and 'age_last_milestone_year' columns. so we decided to fill that null column with a value of 0.","metadata":{}},{"cell_type":"code","source":"df['age_first_milestone_year'] = df['age_first_milestone_year'].fillna(value=\"0\")\ndf['age_last_milestone_year'] = df['age_last_milestone_year'].fillna(value=\"0\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Handling Missing Value state_code.1","metadata":{}},{"cell_type":"markdown","source":"- the **\"state_code\"** column and the **\"state_code.1\"** column must be the same, so the **\"state_code.1\"** column must be dropped. \n- column **\"state_code.1\"** has missing value in line 515.","metadata":{}},{"cell_type":"code","source":"for index, row in df.iterrows():\n    if row['state_code']!=row['state_code.1']:\n        print(index, row['state_code'], row['state_code.1'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop([\"state_code.1\"], axis=1, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"null=pd.DataFrame(df.isnull().sum(),columns=[\"Null Values\"])\nnull[\"% Missing Values\"]=(df.isna().sum()/len(df)*100)\nnull = null[null[\"% Missing Values\"] > 0]\nnull.style.background_gradient(cmap='viridis',low =0.2,high=0.1) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Graphic Approach","metadata":{}},{"cell_type":"markdown","source":"### Correlation heatmap","metadata":{}},{"cell_type":"markdown","source":"Now how to correlate between data variables. \n\nCorrelation is represented as a value between -1 and +1 where +1 indicates the highest positive correlation, -1 indicates the highest negative correlation, and 0 indicates no correlation.","metadata":{}},{"cell_type":"code","source":"df.corr()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['age_first_milestone_year'] = df.age_first_milestone_year.astype(float)\ndf['age_last_milestone_year'] = df.age_last_milestone_year.astype(float)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = ['age_first_funding_year','age_last_funding_year','age_first_milestone_year','age_last_milestone_year','relationships','funding_rounds','funding_total_usd','milestones','is_CA','is_NY','is_MA','is_TX','is_otherstate','is_software','is_web','is_mobile','is_enterprise','is_advertising','is_gamesvideo','is_ecommerce','is_biotech','is_consulting','is_othercategory','has_VC','has_angel','has_roundA','has_roundB','has_roundC','has_roundD','avg_participants','is_top500','status']\n\nplt.figure(figsize=(30,20))\nax = sns.heatmap(data = df[features].corr(),cmap='YlGnBu',annot=True)\n\nbottom, top = ax.get_ylim()\nax.set_ylim(bottom + 0.5,top - 0.5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#number of variables for heatmap\ncols = df[features].corr().nlargest(10,'status')['status'].index\ncm = np.corrcoef(df[cols].values.T) \nsns.set(font_scale=1.25)\nhm = sns.heatmap(cm, cbar=True, annot=True, square=True, cmap='YlGnBu', fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Scatter plot","metadata":{}},{"cell_type":"markdown","source":"based on the correlation table above which says that **'views'** and **'likes'** are very positively correlated. then we then verify that by plotting a scatter plot between **'views'** and **'likes'** to visualize the relationship between those variables.","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots()\n_ = plt.scatter(x=df['age_first_funding_year'], y=df['age_last_funding_year'], edgecolors=\"#000000\", linewidths=0.5)\n_ = ax.set(xlabel=\"age_first_funding_year\", ylabel=\"age_last_funding_year\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We see that **'age_first_milestones_year'** and **'age_last_milestones_year'** are really positively correlated whereas when one increases, the other also increasesâ€”mostly.","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots()\n_ = plt.scatter(x=df['age_first_milestone_year'], y=df['age_last_milestone_year'], edgecolors=\"#000000\", linewidths=0.5)\n_ = ax.set(xlabel=\"status\", ylabel=\"milestones\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Box plots","metadata":{}},{"cell_type":"code","source":"featuresNum = ['age_first_funding_year','age_last_funding_year','age_first_milestone_year','age_last_milestone_year','relationships','funding_rounds','funding_total_usd','milestones','avg_participants']\n\nplt.figure(figsize=(15, 7))\nfor i in range(0, len(featuresNum)):\n    plt.subplot(1, len(featuresNum), i+1)\n    sns.boxplot(y=df[featuresNum[i]], color='green', orient='v')\n    plt.tight_layout()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dataset collection founded years","metadata":{}},{"cell_type":"code","source":"cdf = df[\"founded_at\"].apply(lambda x: '' + x[:2]).value_counts() \\\n            .to_frame().reset_index() \\\n            .rename(columns={\"index\": \"year\", \"founded_at\": \"No_of_startup\"})\n\nfig, ax = plt.subplots()\n_ = sns.barplot(x=\"year\", y=\"No_of_startup\", data=cdf, \n                palette=sns.color_palette(['#003f5c', '#ffa600'], n_colors=7), ax=ax)\n_ = ax.set(xlabel=\"Year\", ylabel=\"No. of startup\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"founded_at\"].apply(lambda x: '20:' + x[:2]).value_counts(normalize=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"founded_at\"].apply(lambda x: '20:' + x[:2]).value_counts(normalize=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"total 563 startups or 60% of startups established in 2001","metadata":{}},{"cell_type":"code","source":"df[\"closed_at\"].apply(lambda x: '20:' + x[:2]).value_counts(normalize=True)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"from the total data available as many as 63% of startups are still standing while the remaining 37% have been closed and most closed in 2001.","metadata":{}},{"cell_type":"markdown","source":"### How many Startup are acquired or closed have?","metadata":{}},{"cell_type":"code","source":"df_acquired = df[(df[\"status\"] == True)]\ndf_acquired.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_closed = df[(df[\"status\"] == False)]\ndf_closed.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"value_counts = df[\"status\"].value_counts().to_dict()\nfig, ax = plt.subplots()\n_ = ax.pie(x=[value_counts[False], value_counts[True]], labels=['No', 'Yes'], \n           colors=['#003f5c', '#ffa600'], textprops={'color': '#040204'})\n_ = ax.axis('equal')\n_ = ax.set_title('Startup Acquired')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Which category has the largest number of startup","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(12,8))\n\n_ = sns.countplot(x=\"category_code\", hue=\"status\", data=df, palette=\"nipy_spectral\",\n              order=df.category_code.value_counts().index)\n\n_ = ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n_ = ax.set(xlabel=\"Category\", ylabel=\"No. of startup\")\nplt.legend(bbox_to_anchor=(0.945, 0.90))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Which category has the largest number Success Rate","metadata":{}},{"cell_type":"code","source":"data1 = df[df['status']==1].groupby(['category_code']).agg({'status':'count'}).reset_index()\ndata1.columns=['category_code','total_success']\n\ndata2 = df[df['status']==0].groupby(['category_code']).agg({'status':'count'}).reset_index()\ndata2.columns=['category_code','total_closed']\n\ndata3=df.groupby(['category_code']).agg({'status':'count'}).reset_index()\ndata3.columns=['category_code','total_startup']\n\ndata1= data1.merge(data2, on='category_code')\ndata1= data1.merge(data3, on='category_code')\n\ndata1['success_rate']= round((data1['total_success'] / data1['total_startup']) * 100,2)\n\nmost_succes_rate = data1.sort_values('success_rate', ascending=False)\nmost_succes_rate","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10,7))\n_ = sns.barplot(x=\"category_code\", y=\"success_rate\", data=most_succes_rate,\n                palette=\"nipy_spectral\", ax=ax)\n_ = ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n_ = ax.set(xlabel=\"Category\", ylabel=\"Success Rate of Start Up\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Which category having most number of total funding","metadata":{}},{"cell_type":"code","source":"funding_sorted_category = pd.pivot_table(df,\n              index=['category_code'],\n              values=['funding_total_usd'],\n              aggfunc=['sum']\n              ).reset_index()\nfunding_sorted_category.columns = ['category_code', 'funding_total_usd']\nfunding_sorted_category = funding_sorted_category.sort_values(['funding_total_usd'], ascending = False)\nfunding_sorted_category.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(15,7))\n_ = sns.barplot(x=\"category_code\", y=\"funding_total_usd\", data=funding_sorted_category,\n                palette=\"nipy_spectral\", ax=ax)\n_ = ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n_ = ax.set(xlabel=\"Category\", ylabel=\"Total Funding USD\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Which State having most number of Startup","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(12,8))\n\n_ = sns.countplot(x=\"state_code\", hue=\"status\", data=df, palette=\"nipy_spectral\",\n              order=df.state_code.value_counts().index)\n\n_ = ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n_ = ax.set(xlabel=\"state_code\", ylabel=\"No. of startup\")\nplt.legend(bbox_to_anchor=(0.945, 0.90))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trending_statea = df.groupby(['state_code']).size().rename('num_startup').reset_index()\n\nmost_trending_statea = trending_statea[trending_statea.groupby('state_code')['num_startup'].transform(max) == trending_statea['num_startup']]\nmost_trending_statea = most_trending_statea.sort_values('num_startup', ascending=False)\nmost_trending_statea","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Which State having most number of acquired Startup per category","metadata":{}},{"cell_type":"code","source":"trending_statea = df_acquired.groupby(['state_code','category_code']).size().rename('num_startup').reset_index()\n\nmost_trending_statea = trending_statea[trending_statea.groupby('state_code')['num_startup'].transform(max) == trending_statea['num_startup']]\nmost_trending_statea = most_trending_statea.sort_values('num_startup', ascending=False)\nmost_trending_statea.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Which State having most number of closed Startup per category","metadata":{}},{"cell_type":"code","source":"trending_statec = df_closed.groupby(['state_code','category_code']).size().rename('num_startup').reset_index()\n\nmost_trending_statec = trending_statec[trending_statec.groupby('state_code')['num_startup'].transform(max) == trending_statec['num_startup']]\nmost_trending_statec = most_trending_statec.sort_values('num_startup', ascending=False)\nmost_trending_statec","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Which city having most number of acquired Startup per category","metadata":{}},{"cell_type":"code","source":"trending_categorya = df_acquired.groupby(['city','category_code']).size().rename('num_startup').reset_index()\n\nmost_trending_categorya = trending_categorya[trending_categorya.groupby('city')['num_startup'].transform(max) == trending_categorya['num_startup']]\nmost_trending_categorya = most_trending_categorya.sort_values('num_startup', ascending=False)\nmost_trending_categorya","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Which city having most number of closed Startup per category","metadata":{}},{"cell_type":"code","source":"trending_categoryc = df_closed.groupby(['city','category_code']).size().rename('num_startup').reset_index()\n\nmost_trending_categoryc = trending_categoryc[trending_categoryc.groupby('city')['num_startup'].transform(max) == trending_categoryc['num_startup']].reset_index()\nmost_trending_categoryc = most_trending_categoryc.sort_values('num_startup', ascending=False)\nmost_trending_categoryc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Which city having most number of total funding","metadata":{}},{"cell_type":"code","source":"funding_sorted_city = pd.pivot_table(df,\n              index=['city'],\n              values=['funding_total_usd'],\n              aggfunc=['sum']\n              ).reset_index()\nfunding_sorted_city.columns = ['city', 'funding_total_usd']\nfunding_sorted_city = funding_sorted_city.sort_values(['funding_total_usd'], ascending = False)\nfunding_sorted_city = funding_sorted_city.head(10)\nfunding_sorted_city","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10,7))\n_ = sns.barplot(x=\"city\", y=\"funding_total_usd\", data=funding_sorted_city,\n                palette=\"nipy_spectral\", ax=ax)\n_ = ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n_ = ax.set(xlabel=\"No of State\", ylabel=\"Number of Start Up\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_what_in_kirkland = df[(df[\"city\"] == 'Kirkland')]\ndf_what_in_kirkland.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_what_in_kirkland.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Round A, Round B,Round C, Round D, VC, Angel = 0 earlier startup status acquired ????????? there is something strange about this data, the possibility of invalid data","metadata":{}},{"cell_type":"markdown","source":"### How many Startup have has_VC?","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10,5))\n\n_ = sns.countplot(x=\"has_VC\", hue=\"status\", data=df, palette=\"nipy_spectral\",\n              order=df.has_VC.value_counts().index)\n\n_ = ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n_ = ax.set(xlabel=\"Has_VC\", ylabel=\"No. of startup\")\nplt.legend(bbox_to_anchor=(0.945, 0.90))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### How many Startup have is_top500?","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10,5))\n\n_ = sns.countplot(x=\"is_top500\", hue=\"status\", data=df, palette=\"nipy_spectral\",\n              order=df.is_top500.value_counts().index)\n\n_ = ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n_ = ax.set(xlabel=\"is_top500\", ylabel=\"No. of startup\")\nplt.legend(bbox_to_anchor=(0.945, 0.90))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#How many Startup have both 'acquired' status and is_top500?\nlen(df[(df[\"status\"] == True) & (df[\"is_top500\"] == True)].index)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#How many Startup have both 'closed' status and is_top500?\nlen(df[(df[\"status\"] == False) & (df[\"is_top500\"] == False)].index)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_acquired[\"is_top500\"].value_counts(normalize=True)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### How many years on average the company closes","metadata":{}},{"cell_type":"code","source":"df_closed.founded_at=pd.to_datetime(df_closed.founded_at)\ndf_closed.closed_at=pd.to_datetime(df_closed.closed_at)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_closed['age_closed_startup'] = df_closed.apply(lambda row: (row.closed_at - row.founded_at) , axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#df_closed['age_closed_startup'] = pd.to_numeric(df['age_closed_startup'].dt.days, downcast='int64')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_closed['age_closed_startup'].head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_closed['year'] = df_closed['age_closed_startup'].dt.days /365","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_closed.head(3)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(df_closed['age_closed_startup'].mean()) ","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ratarata = round(2184 / 365) \nprint(\"Rata-Rata Startup Closed :\", ratarata ,\"tahun\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### which relationship related to acquired or closed startup?","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(17,10))\n\nsns.countplot(x=\"relationships\", hue=\"status\", data=df, palette=\"nipy_spectral\",\n              order=df.relationships.value_counts().index)\nplt.legend(bbox_to_anchor=(0.945, 0.90))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### which funding_rounds related to acquired or closed startup?","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(12,8))\n\nsns.countplot(x=\"funding_rounds\", hue=\"status\", data=df, palette=\"nipy_spectral\",\n              order=df.funding_rounds.value_counts().index)\n# plt.legend(bbox_to_anchor=(0.945, 0.90))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Investing Feature on Acquired","metadata":{}},{"cell_type":"code","source":"coba = df[(df[\"status\"] == 1)]\n\nfeatures = coba[[\"has_VC\",\"has_angel\",\"has_roundA\",\"has_roundB\",\"has_roundC\",\"has_roundD\"]]\n\nfig, ax = plt.subplots(figsize=(12,8))\n\na= np.random.choice([\"{}\".format(i) for i in [1,2,3,4,5,6]], size=(12,8))\ncoba = pd.DataFrame(a, columns=[\"has_{}\".format(i) for i in list(\"features\")])\n\nsns.countplot(x=\"variable\", hue=\"value\",palette=\"nipy_spectral\", data=pd.melt(features))\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Mapping area startup ","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nimport shapefile as shp","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'geopandas' in sys.modules","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.longitude, df.latitude))","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(gdf.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"street_map = gpd.read_file('../input/json-map-file/USA_States.shp')\n\nfig,ax = plt.subplots(figsize = (15,15))\nstreet_map.plot(ax = ax)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\nax = street_map.plot(figsize = (50,50))\n\n# We can now plot our ``GeoDataFrame``.\ngdf.plot(ax=ax, color='red')\n\nplt.show()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"markdown","source":"## Duplicate Values","metadata":{}},{"cell_type":"code","source":"#check\nduplicate = df[df.duplicated()] \n  \nprint(\"Duplicate Rows :\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Negative value","metadata":{}},{"cell_type":"code","source":"age=[\"age_first_funding_year\",\"age_last_funding_year\",\"age_first_milestone_year\",\"age_last_milestone_year\"]\n\nfor a in range(len(age)):\n    print(\"Is there any negative value in '{}' column  : {} \".format(age[a],(df[age[a]]<0).any()))","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=df.drop(df[df.age_first_funding_year<0].index)\ndf=df.drop(df[df.age_last_funding_year<0].index)\ndf=df.drop(df[df.age_first_milestone_year<0].index)\ndf=df.drop(df[df.age_last_milestone_year<0].index)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for a in range(len(age)):\n    print(\"Is there any negative value in '{}' column  : {} \".format(age[a],(df[age[a]]<0).any()))","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Outliers","metadata":{}},{"cell_type":"code","source":"featuresNumfinal = ['age_first_funding_year','age_last_funding_year','age_first_milestone_year','age_last_milestone_year','funding_total_usd']\n\nplt.figure(figsize=(15, 7))\nfor i in range(0, len(featuresNumfinal)):\n    plt.subplot(1, len(featuresNumfinal), i+1)\n    sns.boxplot(y=df[featuresNumfinal[i]], color='green', orient='v')\n    plt.tight_layout()","metadata":{"code_folding":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Log-transformation of the funding and milestone year variable","metadata":{}},{"cell_type":"code","source":"df[\"age_first_funding_year\"] = np.log1p(df[\"age_first_funding_year\"])\ndf[\"age_last_funding_year\"] = np.log1p(df[\"age_last_funding_year\"])\ndf[\"age_first_milestone_year\"] = np.log1p(df[\"age_first_milestone_year\"])\ndf[\"age_last_milestone_year\"] = np.log1p(df[\"age_last_milestone_year\"])\ndf[\"funding_total_usd\"] = np.log1p(df[\"funding_total_usd\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"featuresNumfinal = ['age_first_funding_year','age_last_funding_year','age_first_milestone_year','age_last_milestone_year','funding_total_usd']\n\nplt.figure(figsize=(15, 7))\nfor i in range(0, len(featuresNumfinal)):\n    plt.subplot(1, len(featuresNumfinal), i+1)\n    sns.boxplot(y=df[featuresNumfinal[i]], color='green', orient='v')\n    plt.tight_layout()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"## New Column \"has_RoundABCD\"","metadata":{}},{"cell_type":"code","source":"df['has_RoundABCD'] = np.where((df['has_roundA'] == 1) | (df['has_roundB'] == 1) | (df['has_roundC'] == 1) | (df['has_roundD'] == 1), 1, 0)\ndf.head()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## New Column \"has_Investor\"","metadata":{}},{"cell_type":"code","source":"df['has_Investor'] = np.where((df['has_VC'] == 1) | (df['has_angel'] == 1), 1, 0)\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df[(df[\"has_RoundABCD\"] == 1)].index)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df[ (df['has_RoundABCD']  == 1) & (df['status']  == 1) ].index)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"923-490","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## New Column \"has_Seed\"","metadata":{}},{"cell_type":"code","source":"df['has_Seed'] = np.where((df['has_RoundABCD'] == 0) & (df['has_Investor'] == 1), 1, 0)\ndf.head()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['has_Seed'] == 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df[(df[\"has_Seed\"] == 1)].index)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## New Column \"invalid_startup\"","metadata":{}},{"cell_type":"code","source":"df['invalid_startup'] = np.where((df['has_RoundABCD'] == 0) & (df['has_VC'] == 0) & (df['has_angel'] == 0), 1, 0)\ndf.head()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df[(df[\"invalid_startup\"] == 1)].index)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##  New Column \"age_startup_year\"","metadata":{}},{"cell_type":"code","source":"df.founded_at=pd.to_datetime(df.founded_at)\ndf.closed_at=pd.to_datetime(df.closed_at)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['age_closed_startup'] = df.apply(lambda row: (row.closed_at - row.founded_at) , axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['age_closed_startup'].head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['age_startup_year'] = df['age_closed_startup'].dt.days /365","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##  New Column \"tier_relationships\"","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(12,8))\n\n_ = sns.countplot(x=\"relationships\", hue=\"status\", data=df, palette=\"nipy_spectral\",\n              order=df.relationships.value_counts().index)\n\n_ = ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n_ = ax.set(xlabel=\"relationships\", ylabel=\"No. of startup\")\nplt.legend(bbox_to_anchor=(0.945, 0.90))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create a list of our conditions\nconditions = [\n    (df['relationships'] <= 5),\n    (df['relationships'] > 5) & (df['relationships'] <= 10),\n    (df['relationships'] > 10) & (df['relationships'] <= 16),\n    (df['relationships'] > 16)\n    ]\n\n# create a list of the values we want to assign for each condition\nvalues = ['4', '3', '2', '1']\n\n# create a new column and use np.select to assign values to it using our lists as arguments\ndf['tier_relationships'] = np.select(conditions, values)\n\n# display updated DataFrame\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(12,8))\n\n_ = sns.countplot(x=\"tier_relationships\", hue=\"status\", data=df, palette=\"nipy_spectral\",\n              order=df.tier_relationships.value_counts().index)\n\n_ = ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n_ = ax.set(xlabel=\"tier_relationships\", ylabel=\"No. of startup\")\nplt.legend(bbox_to_anchor=(0.945, 0.90))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['tier_relationships'] = df.tier_relationships.astype(int)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Drop unused column for modelling","metadata":{}},{"cell_type":"code","source":"df = df.drop(['state_code'],axis=1)\ndf = df.drop(['id'],axis=1)\ndf = df.drop(['Unnamed: 6'],axis=1)\ndf = df.drop(['category_code'],axis=1)\ndf = df.drop(['object_id'],axis=1)\ndf = df.drop(['zip_code'],axis=1)\ndf = df.drop(['founded_at'],axis=1)\ndf = df.drop(['closed_at'],axis=1)\ndf = df.drop(['first_funding_at'],axis=1)\ndf = df.drop(['last_funding_at'],axis=1)\ndf = df.drop(['city'],axis=1)\ndf = df.drop(['name'],axis=1)\ndf = df.drop(['Unnamed: 0'],axis=1)\ndf = df.drop(['latitude','longitude'],axis=1)\ndf = df.drop(['geometry'],axis=1)\ndf = df.drop(['age_closed_startup'],axis=1)\ndf = df.drop(['relationships'],axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modeling","metadata":{}},{"cell_type":"code","source":"#Cek categorical\ncat_feature = df.select_dtypes(include='object')\ncat_feature.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n# Split the data\n# Input/independent variables\nX = df.drop('status', axis = 1) # her we are droping the output feature as this is the target and 'X' is input features, the changes are not \n                                # made inplace as we have not used 'inplace = True'\n\ny = df['status'] # Output/Dependent variable","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lets print the shapes again \nprint(\"Shape of the X Train :\", X_train.shape)\nprint(\"Shape of the y Train :\", y_train.shape)\nprint(\"Shape of the X test :\", X_test.shape)\nprint(\"Shape of the y test :\", y_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model Build\nfrom sklearn.metrics import confusion_matrix, classification_report,accuracy_score,roc_curve, auc, precision_recall_curve, f1_score\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## LGBM Classifier","metadata":{}},{"cell_type":"markdown","source":"##### Feature importance by LGBM","metadata":{}},{"cell_type":"code","source":"import lightgbm as lgb\n#lightGBM model fit\ngbm = lgb.LGBMRegressor()\ngbm.fit(X_train,y_train)\ngbm.booster_.feature_importance()\n\n\n# importance of each attribute\nfea_imp_ = pd.DataFrame({'cols':X.columns, 'fea_imp':gbm.feature_importances_})\nfea_imp_.loc[fea_imp_.fea_imp > 0].sort_values(by=['fea_imp'], ascending = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Recursive Feature Elimination(RFE)","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_selection import RFE\n# create the Recursive Feature Elimination model and select 10 attributes\nrfe = RFE(gbm, 10)\nrfe = rfe.fit(X_train,y_train)\n\n# summarize the selection of the attributes\nprint(rfe.support_)\n\n# summarize the ranking of the attributes\nfea_rank_ = pd.DataFrame({'cols':X.columns, 'fea_rank':rfe.ranking_})\nfea_rank_.loc[fea_rank_.fea_rank > 0].sort_values(by=['fea_rank'], ascending = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Build Model","metadata":{}},{"cell_type":"code","source":"from lightgbm import LGBMClassifier\nclf = LGBMClassifier()\n\nclf.fit(X_train,y_train)\n\ny_pred_lgb = clf.predict(X_test)\n\nprint(\"Training Accuracy :\", clf.score(X_train, y_train))\nprint(\"Testing Accuracy :\", clf.score(X_test, y_test))\n\ncm = confusion_matrix(y_test, y_pred_lgb)\nplt.rcParams['figure.figsize'] = (3, 3)\nsns.heatmap(cm, annot = True, cmap = 'YlGnBu', fmt = '.8g')\nplt.show()\n\ncr = classification_report(y_test, y_pred_lgb)\nprint(cr)\n\nprint(\"------------------------------------------\")\n\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,y_pred_lgb)\nroc_auc = auc(false_positive_rate, true_positive_rate)\nprint(\"ROC Curves              =\",roc_auc)\n\nprecision, recall, thresholds = precision_recall_curve(y_test, y_pred_lgb)\nf1 = f1_score(y_test, y_pred_lgb)\nPrecision_Recall_lgbm = auc(recall, precision)\nprint(\"Precision-Recall Curves =\",Precision_Recall_lgbm)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## XGBoost Classifier","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBClassifier\n\n#train\nxgb = XGBClassifier()\n\nxgb.fit(X_train,y_train)\n\n#predict\ny_predicted_xgb = xgb.predict(X_test)\n\nprint(\"Training Accuracy :\", xgb.score(X_train, y_train))\nprint(\"Testing Accuracy :\", xgb.score(X_test, y_test))\n\n#eval\ncm = confusion_matrix(y_test, y_predicted_xgb)\nplt.rcParams['figure.figsize'] = (3, 3)\nsns.heatmap(cm, annot = True, cmap = 'YlGnBu', fmt = '.8g')\nplt.show()\n\ncr = classification_report(y_test, y_predicted_xgb)\nprint(cr)\n\nprint(\"------------------------------------------\")\n\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,y_predicted_xgb)\nroc_auc = auc(false_positive_rate, true_positive_rate)\nprint(\"ROC Curves              =\",roc_auc)\n\nprecision, recall, thresholds = precision_recall_curve(y_test, y_predicted_xgb)\nf1 = f1_score(y_test, y_predicted_xgb)\nPrecision_Recall_xgb = auc(recall, precision)\nprint(\"Precision-Recall Curves =\",Precision_Recall_xgb)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## GradientBoosting Classifier","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\n#train\ngbc = GradientBoostingClassifier(learning_rate=0.02,\n                    max_depth=4,\n                    random_state=100, n_estimators=1000)\n\n\ngbc.fit(X_train,y_train)\n\n#predict\ny_predicted_gb = gbc.predict(X_test)\n\nprint(\"Training Accuracy :\", gbc.score(X_train, y_train))\nprint(\"Testing Accuracy :\", gbc.score(X_test, y_test))\n\n#eval\ncm = confusion_matrix(y_test, y_predicted_gb)\nplt.rcParams['figure.figsize'] = (3, 3)\nsns.heatmap(cm, annot = True, cmap = 'YlGnBu', fmt = '.8g')\nplt.show()\n\ncr = classification_report(y_test, y_predicted_gb)\nprint(cr)\n\n\nprint(\"------------------------------------------\")\n\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,y_predicted_gb)\nroc_auc = auc(false_positive_rate, true_positive_rate)\nprint(\"ROC Curves              =\",roc_auc)\n\nprecision, recall, thresholds = precision_recall_curve(y_test, y_predicted_gb)\nf1 = f1_score(y_test, y_predicted_gb)\nPrecision_Recall_gbs = auc(recall, precision)\nprint(\"Precision-Recall Curves =\",Precision_Recall_gbs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## AdaBoost Classifier","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\n#train\nada = AdaBoostClassifier()\n\n\nada.fit(X_train,y_train)\n\n#predict\ny_predicted_ab = ada.predict(X_test)\n\nprint(\"Training Accuracy :\", ada.score(X_train, y_train))\nprint(\"Testing Accuracy :\", ada.score(X_test, y_test))\n\n#eval\ncm = confusion_matrix(y_test, y_predicted_ab)\nplt.rcParams['figure.figsize'] = (3, 3)\nsns.heatmap(cm, annot = True, cmap = 'YlGnBu', fmt = '.8g')\nplt.show()\n\ncr = classification_report(y_test, y_predicted_ab)\nprint(cr)\n\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,y_predicted_ab)\nroc_auc = auc(false_positive_rate, true_positive_rate)\nprint(\"roc_auc\",roc_auc)\n\nprint(\"------------------------------------------\")\n\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,y_predicted_ab)\nroc_auc = auc(false_positive_rate, true_positive_rate)\nprint(\"ROC Curves              =\",roc_auc)\n\nprecision, recall, thresholds = precision_recall_curve(y_test, y_predicted_ab)\nf1 = f1_score(y_test, y_predicted_ab)\nPrecision_Recall_abs = auc(recall, precision)\nprint(\"Precision-Recall Curves =\",Precision_Recall_abs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Random Forest","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier()\n\nrf.fit(X_train,y_train)\n\n\ny_pred_rf = rf.predict(X_test)\n\nprint(\"Training Accuracy :\", rf.score(X_train, y_train))\nprint(\"Testing Accuracy :\", rf.score(X_test, y_test))\n\ncm = confusion_matrix(y_test, y_pred_rf)\nplt.rcParams['figure.figsize'] = (3, 3)\nsns.heatmap(cm, annot = True, cmap = 'YlGnBu', fmt = '.8g')\nplt.show()\n\ncr = classification_report(y_test, y_pred_rf)\nprint(cr)\n\n\nprint(\"------------------------------------------\")\n\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,y_pred_rf)\nroc_auc = auc(false_positive_rate, true_positive_rate)\nprint(\"ROC Curves              =\",roc_auc)\n\nprecision, recall, thresholds = precision_recall_curve(y_test, y_pred_rf)\nf1 = f1_score(y_test, y_pred_rf)\nPrecision_Recall_rfs = auc(recall, precision)\nprint(\"Precision-Recall Curves =\",Precision_Recall_rfs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Summary","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\n\nscores = {'LGBM':  { \n                             'precision_score': precision_score(y_test, y_pred_lgb),\n                             'recall_score': recall_score(y_test, y_pred_lgb)\n                         },        \n                 'GradientBoosting Classifier':  { \n                             'precision_score': precision_score(y_test, y_predicted_gb),\n                             'recall_score': recall_score(y_test, y_predicted_gb)\n                         },\n                 'Adaboost Classifier':  { \n                             'precision_score': precision_score(y_test, y_predicted_ab),\n                             'recall_score': recall_score(y_test, y_predicted_ab)\n                         },\n                 'XGBoost':  { \n                             'precision_score': precision_score(y_test, y_predicted_xgb),\n                             'recall_score': recall_score(y_test, y_predicted_xgb)\n                         },\n                 'Random Forest':  { \n                             'precision_score': precision_score(y_test, y_pred_rf),\n                            'recall_score': recall_score(y_test, y_pred_rf)\n                         }\n            }","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import precision_score\n\n\nPrecision_Recall = {'LGBM':  { \n                             'Precision_Recall': Precision_Recall_lgbm\n                         },        \n                 'GradientBoosting Classifier':  { \n                             'Precision_Recall': Precision_Recall_gbs\n                         },\n                 'Adaboost Classifier':  { \n                             'Precision_Recall': Precision_Recall_abs\n                         },\n                 'XGBoost':  { \n                             'Precision_Recall': Precision_Recall_xgb\n                         },\n                 'Random Forest':  { \n                             'Precision_Recall': Precision_Recall_rfs\n                         }\n            }","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = pd.DataFrame(scores)\n\n\nscores.plot(kind=\"barh\",figsize=(12, 12)).legend(loc='upper center', ncol=3, title=\"Machine Learning Model\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Precision_Recall = pd.DataFrame(Precision_Recall)\n\n\nPrecision_Recall.plot(kind=\"barh\",figsize=(15, 8)).legend(loc='upper center', ncol=3, title=\"Machine Learning Model\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Deploy Model","metadata":{}},{"cell_type":"code","source":"# import pickle","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Saving model to disk\n# pickle.dump(gbm, open('model.pkl','wb'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Loading model to compare the results\n# model = pickle.load(open('model.pkl','rb'))\n# print(model.predict([[2, 3, 4, 6, 3, 3, 375000, 3, 1, 6,]]))","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df2 = df[[\"status\",\"age_first_funding_year\",\"age_last_funding_year\",\"age_first_milestone_year\",\"age_last_milestone_year\",\"relationships\",\"funding_rounds\",\"funding_total_usd\",\"milestones\",\"avg_participants\"]]\n# df2.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"css and js file for css js elements to work on webpage.Get it from here : https://materializecss.com/getting-started.html","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}