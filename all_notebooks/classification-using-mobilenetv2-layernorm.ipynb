{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install torchsummary","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport torch.backends.cudnn as cudnn\n\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torchvision import datasets, models, transforms\n\nfrom torchsummary import summary\n\nimport os, time, sys","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## MobileNet v2 with LayerNorm"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass Block_LN(nn.Module):\n    '''expand + depthwise + pointwise'''\n    def __init__(self, in_planes, out_planes, expansion, stride):\n        super(Block_LN, self).__init__()\n        self.stride = stride\n\n        planes = expansion * in_planes\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, stride=1, padding=0, bias=False)\n        self.bn1 = nn.GroupNorm(1, planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, groups=planes, bias=False)\n        self.bn2 = nn.GroupNorm(1, planes)\n        self.conv3 = nn.Conv2d(planes, out_planes, kernel_size=1, stride=1, padding=0, bias=False)\n        self.bn3 = nn.GroupNorm(1, out_planes)\n\n        self.shortcut = nn.Sequential()\n        if stride == 1 and in_planes != out_planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=1, padding=0, bias=False),\n                nn.GroupNorm(1, out_planes),\n            )\n\n    def forward(self, x):\n        out = F.relu6(self.bn1(self.conv1(x)))\n        out = F.relu6(self.bn2(self.conv2(out)))\n        out = self.bn3(self.conv3(out))\n        out = out + self.shortcut(x) if self.stride==1 else out\n#         out = out + x if self.stride==1 else out\n        return out\n\n\nclass MobileNetv2LN(nn.Module):\n    # (expansion, out_planes, num_blocks, stride)\n    cfg = [(1,  16, 1, 1),\n           (6,  24, 2, 2), \n           (6,  32, 3, 2),\n           (6,  64, 4, 2),\n           (6,  96, 3, 1),\n           (6, 160, 3, 2),\n           (6, 320, 1, 1)]\n\n    def __init__(self, num_classes=3):\n        super(MobileNetv2LN, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False)\n        self.bn1 = nn.GroupNorm(1, 32)\n        self.layers = self._make_layers(in_planes=32)\n        self.conv2 = nn.Conv2d(320, 160, kernel_size=1, stride=1, padding=0, bias=False)\n        # NOTE: output channel of origin MobileNet v2 : 1280 // Ours : 160\n        self.bn2 = nn.GroupNorm(1, 160)\n        self.linear = nn.Linear(160, num_classes)\n\n    def _make_layers(self, in_planes):\n        layers = []\n        for expansion, out_planes, num_blocks, stride in self.cfg:\n            strides = [stride] + [1]*(num_blocks-1)\n            for stride in strides:\n                layers.append(Block_LN(in_planes, out_planes, expansion, stride))\n                in_planes = out_planes\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = F.relu6(self.bn1(self.conv1(x)))\n        out = self.layers(out)\n        out = F.relu6(self.bn2(self.conv2(out)))\n        out = F.avg_pool2d(out, 7)\n        out = out.view(out.size(0), -1)\n        out = self.linear(out)\n        return out\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## util\n\n# _, term_width = os.popen('stty size', 'r').read().split()\nterm_width = 80\n\nTOTAL_BAR_LENGTH = 65.\nlast_time = time.time()\nbegin_time = last_time\ndef progress_bar(current, total, msg=None):\n    global last_time, begin_time\n    if current == 0:\n        begin_time = time.time()  # Reset for new bar.\n\n    cur_len = int(TOTAL_BAR_LENGTH*current/total)\n    rest_len = int(TOTAL_BAR_LENGTH - cur_len) - 1\n\n    sys.stdout.write(' [')\n    for i in range(cur_len):\n        sys.stdout.write('=')\n    sys.stdout.write('>')\n    for i in range(rest_len):\n        sys.stdout.write('.')\n    sys.stdout.write(']')\n\n    cur_time = time.time()\n    step_time = cur_time - last_time\n    last_time = cur_time\n    tot_time = cur_time - begin_time\n\n    L = []\n    L.append('  Step: %s' % format_time(step_time))\n    L.append(' | Tot: %s' % format_time(tot_time))\n    if msg:\n        L.append(' | ' + msg)\n\n    msg = ''.join(L)\n    sys.stdout.write(msg)\n    for i in range(term_width-int(TOTAL_BAR_LENGTH)-len(msg)-3):\n        sys.stdout.write(' ')\n\n    # Go back to the center of the bar.\n    for i in range(term_width-int(TOTAL_BAR_LENGTH/2)+2):\n        sys.stdout.write('\\b')\n    sys.stdout.write(' %d/%d ' % (current+1, total))\n\n    if current < total-1:\n        sys.stdout.write('\\r')\n    else:\n        sys.stdout.write('\\n')\n    sys.stdout.flush()\n\ndef format_time(seconds):\n    days = int(seconds / 3600/24)\n    seconds = seconds - days*3600*24\n    hours = int(seconds / 3600)\n    seconds = seconds - hours*3600\n    minutes = int(seconds / 60)\n    seconds = seconds - minutes*60\n    secondsf = int(seconds)\n    seconds = seconds - secondsf\n    millis = int(seconds*1000)\n\n    f = ''\n    i = 1\n    if days > 0:\n        f += str(days) + 'D'\n        i += 1\n    if hours > 0 and i <= 2:\n        f += str(hours) + 'h'\n        i += 1\n    if minutes > 0 and i <= 2:\n        f += str(minutes) + 'm'\n        i += 1\n    if secondsf > 0 and i <= 2:\n        f += str(secondsf) + 's'\n        i += 1\n    if millis > 0 and i <= 2:\n        f += str(millis) + 'ms'\n        i += 1\n    if f == '':\n        f = '0ms'\n    return f","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nbest_acc = 0  # best test accuracy\nbest_loss = 1000\nbest_acc_idx = 0\nbest_loss_idx = 0\nstart_epoch = 0  # start from epoch 0 or last checkpoint epoch\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learning_rate = 0.001\ncosine_tmax=200\nbatch_size=128\nepochs=200\ndropout=0.3\narchitecture='mobilenetv2_ln'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_transforms = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.ColorJitter(brightness=(0.2, 2), \n                            contrast=(0.3, 2), \n                            saturation=(0.2, 2), \n                            hue=(-0.3, 0.3)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = \"/kaggle/input/large-covid19-ct-slice-dataset/curated_data/curated_data/\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_datasets = datasets.ImageFolder(path, data_transforms)\n\nclasses = image_datasets.classes\ntrain_size = int(0.8*len(image_datasets))\ntest_size = len(image_datasets)-train_size\n\ntrain_dataset, test_dataset = torch.utils.data.random_split(\n    image_datasets, [train_size, test_size])\n\ntrainloader = torch.utils.data.DataLoader(\n    train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\ntestloader = torch.utils.data.DataLoader(\n    test_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"net = MobileNetv2LN()\nnet = net.to(device)\nprint(summary(net,(3,224,224)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=learning_rate,\n                      momentum=0.9, weight_decay=5e-4)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=cosine_tmax)\n\n# Creates a GradScaler once at the beginning of training.\nscaler = torch.cuda.amp.GradScaler()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training\ndef train(epoch):\n    print('\\nEpoch: %d' % epoch)\n\n    net.train()\n    train_loss = 0\n    correct = 0\n    total = 0\n    closs=0\n    for batch_idx, (inputs, targets) in enumerate(trainloader):\n        inputs, targets = inputs.to(device), targets.to(device)\n        optimizer.zero_grad()\n        \n        with torch.cuda.amp.autocast():\n            outputs = net(inputs)\n            loss = criterion(outputs, targets)\n        \n        scaler.scale(loss).backward()\n#         loss.backward()\n        scaler.step(optimizer)\n#         optimizer.step()\n        # Updates the scale for next iteration.\n        scaler.update()\n        \n        closs=closs+loss.item()\n#         wandb.log({\"batch loss\":loss.item()})\n\n        train_loss += loss.item()\n        _, predicted = outputs.max(1)\n        total += targets.size(0)\n        correct += predicted.eq(targets).sum().item()\n\n        progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n                     % (train_loss / (batch_idx + 1), 100. * correct / total, correct, total))\n#     wandb.log({\"loss\":closs/config.batch_size})\n\ndef test(epoch):\n    global best_acc, best_loss, best_acc_idx, best_loss_idx\n    net.eval()\n    test_loss = 0\n    correct = 0\n    total = 0\n    example_images=[]\n    with torch.no_grad():\n        for batch_idx, (inputs, targets) in enumerate(testloader):\n            inputs, targets = inputs.to(device), targets.to(device)\n            outputs = net(inputs)\n            loss = criterion(outputs, targets)\n\n            test_loss += loss.item()\n            _, predicted = outputs.max(1)\n            total += targets.size(0)\n            correct += predicted.eq(targets).sum().item()\n#             example_images.append(wandb.Image(\n#                 inputs[0], caption=\"Pred: {} Truth: {}\".format(predicted[0].item(), targets[0])))\n            progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n                         % (test_loss / (batch_idx + 1), 100. * correct / total, correct, total))\n    print({\n#         \"Examples\": example_images,\n        \"Test Accuracy\": 100. * correct / len(testloader.dataset),\n        \"Test Loss\": test_loss\n    })\n\n    # Save checkpoint.\n    acc = 100. * correct / total\n    if acc > best_acc:\n        print('Saving best accuracy model..')\n        state = {\n            'net': net.state_dict(),\n            'acc': acc,\n            'epoch': epoch,\n        }\n        if not os.path.isdir('checkpoint'):\n            os.mkdir('checkpoint')\n        torch.save(state, './checkpoint/ckpt.pth')\n        best_acc = acc\n        best_acc_idx = epoch\n\n    if test_loss < best_loss:\n        print('Saving best loss model..')\n        state = {\n            'net': net.state_dict(),\n            'acc': acc,\n            'loss': test_loss,\n            'epoch': epoch,\n        }\n        if not os.path.isdir('checkpoint'):\n            os.mkdir('checkpoint')\n        torch.save(state, './checkpoint/ckpt_loss.pth')\n        best_loss = test_loss\n        best_loss_idx = epoch\n        \n    print({\n        \"best_acc\": best_acc,\n        \"best_acc_idx\": best_acc_idx,\n        \"best_loss\": best_loss,\n        \"best_loss_idx\" : best_loss_idx\n    })","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for epoch in range(start_epoch, start_epoch + epochs):\n    train(epoch)\n    test(epoch)\n    scheduler.step()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Because training takes too long, we evaluate the performance of the best model ended at 47 epochs."},{"metadata":{"trusted":true},"cell_type":"code","source":"test(47)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}