{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction\n\nI'm not doing anything terribly special here. Just creating a catboost classification model and soe visual representations of the results. I know that there's more work to do, but I kind of don't know where I should continue from what I have. Feedback is welcome."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/fetal-health-classification/fetal_health.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA\nThere isn't much cleaning to do here; There aren't any NaN values to replace, and all of the data is already in numerical values. Like the task for the dataset says, there is a class imbalance, but I ignored that for now, thinking that I would come back and stratify later if it was an issue."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.fetal_health.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Column Descriptions\n* Baseline value: Baseline Fetal Heart Rate (FHR)\n* accelerations: Number of Accelerations per second\n* fetal_movement: Number of fetal movements per second\n* uterine_contractions: Number of uterine contractions per second\n* light_decelerations: Number of LDs per second\n* severe_decelerations: Number of SDs per second\n* prolonged_decelerations: Number of PDs per second\n* abnormal_short_term_variability: Percentage of time with abnormal short term variability\n* mean_value_of_short_term_variability: Mean value of short term variability\n* percentage_of_time_with_abnormal_long_term_variability: Percentage of time with abnormal long term variability\n* mean_value_of_long_term_viability: Mean value of long term variability\n* histogram_width: Width of the histogram made using all values from a record\n* histogram_min: Histogram minimum value\n* histogram_max: Histogram maximum value\n* histogram_number_of_peaks: Number of peaks in the exam histogram\n* histogram_number_of_zeroes: Number of Zeroes in the exact histogram\n* histogram_mode: Hist mode\n* histogram_mean: Hist mean\n* histogram_median: Hist median\n* histogram_variance: Hist variance\n* histogram_tendency: Histogram trend\n* fetal_health 1=Normal, 2=Suspect, 3=Pathological"},{"metadata":{},"cell_type":"markdown","source":"I also wanted the results to be in string form, not integer form so that I wouldn't have to remember what they mean."},{"metadata":{"trusted":true},"cell_type":"code","source":"health_map = {\n    1: 'Normal',\n    2: 'Suspect',\n    3: 'Pathological'\n}\n\nfor i in data.index:\n    data.loc[i,'fetal_health'] = health_map[data.loc[i, 'fetal_health']]\ndata.head(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CatBoostCalassifier\n\nI used the hyperparameters from a different notebook for a different dataset. I was also unclear on what the roc_auc meant quantitatively, so I plotted the confusion matrix by prediction to help me make sense of it."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split as TTS\n\nX = data.drop(columns = 'fetal_health')\ny = data.fetal_health\n\nXtrain, Xtest, ytrain, ytest = TTS(X,y, test_size = .3, random_state = 2601744, stratify = y, shuffle = True)\n#Used the recommended test size of %30","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from catboost import CatBoostClassifier\n\ncat = CatBoostClassifier(learning_rate = 0.03, l2_leaf_reg = 1,\n                        iterations = 500, depth = 9,\n                        border_count = 20, eval_metric = 'AUC')\n\ncat = cat.fit(Xtrain, ytrain,\n             eval_set = (Xtest, ytest),\n             early_stopping_rounds = 70, verbose = 20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import plot_confusion_matrix as PCM\n\nPCM(cat, Xtest, ytest, labels = ['Pathological', 'Suspect', 'Normal'], normalize = 'pred',\n   cmap = 'Greens', include_values = True, xticks_rotation = 30)\nplt.title('Confusion Matrix by Prediciton', fontdict = {'fontsize': 18}, pad = 15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here, I'm not exactly sure of where to continue, partially due to a lack of contextual knowledge and partially due to lack of experience.\n\nOn the one hand, I don't know how good this test is in the context of medical tests in general. I do know that the worst possible outcome for this test is the scenario in the top right cell: the false negative prediction of normal condition. That is the one most likely to lead to the death of a baby. Is about a %1.3 chance of a false positive normal (but acutally Pathological) acceptably low in the context of such a test? Is the false positive Normal in the case that the result should be suspect also disasterous? I don't believe that the dataset gave much of an explanation as to what the difference is between a Pathological case and a Suspect.\n\nOn the other hand, I'm not sure about what I should do first to try to improve this model. I did basically no feature engineering, but I'm not sure what I should start with to improve the model and if the results I'm seeing here indicate that I should do something first. Should I stratify the sampling first or work on tuning the hyperparameters?\n\nThanks for reading and any input is appreciated."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}