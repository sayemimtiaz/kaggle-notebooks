{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Top Women Chess Players\n\n<hr>"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"Context\nThe International Chess Federation (FIDE) governs international chess competition. FIDE used Elo rating system for calculating the relative skill levels of players.\n\nContent\nThe dataset contains details of Top women chess players in the world sorted by their Standard FIDE rating (highest to lowest above 1800 Elo) as updated in August 2020. The data includes all active and inactive players which can be identified by the Inactive_flag column.\n\nNote: All ratings are updated as published by FIDE in August 2020.\n\nAcknowledgements\nFIDE: https://www.fide.com/"},{"metadata":{},"cell_type":"markdown","source":"# Summary\n\n<hr>\n\n* 1 - [Import libraries and data](#a)\n* 2 - [Distributions analysis](#b)\n* 3 - [No title group](#c)\n* 4 - [Radar plot](#d)\n* 5 - [Prediction of the Federation](#e)"},{"metadata":{},"cell_type":"markdown","source":"## 1 - Import libraries and data <a id=a><a/>"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(r'/kaggle/input/top-women-chess-players/top_women_chess_players_aug_2020.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data.info())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2 - Distributions analysis <a id='b'><a/>\n<hr>"},{"metadata":{},"cell_type":"markdown","source":"### In this notebook:\nWe will do some explanatory analysis and clustering. I will try to analyse original aspects of this dataset.\nFirst, it's usefull to plot a pairplot graph. It's giving us good informations on the distribution and links between columns."},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\ndata_sorted = data.sort_values(by='Standard_Rating', ascending=False)\ndata_sorted.Title = data_sorted.Title.fillna('No title')\ndf = data_sorted.loc[:,['Title','Year_of_birth','Standard_Rating','Rapid_rating','Blitz_rating']]\nsns.pairplot(df, hue=\"Title\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can observe linear regression between the three different rating, it could be interesting to calculate it but this is not original.\n\n### Other fact:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib import patches\n\nf, ax = plt.subplots(figsize=(10,10))\nsns.scatterplot(x=\"Year_of_birth\", y=\"Rapid_rating\",\n                hue=\"Title\",\n                sizes=(1, 8),\n                data=data_sorted, ax=ax)\n\nax.add_artist(\n    patches.Rectangle((1995, 1200),15,400, color = 'r', zorder = 1, alpha=0.1))\n\nax.annotate('Young area', (1995,1400),(1980,1405), arrowprops=dict(facecolor='black'))\nplt.title('Rapid_rating')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that only young are under 1600 "},{"metadata":{},"cell_type":"markdown","source":"## 3 - No Title group <a id='c'><a/>\n\n<hr>"},{"metadata":{},"cell_type":"markdown","source":"The column Title is filled with the level of the players, however a group has no title. \n> ### My first idea was to determine their affilation to an existing group.\n\nI used a statistical test based on population quantiles named mann-whitney-u test.\nI used it and not the T test because some distributions are not normally distributed.\nIt compares the median of two samples and said if they are close enough to conclude they are equals."},{"metadata":{"trusted":true},"cell_type":"code","source":"import scipy.stats as stat","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def best_group_proximity(dataset, Title, target):\n    \"\"\"\n    dataset: DataFrame\n    Title: group you want to analyse (str)\n    target: On which data (str)\n    \n    return: Name of the closest group to 'Title' (str)\n    \"\"\"\n    results = pd.Series(dtype='float64')\n    for group in dataset.Title.loc[dataset.Title!=Title].unique():\n        print(group)\n        w, p = stat.mannwhitneyu(dataset[dataset.Title==Title][target], dataset[dataset.Title==group][target])\n        print(stat.mannwhitneyu(dataset[dataset.Title==Title][target], dataset[dataset.Title==group][target]))\n        results.loc[group] = p\n    print('---end---')\n    return results.sort_values(ascending=False).index[0]\n        \nbest_group_proximity(data_sorted, 'No title', 'Rapid_rating')\nbest_group_proximity(data_sorted, 'No title', 'Blitz_rating')\nbest_group_proximity(data_sorted, 'No title', 'Standard_Rating')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The No title group is close to WH group: Pval > 5% only for standard_Rating."},{"metadata":{},"cell_type":"markdown","source":"## 4 - Radar plot <a id='d'><a/>\n\n<hr>\n\nWe want to compare the stats of the players. We decided to create a radar chart."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fillna\ndata_sorted[['Standard_Rating','Rapid_rating','Blitz_rating']] = data_sorted[['Standard_Rating','Rapid_rating','Blitz_rating']].fillna(0)\ndata_sorted","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The two following cells are overriding RadarAxes object and defining functions usefull for the creation of the radar plot"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.path import Path\nfrom matplotlib.spines import Spine\nfrom matplotlib.projections.polar import PolarAxes\nfrom matplotlib.projections import register_projection\n\n\ndef radar_factory(num_vars, frame='circle'):\n    \"\"\"Create a radar chart with `num_vars` axes.\n\n    This function creates a RadarAxes projection and registers it.\n\n    Parameters\n    ----------\n    num_vars : int\n        Number of variables for radar chart.\n    frame : {'circle' | 'polygon'}\n        Shape of frame surrounding axes.\n\n    \"\"\"\n    # calculate evenly-spaced axis angles\n    theta = np.linspace(0, 2*np.pi, num_vars, endpoint=False)\n\n    def draw_poly_patch(self):\n        # rotate theta such that the first axis is at the top\n        verts = unit_poly_verts(theta + np.pi / 2)\n        return plt.Polygon(verts, closed=True, edgecolor='k')\n\n    def draw_circle_patch(self):\n        # unit circle centered on (0.5, 0.5)\n        return plt.Circle((0.5, 0.5), 0.5)\n\n    patch_dict = {'polygon': draw_poly_patch, 'circle': draw_circle_patch}\n    if frame not in patch_dict:\n        raise ValueError('unknown value for `frame`: %s' % frame)\n\n    class RadarAxes(PolarAxes):\n\n        name = 'radar'\n        # use 1 line segment to connect specified points\n        RESOLUTION = 1\n        # define draw_frame method\n        draw_patch = patch_dict[frame]\n\n        def __init__(self, *args, **kwargs):\n            super(RadarAxes, self).__init__(*args, **kwargs)\n            # rotate plot such that the first axis is at the top\n            self.set_theta_zero_location('N')\n            self.angle = theta\n\n        def fill(self, *args, **kwargs):\n            \"\"\"Override fill so that line is closed by default\"\"\"\n            closed = kwargs.pop('closed', True)\n            return super(RadarAxes, self).fill(closed=closed, *args, **kwargs)\n\n        def plot(self, *args, **kwargs):\n            \"\"\"Override plot so that line is closed by default\"\"\"\n            lines = super(RadarAxes, self).plot(*args, **kwargs)\n            for line in lines:\n                self._close_line(line)\n\n        def _close_line(self, line):\n            x, y = line.get_data()\n            # FIXME: markers at x[0], y[0] get doubled-up\n            if x[0] != x[-1]:\n                x = np.concatenate((x, [x[0]]))\n                y = np.concatenate((y, [y[0]]))\n                line.set_data(x, y)\n\n        def set_varlabels(self, labels):\n            self.set_thetagrids(np.degrees(theta), labels)\n            \n        def label_pos(self):\n            for label, angle_rad in zip(self.get_xticklabels(), self.angle):\n                if angle_rad == 0 or angle_rad == np.pi:\n                    ha = 'center'\n                elif angle_rad == np.pi/2:\n                    ha = 'right'\n                elif angle_rad == 3*np.pi/2:\n                    ha = 'left'\n                label.set_horizontalalignment(ha)             \n\n        def _gen_axes_patch(self):\n            return self.draw_patch()\n\n        def _gen_axes_spines(self):\n            if frame == 'circle':\n                return PolarAxes._gen_axes_spines(self)\n            # The following is a hack to get the spines (i.e. the axes frame)\n            # to draw correctly for a polygon frame.\n\n            # spine_type must be 'left', 'right', 'top', 'bottom', or `circle`.\n            spine_type = 'circle'\n            verts = unit_poly_verts(theta + np.pi / 2)\n            # close off polygon by repeating first vertex\n            verts.append(verts[0])\n            path = Path(verts)\n\n            spine = Spine(self, spine_type, path)\n            spine.set_transform(self.transAxes)\n            return {'polar': spine}\n\n    register_projection(RadarAxes)\n    return theta\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def unit_poly_verts(theta):\n    \"\"\"Return vertices of polygon for subplot axes.\n\n    This polygon is circumscribed by a unit circle centered at (0.5, 0.5)\n    \"\"\"\n    x0, y0, r = [0.5] * 3\n    verts = [(r*np.cos(t) + x0, r*np.sin(t) + y0) for t in theta]\n    return verts\n\n\nclass Players():\n    \"\"\"Create players object with their stats like attributes.\n    \n    Params: str\n            players name (like it's written in the dataset)\n    \"\"\"\n    def __init__(self, *args):\n        self.data, self.titles, self.federation = self.chess_players(*args)\n        self.players = [p+' in '+t[0]+' from '+f[0] for p,t,f in zip(args, self.titles, self.federation)]\n        \n    def chess_players(self, *args):\n        names, stats, titles, federation = self.get_chess_stats(*args)\n        data = [\n            ['Age', 'Standard_Rating', 'Rapid_rating', 'Blitz_rating'],\n            (names, stats)\n        ]\n        return data, titles, federation\n\n    def get_chess_stats(self, *args, data=data_sorted.copy()):\n        stat_default = [0,0,0,0]\n        try:\n            return (' vs '.join(args),\n                data.loc[data.Name.isin(args),['Year_of_birth', 'Standard_Rating', 'Rapid_rating', 'Blitz_rating']].fillna(0).values + stat_default,\n                data.loc[data.Name.isin(args),['Title']].values,\n                data.loc[data.Name.isin(args),['Federation']].values)\n        except ValueError:\n            return (stat_default,'No title')\n        \n\ndef _scale_data(data, ranges):\n    \"\"\"\n    Need to scale the data to have different scale on a same radar plot\n    Params: \n    \n    data: list\n          The values of yours players\n    ranges: tuple\n            Limits of each axes\n    \"\"\"\n    x1, x2 = ranges[0]\n    d = data[0]\n    sdata = [d]\n\n    for d, (y1, y2) in zip(data[1:], ranges[1:]):\n        sdata.append((d-y1) / (y2-y1) * (x2 - x1) + x1)\n\n    return sdata\n\ndef append_label(label, value, ranges):\n    \"\"\"\n    Append value in label and remove closest values\n    Params: \n    label: list\n           Grid and players values\n    value: numpy.array\n           Values to append\n    ranges: tuple\n            Limits of each axes\n    \"\"\"\n    for val in value:\n        x = label - val\n        perc = (max(ranges) - min(ranges)) * 10 / 100\n        label = [label[i] for i,e in enumerate(x) if abs(e)>perc] \n    label = label + value.astype('int').tolist()\n    return label\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Main script"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get players\nN = 4\ntheta = np.degrees(radar_factory(N, frame='circle'))\n\n# Add players to compare them\nplayers = Players('Vorpahl, Sina Fleur','Gochoshvili, Anetta')\nspoke_labels = players.data.pop(0)\n \n#Create figure\nfig = plt.figure(figsize=(10,10))\n    \nfig.subplots_adjust(wspace=0.25, hspace=0.20, top=0.85, bottom=0.05)\n   \n#Create 4 differents axes for the 4 differents scales\naxes = [fig.add_axes([0.05, 0.05, 0.95, 0.95], projection=\"radar\", label=\"axes%d\" % i) \n                     for i in range(len(spoke_labels))]\n\n#Main axes where the data will be plot\naxe1 = axes[0]\naxe1.set_thetagrids(theta, labels=spoke_labels, fontsize=12, weight=\"bold\", color=\"black\")\naxe1.yaxis.grid(False)\naxe1.label_pos()\n    \ntitle, case_data = players.data[0]\n   \n#Set invisible the other axes but not the grid\nfor ax in axes[1:]:\n    ax.patch.set_visible(False)\n    ax.grid(\"off\")\n    ax.xaxis.set_visible(False)\n    ax.yaxis.grid(False)\n\n# Define limits\nranges = [[1950, 2010], [1500, 2900],[1500, 2900], [1500, 2900]] \nranges_grid = [list(range(1960,2000, 10)),\n                   list(range(1600,2800,200)),\n                   list(range(1600,2800,200)),\n                   list(range(1600,2800,200))]\n\n# For each axe we are defining the grid.\ni=0\nfor ax, angle, lim, label in zip(axes, theta, ranges, ranges_grid):\n    label = append_label(label, case_data[:,i], lim)\n    ax.set_rgrids(label, labels=label, angle=angle)\n    ax.spines[\"polar\"].set_visible(False)\n    ax.set_ylim(*lim)  \n    ax.xaxis.grid(True,color='black',linestyle='-')\n    i += 1\n        \naxe1.set_title(title, weight='bold', size='medium', position=(0.5, 1.1),\n                     horizontalalignment='center', verticalalignment='center')\n\n#Plot\ncolor = ['b', 'r', 'g','y','black']\nfor d, c in zip(case_data, color):\n    angle = np.deg2rad(np.r_[theta])\n    sdata = _scale_data(d, ranges)\n    axe1.plot(angle, np.r_[sdata], color=c)\n    axe1.fill(angle, np.r_[sdata], facecolor=c, alpha=0.25)\n        \nlabels = players.players\nlegend = fig.legend(labels, loc=(0.7, .85),\n                       labelspacing=0.1, fontsize='small')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Prediction of the Federation <a id='e'><a/>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.gaussian_process.kernels import RBF\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.linear_model import LogisticRegression, LogisticRegressionCV\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.multioutput import MultiOutputClassifier\nimport xgboost\nfrom sklearn.model_selection import ParameterGrid\nimport sklearn\nimport eli5\nfrom eli5.lime import TextExplainer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder = LabelEncoder()\nY = encoder.fit_transform(data_sorted.Federation)\nX_train, X_test, y_train, y_test = train_test_split(data_sorted.Name.str.replace(',',''), \n                                                    Y, random_state=0, test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classes = [MultinomialNB(),\n           SGDClassifier(),\n           KNeighborsClassifier(),\n           RandomForestClassifier(), \n           AdaBoostClassifier(),\n           LogisticRegression(),\n           xgboost.XGBClassifier()\n]\n\nfor cls in classes:\n    \n    txt_cls = Pipeline([\n        ('vect', CountVectorizer(analyzer='char', ngram_range=(1,4))),\n        ('model', cls)\n    ])\n    \n    txt_cls.fit(X_train, y_train)\n    print('accuracy: '+str(txt_cls.score(X_test, y_test)))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"txt_cls = Pipeline([\n        ('vect', CountVectorizer(analyzer='char')),\n        ('model', LogisticRegression())\n    ])\n    \nparameters = {\n    'vect__ngram_range':[(1,2),(1,3),(1,4)],\n    'model__solver':['lbfgs'],\n    'model__C': [1, 1.5, 2],\n }\n\ntxt_cls = GridSearchCV(txt_cls, parameters)\ntxt_cls.fit(X_train, y_train)\nfor param_name in sorted(parameters.keys()):\n    print(\"%s: %r\" % (param_name, txt_cls.best_params_[param_name]))\nprint('accuracy: '+str(txt_cls.score(X_test, y_test)))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}