{"cells":[{"metadata":{"_cell_guid":"3f196ae2-25cb-42d5-89ec-f1cfc367f3ba","_uuid":"921952644dccef41a343cd00d283f06717026974"},"cell_type":"markdown","source":"**    Based on the given attributes predict the flower class. **\n    **Lets start with importing data and checking the first few rows of the data**"},{"metadata":{"scrolled":false,"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\nfrom pandas.plotting import scatter_matrix\nimport matplotlib.pyplot as plt\n\nplt.style.use('seaborn-colorblind')\n\ncol_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\ndataset = pd.read_csv('../input/iris-dataset/iris.csv', header= None, names=col_names)\niris_class = {'Iris-setosa':0, 'Iris-versicolor':1, 'Iris-virginica':2}\ndataset['species_num'] = [iris_class[i] for i in dataset.species]\nX = dataset.drop(['species', 'species_num'], axis=1)\ndataset.head()","execution_count":1,"outputs":[]},{"metadata":{"_cell_guid":"d670420a-168e-47a7-be76-b93a095a1fce","_uuid":"c6d98b2812d9166483a34b8f14c70caf76fc1c27"},"cell_type":"markdown","source":"    Visualizations will help in understanding our data in more better way. Following are the few visualiazations like :\n*  Histogram\n*  Line chart\n*  Kernel Density Chart\n*  Box plot"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"dataset[['sepal_length','sepal_width','petal_length', 'petal_width']].plot.hist(alpha=0.7);","execution_count":2,"outputs":[]},{"metadata":{"_cell_guid":"6b9f791e-1634-4056-94b6-39cbc45f7074","_uuid":"76e281ec584b130c4d0b918ca5f46e1706f64fca","trusted":true},"cell_type":"code","source":"dataset[['sepal_length','sepal_width','petal_length', 'petal_width']].plot();","execution_count":3,"outputs":[]},{"metadata":{"scrolled":true,"_cell_guid":"f908b9b8-9c1f-4842-a3dd-82fdff142284","_uuid":"63f0eaec2aa0f3dae05f2a7896aecfea2099afb0","trusted":true},"cell_type":"code","source":"dataset[['sepal_length','sepal_width','petal_length', 'petal_width']].plot.kde();","execution_count":4,"outputs":[]},{"metadata":{"scrolled":true,"_cell_guid":"c1f484d9-00cf-4963-865a-8d072661bf97","_uuid":"6bfc6af16188bfcd88ac0ee9818a529fbabf526d","trusted":true},"cell_type":"code","source":"dataset[['sepal_length','sepal_width','petal_length', 'petal_width']].plot.box();","execution_count":5,"outputs":[]},{"metadata":{"_cell_guid":"f6b93d2c-82e5-4ee1-9b04-62935b50354a","_uuid":"599f055b7780ab7bed514574c3a5f34f7aa13106","trusted":true},"cell_type":"code","source":"sns.pairplot(dataset[['sepal_length','sepal_width','petal_length', 'petal_width','species']], hue='species', diag_kind='kde', size=2);","execution_count":6,"outputs":[]},{"metadata":{"_cell_guid":"be03a47d-dfc7-4248-8929-0685d614e1ad","_uuid":"6f0a580c7757905bd87a87b04ee6ef7216a38558","trusted":true},"cell_type":"code","source":"## Create an 'X' matrix by dropping the irrelevant columns.\nX = dataset.drop(['species', 'species_num'], axis=1)\ny = dataset.species_num\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n## Import the Classifier.\n\n## Instantiate the model with 5 neighbors. \nknn = KNeighborsClassifier(n_neighbors=5)\n## Fit the model on the training data.\nknn.fit(X_train, y_train)\npred = knn.predict(X_test)\nprint (\"The accuracy of the model - \", format(accuracy_score(y_test, pred) * 100))","execution_count":7,"outputs":[]},{"metadata":{"_uuid":"57ff48704f4e5a0ada9b5748cbf04683b685b0b7"},"cell_type":"markdown","source":"Lets implement K-NN for Regression also.  We will make a sample regression dataset using sklearn.\n1.  We will generate 100 test samples for regression"},{"metadata":{"_uuid":"83bdf15470b7006c8e4e33154c7159500d1879c0","trusted":true},"cell_type":"code","source":"# synthetic dataset for simple regression\nfrom sklearn.datasets import make_regression\nplt.figure()\nplt.title('Sample regression problem with one input variable')\nX_R1, y_R1 = make_regression(n_samples = 100, n_features=1,\n                            n_informative=1, bias = 150.0,\n                            noise = 30, random_state=0)\nplt.scatter(X_R1, y_R1, marker= 'o', s=50)\nplt.show()","execution_count":8,"outputs":[]},{"metadata":{"_uuid":"bce6b46dd109a70cbdec233496abcaf4e9e17114"},"cell_type":"markdown","source":"     Lets implement the k-NN for regression problem using the above sample regression dataset"},{"metadata":{"scrolled":true,"_uuid":"ca338a98f7a31d27d8cad43eac14c4b59805e45d","trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsRegressor\n\nX_train, X_test, y_train, y_test = train_test_split(X_R1, y_R1, random_state = 0)\nknnreg = KNeighborsRegressor(n_neighbors = 5).fit(X_train, y_train)\ntrain_score = knnreg.score(X_train, y_train)\ntest_score = knnreg.score(X_test, y_test)\nplt.plot(X_train, y_train, 'o', alpha=0.9, label='Train')\nplt.plot(X_test, y_test, '^', alpha=0.9, label='Test')\nplt.xlabel('Input feature')\nplt.ylabel('Target value')\nplt.title('KNN Regression (K={})\\n Train $R^2 = {:.3f}$,  Test $R^2 = {:.3f}$'.format(5, train_score, test_score))\nplt.legend()\nfig = plt.figure(figsize=(18, 18))\n\nplt.show()\n#print(knnreg.predict(X_test))\n#print('R-squared test score: {:.3f}'.format(knnreg.score(X_test, y_test)))","execution_count":9,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"8fd7645e5912105a86c6223f64986585a96d6118","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}