{"cells":[{"metadata":{},"cell_type":"markdown","source":"#### Introduction\n\nAs a former Business Intelligence Analyst, now part of an Advanced Analytics team, I have been in the past months focusing on the enhancement my technical skills (Python, pandas, SkLearn, etc). \nThanks to the great diversity of e-learning courses and blogs I covered the basic tools of Data Science, allowing me to start playing around predictive models in simple use cases (thanks Kaggle!). \n\nThis being said, my first goal for this work was to contribute to the online librairy of use cases for beginners like me. Hope it will help you! \n\n#### Goal of the analysis\n\nIdentify the predictors of the daily bike traffic in Seattle and build a simple predictive model.\n\n#### Agenda\n\nIn this notebook I will cover the 3 main steps to follow to produce simple regression model and assess their performance : \n\n    I. Environment setup\n    \n    II.Exploratory data analysis\n    \n    III. Building a predicive model \n        A. Multivariate linear regression\n        B. Decision tree & Random Forest regression\n    \n\nThis notebook is based on the great Python Data Science Handobook by Jake VanderPlas, I highly recommend it for your learning journey!\nhttps://jakevdp.github.io/PythonDataScienceHandbook/"},{"metadata":{},"cell_type":"markdown","source":"# **I. Environment set up**"},{"metadata":{},"cell_type":"markdown","source":"#### Import relevant librairies"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Get the datasets from the following 2 open sources for the city of Seattle : \n\nSeattle Fremonth bridge bike count : https://data.seattle.gov/api/views/65db-xm6k/rows.csv?accessType=DOWNLOADssType=DOWNLOAD\n\nWeather data of Seattle : https://www.ncdc.noaa.gov/cdo-web/search?datasetid=GHCND\n            Use the location ID as Search term : USW00024233"},{"metadata":{},"cell_type":"markdown","source":"#### Import datasets, here from csv file with pd.read_csv(\"directory/file.csv\")"},{"metadata":{"trusted":true},"cell_type":"code","source":"traffic_data = pd.read_csv('../input/Fremont_Bridge_Bicycle_Counter.csv', index_col='Date', parse_dates=True)\nweather_data = pd.read_csv('../input/Seattle_weather_daily.csv', index_col='DATE', parse_dates=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Quickly visualize the 'head', by default the top 5 observations of the panda dataframe : using [.head()] or [.tail()] to print the last 5 \n\nNote that you can only print the head of 1 dataframe at a time, create an extra cell to print the head of the second dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"traffic_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weather_data.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> # **II. Exploratory data analysis**"},{"metadata":{},"cell_type":"markdown","source":"A quick way to get a first grasp of the dataset is the print its shape (number of observations,number of columns)"},{"metadata":{"trusted":true},"cell_type":"code","source":"weather_data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Another useful function to get the descriptive statistics include those that summarize the central tendency, dispersion and shape of a dataset’s distribution, excluding NaN values.\nsource : https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html?highlight=describe#pandas.DataFrame.describe"},{"metadata":{"trusted":true},"cell_type":"code","source":"weather_data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"traffic_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"traffic_data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"traffic_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The traffic data set contains hourly measures, on both sides of the bridge. \nWe only need daily totals for the purpose of the analysis, thus we will resample the data to get to the daily traffic (similar to group by day)."},{"metadata":{"trusted":true},"cell_type":"code","source":"daily = (\n    traffic_data\n    .resample('d')\n    .sum()\n    .loc[:, ['Fremont Bridge Total']]\n    .rename(\n        columns={\n            'Fremont Bridge Total': 'Total'\n        }\n    )\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note that we used the Modern Pandas to increase the readability of our code. \n\nCheck it out here : https://tomaugspurger.github.io/modern-1-intro.html"},{"metadata":{"trusted":true},"cell_type":"code","source":"daily.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Resampling\n\nTo get a better grasp of traffic variation in the monthl/yearl/hourl, we cna resample the daily data to show plot trends.  \n\nSee full pandas documentation here : https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#resampling\n\nAnd some documentation regarding the possibilities of the DateOffets object : https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#dateoffset-objects\n\n\n##### By month\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"monthly = (\n    traffic_data\n    .resample('m')\n    .sum()\n).plot(figsize = (15,5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### By hour"},{"metadata":{"trusted":true},"cell_type":"code","source":"by_time = (\n    traffic_data\n    .groupby(traffic_data.index.time)\n    .mean()\n)\n\nhourly_ticks = 4 * 60 * 60 * np.arange(6)\n\nby_time.plot(xticks=hourly_ticks, style=[':', '--', '-']);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can here clearly read 2 peaks of traffic during the day : a strong one in the morning on the East side of the Bridge (residential area?) and a second in the evening on the West side (business district?). \n\n##### By day of the week"},{"metadata":{"trusted":true},"cell_type":"code","source":"by_weekday = (\n    traffic_data\n    .groupby(traffic_data.index.dayofweek)\n    .mean()\n)\nby_weekday.index = ['Mon', 'Tues', 'Wed', 'Thurs', 'Fri', 'Sat', 'Sun']\nby_weekday.plot(style=[':', '--', '-']);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" We can see on the figure above that weekdays register a higher traffic than during weekends,this support our hypothesis of communiting towards business district. \n  \nIn order to take this information in account for our model, we will assign the day of the week to our daily traffic data. \n\nWe are here starting to actually build the data set on which we will train our model to predict the numbe rof bikes per day. The step is called feature engineering and his the first step to take to build or improve a predictive model. \n "},{"metadata":{},"cell_type":"markdown","source":"> # **III. Building a predictive model**"},{"metadata":{},"cell_type":"markdown","source":"#### 1. Feature engineering\n\n##### Week day label \nWe could simply create an extra column with the label of each date (nominal metric). BUT as we are planning to build a linear regression model afterwards, and this model can only support continuous data. We will create a binary column for each day. \n\nFor further info on ' Feature engineering' : \nhttps://jakevdp.github.io/PythonDataScienceHandbook/05.04-feature-engineering.html"},{"metadata":{"trusted":true},"cell_type":"code","source":"### let's assign those days of the week labels in the dataset itself \n\ndaily = (\n    daily\n    .assign(\n        day_of_week=lambda _df: _df.index.dayofweek\n    )\n    .pipe(pd.get_dummies, columns=['day_of_week'])\n    .rename(\n        columns={\n            'day_of_week_0': 'Mon',\n            'day_of_week_1': 'Tue',\n            'day_of_week_2': 'Wed',\n            'day_of_week_3': 'Thu',\n            'day_of_week_4': 'Fri',\n            'day_of_week_5': 'Sat',\n            'day_of_week_6': 'Sun'\n        }\n    )\n)\ndaily.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### National holidays \n\nIf working days have such an impact on the traffic, we might want to check also for the impact of holidays.\n\nUS holiday calendar available directly in panda timeseries !\n\nWe will add this information in a new binary column 'holiday'"},{"metadata":{"trusted":true},"cell_type":"code","source":"from pandas.tseries.holiday import USFederalHolidayCalendar\ncal = USFederalHolidayCalendar()\nholidays = cal.holidays('2012', '2020')\ndaily = daily.join(pd.Series(1, index=holidays, name='holiday'))\ndaily['holiday'].fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(\n    daily\n    .loc[daily.holiday == 1]\n    .reset_index()\n    .sort_values(by= \"Date\")\n    .tail(10)\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looking at 2019 national holidays, we see that the Xmas period only counts 1 official day off on the 25th whereas people tend to take longer breaks that will not then be accounted for. Let's keep this in mind and see if correction will be needed to improve performance of our model. "},{"metadata":{},"cell_type":"markdown","source":"##### Weather data\n\nOur daily dataset is now ready, we still need to fix the weather dataset by : \n\nConverting metrics in the right unit of measure (like Celsius for Temperature) \n\nMerger with the weather dataframe with the daily one based on Date\n\nDrop missing value before running our linear model trial"},{"metadata":{"trusted":true},"cell_type":"code","source":"weather_data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weather_data.tail(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Temperatures are in 1/10 deg C; convert to C\nweather_data['Temp (C)'] = (weather_data['TAVG'] - 32)/(9/5)\n\n# We can create a new binomial metric 'Dry day' as day with or without precipitation\nweather_data['dry day'] = (weather_data['PRCP'] == 0).astype(int)\n\n# Join the 2 datasets\ndaily = daily.join(weather_data[['PRCP', 'Temp (C)', 'dry day']])\n\n# Drop any rows with null values\ndaily.dropna(axis=0, how='any', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"daily.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can add quick and easy plot to show the relationships between some of these variables and the target (Total).\n\n##### Dry Days"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x='dry day', y='Total', data=daily, hue='dry day')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dry days have a higher traffic median than rainy ones, this features is positively correlated with the Total traffic target metric. \n\n##### Temperature"},{"metadata":{},"cell_type":"markdown","source":"to check correlation between Temperature and Traffic we will use the more advanced Joint plot from Seaborn library that replaces the scatterplots and histograms with density estimates. It gives indication on both distribution and direction of the relationship."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.jointplot(daily['Temp (C)'], daily['Total'], kind='kde')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that the relationship between total traffic and temp is positive, meaning the higher the temperature the higher the traffic."},{"metadata":{},"cell_type":"markdown","source":"#### 2. Multivariate linear regression \n\nLet's build our very first model to see if the select metrics have linear relationship with the total number of riders \nto do so we use SkLearn LinearRegression model, predicting the number of riders based on the selected independant variables \nand finally comparing with the actual count of riders."},{"metadata":{"trusted":true},"cell_type":"code","source":"daily.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"column_names = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun', 'holiday','dry day', 'Temp (C)']\nX = daily[column_names] # define the independant varibles \ny = daily['Total'] # define the target value, the dependant variable\n\nfrom sklearn.model_selection  import train_test_split   \nXtrain, Xtest, ytrain, ytest = train_test_split(X, y, random_state=1)  ## split the dataset in train and test sub-sets\n\nfrom sklearn.linear_model import LinearRegression # 1. choose model class\nmodel = LinearRegression(fit_intercept=False)     # 2. instantiate model\nmodel.fit(Xtrain, ytrain)                         # 3. fit model to train data\ny_model = model.predict(Xtest)                    # 4. predict on new test data\n\nfrom sklearn.metrics import r2_score\nr2_score(ytest, y_model)  ## check score of the model chosen","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection  import cross_validate\ncv = cross_validate(model, X, y, cv=10, return_train_score=True)\ncv_df = pd.DataFrame({\"train_score\": cv[\"train_score\"], \"test_score\": cv[\"test_score\"]})\ncv_df","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"print(cv_df[\"train_score\"].mean(),cv_df[\"test_score\"].mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"By default the score used in linear regression is the coefficient of determination R2. \nIt is the proportion of the variance in the dependent variable that is predictable from the independent variable(s).\nIt ranges from 0 to 1."},{"metadata":{},"cell_type":"markdown","source":"The linear model we have build has a score of 0.77 on unseen (test) data, a fair score for a straighforward linear regression. \nTo understand how to enhance the model we can look at gaps between actual and predicted (error) :"},{"metadata":{"trusted":true},"cell_type":"code","source":"daily['predicted'] = model.predict(X) # add the predicted number of riders in the orginial data set\ndaily[['Total', 'predicted']].plot(figsize =(20,10), legend=True);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can have a look at the coefficient of all independant variables of our multivariate linear model.\nOur regression model has found the optimal coefficients for all the attribute. \n\nHere is how to read it : \nFor each increase of 1 degree of Temperature(Celsius), we have around +100 bikers on the bridge."},{"metadata":{"trusted":true},"cell_type":"code","source":"coeff_df = pd.DataFrame(model.coef_, X.columns, columns=['Coefficient'])\ncoeff_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above results conforts us in saying that bike traffic is mainly due to work commute as days of the week have a positive effect on traffic, with no big difference on the day itself. Whilst weekends tends to see a decrease of traffic, so are holidays. \n\nWeather condition also have an impact with dry days and high temperature do influence traffic in a positive way. "},{"metadata":{},"cell_type":"markdown","source":"Let's have a quick look at the errors of our model, the difference between our Total traffic and predicted one. \nAs we do not have the same number of datapoints per year (e.g. in 2020 I only had 31 days of data), we will use the average error instead of the sum. \n(You can check that you have less data points for 2020 by doing daily.resample('y').count()"},{"metadata":{"trusted":true},"cell_type":"code","source":"daily[\"error\"]= (daily.predicted - daily.Total).astype(int)\ndaily[\"error_abs\"]= (daily.predicted - daily.Total).abs().astype(int)\n\nmonthly_error = daily.resample('m').mean().reset_index()\nmonthly_error.plot(x=\"Date\", y=[\"Total\",\"predicted\"], figsize=(15,5))\nyear_error = daily.resample('y').mean().reset_index()\nyear_error.plot(x=\"Date\", y=[\"error_abs\"], figsize=(15,5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Overall our linear model as a faire prediction score (0.77). Looking at the monthly graph, we see gaps year on year we could compensate by intrucing additional features. Indeed national holidays may not be accurate enought, we might want to try the model with holiday 'periods' based on scolar breaks for instance : Xmas and Summer periods.\n\nIn addtion, with the above yearly graph we see that the model had a steady performance from 2013-2018, but for 2019 the bike traffic has been highly underestimated. This may be due to an increase of bike usage in the population itself. \n\nLet's do some additional feature engineering to cover the 2 points above and try to improve the accuracy score of our linear regression."},{"metadata":{},"cell_type":"markdown","source":"#### 3. Model enhancement\n\n##### Holiday period\nResampling by month allow use to see if the error tend to repeat for specific month on the year.\nThe plot below shows indeed that summer and Xmas periods tend to be over estimated. "},{"metadata":{"trusted":true},"cell_type":"code","source":"monthly_error = (\n    daily\n    .resample('m')\n    .mean()\n    .reset_index()\n)\nmonthly_error.plot(x='Date',y='error', figsize=(15,5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The holiday calendar imported before only includes national holiday thus does not cover this notion of holiday period.\n\nLooking at error per month we see that December, July and August tend to be over estimated year on year. "},{"metadata":{"trusted":true},"cell_type":"code","source":"(\n    monthly_error\n    .sort_values(by ='error')\n    .tail(5)\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's create 2 new features : Xmas_period and Summer_period to integrate those notions to our model. "},{"metadata":{},"cell_type":"markdown","source":"We will define Xmas (December) and Summer (July & August) periods as full month periods for simplicity. "},{"metadata":{"trusted":true},"cell_type":"code","source":"daily =(\n    daily\n    .assign(\n        month_num=lambda _df: _df.index.month, # get the month number from date\n        Xmas_period=lambda _df: _df['month_num'] == 12,\n        Summer_period=lambda _df: _df['month_num'].isin([7, 8])\n    )\n    .drop(columns=['month_num'])\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 4. Performance comparision \n\nWe will now try again the multivariate linear regression model with the additional 2 holiday periods features. "},{"metadata":{"trusted":true},"cell_type":"code","source":"column_names_fe = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun', 'holiday','dry day', 'Temp (C)','Xmas_period','Summer_period']\nX_fe = daily[column_names_fe] # define the independant varibles \ny_fe = daily['Total'] # define the target value, the dependant variable\n\nXtrain, Xtest, ytrain, ytest = train_test_split(X_fe, y_fe, random_state=1)  ## split the dataset in train and test sub-sets\n\nmodel = LinearRegression(fit_intercept=False)     # 2. instantiate model\nmodel.fit(Xtrain, ytrain)                         # 3. fit model to train data\ny_model = model.predict(Xtest)\n\nr2_score(ytest, y_model)  ## check score of the model chosen","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv = cross_validate(model, X_fe, y_fe, cv=10, return_train_score=True)\ncv_df = pd.DataFrame({\"train_score\": cv[\"train_score\"], \"test_score\": cv[\"test_score\"]})\ncv_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(cv_df[\"train_score\"].mean(),cv_df[\"test_score\"].mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"coeff_df = pd.DataFrame(model.coef_, X_fe.columns, columns=['Coefficient'])\ncoeff_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that those 2 holiday periods have a negative impact on the number of bikers on the road. "},{"metadata":{"trusted":true},"cell_type":"code","source":"daily['predicted_fe'] = model.predict(X_fe) # incoporated the predicted number of riders in the orginial data set\n\ndaily[\"error_fe\"]= (daily.predicted_fe - daily.Total).astype(int)\ndaily[\"error_fe_abs\"]= (daily.predicted - daily.Total).abs().astype(int)\n\nmonthly_error = daily.resample('m').mean().reset_index()\n\nmonthly_error.plot(x=\"Date\", y=[\"Total\",\"predicted_fe\",\"predicted\"], figsize=(15,5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that the Xmas_period feature improved the prediction for the end of the year period, summer is stillfar from actuals. "},{"metadata":{"trusted":true},"cell_type":"code","source":"year_error = daily.resample('y').mean().reset_index()\nyear_error.plot(x=\"Date\", y=[\"error_abs\",\"error_fe_abs\"], figsize=(15,5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Population data"},{"metadata":{},"cell_type":"markdown","source":"This increased of bikers in 2019 might be explained by an increase of the city population, we can get this information from the city of Seattle webiste : \nhttps://www.ofm.wa.gov/washington-data-research/population-demographics/population-estimates/april-1-official-population-estimates\n\nNote that those figures are yearly, for the sake of quickness we will simple split those figures per day."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dataset import\npopulation_data = pd.read_csv(\"../input/Seattle_yearly_pop.csv\", index_col='Date', parse_dates=True)\n\n# Join the 2 datasets\ndaily = daily.join(population_data[['population']])\n\n# Drop any rows with null values\ndaily.dropna(axis=0, how='any', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"column_names_fe = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun', 'holiday','dry day', 'Temp (C)','Xmas_period','Summer_period','population']\nX_fe = daily[column_names_fe] # define the independant varibles \ny_fe = daily['Total'] # define the target value, the dependant variable\n\nXtrain, Xtest, ytrain, ytest = train_test_split(X_fe, y_fe, random_state=1)\nmodel = LinearRegression(fit_intercept=False)     \nmodel.fit(Xtrain, ytrain)                         \ny_model = model.predict(Xtest)\n\nr2_score(ytest, y_model)  ## check score of the model chosen\n\n#daily['predicted_fe'] = model_fe.predict(X_fe) # incoporated the predicted number of riders in the orginial data set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"coeff_df = pd.DataFrame(model.coef_, X_fe.columns, columns=['Coefficient'])\ncoeff_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"daily[\"error_fe\"]= (daily.predicted_fe - daily.Total).astype(int)\ndaily[\"error_fe_abs\"]= (daily.predicted - daily.Total).abs().astype(int)\n\nmonthly_error = daily.resample('m').mean().reset_index()\n\nmonthly_error.plot(x=\"Date\", y=[\"Total\",\"predicted_fe\",\"predicted\"], figsize=(15,5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This population feature does not improve much the score of the model, and does not contribute to reduce the error for 2019. We can diregard this metric as is. "},{"metadata":{},"cell_type":"markdown","source":"## IV. Regression tree\n\nAnother widely used prediction model is regression trees, let's give it a try to predict the traffic.\n\nI would recommend to have a look at this other great kernel to get some background and further explanation on decision trees (classification and regression) : https://www.kaggle.com/vipulgandhi/a-guide-to-decision-trees-for-beginners"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\nfrom sklearn.model_selection  import cross_val_score\n\ndaily_X = daily[['Mon','Tue','Wed','Thu','Fri','Sat','Sun','holiday','Temp (C)','dry day','Xmas_period','Summer_period']]\ndaily_y = daily['Total']\n\ntree_reg = DecisionTreeRegressor(max_depth=6)\ntree_reg.fit(daily_X, daily_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cross_val_score(tree_reg, X, y, cv=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores_tree = cross_val_score(tree_reg, X, y, cv=10).mean()\nscores_tree","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The accuracy of our regression tree is actually lower than our linear regression model (0.8). \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualize the trained Decision Tree by export_graphviz() method\n\nfrom sklearn.tree import export_graphviz\nfrom sklearn import tree\nfrom IPython.display import SVG\nfrom sklearn.tree import DecisionTreeClassifier, export_graphviz\nfrom graphviz import Source\nfrom IPython.display import display","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = daily_X.columns\n\ngraph = Source(tree.export_graphviz(tree_reg ,feature_names = labels,max_depth=5, filled = True))\ndisplay(SVG(graph.pipe(format='svg')))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note that for visualization purpose we've set the depth of the tree to 3 only. "},{"metadata":{},"cell_type":"markdown","source":"To summarize, our linear model perfromed better than the regression tree, here are 3 rules that I gathered in my trainings when to assess between Tree based models vs. Linear models :\n\n\t• If the relationship between dependent & independent variable is well approximated by a linear model, linear regression will outperform tree based model.\n    \n\t• If there is a high non-linearity & complex relationship between dependent & independent variables, a tree model will outperform a classical regression method.\n    \n    • If we need to build a model which is easy to explain to people, a decision tree model will always do better than a linear model. Decision tree models are even simpler to interpret than linear regression!"},{"metadata":{},"cell_type":"markdown","source":"### Conclusion and potential improvements\n\nAdditional features you might want to research to explain the increase of bikes in 2019 : \n- new city cycling incentives \n- new companies policies \n- improved cycling infrastrucure\n\nIn addition, another predicive method would be interesting to try out : Time series analysis. This method is good to spot seasonality and overall trend but hard to understand the actual cause (like enhanced bike lanes, etc). \n\nAnother more advanced improvement of our model training would be not to shuffle our training data as we have a time component in our data. Indeed we are here randomly predicting traffic on past dates, whereas it would make more sense to train our model on 2015 to 2018 and predict 2019/2020 figures for instance.  \nTo do this : train_test_split with (shuffle=False) see full documentation here https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python [conda env:.conda-training-celia]","language":"python","name":"conda-env-.conda-training-celia-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":4}