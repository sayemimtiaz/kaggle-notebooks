{"cells":[{"metadata":{},"cell_type":"markdown","source":"Sarcasm is \"a sharp, bitter, or cutting expression or remark; a bitter gibe or taunt\". Sarcasm may employ ambivalence, although sarcasm is not necessarily ironic. Most noticeable in spoken word, sarcasm is mainly distinguished by the inflection with which it is spoken and is largely context-dependent.https://en.wikipedia.org/wiki/Sarcasm"},{"metadata":{},"cell_type":"markdown","source":"![](https://media0.giphy.com/media/dDarLms1uet0Y/200.webp?cid=790b76111c1eab42a23e05c0b1da70e694503538f9a31b13&rid=200.webp)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"nRowsRead = 1000 # specify 'None' if want to read whole file\n# train-balanced-sarcasm.csv has 1010826 rows in reality, but we are only loading/previewing the first 1000 rows\ndf = pd.read_csv('../input/sarcastic-comments-on-reddit/train-balanced-sarcasm.csv', delimiter=',', nrows = nRowsRead)\ndf.dataframeName = 'train-balanced-sarcasm.csv'\nnRow, nCol = df.shape\nprint(f'There are {nRow} rows and {nCol} columns')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"\n#codes from Rodrigo Lima  @rodrigolima82\nfrom IPython.display import Image\nImage(url = 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcR3xjPuH9PdZzMlj1VpEKlj7VVE-RkAmIjN4Jc7jaWmwMwFE_N4dg&s',width=400,height=400)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Image naukrinama.com  - Sméagol (aka Gollum) I love you!"},{"metadata":{"trusted":true},"cell_type":"code","source":"corrs = df.corr()\ncorrs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (20, 8))\n\n# Heatmap of correlations\nsns.heatmap(corrs, cmap = plt.cm.RdYlBu_r, vmin = -0.25, annot = True, vmax = 0.6)\nplt.title('SARCASM');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df[\"ups\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df[\"downs\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x='score',y='downs',data=df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df[\"ups\"])\nplt.xticks(rotation=45)\nplt.yticks(rotation=45)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels1=df.score.value_counts().index\nsizes1=df.score.value_counts().values\nplt.figure(figsize=(11,11))\nplt.pie(sizes1,labels=labels1,autopct=\"%1.1f%%\")\nplt.title(\"score\",size=25)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (\"Skew is:\", df.score.skew())\nplt.hist(df.score, color='pink')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"![](https://media0.giphy.com/media/WdjUZDwLsd1PCgVHxN/giphy.webp?cid=790b76111c1eab42a23e05c0b1da70e694503538f9a31b13&rid=giphy.webp)"},{"metadata":{},"cell_type":"markdown","source":"* In the Documentary \"This Changes Everything\"(2018), Geena Davis expressed how she hated \"Great\". After we've made a lot of effort doing smth and all we got is a \"Great\". \n* Above we've the actress Anna Paquin. "},{"metadata":{},"cell_type":"markdown","source":"Codes below from https://www.kaggle.com/andresionek/how-to-create-award-winning-data-visualizations"},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px\n\n# Grouping it by Genre and track\nplot_data = df.groupby(['score', 'downs'], as_index=False).ups.sum()\n\nfig = px.bar(plot_data, x='score', y='ups', color='downs')\nfig.update_layout(\n    title_text='Sarcastic comments',\n    height=500, width=1000)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px\n\n# Grouping it by Genre and track\nplot_data = df.groupby(['score', 'downs'], as_index=False).ups.sum()\n\nfig = px.line_polar(plot_data, theta='score', r='ups', color='downs')\nfig.update_layout(\n    title_text='Sarcastic Comments',\n    height=500, width=1000)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px\n\n# Grouping it by Genre and artist\nplot_data = df.groupby(['score', 'downs'], as_index=False).ups.sum()\n\nfig = px.line(plot_data, x='score', y='ups', color='downs')\nfig.update_layout(\n    title_text='Sarcastic Comments',\n    height=500, width=1000)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#sample codes from Mikey_Mtk @motokinakamura https://www.kaggle.com/motokinakamura/treemap-with-plotly\nfig = go.Figure(go.Treemap(\n    labels = [\"Eve\",\"Cain\", \"Seth\", \"Enos\", \"Noam\", \"Abel\", \"Awan\", \"Enoch\", \"Azura\"],\n    parents = [\"\", \"Eve\", \"Eve\", \"Seth\", \"Seth\", \"Eve\", \"Eve\", \"Awan\", \"Eve\"]\n))\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#codes from Mikey_Mtk @motokinakamura https://www.kaggle.com/motokinakamura/treemap-with-plotly\n#make a df it's grouped by \"Genre\"\ngb_score =df.groupby(\"score\").sum()\n\ngb_score.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# codes from Mikey_Mtk @motokinakamura https://www.kaggle.com/motokinakamura/treemap-with-plotly\nscore = list(gb_score.index)\nsarc = list(gb_score.ups)\n\nprint(score)\nprint(sarc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#codes from Mikey_Mtk @motokinakamura https://www.kaggle.com/motokinakamura/treemap-with-plotly\n#first treemap\ntest_tree = go.Figure(go.Treemap(\n    labels =  score,\n    parents=[\"\"]*len(score),\n    values =  sarc,\n    textinfo = \"label+value\"\n))\n\ntest_tree.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#codes from Mikey_Mtk @motokinakamura https://www.kaggle.com/motokinakamura/treemap-with-plotly\n#second treemap\ntest_tree_blue = go.Figure(go.Treemap(\n    labels =  score,\n    parents=[\"\"]*len(score),\n    values =  sarc,\n    textinfo = \"label+value\",\n    marker_colorscale = 'magma'\n))\n\ntest_tree_blue.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#codes from Rodrigo Lima  @rodrigolima82\nfrom IPython.display import Image\nImage(url = 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcT2Ymvgxnf4XsEy1UnrjJM4-v4cQISc20XrI-q3gucZD61WmN_0&s',width=400,height=400)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Image geeksoncoffee.com  - Yes, I'm so sweet, almost Jekyll and Hyde. "},{"metadata":{},"cell_type":"markdown","source":"#Codes (WordCloud) from Shivam Ralli https://www.kaggle.com/hoshi7/what-do-i-watch-next\n#Taken From: https://www.kaggle.com/shivamb/netflix-shows-and-movies-exploratory-analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Necessary Functions: \ndef pie_plot(labels, values, colors, title):\n    fig = {\n      \"data\": [\n        {\n          \"values\": values,\n          \"labels\": labels,\n          \"domain\": {\"x\": [0, .48]},\n          \"name\": \"Job Type\",\n          \"sort\": False,\n          \"marker\": {'colors': colors},\n          \"textinfo\":\"percent+label+value\",\n          \"textfont\": {'color': '#FFFFFF', 'size': 10},\n          \"hole\": .6,\n          \"type\": \"pie\"\n        } ],\n        \"layout\": {\n            \"title\":title,\n            \"annotations\": [\n                {\n                    \"font\": {\n                        \"size\": 25,\n\n                    },\n                    \"showarrow\": False,\n                    \"text\": \"\"\n\n                }\n            ]\n        }\n    }\n    return fig","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.offline as py\nvalue_counts = df['score'].value_counts()\nlabels = value_counts.index.tolist()\npy.iplot(pie_plot(labels, value_counts,['#1B9E77', '#7570B3'], \"Type Distribution\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import Counter\nimport json\nfrom IPython.display import HTML\nimport altair as alt\nfrom  altair.vega import v5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##-----------------------------------------------------------\n# This whole section \nvega_url = 'https://cdn.jsdelivr.net/npm/vega@' + v5.SCHEMA_VERSION\nvega_lib_url = 'https://cdn.jsdelivr.net/npm/vega-lib'\nvega_lite_url = 'https://cdn.jsdelivr.net/npm/vega-lite@' + alt.SCHEMA_VERSION\nvega_embed_url = 'https://cdn.jsdelivr.net/npm/vega-embed@3'\nnoext = \"?noext\"\n\npaths = {\n    'vega': vega_url + noext,\n    'vega-lib': vega_lib_url + noext,\n    'vega-lite': vega_lite_url + noext,\n    'vega-embed': vega_embed_url + noext\n}\n\nworkaround = \"\"\"\nrequirejs.config({{\n    baseUrl: 'https://cdn.jsdelivr.net/npm/',\n    paths: {}\n}});\n\"\"\"\n\n#------------------------------------------------ Defs for future rendering\ndef add_autoincrement(render_func):\n    # Keep track of unique <div/> IDs\n    cache = {}\n    def wrapped(chart, id=\"vega-chart\", autoincrement=True):\n        if autoincrement:\n            if id in cache:\n                counter = 1 + cache[id]\n                cache[id] = counter\n            else:\n                cache[id] = 0\n            actual_id = id if cache[id] == 0 else id + '-' + str(cache[id])\n        else:\n            if id not in cache:\n                cache[id] = 0\n            actual_id = id\n        return render_func(chart, id=actual_id)\n    # Cache will stay outside and \n    return wrapped\n\n@add_autoincrement\ndef render(chart, id=\"vega-chart\"):\n    chart_str = \"\"\"\n    <div id=\"{id}\"></div><script>\n    require([\"vega-embed\"], function(vg_embed) {{\n        const spec = {chart};     \n        vg_embed(\"#{id}\", spec, {{defaultStyle: true}}).catch(console.warn);\n        console.log(\"anything?\");\n    }});\n    console.log(\"really...anything?\");\n    </script>\n    \"\"\"\n    return HTML(\n        chart_str.format(\n            id=id,\n            chart=json.dumps(chart) if isinstance(chart, dict) else chart.to_json(indent=None)\n        )\n    )\n\n\n\nHTML(\"\".join((\n    \"<script>\",\n    workaround.format(json.dumps(paths)),\n    \"</script>\")))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def word_cloud(df, pixwidth=6000, pixheight=350, column=\"index\", counts=\"count\"):\n    data= [dict(name=\"dataset\", values=df.to_dict(orient=\"records\"))]\n    wordcloud = {\n        \"$schema\": \"https://vega.github.io/schema/vega/v5.json\",\n        \"width\": pixwidth,\n        \"height\": pixheight,\n        \"padding\": 0,\n        \"title\": \"Hover to see number of occureances from all the sequences\",\n        \"data\": data\n    }\n    scale = dict(\n        name=\"color\",\n        type=\"ordinal\",\n        range=[\"cadetblue\", \"royalblue\", \"steelblue\", \"navy\", \"teal\"]\n    )\n    mark = {\n        \"type\":\"text\",\n        \"from\":dict(data=\"dataset\"),\n        \"encode\":dict(\n            enter=dict(\n                text=dict(field=column),\n                align=dict(value=\"center\"),\n                baseline=dict(value=\"alphabetic\"),\n                fill=dict(scale=\"color\", field=column),\n                tooltip=dict(signal=\"datum.count + ' occurrances'\")\n            )\n        ),\n            \"transform\": [{\n            \"type\": \"wordcloud\",\n            \"text\": dict(field=column),\n            \"size\": [pixwidth, pixheight],\n            \"font\": \"Helvetica Neue, Arial\",\n            \"fontSize\": dict(field=\"datum.{}\".format(counts)),\n            \"fontSizeRange\": [10, 60],\n            \"padding\": 2\n        }]\n    }\n    wordcloud[\"scales\"] = [scale]\n    wordcloud[\"marks\"] = [mark]\n    \n    return wordcloud\n\nfrom collections import defaultdict\n\ndef wordcloud_create(df):\n    ult = {}\n    corpus = df.comment.values.tolist()\n    final = defaultdict(int) #Declaring an empty dictionary for count (Saves ram usage)\n    for words in corpus:\n        for word in words.split():\n             final[word]+=1\n    temp = Counter(final)\n    for k, v in  temp.most_common(200):\n        ult[k] = v\n    corpus = pd.Series(ult) #Creating a dataframe from the final default dict\n    return render(word_cloud(corpus.to_frame(name=\"count\").reset_index(), pixheight=600, pixwidth=900))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wordcloud_create(df)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#codes from Rodrigo Lima  @rodrigolima82\nfrom IPython.display import Image\nImage(url = 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTllzoOJzbtATW5rkE6l5uPVALudyrMLrr--zkLCb9M3pSiOuOG&s',width=400,height=400)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Image solifequotes.com -  Sure, another \"brilliant\" Notebook of mine. Got it? That's Sarcasm!"},{"metadata":{},"cell_type":"markdown","source":"#Codes (WordCloud) from Shivam Ralli https://www.kaggle.com/hoshi7/what-do-i-watch-next\n#Taken From: https://www.kaggle.com/shivamb/netflix-shows-and-movies-exploratory-analysis"},{"metadata":{},"cell_type":"markdown","source":"![](https://media2.giphy.com/media/26n79l9afmfm1POjC/giphy.webp?cid=790b76111c1eab42a23e05c0b1da70e694503538f9a31b13&rid=giphy.webp)"},{"metadata":{},"cell_type":"markdown","source":"Thank you for reading this Notebook."},{"metadata":{},"cell_type":"markdown","source":"Kaggle Notebook Runner: Marília Prata @mpwolke"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}