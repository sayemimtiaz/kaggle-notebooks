{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"\n{\n   \"schemaVersion\": 2,\n   \"mediaType\": \"application/vnd.docker.distribution.manifest.v2+json\",\n   \"config\": {\n      \"mediaType\": \"application/vnd.docker.container.image.v1+json\",\n      \"size\": 8427,\n      \"digest\": \"sha256:32a1a53fdb28035db0bdb568c202ca7f13195427d01962a8f62e25bc9d6622eb\"\n   },\n   \"layers\": [\n      {\n         \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n         \"size\": 51081712,\n         \"digest\": \"sha256:ab85f11dd933cfda19130a6b6986c591e8e70d8a2ac8a73dddd8722c7ec8eab1\"\n      },\n      {\n         \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n         \"size\": 825,\n         \"digest\": \"sha256:2922171b2513070bd982f9030107e0a9b22fa141ce22fe185cea0b22dc34dc32\"\n      },\n      {\n         \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n         \"size\": 442,\n         \"digest\": \"sha256:03dd2bb85c8ab012f80afe6dee177f3c05e20bdfc059beeb2c03ad6ca14189f2\"\n      },\n      {\n         \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n         \"size\": 676,\n         \"digest\": \"sha256:4a9039a61c36f62d62cb71a8087c71fc6046b0918617a8ae13f20fa48060983f\"\n      },\n      {\n         \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n         \"size\": 163,\n         \"digest\": \"sha256:82e5f1ef816256c961c51a8deae0ff5c038e7a4e92f0b52bf1d60340f21d9502\"\n      },\n      {\n         \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n         \"size\": 833526336,\n         \"digest\": \"sha256:67eed9560bab0b1bf847ffbc73f384a2841d3680a37a3681c9ac8cd89e38e46d\"\n      },\n      {\n         \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n         \"size\": 568,\n         \"digest\": \"sha256:ce8abd2c7b1cd94ca3fc88a34ea7c6d451b197b28bc02c5f6cf9714b95996ecd\"\n      },\n      {\n         \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n         \"size\": 343945402,\n         \"digest\": \"sha256:11bc6f91b846cb9c1efddd0e132773099bc29e577eca085742566e5c258e8321\"\n      },\n      {\n         \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n         \"size\": 3029994,\n         \"digest\": \"sha256:91433bc796c21fe3d7b513c5aab421b10c784bb22712ec1b68698b0910b8116e\"\n      },\n      {\n         \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n         \"size\": 57935,\n         \"digest\": \"sha256:1e5c91351872e093c596d34ad80f63f8a539a57b18fba87a7ab708aa79983ed1\"\n      },\n      {\n         \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n         \"size\": 81865183,\n         \"digest\": \"sha256:fb8c8966667d0589428e3f40598742586a49b4e484339cdac3196c2c22317394\"\n      }\n   ]\n}\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"covid 2019","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"*.pyc\n.idea/\n.vscode\n.mypy_cachel","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Updates\n * 13Feb2020-17Apr2020: (Please read [Change log](#11) subsection.)\n \n * 18Apr2020: Update RMSLE score fucntion of Estimator, $\\ln(x)$ to $log_{10}(x)$\n * 18Apr2020: Add explanation of accuracy index of hyperparameter estimation\n * 18Apr2020: Japan entered 3rd phase\n * 18Apr2020: Data in \"Expalanation of concept part\" was changed from actual data to example data\n * 27Apr2020: \"S-R trend analysis\" section\n * 28Apr2020: In scenario analysis, Exponential trend analysis was replaced with S-R trend analysis\n \n <!--* 10Mar2020: In Estimator.objective(), apply adjusted Exponential Moving Average (span=7days) on the training data-->\n \n <!--* 08Mar2020: ODE solver method was changed from RK45 to Radau (Implicit Runge-Kutta method of the Radau IIA family of order 5) because max value of $\\tau$ is 1440[min] and the number of iterations tends to small. The numerical simulation system seems stiff equation. Please refer to [scipy.integrate.solve_ivp guide](https://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.solve_ivp.html).-->"},{"metadata":{"_uuid":"e8837623-1d76-40e3-8710-af80d55cfc9c","_cell_guid":"3779540e-8e00-4811-a789-6107b0d51e0c","trusted":true},"cell_type":"markdown","source":"# Dataset and tools<a id=\"1\"></a>"},{"metadata":{},"cell_type":"markdown","source":"## Package"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"from collections import defaultdict\nfrom datetime import timedelta\nfrom dateutil.relativedelta import relativedelta\nimport functools\nfrom IPython.display import display, Markdown\nimport math\nimport os\nfrom pprint import pprint\nimport warnings\nfrom fbprophet import Prophet\nfrom fbprophet.plot import add_changepoints_to_plot\nimport pystan.misc # in model.fit(): AttributeError: module 'pystan' has no attribute 'misc'\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nimport matplotlib\nfrom matplotlib.ticker import ScalarFormatter\n%matplotlib inline\nimport numpy as np\nimport optuna\noptuna.logging.disable_default_handler()\nimport pandas as pd\nimport dask.dataframe as dd\npd.plotting.register_matplotlib_converters()\nimport seaborn as sns\nimport scipy as sci\nfrom scipy.integrate import solve_ivp\nfrom scipy.optimize import curve_fit\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.cluster import KMeans\nimport sympy as sym","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Ramdam\nnp.random.seed(2019)\nos.environ[\"PYTHONHASHSEED\"] = \"2019\"\n# Matplotlib\nplt.style.use(\"seaborn-ticks\")\nplt.rcParams[\"xtick.direction\"] = \"in\"\nplt.rcParams[\"ytick.direction\"] = \"in\"\nplt.rcParams[\"font.size\"] = 11.0\nplt.rcParams[\"figure.figsize\"] = (9, 6)\n# Pandas\npd.set_option(\"display.max_colwidth\", 1000)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"!pip install japanmap\nimport japanmap","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## List of dataset"},{"metadata":{"trusted":true,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"for dirname, _, filenames in os.walk(\"/kaggle/input\"):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Total population"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"population_raw = pd.read_csv(\n    \"/kaggle/input/covid19-global-forecasting-locations-population/locations_population.csv\"\n)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"population_raw.head()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"pd.DataFrame(population_raw.isnull().sum()).T","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df = population_raw.copy()\ndf = df.rename({\"Province.State\": \"Province\", \"Country.Region\": \"Country\"}, axis=1)\ncols = [\"Country\", \"Province\", \"Population\"]\ndf = df.loc[:, cols].fillna(\"-\")\ndf.loc[df[\"Country\"] == df[\"Province\"], \"Province\"] = \"-\"\n# Add total records\n_total_df = df.loc[df[\"Province\"] != \"-\", :].groupby(\"Country\").sum()\n_total_df = _total_df.reset_index().assign(Province=\"-\")\ndf = pd.concat([df, _total_df], axis=0, sort=True)\ndf = df.drop_duplicates(subset=[\"Country\", \"Province\"], keep=\"first\")\n# Global\nglobal_value = df.loc[df[\"Province\"] == \"-\", \"Population\"].sum()\ndf = df.append(pd.Series([\"Global\", \"-\", global_value], index=cols), ignore_index=True)\n# Sorting\ndf = df.sort_values(\"Population\", ascending=False).reset_index(drop=True)\ndf = df.loc[:, cols]\npopulation_df = df.copy()\npopulation_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"df = population_df.loc[population_df[\"Province\"] == \"-\", :]\npopulation_dict = df.set_index(\"Country\").to_dict()[\"Population\"]\npopulation_dict","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Population pyramid"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"pyramid_csv_list = list()\nfor dirname, _, filenames in os.walk(\"/kaggle/input/population-pyramid-2019/\"):\n    for filename in filenames:\n        name = os.path.join(dirname, filename)\n        df = pd.read_csv(name)\n        df[\"Country\"], df[\"Year\"], _ = filename.replace(\".\", \"-\").split(\"-\")\n        pyramid_csv_list.append(df)\npyramid_raw = pd.concat(pyramid_csv_list, sort=True)\npyramid_raw.head()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"pyramid_raw[\"Country\"].unique()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df = pyramid_raw.copy()\ndf[\"Country\"] = df[\"Country\"].replace(\n    {\n        \"United States of America\": \"US\",\n        \"United Kingdom\": \"UK\",\n    }\n)\n# Global (WORLD)\n_male = [\n    349432556, 342927576, 331497486, 316642222, 308286775, 306059387, 309236984,\n    276447037, 249389688, 241232876, 222609691, 192215395, 157180267, 128939392,\n    87185982, 54754941, 33648953, 15756942, 5327866, 1077791, 124144\n]\n_female = [\n    328509234, 321511867, 309769906, 295553758, 289100903, 288632766, 296293748,\n    268371754, 244399176, 238133281, 223162982, 195633743, 164961323, 140704320,\n    101491347, 69026831, 48281201, 26429329, 11352182, 3055845, 449279\n]\n_df = pd.DataFrame(\n    {\n        \"Age\": df[\"Age\"].unique(),\n        \"Country\": \"Global\",\n        \"F\": _female,\n        \"M\": _male,\n        \"Year\": 2019\n    }\n)\ndf = pd.concat([df, _df], axis=0, ignore_index=True, sort=True)\n# Sweden\n_male = [\n    307116,\n    304759,\n    296771,\n    270840,\n    291723,\n    376952,\n    343311,\n    315086,\n    312017,\n    336452,\n    342117,\n    306949,\n    279609,\n    265511,\n    273061,\n    195029,\n    113166,\n    61775,\n    26170,\n    6768,\n    415\n]\n_female = [\n    290553,\n    288817,\n    280944,\n    257677,\n    274760,\n    361526,\n    330153,\n    300752,\n    301288,\n    327453,\n    331458,\n    300084,\n    280009,\n    272149,\n    286879,\n    212480,\n    143654,\n    97633,\n    52624,\n    18130,\n    1771\n]\n_df = pd.DataFrame(\n    {\n        \"Age\": df[\"Age\"].unique(),\n        \"Country\": \"Sweden\",\n        \"F\": _female,\n        \"M\": _male,\n        \"Year\": 2019\n    }\n)\ndf = pd.concat([df, _df], axis=0, ignore_index=True, sort=True)\n# Philippines\n_male = [\n    5534962,\n    5820604,\n    5538414,\n    5383822,\n    5149849,\n    4710777,\n    4061897,\n    3581091,\n    3237426,\n    2832825,\n    2482953,\n    2015857,\n    1556935,\n    1082875,\n    668107,\n    364200,\n    199400,\n    73508,\n    17327,\n    3035,\n    208\n]\n_female = [\n    5240508,\n    5541514,\n    5273495,\n    5029137,\n    4896316,\n    4589506,\n    3982681,\n    3544279,\n    3191565,\n    2825286,\n    2521463,\n    2112380,\n    1714689,\n    1285782,\n    895866,\n    567282,\n    360751,\n    155294,\n    57969,\n    13376,\n    1411\n]\n_df = pd.DataFrame(\n    {\n        \"Age\": df[\"Age\"].unique(),\n        \"Country\": \"Philippines\",\n        \"F\": _female,\n        \"M\": _male,\n        \"Year\": 2019\n    }\n)\ndf = pd.concat([df, _df], axis=0, ignore_index=True, sort=True)\n# Arrange\ndf[\"Population\"] = df[\"F\"] + df[\"M\"]\ndf = df.pivot_table(\n    index=\"Age\", columns=[\"Country\"], values=\"Population\", aggfunc=\"last\"\n)\ndf = df.astype(np.int64).reset_index().rename({\"Age\": \"Age_bin\"}, axis=1)\nseries = df[\"Age_bin\"].str.replace(\"+\", \"-122\")\ndf[[\"Age_first\", \"Age_last\"]] = series.str.split(\"-\", expand=True).astype(np.int64)\ndf = df.drop(\"Age_bin\", axis=1)\nseries = df[\"Age_last\"]\ndf = df.apply(lambda x: x[:-2] / (x[-1] - x[-2] + 1), axis=1)\ndf[\"Age\"] = series\ndf = pd.merge(df, pd.DataFrame({\"Age\": np.arange(0, 123, 1)}), on=\"Age\", how=\"right\", sort=True)\ndf = df.fillna(method=\"bfill\").astype(np.int64)\ndf = df.set_index(\"Age\")\npyramid_df = df.copy()\npyramid_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## The number of days go out (template data)\n**As a comment of this notebook, @marcoferrante estimated the number of days persons of each age group usually go out. Thank you for your kind cooperation!!**"},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"# @marcoferrante estimation\n_period_of_life_list = [\n    \"nursery\", \"nursery school\", \"elementary school\", \"middle school\",\n    \"high school\", \"university/work\", \"work\", \"work\", \"work\", \"work\",\n    \"retired\", \"retired\", \"retired\"\n]\ndf = pd.DataFrame(\n    {\n        \"Age_first\": [0, 3, 6, 11, 14, 19, 26, 36, 46, 56, 66, 76, 86],\n        \"Age_last\": [2, 5, 10, 13, 18, 25, 35, 45, 55, 65, 75, 85, 95],\n        \"Period_of_life\": _period_of_life_list,\n        \"Days\": [3, 5, 6, 6, 7, 7, 6, 5, 5, 5, 4, 3, 2]\n    }\n)\n# Adjustment by author\ndf[\"Types\"] = df[\"Period_of_life\"].replace(\n    {\n        \"nursery\": \"school\",\n        \"nursery school\": \"school\",\n        \"elementary school\": \"school\",\n        \"middle school\": \"school\",\n        \"high school\": \"school\",\n        \"university/work\": \"school/work\"\n    }\n)\ndf[\"School\"] = df[[\"Types\", \"Days\"]].apply(lambda x: x[1] if \"school\" in x[0] else 0, axis=1)\ndf[\"Office\"] = df[[\"Types\", \"Days\"]].apply(lambda x: x[1] if \"work\" in x[0] else 0, axis=1)\ndf[\"Others\"] = df[\"Days\"] - df[[\"School\", \"Office\"]].sum(axis=1)\ndf.loc[df[\"Others\"] < 0, \"Others\"] = 0\ndf.loc[df.index[1:5], \"School\"] -= 1\ndf.loc[df.index[1:5], \"Others\"] += 1\ndf.loc[df.index[5], [\"School\", \"Office\", \"Others\"]] = [3, 3, 1]\ndf[[\"School\", \"Office\", \"Others\"]] = df[[\"Days\", \"School\", \"Office\", \"Others\"]].apply(\n    lambda x: x[1:] / sum(x[1:]) * x[0], axis=1\n).astype(np.int64)\ndf.loc[df.index[6:10], \"Others\"] += 1\ndf = df.drop([\"Days\", \"Types\"], axis=1)\n# Show dataset\n_out_df = df.copy()\n_out_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For each country, population pyramid data will be combined to the table. The columns with countriy names are the portion of the total population."},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"df = pyramid_df.cumsum()\ncountries = df.columns[:]\ndf = pd.merge(_out_df, df, left_on=\"Age_last\", right_on=\"Age\", how=\"left\")\n_first = df.loc[df.index[0], countries]\ndf[countries] = df[countries].diff()\ndf.loc[df.index[0], countries] = _first\ndf[countries] = df[countries].apply(lambda x: x / x.sum(), axis=0)\nout_df = df.copy()\nout_df","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def go_out(country, out_df=out_df):\n    \"\"\"\n    Return the estimated number of days people usually go out.\n    @country <str>: coutry name\n    @out_df <pd.DataFrame>: template dataframe\n    \"\"\"\n    df = out_df.copy()\n    try:\n        series = df[country]\n    except KeyError:\n        raise KeyError(f\"Population pyramid data of {country} is not defined!\")\n    df = df.iloc[:, :6]\n    df[\"Portion\"] = series\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"go_out(\"Global\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c3ebe4cf-2cd1-4d69-9882-8d2cc490e1ea","_cell_guid":"8c2f4e86-2ce9-4aa4-8352-348523a88b51","trusted":true},"cell_type":"markdown","source":"## Functions\nHere, we define the functions to use repeatedly in this notebook."},{"metadata":{"_uuid":"e619de8a-4351-4f6a-97f1-2a07dfc8df8c","_cell_guid":"9aa77813-b9cc-46a4-a77f-88c1b5eb220e","trusted":true},"cell_type":"markdown","source":"### Plotting"},{"metadata":{"_uuid":"102b157f-f1f0-4430-91ba-0660f388c945","_cell_guid":"5b76a2ac-df0d-4c4c-85c6-38c8b147ef93","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def line_plot(df, title, xlabel=None, ylabel=\"Cases\",\n              h=None, v=None, xlim=(None, None), ylim=(0, None),\n              math_scale=True, x_logscale=False, y_logscale=False, y_integer=False,\n              show_legend=True, bbox_to_anchor=(1.02, 0),  bbox_loc=\"lower left\"):\n    \"\"\"\n    Show chlonological change of the data.\n    \"\"\"\n    ax = df.plot()\n    # Scale\n    if math_scale:\n        ax.yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n        ax.ticklabel_format(style=\"sci\",  axis=\"y\",scilimits=(0, 0))\n    if x_logscale:\n        ax.set_xscale(\"log\")\n        if xlim[0] == 0:\n            xlim = (None, None)\n    if y_logscale:\n        ax.set_yscale(\"log\")\n        if ylim[0] == 0:\n            ylim = (None, None)\n    if y_integer:\n        fmt = matplotlib.ticker.ScalarFormatter(useOffset=False)\n        fmt.set_scientific(False)\n        ax.yaxis.set_major_formatter(fmt)\n    # Set metadata of figure\n    ax.set_title(title)\n    ax.set_xlabel(xlabel)\n    ax.set_ylabel(ylabel)\n    ax.set_xlim(*xlim)\n    ax.set_ylim(*ylim)\n    if show_legend:\n        ax.legend(bbox_to_anchor=bbox_to_anchor, loc=bbox_loc, borderaxespad=0)\n    else:\n        ax.legend().set_visible(False)\n    if h is not None:\n        ax.axhline(y=h, color=\"black\", linestyle=\":\")\n    if v is not None:\n        if not isinstance(v, list):\n            v = [v]\n        for value in v:\n            ax.axvline(x=value, color=\"black\", linestyle=\":\")\n    plt.tight_layout()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def jpn_map(prefectures, values, title, cmap_name=\"Reds\"):\n    \"\"\"\n    Show colored Japan prefecture map.\n    @prefectures <list/pd.Series[str]>: prefecture name.\n    @values <int/float>: value of each prefectures\n    @title <str>: title of the figure\n    @cmap_name <str>: Please refere to\n        - https://matplotlib.org/3.1.0/tutorials/colors/colormaps.html\n    \"\"\"\n    # Prefecture code created in\n    # https://www.kaggle.com/lisphilar/eda-of-japan-dataset\n    # Primary data: http://nlftp.mlit.go.jp/ksj/gml/codelist/PrefCd.html\n    # cf. https://www.japanvisitor.com/japan-travel/prefectures-map\n    pref_code_dict = dict(\n        [\n            ('Hokkaido', 1), ('Aomori', 2), ('Iwate', 3),\n            ('Miyagi', 4), ('Akita', 5), ('Yamagata', 6),\n            ('Fukushima', 7), ('Ibaraki', 8), ('Tochigi', 9),\n            ('Gunma', 10), ('Saitama', 11), ('Chiba', 12),\n            ('Tokyo', 13), ('Kanagawa', 14), ('Niigata', 15),\n            ('Toyama', 16), ('Ishikawa', 17), ('Fukui', 18),\n            ('Yamanashi', 19), ('Nagano', 20), ('Gifu', 21),\n            ('Shizuoka', 22), ('Aichi', 23), ('Mie', 24),\n            ('Shiga', 25), ('Kyoto', 26), ('Osaka', 27), ('Hyogo', 28),\n            ('Nara', 29), ('Wakayama', 30), ('Tottori', 31),\n            ('Shimane', 32), ('Okayama', 33), ('Hiroshima', 34),\n            ('Yamaguchi', 35), ('Tokushima', 36), ('Kagawa', 37),\n            ('Ehime', 38), ('Kochi', 39), ('Fukuoka', 40),\n            ('Saga', 41), ('Nagasaki', 42), ('Kumamoto', 43),\n            ('Oita', 44), ('Miyazaki', 45), ('Kagoshima', 46),\n            ('Okinawa', 47)\n        ]\n    )\n    # Data to dataframe\n    df = pd.DataFrame({\"Name\": prefectures, \"Value\": values})\n    df[\"Code\"] = df[\"Name\"].map(pref_code_dict)\n    df = df.set_index(\"Code\")\n    # Color code\n    cmap = plt.get_cmap(\"Reds\")\n    norm = plt.Normalize(vmin=df[\"Value\"].min(), vmax=df[\"Value\"].max())\n    fcol = lambda x: \"#\" + bytes(cmap(norm(x), bytes=True)[:3]).hex()\n    # Show figure\n    plt.xticks(color=\"None\")\n    plt.yticks(color=\"None\")\n    plt.tick_params(length=0)\n    plt.colorbar(plt.cm.ScalarMappable(norm, cmap))\n    plt.imshow(japanmap.picture(df[\"Value\"].apply(fcol)))\n    plt.title(title)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Select data at country/province level"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def select_area(ncov_df, group=\"Date\", places=None, areas=None, excluded_places=None,\n                start_date=None, end_date=None, date_format=\"%d%b%Y\"):\n    \"\"\"\n    Select the records of the palces.\n    @ncov_df <pd.DataFrame>: the clean data\n    @group <str or None>: group-by the group, or not perform (None)\n    @area or @places:\n        if ncov_df has Country and Province column,\n            @places <list[tuple(<str/None>, <str/None>)]: the list of places\n                - if the list is None, all data will be used\n                - (str, str): both of country and province are specified\n                - (str, None): only country is specified\n                - (None, str) or (None, None): Error\n        if ncov_df has Area column,\n            @areas <list[str]>: the list of area names\n                - if the list is None, all data will be used\n                - eg. Japan\n                - eg. US/California\n    @excluded_places <list[tuple(<str/None>, <str/None>)]: the list of excluded places\n        - if the list is None, all data in the \"places\" will be used\n        - (str, str): both of country and province are specified\n        - (str, None): only country is specified\n        - (None, str) or (None, None): Error\n    @start_date <str>: the start date or None\n    @end_date <str>: the start date or None\n    @date_format <str>: format of @start_date and @end_date\n    @return <pd.DataFrame>: index and columns are as same as @ncov_df\n    \"\"\"\n    # Select the target records\n    df = ncov_df.copy()\n    if (places is not None) or (excluded_places is not None):\n        c_series = df[\"Country\"]\n        p_series = df[\"Province\"]\n        if places is not None:\n            df = pd.DataFrame(columns=ncov_df.columns)\n            for (c, p) in places:\n                if c is None:\n                    raise Exception(\"places: Country must be specified!\")\n                if p is None:\n                    new_df = ncov_df.loc[c_series == c, :]\n                else:\n                    new_df = ncov_df.loc[(c_series == c) & (p_series == p), :]\n                df = pd.concat([df, new_df], axis=0)\n        if excluded_places is not None:\n            for (c, p) in excluded_places:\n                if c is None:\n                    raise Exception(\"excluded_places: Country must be specified!\")\n                if p is None:\n                    df = df.loc[c_series != c, :]\n                else:\n                    c_df = df.loc[(c_series == c) & (p_series != p), :]\n                    other_df = df.loc[c_series != c, :]\n                    df = pd.concat([c_df, other_df], axis=0)\n    if areas is not None:\n        df = df.loc[df[\"Area\"].isin(areas), :]\n    if group is not None:\n        df = df.groupby(group).sum().reset_index()\n    # Range of date\n    if start_date is not None:\n        df = df.loc[df[\"Date\"] >= datetime.strptime(start_date, date_format), :]\n    if end_date is not None:\n        df = df.loc[df[\"Date\"] <= datetime.strptime(end_date, date_format), :]\n    # Only use the records with Confirmed > 0\n    try:\n        df = df.loc[df[\"Confirmed\"] > 0, :]\n    except KeyError:\n        pass\n    # Aleart empty\n    if df.empty:\n        raise Exception(\"The output dataframe is empty!\")\n    return df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Exponential trend analysis"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def show_trend(ncov_df, name=None, variable=\"Confirmed\", n_changepoints=2, **kwargs):\n    \"\"\"\n    Show trend of log10(@variable) using fbprophet package.\n    @ncov_df <pd.DataFrame>: the clean data\n    @variable <str>: variable name to analyse\n        - if Confirmed, use Infected + Recovered + Deaths\n    @n_changepoints <int>: max number of change points\n    @kwargs: keword arguments of select_area()\n    \"\"\"\n    # Data arrangement\n    df = select_area(ncov_df, **kwargs)\n    df = df.loc[:, [\"Date\", variable]]\n    df.columns = [\"ds\", \"y\"]\n    # Log10(x)\n    warnings.resetwarnings()\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\")\n        df[\"y\"] = np.log10(df[\"y\"]).replace([np.inf, -np.inf], 0)\n    # fbprophet\n    model = Prophet(growth=\"linear\", daily_seasonality=False, n_changepoints=n_changepoints)\n    model.fit(df)\n    future = model.make_future_dataframe(periods=0)\n    forecast = model.predict(future)\n    # Create figure\n    fig = model.plot(forecast)\n    _ = add_changepoints_to_plot(fig.gca(), model, forecast)\n    if name is None:\n        try:\n            name = f\"{kwargs['places'][0][0]}: \"\n        except Exception:\n            name = str()\n    else:\n        name = f\"{name}: \"\n    plt.title(f\"{name}log10({variable}) over time and chainge points\")\n    plt.ylabel(f\"log10(the number of cases)\")\n    plt.xlabel(\"\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### S-R trend analysis"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"class Trend(object):\n    \"\"\"\n    Class for S-R trend analysis.\n    \"\"\"\n    SUFFIX_DICT = defaultdict(lambda: \"th\")\n    SUFFIX_DICT.update({1: \"st\", 2: \"nd\", 3: \"rd\"})\n\n    def __init__(self, ncov_df, total_population, name=None, **kwargs):\n        \"\"\"\n        @ncov_df <pd.DataFrame>: the clean data\n        @total_population <int>: total population in the target area\n        @name <str>: name of the area\n        @kwargs: keword arguments of select_area()\n        \"\"\"\n        # Data arrangement\n        df = select_area(ncov_df, **kwargs)\n        self.start_date = df[\"Date\"].min()\n        df[\"day\"] = ((df[\"Date\"] - self.start_date).dt.total_seconds() / 24 / 60 / 60).astype(np.int64)\n        df = df.groupby(\"day\").sum()\n        df[\"Susceptible\"] = total_population - df[\"Confirmed\"]\n        df = df.loc[:, [\"Recovered\", \"Susceptible\"]]\n        df = df.rename({\"Susceptible\": \"Actual\"}, axis=1)\n        self.all_df = df.copy()\n        self.subsets = [df.copy()]\n        self.total_population = total_population\n        # Name\n        if name is None:\n            try:\n                self.title = f\"{kwargs['places'][0][0]}: \"\n            except Exception:\n                self.title = str()\n        else:\n            self.title = f\"{name}: \"\n        # Initiation\n        self.n_points = 0\n        self.study = None\n        # Debug\n        self.n_trials_performed = 0\n\n    def _num2str(self, num):\n        \"\"\"\n        Convert numbers to 1st, 2nd etc.\n        @num <int>: number\n        @return <str>\n        \"\"\"\n        q, mod = divmod(num, 10)\n        suffix = \"th\" if q == 1 else self.SUFFIX_DICT[mod]\n        return f\"{num}{suffix}\"\n\n    def curve_fit(self, subset_df, num):\n        \"\"\"\n        Peform curve fitting and return the predicted values.\n        @subset_df <pd.DataFrame>: subset of data to fit\n        @num <int>: the number of subset\n        @return <pd.DataFrame>:\n            - index: elapsed time [day] from the start date\n            - Recovered: actual number of Recovered\n            - Actual: actual number of Susceptible\n            - {num}th_phase: predicted number of Susceptible\n        \"\"\"\n        # Arguments\n        df = subset_df.copy()\n        title = self._num2str(num)\n        # Curve fitting\n        # S = a * np.exp(-b * R)\n        # dS/dR = - b * S\n        f = lambda x, a, b: a * np.exp(-b * x)\n        a_ini = self.total_population\n        b_ini = - df[\"Actual\"].diff().reset_index(drop=True)[1] / a_ini\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\")\n            param, _ = curve_fit(f, df[\"Recovered\"], df[\"Actual\"], p0=[a_ini, b_ini])\n        # Predict Susceptible\n        f_partial = functools.partial(f, a=param[0], b=param[1])\n        df[f\"{title}_phase\"] = df[\"Recovered\"].apply(lambda x: f_partial(x))\n        return df\n\n    def show(self):\n        \"\"\"\n        Show trend and return list of change points.\n        @return <list[str]>: list of change points, like ['30Jan2020', '31Mar2020']\n        \"\"\"\n        fixed_cols = [\"Recovered\", \"Actual\"]\n        # Predict the future with curve fitting\n        df_list = [\n            self.curve_fit(df, num).drop(fixed_cols, axis=1)\n            for (num, df) in enumerate(self.subsets)\n        ]\n        pred_df = pd.concat(df_list, axis=1)\n        pred_df[fixed_cols] = self.all_df[fixed_cols]\n        phase0_name = \"Initial_phase\" if \"1st_phase\" in pred_df.columns else \"Regression\"\n        pred_df = pred_df.rename({\"0th_phase\": phase0_name}, axis=1)\n        # The list of change points\n        day_list = [df.index.min() for df in df_list]\n        dates = [\n            (self.start_date + timedelta(days=day))\n            for day in day_list[1:]\n        ]\n        str_dates = [d.strftime(\"%d%b%Y\") for d in dates]\n        # Show figure\n        for col in pred_df.columns:\n            if col == \"Recovered\":\n                continue\n            if col == \"Actual\":\n                plt.plot(\n                    pred_df[\"Recovered\"], pred_df[\"Actual\"],\n                    label=col, color=\"black\", marker=\".\", markeredgewidth=0, linewidth=0\n                )\n                continue\n            plt.plot(pred_df[\"Recovered\"], pred_df[col], label=col)\n        plt.yscale(\"log\")\n        ymin, ymax = pred_df[\"Actual\"].min(), pred_df[\"Actual\"].max()\n        ydiff_scale = int(np.log10(ymax - ymin))\n        yticks = np.linspace(round(ymin, - ydiff_scale), round(ymax, - ydiff_scale), 5)\n        plt.yticks([v.round() for v in yticks])\n        plt.xlim(0, None)\n        plt.xlabel(\"Recovered\")\n        plt.ylabel(\"Susceptible\")\n        if len(day_list) > 1:\n            for day in day_list[1:]:\n                value = pred_df.loc[pred_df.index[day], \"Recovered\"]\n                plt.axvline(x=value, color=\"black\", linestyle=\":\")\n        fmt = matplotlib.ticker.ScalarFormatter(useOffset=False)\n        fmt.set_scientific(False)\n        plt.gca().xaxis.set_major_formatter(fmt)\n        plt.gca().yaxis.set_major_formatter(fmt)\n        plt.legend(bbox_to_anchor=(1.02, 0), loc=\"lower left\", borderaxespad=0)\n        if str_dates:\n            plt.title(f\"{self.title}S-R trend change at {','.join(str_dates)}\")\n        else:\n            plt.title(f\"{self.title}S-R trend without change points\")\n        plt.show()\n        # Return the change points\n        return str_dates\n\n    def analyse(self, n_points=0, n_trials_cycle=10, allowance=1, n_trials_max=500):\n        \"\"\"\n        Find change points and return list of change points.\n        @n_points <int>: the number of change points\n        @n_trials_cycle <int>: the number of trials in one cycle\n            - When one cycle will ended,\n            - check whether the list of estimated time points is\n               equal to that of the last cycle with @allowance\n        @allowance <int>: allowance of the check of @n_trial_cycle\n        @n_trials_max <int>: max value of the number of trials\n        @return: the same as self.show()\n        \"\"\"\n        if len(self.all_df) < (n_points + 1) * 3:\n            raise Exception(\"Get more data or reduce n_points!\")\n        # Without change points\n        if n_points <= 0 or not isinstance(n_points, int):\n            self.subsets = [self.all_df.copy()]\n            return self.show()\n        # Find change points using Optuna\n        self.n_points = n_points\n        last_start_ids  = list()\n        n_trials_performed = 0\n        while True:\n            self.run(n_trials=n_trials_cycle)\n            n_trials_performed += n_trials_cycle\n            # Check the result with allowance\n            param_dict = self.study.best_params.copy()\n            start_ids = list(param_dict.values()) # 0 is not included\n            if last_start_ids:\n                are_settled = [\n                    abs(this - last) <= allowance\n                    for (this, last) in zip(start_ids, last_start_ids)\n                ]\n                if all(are_settled) or n_trials_performed > n_trials_max:\n                    break\n            last_start_ids = start_ids[:]\n        # Update the list of subsets\n        self.subsets = self.create_subsets(start_ids)\n        self.n_trials_performed = n_trials_performed\n        return self.show()\n    \n    def create_subsets(self, start_ids):\n        \"\"\"\n        Create the list of subsets using a list of the first row IDs.\n        @star_ids <list[int]>: list of the first row IDs\n        \"\"\"\n        subsets = list()\n        df = self.all_df.copy()\n        for sid in start_ids:\n            df2 = df.loc[sid:, :]\n            subsets.append(df.drop(df2.index, axis=0))\n            df = df2.copy()\n        subsets.append(df)\n        return subsets\n\n    def run(self, n_trials=10):\n        \"\"\"\n        Try optimization using Optuna.\n        @n_trials <int>: the number of trials\n        \"\"\"\n        # Create study object\n        if self.study is None:\n            self.study = optuna.create_study(direction=\"minimize\")\n        # Run trials\n        self.study.optimize(\n            lambda x: self.objective(x),\n            n_trials=n_trials,\n            n_jobs=-1\n        )\n\n    def objective(self, trial):\n        \"\"\"\n        Objective function for Optuna study.\n        @trial <Optuna.trial object>\n        \"\"\"\n        # Suggest start row IDs\n        start_ids = list()\n        for i in range(self.n_points):\n            id_min = start_ids[-1] + 3 if start_ids else 3\n            id_max = self.all_df.index.max() - 3 * (self.n_points + len(start_ids))\n            if id_min + 3 > id_max:\n                return np.inf\n            start_ids.append(trial.suggest_int(str(i), id_min, id_max))\n        # Create subsets\n        subsets = self.create_subsets(start_ids)\n        # Curve fitting for each subset\n        df_list = [self.curve_fit(df, num) for (num, df) in enumerate(subsets, start=1)]\n        # Calculate the error\n        return self.error_f(df_list)\n\n    def error_f(self, df_list):\n        \"\"\"\n        Error function of self.objective.\n        We need to minimize the difference of actual/predicted Susceptibe.\n        \"\"\"\n        diffs = [\n            abs(df[\"Actual\"] - df[f\"{self._num2str(num)}_phase\"]).sum()\n            for (num, df) in enumerate(df_list, start=1)\n        ]\n        return sum(diffs)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1f5acaa2-fff5-45ba-b371-daafda9ce78c","_cell_guid":"7eb3a21d-006c-43bd-ba1d-82fb46cec274","trusted":true},"cell_type":"markdown","source":"### Dataset arrangement"},{"metadata":{"_uuid":"ae73742e-4671-40d8-bd9f-b172e5894660","_cell_guid":"673e50af-45d8-4a5a-897d-88e88cb03cd8","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def create_target_df(ncov_df, total_population,\n                     confirmed=\"Confirmed\", recovered=\"Recovered\", fatal=\"Deaths\", **kwargs):\n    \"\"\"\n    Select the records of the places, calculate the number of susceptible people,\n     and calculate the elapsed time [day] from the start date of the target dataframe.\n    @ncov_df <pd.DataFrame>: the clean data\n    @total_population <int>: total population in the places\n    column names in @ncov_df:\n        @confirmed <str>: column name of the number of confirmed cases\n        @recovered <str>: column name of the number of recovered cases\n        @fatal <str>: column name of the number of fatal cases\n    @kwargs: keword arguments of select_area()\n    @return <tuple(2 objects)>:\n        - 1. first_date <pd.Timestamp>: the first date of the selected records\n        - 2. target_df <pd.DataFrame>:\n            - column T: elapsed time [min] from the start date of the dataset\n            - column Susceptible: the number of patients who are in the palces but not infected/recovered/died\n            - column Infected: the number of infected cases\n            - column Recovered: the number of recovered cases\n            - column Deaths: the number of death cases\n    \"\"\"\n    # Select the target records\n    df = select_area(ncov_df, **kwargs)\n    first_date = df.loc[df.index[0], \"Date\"]\n    # column T\n    df[\"T\"] = ((df[\"Date\"] - first_date).dt.total_seconds() / 60).astype(int)\n    # coluns except T\n    df = df.rename({\"Fatal\": fatal}, axis=1)\n    cols = [confirmed, recovered, fatal]\n    if not set(cols).issubset(set(df.columns)):\n        raise KeyError(f\"ncov_df must have {', '.join(cols)} column!\")\n    df[\"Susceptible\"] = total_population - df[confirmed]\n    df[\"Infected\"] = df[confirmed] - df[recovered] - df[fatal]\n    df[\"Recovered\"] = df[recovered]\n    df[\"Fatal\"] = df.loc[:, fatal]\n    response_variables = [\"Susceptible\", \"Infected\", \"Recovered\", \"Fatal\"]\n    # Return\n    target_df = df.loc[:, [\"T\", *response_variables]]\n    return (first_date, target_df)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9f164794-196a-4755-9d8f-083370aab0a3","_cell_guid":"5102c179-986a-40a7-91a2-711e3c9215fe","trusted":true},"cell_type":"markdown","source":"### Numerical simulation\nWe will perform numerical analysis to solve the ODE using scipy.integrate.solve_ivp function."},{"metadata":{"_uuid":"6007f8a5-764f-4e7e-95b3-ba8796f66402","_cell_guid":"95bcd2ad-14bb-42d1-8db0-d6dfda502f69","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def simulation(model, initials, step_n, **params):\n    \"\"\"\n    Solve ODE of the model.\n    @model <ModelBase>: the model\n    @initials <tuple[float]>: the initial values\n    @step_n <int>: the number of steps\n    @params: the paramerters of the model\n    \"\"\"\n    tstart, dt, tend = 0, 1, step_n\n    sol = solve_ivp(\n        fun=model(**params),\n        t_span=[tstart, tend],\n        y0=np.array(initials, dtype=np.float64),\n        t_eval=np.arange(tstart, tend + dt, dt),\n        dense_output=False\n    )\n    t_df = pd.Series(data=sol[\"t\"], name=\"t\")\n    y_df = pd.DataFrame(data=sol[\"y\"].T.copy(), columns=model.VARIABLES)\n    sim_df = pd.concat([t_df, y_df], axis=1)\n    return sim_df","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3922e417-890c-431a-a8bf-507662ce70e8","_cell_guid":"decfa29f-ccbe-4cad-9574-5ff0e771aae7","trusted":true},"cell_type":"markdown","source":"### Description of math model"},{"metadata":{"_uuid":"02915ddd-c0fd-4544-9e47-0a7b4f249cc2","_cell_guid":"eed8b0f8-1e0e-4c8c-8f87-02467bae6912","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"class ModelBase(object):\n    NAME = \"Model\"\n    VARIABLES = [\"x\"]\n    PRIORITIES = np.array([1])\n    QUANTILE_RANGE = [0.3, 0.7]\n    MONOTONIC = [\"x\"]\n\n    @classmethod\n    def param_dict(cls, train_df_divided=None, q_range=None):\n        \"\"\"\n        Define parameters without tau. This function should be overwritten.\n        @train_df_divided <pd.DataFrame>:\n            - column: t and non-dimensional variables\n        @q_range <list[float, float]>: quantile rage of the parameters calculated by the data\n        @return <dict[name]=(min, max):\n            @min <float>: min value\n            @max <float>: max value\n        \"\"\"\n        param_dict = dict()\n        return param_dict\n\n    @staticmethod\n    def calc_variables(df):\n        \"\"\"\n        Calculate the variables of the model.\n        This function should be overwritten.\n        @df <pd.DataFrame>\n        @return <pd.DataFrame>\n        \"\"\"\n        return df\n\n    @staticmethod\n    def calc_variables_reverse(df):\n        \"\"\"\n        Calculate measurable variables using the variables of the model.\n        This function should be overwritten.\n        @df <pd.DataFrame>\n        @return <pd.DataFrame>\n        \"\"\"\n        return df\n\n    @classmethod\n    def create_dataset(cls, ncov_df, total_population, **kwargs):\n        \"\"\"\n        Create dataset with the model-specific varibles.\n        The variables will be divided by total population.\n        The column names (not include T) will be lower letters.\n        **kwargs: See the function named create_target_df()\n        @return <tuple(objects)>:\n            - start_date <pd.Timestamp>\n            - initials <tuple(float)>: the initial values\n            - Tend <int>: the last value of T\n            - df <pd.DataFrame>: the dataset\n        \"\"\"\n        start_date, target_df = create_target_df(ncov_df, total_population, **kwargs)\n        df = cls.calc_variables(target_df).set_index(\"T\") / total_population\n        df.columns = [n.lower() for n in df.columns]\n        initials = df.iloc[0, :].values\n        df = df.reset_index()\n        Tend = df.iloc[-1, 0]\n        return (start_date, initials, Tend, df)\n\n    def calc_r0(self):\n        \"\"\"\n        Calculate R0. This function should be overwritten.\n        \"\"\"\n        return None\n\n    def calc_days_dict(self, tau):\n        \"\"\"\n        Calculate 1/beta [day] etc.\n        This function should be overwritten.\n        @param tau <int>: tau value [hour]\n        \"\"\"\n        return dict()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1bc607ad-3e75-445b-9c90-d88d84783237","_cell_guid":"52b04482-dbfb-4f59-a148-0d696eccfc3a","trusted":true},"cell_type":"markdown","source":"#### SIR model"},{"metadata":{"_uuid":"f4437e32-5ceb-4bd3-9efe-95b84dbcefc8","_cell_guid":"eada8314-baf7-49b0-8d26-d788c45f4cfb","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"class SIR(ModelBase):\n    NAME = \"SIR\"\n    VARIABLES = [\"x\", \"y\", \"z\"]\n    PRIORITIES = np.array([1, 1, 1])\n    MONOTONIC = [\"z\"]\n\n    def __init__(self, rho, sigma):\n        super().__init__()\n        self.rho = rho\n        self.sigma = sigma\n\n    def __call__(self, t, X):\n        # x, y, z = [X[i] for i in range(len(self.VARIABLES))]\n        # dxdt = - self.rho * x * y\n        # dydt = self.rho * x * y - self.sigma * y\n        # dzdt = self.sigma * y\n        dxdt = - self.rho * X[0] * X[1]\n        dydt = self.rho * X[0] * X[1] - self.sigma * X[1]\n        dzdt = self.sigma * X[1]\n        return np.array([dxdt, dydt, dzdt])\n\n    @classmethod\n    def param_dict(cls, train_df_divided=None, q_range=None):\n        param_dict = super().param_dict()\n        q_range = super().QUANTILE_RANGE[:] if q_range is None else q_range\n        if train_df_divided is not None:\n            df = train_df_divided.copy()\n            # rho = - (dx/dt) / x / y\n            rho_series = 0 - df[\"x\"].diff() / df[\"t\"].diff() / df[\"x\"] / df[\"y\"]\n            param_dict[\"rho\"] = rho_series.quantile(q_range)\n            # sigma = (dz/dt) / y\n            sigma_series = df[\"z\"].diff() / df[\"t\"].diff() / df[\"y\"]\n            param_dict[\"sigma\"] = sigma_series.quantile(q_range)\n            return param_dict\n        param_dict[\"rho\"] = (0, 1)\n        param_dict[\"sigma\"] = (0, 1)\n        return param_dict\n\n    @staticmethod\n    def calc_variables(df):\n        df[\"X\"] = df[\"Susceptible\"]\n        df[\"Y\"] = df[\"Infected\"]\n        df[\"Z\"] = df[\"Recovered\"] + df[\"Fatal\"]\n        return df.loc[:, [\"T\", \"X\", \"Y\", \"Z\"]]\n\n    @staticmethod\n    def calc_variables_reverse(df):\n        df[\"Susceptible\"] = df[\"X\"]\n        df[\"Infected\"] = df[\"Y\"]\n        df[\"Recovered/Deaths\"] = df[\"Z\"]\n        return df\n\n    def calc_r0(self):\n        if self.sigma == 0:\n            return np.nan\n        r0 = self.rho / self.sigma\n        return round(r0, 2)\n\n    def calc_days_dict(self, tau):\n        _dict = dict()\n        _dict[\"1/beta [day]\"] = int(tau / 24 / 60 / self.rho)\n        _dict[\"1/gamma [day]\"] = int(tau / 24 / 60 / self.sigma)\n        return _dict","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"da7442b6-fa0b-4bf2-bb2d-70625b5b944f","_cell_guid":"945c3774-cf7c-40c8-b63f-d852df420781","trusted":true},"cell_type":"markdown","source":"#### SIR-D model"},{"metadata":{"_uuid":"66a9f00d-1639-4fef-b66e-9fe8adb3f7dc","_cell_guid":"4bbd4ca2-bf18-440a-8fef-a81f8694957f","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"class SIRD(ModelBase):\n    NAME = \"SIR-D\"\n    VARIABLES = [\"x\", \"y\", \"z\", \"w\"]\n    PRIORITIES = np.array([1, 10, 10, 2])\n    MONOTONIC = [\"z\", \"w\"]\n\n    def __init__(self, kappa, rho, sigma):\n        super().__init__()\n        self.kappa = kappa\n        self.rho = rho\n        self.sigma = sigma\n\n    def __call__(self, t, X):\n        # x, y, z, w = [X[i] for i in range(len(self.VARIABLES))]\n        # dxdt = - self.rho * x * y\n        # dydt = self.rho * x * y - (self.sigma + self.kappa) * y\n        # dzdt = self.sigma * y\n        # dwdt = self.kappa * y\n        dxdt = - self.rho * X[0] * X[1]\n        dydt = self.rho * X[0] * X[1] - (self.sigma + self.kappa) * X[1]\n        dzdt = self.sigma * X[1]\n        dwdt = self.kappa * X[1]\n        return np.array([dxdt, dydt, dzdt, dwdt])\n\n    @classmethod\n    def param_dict(cls, train_df_divided=None, q_range=None):\n        param_dict = super().param_dict()\n        q_range = super().QUANTILE_RANGE[:] if q_range is None else q_range\n        if train_df_divided is not None:\n            df = train_df_divided.copy()\n            # kappa = (dw/dt) / y\n            kappa_series = df[\"w\"].diff() / df[\"t\"].diff() / df[\"y\"]\n            param_dict[\"kappa\"] = kappa_series.quantile(q_range)\n            # rho = - (dx/dt) / x / y\n            rho_series = 0 - df[\"x\"].diff() / df[\"t\"].diff() / df[\"x\"] / df[\"y\"]\n            param_dict[\"rho\"] = rho_series.quantile(q_range)\n            # sigma = (dz/dt) / y\n            sigma_series = df[\"z\"].diff() / df[\"t\"].diff() / df[\"y\"]\n            param_dict[\"sigma\"] = sigma_series.quantile(q_range)\n            return param_dict\n        param_dict[\"kappa\"] = (0, 1)\n        param_dict[\"rho\"] = (0, 1)\n        param_dict[\"sigma\"] = (0, 1)\n        return param_dict\n\n    @staticmethod\n    def calc_variables(df):\n        df[\"X\"] = df[\"Susceptible\"]\n        df[\"Y\"] = df[\"Infected\"]\n        df[\"Z\"] = df[\"Recovered\"]\n        df[\"W\"] = df[\"Fatal\"]\n        return df.loc[:, [\"T\", \"X\", \"Y\", \"Z\", \"W\"]]\n\n    @staticmethod\n    def calc_variables_reverse(df):\n        df[\"Susceptible\"] = df[\"X\"]\n        df[\"Infected\"] = df[\"Y\"]\n        df[\"Recovered\"] = df[\"Z\"]\n        df[\"Deaths\"] = df[\"W\"]\n        return df\n\n    def calc_r0(self):\n        try:\n            r0 = self.rho / (self.sigma + self.kappa)\n        except ZeroDivisionError:\n            return np.nan\n        return round(r0, 2)\n\n\n    def calc_days_dict(self, tau):\n        _dict = dict()\n        if self.kappa == 0:\n            _dict[\"1/alpha2 [day]\"] = 0\n        else:\n            _dict[\"1/alpha2 [day]\"] = int(tau / 24 / 60 / self.kappa)\n        _dict[\"1/beta [day]\"] = int(tau / 24 / 60 / self.rho)\n        if self.sigma == 0:\n            _dict[\"1/gamma [day]\"] = 0\n        else:\n            _dict[\"1/gamma [day]\"] = int(tau / 24 / 60 / self.sigma)\n        return _dict","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c178ee57-8983-4f55-84dd-71997fec53ce","_cell_guid":"1e115ae8-7e81-4055-896d-95889d3c973e","trusted":true},"cell_type":"markdown","source":"#### SIR-F model"},{"metadata":{"_uuid":"04c1a590-1767-4ab1-b7de-d58d8ca69841","_cell_guid":"b4fc216a-fe30-4316-90e1-2034c5abff38","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"class SIRF(ModelBase):\n    NAME = \"SIR-F\"\n    VARIABLES = [\"x\", \"y\", \"z\", \"w\"]\n    PRIORITIES = np.array([1, 10, 10, 2])\n    MONOTONIC = [\"z\", \"w\"]\n\n    def __init__(self, theta, kappa, rho, sigma):\n        super().__init__()\n        self.theta = theta\n        self.kappa = kappa\n        self.rho = rho\n        self.sigma = sigma\n\n    def __call__(self, t, X):\n        # x, y, z, w = [X[i] for i in range(len(self.VARIABLES))]\n        # dxdt = - self.rho * x * y\n        # dydt = self.rho * (1 - self.theta) * x * y - (self.sigma + self.kappa) * y\n        # dzdt = self.sigma * y\n        # dwdt = self.rho * self.theta * x * y + self.kappa * y\n        dxdt = - self.rho * X[0] * X[1]\n        dydt = self.rho * (1 - self.theta) * X[0] * X[1] - (self.sigma + self.kappa) * X[1]\n        dzdt = self.sigma * X[1]\n        dwdt = self.rho * self.theta * X[0] * X[1] + self.kappa * X[1]\n        return np.array([dxdt, dydt, dzdt, dwdt])\n\n    @classmethod\n    def param_dict(cls, train_df_divided=None, q_range=None):\n        param_dict = super().param_dict()\n        q_range = super().QUANTILE_RANGE[:] if q_range is None else q_range\n        param_dict[\"theta\"] = (0, 1)\n        param_dict[\"kappa\"] = (0, 1)\n        if train_df_divided is not None:\n            df = train_df_divided.copy()\n            # rho = - (dx/dt) / x / y\n            rho_series = 0 - df[\"x\"].diff() / df[\"t\"].diff() / df[\"x\"] / df[\"y\"]\n            param_dict[\"rho\"] = rho_series.quantile(q_range)\n            # sigma = (dz/dt) / y\n            sigma_series = df[\"z\"].diff() / df[\"t\"].diff() / df[\"y\"]\n            param_dict[\"sigma\"] = sigma_series.quantile(q_range)\n            return param_dict\n        param_dict[\"rho\"] = (0, 1)\n        param_dict[\"sigma\"] = (0, 1)\n        return param_dict\n\n    @staticmethod\n    def calc_variables(df):\n        df[\"X\"] = df[\"Susceptible\"]\n        df[\"Y\"] = df[\"Infected\"]\n        df[\"Z\"] = df[\"Recovered\"]\n        df[\"W\"] = df[\"Fatal\"]\n        return df.loc[:, [\"T\", \"X\", \"Y\", \"Z\", \"W\"]]\n\n    @staticmethod\n    def calc_variables_reverse(df):\n        df[\"Susceptible\"] = df[\"X\"]\n        df[\"Infected\"] = df[\"Y\"]\n        df[\"Recovered\"] = df[\"Z\"]\n        df[\"Fatal\"] = df[\"W\"]\n        return df\n\n    def calc_r0(self):\n        try:\n            r0 = self.rho * (1 - self.theta) / (self.sigma + self.kappa)\n        except ZeroDivisionError:\n            return np.nan\n        return round(r0, 2)\n\n    def calc_days_dict(self, tau):\n        _dict = dict()\n        _dict[\"alpha1 [-]\"] = round(self.theta, 3)\n        if self.kappa == 0:\n            _dict[\"1/alpha2 [day]\"] = 0\n        else:\n            _dict[\"1/alpha2 [day]\"] = int(tau / 24 / 60 / self.kappa)\n        _dict[\"1/beta [day]\"] = int(tau / 24 / 60 / self.rho)\n        if self.sigma == 0:\n            _dict[\"1/gamma [day]\"] = 0\n        else:\n            _dict[\"1/gamma [day]\"] = int(tau / 24 / 60 / self.sigma)\n        return _dict","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### SEWIR-F model"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"class SEWIRF(ModelBase):\n    NAME = \"SEWIR-F\"\n    VARIABLES = [\"x1\", \"x2\", \"x3\", \"y\", \"z\", \"w\"]\n    PRIORITIES = np.array([0, 0, 0, 10, 10, 2])\n    MONOTONIC = [\"z\", \"w\"]\n\n    def __init__(self, theta, kappa, rho1, rho2, rho3, sigma):\n        super().__init__()\n        self.theta = theta\n        self.kappa = kappa\n        self.rho1 = rho1\n        self.rho2 = rho2\n        self.rho3 = rho3\n        self.sigma = sigma\n\n    def __call__(self, t, X):\n        # x1, x2, x3, y, z, w = [X[i] for i in range(len(self.VARIABLES))]\n        # dx1dt = - self.rho1 * x1 * (x3 + y)\n        # dx2dt = self.rho1 * x1 * (x3 + y) - self.rho2 * x2\n        # dx3dt = self.rho2 * x2 - self.rho3 * x3\n        # dydt = self.rho3 * (1 - self.theta) * x3 - (self.sigma + self.kappa) * y\n        # dzdt = self.sigma * y\n        # dwdt = self.rho3 * self.theta * x3 + self.kappa * y\n        dx1dt = - self.rho1 * X[0] * (X[2] + X[3])\n        dx2dt = self.rho1 * X[0] * (X[2] + X[3]) - self.rho2 * X[1]\n        dx3dt = self.rho2 * X[1] - self.rho3 * X[2]\n        dydt = self.rho3 * (1 - self.theta) * X[2] - (self.sigma + self.kappa) * X[3]\n        dzdt = self.sigma * X[3]\n        dwdt = self.rho3 * self.theta * X[2] + self.kappa * X[3]\n        return np.array([dx1dt, dx2dt, dx3dt, dydt, dzdt, dwdt])\n\n    @classmethod\n    def param_dict(cls, train_df_divided=None, q_range=None):\n        param_dict = super().param_dict()\n        q_range = super().QUANTILE_RANGE[:] if q_range is None else q_range\n        param_dict[\"theta\"] = (0, 1)\n        param_dict[\"kappa\"] = (0, 1)\n        param_dict[\"rho1\"] = (0, 1)\n        param_dict[\"rho2\"] = (0, 1)\n        param_dict[\"rho3\"] = (0, 1)\n        if train_df_divided is not None:\n            df = train_df_divided.copy()\n            # sigma = (dz/dt) / y\n            sigma_series = df[\"z\"].diff() / df[\"t\"].diff() / df[\"y\"]\n            param_dict[\"sigma\"] = sigma_series.quantile(q_range)\n            return param_dict\n        param_dict[\"sigma\"] = (0, 1)\n        return param_dict\n\n    @staticmethod\n    def calc_variables(df):\n        df[\"X1\"] = df[\"Susceptible\"]\n        df[\"X2\"] = 0\n        df[\"X3\"] = 0\n        df[\"Y\"] = df[\"Infected\"]\n        df[\"Z\"] = df[\"Recovered\"]\n        df[\"W\"] = df[\"Fatal\"]\n        return df.loc[:, [\"T\", \"X1\", \"X2\", \"X3\", \"Y\", \"Z\", \"W\"]]\n\n    @staticmethod\n    def calc_variables_reverse(df):\n        df[\"Susceptible\"] = df[\"X1\"]\n        df[\"Infected\"] = df[\"Y\"]\n        df[\"Recovered\"] = df[\"Z\"]\n        df[\"Fatal\"] = df[\"W\"]\n        df[\"Exposed\"] = df[\"X2\"]\n        df[\"Waiting\"] = df[\"X3\"]\n        return df\n\n    def calc_r0(self):\n        try:\n            r0 = self.rho1 * (1 - self.theta) / (self.sigma + self.kappa)\n        except ZeroDivisionError:\n            return np.nan\n        return round(r0, 2)\n\n    def calc_days_dict(self, tau):\n        _dict = dict()\n        _dict[\"alpha1 [-]\"] = round(self.theta, 3)\n        if self.kappa == 0:\n            _dict[\"1/alpha2 [day]\"] = 0\n        else:\n            _dict[\"1/alpha2 [day]\"] = int(tau / 24 / 60 / self.kappa)\n        _dict[\"1/beta1 [day]\"] = int(tau / 24 / 60 / self.rho1)\n        _dict[\"1/beta2 [day]\"] = int(tau / 24 / 60 / self.rho2)\n        _dict[\"1/beta3 [day]\"] = int(tau / 24 / 60 / self.rho3)\n        if self.sigma == 0:\n            _dict[\"1/gamma [day]\"] = 0\n        else:\n            _dict[\"1/gamma [day]\"] = int(tau / 24 / 60 / self.sigma)\n        return _dict","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c713d3b8-105c-4cb0-82ed-dc1f54011715","_cell_guid":"acd82be6-702c-46fb-8b36-bf8b9afe9be4","trusted":true},"cell_type":"markdown","source":"#### SIR-FV model"},{"metadata":{"_uuid":"2a3978f2-82e3-4945-a981-4a6372e1bb20","_cell_guid":"25dec87e-96eb-4198-832e-6babe9381e4c","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"class SIRFV(ModelBase):\n    NAME = \"SIR-FV\"\n    VARIABLES = [\"x\", \"y\", \"z\", \"w\"]\n    PRIORITIES = np.array([1, 10, 10, 2])\n    MONOTONIC = [\"z\", \"w\"]\n\n    def __init__(self, theta, kappa, rho, sigma, omega=None, n=None, v_per_day=None):\n        \"\"\"\n        (n and v_per_day) or omega must be applied.\n        @n <float or int>: total population\n        @v_par_day <float or int>: vacctinated persons per day\n        \"\"\"\n        super().__init__()\n        self.theta = theta\n        self.kappa = kappa\n        self.rho = rho\n        self.sigma = sigma\n        if omega is None:\n            try:\n                self.omega = float(v_per_day) / float(n)\n            except TypeError:\n                s = \"Neither (n and va_per_day) nor omega must be applied!\"\n                raise TypeError(s)\n        else:\n            self.omega = float(omega)\n\n    def __call__(self, t, X):\n        # x, y, z, w = [X[i] for i in range(len(self.VARIABLES))]\n        # x with vacctination\n        dxdt = - self.rho * X[0] * X[1] - self.omega\n        dxdt = 0 - X[0] if X[0] + dxdt < 0 else dxdt\n        # y, z, w\n        dydt = self.rho * (1 - self.theta) * X[0] * X[1] - (self.sigma + self.kappa) * X[1]\n        dzdt = self.sigma * X[1]\n        dwdt = self.rho * self.theta * X[0] * X[1] + self.kappa * X[1]\n        return np.array([dxdt, dydt, dzdt, dwdt])\n\n    @classmethod\n    def param_dict(cls, train_df_divided=None, q_range=None):\n        param_dict = super().param_dict()\n        q_range = super().QUANTILE_RANGE[:] if q_range is None else q_range\n        param_dict[\"theta\"] = (0, 1)\n        param_dict[\"kappa\"] = (0, 1)\n        param_dict[\"omega\"] = (0, 1)\n        if train_df_divided is not None:\n            df = train_df_divided.copy()\n            # rho = - (dx/dt) / x / y\n            rho_series = 0 - df[\"x\"].diff() / df[\"t\"].diff() / df[\"x\"] / df[\"y\"]\n            param_dict[\"rho\"] = rho_series.quantile(q_range)\n            # sigma = (dz/dt) / y\n            sigma_series = df[\"z\"].diff() / df[\"t\"].diff() / df[\"y\"]\n            param_dict[\"sigma\"] = sigma_series.quantile(q_range)\n            return param_dict\n        param_dict[\"rho\"] = (0, 1)\n        param_dict[\"sigma\"] = (0, 1)\n        return param_dict\n\n    @staticmethod\n    def calc_variables(df):\n        df[\"X\"] = df[\"Susceptible\"]\n        df[\"Y\"] = df[\"Infected\"]\n        df[\"Z\"] = df[\"Recovered\"]\n        df[\"W\"] = df[\"Fatal\"]\n        return df.loc[:, [\"T\", \"X\", \"Y\", \"Z\", \"W\"]]\n\n    @staticmethod\n    def calc_variables_reverse(df):\n        df[\"Susceptible\"] = df[\"X\"]\n        df[\"Infected\"] = df[\"Y\"]\n        df[\"Recovered\"] = df[\"Z\"]\n        df[\"Fatal\"] = df[\"W\"]\n        df[\"Immuned\"] = 1 - df[[\"X\", \"Y\", \"Z\", \"W\"]].sum(axis=1)\n        return df\n\n    def calc_r0(self):\n        try:\n            r0 = self.rho * (1 - self.theta) / (self.sigma + self.kappa)\n        except ZeroDivisionError:\n            return np.nan\n        return round(r0, 2)\n\n    def calc_days_dict(self, tau):\n        _dict = dict()\n        _dict[\"alpha1 [-]\"] = round(self.theta, 3)\n        if self.kappa == 0:\n            _dict[\"1/alpha2 [day]\"] = 0\n        else:\n            _dict[\"1/alpha2 [day]\"] = int(tau / 24 / 60 / self.kappa)\n        _dict[\"1/beta [day]\"] = int(tau / 24 / 60 / self.rho)\n        if self.sigma == 0:\n            _dict[\"1/gamma [day]\"] = 0\n        else:\n            _dict[\"1/gamma [day]\"] = int(tau / 24 / 60 / self.sigma)\n        return _dict","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Parameter Estimation using Optuna"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"class Estimator(object):\n    def __init__(self, model, ncov_df, total_population, name=None, places=None, areas=None,\n                 excluded_places=None, start_date=None, end_date=None, date_format=\"%d%b%Y\", **params):\n        \"\"\"\n        Set training data.\n        @model <ModelBase>: the model\n        @name <str>: name of the area\n        @params: fixed parameter of the model\n        @the other params: See the function named create_target_df()\n        \"\"\"\n        # Fixed parameters\n        self.fixed_param_dict = params.copy()\n        if None in params.values():\n            self.fixed_param_dict = {\n                k: v for (k, v) in params.items() if v is not None\n            }\n        # Register the dataset arranged for the model\n        dataset = model.create_dataset(\n            ncov_df, total_population, places=places, areas=areas,\n            excluded_places=excluded_places,\n            start_date=start_date, end_date=end_date, date_format=date_format\n        )\n        self.start_time, self.initials, self.Tend, self.train_df = dataset\n        self.total_population = total_population\n        self.name = name\n        self.model = model\n        self.param_dict = dict()\n        self.study = None\n        self.optimize_df = None\n\n    def run(self, n_trials=500):\n        \"\"\"\n        Try estimation (optimization of parameters and tau).\n        @n_trials <int>: the number of trials\n        \"\"\"\n        if self.study is None:\n            self.study = optuna.create_study(direction=\"minimize\")\n        self.study.optimize(\n            lambda x: self.objective(x),\n            n_trials=n_trials,\n            n_jobs=-1\n        )\n        param_dict = self.study.best_params.copy()\n        param_dict.update(self.fixed_param_dict)\n        param_dict[\"R0\"] = self.calc_r0()\n        param_dict[\"score\"] = self.score()\n        param_dict.update(self.calc_days_dict())\n        self.param_dict = param_dict.copy()\n        return param_dict\n\n    def history_df(self):\n        \"\"\"\n        Return the hsitory of optimization.\n        @return <pd.DataFrame>\n        \"\"\"\n        optimize_df = self.study.trials_dataframe()\n        optimize_df[\"time[s]\"] = optimize_df[\"datetime_complete\"] - \\\n            optimize_df[\"datetime_start\"]\n        optimize_df[\"time[s]\"] = optimize_df[\"time[s]\"].dt.total_seconds()\n        self.optimize_df = optimize_df.drop(\n            [\"datetime_complete\", \"datetime_start\", \"system_attrs__number\"], axis=1)\n        return self.optimize_df.sort_values(\"value\", ascending=True)\n\n    def history_graph(self):\n        \"\"\"\n        Show the history of parameter search using pair-plot.\n        \"\"\"\n        if self.optimize_df is None:\n            self.history_df()\n        df = self.optimize_df.copy()\n        sns.pairplot(df.loc[:, df.columns.str.startswith(\n            \"params_\")], diag_kind=\"kde\", markers=\"+\")\n        plt.show()\n\n    def objective(self, trial):\n        \"\"\"\n        Objective function for Optuna study.\n        @trial <Optuna.trial object>\n        \"\"\"\n        # Time\n        try:\n            tau = self.fixed_param_dict[\"tau\"]\n        except KeyError:\n            tau = trial.suggest_int(\"tau\", 1, 1440)\n        train_df_divided = self.train_df.copy()\n        train_df_divided[\"t\"] = (train_df_divided[\"T\"] / tau).astype(np.int64)\n        # Parameters\n        param_dict = self.model.param_dict(train_df_divided)\n        p_dict = {\"tau\": None}\n        p_dict.update(\n            {\n                k: trial.suggest_uniform(k, *v)\n                for (k, v) in param_dict.items()\n            }\n        )\n        p_dict.update(self.fixed_param_dict)\n        p_dict.pop(\"tau\")\n        # Simulation\n        t_end = train_df_divided.loc[train_df_divided.index[-1], \"t\"]\n        sim_df = simulation(self.model, self.initials, step_n=t_end, **p_dict)\n        return self.error_f(train_df_divided, sim_df)\n\n    def error_f(self, train_df_divided, sim_df):\n        \"\"\"\n        We need to minimize the difference of the observed values and estimated values.\n        This function calculate the difference of the estimated value and obsereved value.\n        \"\"\"\n        n = self.total_population\n        df = pd.merge(train_df_divided, sim_df, on=\"t\", suffixes=(\"_observed\", \"_estimated\"))\n        diffs = [\n            # Weighted Average: the recent data is more important\n            p * np.average(\n                abs(df[f\"{v}_observed\"] - df[f\"{v}_estimated\"]) / (df[f\"{v}_observed\"] * n + 1),\n                weights=df[\"t\"]\n            )\n            for (p, v) in zip(self.model.PRIORITIES, self.model.VARIABLES)\n        ]\n        return sum(diffs) * n\n\n    def compare_df(self):\n        \"\"\"\n        Show the taining data and simulated data in one dataframe.\n\n        \"\"\"\n        est_dict = self.study.best_params.copy()\n        est_dict.update(self.fixed_param_dict)\n        tau = est_dict[\"tau\"]\n        est_dict.pop(\"tau\")\n        observed_df = self.train_df.drop(\"T\", axis=1)\n        observed_df[\"t\"] = (self.train_df[\"T\"] / tau).astype(int)\n        t_end = observed_df.loc[observed_df.index[-1], \"t\"]\n        sim_df = simulation(self.model, self.initials, step_n=t_end, **est_dict)\n        df = pd.merge(observed_df, sim_df, on=\"t\", suffixes=(\"_observed\", \"_estimated\"))\n        df = df.set_index(\"t\")\n        return df\n\n    def compare_graph(self):\n        \"\"\"\n        Compare obsereved and estimated values in graphs.\n        \"\"\"\n        df = self.compare_df()\n        use_variables = [\n            v for (i, (p, v)) in enumerate(zip(self.model.PRIORITIES, self.model.VARIABLES))\n            if p != 0 and i != 0\n        ]\n        val_len = len(use_variables) + 1\n        fig, axes = plt.subplots(\n            ncols=1, nrows=val_len, figsize=(9, 6 * val_len / 2))\n        for (ax, v) in zip(axes.ravel()[1:], use_variables):\n            df[[f\"{v}_observed\", f\"{v}_estimated\"]].plot.line(\n                ax=ax, ylim=(0, None), sharex=True,\n                title=f\"{self.model.NAME}: Comparison of observed/estimated {v}(t)\"\n            )\n            ax.yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n            ax.ticklabel_format(style=\"sci\",  axis=\"y\", scilimits=(0, 0))\n            ax.legend(bbox_to_anchor=(1.02, 0),\n                      loc=\"lower left\", borderaxespad=0)\n        for v in use_variables:\n            df[f\"{v}_diff\"] = df[f\"{v}_observed\"] - df[f\"{v}_estimated\"]\n            df[f\"{v}_diff\"].plot.line(\n                ax=axes.ravel()[0], sharex=True,\n                title=f\"{self.model.NAME}: observed - estimated\"\n            )\n        axes.ravel()[0].axhline(y=0, color=\"black\", linestyle=\"--\")\n        axes.ravel()[0].yaxis.set_major_formatter(\n            ScalarFormatter(useMathText=True))\n        axes.ravel()[0].ticklabel_format(\n            style=\"sci\",  axis=\"y\", scilimits=(0, 0))\n        axes.ravel()[0].legend(bbox_to_anchor=(1.02, 0),\n                               loc=\"lower left\", borderaxespad=0)\n        fig.tight_layout()\n        fig.show()\n\n    def calc_r0(self):\n        \"\"\"\n        Calculate R0.\n        \"\"\"\n        est_dict = self.study.best_params.copy()\n        est_dict.update(self.fixed_param_dict)\n        est_dict.pop(\"tau\")\n        model_instance = self.model(**est_dict)\n        return model_instance.calc_r0()\n\n    def calc_days_dict(self):\n        \"\"\"\n        Calculate 1/beta etc.\n        \"\"\"\n        est_dict = self.study.best_params.copy()\n        est_dict.update(self.fixed_param_dict)\n        tau = est_dict[\"tau\"]\n        est_dict.pop(\"tau\")\n        model_instance = self.model(**est_dict)\n        return model_instance.calc_days_dict(tau)\n\n    def predict_df(self, step_n):\n        \"\"\"\n        Predict the values in the future.\n        @step_n <int>: the number of steps\n        @return <pd.DataFrame>: predicted data for measurable variables.\n        \"\"\"\n        est_dict = self.study.best_params.copy()\n        est_dict.update(self.fixed_param_dict)\n        tau = est_dict[\"tau\"]\n        est_dict.pop(\"tau\")\n        df = simulation(self.model, self.initials, step_n=step_n, **est_dict)\n        df[\"Time\"] = (\n            df[\"t\"] * tau).apply(lambda x: timedelta(minutes=x)) + self.start_time\n        df = df.set_index(\"Time\").drop(\"t\", axis=1)\n        df = (df * self.total_population).astype(np.int64)\n        upper_cols = [n.upper() for n in df.columns]\n        df.columns = upper_cols\n        df = self.model.calc_variables_reverse(df).drop(upper_cols, axis=1)\n        return df\n\n    def predict_graph(self, step_n, name=None, excluded_cols=None):\n        \"\"\"\n        Predict the values in the future and create a figure.\n        @step_n <int>: the number of steps\n        @name <str>: name of the area\n        @excluded_cols <list[str]>: the excluded columns in the figure\n        \"\"\"\n        if self.name is not None:\n            name = self.name\n        else:\n            name = str() if name is None else name\n        df = self.predict_df(step_n=step_n)\n        if excluded_cols is not None:\n            df = df.drop(excluded_cols, axis=1)\n        r0 = self.param_dict[\"R0\"]\n        title = f\"Prediction in {name} with {self.model.NAME} model: R0 = {r0}\"\n        today = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)\n        line_plot(df, title, v=today, h=self.total_population)\n\n    def rmsle(self, compare_df):\n        \"\"\"\n        Return the value of RMSLE.\n        @param compare_df <pd.DataFrame>\n        \"\"\"\n        df = compare_df.set_index(\"t\") * self.total_population\n        score = 0\n        for (priority, v) in zip(self.model.PRIORITIES, self.model.VARIABLES):\n            if priority == 0:\n                continue\n            observed, estimated = df[f\"{v}_observed\"], df[f\"{v}_estimated\"]\n            diff = (np.log10(observed + 1) - np.log10(estimated + 1))\n            score += (diff ** 2).sum()\n        rmsle = np.sqrt(score / len(df) * 2)\n        return rmsle\n\n    def score(self):\n        \"\"\"\n        Return the value of RMSLE.\n        \"\"\"\n        rmsle = self.rmsle(self.compare_df().reset_index(\"t\"))\n        return rmsle\n\n    def info(self):\n        \"\"\"\n        Return Estimater information.\n        @return <tupple[object]>:\n            - <ModelBase>: model\n            - <dict[str]=str>: name, total_population, start_time, tau\n            - <dict[str]=float>: values of parameters of model\n        \"\"\"\n        param_dict = self.study.best_params.copy()\n        param_dict.update(self.fixed_param_dict)\n        info_dict = {\n            \"name\": self.name,\n            \"total_population\": self.total_population,\n            \"start_time\": self.start_time,\n            \"tau\": param_dict[\"tau\"],\n            \"initials\": self.initials\n        }\n        param_dict.pop(\"tau\")\n        return (self.model, info_dict, param_dict)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b6456fea-dbb4-429f-bddd-f2f28adb2850","_cell_guid":"b3dc178b-d383-4d93-be08-d7ae4b1641c8","trusted":true},"cell_type":"markdown","source":"### Prediction of the data using some models"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"class Predicter(object):\n    \"\"\"\n    Predict the future using models.\n    \"\"\"\n    def __init__(self, name, total_population, start_time, tau, initials, date_format=\"%d%b%Y\"):\n        \"\"\"\n        @name <str>: place name\n        @total_population <int>: total population\n        @start_time <datatime>: the start time\n        @tau <int>: tau value (time step)\n        @initials <list/tupple/np.array[float]>: initial values of the first model\n        @date_format <str>: date format to display in figures\n        \"\"\"\n        self.name = name\n        self.total_population = total_population\n        self.start_time = start_time.replace(hour=0, minute=0, second=0, microsecond=0)\n        self.tau = tau\n        self.date_format = date_format\n        # Un-fixed\n        self.last_time = start_time\n        self.axvlines = list()\n        self.initials = initials\n        self.df = pd.DataFrame()\n        self.title_list = list()\n        self.reverse_f = lambda x: x\n        self.model_names = list()\n\n    def add(self, model, end_day_n=None, count_from_last=False, vline=True, **param_dict):\n        \"\"\"\n        @model <ModelBase>: the epidemic model\n        @end_day_n <int/None>: day number of the end date (0, 1, 2,...), or None (now)\n            - if @count_from_last <bool> is True, start point will be the last date registered to Predicter\n        @vline <bool>: if True, vertical line will be shown at the end date\n        @**param_dict <dict>: keyword arguments of the model\n        \"\"\"\n        # Validate day number, and calculate step number\n        vline_yesterday = False\n        if end_day_n == 0:\n            end_day_n = 1\n            vline_yesterday = True\n        if end_day_n is None:\n            end_time = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)\n        else:\n            if count_from_last:\n                end_time = self.last_time + timedelta(days=end_day_n)\n            else:\n                end_time = self.start_time + timedelta(days=end_day_n)\n        if end_time <= self.last_time:\n            raise Exception(f\"Model on {end_time.strftime(self.date_format)} has been registered!\")\n        step_n = int((end_time - self.last_time).total_seconds() / 60 / self.tau) + 1\n        self.last_time = end_time.replace(hour=0, minute=0, second=0, microsecond=0)\n        # Perform simulation\n        new_df = simulation(model, self.initials, step_n=step_n, **param_dict)\n        new_df[\"t\"] = new_df[\"t\"] + len(self.df)\n        self.df = pd.concat([self.df, new_df.iloc[1:, :]], axis=0).fillna(0)\n        self.initials = new_df.set_index(\"t\").iloc[-1, :]\n        # For title\n        self.model_names.append(model.NAME)\n        if vline:\n            vline_date = end_time.replace(hour=0, minute=0, second=0, microsecond=0)\n            if vline_yesterday:\n                vline_date -= timedelta(days=1)\n            self.axvlines.append(vline_date)\n            r0 = model(**param_dict).calc_r0()\n            if len(self.axvlines) == 1:\n                self.title_list.append(f\"{model.NAME}(R0={r0}, -{vline_date.strftime(self.date_format)})\")\n            else:\n                if model.NAME == self.model_names[-1]:\n                    self.title_list.append(f\"({r0}, -{vline_date.strftime(self.date_format)})\")\n                else:\n                    self.title_list.append(f\"{model.NAME}({r0}, -{end_time.strftime(self.date_format)})\")\n        # Update reverse function (X, Y,.. to Susceptible, Infected,...)\n        self.reverse_f = model.calc_variables_reverse\n        return self\n\n    def restore_df(self, min_infected=1):\n        \"\"\"\n        Return the dimentional simulated data.\n        @min_infected <int>: if Infected < min_infected, the records will not be used\n        @return <pd.DataFrame>\n        \"\"\"\n        df = self.df.copy()\n        df[\"Time\"] = self.start_time + df[\"t\"].apply(lambda x: timedelta(minutes=x * self.tau))\n        df = df.drop(\"t\", axis=1).set_index(\"Time\") * self.total_population\n        df = df.astype(np.int64)\n        upper_cols = [n.upper() for n in df.columns]\n        df.columns = upper_cols\n        df = self.reverse_f(df).drop(upper_cols, axis=1)\n        df = df.loc[df[\"Infected\"] >= min_infected, :]\n        return df\n\n    def restore_graph(self, drop_cols=None, min_infected=1, **kwargs):\n        \"\"\"\n        Show the dimentional simulate data as a figure.\n        @drop_cols <list[str]>: the columns not to be shown\n        @min_infected <int>: if Infected < min_infected, the records will not be used\n        @kwargs: keyword arguments of line_plot() function\n        \"\"\"\n        df = self.restore_df(min_infected=min_infected)\n        if drop_cols is not None:\n            df = df.drop(drop_cols, axis=1)\n        today = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)\n        axvlines = [today, *self.axvlines] if len(self.axvlines) == 1 else self.axvlines[:]\n        line_plot(\n            df,\n            title=f\"{self.name}: {', '.join(self.title_list)}\",\n            v=axvlines[:-1],\n            h=self.total_population,\n            **kwargs\n        )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Scenario analysis"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"class Scenario(object):\n    \"\"\"\n    Class for scenario analysis.\n    \"\"\"\n    SUFFIX_DICT = defaultdict(lambda: \"th\")\n    SUFFIX_DICT.update({1: \"st\", 2: \"nd\", 3: \"rd\"})\n\n    def __init__(self, ncov_df, name, is_country=True, date_format=\"%d%b%Y\",\n                 total_population=None, population_dict=None, **kwargs):\n        \"\"\"\n        @ncov_df <pd.DataFrame>: the cleaned data\n        @name <str>: name of the country/area\n        @is_country <bool>: if True, @places arguments can be ommited\n        @date_format <str>: string format of date\n        @total_population <int>: total population of the area\n        @population_dict <dict[country] = int>: dictionary of total population of each country\n        @kwargs: keyword arguments of select_area() function\n        \"\"\"\n        # Select area\n        kwargs_key_set = set(kwargs.keys())\n        if is_country and not set([\"places\", \"excluded_places\", \"areas\"]).issubset(kwargs_key_set):\n            record_df = select_area(\n                ncov_df, places=[(name, None)], areas=None, excluded_places=None,\n                **kwargs\n            )\n        else:\n            record_df = select_area(ncov_df, **kwargs)\n        # Total population\n        try:\n            total_population = population_dict[name]\n        except (TypeError, KeyError):\n            pass\n        if not isinstance(total_population, int) and total_population is not None:\n            raise TypeError(\"total_population must be a integer!\")\n        self.total_population = total_population\n        # Arrange dataset\n        record_df = record_df.set_index(\"Date\").resample(\"D\").last()\n        record_df = record_df.interpolate(method=\"linear\")\n        record_df = record_df.loc[:, [\"Confirmed\", \"Infected\", \"Deaths\", \"Recovered\"]]\n        self.record_df = record_df.reset_index()\n        self.name = name\n        self.date_format = date_format\n        self.phase_dict = dict()\n        self.estimator_dict = dict()\n        self.param_df = pd.DataFrame()\n        self.future_phase_dict = dict()\n        self.future_param_dict = dict()\n        self.phases_without_vline = list()\n        self.last_model = ModelBase\n\n    def show_record(self):\n        \"\"\"\n        Show the records.\n        \"\"\"\n        line_plot(\n            self.record_df.drop(\"Confirmed\", axis=1).set_index(\"Date\"),\n            f\"{self.name}: Cases over time\",\n            y_integer=True\n        )\n        return self.record_df\n\n    def growth_factor(self, days_to_predict=0, until_stopping=False, show_figure=True):\n        \"\"\"\n        Return growth factor group and the history of growth factor values.\n        @days_to_predict <int>: how many days to predict\n        @until_stopping <bool>:\n            if True and days_to_predict > 0,\n            calculate growth factor values until the group will shift stopping\n            after the last observation date\n        @show_figure <bool>: if True, show line plot of cases over time\n        \"\"\"\n        # Calculate growth factor\n        if days_to_predict <= 0:\n            # Value\n            records = self.record_df.set_index(\"Date\")[\"Confirmed\"]\n            growth = records.diff() / records.diff().shift(freq=\"D\")\n            growth = growth[:self.record_df[\"Date\"].max()]\n        else:\n            records = self.predict(days=days_to_predict, show_figure=False)\n            records = records[\"Confirmed\"].fillna(\"ffill\")\n            growth = records.diff() / records.diff().shift()\n        growth = growth.replace(np.inf, np.nan).fillna(1.0)\n        growth = growth.rolling(7).mean().dropna().round(2)\n        # Group\n        if days_to_predict > 0 and until_stopping:\n            last_observe_date = self.record_df[\"Date\"].max().round(\"D\")\n            df = pd.DataFrame(\n                {\"Date\": growth.index.round(\"D\"), \"Value\": growth}\n            )\n            df = df.set_index(\"Date\").resample(\"D\").last().reset_index()\n            df = df.loc[df[\"Date\"] > (last_observe_date - timedelta(days=8)), :]\n            date_df = df.loc[(df[\"Value\"] < 1).rolling(7).sum() >= 7, \"Date\"]\n            try:\n                calc_date = date_df.reset_index(drop=True)[0]\n            except IndexError:\n                calc_date = df[\"Date\"].max()\n            group = \"Stopping\"\n            growth = df.loc[df[\"Date\"] <= calc_date, :]\n            more_n = (growth[\"Value\"] > 1)[::-1].cumprod().sum()\n            less_n = (growth[\"Value\"] < 1)[::-1].cumprod().sum()\n            growth = growth.set_index(\"Date\")\n            date_str = calc_date.strftime(\"%d%b%Y\")\n            fig_title = f\"{self.name}: Growth factor over time with prediction until {date_str}\"\n        else:\n            more_n = (growth > 1)[::-1].cumprod().sum()\n            less_n = (growth < 1)[::-1].cumprod().sum()\n            calc_date = growth.index[-1]\n            group = \"Outbreaking\" if more_n >= 7 else \"Stopping\" if less_n >= 7 else \"Crossroad\"\n            fig_title = f\"{self.name}: Growth Factor over time\"\n        group_df = pd.DataFrame(\n            {\n                \"Date\": calc_date,\n                \"Group\": group,\n                \"GF > 1 [straight days]\": more_n,\n                \"GF < 1 [straight days]\": less_n\n            },\n            index=[self.name]\n        )\n        # Growth factor over time\n        if show_figure:\n            growth.plot(title=fig_title, legend=False)\n            plt.axhline(1.0, color=\"black\", linestyle=\"--\")\n            plt.xlabel(None)\n            today = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)\n            plt.axvline(today, color=\"black\", linestyle=\"--\")\n            plt.show()\n        return group_df\n        \n    def trend(self, n_points=0, total_population=None, **kwargs):\n        \"\"\"\n        Perform trend analysis.\n        @n_points <int>: the number of change points\n        @total_population <int or list[int]>: total population\n        @kwargs: the other keyword arguments of Trend.analyse() method\n        \"\"\"\n        # Total population\n        if total_population is None:\n            if self.total_population is None:\n                raise Exception(\"Please set total_population!\")\n            total_population = self.total_population\n        else:\n            if self.total_population is None:\n                self.total_population = total_population\n        # Trend analysis\n        trend_obj = Trend(self.record_df, total_population, name=self.name)\n        return trend_obj.analyse(n_points=n_points, **kwargs)\n\n    def set_phase(self, start_dates, total_population=None, population=None):\n        \"\"\"\n        Set phase for hyperparameter estimation.\n        @start_dates <list[str]>: list of start dates of the phases\n        @total_population/population <int or list[int]>: total population or list of total population\n            - if None, use the value set by self.init() or self.trend()\n        \"\"\"\n        total_population = population if total_population is None else total_population\n        if total_population is None:\n            if self.total_population is None:\n                raise Exception(\"Please set total_population!\")\n            total_population = self.total_population\n        end_dates = [\n            (datetime.strptime(s, self.date_format) - timedelta(days=1)).strftime(self.date_format)\n            for s in start_dates[1:]\n        ]\n        end_dates.append(None)\n        if isinstance(total_population, int):\n            population_values = [total_population for _ in range(len(start_dates))]\n        elif len(total_population) == len(start_dates):\n            population_values = total_population[:]\n        else:\n            raise Exception(\"start_date and population must have the same length!\")\n        self.phase_dict = {\n            self._num2str(n): {\"start_date\": s, \"end_date\": e, \"population\": p}\n            for (n, (s, e, p)) in enumerate(zip(start_dates, end_dates, population_values), 1)\n        }\n        self.estimator_dict = dict()\n        return pd.DataFrame.from_dict(self.phase_dict, orient=\"index\").fillna(\"-\")\n\n    def estimate(self, model, n_trials=100, same_tau=True):\n        \"\"\"\n        Perform hyperparameter estimation.\n        @model <ModelBase>: math model\n        @n_trials <int>: the number of trials\n        @same_tau <bool>:\n            whether apply the tau value of first phase to the following phases or not.\n        \"\"\"\n        if not self.phase_dict:\n            raise Exception(\"Please use Scenario.set_phase() at first.\")\n        tau = None\n        est_start_time = datetime.now()\n        for num in self.phase_dict.keys():\n            print(f\"Hyperparameter estimation of {num} phase.\")\n            target_dict = self.phase_dict[num]\n            while True:\n                # Create estimator\n                est_start_time_class = datetime.now()\n                self.estimator_dict[num] = Estimator(\n                    model, self.record_df, target_dict[\"population\"],\n                    name=self.name,\n                    start_date=target_dict[\"start_date\"],\n                    end_date=target_dict[\"end_date\"],\n                    date_format=self.date_format,\n                    tau=tau\n                )\n                print(\"\\tEstimator was created.\")\n                # Run trials\n                while True:\n                    print(f\"\\t\\t{n_trials} trials\", end=\" \")\n                    est_start_time_run = datetime.now()\n                    with warnings.catch_warnings():\n                        warnings.simplefilter(\"ignore\")\n                        _ = self.estimator_dict[num].run(n_trials=n_trials)\n                    minutes, seconds = divmod(int((datetime.now() - est_start_time_run).total_seconds()), 60)\n                    print(f\"finished in {minutes} min {seconds} sec.\")\n                    # Check if estimated in (observed * 0.8, observed * 1.2)\n                    compare_df = self.estimator_dict[num].compare_df()\n                    targets = [\n                        (compare_df[f\"{val}_estimated\"], compare_df[f\"{val}_observed\"])\n                        for val in model.MONOTONIC\n                    ]\n                    max_ok = [obs.max() * 0.8 <= est.max() <= obs.max() * 1.2 for (est, obs) in targets]\n                    monotonic_ok = [target[0].is_monotonic for target in targets]\n                    elapsed = (datetime.now() - est_start_time_class).total_seconds()\n                    if all(max_ok) or not all(monotonic_ok) or elapsed > 60 * 3:\n                        break\n                if all(monotonic_ok) and all(max_ok):\n                    print(\"\\tSuccessfully estimated.\")\n                    break\n                vals = [val for (val, ok) in zip(model.MONOTONIC, monotonic_ok) if not ok]\n                try:\n                    print(f\"\\tEstimator will be replaced because estimated {vals[0]} is non-monotonic.\")\n                except IndexError:\n                    print(f\"\\tEstimator will be replaced because it is incapable of improvement.\")\n            tau = self.estimator_dict[num].param_dict[\"tau\"]\n        minutes, seconds = divmod(int((datetime.now() - est_start_time).total_seconds()), 60)\n        print(f\"Total: {minutes} min {seconds} sec.\")\n        self.show_parameters()\n        self.last_model = model\n\n    def accuracy_graph(self, phase_n=1):\n        \"\"\"\n        Show observed - estimated graph.\n        @phase_n <int>: phase number\n        \"\"\"\n        phase_numbers = self.estimator_dict.keys()\n        phase = self._num2str(phase_n)\n        if phase not in phase_numbers:\n            raise KeyError(f\"phase_n must be in {list(phase_numbers)[0]} - {list(phase_numbers)[-1]}\")\n        self.estimator_dict[phase].compare_graph()\n\n    def _num2str(self, num):\n        \"\"\"\n        Convert numbers to 1st, 2nd etc.\n        @num <int>: number\n        @return <str>\n        \"\"\"\n        q, mod = divmod(num, 10)\n        suffix = \"th\" if q == 1 else self.SUFFIX_DICT[mod]\n        return f\"{num}{suffix}\"\n\n    def show_parameters(self):\n        \"\"\"\n        Show the parameter values.\n        @retunr <pd.DataFrame>\n        \"\"\"\n        # Phase information\n        phase_dict = self.phase_dict.copy()\n        phase_dict.update(self.future_phase_dict)\n        df1 = pd.DataFrame.from_dict(phase_dict, orient=\"index\")\n        # Parameter information\n        _dict = {\n            k: estimator.param_dict\n            for (k, estimator) in self.estimator_dict.items()\n        }\n        _future_dict = {\n            k: {\n                \"tau\": _dict[\"1st\"][\"tau\"],\n                **param_dict,\n                \"R0\": self.last_model(**param_dict).calc_r0(),\n                \"score\": None,\n                **self.last_model(**param_dict).calc_days_dict(_dict[\"1st\"][\"tau\"])\n            }\n            for (k, param_dict) in self.future_param_dict.items()\n        }\n        _dict.update(_future_dict)\n        df2 = pd.DataFrame.from_dict(_dict, orient=\"index\")\n        # Rename R0 to Rt\n        df2 = df2.rename({\"R0\": \"Rt\"}, axis=1)\n        self.param_df = pd.concat([df1, df2], axis=1).fillna(\"-\")\n        return self.param_df\n\n    def param(self, phase, param_name):\n        \"\"\"\n        Return parameter value.\n        @phase <str>: phase name, like 1st, 2nd..., or last\n        @param_name <str>: name of parameter, like rho\n        \"\"\"\n        if phase == \"last\":\n            phase = list(self.phase_dict.items())[-1][0]\n        try:\n            estimator = self.estimator_dict[phase]\n        except KeyError:\n            raise KeyError(\"Please revise phase name (NOT iinclude future params). e.g. 1st, 2nd,... or last\")\n        try:\n            param_name = \"R0\" if param_name == \"Rt\" else param_name\n            return estimator.param_dict[param_name]\n        except KeyError:\n            raise KeyError(\"Please revise parameter name. e.g. rho, gamma, R0 or R0\")\n\n    def param_history(self, targets=None, box_plot=True, **kwargs):\n        \"\"\"\n        Show the ratio to 1st parameters as a figure (bar plot).\n        @targets <list[str] or str>: parameters to show (including Rt etc.)\n        @box_plot <bool>: if True, box plot. if False, line plot.\n        @kwargs: keword arguments of pd.DataFrame.plot or line_plot()\n        \"\"\"\n        _ = self.show_parameters()\n        targets = self.param_df.columns if targets is None else targets\n        targets = [targets] if isinstance(targets, str) else targets\n        if \"R0\" in targets:\n            targets = [t.replace(\"R0\", \"Rt\") for t in targets]\n        df = self.param_df.loc[:, targets]\n        df.index = self.param_df[[\"start_date\", \"end_date\"]].apply(\n            lambda x: f\"{x[0]}-{x[1].replace('-', 'today')}\",\n            axis=1\n        )\n        df = df / df.iloc[0]\n        if box_plot:\n            df.plot.bar(title=\"Ratio to 1st parameters\", **kwargs)\n            plt.xticks(rotation=0)\n            plt.legend(bbox_to_anchor=(1.02, 0), loc=\"lower left\", borderaxespad=0)\n            plt.show()\n        else:\n            _df = df.reset_index(drop=True)\n            _df.index = _df.index + 1\n            line_plot(\n                _df, title=\"Ratio to 1st parameters\",\n                xlabel=\"Phase\", ylabel=str(), math_scale=False,\n                **kwargs\n            )\n\n    def compare_estimated_numbers(self, phases=None):\n        \"\"\"\n        Compare the number of confimred cases estimated with the parameters and show graph.\n        @variable <str>: variable to compare\n        @phases <list[str]>: phase to show (if None, all)\n        \"\"\"\n        phases = list(self.phase_dict.keys()) if phases is None else phases\n        # Observed\n        df = pd.DataFrame(self.record_df.set_index(\"Date\")[\"Confirmed\"])\n        # Estimated\n        for (num, estimator) in self.estimator_dict.items():\n            model, info_dict, param_dict = estimator.info()\n            day_n = int((datetime.today() - info_dict[\"start_time\"]).total_seconds() / 60 / 60 / 24 + 1)\n            predicter = Predicter(**info_dict)\n            predicter.add(model, end_day_n=day_n, **param_dict)\n            # Calculate the number of confirmed cases\n            new_df = predicter.restore_df().drop(\"Susceptible\", axis=1).sum(axis=1)\n            new_df = new_df.resample(\"D\").last()\n            df = pd.concat([df, new_df], axis=1)\n        # Show graph\n        df = df.fillna(0).astype(np.int64)\n        df.columns = [\"Observed\"] + [f\"{phase}_param\" for phase in self.phase_dict.keys()]\n        df = df.loc[self.phase_dict[\"1st\"][\"start_date\"]: self.record_df[\"Date\"].max(), :]\n        for col in df.columns[1:]:\n            if col[:col.find(\"_\")] not in phases:\n                continue\n            line_plot(\n                df.replace(0, np.nan)[[\"Observed\", col]],\n                f\"Confirmed cases over time: Actual and predicted with {col}\",\n                y_integer=True\n            )\n\n    def clear_future_param(self):\n        \"\"\"\n        Clear the future parameters.\n        \"\"\"\n        self.future_param_dict = dict()\n        self.future_phase_dict = dict()\n        last_phase = list(self.phase_dict.items())[-1][0]\n        self.phase_dict[last_phase][\"end_date\"] = None\n        return self\n\n    def add_future_param(self, start_date, vline=True, **kwargs):\n        \"\"\"\n        Add parameters of the future.\n        @start_date <str>: the start date of the phase\n        @vline <bool>: if True, add vertical line in the figure of predicted number of cases\n        @kwargs: keword argument of parameters to change\n        \"\"\"\n        yesterday_of_start = (pd.to_datetime(start_date) - timedelta(days=1)).strftime(self.date_format)\n        # Last phase registered\n        phase_dict = self.phase_dict.copy()\n        phase_dict.update(self.future_phase_dict)\n        last_phase = list(phase_dict.items())[-1][0]\n        # Set the end date of the last phase\n        if self.future_phase_dict:\n            self.future_phase_dict[last_phase][\"end_date\"] = yesterday_of_start\n        else:\n            self.phase_dict[last_phase][\"end_date\"] = yesterday_of_start\n        # Set the new phase\n        try:\n            param_dict = self.estimator_dict[last_phase].info()[2]\n            population = self.phase_dict[last_phase][\"population\"]\n        except KeyError:\n            param_dict = self.future_param_dict[last_phase].copy()\n            population = self.future_phase_dict[last_phase][\"population\"]\n        param_dict.update(**kwargs)\n        new_phase = self._num2str(len(phase_dict) + 1)\n        self.future_param_dict[new_phase] = param_dict\n        self.future_phase_dict[new_phase] = {\n            \"start_date\": start_date,\n            \"end_date\": None,\n            \"population\": population\n        }\n        if not vline:\n            self.phases_without_vline.append(new_phase)\n        return pd.DataFrame.from_dict(self.future_param_dict, orient=\"index\")\n\n    def add_future_param_gradually(self, start_date, end_date, param, first, last):\n        \"\"\"\n        Set the future parameters. The value will be gradually (log-scale) changed.\n        @start_date <str>: the start date of change\n        @end_date <str>: the end date of change\n        @param <str>: parameter name\n        @first <float>: parameter value of the start date\n        @last <float>: parameter value of the end date\n        \"\"\"\n        start = (pd.to_datetime(start_date) - timedelta(days=1)).strftime(self.date_format)\n        dates = pd.date_range(start=start, end=end_date, freq=\"D\")\n        values = np.logspace(\n            start=np.log10(first), stop=np.log10(last), num=len(dates), base=10.0\n        )\n        for (d, v) in zip(dates[1:], values[1:]):\n            vline = True if d in dates[-2:] else False\n            self.add_future_param(d.strftime(self.date_format), vline=vline, **{param: v})\n        return pd.DataFrame.from_dict(self.future_param_dict, orient=\"index\")\n\n    def predict(self, days=1000, min_infected=1, show_figure=True):\n        \"\"\"\n        Predict the future.\n        @days <int or None>: how many days to predict from the last records date\n        @min_infected <int>: if Infected < min_infected, the records will not be used\n        @show_figure <bool>: if True, show line plot of cases over time\n        \"\"\"\n        if not isinstance(days, int):\n            raise TypeError(\"days must be integer!\")\n        # Create parameter dictionary\n        predict_param_dict = {\n            phase: self.estimator_dict[phase].info()[2]\n            for (phase, _) in self.phase_dict.items()\n        }\n        predict_param_dict.update(self.future_param_dict)\n        # Define phases\n        model, info_dict, _ = self.estimator_dict[\"1st\"].info()\n        predicter = Predicter(**info_dict)\n        phase_dict = self.phase_dict.copy()\n        phase_dict.update(self.future_phase_dict)\n        # Simulation with Predicter\n        for (phase, date_dict) in phase_dict.items():\n            start = pd.to_datetime(date_dict[\"start_date\"])\n            end = pd.to_datetime(date_dict[\"end_date\"])\n            if end is None:\n                day_n = days\n            elif start == end:\n                day_n = 0\n            else:\n                day_n = int((end - start).total_seconds() / 60 / 60 / 24) + 1\n            param_dict = predict_param_dict[phase].copy()\n            vline = False if phase in self.phases_without_vline else True\n            predicter.add(model, end_day_n=day_n, count_from_last=True, vline=vline, **param_dict)\n        # Restore\n        df = predicter.restore_df(min_infected=min_infected)\n        try:\n            df[\"Confirmed\"] = df[\"Infected\"] + df[\"Recovered\"] + df[\"Fatal\"]\n        except KeyError:\n            pass\n        # Graph: If max(other variables) < min(Susceptible), not show Susceptible\n        if show_figure:\n            without_s = df.drop(\"Susceptible\", axis=1).sum(axis=1).max()\n            drop_cols = [\"Susceptible\"] if without_s < df[\"Susceptible\"].min() else None\n            predicter.restore_graph(drop_cols=drop_cols, min_infected=min_infected, y_integer=True)\n        return df","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"980b4b4e-b055-4c2a-b06f-823e90a42421","_cell_guid":"6347198d-b95f-495b-9d50-f55e917c77e9","trusted":true},"cell_type":"markdown","source":"## Raw data: the number of cases"},{"metadata":{"_uuid":"bc109822-1f6c-48ac-baaa-13698ef4155e","_cell_guid":"b0ede625-76d1-4c24-b85d-6b949c4c98f1","trusted":true,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"raw = pd.read_csv(\"/kaggle/input/novel-corona-virus-2019-dataset/covid_19_data.csv\")\nraw.tail()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"73225ddf-46f9-4d8b-bee9-4a5652ecc9fd","_cell_guid":"cde46880-86b1-4177-9c1a-dc3b34e51935","trusted":true,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"raw.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"958fa8de-84d8-4b89-aa22-4a14838ee235","_cell_guid":"fb0a8feb-e0f1-49a3-bc6e-902305e0e4b3","trusted":true,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"raw.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ef52159f-5ad3-4258-ab84-d37a194bbb27","_cell_guid":"4f00def7-9acd-49a8-ae1f-a005873d49ae","trusted":true,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"pd.DataFrame(raw.isnull().sum()).T","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f95e36db-f400-4b53-86ec-e15e19d4559e","_cell_guid":"550da578-5c47-45d5-bdf2-80187a491fd0","trusted":true,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"\", \".join(raw[\"Country/Region\"].unique().tolist())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"962463b8-db0f-4f2d-b7cd-ea3ccbce8fb7","_cell_guid":"6b5046c3-897d-438e-b483-ae940da47e72","trusted":true,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"pprint(raw.loc[raw[\"Country/Region\"] == \"Others\", \"Province/State\"].unique().tolist(), compact=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7b860d14-e603-420a-a655-de2cae2a082e","_cell_guid":"bafa861d-2610-44dd-bd21-2996ccea0d58","trusted":true},"cell_type":"markdown","source":"## Data Cleening: the number of cases\nNote: \"Infected\" = \"Confirmed\" - \"Deaths\" - \"Recovered\""},{"metadata":{"_uuid":"41f0be0f-f8dc-42f7-8773-65dc60f893e5","_cell_guid":"605752b1-4a5c-421c-82a7-d8ae766d893f","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"data_cols = [\"Infected\", \"Deaths\", \"Recovered\"]\ndata_cols_all = [\"Confirmed\", \"Infected\", \"Deaths\", \"Recovered\"]\nrate_cols = [\"Fatal per Confirmed\", \"Recovered per Confirmed\", \"Fatal per (Fatal or Recovered)\"]\nvariable_dict = {\"Susceptible\": \"S\", \"Infected\": \"I\", \"Recovered\": \"R\", \"Deaths\": \"D\"}","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2988a829-895b-401a-82ae-97d8026b271e","_cell_guid":"d6846623-7a01-4c27-8efc-61ce58d2553c","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df = raw.rename({\"ObservationDate\": \"Date\", \"Province/State\": \"Province\"}, axis=1)\ndf[\"Date\"] = pd.to_datetime(df[\"Date\"])\ndf[\"Country\"] = df[\"Country/Region\"].replace(\n    {\n        \"Mainland China\": \"China\",\n        \"Hong Kong SAR\": \"Hong Kong\",\n        \"Taipei and environs\": \"Taiwan\",\n        \"Iran (Islamic Republic of)\": \"Iran\",\n        \"Republic of Korea\": \"South Korea\",\n        \"Republic of Ireland\": \"Ireland\",\n        \"Macao SAR\": \"Macau\",\n        \"Russian Federation\": \"Russia\",\n        \"Republic of Moldova\": \"Moldova\",\n        \"Taiwan*\": \"Taiwan\",\n        \"Cruise Ship\": \"Others\",\n        \"United Kingdom\": \"UK\",\n        \"Viet Nam\": \"Vietnam\",\n        \"Czechia\": \"Czech Republic\",\n        \"St. Martin\": \"Saint Martin\",\n        \"Cote d'Ivoire\": \"Ivory Coast\",\n        \"('St. Martin',)\": \"Saint Martin\",\n        \"Congo (Kinshasa)\": \"Congo\",\n        \"Congo (Brazzaville)\": \"Congo\",\n        \"The, Bahamas\": \"Bahamas\",\n    }\n)\ndf[\"Province\"] = df[\"Province\"].fillna(\"-\").replace(\n    {\n        \"Cruise Ship\": \"Diamond Princess\",\n        \"Diamond Princess cruise ship\": \"Diamond Princess\"\n    }\n)\ndf.loc[df[\"Country\"] == \"Diamond Princess\", [\"Country\", \"Province\"]] = [\"Others\", \"Diamond Princess\"]\ndf[\"Infected\"] = df[\"Confirmed\"] - df[\"Deaths\"] - df[\"Recovered\"]\ndf[data_cols_all] = df[data_cols_all].astype(np.int64)\nncov_df_ungrouped = df.loc[:, [\"Date\", \"Country\", \"Province\", *data_cols_all]]\nncov_df_ungrouped.tail()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"10e610b6-923a-40b3-955f-e9e5b5bc33a6","_cell_guid":"74d4ce99-e727-4183-b946-88b89a535356","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"ncov_df_ungrouped.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"de5f92d7-6dbb-4fe6-bdec-1f9a724b77a6","_cell_guid":"efb366ae-124b-467d-90ed-60a8280391c5","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"ncov_df_ungrouped.describe(include=\"all\").fillna(\"-\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"faa20bbf-b953-4cb7-af45-beab12cf7c0a","_cell_guid":"58b41156-5c89-47a7-a0dc-ceedc742a9c7","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"pd.DataFrame(ncov_df_ungrouped.isnull().sum()).T","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"513c542b-99ec-4a83-b073-7c70cda0340b","_cell_guid":"e36b6608-3109-4811-ae88-c22d1b47d1a9","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"\", \".join(ncov_df_ungrouped[\"Country\"].unique().tolist())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f8a797b1-fee9-4fd1-8859-9a74cd992bbe","_cell_guid":"8e4e6d71-d916-4a64-95a9-69d4fe2eb02c","trusted":true},"cell_type":"markdown","source":"## Visualize total data"},{"metadata":{"_uuid":"44072383-352b-4501-b174-f0ebfef3f95a","_cell_guid":"73d5e052-ebff-4f90-88fb-709637cfb2c4","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"total_df = ncov_df_ungrouped.groupby(\"Date\").sum()\ntotal_df[rate_cols[0]] = total_df[\"Deaths\"] / total_df[data_cols].sum(axis=1)\ntotal_df[rate_cols[1]] = total_df[\"Recovered\"] / total_df[data_cols].sum(axis=1)\ntotal_df[rate_cols[2]] = total_df[\"Deaths\"] / (total_df[\"Deaths\"] + total_df[\"Recovered\"])\ntotal_df.tail()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9c5d84b3-2cd6-42c3-a740-cd84d2c0a52c","_cell_guid":"9fd5240a-1d2b-48ba-8e3d-5e6723af0e8f","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"f\"{(total_df.index.max() - total_df.index.min()).days} days have passed from the date of the first record.\"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"12f82256-a349-49b8-9e17-5ac5bd74f5ae","_cell_guid":"2256ddcb-f67f-4c0a-ba93-6768433fc144","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"line_plot(total_df[data_cols], \"Total number of cases over time\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cace33e4-be48-438a-93ca-d2635ea23189","_cell_guid":"acd0eff2-af43-4859-bb62-af9c7ca10809","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"line_plot(total_df[rate_cols], \"Global rate over time\", ylabel=\"\", math_scale=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"79935285-74b5-49f7-a46d-bc191a9d38f2","_cell_guid":"a2318e23-9cf4-495b-8bbf-bcf893898e77","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"total_df[rate_cols].plot.kde()\nplt.title(\"Kernel density estimation of the rates\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"37364cc6-0190-49f7-a554-92b67db8d100","_cell_guid":"bd16187a-99ec-4ec8-8aaf-016fd2b53fd8","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"total_df[rate_cols].describe().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data cleaning: Linelist (COVID19_open_line_list.csv)"},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"linelist_open_raw = pd.read_csv(\"/kaggle/input/novel-corona-virus-2019-dataset/COVID19_open_line_list.csv\")\nlinelist_open_raw.info()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"df = linelist_open_raw.loc[:, ~linelist_open_raw.columns.str.startswith(\"Unnamed:\")]\ndf = df.dropna(axis=0, how=\"all\")\ndf = df.drop(\n    [\n        # Unnecessary in this notebook\n        \"ID\", \"wuhan(0)_not_wuhan(1)\", \"admin3\", \"admin2\", \"admin1\", \"country_new\", \"admin_id\",\n        \"data_moderator_initials\", \"source\", \"location\", \"lives_in_Wuhan\", \"notes_for_discussion\",\n        \"sequence_available\", \"reported_market_exposure\",\n        # Maybe useful, but un-used\n        \"city\", \"latitude\", \"longitude\", \"geo_resolution\", \"additional_information\",\n        \"travel_history_dates\", \"travel_history_location\", \n    ],\n    axis=1\n)\n# Personal\nage = linelist_open_raw[\"age\"].str.split(\"-\", expand=True)\nage[0] = pd.to_numeric(age[0], errors=\"coerce\")\nage[1] = pd.to_numeric(age[1], errors=\"coerce\")\ndf[\"Age\"] = age.mean(axis=1)\ndf[\"Age\"] = df[\"Age\"].fillna(df[\"Age\"].median()).astype(np.int64)\ndf[\"Sex\"] = df[\"sex\"].fillna(\"-\").str.replace(\"4000\", \"-\").str.capitalize()\n# Place\ndf[\"Country\"] = df[\"country\"].fillna(\"-\")\ndf[\"Province\"] = df[\"province\"].fillna(\"-\")\n# Onset Date\nseries = df[\"date_onset_symptoms\"].str.replace(\"end of December 2019\", \"31.12.2019\").replace(\"-25.02.2020\", \"25.02.2020\")\nseries = series.replace(\"20.02.220\", \"20.02.2020\").replace(\"none\", np.NaN).replace(\"10.01.2020 - 22.01.2020\", np.NaN)\ndf[\"Onset_date\"] = pd.to_datetime(series)\n# Hospitalized date\nseries = df[\"date_admission_hospital\"].replace(\"18.01.2020 - 23.01.2020\", np.NaN)\ndf[\"Hospitalized_date\"] = pd.to_datetime(series)\n# Confirmed date\nseries = df[\"date_confirmation\"].replace(\"25.02.2020-26.02.2020\", np.NaN)\ndf[\"Confirmed_date\"] = pd.to_datetime(series)\n# Symptoms/events\ndf[\"Symptoms\"] = df[\"symptoms\"].fillna(\"-\").str.lower()\n# Underlying disease\ndf[\"Underlying_disease\"] = df[[\"chronic_disease_binary\", \"chronic_disease\"]].apply(\n    lambda x: \"No\" if x[0] == 0 else x[1] if x[1] is not np.NaN else \"-\",\n    axis=1\n).str.strip(\";\").str.replace(\"; \", \",\").str.replace(\", \", \",\")\n# Outcome\ndf[\"Outcome\"] = df[\"outcome\"].replace(\n    {\n        \"discharge\": \"discharged\", \"Discharged\": \"discharged\", \"death\": \"died\",\n        \"critical condition, intubated as of 14.02.2020\": \"severe\",\n        \"treated in an intensive care unit (14.02.2020)\": \"severe\", \"05.02.2020\": \"-\",\n        \"Symptoms only improved with cough. Currently hospitalized for follow-up.\": \"stable\"\n    }\n).fillna(\"-\")\nseries = df[\"date_death_or_discharge\"].replace(\"discharge\", np.NaN)\ndf[\"Closed_date\"] = pd.to_datetime(series)\n# Show\nuse_cols = [\n    \"Age\", \"Sex\", \"Country\", \"Province\", \"Onset_date\", \"Hospitalized_date\", \"Confirmed_date\", \n    \"Symptoms\", \"Underlying_disease\", \"Outcome\", \"Closed_date\"\n]\nopen_linelist_df = df.loc[:, use_cols]\nopen_linelist_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data cleaning: Linelist (COVID19_line_list_data.csv)\nLinelist in clinical trials is a list of many case reports."},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"linelist_raw = pd.read_csv(\"/kaggle/input/novel-corona-virus-2019-dataset/COVID19_line_list_data.csv\")\nlinelist_raw.info()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"linelist_raw.head()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"df = linelist_raw.loc[:, ~linelist_raw.columns.str.startswith(\"Unnamed:\")]\ndf = df.drop([\"id\", \"case_in_country\", \"summary\", \"source\", \"link\"], axis=1)\n# Date\ncase_date_dict = {\n    \"reporting date\": \"Confirmed_date\",\n    \"exposure_start\": \"Exposed_date\",\n    \"exposure_end\": \"Quarantined_date\",\n    \"hosp_visit_date\": \"Hospitalized_date\",\n    \"symptom_onset\": \"Onset_date\",\n    \"death\": \"Deaths_date\",\n    \"recovered\": \"Recovered_date\"    \n}\ndf[\"death\"] = df[\"death\"].replace({\"0\": \"\", \"1\": \"\"})\ndf[\"recovered\"] = df[\"recovered\"].replace({\"0\": \"\", \"1\": \"\", \"12/30/1899\": \"12/30/2019\"})\nfor (col, _) in case_date_dict.items():\n    df[col] = pd.to_datetime(df[col])\ndf = df.rename(case_date_dict, axis=1)\n# Location\ndf[\"Country\"] = df[\"country\"].fillna(\"-\")\ndf[\"Province\"] = df[\"location\"].fillna(\"-\")\ndf[\"Province\"] = df[[\"Country\", \"Province\"]].apply(lambda x: \"-\" if x[0] == x[1] else x[1], axis=1)\n# Personal\ndf[\"Gender\"] = df[\"gender\"].fillna(\"-\").str.capitalize()\ndf[\"Age\"] = df[\"age\"].fillna(df[\"age\"].median()).astype(np.int64) ## Fill in NA with median\ndf[\"From_Wuhan\"] = df[\"from Wuhan\"]\ndf[\"To_Wuhan\"] = df[\"visiting Wuhan\"]\n# Medical\ndf[\"Events\"] = df[\"symptom\"].fillna(\"-\")\n# Order of columns\nlinelist_df = df.loc[\n    :,\n    [\n        \"Country\", \"Province\",\n        \"Exposed_date\", \"Onset_date\", \"Hospitalized_date\", \"Confirmed_date\", \"Quarantined_date\", \"Deaths_date\", \"Recovered_date\",\n        \"Events\",\n        \"Gender\", \"Age\", \"From_Wuhan\", \"To_Wuhan\"\n    ]\n]\nlinelist_df.tail()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"linelist_df.info()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"linelist_df.describe(include=\"all\").fillna(\"-\")","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"period_df = select_area(linelist_df, group=None)\nperiod_df = period_df.loc[:, [\"Exposed_date\", \"Onset_date\", \"Confirmed_date\"]]\nperiod_df[\"Latent [min]\"] = (period_df[\"Onset_date\"] - period_df[\"Exposed_date\"]).dt.total_seconds() / 60\nperiod_df[\"Waiting [min]\"] = (period_df[\"Confirmed_date\"] - period_df[\"Onset_date\"]).dt.total_seconds() / 60\nperiod_df[\"Latent [day]\"] = period_df[\"Latent [min]\"] / 60 / 24\nperiod_df[\"Waiting [day]\"] = period_df[\"Waiting [min]\"] / 60 / 24\nperiod_df[\"Latent + Waiting [day]\"] = period_df[\"Latent [day]\"] + period_df[\"Waiting [day]\"]\nperiod_df.dropna(axis=0).tail()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"cols = [\"Latent [day]\", \"Waiting [day]\", \"Latent + Waiting [day]\"]\nperiod_df[cols].plot.kde()\nplt.title(\"Kernel density estimation of latent period and waiting time for confirmation [day]\")\nplt.show()\nperiod_df[cols].describe().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Measures in each country"},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"action_raw = dd.read_csv(\n    \"/kaggle/input/covid19-containment-and-mitigation-measures/COVID 19 Containment measures data.csv\"\n).compute()\naction_raw.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"df  = action_raw.copy()\ndf = df.rename(\n    {\n        \"Description of measure implemented\": \"Details\",\n        \"Implementing State/Province\": \"Province\",\n    },\n    axis=1\n)\n# Country/Province\ndf[\"Country\"] = df[\"Country\"].replace({\"United Kingdom\": \"UK\"})\ndf[\"Country\"] = df[\"Country\"].str.replace(\"US: \", \"US/\").str.replace(\"US:\", \"US/\")\ndf = df.loc[~df[\"Country\"].isnull(), :]\ndf[\"Province\"] = df[\"Province\"].fillna(\"-\")\ndf[[\"Country\", \"Province\", \"-\"]] = (df[\"Country\"] + \"/\" + df[\"Province\"]).str.split(\"/\", expand=True)\n# Date\ndf[\"Start_date\"] = pd.to_datetime(df[\"Date Start\"])\ndf[\"End_date\"] = pd.to_datetime(df[\"Date end intended\"])\ndf = df.loc[~df[\"Start_date\"].isnull(), :]\n# Detail\ndf = df.loc[~df[\"Details\"].isnull(), :]\ndf[\"Keywords\"] = df[\"Keywords\"].fillna(\"-\")\ndf[\"Exceptions\"] = df[\"Exceptions\"].fillna(\"-\")\n# _df = df[\"Keywords\"].str.split(\", \", expand=True)\n# df = pd.concat([df, _df], axis=1)\n# Save\ndf = df.loc[:, [\"Country\", \"Province\", \"Start_date\", \"End_date\", \"Keywords\", \"Details\", \"Exceptions\"]]\ndf = df.sort_values([\"Start_date\", \"End_date\", \"Country\", \"Province\"])\naction_df = df.copy()\naction_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"words = pd.Series(\", \".join(action_df[\"Keywords\"].tolist()).split(\", \")).unique().tolist()\nwords","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"vectorizer = TfidfVectorizer(use_idf=True)\nvecs = vectorizer.fit_transform(words)\nclusters = KMeans(n_clusters=20, random_state=0).fit_predict(vecs)\ndf = pd.DataFrame(\n    {\n        \"Group\": clusters,\n        \"Word\": words\n    }\n)\ndf = df.sort_values(\"Group\")\ndf = pd.DataFrame(df.groupby(\"Group\")[\"Word\"].apply(lambda x: \", \".join(x)))\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Measures in Italy"},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"ita_action_raw = pd.read_excel(\n    \"/kaggle/input/covid19-prevention-in-italy/Dataset_Italy_COVID_19.xlsx\",\n    sheet_name=\"Foglio1\"\n)\nita_action_raw.head()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"df = ita_action_raw.copy()\ndf = df.drop([\"Country\", \"Village\", \"link\"], axis=1)\ndf.columns = [col.capitalize().replace(\" \", \"_\") for col in df.columns]\ndf[\"Start_date\"] = pd.to_datetime(df[\"Start_date\"])\ndf[\"End_date\"] = pd.to_datetime(df[\"End_date\"])\ndf[\"Region\"] = df[\"Region\"].fillna(\"-\")\ndf[\"Number_of_people\"] = df[\"Number_of_people\"].fillna(-1)\nita_action_df = df.copy()\nita_action_df.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## The number of cases in Japan"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"jpn_ncov_raw = pd.read_csv(\"/kaggle/input/covid19-dataset-in-japan/covid_jpn_total.csv\")\njpn_ncov_raw.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# https://www.kaggle.com/lisphilar/eda-of-japan-dataset\n# and remove returunee/airport cases\ndf = jpn_ncov_raw.copy()\ndf.dropna(how=\"any\", inplace=True)\ndf[\"Date\"] = pd.to_datetime(df[\"Date\"])\ndf = df.groupby(\"Location\").apply(\n    lambda x: x.set_index(\"Date\").resample(\"D\").interpolate(method=\"linear\")\n)\ndf = df.drop(\"Location\", axis=1).reset_index()\ndf = df.loc[df[\"Location\"] == \"Domestic\", :].drop(\"Location\", axis=1)\ndf = df.set_index(\"Date\").resample(\"D\").last().fillna(\"ffill\")\nsel = df.columns.isin([\"Location\", \"Date\"])\ndf.loc[:, ~sel] = df.loc[:, ~sel].astype(np.int64)\njpn_ncov_df = df.copy()\njpn_ncov_df.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## The number of cases in Japan at prefecture level"},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"jpn_pref_raw = pd.read_csv(\"/kaggle/input/covid19-dataset-in-japan/covid_jpn_prefecture.csv\")\njpn_pref_raw.tail()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df = jpn_pref_raw.copy()\ndf.dropna(how=\"all\", inplace=True)\ndf[\"Date\"] = pd.to_datetime(df[\"Date\"])\nsel = df.columns.isin([\"Date\", \"Prefecture\"])\ndf = df.groupby(\"Prefecture\").apply(\n    lambda x: x.set_index(\"Date\").resample(\"D\").interpolate(\"linear\")\n)\ndf = df.drop(\"Prefecture\", axis=1).reset_index()\ndf = df.sort_values(\"Date\").reset_index(drop=True)\nsel = df.columns.isin([\"Date\", \"Prefecture\"])\ndf.loc[:, ~sel] = df.loc[:, ~sel].interpolate(\"linear\").astype(np.int64)\njpn_pref_df = df.copy()\njpn_pref_df.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Metadata of prefectures in Japan"},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"jpn_meta_raw = pd.read_csv(\"/kaggle/input/covid19-dataset-in-japan/covid_jpn_metadata.csv\")\njpn_meta_raw.tail()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df = jpn_meta_raw.copy()\ndf[\"Title\"] = df[\"Category\"].str.cat(df[\"Item\"], sep=\"_\")\ndf = df.pivot_table(\n    index=\"Prefecture\", columns=\"Title\", values=\"Value\", aggfunc=\"last\"\n)\n# Integer\ncols = df.columns.str.startswith(\"Population\")\ncols += df.columns.str.startswith(\"Area\")\ncols += df.columns.str.startswith(\"Hospital_bed\")\ncols += df.columns.str.startswith(\"Clinic_bed\")\ndf.loc[:, cols] = df.loc[:, cols].astype(np.int64)\ndf[\"Admin_Num\"] = df[\"Admin_Num\"].astype(np.int64)\n# Numeric\ncols = df.columns.str.startswith(\"Location\")\ndf.loc[:, cols] = df.loc[:, cols].astype(np.float64)\n# Sorting\ndf = df.loc[jpn_meta_raw[\"Prefecture\"].unique(), :]\njpn_meta_df = df.copy()\njpn_meta_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Grouping by growth factor<a id=\"2\"></a>\nThe number of confirmed cases is increasing in many countries, but there are two of countries. In a first-type country, growth factor is larger than 1 and the number of cases is rapidly increasing. In a second-type country, growth factor is less than 1."},{"metadata":{},"cell_type":"markdown","source":"## Calculate growth factor\nWhere $C$ is the number of confirmed cases,  \n$$\\mathrm{Growth\\ Factor} = \\cfrac{\\Delta \\mathrm{C}_{n}}{\\Delta \\mathrm{C}_{n-1}}$$"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df = ncov_df_ungrouped.pivot_table(\n    index=\"Date\", columns=\"Country\", values=\"Confirmed\", aggfunc=\"sum\"\n).fillna(method=\"ffill\").fillna(0)\n# Growth factor: (delta Number_n) / (delta Number_n)\ndf = df.diff() / df.diff().shift(freq=\"D\")\ndf = df.replace(np.inf, np.nan).fillna(1.0)\n# Rolling mean (window: 7 days)\ndf = df.rolling(7).mean().dropna().loc[:ncov_df_ungrouped[\"Date\"].max(), :]\n# round: 0.01\ngrowth_value_df = df.round(2)\ngrowth_value_df.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Grouping countires based on growth factor\n* Outbreaking: growth factor $>$ 1 for the last 7 days\n* Stopping: growth factor $<$ 1 for the last 7 days\n* At a crossroad: the others"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df = growth_value_df.copy()\ndf = df.iloc[-7:, :].T\nday_cols = df.columns.strftime(\"%d%b%Y\")\ndf.columns = day_cols\nlast_date = day_cols[-1]\n# Grouping\nmore_col, less_col = \"GF > 1 [straight days]\", \"GF < 1 [straight days]\"\ndf[more_col] = (growth_value_df > 1).iloc[::-1].cumprod().sum(axis=0)\ndf[less_col] = (growth_value_df < 1).iloc[::-1].cumprod().sum(axis=0)\ndf[\"Group\"] = df[[more_col, less_col]].apply(\n    lambda x: \"Outbreaking\" if x[0] >= 7 else \"Stopping\" if x[1] >= 7 else \"Crossroad\",\n    axis=1\n)\n# Sorting\ndf = df.loc[:, [\"Group\", more_col, less_col, *day_cols]]\ndf = df.sort_values([\"Group\", more_col, less_col], ascending=False)\ngrowth_df = df.copy()\ngrowth_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.merge(ncov_df_ungrouped, growth_df[\"Group\"].reset_index(), on=\"Country\")\nncov_df = df.loc[:, [\"Date\", \"Group\", *ncov_df_ungrouped.columns[1:]]]\nncov_df.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Group 1: Outbreaking, growth factor $>$ 1 for the last 7 days"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = growth_df.loc[growth_df[\"Group\"] == \"Outbreaking\", :]\n\", \".join(df.index.tolist()) + \".\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"growth_df.loc[growth_df[\"Group\"] == \"Outbreaking\", :].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df = ncov_df.loc[ncov_df[\"Group\"] == \"Outbreaking\", [\"Date\", *data_cols]].groupby(\"Date\").sum()\nline_plot(df, \"Group 1 (Outbreaking): Cases over time\", y_integer=True)\ndf.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Group 2: Stopping, growth factor $<$ 1 for the last 7 days"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = growth_df.loc[growth_df[\"Group\"] == \"Stopping\", :]\n\", \".join(df.index.tolist()) + \".\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"growth_df.loc[growth_df[\"Group\"] == \"Stopping\", :].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df = ncov_df.loc[ncov_df[\"Group\"] == \"Stopping\", [\"Date\", *data_cols]].groupby(\"Date\").sum()\nline_plot(df, \"Group 2 (Stopping): Cases over time\", y_integer=True)\ndf.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Group 3: At a crossroad, the others"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = growth_df.loc[growth_df[\"Group\"] == \"Crossroad\", :]\n\", \".join(df.index.tolist()) + \".\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"growth_df.loc[growth_df[\"Group\"] == \"Crossroad\", :].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df = ncov_df.loc[ncov_df[\"Group\"] == \"Crossroad\", [\"Date\", *data_cols]].groupby(\"Date\").sum()\nline_plot(df, \"Group 3 (At a crossroad): Cases over time\", y_integer=True)\ndf.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# SIR to SIR-F<a id=\"4\"></a>\nIn this section, we will create a mathematical model derived from SIR model."},{"metadata":{"_uuid":"df2ad5db-4dbb-4533-ba9e-d335befe57eb","_cell_guid":"cfcd204a-5677-479e-9362-94c15761a4ac","trusted":true},"cell_type":"markdown","source":"## SIR model\nTo understand the trend of infection, we will use mathematical epidemic model. Let's start discussion using the simplest model named SIR."},{"metadata":{"_uuid":"12135786-c9e9-49f9-a911-0bc18ee5f596","_cell_guid":"0f8c4e04-c768-4933-b547-92588965dbea","trusted":true},"cell_type":"markdown","source":"### What is SIR model?\nSIR model is a simple mathematical model to understand outbreak of infectious diseases.  \n[The SIR epidemic model - Learning Scientific Programming with Python](https://scipython.com/book/chapter-8-scipy/additional-examples/the-sir-epidemic-model/)\n\n * S: Susceptible (=All - Confirmed)\n * I: Infected (=Confirmed - Recovered - Deaths)\n * R: Recovered or fatal (=Recovered + Deaths)\n \nNote: THIS IS NOT THE GENERAL MODEL!  \nThough R in SIR model is \"Recovered and have immunity\", I defined \"R as Recovered or fatal\". This is because mortality rate cannot be ignored in the real COVID-19 data.\n\nModel:  \n\\begin{align*}\n\\mathrm{S} \\overset{\\beta I}{\\longrightarrow} \\mathrm{I} \\overset{\\gamma}{\\longrightarrow} \\mathrm{R}  \\\\\n\\end{align*}\n\n$\\beta$: Effective contact rate [1/min]  \n$\\gamma$: Recovery(+Mortality) rate [1/min]  \n\nOrdinary Differential Equation (ODE):  \n\\begin{align*}\n& \\frac{\\mathrm{d}S}{\\mathrm{d}T}= - N^{-1}\\beta S I  \\\\\n& \\frac{\\mathrm{d}I}{\\mathrm{d}T}= N^{-1}\\beta S I - \\gamma I  \\\\\n& \\frac{\\mathrm{d}R}{\\mathrm{d}T}= \\gamma I  \\\\\n\\end{align*}\n\nWhere $N=S+I+R$ is the total population, $T$ is the elapsed time from the start date."},{"metadata":{"_uuid":"769f133b-0a3a-4779-a15b-f199a2a3a411","_cell_guid":"58bc8d44-4df3-49fb-85c0-d01a804accc1","trusted":true},"cell_type":"markdown","source":"### Non-dimensional SIR model\nTo simplify the model, we will remove the units of the variables from ODE.\n\nSet $(S, I, R) = N \\times (x, y, z)$ and $(T, \\beta, \\gamma) = (\\tau t, \\tau^{-1} \\rho, \\tau^{-1} \\sigma)$.  \n\nThis results in the ODE  \n\\begin{align*}\n& \\frac{\\mathrm{d}x}{\\mathrm{d}t}= - \\rho x y  \\\\\n& \\frac{\\mathrm{d}y}{\\mathrm{d}t}= \\rho x y - \\sigma y  \\\\\n& \\frac{\\mathrm{d}z}{\\mathrm{d}t}= \\sigma y  \\\\\n\\end{align*}\n\nWhere $N$ is the total population and $\\tau$ is a coefficient ([min], is an integer to simplify).  \n\nThe range of variables and parameters:  \n\\begin{align*}\n& 0 \\leq (x, y, z, \\rho, \\sigma) \\leq 1  \\\\\n\\end{align*}\n\\begin{align*}\n& 1\\leq \\tau \\leq 1440  \\\\\n\\end{align*}\n\nBasic reproduction number, Non-dimentional parameter, is defined as  \n\\begin{align*}\nR_0 = \\rho \\sigma^{-1} = \\beta \\gamma^{-1}\n\\end{align*}\n\nEstimated Mean Values of $R_0$:  \n$R_0$ (\"R naught\") means \"the average number of secondary infections caused by an infected host\" ([Infection Modeling  Part 1](https://towardsdatascience.com/infection-modeling-part-1-87e74645568a)).  \n(Secondary data: [Van den Driessche, P., & Watmough, J. (2002).](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6002118))  \n2.06: Zika in South America, 2015-2016  \n1.51: Ebola in Guinea, 2014  \n1.33: H1N1 influenza in South Africa, 2009  \n3.5 : SARS in 2002-2003  \n1.68: H2N2 influenza in US, 1957  \n3.8 : Fall wave of 1918 Spanish influenza in Genova  \n1.5 : Spring wave of 1918 Spanish influenza in Genova  \n\nWhen $x=\\frac{1}{R_0}$, $\\frac{\\mathrm{d}y}{\\mathrm{d}t}=0$.\n<!--This means that the max value of confirmed ($=y+z$) is $1-\\frac{1}{R_0}$.-->"},{"metadata":{"_uuid":"e64fc4d7-785a-46e5-95e4-c0d98ab7406a","_cell_guid":"ed7f7e66-b59e-48ec-a72b-a709c3ac9ba8","trusted":true},"cell_type":"markdown","source":"### Example of non-dimensional SIR model\nFor example, set $R_0 = 2.5, \\rho=0.2$ and initial values $(x_{(0)}, y_{(0)}, z_{(0)}) = (0.999, 0.001, 0)$. SIR class was defined in \"Preparation\" section."},{"metadata":{"_uuid":"dc79d91a-c375-425a-abdf-f076b9a9e85f","_cell_guid":"9b9b266d-cbbf-40e7-a3a4-6dacc93a4d15","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"eg_r0, eg_rho = (2.5, 0.2)\neg_sigma = eg_rho / eg_r0\neg_initials = (0.999, 0.001, 0)\ndisplay(Markdown(rf\"$\\rho = {eg_rho},\\ \\sigma = {eg_sigma}$.\"))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"121b3dd1-c224-4326-bede-80b33cebd9d1","_cell_guid":"ee3ee9aa-4f12-4da7-b020-c2b957dfeee9","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"%%time\neg_df = simulation(SIR, eg_initials, step_n=180, rho=eg_rho, sigma=eg_sigma)\neg_df.tail()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f122114e-f47d-4333-9ffd-6a4a688583fe","_cell_guid":"b5412f17-29a7-43a2-ac5b-e013db3047cf","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"line_plot(\n    eg_df.set_index(\"t\"),\n    title=r\"SIR: $R_0={0}\\ (\\rho={1}, \\sigma={2})$\".format(eg_r0, eg_rho, eg_sigma),\n    ylabel=\"\",\n    h=1\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is an inflection point of y (the number of currentry infected cases per total population). At this point, value of x (the number of susceptible cases per total population) is nearly equal to $\\frac{1}{R_0}$."},{"metadata":{"trusted":true},"cell_type":"code","source":"x_max = eg_df.loc[eg_df[\"y\"].idxmax(), \"x\"]\n(x_max, 1/eg_r0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dimensionalization\nHere, we will dimensionalize the data, assuming that start date is the first date of JHU dataset, $\\tau=1440$ [min] and total population $N=1,000,000$."},{"metadata":{"trusted":true},"cell_type":"code","source":"eg_tau = 1440\neg_start_date = ncov_df[\"Date\"].min()\neg_total_population = 1_000_000\nprint(f\"The start date is {eg_start_date.strftime('%d%b%Y')}.\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"eg_ori_df = pd.DataFrame(\n    {\n        \"Date\": (eg_df[\"t\"] * eg_tau).apply(lambda x: timedelta(minutes=x)) + eg_start_date,\n        \"Group\": \"Stopping\",\n        \"Country\": \"Example\",\n        \"Province\": \"-\",\n        \"Susceptible\": 0,\n        \"Confirmed\": 0,\n        \"Infected\": (eg_df[\"y\"] * eg_total_population).astype(np.int64)\n    }\n)\neg_ori_df[\"Recovered + Deaths\"] = (eg_df[\"z\"] * eg_total_population).astype(np.int64)\neg_ori_df [\"Confirmed\"] = eg_ori_df[[\"Infected\", \"Recovered + Deaths\"]].sum(axis=1)\neg_ori_df[\"Susceptible\"] = eg_total_population - eg_ori_df[\"Confirmed\"]\neg_ori_df.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"line_plot(\n    eg_ori_df.set_index(\"Date\")[[\"Susceptible\", \"Infected\", \"Recovered + Deaths\"]],\n    \"Example data of SIR model\",\n    h=eg_total_population,\n    y_integer=True\n)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"abc5f4a0-5674-4678-938b-79db83e4f4f5","_cell_guid":"6ad03ba6-eaba-41ea-b816-17962a58bd54","trusted":true},"cell_type":"markdown","source":"## SIR-D model\nBecause we are measuring the number of fatal cases and recovered cases separately, we can use two variables (\"Recovered\" and \"Deaths\") instead of \"Recovered + Deaths\" in the mathematical model."},{"metadata":{"_uuid":"ac79b973-cdd3-4beb-825d-c29f987f6cd1","_cell_guid":"54813702-3d5a-4aeb-89dc-b7b5014fb9fb","trusted":true},"cell_type":"markdown","source":"### What is SIR-D model?\n* S: Susceptible\n* I: Infected\n* R: Recovered\n* D: Deaths\n\nModel:  \n\\begin{align*}\n\\mathrm{S} \\overset{\\beta  I}{\\longrightarrow}\\ & \\mathrm{I} \\overset{\\gamma}{\\longrightarrow} \\mathrm{R}  \\\\\n& \\mathrm{I} \\overset{\\alpha}{\\longrightarrow} \\mathrm{D}  \\\\\n\\end{align*}\n\n$\\alpha$: Mortality rate [1/min]  \n$\\beta$: Effective contact rate [1/min]  \n$\\gamma$: Recovery rate [1/min]  \n\nOrdinary Differential Equation (ODE):\n\\begin{align*}\n& \\frac{\\mathrm{d}S}{\\mathrm{d}T}= - N^{-1}\\beta S I  \\\\\n& \\frac{\\mathrm{d}I}{\\mathrm{d}T}= N^{-1}\\beta S I - (\\gamma + \\alpha) I  \\\\\n& \\frac{\\mathrm{d}R}{\\mathrm{d}T}= \\gamma I  \\\\\n& \\frac{\\mathrm{d}D}{\\mathrm{d}T}= \\alpha I  \\\\\n\\end{align*}\n\nWhere $N=S+I+R+D$ is the total population, $T$ is the elapsed time from the start date."},{"metadata":{"_uuid":"20008d93-6fef-4053-af91-aef177eed421","_cell_guid":"b3cbf5d5-c269-4695-8835-46ed417d9c48","trusted":true},"cell_type":"markdown","source":"### Non-dimensional SIR-D model\nSet $(S, I, R, D) = N \\times (x, y, z, w)$ and $(T, \\alpha, \\beta, \\gamma) = (\\tau t, \\tau^{-1} \\kappa, \\tau^{-1} \\rho, \\tau^{-1} \\sigma)$.  \nThis results in the ODE  \n\\begin{align*}\n& \\frac{\\mathrm{d}x}{\\mathrm{d}t}= - \\rho x y  \\\\\n& \\frac{\\mathrm{d}y}{\\mathrm{d}t}= \\rho x y - (\\sigma + \\kappa) y  \\\\\n& \\frac{\\mathrm{d}z}{\\mathrm{d}t}= \\sigma y  \\\\\n& \\frac{\\mathrm{d}w}{\\mathrm{d}t}= \\kappa y  \\\\\n\\end{align*}\n\nWhere $N$ is the total population and $\\tau$ is a coefficient ([min], is an integer to simplify).  \n\nThe range of variables and parameters:  \n\\begin{align*}\n& 0 \\leq (x, y, z, w, \\kappa, \\rho, \\sigma) \\leq 1  \\\\\n\\end{align*}\n\\begin{align*}\n& 1\\leq \\tau \\leq 1440  \\\\\n\\end{align*}\n\nReproduction number can be defined as  \n\\begin{align*}\nR_0 = \\rho (\\sigma + \\kappa)^{-1} = \\beta (\\gamma + \\alpha)^{-1}\n\\end{align*}"},{"metadata":{},"cell_type":"markdown","source":"### Example of non-dimensional SIR-D model\nFor example, set $R_0 = 2.5, \\kappa=0.005, \\rho=0.2$ and initial values $(x_{(0)}, y_{(0)}, z_{(0)}, w_{(0)}) = (0.999, 0.001, 0, 0)$."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"eg_r0, eg_kappa, eg_rho = (2.5, 0.005, 0.2)\neg_sigma = eg_rho / eg_r0 - eg_kappa\neg_initials = (0.999, 0.001, 0, 0)\ndisplay(Markdown(rf\"$\\kappa = {eg_kappa},\\ \\rho = {eg_rho},\\ \\sigma = {eg_sigma}$.\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\neg_df = simulation(SIRD, eg_initials, step_n=180, kappa=eg_kappa, rho=eg_rho, sigma=eg_sigma)\neg_df.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"line_plot(\n    eg_df.set_index(\"t\"),\n    title=r\"SIR-D: $R_0={0}\\ (\\kappa={1}, \\rho={2}, \\sigma={3})$\".format(eg_r0, eg_kappa, eg_rho, eg_sigma),\n    ylabel=\"\",\n    h=1\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is an inflection point of y (the number of currentry infected cases per total population). At this point, value of x (the number of susceptible cases per total population) is nearly equal to $\\frac{1}{R_0}$."},{"metadata":{"trusted":true},"cell_type":"code","source":"x_max = eg_df.loc[eg_df[\"y\"].idxmax(), \"x\"]\n(x_max, 1/eg_r0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dimensionalization\nHere, we will dimensionalize the data, assuming that start date is the first date of JHU dataset, $\\tau=1440$ [min] and total population $N=1,000,000$."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"eg_tau = 1440\neg_start_date = ncov_df[\"Date\"].min()\neg_total_population = 1_000_000\nprint(f\"The start date is {eg_start_date.strftime('%d%b%Y')}.\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"eg_ori_df = pd.DataFrame(\n    {\n        \"Date\": (eg_df[\"t\"] * eg_tau).apply(lambda x: timedelta(minutes=x)) + eg_start_date,\n        \"Group\": \"Stopping\",\n        \"Country\": \"Example\",\n        \"Province\": \"-\",\n        \"Susceptible\": 0,\n        \"Confirmed\": 0,\n        \"Infected\": (eg_df[\"y\"] * eg_total_population).astype(np.int64)\n    }\n)\neg_ori_df[\"Recovered\"] = (eg_df[\"z\"] * eg_total_population).astype(np.int64)\neg_ori_df[\"Deaths\"] = (eg_df[\"w\"] * eg_total_population).astype(np.int64)\neg_ori_df[\"Confirmed\"] = eg_ori_df[[\"Infected\", \"Recovered\", \"Deaths\"]].sum(axis=1)\neg_ori_df[\"Susceptible\"] = eg_total_population - eg_ori_df[\"Confirmed\"]\neg_ori_df.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"line_plot(\n    eg_ori_df.set_index(\"Date\")[[\"Susceptible\", \"Infected\", \"Recovered\", \"Deaths\"]],\n    \"Example data of SIR-D model\",\n    h=eg_total_population,\n    y_integer=True\n)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b17a61ed-d8da-43ba-b028-1949760dc0ca","_cell_guid":"c19b122a-84fb-4757-834e-bb72002cdfb3","trusted":true},"cell_type":"markdown","source":"## SIR-F model\nIt is reported that some cases died before clinical diagnosis of COVID-19. To consider this issue, \"S + I $\\to$ Fatal + I\" will be added to the model."},{"metadata":{"_uuid":"3f40d0e2-7fb1-4082-8308-e27d37efc943","_cell_guid":"0a2eafd9-5355-4953-af46-025e6554fa59","trusted":true},"cell_type":"markdown","source":"### What is SIR-F model?\n* S: Susceptible\n* S$^\\ast$: Confirmed and un-categorized\n* I: Confirmed and categorized as I\n* R: Recovered\n* F: Fatal with confirmation\n\nMeasurable variables:  \nConfirmed = $I+R+F$  \nRecovered = $R$  \nDeaths = $F$  \n\nModel:  \n\\begin{align*}\n\\mathrm{S} \\overset{\\beta I}{\\longrightarrow} \\mathrm{S}^\\ast \\overset{\\alpha_1}{\\longrightarrow}\\ & \\mathrm{F}    \\\\\n\\mathrm{S}^\\ast \\overset{1 - \\alpha_1}{\\longrightarrow}\\ & \\mathrm{I} \\overset{\\gamma}{\\longrightarrow} \\mathrm{R}    \\\\\n& \\mathrm{I} \\overset{\\alpha_2}{\\longrightarrow} \\mathrm{F}    \\\\\n\\end{align*}\n\n$\\alpha_1$: Mortality rate of S$^\\ast$ cases [-]  \n$\\alpha_2$: Mortality rate of I cases [1/min]  \n$\\beta$: Effective contact rate [1/min]  \n$\\gamma$: Recovery rate [1/min]  \n\nNote: When $\\alpha_1 = 0$, SIR-F model is the same as SIR-D model.\n\nOrdinary Differential Equation (ODE):   \n\\begin{align*}\n& \\frac{\\mathrm{d}S}{\\mathrm{d}T}= - N^{-1}\\beta S I  \\\\\n& \\frac{\\mathrm{d}I}{\\mathrm{d}T}= N^{-1}(1 - \\alpha_1) \\beta S I - (\\gamma + \\alpha_2) I  \\\\\n& \\frac{\\mathrm{d}R}{\\mathrm{d}T}= \\gamma I  \\\\\n& \\frac{\\mathrm{d}F}{\\mathrm{d}T}= N^{-1}\\alpha_1 \\beta S I + \\alpha_2 I  \\\\\n\\end{align*}\n\nWhere $N=S+I+R+F$ is the total population, $T$ is the elapsed time from the start date."},{"metadata":{"_uuid":"1a5a19e0-d71a-409b-902e-707d2afe8249","_cell_guid":"fa88a43d-671a-4109-8d60-8b2cacebed68","trusted":true},"cell_type":"markdown","source":"### Non-dimensional SIR-F model\nSet $(S, I, R, F) = N \\times (x, y, z, w)$ and $(T, \\alpha_1, \\alpha_2, \\beta, \\gamma) = (\\tau t, \\theta, \\tau^{-1} \\kappa, \\tau^{-1} \\rho, \\tau^{-1} \\sigma)$.  \nThis results in the ODE  \n\\begin{align*}\n& \\frac{\\mathrm{d}x}{\\mathrm{d}t}= - \\rho x y  \\\\\n& \\frac{\\mathrm{d}y}{\\mathrm{d}t}= \\rho (1-\\theta) x y - (\\sigma + \\kappa) y  \\\\\n& \\frac{\\mathrm{d}z}{\\mathrm{d}t}= \\sigma y  \\\\\n& \\frac{\\mathrm{d}w}{\\mathrm{d}t}= \\rho \\theta x y + \\kappa y  \\\\\n\\end{align*}\n\nWhere $N$ is the total population and $\\tau$ is a coefficient ([min], is an integer to simplify).  \n\nThe range of variables and parameters:  \n\\begin{align*}\n& 0 \\leq (x, y, z, w, \\theta, \\kappa, \\rho, \\sigma) \\leq 1  \\\\\n\\end{align*}\n\\begin{align*}\n& 1\\leq \\tau \\leq 1440  \\\\\n\\end{align*}\n\nReproduction number can be defined as  \n\\begin{align*}\nR_0 = \\rho (1 - \\theta) (\\sigma + \\kappa)^{-1} = \\beta (1 - \\alpha_1) (\\gamma + \\alpha_2)^{-1}\n\\end{align*}"},{"metadata":{},"cell_type":"markdown","source":"### Example of non-dimensional SIR-F model\nFor example, set $R_0 = 2.5, \\theta=0.002, \\kappa=0.005, \\rho=0.2$ and initial values $(x_{(0)}, y_{(0)}, z_{(0)}, w_{(0)}) = (0.999, 0.001, 0, 0)$."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"eg_r0, eg_theta, eg_kappa, eg_rho = (2.5, 0.002, 0.005, 0.2)\neg_sigma = eg_rho / eg_r0 - eg_kappa\neg_initials = (0.999, 0.001, 0, 0)\ndisplay(Markdown(rf\"$\\theta = {eg_theta},\\ \\kappa = {eg_kappa},\\ \\rho = {eg_rho},\\ \\sigma = {eg_sigma}$.\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\neg_df = simulation(SIRF, eg_initials, step_n=180, theta=eg_theta, kappa=eg_kappa, rho=eg_rho, sigma=eg_sigma)\neg_df.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"line_plot(\n    eg_df.set_index(\"t\"),\n    title=r\"SIR-F: $R_0={0}\\ (\\theta={1}, \\kappa={2}, \\rho={3}, \\sigma={4})$\".format(\n        eg_r0, eg_theta, eg_kappa, eg_rho, eg_sigma\n    ),\n    ylabel=\"\",\n    h=1\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is an inflection point of y (the number of currentry infected cases per total population). At this point, value of x (the number of susceptible cases per total population) is nearly equal to $\\frac{1}{R_0}$."},{"metadata":{"trusted":true},"cell_type":"code","source":"x_max = eg_df.loc[eg_df[\"y\"].idxmax(), \"x\"]\n(x_max, 1/eg_r0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dimensionalization\nHere, we will dimensionalize the data, assuming that start date is the first date of JHU dataset, $\\tau=1440$ [min] and total population $N=1,000,000$."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"eg_tau = 1440\neg_start_date = ncov_df[\"Date\"].min()\neg_total_population = 1_000_000\nprint(f\"The start date is {eg_start_date.strftime('%d%b%Y')}.\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"eg_ori_df = pd.DataFrame(\n    {\n        \"Date\": (eg_df[\"t\"] * eg_tau).apply(lambda x: timedelta(minutes=x)) + eg_start_date,\n        \"Group\": \"Stopping\",\n        \"Country\": \"Example\",\n        \"Province\": \"-\",\n        \"Susceptible\": 0,\n        \"Confirmed\": 0,\n        \"Infected\": (eg_df[\"y\"] * eg_total_population).astype(np.int64)\n    }\n)\neg_ori_df[\"Recovered\"] = (eg_df[\"z\"] * eg_total_population).astype(np.int64)\neg_ori_df[\"Fatal\"] = (eg_df[\"w\"] * eg_total_population).astype(np.int64)\neg_ori_df[\"Confirmed\"] = eg_ori_df[[\"Infected\", \"Recovered\", \"Fatal\"]].sum(axis=1)\neg_ori_df[\"Susceptible\"] = eg_total_population - eg_ori_df[\"Confirmed\"]\neg_ori_df.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"line_plot(\n    eg_ori_df.set_index(\"Date\")[[\"Susceptible\", \"Infected\", \"Recovered\", \"Fatal\"]],\n    \"Example data of SIR-F model\",\n    h=eg_total_population,\n    y_integer=True\n)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3312c5a7-3ce0-41f1-bc8b-67da61091c70","_cell_guid":"9ad0cd56-fc56-495c-8e4e-698931fd756f","trusted":true},"cell_type":"markdown","source":"### Hyperparameter optimization\nIn the previous paragraphs figures, we calculated the number of cases based on hypothesized parameter values. However, we do not know parameter values of the actual data. Here, we will estimate the ($\\theta, \\kappa, \\rho, \\sigma$) values of the example data using hyperparameter optimization method by Optuna package. $\\tau$ will be fixed as 1440 [min]. Estimator class was defined in \"Preparation\" section."},{"metadata":{"_uuid":"177c29e4-93fa-4fae-864a-77a952f818ad","_cell_guid":"9e90ff6d-2612-4fa1-bc3d-0dae73843f44","trusted":true},"cell_type":"code","source":"%%time\nsirf_estimator = Estimator(\n    # We can replace SIRF with SIR or SIRD\n    SIRF, eg_ori_df, eg_total_population,\n    name=\"Example\", places=[(\"Example\", None)],\n    tau=eg_tau\n)\nsirf_dict = sirf_estimator.run(500)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Trajectorie of parameter values in hyperparameter estimation are shown here."},{"metadata":{"trusted":true,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"sirf_estimator.history_df().head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b11aeb29-afd0-4378-8574-d5124b821ea0","_cell_guid":"75abc8cf-b898-4d9f-b30c-e8e403626447","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"sirf_estimator.history_graph()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Estimated parameter values are shown here."},{"metadata":{"_uuid":"375cb268-d100-4c5b-8f7a-fa3aeb9f319e","_cell_guid":"13b5989d-1ea6-4dae-812e-e5b0ce735c5f","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"pd.DataFrame.from_dict({\"SIR-F\": sirf_dict}, orient=\"index\").fillna(\"-\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note:  \n\"Score\" is Root Mean Squared Log Error (RMSLE) score.\n\\begin{align*}\n& \\sqrt{\\cfrac{1}{n}\\sum_{i=1}^{n}(log_{10}(A_{i} + 1) - log_{10}(P_{i} + 1))^2}\n\\end{align*}\nWhere $A$ is observed (actual) values, $P$ is estimated (predicted) values. Variables are $S$ ($i=1$), $I$ ($i=2$), $R$ ($i=3$) and $F$ ($i=n$) for SIR-F model. When RMSLE socre is low, hyperparameter estimation is highly accurate.  \nPlease refer to [Whats the Difference Between RMSE and RMSLE?](https://medium.com/analytics-vidhya/root-mean-square-log-error-rmse-vs-rmlse-935c6cc1802a)"},{"metadata":{},"cell_type":"markdown","source":"Comparison of observed values and estimated values is shown here.\n\nNote:  \nThis figures show the accuracy for each parameter. When \"v_observed\" and \"v_estimated\" (v=y, z, w) is overlapping, highly accurate."},{"metadata":{"_uuid":"8a15a081-716a-4638-907a-60330536b1ef","_cell_guid":"eb91e6c8-7df1-4c50-8765-05f5375f4099","trusted":true},"cell_type":"code","source":"sirf_estimator.compare_graph()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With the estimated the parameters, we can predict the number of cases. Vertical broken line indicates today."},{"metadata":{"_uuid":"82cac758-9303-43f5-bd76-5113010cbd12","_cell_guid":"1de174a0-fbaf-4951-bd78-d7071b5ceda4","trusted":true},"cell_type":"code","source":"sirf_estimator.predict_graph(step_n=180)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# SIR-F with exposed/waiting cases<a id=\"5\"></a>\nThe number of exposed cases in latent period (E) and wating cases for confirmation (W) are un-measurable variables, but key variables as well as S, I, R, F. If E and W are large, outbreak will occur in the near future. Let's replace S $\\overset{\\beta I}{\\longrightarrow}$ S$^\\ast$ with S $\\overset{\\beta_1 (W+I)}{\\longrightarrow}$ E $\\overset{\\beta_2}{\\longrightarrow}$ W $\\overset{\\beta_3}{\\longrightarrow}$ S$^\\ast$ because W also has infectivity.\n\nNote:  \nW and some rules were added to explain COVID-19 dataset, but this is like-SEIR model.  \nTo study general SEIR-model, please refer to PDF material in [Introduction to SEIR model Models](http://indico.ictp.it/event/7960/session/3/contribution/19/material/slides/)."},{"metadata":{},"cell_type":"markdown","source":"## What is SEWIR-F model?\n* S: Susceptible\n* <u>E: Exposed and in latent period (without infectivity)</u>\n* <u>W: Waiting cases for confirmation (with infectivity)</u>\n* S$^\\ast$: Confirmed and un-categorized\n* I: Confirmed and categorized as I\n* R: Recovered\n* F: Fatal with confirmation\n\nMeasurable variables:  \nTotal population - Confirmed = $S+E+W+S^\\ast$  \nConfirmed = $I+R+F$  \nRecovered = $R$  \nDeaths = $F$  \n\nModel:  \n\\begin{align*}\n\\mathrm{S} \\overset{\\beta_1 (W+I)}{\\longrightarrow} \\mathrm{E} \\overset{\\beta_2}{\\longrightarrow} \\mathrm{W} \\overset{\\beta_3}{\\longrightarrow} \\mathrm{S}^\\ast \\overset{\\alpha_1}{\\longrightarrow}\\ & \\mathrm{F}    \\\\\n\\mathrm{S}^\\ast \\overset{1 - \\alpha_1}{\\longrightarrow}\\ & \\mathrm{I} \\overset{\\gamma}{\\longrightarrow} \\mathrm{R}    \\\\\n& \\mathrm{I} \\overset{\\alpha_2}{\\longrightarrow} \\mathrm{F}    \\\\\n\\end{align*}\n\n$\\alpha_1$: Mortality rate of S$^\\ast$ cases [-]  \n$\\alpha_2$: Mortality rate of I cases [1/min]  \n$\\beta_1$: <u>Exposure rate (the number of encounter with the virus in a minute)</u> [1/min]  \n$\\beta_2$: <u>Inverse of latent period</u> [1/min]  \n$\\beta_3$: <u>Inverse of waiting time for confirmation</u> [1/min]  \n$\\gamma$: Recovery rate [1/min]  \n\nOrdinary Differential Equation (ODE):   \n\\begin{align*}\n& \\frac{\\mathrm{d}S}{\\mathrm{d}T}= - N^{-1}\\beta_1 S (W + I)  \\\\\n& \\frac{\\mathrm{d}E}{\\mathrm{d}T}= N^{-1}\\beta_1 S (W + I) - \\beta_2 E  \\\\\n& \\frac{\\mathrm{d}W}{\\mathrm{d}T}= \\beta_2 E - \\beta_3 W  \\\\\n& \\frac{\\mathrm{d}I}{\\mathrm{d}T}= (1 - \\alpha_1)\\beta_3 W - (\\gamma + \\alpha_2) I  \\\\\n& \\frac{\\mathrm{d}R}{\\mathrm{d}T}= \\gamma I  \\\\\n& \\frac{\\mathrm{d}F}{\\mathrm{d}T}= N^{-1}\\alpha_1 \\beta_3 W + \\alpha_2 I  \\\\\n\\end{align*}\n\nWhere $N=S+E+W+I+R+F$ is the total population, $T$ is the elapsed time from the start date."},{"metadata":{},"cell_type":"markdown","source":"## Non-dimensional SEWIR-F model\nSet $(S, E, W, I, R, F) = N \\times (x_1, x_2, x_3, y, z, w)$, $(T, \\alpha_1) = (\\tau t, \\theta)$ and $(\\alpha_2, \\beta_i, \\gamma) = \\tau^{-1} \\times (\\kappa, \\rho_i, \\sigma)$.  \nThis results in the ODE  \n\\begin{align*}\n& \\frac{\\mathrm{d}x_1}{\\mathrm{d}t}= - \\rho_1 x_1 (x_3 + y)  \\\\\n& \\frac{\\mathrm{d}x_2}{\\mathrm{d}t}= \\rho_1 x_1 (x_3 + y) - \\rho_2 x_2  \\\\\n& \\frac{\\mathrm{d}x_3}{\\mathrm{d}t}= \\rho_2 x_2 - \\rho_3 x_3  \\\\\n& \\frac{\\mathrm{d}y}{\\mathrm{d}t}= (1-\\theta) \\rho_3 x_3 - (\\sigma + \\kappa) y  \\\\\n& \\frac{\\mathrm{d}z}{\\mathrm{d}t}= \\sigma y  \\\\\n& \\frac{\\mathrm{d}w}{\\mathrm{d}t}= \\theta \\rho_3 x_3 + \\kappa y  \\\\\n\\end{align*}\n\nWhere $N$ is the total population and $\\tau$ is a coefficient ([min], is an integer to simplify).  \n\nThe range of variables and parameters:  \n\\begin{align*}\n0 < (x_i, y, z, w, \\theta, \\kappa, \\rho_i, \\sigma) < 1\\ \\mathrm{for}\\ i = 1, 2, 3\n\\end{align*}\n\\begin{align*}\n1 \\leq \\tau \\leq 1440\n\\end{align*}\n\nReproduction number can be defined as  \n\\begin{align*}\nR_0 = \\rho_1 (1-\\theta) (\\sigma + \\kappa)^{-1}\n\\end{align*}"},{"metadata":{},"cell_type":"markdown","source":"## Calculate $\\rho_2$ and $\\rho_3$\nTo estimate $\\rho_2 = \\tau \\beta_2$ and $\\rho_3 = \\tau \\beta_3$ of COVID-19, we first calculate median value of latent period $\\overline{L_{E}}$ and waiting time for confirmation $\\overline{L_{W}}$ using linelist. We assume that patients start to have infectivity from onset dates. This means latent period is equal to incubation period.\n\n$\\beta_2$: Inverse of latent period [1/min]  \n$\\beta_3$: Inverse of waiting time for confirmation [1/min]"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"period_df = select_area(linelist_df, group=None)\nperiod_df = period_df.loc[:, [\"Exposed_date\", \"Onset_date\", \"Confirmed_date\"]]\nperiod_df[\"Latent [min]\"] = (period_df[\"Onset_date\"] - period_df[\"Exposed_date\"]).dt.total_seconds() / 60\nperiod_df[\"Waiting [min]\"] = (period_df[\"Confirmed_date\"] - period_df[\"Onset_date\"]).dt.total_seconds() / 60\nperiod_df[\"Latent [day]\"] = period_df[\"Latent [min]\"] / 60 / 24\nperiod_df[\"Waiting [day]\"] = period_df[\"Waiting [min]\"] / 60 / 24\nperiod_df[\"Latent + Waiting [day]\"] = period_df[\"Latent [day]\"] + period_df[\"Waiting [day]\"]\nperiod_df.dropna(axis=0).tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"cols = [\"Latent [day]\", \"Waiting [day]\", \"Latent + Waiting [day]\"]\nperiod_df[cols].plot.kde()\nplt.title(\"Kernel density estimation of latent period and waiting time for confirmation [day]\")\nplt.show()\nperiod_df[cols].describe().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"latent_period = period_df[\"Latent [min]\"].median()\nwaiting_time = period_df[\"Waiting [min]\"].median()\nlatent_waiting_day = period_df[\"Latent + Waiting [day]\"].median()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tau = sirf_estimator.info()[1][\"tau\"]\neg_rho2, eg_rho3 = tau / latent_period, tau / waiting_time\n(eg_rho2, eg_rho3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Example of non-dimensional SEWIR-F model\nFor example, set $\\theta=0.002, \\kappa=0.005, \\rho_1=0.2, \\sigma=0.08$ and initial values $(x_{1(0)}, x_{2(0)}, x_{3(0)}, y_{(0)}, z_{(0)}, w_{(0)}) = (0.994, 0.003, 0.002, 0.001, 0, 0)$."},{"metadata":{"trusted":true},"cell_type":"code","source":"eg_theta, eg_kappa, eg_rho1, eg_sigma = (0.002, 0.005, 0.2, 0.08)\neg_initials = (0.994, 0.003, 0.002, 0.001, 0, 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\neg_df = simulation(\n    SEWIRF, eg_initials, step_n=180,\n    theta=eg_theta, kappa=eg_kappa, rho1=eg_rho1, rho2=eg_rho2, rho3=eg_rho3, sigma=eg_sigma)\neg_df.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"line_plot(\n    eg_df.set_index(\"t\"),\n    title=r\"SEWIR-F: $\\theta={0}, \\kappa={1}, \\rho_1={2}, \\rho_2={3}, \\rho_3={4}, \\sigma={5})$\".format(\n        eg_theta, eg_kappa, eg_rho1, round(eg_rho2, 2), round(eg_rho3, 2), eg_sigma\n    ),\n    ylabel=\"\",\n    h=1\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dimensionalization\nHere, we will dimensionalize the data, assuming that start date is the first date of JHU dataset, $\\tau=1440$ [min] and total population $N=1,000,000$."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"eg_tau = 1440\neg_start_date = ncov_df[\"Date\"].min()\neg_total_population = 1_000_000\nprint(f\"The start date is {eg_start_date.strftime('%d%b%Y')}.\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"eg_ori_df = pd.DataFrame(\n    {\n        \"Date\": (eg_df[\"t\"] * eg_tau).apply(lambda x: timedelta(minutes=x)) + eg_start_date,\n        \"Group\": \"Stopping\",\n        \"Country\": \"Example\",\n        \"Province\": \"-\",\n        \"Susceptible\": (eg_df[\"x1\"] * eg_total_population).astype(np.int64),\n        \"Exposed\": (eg_df[\"x2\"] * eg_total_population).astype(np.int64),\n        \"Waiting\": (eg_df[\"x3\"] * eg_total_population).astype(np.int64),\n        \"Confirmed\": 0,\n        \"Infected\": (eg_df[\"y\"] * eg_total_population).astype(np.int64)\n    }\n)\neg_ori_df[\"Recovered\"] = (eg_df[\"z\"] * eg_total_population).astype(np.int64)\neg_ori_df[\"Fatal\"] = (eg_df[\"w\"] * eg_total_population).astype(np.int64)\neg_ori_df[\"Confirmed\"] = eg_ori_df[[\"Infected\", \"Recovered\", \"Fatal\"]].sum(axis=1)\neg_ori_df.tail()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":false,"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"cols = [\"Susceptible\", \"Exposed\", \"Waiting\", \"Infected\", \"Recovered\", \"Fatal\"]\nline_plot(\n    eg_ori_df.set_index(\"Date\")[cols],\n    \"Example data of SIR-F model\",\n    h=eg_total_population,\n    y_integer=True\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Factors of model parameters<a id=\"6\"></a>\nTo figure out what to do for minimizing the damage, we will perform scenario analysis in the next section. In this section, we will define the control factors of the SIR-F parameters."},{"metadata":{},"cell_type":"markdown","source":"## Control factors of effective contact rate $\\beta_1$\nPlease reconsider S $\\overset{\\beta_1 (W+I)}{\\longrightarrow}$ E formula. Susceptible persons may contact with waiting/confirmed patients, and susceptible persons will be infected with COVID-19. The formura can be replaced with  \n\\begin{alignat}{1}\n{\\mathrm{S}}_{\\mathrm{q}} & \\overset{g_{s}}{\\Longleftrightarrow} {\\mathrm{S}}_{\\mathrm{g}} \\overset{f_1}\n {\\longrightarrow} \\ & \\mathrm{E}^\\ast \\overset{e^{-h_2}}{\\longrightarrow} \\mathrm{E}   \\\\\n& & \\mathrm{E}^\\ast \\overset{1-e^{-h_2}}{\\longrightarrow} \\mathrm{R}^\\ast  \\\\\n\\mathrm{W}_\\mathrm{q} & \\overset{g_w}{\\Longleftrightarrow} \\mathrm{W}_{\\mathrm{g}}  \\\\\n\\mathrm{I}_\\mathrm{q} & \\overset{g_i}{\\Longleftrightarrow} \\mathrm{I}_{\\mathrm{g}}  \\\\\n\\mathrm{I}_\\mathrm{q} & \\overset{q}{\\longrightarrow} \\mathrm{I}_{\\hat{\\mathrm{q}}}  \\\\\n\\end{alignat}"},{"metadata":{},"cell_type":"markdown","source":"$\\Longleftrightarrow$ (as substitute for $\\longrightarrow$ with $\\longleftarrow$) means that right side can be return to the left side.  \nS$_\\mathrm{q}$: Susceptible persons with self-quaranting <!--Susceptible in the strict sense-->  \nS$_\\mathrm{g}$: Susceptible persons with family members or friends etc.  \nW$_\\mathrm{q}$: Waiting patients with self-quaranting  \nW$_\\mathrm{g}$: Waiting patients with family members or friends etc.  \nI$_\\mathrm{q}$: Confimered and un-recovered patients with self-quaranting  \nI$_\\mathrm{g}$: Confimered and un-recovered patients with family members or friends etc.  \nI$_\\hat{\\mathrm{q}}$: Confimered and un-recovered patients who was hospitalized  \nE$^\\ast$: Just after being exposed to the virus  \nR$^\\ast$: Being exposed to the virus, fighted with the virus, recovered and immuned without confirmation  "},{"metadata":{},"cell_type":"markdown","source":"$f_1 = v(W_{\\mathrm{g}} + I_{\\mathrm{g}})(1-m)^2(1-w_e)^{w_n}e^{-h_1}sc$ [-] "},{"metadata":{},"cell_type":"markdown","source":"Control factors:  \n$g_s$: The number of days in <u>a week</u> susceptible persons go out [day]  \n$g_w$: The number of days in <u>a week</u> waiting but un-quarantined persons go out [day]  \n$g_i$: The number of days in <u>a week</u> currently infected (confirmed) but un-quarantined persons go out [day]  \n$q$: Quarantine rate of currently infected (confirmed) patients [-]  \n$v$: Probability of virus existance in a droplet [-]  \n$m$: Rate of persons wearing masks effectively (depends logistically on supply of masks) [-]  \n$w_e$: Virus reduction effect of washing hands [-]  \n$w_n$: The number of times people washes their hands before touching their own faces after go out [-]  \n$h_1$: Health condition (active rate of cellular immunity factors) of susceptible and contacted persons [-]  \n$h_2$: Health condition (active rate of humoral immunity factors) of susceptible and contacted persons [-]  \n$c$: The number of contacts between susceptible persons and patients while on the go in a minute (depends on population density) [1/min]  \n$\\delta$:The product of unknown real factors [-]  \n\nThe parameter in the math model:  \n$\\beta_1 = \\cfrac{1}{49}[g_s \\{g_w + g_i (1-q) \\} v (1-m)^2 (1-w_e)^{w_n} e^{-(h_{1}+h_{2})} c \\delta]$ [1/min]"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Value of beta before actions are taken\n_, info_dict, param_dict = sirf_estimator.info()\nbeta_before = param_dict[\"rho\"] / info_dict[\"tau\"]\nbeta_before","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**As a example, we will predict the impact of lockdown. $g_s$ will be minimized.**"},{"metadata":{},"cell_type":"markdown","source":"### $g_s$ value before actions are taken\n$g_s$: The number of days in <u>a week</u>, susceptible persons go out [day]  "},{"metadata":{},"cell_type":"markdown","source":"We can calculate weighted average of days with age composion of population. Population pyramid in the entire world (global data) will be used."},{"metadata":{"trusted":true},"cell_type":"code","source":"eg_out_df = go_out(\"Global\")\neg_out_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"$g_s$ value is"},{"metadata":{"trusted":true},"cell_type":"code","source":"gs_before = (eg_out_df[[\"School\", \"Office\", \"Others\"]].sum(axis=1) * eg_out_df[\"Portion\"]).sum()\ngs_before","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### $g_s$ value AFTER actions are taken\nIf all schools and offices will be closed, $g_s$ can be reduced. People will go out one day for other reasons instead of going to school/office."},{"metadata":{"trusted":true},"cell_type":"code","source":"df = eg_out_df.copy()\ndf.loc[df[\"School\"] + df[\"Office\"] > 0, \"Others\"] += 1\ndf[\"School\"] = 0\ndf[\"Office\"] = 0\neg_out_df_after = df.copy()\neg_out_df_after","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = eg_out_df_after.copy()\ngs_after = (df[[\"School\", \"Office\", \"Others\"]].sum(axis=1) * df[\"Portion\"]).sum()\ngs_after","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Impact of actions on $\\beta$\nIn SIR-F model $g_s$ is a control factor of $\\beta$.  \nActions taken at 30th day:  \nAll schools and offices will be closed.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"beta_after = beta_before * (gs_after / gs_before)\nbeta_after / beta_before","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predict the number of cases: with actions from 30th day\nThere is a delay between the time point of starting actions and that of appearing the effect. Because $I$ is the main variable, the length of delay can be estimated as sum of latent period and waiting time for confirmation. This value [day] was calculated in \"SIR-F with exposed/waiting cases\" section."},{"metadata":{"trusted":true},"cell_type":"code","source":"latent_waiting_day","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"first_model, info_dict, param_dict = sirf_estimator.info()\ninfo_dict[\"name\"] = \"Example\"\nchanged_param_dict = param_dict.copy()\nchanged_param_dict[\"rho\"] = param_dict[\"rho\"] * beta_after / beta_before\ndf = pd.DataFrame.from_dict(\n    {\"No actions\": param_dict, \"With actions\": changed_param_dict},\n    orient=\"index\"\n)\ndf = df.loc[:, [\"theta\", \"kappa\", \"rho\", \"sigma\"]]\ndf[\"R0\"] = df.apply(lambda x: first_model(**x.to_dict()).calc_r0(), axis=1)\ndf[\"tau\"] = info_dict[\"tau\"]\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Without actions:"},{"metadata":{"trusted":true},"cell_type":"code","source":"predicter = Predicter(**info_dict)\npredicter.add(SIRF, end_day_n=30, count_from_last=False, vline=False, **param_dict)\npredicter.add(SIRF, end_day_n=latent_waiting_day, count_from_last=True, **param_dict)\npredicter.add(SIRF, end_day_n=180, count_from_last=False, **param_dict)\npredicter.restore_graph(drop_cols=None, y_integer=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With actions:"},{"metadata":{"trusted":true},"cell_type":"code","source":"predicter = Predicter(**info_dict)\npredicter.add(SIRF, end_day_n=30, count_from_last=False, vline=False, **param_dict)\npredicter.add(SIRF, end_day_n=latent_waiting_day, count_from_last=True, **param_dict)\npredicter.add(SIRF, end_day_n=180, count_from_last=False, **changed_param_dict)\npredicter.restore_graph(drop_cols=None, y_integer=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The actions result in:  \nTotal number of confirmed cases was decreased.  \nPeak point of infected cases was delayed.   \n<!--We need to fight with the virus for longer period.-->"},{"metadata":{},"cell_type":"markdown","source":"## Control factors of recovery rate $\\gamma$ and mortality rate $\\alpha_2$\nHere, let's reconsider I $\\overset{\\gamma}{\\longrightarrow}$ R and I $\\overset{\\alpha_2}{\\longrightarrow}$ F.  \nBecause balance of immunity (+effect of treatments) and virulence determines whether patients can recover or not, the formulas can be replaced with  \n\n\\begin{align*}\n& \\mathrm{I} \\overset{\\bar{h}}{\\longrightarrow} \\mathrm{I}^\\star \\overset{\\bar{s}}{\\longrightarrow} \\mathrm{F}^\\star \\overset{L^{-1}}{\\longrightarrow} \\mathrm{F}    \\\\\n& \\mathrm{I} \\overset{f_2}{\\longrightarrow} \\mathrm{R}^\\star \\overset{l^{-1}}{\\longrightarrow} \\mathrm{R}    \\\\\n\\end{align*}\n\nI$^\\star$: Confirmed cases whose immune systems did not overcome virus multiplication, and <u>without</u> severe events  \nF$^\\star$: Confirmed cases whose immune systems did not overcome virus multiplication, and <u>with</u> severe events  \nR$^\\star$: Confirmed cases whose immune systems overcame virus multiplication or comfirmed cases whose severe events can be stopped"},{"metadata":{},"cell_type":"markdown","source":"Where $f_2 = 1 - \\bar{h}\\ \\bar{s}$  \n\n$\\bar{h}$: Rate of I whose immune systems does NOT overcame virus multiplication [-]  \n$\\bar{s}$: Rate of I$^\\star$ who have severe events, including respiratory failure  [-]  \n$L_i$: Inverse of F$^\\star$'s mortality rate for people $i$ years old [min]  \n$l_i$: Inverse of R$^\\star$'s mortality rate for people $i$ years old [min]  \n$P_i$: The number of people $i$ years old [-]  \n$N$: Total population  \n\n\\begin{align*}\n& \\alpha_2 = \\cfrac{\\bar{h}\\ \\bar{s}}{N} \\sum_{n=0}^{\\infty}\\cfrac{P_{i}}{L_i} \\\\\n& \\gamma = \\cfrac{1 - \\bar{h}\\ \\bar{s}}{N} \\sum_{n=0}^{\\infty}\\cfrac{P_{i}}{l_i} \\\\\n\\end{align*}"},{"metadata":{},"cell_type":"markdown","source":"## $\\bar{h}$ and $\\bar{s}$ value before actions are taken\nWe assume that $\\bar{h}=0.5$ and $\\bar{s}=0.5$.  \n**(Using population distribution data and case reports, $\\bar{h}\\ \\bar{s}$ and $1 - \\bar{h}\\ \\bar{s}$ can be calculated.)**"},{"metadata":{"trusted":true},"cell_type":"code","source":"gamma_before = param_dict[\"sigma\"] / info_dict[\"tau\"]\nalpha2_before = param_dict[\"kappa\"] / info_dict[\"tau\"]\n(gamma_before, alpha2_before)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"h_bar_before, s_bar_before = 0.5, 0.5","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## $\\bar{h}$ and $\\bar{s}$ value AFTER actions are taken\nAssumtions of new medicines:  \n\"Protease inhibitor\" inhibits virus multiplication. This will reduce $\\bar{h}$. We assume the $\\bar{h}$ will 10%."},{"metadata":{"trusted":true},"cell_type":"code","source":"h_bar_after = h_bar_before * 0.1\ns_bar_after = s_bar_before\n(h_bar_after, s_bar_after)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Impact on $\\gamma$ and $\\alpha_2$\nActions to take:  \nNew Protein inhibitor medicine was introduced."},{"metadata":{"trusted":true},"cell_type":"code","source":"gamma_after = gamma_before * (1 - h_bar_after * s_bar_after) / (1 - h_bar_before * s_bar_before)\ngamma_after","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"alpha2_after = alpha2_before * (h_bar_after * s_bar_after) / (h_bar_before * s_bar_before)\nalpha2_after","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predict the number of case: with new medicines after 30th day"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"first_model, info_dict, param_dict = sirf_estimator.info()\ninfo_dict[\"name\"] = \"Example\"\nchanged_param_dict = param_dict.copy()\nchanged_param_dict[\"sigma\"] = param_dict[\"sigma\"] * gamma_after / gamma_before\nchanged_param_dict[\"kappa\"] = param_dict[\"kappa\"] * alpha2_after / alpha2_before\ndf = pd.DataFrame.from_dict(\n    {\"No medicines\": param_dict, \"With medicines\": changed_param_dict},\n    orient=\"index\"\n)\ndf = df.loc[:, [\"theta\", \"kappa\", \"rho\", \"sigma\"]]\ndf[\"R0\"] = df.apply(lambda x: first_model(**x.to_dict()).calc_r0(), axis=1)\ndf[\"tau\"] = info_dict[\"tau\"]\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Without new medicines:"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"predicter = Predicter(**info_dict)\npredicter.add(SIRF, end_day_n=30, count_from_last=False, vline=True, **param_dict)\npredicter.add(SIRF, end_day_n=180, count_from_last=False, **param_dict)\npredicter.restore_graph(drop_cols=None)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With new medicines:"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"predicter = Predicter(**info_dict)\npredicter.add(SIRF, end_day_n=30, count_from_last=False, vline=True, **param_dict)\npredicter.add(SIRF, end_day_n=180, count_from_last=False, **changed_param_dict)\npredicter.restore_graph(drop_cols=None)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"New medicines result in:  \nTotal numbers of confirmed/deaths cases were decreased."},{"metadata":{},"cell_type":"markdown","source":"## If 100,000/day are vaccinated (SIR-FV model) from 30th day\nWe will predict the numbers of cases in the assumption that 100,000 persons will be vacctinated in one day until there are no susceptible people.  \n\n\\begin{align*}\n& \\frac{\\mathrm{d}x}{\\mathrm{d}t}= - \\rho x y - \\omega  \\\\\n& \\frac{\\mathrm{d}y}{\\mathrm{d}t}= \\rho (1-\\theta) x y - (\\sigma + \\kappa) y  \\\\\n& \\frac{\\mathrm{d}z}{\\mathrm{d}t}= \\sigma y  \\\\\n& \\frac{\\mathrm{d}w}{\\mathrm{d}t}= \\rho \\theta x y + \\kappa y  \\\\\n\\end{align*}\n\nWhere $\\omega_{(x>0)}=\\frac{100,000}{N}$ and $N$ is the total population.\n\nReproduction number can be defined as  \n\\begin{align*}\nR_0 = \\rho (1 - \\theta) (\\sigma + \\kappa)^{-1}\n\\end{align*}"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"first_model, info_dict, param_dict = sirf_estimator.info()\nchanged_param_dict = param_dict.copy()\nchanged_param_dict[\"n\"] = population_dict[critical_country]\nchanged_param_dict[\"v_per_day\"] = 100000\npredicter = Predicter(**info_dict)\npredicter.add(SIRF, end_day_n=30, count_from_last=False, **param_dict)\npredicter.add(SIRFV, end_day_n=300, count_from_last=False, **changed_param_dict)\npredicter.restore_graph(drop_cols=None)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With vactination:  \nOutbreak will end relatively quickly."},{"metadata":{},"cell_type":"markdown","source":"# S-R trend analysis<a id=\"10\"></a>\nIn the previous section, we found that parameter values can be changed by actions. To predict the future, we need to recognize the parameter change from the actual records. Here, trend analysis method will be introduced."},{"metadata":{},"cell_type":"markdown","source":"## Example datasets\nWith the same initial values $(x_{(0)}, y_{(0)}, z_{(0)}, w_{(0)})=(0.999, 0.001, 0, 0)$, we will create five SIR-F example datasets.\n* Example 1: $(\\theta, \\kappa, \\rho, \\sigma) = (0.0002, 0.005, 0.20, 0.075)$\n* Example 2: $(\\theta, \\kappa, \\rho, \\sigma) = (0.0002, 0.005, \\underline{0.40}, 0.075)$, spread quickly\n* Example 3: $(\\theta, \\kappa, \\rho, \\sigma) = (0.0002, 0.005, \\underline{0.15}, 0.075)$, spread slowly\n* Example 4: $(\\theta, \\kappa, \\rho, \\sigma) = (0.0002, \\underline{0.003}, 0.20, \\underline{0.150})$, improved heakthcare system\n* Example 5: $(\\theta, \\kappa, \\rho, \\sigma) = (\\underline{0.0000}, 0.005, 0.20, 0.075)$, equal to SIR-D model\n\nValues are dimensionalized with total population $N=1,000,000$ in the example datasets."},{"metadata":{"_kg_hide-input":true,"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"df = pd.DataFrame()\neg_initials = (0.999, 0.001, 0, 0)\neg_total_population = 1_000_000\neg_step_n = 200\neg_param_dict = {\n    \"1\": {\"theta\": 0.0002, \"kappa\": 0.005, \"rho\": 0.20, \"sigma\": 0.075},\n    \"2\": {\"theta\": 0.0002, \"kappa\": 0.005, \"rho\": 0.40, \"sigma\": 0.075},\n    \"3\": {\"theta\": 0.0002, \"kappa\": 0.005, \"rho\": 0.15, \"sigma\": 0.075},\n    \"4\": {\"theta\": 0.0002, \"kappa\": 0.003, \"rho\": 0.20, \"sigma\": 0.150},\n    \"5\": {\"theta\": 0.0000, \"kappa\": 0.005, \"rho\": 0.20, \"sigma\": 0.075},\n}\n\nfor (num, _dict) in eg_param_dict.items():\n    _df = simulation(SIRF, eg_initials, step_n=eg_step_n, **_dict)\n    _df = (_df.set_index(\"t\") * eg_total_population).astype(np.int64)\n    _df = _df.reset_index()\n    _df[\"Country\"] = f\"Example {num}\"\n    df = pd.concat([df, _df], axis=0, ignore_index=True)\n\ndf[\"Date\"] = ncov_df[\"Date\"].min() + pd.Series(df[\"t\"]).apply(lambda x: timedelta(days=x))\ndf[\"Group\"] = \"Stopping\"\ndf[\"Province\"] = \"-\"\ndf = df.rename({\"y\": \"Infected\", \"z\": \"Recovered\", \"w\": \"Deaths\"}, axis=1)\ndf[\"Confirmed\"] = df[[\"Infected\", \"Recovered\", \"Deaths\"]].sum(axis=1)\ndf = df.loc[:, ncov_df.columns]\neg_ncov_df = df.copy()\neg_ncov_df.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"line_plot(\n    eg_ncov_df.pivot_table(index=\"Date\", columns=\"Country\", values=\"Confirmed\"),\n    \"Example dataset: Confirmed cases over time\"\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Values of Example 1 $(\\kappa=0.002)$ are nealy equal to that of Example 5 $(\\kappa=0.000)$ as shown in the next figure."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df = eg_ncov_df.pivot_table(index=\"Date\", columns=\"Country\", values=\"Confirmed\")\ndf.plot.scatter(x=\"Example 1\", y=\"Example 5\")\nplt.plot(df[\"Example 1\"], df[\"Example 1\"], color=\"black\", linewidth=0.5)\nplt.xlim(0, None)\nplt.ylim(0, None)\nplt.title(\"Scatter plot of confirmed cases with y=x line\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"line_plot(\n    eg_ncov_df.pivot_table(index=\"Date\", columns=\"Country\", values=\"Infected\"),\n    \"Example dataset: Infected cases over time\"\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note: This seems Gamma distribution curve.\n\\begin{align*}\nf(x>0) & = \\cfrac{\\lambda^{k}}{\\Gamma(k)} x^{k-1} e^{-\\lambda x}  \\\\\n\\Gamma(k) & = \\int_{0}^{\\infty} t^{k-1} e^{-t} dt\n\\end{align*}"},{"metadata":{},"cell_type":"markdown","source":"Curve fitting with Gamma distribution curve is done by Bill Holst. Please find the URLs in \"Acknowledgement\" subsection."},{"metadata":{},"cell_type":"markdown","source":"## $\\Delta$Confirmed vs. Confirmed in log-log plot\nThe numer of new confirmed cases $\\Delta C$ can be desribed as,\n\\begin{align*}\n\\Delta C=N^{-1}\\beta (N - C) I\n\\end{align*}\nThis is because $C=I+R+F$ and $S=N-C$ in SIR-F model."},{"metadata":{},"cell_type":"markdown","source":"$t$ is a measurable variable, but this is just an intermediate variable. $\\Delta C$ is determined by cummurative number of cases."},{"metadata":{},"cell_type":"markdown","source":"In addition, $I$ is determined by $C$ when the parameters $(\\alpha_1, \\alpha_2, \\beta, \\gamma)$ are fixed.  \nThen,\n$$\\Delta C = f(C)$$"},{"metadata":{},"cell_type":"markdown","source":"Plots of $(x, y) = (C, \\Delta C)$ in log-log scale are shown in the next figure.  \n\nNote:  \nThis idea is from [YouTube: How To Tell If We're Beating COVID-19](https://www.youtube.com/watch?v=54XLXg4fYsc). SIR-type models are not mentioned in this video, but we can link the idea with SIR-F model as above."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"for country in eg_ncov_df[\"Country\"].unique():\n    df = eg_ncov_df.copy()\n    df = df.loc[df[\"Country\"] == country, :]\n    df = df.groupby(\"Date\").last()\n    plt.plot(df[\"Confirmed\"], df[\"Confirmed\"].diff(), label=country)\n\nplt.title(r\"Trajectory of $\\Delta$Confirmed against Confirmed in SIR-F model\")\nplt.xscale(\"log\")\nplt.yscale(\"log\")\nplt.xlabel(\"Confirmed\")\nplt.ylabel(r\"$\\Delta$Confirmed\")\nfmt = matplotlib.ticker.ScalarFormatter(useOffset=False)\nfmt.set_scientific(False)\nplt.gca().xaxis.set_major_formatter(fmt)\nplt.gca().yaxis.set_major_formatter(fmt)\nplt.legend(bbox_to_anchor=(1.02, 0), loc=\"lower left\", borderaxespad=0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Nete: Because $C(t)$ is a cummurative number, $C(t+\\Delta t) \\geq C(t)$ for all $t$ and $\\Delta t > 0$."},{"metadata":{},"cell_type":"markdown","source":"## argmax($\\Delta C$) in $(x, y) = (t, C(t))$ plot\nWhat can we know from $(C, \\Delta C)$ plot? Here, we will discuss max value of $\\Delta C$."},{"metadata":{},"cell_type":"markdown","source":"When $\\Delta C$ shows max value of $\\Delta C$ in \"Example 5\" dataset (equal to SIR-D model), $t$ and $C(t)$ is"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"country = \"Example 5\"\ndf = eg_ncov_df.copy()\ndf = df.loc[df[\"Country\"] == country, :].groupby(\"Date\").last()\narg_tt = df[\"Confirmed\"].diff().idxmax()\narg_cc = df.loc[arg_tt, \"Confirmed\"]\n# Plot\ndf[\"Confirmed\"].plot()\nplt.axhline(y=arg_cc, color=\"black\", linestyle=\":\")\nplt.axvline(x=arg_tt, color=\"black\", linestyle=\":\")\nplt.ylabel(\"Confirmed\")\nplt.title(\n    r'{0}: $C({1})={2}$ when $\\Delta C$ shows max value'.format(\n        country, arg_tt.strftime(\"%d%b%Y\"), arg_cc)\n)\nfmt = matplotlib.ticker.ScalarFormatter(useOffset=False)\nfmt.set_scientific(False)\nplt.gca().yaxis.set_major_formatter(fmt)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Curve fitting of $C(t)$\n$C(t)$ is sometimes described by logistic function and Gompertz function.\n\n\\begin{align*}\n\\mathrm{Logistic\\ function:\\ } g(t) & = \\cfrac{N}{1 + A e^{-Bt}}  \\\\\n\\mathrm{Gompertz\\ function:\\ } h(t) & = N e^{-A e^{-Bt}}\n\\end{align*}\n\ncf.)  \nThese functions are used for prediction of the number of case in [Jia, Lin, et al., 2020](https://arxiv.org/ftp/arxiv/papers/2003/2003.05447.pdf).  "},{"metadata":{},"cell_type":"markdown","source":"$f(t)$ can be divided to to stages;\n* exponential growth function ($t \\leq \\mathrm{argmax}\\ \\Delta C(t))$ and\n* negative exponential function $(otherwise)$.\n\nWith constant $(a, b, A, B, C)$,\n$$\nf(t) = \\left\\{\n\\begin{array}{ll}\n    a e^{bt} & (t \\leq \\mathrm{argmax}\\ \\Delta C(t)) \\\\\n    C - Ae^{-Bt} & (otherwise)\n\\end{array}\n\\right.\n$$"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"country = \"Example 5\"\ndf = eg_ncov_df.copy()\ndf = df.loc[df[\"Country\"] == country, :].groupby(\"Date\").last()\nstart_date = df.index.min()\narg_tt = df[\"Confirmed\"].diff().idxmax()\narg_dd = int((arg_tt - start_date).total_seconds() / 60 / 60 / 24)\narg_cc = df.loc[arg_tt, \"Confirmed\"]\n# Convert date to elapsed time (day)\ndf.index = ((df.index - start_date).total_seconds() / 60 / 60 / 24).astype(np.int64)\n# Curve fitting with exponential growth function\nf = lambda x, a, b: a * np.exp(b * x)\nseries = df.loc[df.index <= arg_dd, \"Confirmed\"]\na_ini = series[0]\nb_ini = np.log(arg_cc / a_ini) / arg_dd\nparam, _ = curve_fit(f, series.index, series, p0=[a_ini, b_ini])\nf_partial = functools.partial(f, a=param[0], b=param[1])\ndf[\"Exponential_growth\"] = pd.Series(df.index).apply(lambda x: f_partial(x))\n# Curve fitting with negative exponential function\nf = lambda x, a, b, c: c - a * np.exp(- b * (x - arg_dd))\nseries = df.loc[df.index >= arg_dd, \"Confirmed\"]\nc_ini = series.max()\na_ini = c_ini - arg_cc\nb_ini = series.diff()[arg_dd + 1] / a_ini\nparam, _ = curve_fit(f, series.index, series, p0=[a_ini, b_ini, c_ini])\nf_partial = functools.partial(f, a=param[0], b=param[1], c=param[2])\ndf[\"Negative_exponential\"] = pd.Series(df.index).apply(lambda x: f_partial(x))\n# Convert elapsed time (day) to date\ndf.index = start_date + pd.Series(df.index).apply(lambda x: timedelta(days=x))\n# Plot\ndf[[\"Exponential_growth\", \"Negative_exponential\"]].plot(color=[\"red\", \"green\"])\ndf[\"Actual\"] = df[\"Confirmed\"]\ndf[\"Actual\"].plot(color=\"blue\", marker=\".\", markeredgewidth=0, linewidth=0)\nplt.axhline(y=arg_cc, color=\"black\", linestyle=\":\")\nplt.axvline(x=arg_tt, color=\"black\", linestyle=\":\")\nplt.ylabel(\"Confirmed\")\nplt.ylim(0, max(df[\"Confirmed\"]) * 1.05)\nplt.title(r\"{0}: $(t, C(t))$ with exponential growth and negative exponential\".format(country))\nfmt = matplotlib.ticker.ScalarFormatter(useOffset=False)\nfmt.set_scientific(False)\nplt.gca().yaxis.set_major_formatter(fmt)\nplt.legend(bbox_to_anchor=(1.02, 0), loc=\"lower left\", borderaxespad=0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"However, errors were found for curve fitting. This is because\n$$\n\\cfrac{\\mathrm{d}C}{\\mathrm{d}T} = \\cfrac{\\beta}{N} S I\n$$\n$S \\simeq S(0) := const.$ for $t \\leq \\mathrm{argmax}\\ \\Delta C(t))$, but $I$ is not proportinal to $S$ in SIR-like model.  \n\nThis means we cannot convert the differencial equation to the following equations.\n\\begin{align*}\n\\frac{\\mathrm{d}x}{\\mathrm{d}t} & = B x \\\\\n\\mathrm{i.e.\\ } x(t) & = A e^{Bt}\n\\end{align*}"},{"metadata":{},"cell_type":"markdown","source":"## S-R plane\nHere, we will discuss the replationship of Susceptible and Recovered."},{"metadata":{},"cell_type":"markdown","source":"In SIR-F model,\n\\begin{align*}\n\\frac{\\mathrm{d}S}{\\mathrm{d}T} &= - N^{-1} \\beta S I  \\\\\n\\frac{\\mathrm{d}R}{\\mathrm{d}T} &= \\gamma I  \\\\\nI &> 0 \\\\\n\\end{align*}"},{"metadata":{},"cell_type":"markdown","source":"Then,\n\\begin{align*}\n\\cfrac{\\mathrm{d}S}{\\mathrm{d}R} &= - \\cfrac{\\beta}{N \\gamma} S  \\\\\n\\end{align*}"},{"metadata":{},"cell_type":"markdown","source":"This leads to"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"S = sym.symbols(\"S\", cls=sym.Function)\nN, R = sym.symbols(\"N R\", positive=True)\nbeta, gamma = sym.symbols(r\"\\beta \\gamma\", positive=True)\ndSdR = - beta / (N * gamma) * S(R)\nsr = sym.dsolve(S(R).diff(R) - dSdR, hint=\"separable\", ics={S(0): N})\nsr","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note:  \nThis idea is from [Balkew, Teshome Mogessie, \"The SIR Model When S(t) is a Multi-Exponential Function.\" (2010).Electronic Theses and Dissertations.Paper 1747.](https://dc.etsu.edu/cgi/viewcontent.cgi?article=3102&context=etd) This is for simplest SIR model, but we can apply it to SIR-F model."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"sym.Eq(sym.simplify(sym.log(sr.lhs)), sym.simplify(sym.log(sr.rhs)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With constant $a=\\frac{\\beta}{N\\gamma}$ and constant $b=\\log N$,\n$$\n\\log S_{(R)} = - a R + b\n$$"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"for country in eg_ncov_df[\"Country\"].unique():\n    df = eg_ncov_df.copy()\n    df = df.loc[df[\"Country\"] == country, :]\n    df = df.groupby(\"Date\").last()\n    plt.plot(df[\"Recovered\"], eg_total_population - df[\"Confirmed\"], label=country)\n\nplt.title(r\"Trajectory of Susceptible against Recovered in SIR-F model\")\nplt.yscale(\"log\")\nplt.xlabel(\"Recovered\")\nplt.ylabel(\"Susceptible\")\nfmt = matplotlib.ticker.ScalarFormatter(useOffset=False)\nfmt.set_scientific(False)\nplt.gca().xaxis.set_major_formatter(fmt)\nplt.gca().yaxis.set_major_formatter(fmt)\nplt.legend(bbox_to_anchor=(1.02, 0), loc=\"lower left\", borderaxespad=0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Nete: Because $R(t)$ is a cummurative number, $R(t+\\Delta t) \\geq R(t)$ for all $t$ and $\\Delta t > 0$."},{"metadata":{},"cell_type":"markdown","source":"**Thus, slope of $\\log S_{(R)}$ will be changed when SIR-F parameters are changed. We need to split the actual data, considering the change points of S-R line in log-scale. This logic will be used for actual data in scenario analysis section.**"},{"metadata":{},"cell_type":"markdown","source":"## S-R trend of actual data in Italy\nWe will perform S-R trend analysis for actual data in Italy as an example."},{"metadata":{},"cell_type":"markdown","source":"Let's see the plot of S-R trend."},{"metadata":{"trusted":true},"cell_type":"code","source":"ita_trend = Trend(ncov_df, population_dict[\"Italy\"], name=\"Italy\", places=[(\"Italy\", None)])\n_ = ita_trend.analyse()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plots of Actual data do not show a line. This means SIR-F parameters changed at some time-points. Next, we will find the time-points, assuming that there are three change points."},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nchange_points = ita_trend.analyse(n_points=3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Initial phase will be ignored in scenario analysis. The change points (start dates of phases) are"},{"metadata":{"trusted":true},"cell_type":"code","source":"\", \".join(change_points)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Scenario in Italy<a id=\"7\"></a>\nIn this section, we will perform scenario analysis using the records of Italy."},{"metadata":{"trusted":true},"cell_type":"code","source":"ita_scenario = Scenario(ncov_df, name=\"Italy\", population_dict=population_dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ita_scenario.show_record().tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ita_scenario.growth_factor()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Trend analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"_ = ita_scenario.trend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We will find the time-points, assuming that there are three change points.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"ita_change_points = ita_scenario.trend(n_points=3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Phases in Italy\nWe will use the change points as the start date of phases. For each phase, will apply SIR-F model. $\\tau$ values will be the same value."},{"metadata":{"trusted":true},"cell_type":"code","source":"ita_scenario.set_phase(start_dates=ita_change_points)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Estimate SIR-F parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"ita_scenario.estimate(SIRF)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1st phase"},{"metadata":{"trusted":true},"cell_type":"code","source":"ita_scenario.accuracy_graph(phase_n=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2nd phase"},{"metadata":{"trusted":true},"cell_type":"code","source":"ita_scenario.accuracy_graph(phase_n=2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3rd phase"},{"metadata":{"trusted":true},"cell_type":"code","source":"ita_scenario.accuracy_graph(phase_n=3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Compare predicted number of confirmed cases"},{"metadata":{"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"ita_scenario.compare_estimated_numbers(phases=[\"1st\", \"2nd\", \"3rd\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Compare parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"ita_scenario.show_parameters()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ita_scenario.param_history([\"kappa\", \"rho\", \"sigma\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Non-dimensional effective contact rate $\\rho$ seems to be reduced.**"},{"metadata":{},"cell_type":"markdown","source":"## Why $\\rho$ was reduced?"},{"metadata":{"trusted":true},"cell_type":"code","source":"ita_scenario.param_df[[\"start_date\", \"end_date\", \"rho\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def _color(data_df):\n    df = data_df.copy()\n    df.loc[:, :] = str()\n    df.iloc[[3, 6, 8], :] = \"background-color: lightgreen\"\n    return df\n\nita_action_df.style.apply(_color, axis=None)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**It seems that (quaranitine of person contacted with positive patients), school closure and lockdown reduced $\\rho$ value.**"},{"metadata":{},"cell_type":"markdown","source":"## Effect of school closure/lockdown\n\nAcording to first report of [COVID-19 Mobility Monitoring project](https://covid19mm.github.io/in-progress/2020/03/13/first-report-assessment.html) on 13Mar2020, the government of Italy declared a national lockdown on 09Mar2020 and all peole are asked to remain home. This resulted in average reduction of potential encounters of 19% during week 3 (from 07Mar2020 to 10Mar2020)."},{"metadata":{},"cell_type":"markdown","source":"**Here, we will predict the effect of school closure (started before 04Mar2020), lockdown on 13Mar2020 with assumtion that the effect will be shown from the start date of 3rd phase.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"ita_scenario.phase_dict[\"3rd\"][\"start_date\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Real factors of $\\beta_1$\n\nThe parameter in the math model:  \n\\begin{align*}\n\\rho_1 & = \\tau \\beta_1  \\\\  \n\\beta_1 & = \\cfrac{1}{49}[g_s \\{g_w + g_i (1-q) \\} v (1-m)^2 (1-w_e)^{w_n} e^{-(h_{1}+h_{2})} c \\delta]  \\\\\n\\end{align*}\n\nControl factors:  \n$g_s$: The number of days in <u>a week</u> susceptible persons go out [day]  \n$g_w$: The number of days in <u>a week</u> waiting but un-quarantined persons go out [day]  \n$g_i$: The number of days in <u>a week</u> currently infected (confirmed) but un-quarantined persons go out [day]  \n$q$: Quarantine rate of currently infected (confirmed) patients [-]  \n$v$: Probability of virus existance in a droplet [-]  \n$m$: Rate of persons wearing masks effectively (depends logistically on supply of masks) [-]  \n$w_e$: Virus reduction effect of washing hands [-]  \n$w_n$: The number of times people washes their hands before touching their own faces after go out [-]  \n$h_1$: Health condition (active rate of cellular immunity factors) of susceptible and contacted persons [-]  \n$h_2$: Health condition (active rate of humoral immunity factors) of susceptible and contacted persons [-]  \n$c$: The number of contacts between susceptible persons and patients while on the go in a minute (depends on population density) [1/min]  \n$\\delta$:The product of unknown real factors [-]  "},{"metadata":{},"cell_type":"markdown","source":"### Value of control factors of $\\beta_1$ before/after the national lockdown\nA national lockdown will effect on $g_s$ and $c$."},{"metadata":{},"cell_type":"markdown","source":"Acccoring the report, we assume average reduction of potential encounters of 19%."},{"metadata":{"trusted":true},"cell_type":"code","source":"c_before, c_after = 1.0, 0.81","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### $g_s$ before the lockdown\nWe will estimate average number peple go out using @marcoferrante estimation table and population pyramid data.\nIt is necessary to replace the population pyramid data for Italy because the situation is different from the average data."},{"metadata":{"trusted":true},"cell_type":"code","source":"ita_out_df = go_out(\"Italy\")\nita_out_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gs_before = (ita_out_df[[\"School\", \"Office\", \"Others\"]].sum(axis=1) * ita_out_df[\"Portion\"]).sum()\nprint(f\"{round(gs_before, 1)} days in a week susceptible people go out.\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Estimation of $g_s$ after school closure/lockdown\nHere, we estimate the $g_s$ after school closure/lockdown with the assumption that only $g_s$ and $c$ was changed.   \n\nBecause\n$$\\cfrac{\\rho_{\\mathrm{after}}}{gs_{\\mathrm{after}}\\times c_{\\mathrm{after}}} = \\cfrac{\\rho_{\\mathrm{before}}}{gs_{\\mathrm{before}}\\times c_{\\mathrm{before}}}$$\n\n$gs_{\\mathrm{after}}$ is"},{"metadata":{"trusted":true},"cell_type":"code","source":"rho_before = ita_scenario.param(\"1st\", \"rho\")\nrho_after = ita_scenario.param(\"3rd\", \"rho\")\ngs_after = rho_after / rho_before / c_after * gs_before * c_before\nprint(f\"{round(gs_after, 1)} days in a week susceptible people go out after lockdown.\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's apply this value to the go_out table!  \nWe assume that workers go to their office one day in a week."},{"metadata":{"trusted":true},"cell_type":"code","source":"df = ita_out_df.copy()\ndf[\"School\"] = 0\ndf.loc[df[\"Office\"] > 0, \"Office\"] = 1\nsum_so = (df[[\"School\", \"Office\"]].sum(axis=1) * df[\"Portion\"]).sum()\ndf.loc[df[\"Others\"] > 0, \"Others\"] = round(gs_after - sum_so, 1)\nita_out_after_df = df.copy()\nita_out_after_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check the $g_s$ value calculated with the table."},{"metadata":{"trusted":true},"cell_type":"code","source":"gs_after = (ita_out_after_df[[\"School\", \"Office\", \"Others\"]].sum(axis=1) * ita_out_after_df[\"Portion\"]).sum()\nround(gs_after, 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predict the future with the last parameters"},{"metadata":{},"cell_type":"markdown","source":"In a week,"},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"ita_scenario.predict(days=7).tail(7).style.background_gradient(axis=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In 30 days,"},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"ita_scenario.predict(days=30).tail(7).style.background_gradient(axis=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the long-term,"},{"metadata":{"trusted":true},"cell_type":"code","source":"_ = ita_scenario.predict(days=1000, min_infected=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Effect of expected new medicines (Favipiravir, AVIGAN)\nNew medicines are necessary so that patients can recover more quicky from the disease. Drug repositioning strategy (i.e.finding effective candidates from library of existing drugs of different diseases) is used to develop the medicines of COVID-19. For example, Favipiravir (AVIGAN) is a candidate. Certainly, this medicine may lead many serious adverse reactions and it cannot be provided to expectant mothers [KEGG database AVIGAN](https://www.kegg.jp/medicus-bin/japic_med?japic_code=00066852) (Sorry, this is written in Japanese). However, it may help to save many thousand lives.  \n\n**We do not have information about its criteria to administrate and medicinal effect on COVID-19. We assume that fatal risk $\\bar{h}\\ \\bar{s}$ will be halved (0.50 $\\to$ 0.25) from 01Jun2020.**\n(The values may be different for each age group, but we assume they are constant now.)\n\nWhere  \n\\begin{align*}\n& \\kappa \\tau^{-1} = \\alpha_2 = \\cfrac{\\bar{h}\\ \\bar{s}}{N} \\sum_{n=0}^{\\infty}\\cfrac{P_{i}}{L_i} \\\\\n& \\sigma \\tau^{-1} = \\gamma = \\cfrac{1 - \\bar{h}\\ \\bar{s}}{N} \\sum_{n=0}^{\\infty}\\cfrac{P_{i}}{l_i} \\\\\n\\end{align*}\n\n$\\bar{h}$: Rate of I whose immune systems does NOT overcame virus multiplication [-]  \n$\\bar{s}$: Rate of I$^\\star$ who have severe events, including respiratory failure  [-]  \n$L_i$: Inverse of F$^\\star$'s mortality rate for people $i$ years old [min]  \n$l_i$: Inverse of R$^\\star$'s mortality rate for people $i$ years old [min]  \n$P_i$: The number of people $i$ years old [-]  \n$N$: Total population  \n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"med_kappa = ita_scenario.param(\"last\", \"kappa\") * 0.25 / 0.50\nmed_sigma = ita_scenario.param(\"last\", \"sigma\") * (1 - 0.25) / (1 - 0.50)\nita_scenario.add_future_param(start_date=\"01Jun2020\", kappa=med_kappa, sigma=med_sigma)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In three 90 days,"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = ita_scenario.predict(days=90)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Values are here,"},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"df.tail(7).style.background_gradient(axis=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the long-term,"},{"metadata":{"trusted":true},"cell_type":"code","source":"_ = ita_scenario.predict(days=600, min_infected=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Scenario in Japan<a id=\"8\"></a>\nIn this section, we will perform scenario analysis using the records of Japan."},{"metadata":{"trusted":true},"cell_type":"code","source":"jpn_scenario = Scenario(ncov_df, name=\"Japan\", population_dict=population_dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"jpn_scenario.show_record().tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"jpn_scenario.growth_factor()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Trend analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"_ = jpn_scenario.trend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We will find the time-points, assuming that there are three change points.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"jpn_change_points = jpn_scenario.trend(n_points=3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Phase in Japan\nWe will use the change points as the start date of phases. For each phase, will apply SIR-F model. $\\tau$ values will be the same value."},{"metadata":{"trusted":true},"cell_type":"code","source":"jpn_scenario.set_phase(start_dates=jpn_change_points, population=population_dict[\"Japan\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Estimate SIR-F parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"jpn_scenario.estimate(SIRF)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1st phase"},{"metadata":{"trusted":true},"cell_type":"code","source":"jpn_scenario.accuracy_graph(phase_n=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2nd phase"},{"metadata":{"trusted":true},"cell_type":"code","source":"jpn_scenario.accuracy_graph(phase_n=2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3rd phase"},{"metadata":{"trusted":true},"cell_type":"code","source":"jpn_scenario.accuracy_graph(phase_n=3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Compare predicted number of confirmed cases"},{"metadata":{"trusted":true},"cell_type":"code","source":"jpn_scenario.compare_estimated_numbers()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Compare parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"jpn_scenario.show_parameters()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"jpn_scenario.clear_future_param()\njpn_scenario.param_history([\"kappa\", \"rho\", \"sigma\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From 1st phase to 2nd phase, $\\rho$ was increased and $\\sigma$ was decreased."},{"metadata":{},"cell_type":"markdown","source":"## From 1st to 2nd: Why $\\rho$ was increased and $\\sigma$ was decreased?"},{"metadata":{},"cell_type":"markdown","source":"## Why $\\rho$ was increased?\nTokyo 2020 Olympics was postponed until 2021, but $\\rho$ was increasing from 1st phase to 2st phase."},{"metadata":{"trusted":true},"cell_type":"code","source":"jpn_scenario.param(\"2nd\", \"rho\") / jpn_scenario.param(\"1st\", \"rho\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"line_plot(\n    jpn_ncov_df[\"Tested\"], \"Log-scale: Tested cases over time in Japan\",\n    y_logscale=True, y_integer=True, v=jpn_scenario.phase_dict[\"2nd\"][\"start_date\"]\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The trend of the number of PCR-tested cases was not changed."},{"metadata":{},"cell_type":"markdown","source":"Many people went out to hanami from 20mar2020 to 22Mar2020, but this was a temporary episode."},{"metadata":{"trusted":true},"cell_type":"code","source":"df = jpn_pref_df.pivot_table(\n    index=\"Date\", columns=\"Prefecture\", values=\"Positive\", aggfunc=\"last\"\n)\njpn_confirmed_df = df.sort_values(by=df.index[-1], axis=1, ascending=False)\nconfirmed_top = jpn_confirmed_df.columns[0]\nline_plot(\n    jpn_confirmed_df.iloc[:, :10],\n    \"top 10 prefectures in Japan: Confirmed cases over time\",\n    y_integer=True\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most of the cases are in Tokyo or Osaka. Tokyo is the capital city of Japan and the most densely populated area. Osaka is the second. We can assume that high population density makes high value of effective transmission rate $\\beta$, $\\rho$."},{"metadata":{},"cell_type":"markdown","source":"The prefecture where the highest number of confirmed (PCR positive) cases was chronologically changed as follows."},{"metadata":{"trusted":true},"cell_type":"code","source":"df = jpn_confirmed_df.idxmax(axis=1)\ndf = df[df != df.shift()].reset_index()\ndf.columns = [\"Start_date\", \"Where_highest\"]\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here, we will k-means clustering analysis of prefectures based on $\\rho$ and population density.\n<!--Here, we will classify the prefectures based on population density and compare the $\\rho$ values of the groups.-->"},{"metadata":{},"cell_type":"markdown","source":"To be continued."},{"metadata":{},"cell_type":"markdown","source":"## Why $\\sigma$ was decreased?"},{"metadata":{"trusted":true},"cell_type":"code","source":"jpn_scenario.param(\"2nd\", \"sigma\") / jpn_scenario.param(\"1st\", \"sigma\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"line_plot(jpn_ncov_df.drop([\"Tested\"], axis=1), \"Cases over time in Japan\", y_integer=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"line_plot(\n    jpn_ncov_df[\"Hosp_waiting\"], \"Cases who are waiting for hospitalization over time in Japan\",\n    y_integer=True,\n    v=[jpn_scenario.phase_dict[\"2nd\"][\"start_date\"],jpn_scenario.phase_dict[\"3rd\"][\"start_date\"]]\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The number of cases who are waiting for hospitalization was sharply increased after the start date of 23rd phase.  this needs futher investigation."},{"metadata":{},"cell_type":"markdown","source":"## Predict the future with the last parameters"},{"metadata":{},"cell_type":"markdown","source":"In a week,"},{"metadata":{"trusted":true},"cell_type":"code","source":"jpn_scenario.predict(days=7).tail(7).style.background_gradient(axis=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In 30 days,"},{"metadata":{"trusted":true},"cell_type":"code","source":"jpn_scenario.predict(days=30).tail(7).style.background_gradient(axis=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the logn-term,"},{"metadata":{"trusted":true},"cell_type":"code","source":"_ = jpn_scenario.predict(days=1000, min_infected=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Strategy of Japan\nJapan declared a state of emergency for three metropolitan areas (Tokyo/Kanagawa/Saitama/Chiba, Osaka/Hyogo, Fukuoka) on 07Apr2020, but national lockdown will not be done. Japan is mainly taking the following three actions.\n* Physical (social) distancing: to avoid closed spaces, crowd, conversation at close distance\n* Trace the link of patients and give tests on the linked persons preferentially\n* Maintain medical level to increase recovery rate and decrease mortality rate"},{"metadata":{},"cell_type":"markdown","source":"## How to make way by 31May2020 for the number of cases peaking out"},{"metadata":{},"cell_type":"markdown","source":"### The current situation\nUnder the assumtion that the current trend continues, when will the number of currently infected cases peak out?  \nWe can use $R_t$ as the index. When $R_t < 1$, $\\frac{\\mathrm{d}y}{\\mathrm{d}t} < 0$.\n\nThis is because  \n\\begin{align*}\n& \\frac{\\mathrm{d}y}{\\mathrm{d}t}= \\rho (1-\\theta) x y - (\\sigma + \\kappa) y\\\\\n& R_t = \\rho (1 - \\theta) (\\sigma + \\kappa)^{-1}\\\\\n& x \\simeq 1 \\\\\n\\end{align*}\n\nwhere $R_t$ is reproduction number (phase/time-dependent version of $R_0$)."},{"metadata":{},"cell_type":"markdown","source":"$x$ is"},{"metadata":{"trusted":true},"cell_type":"code","source":"1 - jpn_scenario.record_df.iloc[-1, :][\"Confirmed\"] / population_dict[\"Japan\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The current value of $R_t$ is"},{"metadata":{"trusted":true},"cell_type":"code","source":"jpn_scenario.clear_future_param()\njpn_scenario.param(\"last\", \"Rt\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The number of currently infected cases will peak on"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = jpn_scenario.predict(days=1000, show_figure=False)\ndf[\"Infected\"].idxmax().strftime(\"%d%b%Y\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### How to set $R_t < 1$ by 31May2020\n$R_t < 1$ when $\\rho$ is under"},{"metadata":{"trusted":true},"cell_type":"code","source":"current_rho = jpn_scenario.param(\"last\", \"rho\")\nlimit_rho = current_rho / jpn_scenario.param(\"last\", \"Rt\") * 1.0\nlimit_rho","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here, we assume $\\rho$ is"},{"metadata":{"trusted":true},"cell_type":"code","source":"beta_inv = math.ceil(jpn_scenario.param(\"last\", \"tau\") / 24 / 60 / limit_rho) + 1\ntarget_rho = jpn_scenario.param(\"last\", \"tau\") / 24 / 60 / beta_inv\ntarget_rho","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_rho < limit_rho","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Set $\\rho$ with the assumtion that $\\rho$ will gradually (log-scale) decrease,"},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"jpn_scenario.clear_future_param()\n_ = jpn_scenario.add_future_param_gradually(\"25Apr2020\", \"31May2020\", \"rho\", current_rho, target_rho)\njpn_scenario.show_parameters()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"$R_t$ will be"},{"metadata":{"trusted":true},"cell_type":"code","source":"line_plot(\n    jpn_scenario.show_parameters().set_index(\"start_date\")[\"Rt\"],\n    title=\"Rt over time\", xlabel=\"start_date\", ylabel=\"\", h=1.0, math_scale=False\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Trajectory of the number of cases and peak date will be"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = jpn_scenario.predict(days=100)\ndf[\"Infected\"].idxmax().strftime(\"%d%b%Y\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Change factor of $\\beta$\nJapan focuses on the rate of people in closed spaces/crowd. We need to avoid business offices, meeting spaces, entertainment distincts, shopping malls etc.\n\nHere, we assume that $\\beta=\\tau^{-1}\\rho$ is\n\\begin{align*}\n& \\beta_{(p)} = \\overline{\\beta}(1-p) + \\beta^{\\ast}p\n\\end{align*}\nwhere  \n$\\overline{\\beta}$: effective contact rate in average [1/min]  \n$\\beta^{\\ast}$: effective contact rate in closed spaces/crowd [1/min]  \n$p$: rate of people in closed spaces/crowd [-]"},{"metadata":{},"cell_type":"markdown","source":"### Max value of $p$ to meet the goal"},{"metadata":{},"cell_type":"markdown","source":"@ClusterJapan (expert team to prevent COVID-19 outbreak in Japan) analysed link of patients and summarized as follows. This is from [Twitter @ClusterJapan on 11Apr2020](https://twitter.com/ClusterJapan/status/1248884086581514242?s=20) (in Japanese).\n* 80% of patients have less than 1 secondary infected patient\n* 10% of patients have 8-12 secondary patients and they are in closed space/crowd"},{"metadata":{},"cell_type":"markdown","source":"As my personal point of view, $\\beta^{\\ast}$ can be estimated as $\\beta^{\\ast} = 10 \\times \\overline{\\beta}$.  \nThis means\n\\begin{align*}\n& \\beta_{(p)} = \\overline{\\beta}(1+9P)\n\\end{align*}\n\n$P$ is the rate of people in the spaces where effcetive contact rate is 10 times as the average value."},{"metadata":{},"cell_type":"markdown","source":"With the assumption that $\\overline{\\beta}$ is constant,  \n\\begin{align*}\n& \\cfrac{\\beta_{before}}{1+9P_{before}} = \\cfrac{\\beta_{after}}{1+9P_{after}}\n\\end{align*}\n(\"Before\" means \"before the national emergency declaration on 06Apr2020.)"},{"metadata":{},"cell_type":"markdown","source":"Then,\n\\begin{align*}\n& \\cfrac{1+9P_{after}}{1+9P_{before}} = \\cfrac{\\rho_{after}}{\\rho_{before}}\n\\end{align*}"},{"metadata":{},"cell_type":"markdown","source":"So,\n\\begin{align*}\n& P_{after} = \\frac{1}{9}\\left[ \\cfrac{\\rho_{after}}{\\rho_{before}}(1+9P_{before}) - 1 \\right]\n\\end{align*}"},{"metadata":{},"cell_type":"markdown","source":"$\\cfrac{\\rho_{after}}{\\rho_{before}}$ is"},{"metadata":{"trusted":true},"cell_type":"code","source":"target_rho / jpn_scenario.param(\"last\", \"rho\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can estimate $P_{before}$ with go-out table.\n* Schools were closed\n* 10.6% of people work remotely because\n  - 5.6% of respondents work remotely (cf.1),\n  - total number of respondents is 23,992,701 (cf.2),\n  - 2,651,272 respondents are working in service industry (cf.2),\n  - 2,128,322 respondents are medical personnel or care worker (cf.2),\n  - 7,928,268 respondents are office workers or workers of logistics companies (cf.2).\n  - The number of days the respondent work remotely is not known.\n* As usual, 75% of people are in closed space/crowded (CC) area: this is just my point of view, I'm gathering information.\n* Compared to baseline, 25% reduction was shown in Retail & recreation area: cf.3\n\ncf.1: (In Japanese) [Report of 1st survey by Ministry of Health, Labor and Welfare & LINE Corporation](https://www.mhlw.go.jp/stf/newpage_10695.html)  \ncf.2: (In Japanese) [Detailed report of 1st survey by Ministry of Health, Labor and Welfare & LINE Corporation](https://www.mhlw.go.jp/stf/newpage_10798.html)\nMovility reports: [COVID-19 Community Mobility Reports in Japan on 05Apr2020](https://www.gstatic.com/covid19/mobility/2020-04-05_JP_Mobility_Report_en.pdf)"},{"metadata":{"trusted":true},"cell_type":"code","source":"remote_rate = round(0.056 * 23992701 / (2651272 + 2128322 + 7928268), 3)\nremote_rate","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = go_out(\"Japan\")\ndf[\"School\"] = 0\ndf[\"Remote\"] = df[\"Office\"] * remote_rate\ndf[\"Workplace\"] = df[\"Office\"] - df[\"Remote\"]\ndf[\"Others_CC\"] = df[\"Others\"] * 0.75 * (1 - 0.25)\ndf[\"Others\"] = df[\"Others\"] - df[\"Others_CC\"]\ndf = pd.concat([df[\"Portion\"], df.loc[:, ~df.columns.isin([\"Portion\"])]], axis=1)\ndf = df.drop(\"Office\", axis=1)\njpn_go_df = df.copy()\njpn_go_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"$P_{before}$ can be estimated as"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = jpn_go_df.copy()\np_before = (df[[\"School\", \"Workplace\", \"Others_CC\"]].sum(axis=1) * df[\"Portion\"]).sum() / 7\np_before","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\\begin{align*}\n& P_{after} = \\frac{1}{9}\\left[ \\cfrac{\\rho_{after}}{\\rho_{before}}(1+9P_{before}) - 1 \\right]\n\\end{align*}"},{"metadata":{},"cell_type":"markdown","source":"To meet the goal, $P_{after}$ should be under"},{"metadata":{"trusted":true},"cell_type":"code","source":"def calc_target_p(rho_before, rho_after, p_before):\n    return (rho_before / rho_after * (1 + 9 * p_before) - 1) / 9","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_p = calc_target_p(target_rho, jpn_scenario.param(\"last\", \"rho\"), p_before)\ntarget_p","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Max value of go-out index to meet the goal"},{"metadata":{},"cell_type":"markdown","source":"## How to prevent overwhelming medical system\nWe need to flatten the curve of currently infected cases so that prevent overwhelming medical system. The peak value of currently infected cases must not exceed the number of hospital capacity."},{"metadata":{},"cell_type":"markdown","source":"### How many medical staffs, ICU beds, hospitals and other sites we have"},{"metadata":{},"cell_type":"markdown","source":"### Severity of the currently infected patients\nWe categoize the patient with severity as the following.\n* Grade1: Asymptomtic or mild symptoms, need self-quarantine at home or hotel\n* Grade2: Severity is unknown and need hospitalization for diagnosis\n* Grade3: Severe and need ICU"},{"metadata":{"_kg_hide-input":false,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"jpn_ncov_df.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Proportion of each grade is as below."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df = jpn_ncov_df.copy()\ndf[\"Grade1\"] = df[\"Asymptomatic\"] + df[\"Hosp_mild\"]\ndf[\"Grade2\"] = df[\"Sym-unknown\"] + df[\"Hosp_unknown\"] + df[\"Hosp_waiting\"]\ndf[\"Grade3\"] = df[\"Hosp_severe\"]\ndf = df.loc[:, [\"Grade1\", \"Grade2\", \"Grade3\"]]\ndf = df.apply(lambda x: x / np.sum(x), axis=1)\ngrade_df = df.copy()\ngrade_df.tail()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"line_plot(grade_df, \"Proportion of each grade over time\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grade_df.plot.kde(title=\"Kernel density estiomation of protion of each grade\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grade_df.describe().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grade_dict = grade_df.median().to_dict()\ngrade_dict","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Max value of $\\gamma$ to meet the goal"},{"metadata":{},"cell_type":"markdown","source":"### Are new medicines are effective?"},{"metadata":{},"cell_type":"markdown","source":"# Scenario in India<a id=\"12\"></a>\nIn this section, we will perform scenario analysis using the records of India."},{"metadata":{"trusted":true},"cell_type":"code","source":"ind_scenario = Scenario(ncov_df, name=\"India\", population_dict=population_dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ind_scenario.show_record().tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ind_scenario.growth_factor()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Trend analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"_ = ind_scenario.trend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We will find the time-points, assuming that there are two change points.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"ind_change_points = ind_scenario.trend(n_points=2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Phases in India\nWe will use the change points as the start date of phases. For each phase, will apply SIR-F model. $\\tau$ values will be the same value."},{"metadata":{"trusted":true},"cell_type":"code","source":"ind_scenario.set_phase(start_dates=ind_change_points)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ind_scenario.estimate(SIRF)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1st phase"},{"metadata":{"trusted":true},"cell_type":"code","source":"ind_scenario.accuracy_graph(phase_n=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2nd phase"},{"metadata":{"trusted":true},"cell_type":"code","source":"ind_scenario.accuracy_graph(phase_n=2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Compare predicted number of confirmed cases"},{"metadata":{"trusted":true},"cell_type":"code","source":"ind_scenario.compare_estimated_numbers(phases=[\"1st\", \"2nd\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Compare parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"ind_scenario.show_parameters()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ind_scenario.param_history([\"kappa\", \"rho\", \"sigma\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predict the future with the last parameters"},{"metadata":{},"cell_type":"markdown","source":"In a week,"},{"metadata":{"trusted":true},"cell_type":"code","source":"ind_scenario.predict(days=7).tail(7).style.background_gradient(axis=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In 30 days,"},{"metadata":{"trusted":true},"cell_type":"code","source":"ind_scenario.predict(days=30).tail(7).style.background_gradient(axis=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the long-term,"},{"metadata":{"trusted":true},"cell_type":"code","source":"_ = ind_scenario.predict(days=1000, min_infected=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Scenario in USA<a id=\"14\"></a>\nIn this section, we will perform scenario analysis using the records of USA (United States of America, US)."},{"metadata":{"trusted":true},"cell_type":"code","source":"usa_scenario = Scenario(ncov_df, name=\"US\", population_dict=population_dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"usa_scenario.show_record().tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"usa_scenario.growth_factor()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Trend analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"_ = usa_scenario.trend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We will find the time-points, assuming that there are three change points.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"usa_change_points = usa_scenario.trend(n_points=2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Phases in USA\nWe will use the change points as the start date of phases. For each phase, will apply SIR-F model. $\\tau$ values will be the same value."},{"metadata":{"trusted":true},"cell_type":"code","source":"usa_scenario.set_phase(start_dates=usa_change_points)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"usa_scenario.estimate(SIRF)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1st phase"},{"metadata":{"trusted":true},"cell_type":"code","source":"usa_scenario.accuracy_graph(phase_n=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2nd phase"},{"metadata":{"trusted":true},"cell_type":"code","source":"usa_scenario.accuracy_graph(phase_n=2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Compare predicted number of confirmed cases"},{"metadata":{"trusted":true},"cell_type":"code","source":"usa_scenario.compare_estimated_numbers(phases=[\"1st\", \"2nd\", \"3rd\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Compare parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"usa_scenario.show_parameters()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"usa_scenario.param_history([\"kappa\", \"rho\", \"sigma\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predict the future with the last parameters"},{"metadata":{},"cell_type":"markdown","source":"In a week,"},{"metadata":{"trusted":true},"cell_type":"code","source":"usa_scenario.predict(days=7).tail(7).style.background_gradient(axis=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In 30 days,"},{"metadata":{"trusted":true},"cell_type":"code","source":"usa_scenario.predict(days=30).tail(7).style.background_gradient(axis=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the long-term,"},{"metadata":{"trusted":true},"cell_type":"code","source":"_ = usa_scenario.predict(days=1000, min_infected=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c6031338-1749-4ecc-a8c7-86576a7abbf0","_cell_guid":"8a74f1df-afc5-47a1-8a81-e2cdeceea031","trusted":true},"cell_type":"markdown","source":"# Remarks<a id=\"9\"></a>\nThank you for reading!  \nLisphilar from Japan"},{"metadata":{},"cell_type":"markdown","source":"## Conclusion\n(Will be updated)"},{"metadata":{},"cell_type":"markdown","source":"## Acknowledgement<a id=\"3\"></a>\n### Datasets in kaggle\n* The number of cases: [Novel Corona Virus 2019 Dataset](https://www.kaggle.com/sudalairajkumar/novel-corona-virus-2019-dataset)\n* Total population: [covid19-global-forecasting-locations-population](https://www.kaggle.com/dgrechka/covid19-global-forecasting-locations-population/metadata)\n* Population pyramid: [Population Pyramid 2019](https://www.kaggle.com/hotessy/population-pyramid-2019)\n* Mesaures in each country: [COVID-19 containment and mitigation measures](https://www.kaggle.com/paultimothymooney/covid19-containment-and-mitigation-measures)\n* Measures in Italy: [COVID-19 Prevention in Italy](https://www.kaggle.com/marcoferrante/covid19-prevention-in-italy)\n\n#### Datasets created by the notebook auther\n[COVID-19 dataset in Japan](https://www.kaggle.com/lisphilar/covid19-dataset-in-japan)\n* The number of cases in Japan: PCR-tested, with/without symptoms, mild/severe, hospitalized or not etc.\n* The number of cases at prefecture level: PCR-test, confirmed, discharged, fatal\n* Basic information of each prefecture: Population, area, the number of beds\n\nData is from HP of Ministry of Health, Labour and Welefare, Japan:  \n[Ministry of Health, Labour and Welefare HP (in Japanese)](https://www.mhlw.go.jp/)  \n[Ministry of Health, Labour and Welefare HP (in English)](https://www.mhlw.go.jp/english/)  \n[COVID-19 Japan   (CC BY)](https://code4sabae.github.io/bedforinfection/)  \n[Wikipedia](https://ja.wikipedia.org/wiki/)  "},{"metadata":{},"cell_type":"markdown","source":"### Data provided by kagglers as a comment on this notebook\n* The number of days persons of each age group usually go out provided by [Marco Ferrante](https://www.kaggle.com/marcoferrante)"},{"metadata":{},"cell_type":"markdown","source":"### External resources\n* Population pyramid: [PopulationPyramid.net](https://www.populationpyramid.net/) licensed under [Creative Commons license CC BY 3.0](https://creativecommons.org/licenses/by/3.0/)\n* Movility report in Italy: [COVID-19 Mobility Monitoring project](https://covid19mm.github.io/) licenced under [Creative Commons license CC BY 4.0](https://creativecommons.org/licenses/by/4.0/)\n* Movility reports: [Google: COVID-19 Community Mobility Reports](https://www.google.com/covid19/mobility/)\n* Gomperz curve: [Jia, Lin, et al. \"Prediction and analysis of Coronavirus Disease 2019.\" arXiv preprint arXiv:2003.05447 (2020).](https://arxiv.org/ftp/arxiv/papers/2003/2003.05447.pdf)\n\n\n(In Japanese)\n* Medical package insert of AVIGAN (In Japanese): [KEGG database \"AVIGAN\"](https://www.kegg.jp/medicus-bin/japic_med?japic_code=00066852)\n* Mobility: [Report of 1st survey by Ministry of Health, Labor and Welfare & LINE Corporation](https://www.mhlw.go.jp/stf/newpage_10695.html)  \n* Mobility: [Detailed report of 1st survey by Ministry of Health, Labor and Welfare & LINE Corporation](https://www.mhlw.go.jp/stf/newpage_10798.html)\n* @ClusterJapan (expert team to prevent COVID-19 outbreak in Japan) comments: [Twitter @ClusterJapan on 11Apr2020](https://twitter.com/ClusterJapan/status/1248884086581514242?s=20)\n* Gomperz curve: [(In Japanese) 3](https://qiita.com/BMJr/items/4e2782e8f1d3c1db6801)"},{"metadata":{},"cell_type":"markdown","source":"### References and reading materials\n\n#### Papers\n* Basic reproduction number: [Van den Driessche, P., & Watmough, J. (2002).](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6002118/)\n* Curve fitting with Logistic function and Gompertz function: [Jia, Lin, et al., 2020.](https://arxiv.org/ftp/arxiv/papers/2003/2003.05447.pdf)\n* S-R place: [Balkew, Teshome Mogessie, \"The SIR Model When S(t) is a Multi-Exponential Function.\" (2010).Electronic Theses and Dissertations.Paper 1747](https://dc.etsu.edu/cgi/viewcontent.cgi?article=3102&context=etd)\n\n#### Kaggle\nCurve fitting with Gamma PDF etc. by [Bill Holst](https://www.kaggle.com/wjholst). \n* [COVID-19 Growth Patterns in Critical Countries](https://www.kaggle.com/wjholst/covid-19-growth-patterns-in-critical-countries#Gaussian-Approximation-of-Active-Cases)\n* [COVID-19 - Growth of Virus in Specific Countries](https://www.kaggle.com/wjholst/covid-19-growth-of-virus-in-specific-countries#Gaussian-Approximation-of-Active-Cases)\n* [Prediction With a Gamma PDF](https://www.kaggle.com/wjholst/prediction-with-a-gamma-pdf)\n\n#### YouTube\n* Growth Factor: [YouTube \"Exponential growth and epidemics\"](https://www.youtube.com/watch?v=Kas0tIxDvrg)\n* Physical distancing (social distancing): [YouTube \"Simulating an epidemic\"](https://www.youtube.com/watch?v=gxAaO2rsdIs)\n* $\\Delta$Confirmed vs. Confirmed plot: [YouTube: How To Tell If We're Beating COVID-19](https://www.youtube.com/watch?v=54XLXg4fYsc)\n\n#### Other online resources\n* Simple SIR model: [The SIR epidemic model](https://scipython.com/book/chapter-8-scipy/additional-examples/the-sir-epidemic-model/)\n* SEIR model: [Introduction to SEIR model Models](http://indico.ictp.it/event/7960/session/3/contribution/19/material/slides/)\n* Basic reproduction number: [Estimating the Impact of a Pathogen via Monte Carlo Simulation](https://towardsdatascience.com/infection-modeling-part-1-87e74645568a)\n* RMSLE score: [Whats the Difference Between RMSE and RMSLE?](https://medium.com/analytics-vidhya/root-mean-square-log-error-rmse-vs-rmlse-935c6cc1802a)\n"},{"metadata":{},"cell_type":"markdown","source":"## Change log<a id=\"11\"></a>"},{"metadata":{},"cell_type":"markdown","source":"### In Feb2020\n * 13Feb2020: SIR model\n * 15Feb2020: SIR-D model\n * 22Feb2020: SIR-F model\n * 23Feb2020: Changed the dataset from 2019_ncov_data.csv to covid_19_data.csv\n * 23Feb2020: $\\tau$ was fixed as \"1 day\" because the time format of ObservationDate is MM/DD/YYYY\n * 23Feb2020: SIR-F model with other countries\n * 23Feb2020: How to minimize the damage (Change of parameter, Vacctination)\n * 24Feb2020: Use $\\tau$ again"},{"metadata":{},"cell_type":"markdown","source":"### In Mar2020\n * 01Mar2020: $\\tau$ definition was changed. $1\\leq \\tau \\mathrm{[hour]} \\leq 24$ $\\to$ $1\\leq \\tau \\mathrm{[min]} \\leq 1440$ \n * 01Mar2020: Added \"Test of hyperparameter optimization using example data\" in SIR model section\n * 02Mar2020: Analysis of Linelist (estimation of Effective contact/Recovery/Death rate using case reports)\n * 03Mar2020: Trend analysis\n * 03Mar2020: Update estimator error function; Exponential Weighted Moving Average (span=14days) of |observed - estimated|\n * 04Mar2020: \"Analysis of Linelist\" was moved to [EDA of linelist](https://www.kaggle.com/lisphilar/eda-of-linelist?scriptVersionId=29640733#Remarks)\n * 04Mar2020: Data in Hubei and China will be analysed in another notebook. Please refer to [Data in China with SIR model](https://www.kaggle.com/lisphilar/data-in-china-with-sir-model?scriptVersionId=29646940).\n * 06Mar2020: Random seed was fixed as 2019\n * 06Mar2020: Update estimator error function; Weighted Average of |Exponential Weighted Moving Average (span=14days) of observed - estimated|\n * 07Mar2020: Update estimator error function; Total population $\\times$ Wighted Average of |observed - estimated| with step number t\n * 07Mar2020: Priorities of variables in estimator error function was set as $(x, y, z, w) = (1, 10, 10, 1)$ in SIR-F model.\n * 09Mar2020: Update estimator error function; $(\\mathrm{Population})^2$ $\\times$ (Wighted Average of |observed - estimated|/[observed $\\times$ Population + 1] with step number t)\n * 09Mar2020: Priorities of variables in estimator error function were set as $(x, y, z, w) = (1, 10, 10, 2)$ in SIR-F model.\n * 11Mar2020: Update model.param_dict(); each parametor range was limited to 30%-70% quantiles of the estimated values ($\\frac{\\mathrm{d}z}{\\mathrm{d}t}\\left(\\frac{1}{y}\\right)$ for $\\sigma$) of training dataset.\n * 12Mar2020: Update model.param_dict(); each parameter range was limited to 5%-95% quantiles\n * 12Mar2020: Detailed scenario analysis. Thank you, Marco Ferrante!\n * 13Mar2020: Update model.param_dict(); each parameter range was limited to 0%-100% quantiles\n * 13Mar2020: Update \"Detailed scenario analysis\" > \"Real factors of effective contact rate $\\beta$\"\n * 14Mar2020: Update model.param_dict(); rho/sigma range was limited to 30%-70% quantiles of their estimated values\n * 14Mar2020: Applied trend analysis on country level data to use only a part of records for estimation\n * 14Mar2020: Recovered without confirmation was added to \"Real factors of effective contact rate $\\beta$\"\n * 15Mar2020: Merge \"How to minimize the damage (Change of parameter, Vacctination)\" with \"Scenario analysis\" section\n * 15Mar2020: Update Estimator, int to np.int. Thank you Enrico Papalini!\n * 15Mar2020: Update Estimator, some parameters can be fixed. Some of SIR parameters can be applied to SIR-F model.\n * 17Mar2020: The number of exposed cases and waiting cases\n * 17Mar2020: Update Scenario analysis\n * 18Mar2020: Scenario analysis in Italy\n * 19Mar2020: Estimation of new drugs effect in \"Scenario analysis in Italy\" section\n * 29Mar2020: Grouping of countries by growth factor\n * 29Mar2020: Update \"Scenario in Italy\" section to include confirmed national lockdown effect"},{"metadata":{},"cell_type":"markdown","source":"### In Apr2020\n * 05Apr2020: Update simulation() fucntion, dense_ouput=False\n * 05Apr2020: Create Scenario() class\n * 06Apr2020: Update Scenario() class to reduce running time\n * 11Apr2020: Italy entered 4th phase\n * 11Apr2020: Add \"How to make way by 31May2020 for the number of cases peaking out\" in Japan\n * 13Apr2020: \"excluded_places\" was used for SEWIR-F and showed incorrected graph in the previous versions. Replaced with \"places\"\n * 17Apr2020: Prepare the dataset in Japan"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}