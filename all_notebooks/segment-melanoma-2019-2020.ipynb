{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"!pip show tensorflow","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!pip install git+https://github.com/tensorflow/examples.git\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nimport cv2\nimport math\nimport time\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm_notebook as tqdm\nfrom kaggle_datasets import KaggleDatasets\nfrom tensorflow_examples.models.pix2pix import pix2pix\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.models import Model,Sequential\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras import initializers, layers\nfrom kaggle_datasets import KaggleDatasets\nimport pickle\nimport os\nimport glob\nimport matplotlib.pyplot as plt\n\n# f= open(\"guru99.txt\",\"w+\")\n# for i in range(10):\n#      f.write(\"This is line %d\\r\\n\" % (i+1))\n\nprint(\"start\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"AUTO = tf.data.experimental.AUTOTUNE\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy()\n    \nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SEED = 42\nSIZE = [128,128]\n# \nINPUT_SHAPE = (128, 128, 3)\n\nnp.set_printoptions(threshold=np.inf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def seed_everything(SEED):\n    np.random.seed(SEED)\n    tf.random.set_seed(SEED)\n\nseed_everything(SEED)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef _Float_feature(value):\n    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n\n\ndef _bytes_feature(value):\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef _int64_feature(value):\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n\ndef write_melanoma2020_input_tfrecords_file( out_path, images,image_names, labels=None) -> None:\n    if labels != None:\n        assert len(images) == len(labels)\n    assert len(images) == len(image_names)\n#     options=tf.io.TFRecordOptions(compression_type=\"GZIP\",compression_level=3,mem_level=3)\n    with tf.io.TFRecordWriter(out_path) as writer:\n            for i in range(len(images)):\n                img = tf.cast(images[i]*255, tf.uint8)\n                img_bytes = tf.image.encode_png(img).numpy()\n                image_name = image_names[i]\n                if labels!=None:\n                    label = labels[i]\n                    data = {'image': _bytes_feature(img_bytes), 'target': _int64_feature(label),'image_name': _bytes_feature(image_name)}\n                else:\n                    data = {'image': _bytes_feature(img_bytes), 'image_name': _bytes_feature(image_name)}   \n                feature = tf.train.Features(feature=data) \n                example = tf.train.Example(features=feature) \n                serialized = example.SerializeToString() \n                writer.write(serialized)  \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def decode_image(image):\n    image = tf.image.decode_jpeg(image, channels=3) \n    image = tf.cast(image, tf.float32)/255.0\n    image = tf.reshape(image, [*SIZE, 3])\n    return image\n\ndef parse_example_melanoma(example,labeled):  \n    if labeled:\n       LABELED_TFREC_FORMAT ={\n         \"image\": tf.io.FixedLenFeature([], tf.string),\n         \"target\": tf.io.FixedLenFeature([], tf.int64),\n         \"image_name\": tf.io.FixedLenFeature([], tf.string) }\n    else:\n       LABELED_TFREC_FORMAT ={\n         \"image\": tf.io.FixedLenFeature([], tf.string),\n         \"image_name\": tf.io.FixedLenFeature([], tf.string) } \n    parsed_example = tf.io.parse_single_example(example,LABELED_TFREC_FORMAT)\n    image = decode_image(parsed_example['image'])\n    image_name = parsed_example['image_name']\n    if labeled:\n        label = tf.cast(parsed_example['target'], tf.int64)\n        return (image,image_name,label)\n    else:\n        return (image,image_name)\n\ndef load_dataset_melanoma(filenames,labeled=False, ordered=True):\n    ignore_order = tf.data.Options()\n    if not ordered:\n        ignore_order.experimental_deterministic = False\n    parse_function = lambda x: parse_example_melanoma(example=x,labeled=labeled)\n    return (tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO) \n              .with_options(ignore_order)\n               .map(parse_function, num_parallel_calls=AUTO))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_images(np_images, titles = [], columns = 3, figure_size = (24, 15)):\n    count = len(np_images)\n    rows = math.ceil(count / columns)\n\n    fig = plt.figure(figsize=figure_size)\n    subplots = []\n    for index in range(count):\n        subplots.append(fig.add_subplot(rows, columns, index + 1))\n        if len(titles):\n            subplots[-1].set_title(str(titles[index]))\n        plt.imshow(np_images[index])\n\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_segmentation_unet_model():\n    base_model = tf.keras.applications.MobileNetV2(\n        input_shape=[INPUT_SHAPE[0], INPUT_SHAPE[1], INPUT_SHAPE[2]], include_top=False)\n\n    # Use the activations of these layers\n    layer_names = [\n        'block_1_expand_relu',  # 64x64\n        'block_3_expand_relu',  # 32x32\n        'block_6_expand_relu',  # 16x16\n        'block_13_expand_relu',  # 8x8\n        'block_16_project',  # 4x4\n    ]\n    layers = [base_model.get_layer(name).output for name in layer_names]\n\n    # Create the feature extraction model\n    down_stack = tf.keras.Model(inputs=base_model.input, outputs=layers)\n\n    down_stack.trainable = False\n    up_stack = [\n        pix2pix.upsample(512, 3),  # 4x4 -> 8x8\n        pix2pix.upsample(256, 3),  # 8x8 -> 16x16\n        pix2pix.upsample(128, 3),  # 16x16 -> 32x32\n        pix2pix.upsample(64, 3),  # 32x32 -> 64x64\n    ]\n\n    def unet_model(output_channels):\n        inputs = tf.keras.layers.Input(shape=[INPUT_SHAPE[0],INPUT_SHAPE[1], INPUT_SHAPE[2]])\n        x = inputs\n\n        # Downsampling through the model\n        skips = down_stack(x)\n        x = skips[-1]\n        skips = reversed(skips[:-1])\n\n        # Upsampling and establishing the skip connections\n        for up, skip in zip(up_stack, skips):\n            x = up(x)\n            concat = tf.keras.layers.Concatenate()\n            x = concat([x, skip])\n\n        # This is the last layer of the model\n        last = tf.keras.layers.Conv2DTranspose(\n            output_channels, 3, strides=2,\n            padding='same')  # 64x64 -> 128x128\n\n        x = last(x)\n\n        return tf.keras.Model(inputs=inputs, outputs=x)\n\n    model = unet_model(INPUT_SHAPE[2])\n    model.compile(optimizer='adam',\n                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n                  metrics=['accuracy'])\n    return model\n\nsegmentation_model = get_segmentation_unet_model()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_final_image(main_images, predict_images):\n    predict_images=np.logical_not(predict_images)\n#     print(\"result:\",predict_images.shape)\n\n# Return images that are not segmented well enough\n    zero_counts = np.count_nonzero(predict_images,(1,2))\n#     print(\"Zeros\",zero_counts.shape,zero_counts)\n    for i in range(0,zero_counts.shape[0]):\n        if zero_counts[i]<400 :\n#             print(\"Wrng \",i,zero_counts[i])\n#             plot_images(np.reshape(main_images[i],(1,128,128,3)))\n#             plot_images(np.reshape(predict_images[i],(1,128,128)))\n            predict_images[i]=np.ones((predict_images.shape[1],predict_images.shape[2]))\n    \n    reshaped_masks = np.reshape(predict_images,(main_images.shape[0],main_images.shape[1],main_images.shape[2],1))\n    results = main_images * np.tile(reshaped_masks,(1,1,3))\n    return results\n\ndef segment_image(input_imgs):\n    pred_masks= segmentation_model.predict(input_imgs)\n    pred_masks = tf.argmax(pred_masks, axis=-1)\n    return create_final_image(input_imgs,pred_masks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DATASET = 'melanoma-128x128'\nGCS_PATH = KaggleDatasets().get_gcs_path(DATASET)\ntrain_filenames = tf.io.gfile.glob(GCS_PATH + '/train*.tfrec')\ntest_filenames = tf.io.gfile.glob(GCS_PATH + '/test*.tfrec')\nDATASET = 'isic2019-128x128'\nGCS_PATH = KaggleDatasets().get_gcs_path(DATASET)\ntrain2019_filenames = tf.io.gfile.glob(GCS_PATH + '/train*.tfrec')\n\nsegmentation_model.load_weights(\"/kaggle/input/unet-segment-weights/weights\")\n\ndef segment_save(filenames, tf_record_name,labeled=True):\n    segment_batch_size = 128\n    index = 0\n    tf_record_count = len(filenames)\n    for tf_record_number in range(0, tf_record_count):\n        print(\"tf_record_number\" ,tf_record_number, \"from\", tf_record_count - 1)\n        dataset = load_dataset_melanoma(filenames[tf_record_number],labeled=labeled).batch(segment_batch_size)\n        segmented_images = []\n        segmented_lables = []\n        segmented_image_names =[]\n        batch_number =0\n        for item in dataset:\n            if labeled:\n                (images,image_names,labels)=item\n                labels=labels.numpy()\n            else:\n                (images,image_names)=item\n            image_names = image_names.numpy()\n            batch_number +=1 \n            segment_result = segment_image(images)\n            segment_result = images\n            segment_result_array = np.split(segment_result, images.shape[0])\n            for image_number in range(0, images.shape[0]):\n                segmented_images.append(np.squeeze(segment_result_array[image_number], 0))\n                if labeled:\n                    segmented_lables.append(labels[image_number])\n                segmented_image_names.append(image_names[image_number])\n        save_path = tf_record_name + str(index).zfill(2) + \"-\" + str(len(segmented_images)) + \".tfrec\"\n        if labeled:\n            write_melanoma2020_input_tfrecords_file(save_path, segmented_images,segmented_image_names, segmented_lables)\n        else:\n            write_melanoma2020_input_tfrecords_file(save_path, segmented_images,segmented_image_names)\n        index += 1\n        \n\nsegment_save(train_filenames, \"train_2020_\")\nsegment_save(train2019_filenames, \"train_2019_\")\nsegment_save(test_filenames, \"test_\",False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# !rm  /kaggle/working/data_2020.tar.gz\n# !tar -zcvf data_2020.tar.gz train_2020*\n# !rm /kaggle/working/train_2020*.tfrec\n\n# !rm  /kaggle/working/data_2019.tar.gz\n# !tar -zcvf data_2019.tar.gz train_2019*\n# !rm /kaggle/working/train_2019*.tfrec\n\n# !rm  /kaggle/working/data_test_2020.tar.gz\n# !tar -zcvf data_test_2020.tar.gz test*\n# !rm /kaggle/working/data_test_2020*.tfrec\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n<a href=\"./data_2019.tar.gz\"> Download File 2019 Train</a>\n\n<a href=\"./data_2020.tar.gz\"> Download File 2020 Train</a>\n\n<a href=\"./data_test_2020.tar.gz\"> Download File 2020 Test</a>\n\n\n"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}