{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly as py\nimport plotly.graph_objs as go\nimport seaborn as sns\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"test=pd.read_csv('../input/hr-analytics-job-change-of-data-scientists/aug_test.csv')\ntrain=pd.read_csv('../input/hr-analytics-job-change-of-data-scientists/aug_train.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First we are going to check our training and testing datasets:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Features:\n\n* enrollee_id : Unique ID for candidate\n* city: City code\n* city_ development _index : Developement index of the city (scaled)\n* gender: Gender of candidate\n* relevent_experience: Relevant experience of candidate\n* enrolled_university: Type of University course enrolled if any\n* education_level: Education level of candidate\n* major_discipline :Education major discipline of candidate\n* experience: Candidate total experience in years\n* company_size: No of employees in current employer's company\n* company_type : Type of current employer\n* lastnewjob: Difference in years between previous job and current job\n* training_hours: training hours completed\n* target: 0 – Not looking for job change, 1 – Looking for a job change"},{"metadata":{"trusted":true},"cell_type":"code","source":"print (\"The training data set has {a} rows and {b} columns\".format(a=train.shape[0], b=train.shape[1]))\nprint (\"The testing data set has {a} rows and {b} columns\".format(a=test.shape[0], b=test.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Cleaning =================================================="},{"metadata":{},"cell_type":"markdown","source":"Lets check how many NAN values do we have and how to deal with them:"},{"metadata":{"trusted":true},"cell_type":"code","source":"(train.isna().sum()/train.shape[0])*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(test.isna().sum()/test.shape[0])*100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have many NAN values in both training and test datasets. We are going to check the columns with NAN values one by one to see how should we deal with them:\nI am going to start from the columns with the lower number of 'NAN' values:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print (\"we have {} number of 'NAN' values in experinece column\".format (train.experience.isna().sum()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get the 'nan' values from experience column\ntrain[train.experience.isna()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import chi2_contingency\nfor items in list(train.columns):\n    chi_res = chi2_contingency(pd.crosstab(train['experience'], train[items]))\n    print('{} ===> Chi2 Statistic: {}, p-value: {}'.format(items, round(chi_res[0],3), round(chi_res[1], 4)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Based on the p-values, except enrollee_id and training_hours, other features can affect the experience. Hence, chi2 feature selection does not help us. We are going to replace 'nan' values with '<1', as it most probably is zero. "},{"metadata":{"trusted":true},"cell_type":"code","source":"train.experience.fillna('<1', inplace=True)\ntest.experience.fillna('<1', inplace=True)\nprint(\"Null values of test and train data in experience column are {} and {}, respectively\".format(test.experience.isna().sum(), test.experience.isna().sum()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.experience.unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"One last thing before moving to another column, the experience column is 'object' data type. However, we need it as a number so lets change the data type to 'int'. The only problem would be '>20' and '<1' values. We are going to replace them with '21'and '0', respectively. Then will change the data type to 'int'. "},{"metadata":{"trusted":true},"cell_type":"code","source":"test.experience.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.experience[train.experience=='>20']='21'\ntrain.experience[train.experience=='<1']='0'\npd.to_numeric(train.experience)\ntest.experience[test.experience=='>20']='21'\ntest.experience[test.experience=='<1']='0'\npd.to_numeric(test.experience)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now it is time to fill the 'NAN' values of 'enrolled_university' column:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print (\"we have {} number of 'NAN' values in experinece column\".format (train.enrolled_university.isna().sum()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.education_level.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[train.education_level.isna()]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We know that if \"enrolled_university\" is \"no_enrollment\", then the education can be 'Primary School' or 'High School'. Now lets see which one is most dominant:"},{"metadata":{"trusted":true},"cell_type":"code","source":"a=train[(train.enrolled_university=='no_enrollment') & (train.education_level=='High School')].shape [0]\nb=train[(train.enrolled_university=='no_enrollment') & (train.education_level=='Primary School')].shape [0]\nprint(\"number of no_enrollment with High School: {}\".format(a))\nprint(\"number of no_enrollment with High School: {}\".format(b))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, it is more likely to have \"High School\" than \"Primary School\" education for no_enrollment."},{"metadata":{"trusted":true},"cell_type":"code","source":"train.education_level[(train.enrolled_university=='no_enrollment') & (train.education_level.isna())] = \"High School\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[train.education_level.isna()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.enrolled_university.unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If we have \"Full time course\" or \"Part time course\" in \"enrolled_university\" column, it means we may have \"education_level\" of ['Phd', 'Graduate', or 'Masters' ]"},{"metadata":{"trusted":true},"cell_type":"code","source":"a=train[(train.enrolled_university=='Full time course') & (train.education_level=='Masters')].shape [0]\nb=train[(train.enrolled_university=='Full time course') & (train.education_level=='Phd')].shape [0]\nc=train[(train.enrolled_university=='Full time course') & (train.education_level=='Graduate')].shape [0]\nprint(\"number of 'Full time course' with Masters degree: {}\".format(a))\nprint(\"number of 'Full time course' with PhD degree: {}\".format(b))\nprint(\"number of 'Full time course' with Graduate degree: {}\".format(c))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a=train[(train.enrolled_university=='Part time course') & (train.education_level=='Masters')].shape [0]\nb=train[(train.enrolled_university=='Part time course') & (train.education_level=='Phd')].shape [0]\nc=train[(train.enrolled_university=='Part time course') & (train.education_level=='Graduate')].shape [0]\nprint(\"number of 'Part time course' with Masters degree: {}\".format(a))\nprint(\"number of 'Part time course' with PhD degree: {}\".format(b))\nprint(\"number of 'Part time course' with Graduate degree: {}\".format(c))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.education_level[(train.enrolled_university=='Full time course') & (train.education_level.isna())] = \"Graduate\"\ntrain.education_level[(train.enrolled_university=='Full time course') & (train.education_level.isna())] = \"Graduate\"\ntest.education_level[(test.enrolled_university=='Full time course') & (test.education_level.isna())] = \"Graduate\"\ntest.education_level[(test.enrolled_university=='Full time course') & (test.education_level.isna())] = \"Graduate\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We are going to drop the rest of the 'NAN' values for \"education_level\":"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop((train.education_level[train.education_level.isna()]).index, inplace=True)\ntest.drop((test.education_level[test.education_level.isna()]).index, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, lets check \"enrolled_university\" column:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.enrolled_university.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='enrolled_university', hue='education_level', data=train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As can be seen from the countplot, the most common term in the enrolled_university column is \"no_enrollment\" regardless of education level. Hence, we are going to replace 'NAN' values with \"no_enrollment\"."},{"metadata":{"trusted":true},"cell_type":"code","source":"train.enrolled_university[train.enrolled_university.isna()]=\"no_enrollment\"\ntest.enrolled_university[test.enrolled_university.isna()]=\"no_enrollment\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now trying to replace \"NAN\" values of \"last_new_job\" column:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.last_new_job.unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It has a great chance that the one who has no relevent experience, the difference in years between previous job and current job be 'never'. "},{"metadata":{"trusted":true},"cell_type":"code","source":"train.last_new_job[(train.last_new_job.isna()) & (train.relevent_experience=='No relevent experience')]='never'\ntest.last_new_job[(test.last_new_job.isna()) & (test.relevent_experience=='No relevent experience')]='never'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I am going to drop the remaining 'nan' values."},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop((train.last_new_job[train.last_new_job.isna()]).index, inplace=True)\ntest.drop((test.last_new_job[test.last_new_job.isna()]).index, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.last_new_job[train.last_new_job=='>4']='5'\ntrain.last_new_job[train.last_new_job=='never']='0'\npd.to_numeric(train.last_new_job)\ntest.last_new_job[test.last_new_job=='>4']='5'\ntest.last_new_job[test.last_new_job=='never']='0'\npd.to_numeric(test.last_new_job)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we have 4 columns with a high number of 'nan' values: \"gender\", \"major_discipline\", \"company_size\", and \"company_type\""},{"metadata":{"trusted":true},"cell_type":"code","source":"(train.isna().sum()/train.shape[0])*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train2=train.fillna('nan')\nfig=go.Figure(data=[go.Pie(labels=['Male', 'nan', 'Female', 'Other'], values=train2.gender.value_counts())])\nfig.update_traces( hole= 0.3, hoverinfo='label+percent', textinfo='value', textfont_size=20)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As can be seen from the pie-plot, we are dealing with an extremly unbalanced data. The majority of the data are 'Male', while small percentage are \"Female\" or \"Other\". Now, lets check if this column has a significant effect on \"target\" column or not:"},{"metadata":{"trusted":true},"cell_type":"code","source":"M=train[(train.gender=='Male') & (train.target==1.0)].shape[0]/train[(train.gender=='Male') & (train.target==0.0)].shape[0]\nF=train[(train.gender=='Female') & (train.target==1.0)].shape[0]/train[(train.gender=='Female') & (train.target==0.0)].shape[0]\nO=train[(train.gender=='Other') & (train.target==1.0)].shape[0]/train[(train.gender=='Other') & (train.target==0.0)].shape[0]\nN=train[(train.gender.isna()) & (train.target==1.0)].shape[0]/train[(train.gender.isna()) & (train.target==0.0)].shape[0]\n# if we add all'nan' values to 'Male'\nM_and_NAN=train[((train.gender=='Male') | (train.gender.isna())) & (train.target==1.0)].shape[0]/train[((train.gender=='Male') | (train.gender.isna())) & (train.target==0.0)].shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(1,2, figsize=(12,5))\nsns.countplot(x='gender', hue='target', data=train, ax=axs[0])\nsns.barplot(x=['Male', 'Female', 'Other', 'NAN', 'Male+NAN'], y=[M, F, O, N, M_and_NAN], ax=axs[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As can be seen from the figures, we have relatively the same portion of target 0 and target 1 for all genders if we add all NAN's to Male. Hence, it is better to replace null values with 'Male'. In general, as can be seen from the barplot, the gender does not have a significant effect on the target and we may want to drop the whole column. "},{"metadata":{"trusted":true},"cell_type":"code","source":"train.gender[train.gender.isna()]=\"Male\"\ntest.gender[test.gender.isna()]=\"Male\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, trying to fill the null values of major_discipline  column:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.major_discipline.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[train.major_discipline.isna()]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It seems the educational level has a significant effect on the major_discipline. Obviously, there is no discipline for \"High School\" and \"Primary School\". Therefore, Null values in this column is not missed values but means \"not applicable\". So we are going to replace null values with \"Not applicable\" when the dicipline is \"High School\" or \"Primary School"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.major_discipline[(train.major_discipline.isna()) & ((train.education_level=='High School') | (train.education_level=='Primary School'))]='Not Applicable'\ntest.major_discipline[(test.major_discipline.isna()) & ((test.education_level=='High School') | (test.education_level=='Primary School'))]='Not Applicable'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nsns.countplot(x='education_level', hue='major_discipline', data=train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As can be seen from the above graph, we can replace the remaining Null values with STEM as it is most likely."},{"metadata":{"trusted":true},"cell_type":"code","source":"train.major_discipline[train.major_discipline.isna()]='STEM'\ntest.major_discipline[test.major_discipline.isna()]='STEM'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The null values of company types and company size are very challanging to fill. On the other hand we want to have these columns for our prediction."},{"metadata":{},"cell_type":"markdown","source":"in the almost 28% of the data, we do not have any information about company type and company size. "},{"metadata":{"trusted":true},"cell_type":"code","source":"train[(train.company_type.isna()) & (train.company_size.isna())].shape[0]/train.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.company_type.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax =plt.subplots(6,1, figsize=(15,20))\nsns.countplot(train.company_type, ax=ax[0])\nsns.countplot(x='company_type', hue='major_discipline', data=train, ax=ax[1])\nsns.countplot(x='company_type', hue='education_level', data=train, ax=ax[2])\nsns.countplot(x='company_type', hue='relevent_experience', data=train, ax=ax[3])\nsns.boxplot(x=train.company_type, y=train.training_hours, ax=ax[4])\nsns.countplot(x='company_type', hue='company_size', data=train, ax=ax[5])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Conclusion: The majority of company_types are \"Pvt Ltd\". If one's major is not \"STEM\", he/she most probably is hired in the \"Pvt Ltd\" companies. \"no relevant experience\" got a job mainly in either \"Pvt Ltd\" or \"Public Sector\"."},{"metadata":{"trusted":true},"cell_type":"code","source":"train.company_type[(train.major_discipline!=\"STEM\") & (train.company_type.isna())]=\"Pvt Ltd\"\ntest.company_type[(test.major_discipline!=\"STEM\") & (test.company_type.isna())]=\"Pvt Ltd\"\ntrain.company_type[(train.major_discipline==\"Not Applicable\") & (train.company_type.isna())]=\"Pvt Ltd\"\ntest.company_type[(test.major_discipline==\"Not Applicable\") & (test.company_type.isna())]=\"Pvt Ltd\"\ntrain.company_type[(train.education_level==\"Masters\") & (train.company_type.isna())]=\"Pvt Ltd\"\ntest.company_type[(test.education_level==\"Masters\") & (test.company_type.isna())]=\"Pvt Ltd\"\ntrain.company_type[(train.relevent_experience==\"No relevent experience\") & (train.company_type.isna())]=\"Public Sector\"\ntest.company_type[(test.relevent_experience==\"No relevent experience\") & (test.company_type.isna())]=\"Public Sector\"\n# the percentages of null values is reduced from 30% to 8% by these methods","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is very difficult to guess the remaining Null values in the Company_type, hence, we are going to use the mode method to replace the remaining null values. However, we are going to edit them in the new dataset to use it in the modeling after visulization. I am also going to drop the company_size for now. If you find a better way to fill the null values in these two columns please let me know in the comment :)"},{"metadata":{"trusted":true},"cell_type":"code","source":"train2=train.drop(['company_size'], axis=1).dropna()\ntest2=test.drop(['company_size'], axis=1).dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train2.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test2.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Visulization ============================================="},{"metadata":{},"cell_type":"markdown","source":"We are going to discover the relation btw different features and \"target\" feature. Lets start from the target data:"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig=go.Figure(data=[go.Pie(labels=['Not looking for job change', 'Looking for a job change'], values=train.target.value_counts())])\nfig.update_traces( hole= 0.3, hoverinfo='label+percent', textinfo='value+percent', textfont_size=20)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Almost 1/4 of the employees are looking for a job change. Lets see which groups are mainly trying to change their jobs :)"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='target', hue='education_level', data=train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"P=100*train[(train.education_level=='Phd') & (train.target==1.0)].shape[0]/train[(train.education_level=='Phd') & (train.target==0.0)].shape[0]\nG=100*train[(train.education_level=='Graduate') & (train.target==1.0)].shape[0]/train[(train.education_level=='Graduate') & (train.target==0.0)].shape[0]\nM=100*train[(train.education_level=='Masters') & (train.target==1.0)].shape[0]/train[(train.education_level=='Masters') & (train.target==0.0)].shape[0]\nH=100*train[(train.education_level=='High School') & (train.target==1.0)].shape[0]/train[(train.education_level=='High School') & (train.target==0.0)].shape[0]\nP=100*train[(train.education_level=='Primary School') & (train.target==1.0)].shape[0]/train[(train.education_level=='Primary School') & (train.target==0.0)].shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from plotly.offline import iplot, init_notebook_mode\nfigu=go.Figure(data=go.Bar( x = ['Phd', 'Graduate','Masters','High School','Primary School' ],\n                y = [P, G, M, H, P],\n                \n                marker = dict(color = 'rgba(255, 174, 255, 0.5)',\n                             line=dict(color='rgb(0,0,0)',width=1.5))),\n              layout=dict(title = \"The Percentage of ['not looking for a job' / 'looking for a job']\",\n              yaxis= dict(title= 'Percentage',ticklen= 5,zeroline= False)\n             ))\niplot(figu)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It seems \"Graduate\"s are more likely to look for a new job compared to other education levels. \"Phd\"s are less likely to change their job (look for new job), maybe they are already making a good money :)"},{"metadata":{"trusted":true},"cell_type":"code","source":"figu = go.Figure(data=go.Box(x=train['target'], y=train['city_development_index'],\n                         notched=True,\n                         fillcolor='rgba(0,255,0,0.5)'), \n                 layout=dict(title = \"City development index vs. Target\",\n                 yaxis= dict(title= 'City development index',ticklen= 5,zeroline= False),\n                 xaxis= dict(title= 'Target',ticklen= 5,zeroline= False)\n                            ))\n\niplot(figu)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Employee's in the cities with higher development index have more tendency to do not change their job. "},{"metadata":{"trusted":true},"cell_type":"code","source":"M=train[(train.gender=='Male') & (train.target==1.0)].shape[0]/train[(train.gender=='Male') & (train.target==0.0)].shape[0]\nF=train[(train.gender=='Female') & (train.target==1.0)].shape[0]/train[(train.gender=='Female') & (train.target==0.0)].shape[0]\nO=train[(train.gender=='Other') & (train.target==1.0)].shape[0]/train[(train.gender=='Other') & (train.target==0.0)].shape[0]\nfig, ax=plt.subplots(1,2, figsize=(15,5))\nsns.countplot(x='target', hue='gender', data=train, ax=ax[0])\nsns.barplot(x=['Male','Female','Other'], y=[M, F, O], ax=ax[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As previously talked, gender does not have a significant effect on target. All genders have btw 30-35% tendency to change their jobs."},{"metadata":{"trusted":true},"cell_type":"code","source":"train.major_discipline.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"M=[]\nvalues=['STEM', 'Business Degree', 'Not Applicable', 'Arts', 'Humanities','No Major', 'Other']\nfor items in values:\n    M.append(train[(train.major_discipline==items) & (train.target==1.0)].shape[0]/train[(train.major_discipline==items) & (train.target==0.0)].shape[0])\nfigu=go.Figure(data=(go.Bar(x=values, y=M, \n                           marker=dict(color = 'rgba(355, 50, 55, 1.0)',\n                             line=dict(color='rgb(0,0,0)',width=1.5)))),\n              layout=dict(title= 'Likelihood of seeking new job vs. major discipline',yaxis= dict(title= 'Likelihood of seeking a new job',ticklen= 5,zeroline= False)))\n\n\niplot(figu)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Those who do not have any discipline, Arts, and Humanities are less likely to seek for a new job compared to other disciplines."},{"metadata":{"trusted":true},"cell_type":"code","source":"train.enrolled_university.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"E=[]\nvalues=['no_enrollment', 'Full time course', 'Part time course']\nfor items in values:\n    E.append(train[(train.enrolled_university==items) & (train.target==1.0)].shape[0]/train[(train.enrolled_university==items) & (train.target==0.0)].shape[0])\nfigu=go.Figure(data=(go.Bar(x=values, y=E, \n                           marker=dict(color = 'rgba(55, 50, 100, 0.5)',\n                             line=dict(color='rgb(0,0,0)',width=1.5)))),\n              layout=dict(title= 'Likelihood of seeking new job vs. enrolled_university',yaxis= dict(title= 'Likelihood of seeking a new job',ticklen= 5,zeroline= False)))\n\n\niplot(figu)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Those who enrolled a \"Full time course\"s in the university are more likely to seek for a new job. Why?!"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.relevent_experience.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"R=[]\nvalues=['Has relevent experience', 'No relevent experience']\nfor items in values:\n    R.append(train[(train.relevent_experience==items) & (train.target==1.0)].shape[0]/train[(train.relevent_experience==items) & (train.target==0.0)].shape[0])\nfigu=go.Figure(data=(go.Bar(x=values, y=E, \n                           marker=dict(color = 'rgba(55, 50, 200, 0.5)',\n                             line=dict(color='rgb(0,0,0)',width=1.5)))),\n              layout=dict(title= 'Likelihood of seeking new job vs. relevent_experience',yaxis= dict(title= 'Likelihood of seeking a new job',ticklen= 5,zeroline= False)))\n\n\niplot(figu)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Those who does not have any relevant experience, looking for a new job more often. Maybe they did not have too much idea about their job and they are not too interested."},{"metadata":{"trusted":true},"cell_type":"code","source":"figu = go.Figure(data=go.Box(x=train['target'], y=train['experience'],\n                         notched=True,\n                         fillcolor='rgba(0,255,0,0.5)'), \n                 layout=dict(title = \"experience vs. Target\",\n                 yaxis= dict(title= 'experience',ticklen= 5,zeroline= False),\n                 xaxis= dict(title= 'Target',ticklen= 5,zeroline= False)\n                            ))\n\niplot(figu)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First we are going to edit city column. We are going to remove \"city_\""},{"metadata":{"trusted":true},"cell_type":"code","source":"train.city=train.city.str.strip('city_')\ntest.city=test.city.str.strip('city_')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, going to convert categorical data:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train=pd.concat([train, pd.get_dummies(train['relevent_experience'], drop_first=True)], axis=1).drop(['relevent_experience'], axis=1)\ntest=pd.concat([test, pd.get_dummies(test['relevent_experience'], drop_first=True)], axis=1).drop(['relevent_experience'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since we have 'Other' in gender column, we are going to change \"Other\" in major_discipline to \"Another\""},{"metadata":{"trusted":true},"cell_type":"code","source":"train.major_discipline[train.major_discipline=='Other']='Another'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\nCat_c=['gender', 'enrolled_university','major_discipline', 'education_level']\nfor items in Cat_c:\n    le=OneHotEncoder()\n    t=le.fit_transform(train[[items]]).toarray()\n    a=train[items].unique()\n    indexs=np.unique(a, return_index=True)[1]\n    col=[a[indexs] for index in sorted(indexs)]\n    new=pd.DataFrame(t, columns=col[1])\n    train=pd.concat([train, new], axis=1, join='inner')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\nCat_c=['gender', 'enrolled_university','major_discipline', 'education_level']\nfor items in Cat_c:\n    le=OneHotEncoder()\n    t=le.fit_transform(test[[items]]).toarray()\n    a=test[items].unique()\n    indexs=np.unique(a, return_index=True)[1]\n    col=[a[indexs] for index in sorted(indexs)]\n    new=pd.DataFrame(t, columns=col[1])\n    test=pd.concat([test, new], axis=1, join='inner')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop(['gender', 'enrolled_university','major_discipline','company_size','company_type', 'education_level'], axis=1, inplace=True)\ntest.drop(['gender', 'enrolled_university','major_discipline','company_size','company_type', 'education_level'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now it is time to model :)"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=train.drop(['target'], axis=1)\ny=train['target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.last_new_job.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Section"},{"metadata":{"trusted":true},"cell_type":"code","source":"X.city=pd.to_numeric(X.city)\nX.experience=pd.to_numeric(X.experience)\nX.last_new_job=pd.to_numeric(X.last_new_job)\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nmodel=LogisticRegression()\nmodel.fit(X_train,y_train)\nprediction=model.predict(X_test)\nfrom sklearn.metrics import accuracy_score\naccuracy_score(prediction, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nmodel=DecisionTreeClassifier()\nmodel.fit(X_train,y_train)\nprediction=model.predict(X_test)\nfrom sklearn.metrics import accuracy_score\naccuracy_score(prediction, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier\nn_est=[50, 100, 150, 200, 250]\nfor items in n_est:\n    model=RandomForestClassifier(items)\n    model.fit(X_train,y_train)\n    prediction=model.predict(X_test)\n    print('{} : {}'.format(items, accuracy_score(prediction, y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\nmodel=XGBClassifier()\nmodel.fit(X_train,y_train)\nprediction=model.predict(X_test)\naccuracy_score(prediction, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nconfusion_matrix(prediction, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. Logestic Regression:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nmodel=LogisticRegression()\nmodel.fit(X,y)\nprediction=model.predict(test)\noutput=pd.DataFrame({'enrollee_id':test.enrollee_id, 'target':prediction})\noutput\n#pd.DataFrame.to_csv(output)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2. Decision Tree:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nmodel=DecisionTreeClassifier()\nmodel.fit(X,y)\nprediction=model.predict(test)\noutput=pd.DataFrame({'enrollee_id':test.enrollee_id, 'target':prediction})\noutput","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3. RandomForest:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nmodel=RandomForestClassifier(n_estimators=250)\nmodel.fit(X,y)\nprediction=model.predict(test)\noutput=pd.DataFrame({'enrollee_id':test.enrollee_id, 'target':prediction})\noutput","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}