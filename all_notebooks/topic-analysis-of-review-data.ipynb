{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Importing Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport nltk\nfrom nltk.tokenize import word_tokenize, sent_tokenize\nfrom nltk.tag import pos_tag\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import stopwords\nimport re\nfrom pprint import pprint\n\n# Gensim\nimport gensim\nimport gensim.corpora as corpora\nfrom gensim.utils import simple_preprocess\nfrom gensim.models import CoherenceModel\n\nimport pyLDAvis\nimport pyLDAvis.gensim  # don't skip this\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. Read the .csv file using Pandas. Take a look at the top few records"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Read the .csv file using Pandas. Take a look at the top few records.\nReviewData = pd.read_csv('../input/topic-analysis-of-review-data/K8 Reviews v0.2.csv')\nReviewData.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Normalize casings for the review text and extract the text into a list for easier manipulation."},{"metadata":{"trusted":true},"cell_type":"code","source":"def Normalize(reviews):\n    NormalizeReviews = []\n    for review in reviews:\n        NormalizeReviews.append(review.lower())\n    return NormalizeReviews","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Normalize casings for the review text and extract the text into a list for easier manipulation.\nNormalizeReviewText = Normalize(ReviewData['review'].values)\nNormalizeReviewText","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Perform parts-of-speech tagging on each sentence using the NLTK POS tagger.\n\n# 5. For the topic model, we should  want to include only nouns.\n\n    Find out all the POS tags that correspond to nouns.\n\n    Limit the data to only terms with these tags."},{"metadata":{"trusted":true},"cell_type":"code","source":"def Tokenize_POS(reviews):\n    TokenizeReviews = []\n    for review in reviews:\n        #review = nltk.word_tokenize(review)\n        #TokenizeReviews.append(nltk.pos_tag(review))  \n        for word,pos in nltk.pos_tag(nltk.word_tokenize(review)):\n            if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS'):\n                #review = lemmatizer.lemmatize(word)\n                #print (word)\n                TokenizeReviews.append(review)    \n    return TokenizeReviews    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Tokenize the reviews using NLTKs word_tokenize function.\n#Perform parts-of-speech tagging on each sentence using the NLTK POS tagger.\nTokenizeReviews = Tokenize_POS(NormalizeReviewText)\nTokenizeReviews","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6. Lemmatize. \n\n    Different forms of the terms need to be treated as one.\n    No need to provide POS tag to lemmatizer for now.\n\n# 7. Remove stopwords and punctuation (if there are any). "},{"metadata":{"trusted":true},"cell_type":"code","source":"# function to remove Stopwords\ndef Remove_Stopwords(word_list, lang='english'):\n    \"\"\"Function removes english stopwords\n    Args:\n        word_list  : list of words\n    Return:\n        The return value. List of words\n    \"\"\"\n    content = []\n    stopwords_list = stopwords.words(lang)\n    #print(type(word_list))\n    #for word in word_list:\n    #    print(word)\n    #    if word.lower() not in stopwords_list:\n    #        content.append(word)\n    content = [w for w in word_list if w.lower() not in stopwords_list]\n    #print(content)\n    return content\n            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# function to remove punctuation\ndef Simplify_Punctuation(text):\n    \"\"\"\n    This function simplifies doubled or more complex punctuation. The exception is '...'.\n    \"\"\"\n    corrected = str(text)\n    corrected = re.sub(r'([!?,;])\\1+', r'\\1', corrected)\n    corrected = re.sub(r'\\.{2,}', r'...', corrected)\n    return corrected","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# function to lemmatize using WordNetLemmatizer\ndef Lemmatize_WordNet(words_list):\n    wnl = WordNetLemmatizer()\n    encoded_list = []\n    for word in words_list:\n        encoded_list.append(wnl.lemmatize(word, pos=\"v\"))#.encode(\"utf8\"))\n    #print(encoded_list)\n    return encoded_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def tokenize(txt):\n    \"\"\"Function computes Tokenizes into sentences, strips punctuation/abbr, \n       converts to lowercase and tokenizes words\n    Args:\n        txt  : text documents\n    Return:\n        The return value. Tokenized words\n    \"\"\"\n    return [word_tokenize(\" \".join(re.findall(r'\\w+', t,flags = re.UNICODE )).lower()) \n                for t in sent_tokenize(txt.replace(\"'\", \"\"))]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def Apply_Stopwords_punctuation_lemmatize(reviews):\n    PreprocessReviews = []\n    for review in reviews:\n        lemmetized = []\n        review = Simplify_Punctuation(review)  # Remove Punctuation        \n        sentences = tokenize(review)\n        for sentence in sentences:\n            words = Remove_Stopwords(sentence)         # Remove Stopwords\n            words = Lemmatize_WordNet(words)           # lemmatize \n            # lets's skip short sentences with less than 3 words\n            if len(words) < 3:\n                continue\n            lemmetized.append(\" \".join(words))\n        PreprocessReviews.append(\" \".join(lemmetized))\n    return PreprocessReviews","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lemmatize. \nDifferent forms of the terms need to be treated as one.\nNo need to provide POS tag to lemmatizer for now.\nRemove stopwords and punctuation (if there are any). "},{"metadata":{"trusted":true},"cell_type":"code","source":"PreProcessReviews = Apply_Stopwords_punctuation_lemmatize(TokenizeReviews)\nPreProcessReviews","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 8. Create a topic model using LDA on the cleaned-up data with 12 topics.\n\n    Print out the top terms for each topic.\n    What is the coherence of the model with the c_v metric?"},{"metadata":{"trusted":true},"cell_type":"code","source":"TokenizeReviews = []\nfor review in PreProcessReviews:\n    TokenizeReviews.append(nltk.word_tokenize(review)) \n#TokenizeReviews","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create Dictionary\n\nid2word = corpora.Dictionary(TokenizeReviews)\n\n# Create Corpus\ntexts = TokenizeReviews\n\n# Term Document Frequency\ncorpus = [id2word.doc2bow(text) for text in texts]\n\n# View\nprint(corpus[:1])\nprint(id2word[0])\n\n[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build LDA model\nlda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n                                           id2word=id2word,\n                                           num_topics=12, \n                                           random_state=100,\n                                           update_every=1,\n                                           chunksize=100,\n                                           passes=10,\n                                           alpha='auto',\n                                           per_word_topics=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print the Keyword in the 12 topics\npprint(lda_model.print_topics())\ndoc_lda = lda_model[corpus]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compute Perplexity\nprint('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n\n# Compute Coherence Score\ncoherence_model_lda = CoherenceModel(model=lda_model, texts=TokenizeReviews, dictionary=id2word, coherence='c_v')\ncoherence_lda = coherence_model_lda.get_coherence()\nprint('\\nCoherence Score: ', coherence_lda)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Analyze the topics through the business lens.\n\n\nHere are the possible topic headers\n\n  0 - Possible Topic - Lenovo Note K8 (1)\n  \n  1 - Possible Topic - First Touch Phone (2)\n  \n  2 - Possible Topic - Charging Review (3)\n  \n  3 - Possible Topic - Review on sensor time (4)\n  \n  4 - Possible Topic - Positive Mobile Review (5) \n  \n  5 - Possible Topic - Picture quality (6)\n  \n  6 - Possible Topic - Positive Review (5)\n  \n  7 - Possible Topic - Review on Processor (7)\n  \n  8 - Possible Topic - Positive Review (5)\n  \n  9 - Possible Topic - Negative Review (8)\n  \n  10 - Possible Topic - Review on Return policy (9)\n  \n  11 - Possible Topic - Review on software update (10)\n  \n  # Determine which of the topics can be combined.\n\n  \n  Distinct topics can be treated as 10"},{"metadata":{},"cell_type":"markdown","source":"# 10 Create a topic model using LDA with what you think is the optimal number of topics\n\n    What is the coherence of the model?"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build LDA model with 8 topics\nlda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n                                           id2word=id2word,\n                                           num_topics=10, \n                                           random_state=100,\n                                           update_every=1,\n                                           chunksize=100,\n                                           passes=10,\n                                           alpha='auto',\n                                           per_word_topics=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print the Keyword in the 8 topics\npprint(lda_model.print_topics())\ndoc_lda = lda_model[corpus]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compute Perplexity\nprint('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n\n# Compute Coherence Score\ncoherence_model_lda = CoherenceModel(model=lda_model, texts=TokenizeReviews, dictionary=id2word, coherence='c_v')\ncoherence_lda = coherence_model_lda.get_coherence()\nprint('\\nCoherence Score: ', coherence_lda)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# The business should be able to interpret the topics.\n\n    Name each of the identified topics.\n\n    Create a table with the topic name and the top 10 terms in each to present to the business.\n"},{"metadata":{},"cell_type":"markdown","source":"Here are possible topics and and top words for each topic \n\n(Topic 1: General Review, \n\n  Words: \"heat\" , \"product\" , \"update\" , \"days\" , 1\" , \"play\" , \"software\" , \"need\" , \"user\" , \"ok\"\n  ),\n  \n (Topic 2: Review on Lenovo Note K8,\n \n  Words: \"lenovo\" , \"note\" , \"k8\" , \"first\" , \"u\" , \"previous\" , \"mobiles\" , \"still\" , \"face\" , \"office\"\n  ),\n  \n (\n  Topic 3: Review on Charging time ,\n  \n  Words: \"work\" , \"use\" , \"charge\" , \"get\" , \"take\" , \"4\" , \"2\" , \"5\" , \"like\" , \"charger\"\n  ),\n  \n (\n  Topic 4: Review on Sensor time,\n  \n  Words: \"time\" , \"bite\" , \"sensor\" , \"back\" , \"android\" , \"image\" , \"dedicate\" , \"stock\" , \"lot\" , \"music\" \n  ),\n  \n (\n  Topic 5: Negative Review,\n  \n  Words: \"phone\" , \"buy\" , \"dont\" , \"better\" , \"get\" , \"compare\" , \"one\" , \"worst\" , \"last\" , \"service\"\n  ),\n  \n (\n  Topic 6: Review on redmi ,\n  \n  Words: \"poor\" , \"dual\" , \"much\" , \"make\" , \"life\" , \"8\" , \"purchase\" , \"provide\" , \"redmi\" , \"two\"\n  ),\n  \n (\n  Topic 7: Review on camera,\n  \n  Words: \"good\" , \"camera\" , \"quality\" , \"issue\" , \"game\" , \"also\" , \"clarity\" , \"average\" , \"screen\" , \"light\"\n  ),\n  \n (\n  Topic 8: Review on network,\n  \n  Words: \"doesnt\" , \"call\" , \"even\" , \"bad\" , \"network\" , \"many\" , \"cant\" , \"support\" , \"full\" , \"find\"\n  ),\n \n (\n  Topic 9: Review on battery life,\n  \n  Words: \"battery\" , \"feature\" , \"mode\" , \"fast\" , \"drain\" , \"great\" , \"speed\" , \"nice\" , \"device\" , \"really\"\n  ),\n  \n (\n   Topic 10: Review on price, \n   \n   Words: \"mobile\" , \"amazon\" , \"problem\" , \"price\" , \"awesome\" , \"hai\" , \"return\" , \"properly\" , \"best\" , \"hang\"\n  )"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}