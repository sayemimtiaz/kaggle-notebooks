{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1>Medical Report Generation From X-Ray Images :</h1>\n","metadata":{"id":"LwhGAVtgxHsi"}},{"cell_type":"markdown","source":"<h2>Business Problem/Problem Statement :</h2>\n\n> Clinical imaging captures enormous amounts of information but most radio-logic data are reported in qualitative and subjective terms. X-Rays are a form of Electromagnetic Radiation that is used for medical imaging. Analysis of X-ray reports is a very important task of radiologists and pathologists to recommend the correct diagnosis to the patients. In this project, we are tackling the image captioning problem for a dataset containing Chest X-ray images. With the help of the state of the art deep learning architecture and optimizing parameters of the architecture. The problem statement here is to find the impression from the given chest X-Ray images. These images are in two types: Frontal and Lateral view of the chest. With these two types of images as input we need to find the impression for given X-Ray. To resolve this problem statement, we will be building a predictive model which involves both image and text processing to build a deep learning model. Image captioning is an interesting problem, where we can learn both Natural Language Processing(NLP) and Computer Vision(CV) techniques.\n\n<h2>Dataset Overview :</h2>\n\nOriginal data source : https://openi.nlm.nih.gov/\n\nThe dataset contains chest X-ray images and radiology text reports. Each image has been paired with four captions such as Impressions, Findings, Comparison and Indication that provide clear descriptions of the salient entities and events.\n\n> Chest X-ray -There are 7,471 images in .png file format (contain lateral view and frontal view of each patient).\n\n> Radiology Report -There are about 3955 patients text reports available in .XML format.\n\n<h2>Mapping the real-world problem to Machine Learning problem :</h2>\n\n> The problem we are going to solve in this case study is Medical Image Captioning. Basically, we have to extract features from images using a Convolutional Neural Network(CNN) from scratch or using transfer learning (preferable as we have less amount of data). Then use these extracted features to predict the captions LSTMs or GRUs. The output would be a sequence of words.\n\n<h2>Real-world constraints :</h2>\n\n> Interpretability is moderately important.\n\n> There are no latency constraints.\n\n> As the cost of mistakes in the Medical domain is very high the model should be very good in its predictions. \n\n\n<h2>Performance Metric :</h2>\n\n> To evaluate the model performance, I will use bilingual evaluation understudy (BLEU) score. BLEU is a well-acknowledged metric to measure the similarity of one hypothesis sentence to multiple reference sentences. Given a single hypothesis sentence and multiple reference sentences, it returns value between 0 and 1. The metric close to 1 means that the two are very similar. Apparently we need to have a higher BLEU score.\n","metadata":{"id":"2cTagejwxiJV"}},{"cell_type":"markdown","source":"**P.S : Initially, I made this notebook on google colab. So, I have used the data from original source by manually uploading it on kaggle, just to keep the path same. We can use the given dataset as well.**","metadata":{}},{"cell_type":"markdown","source":"**Import all the libraries :**","metadata":{"id":"n8aC88ha3w49"}},{"cell_type":"code","source":"import os\nimport re\nimport cv2\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom tqdm import tqdm\nsns.set_style(\"whitegrid\")\nfrom bs4 import BeautifulSoup\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nwarnings.filterwarnings('ignore')\nimport xml.etree.ElementTree as ET\nfrom wordcloud import WordCloud, ImageColorGenerator","metadata":{"id":"sTw4JlSz3why","execution":{"iopub.status.busy":"2021-05-21T17:13:28.605262Z","iopub.execute_input":"2021-05-21T17:13:28.605622Z","iopub.status.idle":"2021-05-21T17:13:28.612749Z","shell.execute_reply.started":"2021-05-21T17:13:28.60559Z","shell.execute_reply":"2021-05-21T17:13:28.611452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cwd = os.getcwd()","metadata":{"id":"MpO0rOy-G_7R","execution":{"iopub.status.busy":"2021-05-21T17:07:30.708306Z","iopub.execute_input":"2021-05-21T17:07:30.708694Z","iopub.status.idle":"2021-05-21T17:07:30.713353Z","shell.execute_reply.started":"2021-05-21T17:07:30.708647Z","shell.execute_reply":"2021-05-21T17:07:30.712125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tarfile\nimages = tarfile.open('../input/images/NLMCXR_png.tgz')\nimages.extractall(cwd+'/xray_images/')","metadata":{"id":"rS37CTqZ20N2","execution":{"iopub.status.busy":"2021-05-21T17:07:33.988101Z","iopub.execute_input":"2021-05-21T17:07:33.988499Z","iopub.status.idle":"2021-05-21T17:08:00.530795Z","shell.execute_reply.started":"2021-05-21T17:07:33.988467Z","shell.execute_reply":"2021-05-21T17:08:00.529928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xml = tarfile.open('../input/reports/NLMCXR_reports.tgz')\nxml.extractall(cwd+'/xray_reports/')","metadata":{"id":"sB5hhyCo2vo0","execution":{"iopub.status.busy":"2021-05-21T17:08:00.532595Z","iopub.execute_input":"2021-05-21T17:08:00.532885Z","iopub.status.idle":"2021-05-21T17:08:01.664634Z","shell.execute_reply.started":"2021-05-21T17:08:00.532858Z","shell.execute_reply":"2021-05-21T17:08:01.661942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Below is the sample image and the report :**\n\n\n![](https://i.imgur.com/PWo3x47.png)","metadata":{"id":"NUy6ai6tnQF4"}},{"cell_type":"markdown","source":"**Display an XML :**","metadata":{"id":"N9nyGmvknhqf"}},{"cell_type":"code","source":"with open(\"./xray_reports/ecgen-radiology/1.xml\", 'r') as f:\n    print(f.read())","metadata":{"id":"KbIcUiMFp1Z6","outputId":"c59be79e-4454-44d3-daa0-70bcf539cb78","execution":{"iopub.status.busy":"2021-05-21T17:08:01.666188Z","iopub.execute_input":"2021-05-21T17:08:01.66652Z","iopub.status.idle":"2021-05-21T17:08:01.674958Z","shell.execute_reply.started":"2021-05-21T17:08:01.666484Z","shell.execute_reply":"2021-05-21T17:08:01.673693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observations :**\n\nThe fields which seem to be important and userful are :\n\n* pmcid : Patient id\n* COMPARISION\n* INDICATION\n* FINDINGS\n* IMPRESSIONS (Target Variable)\n* Image id\n\nWe can see there are two image files associated with this report. First I will check the stats of data. Then we will see the maximum and minimum possible value for number of images that are associated with a report.","metadata":{"id":"1aYKg3-uqyef"}},{"cell_type":"markdown","source":"**Checking the data stats :**","metadata":{"id":"Xt5JLiajUdfe"}},{"cell_type":"code","source":"print('Total Images in data : ', len(os.listdir('./xray_images')))\nprint('Total Reports in data : ', len(os.listdir('./xray_reports/ecgen-radiology')))","metadata":{"id":"_mzQMOtjUc35","outputId":"1ba7610f-479c-48b6-d1bc-d4331074605f","execution":{"iopub.status.busy":"2021-05-21T17:08:01.676808Z","iopub.execute_input":"2021-05-21T17:08:01.677236Z","iopub.status.idle":"2021-05-21T17:08:01.698038Z","shell.execute_reply.started":"2021-05-21T17:08:01.67718Z","shell.execute_reply":"2021-05-21T17:08:01.696731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Observations :\n\n* There are 7471 images(X-rays) and 3955 reports in dataset.\n* Few reports have more than image associated with them.","metadata":{"id":"pYPfGrIgkUTR"}},{"cell_type":"code","source":"#list of count of images\nimg_count = [] \nfor file in os.listdir('./xray_reports/ecgen-radiology'):\n  xml_file = os.path.join('./xray_reports/ecgen-radiology',file)\n  #reading the xml data\n  with open(xml_file, 'r') as f:  \n    data = f.read()\n  #getting all the image names\n  regex = r\"parentImage id.*\" \n  k  = re.findall(regex,data)\n  temp = len(k)\n  img_count.append(temp)\n\nprint(\"The max number of images associated with a report:\",np.array(img_count).max())\nprint(\"The min number of images associated with a report:\",np.array(img_count).min())","metadata":{"id":"-v2h2nnjsrOM","outputId":"4cff9b8f-9c9d-44e5-afeb-1d1f2c382b20","execution":{"iopub.status.busy":"2021-05-21T17:08:04.804153Z","iopub.execute_input":"2021-05-21T17:08:04.804511Z","iopub.status.idle":"2021-05-21T17:08:04.987726Z","shell.execute_reply.started":"2021-05-21T17:08:04.804476Z","shell.execute_reply":"2021-05-21T17:08:04.986724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (6,5))\nax = pd.Series(img_count).plot(kind='hist',color='brown')\nax.set_xlabel('Number of images associated with report')\nax.set_title(\"Frequency VS Number of images associated with report\")\nplt.show()","metadata":{"id":"s4v4i9chtLWS","outputId":"3d86c79c-d6b3-474d-91c7-669a8108852f","execution":{"iopub.status.busy":"2021-05-21T17:13:40.891229Z","iopub.execute_input":"2021-05-21T17:13:40.891644Z","iopub.status.idle":"2021-05-21T17:13:41.140835Z","shell.execute_reply.started":"2021-05-21T17:13:40.891611Z","shell.execute_reply":"2021-05-21T17:13:41.139762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Images per patient :\\n\")\nprint(pd.Series(img_count).value_counts())","metadata":{"id":"8wKj9Hkjvgrr","outputId":"1ed6765c-679e-467e-f843-d6476d00ca31","execution":{"iopub.status.busy":"2021-05-21T17:08:18.410092Z","iopub.execute_input":"2021-05-21T17:08:18.412138Z","iopub.status.idle":"2021-05-21T17:08:18.433899Z","shell.execute_reply.started":"2021-05-21T17:08:18.412067Z","shell.execute_reply":"2021-05-21T17:08:18.432838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observation :**\n\nWe can see that the maximum number of images associated with a report can be 5 while the minimum is 0. The highest frequecy of being associated with a report are 2 images.","metadata":{"id":"o061dBIm8s1Z"}},{"cell_type":"markdown","source":"**Dataset Preparation :**\n\nReports are in xml format. Need to do xml parsing to read the data and convert it into csv format.\n\n> **Input Features :** Images and we will also take abstract, comparison, indication, findings as text input features.\n\n> **Target variable :** Impression (Text feature).","metadata":{"id":"6Xq4FYCZ_IRm"}},{"cell_type":"code","source":"#Reference : https://stackoverflow.com/questions/2723015/how-to-find-recursively-for-a-tag-of-xml-using-lxml\n\ncolumns = [\"image_name\", \"image_caption\", \"comparison\", \"indication\", \"findings\", \"impression\"]\ndataframe = pd.DataFrame(columns = columns)\nfor file in tqdm(os.listdir('./xray_reports/ecgen-radiology/')):\n    #find files with .xml extension only\n    if file.endswith(\".xml\"):\n        # finding root element \n        tree = ET.parse('./xray_reports/ecgen-radiology/'+file)#parse the xml file\n        \n        findings = tree.find(\".//AbstractText[@Label='FINDINGS']\").text\n        indication = tree.find(\".//AbstractText[@Label='INDICATION']\").text\n        comparision = tree.find(\".//AbstractText[@Label='COMPARISON']\").text\n        impression = tree.find(\".//AbstractText[@Label='IMPRESSION']\").text\n\n        caption = set()\n        name_img = set()\n        #find images in each parentImage tag\n        for iterator in tree.findall(\"parentImage\"):\n            img = iterator.attrib['id']+\".png\"\n            name_img.add(img)\n            #add the corresponding report for each image\n            caption.add('' if iterator.find('caption').text is None else iterator.find('caption').text)\n            \n        # add image details and reports to dataframe\n        dataframe = dataframe.append(pd.Series([','.join(name_img), ','.join(caption), comparision, indication, findings, impression],\n                                                         index = columns), ignore_index = True)\n","metadata":{"id":"IwsYLGEkCy99","outputId":"9ac492f3-9cab-4eef-a4b7-db9a5d2156e8","execution":{"iopub.status.busy":"2021-05-21T17:08:26.027817Z","iopub.execute_input":"2021-05-21T17:08:26.028343Z","iopub.status.idle":"2021-05-21T17:08:40.41936Z","shell.execute_reply.started":"2021-05-21T17:08:26.028299Z","shell.execute_reply":"2021-05-21T17:08:40.418128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataframe.head()","metadata":{"id":"6mO6x7u-DWtV","outputId":"af5505b7-727b-4557-a0ef-d2c739aac158","execution":{"iopub.status.busy":"2021-05-21T17:08:40.421683Z","iopub.execute_input":"2021-05-21T17:08:40.4221Z","iopub.status.idle":"2021-05-21T17:08:40.442486Z","shell.execute_reply.started":"2021-05-21T17:08:40.422054Z","shell.execute_reply":"2021-05-21T17:08:40.441757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Shape of the DataFrame\nprint('Shape of the Dataframe : ', dataframe.shape)","metadata":{"id":"PgJM-44Gw5GI","outputId":"e623d72a-99f5-4b50-a35c-9c45398d82e2","execution":{"iopub.status.busy":"2021-05-21T17:08:40.443591Z","iopub.execute_input":"2021-05-21T17:08:40.443856Z","iopub.status.idle":"2021-05-21T17:08:40.448025Z","shell.execute_reply.started":"2021-05-21T17:08:40.44383Z","shell.execute_reply":"2021-05-21T17:08:40.447262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Preprocessing :**","metadata":{"id":"cSfn0_rj4c7L"}},{"cell_type":"code","source":"# function for obtaining the different information part of the xml report file and preprocessing them and also adding the concernced image and report information to the dataframe\ndef decontracted(phrase): #https://stackoverflow.com/a/47091490\n  \"\"\"\n  performs text decontraction of words like won't to will not\n  \"\"\"\n  # specific\n  phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n  phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n\n  # general\n  phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n  phrase = re.sub(r\"\\'re\", \" are\", phrase)\n  phrase = re.sub(r\"\\'s\", \" is\", phrase)\n  phrase = re.sub(r\"\\'d\", \" would\", phrase)\n  phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n  phrase = re.sub(r\"\\'t\", \" not\", phrase)\n  phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n  phrase = re.sub(r\"\\'m\", \" am\", phrase)\n  return phrase\n","metadata":{"id":"gfioCucj_H8Q","execution":{"iopub.status.busy":"2021-05-21T17:08:42.385187Z","iopub.execute_input":"2021-05-21T17:08:42.385714Z","iopub.status.idle":"2021-05-21T17:08:42.39302Z","shell.execute_reply.started":"2021-05-21T17:08:42.385679Z","shell.execute_reply":"2021-05-21T17:08:42.392121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_text(data): #https://regex101.com/\n  \"\"\"\n  extracts the information data from the xml file and does text preprocessing on them\n  here info can be 1 value in this list [\"COMPARISON\",\"INDICATION\",\"FINDINGS\",\"IMPRESSION\"]\n  \"\"\"\n  preprocessed = []\n\n  for sentence in tqdm(data.values):\n\n    sentence = BeautifulSoup(sentence, 'lxml').get_text()\n\n    regex = r\"\\d.\" \n    sentence = re.sub(regex,\"\",sentence) #removing all values like \"1.\" and \"2.\" etc\n\n    regex = r\"X+\"\n    sentence = re.sub(regex,\"\",sentence) #removing words like XXXX\n\n    regex = r\"[^.a-zA-Z]\" \n    sentence = re.sub(regex,\" \",sentence) #removing all special characters except for full stop\n\n    regex = r\"http\\S+\"\n    sentence = re.sub(regex,\"\", sentence)\n    sentence = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?$%^&*'/+\\[\\]_]+\", \"\", sentence)\n    sentence = re.sub('&', 'and',sentence)\n    sentence = re.sub('@', 'at',sentence)\n    sentence = re.sub('0', 'zero',sentence)\n    sentence = re.sub('1', 'one',sentence)\n    sentence = re.sub('2', 'two',sentence)\n    sentence = re.sub('3', 'three',sentence)\n    sentence = re.sub('4', 'four',sentence)\n    sentence = re.sub('5', 'five',sentence)\n    sentence = re.sub('6', 'six',sentence)\n    sentence = re.sub('7', 'seven',sentence)\n    sentence = re.sub('8', 'eight',sentence)\n    sentence = re.sub('9', 'nine',sentence)\n    sentence = re.sub('year old', \"\", sentence)#Occur multiple times in Indication feature but not necessary     \n    sentence = re.sub('yearold', \"\", sentence)\n    sentence = decontracted(sentence) #perform decontraction\n    sentence = sentence.strip().lower() #strips the begining and end of the string of spaces and converts all into lowercase\n    sentence = \" \".join(sentence.split()) #removes unwanted spaces\n    if sentence==\"\": #if the resulting sentence is an empty string return null value\n      sentence = np.nan\n    preprocessed.append(sentence)\n  return preprocessed","metadata":{"id":"LxYdoR6d8sgX","execution":{"iopub.status.busy":"2021-05-21T17:08:47.868426Z","iopub.execute_input":"2021-05-21T17:08:47.868861Z","iopub.status.idle":"2021-05-21T17:08:47.881615Z","shell.execute_reply.started":"2021-05-21T17:08:47.868825Z","shell.execute_reply":"2021-05-21T17:08:47.880827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Check for Null values in Text columns\nNaN = dataframe.isnull().sum()\nprint(\"Total Nan Values in caption columns -\",NaN[1])\nprint(\"Total Nan Values in comparison columns -\",NaN[2])\nprint(\"Total Nan Values in Indication columns -\",NaN[3])\nprint(\"Total Nan Values in findings columns   -\",NaN[4])\nprint(\"Total Nan Values in Impression columns -\",NaN[5])","metadata":{"id":"FDLJYvUj1U01","outputId":"af1ed637-0671-4e80-f462-0a12678f9307","execution":{"iopub.status.busy":"2021-05-21T17:08:54.199868Z","iopub.execute_input":"2021-05-21T17:08:54.20195Z","iopub.status.idle":"2021-05-21T17:08:54.213851Z","shell.execute_reply.started":"2021-05-21T17:08:54.201897Z","shell.execute_reply":"2021-05-21T17:08:54.212632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Replacing the nan values\ndataframe['image_caption'] = dataframe['image_caption'].fillna('Unknown')\ndataframe['comparison'] = dataframe['comparison'].fillna('No Comparison')\ndataframe['indication'] = dataframe['indication'].fillna('No Indication')\ndataframe['findings'] = dataframe['findings'].fillna('No Findings')\ndataframe['impression'] = dataframe['impression'].fillna('No Impression')","metadata":{"id":"T-qhfTYYyFTe","execution":{"iopub.status.busy":"2021-05-21T17:09:41.936004Z","iopub.execute_input":"2021-05-21T17:09:41.936348Z","iopub.status.idle":"2021-05-21T17:09:41.948601Z","shell.execute_reply.started":"2021-05-21T17:09:41.936317Z","shell.execute_reply":"2021-05-21T17:09:41.947425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Check for Null values in Text columns\nNaN = dataframe.isnull().sum()\nprint(\"Total Nan Values in caption columns -\",NaN[1])\nprint(\"Total Nan Values in comparison columns -\",NaN[2])\nprint(\"Total Nan Values in Indication columns -\",NaN[3])\nprint(\"Total Nan Values in findings columns   -\",NaN[4])\nprint(\"Total Nan Values in Impression columns -\",NaN[5])","metadata":{"id":"nWNel4NGyWsG","outputId":"fdfdcb6a-8a09-46c3-8c7b-a792da312cd1","execution":{"iopub.status.busy":"2021-05-21T17:09:05.211417Z","iopub.execute_input":"2021-05-21T17:09:05.211826Z","iopub.status.idle":"2021-05-21T17:09:05.225194Z","shell.execute_reply.started":"2021-05-21T17:09:05.211789Z","shell.execute_reply":"2021-05-21T17:09:05.222871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Preprocessing of text features\ndataframe['image_caption'] = preprocess_text(dataframe['image_caption'])\ndataframe['comparison'] = preprocess_text(dataframe['comparison'])\ndataframe['indication'] = preprocess_text(dataframe['indication'])\ndataframe['findings'] = preprocess_text(dataframe['findings'])\ndataframe['impression'] = preprocess_text(dataframe['impression'])","metadata":{"id":"fN6BN3tCDXZK","outputId":"da4d293a-e1d3-490c-b07b-5fccb8056e17","execution":{"iopub.status.busy":"2021-05-21T17:09:49.823307Z","iopub.execute_input":"2021-05-21T17:09:49.823676Z","iopub.status.idle":"2021-05-21T17:09:55.61935Z","shell.execute_reply.started":"2021-05-21T17:09:49.823623Z","shell.execute_reply":"2021-05-21T17:09:55.618243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataframe.head()","metadata":{"id":"l9rI4xteDdQ3","outputId":"5c58a88c-dcc4-4d79-d374-29872c377744","execution":{"iopub.status.busy":"2021-05-21T17:10:00.176846Z","iopub.execute_input":"2021-05-21T17:10:00.177187Z","iopub.status.idle":"2021-05-21T17:10:00.193054Z","shell.execute_reply.started":"2021-05-21T17:10:00.177157Z","shell.execute_reply":"2021-05-21T17:10:00.1919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observation :** \n\n* I did some text preprocessing in XML, for four labels (comparision,indcation, impression and findings). I analyze the text data, then perform tasks like decontraction (can't ---> can not), remove special character, convert in lowercase.\n\n* I have also preprocessed Image caption feature, For getting additional information about the corrosponding image.\n\n* Missing values are also present in image_name feature. As at some place nothing is assigned on image_name.","metadata":{"id":"MnPXY6oD-D1W"}},{"cell_type":"code","source":"dataframe.replace(\"\", float(\"NaN\"), inplace=True)","metadata":{"id":"nu0lyk8D7Gwi","execution":{"iopub.status.busy":"2021-05-21T17:10:09.048064Z","iopub.execute_input":"2021-05-21T17:10:09.048444Z","iopub.status.idle":"2021-05-21T17:10:09.057167Z","shell.execute_reply.started":"2021-05-21T17:10:09.048412Z","shell.execute_reply":"2021-05-21T17:10:09.056007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#percentage missing values\nprint(dataframe.isnull().sum()*100/dataframe.shape[0] )","metadata":{"id":"32RKFj5n4UbK","outputId":"c654f2d9-d5bd-4c1c-9e13-824de382328c","execution":{"iopub.status.busy":"2021-05-21T17:10:12.659755Z","iopub.execute_input":"2021-05-21T17:10:12.660118Z","iopub.status.idle":"2021-05-21T17:10:12.694001Z","shell.execute_reply.started":"2021-05-21T17:10:12.660087Z","shell.execute_reply":"2021-05-21T17:10:12.693129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observation :** We can see that there are still missing values in the data. We could remove all rows where image_name are null since they represent below 3% of the total datapoints.","metadata":{"id":"Q6Y8zsqD5ng6"}},{"cell_type":"code","source":"dataframe.dropna(subset = [\"image_name\"], inplace=True)\ndataframe.shape","metadata":{"id":"J22wrojr8SAM","outputId":"ce1aa7e6-e42c-409f-a9fc-4de1acf2a078","execution":{"iopub.status.busy":"2021-05-21T17:10:19.49147Z","iopub.execute_input":"2021-05-21T17:10:19.492066Z","iopub.status.idle":"2021-05-21T17:10:19.505068Z","shell.execute_reply.started":"2021-05-21T17:10:19.492031Z","shell.execute_reply":"2021-05-21T17:10:19.504149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataframe.head()","metadata":{"id":"C9vuSTdf_Duh","outputId":"b51bc1bf-456d-4b02-ee00-19c674c1ecb0","execution":{"iopub.status.busy":"2021-05-21T17:10:22.075464Z","iopub.execute_input":"2021-05-21T17:10:22.075991Z","iopub.status.idle":"2021-05-21T17:10:22.091075Z","shell.execute_reply.started":"2021-05-21T17:10:22.075957Z","shell.execute_reply":"2021-05-21T17:10:22.090185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Add Image count feature :**","metadata":{"id":"JcRr8j_Q-IvX"}},{"cell_type":"code","source":"dataframe['image_count'] = dataframe['image_name'].astype(str).str.split(',').apply(len)","metadata":{"id":"czOGayiq-IMh","execution":{"iopub.status.busy":"2021-05-21T17:10:29.000907Z","iopub.execute_input":"2021-05-21T17:10:29.001501Z","iopub.status.idle":"2021-05-21T17:10:29.016131Z","shell.execute_reply.started":"2021-05-21T17:10:29.001458Z","shell.execute_reply":"2021-05-21T17:10:29.01496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Adding word count feature for indication, findings and impression :**\n","metadata":{"id":"UQDTAqUp-bk5"}},{"cell_type":"code","source":"#Adding word count feature for indication, findings and impression\ndataframe['indication_count'] = dataframe['indication'].astype(str).str.split().apply(lambda x: 0 if x==None else len(x))\ndataframe['findings_count'] = dataframe['findings'].astype(str).str.split().apply(lambda x: 0 if x==None else len(x))\ndataframe['impression_count'] = dataframe['impression'].astype(str).str.split().apply(lambda x: 0 if x==None else len(x))\ndataframe.head()","metadata":{"id":"029ge6qO-XGV","outputId":"693df6b7-15a8-477e-ef78-0b0696b1acf0","execution":{"iopub.status.busy":"2021-05-21T17:10:31.149989Z","iopub.execute_input":"2021-05-21T17:10:31.150352Z","iopub.status.idle":"2021-05-21T17:10:31.215949Z","shell.execute_reply.started":"2021-05-21T17:10:31.150321Z","shell.execute_reply":"2021-05-21T17:10:31.215093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3>Exploring the Image features :</h3>","metadata":{"id":"iOmE5LA2ACSK"}},{"cell_type":"markdown","source":"**Displaying sample 9 patient X-Ray :**","metadata":{"id":"j7cxIjDZQsZP"}},{"cell_type":"code","source":"#Displaying sample 9 patient X-Ray\nfig, axs = plt.subplots(3, 3, figsize = (9,9), tight_layout=True)\nfor row, figure in zip(dataframe[0:10].itertuples(), axs.flatten()):\n    image=mpimg.imread(\"./xray_images/\"+row.image_name.split(',')[0])\n    figure.imshow(image)\nplt.show()","metadata":{"id":"fEq4fe8qAQ_1","outputId":"e3bf9d5c-a06b-47b5-ac3a-440e79dcc7f1","execution":{"iopub.status.busy":"2021-05-21T17:10:38.950102Z","iopub.execute_input":"2021-05-21T17:10:38.950476Z","iopub.status.idle":"2021-05-21T17:10:41.017833Z","shell.execute_reply.started":"2021-05-21T17:10:38.950439Z","shell.execute_reply":"2021-05-21T17:10:41.017016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Displaying Sample Images + Caption :**","metadata":{"id":"yub2y2dPRax0"}},{"cell_type":"code","source":"def show_image_captions(df,sample):\n    '''This function prints the sample images and its other text features.\n       Parameters :\n       - df: dataframe\n       - sample: Number of datapoints'''\n    \n    sampled_row = df.sample(sample)\n\n    for count, row in sampled_row.iterrows():\n        print(\"Caption :\",row['image_caption'])\n        imgs = row[\"image_name\"].split(',')\n        fig, axs = plt.subplots(1, len(imgs), figsize = (10,10), tight_layout=True)\n        iterator = 0\n\n        for img, figure in zip(imgs, axs.flat):\n            image= mpimg.imread(\"./xray_images/\"+img)\n            imgplot = axs[iterator].imshow(image)\n            iterator +=1\n        \n        plt.show()\n        print(\"\\nComparision :\",row.get('comparision'))\n        print(\"\\nIndication :\",row.get('indication'))\n        print(\"\\nFindings :\",row.get('findings'))\n        print(\"\\nImpression :\",row.get('impression'))\n        print(\"=\"*100,'\\n')","metadata":{"id":"YSHKe72sSs-H","execution":{"iopub.status.busy":"2021-05-21T17:10:48.053241Z","iopub.execute_input":"2021-05-21T17:10:48.053797Z","iopub.status.idle":"2021-05-21T17:10:48.062209Z","shell.execute_reply.started":"2021-05-21T17:10:48.05376Z","shell.execute_reply":"2021-05-21T17:10:48.061394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#showing sample 2 datapoints\nshow_image_captions(dataframe, 2)","metadata":{"id":"Gkl8xFW4X3VS","outputId":"458e3dba-7f43-42b9-ea41-464c4a9161d7","execution":{"iopub.status.busy":"2021-05-21T17:10:54.36529Z","iopub.execute_input":"2021-05-21T17:10:54.365737Z","iopub.status.idle":"2021-05-21T17:10:55.493413Z","shell.execute_reply.started":"2021-05-21T17:10:54.365696Z","shell.execute_reply":"2021-05-21T17:10:55.492605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observations :**\n\n* Images are in different shapes.\n* All the X-Ray images are human upper body particularly about Chest part.","metadata":{"id":"MUWDIh8MvrXO"}},{"cell_type":"markdown","source":"<h3>Exploring the Text features :</h3>","metadata":{"id":"7YoAw8aNrs5x"}},{"cell_type":"markdown","source":"**Note :** For text feature analysis, I will not consider the \"Comparision\" label/feature. The reason behind this is, comparision label has most of its values as 'none' and 'no comparision' (which I had put in place of missing values). So, this will be not much helpful to predict the Target.","metadata":{"id":"X536DCIWsSSU"}},{"cell_type":"code","source":"k = dataframe.loc[(dataframe.comparison == 'none') | (dataframe.comparison == 'no comparison')]\nprint(\"Number of rows with no informnation in comparision label:\",k.shape[0])","metadata":{"id":"vgvaIiICokA2","outputId":"24e82a5f-4406-4ef5-c31a-2dc8f8607b15","execution":{"iopub.status.busy":"2021-05-21T17:11:12.089565Z","iopub.execute_input":"2021-05-21T17:11:12.090113Z","iopub.status.idle":"2021-05-21T17:11:12.103318Z","shell.execute_reply.started":"2021-05-21T17:11:12.090073Z","shell.execute_reply":"2021-05-21T17:11:12.102178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observation :** Out of 3851 rows in data, 2805 rows have No Information in comparision feature/label.","metadata":{"id":"NL89WoqFsgqR"}},{"cell_type":"markdown","source":"**Feature Identification : Text or Categorical ?**\n\n**Note :** It seems all of the text features are just text features. We can't consider any of them as categorical. We can confirm that by finding unique values and analysing them. Because if it is categorical, then we could get better predictions compared to giving it as a text feature.\n","metadata":{"id":"BUGwe473KaJ2"}},{"cell_type":"code","source":"def unique_words_features(df):\n    '''This function takes pandas dataframe and show barplot of features unique and repeated words \n       Input  =  pandas dataframe or numpy arrays\n       Output =  barplot of the unique words of dataframe '''\n\n    #length of the feature\n    len_total = len(df.tolist())\n\n    #length of unique words in the featue\n    len_unique = len(np.unique(df.tolist()))\n\n    x = ['Total Values', 'Unique Values']\n    y =  [len_total, len_unique]\n\n    plt.bar(x,y,color = 'Teal')\n    plt.ylabel('Word-Count')\n    for index,data in enumerate(y):\n        plt.text(x=index , y =data+1 , s=f\"{data}\" , fontdict=dict(fontsize=15))\n    \n    plt.ylabel('Word-Count')","metadata":{"id":"ifuY-tPe927t","execution":{"iopub.status.busy":"2021-05-21T17:11:24.343933Z","iopub.execute_input":"2021-05-21T17:11:24.344301Z","iopub.status.idle":"2021-05-21T17:11:24.351733Z","shell.execute_reply.started":"2021-05-21T17:11:24.344271Z","shell.execute_reply":"2021-05-21T17:11:24.350712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (20,7))\nplt.subplot(131)\nunique_words_features(dataframe['indication'])\nplt.title('Unique-Words in Indication')\nplt.subplot(132)\nunique_words_features(dataframe['findings'])\nplt.title('Unique-Words in Findings')\nplt.subplot(133)\nunique_words_features(dataframe['impression'])\nplt.title('Unique-Words in Impression')\nplt.show()","metadata":{"id":"5iKt6DtNKzWx","outputId":"1f8929bf-d7dc-4307-b671-3f00c78beee3","execution":{"iopub.status.busy":"2021-05-21T17:14:39.796409Z","iopub.execute_input":"2021-05-21T17:14:39.796877Z","iopub.status.idle":"2021-05-21T17:14:40.51525Z","shell.execute_reply.started":"2021-05-21T17:14:39.796841Z","shell.execute_reply":"2021-05-21T17:14:40.514162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observation :** We conclude from above features bar plot, That all of them are text features as there are total 3851 entries and and a good chunk of values are unique in all of them i.e, They never repeated. So, they can not be categorical features.","metadata":{"id":"qKGCKe6jgTd0"}},{"cell_type":"markdown","source":"**Analysis of Indication feature :**","metadata":{"id":"e3X_RxUlaPNW"}},{"cell_type":"code","source":"#Printing min,max and median of word_count\nprint(\"Minimum number of word count for Indication is:\",np.min(dataframe.indication_count.values))\nprint(\"Maximum number of word count for Indication is:\",np.max(dataframe.indication_count.values))\nprint(\"median number of word count for Indication is:\",np.median(dataframe.indication_count.values))","metadata":{"id":"zPu9qUPuCWSu","outputId":"c4382ef3-734d-49c0-bf02-7f459de29c2a","execution":{"iopub.status.busy":"2021-05-21T17:11:37.9888Z","iopub.execute_input":"2021-05-21T17:11:37.989158Z","iopub.status.idle":"2021-05-21T17:11:37.998193Z","shell.execute_reply.started":"2021-05-21T17:11:37.989128Z","shell.execute_reply":"2021-05-21T17:11:37.996958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Plotting PDF and CDF for word_count distribution of Indication feature :","metadata":{"id":"G_YtyjPMa6oD"}},{"cell_type":"code","source":"#Plotting PDF and CDF for word_count distribution of Indication feature\nplt.figure(figsize = (12,5))\n# Seaborn PDF\nplt.subplot(121)\nsns.kdeplot(dataframe['indication_count'],shade=True,color='Red')\nplt.title(\"PDF Word-count distribution\")\nplt.subplot(122)\n# Seaborn CDF\nsns.distplot(dataframe['indication_count'], kde_kws={'cumulative': True,'shade': True}, hist=False,color='Lime')\nplt.title(\"CDF Word-count distribution\")\nplt.show()","metadata":{"id":"VR5tn0f5a55N","outputId":"2fccefa7-3c2a-4f92-a0be-5d0fc94bc1f3","execution":{"iopub.status.busy":"2021-05-21T17:14:56.699542Z","iopub.execute_input":"2021-05-21T17:14:56.699982Z","iopub.status.idle":"2021-05-21T17:14:57.23262Z","shell.execute_reply.started":"2021-05-21T17:14:56.699935Z","shell.execute_reply":"2021-05-21T17:14:57.231776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Top 50 frequent sentences of Indication feature :","metadata":{"id":"8CugP_d-d2xN"}},{"cell_type":"code","source":"#Plotting top 50 frequent sentences of Indication feature\nsentences = dataframe['indication'].value_counts()[:50]\nplt.figure(figsize=(20,5))\nsns.barplot(sentences.index, sentences.values, alpha=0.8)\nplt.ylabel('Number of Occurrences', fontsize=10)\nplt.xticks(fontsize='large',rotation=90)\nplt.title(\"Indication-Unique sentences\")\nplt.show()","metadata":{"id":"ZXKVcbpcH-W-","outputId":"9f942c81-004c-4c50-962a-045ffe97c632","execution":{"iopub.status.busy":"2021-05-21T17:15:09.020632Z","iopub.execute_input":"2021-05-21T17:15:09.021035Z","iopub.status.idle":"2021-05-21T17:15:10.303384Z","shell.execute_reply.started":"2021-05-21T17:15:09.021002Z","shell.execute_reply":"2021-05-21T17:15:10.302497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Word cloud on Indication feature : max 500 words","metadata":{"id":"MdM_P_cTeY7z"}},{"cell_type":"code","source":"wordcloud = WordCloud(max_words=500, background_color=\"black\", colormap=\"Set3\").generate(' '.join(dataframe['indication'].astype(str)))\nplt.figure(figsize=(15,10))\nplt.imshow(wordcloud, interpolation='Bilinear')\nplt.axis(\"off\")\nplt.show()","metadata":{"id":"aERNWn-BeYIi","outputId":"ad5ff06b-f47b-4426-a550-2c0948b599f8","execution":{"iopub.status.busy":"2021-05-21T17:11:58.93418Z","iopub.execute_input":"2021-05-21T17:11:58.934547Z","iopub.status.idle":"2021-05-21T17:11:59.684683Z","shell.execute_reply.started":"2021-05-21T17:11:58.934511Z","shell.execute_reply":"2021-05-21T17:11:59.683866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observations for Indication feature :**\n\n* Top two most frequent words are 'no indication' and 'chest pain' above 300 counts in feature.\n* In indication feature, 50% data have 7-8 words, 99% text data have less than 10 words in rows. Only 1% data have legnth above 10.\n* From wordcloud : chest, pain, shortness, breath, indication are the highlighted words i.e. these are important words.","metadata":{"id":"36tQB21Pujiq"}},{"cell_type":"markdown","source":"**Analysis of Findings feature :**","metadata":{"id":"8La-HvwsfyFn"}},{"cell_type":"code","source":"#Printing min,max and median of word_count\nprint(\"Minimum number of word count for finding is:\",np.min(dataframe.findings_count.values))\nprint(\"Maximum number of word count for finding is:\",np.max(dataframe.findings_count.values))\nprint(\"Median number of word count for finding is:\",np.median(dataframe.findings_count.values))","metadata":{"id":"MoYkMZlFC-gL","outputId":"6627669c-d11d-433f-f4ff-5c826e03572c","execution":{"iopub.status.busy":"2021-05-21T17:12:06.511646Z","iopub.execute_input":"2021-05-21T17:12:06.51214Z","iopub.status.idle":"2021-05-21T17:12:06.523368Z","shell.execute_reply.started":"2021-05-21T17:12:06.512108Z","shell.execute_reply":"2021-05-21T17:12:06.522478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Plotting PDF and CDF for word_count distribution of Findings feature :","metadata":{"id":"wl167H61gFEh"}},{"cell_type":"code","source":"#Plotting the PDF for word_count distribution of Findings feature\nplt.figure(figsize = (12,5))\n# Seaborn PDF\nplt.subplot(121)\nsns.kdeplot(dataframe['findings_count'],shade=True,color='Magenta')\nplt.title(\"PDF Word-count distribution\")\nplt.subplot(122)\n# Seaborn CDF\nsns.distplot(dataframe['findings_count'], kde_kws={'cumulative': True,'shade': True}, hist=False,color='Lime')\nplt.title(\"CDF Word-count distribution\")\nplt.show()","metadata":{"id":"E39rH38RgGMk","outputId":"3dff7ed9-0337-49b4-f85c-d1e209cf81a3","execution":{"iopub.status.busy":"2021-05-21T17:16:33.218725Z","iopub.execute_input":"2021-05-21T17:16:33.219262Z","iopub.status.idle":"2021-05-21T17:16:33.775317Z","shell.execute_reply.started":"2021-05-21T17:16:33.219228Z","shell.execute_reply":"2021-05-21T17:16:33.774171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Top 50 frequent sentences of Findings feature :","metadata":{"id":"ktLwg-itgb_T"}},{"cell_type":"code","source":"#Plotting top 50 frequent sentences of Findings feature\nsentences = dataframe['findings'].value_counts()[:50]\nplt.figure(figsize=(20,5))\nsns.barplot(sentences.index, sentences.values, alpha=0.8)\nplt.ylabel('Number of Occurrences', fontsize=10)\nplt.xticks(fontsize='large',rotation=90)\nplt.title(\"Findings-Unique sentences\")\nplt.show()","metadata":{"id":"aZvINFFfHUfg","outputId":"b100f160-ddba-431f-cbe0-9598cfff44cf","execution":{"iopub.status.busy":"2021-05-21T17:16:41.159081Z","iopub.execute_input":"2021-05-21T17:16:41.159483Z","iopub.status.idle":"2021-05-21T17:16:45.616027Z","shell.execute_reply.started":"2021-05-21T17:16:41.159443Z","shell.execute_reply":"2021-05-21T17:16:45.615071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Word cloud on Findings feature : max 500 words","metadata":{"id":"OiU03PXUgxAs"}},{"cell_type":"code","source":"wordcloud = WordCloud(max_words=500, background_color=\"black\", colormap=\"Set3\").generate(' '.join(dataframe['findings'].astype(str)))\nplt.figure(figsize=(15,10))\nplt.imshow(wordcloud, interpolation='Bilinear')\nplt.axis(\"off\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-21T17:17:00.778423Z","iopub.execute_input":"2021-05-21T17:17:00.778844Z","iopub.status.idle":"2021-05-21T17:17:01.680707Z","shell.execute_reply.started":"2021-05-21T17:17:00.778812Z","shell.execute_reply":"2021-05-21T17:17:01.679506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observations for Findings feature :**\n\n* In finding feature, 50% data have less than 20 words per findings, 99% data have less than 48 words per findings. Only 1% data have legnth above 48.\n* From wordcloud : pleural, effusion, silhouette, within, normal, lungs, cardiomediastinal are the highlighted words i.e. these are important words.","metadata":{"id":"c4Lt6lv6wM5I"}},{"cell_type":"markdown","source":"**Analysis of Target Feature : Impression**","metadata":{"id":"2dHGv-lFhQFE"}},{"cell_type":"code","source":"#Printing min,max and median of word_count\nprint(\"Minimum number of word count for Impression is:\",np.min(dataframe.impression_count.values))\nprint(\"Maximum number of word count for Impression is:\",np.max(dataframe.impression_count.values))\nprint(\"Median number of word count for Impression is:\",np.median(dataframe.impression_count.values))","metadata":{"id":"ImIn6x2UDOsm","outputId":"0d684559-c49e-4e35-df8f-48e3e2a086a0","execution":{"iopub.status.busy":"2021-05-21T17:12:42.179928Z","iopub.execute_input":"2021-05-21T17:12:42.180466Z","iopub.status.idle":"2021-05-21T17:12:42.188133Z","shell.execute_reply.started":"2021-05-21T17:12:42.180431Z","shell.execute_reply":"2021-05-21T17:12:42.186768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Plotting PDF and CDF for word_count distribution of Impression feature :","metadata":{"id":"cOZpf4EBhjq-"}},{"cell_type":"code","source":"#Plotting PDF and CDF for word_count distribution of Impression feature\nplt.figure(figsize = (12,5))\n# Seaborn PDF\nplt.subplot(121)\nsns.kdeplot(dataframe['impression_count'],shade=True,color='Red')\nplt.title(\"PDF Word-count distribution\")\nplt.subplot(122)\n# Seaborn CDF\nsns.distplot(dataframe['impression_count'], kde_kws={'cumulative': True,'shade': True}, hist=False,color='Lime')\nplt.title(\"CDF Word-count distribution\")\nplt.show()","metadata":{"id":"TkdHx2pthkRZ","outputId":"8105d9e7-5ed8-4066-f134-76f4d0319a1f","execution":{"iopub.status.busy":"2021-05-21T17:17:22.051769Z","iopub.execute_input":"2021-05-21T17:17:22.052161Z","iopub.status.idle":"2021-05-21T17:17:22.565854Z","shell.execute_reply.started":"2021-05-21T17:17:22.052128Z","shell.execute_reply":"2021-05-21T17:17:22.564566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Top 50 frequent sentences of Impression feature :","metadata":{"id":"_Z5RZkLEiE1n"}},{"cell_type":"code","source":"#Plotting top 50 frequent sentences of Impression feature\nsentences = dataframe['impression'].value_counts()[:50]\nplt.figure(figsize=(20,5))\nsns.barplot(sentences.index, sentences.values, alpha=0.8)\nplt.ylabel('Number of Occurrences', fontsize=10)\nplt.xticks(fontsize='large',rotation=90)\nplt.title(\"Impression-Unique sentences\")\nplt.show()","metadata":{"id":"5bRW-F84Gq4e","outputId":"c2bfed87-7cc9-4952-af0c-a391708d32e3","execution":{"iopub.status.busy":"2021-05-21T17:17:30.095938Z","iopub.execute_input":"2021-05-21T17:17:30.096295Z","iopub.status.idle":"2021-05-21T17:17:32.240473Z","shell.execute_reply.started":"2021-05-21T17:17:30.096266Z","shell.execute_reply":"2021-05-21T17:17:32.239733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Word cloud on Impression feature : max 500 words","metadata":{"id":"L_iE9cAAisfT"}},{"cell_type":"code","source":"wordcloud = WordCloud(max_words=500, background_color=\"black\", colormap=\"Set3\").generate(' '.join(dataframe['impression'].astype(str)))\nplt.figure(figsize=(15,10))\nplt.imshow(wordcloud, interpolation='Bilinear')\nplt.axis(\"off\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-21T17:18:01.149287Z","iopub.execute_input":"2021-05-21T17:18:01.149699Z","iopub.status.idle":"2021-05-21T17:18:01.968398Z","shell.execute_reply.started":"2021-05-21T17:18:01.149635Z","shell.execute_reply":"2021-05-21T17:18:01.967188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observations for Indication feature :**\n\n* Top two most impression are 'no actue cardiopulmonary abnormality' and 'no actue cardiopulmonary findings' above 400 counts in feature.\n* In indication feature, 50% data have less than 4 words per impression, it means only few impression have less words. 99% data have less than 39 words per impression. Only 1% data have legnth above 39.\n* From wordcloud : actue cardiopulmonary, cardiopulmonary abnormality, disease acute, heart size are the highlighted words i.e. these are important words.","metadata":{"id":"VGwJF9GAx1Pf"}},{"cell_type":"markdown","source":"**Total Observations :**\n\n* The dataset contains chest X-ray images and radiology text reports. Each image has been paired with four captions such as Impressions, Findings, Comparison and Indication that provide clear descriptions of the salient entities and events.. All the raw texts from xml files are parsed and created the dataset.\n\n* Images are in different shapes. All the X-Ray images are human upper body particularly about Chest part.\n\n* Each patient have multiple x-rays associated with them. The maximum number of images associated with a report can be 5 while the minimum is 0. The highest frequecy of being associated with a report are 2 images.\n\n* Data is incomplete. Because all the features have few missing values except caption. We have to impute the missing values in data preprocessing step.\n\n* In text features there are some unknown values like XXXX XXXXX these are replaced with empty string.\n\n* We have total of 3955 records and Impression is our target variable.\n\n* Most occurring words of diffrent features:\n    > Indication: Chest pain\n\n    > Findings: Pleural effusion\n\n    > Impression: acute cardiopulmonary\n\n* I created wordcloud, for 500 most frequent words of the feature. These are important words. Some of them are: acute, findings, disease, abnormality, high, right, impression, etc.","metadata":{"id":"d6cIVfzckFsB"}}]}