{"cells":[{"metadata":{},"cell_type":"markdown","source":"# First: Choose best learning rate"},{"metadata":{},"cell_type":"markdown","source":"### Import"},{"metadata":{"trusted":true},"cell_type":"code","source":"from pandas import read_csv\nfrom pandas.plotting import scatter_matrix\nfrom matplotlib import pyplot\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import preprocessing\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import accuracy_score\nimport math\n\ndf=read_csv(\"../input/telugu-6-vowel-dataset/CSV_datasetsix_vowel_dataset_with_class.csv\")\nle = preprocessing.LabelEncoder()\nle.fit(list(df[\"class\"].unique()))\ndf[\"class\"] = le.transform(df[\"class\"])\nprint(df.shape)\ndf.head(1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"X=df.iloc[:,:df.shape[1]-1]\ny=df.iloc[:,df.shape[1]-1]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\nn_inp = X.shape[1]\nn_out = len(df[\"class\"].unique())\nprint(n_inp)\nprint(n_out)\nTs = [ [1,0,0,0,0,0] , [0,1,0,0,0,0] , [0,0,1,0,0,0] , [0,0,0,1,0,0] ,[0,0,0,0,1,0], [0,0,0,0,0,1]] ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Sigmoid"},{"metadata":{"trusted":true},"cell_type":"code","source":"def sig(arr):\n    return 1/ (1+np.exp(-np.array(arr)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fit"},{"metadata":{"trusted":true},"cell_type":"code","source":"#initialize\nlrs=[0.0001,0.001,0.005,0.009,0.1,0.101,0.2,0.3,0.4,0.5,0.6,0.7,0.8]\n\ntrain_errs_list = []\ntest_errs = []\nlr_list = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for lr in lrs:\n    #train\n    #1.initialize\n    shape = [n_inp,2,n_out] ; W = [] \n    for w_random in range(len(shape)-1):\n        l = np.random.rand(shape[w_random],shape[w_random+1])\n        W.append(l)\n\n    train_err = []\n    err = 100000\n    check_err = False\n\n    for epoch in range(5): #epochs\n        if(err < 0.0001 or math.isnan(err) ):\n            break\n        if(check_err):\n            if(np.mean(epoch_err0) == np.mean(epoch_err1)): \n                break\n        epoch_err0 = []; epoch_err1 = []\n\n        for i in range(X_train.shape[0]): # batches\n            if(math.isnan(err)):\n                break\n            #2.ForWard\n            inp = X_train.iloc[i] ; a = inp ; A = [] ; H = [] ;\n            for p in range(len(W)):\n                h = np.dot(a,W[p])\n                a = sig(h)\n                H.append(h)\n                A.append(a)\n\n            #3.BackWard\n            #3.1.const\n            T_y = y_train.iloc[i] \n            T = Ts[T_y]\n            O = A[1]\n            const = (2 * (T-O)* sig(H[1] ) * (1-sig(H[1])))\n            \n            #3.2.W[1]\n            dev1 = np.dot(const.reshape(-1,1) , (A[0]).reshape(-1,1).T ).T \n            for d in range(len(dev1)):\n                W[1][d] = W[1][d] + lr * dev1[d]\n\n            #3.3.W[0]\n            WC = np.dot(W[1] , const.reshape(-1,1))\n            l = []\n            for h in range(len(H[0])):\n                l.append((WC[h] * sig(H[0][h]) * (1- sig(H[0][h])) )[0])\n            WC_arr = np.array(l).reshape(-1,1)\n            ini = np.array(inp).reshape(-1,1)\n            W[0] = W[0] + lr * ( np.dot(WC_arr,ini.T) ).T\n\n            #3.4.error\n            err = np.sum(T-O)**2/2\n            train_err.append(err)\n\n            if(epoch%2 ==0):\n                epoch_err0.append(err)\n            else:\n                epoch_err1.append(err)\n                check_err = True\n    \n    #test\n    err=0\n    for test in range(X_test.shape[0]): # batches\n        inp = X_test.iloc[test] \n        a = inp \n        A = [] ; H = [] \n        for j in range(len(W)):\n            h = np.dot(a,W[j])\n            a = sig(h)\n            H.append(h)\n            A.append(a)\n\n        T = y_test.iloc[test] # const\n        O = A[1]\n        \n        Os= list(df[\"class\"].unique())\n        O = Os[np.argmax(O)]\n        \n        if(T!=O):\n            err+=1\n    print(\"error at lr: \" , lr,\" : \", err/X_test.shape[0]*100 , \" %\")\n    train_errs_list.append( train_err )\n    test_errs.append(err/X_test.shape[0]*100)\n    lr_list.append(lr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **<span style=\"color:red\"> N.B. high error is due to small number of epochs for time saving as at this very large number of column each iteration take about 15 min -> need very high GPU  </span>**"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plot best errors"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_errs_sort = np.sort(test_errs)\ntrain_errs_list_sort = [x for _,x in sorted(zip(test_errs,train_errs_list))]\nlr_list_sort = [x for _,x in sorted(zip(test_errs,lr_list))]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_errs_list_sort_new = []\n# take every 50 points for better view of graph\nfor i in range(len(train_errs_list_sort)):\n    train_errs_list_sort_new.append(train_errs_list_sort[i][0::20])\n\nprint(np.shape(train_errs_list_sort[0]))\nprint(np.shape(train_errs_list_sort_new[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n=4\nfig, ax = plt.subplots(n,2,figsize=(15,15))\ncolor = ['r','b','g','k','y','r','b','g','k','y','r','b','g','k','y','r','b','g','k','y']\n\nfor i in range(n):\n    ax[i,0].plot(train_errs_list_sort_new[i], color[i]) \n    title = 'lr: '+str(lr_list_sort[i])\n    ax[i,0].set_title(title)\n\nfor i in range(n,8):\n    ax[i-n,1].plot(train_errs_list_sort_new[i], color[i]) \n    title = 'lr: '+str(lr_list_sort[i])\n    ax[i-n,1].set_title(title)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### From the graph we can see that lr = 0.0001  is the best and the most stable choice as it is converging while fluctuating"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Now, choose best number of nodes"},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = 0.0001\ntrain_errs_list = []\ntest_errs = []\nlr_list = []\nnodes_list = []\nfor node in range(1,12):\n    #train\n    #1.initialize\n    shape = [n_inp,node,n_out] ; W = [] \n    for w_random in range(len(shape)-1):\n        l = np.random.rand(shape[w_random],shape[w_random+1])\n        W.append(l)\n\n    train_err = []\n    err = 100000\n    check_err = False\n\n    for epoch in range(5): #epochs\n        if(err < 0.0001 or math.isnan(err) ):\n            break\n        if(check_err):\n            if(np.mean(epoch_err0) == np.mean(epoch_err1)): \n                break\n        epoch_err0 = []; epoch_err1 = []\n\n        for i in range(X_train.shape[0]): # batches\n            if(math.isnan(err)):\n                break\n            #2.ForWard\n            inp = X_train.iloc[i] ; a = inp ; A = [] ; H = [] ;\n            for p in range(len(W)):\n                h = np.dot(a,W[p])\n                a = sig(h)\n                H.append(h)\n                A.append(a)\n\n            #3.BackWard\n            #3.1.const\n            T_y = y_train.iloc[i] \n            T = Ts[T_y]\n            O = A[1]\n            const = (2 * (T-O)* sig(H[1] ) * (1-sig(H[1])))\n            \n            #3.2.W[1]\n            dev1 = np.dot(const.reshape(-1,1) , (A[0]).reshape(-1,1).T ).T \n            for d in range(len(dev1)):\n                W[1][d] = W[1][d] + lr * dev1[d]\n\n            #3.3.W[0]\n            WC = np.dot(W[1] , const.reshape(-1,1))\n            l = []\n            for h in range(len(H[0])):\n                l.append((WC[h] * sig(H[0][h]) * (1- sig(H[0][h])) )[0])\n            WC_arr = np.array(l).reshape(-1,1)\n            ini = np.array(inp).reshape(-1,1)\n            W[0] = W[0] + lr * ( np.dot(WC_arr,ini.T) ).T\n\n            #3.4.error\n            err = np.sum(T-O)**2/2\n            train_err.append(err)\n\n            if(epoch%2 ==0):\n                epoch_err0.append(err)\n            else:\n                epoch_err1.append(err)\n                check_err = True\n    \n    #test\n    err=0\n    for test in range(X_test.shape[0]): # batches\n        inp = X_test.iloc[test] \n        a = inp \n        A = [] ; H = [] \n        for j in range(len(W)):\n            h = np.dot(a,W[j])\n            a = sig(h)\n            H.append(h)\n            A.append(a)\n\n        T = y_test.iloc[test] # const\n        O = A[1]\n        \n        Os= list(df[\"class\"].unique())\n        O = Os[np.argmax(O)]\n        \n        if(T!=O):\n            err+=1\n    print(\"error at node: \" , node,\" : \", err/X_test.shape[0]*100 , \" %\")\n    train_errs_list.append( train_err )\n    test_errs.append(err/X_test.shape[0]*100)\n    nodes_list.append(node)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## plot best error"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_errs_sort = np.sort(test_errs)\ntrain_errs_list_sort = [x for _,x in sorted(zip(test_errs,train_errs_list))]\nnodes_list_sort = [x for _,x in sorted(zip(test_errs,nodes_list))]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_errs_list_sort_new = []\n# take every 50 points for better view of graph\nfor i in range(len(train_errs_list_sort)):\n    train_errs_list_sort_new.append(train_errs_list_sort[i][0::5])\n\nprint(np.shape(train_errs_list_sort))\nprint(np.shape(train_errs_list_sort_new))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n=2\nfig, ax = plt.subplots(n,2,figsize=(8,8))\ncolor = ['r','b','g','k','y','r','b','g','k','y','r','b','g','k','y','r','b','g','k','y']\n\nfor i in range(n):\n    ax[i,0].plot(train_errs_list_sort_new[i], color[i]) \n    title = 'node: '+str(nodes_list_sort[i])\n    ax[i,0].set_title(title)\n\nfor i in range(n,4):\n    ax[i-n,1].plot(train_errs_list_sort_new[i], color[i]) \n    title = 'node: '+str(nodes_list_sort[i])\n    ax[i-n,1].set_title(title)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## From the graph we can see that nodes = 2 is the best and the most converging choiceÂ¶"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}