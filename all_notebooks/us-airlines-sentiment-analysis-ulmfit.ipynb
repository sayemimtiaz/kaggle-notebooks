{"cells":[{"metadata":{},"cell_type":"markdown","source":"# US Airlines Sentiment Analysis (ULMFIT)\n\n### Introduction\n\nObjective: Apply a supervised or semi-supervised ULMFiT model to Twitter US Airlines Sentiment\n\nTwitter US Airline Sentiment dataset: https://www.kaggle.com/crowdflower/twitter-airline-sentiment#Tweets.csv \n\nUlmfit model Description: http://nlp.fast.ai/classification/2018/05/15/introducing-ulmfit.html.\n\n### Methodology\n\nThe outline of the steps taken are as follows: \n\n1) Data wrangling: In this step, we observe the dataset and make sure there aren't important features missing or missing columns. We also look at the number of labels per class for each airline. We see that the sentiment varies for every airline. Because of this, it is necessary to implement a regular expression to replace the airline name in every tweet. We don't want our machine to use 'airline name' as a means to predict the sentiment.\n\n2) Language Model Fine Tuning: First, we import a pretrained language model. For this project, we used the wikitext103 language model. We then fine tune it a bit for our particular problem by training it on our Twitter dataset. \n\n3) Classifier Fine Tuning: Currently, we have a language model that is fairly decent at predicting the next word in a sentence. But it cannot yet perform sentiment analysis. So, we train the language model to be a classifier using tweets and associated labels of \"positive\", \"negative\", or \"neutral\" also provided to us in the dataset.\n\n4) Results: In this last step, we analyze the performance of our classifier. It can predict the sentiment of the tweets at an 82.7 percent accuracy which is fairly decent at face value. Tweets can be somewhat ambiguous and things like sarcasm are difficult to account for. The misclassified tweets are observed and it seems that it is diffiuclt to distinguish between positive and neutral tweets. "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Import necessary libraries \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import fast.ai libraries for nlp\n\nfrom fastai import *\nfrom fastai.text import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport fastai.utils.collect_env\n\nfastai.utils.collect_env.show_install()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# bs=48\n# bs=24\nbs=192","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### Data Wrangling\n\nThe following cells will process our data into a dataframe. From there, we will select relevant columns for the project and use a regualar expression to filter out the airline names in all of our tweets. "},{"metadata":{"trusted":true},"cell_type":"code","source":"path = Path('../input/twitter-airline-sentiment/')\nfile_name = 'Tweets.csv'\npath.ls()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"file_path = path / file_name\ndf_airline = pd.read_csv(file_path)\ndf_airline.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_final = df_airline[['airline_sentiment', 'text']]\npd.set_option('display.max_colwidth',0)\ndf_final.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#check for missing values in data\ndf_final.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Data is skewed more towards the negative sentiment\ndf_final['airline_sentiment'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Visualize the sentiment for each airline\nsns.set(style=\"darkgrid\")\nsns.set(rc={'figure.figsize':(11.7,8.27)})\nsns.countplot(x=\"airline\", hue='airline_sentiment', data=df_airline)\nplt.title(\"Airline Sentiment For Each Airline\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we see from the plot above, the airline sentiments vary greatly depending on the airline. Virgin America is the most positive while United is the most negative overall. In order for NLP to be effective on the tweets, we need to remove the airline name in each tweet, so we don't accidentally influence our predictive model with them"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport re\nregex = r\"@(VirginAmerica|united|SouthwestAir|Delta|USAirways|AmericanAir)\"\ndef text_replace(text):\n    return re.sub(regex, '@airline', text, flags=re.IGNORECASE)\n\ndf_final['text'] = df_final['text'].apply(text_replace)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_final.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### Language Model Fine Tuning\n\nThe following cells will process our cleaned dataframe into a databunch. A databunch is a temp file perfectly organized to work in the tracks required by the training method. Then, the language model is downloaded and fine tuned on our tweets dataset. "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Split the dataframe randomly into train set and valid set. \n#TextLMDataBunch only accepts two separate dataframes for train and valid\ntrain, valid = train_test_split(df_final, test_size=0.1)\nmoms = (0.8,0.7)\nwd = 0.1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_lm = TextLMDataBunch.from_df(path, train_df = train, valid_df = valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_lm.show_batch()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.5, model_dir='/tmp/models')\nlearn.freeze()\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#learn.model_dir='/kaggle/working/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#To Find the proper learning rate, use the x value where the slope is steepest in the -y direction.\nlearn.lr_find()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.recorder.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"moms = (0.8,0.7)\nwd = 0.1\nlr = 1.0E-02\nlearn.fit_one_cycle(1, lr, moms=moms, wd=wd)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.unfreeze()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(3, lr, moms=moms, wd=wd)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.predict('This flight sucks!', n_words=20)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.save_encoder('ft_enc')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### Classifier Fine Tuning\n\nWe repeat the process of creating a databunch. Then, we train our language model to classify sentiment using the existing data and labels. "},{"metadata":{"trusted":true},"cell_type":"code","source":"train_valid, test = train_test_split(df_final, test_size=0.1)\ntrain, valid = train_test_split(train_valid, test_size=0.1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_clas = TextClasDataBunch.from_df(path,train_df=train, valid_df = valid,test_df = test, vocab=data_lm.train_ds.vocab, \n                                      text_cols='text', label_cols='airline_sentiment', bs=48)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_clas.show_batch()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.5, model_dir='/tmp/models')\nlearn.load_encoder('ft_enc')\nlearn.freeze()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.lr_find()\nlearn.recorder.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#The fast.ai ULMFIT method performs better if we do one epoch at a time for the classifier training\nlr = 1.0E-03\nlearn.fit_one_cycle(1, lr, moms=moms, wd=wd)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.freeze_to(-2)\nlr /= 2\nlearn.fit_one_cycle(1, slice(lr/(2.6**4), lr), moms=moms, wd=wd)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.freeze_to(-3)\nlr /= 2\nlearn.fit_one_cycle(1, slice(lr/(2.6**4), lr), moms=moms, wd=wd)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.unfreeze()\nlr /= 5\nlearn.fit_one_cycle(2, slice(lr/(2.6**4), lr), moms=moms, wd=wd)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.predict('this airline sucks!')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### Results\n\nFinally, we quantify the performance of our classifier by finding the accuracy. The confusion matrix is produced to help figure out which tweets the classifier is misclassifying. After that, we observe the misclassified tweets to form a hypothesis as to why they're being misclassified. "},{"metadata":{"trusted":true},"cell_type":"code","source":"interp = TextClassificationInterpretation.from_learner(learn)\nacc = accuracy(interp.preds, interp.y_true)\nprint('Accuracy: {0:.3f}'.format(acc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"interp.plot_confusion_matrix()\nplt.title('Classifation Confusion Matrix')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test_df = df_final\n#test_df['pred_sentiment'] = test_df['text'].apply(lambda row: str(learn.predict(row)[0]))\n#pred_sent_df = test_df.loc[(test_df['airline_sentiment'] == 'positive') & (test_df['pred_sentiment'] == 'negative')]\n#pred_sent_df.head(20)\n\n\ninterp.show_top_losses(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above confusion matrix highlights the number of correctly and incorrectly predicted sentiment. \nWe then observe the top losses for insight. We want to examine the incorrect predictions to understand where our\nmodel fell short"},{"metadata":{},"cell_type":"markdown","source":"> ### Conclusion\n\nWe applied the Ulmfit method in order to classify sentiment of tweets corresponding to various airlines. The method performed exceptionally well achieving a ~81 percent accuracy. \n\nThe above table shows the misclassified positive tweets as negative. Although our method is very accurate - moreso than other methods, we still want to understand better why we got these predictions wrong. \n\nIt is still unclear. But some of the tweets do carry negative sentiment aimed at other users instead of the particular airline. In addition, there are other things to consider with informal writing such as sarcasm. Finally, \nthere do appear to be tweets that are mislabeled in the dataset. Perhaps the sentiment judgment is a bit subjective. But take for example the tweet in the table above: \"@airline # epicfail on connections in # xxmaj chicago today , extremely disappointed w / xxunk customer service , rethinking loyalty üòê.\" This tweet is labeled neutral in the dataset. However, our model predicted it to be negative. I agree more with the model's prediction for this tweet than the label it came with. \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}