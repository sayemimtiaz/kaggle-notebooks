{"cells":[{"metadata":{},"cell_type":"markdown","source":"## In this study, the preprocessing of the data, the application of the models with best parameters and the performance scores of the models were determined.","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\nimport numpy as np\nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, f1_score, confusion_matrix\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom xgboost import XGBClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.naive_bayes import GaussianNB\nimport warnings\nfrom sklearn import metrics\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/bank-marketing/bank-additional-full.csv\", sep=\";\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nsns.countplot(x='education', data= df)\nsns.despine()\nprint(df['previous'].value_counts())\nprint(\" Job title : \", df['job'].unique())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Education state\nfig, ax=plt.subplots()\nfig.set_size_inches(10,8)\nsns.countplot(x='education',data=df)\nax.set_xlabel('Education', fontsize=15)\nax.set_ylabel('Count', fontsize=15)\nax.set_title(\"Education State\", fontsize=15)\nsns.despine()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# marital\nprint(\"\\nMarital\")\nfig, ax=plt.subplots()\nfig.set_size_inches(10,8)\nsns.countplot(x='marital', data=df)\nax.set_xlabel(\"marital\", fontsize=10)\nax.set_ylabel(\"Count\", fontsize=10)\nax.set_title(\"Marital State\", fontsize=15)\nsns.despine()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Encoding \n\nfrom sklearn.preprocessing import  LabelEncoder\n\nEncoder=LabelEncoder()\n\ndf['job']=Encoder.fit_transform(df['job'])\n#df['marital']=Encoder.fit_transform(df['marital'])\ndf['education']=Encoder.fit_transform(df['education'])\ndf['default']=Encoder.fit_transform(df['default'])\ndf['housing']=Encoder.fit_transform(df['housing'])\ndf['loan']=Encoder.fit_transform(df['loan'])\ndf['month']=Encoder.fit_transform(df['month'])\ndf['contact']=Encoder.fit_transform(df['contact'])\ndf['day_of_week']=Encoder.fit_transform(df[\"day_of_week\"])\ndf['poutcome']=Encoder.fit_transform(df['poutcome'])\n\n# transform to binary the target attribute\ndf['y']=Encoder.fit_transform(df['y'])\n\n# setting value of marital\n\ndf['marital'].replace(['married', 'single', 'divorced','unknown'],[1,2,3,4], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Setting value of age","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[df['age'] <26, 'age'] = 1\ndf.loc[(df['age'] >25) & (df['age']< 49 ),'age']=2\ndf.loc[(df['age']>48)&(df['age']<71), 'age']=3\ndf.loc[(df['age'] >70)&(df['age']<98), 'age']=4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfig, (ax1,ax2) = plt.subplots(ncols=2,nrows=1, figsize = (13, 5))\n\nsns.boxplot(x=df['education'],ax=ax2)\nax2.set_xlabel(\"education\", fontsize=15)\nsns.despine(ax=ax2)\nax1.tick_params(labelsize=10)\n\nsns.distplot(df['duration'], ax = ax1)\nsns.despine(ax = ax1)\nprint(\"Max : {} and Min duration  : {} \" .format(max(df['duration']), min(df['duration'])))\n\n# Setting value of duration\ndf.loc[df['duration']<120 , 'duration'] = 1 \ndf.loc[(df['duration'] > 119)&( df['duration'] <= 200) , 'duration'] =2\ndf.loc[(df['duration'] >200)&( df['duration'] <=350), 'duration']=3\ndf.loc[(df['duration'] >350)&( df['duration']<=550), 'duration']=4\ndf.loc[df['duration'] > 550, 'duration']=5\n\n# Target Attribute\ny=df.iloc[:,df.columns=='y']\nx=df.iloc[:,df.columns!='y']\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## last state the data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n## Splitting the data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3, random_state=0)\n\n# proccess of Standardize\nfrom sklearn.preprocessing import StandardScaler\nS_Scaler=StandardScaler()\nx_train=S_Scaler.fit_transform(x_train)\nx_test=S_Scaler.fit_transform(x_test)\n\nprint(x_train.shape, x_test.shape, y_train.shape, y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n## KNN model implamentation with best parameters GridSourceCV","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#grid={'n_neighbors': np.arange(1,20,1)}\nKnnClass=KNeighborsClassifier(n_neighbors=9)\n#KnnCV=GridSearchCV(KnnClas, grid, cv=10)\nKnnClass.fit(x_train,np.ravel(y_train,order='C'))\n#print(\"Best Parameters : {}\\nBest Score {} \".format(KnnCV.best_params_, KnnCV.best_score_) )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Xgboosting model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#%% Xgboosting model \n\nXgboost=XGBClassifier(learning_rate=0.1,max_depth=4, n_estimators=100,verbosity=1)\nXgboost.fit(x_train,np.ravel(y_train,order='C'))\ny_pred=Xgboost.predict(x_test)\nprint(\"Test accuracy with XGBoos: \",accuracy_score(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## SVM model with best parameters","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\ngrid={'C':[0.0001,0.001,0.01,1] ,'gamma':['auto','scale'],'kernel':['rbf','linear','sigmoid'] , 'max_iter':[10,100]}\nSVCModel=SVC(probability=True)\nSVCGCV=GridSearchCV(SVCModel,grid,cv=10)\nSVCGCV.fit(x_train,np.ravel(y_train, order='C'))\nprint(\"Best Params {} and best score {}\".format(SVCGCV.best_params_, SVCGCV.best_score_))\n#print(SVCModel.score(x_test,np.ravel(y_test, order='C')))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Best Params for SVM model** {'C': 1, 'gamma': 'scale', 'kernel': 'sigmoid', 'max_iter': 100} and best score : 0.8270261536011716\n\n\nThis parameters are detection with method of 'GridSourceCV'","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Random Forest Model And Confusion Matrix","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RForest=RandomForestClassifier(n_estimators=20)\nRForest.fit(x_train,np.ravel(y_train,order='C'))\nRFPred=RForest.predict(x_test)\nprint(\"Random Forest Accuracy : \" ,accuracy_score(y_test,RFPred))\nprint(\"Cross Valudate Score : \", cross_val_score(RForest,x_test,y_test.values.ravel()))\nprint(\"Confisuon matrix :\", confusion_matrix(y_test,RFPred.ravel()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Logistic Regression Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"LRegression=LogisticRegression()\nLRegression.fit(x_train,y_train.values.ravel())\ny_predLR=LRegression.predict(x_test)\nprint(\"Logistic Regression Accuracy :\", accuracy_score(y_test,y_predLR.ravel()))\nprint(\"Cross val score :\", cross_val_score(LRegression,x_train,y_train.values.ravel(),cv=10,n_jobs=1,scoring='accuracy').mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Naive Bayes Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\nBayesModel=GaussianNB()\nBayesModel.fit(x_train,y_train.values.ravel())\nbayesPred=BayesModel.predict(x_test)\nprint(\"Bayes Model Accuracy :\", accuracy_score(y_test,bayesPred.ravel()))\nprint(\"Cross val score :\", cross_val_score(BayesModel,x_train,y_train.values.ravel(),cv=10,n_jobs=2,scoring='accuracy').mean())\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Seeing best model by use roc curve.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"\nWe can use graphic roc to see the accuracy score of the applied methods. The Roc method shows us the accuracy shape with the infographic shape.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax_Array = plt.subplots(nrows = 1,  figsize = (8,6))\n\n# bayes roc\nprobs = BayesModel.predict_proba(x_test)\npreds = probs[:,1]\nfprbayes, tprxbayes, thresholdbayes = metrics.roc_curve(y_test, preds)\nroc_aucbayes = metrics.auc(fprbayes, tprxbayes)\n\n# LR roc\n\nprobs=LRegression.predict_proba(x_test)\npredicts=probs[:,1]\nfprLR,tprLR, thresholdLR=metrics.roc_curve(y_test,predicts)\nroc_aucLR=metrics.auc(fprLR,tprLR)\n\n# KNN roc\nprobs=KnnClass.predict_proba(x_test)\npredKnn=probs[:,1]\nfprKnn, tprKnn, thresholdKnn=metrics.roc_curve(y_test,predKnn)\nroc_aucknn=metrics.auc(fprKnn,tprKnn)\n\n\n# Random Forest \nprobs=RForest.predict_proba(x_test)\npred_RForest=probs[:,1]\nfprRF,tprRF,thresholfRF= metrics.roc_curve(y_test,pred_RForest)\nroc_aucRF=metrics.auc(fprRF,tprRF)\n\n # SVM model roc\n \nprob=SVCGCV.predict_proba(x_test)\npred_Svm=prob[:,1]\nfprSvm,tprsvm,tresholdSvm=metrics.roc_curve(y_test,pred_Svm)\nroc_aucSvm=metrics.auc(fprSvm,tprsvm) \n\n\n\n\nax_Array.plot(fprSvm,tprsvm, 'b', label='SMV Auc %0.2f' %roc_aucSvm, color=\"green\")\nax_Array.plot(fprRF,tprRF,'b', label=\"RF Auc %0.2f\"%roc_aucRF, color=\"blue\")\nax_Array.plot(fprKnn,tprKnn,'b', label=\"Knn Auc %0.2f\" %roc_aucknn, color=\"red\")\nax_Array.plot(fprLR,tprLR, 'b', label='LR Auc = %0.2f' % roc_aucLR, color='pink')\nax_Array.plot(fprbayes,tprxbayes,'b', label='Bayes Auc %0.2f' % roc_aucbayes, color=\"black\")\nax_Array.set_title('Receiver Operating Characteristic LR ',fontsize=10)\nax_Array.set_ylabel('True Positive Rate',fontsize=20)\nax_Array.set_xlabel('False Positive Rate',fontsize=15)\nax_Array.legend(loc = 'lower right', prop={'size': 10})\n\n\n\nplt.subplots_adjust(wspace=1)\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}