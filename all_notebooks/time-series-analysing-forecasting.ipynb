{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Time Series Analysis and Forecastingüìà on Australia TourismüåÖ\n"},{"metadata":{},"cell_type":"markdown","source":"In this notebook:\n* Dataset Exploration\n* Data Preprocessing\n* Time-Series Analysis\n* Time Series Forecasting with ARIMA\n* Time Series Forecasting with Prophet\n* LSTM out-of-sample prediction\n* LSTM one-step-ahead forecast for future"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# import packages\nimport csv\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nplt.style.use('fivethirtyeight')\nimport statsmodels.api as sm\nimport matplotlib.dates as mdates\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom pandas.plotting import register_matplotlib_converters\nregister_matplotlib_converters()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#read data\ndata = pd.read_csv('../input/au-tourism/tourism.csv')\ndata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=data.drop(columns=\"Unnamed: 0\")\ndata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"sorted(data['Quarter'].value_counts().index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['State'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom palettable.colorbrewer.qualitative import Pastel1_8\n\ndw=data.groupby('State')[\"Trips\"].sum().reset_index()\n\n#create data\nnames=list(data[\"State\"].unique())\ntotal_trips=dw[\"Trips\"].sum()\n\ndw[\"Trips-%\"]=dw[\"Trips\"] / total_trips\n\nsns.set(style = 'white', font_scale = 1)\ncolors = Pastel1_8.hex_colors\nexplode = (0, 0, 0, 0, 0, 0, 0, 0)  # explode a slice if required\n\nplt.figure(figsize=(5,5))\nplt.pie(dw[\"Trips-%\"], explode=explode, labels=names, colors=colors,\n        autopct='%1.1f%%', shadow=True)\n        \n#draw a circle at the center of pie to make it look like a donut\ncentre_circle = plt.Circle((0,0),0.75,color='black', fc='white',linewidth=2)\nfig = plt.gcf()\nfig.gca().add_artist(centre_circle)\n\n#set aspect ratio to be equal so that pie is drawn as a circle.\nplt.axis('equal')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom palettable.colorbrewer.qualitative import Pastel2_5\n\ndp=data.groupby('Purpose')[\"Trips\"].sum().reset_index()\n\n#create data\nnames=list(data[\"Purpose\"].unique())\ntotal_trips=dw[\"Trips\"].sum()\n\ndp[\"Trips-%\"]=dp[\"Trips\"] / total_trips\n\nsns.set(style = 'white', font_scale = 1)\ncolors = Pastel2_5.hex_colors\nexplode = (0, 0, 0, 0)  # explode a slice if required\n\nplt.figure(figsize=(5,5))\nplt.pie(dp[\"Trips-%\"], explode=explode, labels=names, colors=colors,\n        autopct='%1.1f%%', shadow=True)\n        \n#draw a circle at the center of pie to make it look like a donut\ncentre_circle = plt.Circle((0,0),0.75, color='black', fc='white',linewidth=2)\nfig = plt.gcf()\nfig.gca().add_artist(centre_circle)\n\n#set aspect ratio to be equal so that pie is drawn as a circle.\nplt.axis('equal')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#most visited 10 regions\ndf_region=data.groupby('Region')[\"Trips\"].sum().reset_index().sort_values(\"Trips\", ascending=False)\ndf_region.reset_index(drop=True, inplace=True)\ntop_10_region=df_region.loc[:9, :]\ntop_10_region\n\n\n#least visited 10 regions\nbottom_10_region=df_region.tail(10)\nbottom_10_region","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(7,7))\nsns.barplot(x=\"Region\", y=\"Trips\", data=top_10_region, palette=\"rocket\")\nplt.title(\"Top 10 visited regions\")\nplt.xticks(rotation=90);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(7,7))\nsns.barplot(x=\"Region\", y=\"Trips\", data=bottom_10_region, palette=\"vlag\")\nplt.title(\"Least 10 visited regions\")\nplt.xticks(rotation=90);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We need \"Quarter\" feature in \"datetime type\"  while making forecast, below convert object type to datetime type and \nrename column as a \"date\"."},{"metadata":{"trusted":true},"cell_type":"code","source":"date=pd.to_datetime(data['Quarter'].str.replace(' ', '')) + pd.offsets.QuarterEnd(0)\ndf_date=date.to_frame()\ndf_date=df_date.rename(columns={\"Quarter\": \"date\"})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.concat([df_date, data], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[['year','q']] = df['Quarter'].str.split('Q', expand=True)\ndf['year'] = df['year'].astype(int)\ndf['q'] = 'Q' + df['q']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df[['date', 'Quarter', 'year', 'q', 'State', 'Region', 'Purpose', 'Trips']]\ndf=df.drop(columns=[\"Quarter\", \"q\"])\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"state_trips = df.groupby(['State'])['Trips'].sum()\ndf_state_trips=pd.DataFrame(state_trips)\ndf_state_trips","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"state_year_trips = df.groupby(['State', 'year'])['Trips'].sum()\ndf_state_year_trips=pd.DataFrame(state_year_trips)\ndd=df_state_year_trips.reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"state_names=list(df['State'].unique())\n\n#parameters\nplt.rcParams['figure.figsize'] = [30, 15]\nsns.set(style = 'white', font_scale = 2)\nsns.set_style(\"darkgrid\")\n\n#plot\narrival = sns.barplot(x='year', y=\"Trips\", hue = 'State', data = dd, palette = sns.color_palette(\"hls\", 8), hue_order = state_names)\n\narrival.set(title = \"Number of trips per year for each state\")\nplt.legend(loc='right', bbox_to_anchor=(1.18, 0.5));","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"state_purpose_trips = df.groupby(['State', 'Purpose'])['Trips'].sum()\ndf_state_purpose_trips=pd.DataFrame(state_purpose_trips)\nds=df_state_purpose_trips.reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# parameters\nplt.rcParams['figure.figsize'] = [17, 5]\nsns.set(style = 'white', font_scale = 1)\nsns.set_style(\"darkgrid\")\n\n# plot\narr = sns.barplot(x='State', y=\"Trips\", hue = 'Purpose', data = ds, palette = sns.color_palette(\"rocket_r\", 4))\n\narr.set(title = \"Number of trips per state for each purpose\")\nsns.despine(left=True);\nplt.legend(loc='right', bbox_to_anchor=(1, 0.85));","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Time Series Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"state_sa = df.loc[df['State'] == 'South Australia']\nstate_nsw = df.loc[df['State'] == 'New South Wales']\nstate_vic = df.loc[df['State'] == 'Victoria']\n\n#state_sa['date'].min(), state_sa['date'].max()\n#state_nsw['date'].min(), state_nsw['date'].max()\nstate_vic['date'].min(), state_vic['date'].max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols=[\"year\", \"Region\", \"Purpose\"]\nstate_sa.drop(cols, axis=1, inplace=True)\nstate_sa = state_sa.sort_values('date')\n\nprint(\"South Australia:\\n\", state_sa.isnull().sum())\n\n###########    ###########   ###########\n\nstate_nsw.drop(cols, axis=1, inplace=True)\nstate_nsw = state_nsw.sort_values('date')\n\nprint(\"New South Wales:\\n\", state_nsw.isnull().sum())\n\n###########    ###########   ###########\n\nstate_vic.drop(cols, axis=1, inplace=True)\nstate_vic = state_vic.sort_values('date')\n\nprint(\"Victoria:\\n\", state_vic.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"state_sa = state_sa.groupby('date')['Trips'].sum().reset_index()\nstate_sa = state_sa.set_index('date')\nstate_sa.index\n\n###########    ###########   ###########\nstate_nsw = state_nsw.groupby('date')['Trips'].sum().reset_index()\nstate_nsw = state_nsw.set_index('date')\nstate_nsw.index\n\n###########    ###########   ###########\nstate_vic = state_vic.groupby('date')['Trips'].sum().reset_index()\nstate_vic = state_vic.set_index('date')\nstate_vic.index","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Our current datetime data can be tricky to work with, but not(dataset only consists end of the each four quarters).\nMake it guarantee we will be using the end of each quarter as the timestamp."},{"metadata":{"trusted":true},"cell_type":"code","source":"south_au = state_sa['Trips'].resample('Q').mean()\ndf_state_sa=south_au.reset_index()\n\n###########    ###########   ###########\nnsw = state_nsw['Trips'].resample('Q').mean()\ndf_state_nsw=nsw.reset_index()\n\n###########    ###########   ###########\nvic = state_vic['Trips'].resample('Q').mean()\ndf_state_vic=vic.reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"###### South Australia ######\nplt.style.use(\"seaborn-darkgrid\")\n\nplt.figure(figsize=(40, 10))\nplt.title(\"Trips to state: South Australia\", fontsize=30)\nplt.xlabel(\"date\", fontsize=25)\nplt.ylabel(\"# of trips\", fontsize=25)\n\nax = plt.gca()\n\nyearformatter = mdates.DateFormatter(\"%Y\")\nmonthformatter = mdates.DateFormatter(\"%m\")\n\nyearlocator = mdates.YearLocator()\nax.xaxis.set_major_locator(yearlocator)\n\nmonthlocator = mdates.MonthLocator((3,6,9,12))\nax.xaxis.set_minor_locator(monthlocator)\n\nax.xaxis.set_major_formatter(yearformatter)\nax.xaxis.set_minor_formatter(monthformatter)\n\nax.tick_params(which='major', length=25)\nax.tick_params(which='minor',length=4 )\n\nplt.grid(b=True, which='minor', color='0.7', linestyle='-')\n\nplt.plot(df_state_sa[\"date\"], df_state_sa[\"Trips\"], color='r')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- There is a seasonality in the data. We can see that for each year trend goes up Q1->Q2 and Q3->Q4, goes down Q2->Q3.\n- Trips reach top values between Q1-Q2 and bottom values between Q3-Q4"},{"metadata":{},"cell_type":"markdown","source":"We can also visualize our data using a method called time-series decomposition that allows us to decompose our time series into three distinct components: trend, seasonality, and noise.\n\n1. Trend: how things are overall changing\n2. Seasonality: how things change within a given period(a year, month, week, day)\n3. Residual(error): activity not explained by the trend or the seasonal value\n\n==> O = T + S + R"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Region: South Australia(trend-seasonality-noise)\nfrom pylab import rcParams\n\nrcParams['figure.figsize'] = 18, 10\ndecomposition = sm.tsa.seasonal_decompose(south_au, model='additive')#seasonal var. is constant\nfig = decomposition.plot()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- The plot above clearly shows that the trips for state(South Australia) is unstable, along with its obvious seasonality."},{"metadata":{"trusted":true},"cell_type":"code","source":"###### New South Wales ######\nplt.style.use(\"seaborn-darkgrid\")\n\nplt.figure(figsize=(40, 10))\nplt.title(\"Trips to state:New South Wales\", fontsize=30)\nplt.xlabel(\"date\", fontsize=25)\nplt.ylabel(\"# of trips\", fontsize=25)\n\nax = plt.gca()\n\nyearformatter = mdates.DateFormatter(\"%Y\")\nmonthformatter = mdates.DateFormatter(\"%m\")\n\nyearlocator = mdates.YearLocator()\nax.xaxis.set_major_locator(yearlocator)\n\nmonthlocator = mdates.MonthLocator((3,6,9,12))\nax.xaxis.set_minor_locator(monthlocator)\n\nax.xaxis.set_major_formatter(yearformatter)\nax.xaxis.set_minor_formatter(monthformatter)\n\nax.tick_params(which='major', length=25)\nax.tick_params(which='minor',length=4 )\n\nplt.grid(b=True, which='minor', color='0.7', linestyle='-')\n\nplt.plot(df_state_nsw[\"date\"], df_state_nsw[\"Trips\"], color='g')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Region: New South Wales(trend-seasonality-noise)\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 18, 10\ndecomposition = sm.tsa.seasonal_decompose(nsw, model='additive')\nfig = decomposition.plot()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"###### Victoria ######\nplt.style.use(\"seaborn-darkgrid\")\n\nplt.figure(figsize=(40, 10))\nplt.title(\"Trips to state:Victoria\", fontsize=30)\nplt.xlabel(\"date\", fontsize=25)\nplt.ylabel(\"# of trips\", fontsize=25)\n\nax = plt.gca()\n\nyearformatter = mdates.DateFormatter(\"%Y\")\nmonthformatter = mdates.DateFormatter(\"%m\")\n\nyearlocator = mdates.YearLocator()\nax.xaxis.set_major_locator(yearlocator)\n\nmonthlocator = mdates.MonthLocator((3,6,9,12))\nax.xaxis.set_minor_locator(monthlocator)\n\nax.xaxis.set_major_formatter(yearformatter)\nax.xaxis.set_minor_formatter(monthformatter)\n\nax.tick_params(which='major', length=25)\nax.tick_params(which='minor',length=4 )\n\nplt.grid(b=True, which='minor', color='0.7', linestyle='-')\n\nplt.plot(df_state_vic[\"date\"], df_state_vic[\"Trips\"], color='y')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Region: Victoria(trend-seasonality-noise)\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 18, 10\ndecomposition = sm.tsa.seasonal_decompose(vic, model='additive')\nfig = decomposition.plot()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Time Series of South Australia - New South Wales - Victoria"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_south_au = pd.DataFrame({'date':south_au.index, 'Trips':south_au.values})\ndf_nsw = pd.DataFrame({'date': nsw.index, 'Trips': nsw.values})\ndf_vic = pd.DataFrame({'date': vic.index, 'Trips': vic.values})\n\ndf_sa_nsw = df_south_au.merge(df_nsw, how='inner', on='date')\ndf_sa_nsw.rename(columns={'Trips_x': 'Trips_SA', 'Trips_y': 'Trips_NSW'}, inplace=True)\n\ndf_sa_nsw_vic = df_sa_nsw.merge(df_vic, how='inner', on='date')\ndf_sa_nsw_vic.rename(columns={'Trips': 'Trips_VIC'}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(25, 8))\nplt.plot(df_sa_nsw_vic['date'], df_sa_nsw_vic['Trips_SA'], 'b-', label = 'South Australia')\nplt.plot(df_sa_nsw_vic['date'], df_sa_nsw_vic['Trips_NSW'], 'r-', label = 'New South Wales')\nplt.plot(df_sa_nsw_vic['date'], df_sa_nsw_vic['Trips_VIC'], 'g-', label = 'Victoria')\nplt.xlabel('Date', fontsize=18); \nplt.ylabel('Trips', fontsize=18);\nplt.title('Trips of South Australia - New South Wales - Victoria', fontsize=25)\nplt.legend(loc=\"right\", bbox_to_anchor=(1.10, 0.8));","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Before we can build a model, we must ensure that the time series is stationary. There are two primary way to determine whether a given time series is stationary.\n\n==>Rolling Statistics: Plot the rolling mean and rolling standard deviation. The time series is stationary if they remain constant with time (with the naked eye look to see if the lines are straight and parallel to the x-axis).\n\n==>Augmented Dickey-Fuller Test: The time series is considered stationary if the p-value is low (according to the null hypothesis) and the critical values at 1%, 5%, 10% confidence intervals are as close as possible to the ADF Statistics"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_stats_sa=df_south_au.set_index([\"date\"])\ndf_stats_sa.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rolling_mean = df_stats_sa.rolling(window = 4).mean()\nrolling_std = df_stats_sa.rolling(window = 4).std()\n\nplt.plot(df_stats_sa, color = 'black', label = 'Original')\nplt.plot(rolling_mean, color = 'yellow', label = 'Rolling Mean')\nplt.plot(rolling_std, color = 'darkblue', label = 'Rolling Std')\n\nplt.legend(loc = 'best')\nplt.title('Rolling Mean & Rolling Standard Deviation')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- As you can see, the rolling mean and rolling standard deviation is changing with time. Therefore, we can conclude that the time series is not stationary."},{"metadata":{"trusted":true},"cell_type":"code","source":"result = adfuller(df_stats_sa['Trips'])\nprint('ADF Statistic: {}'.format(result[0]))\nprint('p-value: {}'.format(result[1]))\nprint('Critical Values:')\nfor key, value in result[4].items():\n    print('\\t{}: {}'.format(key, value))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- The ADF Statistic is far from the critical values and the p-value is greater than the threshold (0.05). Thus, we can conclude that the time series is not stationary."},{"metadata":{},"cell_type":"markdown","source":"So, now what we will do?"},{"metadata":{},"cell_type":"markdown","source":"==> There are multiple transformations that we can apply to a time series to render it stationary. For instance, we subtract the rolling mean."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Taking the log of the dep. var. to make lower the rate at which rol. mean increases\ndf_log = np.log(df_stats_sa)\n#plt.plot(df_log)\n\nrolling_mean_new = df_log.rolling(window=4).mean()\ndf_log_mean = df_log - rolling_mean_new\ndf_log_mean.dropna(inplace=True)\n\n###### get stationarity ######\nrol_mean = df_log_mean.rolling(window = 4).mean()\nrol_std = df_log_mean.rolling(window = 4).std()\n\nplt.plot(df_log_mean, color = 'black', label = 'Original')\nplt.plot(rol_mean, color = 'orange', label = 'Rolling Mean')\nplt.plot(rol_std, color = 'purple', label = 'Rolling Std')\n\nplt.legend(loc = 'best')\nplt.title('Rolling Mean & Rolling Standard Deviation')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_new = adfuller(df_log_mean['Trips'])\nprint('ADF Statistic: {}'.format(result_new[0]))\nprint('p-value: {}'.format(result_new[1]))\nprint('Critical Values:')\nfor key, value in result[4].items():\n    print('\\t{}: {}'.format(key, value))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- As we can see, after subtracting the mean, the rolling mean and standard deviation are approximately horizontal. The p-value=0.04 is below the threshold of 0.05 and the ADF Statistic is close to the critical values. Now, we can say that the time series is stationary."},{"metadata":{},"cell_type":"markdown","source":"\n\n*Friends, I hope everyting is clear so far. Since you've came this far, you're wondering about the end of the movie, right? So, let's get a cup of coffee and stay with me:))‚òïÔ∏èüçÆ*"},{"metadata":{},"cell_type":"markdown","source":"One of the methods available in Python to model and predict future points of a Time Series is known as SARIMAX, which stands for Seasonal AutoRegressive Integrated Moving Averages with eXogenous regressors. Here, we will primarily focus on the ARIMA component, which is used to fit time-series data to better understand and forecast future points in the time series."},{"metadata":{},"cell_type":"markdown","source":"# Time series forecasting with ARIMA"},{"metadata":{},"cell_type":"markdown","source":"#  **1. Parameter Selection for the ARIMA Time Series Model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import itertools\n\np = d = q = range(0, 3)\npdq = list(itertools.product(p, d, q))\nseasonal_pdq = [(x[0], x[1], x[2], 4) for x in list(itertools.product(p, d, q))]\naic_min=np.inf\nparam_min=0\nparam_seasonal_min=0\n\n\n#‚Äúgrid search‚Äù to find the optimal set of parameters that yields the best performance for our model.\nfor param in pdq:\n    for param_seasonal in seasonal_pdq:\n        try:\n            mod = sm.tsa.statespace.SARIMAX(south_au,\n                                            order=param,\n                                            seasonal_order=param_seasonal,\n                                            enforce_stationarity=False,\n                                            enforce_invertibility=False)\n            \n            results = mod.fit()\n            aic_current=results.aic\n            #print('ARIMA{}x{}4 - AIC:{}'.format(param, param_seasonal, aic_current))\n            if(aic_current < aic_min):\n                aic_min=aic_current\n                param_min=param\n                param_seasonal_min=param_seasonal\n        except:\n            continue\n            \nprint(aic_min, \"-->>\", param_min,\"---\",param_seasonal_min)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **2. Fitting an ARIMA Time Series Model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = sm.tsa.statespace.SARIMAX(south_au,\n                                order=param_min,\n                                seasonal_order=param_seasonal_min,\n                                enforce_stationarity=False,\n                                enforce_invertibility=False)\n\n\nresults = model.fit()\nresults.summary().tables[1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- The summary attribute that results from the output of SARIMAX returns a significant amount of information, but we‚Äôll focus our attention on the table of coefficients. The coef column shows the weight (i.e. importance) of each feature and how each one impacts the time series. The P>|z| column informs us of the significance of each feature weight. Here, each weight has a p-value nearly close to 0.05, so it is reasonable to retain all of them in our model."},{"metadata":{},"cell_type":"markdown","source":"- When fitting seasonal ARIMA models, it is important to run model diagnostics to ensure that none of the assumptions made by the model have been violated. The plot_diagnostics object allows us to quickly generate model diagnostics and investigate for any unusual behavior."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use('fivethirtyeight')\nresults.plot_diagnostics(figsize=(16, 8))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Our primary concern is to ensure that the residuals of our model are uncorrelated and normally distributed with zero-mean. If the  SARIMA model does not satisfy these properties, it is a good indication that it can be further improved.\n\n==> In the top right plot, we see that the red KDE line follows closely with the N(0,1) line (where N(0,1)) is the standard notation for a normal distribution with mean 0 and standard deviation of 1). This is a good indication that the residuals are normally distributed.\n\n\n==> The qq-plot on the bottom left shows that the ordered distribution of residuals (blue dots) follows the linear trend of the samples taken from a standard normal distribution with N(0, 1). Again, this is a strong indication that the residuals are normally distributed.\n\n\n==> The residuals over time (top left plot) don‚Äôt display any obvious seasonality. This is confirmed by the autocorrelation (i.e. correlogram) plot on the bottom right, which shows that the time series residuals have low correlation with lagged versions of itself."},{"metadata":{},"cell_type":"markdown","source":"# **3. Validating Forecasts(static/dynamic)**"},{"metadata":{},"cell_type":"markdown","source":"- We have obtained a model for our time series that can now be used to produce forecasts. We start by comparing predicted values to real values of the time series, which will help us understand the accuracy of our forecasts."},{"metadata":{"trusted":true},"cell_type":"code","source":"########## Static Forecasting(one-step ahead, dynamic=False) ##########\n\npred_static = results.get_prediction(start=pd.to_datetime('2015-03-31'), dynamic=False)\npred_ci_static = pred_static.conf_int()\n\nplt.style.use(\"seaborn-darkgrid\")\nax = south_au['2010':].plot(label='observed')\n\nyearformatter = mdates.DateFormatter(\"%Y\")\nmonthformatter = mdates.DateFormatter(\"%m\")\n\nyearlocator = mdates.YearLocator()\nmonthlocator = mdates.MonthLocator((3,6,9,12))\n\nax.xaxis.set_major_locator(yearlocator)\nax.xaxis.set_minor_locator(monthlocator)\n\nax.xaxis.set_major_formatter(yearformatter)\nax.xaxis.set_minor_formatter(monthformatter)\n\nax.tick_params(which='major', length=4)\nax.tick_params(which='minor', length=2)\n\npred_static.predicted_mean.plot(ax=ax, label='One-step ahead Forecast', alpha=.7, figsize=(14, 7))\nax.fill_between(pred_ci_static.index,\n                pred_ci_static.iloc[:, 0],\n                pred_ci_static.iloc[:, 1], color='k', alpha=.2)\n\nplt.grid(b=True, which='minor', color='0.7', linestyle='-')\n\nax.set_xlabel('Date')\nax.set_ylabel('Trips')\nplt.legend(loc='top', bbox_to_anchor=(1.2, .8))\n\nplt.title(\"Validate one-step-ahead(static) forecast: South Australia\", fontsize=15)\n\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#the mean square error of static static forecast\ny_forecasted = pred_static.predicted_mean\ny_truth = south_au['2015-03-31':]\nmse = ((y_forecasted - y_truth) ** 2).mean()\nprint('The MSE of one-step-ahead(static) forecast: {}'.format(round(mse, 2)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- In statistics, the mean squared error (MSE) of an estimator measures the average of the squares of the errors ‚Äî that is, the average squared difference between the estimated values and what is estimated. The MSE is a measure of the quality of an estimator ‚Äî it is always non-negative, and the smaller the MSE, the closer we are to finding the line of best fit."},{"metadata":{},"cell_type":"markdown","source":"==> better representation of our true predictive power can be obtained using dynamic forecasts. In this case, we only use information from the time series up to a certain point, and after that, forecasts are generated using values from previous forecasted time points."},{"metadata":{"trusted":true},"cell_type":"code","source":"########## Dynamic Forecasting(dynamic=True) ##########\n\npred_dynamic = results.get_prediction(start=pd.to_datetime('2015-03-31'), dynamic=True, full_results=True)\npred_dynamic_ci = pred_dynamic.conf_int()\n\n\nplt.style.use(\"seaborn-darkgrid\")\nax = south_au['2010':].plot(label='observed')\n\nyearformatter = mdates.DateFormatter(\"%Y\")\nmonthformatter = mdates.DateFormatter(\"%m\")\n\nyearlocator = mdates.YearLocator()\nmonthlocator = mdates.MonthLocator((3,6,9,12))\n\nax.xaxis.set_major_locator(yearlocator)\nax.xaxis.set_minor_locator(monthlocator)\n\nax.xaxis.set_major_formatter(yearformatter)\nax.xaxis.set_minor_formatter(monthformatter)\n\nax.tick_params(which='major', length=4)\nax.tick_params(which='minor', length=2)\n\npred_dynamic.predicted_mean.plot(ax=ax, label='Dynamic Forecast', alpha=.7, figsize=(14, 7))\nax.fill_between(pred_dynamic_ci.index,\n                pred_dynamic_ci.iloc[:, 0],\n                pred_dynamic_ci.iloc[:, 1], color='k', alpha=.2)\n\nplt.grid(b=True, which='minor', color='0.7', linestyle='-')\n\nax.fill_betweenx(ax.get_ylim(), pd.to_datetime('2015-03-31'), south_au.index[-1],\n                 alpha=.1, zorder=-1)\n\n\nax.set_xlabel('Date')\nax.set_ylabel('Trips')\nplt.legend(loc='top', bbox_to_anchor=(1., .8))\n\nplt.title(\"Validate dynamic forecast: South Australia\", fontsize=15)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#the mean square error of static static forecast\ny_forecasted_dynamic = pred_dynamic.predicted_mean\ny_truth = south_au['2015-03-31':]\nmse = ((y_forecasted_dynamic - y_truth) ** 2).mean()\nprint('The MSE of dynamic forecast: {}'.format(round(mse, 2)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"MSE(one-step ahead forecast) < MSE(dynamic forecast) ==> its normal because we are relying on less historical data."},{"metadata":{},"cell_type":"markdown","source":"# 4.  Producing and visualizing forecasts for future"},{"metadata":{"trusted":true},"cell_type":"code","source":"\npred_uc = results.get_forecast(steps=36) #forecast next 12 years\npred_ci_uc = pred_uc.conf_int()\n\nax = south_au.plot(label='observed', figsize=(14, 7))\n#ax = south_au['2010':].plot(label='observed')\n\nyearformatter = mdates.DateFormatter(\"%Y\")\nmonthformatter = mdates.DateFormatter(\"%m\")\n\nyearlocator = mdates.YearLocator()\nmonthlocator = mdates.MonthLocator((3,6,9,12))\n\nax.xaxis.set_major_locator(yearlocator)\nax.xaxis.set_minor_locator(monthlocator)\n\nax.xaxis.set_major_formatter(yearformatter)\nax.xaxis.set_minor_formatter(monthformatter)\n\nax.tick_params(which='major', length=4)\nax.tick_params(which='minor', length=2)\n\n\nplt.grid(b=True, which='minor', color='0.7', linestyle='-')\n\nplt.title(\"\", fontsize=15)\n\npred_uc.predicted_mean.plot(ax=ax, label='Forecast')\nax.fill_between(pred_ci_uc.index,\n                pred_ci_uc.iloc[:, 0],\n                pred_ci_uc.iloc[:, 1], color='k', alpha=.25)\nax.set_xlabel('Date')\nax.set_ylabel('# of Trips')\nplt.legend()\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- As we forecast further out into the future, it is natural for us to become less confident in our values. This is reflected by the confidence intervals generated by our model, which grow larger as we move further out into the future."},{"metadata":{},"cell_type":"markdown","source":"# Time Series Forecasting with Prophet"},{"metadata":{"trusted":true},"cell_type":"code","source":"from fbprophet import Prophet\n\ndf_state_sa = df_state_sa.rename(columns={'date': 'ds', 'Trips': 'y'})\nmodel_sa = Prophet(interval_width=0.95)\nmodel_sa.fit(df_state_sa)\n\ndf_state_nsw = df_state_nsw.rename(columns={'date': 'ds', 'Trips': 'y'})\nmodel_nsw = Prophet(interval_width=0.95)\nmodel_nsw.fit(df_state_nsw)\n\ndf_state_vic = df_state_vic.rename(columns={'date': 'ds', 'Trips': 'y'})\nmodel_vic = Prophet(interval_width=0.95)\nmodel_vic.fit(df_state_vic)\n\n######################### ###############################\nsa_forecast = model_sa.make_future_dataframe(periods=12, freq='Q')\nsa_forecast = model_sa.predict(sa_forecast)\n\nnsw_forecast = model_nsw.make_future_dataframe(periods=12, freq='Q')\nnsw_forecast = model_nsw.predict(nsw_forecast)\n\nvic_forecast = model_vic.make_future_dataframe(periods=12, freq='Q')\nvic_forecast = model_vic.predict(vic_forecast)\n\n######################### ###############################\nplt.figure(figsize=(18, 6))\nmodel_sa.plot(sa_forecast, xlabel = 'Date', ylabel = 'Trips')\nplt.title('South Australia Trips');\n\nplt.figure(figsize=(18, 6))\nmodel_nsw.plot(nsw_forecast, xlabel = 'Date', ylabel = 'Trips')\nplt.title('New South Wales Trips');\n\nplt.figure(figsize=(18, 6))\nmodel_vic.plot(vic_forecast, xlabel = 'Date', ylabel = 'Trips')\nplt.title('Victoria Trips');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"==> Prophet plots the observed values of our time series (the black dots), the forecasted values (blue line) and the uncertainty intervals of our forecasts (the blue shaded regions)."},{"metadata":{},"cell_type":"markdown","source":"One other particularly strong feature of Prophet is its ability to return the components of our forecasts. This can help reveal how daily, weekly and yearly patterns of the time series contribute to the overall forecasted values."},{"metadata":{"trusted":true},"cell_type":"code","source":"#model_sa.plot_components(sa_forecast);\nmodel_nsw.plot_components(nsw_forecast);\n#model_vic.plot_components(vic_forecast);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"==> See each state trips have been linearly increasing over time. Also NSW and VIC states nearly have the same trends, although SA  has growth slightly slower than others. \n- State: SA --> worst month: May&Sep, best month: Jun&Aug\n- State: NSW --> worst month: Dec, best month: Apr\n- State: VIC --> worst month: Feb , best month: Jun"},{"metadata":{},"cell_type":"markdown","source":"# Compare Forecasts of States(SA-NSW-VIC)"},{"metadata":{},"cell_type":"markdown","source":"- We already have the forecasts for three years(2018-2020) for these three states into the future. We will now join them together to compare their future forecasts."},{"metadata":{"trusted":true},"cell_type":"code","source":"sa_names = ['SA_%s' % column for column in sa_forecast.columns]\nnsw_names = ['NSW_%s' % column for column in nsw_forecast.columns]\nvic_names = ['VIC_%s' % column for column in vic_forecast.columns]\n\n\nsa_forecast_copy = sa_forecast.copy()\nnsw_forecast_copy = nsw_forecast.copy()\nvic_forecast_copy = vic_forecast.copy()\n\nsa_forecast_copy.columns = sa_names\nnsw_forecast_copy.columns = nsw_names\nvic_forecast_copy.columns = vic_names\n\nsa_nsw_forecast = pd.merge(sa_forecast_copy, nsw_forecast_copy, how = 'inner', left_on = 'SA_ds', right_on = 'NSW_ds')\nsa_nsw_forecast = sa_nsw_forecast.rename(columns={'SA_ds': 'DATE'}).drop('NSW_ds', axis=1)\n\nforecast = pd.merge(vic_forecast_copy, sa_nsw_forecast, how = 'inner', left_on = 'VIC_ds', right_on = 'DATE')\nforecast = forecast.drop('DATE', axis=1)\nforecast = forecast.rename(columns={'VIC_ds': 'DATE'})\nforecast.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 7))\nplt.plot(forecast['DATE'], forecast['SA_yhat'], 'r-', label=\"South Australia\")\nplt.plot(forecast['DATE'], forecast['NSW_yhat'], 'b-', label=\"New South Wales\")\nplt.plot(forecast['DATE'], forecast['VIC_yhat'], 'g-', label=\"Victoria\")\n\nplt.legend(); \nplt.xlabel('Date'); \nplt.ylabel('Trips')\nplt.title('SA - NSW - VIC Estimate', fontsize=10);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# One-step-ahead in-sample evaluation with Prophet"},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_df=forecast[[\"DATE\", \"SA_yhat\"]].set_index(\"DATE\")\npred=pred_df['2015-03-31': '2017-12-31'][\"SA_yhat\"]\n\ny_truth = south_au['2015-03-31':]\nmse = ((pred - y_truth) ** 2).mean()\nprint('The MSE in-sample static Prophet: {}'.format(round(mse, 2)))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- MSE(ARIMA)=10051.78, MSE(Prophet)=4267.47 ==> so Prophet performs better than ARIMA since Prophet considers non-linear relationship between elements of time series."},{"metadata":{},"cell_type":"markdown","source":"# LSTM out-of-sample prediction"},{"metadata":{},"cell_type":"markdown","source":"This is not one-step-ahead, we first fit on train and then make predictions on test dataset.\nFor each prediction, use truth values, not forecasted values.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Keras models\nfrom tensorflow.keras import models, layers, preprocessing as kprocessing\nfrom sklearn.preprocessing import MinMaxScaler\n\nmodel_lstm = models.Sequential()\nmodel_lstm.add(layers.LSTM(input_shape=(1,4), units=50, activation='relu', return_sequences=False) )\nmodel_lstm.add(layers.Dense(1))\nmodel_lstm.compile(optimizer='adam', loss='mean_absolute_error')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = MinMaxScaler(feature_range=(0,1))\nsa_preprocessed = scaler.fit_transform(south_au.values.reshape(-1,1)).reshape(-1) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## create X,y for train, since the data has seasnoality length=4(quarter-based)\nts_preprocessed = kprocessing.sequence.TimeseriesGenerator(data=sa_preprocessed, \n                                                           targets=sa_preprocessed, \n                                                           length=4, batch_size=1)\nlst_X, lst_y = [], []\nfor i in range(len(ts_preprocessed)):\n    xi, yi = ts_preprocessed[i] \n    lst_X.append(xi)\n    lst_y.append(yi)\n    \nX = np.array(lst_X) #4'l√º frameler\ny = np.array(lst_y) #truth values\n\nX_train=X[:-12, :] #son 3 yƒ±l hari√ß\nX_test=X[64:, :] #son 3 yƒ±l\n\ny_train=y[:-12, :]\ny_test=y[64:, :]\n\n\nmodel_lstm.fit(X_train, y_train, epochs=500, batch_size=4, verbose=2) \n\npred_trips = model_lstm.predict(X_test) #0..1\npred_trip = scaler.inverse_transform(pred_trips) #100k, 80k etc ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_truth = south_au['2015-03-31':].values\nmse = ((pred_trip - y_truth) ** 2).mean()\nprint('The MSE for LSTM prediction: {}'.format(round(mse, 2)))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dd=south_au.copy()\ndd[\"2015-03-31\":]=pred_trip.ravel()#(12, 1) --> (12)\npred=dd[\"2015-03-31\":]\n\n#df=pd.DataFrame(zip(south_au[\"2015-03-31\":], pred), columns=[\"truth\", \"pred\"], index=pred.index)\n\nplt.figure(figsize=(14,7))\nplt.plot(south_au[:\"2015-03-31\"], label=\"Train\")\nplt.plot(south_au[\"2015-03-31\":], label=\"Truths\")\nplt.plot(pred, label=\"Predictions\")\nplt.legend(loc=\"right\", bbox_to_anchor=(1.12, 0.8));","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# LSTM one-step-ahead forecast for future"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_lstm_2 = models.Sequential()\nmodel_lstm_2.add(layers.LSTM(input_shape=(1,4), units=50, activation='relu', return_sequences=False) )\nmodel_lstm_2.add(layers.Dense(1))\nmodel_lstm_2.compile(optimizer='adam', loss='mean_absolute_error')\n\n#here give full dataset to the lstm-model, then forecast for future!!\nmodel_lstm_2.fit(X, y, epochs=500, batch_size=4, verbose=2) #batch_size=4(since 1 year=4 quarters)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## predict, append, re-predict\npred_list = []\ninit_list=list(y[-4:])#select last 4 truth(y) values for our next pred\n\nfor i in range(12):\n    input_x = np.array(init_list[len(init_list) - 4 : ]) #take last 4 elements in \"init_list\" list\n    input_x = np.reshape(input_x, (1, 1, input_x.shape[0])).astype(np.float32) # (4, 1) -->> (1, 1, 4) (since Keras wants this(1: sample))\n    pred = model_lstm_2.predict(input_x)\n    init_list.append(pred)\n    pred_final = scaler.inverse_transform(pred)[0][0]\n    pred_list.append(pred_final)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#convert pred to time-series\ndate_index=sa_forecast_copy[\"SA_ds\"]\ndate_index=date_index[-12:] #future indexes(2018-2020)\n\ndf_pred=pd.DataFrame(pred_list, index=date_index, columns=[\"Forecasts\"])\n\nplt.figure(figsize=(14,6))\nplt.plot(south_au, label=\"Train\")\nplt.plot(df_pred, label=\"Forecast\")\nplt.legend(loc=\"right\", bbox_to_anchor=(1.12, 0.8));","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"References:\n\n> https://towardsdatascience.com/machine-learning-part-19-time-series-and-autoregressive-integrated-moving-average-model-arima-c1005347b0d7\n\n> https://medium.com/fintechexplained/understanding-auto-regressive-model-arima-4bd463b7a1bb\n\n> https://medium.com/fintechexplained/forecasting-time-series-explained-5cc773b232b6\n\n> https://www.digitalocean.com/community/tutorials/a-guide-to-time-series-forecasting-with-prophet-in-python-3\n\n> https://www.digitalocean.com/community/tutorials/a-guide-to-time-series-forecasting-with-arima-in-python-3#step-5\n\n"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}