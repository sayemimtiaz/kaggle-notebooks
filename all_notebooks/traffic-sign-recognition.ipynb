{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction"},{"metadata":{},"cell_type":"markdown","source":"* **This is notebook for absolute beginner who is learning TensorFlow framework.**\n* First go through the Traffic Sign Dataset which I used for this notebook. I will be highly obliged if you upvote the dataset alsoüòä.\n* Basically this is a Multi class classification using Transfer Learning in Tensorflow."},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport shutil\nimport tensorflow as tf\nimport pathlib\nimport PIL\nimport time\nimport zipfile\nimport random\nfrom tensorflow.keras.layers import *","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"MAIN_PATH = \"../input/traffic-sign-cropped/crop_dataset/crop_dataset\"\nTEST_PATH = \"../input/traffic-sign-cropped/test_data\"\nCLASSES = os.listdir(MAIN_PATH)\nNUM_CLASSES = len(CLASSES)\nNUM_TEST_IMAGES = len(os.listdir(os.path.join(TEST_PATH,\"test_data\")))\nHEIGHT,WIDTH = 32,32\nBATCH_SIZE = 32\nSPLIT = 0.2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing Data"},{"metadata":{},"cell_type":"markdown","source":"### Go through the [Tensorflow preprocessing](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator) image data documentation for more details"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=20,\n    horizontal_flip=True,\n    validation_split=SPLIT)\n'''\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    '''\ntrain_ds = train_datagen.flow_from_directory(\n    MAIN_PATH,\n    target_size = (HEIGHT,WIDTH),\n    batch_size = BATCH_SIZE,\n    subset = \"training\",\n    class_mode = \"categorical\",\n    shuffle = True\n)\n\nval_ds = train_datagen.flow_from_directory(\n    MAIN_PATH,\n    target_size = (HEIGHT,WIDTH),\n    batch_size = BATCH_SIZE,\n    subset = \"validation\",\n    class_mode = \"categorical\",\n    shuffle = True\n)\n\ntest_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale=1./255)\ntest_ds = test_datagen.flow_from_directory(\n    TEST_PATH,\n    target_size = (HEIGHT,WIDTH),\n    shuffle = False\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creating model"},{"metadata":{},"cell_type":"markdown","source":"### I am using transfer learning for this task. Based on the number of elements of 'ls', I will be varying the number of pretrained model I am using. If I use more than one pretrained model, I will take average of all the outputs."},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model():\n    vgg16 = tf.keras.applications.VGG16(include_top=False, weights='imagenet',input_shape=[HEIGHT,WIDTH, 3])\n            \n    x = vgg16.output\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    x = tf.keras.layers.Dropout(0.3) (x)\n    x = tf.keras.layers.Dense(128) (x)\n    x = tf.keras.layers.LeakyReLU(alpha=0.2) (x)\n    x = tf.keras.layers.GaussianDropout(0.4) (x)\n    outputs = tf.keras.layers.Dense(NUM_CLASSES,activation=\"softmax\", dtype='float32')(x)\n        \n    model = tf.keras.Model(vgg16.input, outputs)\n    return model\n\nmodel = create_model()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Function for compiling the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def compile_model(model, lr=0.0001):\n    \n    optimizer = tf.keras.optimizers.Adam(lr=lr)\n    \n    loss = tf.keras.losses.CategoricalCrossentropy()\n        \n    metrics = [\n       tf.keras.metrics.CategoricalAccuracy(name='categorical_accuracy')\n    ]\n\n    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Function for callbacks"},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_callbacks():\n    \n    cpk_path = './best_model.h5'\n    \n    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n        filepath=cpk_path,\n        monitor='val_categorical_accuracy',\n        mode='max',\n        save_best_only=True,\n        verbose=1,\n    )\n\n    reducelr = tf.keras.callbacks.ReduceLROnPlateau(\n        monitor='val_categorical_accuracy',\n        mode='max',\n        factor=0.1,\n        patience=3,\n        verbose=0\n    )\n\n    earlystop = tf.keras.callbacks.EarlyStopping(\n        monitor='val_categorical_accuracy',\n        mode='max',\n        patience=10, \n        verbose=1\n    )\n    \n    callbacks = [checkpoint, reducelr, earlystop]         \n    \n    return callbacks","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS= 60\nVERBOSE =1\n\ntf.keras.backend.clear_session()\n\nwith tf.device('/device:GPU:0'):\n    \n    model = create_model()\n    model = compile_model(model, lr=0.0001)\n   \n    callbacks = create_callbacks()\n    \n    history = model.fit(train_ds, \n                        epochs=EPOCHS,\n                        callbacks=callbacks,\n                        validation_data = val_ds,\n                        verbose=VERBOSE)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# METRICS VISUALIZATION"},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = history.history['categorical_accuracy']\nval_acc = history.history['val_categorical_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs_range = range(len(history.history['val_loss']))\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Categorical Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Categorical Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Categorical Accuracy')\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# TESTING"},{"metadata":{"trusted":true},"cell_type":"code","source":"label_df = pd.read_csv(\"../input/traffic-sign-cropped/test_labels.csv\")\nlabels = np.array(label_df.label)\n\nmodel = tf.keras.models.load_model(\"./best_model.h5\")\n\npred_arr = model.predict(test_ds)\n\npredictions = np.zeros((NUM_TEST_IMAGES,))\nfor i,pred in enumerate(pred_arr):\n    predictions[i] = np.argmax(pred)\n    \nconfusion_matrix = tf.math.confusion_matrix(labels,predictions,num_classes=NUM_CLASSES)\n\ncount = 0\nfor i in range(NUM_TEST_IMAGES):\n    if predictions[i]== labels[i]:\n        count+=1\n        \ntest_acc = count/NUM_TEST_IMAGES\nprint(\"Test Accuracy: \",test_acc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\n\nsns.set(rc={'figure.figsize':(13,10)})\n\nsns.heatmap(confusion_matrix,cmap='Blues')  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Hope you learnt something useful from this notebook. Feel free to contact me in case of doubts or any suggestions. \n## Happy coding‚ù§"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}