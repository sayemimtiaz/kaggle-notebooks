{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Import numpy and pandas\nimport numpy as np\nimport pandas as pd\n\n# Read the CSV file into a DataFrame: df\ndf = pd.read_csv('../input/gapminder.csv')\ndf.columns\n\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create arrays for features and target variable\ny = df.life.values\nX_fertility= df.fertility.values\nX= df[['population','fertility','GDP']].values\n\ny=y.reshape(-1,1)\nX_fertility=X_fertility.reshape(-1,1)\nX= X.reshape(-1,3)\nprint(y.shape,X_fertility.shape,X.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import LinearRegression\nfrom sklearn.linear_model import LinearRegression\n\n# Create the regressor: reg\nreg = LinearRegression()\n\n# Create the prediction space\nprediction_space = np.linspace(min(X_fertility), max(X_fertility)).reshape(-1,1)\n\n\n# Fit the model to the data\nreg.fit(X_fertility,y)\n\n# Compute predictions over the prediction space: y_pred\ny_pred = reg.predict(prediction_space)\n\n# Print R^2 \nprint(reg.score(X_fertility, y))\n\n# Plot regression line\nplt.scatter(x=df.fertility.values,y=df.life.values,color='blue')\nplt.plot(prediction_space, y_pred, color='black', linewidth=3)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import necessary modules\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\n\n# Create training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size =.3, random_state=42)\n\n# Create the regressor: reg_all\nreg_all = LinearRegression()\n\n# Fit the regressor to the training data\nreg_all.fit(X_train,y_train)\n\n# Predict on the test data: y_pred\ny_pred = reg_all.predict(X_test)\n\n# Compute and print R^2 and RMSE\nprint(\"R^2: {}\".format(reg_all.score(X_test, y_test)))\nrmse = np.sqrt(mean_squared_error(y_test,y_pred))\nprint(\"Root Mean Squared Error: {}\".format(rmse))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\ncv_scores = cross_val_score(reg_all, X, y, cv=5)\nprint(cv_scores)\nprint(np.mean(cv_scores))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Perform 3-fold CV\ncvscores_3 = cross_val_score(reg,X,y,cv=3)\nprint(np.mean(cvscores_3))\n\n# Perform 10-fold CV\ncvscores_10 = cross_val_score(reg,X,y,cv=10)\nprint(np.mean(cvscores_10))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%timeit cvscores_3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%timeit cvscores_10","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import Lasso\nfrom sklearn.linear_model import Lasso\n\n# Instantiate a lasso regressor: lasso\nlasso = Lasso(alpha=0.4,normalize=True)\nX=df.drop(['life','Region'],axis=1).values\ny=df.life.values\nX=X.reshape(-1,8)\n\n\n# Fit the regressor to the data\nlasso.fit(X,y)\n\n# Compute and print the coefficients\nlasso_coef = lasso.fit(X,y).coef_\nprint(lasso_coef)\ndf_columns= df.drop(['life','Region'],axis=1).columns\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(range(len(df_columns)), lasso_coef)\nplt.xticks(range(len(df_columns)), df_columns.values, rotation=60)\nplt.margins(0.02)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"it seems like 'child_mortality' is the most important feature when predicting life expectancy."},{"metadata":{"trusted":true},"cell_type":"code","source":"def display_plot(cv_scores, cv_scores_std):\n    fig = plt.figure()\n    ax = fig.add_subplot(1,1,1)\n    ax.plot(alpha_space, cv_scores)\n\n    std_error = cv_scores_std / np.sqrt(10)\n\n    ax.fill_between(alpha_space, cv_scores + std_error, cv_scores - std_error, alpha=0.2)\n    ax.set_ylabel('CV Score +/- Std Error')\n    ax.set_xlabel('Alpha')\n    ax.axhline(np.max(cv_scores), linestyle='--', color='.5')\n    ax.set_xlim([alpha_space[0], alpha_space[-1]])\n    ax.set_xscale('log')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import necessary modules\nfrom sklearn.linear_model import Ridge\nfrom sklearn.model_selection import cross_val_score\n\n# Setup the array of alphas and lists to store scores\nalpha_space = np.logspace(-4, 0, 50)\nridge_scores = []\nridge_scores_std = []\n\n# Create a ridge regressor: ridge\nridge = Ridge(normalize=True)\n\n# Compute scores over range of alphas\nfor alpha in alpha_space:\n\n    # Specify the alpha value to use: ridge.alpha\n    ridge.alpha = alpha\n    \n    # Perform 10-fold CV: ridge_cv_scores\n    ridge_cv_scores = cross_val_score(ridge,X,y,cv=10)\n    \n    # Append the mean of ridge_cv_scores to ridge_scores\n    ridge_scores.append(np.mean(ridge_cv_scores))\n    \n    # Append the std of ridge_cv_scores to ridge_scores_std\n    ridge_scores_std.append(np.std(ridge_cv_scores))\n\n# Display the plot\ndisplay_plot(ridge_scores, ridge_scores_std)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import necessary modules\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import GridSearchCV, train_test_split\n\n# Create train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.4,random_state=42)\n\n# Create the hyperparameter grid\nl1_space = np.linspace(0, 1, 30)\nparam_grid = {'l1_ratio': l1_space}\n\n# Instantiate the ElasticNet regressor: elastic_net\nelastic_net = ElasticNet()\n\n# Setup the GridSearchCV object: gm_cv\ngm_cv = GridSearchCV(elastic_net, param_grid, cv=5)\n\n# Fit it to the training data\ngm_cv.fit(X_train,y_train)\n\n# Predict on the test set and compute metrics\ny_pred = gm_cv.predict(X_test)\nr2 = gm_cv.score(X_test, y_test)\nmse = mean_squared_error(y_test, y_pred)\nprint(\"Tuned ElasticNet l1 ratio: {}\".format(gm_cv.best_params_))\nprint(\"Tuned ElasticNet R squared: {}\".format(r2))\nprint(\"Tuned ElasticNet MSE: {}\".format(mse))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.boxplot( 'life','Region', rot=60)\n\n# Show the plot\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_region = pd.get_dummies(df,drop_first=True)\n\n# Print the new columns of df_region\nprint(df_region.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import Ridge\n\n# Instantiate a ridge regressor: ridge\nridge = Ridge(alpha=0.5,normalize=True)\n\n# Perform 5-fold cross-validation: ridge_cv\nridge_cv = cross_val_score(ridge,X,y,cv=5)\n\n# Print the cross-validated scores\nprint(ridge_cv)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}