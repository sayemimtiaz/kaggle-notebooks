{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"from IPython.display import display,HTML\ndef dhtml(str):\n    display(HTML(\"\"\"<style>\n    @import 'https://fonts.googleapis.com/css?family=Monoton&effect=3d';      \n    </style><h1 class='font-effect-3d' \n    style='font-family:Monoton; color:#ff1155; font-size:35px;'>\n    %s</h1>\"\"\"%str))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Reading classics [Deep Learning Models](https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/ordinal/ordinal-cnn-beckham2016-afadlite.ipynb)\n\n[Google Colaboratory Version](https://colab.research.google.com/drive/1Nkr8BybYG-iIy7nha-A6S2d2QIa3rTx2)","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"dhtml('Code Modules & Functions')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np,pandas as pd,pylab as pl\nimport os,torch\nfrom torch.utils.data import DataLoader as tdl\nfrom torch.utils.data import Dataset as tds\nimport torch.nn.functional as tnnf\nimport torch.nn as tnn\nfrom torchvision import transforms,utils\nfrom PIL import Image\nfrom IPython.core.magic import register_line_magic\ndev=torch.device(\"cuda:0\" \\\nif torch.cuda.is_available() else \"cpu\")\ntrain_csv='train.csv'; test_csv='test.csv'\nimg_path='AFAD-Lite'","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"@register_line_magic\ndef display_examples(data):\n    for images,labels in dataloaders[data]:  \n        print('Image dimensions: %s'%str(images.shape))\n        print('Label dimensions: %s'%str(labels.shape))\n        n=np.random.randint(1,50)\n        fig=pl.figure(figsize=(10,4))\n        for i in range(n,n+5):\n            ax=fig.add_subplot(1,5,i-n+1,\\\n            xticks=[],yticks=[],title=labels[i].item())\n            ax.imshow(np.transpose(images[i],(1,2,0)))\n        break","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def conv31(in_planes,out_planes,stride=1):\n    return tnn.Conv2d(in_planes,out_planes,\n                      kernel_size=3,stride=stride,\n                      padding=1,bias=False)\ndef cost_fit(targets,predictions):\n    return torch.mean((targets.float()-predictions)**2)\ndef mae_mse(model,data_loader):\n    mae,mse,num_examples=\\\n    torch.tensor([0.]),torch.tensor([0.]),0\n    for features,targets in data_loader:\n        features=features.to(dev)\n        targets=targets.float().to(dev)\n        logits,probs,predictions=model(features)\n        assert len(targets.size())==1\n        assert len(predictions.size())==1\n        predicted_labels=torch.round(predictions).float()\n        num_examples+=targets.size(0)\n        mae+=torch.abs(predicted_labels-targets).sum()\n        mse+=torch.sum((predicted_labels-targets)**2)\n    return mae/num_examples,mse/num_examples","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"dhtml('Data')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"!git clone https://github.com/afad-dataset/tarball-lite.git","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!cat tarball-lite/AFAD-Lite.tar.xz*>tarball-lite/AFAD-Lite.tar.xz","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!tar xf tarball-lite/AFAD-Lite.tar.xz","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"files=[os.path.relpath(os.path.join(dirpath,fn),img_path) \\\nfor (dirpath,dirnames,filenames) in os.walk(img_path) \\\nfor fn in filenames if fn.endswith('.jpg')]\nd={'age':[],'gender':[],\n   'file':[],'path':[]}\nfor f in files:\n    age,gender,fn=f.split('/')\n    if gender=='111': gender='male'\n    else: gender='female'        \n    d['age'].append(age)\n    d['gender'].append(gender)\n    d['file'].append(fn)\n    d['path'].append(f)\ndf=pd.DataFrame.from_dict(d)\ndf['age']=df['age'].values.astype(int)-18\nnp.random.seed(123)\nids=np.random.rand(len(df))<.8\ndf_train=df[ids]; df_test=df[~ids]\ndf_train.set_index('file',inplace=True)\ndf_train.to_csv(train_csv)\ndf_test.set_index('file',inplace=True)\ndf_test.to_csv(test_csv)\nnum_classes=np.unique(df['age'].values).shape[0]\nprint([num_classes,len(files)]); df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class AFADAgeData(tds):\n    def __init__(self,csv_path,img_dir,transform=None):\n        df=pd.read_csv(csv_path,index_col=0)\n        self.img_dir=img_dir\n        self.csv_path=csv_path\n        self.img_paths=df['path']\n        self.y=df['age'].values\n        self.transform=transform\n    def __getitem__(self,index):\n        img=Image.open(os.path\\\n        .join(self.img_dir,self.img_paths[index]))\n        if self.transform is not None:\n            img=self.transform(img)\n        lbl=self.y[index]\n        return img,lbl\n    def __len__(self):\n        return self.y.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size=256; num_workers=4\ngrayscale=False; img_size=120\ntrans=transforms\\\n.Compose([transforms.Resize((128,128)),\n          transforms.RandomCrop((img_size,img_size)),\n          transforms.ToTensor()])\ntrans2=transforms\\\n.Compose([transforms.Resize((128,128)),\n          transforms.CenterCrop((img_size,img_size)),\n          transforms.ToTensor()])\ntrain=AFADAgeData(csv_path=train_csv,\n                  img_dir=img_path,\n                  transform=trans)\ntest=AFADAgeData(csv_path=test_csv,\n                 img_dir=img_path,\n                 transform=trans2)\ndataloaders={'train':tdl(dataset=train,batch_size=batch_size,\n                         shuffle=True,num_workers=num_workers),\n             'test':tdl(dataset=test,batch_size=batch_size,\n                        shuffle=True,num_workers=num_workers)}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%display_examples test","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"dhtml('Ordinal Regression CNN')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class BasicBlock(tnn.Module):\n    expansion=1\n    def __init__(self,inplanes,planes,stride=1,downsample=None):\n        super(BasicBlock,self).__init__()\n        self.conv1=conv31(inplanes,planes,stride)\n        self.bn1=tnn.BatchNorm2d(planes)\n        self.relu=tnn.ReLU(inplace=True)\n        self.conv2=conv31(planes,planes)\n        self.bn2=tnn.BatchNorm2d(planes)\n        self.downsample=downsample\n        self.stride=stride\n    def forward(self,x):\n        residual=x\n        out=self.conv1(x)\n        out=self.bn1(out)\n        out=self.relu(out)\n        out=self.conv2(out)\n        out=self.bn2(out)\n        if self.downsample is not None:\n            residual=self.downsample(x)\n        out+=residual\n        out=self.relu(out)\n        return out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ResNN(tnn.Module):\n    def __init__(self, block,layers,num_classes,grayscale):\n        self.num_classes=num_classes\n        self.inplanes=64\n        base_num=64\n        if grayscale: in_dim=1\n        else: in_dim=3\n        super(ResNN,self).__init__()\n        self.conv1=tnn\\\n        .Conv2d(in_dim,base_num,kernel_size=7,\n                stride=2,padding=3,bias=False)\n        self.bn1=tnn.BatchNorm2d(base_num)\n        self.relu=tnn.ReLU(inplace=True)\n        self.maxpool=tnn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n        self.layer1=self._make_layer(block,base_num,layers[0])\n        self.layer2=self._make_layer(block,2*base_num,layers[1],stride=2)\n        self.layer3=self._make_layer(block,4*base_num,layers[2],stride=2)\n        self.layer4=self._make_layer(block,8*base_num,layers[3],stride=2)\n        self.avgpool=tnn.AvgPool2d(7,stride=1,padding=2)\n        self.fc=tnn.Linear(2048*block.expansion,num_classes)\n        self.a=tnn.Parameter(torch.zeros(\n            self.num_classes).float().normal_(0.,.1).view(-1,1))\n        for m in self.modules():\n            if isinstance(m,tnn.Conv2d):\n                n=m.kernel_size[0]*m.kernel_size[1]*m.out_channels\n                m.weight.data.normal_(0,(2./n)**.5)\n            elif isinstance(m,tnn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n    def _make_layer(self,block,planes,blocks,stride=1):\n        downsample=None\n        if stride!=1 or self.inplanes!=planes*block.expansion:\n            downsample=tnn.Sequential(\n                tnn.Conv2d(self.inplanes,planes*block.expansion,\n                           kernel_size=1,stride=stride,bias=False),\n                tnn.BatchNorm2d(planes*block.expansion),)\n\n        layers=[]\n        layers.append(block(self.inplanes,planes,stride,downsample))\n        self.inplanes=planes*block.expansion\n        for i in range(1,blocks):\n            layers.append(block(self.inplanes,planes))\n        return tnn.Sequential(*layers)\n    def forward(self, x):\n        x=self.conv1(x); x=self.bn1(x)\n        x=self.relu(x); x=self.maxpool(x)\n        x=self.layer1(x); x=self.layer2(x)\n        x=self.layer3(x); x=self.layer4(x)\n        x=self.avgpool(x)\n        x=x.view(x.size(0),-1)\n        logits=self.fc(x)\n        probs=torch.softmax(logits,dim=1)\n        predictions=((self.num_classes-1)*torch\\\n                     .sigmoid(probs.mm(self.a).view(-1)))\n        return logits,probs,predictions\ndef ResNN34(num_classes,grayscale):\n    return ResNN(block=BasicBlock,\n                 layers=[3,4,6,3],\n                 num_classes=num_classes,\n                 grayscale=grayscale)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"dhtml('Training')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_seed=12; learning_rate=.0005\ntorch.manual_seed(random_seed)\ntorch.cuda.manual_seed(random_seed)\nmodel=ResNN34(num_classes,grayscale)\nmodel.to(dev)\noptimizer=torch.optim\\\n.Adam(model.parameters(),lr=learning_rate)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"epochs=130\nfor epoch in range(epochs):\n    model.train()\n    for batch_ids,(features,targets) \\\n    in enumerate(dataloaders['train']):\n        features=features.to(dev)\n        targets=targets.to(dev)\n        logits,probs,predictions=model(features)\n        assert len(targets.size())==1\n        assert len(predictions.size())==1\n        cost=cost_fit(targets,predictions)\n        optimizer.zero_grad()\n        cost.backward()\n        optimizer.step()\n        if not batch_ids%100:\n            st='Epoch: %03d/%03d | Batch: %04d/%04d | Cost: %.4f'\n            print(st%(epoch+1,epochs,batch_ids,\n                     len(dataloaders['train']),cost))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"dhtml('Evaluation')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.eval()\nwith torch.set_grad_enabled(False):\n    train_mae,train_mse=\\\n    mae_mse(model,dataloaders['train'])\n    test_mae,test_mse=\\\n    mae_mse(model,dataloaders['test'])\n    st='MAE/RMSE => Train: %.2f/%.2f | Test: %.2f/%.2f'\n    print(st%(train_mae,torch.sqrt(train_mse),\n              test_mae,torch.sqrt(test_mse)))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}