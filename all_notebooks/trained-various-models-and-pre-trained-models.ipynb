{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle'):\n    print(dirname)\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Importing all used Libraries."},{"metadata":{"trusted":true},"cell_type":"code","source":"from shutil import copyfile\nfrom random import seed\nfrom random import random\nimport cv2\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom matplotlib import pyplot\nfrom matplotlib.image import imread\nimport tensorflow as tf\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import Model\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Defining parent directory and listing files in it."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"PARENT_DIR = '../input/hackerearth-deep-learning-challenge-holidayseason/dataset'\nprint(os.listdir(PARENT_DIR))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Defining data directories."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_csv = os.path.join(PARENT_DIR, 'train.csv')\ntrain_dir = os.path.join(PARENT_DIR, 'train')\ntest_dir = os.path.join(PARENT_DIR, 'test')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Reading CSV file containing training data labels."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels = pd.read_csv(train_csv)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Observing value counts of all Classes."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels.Class.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Viewing Some Images of Training Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_images = train_labels.head(20)\nsample_images","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i = 1\nplt.figure(figsize=(10,10))\nfor img in sample_images.Image:\n    img = cv2.imread(os.path.join(train_dir,img),cv2.COLOR_BGR2RGB)\n    img = cv2.resize(img, (150, 150),interpolation = cv2.INTER_NEAREST)\n    plt.subplot(5,4,i)\n    plt.imshow(img)\n    i+=1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Splitting Training DataSet into Training and Validation Set\n\n*Note* - Doing Stratified Splitting so that the Training and Validation Set have equal proportion of all the Classes."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df,val_df = train_test_split(train_labels,test_size=.20,stratify=train_labels['Class'].values,shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.reset_index(inplace=True,drop=True)\nval_df.reset_index(inplace=True,drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.Class.value_counts()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_df.Class.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Creating Seperate DataFrames for each classes, for both, training and validation set."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_Airplane = train_df[train_df['Class']=='Airplane']\ntrain_Candle = train_df[train_df['Class']=='Candle']\ntrain_Christmas_Tree = train_df[train_df['Class']=='Christmas_Tree']\ntrain_Jacket = train_df[train_df['Class']=='Jacket']\ntrain_Miscellaneous = train_df[train_df['Class']=='Miscellaneous']\ntrain_Snowman = train_df[train_df['Class']=='Snowman']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_Airplane = val_df[val_df['Class']=='Airplane']\nval_Candle = val_df[val_df['Class']=='Candle']\nval_Christmas_Tree = val_df[val_df['Class']=='Christmas_Tree']\nval_Jacket = val_df[val_df['Class']=='Jacket']\nval_Miscellaneous = val_df[val_df['Class']=='Miscellaneous']\nval_Snowman = val_df[val_df['Class']=='Snowman']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Creating new mentioned directory under mentioned parent directory followed by creating sub directories of training and validation set along all the Classes."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Directory\ndirectory = \"dataset_classes\"\n \n# Parent Directory path\nparent_dir = \"/kaggle/working\"\n \n# Path\npath = os.path.join(parent_dir, directory)\ntry:\n    os.makedirs(path, exist_ok = True)\n    print(\"Directory '%s' created successfully\" %directory)\nexcept OSError as error:\n    print(\"Directory '%s' can not be created\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_home = '/kaggle/working/dataset_classes/'\nsubdirs = ['train/', 'test/']\nfor subdir in subdirs:\n\t# create label subdirectories\n\tlabeldirs = ['airplane/', 'candle/', 'christmas_tree/', 'jacket/', 'miscellaneous/', 'snowman/']\n\tfor labldir in labeldirs:\n\t\tnewdir = dataset_home + subdir + labldir\n\t\tos.makedirs(newdir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/working'):\n    print(dirname)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Copying training data to the respective Class Sub directory,for both, training and validation set."},{"metadata":{"trusted":true},"cell_type":"code","source":"# seed random number generator\nseed(1)\n# define ratio of pictures to use for validation\nval_ratio = 0.20\n# copy training dataset images into subdirectories\nsrc_directory = train_dir\nfor file in os.listdir(src_directory):\n    src = src_directory + '/' + file\n    dst_dir1 = 'train/'\n    dst_dir2 = 'test/'\n    if file in list(train_Airplane.Image):\n        dst = dataset_home + dst_dir1 + 'airplane/'  + file\n        copyfile(src, dst)\n    elif file in list(train_Candle.Image):\n        dst = dataset_home + dst_dir1 + 'candle/'  + file\n        copyfile(src, dst)\n    elif file in list(train_Christmas_Tree.Image):\n        dst = dataset_home + dst_dir1 + 'christmas_tree/'  + file\n        copyfile(src, dst)\n    elif file in list(train_Jacket.Image):\n        dst = dataset_home + dst_dir1 + 'jacket/'  + file\n        copyfile(src, dst)\n    elif file in list(train_Snowman.Image):\n        dst = dataset_home + dst_dir1 + 'snowman/'  + file\n        copyfile(src, dst)\n    elif file in list(train_Miscellaneous.Image):\n        dst = dataset_home + dst_dir1 + 'miscellaneous/'  + file\n        copyfile(src, dst)\n    elif file in list(val_Airplane.Image):\n        dst = dataset_home + dst_dir2 + 'airplane/'  + file\n        copyfile(src, dst)\n    elif file in list(val_Candle.Image):\n        dst = dataset_home + dst_dir2 + 'candle/'  + file\n        copyfile(src, dst)\n    elif file in list(val_Christmas_Tree.Image):\n        dst = dataset_home + dst_dir2 + 'christmas_tree/'  + file\n        copyfile(src, dst)\n    elif file in list(val_Jacket.Image):\n        dst = dataset_home + dst_dir2 + 'jacket/'  + file\n        copyfile(src, dst)\n    elif file in list(val_Snowman.Image):\n        dst = dataset_home + dst_dir2 + 'snowman/'  + file\n        copyfile(src, dst)\n    else :\n        dst = dataset_home + dst_dir2 + 'miscellaneous/'  + file\n        copyfile(src, dst)\n        \n            ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plotting Some Images from each Class."},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot airplane photos \n\n# define location of dataset\nfolder = '/kaggle/working/dataset_classes/train/airplane/'\n# plot first few images\nfor i in range(9):\n\t# define subplot\n\tpyplot.subplot(330 + 1 + i)\n\t# define filename\n\tfilename = folder + list(train_Airplane.Image)[i]\n\t# load image pixels\n\timage = imread(filename)\n\t# plot raw pixel data\n\tpyplot.imshow(image)\n# show the figure\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot candle photos \n\n# define location of dataset\nfolder = '/kaggle/working/dataset_classes/train/candle/'\n# plot first few images\nfor i in range(9):\n\t# define subplot\n\tpyplot.subplot(330 + 1 + i)\n\t# define filename\n\tfilename = folder + list(train_Candle.Image)[i]\n\t# load image pixels\n\timage = imread(filename)\n\t# plot raw pixel data\n\tpyplot.imshow(image)\n# show the figure\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot christmas_tree photos \n\n# define location of dataset\nfolder = '/kaggle/working/dataset_classes/train/christmas_tree/'\n# plot first few images\nfor i in range(9):\n\t# define subplot\n\tpyplot.subplot(330 + 1 + i)\n\t# define filename\n\tfilename = folder + list(train_Christmas_Tree.Image)[i+10]\n\t# load image pixels\n\timage = imread(filename)\n\t# plot raw pixel data\n\tpyplot.imshow(image)\n# show the figure\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot jacket photos \n\n# define location of dataset\nfolder = '/kaggle/working/dataset_classes/train/jacket/'\n# plot first few images\nfor i in range(9):\n\t# define subplot\n\tpyplot.subplot(330 + 1 + i)\n\t# define filename\n\tfilename = folder + list(train_Jacket.Image)[i+5]\n\t# load image pixels\n\timage = imread(filename)\n\t# plot raw pixel data\n\tpyplot.imshow(image)\n# show the figure\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot snowman photos \n\n# define location of dataset\nfolder = '/kaggle/working/dataset_classes/train/snowman/'\n# plot first few images\nfor i in range(9):\n\t# define subplot\n\tpyplot.subplot(330 + 1 + i)\n\t# define filename\n\tfilename = folder + list(train_Snowman.Image)[i+33]\n\t# load image pixels\n\timage = imread(filename)\n\t# plot raw pixel data\n\tpyplot.imshow(image)\n# show the figure\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot miscellaneous photos \n\n# define location of dataset\nfolder = '/kaggle/working/dataset_classes/train/miscellaneous/'\n# plot first few images\nfor i in range(9):\n\t# define subplot\n\tpyplot.subplot(330 + 1 + i)\n\t# define filename\n\tfilename = folder + list(train_Miscellaneous.Image)[i]\n\t# load image pixels\n\timage = imread(filename)\n\t# plot raw pixel data\n\tpyplot.imshow(image)\n# show the figure\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Creating a Simple CNN model to see how it performs on the prepared data."},{"metadata":{"trusted":true},"cell_type":"code","source":"model1 = tf.keras.models.Sequential([\n    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'), \n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Dropout(0.2),\n    # Flatten the results to feed into a DNN\n    tf.keras.layers.Flatten(), \n    # 512 neuron hidden layer\n    tf.keras.layers.Dense(512, activation='relu'), \n    # 6 output neuron. It will contain a value from 0-5 for 6 classes\n    tf.keras.layers.Dense(6, activation='softmax')  \n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model1.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"opt = tf.keras.optimizers.Adam(learning_rate=0.001)\nmodel1.compile(optimizer=opt,\n              loss='categorical_crossentropy',\n              metrics = ['categorical_accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# All images will be rescaled by 1./255.\ntrain_datagen = ImageDataGenerator( rescale = 1.0/255. )\ntest_datagen  = ImageDataGenerator( rescale = 1.0/255. )\n\n# --------------------\n# Flow training images in batches of 20 using train_datagen generator\n# --------------------\ntrain_generator = train_datagen.flow_from_directory('/kaggle/working/dataset_classes/train/',\n                                                    batch_size=20,\n                                                    class_mode='categorical',\n                                                    target_size=(150, 150))     \n# --------------------\n# Flow validation images in batches of 20 using test_datagen generator\n# --------------------\nvalidation_generator =  test_datagen.flow_from_directory('/kaggle/working/dataset_classes/test/',\n                                                         batch_size=20,\n                                                         class_mode  = 'categorical',\n                                                         target_size = (150, 150))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history1 = model1.fit(train_generator,\n                              validation_data=validation_generator,\n                              steps_per_epoch=100,\n                              epochs=15,\n                              validation_steps=50,\n                              verbose=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#-----------------------------------------------------------\n# Retrieve a list of list results on training and test data\n# sets for each training epoch\n#-----------------------------------------------------------\nacc      = history1.history[     'categorical_accuracy' ]\nval_acc  = history1.history[ 'val_categorical_accuracy' ]\nloss     = history1.history[    'loss' ]\nval_loss = history1.history['val_loss' ]\n\nepochs   = range(len(acc)) # Get number of epochs\n\n#------------------------------------------------\n# Plot training and validation accuracy per epoch\n#------------------------------------------------\nplt.plot  ( epochs,     acc )\nplt.plot  ( epochs, val_acc )\nplt.title ('Training and validation accuracy')\nplt.figure()\n\n#------------------------------------------------\n# Plot training and validation loss per epoch\n#------------------------------------------------\nplt.plot  ( epochs,     loss )\nplt.plot  ( epochs, val_loss )\nplt.title ('Training and validation loss'   )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Applying Data Augmentation Techniques to the Same Model."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n      rescale=1./255,\n      rotation_range=40,\n      width_shift_range=0.2,\n      height_shift_range=0.2,\n      shear_range=0.2,\n      zoom_range=0.2,\n      horizontal_flip=True,\n      fill_mode='nearest')\n\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\n# Flow training images in batches of 20 using train_datagen generator\ntrain_generator = train_datagen.flow_from_directory(\n        '/kaggle/working/dataset_classes/train/',  # This is the source directory for training images\n        target_size=(150, 150),  # All images will be resized to 150x150\n        batch_size=20,\n        # Since we use categorical_crossentropy loss, we need categoricals labels\n        class_mode='categorical')\n\n# Flow validation images in batches of 20 using test_datagen generator\nvalidation_generator = test_datagen.flow_from_directory(\n        '/kaggle/working/dataset_classes/test/',\n        target_size=(150, 150),\n        batch_size=20,\n        class_mode='categorical')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history2 = model1.fit(\n      train_generator,\n      steps_per_epoch=100,  \n      epochs=15,\n      validation_data=validation_generator,\n      validation_steps=50,  \n      verbose=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#-----------------------------------------------------------\n# Retrieve a list of list results on training and test data\n# sets for each training epoch\n#-----------------------------------------------------------\nacc      = history2.history[     'categorical_accuracy' ]\nval_acc  = history2.history[ 'val_categorical_accuracy' ]\nloss     = history2.history[    'loss' ]\nval_loss = history2.history['val_loss' ]\n\nepochs   = range(len(acc)) # Get number of epochs\n\n#------------------------------------------------\n# Plot training and validation accuracy per epoch\n#------------------------------------------------\nplt.plot  ( epochs,     acc )\nplt.plot  ( epochs, val_acc )\nplt.title ('Training and validation accuracy')\nplt.figure()\n\n#------------------------------------------------\n# Plot training and validation loss per epoch\n#------------------------------------------------\nplt.plot  ( epochs,     loss )\nplt.plot  ( epochs, val_loss )\nplt.title ('Training and validation loss'   )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Applying Transfer Learning."},{"metadata":{},"cell_type":"markdown","source":"### 1.InceptionV3 model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications.inception_v3 import InceptionV3\n\npre_trained_model1 = InceptionV3(input_shape = (150, 150, 3), \n                                include_top = False, \n                                weights = 'imagenet')\n\n\nfor layer in pre_trained_model1.layers:\n  layer.trainable = False\n  \n\nlast_output1 = pre_trained_model1.output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Flatten the output layer to 1 dimension\nx1 = layers.Flatten()(last_output1)\n\n# Add a fully connected layer with 1,024 hidden units and ReLU activation\nx1 = layers.Dense(1024, activation='relu')(x1)\n\n# Add a dropout rate of 0.2\nx1 = layers.Dropout(0.2)(x1) \n\n# Add a fully connected layer with 512 hidden units and ReLU activation\nx1 = layers.Dense(512, activation='relu')(x1)\n\n# Add a dropout rate of 0.2\nx1 = layers.Dropout(0.2)(x1) \n\n# Add a final sigmoid layer for classification\nx1 = layers.Dense  (6, activation='softmax')(x1)     \n\n\nmodel3 = Model( pre_trained_model1.input, x1) \n\nmodel3.compile(optimizer = opt, \n              loss = 'categorical_crossentropy', \n              metrics = ['categorical_accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model3.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history3 = model3.fit(\n            train_generator,\n            validation_data = validation_generator,\n            steps_per_epoch = 100,\n            epochs = 50,\n            validation_steps = 50,\n            verbose = 2)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#-----------------------------------------------------------\n# Retrieve a list of list results on training and test data\n# sets for each training epoch\n#-----------------------------------------------------------\nacc      = history3.history[     'categorical_accuracy' ]\nval_acc  = history3.history[ 'val_categorical_accuracy' ]\nloss     = history3.history[    'loss' ]\nval_loss = history3.history['val_loss' ]\n\nepochs   = range(len(acc)) # Get number of epochs\n\n#------------------------------------------------\n# Plot training and validation accuracy per epoch\n#------------------------------------------------\nplt.plot  ( epochs,     acc )\nplt.plot  ( epochs, val_acc )\nplt.title ('Training and validation accuracy')\nplt.figure()\n\n#------------------------------------------------\n# Plot training and validation loss per epoch\n#------------------------------------------------\nplt.plot  ( epochs,     loss )\nplt.plot  ( epochs, val_loss )\nplt.title ('Training and validation loss'   )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.VGG16 Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications.vgg16 import VGG16\n\npretrained_model2 = VGG16(input_shape = (150, 150, 3), # Shape of our images\n                        include_top = False, # Leave out the last fully connected layer\n                        weights = 'imagenet')\n\nfor layer in pretrained_model2.layers:\n    layer.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Flatten the output layer to 1 dimension\nx = layers.Flatten()(pretrained_model2.output)\n\n# Add a fully connected layer with 1024 hidden units and ReLU activation\nx = layers.Dense(1024, activation='relu')(x)\n\n# Add a dropout rate of 0.2\nx = layers.Dropout(0.2)(x)\n\n# Add a fully connected layer with 512 hidden units and ReLU activation\nx = layers.Dense(512, activation='relu')(x)\n\n# Add a dropout rate of 0.2\nx = layers.Dropout(0.2)(x)\n\n# Add a final sigmoid layer for classification\nx = layers.Dense(6, activation='softmax')(x)\n\nmodel4 = tf.keras.models.Model(pretrained_model2.input, x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model4.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model4.compile(optimizer = opt,\n               loss = 'categorical_crossentropy',\n               metrics = ['categorical_accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history4 = model4.fit(\n            train_generator,\n            validation_data = validation_generator,\n            steps_per_epoch = 100,\n            epochs = 50,\n            validation_steps = 50,\n            verbose = 2)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#-----------------------------------------------------------\n# Retrieve a list of list results on training and test data\n# sets for each training epoch\n#-----------------------------------------------------------\nacc      = history4.history[     'categorical_accuracy' ]\nval_acc  = history4.history[ 'val_categorical_accuracy' ]\nloss     = history4.history[    'loss' ]\nval_loss = history4.history['val_loss' ]\n\nepochs   = range(len(acc)) # Get number of epochs\n\n#------------------------------------------------\n# Plot training and validation accuracy per epoch\n#------------------------------------------------\nplt.plot  ( epochs,     acc )\nplt.plot  ( epochs, val_acc )\nplt.title ('Training and validation accuracy')\nplt.figure()\n\n#------------------------------------------------\n# Plot training and validation loss per epoch\n#------------------------------------------------\nplt.plot  ( epochs,     loss )\nplt.plot  ( epochs, val_loss )\nplt.title ('Training and validation loss'   )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Im going to train few more pretrained models."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Creating Submission CSV"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing import image\nprediction = []\nImage = []\nlabels = (train_generator.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\n\nfor i, file in enumerate(os.listdir(test_dir)):\n    Image.append(file)\n    file = test_dir +'/'+ file\n\n    img = image.load_img(file, target_size=(150,150,3)) \n    img = image.img_to_array(img)\n    img = img/255\n    pred = model4.predict(img.reshape(1,150,150,3))\n\n    prediction.append(labels[np.argmax(pred[0])])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Submission=pd.DataFrame((zip(Image, prediction)),columns=['Image','Class'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Submission.Class.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Submission['Class'] = Submission['Class'].map({\n'airplane':'Airplane',\n'candle':'Candle',\n'christmas_tree':'Christmas_Tree',\n'jacket':'Jacket',\n'miscellaneous':'Miscellaneous',\n'snowman':'Snowman'\n})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Submission.to_csv('VGG16.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Scores On Submission\n\n### Model 1(Simple CNN) gives score of 60.96496\n### Model 2(Simple CNN with Data Augmentation) gives score of 64.43637\n### Model 3(InceptionV3) gives score of 83.27723\n### Model 4(VGG16) gives score of 76.27789\n## ..."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}