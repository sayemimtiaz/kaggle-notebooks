{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Install necessary packages\n!git clone https://github.com/NVIDIA/apex  > /dev/null && cd apex && pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./ --quiet\n!pip install -U git+https://github.com/albu/albumentations > /dev/null","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"root_dir = '../input/traffic-signs-preprocessed/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport pickle\n\n%matplotlib inline\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport torch\nimport cv2\nimport glob\nfrom apex import amp\nfrom tqdm import tqdm\n\nfrom albumentations import Compose, ShiftScaleRotate, Resize, Blur, HorizontalFlip, Equalize, Normalize, ElasticTransform\nfrom albumentations.pytorch import ToTensor","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading the data files\n* Label names\n* Train / Valid / Test images\n* Labels"},{"metadata":{"trusted":true},"cell_type":"code","source":"label_names = pd.read_csv(root_dir + 'label_names.csv')\nlabel_names.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 128\nNUM_CLASSES = 43","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pickle.load(open(root_dir + 'train.pickle', 'rb'))\nvalid = pickle.load(open(root_dir + 'valid.pickle', 'rb'))\ntest = pickle.load(open(root_dir + 'test.pickle', 'rb'))\nlabels = pickle.load(open(root_dir + 'labels.pickle', 'rb'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_images = train['features']\ntrain_labels = train['labels']\n\nvalid_images = valid['features']\nvalid_labels = valid['labels']\n\ntest_images = test['features']\ntest_labels = test['labels']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's see the number of files in our sets"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(train_labels))\nprint(len(valid_labels))\nprint(len(test_labels))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's see if distributions among sets is identical"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(1, 3, figsize=(15,5))\n\naxs[0].hist(train_labels)\naxs[0].set_title('Train')\n\naxs[1].hist(valid_labels)\naxs[1].set_title('Validation')\n\naxs[2].hist(test_labels)\naxs[2].set_title('Test')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Seems to be identical, it's going to be easy."},{"metadata":{},"cell_type":"markdown","source":"Calculating means and standard deviations for normalization only on the training images to avoid test data leaking into training.\nWe should bring our dataset to have mean~0.0 and std~1.0"},{"metadata":{"trusted":true},"cell_type":"code","source":"MEANS = np.mean(train_images, axis=(0, 1, 2)) / 255.\nSTDS = np.std(train_images, axis=(0, 1, 2)) / 255.\n\nprint(MEANS)\nprint(STDS)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creating datasets and transforms"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dataset\n\nclass TrafficSignsDataset(torch.utils.data.Dataset):\n\n    def __init__(self, images, labels, num_classes, transform=None):\n        \n        self.images = images\n        self.labels = labels\n        self.C = num_classes\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        img = self.images[idx]\n        label_idx = self.labels[idx]\n\n        label = np.zeros(self.C)\n        label[label_idx] = 1\n        \n        augmented = self.transform(image=img)\n        img = augmented['image']\n            \n        label = torch.tensor(label)\n        \n        return {'image': img, 'label': label}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We're creating different augmentations for train and test. Train dataset will be heavily augumentated, while test is left as it is.\n\n**Train** - Normalize, Blur, Shift, Scale, Rotate, Elastic transform\n\n**Validation/Test** - Normalize"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data loaders\n\ntransform_train = Compose([\n    Normalize(mean=MEANS, std=STDS),\n    Blur(blur_limit=3, p=0.1),\n    ShiftScaleRotate(rotate_limit=30, p=0.3),\n    ElasticTransform(p=0.1),\n    ToTensor()\n])\n\ntransform_test = Compose([\n    Normalize(mean=MEANS, std=STDS),\n    ToTensor()\n])\n\ntrain_dataset = TrafficSignsDataset(train_images, train_labels, NUM_CLASSES, transform=transform_train)\n\nvalid_dataset = TrafficSignsDataset(valid_images, valid_labels, NUM_CLASSES, transform=transform_test)\n\ntest_dataset = TrafficSignsDataset(test_images, test_labels, NUM_CLASSES, transform=transform_test)\n\ndata_loader_train = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\ndata_loader_valid = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\ndata_loader_test = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plotting some traffic signs for each dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot train example\n\nbatch = next(iter(data_loader_train))\nfig, axs = plt.subplots(1, 5, figsize=(15,5))\n\nprint('shape', batch['image'].shape)\nprint('min', batch['image'].min())\nprint('max', batch['image'].max())\nprint('mean', batch['image'].mean())\nprint('std', batch['image'].std())\n\nfor i in np.arange(5):\n    img = np.transpose(batch['image'][i].numpy(), (1,2,0))\n    img = img * STDS + MEANS\n    sign = label_names[label_names.ClassId == torch.argmax(batch['label'][i]).item()]['SignName'].values[0]\n    axs[i].imshow(img)\n    axs[i].set_title(sign)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot valid example\n\nbatch = next(iter(data_loader_valid))\nfig, axs = plt.subplots(1, 5, figsize=(15,5))\n\nfor i in np.arange(5):\n    img = np.transpose(batch['image'][i].numpy(), (1,2,0))\n    img = img * STDS + MEANS\n    axs[i].imshow(img)\n    sign = label_names[label_names.ClassId == torch.argmax(batch['label'][i]).item()]['SignName'].values[0]\n    axs[i].set_title(sign)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot test example\n\nbatch = next(iter(data_loader_test))\nfig, axs = plt.subplots(1, 5, figsize=(15,5))\n\nfor i in np.arange(5):\n    img = np.transpose(batch['image'][i].numpy(), (1,2,0))\n    img = img * STDS + MEANS\n    axs[i].imshow(img)\n    sign = label_names[label_names.ClassId == torch.argmax(batch['label'][i]).item()]['SignName'].values[0]\n    axs[i].set_title(sign)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model\n\nclass TrafficSignsModel(torch.nn.Module):\n    \n    def __init__(self, num_classes):\n        super().__init__()\n        \n        self.conv = torch.nn.Sequential(\n            torch.nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3, 3)),\n            torch.nn.ReLU(),\n            torch.nn.BatchNorm2d(32),\n            torch.nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(3, 3)),\n            torch.nn.ReLU(),\n            torch.nn.BatchNorm2d(32),\n            torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), stride=2),\n            torch.nn.ReLU(),\n            torch.nn.BatchNorm2d(64),\n            torch.nn.Dropout(0.25),\n            \n            torch.nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3, 3)),\n            torch.nn.ReLU(),\n            torch.nn.BatchNorm2d(64),\n            torch.nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3, 3)),\n            torch.nn.ReLU(),\n            torch.nn.BatchNorm2d(64),\n            torch.nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3, 3), stride=2),\n            torch.nn.ReLU(),\n            torch.nn.BatchNorm2d(128),\n            torch.nn.Dropout(0.25),\n        )\n        \n        self.flatten = torch.nn.Sequential(torch.nn.AdaptiveMaxPool2d(1), torch.nn.Flatten())\n        \n        self.fc = torch.nn.Sequential(\n            torch.nn.Linear(128, 512),\n            torch.nn.ReLU(),\n            torch.nn.Dropout(0.3),\n            torch.nn.Linear(512, num_classes)\n        )\n        \n    def forward(self, inputs):\n        x = self.conv(inputs)\n        x = self.flatten(x) #  x.view(-1, 256 * 7 * 7) # \n        x = self.fc(x)\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = TrafficSignsModel(NUM_CLASSES)\n\ndevice = torch.device(\"cuda:0\")\nmodel.to(device)\n\ncriterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n\nmodel, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train\nn_epochs = 16\n\nfor epoch in range(n_epochs):\n    \n    print('-' * 10)\n    print('Epoch {}/{}'.format(epoch + 1, n_epochs))\n    print('-' * 10)\n\n    tr_loss = 0\n    tr_acc = 0\n    model.train()\n    for step, batch in enumerate(data_loader_train):\n\n        inputs = batch[\"image\"]\n        labels = batch[\"label\"]\n\n        inputs = inputs.to(device, dtype=torch.float)\n        labels = labels.to(device, dtype=torch.long)\n\n        outputs = model(inputs)\n        loss = criterion(outputs, torch.max(labels, 1)[1])\n\n        with amp.scale_loss(loss, optimizer) as scaled_loss:\n            scaled_loss.backward()\n\n        tr_loss += loss.item()\n        tr_acc += (torch.max(outputs, 1)[1] == torch.max(labels, 1)[1]).type(torch.FloatTensor).mean().item()\n\n        optimizer.step()\n        optimizer.zero_grad()\n\n    epoch_loss = tr_loss / len(data_loader_train)\n    epoch_acc = tr_acc / len(data_loader_train)\n    print('Training Loss/Accuracy:\\t{:.4f}\\t{:.4f}'.format(epoch_loss, epoch_acc))\n    # print('Training Accuracy: {:.4f}'.format(epoch_acc))\n    \n    # print('-' * 10)\n    test_loss = 0\n    test_acc = 0\n    model.eval()\n    with torch.no_grad():\n        for step, batch in enumerate(data_loader_valid):\n            inputs = batch[\"image\"]\n            labels = batch[\"label\"]\n\n            inputs = inputs.to(device, dtype=torch.float)\n            labels = labels.to(device, dtype=torch.long)\n\n            outputs = model(inputs)\n            loss = criterion(outputs, torch.max(labels, 1)[1])\n\n            test_loss += loss.item()\n            test_acc += (torch.max(outputs, 1)[1] == torch.max(labels, 1)[1]).type(torch.FloatTensor).mean().item()\n\n    epoch_loss = test_loss / len(data_loader_valid)\n    epoch_acc = test_acc / len(data_loader_valid)\n    print('Validati Loss/Accuracy:\\t{:.4f}\\t{:.4f}'.format(epoch_loss, epoch_acc))\n    # print('Valid Accuracy: {:.4f}'.format(epoch_acc))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Testing"},{"metadata":{"trusted":true},"cell_type":"code","source":"errors = []\n\ntest_loss = 0\ntest_acc = 0\nmodel.eval()\nwith torch.no_grad():\n    for step, batch in enumerate(data_loader_test):\n        inputs = batch[\"image\"]\n        labels = batch[\"label\"]\n\n        inputs = inputs.to(device, dtype=torch.float)\n        labels = labels.to(device, dtype=torch.long)\n\n        outputs = model(inputs)\n        loss = criterion(outputs, torch.max(labels, 1)[1])\n\n        test_loss += loss.item()\n        test_acc += (torch.max(outputs, 1)[1] == torch.max(labels, 1)[1]).type(torch.FloatTensor).mean().item()\n        \n        true_labels = torch.max(labels, 1)[1]\n        pred_labels = torch.max(outputs, 1)[1]\n        for idx in range(len(true_labels)):\n            if true_labels[idx] != pred_labels[idx]:\n                errors.append((np.transpose(inputs[idx].cpu().numpy(), (1,2,0)), true_labels[idx], pred_labels[idx]))\n\nepoch_loss = test_loss / len(data_loader_test)\nepoch_acc = test_acc / len(data_loader_test)\nprint('Test Loss: {:.4f}'.format(epoch_loss))\nprint('Test Accuracy: {:.4f}'.format(epoch_acc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Error rate', len(errors) / len(test_dataset))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Let's print some misclassified images"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(1, 5, figsize=(15,5))\n\nfor i in np.arange(5):\n    error = errors[i]\n    img = error[0] * STDS + MEANS\n    axs[i].imshow(img)\n    true_label = label_names[label_names.ClassId == error[1].item()]['SignName'].values[0]\n    pred_label = label_names[label_names.ClassId == error[2].item()]['SignName'].values[0]\n    axs[i].set_title(true_label + '\\n' + pred_label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!rm -rf /kaggle/working/apex","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}