{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.metrics import mean_squared_error as mse\nfrom sklearn.linear_model import LinearRegression as OLS\nfrom sklearn.preprocessing import StandardScaler\nimport os\nimport multiprocessing\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import datetime","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# read data\ndf = pd.read_csv('/kaggle/input/electric-motor-temperature/measures_v2.csv')\ndf.drop('torque', axis=1, inplace=True)\ntarget_features = ['pm', 'stator_tooth', 'stator_yoke', 'stator_winding']\nPROFILE_ID_COL = 'profile_id'\n\ndf.head(10)","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"extra_feats = {\n     'i_s': lambda x: np.sqrt(x['i_d']**2 + x['i_q']**2),  # Current vector norm\n     'u_s': lambda x: np.sqrt(x['u_d']**2 + x['u_q']**2),  # Voltage vector norm\n     #'S_el': lambda x: x['i_s']*x['u_s'],                  # Apparent power\n     #'P_el': lambda x: x['i_d'] * x['u_d'] + x['i_q'] *x['u_q'],  # Effective power\n     #'i_s_x_w': lambda x: x['i_s']*x['motor_speed'],\n     #'S_x_w': lambda x: x['S_el']*x['motor_speed'],\n}\ndf = df.assign(**extra_feats)\nx_cols = [x for x in df.columns.tolist() if x not in target_features + [PROFILE_ID_COL]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"spans = [6360, 3360, 1320, 9480]  # these values correspond to cutoff-frequencies in terms of low pass filters, or half-life in terms of EWMAs, respectively\n\ndef dig_into_rolling_features(_df):\n    \"\"\"_df corresponds to a unique measurement session\"\"\"\n\n    # get max lookback\n    max_lookback = max(spans)\n    # prepad default values until max lookback in order to get unbiased\n    # rolling lookback feature during first observations\n    dummy = pd.DataFrame(np.zeros((max_lookback, len(_df.columns))),\n                         columns=_df.columns)\n\n    temperature_cols = [c for c in ['ambient', 'coolant'] if c in _df]\n    dummy.loc[:, temperature_cols] = _df.loc[0, temperature_cols].values\n\n    # prepad\n    _df = pd.concat([dummy, _df], axis=0, ignore_index=True)\n\n    ew_mean = [_df.ewm(span=lb).mean()\n                   .rename(columns=lambda c: c+'_ewma_'+str(lb))\n               for lb in spans]\n    ew_std = pd.concat(\n        [_df.ewm(span=lb).std().fillna(0).astype(np.float32)\n             .rename(columns=lambda c: c+'_ewms_'+str(lb))\n         for lb in spans], axis=1)\n\n    concat_l = [pd.concat(ew_mean, axis=1).astype(np.float32),\n                ew_std,\n                ]\n    ret = pd.concat(concat_l, axis=1).iloc[max_lookback:, :]\\\n        .reset_index(drop=True)\n    return ret","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# smooth input temperatures (mitigate artifacts)\ncols_to_smooth = ['ambient', 'coolant']\nsmoothing_window = 100\norig_x = df.loc[:, cols_to_smooth]\nx_smoothed = [x.rolling(smoothing_window,\n                        center=True).mean() for p_id, x in\n              df[cols_to_smooth + [PROFILE_ID_COL]]\n                  .groupby(PROFILE_ID_COL, sort=False)]\ndf.loc[:, cols_to_smooth] = pd.concat(x_smoothed).fillna(orig_x)\n\np_df_list = [meas.drop(PROFILE_ID_COL, axis=1).reset_index(drop=True)\n             for _, meas in df[x_cols + [PROFILE_ID_COL]].groupby([PROFILE_ID_COL], sort=False)]\n# add EWMA and EWMS\ndf = pd.concat([df, \n                pd.concat([dig_into_rolling_features(p) for p in p_df_list], ignore_index=True)],\n               axis=1).dropna().reset_index(drop=True)\n\nx_cols = [x for x in df.columns.tolist() if x not in target_features + [PROFILE_ID_COL]]\ny_cols = target_features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### helper functions and classes\nA small collection of formatting and visualization helper functions.\nPlease feel free to reuse for easier comparability.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error as mse, mean_squared_log_error\\\n    as msle, mean_absolute_error as mae, r2_score\nfrom matplotlib.colors import rgb2hex\n\n\ndef print_scores(y_true, y_pred):\n    if hasattr(y_true, 'values'):\n        y_true = y_true.values\n    if hasattr(y_pred, 'values'):\n        y_pred = y_pred.values\n    print(f'MSE: {mse(y_true, y_pred):.6} K²')\n    print(f'MAE: {mae(y_true, y_pred):.6} K')\n    print(f'MaxAbsDev: {np.max(np.abs(y_pred - y_true)):.6} K')\n    print(f'R2 : {r2_score(y_true, y_pred):.6}')\n\nclass Report:\n    \"\"\"Summary of an experiment/trial\"\"\"\n\n    param_map = {'pm': '{PM}',\n                 'stator_tooth': '{ST}',\n                 'stator_yoke': '{SY}',\n                 'stator_winding': '{SW}',\n                 'motor_speed': 'motor speed',\n                 'ambient': 'ambient temperature',\n                 'coolant': 'coolant temperature'}\n    output_param_map = {'pm': 'magnet temperature',\n                        'stator_tooth': 'stator tooth temperature',\n                        'stator_yoke': 'stator yoke temperature',\n                        'stator_winding': 'stator winding temperature'}\n\n    def __init__(self, uid, yhat=None, actual=None, history=None,\n                 used_loss=None, model=None,):\n\n       \n        self.yhat_te = yhat\n        self.actual = actual\n        self.history = history\n        self.uid = uid\n        self.yhat_tr = None\n        self.start_time = datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n        self.used_loss = used_loss\n        self.model = model\n\n        clr_sets =\\\n            {'dark_background': {k: v for k, v in zip(\n                ['turquoise', 'yellow', 'violet',\n                 'red', 'blue', 'orange', 'green'] +\n                 ['other_{}'.format(i) for i in range(5)],\n                 [rgb2hex(c[:3]) for c in plt.cm.Set3(np.linspace(0, 1, 12))])}\n             }\n        self.clrs = clr_sets['dark_background']\n        \n    def plot(self, show=True, with_input=False):\n        plt.style.use('dark_background')\n\n        self.plot_history()\n        self.plot_compact_testset_error(with_input)\n        self.plot_residual_over_y_range()\n\n        if show:\n            plt.show() \n    \n    def plot_history(self):\n        if self.history is not None:\n            history = self.history.history\n            plt.figure(figsize=(6, 4))\n            plt.plot(history['loss'], label='train loss')\n            plt.plot(history['val_loss'], label='validation loss')\n            plt.xlabel('epoch')\n            plt.ylabel(f'{self.used_loss} in K²')\n            plt.title(f'Training/Validation Score over Epochs of Experiment '\n                      f'{self.uid}')\n            plt.semilogy()\n            plt.legend()\n    \n    def plot_compact_testset_error(self, with_input=True):\n        n_targets = len(self.actual.columns)\n\n        rows = 2\n        tst_df = None\n        input_cols = ['motor_speed', 'torque', 'ambient', 'coolant']\n\n        plot_length = 2 * rows\n        fig, axes = plt.subplots(rows, n_targets, sharex=True, sharey='row',\n                                 figsize=(12, plot_length))\n\n        for i, c in enumerate(self.actual):\n            # plot signal measured and estimated\n            # todo: Having only 1 target will break here\n            #  axes is 1d then\n            ax = axes[0, i]\n            diff = self.yhat_te[c] - self.actual[c]\n            ax.set_title(r'$\\vartheta_{}$'.format(self.param_map[c]),\n                         fontdict=dict(fontsize=12))\n            ax.plot(self.actual[c], color=self.clrs['turquoise'],\n                    label='ground truth',\n                    linestyle='-')\n            ax.plot(self.yhat_te[c], color=self.clrs['orange'],\n                    label='prediction',\n                    linestyle='-')\n            ax.set_xlim(-1000, np.around(len(self.actual), -3) + 300)\n            tcks = np.arange(0, np.around(len(self.actual), -3), 7200)\n            tcks_lbls = tcks // 7200\n            if i == 0:\n                ax.set_ylabel('Measured and\\nestimated\\ntemp. °C')\n                ax.legend(ncol=1, loc='lower left')\n            ax.set_xticks(tcks)\n            ax.set_xticklabels(tcks_lbls)\n            ax.text(0.5, 0.95,\n                    s=f'MSE: {(diff ** 2).mean():.2f} (°C)²',\n                    #bbox={'facecolor': 'white',\n                    #      'edgecolor': 'black'},\n                    transform=ax.transAxes,\n                    verticalalignment='top', horizontalalignment='center')\n            ax.grid(alpha=0.5)\n            # plot signal estimation error\n            ax = axes[1, i]\n            ax.plot(diff, color=self.clrs['red'],\n                    label='Temperature Estimation error ' +\n                          r'$\\vartheta_{}$'.format(self.param_map[c]))\n            if i == 0:\n                ax.set_ylabel('Temperature\\nestimation\\nerror °C')\n            ax.text(0.5, 0.95,\n                    #bbox={'facecolor': 'white', 'edgecolor': 'black'},\n                    transform=ax.transAxes,\n                    s=r'$||e||_\\infty$: ' + f'{diff.abs().max():.2f} °C',\n                    verticalalignment='top', horizontalalignment='center')\n            ax.grid(alpha=0.5)\n            if not with_input:\n                ax.set_xlabel('Time in hours')\n        \n        fig.tight_layout()\n        \n    def plot_residual_over_y_range(self):\n        n_targets = len(self.actual.columns)\n        rows = 1\n        plot_length = 3 * rows\n        fig, axes = plt.subplots(rows, n_targets, sharex=True, sharey='row',\n                                 figsize=(n_targets*12/4, plot_length))\n        for i, (c, ax) in enumerate(zip(self.actual, axes.flatten())):\n            # plot signal measured and estimated\n            residuals = \\\n                (pd.DataFrame({c + '_true': self.actual[c],\n                               c + '_pred': self.yhat_te[c]})\n                 .sort_values(c + '_true')\n                 )\n            ax.scatter(residuals[f'{c}_true'],\n                        residuals[f'{c}_pred'] - residuals[f'{c}_true'],\n                        s=1, label=c, color=self.clrs['red'])\n            ax.axhline(color='white', ls='--')\n            ax.set_xlabel(r'$\\vartheta_{}$'.format(self.param_map[c]) +\n                       ' ground truth °C')\n            ax.set_title(r'$\\vartheta_{0}$ prediction'.format(self.param_map[c]))\n            if i == 0:\n                ax.set_ylabel('prediction error °C')\n            ax.grid(alpha=0.5)\n\n        fig.tight_layout()\n    \n    def print(self):\n        print('')\n        print('#' * 5 + ' Trial Report ' + '#'*5)\n        print(f\"Trial ID: {self.uid}\")\n        print_scores(self.actual, self.yhat_te)\n        print('#' * 20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model training\n\nWe present the most basic statistical model, the ordinary least squares (OLS) approach.","metadata":{}},{"cell_type":"code","source":"test_set_profiles = [65, 72]\ntrainset = df.loc[~df.profile_id.isin(test_set_profiles), :].reset_index(drop=True)\ntestset = df.loc[df.profile_id.isin(test_set_profiles), :].reset_index(drop=True)\n\nx_train = trainset.loc[:, x_cols]\ny_train = trainset.loc[:, target_features]\nx_test = testset.loc[:, x_cols]\ny_test = testset.loc[:, target_features]\n\n# standardize\nscaler = StandardScaler()\ny_scaler = StandardScaler()\nx_train = pd.DataFrame(scaler.fit_transform(x_train), columns=x_cols)\nx_test = pd.DataFrame(scaler.transform(x_test), columns=x_cols)\ny_train = pd.DataFrame(y_scaler.fit_transform(y_train), columns=y_cols)\n\nols = OLS(fit_intercept=False)\nprint('Start fitting OLS...')\nols.fit(x_train, y_train)\nprint('Predict with OLS...')\npred = ols.predict(x_test)\npred = pd.DataFrame(y_scaler.inverse_transform(pred), columns=y_test.columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The Report class can be used to have a quick performance overview\nreport = Report('OLS', pred, y_test)\nreport.plot()\nreport.print()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}