{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np \nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# reading dataset\ndf = pd.read_csv(\"/kaggle/input/hackerearth-ml-challenge-pet-adoption/train.csv\")\ndf = df.fillna(df.mean())\n\n# This is for Features\nx = df[['condition', 'color_type', 'length(m)', 'height(cm)','X1', 'X2']]\n\n# We have Two Targer Value that is y1 and y2\ny1 = df['breed_category']\ny2 = df['pet_category']\n\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nx['color_type'] = le.fit_transform(x['color_type'])\nx.head()\n\ndf_t = pd.read_csv(\"/kaggle/input/hackerearth-ml-challenge-pet-adoption/test.csv\")\ndf_t = df_t.fillna(df.mean())\nxt = df_t[['condition', 'color_type', 'length(m)', 'height(cm)','X1', 'X2']]\nxt['color_type'] = le.transform(xt['color_type'])\nyt1 = []\nyt2 = []\nxt.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## CatBoosting : 88.62%","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from catboost import CatBoostRegressor\ncbc = CatBoostRegressor()\ncbc.fit(x,y1)\ny_pred1=cbc.predict(xt)\n\ncbc.fit(x,y2)\ny_pred2=cbc.predict(xt)\n\no = list(zip(df_t[\"pet_id\"], y_pred1, y_pred2))\no = np.array(o)\ndf = pd.DataFrame(o, columns = [\"pet_id\", 'breed_category', 'pet_category'])\ndf.to_csv(\"CatBoost.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## AdaBoosting : 76.179% Acc","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import AdaBoostRegressor\nrf_boost=AdaBoostRegressor()\n\nmodel = rf_boost.fit(x, y1)\ny_pred1 = model.predict(xt)\n\nmodel1 = rf_boost.fit(x, y2)\ny_pred2 = model1.predict(xt)\n\no = list(zip(df_t[\"pet_id\"], y_pred1, y_pred2))\no = np.array(o)\ndf = pd.DataFrame(o, columns = [\"pet_id\", 'breed_category', 'pet_category'])\ndf.to_csv(\"AdaBoost.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Gradient Boosting : 87.35% Acc","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor\ngboost=GradientBoostingRegressor()\n\nmodel = gboost.fit(x, y1)\ny_pred1 = model.predict(xt)\n\nmodel2 = gboost.fit(x, y2)\ny_pred2 = model2.predict(xt)\n\no = list(zip(df_t[\"pet_id\"], y_pred1, y_pred2))\no = np.array(o)\ndf = pd.DataFrame(o, columns = [\"pet_id\", 'breed_category', 'pet_category'])\ndf.to_csv(\"GradientBoost.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Linear Regression : 55.80% Acc","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nlr=LinearRegression()\n\nmodel = lr.fit(x, y1)\ny_pred = model.predict(xt)\n\nmodel1 = lr.fit(x, y2)\ny_pred1 = model1.predict(xt)\n\no = list(zip(df_t[\"pet_id\"], y_pred, y_pred1))\no = np.array(o)\n\ndf = pd.DataFrame(o, columns = [\"pet_id\", 'breed_category', 'pet_category'])\ndf.to_csv(\"LinearRegressor.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## XGBoost : 89.27% Acc","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\nmodel = XGBClassifier()\n\nmodel = model.fit(x, y1)\ny_pred1 = model.predict(xt)\n\nmodel1 = model.fit(x, y2)\ny_pred2 = model1.predict(xt)\n\no = list(zip(df_t[\"pet_id\"], y_pred1, y_pred2))\no = np.array(o)\n\ndf = pd.DataFrame(o, columns = [\"pet_id\", 'breed_category', 'pet_category'])\ndf.to_csv(\"XGBoost.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## SVM : 71.91 % Acc","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nsvm = SVC(probability=True)\n\nsvm1 = svm.fit(x, y1)\ny_pred1 = svm1.predict(xt)\n\nsvm2 = svm.fit(x, y2)\ny_pred2 = svm2.predict(xt)\n\no = list(zip(df_t[\"pet_id\"], y_pred1, y_pred2))\no = np.array(o)\n\ndf = pd.DataFrame(o, columns = [\"pet_id\", 'breed_category', 'pet_category'])\ndf.to_csv(\"SVM.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Naive Bayes: 76.77% Acc","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nnb = GaussianNB()\n\nnb1 = nb.fit(x, y1)\ny_pred1 = nb1.predict(xt)\n\nnb2 = nb.fit(x, y2)\ny_pred2 = nb2.predict(xt)\n\no = list(zip(df_t[\"pet_id\"], y_pred1, y_pred2))\no = np.array(o)\n\ndf = pd.DataFrame(o, columns = [\"pet_id\", 'breed_category', 'pet_category'])\ndf.to_csv(\"NaiveBayes.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random Forest : 87.72% Acc","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrf=RandomForestClassifier()\n\nrf1 = rf.fit(x, y1)\ny_pred1 = rf1.predict(xt)\n\nrf2 = rf.fit(x, y2)\ny_pred2 = rf2.predict(xt)\n\no = list(zip(df_t[\"pet_id\"], y_pred1, y_pred2))\no = np.array(o)\n\ndf = pd.DataFrame(o, columns = [\"pet_id\", 'breed_category', 'pet_category'])\ndf.to_csv(\"RandomForest.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## KNN : 79.90% Acc","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nknn=KNeighborsClassifier()\n\nknn1 = knn.fit(x, y1)\ny_pred1 = knn1.predict(xt)\n\nknn2 = knn.fit(x, y2)\ny_pred2 = knn2.predict(xt)\n\no = list(zip(df_t[\"pet_id\"], y_pred1, y_pred2))\no = np.array(o)\n\ndf = pd.DataFrame(o, columns = [\"pet_id\", 'breed_category', 'pet_category'])\ndf.to_csv(\"KNN.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import SGDRegressor\n\nsgd_reg = SGDRegressor(random_state= 0, max_iter = 10000, learning_rate = 'optimal', penalty = 'l2')\nsgd1 = sgd_reg.fit(x, y1)\ny_pred1 = sgd1.predict(xt) \n\nsgd_reg = SGDRegressor(random_state= 0, max_iter = 25000, learning_rate = 'optimal', penalty = 'l2')\nsgd2 = sgd_reg.fit(x, y2)\ny_pred2 = sgd2.predict(xt) \n\no = list(zip(df_t[\"pet_id\"], y_pred1, y_pred2))\no = np.array(o)\n\ndf = pd.DataFrame(o, columns = [\"pet_id\", 'breed_category', 'pet_category'])\ndf.to_csv(\"SGDRegressor.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import LinearSVR\nfrom sklearn.datasets import make_regression\nlin_SVR = LinearSVR(random_state=0, tol=0.05, C=100, epsilon=0.1)\nSVR1 = lin_SVR.fit(x, y1)\ny_pred1 = SVR1.predict(xt)\n\nSVR2 = lin_SVR.fit(x, y2)\ny_pred2 = SVR2.predict(xt)\n\no = list(zip(df_t[\"pet_id\"], y_pred1, y_pred2))\no = np.array(o)\n\ndf = pd.DataFrame(o, columns = [\"pet_id\", 'breed_category', 'pet_category'])\ndf.to_csv(\"linear_SVR.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Thank You\n### if you like this kerner just hit the like.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/hackerearth-ml-challenge-pet-adoption/train.csv\")\ndf = df.fillna(df.mean())\n\n# This is for Features\nx = df[['condition', 'color_type', 'length(m)', 'height(cm)','X1', 'X2']]\n\n# We have Two Targer Value that is y1 and y2\ny1 = df['breed_category']\ny2 = df['pet_category']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nx['color_type'] = le.fit_transform(x['color_type'])\nx.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_t = pd.read_csv(\"/kaggle/input/hackerearth-ml-challenge-pet-adoption/test.csv\")\ndf_t = df_t.fillna(df.mean())\nxt = df_t[['condition', 'color_type', 'length(m)', 'height(cm)','X1', 'X2']]\nxt['color_type'] = le.transform(xt['color_type'])\nxt.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom catboost import CatBoostClassifier\n\n\nresults=[]\nnames=[]\nmodels=[]\nlr=LogisticRegression()\nknn=KNeighborsClassifier()\nsvm=SVC(probability=True)\nrf=RandomForestClassifier()\nnb=GaussianNB()\nrf_boost=AdaBoostClassifier()\ngboost=GradientBoostingClassifier()\ncbc=CatBoostClassifier()\n\nmodels.append(('cbc',cbc))\nmodels.append(('lr',lr))\nmodels.append(('knn',knn))\nmodels.append(('svm',svm))\nmodels.append(('rf',rf))\nmodels.append(('nb',nb))\nmodels.append(('rf_boost',rf_boost))\nmodels.append(('gboost',gboost))\n\nfor name,model in models:\n    kfold=KFold(shuffle=True,n_splits=10,random_state=1)\n    cv_results=cross_val_score(model,x,y1,cv=kfold) \n    results.append(cv_results)\n    names.append(name)\n    print(\"%s:%f (%f)\" % (name,np.mean(cv_results),np.var(cv_results,ddof=1)))  ##we have 10 recall scores. we are taking its average.\n    \n#boxplot algorithm comparison\nfig=plt.figure()\nfig.suptitle('algorithm comparison')\nax=fig.add_subplot(111)\nplt.boxplot(results)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Day3","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pre = []\ny_pre1 = []\nfor i in range(len(y_pred)):\n    y_pre.append(y_pred[i][0])\n    y_pre1.append(y_pred1[i][0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport lightgbm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelBinarizer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/hackerearth-ml-challenge-pet-adoption/train.csv\")\ndf = df.fillna(df.mean())\n\n# This is for Features\nx = df[['condition', 'color_type', 'length(m)', 'height(cm)','X1', 'X2']]\n\n# We have Two Targer Value that is y1 and y2\ny1 = df['breed_category']\ny2 = df['pet_category']\n\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nx['color_type'] = le.fit_transform(x['color_type'])\nx.head()\n\n\ndf_t = pd.read_csv(\"/kaggle/input/hackerearth-ml-challenge-pet-adoption/test.csv\")\ndf_t = df_t.fillna(df.mean())\nxt = df_t[['condition', 'color_type', 'length(m)', 'height(cm)','X1', 'X2']]\nxt['color_type'] = le.transform(xt['color_type'])\nxt.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from lightgbm import LGBMClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom matplotlib import pyplot\n\nmodel = LGBMClassifier(boosting_type='gbdt', \n                       num_leaves=31, \n                       max_depth=- 1, \n                       learning_rate=0.05, \n                       n_estimators=1000, \n                       subsample_for_bin=15, \n                       min_split_gain=0.0, \n                       min_child_weight=0.001, \n                       min_child_samples=20, \n                       subsample=1.0, \n                       random_state=5)\ncv = RepeatedStratifiedKFold(n_splits=100, n_repeats=3, random_state=1)\nn_scores = cross_val_score(model, x, y1, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\nprint('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fit the model on the whole dataset\nmodel = LGBMClassifier()\nmodel.fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}