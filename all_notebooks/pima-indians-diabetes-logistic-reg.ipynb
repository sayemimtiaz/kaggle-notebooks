{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# To enable plotting graphs in Jupyter notebook\n%matplotlib inline ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom sklearn.linear_model import LogisticRegression\n\n# importing ploting libraries\nimport matplotlib.pyplot as plt   \n\n#importing seaborn for statistical plots\nimport seaborn as sns\n\n#Let us break the X and y dataframes into training set and test set. For this we will use\n#Sklearn package's data splitting function which is based on random function\n\nfrom sklearn.model_selection import train_test_split\n\nimport numpy as np\n\n\n# calculate accuracy measures and confusion matrix\nfrom sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The data lies in the following URL.\n#url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Since it is a data file with no header, we will supply the column names which have been obtained from the above URL \n# Create a python list of column names called \"names\"\n\ncolnames = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n\n#Load the file from local directory using pd.read_csv which is a special form of read_table\n#while reading the data, supply the \"colnames\" list\n\npima_df = pd.read_csv(\"../input/pima-indians-diabetes-database/diabetes.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pima_df.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let us check whether any of the columns has any value other than numeric i.e. data is not corrupted such as a \"?\" instead of \n# a number.\n\n# we use np.isreal a numpy function which checks each column for each row and returns a bool array, \n# where True if input element is real.\n# applymap is pandas dataframe function that applies the np.isreal function columnwise\n# Following line selects those rows which have some non-numeric value in any of the columns hence the  ~ symbol\n\npima_df[~pima_df.applymap(np.isreal).all(1)]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# replace the missing values in pima_df with median value :Note, we do not need to specify the column names\n# every column's missing value is replaced with that column's median respectively\n#pima_df = pima_df.fillna(pima_df.median())\n#pima_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets analysze the distribution of the various attributes\npima_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let us look at the target column which is 'class' to understand how the data is distributed amongst the various values\npima_df.groupby([\"Outcome\"]).count()\n\n# Most are not diabetic. The ratio is almost 1:2 in favor or class 0.  The model's ability to predict class 0 will \n# be better than predicting class 1. ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let us do a correlation analysis among the different dimensions and also each dimension with the dependent dimension\n# This is done using scatter matrix function which creates a dashboard reflecting useful information about the dimensions\n# The result can be stored as a .png file and opened in say, paint to get a larger view \n\n#pima_df_attr = pima_df.iloc[:,0:9]\n\n#axes = pd.plotting.scatter_matrix(pima_df_attr)\n#plt.tight_layout()\n#plt.savefig('d:\\greatlakes\\pima_pairpanel.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Pairplot using sns\n\nsns.pairplot(pima_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#data for all the attributes are skewed, especially for the variable \"test\"\n\n#The mean for test is 80(rounded) while the median is 30.5 which clearly indicates an extreme long tail on the right\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Attributes which look normally distributed (plas, pres, skin, and mass).\n# Some of the attributes look like they may have an exponential distribution (preg, test, pedi, age).\n# Age should probably have a normal distribution, the constraints on the data collection may have skewed the distribution.\n\n# There is no obvious relationship between age and onset of diabetes.\n# There is no obvious relationship between pedi function and onset of diabetes.\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"array = pima_df.values\nX = pima_df.iloc[:,0:8]\ny = pima_df.iloc[:,8]\n#X = array[:,0:8] # select all rows and first 8 columns which are the attributes\n#Y = array[:,8]   # select all rows and the 8th column which is the classification \"Yes\", \"No\" for diabeties\ntest_size = 0.30 # taking 70:30 training and test set\nseed =1 # Random numbmer seeding for reapeatability of the code\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fit the model on 30%\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\ny_predict = model.predict(X_test)\n\nt=list(X_train.columns)\n\ncoef_df = pd.DataFrame(model.coef_, columns= t)\ncoef_df['intercept'] = model.intercept_\nprint(coef_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_score = model.score(X_test, y_test)\nprint(model_score)\nprint(metrics.confusion_matrix(y_test, y_predict))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Improve the model -----------------------------Iteration 2 -----------------------------------------------","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# To scale the dimensions we need scale function which is part of sckikit preprocessing libraries\n\nfrom sklearn import preprocessing\n\n# scale all the columns of the mpg_df. This will produce a numpy array\n#pima_df_scaled = preprocessing.scale(pima_df[0:7])\nX_train_scaled = preprocessing.scale(X_train)\nX_test_scaled = preprocessing.scale(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fit the model on 30%\nmodel = LogisticRegression()\nmodel.fit(X_train_scaled, y_train)\ny_predict = model.predict(X_test_scaled)\nmodel_score = model.score(X_test_scaled, y_test)\nprint(model_score)\n\n\n# IMPORTANT: first argument is true values, second argument is predicted values\n# this produces a 2x2 numpy array (matrix)\nprint(metrics.confusion_matrix(y_test, y_predict))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(metrics.classification_report(y_test, y_predict))","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true},"cell_type":"markdown","source":"    Analyzing the confusion matrix\n\nTrue Positives (TP): we correctly predicted that they do have diabetes 132\n\nTrue Negatives (TN): we correctly predicted that they don't have diabetes 48\n\nFalse Positives (FP): we incorrectly predicted that they do have diabetes (a \"Type I error\") 37\nFalsely predict positive Type I error\n\n\nFalse Negatives (FN): we incorrectly predicted that they don't have diabetes (a \"Type II error\") 48\nFalsely predict negative Type II error","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}