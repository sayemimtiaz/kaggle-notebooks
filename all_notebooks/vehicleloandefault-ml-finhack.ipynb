{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Vehicle Loan Default - LTFS"},{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom scipy import stats, integrate\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt \nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom xgboost import XGBClassifier\n%matplotlib inline\nfrom sklearn.linear_model import LinearRegression\npd.options.display.float_format = '{:.2f}'.format\nplt.rcParams['figure.figsize'] = (10, 8)\nplt.rcParams['font.size'] = 14","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing the train and test datasets\n\ntrain = pd.read_csv(\"../input/train_LTFS.csv\")\ntest = pd.read_csv(\"../input/test_LTFS.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_original=train.copy() \ntest_original=test.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.columns, train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have 40 independent variables and 1 target variable, i.e. Loan_Status in the train dataset. Let’s also have a look at the columns of test dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"test.columns, test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print data types for each variable \nprint(train.dtypes)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see there are three format of data types:\n\nobject:variables in our dataset are: Date.of.Birth, Employment.Type, DisbursalDate, PERFORM_CNS.SCORE.DESCRIPTION, AVERAGE.ACCT.AGE, CREDIT.HISTORY.LENGTH     \n\nint64:represents the integer variables. \nUniqueID, disbursed_amount, asset_cost, branch_id, supplier_id, manufacturer_id, Current_pincode_ID , State_ID, Employee_code_ID, MobileNo_Avl_Flag, Aadhar_flag, PAN_flag, VoterID_flag, Driving_flag, Passport_flag, PERFORM_CNS.SCORE, PRI.NO.OF.ACCTS, PRI.ACTIVE.ACCTS, PRI.OVERDUE.ACCTS, PRI.CURRENT.BALANCE, PRI.SANCTIONED.AMOUNT, PRI.DISBURSED.AMOUNT, SEC.NO.OF.ACCTS, SEC.ACTIVE.ACCTS, SEC.OVERDUE.ACCTS, SEC.CURRENT.BALANCE, SEC.SANCTIONED.AMOUNT, SEC.DISBURSED.AMOUNT, PRIMARY.INSTAL.AMT, SEC.INSTAL.AMT, NEW.ACCTS.IN.LAST.SIX.MONTHS, DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS, NO.OF_INQUIRIES, loan_default                                                          \n                                        \nfloat64:represents the variable which have some decimal values involved: ltv\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum(),train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.isnull().sum(),test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Filling Missing values\n\ntrain['Employment.Type'].fillna('Unemployed', inplace = True)\ntest['Employment.Type'].fillna('Unemployed', inplace = True)\n\n# let's check if there is any null values still left or not\nprint(\"Null values left in the train set:\", train.isnull().sum().sum())\nprint(\"Null values left in the test set:\", test.isnull().sum().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Target Variable\nWe will first look at the target variable, i.e., Loan_default. As it is a int64 variable, let us look at its frequency table, percentage distribution and bar plot.\n\nFrequency table of a variable will give us the count of each category in that variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['loan_default'].value_counts()\n\n# Normalize can be set to True to print proportions instead of number \ntrain['loan_default'].value_counts(normalize=True)\n\ntrain['loan_default'].value_counts().plot.bar()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Not Default(0) =  182543 Count <br>\n    Default(1) =   50611 Count"},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix = train.corr() \nf, ax = plt.subplots(figsize=(30, 18)) \nsns.heatmap(matrix, vmax=1.5, square=True,annot=True, fmt=\".1f\",cmap=\"BuPu\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**The most correlated variables are:<br>**\n\n- PRI Sanctioned Amount & PRI Disbursed Amount. (1.0)<br> \n- PRI No. of Accts & PRI Active Accts. (0.8)<br>\n- SEC. No. of Accts & SEC.Active Accts. (1.0)<br>\n- SEC. Current Balance & SEC Sanctioned Amount. (0.9)<br>\n- SEC. Current Balance & SEC. Disbursed Amount. (0.9)<br>\n- SEC Sanctioned Amount & SEC. Disbursed Amount. (1.0)<br>\n- Adhar_flag & VoterID_flag. (-0.9)<br>\n- New Accts in last 6 months & PRI Active Accts.(0.7)<br>\n- Disbursed_Amount & Asset_cost.(0.7)<br>\n\n\n    "},{"metadata":{"trusted":true},"cell_type":"code","source":"#performing log transformations on disbursed amount, ltv, and asset cost\n\n# training dataset\ntrain['disbursed_amount'] = np.log1p(train['disbursed_amount'])\ntrain['ltv'] = np.log1p(train['ltv'])\ntrain['asset_cost'] = np.log1p(train['asset_cost'])\n\n# test data set\ntest['disbursed_amount'] = np.log1p(test['disbursed_amount'])\ntest['ltv'] = np.log1p(test['ltv'])\ntest['asset_cost'] = np.log1p(test['asset_cost'])\n\n# plotting training dataset\nplt.rcParams['figure.figsize'] = (18, 5)\n\nplt.subplot(1, 3, 1)\nsns.distplot(train['disbursed_amount'],  color = 'orange')\nplt.title('Disburesed Amount')\n\nplt.subplot(1, 3, 2)\nsns.distplot(train['asset_cost'], color = 'pink')\nplt.title('Asset Cost')\n\nplt.subplot(1, 3, 3)\nsns.distplot(train['ltv'], color = 'red')\nplt.title('Loan to value of the asset')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Total no. of Unique Ids :\", train['UniqueID'].nunique())\nprint(\"Total no. of Unique Branches :\", train['branch_id'].nunique())\nprint(\"Total no. of Unique Suppliers :\", train['supplier_id'].nunique())\nprint(\"Total no. of Unique Manufactures :\", train['manufacturer_id'].nunique())\nprint(\"Total no. of Unique Current pincode Ids :\", train['Current_pincode_ID'].nunique())\nprint(\"Total no. of Unique State IDs :\", train['State_ID'].nunique())\nprint(\"Total no. of Unique Employee code IDs :\", train['Employee_code_ID'].nunique())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Total no. of Unique Ids :\", test['UniqueID'].nunique())\nprint(\"Total no. of Unique Branches :\", test['branch_id'].nunique())\nprint(\"Total no. of Unique Suppliers :\", test['supplier_id'].nunique())\nprint(\"Total no. of Unique Manufactures :\", test['manufacturer_id'].nunique())\nprint(\"Total no. of Unique Current pincode Ids :\", test['Current_pincode_ID'].nunique())\nprint(\"Total no. of Unique State IDs :\", test['State_ID'].nunique())\nprint(\"Total no. of Unique Employee code IDs :\", test['Employee_code_ID'].nunique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# normalizing the value \nplt.figure(1) \nplt.subplot(311) \ntrain['manufacturer_id'].value_counts(normalize=True).plot.bar(figsize=(24,10), title= 'manufacturer_id', fontsize=14) \nplt.subplot(312) \ntrain['State_ID'].value_counts(normalize=True).plot.bar(title= 'State_ID',fontsize=14) \nplt.subplot(313) \ntrain['branch_id'].value_counts(normalize=True).plot.bar(title= 'branch_id', fontsize=14) \n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# converting the DOB in date-time-format to extract the year of birth \n\ntrain['Date.of.Birth'] = pd.to_datetime(train['Date.of.Birth'],errors = 'coerce')\n\n# extracting the year of birth of the customers\ntrain['Year_of_birth'] = train['Date.of.Birth'].dt.year\n\n# checking the values inside date of year\nsns.distplot(train['Year_of_birth'], color = 'green')\nplt.title('Distribution of Year of birth')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Changing Employment.Type dtype object to int64\n\ntrain['Employment.Type'] = train['Employment.Type'].replace(('Self employed', 'Salaried', 'Unemployed'), (2, 1, 0))\n\n# checking the values  of employement type\ntrain['Employment.Type'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['Employment.Type'] = test['Employment.Type'].replace(('Self employed', 'Salaried', 'Unemployed'), (2, 1, 0))\n\n# checking the values  of employement type\ntest['Employment.Type'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n\n#Visualizing the Employment Type\n\nsns.countplot(x='Employment.Type',data=train)\n\nplt.show()\n\ntrain['Employment.Type'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# features extraction from disbursal dates\n# Extracting months as all disbursement done in year 2018.\n\ntrain['DisbursalDate'] = pd.to_datetime(train['DisbursalDate'], errors = 'coerce')\n\n# extracting the month of the disbursement\ntrain['DisbursalMonth'] = train['DisbursalDate'].dt.month\n\ntrain['DisbursalMonth'].value_counts()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (18, 5)\nsns.countplot(train['DisbursalMonth'], palette = 'colorblind')\nplt.title('Months', fontsize = 30)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# customer has aadhar card or not\nsns.countplot(x=\"Aadhar_flag\", data=train)\n\ntrain['Aadhar_flag'].value_counts()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# customer has shared the mobile no. or not\n\nsns.countplot(x=\"MobileNo_Avl_Flag\", data=train)\n\ntrain['MobileNo_Avl_Flag'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# customer has pan card or not\nsns.countplot(x=\"PAN_flag\", data=train)\ntrain['PAN_flag'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# customer shared voter-id card or not\nsns.countplot(x=\"VoterID_flag\", data=train)\ntrain['VoterID_flag'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# customer shared driving license or not\nsns.countplot(x=\"Driving_flag\", data=train)\ntrain['Driving_flag'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# customer shared passport or not\nsns.countplot(x=\"Passport_flag\", data=train)\ntrain['Passport_flag'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking the perform cns score description\n\nsns.countplot(x='PERFORM_CNS.SCORE.DESCRIPTION',data=train)\nplt.xticks(rotation = 90)\nplt.show()\n\ntrain['PERFORM_CNS.SCORE.DESCRIPTION'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# encodings for bureau score(perform cns score distribution)\n\ntrain['PERFORM_CNS.SCORE.DESCRIPTION'] = train['PERFORM_CNS.SCORE.DESCRIPTION'].replace('No Bureau History Available', 0)\ntrain['PERFORM_CNS.SCORE.DESCRIPTION'] = train['PERFORM_CNS.SCORE.DESCRIPTION'].replace('Not Scored: Sufficient History Not Available', 0)\ntrain['PERFORM_CNS.SCORE.DESCRIPTION'] = train['PERFORM_CNS.SCORE.DESCRIPTION'].replace('Not Scored: Not Enough Info available on the customer', 0)\ntrain['PERFORM_CNS.SCORE.DESCRIPTION'] = train['PERFORM_CNS.SCORE.DESCRIPTION'].replace('Not Scored: No Activity seen on the customer (Inactive)',0)\ntrain['PERFORM_CNS.SCORE.DESCRIPTION'] = train['PERFORM_CNS.SCORE.DESCRIPTION'].replace('Not Scored: No Updates available in last 36 months', 0)\ntrain['PERFORM_CNS.SCORE.DESCRIPTION'] = train['PERFORM_CNS.SCORE.DESCRIPTION'].replace('Not Scored: Only a Guarantor', 0)\ntrain['PERFORM_CNS.SCORE.DESCRIPTION'] = train['PERFORM_CNS.SCORE.DESCRIPTION'].replace('Not Scored: More than 50 active Accounts found',0)\ntrain['PERFORM_CNS.SCORE.DESCRIPTION'] = train['PERFORM_CNS.SCORE.DESCRIPTION'].replace('M-Very High Risk', 1)\ntrain['PERFORM_CNS.SCORE.DESCRIPTION'] = train['PERFORM_CNS.SCORE.DESCRIPTION'].replace('L-Very High Risk', 1)\ntrain['PERFORM_CNS.SCORE.DESCRIPTION'] = train['PERFORM_CNS.SCORE.DESCRIPTION'].replace('K-High Risk', 2)\ntrain['PERFORM_CNS.SCORE.DESCRIPTION'] = train['PERFORM_CNS.SCORE.DESCRIPTION'].replace('J-High Risk', 2)\ntrain['PERFORM_CNS.SCORE.DESCRIPTION'] = train['PERFORM_CNS.SCORE.DESCRIPTION'].replace('I-Medium Risk', 3)\ntrain['PERFORM_CNS.SCORE.DESCRIPTION'] = train['PERFORM_CNS.SCORE.DESCRIPTION'].replace('H-Medium Risk', 3)\ntrain['PERFORM_CNS.SCORE.DESCRIPTION'] = train['PERFORM_CNS.SCORE.DESCRIPTION'].replace('G-Low Risk', 4)\ntrain['PERFORM_CNS.SCORE.DESCRIPTION'] = train['PERFORM_CNS.SCORE.DESCRIPTION'].replace('F-Low Risk', 4)\ntrain['PERFORM_CNS.SCORE.DESCRIPTION'] = train['PERFORM_CNS.SCORE.DESCRIPTION'].replace('E-Low Risk', 4)\ntrain['PERFORM_CNS.SCORE.DESCRIPTION'] = train['PERFORM_CNS.SCORE.DESCRIPTION'].replace('D-Very Low Risk', 5)\ntrain['PERFORM_CNS.SCORE.DESCRIPTION'] = train['PERFORM_CNS.SCORE.DESCRIPTION'].replace('C-Very Low Risk', 5)\ntrain['PERFORM_CNS.SCORE.DESCRIPTION'] = train['PERFORM_CNS.SCORE.DESCRIPTION'].replace('B-Very Low Risk', 5)\ntrain['PERFORM_CNS.SCORE.DESCRIPTION'] = train['PERFORM_CNS.SCORE.DESCRIPTION'].replace('A-Very Low Risk', 5)\n\n# checing the values in bureau score\ntrain['PERFORM_CNS.SCORE.DESCRIPTION'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# encodings for bureau score(perform cns score distribution)\n\ntest['PERFORM_CNS.SCORE.DESCRIPTION'] = test['PERFORM_CNS.SCORE.DESCRIPTION'].replace('No Bureau History Available', 0)\ntest['PERFORM_CNS.SCORE.DESCRIPTION'] = test['PERFORM_CNS.SCORE.DESCRIPTION'].replace('Not Scored: Sufficient History Not Available', 0)\ntest['PERFORM_CNS.SCORE.DESCRIPTION'] = test['PERFORM_CNS.SCORE.DESCRIPTION'].replace('Not Scored: Not Enough Info available on the customer', 0)\ntest['PERFORM_CNS.SCORE.DESCRIPTION'] = test['PERFORM_CNS.SCORE.DESCRIPTION'].replace('Not Scored: No Activity seen on the customer (Inactive)',0)\ntest['PERFORM_CNS.SCORE.DESCRIPTION'] = test['PERFORM_CNS.SCORE.DESCRIPTION'].replace('Not Scored: No Updates available in last 36 months', 0)\ntest['PERFORM_CNS.SCORE.DESCRIPTION'] = test['PERFORM_CNS.SCORE.DESCRIPTION'].replace('Not Scored: Only a Guarantor', 0)\ntest['PERFORM_CNS.SCORE.DESCRIPTION'] = test['PERFORM_CNS.SCORE.DESCRIPTION'].replace('M-Very High Risk', 1)\ntest['PERFORM_CNS.SCORE.DESCRIPTION'] = test['PERFORM_CNS.SCORE.DESCRIPTION'].replace('L-Very High Risk', 1)\ntest['PERFORM_CNS.SCORE.DESCRIPTION'] = test['PERFORM_CNS.SCORE.DESCRIPTION'].replace('K-High Risk', 2)\ntest['PERFORM_CNS.SCORE.DESCRIPTION'] = test['PERFORM_CNS.SCORE.DESCRIPTION'].replace('J-High Risk', 2)\ntest['PERFORM_CNS.SCORE.DESCRIPTION'] = test['PERFORM_CNS.SCORE.DESCRIPTION'].replace('I-Medium Risk', 3)\ntest['PERFORM_CNS.SCORE.DESCRIPTION'] = test['PERFORM_CNS.SCORE.DESCRIPTION'].replace('H-Medium Risk', 3)\ntest['PERFORM_CNS.SCORE.DESCRIPTION'] = test['PERFORM_CNS.SCORE.DESCRIPTION'].replace('G-Low Risk', 4)\ntest['PERFORM_CNS.SCORE.DESCRIPTION'] = test['PERFORM_CNS.SCORE.DESCRIPTION'].replace('F-Low Risk', 4)\ntest['PERFORM_CNS.SCORE.DESCRIPTION'] = test['PERFORM_CNS.SCORE.DESCRIPTION'].replace('E-Low Risk', 4)\ntest['PERFORM_CNS.SCORE.DESCRIPTION'] = test['PERFORM_CNS.SCORE.DESCRIPTION'].replace('D-Very Low Risk', 5)\ntest['PERFORM_CNS.SCORE.DESCRIPTION'] = test['PERFORM_CNS.SCORE.DESCRIPTION'].replace('C-Very Low Risk', 5)\ntest['PERFORM_CNS.SCORE.DESCRIPTION'] = test['PERFORM_CNS.SCORE.DESCRIPTION'].replace('B-Very Low Risk', 5)\ntest['PERFORM_CNS.SCORE.DESCRIPTION'] = test['PERFORM_CNS.SCORE.DESCRIPTION'].replace('A-Very Low Risk', 5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking the bureau score\n\nplt.rcParams['figure.figsize'] = (15, 5)\nplt.subplot(1, 2, 1)\nsns.distplot(train['PERFORM_CNS.SCORE'], color = 'green')\nplt.title('Before Log transformations')\n\n# tranforming to log \n\nplt.subplot(1, 2, 2)\ntrain['PERFORM_CNS.SCORE'] = np.log1p(train['PERFORM_CNS.SCORE'])\nsns.distplot(train['PERFORM_CNS.SCORE'], color = 'blue')\nplt.title('After Log transformations')\nplt.show()\n\n# for test\ntest['PERFORM_CNS.SCORE'] = np.log1p(test['PERFORM_CNS.SCORE'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#  applying log transformations to the primary account attributes\n\ntrain['PRI.NO.OF.ACCTS'] = np.log1p(train['PRI.NO.OF.ACCTS'])\ntrain['PRI.ACTIVE.ACCTS'] = np.log1p(train['PRI.ACTIVE.ACCTS'])\ntrain['PRI.OVERDUE.ACCTS'] = np.log1p(train['PRI.OVERDUE.ACCTS'])\n#train['PRI.CURRENT.BALANCE'] = np.log1p(train['PRI.CURRENT.BALANCE'])\n#train['PRI.SANCTIONED.AMOUNT'] = np.log1p(train['PRI.SANCTIONED.AMOUNT'])\ntrain['PRI.DISBURSED.AMOUNT'] = np.log1p(train['PRI.DISBURSED.AMOUNT'])\n\n\n#  filling  missing values in sec.current.balance\ntrain['PRI.CURRENT.BALANCE'].fillna(train['PRI.CURRENT.BALANCE'].mean(), inplace = True)\ntrain['PRI.SANCTIONED.AMOUNT'].fillna(train['PRI.SANCTIONED.AMOUNT'].mean(), inplace = True)\n\n#  for test\ntest['PRI.NO.OF.ACCTS'] = np.log1p(test['PRI.NO.OF.ACCTS'])\ntest['PRI.ACTIVE.ACCTS'] = np.log1p(test['PRI.ACTIVE.ACCTS'])\ntest['PRI.OVERDUE.ACCTS'] = np.log1p(test['PRI.OVERDUE.ACCTS'])\n#test['PRI.CURRENT.BALANCE'] = np.log1p(test['PRI.CURRENT.BALANCE'])\n#test['PRI.SANCTIONED.AMOUNT'] = np.log1p(test['PRI.SANCTIONED.AMOUNT'])\ntest['PRI.DISBURSED.AMOUNT'] = np.log1p(test['PRI.DISBURSED.AMOUNT'])\n\n\n#  filling  missing values in sec.current.balance\ntest['PRI.CURRENT.BALANCE'].fillna(test['PRI.CURRENT.BALANCE'].mean(), inplace = True)\ntest['PRI.SANCTIONED.AMOUNT'].fillna(test['PRI.SANCTIONED.AMOUNT'].mean(), inplace = True)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# plotting distribution plots for these attributes\n\nplt.rcParams['figure.figsize'] = (20, 16)    \nplt.subplot(2, 3, 1)\nsns.distplot(train['PRI.NO.OF.ACCTS'], color = 'violet')\nplt.title('Total loan taken by customer')\nplt.xticks(rotation = 45)\n\nplt.subplot(2, 3, 2)\nsns.distplot(train['PRI.ACTIVE.ACCTS'], color = 'violet')\nplt.title('Active loan taken by customer')\nplt.xticks(rotation = 45)\n\nplt.subplot(2, 3, 3)\nsns.distplot(train['PRI.OVERDUE.ACCTS'], color = 'violet')\nplt.title('Default Accounts')\nplt.xticks(rotation = 45)\n\nplt.subplot(2, 3, 4)\nsns.distplot(train['PRI.CURRENT.BALANCE'], color = 'violet')\nplt.title('Principal Outstanding amount')\nplt.xticks(rotation = 45)\n\nplt.subplot(2, 3, 5)\nsns.distplot(train['PRI.SANCTIONED.AMOUNT'], color = 'violet')\nplt.title('Total Sanctioned Amount')\nplt.xticks(rotation = 45)\n\nplt.subplot(2, 3, 6)\nsns.distplot(train['PRI.DISBURSED.AMOUNT'], color = 'violet')\nplt.title('Total Disbured Amount')\nplt.xticks(rotation = 45)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# distribution for different attributesof secondary accounts\n\n\nplt.rcParams['figure.figsize'] = (20, 14)    \nplt.subplot(2, 3, 1)\nsns.distplot(train['SEC.NO.OF.ACCTS'], color = 'red')\nplt.title('Total loan taken by customer')\nplt.xticks(rotation = 45)\n\nplt.subplot(2, 3, 2)\nsns.distplot(train['SEC.ACTIVE.ACCTS'], color = 'red')\nplt.title('Active loan taken by customer')\nplt.xticks(rotation = 45)\n\nplt.subplot(2, 3, 3)\nsns.distplot(train['SEC.OVERDUE.ACCTS'], color = 'red')\nplt.title('Default Accounts at the time of disbursement')\nplt.xticks(rotation = 45)\n\nplt.subplot(2, 3, 4)\nsns.distplot(train['SEC.CURRENT.BALANCE'], color = 'red')\nplt.title('Principal Outstanding amount')\nplt.xticks(rotation = 45)\n\nplt.subplot(2, 3, 5)\nsns.distplot(train['SEC.SANCTIONED.AMOUNT'], color = 'red')\nplt.title('Total Sanctioned Amount')\nplt.xticks(rotation = 45)\n\nplt.subplot(2, 3, 6)\nsns.distplot(train['SEC.DISBURSED.AMOUNT'], color = 'red')\nplt.title('Total Disbured Amount')\nplt.xticks(rotation = 45)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['SEC.NO.OF.ACCTS'] = np.log1p(train['SEC.NO.OF.ACCTS'])\ntrain['SEC.ACTIVE.ACCTS'] = np.log1p(train['SEC.ACTIVE.ACCTS'])\ntrain['SEC.OVERDUE.ACCTS'] = np.log1p(train['SEC.OVERDUE.ACCTS'])\n\ntrain['SEC.SANCTIONED.AMOUNT'] = np.log1p(train['SEC.SANCTIONED.AMOUNT'])\ntrain['SEC.DISBURSED.AMOUNT'] = np.log1p(train['SEC.DISBURSED.AMOUNT'])\n\n#  filling  missing values in sec.current.balance\ntrain['SEC.CURRENT.BALANCE'].fillna(train['SEC.CURRENT.BALANCE'].mean(), inplace = True)\n\n\n# for test \n\n\ntest['SEC.NO.OF.ACCTS'] = np.log1p(test['SEC.NO.OF.ACCTS'])\ntest['SEC.ACTIVE.ACCTS'] = np.log1p(test['SEC.ACTIVE.ACCTS'])\ntest['SEC.OVERDUE.ACCTS'] = np.log1p(test['SEC.OVERDUE.ACCTS'])\n\ntest['SEC.SANCTIONED.AMOUNT'] = np.log1p(test['SEC.SANCTIONED.AMOUNT'])\ntest['SEC.DISBURSED.AMOUNT'] = np.log1p(test['SEC.DISBURSED.AMOUNT'])\n\n#  filling  missing values in sec.current.balance\ntest['SEC.CURRENT.BALANCE'].fillna(test['SEC.CURRENT.BALANCE'].mean(), inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (20, 16)    \nplt.subplot(2, 3, 1)\nsns.distplot(train['SEC.NO.OF.ACCTS'], color = 'blue')\nplt.title('Total loan taken by customer')\nplt.xticks(rotation = 45)\n\nplt.subplot(2, 3, 2)\nsns.distplot(train['SEC.ACTIVE.ACCTS'], color = 'blue')\nplt.title('Active loan taken by customer')\nplt.xticks(rotation = 45)\n\nplt.subplot(2, 3, 3)\nsns.distplot(train['SEC.OVERDUE.ACCTS'], color = 'blue')\nplt.title('Default Accounts')\nplt.xticks(rotation = 45)\n\nplt.subplot(2, 3, 4)\nsns.distplot(train['SEC.CURRENT.BALANCE'], color = 'blue')\nplt.title('Principal Outstanding amount')\nplt.xticks(rotation = 45)\n\nplt.subplot(2, 3, 5)\nsns.distplot(train['SEC.SANCTIONED.AMOUNT'], color = 'blue')\nplt.title('Total Sanctioned Amount')\nplt.xticks(rotation = 45)\n\nplt.subplot(2, 3, 6)\nsns.distplot(train['SEC.DISBURSED.AMOUNT'], color = 'blue')\nplt.title('Total Disbured Amount')\nplt.xticks(rotation = 45)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# EMI Amount of the Secondary Plan\n\nplt.subplot(1, 2, 1)\nsns.distplot(train['SEC.INSTAL.AMT'])\nplt.title('EMI Amount Secondary Plan', fontsize = 20)\nplt.xticks(rotation = 45)\n\nplt.subplot(1, 2, 2)\nsns.distplot(train['PRIMARY.INSTAL.AMT'])\nplt.title('EMI Amount Primary Plan', fontsize = 20)\nplt.xticks(rotation = 45)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#performing log transformations\n\ntrain['PRIMARY.INSTAL.AMT'] = np.log1p(train['PRIMARY.INSTAL.AMT'])\ntrain['SEC.INSTAL.AMT'] = np.log1p(train['SEC.INSTAL.AMT'])\n\n\nplt.subplot(1, 2, 1)\nsns.distplot(train['SEC.INSTAL.AMT'], color = 'yellow')\nplt.title('EMI Amount Secondary Plan', fontsize = 20)\nplt.xticks(rotation = 45)\n\nplt.subplot(1, 2, 2)\nsns.distplot(train['PRIMARY.INSTAL.AMT'],color = 'yellow')\nplt.title('EMI Amount Primary Plan', fontsize = 20)\nplt.xticks(rotation = 45)\n\nplt.show()\n\n# test\n\ntest['PRIMARY.INSTAL.AMT'] = np.log1p(test['PRIMARY.INSTAL.AMT'])\ntest['SEC.INSTAL.AMT'] = np.log1p(test['SEC.INSTAL.AMT'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# New Accts in last six months\ntrain['NEW.ACCTS.IN.LAST.SIX.MONTHS'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# loans defaulted accounts in last six months\ntrain['DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplot(1, 2, 1)\nsns.distplot(train['NEW.ACCTS.IN.LAST.SIX.MONTHS'])\nplt.title('NEW.ACCTS.IN.LAST.SIX.MONTHS', fontsize = 20)\nplt.xticks(rotation = 45)\n\nplt.subplot(1, 2, 2)\nsns.distplot(train['DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS'])\nplt.title('DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS', fontsize = 20)\nplt.xticks(rotation = 45)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# average.acct.age i.e., average loan tenure\n\nsns.countplot(train['AVERAGE.ACCT.AGE'].head(50), palette = 'colorblind')\nplt.title('Average Loan Tenure')\nplt.xticks(rotation = 45)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converting the given 'CREDIT.HISTORY.LENGTH' in months\n\nimport re\n\ntrain['CREDIT.HISTORY.LENGTH']= train['CREDIT.HISTORY.LENGTH'].apply(lambda x: (re.sub('[a-z]','',x)).split())\ntrain['CREDIT.HISTORY.LENGTH']= train['CREDIT.HISTORY.LENGTH'].apply(lambda x: int(x[0])*12+int(x[1]))\n\n# Converting the given 'AVERAGE.ACCT.AGE' in months\ntrain['AVERAGE.ACCT.AGE']= train['AVERAGE.ACCT.AGE'].apply(lambda x: (re.sub('[a-z]','',x)).split())\ntrain['AVERAGE.ACCT.AGE']= train['AVERAGE.ACCT.AGE'].apply(lambda x: int(x[0])*12+int(x[1]))\n\n# Converting the given 'CREDIT.HISTORY.LENGTH' in months\ntest['CREDIT.HISTORY.LENGTH']= test['CREDIT.HISTORY.LENGTH'].apply(lambda x: (re.sub('[a-z]','',x)).split())\ntest['CREDIT.HISTORY.LENGTH']= test['CREDIT.HISTORY.LENGTH'].apply(lambda x: int(x[0])*12+int(x[1]))\n\n# Converting the given 'AVERAGE.ACCT.AGE' in months\ntest['AVERAGE.ACCT.AGE']= test['AVERAGE.ACCT.AGE'].apply(lambda x: (re.sub('[a-z]','',x)).split())\ntest['AVERAGE.ACCT.AGE']= test['AVERAGE.ACCT.AGE'].apply(lambda x: int(x[0])*12+int(x[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# distribution of AVERAGE LOAN TENURE in years\nplt.title('AVERAGE LOAN TENURE', fontsize = 25)\nplt.rcParams['figure.figsize'] = (18, 5)\nsns.countplot(train['AVERAGE.ACCT.AGE'].head(50))\n#(x='AVERAGE.ACCT.AGE',data=train,palette = 'dark')\nplt.show()\n#train['AVERAGE.ACCT.AGE'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plotting credit history of users\n\nplt.rcParams['figure.figsize'] = (18, 5)\nsns.countplot(train['CREDIT.HISTORY.LENGTH'].head(50))\nplt.title('Credit History')\nplt.xticks(rotation = 90)\nplt.show()\n#train['CREDIT.HISTORY.LENGTH'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(train['NO.OF_INQUIRIES'], palette = 'muted')\nplt.title('No. of Inquiries',  fontsize = 30)\nplt.show()\ntrain['NO.OF_INQUIRIES'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Downpayment']=train['asset_cost']-train['disbursed_amount'] \ntest['Downpayment']=test['asset_cost']-test['disbursed_amount']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nplt.figure(1) \nplt.subplot(121) \nsns.distplot(train['Downpayment']);\nplt.subplot(122) \ntrain['Downpayment'].plot.box(figsize=(16,5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see it is shifted towards left, i.e., the distribution is right skewed. So, let’s tae the log transformation to make the distribution normal.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Downpayment_log'] = np.log(train['Downpayment'])\nplt.figure(1) \nplt.subplot(121) \nsns.distplot(train['Downpayment_log']);\nplt.subplot(122) \ntrain['Downpayment_log'].plot.box(figsize=(16,5))\ntest['Downpayment_log'] = np.log(test['Downpayment'])\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now the distribution looks much closer to normal and effect of extreme values has been significantly subsided."},{"metadata":{"trusted":true},"cell_type":"code","source":"# some attributes are categorical but they are in integer so let's convert them into category\n\ntrain['branch_id'] = train['branch_id'].astype('category')\ntrain['manufacturer_id'] = train['manufacturer_id'].astype('category')\ntrain['State_ID'] = train['State_ID'].astype('category')\n\n\ntest['branch_id'] = test['branch_id'].astype('category')\ntest['manufacturer_id'] = test['manufacturer_id'].astype('category')\ntest['State_ID'] = test['State_ID'].astype('category')\n\n\nfrom sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\ntrain['branch_id'] = le.fit_transform(train['branch_id'])\ntrain['manufacturer_id'] = le.fit_transform(train['manufacturer_id'])\ntrain['State_ID'] = le.fit_transform(train['State_ID'])\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=train.drop(['supplier_id','Current_pincode_ID', 'Date.of.Birth', 'DisbursalDate', 'Employee_code_ID','PRI.DISBURSED.AMOUNT', 'disbursed_amount','PRI.NO.OF.ACCTS','SEC.NO.OF.ACCTS','SEC.SANCTIONED.AMOUNT','SEC.DISBURSED.AMOUNT','VoterID_flag','PRI.ACTIVE.ACCTS','Year_of_birth','DisbursalMonth','branch_id', 'manufacturer_id', 'State_ID'], axis=1) \ntest=test.drop(['supplier_id','Current_pincode_ID', 'Date.of.Birth', 'DisbursalDate', 'Employee_code_ID','PRI.DISBURSED.AMOUNT', 'disbursed_amount','PRI.NO.OF.ACCTS','SEC.NO.OF.ACCTS','SEC.SANCTIONED.AMOUNT','SEC.DISBURSED.AMOUNT','VoterID_flag','PRI.ACTIVE.ACCTS','branch_id', 'manufacturer_id', 'State_ID'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train.drop('loan_default',1) \ny = train.loan_default","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_cv, y_train, y_cv = train_test_split(X,y, test_size =0.3, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(x_train.shape)\nprint(y_train.shape)\nprint(x_cv.shape)\nprint(y_cv.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#calling logistic regression\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\nlogreg = LogisticRegression(class_weight='balanced')\nlogreg.fit(X, y)\nprint(logreg.coef_)\nprint(logreg.intercept_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#fitting the model with x and y attributes of train data\n#in this it is goin to learn the pattern\nlogreg.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#now applying our learnt model on test and also on train data\ny_log_pred_test = logreg.predict(x_cv)\ny_log_pred_train = logreg.predict(x_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#creating a confusion matrix to understand the classification\nconf = metrics.confusion_matrix(y_cv, y_log_pred_test)\nconf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# save confusion matrix and slice into four pieces\nconfusion = metrics.confusion_matrix(y_cv, y_log_pred_test)\nprint(confusion)\n#[row, column]\nTP = confusion[1, 1]\nTN = confusion[0, 0]\nFP = confusion[0, 1]\nFN = confusion[1, 0]\nprint (\"TP\",TP)\nprint (\"TN\",TN)\nprint(\"FN\",FN)\nprint (\"FP\",FP)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cmap = sns.cubehelix_palette(50, hue=0.05, rot=0, light=0.9, dark=0, as_cmap=True)\nsns.heatmap(conf,cmap = cmap,xticklabels=['predicted_default_NO=0','predicted_default_yes=1'],yticklabels=['actual_default_NO=0','actual_default_yes=1'],annot=True, fmt=\"d\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print the first 25 true and predicted responses\nprint('True', y_cv.values[0:15])\nprint('Pred', y_log_pred_test[0:15])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#comparing the metrics of predicted lebel and real label of test data\nprint('Accuracy_Score:', metrics.accuracy_score(y_cv, y_log_pred_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Method to calculate Classification Error\n    \n\nprint('Classification Error:',1 - metrics.accuracy_score(y_cv, y_log_pred_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Method to calculate Sensitivity\n\nprint('Sensitivity or Recall:', metrics.recall_score(y_cv, y_log_pred_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"specificity = TN / (TN + FP)\n\nprint(specificity)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_cv, y_log_pred_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print the first 10 predicted responses\n# 1D array (vector) of binary values (0, 1)\nlogreg.predict(x_cv)[0:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print the first 10 predicted probabilities of class membership\nlogreg.predict_proba(x_cv)[0:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print the first 10 predicted probabilities for class 1   ( predicting Loan_default =1)\nlogreg.predict_proba(x_cv)[0:10, 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# store the predicted probabilities for class 1\ny_pred_prob = logreg.predict_proba(x_cv)[:, 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_prob[0:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting predicion through histogram of predicted probabilities\n%matplotlib inline\nimport matplotlib.pyplot as plt\n\n# 8 bins\nplt.hist(y_pred_prob, bins=8)\n\n# x-axis limit from 0 to 1\nplt.xlim(0,1)\nplt.title('Histogram of predicted probabilities')\nplt.xlabel('Predicted probability of default')\nplt.ylabel('Frequency')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Histogram suggest that the predicted probabilities are almost normaly distributed with a tail on left side and most of the probabilities are <0.5. "},{"metadata":{},"cell_type":"markdown","source":"<b> As our default probability and threshold probability is same. So there is no change in values. \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# IMPORTANT: first argument is true values, second argument is predicted probabilities\n\n# we pass y_cv and y_pred_prob\n# we do not use y_pred, because it will give incorrect results without generating an error\n# roc_curve returns 3 objects fpr, tpr, thresholds\n# fpr: false positive rate\n# tpr: true positive rate\nfpr, tpr, thresholds = metrics.roc_curve(y_cv, y_pred_prob)\n\nplt.plot(fpr, tpr)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.rcParams['font.size'] = 12\nplt.title('ROC curve for default classifier')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\nplt.grid(True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# IMPORTANT: first argument is true values, second argument is predicted probabilities\n\nprint(metrics.roc_auc_score(y_cv, y_pred_prob))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Random FOREST"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_cv, y_train, y_cv = train_test_split(X,y, test_size =0.3,random_state =4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Handing Class im balance\nfrom imblearn.combine import SMOTETomek\nsmt = SMOTETomek(ratio='auto')\nX_smt, y_smt = smt.fit_sample(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\ncv =StratifiedKFold(n_splits=10,shuffle=True,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrf= RandomForestClassifier(max_depth = 10, n_estimators=300,verbose=1, n_jobs=1,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"forest=rf.fit(X_smt,y_smt)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(forest.score(X_smt,y_smt))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pre = forest.predict(X_smt)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pre_ = forest.predict_proba(X_smt)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = forest.predict(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_=forest.predict_proba(test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluating the Random Forest Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_confusion_rf = metrics.confusion_matrix(y_smt, pre)\ndf_confusion_rf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cmap = sns.cubehelix_palette(50, hue=0.05, rot=0, light=0.9, dark=0, as_cmap=True)\nsns.heatmap(df_confusion_rf, cmap = cmap,xticklabels=['Prediction No','Prediction Yes'],yticklabels=['Actual No','Actual Yes'], annot=True,\n            fmt='d')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_smt.shape, pre.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print the first 15 true and predicted responses\nprint('True', y_smt[0:15])\nprint('Pred', pre[0:15])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#comparing the metrics of predicted lebel and real label of test data\nprint('Accuracy_Score:', metrics.accuracy_score(y_smt, pre))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Method to calculate Sensitivity\n\nprint('Sensitivity or Recall:', metrics.recall_score(y_smt, pre))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(y_smt, pre))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn import metrics \nfpr, tpr, thresholds = metrics.roc_curve(y_smt, pre) \nauc = metrics.roc_auc_score(y_smt, pre) \nplt.figure(figsize=(12,8)) \nplt.plot(fpr,tpr,label=\"validation, auc=\"+str(auc)) \nplt.xlabel('False Positive Rate')  \nplt.ylabel('True Positive Rate') \nplt.legend(loc=4) \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_predict\npre_rf = cross_val_predict(rf, cv=cv, X=X_smt,y=y_smt, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nprint(\"auc score =\\t\" ,roc_auc_score(y_smt, pre_rf))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pre_rf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nrf.fit(X_smt,y_smt)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_out = rf.predict(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prob_out=rf.predict_proba(test)[:,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prob_out[0:10], pred_out.shape, prob_out.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv(\"../input/Submission_LTFS.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission['loan_default']=pred_out            # filling Loan_Status with predictions\nsubmission['UniqueID']=test['UniqueID'] # filling Unique_ID with test Unique_ID","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(submission, columns=['UniqueID','loan_default']).to_csv('submission_rf.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# XGBoosting"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing \nfor f in train.columns: \n    if train[f].dtype=='object': \n        lbl = preprocessing.LabelEncoder() \n        lbl.fit(list(train[f].values)) \n        train[f] = lbl.transform(list(train[f].values))\n\nfor f in test.columns: \n    if test[f].dtype=='object': \n        lbl = preprocessing.LabelEncoder() \n        lbl.fit(list(test[f].values)) \n        test[f] = lbl.transform(list(test[f].values))\n\ntrain.fillna((-999), inplace=True) \ntest.fillna((-999), inplace=True)\n\ntrain=np.array(train) \ntest=np.array(test) \ntrain = train.astype(float) \ntest = test.astype(float)\n\n ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_cv, y_train, y_cv = train_test_split(X,y, test_size =0.3,random_state =4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\nfrom xgboost import XGBClassifier\nxgb= XGBClassifier(n_estimators=120, learning_rate=1, n_jobs=-1,random_state=42)\npredict = cross_val_predict(xgb, cv=cv, X=X_smt,y=y_smt, verbose=1,method='predict_proba')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"boost=xgb.fit(X_smt,y_smt)\npred_xgb = boost.predict(X_smt)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_xg=boost.predict(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nprint(\"auc score =\\t\" ,roc_auc_score(y_smt, pred_xgb))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_xgb, pred_xgb.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nxgb= XGBClassifier(n_estimators=120, learning_rate=1, n_jobs=-1,random_state=42)\nscores = cross_val_score(xgb, cv=cv, X=X_smt,y=y_smt, verbose=1,scoring='roc_auc')\nprint(\"auc\\t=\\t\",scores.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nsubmission[\"loan_default\"] = pred_xg\nsubmission.to_csv(\"submission_xgb.csv\", index=False)\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"END"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":1}