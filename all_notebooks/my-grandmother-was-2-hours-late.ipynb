{"cells":[{"metadata":{},"cell_type":"markdown","source":"**My Grandmother Was 2 Hours Late to the Titanic**\n\n\nIn 1912, my grandmother traveled from a small town in Hungary to South Hampton, England, in hopes of beginning a new life in America. With her mother and sister in toe, they made the trek to be united with their father in The States. \n\nUpon arrival, they were dissapointed learn that their vessel of freedom had left without them, a mere two hours before. \nI can only image their relief when they learned of their good fortune to nearly miss the most famous ship distaster in history.\n\nI had always heard this story by family members, but much to my suprise, elements of this story actually exist in her obitutary. [Check it out!](https://www.findagrave.com/memorial/64694097/mary-barilich)\n\n\n\n**Introduction:**\n\nAfter learning a bit about python, I've decided to tip my toes in machine learning. I beginning with a very simple dataset to grasp the fundamentals of Data Science and attempt to answer a very interesting and person question...\n\n**Had my grandmother sailed on the Titanic, would she have survived? Would I have ever existed!??**\n\nLet see what we can do. \n\n*(Guidance on this mini-project comes from Data Science and Machine Learning with Python by Jose Portilla)*\n\n"},{"metadata":{},"cell_type":"markdown","source":"**First, lets load our data set and necessary package for analysis**"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = pd.read_csv(\"../input/titanic/test.csv\")\ndf_train = pd.read_csv('../input/titanic/train.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Exploratory Data Analysis and Cleaning:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='Survived',hue='Sex',data=df_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the graph, we can see that the majority of females surived and disporportionally to their gender. "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"sns.countplot(x='Survived',hue='Pclass',data=df_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"You better be a wealthy, classy lady though..."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"sns.distplot(df_train['Age'].dropna(),bins=30,kde=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":".info() gives us some a great overview of the data types we have in our columns and shows were data may be missing. "},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Recall, that the SibSP field denotes siblings. "},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"df_train['Fare'].hist(bins=100,figsize=(10,10))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And some paid over 500 dollars for a ticket! Did they survive?! "},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train[df_train['Fare']>500]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Indeed. "},{"metadata":{"trusted":true},"cell_type":"code","source":"#adjusting for inflation, one dollar back then is equal to $25.89/\n#lets ajust for inflation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train[df_train['Fare']>500]['Fare']*25.89","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"BALLIN!"},{"metadata":{},"cell_type":"markdown","source":"So, we noticed from .info() that we were missing a good chunk of our age data. The course that I followed suggested taking the average of age by class and imputing (filling in) those values to remove the nulls. And, there's a good portion of the cabin info missing, so we'll drop that column all together. "},{"metadata":{"trusted":true},"cell_type":"code","source":"age_means = pd.pivot_table(df_train,values = 'Age',index= 'Pclass',aggfunc='mean')\nage_means","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def impute_age(cols):\n    Age = cols[0]\n    Pclass = cols[1]\n    \n    if pd.isnull(Age):\n        \n        if Pclass ==1:\n            return 38\n        elif Pclass ==2:\n            return 30\n        else:\n            return 25\n    else:\n        return Age","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Age'] = df_train[['Age','Pclass']].apply(impute_age,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.drop('Cabin',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To run logistic regression, we'll need to turn Male and Female into 1s and 0s, along with the departure location, because there are three categories. 2 columns are used to fix this! "},{"metadata":{"trusted":true},"cell_type":"code","source":"sex = pd.get_dummies(df_train['Sex'],drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embark = pd.get_dummies(df_train['Embarked'],drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embark.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntrain = pd.concat([df_train,sex,embark],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"train.drop(['Sex','Embarked','Name','Ticket'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"train.drop(['PassengerId'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Logistic Regression:**\n\nIn this section, we'll take all of our explanatory variables and our predicted values and fit them to the logistic model. "},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train.drop('Survived',axis=1)\ny = train['Survived']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logmodel = LogisticRegression()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logmodel.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = logmodel.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here are the predictions for the test sample of our model. "},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And here is the acrruacy of the logistic model to the actual variable. "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test,predictions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"80% isn't bad. "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import precision_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(y_test,predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"precision_score(y_test,predictions)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's round and call it 80%!\n\nI was interested to find what the coefficents were for each of the X variables and the intercept. "},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(index= list(logmodel.coef_),data = list(X_train.columns))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logmodel.intercept_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Would my grandmother have survived?**\n\nLets see based on the predictions of the model. "},{"metadata":{"trusted":true},"cell_type":"code","source":"gma  = pd.read_csv(\"../input/grandmas-attributes/grandma.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From what I know from her obituary and other information from my data family, I make the following inputs:\n\n* **Class = 3** (They were quite poor)\n* **Age = 13**\n* **Siblings = One sister**\n* **Parents or Children = Her mother**\n* **Fare = 3**  This is an estimate from information obtained online. \n* **Male = 0**\n* **Departure = South Hampton**"},{"metadata":{"trusted":true},"cell_type":"code","source":"gma.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"gma_surv = logmodel.predict(gma.drop('Adj. Fare',axis=1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Does she survive!?"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(gma_surv)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Nice!**"},{"metadata":{"trusted":true},"cell_type":"code","source":"logmodel.predict_proba(gma.drop('Adj. Fare',axis=1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"But the probabilites are 59-60%. I don't know about you, but with a 40% chance of rain, I bring an umbrella. \n\nI'm not sure if the data are realistic, but this was cool first experiment to see just how likely my ancestor would be around had she been on that big boat. \n\n"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}