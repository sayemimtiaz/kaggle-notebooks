{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import normalize\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import precision_score, recall_score, f1_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, roc_curve\nfrom sklearn import preprocessing","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Get the data","metadata":{}},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filep = \"/kaggle/input/heart-disease-uci/heart.csv\"\ndf = pd.read_csv(filep)\nnp.random.seed(42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#rows and columns\nprint(df.shape)\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Description per column:\n\n    -age\n    -sex\n    -cp: chest pain type (1, 2, 3, 4)\n    -trestbps: resting blood pressure (in mm Hg on admission to the hospital)\n    -chol: serum cholestoral in mg/dl\n    -fbs: (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false)\n    -restecg: resting electrocardiographic results (0, 1, 2)\n    -thalach: maximum heart rate achieved\n    -exang: exercise induced angina (1 = yes; 0 = no)\n    -oldpeak = ST depression induced by exercise relative to rest\n    -slope: the slope of the peak exercise ST segment (1, 2, 3)\n    -ca: number of major vessels colored by flourosopy (0, 1, 2, 3)\n    -thal: 3 = normal; 6 = fixed defect; 7 = reversable defect\n    -target: diagnosis of heart disease (0: < 50% diameter narrowing, 1: > 50% diameter narrowing)\n    \nDescriptions retrieved from https://archive.ics.uci.edu/ml/datasets/heart+Disease","metadata":{}},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking for missing values\ndf.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> No missing values on the data set","metadata":{}},{"cell_type":"markdown","source":"# Data Visualization\n> A couple quick kde plots to see the relationship between \"age\" and \"chol\" to \"target","metadata":{}},{"cell_type":"code","source":"plt.rcParams['figure.dpi'] = 200\nsns.set_style('darkgrid')\nfig=plt.figure(figsize=(20,8),facecolor='white')\nax=[None for i in range(2)]\ngs=fig.add_gridspec(2,1)\ngs.update(wspace=0, hspace=0.8)\n\nax[0]=fig.add_subplot(gs[0,0])\nax[1]=fig.add_subplot(gs[1,0])\n\nsns.kdeplot(data=df[df.target==1],x='age',ax=ax[0],shade=True,alpha=1)\nsns.kdeplot(data=df[df.target==0],x='age',ax=ax[0],shade=True,alpha=0.5)\nsns.kdeplot(data=df[df.target==1],x='chol',ax=ax[1],shade=True,alpha=1)\nsns.kdeplot(data=df[df.target==0],x='chol',ax=ax[1],shade=True,alpha=0.5)\n\nfor i in range(2):\n    ax[i].set_yticklabels('')\n    ax[i].set_ylabel('')\n    ax[i].tick_params(axis='y',length=0)\n    \n    for direction in ['top','right','left']:\n        ax[i].spines[direction].set_visible(False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Countplots**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,8))\nsns.countplot(df[\"age\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,10))\n\nplt.subplot(2,3,1)\nsns.countplot(df['fbs'])\n\nplt.subplot(2,3,2)\nsns.countplot(df['exang'])\n\nplt.subplot(2,3,3)\nsns.countplot(df['slope'])\n\nplt.subplot(2,3,4)\nsns.countplot(df['ca'])\n\nplt.subplot(2,3,5)\nsns.countplot(df['thal'])\n\nplt.subplot(2,3,6)\nsns.countplot(df['target'])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Scatterplots**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(8, 4))\nsns.scatterplot(x=df[\"age\"], y=df[\"chol\"], hue=df[\"target\"])\nplt.legend()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(14, 6))\nsns.lmplot(x=\"age\", y=\"chol\", hue=\"target\", data=df,size=4, aspect=1)\nplt.legend()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Barplots**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20,10))\n\nplt.subplot(2,3,1)\nsns.barplot(x=df[\"target\"], y=df[\"fbs\"] )\n\nplt.subplot(2,3,2)\nsns.barplot(x=df[\"target\"], y=df['exang'])\n\nplt.subplot(2,3,3)\nsns.barplot(x=df[\"target\"], y=df['slope'])\n\nplt.subplot(2,3,4)\nsns.barplot(x=df[\"target\"], y=df['ca'])\n\nplt.subplot(2,3,5)\nsns.barplot(x=df[\"target\"], y=df['thal'])\n\nplt.subplot(2,3,6)\nsns.barplot(x=df[\"target\"], y=df['age'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,10))\nsns.barplot(x=\"trestbps\", y=\"chol\", data=df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Distplots**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20,15))\n\nplt.subplot(3,2,1)\nsns.distplot(df['age'])\n\nplt.subplot(3,2,2)\nsns.distplot(df['chol'])\n\nplt.subplot(3,2,3)\nsns.distplot(df['thalach'])\n\nplt.subplot(3,2,4)\nsns.distplot(df['oldpeak'])\n\nplt.subplot(3,2,5)\nsns.distplot(df['trestbps'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Pairplot**","metadata":{}},{"cell_type":"code","source":"sns.pairplot(df[['age','chol','trestbps',\"target\"]],hue=\"target\",  height=3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Heatmap**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12,8)) \nsns.heatmap(df.corr(), annot=True, cmap='gist_yarg', linewidths = 2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Getting ready for ML models","metadata":{}},{"cell_type":"code","source":"X = df.drop(\"target\",axis=1,  inplace=False)\ny = df[\"target\"].copy()\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stan_scaler = StandardScaler()\nX_train = stan_scaler.fit_transform(X_train)\nX_test = stan_scaler.transform(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ML models \n> I'm using a couple reggression , classification models and of course Kaggle's favorite model: XGB (Extreme Gradient Boost). Not using NN this time because the dataset is too small and the task seems fairly easy to handle with simpler models.","metadata":{}},{"cell_type":"code","source":"def report(model_predict, model_acc):\n    print(\"Model accuracy:\" ,model_acc*100,\"%\" )\n    print(\"\\n\", classification_report(y_test, model_predict.round()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Our vanilla Linear Regression model\nfrom sklearn.linear_model import LinearRegression\n\nlin_reg = LinearRegression()\nlin_reg.fit(X_train, y_train)\nlin_reg_predict = lin_reg.predict(X_test)\nlin_reg_acc = accuracy_score(y_test, lin_reg_predict.round())\nreport(lin_reg_predict, lin_reg_acc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\nknc = KNeighborsClassifier()\nknc.fit(X_train, y_train)\nknc_predict = knc.predict(X_test)\nknc_acc = accuracy_score(y_test, knc_predict)\nreport(knc_predict, knc_acc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nrfc = RandomForestClassifier(n_estimators=15, max_depth=5, random_state=42)\nrfc.fit(X_train, y_train)\nrfc_predict = rfc.predict(X_test)\nrfc_acc = accuracy_score(y_test, rfc_predict)\nreport(rfc_predict, rfc_acc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from xgboost import XGBClassifier\nxgb = XGBClassifier(max_depth=3, learning_rate=0.1,objective=\"binary:logistic\", n_estimators=15)\nxgb.fit(X_train, y_train)\nxgb_predict = xgb.predict(X_test)\nxgb_acc = accuracy_score(y_test, xgb_predict)\nreport(xgb_predict, xgb_acc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Linear Regression model has a accuracy score of: {x:.5f}% \\n\".format(x=(lin_reg_acc*100)))\nprint(\"KNeighbors model has a accuracy score of: {x:.5f}%\\n\".format(x=(knc_acc*100)))\nprint(\"RandomForest model has a accuracy score of: {x:.5f}%\\n\".format(x=(rfc_acc*100)))\nprint(\"Extreme Gradient Boost model has a accuracy score of: {x:.5f}%\".format(x=(xgb_acc*100)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# K nearest neighbors wins with 90% acc\n\n> I plan on revisiting this small project to polish the data visualization and models hyperparamenter.\n\n> Any feed back is appreciated!\n\n> Have a great day.","metadata":{}}]}