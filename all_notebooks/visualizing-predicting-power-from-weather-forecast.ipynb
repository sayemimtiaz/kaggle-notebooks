{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport datetime\n\nweather = pd.read_csv('../input/weather-dataset-in-antwerp-belgium/weather_in_Antwerp.csv', ';')\npower_info = pd.read_csv('../input/solarpanelspower/PV_Elec_Gas2.csv')\ndisplay(weather.head())\npower_info.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Let's clean solar power table first:**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"power_info = power_info[['Unnamed: 0','cum_power']]\npower_info = power_info.rename(columns= {'Unnamed: 0': 'date'})\npower_info.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have date column as \"object\" dtype, to transform it to pandas' datetime dtype we do: ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"power_info.date = pd.to_datetime(power_info.date)\npower_info.set_index(['date'], inplace=True)       #change the index\npower_info.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"power_info = power_info.shift(periods=-1, freq='D', axis=0)   #Correcting the measure error\n                                                        # (mentioned in Frank's data description)\n    \n#Calculating daily power, because we have the cumulative one\ntemp = power_info.shift(periods=1, freq='D', axis=0)\npower_info['day_power'] = power_info.loc[:, 'cum_power'] - temp.loc[:, 'cum_power']\npower_info.drop(['cum_power'], axis=1, inplace=True)\npower_info.day_power.iloc[0] = 5\npower_info.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nfrom matplotlib import pyplot as plt\n\nsns.set()\npower_index= power_info.reset_index()\npower_index.plot(kind='line', x='date', y='day_power', figsize=(15,5))\n\nplt.title('Daily Power Produced By Solar Panels')\nplt.ylabel('Daily Power')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **To clean weather table now:**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def clear_wind(obj):\n    if isinstance(obj, str):\n        if obj == 'No wind':\n            obj = 0\n        else:\n            obj = obj.replace(' km/h', '')\n    return obj\ndef trans_from_objects(weather):\n    weather.drop(['Unnamed: 0'], axis =1, inplace=True)\n    \n    #try statement is here for the future weather, \n    #as it is without barometer on the site\n    try:\n        weather.barometer = weather.barometer.apply(lambda x: x.replace(' mbar', '') \n                                    if isinstance(x, str) else x).astype(float)\n        weather.drop(['visibility'], axis =1, inplace=True)\n    except AttributeError:\n        pass\n    \n    weather.humidity = weather.humidity.apply(lambda x: x.replace('%', '') \n                                    if isinstance(x, str) else x).astype(float)\n    weather.temp = weather.temp.apply(lambda x: x.replace('Â°C', '') \n                                    if isinstance(x, str) else x).astype(float)\n    weather.wind = weather.wind.apply(clear_wind).astype(float)\n    \n    return weather\n\n#transfer dataframe from objects dtype to numbers\nweather_tran = trans_from_objects(weather)\nweather_tran.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weather_tran.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Form the date column \ndef create_date(weather):    \n    weather['date'] = weather.apply(lambda row:\n                                    f'{row.year}-{row.month}-{row.day} {row.clock}', axis=1)\n    weather.date = pd.to_datetime(weather.date)\n    return weather.drop(['clock', 'year', 'month', 'day'], axis = 1)\n\nweather_pretty = create_date(weather_tran)\nweather_pretty.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#to take the average of each day, so we have daily weather. Because we have the daily cum_power not hourly\ndef take_average_weather(weather, future = False):\n    if future == False:\n        average_weather = pd.DataFrame(columns = ['temp', 'weather', 'wind', 'humidity', 'barometer',\n                                              'date'])\n    else:\n        average_weather = pd.DataFrame(columns = ['temp', 'weather', 'wind', 'humidity','date'])\n    \n    temp, wind, humidity, barometer, counter= [0]*5\n    for i in range(len(weather)):\n        if future == False:\n            if (weather.loc[i, 'date'].time() ==datetime.time(0, 20)) and (i!=0):\n                average_weather = average_weather.append({\n                    'temp':temp/counter,\n                    'wind':wind/counter,\n                    'humidity':humidity/counter,\n                    'barometer':barometer/counter,\n                    'date':pd.to_datetime(weather.loc[i-1, 'date'].date()),\n                    'weather':weath\n                }, ignore_index=True)\n                temp, wind, humidity, barometer, counter= [0]*5\n\n            #Here we'll take the weather status in the most powerful hour (15:20), because you can't take averge \n                                                                                                        #here.\n            if (weather.loc[i, 'date'].time()==datetime.time(15,20)):\n                weath = weather.loc[i, 'weather']\n        else:\n            # or i==len(weather)-1 , so the last day in the data been appended\n            if ((weather.loc[i, 'date'].time() ==datetime.time(0, 0)) and (i!=0)) or (i==len(weather)-1):\n                average_weather = average_weather.append({\n                    'temp':temp/counter,\n                    'wind':wind/counter,\n                    'humidity':humidity/counter,\n                    'date':pd.to_datetime(weather.loc[i-1, 'date'].date()),\n                    'weather':weath\n                }, ignore_index=True)\n                temp, wind, humidity, barometer, counter= [0]*5\n\n            #Here we'll take the weather status in the most powerful hour (15:20),\n            #because you can't take averge with categories.\n            if (weather.loc[i, 'date'].time()==datetime.time(15,0)):\n                weath = weather.loc[i, 'weather']\n        counter += 1\n        temp += weather.loc[i, 'temp']\n        wind += weather.loc[i, 'wind']\n        humidity += weather.loc[i, 'humidity']\n        if future == False:\n            barometer += weather.loc[i, 'barometer']\n        \n    return average_weather\naverage_weather = take_average_weather(weather_pretty)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def merge_weatherANDpower():\n    dataset = average_weather.merge(power_info, on=['date'])\n    return dataset.set_index('date')\nfinal_dataset = merge_weatherANDpower()\nfinal_dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nweather_counts = final_dataset.weather.value_counts()\nplt.figure(figsize=(16,5))\nsns.barplot(weather_counts.index, weather_counts.values, alpha=0.8)\nplt.xticks(rotation=90)\nplt.title('Weather Status')\nplt.xlabel('Status')\nplt.ylabel('Number Of Repetition')\nplt.show() # WHAT THE HECK! Let's reduce this amount of redundant information","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#I need this, so I can deal with \"loc\"\nfinal_dataset = final_dataset.reset_index()\n\ndef reduce_categories(weather):\n    #Delete all first parts of two-part status, and highligh only the necessary categories. \n    #why the first part? Because we don't care about the raining or snowing weather, we care more about \n    #status of clouds\n    for i in range(len(weather)):\n        weather_list = weather.loc[i, 'weather'].split('.')\n        if len(weather_list) > 2:\n            weather.loc[i,'weather'] = weather_list[1].strip()\n        elif len(weather_list) ==2:\n            weather.loc[i, 'weather'] = weather_list[0].strip()\n\n    weather.weather = weather.weather.map({\n        'Ice fog':'Fog',\n        'Haze':'Fog',\n        'Fog':'Fog',\n        'Clear':'Sunny',\n        'Sunny':'Sunny',\n        'Broken clouds':'Scattered clouds',\n        'Scattered clouds':'Scattered clouds',\n        'Overcast':'Cloudy',\n        'More clouds than sun':'Cloudy',\n        'More sun than clouds':'Sunny',\n        'Low clouds':'Cloudy',\n        'Mostly cloudy':'Cloudy',\n        'Cloudy':'Cloudy',\n        'Passing clouds':'Passing clouds',\n        'Partly sunny':'Partly sunny',\n        'Mostly sunny':'Sunny'\n    },na_action='ignore')\n    return weather\nfinal_dataset = reduce_categories(final_dataset)\n\n#get the index back to \"date\"\nfinal_dataset.set_index('date', inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib import pyplot as plt\nfinal_dataset.weather.value_counts()\nweather_counts = final_dataset.weather.value_counts()\n\nplt.figure(figsize=(12,6))\nsns.barplot(weather_counts.index, weather_counts.values, alpha=0.8)\nplt.xticks(rotation=33)\nplt.title('Weather Status')\nplt.xlabel('Status')\nplt.ylabel('Number Of Repetition')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_dataset.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_dataset.hist(figsize=(16,12))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training The Machine Learning Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split \ntrain_set, test_set = train_test_split(final_dataset, test_size=0.2, \n                                                   random_state=42) \ndf = train_set.copy() \ndf.describe() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.corr() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pandas.plotting import scatter_matrix \nscatter_matrix(df, figsize=(16,18), alpha=0.4) \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.plot(kind='scatter', x= 'humidity',y='day_power', figsize=(9,7), alpha=0.4) \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#To delete data anomalies\nimport random\ndf.day_power = df.day_power.apply(lambda x: x+random.randint(0,50)/100 if x==0 else x)\nfor i in range(1,34):\n    df.day_power = df.day_power.apply(lambda x: x+random.randint(-50,50)/100 if x==i else x)\ndf.plot(kind='scatter', x= 'humidity',y='day_power', figsize=(9,7), alpha=0.4) \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#As we have data (which we want to predict), without barometer column\nfeatures = df.drop(['day_power', 'barometer'], axis=1) \ncolumns=features.columns \nlabels = df['day_power'].copy() \nfeatures.head() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_attr = list(features.drop(['weather'],axis=1)) \ncat_attr = ['weather'] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import Pipeline \nfrom sklearn.compose import ColumnTransformer \nfrom sklearn.preprocessing import OneHotEncoder \nfrom sklearn.impute import SimpleImputer \nfrom sklearn.preprocessing import MinMaxScaler \n\n\nnum_pipeline = Pipeline([ \n    ('imputer', SimpleImputer(strategy='median')), \n    ('scaler', MinMaxScaler()) \n]) \n\ncat_pipeline = Pipeline([ \n    ('encoder', OneHotEncoder()) \n]) \n\nfull_pipeline = ColumnTransformer([ \n    ('num_pipeline', num_pipeline, num_attr),\n    ('cat_pipeline', cat_pipeline, cat_attr) \n]) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prepared_features = full_pipeline.fit_transform(features) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \n\nfrom sklearn.linear_model import LinearRegression \nfrom sklearn.metrics import mean_squared_error as mse \nfrom sklearn.model_selection import cross_val_score  \n\nlin_reg = LinearRegression() \nlin_reg.fit(prepared_features, labels) \ny_predicted = lin_reg.predict(prepared_features) \nscores = cross_val_score(lin_reg, prepared_features, labels, \n                         scoring='neg_mean_squared_error', cv=10) \nscores=np.sqrt(-scores) \ndisplay(scores.mean()) \nscores.std() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = test_set.copy()\ntest_features = test.drop(['day_power', 'barometer'], axis=1) \ntest_labels = test['day_power'].copy() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prepared_test = full_pipeline.transform(test_features) \ntest_predicted = lin_reg.predict(prepared_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = cross_val_score(lin_reg, prepared_test, test_labels, \n                         scoring='neg_mean_squared_error', cv=10) \nscores=np.sqrt(-scores) \ndisplay(scores.mean()) \nscores.std() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Visualizing the difference between predicted and real values of day power for the test set\n\navg=[]\nlabels_avg = []\nfor i in range(len(test_labels)):\n    avg.append(test_labels[i])\n    if i % 40 == 0:\n        labels_avg.append(np.array(avg).mean())\n        avg.clear()\navg=[]\npred_avg = []\nfor i in range(len(test_predicted)):\n    avg.append(test_predicted[i])\n    if i % 40 == 0:\n        pred_avg.append(np.array(avg).mean())\n        avg.clear()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,6))\nplt.plot(range(len(labels_avg)), labels_avg)\nplt.plot(range(len(pred_avg)), pred_avg, 'r')\nplt.title('Comparison between average predicted values and real ones in the test set')\nplt.ylabel('Day Power')\nplt.xlabel('Average Of Test Samples')\nplt.legend(['Real Power', 'Predicted Power'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weather_future= pd.read_csv('../input/weather-dataset-in-antwerp-belgium/weather_in_Antwerp_future2.csv', ';')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_future_data(data):\n    tran_fut = trans_from_objects(data)\n    tran_fut = create_date(tran_fut)\n    avg_fut = take_average_weather(tran_fut, future=True)\n    red_fut = reduce_categories(avg_fut)\n    red_fut = red_fut.set_index('date')\n    prepared_future = full_pipeline.transform(red_fut)\n    return red_fut.index, lin_reg.predict(prepared_future)\n\ndate, predicted_data = predict_future_data(weather_future)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,6))\nplt.plot(date,predicted_data)\nplt.title('Next Days Prediction')\nplt.ylabel('Day Power')\nplt.xlabel('Date')\nplt.rcParams['xtick.labelsize']=14\nplt.rcParams['ytick.labelsize']=14\nplt.xticks(rotation=15)\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}