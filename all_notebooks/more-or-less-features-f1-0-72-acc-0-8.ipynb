{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h1 style=\"color:blue\">Purpose:</h1>\n\nWhen i was younger i used to be a First aid teacher. So i found a real interest in the study of this data set for my road to next rank in kaggle. \n\n<li>As an introduction i will give some information about Symptoms and what to do because action can save lifes</li>\n<li>Look at the data </li>\n<li>train 2 models</li>\n\n<p>I want to compare two approachs. One with a blackbox model and an other one with knowledge from my eda. </p>\n<p style=\"color:red\">Considere giving an upvote if you enjoy my work </p>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<h1 style=\"color:blue\">Knowledge:</h1>\n\n\nHeart failure, sometimes known as congestive heart failure, occurs when your heart muscle doesn't pump blood as well as it should. Certain conditions, such as narrowed arteries in your heart (coronary artery disease) or high blood pressure, gradually leave your heart too weak or stiff to fill and pump efficiently.\n\nNot all conditions that lead to heart failure can be reversed, but treatments can improve the signs and symptoms of heart failure and help you live longer. Lifestyle changes — such as exercising, reducing sodium in your diet, managing stress and losing weight — can improve your quality of life.\n\nOne way to prevent heart failure is to prevent and control conditions that cause heart failure, such as coronary artery disease, high blood pressure, diabetes or obesity.\n\n\n<h2 style=\"color:green\">Symptoms:</h2>\n\n\n\nHeart failure signs and symptoms may include:\n\n<li>Shortness of breath (dyspnea) when you exert yourself or when you lie down</li>\n<li>Fatigue and weakness</li>\n<li>Swelling (edema) in your legs, ankles and feet</li>\n<li>Rapid or irregular heartbeat</li>\n<li>Reduced ability to exercise</li>\n<li>Persistent cough or wheezing with white or pink blood-tinged phlegm</li>\n<li>Increased need to urinate at night</li>\n<li>Swelling of your abdomen (ascites)</li>\n<li>Very rapid weight gain from fluid retention</li>\n<li>Lack of appetite and nausea</li>\n<li>Difficulty concentrating or decreased alertness</li>\n<li>Sudden, severe shortness of breath and coughing up pink, foamy mucus</li>\n<li>Chest pain if your heart failure is caused by a heart attack</li>\n<p></p>\n\n\n<h2 style=\"color:green\">What to do:</h2>\n\n<li>Not smoking</li>\n<li>Controlling certain conditions, such as high blood pressure and diabetes</li>\n<li>Staying physically active</li>\n<li>Eating healthy foods</li>\n<li>Maintaining a healthy weight</li>\n<li>Reducing and managing stress</li>\n","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 style=\"color:blue\">Data analysis:</h1>","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/heart-failure-clinical-data/heart_failure_clinical_records_dataset.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pywaffle","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import f1_score\nfrom pywaffle import Waffle","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set_style('whitegrid')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def print_waffle(column):\n\n    equilibre=df[column].value_counts()\n    data = equilibre\n    fig = plt.figure(\n        FigureClass=Waffle, \n        title={'label': column},\n        rows=8, \n        values=data, \n        colors=(\"#232066\", \"#983D3D\"),\n        # legend={'loc': 'upper left', 'bbox_to_anchor': (1, 1)},\n        icons='child', icon_size=10, \n        icon_legend=True,\n        labels=[\"{0}({1})\".format(k,v) for k, v in data.items()],\n        legend={'loc':'lower left','bbox_to_anchor':(0,-0.4),'ncol':len(data),'framealpha':0}\n    )\n    fig.gca().set_facecolor('#EEEEEE')\n    fig.set_facecolor('#EEEEEE')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2 style=\"color:green\">Population analysis:</h2>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print_waffle('DEATH_EVENT')      \nprint_waffle('diabetes')\nprint_waffle('smoking')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For this graph i use pywaffle library. Easy to use and nice visual. What i underlign :\n<li> Death event is 1/3 of the population</li>\n<li> We have the same number of death and smoker (will investigate that later)</li>\n<li> Hight proportion of diabetic </li>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def double_histo_binary(df,column):\n\n    toprint_1=df['DEATH_EVENT'].loc[df[column]==0].value_counts()\n    toprint_2=df['DEATH_EVENT'].loc[df[column]==1].value_counts()\n    df_tempo=pd.DataFrame({'Not_'+column:toprint_1,column:toprint_2})\n    ax=plt.subplot(211)\n    df_tempo.plot.bar(title=column+' vs non-'+column +' in absolute value',colormap='Accent',ax=ax)\n    ax.set(xlabel='Death_event',ylabel='Count')\n    total_Notsmoker=df_tempo['Not_'+column].sum()\n    total_smoker=df_tempo[column].sum()\n    df_tempo1=pd.DataFrame({'Not_'+column:(df_tempo['Not_'+column].values*100)/total_Notsmoker,column:(df_tempo[column].values*100)/total_smoker})\n    ax=plt.subplot(212)\n    df_tempo1.plot.bar(title=column+' vs non-'+column +' in %',colormap='Accent',ax=ax)\n    ax.set(xlabel='Death_event',ylabel='%')\n    \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2 style=\"color:green\">Binary variable:</h2>\n\n<p></p>\n<p>I want to check if the proportion of death event change for smoker or non smoker for instance.In this steps i will use two graphs: One in absolute value and the other one in %.</p>\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"double_histo_binary(df,'smoking')\ndouble_histo_binary(df,'anaemia')\ndouble_histo_binary(df,'diabetes')\ndouble_histo_binary(df,'sex')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Only one really notable variable : anaemia. Seems that if you're in anemia the proportion or death event change. For the other variable i don't see any impact. For my second model i will delete the sex diabete and smoker to see if i have the same accuracy.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<h2 style=\"color:green\">Binary variable:</h2>\n<p> here i will compare distribution of variable compared to death event. To achieve my comparaison i will only use histograms.  </p>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_histogram(column):\n    df_death=df.loc[df['DEATH_EVENT']==1]\n    df_nodeath=df.loc[df['DEATH_EVENT']==0]\n    sns.kdeplot(df_death[column],shade=True,color='red',label='Death_event=1')\n    sns.kdeplot(df_nodeath[column],shade=True,color='blue',label='Death_event=0')\n    plt.title(column+' distribution by class')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_histogram('serum_creatinine')\nplot_histogram('serum_sodium')\nplot_histogram('ejection_fraction')\nplot_histogram('platelets')\nplot_histogram('high_blood_pressure')\nplot_histogram('age')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I will keep four features from here : age,ejection_fraction,serum_sodium and serum_creatrine. In the two others distribution it seems similar and will be difficult use them to separate classes.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(df.corr(),linewidths=2,linecolor='black',cmap='viridis')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 style=\"color:blue\">Prepare data:</h1>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"columns_goodplace=['age','anaemia','creatinine_phosphokinase','ejection_fraction','serum_creatinine','serum_sodium','time',\n                   'smoking','diabetes','sex','platelets','high_blood_pressure']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=df['DEATH_EVENT'].values\ny=to_categorical(y)\ndf.drop(['DEATH_EVENT'],1,inplace=True)\ndf=df[columns_goodplace]\nX=df.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler=StandardScaler()\nss=scaler.fit(X)\nX=scaler.transform(X)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.40, random_state=91)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 style=\"color:blue\">Create models:</h1>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"in this part i will train two models. One in black box with all the features and an other one with only the variable i decide to keep from data analysis. I will optise the two by a simple brut force of the parameters. I will compare results and will conclude which one is better. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n        \n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n    plt.ylim(top=-0.5,bottom=1+0.5)\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.show()\n\ndef evaluate_model(history,predicted_classes,y_test,model):\n    \n#    history.history['acc'][0]=0\n#    history.history['val_acc'][0]=0\n    print(history)\n    fig1, ax_acc = plt.subplots()\n    plt.plot(history.history['accuracy'])\n    plt.plot(history.history['val_accuracy'])\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.title('Model - Accuracy')\n    plt.legend(['Training', 'Validation'], loc='lower right')\n    plt.show()\n#    \n#    history.history['loss'][0]=0.5\n#    history.history['val_loss'][0]=0.5\n    fig2, ax_loss = plt.subplots()\n    plt.xlabel('Epoch')\n    plt.ylabel('loss')\n    plt.title('Model- loss')\n    plt.legend(['Training', 'Validation'], loc='upper right')\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.show()\n    target_names=['0','1']\n    \n    prediction=predicted_classes\n    cnf_matrix = confusion_matrix(y_test, prediction)\n    report=classification_report(y_test, prediction, target_names=target_names)\n    print(cnf_matrix)\n    print(report)\n    np.set_printoptions(precision=2)\n    plt.figure(figsize=(5, 5))\n    plot_confusion_matrix(cnf_matrix, classes=['0', '1'],normalize=True,\n                      title='Confusion matrix, with normalization')\n    plt.show()\n    plt.figure(figsize=(5, 5))\n    plot_confusion_matrix(cnf_matrix, classes=['0', '1'],normalize=False,\n                      title='Confusion matrix, with normalization')\n\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model(Nbr_layer,nbr_per_layer,dropout,batch_size,class_0_weight,class_1_weight,X_train,y_train,X_test,y_test):\n    model = Sequential()\n    for i in range(Nbr_layer):\n        model.add(Dense(nbr_per_layer, activation='relu'))\n    model.add(Dropout(dropout))   \n    model.add(Dense(2, activation='softmax'))\n    model.compile(optimizer=\"Adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n    \n    callbacks = [EarlyStopping(monitor='val_loss', patience=5),\n             ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]\n    class_weight = {0: class_0_weight,\n                    1: class_1_weight}\n    \n    history=model.fit(X_train,y_train,epochs=50,batch_size=batch_size,validation_data=(X_test,y_test),callbacks=callbacks,class_weight=class_weight)\n    model.load_weights('best_model.h5')\n    \n    \n    pred=model.predict(X_test)\n    predicted_classes=np.argmax(pred,axis=1)\n    y_true=np.argmax(y_test,axis=1)\n    # evaluate_model(history,predicted_classes,y_true,model)\n    score=f1_score(y_true,predicted_classes)\n    return(model,score,history)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"layer=[1,2,3]\nnumber_per_layer=[10,20,30,40,60,80]\ndropout=[0.1,0.2,0.3,0.4]\nbatch_size=[8,16,32]\nclass_0_weight=[1]\nclass_1_weight=[1]\n\nscore=0\nbest_model=0\nbest_param=[0,0,0,0]\nbest_history=0\n\nscore_lessdata=0\nbest_model_lessdata=0\nbest_param_lessdata=[0,0,0,0]\nbest_history_lessdata=0","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"for element in layer:\n    for element1 in number_per_layer:\n        for element2 in dropout:\n            for element3 in batch_size:\n                    for element4 in class_0_weight:\n                        for element5 in class_1_weight:\n                            print('+++++++++++++++++++++New_train+++++++++++++++++++')\n                            print([element,element1,element2,element3,element4,element5])\n                            model,score1,history=create_model(element,element1,element2,element3,element4,element5,X_train,y_train,X_test,y_test)\n                            if score1>score:\n                                score=score1\n                                best_model=model\n                                best_param=[element,element1,element2,element3,element4,element5]\n                                best_history=history\n                            model_lessdata,score_lessdata1,history_lessdata=create_model(element,element1,element2,element3,element4,element5,X_train[:,:7],y_train,X_test[:,:7],y_test)\n                            if score_lessdata1>score_lessdata:\n                                score_lessdata=score_lessdata1\n                                best_model_lessdata=model_lessdata\n                                best_param_lessdata=[element,element1,element2,element3,element4,element5]\n                                best_history_lessdata=history_lessdata\n                                                                        \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2 style=\"color:green\">Black box </h2>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pred=best_model.predict(X_test)\npredicted_classes=np.argmax(pred,axis=1)\ny_true=np.argmax(y_test,axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\naccuracy_score(y_true,predicted_classes)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import f1_score\nf1_score(y_true,predicted_classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluate_model(best_history,predicted_classes,y_true,model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2 style=\"color:green\">With knowledge </h2> ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pred1=best_model_lessdata.predict(X_test[:,:7])\npredicted_classes1=np.argmax(pred1,axis=1)\ny_true=np.argmax(y_test,axis=1)\nevaluate_model(best_history_lessdata,predicted_classes1,y_true,best_model_lessdata)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(y_true,predicted_classes1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f1_score(y_true,predicted_classes1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 style=\"color:blue\">Conclusion:</h1>\n\n<p>Model with less data seems to have the same perfomance so we have a gain in computer time.It's seems usefull (sometimes depend of training he is better)</p>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<h1 style=\"color:blue\">Ethik</h1>\n\n<p>thik is a python library for model knoledge. It help to understand as SHAP what is the importance of a variable in a model. I will use this library on my model with more variable to see if i select the correct one in my second model.</p>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install ethik","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import ethik","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"explainer = ethik.ClassificationExplainer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test1=pd.DataFrame(X_test,columns=columns_goodplace)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"explainer.plot_influence_ranking(\n    X_test=X_test1,\n    y_pred=predicted_classes,\n    n_features=5,\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We keep this column in our other model. It's an other proof that our choice was relevant.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"explainer.plot_influence(\n    X_test=X_test1[\"ejection_fraction\"],\n    y_pred=predicted_classes,\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"explainer.plot_influence(\n    X_test=X_test1[\"age\"],\n    y_pred=predicted_classes,\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bob=X_test1.iloc[1]\nMary=X_test1.iloc[4]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"explainer.plot_influence_comparison(\n    X_test=X_test1,\n    y_pred=predicted_classes,\n    reference=bob,\n    compared=Mary,\n)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"How to analyze this graph ? \n<p>Here, we can see that , on average, people of Mary's age are 10 % more likely to have Heart failure.Luckily people with the serum_creatine of mary 17 % chance to avoid heart failure compare to bob </p>\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred=pd.DataFrame(pred,columns=[0,1])\nexplainer.plot_influence(\n    X_test=X_test1[\"anaemia\"],\n    y_pred=y_pred[[0, 1]]\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred=pd.DataFrame(pred,columns=[0,1])\nexplainer.plot_influence(\n    X_test=X_test1[\"high_blood_pressure\"],\n    y_pred=y_pred[[0, 1]]\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I will continue this notebook later...","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}