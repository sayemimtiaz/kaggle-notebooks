{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport re\nimport string\nimport nltk\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom nltk import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nfrom nltk.tokenize import TweetTokenizer\n\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\nnltk.download('punkt')\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/reddit-wallstreetsbets-posts/reddit_wsb.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"title_data = data[['title','timestamp']].copy()\n\ntitle_data = title_data.dropna()\n\n#Lower-case all post\ntitle_data.title = title_data.title.str.lower()\n\n#Remove handlers\ntitle_data.title = title_data.title.apply(lambda x:re.sub('@[^\\s]+','',x))\n\n# Remove URLS\ntitle_data.title = title_data.title.apply(lambda x:re.sub(r\"http\\S+\", \"\", x))\n\n# Remove all the special characters\ntitle_data.title = title_data.title.apply(lambda x:' '.join(re.findall(r'\\w+', x)))\n\n#remove all single characters\ntitle_data.title = title_data.title.apply(lambda x:re.sub(r'\\s+[a-zA-Z]\\s+', '', x))\n\n# Substituting multiple spaces with single space\ntitle_data.title = title_data.title.apply(lambda x:re.sub(r'\\s+', ' ', x, flags=re.I))\n\n#Remove Time From Timestamp\ntitle_data.timestamp = pd.to_datetime(title_data.timestamp).dt.date","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sid = SIA()\n\ntitle_data['sentiments']           = title_data['title'].apply(lambda x: sid.polarity_scores(' '.join(re.findall(r'\\w+',x.lower()))))\ntitle_data['Positive Sentiment']   = title_data['sentiments'].apply(lambda x: x['pos']+1*(10**-6)) \ntitle_data['Neutral Sentiment']    = title_data['sentiments'].apply(lambda x: x['neu']+1*(10**-6))\ntitle_data['Negative Sentiment']   = title_data['sentiments'].apply(lambda x: x['neg']+1*(10**-6))\n\ntitle_data.drop(columns=['sentiments'],inplace=True)\ntitle_data.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating class from sentiment values\ntitle_data['class_name'] = title_data[['Positive Sentiment', 'Neutral Sentiment', 'Negative Sentiment']].idxmax(axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# removing neutral class from reducing bias\ndata = title_data[title_data['class_name'] != 'Neutral Sentiment']\ndata.reset_index(drop=True, inplace=True)\ndata.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# total number of positive and negative sentiments\nl = len(data[data['class_name'] == 'Negative Sentiment'])\nprint(f\"There are {l} negative sentences\")\n\nm = len(data[data['class_name'] == 'Positive Sentiment'])\nprint(f\"There are {m} positive sentences\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# replacing negative and positive sentiment in class with '0' and '1'\ndata['class_name'][data['class_name'] == 'Negative Sentiment'] = 0\ndata['class_name'][data['class_name'] == 'Positive Sentiment'] = 1\n\ndata.rename(columns={'class_name':'class'}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting Positive and Negative Sentiments\nX = data[['Positive Sentiment', 'Negative Sentiment']].values\nY = data['class'].values;\n\nfig, ax = plt.subplots(figsize = (8, 8))\n\ncolors = ['red' , 'green']\n\n# Color based on the sentiment Y\nax.scatter(X[:,0], X[:,1], c=[colors[int(k)] for k in Y], s=0.1)\nplt.xlabel(\"Positive\")\nplt.ylabel(\"Negative\")\n\n# Graph shows that the positive and negative sentiments are majorly separated so theaccuracy should be high","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data[['title','class']].copy()\ndata.head()\n\n# data ready ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating training and testing data\nsplit_ratio = int(len(data) * 0.8)\ntrain_x = data['title'][:split_ratio]\ntest_x = data['title'][split_ratio:]\ntrain_y = data['class'][:split_ratio]\ntest_y = data['class'][split_ratio:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_y = np.asarray(train_y, dtype='int32')\ntest_y = np.asarray(test_y, dtype='int32')\n\ntrain_y = train_y.reshape(-1, 1)\ntest_y = test_y.reshape(-1,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# removing stopwords and stemming for better accuracy\ndef preprocess(sentence):\n    \n    sentence = sentence.lower()\n    stemmer = PorterStemmer()\n    \n    tokenized = word_tokenize(sentence)\n    cleaned_list = []\n    \n    stopwords_english = stopwords.words('english')\n    \n    for word in tokenized:\n        if (word not in stopwords_english and word not in string.punctuation):\n            stem_word = stemmer.stem(word)  \n            cleaned_list.append(stem_word)\n            \n    return cleaned_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_freqs(sentences, ys):\n\n    yslist = np.squeeze(ys).tolist()\n\n    freqs = {}\n    for y, sentence in zip(yslist, sentences):\n        for word in preprocess(sentence):\n            pair = (word, y)\n            if pair in freqs:\n                freqs[pair] += 1\n            else:\n                freqs[pair] = 1\n\n    return freqs\n\nfreqs = build_freqs(train_x, train_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def sigmoid(z): \n    return (1 / (1 + np.exp(-z)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def gradientDescent(x, y, theta, alpha, num_iters):\n\n    m = len(x)\n    \n    for i in range(0, num_iters):\n        z = np.dot(x, theta)\n        h = sigmoid(z)\n        \n        J = (-1/m) * (np.dot((y.T), np.log(h)) + np.dot((1 - y).T, np.log(1 - h))) \n        \n        theta = theta - (alpha/m) * np.dot(x.T, (h - y))\n        \n        if i % (num_iters) == 0:\n            print(i, J)\n    \n    J = float(J)\n    \n    return J, theta","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def extract_features(sentence, freqs):\n\n    word_l = preprocess(sentence)\n    x = np.zeros((1, 3)) \n    \n    x[0,0] = 1 \n    \n    for word in word_l:            \n        x[0,1] += freqs[(word, 1)] if (word, 1) in freqs else 0\n        \n        x[0,2] += freqs[(word, 0)] if (word, 0.0) in freqs else 0 \n\n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = np.zeros((len(train_x), 3))\nfor i in range(len(train_x)):\n    X[i, :]= extract_features(train_x[i], freqs)\n\nY = train_y\n\nJ, theta = gradientDescent(X, Y, np.zeros((3, 1)), 1e-5, 15000)\n\nprint(f\"The cost after training is {J:.8f}.\")\n\nprint(f\"The resulting vector of weights is {[round(t, 8) for t in np.squeeze(theta)]}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict(sentence, freqs, theta):\n\n    x = extract_features(sentence, freqs)\n\n    y_pred = sigmoid(np.dot(x, theta))\n    \n    return y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for text in ['I am happy', 'very bad', 'this movie should have been great.', 'great', 'great great', 'great great great', 'great great great great']:\n    print( '%s -> %f' % (text, predict(text, freqs, theta)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def test_logistic_regression(test_x, test_y, freqs, theta):\n\n    y_hat = []\n    \n    for sentence in test_x:\n        y_pred = predict(sentence, freqs, theta)\n        \n        if y_pred > 0.5:\n            y_hat.append(1.0)\n        else:\n            y_hat.append(0.0)\n\n    accuracy = (np.array((y_hat)) == np.squeeze(test_y)).mean()\n\n    return accuracy\n\ntmp_accuracy = test_logistic_regression(test_x, test_y, freqs, theta)\nprint(f\"Logistic regression model's accuracy = {tmp_accuracy:.4f}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text = 'Gamestop is high'\nprint(preprocess(text))\ny_hat = predict(text, freqs, theta)\nprint(y_hat)\nif y_hat > 0.5:\n    print('Positive sentiment')\nelse: \n    print('Negative sentiment')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}