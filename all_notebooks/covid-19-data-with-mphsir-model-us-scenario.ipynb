{"cells":[{"metadata":{"_uuid":"645a811e-a5e6-4126-bdb6-fe0bd1e81f02","_cell_guid":"af437f40-7f19-4668-b92a-28ab5f5e6c5f","trusted":true},"cell_type":"markdown","source":"# Introduction\nUsing a mathematical epidemic model, this notebook will predict the number of cases infected with COVID-19 in US.\nData from (Novel Corona Virus 2019, 2019-nCOV, SARS-COV-2 virus caused disease). \nThe goal of this notebook is to compare Metapopulation models vs traditional epidemic models.\n\n * [Preparation (load data, preprocesing](https://www.kaggle.com/prbocca/covid-19-data-with-mphsir-model-us-scenario#Preparation)\n * [Trend analysis](https://www.kaggle.com/prbocca/covid-19-data-with-mphsir-model-us-scenario#Trend-analysis)\n * [Traditional Epidemic Models: SIR, SIR-D, SIR-F, SEWIR-F](https://www.kaggle.com/prbocca/covid-19-data-with-mphsir-model-us-scenario#Traditional-Epidemic-Models)\n * [First MetaPopulation model: MPHSIR](https://www.kaggle.com/prbocca/covid-19-data-with-mphsir-model-us-scenario#MetaPopulation-Epidemic-Models)\n * [Conclusion: Models comparision](https://www.kaggle.com/prbocca/covid-19-data-with-mphsir-model-us-scenario#Conclusion:-Models-comparision)\n\nNote: This notebook was created to work with added precision mobility data. For example, with mobility data obtained from applications or mobile operators. For confidentiality reasons, outdated public mobility information from the [Bureau of Transportation Statistics](https://www.transtats.bts.gov/DatabaseInfo.asp?DB_ID=111) is used here.\n\nNote:  \n\"Infected\" means the currently infected and confirmed cases.  \nThis can be calculated  as \"Confirmed\" - \"Deaths\" - \"Recovered\""},{"metadata":{"_uuid":"4a1c505a-af19-4114-9013-4d0cd725fc6e","_cell_guid":"0c5341ac-2f8d-46bb-8749-fa8804155603","trusted":true},"cell_type":"code","source":"# n_trials: main optimization parameter for all models\n#n_trials=10 #debug\nn_trials=500 #production\n\nfrom datetime import datetime\ntime_format = \"%d%b%Y %H:%M\"\ndatetime.now().strftime(time_format)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Major update\n * 11Apr2020: First version following the work done by [@lisphilar](https://www.kaggle.com/lisphilar) in [covid-19-data-with-sir-model](https://www.kaggle.com/lisphilar/covid-19-data-with-sir-model)\n"},{"metadata":{},"cell_type":"markdown","source":"## Acknowledgement\n### Datasets in kaggle\n* The number of cases: [Novel Corona Virus 2019 Dataset](https://www.kaggle.com/sudalairajkumar/novel-corona-virus-2019-dataset)\n* Total population: [covid19-global-forecasting-locations-population](https://www.kaggle.com/dgrechka/covid19-global-forecasting-locations-population/metadata)\n\n### External resources\n* Population pyramid: [PopulationPyramid.net](https://www.populationpyramid.net/) licenced under [Creative Commons license CC BY 3.0](https://creativecommons.org/licenses/by/3.0/igo/)\n\n\n### References\n* Simple SIR model: [The SIR epidemic model](https://scipython.com/book/chapter-8-scipy/additional-examples/the-sir-epidemic-model/)\n* SEIR model: [Introduction to SEIR model Models](http://indico.ictp.it/event/7960/session/3/contribution/19/material/slides/)\n* Basic reproduction number: [Van den Driessche, P., & Watmough, J. (2002).](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6002118/)\n* Basic reproduction number: [Infection Modeling — Part 1: Estimating the Impact of a Pathogen via Monte Carlo Simulation](https://towardsdatascience.com/infection-modeling-part-1-87e74645568a)\n* Growth Factor: [Exponential growth and epidemics](https://www.youtube.com/watch?v=Kas0tIxDvrg)\n* Physical distancing (social distancing): [YouTube: Simulating an epidemic](https://www.youtube.com/watch?v=gxAaO2rsdIs)"},{"metadata":{"_uuid":"e8837623-1d76-40e3-8710-af80d55cfc9c","_cell_guid":"3779540e-8e00-4811-a789-6107b0d51e0c","trusted":true},"cell_type":"markdown","source":"# Preparation"},{"metadata":{},"cell_type":"markdown","source":"## Package"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"from collections import defaultdict\nfrom datetime import timedelta\nfrom dateutil.relativedelta import relativedelta\nimport math\nimport os\nfrom pprint import pprint\nimport warnings\nfrom fbprophet import Prophet\nfrom fbprophet.plot import add_changepoints_to_plot\nimport pystan.misc # in model.fit(): AttributeError: module 'pystan' has no attribute 'misc'\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nimport matplotlib\nfrom matplotlib.ticker import ScalarFormatter\n%matplotlib inline\nimport numpy as np\nimport optuna\noptuna.logging.disable_default_handler()\nimport pandas as pd\nimport dask.dataframe as dd\npd.plotting.register_matplotlib_converters()\nimport seaborn as sns\nfrom scipy.integrate import solve_ivp\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.cluster import KMeans\n\nimport pickle\n\nfrom IPython.display import display  #mostrar varios dataframe por cell\n\nfrom IPython.display import Markdown, display      #mostrar texto enriquecido\ndef printmd(string):\n    display(Markdown(string))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Local Functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"### Upload code as a data\n# + add data\n# create a dataset \"localsrc\", drag and drop .py files\n\nfrom shutil import copyfile\n\n#copy our file into the working directory (make sure it has .py suffix)\ncopyfile(src = \"../input/localsrc/d01_utils_common.py\", dst = \"../working/d01_utils_common.py\")\ncopyfile(src = \"../input/localsrc/d03_models_epidemic_models.py\", dst = \"../working/d03_models_epidemic_models.py\")\ncopyfile(src = \"../input/localsrc/d03_models_mp_epidemic_models.py\", dst = \"../working/d03_models_mp_epidemic_models.py\")\n\n\n#import all our functions\n#from my_functions import *\nfrom d01_utils_common import *\n# Plotting\n# Trend analysis\n# Dataset arrangement\n\nfrom d03_models_epidemic_models import *\n# Numerical simulation. We will perform numerical analysis to solve the ODE using scipy.integrate.solve_ivp function.\n# Parameter Estimation using Optuna\n# Description of math model: SIR, SIR-D, SIR-F, SEWIR-F, SIR-FV models\n# Prediction of the data using some models\n\nfrom d03_models_mp_epidemic_models import *\n# Numerical simulation. We will perform numerical analysis to solve the ODE using scipy.integrate.solve_ivp function.\n# Parameter Estimation using Optuna\n# Description of math model: MPHSIR, ... models\n# Prediction of the data using some models\n\n","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Ramdam\nnp.random.seed(2019)\nos.environ[\"PYTHONHASHSEED\"] = \"2019\"\n# Matplotlib\nplt.style.use(\"seaborn-ticks\")\nplt.rcParams[\"xtick.direction\"] = \"in\"\nplt.rcParams[\"ytick.direction\"] = \"in\"\nplt.rcParams[\"font.size\"] = 11.0\nplt.rcParams[\"figure.figsize\"] = (9, 6)\n# Pandas\npd.set_option(\"display.max_colwidth\", 1000)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## List of dataset"},{"metadata":{"trusted":true,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"for dirname, _, filenames in os.walk(\"/kaggle/input\"):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Total population"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"population_raw = pd.read_csv(\n    \"/kaggle/input/covid19-global-forecasting-locations-population/locations_population.csv\"\n)\n\npprint(\"Number of NULL values:\")\npprint(pd.DataFrame(population_raw.isnull().sum()).T)\n\ndisplay(population_raw.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I transform the dataset, adding population by country / city, also adding the global population, and the global population except China."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df = population_raw.copy()\ndf = df.rename({\"Province.State\": \"Province\", \"Country.Region\": \"Country\"}, axis=1)\ncols = [\"Country\", \"Province\", \"Population\"]\ndf = df.loc[:, cols].fillna(\"-\")\ndf.loc[df[\"Country\"] == df[\"Province\"], \"Province\"] = \"-\"\n# Add total records\n_total_df = df.loc[df[\"Province\"] != \"-\", :].groupby(\"Country\").sum()\n_total_df = _total_df.reset_index().assign(Province=\"-\")\ndf = pd.concat([df, _total_df], axis=0, sort=True)\ndf = df.drop_duplicates(subset=[\"Country\", \"Province\"], keep=\"first\")\n# Global\nglobal_value = df.loc[df[\"Province\"] == \"-\", \"Population\"].sum()\ndf = df.append(pd.Series([\"Global\", \"-\", global_value], index=cols), ignore_index=True)\n# Sorting\ndf = df.sort_values(\"Population\", ascending=False).reset_index(drop=True)\ndf = df.loc[:, cols]\npopulation_df = df.copy()\npopulation_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In US, there are provinces (the States)"},{"metadata":{"trusted":true},"cell_type":"code","source":"display(population_df[population_df['Country']==\"US\"])\npprint(sorted(population_df.loc[population_df['Country']==\"US\", \"Province\"].to_list()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Save population in the dictionary \"population_dict\""},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"df = population_df.loc[population_df[\"Province\"] == \"-\", :]\npopulation_dict = df.set_index(\"Country\").to_dict()[\"Population\"]\npopulation_dict","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"980b4b4e-b055-4c2a-b06f-823e90a42421","_cell_guid":"6347198d-b95f-495b-9d50-f55e917c77e9","trusted":true},"cell_type":"markdown","source":"## Raw data: the number of cases"},{"metadata":{"_uuid":"bc109822-1f6c-48ac-baaa-13698ef4155e","_cell_guid":"b0ede625-76d1-4c24-b85d-6b949c4c98f1","trusted":true,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"raw = pd.read_csv(\"/kaggle/input/novel-corona-virus-2019-dataset/covid_19_data.csv\")\n\npprint(\"INFO:\")\npprint(raw.info())\n\npprint(\"DESCRIBE:\")\npprint(raw.describe())\n\npprint(\"NULL DATA:\")\npprint(pd.DataFrame(raw.isnull().sum()).T)\n\npprint(\"REPORTED COUNTRIES:\")\npprint(\", \".join(raw[\"Country/Region\"].unique().tolist()))\n\npprint(\"RARE COUNTRIES:\")\npprint(raw.loc[raw[\"Country/Region\"] == \"Others\", \"Province/State\"].unique().tolist(), compact=True)\n\nraw.tail()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7b860d14-e603-420a-a655-de2cae2a082e","_cell_guid":"bafa861d-2610-44dd-bd21-2996ccea0d58","trusted":true},"cell_type":"markdown","source":"## Data Cleening: the number of cases\nNote: \"Infected\" = \"Confirmed\" - \"Deaths\" - \"Recovered\""},{"metadata":{"_uuid":"41f0be0f-f8dc-42f7-8773-65dc60f893e5","_cell_guid":"605752b1-4a5c-421c-82a7-d8ae766d893f","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"data_cols = [\"Infected\", \"Deaths\", \"Recovered\"]\ndata_cols_all = [\"Confirmed\", \"Infected\", \"Deaths\", \"Recovered\"]\nrate_cols = [\"Fatal per Confirmed\", \"Recovered per Confirmed\", \"Fatal per (Fatal or Recovered)\"]\nvariable_dict = {\"Susceptible\": \"S\", \"Infected\": \"I\", \"Recovered\": \"R\", \"Deaths\": \"D\"}","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2988a829-895b-401a-82ae-97d8026b271e","_cell_guid":"d6846623-7a01-4c27-8efc-61ce58d2553c","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df = raw.rename({\"ObservationDate\": \"Date\", \"Province/State\": \"Province\"}, axis=1)\ndf[\"Date\"] = pd.to_datetime(df[\"Date\"])\ndf[\"Country\"] = df[\"Country/Region\"].replace(\n    {\n        \"Mainland China\": \"China\",\n        \"Hong Kong SAR\": \"Hong Kong\",\n        \"Taipei and environs\": \"Taiwan\",\n        \"Iran (Islamic Republic of)\": \"Iran\",\n        \"Republic of Korea\": \"South Korea\",\n        \"Republic of Ireland\": \"Ireland\",\n        \"Macao SAR\": \"Macau\",\n        \"Russian Federation\": \"Russia\",\n        \"Republic of Moldova\": \"Moldova\",\n        \"Taiwan*\": \"Taiwan\",\n        \"Cruise Ship\": \"Others\",\n        \"United Kingdom\": \"UK\",\n        \"Viet Nam\": \"Vietnam\",\n        \"Czechia\": \"Czech Republic\",\n        \"St. Martin\": \"Saint Martin\",\n        \"Cote d'Ivoire\": \"Ivory Coast\",\n        \"('St. Martin',)\": \"Saint Martin\",\n        \"Congo (Kinshasa)\": \"Congo\",\n    }\n)\ndf[\"Province\"] = df[\"Province\"].fillna(\"-\").replace(\n    {\n        \"Cruise Ship\": \"Diamond Princess\",\n        \"Diamond Princess cruise ship\": \"Diamond Princess\"\n    }\n)\ndf.loc[df[\"Country\"] == \"Diamond Princess\", [\"Country\", \"Province\"]] = [\"Others\", \"Diamond Princess\"]\ndf[\"Infected\"] = df[\"Confirmed\"] - df[\"Deaths\"] - df[\"Recovered\"]\ndf[data_cols_all] = df[data_cols_all].astype(np.int64)\nncov_df_ungrouped = df.loc[:, [\"Date\", \"Country\", \"Province\", *data_cols_all]]\n\n\npprint(\"INFO:\")\ndisplay(ncov_df_ungrouped.info())\n\npprint(\"DESCRIBE:\")\ndisplay(ncov_df_ungrouped.describe(include=\"all\").fillna(\"-\"))\n\npprint(\"NULL DATA:\")\ndisplay(pd.DataFrame(ncov_df_ungrouped.isnull().sum()).T)\n\npprint(\"REPORTED COUNTRIES:\")\npprint(\", \".join(ncov_df_ungrouped[\"Country\"].unique().tolist()))\n\nncov_df_ungrouped.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Grouping by growth factor\nThe number of confirmed cases is increasing in many countries, but there are two of countries. In a first-type country, growth factor is larger than 1 and the number of cases is rapidly increasing. In a second-type country, growth factor is less than 1."},{"metadata":{},"cell_type":"markdown","source":"### Calculate growth factor\nWhere $C$ is the number of confirmed cases,  \n$$\\mathrm{Growth\\ Factor} = \\cfrac{\\Delta \\mathrm{C}_{n}}{\\Delta \\mathrm{C}_{n-1}}$$"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df = ncov_df_ungrouped.pivot_table(\n    index=\"Date\", columns=\"Country\", values=\"Confirmed\", aggfunc=\"sum\"\n).fillna(method=\"ffill\").fillna(0)\n# Growth factor: (delta Number_n) / (delta Number_n)\ndf = df.diff() / df.diff().shift(freq=\"D\")\ndf = df.replace(np.inf, np.nan).fillna(1.0)\n# Rolling mean (window: 7 days)\ndf = df.rolling(7).mean()\ndf = df.iloc[6:, :]\n# round: 0.01\ngrowth_value_df = df.round(2)\ngrowth_value_df.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Grouping countires based on growth factor\n* Outbreaking: growth factor $>$ 1 for the last 7 days\n* Stopping: growth factor $<$ 1 for the last 7 days\n* At a crossroad: the others"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df = growth_value_df.copy()\ndf = df.iloc[-7:, :].T\nday_cols = df.columns.strftime(\"%d%b%Y\")\ndf.columns = day_cols\nlast_date = day_cols[-1]\n# Grouping\nmore_col, less_col = \"GF > 1 [straight days]\", \"GF < 1 [straight days]\"\ndf[more_col] = (growth_value_df > 1).iloc[::-1].cumprod().sum(axis=0)\ndf[less_col] = (growth_value_df < 1).iloc[::-1].cumprod().sum(axis=0)\ndf[\"Group\"] = df[[more_col, less_col]].apply(\n    lambda x: \"Outbreaking\" if x[0] >= 7 else \"Stopping\" if x[1] >= 7 else \"Crossroad\",\n    axis=1\n)\n# Sorting\ndf = df.loc[:, [\"Group\", more_col, less_col, *day_cols]]\ndf[\"rank1\"] = df[more_col] * df[last_date]\ndf[\"rank2\"] = df[less_col] * df[last_date]\ndf = df.sort_values([\"Group\", \"rank1\", \"rank2\"], ascending=False)\ndf = df.drop([\"rank1\", \"rank2\"], axis=1)\ngrowth_df = df.copy()\ngrowth_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.merge(ncov_df_ungrouped, growth_df[\"Group\"].reset_index(), on=\"Country\")\nncov_df = df.loc[:, [\"Date\", \"Group\", *ncov_df_ungrouped.columns[1:]]]\nncov_df.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And the US cleaned dataset is..."},{"metadata":{"trusted":true},"cell_type":"code","source":"display(ncov_df[ncov_df['Country']=='US'])\n\ndf = ncov_df[ncov_df['Country']=='US'].groupby(\"Date\").sum()\ndf = df.loc[:,[*data_cols]]\ndisplay(df)\nline_plot(df, \"US: Cases over time\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualize total data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# compute total\ntotal_df = ncov_df.groupby(\"Date\").sum()\ntotal_df[rate_cols[0]] = total_df[\"Deaths\"] / total_df[data_cols].sum(axis=1)\ntotal_df[rate_cols[1]] = total_df[\"Recovered\"] / total_df[data_cols].sum(axis=1)\ntotal_df[rate_cols[2]] = total_df[\"Deaths\"] / (total_df[\"Deaths\"] + total_df[\"Recovered\"])\n\n\n# ploting\npprint(f\"{(total_df.index.max() - total_df.index.min()).days} days have passed from the date of the first record.\")\nline_plot(total_df[data_cols], \"Total number of cases over time\")\nline_plot(total_df[rate_cols], \"Global rate over time\", ylabel=\"\", math_scale=False)\n\ntotal_df[rate_cols].plot.kde()\nplt.title(\"Kernel density estimation of the rates\")\nplt.show()\ndisplay(total_df[rate_cols].describe().T)\n\ntotal_df.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Mobile Mobility"},{"metadata":{},"cell_type":"markdown","source":"Note: This notebook was created to work with added precision mobility data. For example, with mobility data obtained from applications or mobile operators. For confidentiality reasons, outdated public mobility information from the [Bureau of Transportation Statistics](https://www.transtats.bts.gov/DatabaseInfo.asp?DB_ID=111) is used here."},{"metadata":{},"cell_type":"markdown","source":"The data is disaggregated by states, I am going to add these in subpopulations.\nAt the beginning 4 subpopulations according to the census in US: [Census_Bureau-designated_regions_and_divisions](https://en.wikipedia.org/wiki/List_of_regions_of_the_United_States#Census_Bureau-designated_regions_and_divisions)\n<div>\n<img src=\"attachment:image.png\" width=\"500\"/>\n</div>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Region 1: Northeast: Connecticut, Maine, Massachusetts, New Hampshire, Rhode Island, Vermont, New Jersey, New York, Pennsylvania\n#Region 2: Midwest: Illinois, Indiana, Michigan, Ohio, Wisconsin, Iowa, Kansas, Minnesota, Missouri, Nebraska, North Dakota, South Dakota\n#Region 3: South: Delaware, Florida, Georgia, Maryland, North Carolina, South Carolina, Virginia, District of Columbia, West Virginia, Alabama, Kentucky, Mississippi, Tennessee, Arkansas, Louisiana, Oklahoma, Texas\n#Region 4: West: Arizona, Colorado, Idaho, Montana, Nevada, New Mexico, Utah, Wyoming, Alaska, California, Hawaii, Oregon, Washington\n\nsubpopulation_name   = [\"Northeast\", \"Midwest\", \"South\", \"West\"]\nsubpopulation_mapper = {\n     'Alabama':\"South\",\n     'Alaska':\"West\",\n     'Arizona':\"West\",\n     'Arkansas':\"South\",\n     'California':\"West\",\n     'Colorado':\"West\",\n     'Connecticut':\"Northeast\",\n     'Delaware':\"South\",\n     'Diamond Princess':\"-\",\n     'District of Columbia':\"South\",\n     'Florida':\"South\",\n     'Georgia':\"South\",\n     'Grand Princess':\"-\",\n     'Guam': \"-\",\n     'Hawaii':\"West\",\n     'Idaho':\"West\",\n     'Illinois':\"Midwest\",\n     'Indiana':\"Midwest\",\n     'Iowa':\"Midwest\",\n     'Kansas':\"Midwest\",\n     'Kentucky':\"South\",\n     'Louisiana':\"South\",\n     'Maine':\"Northeast\",\n     'Maryland':\"South\",\n     'Massachusetts':\"Northeast\",\n     'Michigan':\"Midwest\",\n     'Minnesota':\"Midwest\",\n     'Mississippi':\"South\",\n     'Missouri':\"Midwest\",\n     'Montana':\"West\",\n     'Nebraska':\"Midwest\",\n     'Nevada':\"West\",\n     'New Hampshire':\"Northeast\",\n     'New Jersey':\"Northeast\",\n     'New Mexico':\"West\",\n     'New York':\"Northeast\",\n     'North Carolina':\"South\",\n     'North Dakota':\"Midwest\",\n     'Ohio':\"Midwest\",\n     'Oklahoma':\"South\",\n     'Oregon':\"West\",\n     'Pennsylvania':\"Northeast\",\n     'Puerto Rico': \"-\",\n     'Rhode Island':\"Northeast\",\n     'South Carolina':\"South\",\n     'South Dakota':\"Midwest\",\n     'Tennessee':\"South\",\n     'Texas':\"South\",\n     'United States Virgin Islands':\"-\",\n     'Utah':\"West\",\n     'Vermont':\"Northeast\",\n     'Virgin Islands':\"-\",\n     'Virginia':\"South\",\n     'Washington':\"West\",\n     'West Virginia':\"South\",\n     'Wisconsin':\"Midwest\",\n     'Wyoming':\"West\"\n}\n    \nsubpopulation_excluded = ['U.S. Pacific Trust Territories and Possessions', \n                          'U.S. Virgin Islands',\n                          'Diamond Princess',\n                          'Grand Princess',\n                          'Guam',\n                          'Puerto Rico',\n                          'United States Virgin Islands',\n                          'Virgin Islands'\n                         ]\n                          ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = population_df.loc[population_df[\"Country\"] == \"US\", :]\ndf = df[df[\"Province\"]!=\"-\"] #quito el total\ndf = df.drop(\"Country\",1) # quito pais\ndf = df[~df.Province.isin(subpopulation_excluded)] #quito provincias raras\n\n# Agrego subpoblaciones\ndf['sp'] = [ subpopulation_mapper[d] for d in df['Province']]\nfor sp in subpopulation_name:\n    sp_value = df.loc[df[\"sp\"]==sp, \"Population\"].sum()\n    df = df.append(pd.Series([sp,sp_value, \"-\"], index=[\"Province\", \"Population\", \"sp\"]), ignore_index=True)\n\n#Agrego Total\nglobal_value = df.loc[df[\"sp\"]!=\"-\", \"Population\"].sum()\ndf = df.append(pd.Series([\"Total\",global_value, \"-\"], index=[\"Province\", \"Population\", \"sp\"]), ignore_index=True)\n\n#display(df)\nsubpopulation_dict = df.set_index(\"Province\").to_dict()[\"Population\"]\ndisplay(subpopulation_dict)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Load mobility\n\nWe will use the \"T-100 Domestic Market (All Carriers)\" dataset from the [Bureau of Transportation Statistics](https://www.transtats.bts.gov/DatabaseInfo.asp?DB_ID=111),\nwith data from January to September of 2019."},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_S = pd.read_csv(\"/kaggle/input/localsrc/8573377_T_T100D_MARKET_ALL_CARRIER.csv\")\n#raw_S[\"Date\"] = [str(row[\"YEAR\"]) + \"-\" + str(row[\"MONTH\"]) + \"-01\"  for index, row in raw_S.iterrows()]\nraw_S[\"Date\"] = raw_S[\"YEAR\"].astype(str) + \"-\" + raw_S[\"MONTH\"].astype(str) + \"-01\" \nraw_S.rename(columns={\"ORIGIN_STATE_NM\": \"orig_dept\", \"DEST_STATE_NM\":\"dest_dept\", \"PASSENGERS\":\"count\"}, inplace=True)\nraw_S = raw_S.loc[:, [\"Date\",\"orig_dept\", \"dest_dept\",\"count\"]]\nraw_S = raw_S.groupby([\"Date\",\"orig_dept\", \"dest_dept\"]).sum()\nraw_S = raw_S.reset_index([\"Date\",\"orig_dept\",\"dest_dept\"])\n#display(raw_S.head())\n\npprint(\"NULL DATA:\")\ndisplay(pd.DataFrame(raw_S.isnull().sum()).T)\nprintmd(\"**No existen datos nulos**\")\n#raw_S = raw_S.dropna()\n\npprint(\"INFO:\")\ndisplay(raw_S.info())\n\npprint(\"DESCRIBE:\")\ndisplay(raw_S.describe(include=\"all\").fillna(\"-\"))\n\npprint(\"REPORTED SUBPOPULATIONS:\")\ndisplay(\", \".join(sorted(raw_S[\"orig_dept\"].fillna(\"-\").unique().tolist())))\n\npprint(\"REMOVE BAD STATES:\")\npprint(raw_S.shape)\nraw_S = raw_S[~raw_S.orig_dept.isin(subpopulation_excluded)]\nraw_S = raw_S[~raw_S.dest_dept.isin(subpopulation_excluded)]\npprint(raw_S.shape)\n\ndisplay(raw_S.tail())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Subpopulation Mapping"},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_S['orig_sp'] = [ subpopulation_mapper[d] for d in raw_S['orig_dept']]\nraw_S['dest_sp'] = [ subpopulation_mapper[d] for d in raw_S['dest_dept']]\n\npprint(\"cantidad de valores nulos:\")\ndisplay(pd.DataFrame(raw_S.isnull().sum()).T)\n\ndisplay(raw_S)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Subpopulation Mobility Analysis\n\nFirst I define the \"market share\" to scale the mobility data. This is the percentage of individuals in each mobility subpopulation, according to the totals of that subpopulation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# TODO I do not have information to the market share in this data\n\n'''\n_marketshare_df = raw_P.groupby([\"Date\",\"sp\"]).sum()\n_marketshare_df = _marketshare_df.reset_index(\"sp\")\n_marketshare_df = _marketshare_df.pivot_table(index=['Date'], columns='sp')\n_marketshare_df.columns = _marketshare_df.columns.droplevel().rename(None)\ndisplay(_marketshare_df.head())\n\n_subpopulation_size = _marketshare_df.mean() #tamaño de subpoblaciones muestradas segun movilidad (no poblacion total)\nsubpopulation_size = np.array([_subpopulation_size[sp] for sp in subpopulation_name]) #me aseguro ponerlo en el orden correcto\nsubpopulation_marketshare = np.array([_subpopulation_size[sp]/subpopulation_dict[sp] for sp in subpopulation_name]) #me aseguro ponerlo en el orden correcto\n\nline_plot(_marketshare_df, \"Total number of individuals in subpopulations over time\", h = subpopulation_size)\n\n_marketshare_df.plot.kde()\nplt.title(\"Kernel density estimation of the marketshares\")\nplt.show()\ndisplay(_marketshare_df.describe().T)\n'''\nsubpopulation_marketshare = np.ones(len(subpopulation_name))\n\n\npprint(\"El porcentaje de subpoblacion \" + str(subpopulation_name) + \" con movilidad conocida es:\")\ndisplay(subpopulation_marketshare)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, I calculate the average mobility matrices during the pandemic.\n\nI do not have actual mobility data, I suppose a 30% lower than similar data in 2019."},{"metadata":{"trusted":true},"cell_type":"code","source":"pprint(\"Min date in datasest: \" + str(min(raw_S[\"Date\"])))\npprint(\"Max date in datasest: \" + str(max(raw_S[\"Date\"])))\n\nbefore_sample_start = \"2019-01-01\" #elegimos domingos para tener promedio semanal\nbefore_sample_end = \"2019-12-31\" #elegimos domingos para tener promedio semanal \n\n#no tenemos datos de pandemia\npandemia_sample_start = \"2019-01-01\" #elegimos domingos para tener promedio semanal\npandemia_sample_end = \"2019-12-31\" #elegimos domingos para tener promedio semanal\npandemic_factor = 0.7\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_l_df = raw_S.groupby([\"Date\",\"orig_sp\",\"dest_sp\"]).sum() #agregar los viajes entre todos los departamentos de las mismas subpoblaciones\n_l_df = _l_df.reset_index([\"orig_sp\",\"dest_sp\"])\n_l_df = _l_df.loc[_l_df[\"orig_sp\"]!= _l_df[\"dest_sp\"],:] # eliminamos los viajes dentro de cada subpoblacion, porque no se usan en el modelo (y ademas no son representativos, son los viajes entre departamentos de la subpoblacion)\n_l_df = _l_df.pivot_table(index=['Date'], columns=[\"orig_sp\",\"dest_sp\"]) #unmelt\n_l_df.columns = _l_df.columns.droplevel() #borro un primer nivel de multindice\n\n_l_before_df = _l_df.loc[(_l_df.index >= before_sample_start) & (_l_df.index < before_sample_end),:]\n_l_pandemia_df = _l_df.loc[(_l_df.index >= pandemia_sample_start) & (_l_df.index < pandemia_sample_end),:]\ndisplay(_l_pandemia_df.head())\n\n_lflatten_df = _l_df.copy()\n_lflatten_df.columns = _lflatten_df.columns.map('|'.join).str.strip('|') #concateno los ultimos dos niveles de multindice para mostrarlo\nline_plot(_lflatten_df, \"Total number of individuals that travel in the day to sp living in orig (sp|orig)\", math_scale=False, \n          h=np.concatenate([np.array(_l_before_df.mean()),np.array(_l_pandemia_df.mean())]))\n\n# lo paso a una matriz, y escalo segun marketshare\n#me aseguro ponerlo en el orden correcto\n_l_before_df = _l_before_df.mean()\n_l_pandemia_df = _l_pandemia_df.mean()\nl_before = np.zeros([len(subpopulation_name),len(subpopulation_name)])\nl_pandemia = np.zeros([len(subpopulation_name),len(subpopulation_name)])\nfor sp_i in range(len(subpopulation_name)):\n    for sp_j in range(len(subpopulation_name)):\n        if (sp_i != sp_j):\n            l_before[sp_i,sp_j] = _l_before_df[subpopulation_name[sp_i],subpopulation_name[sp_j]] / subpopulation_marketshare[sp_j] / subpopulation_dict[subpopulation_name[sp_j]]\n            l_pandemia[sp_i,sp_j] = _l_pandemia_df[subpopulation_name[sp_i],subpopulation_name[sp_j]] / subpopulation_marketshare[sp_j] / subpopulation_dict[subpopulation_name[sp_j]]\nl_before =  l_before/273*9  #monthly average to dayly average (only data from january to september: 9 months, 273 days)\nl_pandemia =  l_pandemia/273*9*pandemic_factor\npprint(\"El porcentaje de individuos que viaja a la subpoblacion i, y viven en la subpoblacion j por dia, escalado segun marketshare:\")\ndisplay(l_pandemia)\n\na_before =  l_before/24/60 \na_pandemia =  l_pandemia/24/60 \npprint(\"El porcentaje de individuos que viaja a la subpoblacion i, y viven en la subpoblacion j por minuto:\")\ndisplay(a_pandemia)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pprint(\"We do not have data,.. I suppose r = l. Please read below...\")\nr_before = l_before\nr_pandemia = l_pandemia\n\n#pprint(\"El porcentaje de individuos que viaja desde la subpoblacion i hacia donde viven en la subpoblacion j por dia, escalado segun marketshare:\")\npprint(\"The rate of individuals that commute from subpopulation i to their homes at subpopulation j, per day, scaled by marketshare:\")\ndisplay(r_pandemia)\n\nb_before =  r_before/24/60 \nb_pandemia =  r_pandemia/24/60 \n#pprint(\"El porcentaje de individuos que viaja desde la subpoblacion i hacia donde viven en la subpoblacion j por minuto:\")\npprint(\"The rate of individuals that commute to subpopulation i to their homes at subpopulation j, per minute:\")\ndisplay(b_pandemia)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Trend analysis"},{"metadata":{},"cell_type":"markdown","source":"Using fbprophet package, we will find changing points of log10(comfirmed/deaths/recovered).  \nWe will use the data in the most cirical country where the number of days with growth factor $>$ 1 is the longest."},{"metadata":{"trusted":true},"cell_type":"code","source":"uy_country = 'US'\nuy_df = ncov_df.loc[ncov_df[\"Country\"] == uy_country, [\"Date\", *data_cols_all]].groupby(\"Date\").sum()\n\ndisplay(uy_df)\nline_plot(uy_df, f\"{uy_country}: Cases over time\", y_integer=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_trend(ncov_df, variable=\"Confirmed\", places=[(uy_country, None)])\nprintmd(\"**The slope was change at 29Feb2020.**\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#show_trend(ncov_df, variable=\"Confirmed\", places=[(uy_country, None)], n_changepoints=-1, start_date=\"29Feb2020\")\nprintmd(\"**It changes again in 28Mar2020...**\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#show_trend(ncov_df, variable=\"Confirmed\", places=[(uy_country, None)], n_changepoints=-1, start_date=\"28Mar2020\")\nprintmd(\"**NPodriamos aceptar que no ha cambiado ahora...**\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"uy_country_start = \"28Mar2020\"\n\nprintmd(\"**Records after \" + uy_country_start + \" will be used for improvement of math model.**\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Traditional Epidemic Models"},{"metadata":{},"cell_type":"markdown","source":"* ## SIR model\nTo understand the trend of infection, we will use mathematical epidemic model. Let's start discussion using a basic model named SIR."},{"metadata":{},"cell_type":"markdown","source":"### What is SIR model?\nSIR model is a simple mathematical model to understand outbreak of infectious diseases.  \n[The SIR epidemic model - Learning Scientific Programming with Python](https://scipython.com/book/chapter-8-scipy/additional-examples/the-sir-epidemic-model/)\n\n * S: Susceptible (=All - Confirmed)\n * I: Infected (=Confirmed - Recovered - Deaths)\n * R: Recovered or fatal (=Recovered + Deaths)\n \nNote: THIS IS NOT THE GENERAL MODEL!  \nThough R in SIR model is \"Recovered and have immunity\", I defined \"R as Recovered or fatal\". This is because mortality rate cannot be ignored in the real COVID-19 data.\n\nModel:  \nS + I $\\overset{\\beta}{\\longrightarrow}$ 2I  \nI $\\overset{\\gamma}{\\longrightarrow}$ R\n\n$\\beta$: Effective contact rate [1/min]  \n$\\gamma$: Recovery(+Mortality) rate [1/min]  \n\nOrdinary Differential Equation (ODE):   \n$\\frac{\\mathrm{d}S}{\\mathrm{d}T}= - N^{-1}\\beta S I$  \n$\\frac{\\mathrm{d}I}{\\mathrm{d}T}= N^{-1}\\beta S I - \\gamma I$  \n$\\frac{\\mathrm{d}R}{\\mathrm{d}T}= \\gamma I$  \n\nWhere $N=S+I+R$ is the total population, $T$ is the elapsed time from the start date."},{"metadata":{},"cell_type":"markdown","source":"#### Non-dimensional SIR model\nTo simplify the model, we will remove the units of the variables from ODE.\n\nSet $(S, I, R) = N \\times (x, y, z)$ and $(T, \\beta, \\gamma) = (\\tau t, \\tau^{-1} \\rho, \\tau^{-1} \\sigma)$.  \n\nThis results in the ODE  \n$\\frac{\\mathrm{d}x}{\\mathrm{d}t}= - \\rho x y$  \n$\\frac{\\mathrm{d}y}{\\mathrm{d}t}= \\rho x y - \\sigma y$  \n$\\frac{\\mathrm{d}z}{\\mathrm{d}t}= \\sigma y$  \n\nWhere $N$ is the total population and $\\tau$ is a coefficient ([min], is an integer to simplify).  \n\nThe range of variables and parameters:  \n$0 < (x, y, z, \\rho, \\sigma) < 1$  \n$1\\leq \\tau \\leq 1440$  \n\nBasic reproduction number, Non-dimentional parameter, is defined as  \n$R_0 = \\rho \\sigma^{-1} = \\beta \\gamma^{-1}$  \n\nEstimated Mean Values of $R_0$:  \n$R_0$ means \"the average number of secondary infections caused by an infected host\" ([Infection Modeling — Part 1](https://towardsdatascience.com/infection-modeling-part-1-87e74645568a)).  \n(Secondary data: [Van den Driessche, P., & Watmough, J. (2002).](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6002118))  \n2.06: Zika in South America, 2015-2016  \n1.51: Ebola in Guinea, 2014  \n1.33: H1N1 influenza in South Africa, 2009  \n3.5 : SARS in 2002-2003  \n1.68: H2N2 influenza in US, 1957  \n3.8 : Fall wave of 1918 Spanish influenza in Genova  \n1.5 : Spring wave of 1918 Spanish influenza in Genova  \n\nWhen $x=\\frac{1}{R_0}$, $\\frac{\\mathrm{d}y}{\\mathrm{d}t}=0$. This means that the max value of confirmed ($=y+z$) is $1-\\frac{1}{R_0}$."},{"metadata":{},"cell_type":"markdown","source":"### Hyperparameter optimization\nUsing Optuna package, ($\\rho, \\sigma, \\tau$) will be estimated by model fitting."},{"metadata":{"trusted":true},"cell_type":"code","source":"tau=1440","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"76193d22-6038-4ec4-91c8-b0a8f2385682","_cell_guid":"efa28bae-2968-43cb-9952-eb1127deafe7","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"%%time\n\nsir_estimator = Estimator(\n    SIR, ncov_df, population_dict[uy_country], name=uy_country, places=[(uy_country, None)],\n    start_date=uy_country_start,\n    tau=tau\n)\nsir_dict = sir_estimator.run(n_trials)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c7d9de06-0f3e-4bf2-bc97-98c7f5f49089","_cell_guid":"ad5d4ac6-93e3-4572-b77d-76fe2d66e47a","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"display(sir_estimator.history_df().head())\n\nsir_estimator.history_graph()\n\ndisplay(pd.DataFrame.from_dict({\"SIR\": sir_dict}, orient=\"index\"))\n\nsir_estimator.compare_graph()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sir_estimator.predict_graph(step_n=400)\n\ndf = sir_estimator.predict_df(400)\ndisplay(df.loc[datetime.today():, [\"Infected\", \"Recovered/Deaths\"]].head(14).style.background_gradient(axis=0))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"abc5f4a0-5674-4678-938b-79db83e4f4f5","_cell_guid":"6ad03ba6-eaba-41ea-b816-17962a58bd54","trusted":true},"cell_type":"markdown","source":"## SIR-D model\nBecause we can measure the number of fatal cases and recovered cases separately, we can use two variables (\"Recovered\" and \"Deaths\") instead of \"Recovered + Deaths\" in the mathematical model."},{"metadata":{"_uuid":"ac79b973-cdd3-4beb-825d-c29f987f6cd1","_cell_guid":"54813702-3d5a-4aeb-89dc-b7b5014fb9fb","trusted":true},"cell_type":"markdown","source":"### What is SIR-D model?\n* S: Susceptible\n* I: Infected\n* R: Recovered\n* D: Fatal\n\nModel:  \nS + I $\\overset{\\beta}{\\longrightarrow}$ 2I  \nI $\\overset{\\gamma}{\\longrightarrow}$ R  \nI $\\overset{\\alpha}{\\longrightarrow}$ D  \n\n$\\alpha$: Mortality rate [1/min]  \n$\\beta$: Effective contact rate [1/min]  \n$\\gamma$: Recovery rate [1/min]  \n\nOrdinary Differential Equation (ODE):   \n$\\frac{\\mathrm{d}S}{\\mathrm{d}T}= - N^{-1}\\beta S I$  \n$\\frac{\\mathrm{d}I}{\\mathrm{d}T}= N^{-1}\\beta S I - (\\gamma + \\alpha) I$  \n$\\frac{\\mathrm{d}R}{\\mathrm{d}T}= \\gamma I$  \n$\\frac{\\mathrm{d}D}{\\mathrm{d}T}= \\alpha I$  \n\nWhere $N=S+I+R+D$ is the total population, $T$ is the elapsed time from the start date."},{"metadata":{"_uuid":"20008d93-6fef-4053-af91-aef177eed421","_cell_guid":"b3cbf5d5-c269-4695-8835-46ed417d9c48","trusted":true},"cell_type":"markdown","source":"### Non-dimensional SIR-D model\nSet $(S, I, R, D) = N \\times (x, y, z, w)$ and $(T, \\alpha, \\beta, \\gamma) = (\\tau t, \\tau^{-1} \\kappa, \\tau^{-1} \\rho, \\tau^{-1} \\sigma)$.  \nThis results in the ODE  \n$\\frac{\\mathrm{d}x}{\\mathrm{d}t}= - \\rho x y$  \n$\\frac{\\mathrm{d}y}{\\mathrm{d}t}= \\rho x y - (\\sigma + \\kappa) y$  \n$\\frac{\\mathrm{d}z}{\\mathrm{d}t}= \\sigma y$  \n$\\frac{\\mathrm{d}w}{\\mathrm{d}t}= \\kappa y$  \n\nWhere $N$ is the total population and $\\tau$ is a coefficient ([min], is an integer to simplify).  \n\nThe range of variables and parameters:  \n$0 \\leq (x, y, z, w, \\kappa, \\rho, \\sigma) \\leq 1$  \n$1\\leq \\tau \\leq 1440$\n\nReproduction number can be defined as  \n$R_0 = \\rho (\\sigma + \\kappa)^{-1} = \\beta (\\gamma + \\alpha)^{-1}$"},{"metadata":{"_uuid":"71f0c51c-dc0e-4b7d-8a00-047dffd01486","_cell_guid":"017ea3f3-b6ca-4bba-8169-bdfdc7f62b8f","trusted":true},"cell_type":"markdown","source":"### Hyperparameter optimization\nUsing Optuna package, ($\\kappa, \\rho, \\sigma, \\tau$) will be estimated by model fitting."},{"metadata":{"_uuid":"c00c15a8-b4aa-44d5-a636-5394d8126ec6","_cell_guid":"6599a692-714f-45db-85cc-e9e44949ac5b","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"%%time\nsird_estimator = Estimator(\n    SIRD, ncov_df, population_dict[uy_country],\n    name=uy_country, places=[(uy_country, None)],\n    start_date=uy_country_start,\n    tau=tau\n)\nsird_dict = sird_estimator.run(n_trials)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7320cf16-e0fa-4bab-b657-1955576864a2","_cell_guid":"d74f4e98-d5cc-402d-af7e-61bb976678a0","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"display(sird_estimator.history_df().head())\n\nsird_estimator.history_graph()\n\ndisplay(pd.DataFrame.from_dict({\"SIR\": sir_dict, \"SIR-D\": sird_dict}, orient=\"index\").fillna(\"-\"))\n\nsird_estimator.compare_graph()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c2260b29-feac-4c56-9a2f-5d6282cead68","_cell_guid":"bf0c3019-c018-4687-a6b8-c5504a5861fc","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"sird_estimator.predict_graph(step_n=300)\n\ndf = sird_estimator.predict_df(300)\ndisplay(df.loc[datetime.today():, [\"Infected\", \"Recovered\", \"Deaths\"]].head(14).style.background_gradient(axis=0))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b17a61ed-d8da-43ba-b028-1949760dc0ca","_cell_guid":"c19b122a-84fb-4757-834e-bb72002cdfb3","trusted":true},"cell_type":"markdown","source":"## SIR-F model\nSome cases are reported as fatal cases before clinical diagnosis of COVID-19. To consider this issue, \"S + I $\\to$ Fatal + I\" will be added to the model."},{"metadata":{"_uuid":"3f40d0e2-7fb1-4082-8308-e27d37efc943","_cell_guid":"0a2eafd9-5355-4953-af46-025e6554fa59","trusted":true},"cell_type":"markdown","source":"### What is SIR-F model?\n* S: Susceptible\n* S$^\\ast$: Confirmed and un-categorized\n* I: Confirmed and categorized as I\n* R: Recovered\n* F: Fatal with confirmation\n\nMeasurable variables:  \nConfirmed = $I+R+F$  \nRecovered = $R$  \nDeaths = $F$  \n\nModel:  \nS $\\overset{\\beta \\mathrm{I}}{\\longrightarrow}$ S$^\\ast$ $\\overset{\\alpha_1}{\\longrightarrow}$ F  \nS $\\overset{\\beta \\mathrm{I}}{\\longrightarrow}$ S$^\\ast$ $\\overset{1 - \\alpha_1}{\\longrightarrow}$ I  \nI $\\overset{\\gamma}{\\longrightarrow}$ R  \nI $\\overset{\\alpha_2}{\\longrightarrow}$ F  \n\n$\\alpha_1$: Mortality rate of S$^\\ast$ cases [-]  \n$\\alpha_2$: Mortality rate of I cases [1/min]  \n$\\beta$: Effective contact rate [1/min]  \n$\\gamma$: Recovery rate [1/min]  \n\nOrdinary Differential Equation (ODE):   \n$\\frac{\\mathrm{d}S}{\\mathrm{d}T}= - N^{-1}\\beta S I$  \n$\\frac{\\mathrm{d}I}{\\mathrm{d}T}= N^{-1}(1 - \\alpha_1) \\beta S I - (\\gamma + \\alpha_2) I$  \n$\\frac{\\mathrm{d}R}{\\mathrm{d}T}= \\gamma I$  \n$\\frac{\\mathrm{d}F}{\\mathrm{d}T}= N^{-1}\\alpha_1 \\beta S I + \\alpha_2 I$  \n\nWhere $N=S+I+R+F$ is the total population, $T$ is the elapsed time from the start date."},{"metadata":{"_uuid":"1a5a19e0-d71a-409b-902e-707d2afe8249","_cell_guid":"fa88a43d-671a-4109-8d60-8b2cacebed68","trusted":true},"cell_type":"markdown","source":"### Non-dimensional SIR-F model\nSet $(S, I, R, F) = N \\times (x, y, z, w)$ and $(T, \\alpha_1, \\alpha_2, \\beta, \\gamma) = (\\tau t, \\theta, \\tau^{-1} \\kappa, \\tau^{-1} \\rho, \\tau^{-1} \\sigma)$.  \nThis results in the ODE  \n$\\frac{\\mathrm{d}x}{\\mathrm{d}t}= - \\rho x y$  \n$\\frac{\\mathrm{d}y}{\\mathrm{d}t}= \\rho (1-\\theta) x y - (\\sigma + \\kappa) y$  \n$\\frac{\\mathrm{d}z}{\\mathrm{d}t}= \\sigma y$  \n$\\frac{\\mathrm{d}w}{\\mathrm{d}t}= \\rho \\theta x y + \\kappa y$  \n\nWhere $N$ is the total population and $\\tau$ is a coefficient ([min], is an integer to simplify).  \n\nThe range of variables and parameters:  \n$0 \\leq (x, y, z, w, \\theta, \\kappa, \\rho, \\sigma) \\leq 1$  \n$1 \\leq \\tau \\leq 1440$  \n\nReproduction number can be defined as  \n$R_0 = \\rho (1 - \\theta) (\\sigma + \\kappa)^{-1} = \\beta (1 - \\alpha_1) (\\gamma + \\alpha_2)^{-1}$"},{"metadata":{"_uuid":"3312c5a7-3ce0-41f1-bc8b-67da61091c70","_cell_guid":"9ad0cd56-fc56-495c-8e4e-698931fd756f","trusted":true},"cell_type":"markdown","source":"### Hyperparameter optimization\nUsing Optuna package, ($\\theta, \\kappa, \\rho, \\sigma, \\tau$) will be estimated by model fitting."},{"metadata":{"_uuid":"177c29e4-93fa-4fae-864a-77a952f818ad","_cell_guid":"9e90ff6d-2612-4fa1-bc3d-0dae73843f44","trusted":true},"cell_type":"code","source":"%%time\nsirf_estimator = Estimator(\n    SIRF, ncov_df, population_dict[uy_country],\n    name=uy_country, places=[(uy_country, None)],\n    start_date=uy_country_start,\n    tau=tau\n)\nsirf_dict = sirf_estimator.run(n_trials)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"display(sirf_estimator.history_df().head())\n\nsirf_estimator.history_graph()\n\ndisplay(pd.DataFrame.from_dict({\"SIR\": sir_dict, \"SIR-D\": sird_dict, \"SIR-F\": sirf_dict}, orient=\"index\").fillna(\"-\"))\n\nsirf_estimator.compare_graph()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b11aeb29-afd0-4378-8574-d5124b821ea0","_cell_guid":"75abc8cf-b898-4d9f-b30c-e8e403626447","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"sirf_estimator.predict_graph(step_n=400)\n\ndf = sirf_estimator.predict_df(400)\ndisplay(df.loc[datetime.today():, [\"Infected\", \"Recovered\", \"Fatal\"]].head(14).style.background_gradient(axis=0))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# MetaPopulation Epidemic Models"},{"metadata":{},"cell_type":"markdown","source":"## MP*SIR model\nTo understand the trend of infection, we will use mathematical epidemic model. Let's start discussion using a basic model named MPHSIR."},{"metadata":{},"cell_type":"markdown","source":"### What is MPHSIR model?\nMPHSIR model is a simple mathematical model to understand the outbreak of infectious diseases where travellers interact between subpopulations.\nThe metapopulation concept is to subdivide the entire population into distinct \"subpopulations\", each of which has independent epidemiological dynamics, together with limited interaction between the subpopulations (caused by the travellers).\nThe epidemiological dynamics are supposed identical (homogeneous) between subpopulations (identical contact and recovery rates),\nthat's where the name MetaPopulationHomogeneous-SIR (MPHSIR) comes from.\n\nThis model is based in [Modeling Infectious Diseases in Humans and Animals\nMatt J. Keeling & Pejman Rohani](https://homepages.warwick.ac.uk/~masfz/ModelingInfectiousDiseases/Chapter7/Program_7.2/index.html)\nNote: This is not the general model because:\n * Though R in SIR model is \"Recovered and have immunity\", we defined \"R as Recovered or fatal\". This is because mortality rate cannot be ignored in the real COVID-19 data.\n * Effective contact rate and Recovery(+Mortality) rate are supposed homogeneous between subpopulations. \n * Birth rate and death rates are ignored because of the fast spread of COVID-19.\n * Permanent relocation from one subpopulation to another is sufficiently rare that it may be ignored as an epidemiologically significant force. Instead, it is more natural to think about commuters spreading the disease. Commuters live in one subpopulation but travel occasionally to another subpopulation. Therefore, we will need two matrices, $l$ and $r$, that determine the rate that individuals leave from and return to their home subpopulation.\n\nAt each subpopulation, a simple SIR model is used to predict, but with the main consideration that the individuals at subpopulations change over time because of travellers (and this is a new factor of infection):\n * $S_{ij}$: number of Susceptible (= All - Confirmed) currently in population $i$ that live in population $j$.\n * $I_{ij}$: number of Infected (= Confirmed - Recovered - Deaths) currently in population $i$ that live in population $j$.\n * $R_{ij}$: number of Recovered or fatal (=Recovered + Deaths) currently in population $i$ that live in population $j$.\n * $N_{ij}$: Total hosts currently in population $i$ that live in population $j$.\n\nFrom the standard SIR models we consider the number of individuals of each type in each spatial class:\n * S + I $\\overset{\\beta}{\\longrightarrow}$ 2I  \n * I $\\overset{\\gamma}{\\longrightarrow}$ R\n * N $=$ S + I + R\n\nOrdinary Differential Equation (ODE):   \n$\\frac{\\mathrm{d}S_{ii}}{\\mathrm{d}T}= - \\beta S_{ii} \\frac{\\sum_j I_{ij}}{\\sum_j N_{ij}} - \\sum_j l_{ji} S_{ii} + \\sum_j r_{ji} S_{ji}$      \n$\\frac{\\mathrm{d}S_{ij}}{\\mathrm{d}T}= - \\beta S_{ij} \\frac{\\sum_j I_{ij}}{\\sum_j N_{ij}} + l_{ij} S_{jj} - r_{ij} S_{ij}$     \n$\\frac{\\mathrm{d}I_{ii}}{\\mathrm{d}T}= + \\beta S_{ii} \\frac{\\sum_j I_{ij}}{\\sum_j N_{ij}} - \\gamma I_{ii} - \\sum_j l_{ji} I_{ii} + \\sum_j r_{ji} I_{ji}$     \n$\\frac{\\mathrm{d}I_{ij}}{\\mathrm{d}T}= + \\beta S_{ij} \\frac{\\sum_j I_{ij}}{\\sum_j N_{ij}} - \\gamma I_{ij} + l_{ij} I_{jj} - r_{ij} I_{ij}$     \n$\\frac{\\mathrm{d}R_{ii}}{\\mathrm{d}T}= + \\gamma I_{ii} - \\sum_j l_{ji} R_{ii} + \\sum_j r_{ji} R_{ji}$      \n$\\frac{\\mathrm{d}R_{ij}}{\\mathrm{d}T}= + \\gamma I_{ij} + l_{ij} R_{jj} - r_{ij} R_{ij}$       \n$\\frac{\\mathrm{d}N_{ii}}{\\mathrm{d}T}= - \\sum_j l_{ji} N_{ii} + \\sum_j r_{ji} N_{ji}$          \n$\\frac{\\mathrm{d}N_{ij}}{\\mathrm{d}T}= + l_{ij} N_{jj} - r_{ij} N_{ij}$    \n\n\nWhere: \n * $T$ is the elapsed time from the start date\n * $n$ is the number of sub-populations. Note that all parameters are vectors of size $n$, or matrices of size $n × n$\n * $\\beta$: Effective contact rate [1/min]  \n * $\\gamma$: Recovery(+Mortality) rate [1/min]  \n * $l_{ij}$: is the rate at which individuals leave their home subpopulation $j$ and commute to subpopulation $i$. $l$ is a matrix of size $n × n$\n * $r_{ij}$: is the rate at which individuals return their home subpopulation $j$ from being in subpopulation $i$. $r$ is a matrix of size $n × n$\nAll rates are specified in mins.\n\nRequirements.\nAll parameters must be positive. It is also expected that the diagonal terms of the $l$ and $r$ matrices are all zero.\n"},{"metadata":{},"cell_type":"markdown","source":"#### Non-dimensional MPHSIR model\nTo simplify the model, we will remove the units of the variables from ODE.\nWe define:   \n$\\tau$ is a coefficient ([min], is an integer to simplify)     \n$T = \\tau t$     \n$\\rho = \\tau \\beta$      \n$\\sigma = \\tau \\gamma$   \n$a_{ij} = \\tau l_{ij}$                   \n$b_{ij} = \\tau r_{ij}$                      \ntotal individuals that lives in subpopulation $j$: $N_j = \\sum_i N_{ij}$            \ntotal individuals currently in subpopulation $i$:  $sumN_i = \\sum_j N_{ij}$, $sumI_i = \\sum_j I_{ij}$\n\nAnd we change the variables:\n\n$S_{ii} = N_i x_{ii}$,\n$S_{ij} = N_j x_{ij}$,\n$I_{ii} = N_i y_{ii}$,\n$I_{ij} = N_j y_{ij}$,\n$R_{ii} = N_i z_{ii}$,\n$R_{ij} = N_j z_{ij}$,\n\n\nThis results in the ODE:\n\n$\\frac{\\mathrm{d}x_{ii}}{\\mathrm{d}t}= - \\rho x_{ii} \\frac{sumI_i}{sumN_i} - \\sum_j a_{ji} x_{ii} + \\sum_j b_{ji} x_{ji}$          \n$\\frac{\\mathrm{d}x_{ij}}{\\mathrm{d}t}= - \\rho x_{ij} \\frac{sumI_i}{sumN_i} + a_{ij} x_{jj} - b_{ij} x_{ij}$           \n$\\frac{\\mathrm{d}y_{ii}}{\\mathrm{d}t}= + \\rho x_{ii} \\frac{sumI_i}{sumN_i} - \\sigma y_{ii} - \\sum_j a_{ji} y_{ii} + \\sum_j b_{ji} y_{ji}$          \n$\\frac{\\mathrm{d}y_{ij}}{\\mathrm{d}t}= + \\rho x_{ij} \\frac{sumI_i}{sumN_i} - \\sigma y_{ij} + a_{ij} y_{jj} - b_{ij} y_{ij}$           \n$\\frac{\\mathrm{d}z_{ii}}{\\mathrm{d}t}= + \\sigma y_{ii} - \\sum_j a_{ji} z_{ii} + \\sum_j b_{ji} z_{ji}$               \n$\\frac{\\mathrm{d}z_{ij}}{\\mathrm{d}t}= + \\sigma y_{ij} + a_{ij} z_{jj} - b_{ij} z_{ij}$             \n\nThe range of variables and parameters :  \n$0 < (x_{ij}, y_{ij}, z_{ij}, \\rho, \\sigma, a_{ij}, b_{ij}) < 1$  for all $i,j$.\n$1\\leq \\tau \\leq 1440$  \n"},{"metadata":{},"cell_type":"markdown","source":"### Hyperparameter optimization"},{"metadata":{},"cell_type":"markdown","source":"I must create the dataset, because it is not obtained from n_cov directly ..."},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef create_target_uscensus_df(ncov_df, subpopulation_total, subpopulation_name, start_date=None):\n    \"\"\"\n    Select the records of the places, calculate the number of susceptible people,\n     and calculate the elapsed time [day] from the start date of the target dataframe.\n    @ncov_df <pd.DataFrame>: the clean data\n    @initials_total_subpopulations <array[int]>: total population in each subpopulation\n    @kwargs: keword arguments of select_area()\n    @return <tuple(2 objects)>:\n        - 1. first_date <pd.Timestamp>: the first date of the selected records\n        - 2. target_df <pd.DataFrame>:\n            - column T: elapsed time [min] from the start date of the dataset\n            - column Susceptible: the number of patients who are in the palces but not infected/recovered/died\n            - column Infected: the number of infected cases\n            - column Recovered: the number of recovered cases\n            - column Deaths: the number of death cases\n    SUPONE Hay registros de todas las provincias en todos los dias\n    \"\"\"\n    province_name= []\n    for k, v in subpopulation_mapper.items():\n        if v!=\"-\":\n            province_name.append(k)\n    \n    df = ncov_df[(ncov_df['Country']=='US') & ncov_df['Province'].isin(province_name)].copy() #solo US y las provincias deseadas\n    df = df[df['Date'] >= start_date] #despues de la fecha\n    df['sp'] = [ subpopulation_mapper[d] for d in df['Province'] ]\n    df = df.groupby([\"Date\",\"sp\"]).sum()\n    df = df.reset_index()\n    #display(df)\n    first_date = df.loc[df.index[0], \"Date\"]\n    # column T\n    df[\"T\"] = ((df[\"Date\"] - first_date).dt.total_seconds() / 60).astype(int)\n    response_variables = [\"Infected\", \"Recovered\", \"Deaths\"]\n    df = df.loc[:, [\"T\", \"sp\", *response_variables]]\n    target_df = pd.DataFrame()\n    for sp in range(len(subpopulation_name)):\n        #pprint( str(sp) + \" - \" + subpopulation_name[sp] + \" - \" + str(subpopulation_total[sp]))\n        target_df_sp =  df.loc[df[\"sp\"]==subpopulation_name[sp], [\"T\", *response_variables]].copy()\n        target_df_sp[\"Susceptible\"] =  int(subpopulation_total[sp]) - target_df_sp[\"Infected\"] - target_df_sp[\"Recovered\"] - target_df_sp[\"Deaths\"]\n        target_df_sp.columns = str(sp) +\"@\" + target_df_sp.columns\n        target_df_sp.rename(columns={str(sp) +'@T': 'T'}, inplace=True)\n        #display(target_df_sp)\n        if len(target_df)>0:\n            target_df = pd.merge(target_df, target_df_sp, on=\"T\")\n        else:\n            target_df = target_df_sp\n    return (first_date, target_df)\n\n\ntau = 1440\nsubpopulation_total = np.array([subpopulation_dict[sp] for sp in subpopulation_name]) #poblacion total \n\n# funcion basica que filtra el dataset ncov_df, y crea un dataset ficticio norte/sur\nstart_date, target_df = create_target_uscensus_df(\n    ncov_df,  subpopulation_total, subpopulation_name, start_date=uy_country_start\n)\npprint([subpopulation_name, subpopulation_total, start_date.strftime(time_format)])\ndisplay(target_df)\n\ndisplay(a_pandemia)\ndisplay(b_pandemia)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n%%time\n\nmphsir_estimator = MPEstimator(\n    MPHSIR, start_date, \n    target_df, subpopulation_total, subpopulation_name,\n    tau=tau, a=a_pandemia, b=b_pandemia, N=subpopulation_total) #parametros fijos\nmphsir_dict = mphsir_estimator.run(n_trials)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(mphsir_estimator.compare_df())\n\ndisplay(mphsir_estimator.history_df().head())\n\nmphsir_estimator.history_graph()\n\ndisplay(pd.DataFrame.from_dict({\"MPHSIR\": mphsir_dict}, orient=\"index\"))\n\nmphsir_estimator.compare_graph()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mphsir_estimator.predict_graph(step_n=400)\n\ndf = mphsir_estimator.predict_df(400)\ndisplay(df.loc[datetime.today():, :].head(14).style.background_gradient(axis=0))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusion: Models comparision"},{"metadata":{},"cell_type":"markdown","source":"### Parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"display(pd.DataFrame.from_dict({\"SIR\": sir_dict, \n                                \"SIR-D\": sird_dict, \n                                \"SIR-F\": sirf_dict, \n                                #\"SEWIR-F\": sewirf_dict, \n                                \"MPHSIR\": mphsir_dict\n                               }, orient=\"index\").fillna(\"-\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plots"},{"metadata":{"trusted":true},"cell_type":"code","source":"sir_estimator.predict_graph(400)\nsird_estimator.predict_graph(400)\nsirf_estimator.predict_graph(400)\n#sewirf_estimator.predict_graph(400)\nmphsir_estimator.predict_graph(400)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"real_data = ncov_df.loc[(ncov_df['Country']==uy_country), [\"Date\",\"Infected\"]].groupby(\"Date\").sum()\nreal_data = real_data.reset_index()\nreal_data[\"Date\"] = real_data[\"Date\"].dt.date\nreal_data.rename(columns={\"Infected\": \"Infected_real\"}, inplace=True)\n#display(real_data)\n\nsir_data = sir_estimator.predict_df(400)\nsir_data[\"Date\"] = pd.to_datetime(sir_data.index)\nsir_data[\"Date\"] = sir_data[\"Date\"].dt.date\nsir_data = pd.DataFrame([g.iloc[np.argmax(g.index)] for l, g in sir_data.groupby('Date')]) #si hay mas de un registro por fecha, me quedo con el ultimo\nsir_data.rename(columns={\"Infected\": \"Infected_sir\"}, inplace=True)\n#display(sir_data)\n\nsird_data = sird_estimator.predict_df(400)\nsird_data[\"Date\"] = pd.to_datetime(sird_data.index)\nsird_data[\"Date\"] = sird_data[\"Date\"].dt.date\nsird_data = pd.DataFrame([g.iloc[np.argmax(g.index)] for l, g in sird_data.groupby('Date')]) #si hay mas de un registro por fecha, me quedo con el ultimo\nsird_data.rename(columns={\"Infected\": \"Infected_sird\"}, inplace=True)\n#display(sird_data)\n\nsirf_data = sirf_estimator.predict_df(400)\nsirf_data[\"Date\"] = pd.to_datetime(sirf_data.index)\nsirf_data[\"Date\"] = sirf_data[\"Date\"].dt.date\nsirf_data = pd.DataFrame([g.iloc[np.argmax(g.index)] for l, g in sirf_data.groupby('Date')]) #si hay mas de un registro por fecha, me quedo con el ultimo\nsirf_data.rename(columns={\"Infected\": \"Infected_sirf\"}, inplace=True)\n#display(sirf_data)\n\n'''\ndf = sewirf_estimator.predict_df(400)\nsewirf_data = sewirf_estimator.predict_df(400)\nsewirf_data[\"Date\"] = pd.to_datetime(sewirf_data.index)\nsewirf_data[\"Date\"] = sewirf_data[\"Date\"].dt.date\nsewirf_data = pd.DataFrame([g.iloc[np.argmax(g.index)] for l, g in sewirf_data.groupby('Date')]) #si hay mas de un registro por fecha, me quedo con el ultimo\nsewirf_data.rename(columns={\"Infected\": \"Infected_sewirf\"}, inplace=True)\n#display(sewirf_data)\n'''\n\nmphsir_data = mphsir_estimator.predict_df(400)\nmphsir_data[\"Date\"] = pd.to_datetime(mphsir_data.index)\nmphsir_data[\"Date\"] = mphsir_data[\"Date\"].dt.date\nmphsir_data = pd.DataFrame([g.iloc[np.argmax(g.index)] for l, g in mphsir_data.groupby('Date')]) #si hay mas de un registro por fecha, me quedo con el ultimo\nmphsir_data.rename(columns={\"Infected\": \"Infected_mphsir\"}, inplace=True)\n#display(mphsir_data)\n\n\njoin_data = pd.merge(real_data, sir_data[[\"Date\",\"Infected_sir\"]], how='inner', on=[\"Date\"])\njoin_data = pd.merge(join_data, sird_data[[\"Date\",\"Infected_sird\"]], how='inner', on=[\"Date\"])\njoin_data = pd.merge(join_data, sirf_data[[\"Date\",\"Infected_sirf\"]], how='inner', on=[\"Date\"])\n#join_data = pd.merge(join_data, sewirf_data[[\"Date\",\"Infected_sewirf\"]], how='inner', on=[\"Date\"])\njoin_data = pd.merge(join_data, mphsir_data[[\"Date\",\"Infected_mphsir\"]], how='inner', on=[\"Date\"])\njoin_data[\"Date\"] =  pd.to_datetime(join_data[\"Date\"])\njoin_data = join_data.set_index(\"Date\")\n\ndisplay(join_data)\nline_plot(join_data, \"Comparación\", math_scale=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}