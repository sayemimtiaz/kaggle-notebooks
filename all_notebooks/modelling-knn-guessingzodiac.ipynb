{"cells":[{"metadata":{},"cell_type":"markdown","source":"In this capstone, you will create a presentation about your findings in this OkCupid dataset.\n\nThe purpose of this capstone is to practice formulating questions and implementing Machine Learning techniques to answer those questions. We will give you guidance about the kinds of questions we asked, and the kinds of methods we used to answer those questions. But the questions you ask and how you answer them are entirely up to you. We’re excited to see what kinds of different things you explore. Compared to the other projects you have completed this far, we are requiring few restrictions on how you structure your code. The project is far more open-ended, and you should use your creativity. In addition, much of the code you write for later parts of this project will depend on how you decided to implement earlier parts. Therefore, we strongly encourage you to read through the entire assignment before writing any code.\n\nThe dataset provided has the following columns of multiple-choice data:\n\nbody_type\ndiet\ndrinks\ndrugs\neducation\nethnicity\nheight\nincome\njob\noffspring\norientation\npets\nreligion\nsex\nsign\nsmokes\nspeaks\nstatus\nAnd a set of open short-answer responses to :\n\nessay0 - My self summary\nessay1 - What I’m doing with my life\nessay2 - I’m really good at\nessay3 - The first thing people usually notice about me\nessay4 - Favorite books, movies, show, music, and food\nessay5 - The six things I could never do without\nessay6 - I spend a lot of time thinking about\nessay7 - On a typical Friday night I am\nessay8 - The most private thing I am willing to admit\nessay9 - You should message me if…","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\nprofiles = pd.read_csv('/kaggle/input/profiles.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_columns', None)\ndisplay(profiles.head(5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Total rows:',profiles.shape[0])\nprint('Total columns:',profiles.shape[1])\n# print('breakdown of column types:')\n# print(profiles.dtypes.value_counts())\nprint(len(profiles.select_dtypes('int64').columns),'numerical columns(integer):',list(profiles.select_dtypes('int64').columns))\nprint(len(profiles.select_dtypes('float64').columns),'numerical columns(float):',list(profiles.select_dtypes('float64').columns))\nprint(len(profiles.select_dtypes('object').columns),'categorical columns:',list(profiles.select_dtypes('object').columns))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#inspect essay questions\nmeaning = dict({'essay0' : 'My self summary',\n'essay1' : 'What I’m doing with my life',\n'essay2' : 'I’m really good at',\n'essay3' : 'The first thing people usually notice about me',\n'essay4' : 'Favorite books, movies, show, music, and food',\n'essay5' : 'The six things I could never do without',\n'essay6' : 'I spend a lot of time thinking about',\n'essay7' : 'On a typical Friday night I am',\n'essay8' : 'The most private thing I am willing to admit',\n'essay9' : 'You should message me if…'})\n\nobjects = profiles.select_dtypes('object').nunique().sort_values(ascending=False).reset_index()\nsummary = objects[objects['index'].str.contains('essay')]\nsummary['meaning'] = summary['index'].map(meaning)\nsummary[0] = summary[0]/len(profiles)\nsummary[['index','meaning',0]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* 90% of people answered essay 0, followed by essay 1 (usually just **things you do**)\n* Obviously, 65% of people answered essay 8. (usually **private thoughts, self-critic**)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#inspect non-essay questions\nobjects = profiles.select_dtypes('object').nunique().sort_values(ascending=False).reset_index()\nnon_essay = [i for i in list(objects['index']) if not 'essay' in i]\nprofiles[non_essay].nunique()\n# summary","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#numeric data & clean it up\nnumeric = profiles._get_numeric_data()\nnumeric.describe() #found income has -1\nnumeric.income = numeric.income.replace({-1:np.nan})\nprofiles.income = profiles.income.replace({-1:np.nan})\nnumeric.height = numeric.height.replace({1:np.nan})\nprofiles.height = profiles.height.replace({1:np.nan})\nnumeric.describe() #found income has -1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot numeric data\nplt.figure(figsize=[26,5])\nk=1\nfor i in list(numeric.columns):\n    plt.subplot(1,len(list(numeric.columns)),k)\n    plt.hist(numeric[i], bins=40,label=i)\n    plt.axvline(x=numeric[i].mean(),color='red',label='mean')\n    plt.axvline(x=numeric[i].median(),color='green',label='median')\n    plt.xlabel(i)\n    plt.ylabel(\"Frequency\")\n    plt.legend()\n    k+=1\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Dating app consists disproportionate young people\n* Height mostly between 60-70inches\n* Income mostly below 10k","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Task: Predict Zodiac signs, using some columns\nAs we started to look at this data, we started to get more and more curious about Zodiac signs. First, we looked at all of the possible values for Zodiac signs:\n\nWe started to wonder if there was a way to predict a user’s Zodiac sign from the information in their profile. Thinking about the columns we had already explored, we thought that maybe we could classify Zodiac signs using drinking, smoking, drugs, and essays as our features.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"profiles['sign_new'] = profiles.sign.str.split(' ').str.get(0)\n\nsign_dict = dict(\n{'leo':0,\n'gemini':1,\n'libra':2,\n'cancer':3,\n'virgo':4,\n'taurus':5,\n'scorpio':6,\n'aries':7,\n'pisces':8,\n'sagittarius':9,\n'aquarius':10,\n'capricorn':11,})\nprofiles['sign_num'] = profiles['sign_new'].map(sign_dict)\nprofiles['sign_num'].value_counts()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_col = ['sign_num','drinks','smokes','drugs'] + list(objects[objects['index'].str.contains('essay')]['index'])\nzodiac = profiles[x_col]\nfor i in ['drinks','smokes','drugs']:\n    print(i,zodiac[i].unique())\n    \nzodiac.drugs = zodiac.drugs.map({'never':0,'sometimes':1,'often':2})\nzodiac.smokes = zodiac.smokes.map({'no':0,'when drinking':1,'sometimes':2,'yes':3,'trying to quit':4})\nzodiac.drinks = zodiac.drinks.map({'not at all':0,'rarely':1,'socially':2,'often':3,'very often':4,'desperately':5})\n\ndisplay(zodiac[['drinks','smokes','drugs']].describe())\n#plot numeric data\nplt.figure(figsize=[26,5])\nk=1\nfor i in ['drinks','smokes','drugs']:\n    plt.subplot(1,3,k)\n    plt.hist(zodiac[i],label=i)\n    plt.axvline(x=zodiac[i].mean(),color='red',label='mean')\n    plt.axvline(x=zodiac[i].median(),color='green',label='median')\n    plt.xlabel(i)\n    plt.ylabel(\"Frequency\")\n    plt.legend()\n    k+=1\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Average person **drinks socially, never smokes, never do drugs**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"zodiac[list(objects[objects['index'].str.contains('essay')]['index'])]\nfor i in list(objects[objects['index'].str.contains('essay')]['index']):\n    split = zodiac[i].str.split(' ')\n    length = [len(i) if type(i)==list else 0 for i in split ]\n    zodiac[i+'_length'] = length\nlength_col = [i for i in list(zodiac.columns) if 'length' in i]\nzodiac[length_col].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = zodiac['sign_num']\ny = zodiac['essay7_length']\nplt.figure(figsize=[13,7])\nsns.boxplot(x,y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* essay 0 length does not seems to differ much from zodiacs","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#use knn\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.impute import SimpleImputer\n\nzodiac = zodiac.dropna()\ny = zodiac.sign_num\nx = zodiac.drop(columns=['sign_num']+list(objects[objects['index'].str.contains('essay')]['index']))\n\ndef missing_values_table(df):\n    mis_val=df.isnull().sum()    \n    mis_val_perc=100*df.isnull().sum()/len(df)\n    mis_val_table=pd.concat([mis_val, mis_val_perc], axis=1) \n    mis_val_table_ren_columns = mis_val_table.rename(columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n    mis_val_table_ren_columns = mis_val_table_ren_columns[mis_val_table_ren_columns.iloc[:,1] != 0].sort_values('% of Total Values', ascending=False).round(1)\n    print (\"Your selected data frame has \" + str(df.shape[1]) + \" columns.\\n\"+\"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n \" columns that have missing values.\")\n    return mis_val_table_ren_columns\n\nmiss = missing_values_table(x)\nmiss.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x, y, train_size = 0.8, test_size = 0.2, random_state = 6)\n\n#impute x_train\n# imputer = SimpleImputer(missing_values=np.nan, strategy = 'median')\n# imputer.fit(x_train)\n# x_train = imputer.transform( x_train )\n# x_test = imputer.transform (x_test )\n\n#scale \nscaler = StandardScaler()\nx_train = scaler.fit_transform(x_train)\nx_test = scaler.transform(x_test)\n\nprint(x_train.shape)\nprint(y_train.shape)\nprint(x_test.shape)\nprint(y_test.shape)\n\nmin_ = 1\nmax_ = 100\nscore = []\nfor i in range(min_,max_):\n    classifier = KNeighborsClassifier(i)\n    classifier.fit(x_train, y_train)\n    score.append(classifier.score(x_test, y_test))\nplt.plot(list(range(min_,max_)),score)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The accuracy is 9%. I am not impressed, mean guess is 1/12 = 8.3%.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Things to explore: \nUse Classification Techniques\nWe have learned how to perform classification in a few different ways.\n\nWe learned about K-Nearest Neighbors by exploring IMDB ratings of popular movies\nWe learned about Support Vector Machines by exploring baseball statistics\nWe learned about Naive Bayes by exploring Amazon Reviews\nSome questions we used classification to tackle were:\n\nCan we predict sex with education level and income??\nCan we predict education level with essay text word counts?\nUse Regression Techniques\nWe have learned how to perform Multiple Linear Regression by playing with StreetEasy apartment data. Is there a way we can apply the techniques we learned to this dataset?\n\nSome questions we used regression to tackle were:\n\nPredict income with length of essays and average word length?\nPredict age with the frequency of “I” or “me” in essays?\nWe also learned about K-Nearest Neighbors Regression. Which form of regression works better to answer your question?","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}