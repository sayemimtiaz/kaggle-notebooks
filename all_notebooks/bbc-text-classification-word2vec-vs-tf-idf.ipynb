{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h1><font color='dark green'>BBC-text-classification</font></h1>\n\n<a href='https://www.linkedin.com/in/rocky-jagtiani-3b390649/'>Myself </a> , along with some of my students at <a href='https://datascience.suvenconsultants.com' >Suven Data Science programme</a> have made many such notebooks to check and enchance our skills in NLP using Machine Learning.\n\n> This is a simple Data science project on **`multi-class text classification`** to predict the category a news article belongs to. **Our Hypothesis is  : Does the type of Vectorizing Process (Word2Vec  vs. TfidfVectorizer ) influence the precision , accuracy , recall score of the classifiers ? If yes, who wins !!**\n\n> **Tech Stack used** : Python, Scikit-Learn, NLTK, Keras, Pandas, Seaborn, NumPy\n\n> Data : Have used the data aviable in kaggle.com itself : bbc-fulltext-and-category/bbc-text.csv","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"## importing all libraries\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport re\nimport nltk\nnltk.download('punkt')\nnltk.download('stopwords')\nnltk.download('wordnet')\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\n\n## Case 1 : Would use Word2Vec and then apply different classifiers\nfrom gensim.models import Word2Vec  \n\n## Case 2 : Would use TfidfVectorizer and then apply different classifiers\nfrom sklearn.feature_extraction.text import TfidfVectorizer   \n\n## This would help us understand : Does the type of Vectorizing Process influence the precision , accuracy , recall score of the classifiers ??\n\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read data frame\nfile_url = '/kaggle/input/bbc-fulltext-and-category/bbc-text.csv'\ndf = pd.read_csv(file_url)\n\n## Doing basic EDA ( Exploratory Data Analysis )\n\n# Description of the dataset\nprint('SHAPE OF DATASET: ', df.shape, '\\n\\nCOLUMNS IN DATASET: ', df.columns, '\\n\\nCATEGORIES: ', df.category.unique(), '\\n\\nDATA SAMPLE: \\n\\n', df.sample(n=5), '\\n\\n')\n\n# Plotting number of samples within each category\nprint('NUMBER OF SAMPLES IN EACH CATEGORY: \\n')\nsns.countplot(df.category)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Note :** Data set seems balanced.  Just in case if it was highly imbalanced say any one category had more than 50% entries then , we could have used SMOTHE (Synthetic Minority Over-sampling Technique) over the Minor classes and undersampling of Major class.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# DATA CLEANING\nprint('Data cleaning in progress...')\n\n# Tokenize : dividing Sentences into words\ndf['text_clean'] = df['text'].apply(nltk.word_tokenize)\nprint('Tokenization complete.')\n\n\n# Remove stop words\nstop_words=set(nltk.corpus.stopwords.words(\"english\"))\ndf['text_clean'] = df['text_clean'].apply(lambda x: [item for item in x if item not in stop_words])\nprint('Stop words removed.')\n\n\n# Remove numbers, punctuation and special characters (only keep words)\nregex = '[a-z]+'\ndf['text_clean'] = df['text_clean'].apply(lambda x: [item for item in x if re.match(regex, item)])\nprint('Numbers, punctuation and special characters removed.')\n\n\n# Lemmatization : lemma means base form of a word.  // Example : leaf and leaves get lemmatized to leaf\nlem = nltk.stem.wordnet.WordNetLemmatizer()\ndf['text_clean'] = df['text_clean'].apply(lambda x: [lem.lemmatize(item, pos='v') for item in x])\nprint('Lemmatization complete.\\nData cleaning complete.\\n')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Classification using word2vec vectorizer\n\nvec_model = Word2Vec(df['text_clean'])\n\nw2v = dict(zip(vec_model.wv.index2word, vec_model.wv.syn0))\n## What is syn0 ?\n## https://stackoverflow.com/questions/53301916/python-gensim-what-is-the-meaning-of-syn0-and-syn0norm\n\nclass Vectorizer(object):\n    \n    def __init__(self, vec):\n        self.vec = vec\n        self.dim = len(vec.values())\n\n    def fit(self, X, y):\n        return self\n\n    def transform(self, X):\n        return np.array([np.mean([self.vec[w] for w in words if w in self.vec] or [np.zeros(self.dim)], axis=0) for words in X])\n\n\n## for any Classifier , we need intialise the model with the parameters. \n## Further I am applying GridSearchCV for 5 runs (i.e 1/5th data used each time for testing) \n## So the model gets trained over 5 runs \n## as well we are predicting also over 5 runs\n## In case if you wish to know about Cross Validation , you can watch my Video here : https://www.youtube.com/watch?v=LmxsySwAhoE&t=84s\nclass Classifier(object):\n    \n    def __init__(self, model, param):\n        self.model = model\n        self.param = param\n        self.gs = GridSearchCV(self.model, self.param, cv=5, error_score=0, refit=True)        \n\n    def fit(self, X, y):        \n        return self.gs.fit(X, y)\n\n    def predict(self, X):\n        return self.gs.predict(X)\n    \n\n## Preparing to make a pipeline \n## What to know about Pipelining : see this https://www.youtube.com/watch?v=Y4iJfKX_QeQ&t=52s\nclf_models = {\n    'Naive Bayes': GaussianNB(), \n    'SVC': SVC(),\n    'Decision Tree': DecisionTreeClassifier(),  \n    'Perceptron': MLPClassifier(),\n    'Gradient Boosting': GradientBoostingClassifier()\n}\n\nclf_params = {\n    'Naive Bayes': { }, \n    'SVC': { 'kernel': ['linear', 'rbf'] },\n    'Decision Tree': { 'min_samples_split': [2, 5] }, \n    'Perceptron': { 'activation': ['tanh', 'relu'] },\n    'Gradient Boosting': { 'min_samples_split': [2, 5] }\n}\n\n\n## splitting the dataset into 80:20.  have kept shuffle=True , so that the data is randomly sampled or simply said shuffled , and then split.\nX_train, X_test, y_train, y_test = train_test_split(df['text'], df['category'], test_size=0.2, shuffle=True)\n\n## for loop traverses , each and every classifier and its corresponding parameters.\nfor key in clf_models.keys():\n    \n    clf = Pipeline([('Word2Vec vectorizer', Vectorizer(w2v)), ('Classifier', Classifier(clf_models[key], clf_params[key]))])\n    \n    clf.fit(X_train, y_train)  ## Note : we are calling user defined fit method. This fit method uses Cross Validation\n    y_pred = clf.predict(X_test)  ## Note : we are calling user defined predict method. This predict method uses Cross Validation\n    \n    ## printing performance metrics for each classifier \n    print(key, ':')\n    print(\"Accuracy: %1.3f \\tPrecision: %1.3f \\tRecall: %1.3f \\t\\tF1: %1.3f\\n\" % (accuracy_score(y_test, y_pred), precision_score(y_test, y_pred, average='macro'), recall_score(y_test, y_pred, average='macro'), f1_score(y_test, y_pred, average='macro')))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **Note** : None of the classifiers have a accuracy of classification more than 50%. Now thats horrible to say , that our ML model is misclassifying about 60% of the test data. We can't the classifier Algos. They are all popular standard algos. So what we do ????\n\n## **Solution** : Instead of gensim.models.Word2Vec , try to use sklearn.feature_extraction.text.TfidfVectorizer  \n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Classification using TFIDF vectorizer\n\n# Vectorize training and testing data. Here we would pass TfidfVectorizer() to vec \ndef Vectorize(vec, X_train, X_test):    \n    \n    X_train_vec = vec.fit_transform(X_train)\n    X_test_vec = vec.transform(X_test)\n    \n    print('Vectorization complete.\\n')\n    \n    return X_train_vec, X_test_vec\n\n\n# Use multiple classifiers and grid search for prediction\ndef ML_modeling(models, params, X_train, X_test, y_train, y_test):    \n    \n    if not set(models.keys()).issubset(set(params.keys())):\n        raise ValueError('Some estimators are missing parameters')\n\n    for key in models.keys():\n    \n        model = models[key]\n        param = params[key]\n        gs = GridSearchCV(model, param, cv=5, error_score=0, refit=True)\n        gs.fit(X_train, y_train)\n        y_pred = gs.predict(X_test)\n        \n        # Print scores for the classifier\n        print(key, ':', gs.best_params_)\n        print(\"Accuracy: %1.3f \\tPrecision: %1.3f \\tRecall: %1.3f \\t\\tF1: %1.3f\\n\" % (accuracy_score(y_test, y_pred), precision_score(y_test, y_pred, average='macro'), recall_score(y_test, y_pred, average='macro'), f1_score(y_test, y_pred, average='macro')))\n    \n    return\n\n\n## Preparing to make a pipeline \nmodels = {\n    'Naive Bayes': MultinomialNB(), \n    'Decision Tree': DecisionTreeClassifier(),  \n    'Perceptron': MLPClassifier(),\n    'Gradient Boosting': GradientBoostingClassifier()   ## This model would take a little longer to run \n}\n\nparams = {\n    'Naive Bayes': { 'alpha': [0.5, 1], 'fit_prior': [True, False] }, \n    'Decision Tree': { 'min_samples_split': [1, 2, 5] }, \n    'Perceptron': { 'alpha': [0.0001, 0.001], 'activation': ['tanh', 'relu'] },\n    'Gradient Boosting': { 'learning_rate': [0.05, 0.1], 'min_samples_split': [2, 5] }\n}\n\n\n# Encode label categories to numbers\nenc = LabelEncoder()\ndf['category'] = enc.fit_transform(df['category'])\nlabels = list(enc.classes_)\n\n# Train-test split and vectorize\nX_train, X_test, y_train, y_test = train_test_split(df['text'], df['category'], test_size=0.2, shuffle=True)\nX_train_vec, X_test_vec = Vectorize(TfidfVectorizer(), X_train, X_test)\n\nML_modeling(models, params, X_train_vec, X_test_vec, y_train, y_test)\n## ML_modeling method also prints performance scores for each classifier","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<span style=\"background-color:yellow\">Conclusion of this Ananlysis</span> : TfidfVectorizer seems to have performed far better than Word2Vec vectorizer.  So with this simple excerise , its proved that we should prefer to use TfidfVectorizer for most Text (NLP) applications.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Let's Connect :\n\nYou can connect with me on Linkedin here (https://www.linkedin.com/in/rocky-jagtiani-3b390649/) as well see our Data Science Programme here ( https://datascience.suvenconsultants.com/ ). Participate with me in my Live Google Classroom sessions, to solve simple real problems.\n\n<br>\n\nDo read <a href='https://www.linkedin.com/posts/rocky-jagtiani-3b390649_story-traditional-teacher-activity-6675014449620926464-Rsgj'> Rakhee kundu's true story </a>   -->  <b>Rakhee Kundu in below pic , being appreciated by myself ( Prof. Rocky Jagtiani - Data Science Practioner & Trainer )</b>\n\n<br>\n\n![CertificationPic_In_the_NB](https://drive.google.com/uc?id=1lLSFd1O5hrIRBIWztjBiO6RcyPwyDmyF)\n\n","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}