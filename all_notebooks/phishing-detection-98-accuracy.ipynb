{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Dataset"},{"metadata":{},"cell_type":"markdown","source":"Please Upvote if you like my work."},{"metadata":{},"cell_type":"markdown","source":"# Dataset\n\n1. Domain: The URL itself.\n2. Ranking: Page Ranking\n3. isIp: Is there an IP address in the weblink\n4. valid: This data is fetched from google's whois API that tells us more about the current\nstatus of the URL's registration.\n5. activeDuration: Also from whois API. Gives the duration of the time since the\nregistration up until now.\n6. urlLen: It is simply the length of the URL\n7. is@: If the link has a '@' character then it's value = 1\n8. isredirect: If the link has double dashes, there is a chance that it is a redirect. 1-> multiple\ndashes present together.\n9. haveDash: If there are any dashes in the domain name.\n10. domainLen: The length of just the domain name.\n11. noOfSubdomain: The number of subdomains preset in the URL.\n12. Labels: 0 -> Legitimate website , 1 -> Phishing Link/ Spam Link"},{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport re\nimport string\nfrom wordcloud import WordCloud, STOPWORDS\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom scipy.sparse import vstack\nimport datetime\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom scipy.sparse import hstack\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_file = pd.read_csv('/kaggle/input/phishing-data/combined_dataset.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_file.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking for null values\ndata_file.isna().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking the distribution of data\nprint(data_file['label'].value_counts())\nprint(data_file.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Cleaning and preprocessing of Questions"},{"metadata":{},"cell_type":"markdown","source":"### Preprocessing"},{"metadata":{},"cell_type":"markdown","source":"1. Remove Spcial characters from domain and space in between them\n2. Convert all the characters into small letters"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef remove_characters(row):\n    chars = re.escape(string.punctuation)\n    return re.sub(r'['+chars+']', ' ',row)\n\ndata_file['domain'] = data_file['domain'].apply(remove_characters)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_file.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating string for Wordcloud of 'domain' tokens\ncomment_words = '' \nstopwords = set(STOPWORDS) \nfor val in data_file['domain']: \n      \n    # typecaste each val to string \n    val = str(val) \n  \n    # split the value \n    tokens = val.split() \n      \n    # Converts each token into lowercase \n    for i in range(len(tokens)): \n        tokens[i] = tokens[i].lower() \n      \n    comment_words += \" \".join(tokens)+\" \"\n  \nwordcloud = WordCloud(width = 800, height = 800, \n                background_color ='white', \n                stopwords=stopwords,\n                min_font_size = 10).generate(comment_words)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot the WordCloud image                        \nplt.figure(figsize = (8, 8), facecolor = None) \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0)\nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_file.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_file_x = data_file.drop(['label'], axis=1)\ndata_file_y = data_file['label']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dividing the dataset into train, val and test datasets\ntrain_df_x = data_file_x[:60000]\ntrain_df_y = data_file_y[:60000]\nval_df_x = data_file_x[60000:78000]\nval_df_y = data_file_y[60000:78000]\ntest_df_x = data_file_x[78000:]\ntest_df_y = data_file_y[78000:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_domain = train_df_x['domain']\nval_domain = val_df_x['domain']\ntest_domain = test_df_x['domain']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Drop 'domain' from dataset since we are converting it into bag of words\ntrain_df_x = train_df_x.drop(['domain'], axis=1)\nval_df_x = val_df_x.drop(['domain'], axis=1)\ntest_df_x = test_df_x.drop(['domain'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_df_x.shape, val_df_x.shape, test_df_x.shape)\nprint(train_df_y.shape, val_df_y.shape, test_df_y.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Bag Of Words"},{"metadata":{"trusted":true},"cell_type":"code","source":"count_vect = CountVectorizer()\nX_train_bow = count_vect.fit_transform(train_domain)\nX_val_bow = count_vect.transform(val_domain)\nX_test_bow = count_vect.transform(test_domain)\nfeature_names_bow = count_vect.get_feature_names()\nprint(X_train_bow.shape)\nprint(X_val_bow.shape)\nprint(X_test_bow.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Stacking the BoW features and other features from dataset\nbow_final_train_x = hstack((X_train_bow, train_df_x))\nbow_final_val_x = hstack((X_val_bow, val_df_x))\nbow_final_test_x = hstack((X_test_bow, test_df_x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Final shape of dataset will be 75926 features of domain plus 10 features of dataset. Therefore 75936 features\nbow_final_train_x.shape\nbow_final_val_x.shape\nbow_final_test_x.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Random Forest on Bag Of Words dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_val = vstack((bow_final_train_x, bow_final_val_x))\nY_train_val = pd.concat([train_df_y, val_df_y], axis= 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"param_grid = {\n 'max_depth': [4, 8, 16, 32],\n 'n_estimators': [1, 2, 5, 10, 50, 100, 200]\n}\nt1 = datetime.datetime.now()\nrf = RandomForestClassifier(n_jobs=-1)\nclf = GridSearchCV(estimator = rf, param_grid = param_grid, scoring = 'roc_auc')\nclf.fit(X_train_val,Y_train_val)\nprint(\"time required = \", datetime.datetime.now() - t1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_clf = RandomForestClassifier(max_depth = clf.best_params_['max_depth'], \n                                n_estimators=clf.best_params_['n_estimators'])\nrf_clf.fit(X_train_val,Y_train_val)\nbow_test_proba = rf_clf.predict_proba(bow_final_test_x)\nbow_train_proba = rf_clf.predict_proba(X_train_val)\nprint(\"Train proba\", bow_train_proba)\nprint(\"Test proba\", bow_test_proba)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Top 20 Important Features\")\nd = sorted(list(zip(count_vect.get_feature_names(), rf_clf.feature_importances_ )), key=lambda x: x[1], reverse=True)[:20]\nfeatures_list = []\nfor (i,j) in d:\n    features_list.append(i)\nprint(features_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#calculatinf the AUC\nbow_fpr_train, bow_tpr_train, _ = roc_curve(Y_train_val, bow_train_proba[:, 1])\nbow_fpr_test, bow_tpr_test, _ = roc_curve(test_df_y, bow_test_proba[:, 1])\nbow_test_auc = auc(bow_fpr_test, bow_tpr_test)\nbow_train_auc = auc(bow_fpr_train, bow_tpr_train)\nprint(\"Train AUC\", bow_train_auc)\nprint(\"Test AUC\", bow_test_auc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pylab\nplt.figure(figsize=(13, 10))\nplt.plot([0,1], [0,1], color='black', lw=2, linestyle='--')\nplt.plot(bow_fpr_test, bow_tpr_test, label=\"Test, auc=\"+str(bow_test_auc), color = 'red')\nplt.plot(bow_fpr_train, bow_tpr_train, label=\"Train, auc=\"+str(bow_train_auc), color = 'green')\n\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Making predictions\nbow_test_conf = rf_clf.predict(bow_final_test_x)\nbow_train_conf = rf_clf.predict(X_train_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Confusion Matrix and classification report\nbow_train_conf_matrix = confusion_matrix(Y_train_val, bow_train_conf)\nbow_test_conf_matrix = confusion_matrix(test_df_y, bow_test_conf)\nclass_report = classification_report(test_df_y, bow_test_conf)\nprint(bow_test_conf_matrix)\nprint(class_report)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train Confusion Matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"ax= plt.subplot()\nsns.heatmap(bow_train_conf_matrix, annot=True, ax = ax, fmt='g')\nax.set_ylabel('Predicted labels')\nax.set_xlabel('True labels')\nax.set_title('Train Confusion Matrix') \nax.xaxis.set_ticklabels(['negative', 'positive']) \nax.yaxis.set_ticklabels(['negative', 'positive'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Test Confusion Matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"ax= plt.subplot()\nsns.heatmap(bow_test_conf_matrix, annot=True, ax = ax, fmt='g')\nax.set_ylabel('Predicted labels')\nax.set_xlabel('True labels')\nax.set_title('Train Confusion Matrix') \nax.xaxis.set_ticklabels(['negative', 'positive']) \nax.yaxis.set_ticklabels(['negative', 'positive'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from prettytable import PrettyTable\n    \nx = PrettyTable()\nx.field_names = [\"Algorithm\", \"Max_depth\", \"n_estimators\",  \"Vectorizer\", \"Train\", \"Test\"]\n\nx.add_row([\"Random Forest\", 32, 200, \"BoW\", 0.98914, 0.9875])\nprint(x)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}