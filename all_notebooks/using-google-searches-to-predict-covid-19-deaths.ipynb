{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n# Importing libs\nimport pandas as pd\nimport numpy as np\nimport matplotlib\nimport matplotlib.dates as mdates\nimport matplotlib.pyplot as plt\nfrom textwrap import wrap\nimport seaborn as sns\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport plotly as py\nimport plotly.graph_objs as go\nimport os\npy.offline.init_notebook_mode(connected = True)\n#print(os.listdir(\"../input\"))\nimport datetime as dt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **COVID-19**\n\nCOVID-19 has, without exaggeration, changed the world. \n\nWith the first reported case in late 2019, over a year later the world is still gripped by this virus.\n\nThe main symptoms of coronavirus (COVID-19) are:\n\n* A high temperature – this means you feel hot to touch on your chest or back (you do not need to measure your temperature)\n\n* A new, continuous cough – this means coughing a lot for more than an hour, or 3 or more coughing episodes in 24 hours (if you usually have a cough, it may be worse than usual)\n\n* A loss or change to your sense of smell or taste – this means you've noticed you cannot smell or taste anything, or things smell or taste different to normal\n\n\nGiven the information available on the internet, it seems reasonable that people often head to Google to search for various symptoms if they are feeliung unwell. This is the basis for this notebook.\n\n# **Problem statement**\n\n# **Can we look at data from Google Trends to see when a new wave of cases or deaths is about to arise?**\n\nI will primarily be focusing on deaths because cases are dependent upon testing levels, and this has varied wildly through the course of this pandemic globally, while deaths are recorded with much higher certainty.\n\nAn important note: **I will not be attempting to predict exact numbers** of deaths or cases. Rather, I will be investigating whether or not Google searches could act as an early warning sign for an imminent increase in cases & deaths.\n\n\n # **Why does this matter?**\n\nThis could be important for governments and local health authorities around the world, **particularly if a given country does not have adequate COVID-19 testing facilities** to be able to track the spread of the virus. \n\nA government or local health authority **could monitor Google searches for a variety of key words or phrases**, for instance all symptoms associated with COVID-19, and perhaps those associated with similar viruses such as Influenza, and if an increase in any of those search terms is detected, **action could be taken to mitigate further spread, and to prepare for a potential increase in hospitalisations**.\n\n\n\n# Project Plan\n\nThe steps I plan to follow during this project are:\n\n* Initial import of data, with brief cleaning & feature engineering\n\n* A plot of deaths throughout the pandemic globally\n\n* A focus on the UK's deaths\n\n* Include Excess Deaths as a measure to provide context\n\n* Introduce Google Search data for COVID-19 symptoms. I'll use \"Loss of taste\" but this could be expanded\n","metadata":{}},{"cell_type":"markdown","source":"# Inspiration\n\nThis is not an origianl peice of research, although I am not aware of it being applied specifiaclly to the United Kingom.\n\nI found an interesting paper by Tado Jurić on 'medrxiv.org', which focused on search terms such as \"PCR +Covid”, “PCR + test”, and symptoms “cough + corona”, “pneumonia + corona”; “muscle pain + corona” in Croatia. This got me thinking, and I wanted to investiagate.\n\nhttps://www.medrxiv.org/content/10.1101/2021.03.12.21253452v1.full\n\nI think this is a really interesting topic with a lot of **potential for all sorts of projects.**","metadata":{}},{"cell_type":"markdown","source":"# The data\n\nI will be using various COVID-19 datasets uploaded on to Kaggle (special thanks to the contributors of those datasets), along with some data pulled from the 'Our World in Data' github (https://github.com/owid)\n\nFor Google Search terms, I will use data downloaded from Google Trends.\n\nTo understand how Google Trends works, here is a link to the FAQ page:\n\nhttps://support.google.com/trends/answer/4365533?hl=en\n\nResults from Google Trends are normalized\n\nHow is Google Trends data normalized?\n\nGoogle Trends normalizes search data to make comparisons between terms easier. Search results are normalized to the time and location of a query by the following process:\n\n* Each data point is divided by the total searches of the geography and time range it represents to compare relative popularity. Otherwise, places with the most search volume would always be ranked highest.\n\n* The resulting numbers are then scaled on a range of 0 to 100 based on a topic’s proportion to all searches on all topics.\n\n* Different regions that show the same search interest for a term don't always have the same total search volumes.","metadata":{}},{"cell_type":"code","source":"daily = pd.read_csv('https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/owid-covid-data.csv')\npop = pd.read_csv('/kaggle/input/corona-virus-report/worldometer_data.csv')\nlatest = pd.read_csv('/kaggle/input/corona-virus-report/country_wise_latest.csv')\nmort = pd.read_csv('https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/excess_mortality/excess_mortality.csv')\ntrend_june = pd.read_csv('/kaggle/input/google-trends/2020_June .csv')\ntrend_2020 = pd.read_csv('/kaggle/input/google-trends/2020_trend.csv')\n\n\n# Correct date formats\ndaily[\"date\"] = pd.to_datetime(daily[\"date\"], format = '%Y-%m-%d')\ndaily['year'], daily['month'] = daily['date'].dt.year, daily['date'].dt.month\n\nmort[\"date\"] = pd.to_datetime(mort[\"date\"], format = '%Y-%m-%d')\nmort['year'], mort['month'] = mort['date'].dt.year, mort['date'].dt.month\n\ntrend_2020[\"Week\"] = pd.to_datetime(trend_2020[\"Week\"], format = '%d/%m/%Y')\ntrend_2020['year'], trend_2020['month'] = trend_2020['Week'].dt.year, trend_2020['Week'].dt.month\n\ntrend_june[\"Week\"] = pd.to_datetime(trend_2020[\"Week\"], format = '%d%m/%Y')\ntrend_june['year'], trend_june['month'] = trend_june['Week'].dt.year, trend_june['Week'].dt.month\n\nmort = mort.replace([np.inf, -np.inf], np.nan)\nmort = mort.fillna(0)\n\nuk = mort[(mort['location'] == 'United Kingdom') & (mort['year'] < 2021)]\n\nall_daily = daily.groupby(['date','date'])['new_cases_smoothed'].sum()\n\n# latest[latest['Country/Region'].str.contains('United')]\n# daily[daily['location'].str.contains('United K')]\n\nuk_daily = daily[daily['location'] == 'United Kingdom']\n\n# formats\n\nbackground_color = 'white'\nother = '#144082'\nCOLOR = '#323232'\nplt.rcParams['text.color'] = '#323232'\nplt.rcParams['axes.labelcolor'] = COLOR\nplt.rcParams['xtick.color'] = COLOR\nplt.rcParams['ytick.color'] = COLOR\nplt.rcParams[\"font.family\"] = \"sansserif\"\nplt.rcParams['xtick.labelsize'] = 12\nplt.rcParams['ytick.labelsize'] = 12","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Overview\n\nThe pandemic has varied in intensity across the continents. However one can say that, as 2020 progressed, the intensity of the pandemic did too.\n\nMost continents experienced a peak in daily deaths during late 2020 and early 2021.\n\nI will draw attention to Europe in this plot, as this notebook will go on to focus on Google searches in the United Kingdom.","metadata":{}},{"cell_type":"code","source":"temp_daily = daily.groupby(['date','continent'])['new_cases_smoothed'].sum().unstack()[:-1]\n\nfig = plt.figure(figsize=(10, 4), dpi=150,facecolor=background_color)\ngs = fig.add_gridspec(1, 1)\ngs.update(wspace=0, hspace=0)\nax0 = fig.add_subplot(gs[0, 0])\nax0.set_facecolor(background_color)\n\nfor i in temp_daily.columns:\n    sns.lineplot(x='date',y=i,data=temp_daily,color='gray',ax=ax0)\nsns.lineplot(x='date',y='Europe',data=temp_daily,color='#0f4c81',ax=ax0)\n\n\nXstart, Xend = ax0.get_xlim()\nYstart, Yend = ax0.get_ylim()\n\nax0.set_ylim([0,Yend])\nax0.set_xlim(Xstart,Xend-1)\nax0.set_ylabel(\"Daily Deaths\",fontsize=8,loc='top')\nax0.set_xlabel(\" \",fontsize=8,loc='left')\nax0.tick_params(axis = \"both\", which = \"both\", left=False, bottom=False)\n\n\nplt.setp(ax0.xaxis.get_majorticklabels(), rotation = 0)\nlocator = mdates.AutoDateLocator(minticks=3, maxticks=12)\nformatter = mdates.ConciseDateFormatter(locator)\nax0.xaxis.set_major_locator(locator)\nax0.xaxis.set_major_formatter(formatter)\nax0.get_yaxis().set_major_formatter(matplotlib.ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n\nfor s in [\"right\", \"top\"]:\n    ax0.spines[s].set_visible(False)\n\nfor s in [\"left\",\"bottom\"]:\n    ax0.spines[s].set_color(COLOR)\n    \n\nfor i in temp_daily.columns:\n    ax0.plot(Xend-25,temp_daily[i][-1], 'ko', markersize=5, fillstyle='full',color='gray', markeredgewidth=1.5)\n    ax0.text(Xend-10,temp_daily[i][-1],i,color='gray',fontweight='light',fontsize=8, rotation=0)\n    \n# highlight Europe\nax0.plot(Xend-25,temp_daily['Europe'][-1], 'ko', markersize=5, fillstyle='full',color='#0f4c81', markeredgewidth=1.5)\nax0.text(Xend-10,temp_daily['Europe'][-1],'Europe',color='#0f4c81',fontweight='light',fontsize=8, rotation=0)\n\nax0.text(Xstart,Yend+50000,'Daily deaths by continent',fontsize=20,fontweight='bold')\n\n\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As mentioned above, late 2020 and early 2021 have been bad across the globe.\n\nIndia is experiencing a particularly sharp upsurge in both cases & deaths at the moment, contributing to the sharp increase in daily deaths observed in Asia. I continue to hope that it slows there and things improve soon.\n\nI'll now **focus on the United Kingdom**, where currently deaths are very low, and a world leading vaccination programme seems to be making a huge difference in redcing both cases and deaths.\n\nHowever, at the peak of the pandemic in the UK, in January 2021, **the UK was suffering a lot - with nearly 2,000 deaths per day.**","metadata":{}},{"cell_type":"code","source":"import math\nimport random\n\nfig = plt.figure(figsize=(10, 4), dpi=150,facecolor=background_color)\ngs = fig.add_gridspec(2, 1)\ngs.update(wspace=0, hspace=0)\nax0 = fig.add_subplot(gs[0, 0])\n\nax0.set_facecolor(background_color)\nfor s in [\"right\", \"top\",\"bottom\",\"left\"]:\n    ax0.spines[s].set_visible(False)\n\n    \n# make cloud of dots this size\nnum_dots = round(uk_daily['new_deaths'].max())\n\n#x = [random.triangular() for i in range(no_of_assets)] - diff shape, more like an oval\n\nx = [np.random.uniform() for i in range(num_dots)]\ny = [random.gauss(0.5, 0.5) for i in range(num_dots)]\n\n#random colours - alternative method\n#colors = [random.randint(1, 3) for i in range(no_of_assets)]\n\n# size of dots\nareas = [math.pi * random.randint(1, 6)**1.3 for i in range(num_dots)]\n\ndef pltcolor(lst):\n    cols=[]\n    for l in lst:\n        if l < random.triangular(0,1,0.2):\n            cols.append('lightgray')\n        elif l > random.triangular(0,1,0.8):\n            cols.append('lightgray')\n        else:\n            cols.append('gray')\n        \n    return cols\n\n\n# Create the colors list using the function above\ncols=pltcolor(x)\n\nsns.scatterplot(x, y, s=areas, c=cols, alpha=0.85,ec='black',linewidth=1.2,ax=ax0)\n\nax0.tick_params(axis = \"both\", which = \"both\", left=False, bottom=False,labelbottom=False, labelleft=False)\n\n\nax0.text(0.5,2.5,'Max. daily deaths in the UK',fontweight='bold',fontsize=14,ha='center')\n\nax0.text(0.5,-2.5,'{:,}'.format(num_dots),color='#0F4C81',fontweight='bold',fontsize=40,ha='center')\n\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I'll now highlight the UK explicitly, and view how daily deaths changed over time.\n\nYou'll clearly see the '**waves**' of the pandemic experienced.\n\n(note that these numbers have been smoothed)","metadata":{}},{"cell_type":"code","source":"temp_daily = uk_daily.groupby(['date','location'])['new_deaths_smoothed'].sum().unstack()\n\nfig = plt.figure(figsize=(10, 4), dpi=150,facecolor=background_color)\ngs = fig.add_gridspec(1, 1)\ngs.update(wspace=0, hspace=0)\nax0 = fig.add_subplot(gs[0, 0])\nax0.set_facecolor(background_color)\n\nsns.lineplot(x='date',y='United Kingdom',data=temp_daily,color='#0f4c81',ax=ax0)\n\nXstart, Xend = ax0.get_xlim()\nYstart, Yend = ax0.get_ylim()\n\nax0.set_ylim([0,Yend])\nax0.set_xlim(Xstart,Xend-1)\nax0.set_ylabel(\"Daily Deaths\",fontsize=8,loc='top')\nax0.set_xlabel(\" \",fontsize=8,loc='left')\nax0.tick_params(axis = \"both\", which = \"both\", left=False, bottom=False)\n\n\nplt.setp(ax0.xaxis.get_majorticklabels(), rotation = 0)\nlocator = mdates.AutoDateLocator(minticks=3, maxticks=12)\nformatter = mdates.ConciseDateFormatter(locator)\nax0.xaxis.set_major_locator(locator)\nax0.xaxis.set_major_formatter(formatter)\nax0.get_yaxis().set_major_formatter(matplotlib.ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n\nfor s in [\"right\", \"top\"]:\n    ax0.spines[s].set_visible(False)\n\nfor s in [\"left\",\"bottom\"]:\n    ax0.spines[s].set_color(COLOR)\n    \nfor i in temp_daily.columns:\n    ax0.plot(Xend-25,temp_daily[i][-1], 'ko', markersize=5, fillstyle='full',color='#0f4c81', markeredgewidth=1.5)\n    ax0.text(Xend-10,temp_daily[i][-1],i,color='#0f4c81',fontweight='light',fontsize=8, rotation=0)\n    \nax0.text(Xstart,Yend+100,\"Daily deaths in the UK\",fontsize=20,fontweight='bold')\n\n\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Adding context\n\nThese patterns look frightening, but without context, it's hard to say if the pattern above is different to ordinary deaths experienced in a given year/timeframe.\n\nA common way to deal with this problem is too introduce \"excess deaths\". \n\nExcess deaths is the amount of deaths above the average amount expected for a given time period. Below, I will look at monthly deaths in every year from 2015 to 2020, and compare that to the expected amount of the 5-year average for any given month.","metadata":{}},{"cell_type":"code","source":"# data prep\n\nuk[[ 'average_deaths_2015_2019_all_ages',\n       'deaths_2015_all_ages', 'deaths_2016_all_ages', 'deaths_2017_all_ages',\n       'deaths_2018_all_ages', 'deaths_2019_all_ages','deaths_2020_all_ages', 'time', 'time_unit',\n       'year', 'month']]\n\nuk['15_to_av'] = uk['deaths_2015_all_ages']/uk['average_deaths_2015_2019_all_ages']\nuk['16_to_av'] = uk['deaths_2016_all_ages']/uk['average_deaths_2015_2019_all_ages']\nuk['17_to_av'] = uk['deaths_2017_all_ages']/uk['average_deaths_2015_2019_all_ages']\nuk['18_to_av'] = uk['deaths_2018_all_ages']/uk['average_deaths_2015_2019_all_ages']\nuk['19_to_av'] = uk['deaths_2019_all_ages']/uk['average_deaths_2015_2019_all_ages']\nuk['20_to_av'] = uk['deaths_2020_all_ages']/uk['average_deaths_2015_2019_all_ages']\n\n#uk[['month','20_to_av','19_to_av','18_to_av','17_to_av','16_to_av','15_to_av']].set_index('month').T\n\ntemp = pd.pivot_table(data=uk, columns=['month','time']).T\n\n###\n\nfig = plt.figure(figsize=(15, 3), dpi=150,facecolor=background_color)\ngs = fig.add_gridspec(1, 1)\ngs.update(wspace=0, hspace=0)\nax0 = fig.add_subplot(gs[0, 0])\n\nax0.set_facecolor(background_color)\n\nfor s in [\"right\", \"top\"]:\n    ax0.spines[s].set_visible(False)\n\ncolors = ['lightgray','gray','#0f4c81','#9b1b30']\ncmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", colors)\n    \nsns.heatmap(temp[['20_to_av','19_to_av','18_to_av','17_to_av','16_to_av','15_to_av']].T,ax=ax0,linewidth=2.5,vmin=0.9,vmax=1.2, cmap=cmap,\n    yticklabels=['2020','2019','2018','2017','2016','2015'],\n    xticklabels=['Jan','','','','Feb','','','','Mar','','','','','Apr','','','','May','','','','','Jun','','','','Jul','','','','Aug',\n                 '','','','','Sep','','','','Oct','','','','Nov','','','','','Dec','','',''],\n            cbar=False,cbar_kws = dict(use_gridspec=False,location=\"bottom\",shrink=0.2),square=True)\n\nplt.yticks(rotation=0,fontfamily='monospace',size=12)\n\nax0.set_xlabel(\"\")\nax0.set_ylabel(\"\")\nax0.tick_params(axis=u'both', which=u'both',length=0)\nax0.xaxis.tick_top()\n\n\nax0.text(0,-3.5,'Excess deaths through the years',fontweight='bold',fontsize=25)\nax0.text(0,-2,'Shown is the deviation from the average deaths for a given month',fontsize=15)\n\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Observations\n\nIt is clear that 2020 has many months 'in the red', meaning way above the 5-year average for deaths in those particular months. Of course, other years see months above the average too, but that is to be expected.\n\nWe also see, even in 2020, months that are very pale coloured, meaning they are below the 5-year average. \n\nLet's now plot these explicitly, highlighting the gap between deaths suffered in 2020, and the 5-year average.","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(10, 3), dpi=150,facecolor=background_color)\ngs = fig.add_gridspec(1, 1)\ngs.update(wspace=0, hspace=0)\nax0 = fig.add_subplot(gs[0, 0])\nax0.set_facecolor(background_color)\n\nfor s in [\"right\", \"top\"]:\n    ax0.spines[s].set_visible(False)\n    \ntemp_3 = uk.loc['2020-01-01':]\n\nsns.lineplot(x='date',y='deaths_2020_all_ages',data=temp_3,color='#0f4c81', ax=ax0)\nsns.lineplot(x='date',y='average_deaths_2015_2019_all_ages',data=temp_3,color='gray', ax=ax0)\n\n\nplt.setp(ax0.xaxis.get_majorticklabels(), rotation = 0)\nlocator = mdates.AutoDateLocator(minticks=3, maxticks=15)\nformatter = mdates.ConciseDateFormatter(locator)\nax0.xaxis.set_major_locator(locator)\nax0.xaxis.set_major_formatter(formatter)\nax0.get_yaxis().set_major_formatter(matplotlib.ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n\nXstart, Xend = ax0.get_xlim()\nYstart, Yend = ax0.get_ylim()\n\nax0.set_ylim([0,Yend])\nax0.set_xlim(Xstart+10,Xend-30)\n\nax0.set_ylabel(\"Daily Deaths\",fontsize=8,loc='top')\nax0.set_xlabel(\" \",fontsize=8,loc='left')\nax0.tick_params(axis = \"both\", which = \"both\", left=False, bottom=False)\n\ny1 = temp_3['deaths_2020_all_ages']\ny2 = temp_3['average_deaths_2015_2019_all_ages']\n\nax0.fill_between(temp_3['date'], y1, y2, where=(y1 > y2), color='#9b1b30', alpha=0.7,interpolate=True)\n\nax0.text(Xstart+10,Yend+2500,\"Excess deaths [Daily]\",fontsize=20,fontweight='bold')\n\nax0.text(Xend-255,list(temp_3['deaths_2020_all_ages'])[-1]+10000,'2020 Deaths',color='#0f4c81',fontweight='bold',fontsize=8, rotation=0)    \nax0.text(Xend-250,list(temp_3['average_deaths_2015_2019_all_ages'])[-1]-2500,'Avg. Deaths 2015-2020',color='gray',fontweight='bold',fontsize=8, rotation=0)\n    \nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"One can see when the pandemic really started to hit the UK. \n\nEarly 2020 was a period of high death. If the data was available for 2021, I am sure we'd see an even larger red area, representing an even greater gap between the experienced deaths and those expected.\n\nWe can also view these differences **cumulatively**, to see the absolute differences across the course of the year.","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(10, 3), dpi=150,facecolor=background_color)\ngs = fig.add_gridspec(1, 1)\ngs.update(wspace=0, hspace=0)\nax0 = fig.add_subplot(gs[0, 0])\nax0.set_facecolor(background_color)\n\nfor s in [\"right\", \"top\"]:\n    ax0.spines[s].set_visible(False)\n    \ntemp_3 = uk.loc['2020-01-01':]\n\nsns.lineplot(x='date',y=temp_3['deaths_2020_all_ages'].cumsum(),data=temp_3,color='#0f4c81', ax=ax0)\nsns.lineplot(x='date',y=temp_3['average_deaths_2015_2019_all_ages'].cumsum(),data=temp_3,color='gray', ax=ax0)\n\n\nplt.setp(ax0.xaxis.get_majorticklabels(), rotation = 0)\nlocator = mdates.AutoDateLocator(minticks=3, maxticks=15)\nformatter = mdates.ConciseDateFormatter(locator)\nax0.xaxis.set_major_locator(locator)\nax0.xaxis.set_major_formatter(formatter)\nax0.get_yaxis().set_major_formatter(matplotlib.ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n\nXstart, Xend = ax0.get_xlim()\nYstart, Yend = ax0.get_ylim()\n\nax0.set_ylim([0,Yend])\nax0.set_xlim(Xstart+10,Xend-30)\n\nax0.set_ylabel(\"Cumulative Deaths\",fontsize=8,loc='top')\nax0.set_xlabel(\" \",fontsize=8,loc='left')\nax0.tick_params(axis = \"both\", which = \"both\", left=False, bottom=False)\n\ny1 = temp_3['deaths_2020_all_ages'].cumsum()\ny2 = temp_3['average_deaths_2015_2019_all_ages'].cumsum()\n\nax0.fill_between(temp_3['date'], y1, y2, where=(y1 > y2), color='#9b1b30', alpha=0.7,interpolate=True)\n\nax0.text(Xstart+10,Yend+100000,\"Excess deaths [Cumulative]\",fontsize=20,fontweight='bold')\n\nax0.text(Xend-165,list(temp_3['deaths_2020_all_ages'].cumsum())[-1]-100000,'2020 Deaths',color='#0f4c81',fontweight='bold',fontsize=8, rotation=0)    \nax0.text(Xend-140,list(temp_3['average_deaths_2015_2019_all_ages'].cumsum())[-1]-300000,'Avg. Deaths 2015-2020',color='gray',fontweight='bold',fontsize=8, rotation=0)\n    \nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"When viewed like this, one can see that the primary increase came in April/May, as we saw earlier, but then the deaths tracked closely to the 5-year average.\n\nTo view these differences explicitly, I'll retrieve the exact figures.\n\nWe see a total difference of **around 80,000 additional deaths** in 2020 when compared to the 5-year average.\n~","metadata":{}},{"cell_type":"code","source":"num_2020 = round(y1.max())\nnum_avg = round(y2.max())\n\ndaily_num_2020 = round(y1.max()/365)\ndaily_num_avg = round(y2.max()/365)\n\nfig = plt.figure(figsize=(6,1.4),dpi=150)\ngs = fig.add_gridspec(1, 1)\ngs.update(wspace=0.2, hspace=0.4)\nax0 = fig.add_subplot(gs[0, 0])\n\nfig.patch.set_facecolor(background_color) # figure background color\nax0.set_facecolor(background_color) \n\n\nax0.text(0,0.6,'{:,}'.format(daily_num_2020),color='#0f4c81',fontsize=25, fontweight='bold',ha='center')\nax0.text(0,0.25,\"2020 daily average\",color='#0f4c81',fontsize=15,ha='center')\n\nax0.text(0.77,0.6,'{:,}'.format(daily_num_avg),color='gray',fontsize=25, fontweight='bold',ha='center')\nax0.text(0.75,0.25,\"2015-2019 daily average\",color='gray',fontsize=15,ha='center')\n\n\nax0.text(0,-0.66,'{:,}'.format(num_2020),color='#0f4c81',fontsize=25, fontweight='bold',ha='center')\nax0.text(0,-0.25,\"2020 total\",color='#0f4c81',fontsize=15,ha='center')\n\nax0.text(0.77,-0.66,'{:,}'.format(num_avg),color='gray',fontsize=25, fontweight='bold',ha='center')\nax0.text(0.75,-0.25,\"2015-2019 total average\",color='gray',fontsize=15,ha='center')\n\nax0.set_yticklabels('')\nax0.set_xticklabels('')\nax0.tick_params(axis='both',length=0)\n\nfor s in ['top','right','left','bottom']:\n    ax0.spines[s].set_visible(False)\n    \nimport matplotlib.lines as lines\nl1 = lines.Line2D([-0.1, 1], [0.155, 0.155], transform=fig.transFigure, figure=fig,color = 'gray', linestyle='-',linewidth = 0.7, alpha = .3)\nfig.lines.extend([l1])\n    \nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We have now expored the situation in some death in the United Kingdom.\n\nWe've looked at:\n\n* Deaths in 2020 and the beginning of 2021\n\n* Excess deaths \n\n* Cumulative differences\n\n\nNow we have gained an understanding of the landscape in the United Kingdom, I will introduce an additional variable which might be able to act as an indicator for an incoming COVID-19 wave","metadata":{}},{"cell_type":"markdown","source":"\n# Introducing Google Searches\n\nNow is the time we ask ourselves the question, **'can Google searches act as an early warning signal that cases, and deaths, are about to increase?'**\n\n**I won't be trying to predict how severe a wave might be, or how many deaths might occur**. Rather, I want to know if an increase in Google searches for particular terms can act as a signal, or early sign, that more people are getting infected, and therefore that there might be more deaths.\n\nThe Google Trends data is indexed to the all-time searches for that particular term. \nFor example, a score of 100 means that it is the highest it has ever been, and all other scores are relative to that number.","metadata":{}},{"cell_type":"code","source":"temp_daily = uk_daily.groupby(['date','location'])['new_deaths_smoothed'].sum().unstack()\n\nfig = plt.figure(figsize=(10, 4), dpi=150,facecolor=background_color)\ngs = fig.add_gridspec(1, 1)\ngs.update(wspace=0, hspace=0)\nax0 = fig.add_subplot(gs[0, 0])\nax0.set_facecolor(background_color)\n\nsns.lineplot(x='date',y='United Kingdom',data=temp_daily,color='#0F4C81',ax=ax0)\n\nax1 = plt.twinx()\nsns.lineplot(x='Week',y='loss of smell: (United Kingdom)',data=trend_2020,color='#7F6917', ax=ax1)\n\n\nXstart, Xend = ax0.get_xlim()\nYstart, Yend = ax0.get_ylim()\n\nax0.set_ylim([0,Yend])\nax0.set_xlim(Xstart,Xend-1)\nax0.set_ylabel(\"Daily Deaths\",fontsize=8,loc='top')\nax0.set_xlabel(\" \",fontsize=8,loc='left')\nax0.tick_params(axis = \"both\", which = \"both\", left=False, bottom=False)\n\nax1.set_ylabel(\"Google searches for 'Loss of Smell' in the UK\",fontsize=8,loc='top')\nax1.tick_params(axis = \"both\", which = \"both\", left=False, bottom=False, right=False)\n\n\nplt.setp(ax0.xaxis.get_majorticklabels(), rotation = 0)\nlocator = mdates.AutoDateLocator(minticks=3, maxticks=12)\nformatter = mdates.ConciseDateFormatter(locator)\nax0.xaxis.set_major_locator(locator)\nax0.xaxis.set_major_formatter(formatter)\nax0.get_yaxis().set_major_formatter(matplotlib.ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n\n\nfor s in [\"top\"]:\n    ax0.spines[s].set_visible(False)\n    ax1.spines[s].set_visible(False)\n\n\nfor s in [\"left\",\"bottom\",\"right\"]:\n    ax0.spines[s].set_color(COLOR)\n    \nax0.text(Xstart,Yend+200,\"Daily deaths in the UK\\nwith Google searches for 'loss of smell'\",fontsize=20,fontweight='bold')\n\n\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Initial Oberservations\n\nAbove it is clear the there does appear to be a relationship between an increase in the search term 'Loss of smell' (a COVID-20 symptom) and a **subsequent rise in deaths.**\n\nWe can clearly see that in March 2020, 'Loss of smell' was searched for the most times. This may be due to people experiencing the symptom, and this be indicative of a rise in cases.\n\nHowever, it could also simply be because this symptom had a lot of exposure on the news & interent, and so people were searching for it.\n\nTo try to figure out which of the explanations above it might be, let's move further in to the pandemic, say from June 2020 onwards. This should remove the initial peak in interest.","metadata":{}},{"cell_type":"code","source":"temp_daily = uk_daily.groupby(['date','location'])['new_deaths_smoothed'].sum().unstack()\ntemp_daily = temp_daily.loc['2020-06-01':]\n\nfig = plt.figure(figsize=(10, 4), dpi=150,facecolor=background_color)\ngs = fig.add_gridspec(1, 1)\ngs.update(wspace=0, hspace=0)\nax0 = fig.add_subplot(gs[0, 0])\nax0.set_facecolor(background_color)\n\nsns.lineplot(x='date',y='United Kingdom',data=temp_daily,color='#0f4c81',ax=ax0)\n\nax1 = plt.twinx()\ntemp2 = trend_2020.loc['2020-06-01':]\nsns.lineplot(x='Week',y='loss of smell: (United Kingdom)',data=temp2,color='#7f6917', ax=ax1)\n\n\nXstart, Xend = ax0.get_xlim()\nYstart, Yend = ax0.get_ylim()\n\nax0.set_ylim([0,Yend])\nax0.set_xlim(Xstart,Xend-1)\nax0.set_ylabel(\"Daily Deaths\",fontsize=8,loc='top')\nax0.set_xlabel(\" \",fontsize=8,loc='left')\nax0.tick_params(axis = \"both\", which = \"both\", left=False, bottom=False)\n\nax1.set_ylabel(\"Google searches for 'Loss of Smell' in the UK\",fontsize=8,loc='top')\nax1.tick_params(axis = \"both\", which = \"both\", left=False, bottom=False, right=False)\n\n\nplt.setp(ax0.xaxis.get_majorticklabels(), rotation = 0)\nlocator = mdates.AutoDateLocator(minticks=3, maxticks=12)\nformatter = mdates.ConciseDateFormatter(locator)\nax0.xaxis.set_major_locator(locator)\nax0.xaxis.set_major_formatter(formatter)\nax0.get_yaxis().set_major_formatter(matplotlib.ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n\nfor s in [\"top\"]:\n    ax0.spines[s].set_visible(False)\n    ax1.spines[s].set_visible(False)\n\n\nfor s in [\"left\",\"bottom\",\"right\"]:\n    ax0.spines[s].set_color(COLOR)\n    \n\nax0.text(Xstart,Yend+200,\"Daily deaths in the UK\\nwith Google searches for 'loss of smell'\",fontsize=20,fontweight='bold')\n\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Observations\n\nNow we have removed the first few months of the pandemic, the relationship is arguably even easier to spot.\n\nIt seems that **when there is an increase in the frequency of people searching for 'Loss of smell'**, after delay of approximately one month, **there is a subsequent increase in recorded deaths.**\n\n\nI will now **smooth** the search terms by plotting the 4 week rolling average. This should help to see underlying trends, rather easier than in the quite erratic plot above","metadata":{}},{"cell_type":"code","source":"temp2['roll'] = temp2[['Week','loss of smell: (United Kingdom)']].rolling(4).mean()\n\ntemp_daily = uk_daily.groupby(['date','location'])['new_deaths_smoothed'].sum().unstack()\ntemp_daily = temp_daily.loc['2020-06-01':]\n\nfig = plt.figure(figsize=(10, 4), dpi=150,facecolor=background_color)\ngs = fig.add_gridspec(1, 1)\ngs.update(wspace=0, hspace=0)\nax0 = fig.add_subplot(gs[0, 0])\nax0.set_facecolor(background_color)\n\nsns.lineplot(x='date',y='United Kingdom',data=temp_daily,color='#0f4c81',ax=ax0)\n\nax1 = plt.twinx()\n#temp2 = trend_2020.loc['2020-06-01':]\nsns.lineplot(x='Week',y='roll',data=temp2,color='#7f6917', ax=ax1)\n\n\nXstart, Xend = ax0.get_xlim()\nYstart, Yend = ax0.get_ylim()\n\nax0.set_ylim([0,Yend])\nax0.set_xlim(Xstart,Xend-1)\nax0.set_ylabel(\"Daily Deaths\",fontsize=8,loc='top')\nax0.set_xlabel(\" \",fontsize=8,loc='left')\nax0.tick_params(axis = \"both\", which = \"both\", left=False, bottom=False)\n\nax1.set_ylabel(\"Google searches for 'Loss of Smell' in the UK\",fontsize=8,loc='top')\nax1.tick_params(axis = \"both\", which = \"both\", left=False, bottom=False, right=False)\n\n\nplt.setp(ax0.xaxis.get_majorticklabels(), rotation = 0)\nlocator = mdates.AutoDateLocator(minticks=5, maxticks=12)\nformatter = mdates.ConciseDateFormatter(locator)\nax0.xaxis.set_major_locator(locator)\nax0.xaxis.set_major_formatter(formatter)\nax0.get_yaxis().set_major_formatter(matplotlib.ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n\nfor s in [\"top\"]:\n    ax0.spines[s].set_visible(False)\n    ax1.spines[s].set_visible(False)\n\n\nfor s in [\"left\",\"bottom\",\"right\"]:\n    ax0.spines[s].set_color(COLOR)\n    \n\nax0.text(Xstart,Yend+200,\"Daily deaths in the UK\\nwith Google searches for 'loss of smell'\",fontsize=20,fontweight='bold')\n\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This is arguably the best plot to view the relationship we have been trying to describe.\n\n**An increase in Google Searches for 'Loss of smell' (a COVID-19 symptom) appears to be indicative of a subsequent increase in recorded deaths.**\n\nI hypothesise that this is the case because as more people start to get infected, and suffer symptoms, they begin 'googling' what it is they are experiencing. \n\nAs there is a delay between infection and subsequent death, this is not reflected instantly in the data. Rather, the delay is also witnessed. \n\n # **Why does this matter?**\n\nThis could be important for governments and local health authorities around the world, **particularly if a given country does not have adequate COVID-19 testing facilities** to be able to track the spread of the virus. \n\nA government or local health authority **could monitor Google searches for a variety of key words or phrases**, for instance all symptoms associated with COVID-19, and perhaps those associated with similar viruses such as Influenza, and if an increase in any of those search terms is detected, **action could be taken to mitigate further spread, and to prepare for a potential increase in hospitalisations**.\n\n\n\n# work in progress \n\nThere is more for me to add on this, such as **more search terms** which may be even more indicative of COVID-19 infection.\n\nI would also like to expand this research in to **other countries, such as India**. Of course, this depends on how widespread Google is used, but it would be worth investigating.\n\nWe could also bring in **vaccinations**. Can Google search trends help to understand vaccine sentiment, or vaccine uptake for instance?","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}