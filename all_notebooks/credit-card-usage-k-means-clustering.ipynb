{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n%matplotlib inline\nfrom sklearn import preprocessing as pp\nfrom sklearn.cluster import KMeans\nimport random \nfrom sklearn.datasets.samples_generator import make_blobs \nimport pylab as pl\n%matplotlib inline\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"card = pd.read_csv(\"../input/CreditCardUsage.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"card.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"card.describe().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"card.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_value=card['CREDIT_LIMIT'].mean()\ncard['CREDIT_LIMIT']=card['CREDIT_LIMIT'].fillna(mean_value)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_value=card['MINIMUM_PAYMENTS'].mean()\ncard['MINIMUM_PAYMENTS']=card['MINIMUM_PAYMENTS'].fillna(mean_value)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"card.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"card.cov()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = card.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,10))\nsns.heatmap(a,vmin=-1,vmax=1,center=0,annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = card.drop('CUST_ID', axis=1)\ndf.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nX = df.values[:,1:]\nX = np.nan_to_num(X)\nClus_dataSet = StandardScaler().fit_transform(X)\nClus_dataSet","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**K Means Modelling**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.cluster import KMeans\nkmeans = KMeans(n_clusters=6,random_state=0)\nkmeans.fit(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans.labels_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Sum_of_squared_distances = []\nK = range(1,21)\nfor k in K:\n    km = KMeans(n_clusters=k)\n    km = km.fit(df)\n    Sum_of_squared_distances.append(km.inertia_)\nplt.plot(K, Sum_of_squared_distances, 'bx-')\nplt.xlabel('k')\nplt.ylabel('Sum_of_squared_distances')\nplt.title('Elbow Method For Optimal k')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n\nThe Elbow curve depicts sum of squared distances for each point from its respective centroid. Our goal is to check for a K value that has minimum sum of square distance.\n"},{"metadata":{},"cell_type":"markdown","source":"**Silhouette Coefficient**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import silhouette_score, silhouette_samples\n\nfor n_clusters in range(2,21):\n    km = KMeans (n_clusters=n_clusters)\n    preds = km.fit_predict(df)\n    centers = km.cluster_centers_\n\n    score = silhouette_score(df, preds, metric='euclidean')\n    print (\"For n_clusters = {}, silhouette score is {}\".format(n_clusters, score))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n\n**K=3 has maximum Silhoutte score. Let us visualize Silhouette score for each cluster at k=3.**\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from yellowbrick.cluster import SilhouetteVisualizer\n\n# Instantiate the clustering model and visualizer\nkm = KMeans (n_clusters=3)\nvisualizer = SilhouetteVisualizer(km)\n\nvisualizer.fit(df) # Fit the training data to the visualizer\nvisualizer.poof() # Draw/show/poof the data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from yellowbrick.cluster import KElbowVisualizer\n# Instantiate the clustering model and visualizer\nkm = KMeans (n_clusters=3)\nvisualizer = KElbowVisualizer(\n    km, k=(2,21),metric ='silhouette', timings=False\n)\n\nvisualizer.fit(df) # Fit the training data to the visualizer\nvisualizer.poof() # Draw/show/poof the data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"km_sample = KMeans(n_clusters=4)\nkm_sample.fit(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels_sample = km_sample.labels_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['label'] = labels_sample","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set_palette('Set2')\nsns.scatterplot(df['BALANCE'],df['PURCHASES'],hue=df['label'],palette='Set1')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"label 0: Low balance and low purchases - Fine group\n\nlabel 1: Low to moderate balance and high purchases - Carefree group\n\nlabel 2: Moderate balance and moderate purchases - choosy group\n\nlabel 3: Moderate to high balance and low purchases - Saving group**\n"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}