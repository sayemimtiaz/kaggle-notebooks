{"cells":[{"metadata":{},"cell_type":"markdown","source":"> This Notebook was solely made for the purpose of learning, mine obviously. I took inspiration from many notebooks from this Dataset. This is quite an interesting Dataset to work to. Some of my models, which I trained are are as below","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import h5py\nimport cv2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now create prep_image:","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from tensorflow.python.keras.applications.resnet import preprocess_input\nfrom tensorflow.python.keras.preprocessing.image import load_img, img_to_array\nfrom tensorflow import keras\nimport matplotlib.pylab as plt\n\nimg_paths=[]\nletters2 = pd.read_csv(\"../input/classification-of-handwritten-letters/letters2.csv\")\nnum_ex=len(letters2)\nfor k in range(0,len(letters2)):\n    img_paths.append('../input/classification-of-handwritten-letters/letters2/'+ letters2['file'][k])\nimage_size = 32\ndef read_prep_images(img_paths, img_height=image_size, img_width=image_size):\n    imgs=[load_img(img_path, target_size=(img_height, img_width)) for img_path in img_paths]\n    img_array = np.array([img_to_array(img) for img in imgs])\n    output = preprocess_input(img_array)\n    output=output/255\n    return(output)\ntest_data=read_prep_images(img_paths)\nx=(np.dot(test_data,[0.299, 0.587, 0.114]))\ny=letters2['label']\nplt.imshow(x[1000], cmap=plt.cm.bone)\n\n#print(np.shape(y))\ny = keras.utils.to_categorical(y-1,num_classes=None)\nx=x.reshape(-1,32,32,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(np.shape(y))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, make a history function","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def history_plot(fit_history, n):\n    plt.plot(fit_history.history['loss'], color='slategrey', label='train')\n    plt.plot(fit_history.history['val_loss'], color='blue', label='valid')\n    plt.xlabel('epochs')\n    plt.ylabel('loss')\n    plt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"split train and bla bla bla","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, \n                                                    test_size = 0.2, \n                                                    random_state = 1)\nn = int(len(x_test)/2)\nx_valid, y_valid = x_test[:n], y_test[:n]\nx_test, y_test = x_test[n:], y_test[n:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print the shape\nprint (\"Training tensor's shape:\", x_train.shape)\nprint (\"Training target's shape\", y_train.shape)\nprint (\"Validating tensor's shape:\", x_valid.shape)\nprint (\"Validating target's shape\", y_valid.shape)\nprint (\"Testing tensor's shape:\", x_test.shape)\nprint (\"Testing target's shape\", y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, create a model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.layers import Dense, Flatten, Conv2D, Dropout, Activation, GlobalMaxPooling2D, MaxPooling2D\n\ndef model():\n    model = Sequential()\n\n    model.add(Conv2D(32, (5, 5), padding='same', input_shape=(32, 32,1)))\n    model.add(Activation('relu'))    \n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n\n    model.add(Conv2D(196, (5, 5)))\n    model.add(Activation('relu'))    \n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n    \n    model.add(GlobalMaxPooling2D()) \n    \n    model.add(Dense(1024, activation='relu'))\n    model.add(Dropout(0.5)) \n    \n    model.add(Dense(33))\n    model.add(Activation('softmax'))\n    \n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    \n    return model\n\nmodel2 = model()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.layers import Dense, Flatten, Conv2D, Dropout\n\nmodel=Sequential()\nmodel.add(Conv2D(32,\n                 activation='relu',\n                 kernel_size=5,\n                 input_shape=(32, 32,1),\n                 padding='same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(20,\n                 kernel_size=5,\n                 activation='relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(20,activation='relu',\n                        kernel_size=3))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(1024, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(33, activation='softplus'))\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics= ['accuracy'])\nhistory=model.fit(x_train, y_train, \n                    epochs=50, batch_size=64, verbose=2,\n                    validation_data=(x_valid, y_valid))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_plot(history,0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}