{"nbformat_minor":1,"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"},"language_info":{"name":"python","version":"3.6.3","pygments_lexer":"ipython3","nbconvert_exporter":"python","mimetype":"text/x-python","file_extension":".py","codemirror_mode":{"name":"ipython","version":3}}},"nbformat":4,"cells":[{"source":"import nltk\nimport re\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom bs4 import BeautifulSoup\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nenglish_stemmer=nltk.stem.SnowballStemmer('english')\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\n#print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\nimport random\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.feature_extraction.text import TfidfVectorizer","cell_type":"code","metadata":{"collapsed":true,"_cell_guid":"7ee1a65e-8e3d-43bd-858f-aff0a89bfb50","_uuid":"1246bd8e1ff5878719de53da70cdce3cc6a59d13"},"outputs":[],"execution_count":1},{"source":"def review_to_wordlist( review, remove_stopwords=True):\n    # 1. Remove HTML\n    review_text = BeautifulSoup(review).get_text()\n\n    # 2. Remove non-letters\n    review_text = re.sub(\"[^a-zA-Z]\",\" \", review)\n\n    # 3. Convert words to lower case and split them\n    words = review_text.lower().split()\n    \n    # 4. Optionally remove stop words (True by default)\n    if remove_stopwords:\n        stops = set(stopwords.words(\"english\"))\n        words = [w for w in words if not w in stops]\n\n    b=[]\n    stemmer = english_stemmer #PorterStemmer()\n    for word in words:\n        b.append(stemmer.stem(word))\n\n    # 5. Return a list of words\n    return(b)","cell_type":"code","metadata":{"collapsed":true,"_cell_guid":"a89efd65-64e6-4480-98ea-af6b796d712a","_uuid":"a816b27f829ea9945347accc544af69833970388"},"outputs":[],"execution_count":2},{"source":"data_file = '../input/Amazon_Unlocked_Mobile.csv'\n\nn = 413000  \ns = 20000 \nskip = sorted(random.sample(range(1,n),n-s))\n\n\ndf = pd.read_csv( data_file, delimiter = \",\", skiprows = skip)\n#print(df)\n# Any results you write to the current directory are saved as output.","cell_type":"code","metadata":{"collapsed":true,"_cell_guid":"dd2c7b53-8b07-4209-af27-d84698cf08ad","_uuid":"ec9a1cd8bcd94c0e1844be0d77530bc0dfb853a6"},"outputs":[],"execution_count":3},{"source":"# Drop missing values\ndf.dropna(inplace=True)\n# Remove any 'neutral' ratings equal to 3\ndf = df[df['Rating'] != 3]\n# Encode 4s and 5s as 1 (rated positively)\n# Encode 1s and 2s as 0 (rated poorly)\ndf['Positively Rated'] = np.where(df['Rating'] > 3, 1, 0)\ndf.head(10)","cell_type":"code","metadata":{"_cell_guid":"c3654543-5496-408c-bd37-0d47f2bee60d","_uuid":"0a89d7acae7b1869f43543f283d7a41e3234c609"},"outputs":[],"execution_count":4},{"source":"print(len(df['Positively Rated']))\n#df['Reviews']\n\n#for i in range(0,len(df['Positively Rated'])-1,1):\n    #review_to_wordlist(df['Positively Rated'][i])\n# Most ratings are positive\n\n","cell_type":"code","metadata":{"_cell_guid":"055e7edb-547b-414b-aecf-b422750abb54","_uuid":"f12f706a9ab064e7dd3f0c7714308dc23c094c21"},"outputs":[],"execution_count":5},{"source":"#data = df[df['Rating'].isnull()==False]\ndf['Positively Rated'].mean()","cell_type":"code","metadata":{"_cell_guid":"4cbd319e-39e4-4388-8d1d-13150744122b","_uuid":"487ed49ac7d5e62378f17f721ac34f0d071665f9"},"outputs":[],"execution_count":6},{"source":"#train, test = train_test_split(data, test_size = 0.3)\n#X_train, X_test, y_train, y_test = train_test_split(df['Rating'], df['Positively Rated'], random_state=0)","cell_type":"code","metadata":{"collapsed":true,"_cell_guid":"1ad0fd37-d487-45cb-9ecd-3cefb507fe80","_uuid":"2d1889e573468a85d4db41d95dd299473d0e1702"},"outputs":[],"execution_count":7},{"source":"","cell_type":"code","metadata":{"collapsed":true,"_cell_guid":"a3ff372a-48a8-42de-8672-175941dffd14","_uuid":"43a9eb1659287b52b338683e87ce29e9845417b1"},"outputs":[],"execution_count":null},{"source":"# Split data into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(df['Reviews'], df['Positively Rated'], random_state=0)","cell_type":"code","metadata":{"collapsed":true,"_cell_guid":"4479c96c-4fb8-41a3-80eb-26f1b3ce4fed","_uuid":"50e687a138a0ca440606d51f7a80bfddb4514838"},"outputs":[],"execution_count":8},{"source":"","cell_type":"code","metadata":{"collapsed":true,"_cell_guid":"4cd29d56-2cf5-442f-9498-157f09949756","_uuid":"f62b4f2ae4968f31fdd8261c8b8f4c3bbb958ae0"},"outputs":[],"execution_count":null},{"source":"print('X_train first entry:\\n\\n', X_train.iloc[0])\nprint('\\n\\nX_train shape: ', X_train.shape)","cell_type":"code","metadata":{"_cell_guid":"895dd55c-9ea9-47b8-b5c9-5fe67152f702","_uuid":"24683483d7df341f345c9d96f228ef460a2d9af3"},"outputs":[],"execution_count":9},{"source":"# Fit the CountVectorizer to the training data\n\nvect = CountVectorizer().fit(X_train)\n#print(vect)","cell_type":"code","metadata":{"collapsed":true,"_cell_guid":"215a76eb-299c-4265-a1ef-70011283b49e","_uuid":"ba95ec6f4511a28e9aae0fcf9428339b3fe8fd31"},"outputs":[],"execution_count":10},{"source":"\nvect.get_feature_names()[::2000]","cell_type":"code","metadata":{"_cell_guid":"8a4ea001-2e51-4c47-852d-5fddc548170a","_uuid":"245c9f624635afec2c117c90b16b0fea6fcadfdb","scrolled":false},"outputs":[],"execution_count":13},{"source":"\n#print(vect.get_feature_names()[0])\n#print(len(vect.get_feature_names()))\nfor i in range(0,len(vect.get_feature_names())-1,1):\n    if vect.get_feature_names()[i].isalpha and len(vect.get_feature_names()[i])>2:\n        #if remove_stopwords==True:\n         #   stops = set(stopwords.words(\"english\"))\n          #  words = [w for w in words if not w in stops]\n        #[x.lower() for x in vect.get_feature_names()]\n        vect.get_feature_names()\n#vect.get_feature_names()\n","cell_type":"code","metadata":{"_cell_guid":"2948c649-a043-49fb-a6f4-75a13b52d994","_uuid":"fb53f3122baeb9941553aa121f7f6d38c04a7508"},"outputs":[],"execution_count":null},{"source":"vect.get_feature_names()[::2000]","cell_type":"code","metadata":{"collapsed":true,"_cell_guid":"b5a2774f-2db4-43a8-a85b-05dac063d07d","_uuid":"059e2110543baf2c48aa9751a7db524e44c84537"},"outputs":[],"execution_count":null},{"source":"# transform the documents in the training data to a document-term matrix\nX_train_vectorized = vect.transform(X_train)\n\nX_train_vectorized","cell_type":"code","metadata":{"collapsed":true,"_cell_guid":"7c56831c-a469-45f0-85cf-0f8dfd34e4ed","_uuid":"65e3b45d54d39b5d08704e11410e7580b2b89133"},"outputs":[],"execution_count":null},{"source":"#data.reshape((999,1))\n# Train the model\n#X = X_train_vectorized.reshape(X_train_vectorized.shape[1:])\nmodel = LogisticRegression()\nmodel.fit(X_train_vectorized, y_train)","cell_type":"code","metadata":{"collapsed":true,"_cell_guid":"0b6747e1-dfb7-4daf-a0b1-5007c9f22b31","_uuid":"b3cde5c2569f00ef6130ef36063c67d39459cac8"},"outputs":[],"execution_count":null},{"source":" #Predict the transformed test documents\npredictions = model.predict(vect.transform(X_test))\n\nprint('AUC: ', roc_auc_score(y_test, predictions))","cell_type":"code","metadata":{"collapsed":true,"_cell_guid":"93980f70-61a9-44ca-a5f6-5e7caa16e12a","_uuid":"2e844e5c8879b8ac4772c64a9ea451867f32adbd"},"outputs":[],"execution_count":null},{"source":"# get the feature names as numpy array\nfeature_names = np.array(vect.get_feature_names())\n\n# Sort the coefficients from the model\nsorted_coef_index = model.coef_[0].argsort()\n\n# Find the 10 smallest and 10 largest coefficients\n# The 10 largest coefficients are being indexed using [:-11:-1] \n# so the list returned is in order of largest to smallest\nprint('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\nprint('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))","cell_type":"code","metadata":{"collapsed":true,"_cell_guid":"a974de98-54f5-4c8e-8193-712580009e12","_uuid":"c7941581ac451919cdb6ca526c8cb5b42be2189d"},"outputs":[],"execution_count":null},{"source":"# Fit the TfidfVectorizer to the training data specifiying a minimum document frequency of 5\nfor i in range(0,len(vect.get_feature_names())-1,1):\n    if vect.get_feature_names()[i].isalpha:\n        vect = TfidfVectorizer(min_df=5).fit(X_train)\n        #len(vect.get_feature_names())\n        vect.get_feature_names()\n        #[x.lower() for x in vect.get_feature_names()]","cell_type":"code","metadata":{"collapsed":true,"_cell_guid":"7072fbe9-bc03-4439-97a7-7ebb1509efee","_uuid":"647cac945855f6daa71f9ddcfb65a7b166d7b289"},"outputs":[],"execution_count":null},{"source":"X_train_vectorized = vect.transform(X_train)\n\nmodel = LogisticRegression()\nmodel.fit(X_train_vectorized, y_train)\n\npredictions = model.predict(vect.transform(X_test))\n\nprint('AUC: ', roc_auc_score(y_test, predictions))","cell_type":"code","metadata":{"collapsed":true,"_cell_guid":"9761f426-d13a-4cb7-9fbe-a99c3c2530cf","_uuid":"b08d4c80c61a2a565037ee8c26cf8598ff1d2433"},"outputs":[],"execution_count":null},{"source":"feature_names = np.array(vect.get_feature_names())\n\nsorted_tfidf_index = X_train_vectorized.max(0).toarray()[0].argsort()\n\nprint('Smallest tfidf:\\n{}\\n'.format(feature_names[sorted_tfidf_index[:10]]))\nprint('Largest tfidf: \\n{}'.format(feature_names[sorted_tfidf_index[:-11:-1]]))","cell_type":"code","metadata":{"collapsed":true,"_cell_guid":"2546dc09-842c-480f-b66e-118b87f047e4","_uuid":"e28c572d2f22232132f31713420f80e47433f383"},"outputs":[],"execution_count":null},{"source":"sorted_coef_index = model.coef_[0].argsort()\n\nprint('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\nprint('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))","cell_type":"code","metadata":{"collapsed":true,"_cell_guid":"11a8e8f4-cf38-4ce8-b479-3c49315e15a8","_uuid":"2ac8267cb82a4d609a7830adc6fcad1300d2ec0d"},"outputs":[],"execution_count":null},{"source":"# These reviews are treated the same by our current model\nprint(model.predict(vect.transform(['not an issue, phone is working',\n                                    'an issue, phone is not working'])))","cell_type":"code","metadata":{"collapsed":true,"_cell_guid":"825b4acf-bac1-48a9-9130-75380f3d3904","_uuid":"b07cac6abd4fbd930c40bc32718e780ea3bb9b0b"},"outputs":[],"execution_count":null},{"source":"# Fit the CountVectorizer to the training data specifiying a minimum \n# document frequency of 5 and extracting 1-grams and 2-grams\nvect = CountVectorizer(min_df=5, ngram_range=(1,2)).fit(X_train)\n\nX_train_vectorized = vect.transform(X_train)\n\nlen(vect.get_feature_names())","cell_type":"code","metadata":{"collapsed":true,"_cell_guid":"0d8ae84c-f4f3-45d2-baff-7cf38b1d49fa","_uuid":"33f74163a8eb0b7420224569de55c2ef98e0d96e"},"outputs":[],"execution_count":null},{"source":"model = LogisticRegression()\nmodel.fit(X_train_vectorized, y_train)\n\npredictions = model.predict(vect.transform(X_test))\n\nprint('AUC: ', roc_auc_score(y_test, predictions))","cell_type":"code","metadata":{"collapsed":true,"_cell_guid":"d28dddf5-5b04-4801-82eb-34670042116f","_uuid":"3aa12c3dc8f40d0c13fc30dca9fa751276e85f2e"},"outputs":[],"execution_count":null},{"source":"feature_names = np.array(vect.get_feature_names())\n\nsorted_coef_index = model.coef_[0].argsort()\n\nprint('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\nprint('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))","cell_type":"code","metadata":{"collapsed":true,"_cell_guid":"e819c4db-732b-459a-990f-a4b115d0ab16","_uuid":"fcdf2866e89f77ef1b8a653aa4dcf8427752c364"},"outputs":[],"execution_count":null},{"source":"# These reviews are now correctly identified\nprint(model.predict(vect.transform(['not an issue, phone is working',\n                                    'an issue, phone is not working'])))","cell_type":"code","metadata":{"collapsed":true,"_cell_guid":"9c04770b-9902-420a-840e-4f59c175aa77","_uuid":"29a827af7abd3c148c1657a31af1c5b117ed81a0"},"outputs":[],"execution_count":null}]}