{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Decoding hotel success","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"This is a project to show how you can work with very large datasets and glean business insighta from them in a quick and easy way.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 1. Data preprocessing","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"import pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt\nimport collections \nfrom sklearn.preprocessing import MinMaxScaler\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report\nimport warnings\nfrom textblob import TextBlob \nfrom sklearn.ensemble import RandomForestClassifier\nimport folium\nwarnings.filterwarnings(\"ignore\")\n\nHotels = pd.read_csv(\"/kaggle/input/515k-hotel-reviews-data-in-europe/Hotel_Reviews.csv\")\n\nUniq_ = Hotels.sort_values('Hotel_Name', ascending=False)\nUniq_hotels = Uniq_.drop_duplicates(subset='Hotel_Address', keep='first')\nhotels = Uniq_.drop([\"Review_Date\",\"days_since_review\",\"lat\",\"lng\",\"Tags\",\"Total_Number_of_Reviews_Reviewer_Has_Given\",\"Positive_Review\",\"Negative_Review\",\"Reviewer_Score\"], axis=1)\n \nnationality_counter = collections.Counter(Hotels[\"Reviewer_Nationality\"].tolist())\nhotel_counter = collections.Counter(Hotels[\"Hotel_Name\"].tolist())\n\nUniq_hotels.tail()\nuniq_hotels = Uniq_hotels.drop([\"Review_Date\",\"Reviewer_Nationality\",\"Negative_Review\",\"Review_Total_Negative_Word_Counts\",\"Positive_Review\",\"Review_Total_Positive_Word_Counts\",\"Total_Number_of_Reviews_Reviewer_Has_Given\",\"Reviewer_Score\",\"Tags\",\"days_since_review\",\"lat\",\"lng\"],axis=1)\n\nhoteladdress = uniq_hotels[\"Hotel_Address\"]\n\nuniq_hotels_lat = Uniq_hotels[\"lat\"]\nuniq_hotels_lng = Uniq_hotels[\"lng\"]\n\nHotel_num = []\n\nfor c in hoteladdress:\n    if \"United Kingdom\" in c:\n        Hotel_num.append(0)\n    elif \"France\" in c:\n        Hotel_num.append(1)\n    elif \"Italy\" in c:\n        Hotel_num.append(2)\n    elif \"Spain\" in c:\n        Hotel_num.append(3)\n    elif \"Austria\" in c:\n        Hotel_num.append(4)\n    elif \"Netherlands\" in c:\n        Hotel_num.append(5)\n        \nuniq_hotels[\"hotel_loc\"] = Hotel_num\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### There are two datasets. Both are storted by Hotel Name alphabetically. \n#### One is called hotels and it has all of the 515738 entries.\n#### The second is called uniq_hotels and it contains 1493 entries and only has unique Hotel names and corresponding addresses, average score, total reviews and additional score.","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"hotel_add = hotels[\"Hotel_Address\"].unique()\n\nneg_rev_avg_words = []\npos_rev_avg_words = []\n\nfor i in range(len(hotel_add)):\n    \n    neg_rev_avg_words.append(sum(hotels[hotels.Hotel_Address == hotel_add[i]][\"Review_Total_Negative_Word_Counts\"])/len(hotels[hotels.Hotel_Address == hotel_add[i]][\"Review_Total_Negative_Word_Counts\"]))\n    pos_rev_avg_words.append(sum(hotels[hotels.Hotel_Address == hotel_add[i]][\"Review_Total_Positive_Word_Counts\"])/len(hotels[hotels.Hotel_Address == hotel_add[i]][\"Review_Total_Positive_Word_Counts\"]))\n\nuniq_hotels[\"positive_review_average_word_count\"] = pos_rev_avg_words\nuniq_hotels[\"negative_review_average_word_count\"] = neg_rev_avg_words  \n\nuniq_hotels.drop(['Hotel_Address'],axis=1, inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"total_reviews = uniq_hotels['Total_Number_of_Reviews']\nadditional_scoring = uniq_hotels['Additional_Number_of_Scoring']\naverage_score = uniq_hotels['Average_Score']\npos_rev_avg_word_count = uniq_hotels[\"positive_review_average_word_count\"]\nneg_rev_avg_word_count = uniq_hotels[\"negative_review_average_word_count\"]\n\ntotal_reviews = total_reviews.values.astype(float)\nadditional_scoring = additional_scoring.values.astype(float)\naverage_score = average_score.values.astype(float)\npos_rev_avg_word_count = pos_rev_avg_word_count.values.astype(float)\nneg_rev_avg_word_count = neg_rev_avg_word_count.values.astype(float)\n\ntotal_reviews = total_reviews .reshape(-1, 1)\nadditional_scoring = additional_scoring.reshape(-1,1)\naverage_score = average_score.reshape(-1,1)\npos_rev_avg_word_count = pos_rev_avg_word_count.reshape(-1,1)\nneg_rev_avg_word_count = neg_rev_avg_word_count.reshape(-1,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"min_max_scaler = MinMaxScaler()\n\nuniq_hotels[\"total_reviews\"] = min_max_scaler.fit_transform(total_reviews)\nuniq_hotels[\"additional_scoring\"] = min_max_scaler.fit_transform(additional_scoring)\nuniq_hotels[\"average_score\"] = min_max_scaler.fit_transform(average_score)\nuniq_hotels[\"pos_rev_avg_word_count\"] = min_max_scaler.fit_transform(pos_rev_avg_word_count)\nuniq_hotels[\"neg_rev_avg_word_count\"] = min_max_scaler.fit_transform(neg_rev_avg_word_count)\n\nuniq_hotels.drop(['Additional_Number_of_Scoring','Total_Number_of_Reviews','Average_Score'], axis=1, inplace = True)\nuniq_hotels.tail()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Data visualisation","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"# Comparing how Additional and Average scoring compares to the number of reviews\nt = uniq_hotels[\"total_reviews\"]\ny = uniq_hotels[\"average_score\"]\n\nplt.scatter(y, t, c='purple')\nplt.xlabel('Scoring')\nplt.ylabel('Number of Reviews')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Comparing how Additional and Average scoring compares to the number of positive reviews\n\nt = uniq_hotels[\"pos_rev_avg_word_count\"]\ny = uniq_hotels[\"average_score\"]\n\nplt.scatter(t, y, c='purple')\nplt.xlabel('Positive review word count')\nplt.ylabel('Score')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Comparing how Additional and Average scoring compares to the number of negative reviews\n\nt = uniq_hotels[\"neg_rev_avg_word_count\"]\ny = uniq_hotels[\"average_score\"]\n\nplt.scatter(t, y, c='purple')\nplt.xlabel('Negative review word count')\nplt.ylabel('Score')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"top_hotels = dict(hotel_counter.most_common(5))\n\nobjects_hotels = list(top_hotels.keys())\nperformance_hotels = top_hotels.values()\n\nplt.barh(objects_hotels, performance_hotels, alpha=1)\nplt.xlabel(\"Number of reviews\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"top_nationalities = dict(nationality_counter.most_common(5))\n\nobjects_nationalities = list(top_nationalities.keys())\nperformance_nationalities = top_nationalities.values()\n\nplt.barh(objects_nationalities, performance_nationalities, alpha=1)\nplt.xlabel(\"Number of reviews\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"\nfrom sklearn.cluster import KMeans\n\n# f1 = Hotels_['neg'].values\n# f2 = Hotels_['pos'].values\n# f3 = Hotels_['Total_revs'].values \n# f4 = Hotels_['Add_sc'].values\n# f5 = Hotels_['Av_sc'].values\n\narray = uniq_hotels.drop([\"Hotel_Name\",\"additional_scoring\", \"pos_rev_avg_word_count\",\"neg_rev_avg_word_count\",\"hotel_loc\"],axis=1)\nX = array.to_numpy()\n\nkmeans = KMeans(n_clusters=3).fit(X)\n\nlabels = kmeans.predict(X)\n\nC = kmeans.cluster_centers_\n\nprint(C)\nprint(array.columns)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"fig = plt.figure()\nax = Axes3D(fig)\nax.scatter(X[:, 0], X[:, 1], X[:, 2], c=y)\nax.scatter(C[:, 0], C[:, 1], C[:, 2],)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"import folium\n\nEurope_coordinates = (54.5260, 15.2551)\n\nUniq_hotels=Uniq_hotels.dropna(subset=['lng'])\nUniq_hotels=Uniq_hotels.dropna(subset=['lat'])\n\n\nlat = list(Uniq_hotels[\"lat\"])\nlong = list(Uniq_hotels[\"lng\"])\nhotel_name = list(Uniq_hotels[\"Hotel_Name\"])\naverage_score = list(Uniq_hotels[\"Average_Score\"])\n    \ndef color(score): \n    for i in average_score:\n        if score >= 9:\n            col = \"green\"\n        elif score < 9 and score > 7:\n            col = \"orange\"\n        elif score < 7 and score > 4.8:\n            col = \"red\"\n        else:\n            col = \"black\"\n    return col\n\n\nhotel_map = folium.Map(location=Europe_coordinates, zoom_start=4)\n\nfor lt, ln, name, score in zip(lat, long, hotel_name, average_score):\n    folium.Marker(location=[lt, ln], popup=str(name), icon= folium.Icon(color=color(score))).add_to(hotel_map)\n\n\n\nhotel_map","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Analysis","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX = uniq_hotels.drop([\"Hotel_Name\", \"hotel_loc\", 'positive_review_average_word_count', 'negative_review_average_word_count'], axis=1)\ny = uniq_hotels[\"hotel_loc\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Logistic Regression\n\nlogreg = LogisticRegression()\nparam_grid = {'C':np.arange(0.01,100,10)}\ngrid = GridSearchCV(logreg,param_grid)\ngrid.fit(X_train,y_train)\n\nlogR = grid.best_estimator_\nlogR.fit(X_train,y_train)\n\ny_predicts = logR.predict(X_test)\n\nprint(classification_report(y_test, y_predicts))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df = pd.read_csv(\"Hotel_Reviews.csv\")\n\nreviewer_score = df[\"Reviewer_Score\"]\nnegative_review = df[\"Negative_Review\"]\npositive_review = df[\"Positive_Review\"]\n\nreviewer_score_label = pd.qcut(reviewer_score, 2, labels = False)\nnegative_review_polarity = []\nnegative_review_subjectivity = []\npositive_review_polarity = []\npositive_review_subjectivity = []\n\nfor i in range(len(negative_review)):\n    term_1 = TextBlob(negative_review[i]).sentiment\n    term_2 = TextBlob(positive_review[i]).sentiment\n    \n    negative_review_polarity.append(term_1[0])\n    negative_review_subjectivity.append(term_1[1])\n    positive_review_polarity.append(term_2[0])\n    positive_review_subjectivity.append(term_2[1])\n    \n \nX = df[['Review_Total_Negative_Word_Counts', 'Total_Number_of_Reviews', 'Review_Total_Positive_Word_Counts', 'Total_Number_of_Reviews_Reviewer_Has_Given']]\n\nX['negative_review_polarity'] = negative_review_polarity\nX['negative_review_subjectivity'] = negative_review_subjectivity\nX['positive_review_polarity'] = positive_review_polarity\nX['positive_review_subjectivity'] = positive_review_subjectivity \n\ny = pd.qcut(reviewer_score, 2, labels = False)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n\ntree = RandomForestClassifier(random_state=0)\ntree.fit(X_train, y_train)\n\ny_pred = tree.predict(X_test)\nprint(classification_report(y_pred, y_test))\n\nfeature_imp = pd.Series(tree.feature_importances_,index=X.columns).sort_values(ascending=False)\nprint(feature_imp)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"\nlog_reg = LogisticRegression()\nlog_reg.fit(X_train, y_train)\ny_pred = tree.predict(X_test)\nprint(classification_report(y_pred, y_test))\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}