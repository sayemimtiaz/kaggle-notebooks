{"metadata":{"kernelspec":{"name":"python3","language":"python","display_name":"Python 3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py","name":"python","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"version":"3.6.1"}},"nbformat":4,"nbformat_minor":0,"cells":[{"metadata":{"collapsed":false,"_cell_guid":"a7eb933d-07c2-4e9e-977f-d82296023593","_execution_state":"idle","_uuid":"6a711171dccfd854e935b60d109fa0d2a80e06e8"},"source":"This notebook is an introduction into the world of Xgboost for Classifcation and Regression. Motivated by the Russia Dataset that I worked on, trained on Random Forest, no ensemble and ended up in the 83% mark","execution_count":null,"cell_type":"markdown","outputs":[]},{"metadata":{"_cell_guid":"12688f47-9564-4ee2-9bba-97069e60a308","_execution_state":"idle","_uuid":"afddcea42e8847ee1ed6e0da0687aec20f03749c","trusted":false},"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport xgboost as xgb\nfrom sklearn.cross_validation import train_test_split\n\n# Input data files are available in the \"../input/\" directory.b\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"collapsed":false,"_cell_guid":"4707e84f-5895-4b1d-806a-b5ae4641e3d3","_execution_state":"idle","_uuid":"a8adc4b606c9f5e3cb7f700323b46d3f60603f69","trusted":false},"source":"#load Dataset\ndata = pd.read_csv('../input/diabetes.csv')\ndata.head()","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"collapsed":false,"_cell_guid":"50e7dccd-d901-4e05-bf62-1ff7b8d4e18a","_execution_state":"idle","_uuid":"a25872189c0f245a213e5c69cc3a3550957c3b46","trusted":false},"source":"data_full = data.copy()\nX_data = data_full.drop('Outcome', axis=1)\ny = data_full.Outcome","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"collapsed":false,"_cell_guid":"99b0a828-66a6-4cdb-9f52-2d328e6616d2","_execution_state":"idle","_uuid":"05e6f455a9ae50ac5b0c111be9c367cf0dba069c","trusted":false},"source":"X_data.head()","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"collapsed":false,"_cell_guid":"1a524d73-d1dc-4895-a9c7-2b95ca0d9a27","_execution_state":"idle","_uuid":"604995c33731c8eee5d2ac9c8812ba89e89bf4a2","trusted":false},"source":"#Split the dataset into train and Test\nseed = 7\ntest_size = 0.3\nX_trian, X_test, y_train, y_test = train_test_split(X_data, y, test_size=test_size, random_state=seed)","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"collapsed":false,"_cell_guid":"a51435a6-12ee-4328-8156-69cb3dfdf852","_execution_state":"idle","_uuid":"dbc95cf7d02268dbdaebd19babc85cf05d8fa5d2","trusted":false},"source":"#Train the XGboost Model for Classification\nmodel1 = xgb.XGBClassifier()\nmodel2 = xgb.XGBClassifier(n_estimators=100, max_depth=8, learning_rate=0.1, subsample=0.5)\n\ntrain_model1 = model1.fit(X_trian, y_train)\ntrain_model2 = model2.fit(X_trian, y_train)","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"collapsed":false,"_cell_guid":"5de86a12-216d-4f31-96fd-43f32ea61570","_execution_state":"idle","_uuid":"fd3df6bd3fec8a7e21df914ac2a9d0b78bb03aa3","trusted":false},"source":"#prediction and Classification Report\nfrom sklearn.metrics import classification_report\n\npred1 = train_model1.predict(X_test)\npred2 = train_model2.predict(X_test)\n\nprint('Model 1 XGboost Report %r' % (classification_report(y_test, pred1)))\nprint('Model 2 XGboost Report %r' % (classification_report(y_test, pred2)))","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"collapsed":false,"_cell_guid":"244804f4-74ad-403d-bc79-ca1c56c37a2b","_execution_state":"idle","_uuid":"810f7dfc5fcfcbb642d41158a2e2c14e51b84957","trusted":false},"source":"#Let's use accuracy score\nfrom sklearn.metrics import accuracy_score\n\nprint(\"Accuracy for model 1: %.2f\" % (accuracy_score(y_test, pred1) * 100))\nprint(\"Accuracy for model 2: %.2f\" % (accuracy_score(y_test, pred2) * 100))","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"collapsed":false,"_cell_guid":"749d0718-24c8-48e6-9f88-fe89dccf5b73","_execution_state":"idle","_uuid":"5c29773a1fc8ea1aeb34c20fd345d4d2d73e7a14"},"source":"Clearly Model 1 performed much better than when we had an estimator","execution_count":null,"cell_type":"markdown","outputs":[]},{"metadata":{"collapsed":false,"_cell_guid":"1c308da1-ab6f-48a4-b875-2f9778e8a77a","_execution_state":"idle","_uuid":"20290ed9c0b7180dab6981c7d3d78f3b972b4e48"},"source":"### Let's see what's in Hyperparameter Tunning of XGboost\nBased on the work of [Aarshay Jain](https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/)","execution_count":null,"cell_type":"markdown","outputs":[]},{"metadata":{"collapsed":false,"_cell_guid":"50f2fecf-e8fe-463c-b362-ae0113379369","_execution_state":"idle","_uuid":"98b5d26570f023459eb6c2f513dc6b9bebc7af31","trusted":false},"source":"#Let's do a little Gridsearch, Hyperparameter Tunning\nmodel3 = xgb.XGBClassifier(\n learning_rate =0.1,\n n_estimators=1000,\n max_depth=5,\n min_child_weight=1,\n gamma=0,\n subsample=0.8,\n colsample_bytree=0.8,\n objective= 'binary:logistic',\n nthread=4,\n scale_pos_weight=1,\n seed=27)","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"collapsed":false,"_cell_guid":"876d36a2-182c-49ae-82e9-530f2a38ea21","_execution_state":"idle","_uuid":"e41b73e90de70e0c32934cab8e732eee45d7c909","trusted":false},"source":"train_model3 = model3.fit(X_trian, y_train)\npred3 = train_model3.predict(X_test)\nprint(\"Accuracy for model 3: %.2f\" % (accuracy_score(y_test, pred3) * 100))","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"collapsed":false,"_cell_guid":"27801166-41bd-48c3-9c41-047b1c26cf32","_execution_state":"idle","_uuid":"16f03324bd997483c5f1591fb23981e1a04939ac","trusted":false},"source":"from sklearn.model_selection import GridSearchCV\n\nparam_test = {\n 'max_depth':[4,5,6],\n 'min_child_weight':[4,5,6]\n}\ngsearch = GridSearchCV(estimator = xgb.XGBClassifier( learning_rate=0.1, n_estimators=140, max_depth=5,\n min_child_weight=2, gamma=0, subsample=0.8, colsample_bytree=0.8,\n objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n param_grid = param_test, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n\ntrain_model4 = gsearch.fit(X_trian, y_train)\npred4 = train_model4.predict(X_test)\nprint(\"Accuracy for model 4: %.2f\" % (accuracy_score(y_test, pred4) * 100))","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"collapsed":false,"_cell_guid":"9abca6c3-c32e-4566-81f6-cc328ffd33e6","_execution_state":"idle","_uuid":"ad24b9d56c94580162f9f8356fc1475ae0ce2080","trusted":false},"source":"param_test2b = {\n 'min_child_weight':[6,8,10,12]\n}\ngsearch2b = GridSearchCV(estimator = xgb.XGBClassifier( learning_rate=0.1, n_estimators=140, max_depth=4,\n min_child_weight=2, gamma=0, subsample=0.8, colsample_bytree=0.8,\n objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n param_grid = param_test2b, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n\ntrain_model5 = gsearch2b.fit(X_trian, y_train)\npred5 = train_model5.predict(X_test)\nprint(\"Accuracy for model 5: %.2f\" % (accuracy_score(y_test, pred5) * 100))","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"collapsed":false,"_cell_guid":"6ae56e43-6aec-414b-ab8c-f4442974b355","_execution_state":"idle","_uuid":"df26443e883a4c4231817338a03935d719829596","trusted":false},"source":"#Tune Gamma\nparam_test3 = {\n 'gamma':[i/10.0 for i in range(0,5)]\n}\ngsearch3 = GridSearchCV(estimator = xgb.XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=4,\n min_child_weight=6, gamma=0, subsample=0.8, colsample_bytree=0.8,\n objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n param_grid = param_test3, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n\ntrain_model6 = gsearch3.fit(X_trian, y_train)\npred6 = train_model6.predict(X_test)\nprint(\"Accuracy for model 6: %.2f\" % (accuracy_score(y_test, pred6) * 100))","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"collapsed":false,"_cell_guid":"12b773df-4f8f-489d-8861-5b2e86fa54b4","_execution_state":"idle","_uuid":"5ee38fc72587d38d4740c8be1e953772f046d3cf","trusted":false},"source":"xgb2 = xgb.XGBClassifier(\n learning_rate =0.7,\n n_estimators=1000,\n max_depth=4,\n min_child_weight=6,\n gamma=0,\n subsample=0.8,\n colsample_bytree=0.8,\n objective= 'binary:logistic',\n nthread=4,\n scale_pos_weight=1,\n seed=27)\n\ntrain_model7 = xgb2.fit(X_trian, y_train)\npred7 = train_model7.predict(X_test)\nprint(\"Accuracy for model 7: %.2f\" % (accuracy_score(y_test, pred7) * 100))","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"collapsed":false,"_cell_guid":"ce36e759-1569-4801-95c9-b992c29f0352","_execution_state":"idle","_uuid":"b7bef0dffba9be3937b23dd7d42ca03a52d2f23a","trusted":false},"source":"#Let's train a fast RandomForest on the dataset\nfrom sklearn.ensemble import RandomForestClassifier\n\nrfc = RandomForestClassifier()\nrfc_model = rfc.fit(X_trian, y_train)\npred8 = rfc_model.predict(X_test)\nprint(\"Accuracy for Random Forest Model: %.2f\" % (accuracy_score(y_test, pred8) * 100))","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"collapsed":false,"_cell_guid":"c097a5a0-3f7f-445a-869f-64ac3d9b9700","_execution_state":"idle","_uuid":"564e1309c51e1ccaa2972b1d08c1ceed11bc8666"},"source":"**Naive XGBoost Perform well than RandomForest**","execution_count":null,"cell_type":"markdown","outputs":[]}]}