{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# STARTUP SUCCESS PREDICTION","metadata":{}},{"cell_type":"markdown","source":"## Problem Statement\n\n**Startup** adalah sesuatu bisnis yang baru saja berdiri dan berkembang dengan didukung oleh layanan digital dan juga telah menjadi elemen penting dari sistem inovasi dan ekonomi di seluruh dunia. Ekosistem **Startup** berkembang sangat pesat dan masih butuh banyak pendanaan untuk beroperasi dengan kelompok kerja yang minimalis. Jadi sangat penting bagi pihak VC untuk memantau kinerja dan performa dari **Startup**, sehingga dapat digunakan sebagai bahan pertimbangan untuk memutuskan apakah akan mendanai suatu Startup untuk mendorong pertumbuhannya atau menolak mengambil andil dalam pendanaan. Untuk memantau kinerja **Startup**, penting untuk menganalisis apa yang membuat sebuah Startup sukses dan bagaimana menentukan kesuksesannya.\n\n## Goals\nTujuan yang ingin dicapai yaitu dapat menentukan apakah suatu StartUp akan sukses atau tidak.\n\n## Objective\nObjective yang ingin dilakukan yaitu dengan membuat analisa behaviour StartUp berdasarkan beberapa variabel yang ada, menentukan variabel apa yang paling mempengaruhi kesuksesan StartUp, kemudian membangun model yang dapat memprediksi kesuksesan dari suatu StartUp.","metadata":{}},{"cell_type":"markdown","source":"# Data Exploration","metadata":{}},{"cell_type":"markdown","source":"## Import Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib as mpl\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nfrom datetime import date\nfrom scipy import stats\nfrom scipy.stats import norm, skew #for some statistics\n\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nfrom plotly.colors import n_colors\nfrom plotly.subplots import make_subplots\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n%matplotlib inline\npd.set_option(\"display.max_columns\",None)\npd.set_option(\"display.max_rows\",None)\nplt.style.use('seaborn')\n\nfrom collections import Counter\nimport datetime\nimport wordcloud\nimport json","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Dataset","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/startup-success-prediction/startup data.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(10)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Description","metadata":{}},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data type identification","metadata":{}},{"cell_type":"code","source":"df.columns","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data numeric","metadata":{}},{"cell_type":"code","source":"numeric=['int8', 'int16', 'int32', 'int64', 'float16', 'float32', 'float64']\ndf_num=df.select_dtypes(include=numeric)\ndf_num.head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data categorical","metadata":{"code_folding":[]}},{"cell_type":"code","source":"df_cat=df.select_dtypes(include='object')\ndf_cat.head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Changing 'status' data value","metadata":{}},{"cell_type":"code","source":"df['status'] = df.status.map({'acquired':1, 'closed':0})\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Handling 'status' data type to int ","metadata":{}},{"cell_type":"code","source":"#Tipe data status diganti dari object ke int\ndf['status'].astype(int)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Drop column labels","metadata":{}},{"cell_type":"code","source":"#labels dan status\nfor index, row in df.iterrows():\n    if row['labels']!=row['status']:\n        print(index, row['labels'], row['status'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" df.drop([\"labels\"], axis=1, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploratory Data Analysis","metadata":{}},{"cell_type":"markdown","source":"## Pendekatan Numerik","metadata":{}},{"cell_type":"markdown","source":"### Statistical Summary","metadata":{}},{"cell_type":"code","source":"describeNum = df.describe(include =['float64', 'int64', 'float', 'int'])\ndescribeNum.T.style.background_gradient(cmap='viridis',low=0.2,high=0.1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"describeNumCat = df.describe(include=[\"O\"])\ndescribeNumCat.T.style.background_gradient(cmap='viridis',low=0.2,high=0.1)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Apakah nilai yang tertera pada setiap kolom masuk akal?\n- age_first_funding_year dan age_last_funding_year memiliki data min,max yang sama, perlu dicek lagi\n- Apakah nilai maksimal/minimal masih berada di batas wajar?\n- Min/max yang terlalu jauh dari mean/median bisa jadi indikasi kesalahan input data\n- Apakah ada kolom dengan perbedaan yang signifikan antara mean dan median?\n- Perbedaan antara mean/median mengindikasikan outlier atau skewed distribution","metadata":{}},{"cell_type":"markdown","source":"### Categorical Value Counting","metadata":{}},{"cell_type":"code","source":"cats = ['state_code','zip_code','id','city','Unnamed: 6','name','founded_at','closed_at','first_funding_at','last_funding_at','state_code.1','category_code','object_id','status'] \nfor col in cats:\n    print(f'''Value count kolom {col}:''')\n    print(df[col].value_counts())\n    print()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Missing Value ","metadata":{}},{"cell_type":"code","source":"null=pd.DataFrame(df.isnull().sum(),columns=[\"Null Values\"])\nnull[\"% Missing Values\"]=(df.isna().sum()/len(df)*100)\nnull = null[null[\"% Missing Values\"] > 0]\nnull.style.background_gradient(cmap='viridis',low =0.2,high=0.1) ","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **Hasil Analisis dalam dataset yang digunakan terdapat Missing Values diantaranya yaitu**\n    - **Total Missing Values yaitu 1386**\n    - **Kolom yang memiliki lebih dari 50% dari missing values**\n        - Variabel 'closed_at' dengan total persentase sebesar 63.70% atau total 588 kolom.\n        - Variabel 'Unnamed: 6' dengan total persentase sebesar 53.41% atau total 493 kolom.\n    - **Kolom yang memiliki kurang dari 50% dari missing values**\n        - Variabel 'age_first_milestone_year' dengan total persentase sebesar 16.46% atau total 152 kolom.\n        - Variabel 'age_last_milestone_year' dengan total persentase sebesar 16.46% atau total 152 kolom.","metadata":{}},{"cell_type":"code","source":"# Checking Missing Values Column \ndf[[\"Unnamed: 6\", \"closed_at\", \"age_first_milestone_year\", \"age_last_milestone_year\", \"state_code.1\", \"status\"]].head(4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **Hasil Analisis pada kolom yang terdapat Missing Values diantaranya yaitu**\n    - **Kolom \"Unnamed: 6\"** merupakan kolom informasi dari gabungan beberapa tabel diantaranya yaitu\n        - Kolom \"city\", \"state_code\", dan \"zip_code\" \n    - **Kolom \"closed_at\"** merupakan kolom dimana StartUp **\"Closed\"** sehingga data yang kosong memang harusnya merupakan StarUp yang statusnya masih **\"Acquired\"**\n    - **Kolom age_first_milestone_year** merupakan informasi kapan milestone pertama kali di lakukan dalam satuan tahun\n        - Kolom ini total memiliki 771 baris data dengan Mean 3.055353 dan median 2.520500 yang memperlihatkan distribusi datanya tidak normal\n    - **Kolom age_Last_milestone_year** merupakan informasi kapan milestone terakhir kali di lakukan dalam satuan tahun\n        - Kolom ini total memiliki 771 baris data dengan Mean 4.754423 dan median 4.476700 yang memperlihatkan distribusi datanya tidak normal","metadata":{}},{"cell_type":"markdown","source":"###  Handling Missing Value Unnamed: 6","metadata":{}},{"cell_type":"markdown","source":"berdasarkan hasil analisis diperoleh bahwa kolom **Unnamed: 6** merupakan kombinasi dari beberapa kolom lainnya diantaranya kolom **city, state_code, dan zip_code**, maka kami memutuskan bahwa menghapus isi dari kolom **Unnamed: 6** terlebih dahulu dan kemudian mengisi data berdasarkan kombinasi dari beberapa kolom terkait.","metadata":{}},{"cell_type":"code","source":"df['Unnamed: 6'] = df.apply(lambda row: (row.city) + \" \" + (row.state_code) + \" \" +(row.zip_code)  , axis = 1)\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Total Missing Values kolom \"Unnamed: 6\"\ntotalNull = df['Unnamed: 6'].isnull().sum()\n\nprint('Total Missing Values Kolom \"Unnamed: 6\": ', totalNull)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Handling Missing Value closed_at","metadata":{}},{"cell_type":"code","source":"#diisi kosong\ndf['closed_at'] = df['closed_at'].fillna(value=\"31/12/2013\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#datetoday\n#option\n# df['closed_at']=df['closed_at'].fillna(date.today())\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"totalNull = df['closed_at'].isnull().sum()\n\nprint('Total Missing Values Kolom \"closed_at\": ', totalNull)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Handling Missing Value age_first_milestone_year and age_last_milestone_year","metadata":{}},{"cell_type":"code","source":"df[['age_first_milestone_year','age_last_milestone_year','milestones']].head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"berdasarkan hasil analisis diperoleh bahwa kolom 'age_first_milestone_year' dan 'age_last_milestone_year' memiliki nilai null karena memang startup tersebut belum memiliki milestones. hal ini bisa dikonfirmasi dengan melihat kolom 'milestones' yang berisi data 0 pasti diiringi dengan kolom 'age_first_milestone_year' dan 'age_last_milestone_year' yang Null. sehingga kami memutuskan untuk mengisi kolom null tersebut dengan nilai 0.","metadata":{}},{"cell_type":"code","source":"df['age_first_milestone_year'] = df['age_first_milestone_year'].fillna(value=\"0\")\ndf['age_last_milestone_year'] = df['age_last_milestone_year'].fillna(value=\"0\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Handling Missing Value state_code.1","metadata":{}},{"cell_type":"markdown","source":"- kolom **\"state_code\"** and kolom **\"state_code.1\"** mestilah sama, jadi kolom **\"state_code.1\"** harus di drop.\n- kolom **\"state_code.1\"** memiliki missing value dibaris 515. ","metadata":{}},{"cell_type":"code","source":"for index, row in df.iterrows():\n    if row['state_code']!=row['state_code.1']:\n        print(index, row['state_code'], row['state_code.1'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop([\"state_code.1\"], axis=1, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"null=pd.DataFrame(df.isnull().sum(),columns=[\"Null Values\"])\nnull[\"% Missing Values\"]=(df.isna().sum()/len(df)*100)\nnull = null[null[\"% Missing Values\"] > 0]\nnull.style.background_gradient(cmap='viridis',low =0.2,high=0.1) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Pendekatan Grafis","metadata":{}},{"cell_type":"markdown","source":"### Correlation heatmap","metadata":{}},{"cell_type":"markdown","source":"Sekarang bagaimana korelasi antar variabel data.\n\nKorelasi direpresentasikan sebagai nilai antara -1 dan +1 di mana +1 menunjukkan korelasi positif tertinggi, -1 menunjukkan korelasi negatif tertinggi, dan 0 menunjukkan tidak ada korelasi.","metadata":{}},{"cell_type":"code","source":"df.corr()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['age_first_milestone_year'] = df.age_first_milestone_year.astype(float)\ndf['age_last_milestone_year'] = df.age_last_milestone_year.astype(float)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = ['age_first_funding_year','age_last_funding_year','age_first_milestone_year','age_last_milestone_year','relationships','funding_rounds','funding_total_usd','milestones','is_CA','is_NY','is_MA','is_TX','is_otherstate','is_software','is_web','is_mobile','is_enterprise','is_advertising','is_gamesvideo','is_ecommerce','is_biotech','is_consulting','is_othercategory','has_VC','has_angel','has_roundA','has_roundB','has_roundC','has_roundD','avg_participants','is_top500','status']\n\nplt.figure(figsize=(30,20))\nax = sns.heatmap(data = df[features].corr(),cmap='YlGnBu',annot=True)\n\nbottom, top = ax.get_ylim()\nax.set_ylim(bottom + 0.5,top - 0.5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 'SalePrice' correlation matrix (zoomed heatmap style)\n\n#number of variables for heatmap\ncols = df[features].corr().nlargest(10,'status')['status'].index\ncm = np.corrcoef(df[cols].values.T) \nsns.set(font_scale=1.25)\nhm = sns.heatmap(cm, cbar=True, annot=True, square=True, cmap='YlGnBu', fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Scatter plot","metadata":{}},{"cell_type":"markdown","source":"berdasarkan tabel korelasi di atas yang mengatakan bahwa **'views'** dan **'likes'** berkorelasi sangat positif. maka kami kemudian memverifikasi itu dengan memplot scatter plot antara **'views'** dan **'likes'** untuk memvisualisasikan hubungan antara variabel-variabel tersebut.","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots()\n_ = plt.scatter(x=df['age_first_funding_year'], y=df['age_last_funding_year'], edgecolors=\"#000000\", linewidths=0.5)\n_ = ax.set(xlabel=\"age_first_funding_year\", ylabel=\"age_last_funding_year\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Kami melihat bahwa **'age_first_funding_year'** dan **'age_last_funding_year'** benar-benar berkorelasi positif dimana saat satu meningkat, yang lain juga meningkat â€” sebagian besar.","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots()\n_ = plt.scatter(x=df['has_roundB'], y=df['funding_rounds'], edgecolors=\"#000000\", linewidths=0.5)\n_ = ax.set(xlabel=\"has_roundB\", ylabel=\"funding_rounds\")","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots()\n_ = plt.scatter(x=df['has_roundC'], y=df['funding_rounds'], edgecolors=\"#000000\", linewidths=0.5)\n_ = ax.set(xlabel=\"has_roundC\", ylabel=\"funding_rounds\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots()\n_ = plt.scatter(x=df['status'], y=df['relationships'], edgecolors=\"#000000\", linewidths=0.5)\n_ = ax.set(xlabel=\"status\", ylabel=\"relationships\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots()\n_ = plt.scatter(x=df['status'], y=df['milestones'], edgecolors=\"#000000\", linewidths=0.5)\n_ = ax.set(xlabel=\"status\", ylabel=\"milestones\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Box plots","metadata":{}},{"cell_type":"code","source":"featuresNum = ['age_first_funding_year','age_last_funding_year','relationships','funding_rounds','funding_total_usd','milestones','avg_participants']\n\nplt.figure(figsize=(15, 7))\nfor i in range(0, len(featuresNum)):\n    plt.subplot(1, len(featuresNum), i+1)\n    sns.boxplot(y=df[featuresNum[i]], color='green', orient='v')\n    plt.tight_layout()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dataset collection founded years","metadata":{}},{"cell_type":"code","source":"cdf = df[\"founded_at\"].apply(lambda x: '' + x[:2]).value_counts() \\\n            .to_frame().reset_index() \\\n            .rename(columns={\"index\": \"year\", \"founded_at\": \"No_of_startup\"})\n\nfig, ax = plt.subplots()\n_ = sns.barplot(x=\"year\", y=\"No_of_startup\", data=cdf, \n                palette=sns.color_palette(['#003f5c', '#ffa600'], n_colors=7), ax=ax)\n_ = ax.set(xlabel=\"Year\", ylabel=\"No. of startup\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"founded_at\"].apply(lambda x: '20:' + x[:2]).value_counts(normalize=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"founded_at\"].apply(lambda x: '20:' + x[:2]).value_counts(normalize=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"total ada 563 startup atau 60% startup yang berdiri pada tahun 2001","metadata":{}},{"cell_type":"code","source":"df[\"closed_at\"].apply(lambda x: '20:' + x[:2]).value_counts(normalize=True)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"dari total data yang ada sebanyak 63% startup masih berdiri sedangkan sisanya 37% sudah closed dan terbanyak closed pada tahun 2001. ","metadata":{}},{"cell_type":"markdown","source":"### How many Startup are acquired or closed have?","metadata":{}},{"cell_type":"code","source":"df_acquired = df[(df[\"status\"] == True)]\ndf_acquired.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_closed = df[(df[\"status\"] == False)]\ndf_closed.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"value_counts = df[\"status\"].value_counts().to_dict()\nfig, ax = plt.subplots()\n_ = ax.pie(x=[value_counts[False], value_counts[True]], labels=['No', 'Yes'], \n           colors=['#003f5c', '#ffa600'], textprops={'color': '#040204'})\n_ = ax.axis('equal')\n_ = ax.set_title('Startup Acquired')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### invest feature acquired check","metadata":{}},{"cell_type":"code","source":"coba = df[(df[\"status\"] == 1)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = coba[[\"has_VC\",\"has_angel\",\"has_roundA\",\"has_roundB\",\"has_roundC\",\"has_roundD\"]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\n\nfig, ax = plt.subplots(figsize=(12,8))\n\na= np.random.choice([\"{}\".format(i) for i in [1,2,3,4,5,6]], size=(12,8))\ncoba = pd.DataFrame(a, columns=[\"has_{}\".format(i) for i in list(\"features\")])\n\nsns.countplot(x=\"variable\", hue=\"value\",palette=\"nipy_spectral\", data=pd.melt(features))\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Which category has the largest number of startup","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(12,8))\n\n_ = sns.countplot(x=\"category_code\", hue=\"status\", data=df, palette=\"nipy_spectral\",\n              order=df.category_code.value_counts().index)\n\n_ = ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n_ = ax.set(xlabel=\"Category\", ylabel=\"No. of startup\")\nplt.legend(bbox_to_anchor=(0.945, 0.90))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Which State having most number of Startup","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(12,8))\n\n_ = sns.countplot(x=\"state_code\", hue=\"status\", data=df, palette=\"nipy_spectral\",\n              order=df.state_code.value_counts().index)\n\n_ = ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n_ = ax.set(xlabel=\"state_code\", ylabel=\"No. of startup\")\nplt.legend(bbox_to_anchor=(0.945, 0.90))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trending_statea = df.groupby(['state_code']).size().rename('num_startup').reset_index()\n\nmost_trending_statea = trending_statea[trending_statea.groupby('state_code')['num_startup'].transform(max) == trending_statea['num_startup']]\nmost_trending_statea = most_trending_statea.sort_values('num_startup', ascending=False)\nmost_trending_statea","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Which State having most number of acquired Startup per category","metadata":{}},{"cell_type":"code","source":"trending_statea = df_acquired.groupby(['state_code','category_code']).size().rename('num_startup').reset_index()\n\nmost_trending_statea = trending_statea[trending_statea.groupby('state_code')['num_startup'].transform(max) == trending_statea['num_startup']]\nmost_trending_statea = most_trending_statea.sort_values('num_startup', ascending=False)\nmost_trending_statea.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Which State having most number of closed Startup per category","metadata":{}},{"cell_type":"code","source":"trending_statec = df_closed.groupby(['state_code','category_code']).size().rename('num_startup').reset_index()\n\nmost_trending_statec = trending_statec[trending_statec.groupby('state_code')['num_startup'].transform(max) == trending_statec['num_startup']]\nmost_trending_statec = most_trending_statec.sort_values('num_startup', ascending=False)\nmost_trending_statec","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Which city having most number of acquired Startup per category","metadata":{}},{"cell_type":"code","source":"trending_categorya = df_acquired.groupby(['city','category_code']).size().rename('num_startup').reset_index()\n\nmost_trending_categorya = trending_categorya[trending_categorya.groupby('city')['num_startup'].transform(max) == trending_categorya['num_startup']]\nmost_trending_categorya = most_trending_categorya.sort_values('num_startup', ascending=False)\nmost_trending_categorya","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Which city having most number of closed Startup per category","metadata":{}},{"cell_type":"code","source":"trending_categoryc = df_closed.groupby(['city','category_code']).size().rename('num_startup').reset_index()\n\nmost_trending_categoryc = trending_categoryc[trending_categoryc.groupby('city')['num_startup'].transform(max) == trending_categoryc['num_startup']].reset_index()\nmost_trending_categoryc = most_trending_categoryc.sort_values('num_startup', ascending=False)\nmost_trending_categoryc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Which category having most number of total funding","metadata":{}},{"cell_type":"code","source":"funding_sorted_category = pd.pivot_table(df,\n              index=['category_code'],\n              values=['funding_total_usd'],\n              aggfunc=['sum']\n              ).reset_index()\nfunding_sorted_category.columns = ['category_code', 'funding_total_usd']\nfunding_sorted_category = funding_sorted_category.sort_values(['funding_total_usd'], ascending = False)\nfunding_sorted_category.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(15,7))\n_ = sns.barplot(x=\"category_code\", y=\"funding_total_usd\", data=funding_sorted_category,\n                palette=\"nipy_spectral\", ax=ax)\n_ = ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n_ = ax.set(xlabel=\"Category\", ylabel=\"Total Funding USD\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Which city having most number of total funding","metadata":{}},{"cell_type":"code","source":"funding_sorted_city = pd.pivot_table(df,\n              index=['city'],\n              values=['funding_total_usd'],\n              aggfunc=['sum']\n              ).reset_index()\nfunding_sorted_city.columns = ['city', 'funding_total_usd']\nfunding_sorted_city = funding_sorted_city.sort_values(['funding_total_usd'], ascending = False)\nfunding_sorted_city = funding_sorted_city.head(10)\nfunding_sorted_city","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10,7))\n_ = sns.barplot(x=\"city\", y=\"funding_total_usd\", data=funding_sorted_city,\n                palette=\"nipy_spectral\", ax=ax)\n_ = ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n_ = ax.set(xlabel=\"No of State\", ylabel=\"Number of Start Up\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_what_in_kirkland = df[(df[\"city\"] == 'Kirkland')]\ndf_what_in_kirkland.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_what_in_kirkland.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Round A, Round B,Round C, Round D, VC, Angel = 0 tadi status startup acquired ?????????\nterdapat hal aneh dari data yang ini, kemungkinan data tidak valid","metadata":{}},{"cell_type":"markdown","source":"### How many Startup have has_VC?","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10,5))\n\n_ = sns.countplot(x=\"has_VC\", hue=\"status\", data=df, palette=\"nipy_spectral\",\n              order=df.has_VC.value_counts().index)\n\n_ = ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n_ = ax.set(xlabel=\"Has_VC\", ylabel=\"No. of startup\")\nplt.legend(bbox_to_anchor=(0.945, 0.90))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### How many Startup have is_top500?","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10,5))\n\n_ = sns.countplot(x=\"is_top500\", hue=\"status\", data=df, palette=\"nipy_spectral\",\n              order=df.is_top500.value_counts().index)\n\n_ = ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n_ = ax.set(xlabel=\"is_top500\", ylabel=\"No. of startup\")\nplt.legend(bbox_to_anchor=(0.945, 0.90))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#How many Startup have both 'acquired' status and is_top500?\nlen(df[(df[\"status\"] == True) & (df[\"is_top500\"] == True)].index)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#How many Startup have both 'closed' status and is_top500?\nlen(df[(df[\"status\"] == False) & (df[\"is_top500\"] == False)].index)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_acquired[\"is_top500\"].value_counts(normalize=True)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### How many years on average the company closes","metadata":{}},{"cell_type":"code","source":"df_closed.founded_at=pd.to_datetime(df_closed.founded_at)\ndf_closed.closed_at=pd.to_datetime(df_closed.closed_at)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_closed['age_closed_startup'] = df_closed.apply(lambda row: (row.closed_at - row.founded_at) , axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#df_closed['age_closed_startup'] = pd.to_numeric(df['age_closed_startup'].dt.days, downcast='int64')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_closed['age_closed_startup'].head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_closed['year'] = df_closed['age_closed_startup'].dt.days /365","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_closed.head(3)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(df_closed['age_closed_startup'].mean()) ","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ratarata = round(2184 / 365) \nprint(\"Rata-Rata Startup Closed :\", ratarata ,\"tahun\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### which relationship related to acquired or closed startup?","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(17,10))\n\nsns.countplot(x=\"relationships\", hue=\"status\", data=df, palette=\"nipy_spectral\",\n              order=df.relationships.value_counts().index)\nplt.legend(bbox_to_anchor=(0.945, 0.90))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### which funding_rounds related to acquired or closed startup?","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(12,8))\n\nsns.countplot(x=\"funding_rounds\", hue=\"status\", data=df, palette=\"nipy_spectral\",\n              order=df.funding_rounds.value_counts().index)\n# plt.legend(bbox_to_anchor=(0.945, 0.90))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Mapping area startup ","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nimport shapefile as shp","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'geopandas' in sys.modules","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.longitude, df.latitude))","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(gdf.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"markdown","source":"## Duplicate Values","metadata":{}},{"cell_type":"code","source":"duplicate = df[df.duplicated()] \n  \nprint(\"Duplicate Rows :\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Outliers","metadata":{}},{"cell_type":"code","source":"#ganti data type ke numerical untuk boxplot\ndf['age_first_milestone_year'] = df.age_first_milestone_year.astype(float)\ndf['age_last_milestone_year'] = df.age_last_milestone_year.astype(float)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"featuresNumfinal = ['age_first_funding_year','age_last_funding_year','age_first_milestone_year','age_last_milestone_year','funding_total_usd','avg_participants']\n\nplt.figure(figsize=(15, 7))\nfor i in range(0, len(featuresNumfinal)):\n    plt.subplot(1, len(featuresNumfinal), i+1)\n    sns.boxplot(y=df[featuresNumfinal[i]], color='green', orient='v')\n    plt.tight_layout()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def drop_outliers(df, field_name):\n    iqr = 1.5 * (np.percentile(df[field_name], 75) - np.percentile(df[field_name], 25))\n    df.drop(df[df[field_name] > (iqr + np.percentile(df[field_name], 75))].index, inplace=True)\n    df.drop(df[df[field_name] < (np.percentile(df[field_name], 25) - iqr)].index, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# drop_outliers(df, 'age_first_funding_year')\n# drop_outliers(df, 'age_last_funding_year')\n# drop_outliers(df, 'age_first_milestone_year')\n# drop_outliers(df, 'age_last_milestone_year')\ndrop_outliers(df, 'funding_total_usd')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# featuresNumfinal = ['age_first_funding_year','age_last_funding_year','age_first_milestone_year','age_last_milestone_year','funding_total_usd']\n\n# plt.figure(figsize=(15, 7))\n# for i in range(0, len(featuresNumfinal)):\n#     plt.subplot(1, len(featuresNumfinal), i+1)\n#     sns.boxplot(y=df[featuresNumfinal[i]], color='green', orient='v')\n#     plt.tight_layout()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Negative value","metadata":{}},{"cell_type":"code","source":"age=[\"age_first_funding_year\",\"age_last_funding_year\",\"age_first_milestone_year\",\"age_last_milestone_year\"]\n\nfor a in range(len(age)):\n    print(\"Is there any negative value in '{}' column  : {} \".format(age[a],(df[age[a]]<0).any()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=df.drop(df[df.age_first_funding_year<0].index)\ndf=df.drop(df[df.age_last_funding_year<0].index)\ndf=df.drop(df[df.age_first_milestone_year<0].index)\ndf=df.drop(df[df.age_last_milestone_year<0].index)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Get the absolute value of columns including negative value\n# df[\"age_first_funding_year\"]=np.abs(df[\"age_first_funding_year\"])\n# df[\"age_last_funding_year\"]=np.abs(df[\"age_last_funding_year\"])\n# df[\"age_first_milestone_year\"]=np.abs(df[\"age_first_milestone_year\"])\n# df[\"age_last_milestone_year\"]=np.abs(df[\"age_last_milestone_year\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for a in range(len(age)):\n    print(\"Is there any negative value in '{}' column  : {} \".format(age[a],(df[age[a]]<0).any()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Log-transformation of the funding and milestone year variable","metadata":{}},{"cell_type":"code","source":"# df[\"age_first_funding_year\"] = np.log(df[\"age_first_funding_year\"])\n# df[\"age_last_funding_year\"] = np.log(df[\"age_last_funding_year\"])\n# df[\"age_first_milestone_year\"] = np.log(df[\"age_first_milestone_year\"])\n# df[\"age_last_milestone_year\"] = np.log(df[\"age_last_milestone_year\"])\n# df[\"funding_total_usd\"] = np.log(df[\"funding_total_usd\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plt.figure(figsize=(15,7),dpi=100)\n\n# df[\"age_first_funding_year\"]=np.log(df[\"age_first_funding_year\"]+1)\n# plt.subplot(2,4,1)\n# plt.xlabel(\"age_first_funding_year\")\n# plt.boxplot(df[\"age_first_funding_year\"])   \n\n# plt.subplot(2,4,5)\n# sns.distplot(df[\"age_first_funding_year\"] , color=\"green\");\n\n\n# df[\"age_last_funding_year\"]=np.log(df[\"age_last_funding_year\"]+1)\n# plt.subplot(2,4,2)\n# plt.xlabel(\"age_last_funding_year\")\n# plt.boxplot(df[\"age_last_funding_year\"])   \n\n# plt.subplot(2,4,6)\n# sns.distplot(df[\"age_last_funding_year\"], color=\"green\")\n\n\n# df[\"age_first_milestone_year\"]=np.log(df[\"age_first_milestone_year\"]+1)\n# plt.subplot(2,4,3)\n# plt.xlabel(\"age_first_milestone_year\")\n# plt.boxplot(df[\"age_first_milestone_year\"])   \n\n# plt.subplot(2,4,7)\n# sns.distplot(df[\"age_first_milestone_year\"], color=\"green\")\n\n\n# df[\"age_last_milestone_year\"]=np.log(df[\"age_last_milestone_year\"]+1)\n# plt.subplot(2,4,4)\n# plt.xlabel(\"age_last_milestone_year\")\n# plt.boxplot(df[\"age_last_milestone_year\"])   \n\n# plt.subplot(2,4,8)\n# sns.distplot(df[\"age_last_milestone_year\"], color=\"green\");\n","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Log-transformation funding_total_usd","metadata":{}},{"cell_type":"code","source":"# print(f\"Skewness Co-efficient: {round(df.funding_total_usd.skew(), 3)}\")\n# fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5), dpi=300)\n\n# ## Histogram \n# sns.distplot(df['funding_total_usd'] , fit=stats.norm, ax=ax1)\n# ax1.set_title('Histogram')\n\n# ## Probability / QQPLOT\n# stats.probplot(df['funding_total_usd'], plot=ax2)\n\n# plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df[\"funding_total_usd\"] = np.log1p(df[\"funding_total_usd\"])\n\n# ##### GET SKEWNESS #####\n# print(f\"Skewness Co-efficient: {round(df.funding_total_usd.skew(), 3)}\")\n\n# fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5), dpi=300)\n\n# ##### HISTOGRAM #####\n# from scipy import stats\n# sns.distplot(df['funding_total_usd'] , fit=stats.norm, ax=ax1)\n# ax1.set_title('Histogram')\n\n# ##### PROBABILITY / QQ PLOT #####\n# stats.probplot(df['funding_total_usd'], plot=ax2)\n\n# plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Normalization/Standardization","metadata":{}},{"cell_type":"markdown","source":"## Feature encoding","metadata":{}},{"cell_type":"markdown","source":"## Class imbalance","metadata":{}},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"## New Column \"has_RoundABCD\"","metadata":{}},{"cell_type":"code","source":"df['has_RoundABCD'] = np.where((df['has_roundA'] == 1) | (df['has_roundB'] == 1) | (df['has_roundC'] == 1) | (df['has_roundD'] == 1), 1, 0)\ndf.head()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## New Column \"has_Investor\"","metadata":{}},{"cell_type":"code","source":"df['has_Investor'] = np.where((df['has_VC'] == 1) | (df['has_angel'] == 1), 1, 0)\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df[(df[\"has_RoundABCD\"] == 1)].index)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df[ (df['has_RoundABCD']  == 1) & (df['status']  == 1) ].index)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"923-490","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## New Column \"has_Seed\"","metadata":{}},{"cell_type":"code","source":"df['has_Seed'] = np.where((df['has_RoundABCD'] == 0) & (df['has_Investor'] == 1), 1, 0)\ndf.head()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['has_Seed'] == 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df[(df[\"has_Seed\"] == 1)].index)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## New Column \"invalid_startup\"","metadata":{}},{"cell_type":"code","source":"df['invalid_startup'] = np.where((df['has_RoundABCD'] == 0) & (df['has_VC'] == 0) & (df['has_angel'] == 0), 1, 0)\ndf.head()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df[(df[\"invalid_startup\"] == 1)].index)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##  New Column \"age_of_startup","metadata":{}},{"cell_type":"code","source":"df.founded_at=pd.to_datetime(df.founded_at)\ndf.closed_at=pd.to_datetime(df.closed_at)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['age_closed_startup'] = df.apply(lambda row: (row.closed_at - row.founded_at) , axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['age_closed_startup'].head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['startUp_age_year'] = df['age_closed_startup'].dt.days /365","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Drop unused column for modelling","metadata":{}},{"cell_type":"code","source":"df = df.drop(['state_code','id','Unnamed: 6','category_code','object_id'],axis=1)\ndf = df.drop(['zip_code','founded_at','closed_at','first_funding_at','last_funding_at','city','name'],axis=1)\ndf = df.drop(['Unnamed: 0'],axis=1)\ndf = df.drop(['latitude','longitude'],axis=1)\ndf = df.drop(['geometry'],axis=1)\n\ndf = df.drop(['age_closed_startup'],axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df['age_first_milestone_year'].astype(str).astype(float)\n# df['age_last_milestone_year'].astype(str).astype(float)\n\ndf['age_first_milestone_year'] = df.age_first_milestone_year.astype(float)\ndf['age_last_milestone_year'] = df.age_last_milestone_year.astype(float)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modeling","metadata":{}},{"cell_type":"code","source":"#Cek categorical\ncat_feature = df.select_dtypes(include='object')\ncat_feature.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n# Split the data\n# Input/independent variables\nX = df.drop('status', axis = 1) # her we are droping the output feature as this is the target and 'X' is input features, the changes are not \n                                              # made inplace as we have not used 'inplace = True'\n\ny = df['status'] # Output/Dependent variable\n# train_x, test_x,train_y,test_y = train_test_split(X,y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Scaling the data\n# from sklearn.preprocessing import StandardScaler\n# sc = StandardScaler()\n# X =  sc.fit_transform(X)\n# X","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lets print the shapes again \nprint(\"Shape of the X Train :\", X_train.shape)\nprint(\"Shape of the y Train :\", y_train.shape)\nprint(\"Shape of the X test :\", X_test.shape)\nprint(\"Shape of the y test :\", y_test.shape)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model Build\nfrom sklearn.metrics import confusion_matrix, classification_report,accuracy_score,roc_curve, auc, precision_recall_curve, f1_score\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## LGBM Classifier","metadata":{}},{"cell_type":"markdown","source":"##### Feature importance by LGBM","metadata":{}},{"cell_type":"code","source":"import lightgbm as lgb\n#lightGBM model fit\ngbm = lgb.LGBMRegressor()\ngbm.fit(X_train,y_train)\ngbm.booster_.feature_importance()\n\n\n# importance of each attribute\nfea_imp_ = pd.DataFrame({'cols':X.columns, 'fea_imp':gbm.feature_importances_})\nfea_imp_.loc[fea_imp_.fea_imp > 0].sort_values(by=['fea_imp'], ascending = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Recursive Feature Elimination(RFE)","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_selection import RFE\n# create the RFE model and select 10 attributes\nrfe = RFE(gbm, 10)\nrfe = rfe.fit(X_train,y_train)\n\n# summarize the selection of the attributes\nprint(rfe.support_)\n\n# summarize the ranking of the attributes\nfea_rank_ = pd.DataFrame({'cols':X.columns, 'fea_rank':rfe.ranking_})\nfea_rank_.loc[fea_rank_.fea_rank > 0].sort_values(by=['fea_rank'], ascending = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Build Model","metadata":{}},{"cell_type":"code","source":"from lightgbm import LGBMClassifier\nclf = LGBMClassifier(learning_rate=0.02,\n                    boosting_type='gbdt', max_depth=4,  objective='binary', \n                    random_state=100,  \n                  n_estimators=1000 ,reg_alpha=0, reg_lambda=1, n_jobs=-1)\n\n\nclf.fit(X_train,y_train)\n\ny_pred_lgb = clf.predict(X_test)\n\n\nprint(\"Training Accuracy :\", clf.score(X_train, y_train))\nprint(\"Testing Accuracy :\", clf.score(X_test, y_test))\n\ncm = confusion_matrix(y_test, y_pred_lgb)\nplt.rcParams['figure.figsize'] = (3, 3)\nsns.heatmap(cm, annot = True, cmap = 'YlGnBu', fmt = '.8g')\nplt.show()\n\ncr = classification_report(y_test, y_pred_lgb)\nprint(cr)\n\nprint(\"------------------------------------------\")\n\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,y_pred_lgb)\nroc_auc = auc(false_positive_rate, true_positive_rate)\nprint(\"ROC Curves              =\",roc_auc)\n\nprecision, recall, thresholds = precision_recall_curve(y_test, y_pred_lgb)\nf1 = f1_score(y_test, y_pred_lgb)\nPrecision_Recall_lgbm = auc(recall, precision)\nprint(\"Precision-Recall Curves =\",Precision_Recall_lgbm)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## XGBoost Classifier","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBClassifier\n\n#train\nxgb = XGBClassifier()\n\nxgb.fit(X_train,y_train)\n\n#predict\ny_predicted_xgb = xgb.predict(X_test)\n\nprint(\"Training Accuracy :\", xgb.score(X_train, y_train))\nprint(\"Testing Accuracy :\", xgb.score(X_test, y_test))\n\n#eval\ncm = confusion_matrix(y_test, y_predicted_xgb)\nplt.rcParams['figure.figsize'] = (3, 3)\nsns.heatmap(cm, annot = True, cmap = 'YlGnBu', fmt = '.8g')\nplt.show()\n\ncr = classification_report(y_test, y_predicted_xgb)\nprint(cr)\n\nprint(\"------------------------------------------\")\n\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,y_predicted_xgb)\nroc_auc = auc(false_positive_rate, true_positive_rate)\nprint(\"ROC Curves              =\",roc_auc)\n\nprecision, recall, thresholds = precision_recall_curve(y_test, y_predicted_xgb)\nf1 = f1_score(y_test, y_predicted_xgb)\nPrecision_Recall_xgb = auc(recall, precision)\nprint(\"Precision-Recall Curves =\",Precision_Recall_xgb)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## GradientBoosting Classifier","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\n#train\ngbc = GradientBoostingClassifier(learning_rate=0.02,\n                    max_depth=4,\n                    random_state=100, n_estimators=1000)\n\n\ngbc.fit(X_train,y_train)\n\n#predict\ny_predicted_gb = gbc.predict(X_test)\n\nprint(\"Training Accuracy :\", gbc.score(X_train, y_train))\nprint(\"Testing Accuracy :\", gbc.score(X_test, y_test))\n\n#eval\ncm = confusion_matrix(y_test, y_predicted_gb)\nplt.rcParams['figure.figsize'] = (3, 3)\nsns.heatmap(cm, annot = True, cmap = 'YlGnBu', fmt = '.8g')\nplt.show()\n\ncr = classification_report(y_test, y_predicted_gb)\nprint(cr)\n\n\nprint(\"------------------------------------------\")\n\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,y_predicted_gb)\nroc_auc = auc(false_positive_rate, true_positive_rate)\nprint(\"ROC Curves              =\",roc_auc)\n\nprecision, recall, thresholds = precision_recall_curve(y_test, y_predicted_gb)\nf1 = f1_score(y_test, y_predicted_gb)\nPrecision_Recall_gbs = auc(recall, precision)\nprint(\"Precision-Recall Curves =\",Precision_Recall_gbs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"0.922681496797328","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## AdaBoost Classifier","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\n#train\nada = AdaBoostClassifier()\n\n\nada.fit(X_train,y_train)\n\n#predict\ny_predicted_ab = ada.predict(X_test)\n\nprint(\"Training Accuracy :\", ada.score(X_train, y_train))\nprint(\"Testing Accuracy :\", ada.score(X_test, y_test))\n\n#eval\ncm = confusion_matrix(y_test, y_predicted_ab)\nplt.rcParams['figure.figsize'] = (3, 3)\nsns.heatmap(cm, annot = True, cmap = 'YlGnBu', fmt = '.8g')\nplt.show()\n\ncr = classification_report(y_test, y_predicted_ab)\nprint(cr)\n\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,y_predicted_ab)\nroc_auc = auc(false_positive_rate, true_positive_rate)\nprint(\"roc_auc\",roc_auc)\n\nprint(\"------------------------------------------\")\n\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,y_predicted_ab)\nroc_auc = auc(false_positive_rate, true_positive_rate)\nprint(\"ROC Curves              =\",roc_auc)\n\nprecision, recall, thresholds = precision_recall_curve(y_test, y_predicted_ab)\nf1 = f1_score(y_test, y_predicted_ab)\nPrecision_Recall_abs = auc(recall, precision)\nprint(\"Precision-Recall Curves =\",Precision_Recall_abs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## SVC","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVC\nsv = SVC()\n\nsv.fit(X_train,y_train)\n\n\ny_pred_sv = sv.predict(X_test)\n\nprint(\"Training Accuracy :\", sv.score(X_train, y_train))\nprint(\"Testing Accuracy :\", sv.score(X_test, y_test))\n\ncm = confusion_matrix(y_test, y_pred_sv)\nplt.rcParams['figure.figsize'] = (3, 3)\nsns.heatmap(cm, annot = True, cmap = 'YlGnBu', fmt = '.8g')\nplt.show()\n\ncr = classification_report(y_test, y_pred_sv)\nprint(cr)\n\nprint(\"------------------------------------------\")\n\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,y_pred_sv)\nroc_auc = auc(false_positive_rate, true_positive_rate)\nprint(\"ROC Curves              =\",roc_auc)\n\nprecision, recall, thresholds = precision_recall_curve(y_test, y_pred_sv)\nf1 = f1_score(y_test, y_pred_sv)\nPrecision_Recall_svc = auc(recall, precision)\nprint(\"Precision-Recall Curves =\",Precision_Recall_svc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Random Forest","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier()\n\nrf.fit(X_train,y_train)\n\n\ny_pred_rf = rf.predict(X_test)\n\nprint(\"Training Accuracy :\", rf.score(X_train, y_train))\nprint(\"Testing Accuracy :\", rf.score(X_test, y_test))\n\ncm = confusion_matrix(y_test, y_pred_rf)\nplt.rcParams['figure.figsize'] = (3, 3)\nsns.heatmap(cm, annot = True, cmap = 'YlGnBu', fmt = '.8g')\nplt.show()\n\ncr = classification_report(y_test, y_pred_rf)\nprint(cr)\n\n\nprint(\"------------------------------------------\")\n\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,y_pred_rf)\nroc_auc = auc(false_positive_rate, true_positive_rate)\nprint(\"ROC Curves              =\",roc_auc)\n\nprecision, recall, thresholds = precision_recall_curve(y_test, y_pred_rf)\nf1 = f1_score(y_test, y_pred_rf)\nPrecision_Recall_rfs = auc(recall, precision)\nprint(\"Precision-Recall Curves =\",Precision_Recall_rfs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Summary","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\n\nscores = {'LGBM':  { \n                             'precision_score': precision_score(y_test, y_pred_lgb),\n                             'recall_score': recall_score(y_test, y_pred_lgb)\n                         },        \n                 'GradientBoosting Classifier':  { \n                             'precision_score': precision_score(y_test, y_predicted_gb),\n                             'recall_score': recall_score(y_test, y_predicted_gb)\n                         },\n                 'Adaboost Classifier':  { \n                             'precision_score': precision_score(y_test, y_predicted_ab),\n                             'recall_score': recall_score(y_test, y_predicted_ab)\n                         },\n                 'SVC':  { \n                             'precision_score': precision_score(y_test, y_pred_sv),\n                             'recall_score': recall_score(y_test, y_pred_sv)\n                         },\n                 'XGBoost':  { \n                             'precision_score': precision_score(y_test, y_predicted_xgb),\n                             'recall_score': recall_score(y_test, y_predicted_xgb)\n                         },\n                 'Random Forest':  { \n                             'precision_score': precision_score(y_test, y_pred_rf),\n                            'recall_score': recall_score(y_test, y_pred_rf)\n                         }\n            }","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import precision_score\n\n\nPrecision_Recall = {'LGBM':  { \n                             'Precision_Recall': Precision_Recall_lgbm\n                         },        \n                 'GradientBoosting Classifier':  { \n                             'Precision_Recall': Precision_Recall_gbs\n                         },\n                 'Adaboost Classifier':  { \n                             'Precision_Recall': Precision_Recall_abs\n                         },\n                 'SVC':  { \n                             'Precision_Recall': Precision_Recall_svc\n                         },\n                 'XGBoost':  { \n                             'Precision_Recall': Precision_Recall_xgb\n                         },\n                 'Random Forest':  { \n                             'Precision_Recall': Precision_Recall_rfs\n                         }\n            }","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = pd.DataFrame(scores)\n\n\nscores.plot(kind=\"barh\",figsize=(12, 12)).legend(loc='upper center', ncol=3, title=\"Machine Learning Model\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Precision_Recall = pd.DataFrame(Precision_Recall)\n\n\nPrecision_Recall.plot(kind=\"barh\",figsize=(15, 8)).legend(loc='upper center', ncol=3, title=\"Machine Learning Model\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}