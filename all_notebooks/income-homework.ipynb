{"cells":[{"metadata":{},"cell_type":"markdown","source":"# **1. The problem statement**\n\nIn this kernel, I try to make predictions where the prediction task is to determine whether a person makes over 50K a year. I implement Random Forest Classification, Decision Tree and SVM with Python and Scikit-Learn. So, to answer the question, I build a Random Forest classifier, Decision Tree and SVM to predict whether a person makes over 50K a year.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 2. Import libraries","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn import metrics\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nsns.set(style=\"whitegrid\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Import dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data='/kaggle/input/income-classification/income_evaluation.csv'\ndf=pd.read_csv(data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Exploratory data analysis\n\nNow, I will explore the data to gain insights about the data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#print the shape\nprint('The shape of the dataset : ' , df.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that there are 32561 instances and 15 attributes in the data set.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Rename column names\n\nWe can see that the dataset does not have proper column names. The column names contain underscore. We should give proper names to the columns. I will do it as follows:-","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"col_names = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', 'relationship',\n             'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country', 'income']\n\ndf.columns = col_names\n\ndf.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Findings\n\nWe can see that the dataset contains 9 character variables and 6 numerical variables.\nincome is the target variable.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above df.describe() command presents statistical properties in vertical form.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#check for missing value\n\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Types of variables\n\nIn this section, I segregate the dataset into categorical and numerical variables.\n\nThere are a mixture of categorical and numerical variables in the dataset.\n\nCategorical variables have data type object. Numerical variables have data type int64.\n\nFirst of all, I will explore categorical variables.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical = [var for var in df.columns if df[var].dtype=='O']\n\nprint('There are {} categorical variables\\n'.format(len(categorical)))\n\nprint('The categorical variables are :\\n\\n', categorical)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* There are 9 categorical variables in the dataset.\n\n* The categorical variables are given by workclass, education, marital_status, occupation, relationship, race, sex, native_country and income.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df[categorical].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we will check the frequency distribution of categorical variables.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for var in categorical: \n    \n    print(df[var].value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Percentage of frequency distribution of values","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Explore income target variable","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# check for missing values\n\ndf['income'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We can see that there are no missing values in the income target variable.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# view number of unique values\n\ndf['income'].nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# view the frequency distribution of values\n\ndf['income'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**The two unique values are <=50K and >50K.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# view percentage of frequency distribution of values\n\ndf['income'].value_counts()/len(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualize frequency distribution of income variable\n\nf,ax=plt.subplots(1,2,figsize=(18,8))\n\nax[0] = df['income'].value_counts().plot.pie(explode=[0,0],autopct='%1.1f%%',ax=ax[0],shadow=True)\nax[0].set_title('Income Share')\n\n\n#f, ax = plt.subplots(figsize=(6, 8))\nax[1] = sns.countplot(x=\"income\", data=df, palette=\"Set1\")\nax[1].set_title(\"Frequency distribution of income variable\")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We can see that males make more money than females in both the income categories.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# check number of unique labels \n\ndf.workclass.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# view frequency distribution of values\n\ndf.workclass.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# replace '?' values in workclass variable with `NaN`\n\ndf['workclass'].replace(' ?', np.NaN, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# again check the frequency distribution of values in workclass variable\n\ndf.workclass.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(figsize=(10, 6))\nax = df.workclass.value_counts().plot(kind=\"bar\", color=\"green\")\nax.set_title(\"Frequency distribution of workclass variable\")\nax.set_xticklabels(df.workclass.value_counts().index, rotation=30)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that there are lot more private workers than other category of workers.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# check number of unique labels\n\ndf.occupation.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# view unique labels\n\ndf.occupation.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# view frequency distribution of values\n\ndf.occupation.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# replace '?' values in occupation variable with `NaN`\n\ndf['occupation'].replace(' ?', np.NaN, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# again check the frequency distribution of values\n\ndf.occupation.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check number of unique labels\n\ndf.native_country.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# view unique labels \n\ndf.native_country.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check frequency distribution of values\n\ndf.native_country.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# replace '?' values in native_country variable with `NaN`\n\ndf['native_country'].replace(' ?', np.NaN, inplace=True)\n# again check the frequency distribution of values\n\ndf.native_country.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[categorical].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that native_country column contains relatively large number of labels as compared to other columns. I will check for cardinality after train-test split.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Find numerical variables","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical = [var for var in df.columns if df[var].dtype!='O']\n\nprint('There are {} numerical variables\\n'.format(len(numerical)))\n\nprint('The numerical variables are :\\n\\n', numerical)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[numerical].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[numerical].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that there are no missing values in the numerical variables.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['age'].nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(figsize=(10,8))\nx = df['age']\nax = sns.distplot(x, bins=10, color='blue')\nax.set_title(\"Distribution of age variable\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Explore relationship between age and income variables**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**As expected, younger people make less money as compared to senior people.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot correlation heatmap to find out correlations\n\ndf.corr().style.format(\"{:.4}\").background_gradient(cmap=plt.get_cmap('coolwarm'), axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We can see that there is no strong correlation between variables.**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":" **Declare feature vector and target variable**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X=df.drop(['income'],axis=1)\n\ny=df['income']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Split data into separate training and test set","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Scikit-Learn (sklearn) â†’ Commonly used open source machine learning library**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#check the shape of X_train and X_test\n\nX_train.shape, X_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**I will do feature engineering on different variables.**\n\n**First, I will show the categorical and numerical variables separately in the training set.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical = [col for col in X_train.columns if X_train[col].dtypes == 'O']\n\ncategorical","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical = [col for col in X_train.columns if X_train[col].dtypes != 'O']\n\nnumerical","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print percentage of missing values in the categorical variables in training set\n\nX_train[categorical].isnull().mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print categorical variables with missing data\n\nfor col in categorical:\n    if X_train[col].isnull().mean()>0:\n        print(col, (X_train[col].isnull().mean()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for df2 in [X_train, X_test]:\n    df2['workclass'].fillna(X_train['workclass'].mode()[0], inplace=True)\n    df2['occupation'].fillna(X_train['occupation'].mode()[0], inplace=True)\n    df2['native_country'].fillna(X_train['native_country'].mode()[0], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check missing values in categorical variables in X_train\n\nX_train[categorical].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check missing values in categorical variables in X_test\n\nX_test[categorical].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**As a final check, I will check for missing values in X_train and X_test.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# check missing values in X_train\n\nX_train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check missing values in X_test\n\nX_test.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We can see that there are no missing values in X_train and X_test.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# preview categorical variables in X_train\n\nX_train[categorical].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import category encoders\n\nimport category_encoders as ce","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**One Hot Encoding means that categorical variables are represented as binary.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# encode categorical variables with one-hot encoding\n\nencoder = ce.OneHotEncoder(cols=['workclass', 'education', 'marital_status', 'occupation', 'relationship', \n                                 'race', 'sex', 'native_country'])\n\nX_train = encoder.fit_transform(X_train)\n\nX_test = encoder.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Similarly, I will take a look at the X_test set.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = X_train.columns\nfrom sklearn.preprocessing import RobustScaler\n\nscaler = RobustScaler()\n\nX_train = scaler.fit_transform(X_train)\n\nX_test = scaler.transform(X_test)\nX_train = pd.DataFrame(X_train, columns=[cols])\nX_test = pd.DataFrame(X_test, columns=[cols])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We now have X_train dataset ready to be fed into the Random Forest classifier.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# import Random Forest classifier\n\nfrom sklearn.ensemble import RandomForestClassifier\n\n\n# instantiate the classifier \n\nrfc = RandomForestClassifier(random_state=0)\n\n\n\n# fit the model\n\nrfc.fit(X_train, y_train)\n\n\n\n# Predict the Test set results\n\ny_pred = rfc.predict(X_test)\n\n#Check accuracy score\n\n\nfrom sklearn.metrics import accuracy_score\n\nprint('Model accuracy score with Random Forest (with 10 decision tree ) : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# instantiate the classifier with n_estimators = 100\n\nrfc_100 = RandomForestClassifier(n_estimators=100, random_state=0)\n\n\n\n# fit the model to the training set\n\nrfc_100.fit(X_train, y_train)\n\n\n\n# Predict on the test set results\n\ny_pred_100 = rfc_100.predict(X_test)\n\n\n\n# Check accuracy score \n\nprint('Model accuracy score with Random Forest (with 100 decision tree ) : {0:0.4f}'. format(accuracy_score(y_test, y_pred_100)))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**The expected accuracy increases with number of decision-trees in the model.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dt = DecisionTreeClassifier()\ndt.fit(X_train,y_train)\ny_predict_dt = dt.predict(X_test)\nacc_dt = metrics.accuracy_score(y_predict_dt,y_test)\nprint('The accuracy of the Decision Tree is', acc_dt)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sv = SVC() #select the algorithm\nsv.fit(X_train,y_train) # we train the algorithm with the training data and the training output\ny_predict_svm = sv.predict(X_test) #now we pass the testing data to the trained algorithm\nacc_svm = metrics.accuracy_score(y_predict_svm,y_test)\nprint('The accuracy of the SVM is:', acc_svm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print the Confusion Matrix and slice it into four pieces\n\nfrom sklearn.metrics import confusion_matrix\n\ncm = confusion_matrix(y_test, y_pred)\n\nprint('Confusion matrix\\n\\n', cm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualize confusion matrix with seaborn heatmap\n\ncm_matrix = pd.DataFrame(data=cm, columns=['Actual Positive:1', 'Actual Negative:0'], \n                                 index=['Predict Positive:1', 'Predict Negative:0'])\n\nsns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nprint(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}