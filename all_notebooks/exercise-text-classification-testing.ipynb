{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"!pip install -U -t /kaggle/working/ git+https://github.com/Kaggle/learntools.git@fix-nlp-bug"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"import sys\nsys.path.append('/kaggle/working')"},{"cell_type":"markdown","metadata":{},"source":"**[Natural Language Processing Home Page](https://www.kaggle.com/learn/natural-language-processing)**\n\n---\n"},{"cell_type":"markdown","metadata":{},"source":"# Natural Language Classification\n\nYou did a great such a great job for DeFalco's restaurant in the previous exercise that the chef has hired you for a new project.\n\nThe restaurant's menu includes an email address where visitors can give feedback about their food. \n\nThe manager wants you to create a tool that automatically sends him all the negative reviews so he can fix them, while automatically sending all the positive reviews to the owner, so the manager can ask for a raise. \n\nYou will first build a model to distinguish positive reviews from negative reviews using Yelp reviews because these reviews include a rating with each review. Your data consists of the text body of each review along with the star rating. Ratings with 1-2 stars count as \"negative\", and ratings with 4-5 stars are \"positive\". Ratings with 3 stars are \"neutral\" and have been dropped from the data.\n\nLet's get started. First, run the next code cell."},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"import pandas as pd\n\n# Set up code checking\nfrom learntools.core import binder\nbinder.bind(globals())\nfrom learntools.nlp.ex2 import *\nprint(\"\\nSetup complete\")"},{"cell_type":"markdown","metadata":{},"source":"# Step 1: Evaluate the Approach\n\nIs there anything about this approach that concerns you? After you've thought about it, run the function below to see one point of view."},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# Check your answer (Run this code cell to receive credit!)\nstep_1.solution()"},{"cell_type":"markdown","metadata":{},"source":"# Step 2: Review Data and Create the model\n\nMoving forward with your plan, you'll need to load the data. Here's some basic code to load data and split it into a training and validation set. Run this code."},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"def load_data(csv_file, split=0.9):\n    data = pd.read_csv(csv_file)\n    \n    # Shuffle data\n    train_data = data.sample(frac=1, random_state=7)\n    \n    texts = train_data.text.values\n    labels = [{\"POSITIVE\": bool(y), \"NEGATIVE\": not bool(y)}\n              for y in train_data.sentiment.values]\n    split = int(len(train_data) * split)\n    \n    train_labels = [{\"cats\": labels} for labels in labels[:split]]\n    val_labels = [{\"cats\": labels} for labels in labels[split:]]\n    \n    return texts[:split], train_labels, texts[split:], val_labels\n\ntrain_texts, train_labels, val_texts, val_labels = load_data('../input/nlp-course/yelp_ratings.csv')"},{"cell_type":"markdown","metadata":{},"source":"You will use this training data to build a model. The code to build the model is the same as what you saw in the tutorial. So that is copied below for you.\n\nBut because your data is different, there are **two lines in the modeling code cell that you'll need to change.** Can you figure out what they are? \n\nFirst, run the cell below to look at a couple elements from your training data."},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"print('Texts from training data\\n------')\nprint(train_texts[:2])\nprint('\\nLabels from training data\\n------')\nprint(train_labels[:2])\n"},{"cell_type":"markdown","metadata":{},"source":"Now, having seen this data, find the two lines that need to be changed."},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"import spacy\n\n# Create an empty model\nnlp = spacy.blank(\"en\")\n\n# Create the TextCategorizer with exclusive classes and \"bow\" architecture\ntextcat = nlp.create_pipe(\n              \"textcat\",\n              config={\n                \"exclusive_classes\": True,\n                \"architecture\": \"bow\"})\n\n# Add the TextCategorizer to the empty model\nnlp.add_pipe(textcat)\n\n# Add labels to text classifier\ntextcat.add_label(\"ham\")\ntextcat.add_label(\"spam\")\n\n# Check your answer\nstep_2.check()"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# Lines below will give you a hint or solution code\nstep_2.hint()\nstep_2.solution()"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"#%%RM_IF(PROD)%%\n\nimport spacy\n\n# Create an empty model\nnlp = spacy.blank(\"en\")\n\n# Create the TextCategorizer with exclusive classes and \"bow\" architecture\ntextcat = nlp.create_pipe(\n            \"textcat\",\n            config={\n                \"exclusive_classes\": True,\n                \"architecture\": \"bow\"})\nnlp.add_pipe(textcat)\n\n# Add NEGATIVE and POSITIVE labels to text classifier\ntextcat.add_label(\"NEGATIVE\")\ntextcat.add_label(\"POSITIVE\")\n\nstep_2.assert_check_passed()"},{"cell_type":"markdown","metadata":{},"source":"# Step 3: Train Function\n\nImplement a function `train` that updates a model with training data. Most of this is general data munging, which we've filled in for you. Just add the one line of code necessary to update your model."},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"from spacy.util import minibatch\nimport random\n\ndef train(model, train_data, optimizer):\n    losses = {}\n    random.seed(1)\n    random.shuffle(train_data)\n    \n    batches = minibatch(train_data, size=8)\n    for batch in batches:\n        # train_data is a list of tuples [(text0, label0), (text1, label1), ...]\n        # Split batch into texts and labels\n        texts, labels = zip(*batch)\n        \n        # Update model with texts and labels\n        ____\n        \n    return losses\n\n# Check your answer\nstep_3.check()"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# Lines below will give you a hint or solution code\nstep_3.hint()\nstep_3.solution()"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"#%%RM_IF(PROD)%%\n\nfrom spacy.util import minibatch\nimport random\n\ndef train(model, train_data, optimizer, batch_size=8):\n    losses = {}\n    #random.seed(1)\n    random.shuffle(train_data)\n    batches = minibatch(train_data, size=batch_size)\n    for batch in batches:\n        texts, labels = zip(*batch)\n        model.update(texts, labels, sgd=optimizer, losses=losses)\n    return losses\n\nstep_3.assert_check_passed()"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# Fix seed for reproducibility\nspacy.util.fix_random_seed(1)\nrandom.seed(1)\n\n# This may take a while to run!\noptimizer = nlp.begin_training()\ntrain_data = list(zip(train_texts, train_labels))\nlosses = train(nlp, train_data, optimizer)\nprint(losses['textcat'])"},{"cell_type":"markdown","metadata":{},"source":"We can try this slightly trained model on some example text and look at the probabilities assigned to each label."},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"text = \"This tea cup was full of holes. Do not recommend.\"\ndoc = nlp(text)\nprint(doc.cats)"},{"cell_type":"markdown","metadata":{},"source":"These probabilities look reasonable. Now you should turn them into an actual prediction.\n\n# Step 4: Making Predictions\n\nImplement a function `predict` that uses a model to predict the sentiment of text examples. The function takes a spaCy model (with a `TextCategorizer`) and a list of texts. First, tokenize the texts using `model.tokenizer`. Then, pass those docs to the TextCategorizer which you can get from `model.get_pipe`. Use the `textcat.predict` method to get scores for each document, then choose the class with the highest score (probability) as the predicted class."},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"def predict(model, texts): \n    # Use the model's tokenizer to tokenize each input text\n    docs = ____\n    \n    # Use textcat to get the scores for each doc\n    ____\n    \n    # From the scores, find the class with the highest score/probability\n    predicted_class = ____\n    \n    return predicted_class\n\n# Check your answer\nstep_4.check()"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# Lines below will give you a hint or solution code\nstep_4.hint()\nstep_4.solution()"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"#%%RM_IF(PROD)%%\n\ndef predict(model, texts): \n    # Use the tokenizer to tokenize each input text example\n    docs = [model.tokenizer(text) for text in texts]\n    \n    # Use textcat to get the scores for each doc\n    textcat = model.get_pipe('textcat')\n    scores, _ = textcat.predict(docs)\n    \n    # From the scores, find the class with the highest score/probability\n    predicted_class = scores.argmax(axis=1)\n    \n    return predicted_class\n\nstep_4.assert_check_passed()"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"texts = val_texts[34:38]\npredictions = predict(nlp, texts)\n\nfor p, t in zip(predictions, texts):\n    print(f\"{textcat.labels[p]}: {t} \\n\")"},{"cell_type":"markdown","metadata":{},"source":"It looks like your model is working well after going through the data just once. However you need to calculate some metric for the model's performance on the hold-out validation data.\n\n# Step 5: Evaluate The Model\n\nImplement a function that evaluates a `TextCategorizer` model. This function `evaluate` takes a model along with texts and labels. It returns the accuracy of the model, which is the number of correct predictions divided by all predictions.\n\nFirst, use the `predict` method you wrote earlier to get the predicted class for each text in `texts`. Then, find where the predicted labels match the true \"gold-standard\" labels and calculate the accuracy."},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"def evaluate(model, texts, labels):\n    \"\"\" Returns the accuracy of a TextCategorizer model. \n    \n        Arguments\n        ---------\n        model: ScaPy model with a TextCategorizer\n        texts: Text samples, from load_data function\n        labels: True labels, from load_data function\n    \n    \"\"\"\n    # Get predictions from textcat model (using your predict method)\n    predicted_class = ____\n    \n    # From labels, get the true class as a list of integers (POSITIVE -> 1, NEGATIVE -> 0)\n    true_class = ____\n    \n    # A boolean or int array indicating correct predictions\n    correct_predictions = ____\n    \n    # The accuracy, number of correct predictions divided by all predictions\n    accuracy = ____\n    \n    return accuracy\n\nstep_5.check()"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# Lines below will give you a hint or solution code\nstep_5.hint()\nstep_5.solution()"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"#%%RM_IF(PROD)%%\n\ndef evaluate(model, texts, labels):\n    \"\"\" Returns the accuracy of a TextCategorizer model. \n    \n        Arguments\n        ---------\n        model: ScaPy model with a TextCategorizer\n        texts: Text samples, from load_data function\n        labels: True labels, from load_data function\n    \n    \"\"\"\n    # Get predictions from textcat model\n    predicted_class = predict(model, texts)\n    \n    # From labels, get the true class as a list of integers (POSITIVE -> 1, NEGATIVE -> 0)\n    true_class = [int(each['cats']['POSITIVE']) for each in labels]\n    \n    # A boolean or int array indicating correct predictions\n    correct_predictions = predicted_class == true_class\n    \n    # The accuracy, number of correct predictions divided by all predictions\n    accuracy = correct_predictions.mean()\n    \n    return accuracy\n\n# just changed this. not sure ...\nstep_5.assert_check_passed()"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"accuracy = evaluate(nlp, val_texts, val_labels)\nprint(f\"Accuracy: {accuracy:.4f}\")"},{"cell_type":"markdown","metadata":{},"source":"With the functions implemented, you can train and evaluate in a loop."},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# This may take a while to run!\nn_iters = 5\nfor i in range(n_iters):\n    losses = train(nlp, train_data, optimizer)\n    accuracy = evaluate(nlp, val_texts, val_labels)\n    print(f\"Loss: {losses['textcat']:.3f} \\t Accuracy: {accuracy:.3f}\")"},{"cell_type":"markdown","metadata":{},"source":"# Step 6: Keep Improving\n\nYou've built the necessary components to train a text classifier with spaCy. What could you do further to optimize the model?\n\nRun the next line to check your answer."},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# Check your answer (Run this code cell to receive credit!)\nstep_6.solution()"},{"cell_type":"markdown","metadata":{},"source":"## Keep Going\n\nThe next step is a big one. See how you can **[represent tokens as vectors that describe their meaning](https://www.kaggle.com/alexisbcook/word-vectors-testing)**, and plug those into your machine learning models."},{"cell_type":"markdown","metadata":{},"source":"---\n**[Natural Language Processing Home Page](https://www.kaggle.com/learn/natural-language-processing)**\n\n\n\n\n\n*Have questions or comments? Visit the [Learn Discussion forum](https://www.kaggle.com/learn-forum/161466) to chat with other Learners.*"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":4}