{"cells":[{"metadata":{},"cell_type":"markdown","source":"Read Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd \n\ndf =  pd.read_csv('../input/telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv')\nvisu_df = df.copy();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Display important information about the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe().transpose()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Quick check of the distribution of our classes."},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Churn'].value_counts().plot(kind = 'barh')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"According to the result, we clearly see a huge difference between Churn and None-Churn.\nDue to that and in order to build good multivariate models we need to apply under/over sampling technics.\nLater in this exemple I will apply a simple under-sampling methodin order to have same length of both Churn and None Churn classes."},{"metadata":{},"cell_type":"raw","source":"Data visualisation"},{"metadata":{"trusted":true},"cell_type":"code","source":"def encode_to_numerical_data(raw_data):\n    for i in raw_data:\n        if raw_data[i].dtype == 'object':\n            raw_data[i] = factorization(raw_data, i)\n    return raw_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def factorization(raw_data, col):\n    return pd.factorize(raw_data[col])[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoded_data = encode_to_numerical_data(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(30,20)) \nx_matrix = encoded_data.drop(['Churn', 'customerID'], axis=1)\ncorr_map = x_matrix.corr()\nsns.heatmap(corr_map, vmax=.8, square=True, annot=True, fmt='.2f', cmap=\"summer\")\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"According to this heatmap we can clearly see a significante correlation between: Internet Service, Online Security, Online Backup,Device Protection, Tech Support,Streaming TV and Streaming Movies plus Contract and Tenure."},{"metadata":{"trusted":true},"cell_type":"code","source":"    fig, axes = plt.subplots(1, 2, sharex=True, figsize=(20, 10))\n    fig.suptitle('Summary')\n\n    sns.countplot(ax=axes[0], x=\"Churn\", hue=\"InternetService\", data=visu_df)\n    sns.countplot(ax=axes[1], x=\"Churn\", hue=\"PhoneService\", data=visu_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Image on the right:** \nThe majority of customers ( churn or not ) have the Phone Service , just a few minority doesn't have this service.\n\n**Image on the left** : \nIn No Churn category : DSL is the most consumed product with small difference with Optical fiber.\nIn Churn category : the churn is significant with fiber optic consumers which give us a prior idea that the company should pay more attention to this product and make an alarm, because it has a huge factor of churn.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"    fig, axes = plt.subplots(4, 2, sharex=True, figsize=(20, 10))\n    fig.suptitle('Summary')\n    sns.barplot(ax=axes[0, 0], x=\"tenure\", y=\"Contract\", hue=\"gender\", data=visu_df,orient=\"h\")\n    sns.barplot(ax=axes[0, 1], x=\"tenure\", y=\"Contract\", hue=\"PaymentMethod\", data=visu_df,orient=\"h\")\n    sns.barplot(ax=axes[1, 0], x=\"tenure\", y=\"StreamingMovies\", hue=\"gender\", data=visu_df,orient=\"h\")\n    sns.barplot(ax=axes[1, 1], x=\"tenure\", y=\"StreamingMovies\", hue=\"Partner\", data=visu_df,orient=\"h\")\n    sns.barplot(ax=axes[2, 0], x=\"MonthlyCharges\", y=\"InternetService\", hue=\"StreamingTV\", data=visu_df,orient=\"h\")\n    sns.barplot(ax=axes[2, 1], x=\"tenure\", y=\"OnlineSecurity\", hue=\"DeviceProtection\", data=visu_df,orient=\"h\")\n    sns.barplot(ax=axes[3, 0], x=\"tenure\", y=\"OnlineSecurity\", hue=\"InternetService\", data=visu_df,orient=\"h\")\n    sns.barplot(ax=axes[3, 1], x=\"tenure\", y=\"Contract\", hue=\"PaperlessBilling\", data=visu_df,orient=\"h\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the left to the right:\n1. No significant info can be recorded with Contract , Gender and Tenure features, same behaviour between males and females.\n2. Payment methods : the favorite means of payments are Electronic Check, Bank transfer and credit card, Mailed check is the less used in all contracts types.\n3. No significant info can be recorded with Internet Service , Gender and Tenure features, same behaviour between males and females.\n4. Streaming Movies : the most custmers that consume this service are partners\n5. Optic fiber is expensive. (I guess this is why customers are leaving out this product)\n6. Some people have device protection without online protection (weird , the company should tell them that it not necessery and they can be rewarded with a usefull service instead.. in order to gain customers trust :))\n7. Internet Service custmers with large tenure tend to make online Seciruty.\n8. Large tenure is significant whith paperless billing ( he company should prioritizee this mean of payment).\n\n"},{"metadata":{},"cell_type":"markdown","source":"Data partition\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\n\n\nx_matrix = encoded_data.drop(['Churn', 'customerID'], axis=1).values\ny_labels = encoded_data['Churn'].values\n\n# Data standardization\nx_matrix = StandardScaler().fit_transform(x_matrix)\n\n# UnderResampling (SMOTE tested but not efficient)\nchurn_args = np.argwhere(y_labels[:] == 1)\nnotChurn_args = np.argwhere(y_labels[:] == 0)\n\nx_reduced = np.vstack((x_matrix[0:len(churn_args)], np.squeeze(x_matrix[churn_args])))\ny_reduced = np.vstack(((y_labels[0:len(churn_args)]).reshape(1869, 1), y_labels[churn_args]))\n\nX_train, X_test, y_train, y_test = train_test_split(x_reduced, np.squeeze(y_reduced))\n\nprint(np.shape(X_train))\nprint(np.shape(y_train))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**As stated before the dataset is imbalanced, so to deal with such problem, under / oversampling methods should be used.\nSmote and several others technics were performed, but the used method performed well.\nSince we have enough data simple undersampling is enough :)**"},{"metadata":{},"cell_type":"markdown","source":"GridSearch CV for best model selection"},{"metadata":{"trusted":true},"cell_type":"code","source":"import joblib\nfrom sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models = ['ADB', 'GBC', 'RF', 'XGB', 'SVC']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clfs = [\n    AdaBoostClassifier(),\n    GradientBoostingClassifier(),\n    RandomForestClassifier(n_jobs=-1),\n    XGBClassifier(),\n    SVC(probability=True)\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\n    models[0]: {'learning_rate': [1, 0.01], 'n_estimators': [500, 1000]},\n    models[1]: {'learning_rate': [0.01], 'n_estimators': [500, 1000], 'max_depth': [3],\n                'min_samples_split': [2], 'min_samples_leaf': [2]},\n    models[2]: {'n_estimators': [500, 1000, 1500], 'criterion': ['gini'], 'min_samples_split': [2],\n                'min_samples_leaf': [4]},\n    models[3]: {},\n    models[4]: {'C': [0.01, 1, 10, 100], 'gamma': [1, 0.1], 'kernel': ['rbf', 'linear']},\n\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"    for name, estimator in zip(models, clfs):\n        print(\"Performing : \" + name)\n        clf = GridSearchCV(estimator, params[name], n_jobs=-1, cv=10)\n\n        clf.fit(X_train, y_train)\n\n        print(\"best params: \" + str(clf.best_params_))\n        print(\"best scores: \" + str(clf.best_score_))\n        y_pred = clf.predict(X_test)\n        acc = accuracy_score(y_test, y_pred)\n        print(\"Accuracy: {:.4%}\".format(acc))\n\n        # save the model to disk\n        if acc >= .8 and clf.best_score_ >= .8:\n            joblib.dump(clf, './' + name + str(clf.best_score_))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}