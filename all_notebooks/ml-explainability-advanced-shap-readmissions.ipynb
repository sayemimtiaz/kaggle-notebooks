{"cells":[{"metadata":{},"cell_type":"markdown","source":"<img src=\"https://storage.googleapis.com/kaggle-competitions/kaggle/19150/logos/header.png\" width=\"1000px\">"},{"metadata":{},"cell_type":"markdown","source":"This is a slightly manipulated version of the Diabetes-130 dataset. The manipulations are just to set it up for modeling with things like one-hot-encoding of categorical variables. The dataset itself is available with description on [Kaggle](https://www.kaggle.com/brandao/diabetes/home) and through [UCI](https://archive.ics.uci.edu/ml/datasets/diabetes+130-us+hospitals+for+years+1999-2008).\n\nThere is more detail in the [original research paper](https://www.hindawi.com/journals/bmri/2014/781670/) for which the dataset was produced."},{"metadata":{},"cell_type":"markdown","source":"**This notebook is an exercise in the [Machine Learning Explainability](https://www.kaggle.com/learn/machine-learning-explainability) course.  You can reference the tutorial at [this link](https://www.kaggle.com/dansbecker/advanced-uses-of-shap-values).**\n\n---\n"},{"metadata":{},"cell_type":"markdown","source":"## Set Up\n\n\nWe have again provided code to do the basic loading, review and model-building. Run the cell below to set everything up:"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\nimport shap\n\n# Environment Set-Up for feedback system.\nfrom learntools.core import binder\nbinder.bind(globals())\nfrom learntools.ml_explainability.ex5 import *\nprint(\"Setup Complete\")\n\n\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\n\ndata = pd.read_csv('../input/hospital-readmissions/train.csv')\ny = data.readmitted\nbase_features = ['number_inpatient', 'num_medications', 'number_diagnoses', 'num_lab_procedures', \n                 'num_procedures', 'time_in_hospital', 'number_outpatient', 'number_emergency', \n                 'gender_Female', 'payer_code_?', 'medical_specialty_?', 'diag_1_428', 'diag_1_414', \n                 'diabetesMed_Yes', 'A1Cresult_None']\n\n# Some versions of shap package error when mixing bools and numerics\nX = data[base_features].astype(float)\n\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\n\n# For speed, we will calculate shap values on smaller subset of the validation data\nsmall_val_X = val_X.iloc[:150]\nmy_model = RandomForestClassifier(n_estimators=30, random_state=1).fit(train_X, train_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.sample(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.sample(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The first few questions require examining the distribution of effects for each feature, rather than just an average effect for each feature.  Run the following cell for a summary plot of the shap_values for readmission. It will take about 20 seconds to run."},{"metadata":{"trusted":true},"cell_type":"code","source":"small_val_X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"explainer = shap.TreeExplainer(my_model)\nshap_values = explainer.shap_values(small_val_X)\n\nshap.summary_plot(shap_values[1], small_val_X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Question 1\n\nWhich of the following features has a bigger range of effects on predictions (i.e. larger difference between most positive and most negative effect)\n- `diag_1_428` or\n- `payer_code_?`"},{"metadata":{"trusted":true},"cell_type":"code","source":"# set following variable to 'diag_1_428' or 'payer_code_?'\nfeature_with_bigger_range_of_effects = 'diag_1_428'\n\n# Check your answer\nq_1.check()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Uncomment the line below to see the solution and explanation."},{"metadata":{"trusted":true},"cell_type":"code","source":"q_1.solution()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Question 2\n\nDo you believe the range of effects sizes (distance between smallest effect and largest effect) is a good indication of which feature will have a higher permutation importance? Why or why not?  \n\nIf the **range of effect sizes** measures something different from **permutation importance**: which is a better answer for the question \"Which of these two features does the model say is more important for us to understand when discussing readmission risks in the population?\"\n\nRun the following line after you've decided your answer."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check your answer (Run this code cell to receive credit!)\nq_2.solution()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Question 3\n\nBoth `diag_1_428` and `payer_code_?` are binary variables, taking values of 0 or 1.\n\nFrom the graph, which do you think would typically have a bigger impact on predicted readmission risk:\n- Changing `diag_1_428` from 0 to 1\n- Changing `payer_code_?` from 0 to 1\n\nTo save you scrolling, we have included a cell below to plot the graph again (this one runs quickly)."},{"metadata":{"trusted":true},"cell_type":"code","source":"shap.summary_plot(shap_values[1], small_val_X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set following var to \"diag_1_428\" if changing it to 1 has bigger effect.  Else set it to 'payer_code_?'\nbigger_effect_when_changed = 'diag_1_428'\n\n# Check your answer\nq_3.check()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For a solution and explanation, uncomment the line below."},{"metadata":{"trusted":true},"cell_type":"code","source":"#q_3.solution()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Question 4\n\nSome features (like `number_inpatient`) have reasonably clear separation between the blue and pink dots. Other variables like `num_lab_procedures` have blue and pink dots jumbled together, even though the SHAP values (or impacts on prediction) aren't all 0.\n\nWhat do you think you learn from the fact that `num_lab_procedures` has blue and pink dots jumbled together? Once you have your answer, run the line below to verify your solution."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check your answer (Run this code cell to receive credit!)\nq_4.solution()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Question 5\n\nConsider the following SHAP contribution dependence plot. \n\nThe x-axis shows `feature_of_interest` and the points are colored based on `other_feature`.\n\n![Imgur](https://i.imgur.com/zFdHneM.png)\n\nIs there an interaction between `feature_of_interest` and `other_feature`?  \nIf so, does `feature_of_interest` have a more positive impact on predictions when `other_feature` is high or when `other_feature` is low?\n\nRun the following code when you are ready for the answer."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check your answer (Run this code cell to receive credit!)\nq_5.solution()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Question 6\n\nReview the summary plot for the readmission data by running the following cell:"},{"metadata":{"trusted":true},"cell_type":"code","source":"shap.summary_plot(shap_values[1], small_val_X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Both **num_medications** and **num_lab_procedures** share that jumbling of pink and blue dots.\n\nAside from `num_medications` having effects of greater magnitude (both more positive and more negative), it's hard to see a meaningful difference between how these two features affect readmission risk.  Create the SHAP dependence contribution plots for each variable, and describe what you think is different between how these two variables affect predictions.\n\nAs a reminder, here is the code you previously saw to create this type of plot.\n\n    shap.dependence_plot(feature_of_interest, shap_values[1], val_X)\n    \nAnd recall that your validation data is called `small_val_X`."},{"metadata":{"trusted":true},"cell_type":"code","source":"shap.dependence_plot('num_medications', shap_values[1], small_val_X) #, interaction_index='num_lab_procedures'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shap.dependence_plot('num_lab_procedures', shap_values[1], small_val_X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Then run the following line to compare your observations from this graph to the solution."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check your answer (Run this code cell to receive credit!)\nq_6.solution()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in small_val_X.columns:\n    print('num_medications interacting with', feature)\n    shap.dependence_plot('num_medications', shap_values[1], small_val_X, interaction_index=feature)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in small_val_X.columns:\n    print('num_lab_procedures interacting with', feature)\n    shap.dependence_plot('num_lab_procedures', shap_values[1], small_val_X, interaction_index=feature)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Congratulations\n\nThat's it!  Machine learning models should not feel like black boxes any more, because you have the tools to inspect them and understand what they learn about the world. \n\nThis is an excellent skill for debugging models, building trust, and learning insights to make better decisions. These techniques have revolutionized how I do data science, and I hope they do the same for you.\n\nReal data science involves an element of exploration. I hope you find an interesting dataset to try these techniques on (Kaggle has a lot of [free datasets](https://www.kaggle.com/datasets) to try out). If you learn something interesting about the world, share your work [in this forum](https://www.kaggle.com/learn-forum/66354). I'm excited to see what you do with your new skills."},{"metadata":{},"cell_type":"markdown","source":"---\n\n\n\n\n*Have questions or comments? Visit the [Learn Discussion forum](https://www.kaggle.com/learn-forum/161307) to chat with other Learners.*"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}