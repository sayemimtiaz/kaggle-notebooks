{"cells":[{"metadata":{},"cell_type":"markdown","source":"**This notebook is an exercise in the [Feature Engineering](https://www.kaggle.com/learn/feature-engineering) course.  You can reference the tutorial at [this link](https://www.kaggle.com/ryanholbrook/mutual-information).**\n\n---\n"},{"metadata":{},"cell_type":"markdown","source":"# Introduction #\n\nIn this exercise you'll identify an initial set of features in the [*Ames*](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data) dataset to develop using mutual information scores and interaction plots.\n\nRun this cell to set everything up!"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Setup feedback system\nfrom learntools.core import binder\nbinder.bind(globals())\nfrom learntools.feature_engineering_new.ex2 import *\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.feature_selection import mutual_info_regression\n\n# Set Matplotlib defaults\nplt.style.use(\"seaborn-whitegrid\")\nplt.rc(\"figure\", autolayout=True)\nplt.rc(\n    \"axes\",\n    labelweight=\"bold\",\n    labelsize=\"large\",\n    titleweight=\"bold\",\n    titlesize=14,\n    titlepad=10,\n)\n\n\n# Load data\ndf = pd.read_csv(\"../input/fe-course-data/ames.csv\")\n\n\n# Utility functions from Tutorial\ndef make_mi_scores(X, y):\n    X = X.copy()\n    for colname in X.select_dtypes([\"object\", \"category\"]):\n        X[colname], _ = X[colname].factorize()\n        \n    # All discrete features should now have integer dtypes\n    discrete_features = [pd.api.types.is_integer_dtype(t) for t in X.dtypes]\n    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features, random_state=0)\n    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n    mi_scores = mi_scores.sort_values(ascending=False)\n    return mi_scores\n\n\ndef plot_mi_scores(scores):\n    scores = scores.sort_values(ascending=True)\n    width = np.arange(len(scores))\n    ticks = list(scores.index)\n    plt.barh(width, scores)\n    plt.yticks(width, ticks)\n    plt.title(\"Mutual Information Scores\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.sample(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"-------------------------------------------------------------------------------\n\nTo start, let's review the meaning of mutual information by looking at a few features from the *Ames* dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"features = [\"YearBuilt\", \"MoSold\", \"ScreenPorch\"]\nsns.relplot(\n    x=\"value\", y=\"SalePrice\", col=\"variable\", data=df.melt(id_vars=\"SalePrice\", value_vars=features), facet_kws=dict(sharex=False),\n);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1) Understand Mutual Information\n\nBased on the plots, which feature do you think would have the highest mutual information with `SalePrice`?"},{"metadata":{"trusted":true},"cell_type":"code","source":"# View the solution (Run this cell to receive credit!)\nq_1.check()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"-------------------------------------------------------------------------------\n\nThe *Ames* dataset has seventy-eight features -- a lot to work with all at once! Fortunately, you can identify the features with the most potential.\n\nUse the `make_mi_scores` function (introduced in the tutorial) to compute mutual information scores for the *Ames* features:\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.copy()\ny = X.pop('SalePrice')\n\nmi_scores = make_mi_scores(X, y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now examine the scores using the functions in this cell. Look especially at top and bottom ranks."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(mi_scores.head(20))\n\nplt.figure(dpi=100, figsize=(8, 5))\nplot_mi_scores(mi_scores.head(20))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(mi_scores.tail(20))\n\nplot_mi_scores(mi_scores.tail(20))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2) Examine MI Scores\n\nDo the scores seem reasonable? Do the high scoring features represent things you'd think most people would value in a home? Do you notice any themes in what they describe? "},{"metadata":{"trusted":true},"cell_type":"code","source":"# View the solution (Run this cell to receive credit!)\nq_2.check()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"-------------------------------------------------------------------------------\n\nIn this step you'll investigate possible interaction effects for the `BldgType` feature. This feature describes the broad structure of the dwelling in five categories:\n\n> Bldg Type (Nominal): Type of dwelling\n>\t\t\n>       1Fam\tSingle-family Detached\t\n>       2FmCon\tTwo-family Conversion; originally built as one-family dwelling\n>       Duplx\tDuplex\n>       TwnhsE\tTownhouse End Unit\n>       TwnhsI\tTownhouse Inside Unit\n\nThe `BldgType` feature didn't get a very high MI score. A plot confirms that the categories in `BldgType` don't do a good job of distinguishing values in `SalePrice` (the distributions look fairly similar, in other words):"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x=\"BldgType\", y=\"SalePrice\", data=df, kind=\"boxen\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Still, the type of a dwelling seems like it should be important information. Investigate whether `BldgType` produces a significant interaction with either of the following:\n\n```\nGrLivArea  # Above ground living area\nMoSold     # Month sold\n```\n\nRun the following cell twice, the first time with `feature = \"GrLivArea\"` and the next time with `feature=\"MoSold\"`:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# YOUR CODE HERE: \nfeature = \"GrLivArea\"\n\nsns.lmplot(\n    x=feature, y=\"SalePrice\", hue=\"BldgType\", col=\"BldgType\",\n    data=df, scatter_kws={\"edgecolor\": 'w'}, col_wrap=3, height=4,\n);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# YOUR CODE HERE: \nfeature = \"MoSold\"\n\nsns.lmplot(\n    x=feature, y=\"SalePrice\", hue=\"BldgType\", col=\"BldgType\",\n    data=df, scatter_kws={\"edgecolor\": 'w'}, col_wrap=3, height=4,\n);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The trend lines being significantly different from one category to the next indicates an interaction effect."},{"metadata":{},"cell_type":"markdown","source":"# 3) Discover Interactions\n\nFrom the plots, does `BldgType` seem to exhibit an interaction effect with either `GrLivArea` or `MoSold`?"},{"metadata":{"trusted":true},"cell_type":"code","source":"# View the solution (Run this cell to receive credit!)\nq_3.check()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# A First Set of Development Features #\n\nLet's take a moment to make a list of features we might focus on. In the exercise in Lesson 3, you'll start to build up a more informative feature set through combinations of the original features you identified as having high potential.\n\nYou found that the ten features with the highest MI scores were:"},{"metadata":{"trusted":true},"cell_type":"code","source":"mi_scores.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Do you recognize the themes here? Location, size, and quality. You needn't restrict development to only these top features, but you do now have a good place to start. Combining these top features with other related features, especially those you've identified as creating interactions, is a good strategy for coming up with a highly informative set of features to train your model on.\n\n# Keep Going #\n\n[**Start creating features**](https://www.kaggle.com/ryanholbrook/creating-features) and learn what kinds of transformations different models are most likely to benefit from."},{"metadata":{},"cell_type":"markdown","source":"---\n\n\n\n\n*Have questions or comments? Visit the [Learn Discussion forum](https://www.kaggle.com/learn-forum/221677) to chat with other Learners.*"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}