{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## I'm using time series analysis electric production by FB Prophet","metadata":{}},{"cell_type":"code","source":"from pyspark.sql.functions import *\nfrom fbprophet import Prophet\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\nimport pandas as pd\nfrom pyspark.sql.types import *\nimport pickle\nimport numpy as np\n\n#read data \nprod_demand_df = read(\"TimeSeries_ElectricProduction.ElectricProduction\")\n#explore data\nprod_demand_df.printSchema()\nprod_demand_df.show(10)\nprod_demand_df.count()\n\n#I found the date is recognized as string \n#I tried to covert Date in string to a date for pandas\nprod_demand_df = prod_demand_df.withColumn('Date_date',to_date(prod_demand_df.DATE, 'MM-dd-yyyy')).drop(prod_demand_df.DATE)\nprod_demand_df.printSchema()\nprod_demand_df.show(10)\n\n#convert spark dataframe to pandas dataframe\npdf = prod_demand_df.toPandas()\n# Check the format of 'Date' column\npdf.info()\n\n#spark dataframe with the datatype still recognized as object \n# convert the 'Date' column to datetime format\npdf['Date_date'] = pdf['Date_date'].astype('datetime64[ns]')\n# Check the format of 'Date' column\npdf.info()\n#set index \npdf.set_index(pd.DatetimeIndex(pdf['Date_date']))\ncutoff_date = \"01-01-2017\"\nbefore_cutoff = pdf[\"Date_date\"] < cutoff_date\nafter_cutoff = pdf[\"Date_date\"] >= cutoff_date\n#filter data before date\ntrain = pdf.loc[before_cutoff]\ntrain.tail(10)\ntrain.info()\nprint(type(train))\n\n#Rename the columns for Prophet\n#ds:date y:indicating the amount we want to predict\ntrain.columns = ['y','ds']\n\n#Create model\nprophet = Prophet(changepoint_prior_scale=0.15, daily_seasonality=False)\nprophet.fit(train)\n#Prediction\nfuture = list()\n\nfor i in range(1, 13):\n    date = '2017-%02d' % i\n    print(i, date)\n    future.append([date])\nfuture = pd.DataFrame(future)\nfuture.columns = ['ds']\nfuture['ds']= pd.to_datetime(future['ds'])\nfuture\n#Use the model(prophet) to make a forecast\nforecast=prophet.predict(future)\nforecast\n\n#filter data before date\ntrain = pdf.loc[before_cutoff]\ntrain\n#filter data after date\ntest = pdf.loc[after_cutoff]\ntest\n#concat dataframe\npdf_with_forecast = pd.concat([train, test])\npdf_with_forecast\n#yhat:predicted value\ntest2 = forecast.loc[:,['ds', 'yhat']]\ntest2\n\n\n#rename columns For the same column name, merge column\ntest2.rename(columns = {'ds':'Date_date'}, inplace = True)\ntest2\n\n#merge colume become 3 columes\ndtest = test.merge(test2, on=\"Date_date\", how = 'inner')\n#Change the order of the columns\ndtest = dtest[['Date_date','Value','yhat']]\ndtest\n#import numpy as np\ntrain['yhat']=np.nan\n#Change the order of the columns\ndtrain = train[['Date_date','Value','yhat']]\ndtrain\n#concat two dataframes\npdf_result = pd.concat([dtrain, dtest])\npdf_result\n#covert pandas dataframe to spark dataframe \nresult_df = spark.createDataFrame(pdf_result)\nsave(result_df)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Here is the result in Incorta. The blue line showing original data, and the green line showing predict electric production. \n\n![this is a pic](https://1.bp.blogspot.com/--WFnbjOfH54/YIj6yUCteNI/AAAAAAAAAs8/o07GNQMMB6MJ6ojiNe69zkk0hfSzHz7UgCLcBGAsYHQ/s16000/Screen%2BShot%2B2021-04-27%2Bat%2B10.32.33%2BPM.png)","metadata":{}}]}