{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction\n### My primary intent is to classify words in positive video game reviews as \"positive\" words in negative game reviews as \"negative\", then use those classifications to predict a game's rating based on its reviews.\n### I then tried to \"reverse engineer\" the article sentiment to predict a video game's score based on the words in its article."},{"metadata":{},"cell_type":"markdown","source":"## Exploratory Analysis"},{"metadata":{"_kg_hide-input":false,"trusted":false},"cell_type":"code","source":"#Essentials\n%matplotlib inline\nimport matplotlib.pyplot as plt # plotting\nimport numpy as np # linear algebra\nimport os # accessing directory structure\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n#Web Scraping\nimport requests #request to scrape GameSpot's website\nfrom bs4 import BeautifulSoup #turn its html into a manipulatable string\nimport seaborn as sns #graphs\n\n#Text Classification\nfrom textblob import TextBlob #text classification and sentiment\nfrom textblob import classifiers\nimport nltk #formatting and cleaning english words\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nnltk.download('punkt')\nnltk.download('stopwords')\n\n#Machine Learning and Predictive Modeling\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression #machine learning through logistic regression\nfrom sklearn.linear_model import LinearRegression #machine learning through linear regression\nfrom sklearn.preprocessing import StandardScaler  #more machine learning methods and tools\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.preprocessing import PowerTransformer","execution_count":0,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Step 1. Gather data by scraping www.gamespot.com 's article section\n### Step 2. Create Dataframes for positive reviews and for negative reviews including the game's<br>\n###     • Name<br>\n###     • Rating<br>\n###     • Article Text"},{"metadata":{"trusted":true},"cell_type":"code","source":"#scrape GameSpot for top and bottom game reviews\n\ngs_game_data = []\n\nfor i in range(1, 75):\n    pos_url = \"https://www.gamespot.com/reviews/?sort=gs_score_desc&page=\" + str(i)\n    neg_url = \"https://www.gamespot.com/reviews/?sort=gs_score_desc&page=\" + str(710-i)\n    pos_request = requests.get(pos_url)\n    neg_request = requests.get(neg_url)\n    pos_soup = BeautifulSoup(pos_request.text, 'lxml')\n    neg_soup = BeautifulSoup(neg_request.text, 'lxml')\n    pos_game_data = pos_soup.find_all('article', {'class':'media-game'})\n    neg_game_data = neg_soup.find_all('article', {'class':'media-game'})\n    gs_game_data.append(pos_game_data)\n    gs_game_data.append(neg_game_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#make sure to clean the data as much as possible by trying to find each element and if there is none, append 'N/A'\n\ngame_names = []\ngame_scores = []\ngame_taglines = []\ngame_boxarts = []\ngame_systems = []\ngame_links = []\ngame_classifiers = []\nfor i in range(len(gs_game_data)):\n    for j in range(8):\n        try:\n            name = gs_game_data[i][j].find('h3', {'class':'media-title'}).text\n            game_names.append(name.replace(\"Review\", \"\"))\n        except:\n            game_names.append('N/A')\n        try:\n            game_scores.append(gs_game_data[i][j].find('span', {'class':'content'}).text)\n        except:\n            game_scores.append('N/A')\n        try:\n            game_taglines.append(gs_game_data[i][j].find('p', {'class':'media-deck'}).text)\n        except:\n            game_taglines.append('N/A')\n        try:\n            game_boxarts.append(gs_game_data[i][j].find('img').get('src'))\n        except:\n            game_boxarts.append('N/A')\n        try:\n            game_systems.append(gs_game_data[i][j].find('li', {'class':'system--pill'}).text)\n        except:\n            game_systems.append('N/A')\n        try:\n            game_links.append(\"https://www.gamespot.com\" + str(gs_game_data[i][j].find('a').get('href')))\n        except:\n            game_links.append('N/A')\n        if (float(gs_game_data[i][j].find('span', {'class':'content'}).text) > 5):\n            game_classifiers.append('pos')\n        else:\n            game_classifiers.append('neg')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gamespot_game_data = ({'name':game_names, 'score':game_scores, 'tagline':game_taglines, 'boxart':game_boxarts, 'system':game_systems, 'link':game_links, 'classifier':game_classifiers})\ngamespot_game_reviews = pd.DataFrame(data=gamespot_game_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#get full article text from each of the webpages\n#WARNING: this takes a few minutes to run\n\nfull_articles = []\nfor i in range(gamespot_game_reviews.shape[0]):\n    url = gamespot_game_reviews.link[i]\n    gs_request = requests.get(url)\n    gs_soup = BeautifulSoup(gs_request.text, 'lxml')\n    article = gs_soup.find_all('section', {'class':'article-body'})\n    full_articles.append(article)\n    \narticle_text = []\nfor i in range(len(full_articles)):\n    try:\n        article_text.append(full_articles[i][0].find('div').text)\n    except:\n        article_text.append('N/A')\n        \ngamespot_game_reviews['article'] = article_text","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This csv is available in the 'Downloads' section as 'gamespot_game_reviews.csv'\n\n### Step 3. Filter the articles to get rid of uneccesary words"},{"metadata":{"collapsed":true,"_kg_hide-input":true,"trusted":false},"cell_type":"code","source":"#filtering most common words with nltk\n#https://www.geeksforgeeks.org/removing-stop-words-nltk-python/\n\ngamespot_game_reviews['filtered article'] = gamespot_game_reviews['article']\n\nfor i in range(gamespot_game_reviews.shape[0]):\n    stop_words = set(stopwords.words('english')) \n    word_tokens = word_tokenize(gamespot_game_reviews['article'][i]) \n    filtered_sentence = [w for w in word_tokens if not w in stop_words] \n    filtered_sentence = [] \n    for w in word_tokens: \n        if w not in stop_words: \n            filtered_sentence.append(w)\n    gamespot_game_reviews['filtered article'][i] = filtered_sentence","execution_count":0,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Step 4. Run the positive and negative articles through TextBlob's word classification service\n### Step 5. Train and Test"},{"metadata":{"collapsed":true,"_kg_hide-input":true,"trusted":false},"cell_type":"code","source":"#training and testing in textblob\n#https://www.analyticsvidhya.com/blog/2018/02/natural-language-processing-for-beginners-using-textblob/\n\ntraining = []\ntesting = []\nfor i in range(100):\n    training.append((gamespot_game_reviews['filtered article'][i], gamespot_game_reviews['classifier'][i]))\n    training.append((gamespot_game_reviews['filtered article'][len(gamespot_game_reviews)-1-i], gamespot_game_reviews['classifier'][len(gamespot_game_reviews)-1-i]))","execution_count":0,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gs_classifier = classifiers.NaiveBayesClassifier(training)\nprint (gs_classifier.accuracy(testing))\ngs_classifier.show_informative_features()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most Informative Features<br>\n      contains(terrible) = True              neg : pos    =     23.0 : 1.0<br>\n       contains(amazing) = True              pos : neg    =     21.7 : 1.0<br>\n         contains(helps) = True              pos : neg    =     17.7 : 1.0<br>\n      contains(improved) = True              pos : neg    =     15.7 : 1.0<br>\n    contains(incredible) = True              pos : neg    =     15.7 : 1.0<br>\n    contains(satisfying) = True              pos : neg    =     15.7 : 1.0<br>\n   contains(outstanding) = True              pos : neg    =     15.0 : 1.0<br>\n        contains(varied) = True              pos : neg    =     14.3 : 1.0<br>\n     contains(perfectly) = True              pos : neg    =     12.3 : 1.0<br>\n         contains(awful) = True              neg : pos    =     12.2 : 1.0<br>"},{"metadata":{},"cell_type":"markdown","source":"# Now let's try to determine a game's score based on the sentiment of its article"},{"metadata":{"collapsed":true,"_kg_hide-input":true,"trusted":false},"cell_type":"code","source":"#add new columns to data for polarity and sujectivity of sentiment\n\ngamespot_game_reviews['polarity'] = gamespot_game_reviews['score']\ngamespot_game_reviews['subjectivity'] = gamespot_game_reviews['score']\nfor i in range(gamespot_game_reviews.shape[0]):\n    gamespot_game_reviews['polarity'][i] = TextBlob(gamespot_game_reviews['article'][i]).sentiment.polarity\n    gamespot_game_reviews['subjectivity'][i] = TextBlob(gamespot_game_reviews['article'][i]).sentiment.subjectivity","execution_count":0,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#method 1: LinearRegression\nlr = LinearRegression()\nlr.fit(gamespot_game_reviews[['polarity', 'subjectivity']], gamespot_game_reviews['score'])\nprint(\"Intercept: \", lr.intercept_, \"\\nCoefficients: \", lr.coef_)\npreds = lr.predict(gamespot_game_reviews[['polarity', 'subjectivity']])\nmse = mean_squared_error(gamespot_game_reviews['score'], preds)\nprint(\"MSE: \", mse)\nrmse = np.sqrt(mse)\nprint(\"RMSE: \", rmse)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Intercept:  4.219209027375533 <br>\nCoefficients:  [27.51971767  1.06704699]<br>\nMSE:  3.3837283091218806<br>\nRMSE:  1.839491318033842<br>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#method 2: train test split\n\nX_train, X_test, y_train, y_test = train_test_split(gamespot_game_reviews[['polarity', 'subjectivity']], gamespot_game_reviews['score'])\nlr2 = LinearRegression()\nlr2.fit(X_train, y_train)\nprint(\"Intercept: \", lr2.intercept_, \"\\nCoefficients: \", lr2.coef_)\npreds2 = lr2.predict(X_test)\nmse2 = mean_squared_error(y_test, preds2)\nprint('MSE: ', mse2)\nrmse2 = np.sqrt(mse2)\nprint('RMSE: ', rmse2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Intercept:  3.7388839047967086 <br>\nCoefficients:  [27.59325051  1.97349451]<br>\nMSE:  3.7069296068158666<br>\nRMSE:  1.9253388290936915<br>\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#method 3: grid search cv\n\nparams = {'poly__degree':[1, 2, 3], 'lr__fit_intercept':[True, False]}\npipe = Pipeline([('poly', PolynomialFeatures()), ('lr', LinearRegression())])\ngrid = GridSearchCV(pipe, param_grid=params)\ngrid.fit(X_train, y_train)\npreds3 = grid.predict(X_test)\nmse3 = mean_squared_error(y_test, preds3)\nprint('MSE: ', mse3)\nrmse3 = np.sqrt(mse3)\nprint('RMSE: ', rmse3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"MSE:  3.696839642906127<br>\nRMSE:  1.9227167349628305"},{"metadata":{"trusted":true},"cell_type":"code","source":"#method 4: gradient boosting\n\nfrom sklearn import ensemble\nfrom sklearn.preprocessing import scale\n\nX = scale(X_train)\n\n#Model:\n\nparams = {'n_estimators': 100, 'max_depth': 3}\nrf = ensemble.GradientBoostingRegressor(**params)\nrfc = rf.fit(X, y_train)\n\n# R:\nR = rfc.score(X, y_train)\nprint('R^2 Score: {:0.4f}'.format(R))\n\n# Predictions\ny_pred = rf.predict(X)\nRMSE = mean_squared_error(y_train, y_pred)**0.5\nprint('RMSE: {:0.3f}'.format(RMSE))\nprint('Minimum LE: {:0.1f}'.format(y_pred.min()))\nprint('Maximum LE: {:0.1f}'.format(y_pred.max()))\nprint('Average Predicted LE: {:0.1f}'.format(y_pred.mean()))\nprint('LE Standard Deviation: {:0.3f}'.format(y_pred.std()))\nprint('LE Variance: {:0.3f}'.format(y_pred.std()**2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"R^2 Score: 0.7540<br>\nRMSE: 1.343<br>\nMinimum LE: 2.1<br>\nMaximum LE: 9.4<br>\nAverage Predicted LE: 6.2<br>\nLE Standard Deviation: 2.192<br>\nLE Variance: 4.804<br>"},{"metadata":{},"cell_type":"markdown","source":"# Conclusion\n\n### if i pass my Classifier a positive article it hasn't seem before, will it determine it successfully?\n    print(gamespot_game_reviews['classifier'][101])\n    blob = TextBlob(gamespot_game_reviews['article'][101], classifier = gs_classifier)\n    print(blob.classify())\npos<br>\npos<br>\n\n### how about a negative one?\n    print(gamespot_game_reviews['classifier'][len(gamespot_game_reviews)-102])\n    blob = TextBlob(gamespot_game_reviews['article'][len(gamespot_game_reviews)-102], classifier = gs_classifier)\n    print(blob.classify())\nneg<br>\nneg<br>\n\n## During the last few times I've run this kernel, the classifier has received accuracy scores of between 90-96% in classifying articles as positive or negative.\n\n## As for predicting a video game's score...\n\n### 1. LinearRegression<br>\n    • Using this method, my MSE is 3.4496143973824944 and my **RMSE is  1.8573137584647603**, which, in terms of a 1-10 score is like a 36% margin of error.\n    # predicting the first element of the dataframe with this model\n    lr.predict([[gamespot_game_reviews['polarity'][0], gamespot_game_reviews['subjectivity'][0]]])\n   array([9.28099969])\n   \n### 2. Train / Test Split<br>\n    • Using this method, my MSE is 3.152704279159698 and my **RMSE is 1.775585615834871**, which is only a slightly better score of a 34% margin of error.\n    # predicting the first element of the dataframe with this model\n    lr2.predict([[gamespot_game_reviews['polarity'][0], gamespot_game_reviews['subjectivity'][0]]])\n   array([9.26537513])\n   \n### 3. GridSearchCV with Pipeline<br>\n    • Using this method, my MSE is 3.1527042791596984 and my **RMSE is 1.775585615834871**, which is exactly the same as the previous model.\n    # predicting the first element of the dataframe with this model\n    grid.predict([[gamespot_game_reviews['polarity'][0], gamespot_game_reviews['subjectivity'][0]]])\n   array([9.36835043])\n   \n### 4. Gradient Boosting<br>\n    • Using this method, my **RMSE is 1.343**, which is remarkably better than previous models with an error rate of around 27%.\n    # predicting the first element of the dataframe with this model\n    rf.predict([[gamespot_game_reviews['polarity'][0], gamespot_game_reviews['subjectivity'][0]]])\n   array([6.03828307])\n   \n### *(the score of first element of the dataframe is 10)*"},{"metadata":{},"cell_type":"markdown","source":"One of my biggest takeaways from this project is that I believe that my classifier is \"biased\", kind of, to articles on gamespot's website. Since I trained it entirely on the contents of one website, it occasionally misclassifies video game articles from other websites. I've passed it articles that it has treated as positive but predicted a low score, as well as articles that it said were negative but the predicted score was higher than it should have been to support that classification. I wonder if that has to do with the common word choices by those who write GameSpot's articles, as opposed to the writing styles of the other writers I've passed through as test subjects..."}],"metadata":{"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}