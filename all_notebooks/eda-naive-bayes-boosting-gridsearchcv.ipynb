{"cells":[{"metadata":{},"cell_type":"markdown","source":"## CSU-SpringÂ∞èÈòü Kernel introduction\n<br>\n\n### Introduction\n\n1. üå± team: SpringÂ∞èÈòü<br><br>\n2. üòÑ ÊàêÂëò: Aczy156(ÈôàÂÜâÈ£û) Chun yu(Èô≥‰øäÁëú) AFun(Á∫™Êò±Â∏Ü)<br><br>\n3. ‚ö° ÈÄâÈ¢ò: ‰∏≠ÂçóÂ§ßÂ≠¶(Central South University) Â§ß‰∏â‰∏äÂçäÂ≠¶Âπ¥ Â∑•Á®ãÁ†îÁ©∂‰∏éÂÆû‰π† ËΩØ‰ª∂Áº∫Èô∑ÊµãËØï<br><br>\n4. üî≠ dataset source: <br>\n    * Tronclass ‰ªªËÄÅÂ∏àÁöÑËµÑÊñôÂ§π‰∏≠ÁöÑ NASAËµÑÊñôÂ§π‰∏≠Êñá‰ª∂<br>\n    * [NASA open dataset](https://nasa.github.io/data-nasa-gov-frontpage/)<br>\n    * [Kaggle open dataset](https://www.kaggle.com/semustafacevik/software-defect-prediction)<br>\n\n<br>\n### Dataset and Kernel\n\nDataset: Êï¥ÂêàÊï∞ÊçÆÔºåÂπ∂uploadËá≥KaggleÔºåÊï∞ÊçÆÈõÜÂ∑≤ÂºÄÊ∫ê„ÄÇ<br>\nURL: [https://www.kaggle.com/aczy156/software-defect-prediction-nasa](https://www.kaggle.com/aczy156/software-defect-prediction-nasa)\n<br><br>\n\nKernelÔºö(‰πüÂ∞±ÊòØÂΩìÂâçÊ≠§kernel)\n* URL: [https://www.kaggle.com/aczy156/software-defect-prediction-nasa-eda-naive-bayes](https://www.kaggle.com/aczy156/software-defect-prediction-nasa-eda-naive-bayes)\n* VersionÔºö\n    * Version1: \"build: Baseline(based on machine leanring)\"\n    * Version2: \"feats: Introduction\"\n    * Version3: \"fix: EDA plot method\"\n    * Version4: \"feats: Machine Learning model - Decision Tree\"\n    * Version5: \"fix: evaluate function\"\n    * Version6: \"feats: Machine Learning model - boosting ['xgboost', 'lightgbm', 'catboost']\"\n    * Version7: \"feats: Model Compare by P-R curve and ROC curve\"\n    * Version8: \"feats: GridSearchCV for better parameters\"\n    * Version9: \"fix: model tuning.\"\n    * Versino10: \"styles: format kernel.\""},{"metadata":{},"cell_type":"markdown","source":"## prework\n\n* import basic dependencies\n* load data"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns\nsns.set_style('whitegrid')\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load data\ndata = pd.read_csv('/kaggle/input/software-defect-prediction-nasa/jm1.csv')\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## EDA\n\n* import some dependencies to plot\n* use plotly to visualization\n    * label classification\n        * count and plot(visualization)\n    * value visualization\n        * use historgram to visualization attribution\n        * relationship\n            * covariance\n            * heatmap\n    * scatter\n    "},{"metadata":{"trusted":true},"cell_type":"code","source":"# import some dependencies to plot\n\nfrom plotly.offline import iplot\n# init_notebook_mode(connected=True)\nimport plotly.graph_objs as go","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"# check data\ndef show_info(data, is_matrix_transpose=False):\n    # basic shape\n    print('data shape is: {}   sample number {}   attribute number {}\\n'.format(data.shape, data.shape[0], data.shape[1]))\n    # attribute(key)\n    print('data columns number {}  \\nall columns: {}\\n'.format(len(data.columns) ,data.columns))\n    # value's null\n    print('data all attribute count null:\\n', data.isna().sum())\n    # data value analysis and data demo\n    if is_matrix_transpose:\n        print('data value analysis: ', data.describe().T)\n        print('data demo without matrix transpose: ', data.head().T)\n    else:\n        print('data value analysis: ', data.describe())\n        print('data demo without matrix transpose: ', data.head())\n        \nshow_info(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# label classification\ndefects_true_false = data.groupby('defects')['b'].apply(lambda x: x.count())\nprint('True: ', defects_true_false[1], 'False: ', defects_true_false[0])\ndata.defects.value_counts().plot.bar()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Then show the covariance.**\n -- by coveriance matrix"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Attribute relationship -- covariance\ndata.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot columns distribution\ndef plotPerColumnDistribution(df, nGraphShown, nGraphPerRow):\n    nunique = df.nunique()\n    df = df[[col for col in df if nunique[col] > 1 and nunique[col] < 50]] # For displaying purposes, pick columns that have between 1 and 50 unique values\n    nRow, nCol = df.shape\n    columnNames = list(df)\n    nGraphRow = (nCol + nGraphPerRow - 1) / nGraphPerRow\n    plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * nGraphRow), dpi = 80, facecolor = 'w', edgecolor = 'k')\n    for i in range(min(nCol, nGraphShown)):\n        plt.subplot(nGraphRow, nGraphPerRow, i + 1)\n        columnDf = df.iloc[:, i]\n        if (not np.issubdtype(type(columnDf.iloc[0]), np.number)):\n            valueCounts = columnDf.value_counts()\n            valueCounts.plot.bar()\n        else:\n            columnDf.hist()\n        plt.ylabel('counts')\n        plt.xticks(rotation = 90)\n        plt.title(f'{columnNames[i]} (column {i})')\n    plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)\n    plt.show()\n    \nplotPerColumnDistribution(data, 10, 5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot corr\ndef plotCorrelationMatrix(df, graphWidth):\n    df = df.dropna('columns') # drop columns with NaN\n    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values\n    if df.shape[1] < 2:\n        print(f'No correlation plots shown: The number of non-NaN or constant columns ({df.shape[1]}) is less than 2')\n        return\n    corr = df.corr()\n    plt.figure(num=None, figsize=(graphWidth, graphWidth), dpi=80, facecolor='w', edgecolor='k')\n    corrMat = plt.matshow(corr, fignum = 1)\n    plt.xticks(range(len(corr.columns)), corr.columns, rotation=90)\n    plt.yticks(range(len(corr.columns)), corr.columns)\n    plt.gca().xaxis.tick_bottom()\n    plt.colorbar(corrMat)\n    plt.show()\n\nplotCorrelationMatrix(data, 8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scatter and density plots\ndef plotScatterMatrix(df, plotSize, textSize):\n    df = df.select_dtypes(include =[np.number]) # keep only numerical columns\n    # Remove rows and columns that would lead to df being singular\n    df = df.dropna('columns')\n    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values\n    columnNames = list(df)\n    if len(columnNames) > 10: # reduce the number of columns for matrix inversion of kernel density plots\n        columnNames = columnNames[:10]\n    df = df[columnNames]\n    ax = pd.plotting.scatter_matrix(df, alpha=0.75, figsize=[plotSize, plotSize], diagonal='kde')\n    corrs = df.corr().values\n    for i, j in zip(*plt.np.triu_indices_from(ax, k = 1)):\n        ax[i, j].annotate('Corr. coef = %.3f' % corrs[i, j], (0.8, 0.2), xycoords='axes fraction', ha='center', va='center', size=textSize)\n    plt.suptitle('Scatter and Density Plot')\n    plt.show()\n    \nplotScatterMatrix(data, 20, 10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data cleaning\n\n* fillna\n* remove outliars (by use boxplot to visualization)\n* data type transform\n    * remove ~char"},{"metadata":{"trusted":true},"cell_type":"code","source":"trace1 = go.Box(x=data['uniq_Op'])\nbox_data = [trace1]\niplot(box_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### some special columns \n\n* data cleaning\n* change data type"},{"metadata":{"trusted":true},"cell_type":"code","source":"# some special columns [type is 'object']\nobject_type_cols = ['uniq_Op', 'uniq_Opnd', 'total_Op', 'total_Opnd', 'branchCount']\n# data.head()\n# data['uniq_Op'] = data['uniq_Op'].astype(np.float64)\n# data['uniq_Opnd'] = data['uniq_Opnd'].astype(np.float64)\n# data['total_Op'] = data['total_Op'].astype(np.float64)\n# data['total_Opnd'] = data['total_Opnd'].astype(np.float64)\n# data['branchCount'] = data['branchCount'].astype(np.float64)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature engineering\n\n* extract some useful attributions and create new attribution"},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"# extract useful attributions and create new attribution\ndef extract_and_eval(data):\n    '''\n    input: data\n    goal: make an evaluation to every sample and label\n    '''\n    eval = (data.n < 300) & (data.v < 1000) & (data.d < 50) & (data.e < 500000) & (data.t < 5000)\n    data['eval'] = pd.DataFrame(eval)\n    data['eval'] = [1 if e == True else 0 for e in data['eval']]\n\nextract_and_eval(data)\nshow_info(data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Normalization\n\n* load importance\n* use Min-Max Normalization"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"scale_v = data[['v']]\nscale_b = data[['b']]\n\nminmax_scaler = MinMaxScaler()\n\nv_scaled = minmax_scaler.fit_transform(scale_v)\nb_scaled = minmax_scaler.fit_transform(scale_b)\ndata['scaled_v'] = pd.DataFrame(v_scaled)\ndata['scaled_b'] = pd.DataFrame(b_scaled)\n\n# check data\nshow_info(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tem_data = data.copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model\n\n* hyper-parameter\n* data prepare\n    * extract target(label)\n    * train train split\n    * cross-validation(because of data size only 1w) => use 10-cv\n* build model\n    * naive bayes\n    * LR\n    * Boosting\n        * xgboost\n        * lightgbm\n* fit, predict, evaluate(precision, recall, f1-score, acc, roc, auc)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split, KFold, cross_val_score\n\n# machine learning model\nfrom sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeClassifier\n# boosting\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# hyper-parameter\nvalidation_size = 0.2\nrandom_seed=7","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# extract target\ndata['target'] = data['defects'].apply(lambda x: 1 if x == True else 0)\ndata = data.drop(['defects'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def is_number(s):\n#     try:\n#         float(s)\n#         return True\n#     except ValueError:\n#         pass\n \n#     try:\n#         import unicodedata\n#         unicodedata.numeric(s)\n#         return True\n#     except (TypeError, ValueError):\n#         pass\n \n#     return False\n\n# data type change prework\norigin_data_type_cols = ['uniq_Op', 'uniq_Opnd', 'total_Op', 'total_Opnd', 'branchCount']\ndata = data.drop(origin_data_type_cols, axis=1)\n# for col in origin_data_type_cols:\n#     data[col] = data[data[col].is_number()]\n#     data[col] = data[col].astype(np.float64)\n# data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target = data['target']\ndata = data.drop(['target'], axis=1)\nX_train, X_val, y_train, y_val = train_test_split(\n    data,\n    target,\n    test_size=validation_size,\n    random_state=random_seed\n)\nX_train.shape, X_val.shape, y_train.shape, y_val.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model evaluation calculate and score\nfrom sklearn.metrics import accuracy_score, recall_score, precision_score, roc_auc_score,  mean_squared_error\n# model evaluation \nfrom sklearn.metrics import classification_report, confusion_matrix\n\n# metrics method\ndef metrics_calculate(model_name, y_val, y_pred):\n    '''\n    0. basic metrics values ['accuracy', 'precision', 'recall', 'fpr', 'fnr', 'auc']\n    1. classification report\n    2. confusion matrix\n    '''\n#     y_val = np.reshape(y_val, -1).astype(np.int32)\n#     y_pred = np.where(np.reshape(y_pred, -1) > 0.5, 1, 0)\n#     accuracy = accuracy_score(y_val, y_pred)\n#     precision = precision_score(y_val, y_pred)\n#     recall = recall_score(y_val, y_pred)\n    tn, fp, fn, tp = confusion_matrix(y_val, y_pred).ravel()\n    fpr = fp / (tn + fp)\n    fnr = fn / (tp + fn)\n#     auc = roc_auc_score(y_val, y_pred)\n#     print('Model:%s Acc:%.8f Prec:%.8f Recall:%.8f FNR:%.8f FPR:%.8f AUC:%.8f' % (model_name, accuracy, precision, recall, fnr, fpr, auc))\n    print(model_name, 'classification report:\\n', classification_report(y_val, y_pred))\n    print(model_name, 'confusion_matrix:\\n', confusion_matrix(y_val, y_pred))\n    print('\\n%s FNR:%.8f FPR:%.8f\\n%s accuracy:%.8f' % (model_name, fnr, fpr, model_name, accuracy_score(y_pred,y_val)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot metrics model answer(metrics)\nfrom sklearn.metrics import plot_roc_curve, plot_precision_recall_curve\n\ndef metrics_plot(model_name, model, X_val, y_val):\n    # plot P-R curve\n    disp = plot_precision_recall_curve(model, X_val, y_val)\n#     disp.ax_.set_title('2-class Precision-Recall curve: ''AP={0:0.2f}'.format(average_precision))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Boosting\n\n* xgboost\n* lightgbm\n* catboost\n\n#### Choose a model that performs best => gridSearchCV\n* get best parameter"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\n# lightgbm\nlgb = LGBMClassifier(\n    max_depth=7,\n    lambda_l1=0.1,\n    lambda_l2=0.01,\n    learning_rate=0.01,\n    n_estimators=500,\n    reg_aplha=1.1,\n    colsample_bytree=0.9,\n    subsample=0.9,\n    n_jobs=5\n)\n# cv = cross_val_score(model, X_train, y_train, cv=kfold, scoring='accuracy')\n# print('lightgbm cv score: ', cv)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fit\nlgb.fit(X_train, y_train, eval_set=[(X_val, y_val)], eval_metric='accuracy', verbose=True, early_stopping_rounds=50)\n# predict\ny_pred = lgb.predict(X_val)\n# evaluate\nmetrics_calculate('Boosting lightgbm', y_val, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\n# catboost\ncb = CatBoostClassifier(\n    depth = 9, \n    reg_lambda=0.1,\n    learning_rate = 0.09,\n    iterations = 500\n)\n# cv = cross_val_score(model, X_train, y_train, cv=kfold, scoring='accuracy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fit\ncb.fit(X_train, y_train, eval_set=[(X_val, y_val)],  verbose=True, early_stopping_rounds=50)\n# predict\ncb.predict(X_val)\n# evaluate\nmetrics_calculate('Catboost', y_val, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\n# xgboost\nxgb = XGBClassifier(\n    max_depth=9,\n    learning_rate=0.01,\n    n_estimators=500,\n    reg_alpha=1.1,\n    colsample_bytree = 0.9, \n    subsample = 0.9,\n    n_jobs = 5\n)\n# cv = cross_val_score(model, X_train, y_train, cv=kfold, scoring='accuracy')\n# print('xgboost cv score: ', cv)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fit\n%time xgb.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=True, early_stopping_rounds=2)\n# pred\ny_pred = xgb.predict(X_val)\n# evaluate\nmetrics_calculate('Boosting xgboost', y_val, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# compare boosting [P-R curve]\nPR_curve = plot_precision_recall_curve(xgb, X_val, y_val)\nPR_curve = plot_precision_recall_curve(lgb, X_val, y_val, ax=PR_curve.ax_)\nPR_curve = plot_precision_recall_curve(cb, X_val, y_val, ax=PR_curve.ax_)\n# compare boosting [ROC curve]\nROC_curve = plot_roc_curve(xgb, X_val, y_val)\nROC_curve = plot_roc_curve(lgb, X_val, y_val, ax=ROC_curve.ax_)\nROC_curve = plot_roc_curve(cb, X_val, y_val, ax=ROC_curve.ax_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\ndef grid_search_params(model, parameters, X_train, y_train):\n    gsearch = GridSearchCV(model, param_grid=parameters, scoring='roc_auc', cv=3)\n    gsearch.fit(X_train, y_train)\n    print('Best param value is: {0}\\n'.format(gsearch.best_params_))\n    print('Best score is: {0}\\n'.format(gsearch.best_score_))\n    print(gsearch.cv_results_['mean_test_score'], '\\n')\n#     print(gsearch.cv_results_['params'], '\\n')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %%time\n\n# # xgboost -- gridsearchcv\n# gs_xgb = XGBClassifier(\n#     eta= 0.3, \n#     n_estimators= 500,\n#     gamma= 0,\n#     max_depth= 6, \n#     min_child_weight= 1,\n#     colsample_bytree= 1, \n#     colsample_bylevel= 1, \n#     subsample= 1, \n#     reg_lambda= 1, \n#     reg_alpha= 0,\n#     seed= 33\n# )\n\n# # scale of tree\n# scale_tree_params = {\n#     'max_depth':[3,5,7,9],\n#     'min_child_weight':[1,3,5]\n# }\n\n\n# # control fit degree\n# fit_degree_params = {\n#     'subsample':[i/10.0 for i in range(6,10)],\n#     'colsample_bytree':[i/10.0 for i in range(6,10)],\n#     'min_child_weight':[6,8,10,12],\n#     'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]\n# }\n\n# print('Search for best tree scale parameters')\n# grid_search_params(gs_xgb, scale_tree_params, X_train, y_train)\n\n# print('Search for best fit degree parameters')\n# grid_search_params(gs_xgb, fit_degree_params, X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# gs_xgb = XGBClassifier(\n#     eta= 0.3, \n#     n_estimators= 500,\n#     gamma= 0,\n#     max_depth= 6, \n#     min_child_weight= 1,\n#     colsample_bytree= 1, \n#     colsample_bylevel= 1, \n#     subsample= 1, \n#     reg_lambda= 1, \n#     reg_alpha= 0,\n#     seed= 33\n# )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # test best parameters and origin \n# gs_xgb.fit(X_train, y_train, eval_set=[(X_val, y_val)], eval_metric='accuracy', verbose=True, early_stopping_rounds=5)\n# # predict\n# y_pred = gs_xgb.predict(X_val)\n# # evaluate\n# metrics_calculate('Boosting xgboost after grid-search-cv: ', y_val, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Other models\n\n* Naive bayes\n    * GaussionNB È´òÊñØÂàÜÂ∏ÉÁöÑÊú¥Á¥†Ë¥ùÂè∂ÊñØ\n    * MultinomialNB Â§öÈ°πÂºèÂàÜÂ∏ÉÁöÑÊú¥Á¥†Ë¥ùÂè∂ÊñØ\n    * BernoulliNB ‰ºØÂä™Âà©ÂàÜÂ∏ÉÁöÑÊú¥Á¥†Ë¥ùÂè∂ÊñØ"},{"metadata":{"trusted":true},"cell_type":"code","source":"# get data\n# tem_data.head()\nX_train, X_val, y_train, y_val = train_test_split(\n    tem_data.iloc[:, :-10].values, \n    tem_data['eval'].values, \n    test_size=validation_size,\n    random_state=random_seed\n)\nX_train.shape, X_val.shape, y_train.shape, y_val.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kfold = KFold(n_splits=10, random_state=random_seed)\n# get model -- GaussianNB\ngaussion_nb = GaussianNB()\n%time cv = cross_val_score(gaussion_nb, X_train, y_train, cv=kfold, scoring='accuracy')\nprint('Naive Bayes GaussianNB cv score: ', cv)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fit\n%time gaussion_nb.fit(X_train, y_train)\n# predict\ny_pred = gaussion_nb.predict(X_val)\n# evaluate\nmetrics_calculate('Naive Bayes - GaussionNB', y_val, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get model -- MultinomialNB\nmultinomial_nb = MultinomialNB()\n%time cv = cross_val_score(multinomial_nb, X_train, y_train, cv=kfold, scoring='accuracy')\nprint('Naive Bayes MultinomialNB cv score: ', cv)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fit\n%time multinomial_nb.fit(X_train, y_train)\n# predict\ny_pred = multinomial_nb.predict(X_val)\n# evaluate\nmetrics_calculate('Naive Bayes - MultinomialNB', y_val, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get model -- BernoulliNB\nbernoulli_nb = BernoulliNB()\n%time cv = cross_val_score(bernoulli_nb, X_train, y_train, cv=kfold, scoring='accuracy')\nprint('Naive Bayes BernoulliNB cv score: ', cv)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fit\n%time bernoulli_nb.fit(X_train, y_train)\n# predict\ny_pred = bernoulli_nb.predict(X_val)\n# evaluate\nmetrics_calculate('Naive Bayes - BernoulliNB', y_val, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# compare boosting [P-R curve]\nPR_curve_nb = plot_precision_recall_curve(gaussion_nb, X_val, y_val)\nPR_curve_nb = plot_precision_recall_curve(multinomial_nb, X_val, y_val, ax=PR_curve_nb.ax_)\nPR_curve_nb = plot_precision_recall_curve(bernoulli_nb, X_val, y_val, ax=PR_curve_nb.ax_)\n# compare boosting [ROC curve]\nROC_curve_nb = plot_roc_curve(gaussion_nb, X_val, y_val)\nROC_curve_nb = plot_roc_curve(multinomial_nb, X_val, y_val, ax=ROC_curve_nb.ax_)\nROC_curve_nb = plot_roc_curve(bernoulli_nb, X_val, y_val, ax=ROC_curve_nb.ax_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Lightgbm GridSearchCV\n\n* tree scale [cart regression tree]\n* control fit degree\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\n# init parameters\ngs_lgb = LGBMClassifier(\n    objective = 'binary',\n    is_unbalance = True,\n    metric = 'binary_logloss,auc',\n    max_depth = 6,\n    num_leaves = 40,\n    learning_rate = 0.1,\n    feature_fraction = 0.7,\n    min_child_samples=21,\n    min_child_weight=0.001,\n    bagging_fraction = 1,\n    bagging_freq = 2,\n    reg_alpha = 0.001,\n    reg_lambda = 8,\n    cat_smooth = 0,\n    num_iterations = 200,\n)\n\n# scale of tree\nscale_tree_params = {\n    'max_depth': [4, 6, 8],\n    'num_leaves': [20, 30, 40],\n    'min_child_samples': [18, 19, 20, 21, 22],\n    'min_child_weight': [0.001, 0.002],\n    'feature_fraction': [0.6, 0.8, 1],\n}\n\n# control fit degree\nfit_degree_params = {\n    \n}\n\nprint('Search for best tree scale parameters')\ngrid_search_params(gs_lgb, scale_tree_params, X_train, y_train)\n\n# print('Search for best fit degree parameters')\n# grid_search_params(gs_lgb, fit_degree_params, X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**get best parameters**\n\n* 'feature_fraction': 0.8, \n* 'min_child_samples': 19, \n* 'min_child_weight': 0.001\n* 'max_depth': 6, \n* 'num_leaves': 20\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# init\ngs_lgb = LGBMClassifier(\n    objective = 'binary',\n    is_unbalance = True,\n    metric = 'binary_logloss,auc',\n    max_depth = 6,\n    num_leaves = 20,\n    learning_rate = 0.1,\n    feature_fraction = 1,\n    min_child_samples=19,\n    min_child_weight=0.001,\n    bagging_fraction = 1,\n    bagging_freq = 2,\n    reg_alpha = 0.001, \n    reg_lambda = 8,\n    cat_smooth = 0,\n    num_iterations = 200,\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fit\n%time gs_lgb.fit(X_train, y_train)\n# predict\ny_pred = gs_lgb.predict(X_val)\n# evaluate\nmetrics_calculate('Boosting lightgbm after grid-search-cv: ', y_val, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Decision Tree"},{"metadata":{"trusted":true},"cell_type":"code","source":"# %%time\n\n# tree_model = DecisionTreeClassifier()\n# cv = cross_val_score(tree_model, X_train, y_train, cv=kfold, scoring='accuracy')\n# print('Naive Bayes cv score: ', cv)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # fit\n# %time tree_model.fit(X_train, y_train)\n# # predict\n# y_pred = tree_model.predict(X_val)\n# # evaluate\n# metrics_calculate('Decision Tree', y_val, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### LR (Linear Regression)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# # LR\n# X = data['loc'].values.reshape(-1, 1)\n# X_train, X_val, y_train, y_val = train_test_split(X, data['loc'].values)\n# X_train.shape, X_val.shape, y_train.shape, y_val.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %%time\n\n# model = LinearRegression()\n# model.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # predict\n# y_pred = model.predict(X_val)\n# print('Mean Squared Error (MSE):', mean_squared_error(y_val, y_pred))  \n# print('Root Mean Squared Error (RMSE):', np.sqrt(mean_squared_error(y_val, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X_train.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}