{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom collections import Counter \n\nfrom os import listdir\nfrom os.path import isfile, join\nimport json\nfrom collections import Counter\nimport geopandas \nimport re\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        #print(os.path.join(dirname, filename))\n        break\n    \n    break \n# Any results you write to the current directory are saved as output.\n\n# Corona = pd.read_csv('/kaggle/input/CORD-19-research-challenge/metadata.csv')\ncovResearch = pd.read_csv('/kaggle/input/CORD-19-research-challenge/metadata.csv')\npaperName = covResearch[['title', 'cord_uid', 'pmcid','pubmed_id']]\n\n#https://www.geeksforgeeks.org/python-pandas-series-str-find/\n# dropping null value columns to avoid errors \npaperName.dropna(inplace = True) \n  \n# substring to be searched \nsub1 = 'Temperature'\nsub2 = 'temperature'\n\n\n# Alternatively: sub = 'emperature'\nstart = 2\n  \n# creating and passsing series to new column \npaperName[\"Indexes\"]= paperName[\"title\"].str.find(sub1, start) + paperName[\"title\"].str.find(sub2, start) \n# display\npaperName = paperName.drop(paperName[paperName.Indexes < 0].index)\n  \npaperName \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# https://www.kaggle.com/diamazov/export-usa-names-into-csv\n    \n# import package with helper functions \nimport bq_helper\n\n# create a helper object for this dataset\npaper_names = bq_helper.BigQueryHelper(active_project=\"Temperature-Research-Papers-Covid\", dataset_name=\"paperNames\")\n\n# query and export data \nquery = \"\"\"SELECT title, pmcid, Indexes as number FROM `Temperature-Research-Papers-Covid` GROUP BY title, pmcid, Indexes\"\"\"\npaper_namesfile = paper_names.query_to_pandas_safe(query)\npaper_namesfile.to_csv(\"researchPapersonTemp.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Papers that has the word temperatures in their title. This might not be fully encompass an entire document but it does highlight papers that focus on the correlation between COVID-19 and temperature. "},{"metadata":{"trusted":true},"cell_type":"code","source":"def extract_values(obj, key):\n    \"\"\"Pull all values of specified key from nested JSON.\"\"\"\n    arr = []\n\n    def extract(obj, arr, key):\n        \"\"\"Recursively search for values of key in JSON tree.\"\"\"\n        if isinstance(obj, dict):\n            for k, v in obj.items():\n                if isinstance(v, (dict, list)):\n                    extract(v, arr, key)\n                elif k == key:\n                    arr.append(v)\n        elif isinstance(obj, list):\n            for item in obj:\n                extract(item, arr, key)\n        return arr\n\n    results = extract(obj, arr, key)\n    return results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def removeNestings(l): \n    for i in l: \n        if type(i) == list: \n            removeNestings(i) \n        else: \n            output.append(i)  ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"DATA_PATH = \"../input/CORD-19-research-challenge/\"\nfolder_paths = {\"biorxiv_medrxiv/biorxiv_medrxiv/\", \"comm_use_subset/comm_use_subset/\", \"custom_license/custom_license/\", \"noncomm_use_subset/noncomm_use_subset/\"} \npdf_pmc = {\"pdf_json\", \"pmc_json\"}\np = \"pmc_json\"\npmcID = paperName[['pmcid']]\npmc_list = pmcID.values.tolist()\n\nonlyfiles = []\ndata_list = []\n\nfor fp in folder_paths:\n    if (p in listdir(DATA_PATH+fp)):\n        onlyfiles = [f for f in listdir(DATA_PATH+fp+p) if isfile(join(DATA_PATH+fp+ p, f))]\n        for n in onlyfiles:\n            paper_id = re.sub('.xml.json$', '', n)\n            #for y in pmc_list:\n            if any(paper_id in s for s in pmc_list):\n                with open(f'{DATA_PATH}{fp}pmc_json/{n}') as json_data:\n                    this_file = json.load(json_data)\n                data_list.append(extract_values(this_file, \"text\"))\n                paper_text = data_list\n        \n    \noutput = []\nremoveNestings(data_list)       \n#for l in this_file:\n                    #if (string pmcID in l):\n                        #data_list.append(l)\n                        \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Wordclouds"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Wordloud: https://www.datacamp.com/community/tutorials/wordcloud-python\n#Stopwords: https://programminghistorian.org/en/lessons/counting-frequencies#removing-stop-words\nfrom wordcloud import WordCloud, STOPWORDS # Making wordcloud\nfrom PIL import Image    # Imports PIL module, to see and scan images  \n\nimport matplotlib.pyplot as plt \n\n#def list2string(l2s):\n#    textSTR = \" \"   #making the text into string\n#    return (textSTR.join(l2s))\n\npaper_textSTR = ' '.join(map(str, paper_text)) \n\n\nfilteredWords = set(STOPWORDS)\nfilteredWords.update([\"may\",\"Figure\", \"Fig\", \"et al\", \"showed\", \"one\", \"two\", \"three\", \"mean\", \"table\", \"using\", \"well\", \"result\", \"model\"])\n                      \nwordcloud = WordCloud(stopwords=filteredWords,\n                          background_color='white', \n                      max_words=300\n                         ).generate(paper_textSTR)\n\n\nplt.clf()\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Top "},{"metadata":{},"cell_type":"markdown","source":"Counter"},{"metadata":{"trusted":true},"cell_type":"code","source":"#https://stackoverflow.com/questions/20723133/remove-a-list-of-stopwords-from-a-counter-in-python\n#https://stackoverflow.com/questions/56558006/counter-that-returns-the-10-most-common-words\n\n# This didnt work, Ignore this but an attempt was made and I might want to make it work in the future. this function is not in the paper \n\ndef removeStopwords(wordlist, stopwords):\n    return [w for w in wordlist if w not in stopwords]\n\nwordCounter = \"\".join(map(str, paper_textSTR))\n\nwordCounterSTR = removeStopwords(wordCounter, filteredWords)\nprint(wordCounterSTR)\n\n# split() returns list of all the words in the string \nsplit_it = wordCounterSTR.split() \n  \n# Pass the split_it list to instance of Counter class. \nCounter = Counter(split_it) \n\n# most_common() produces k frequently encountered \n# input values and their respective counts. \n = Counter.most_common(10) \n  \n#print(most_occur) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DATA_PATH = \"../input/CORD-19-research-challenge/\"\nfolder_paths = {\"biorxiv_medrxiv/biorxiv_medrxiv/\", \"comm_use_subset/comm_use_subset/\", \"custom_license/custom_license/\", \"noncomm_use_subset/noncomm_use_subset/\"} \npdf_pmc = {\"pdf_json\", \"pmc_json\"}\n\nonlyfiles = []\ndata_list = []\n\nfor fp in folder_paths:\n    for p in pdf_pmc:\n        if (p in listdir(DATA_PATH+fp)):\n            onlyfiles = [f for f in listdir(DATA_PATH+fp+p) if isfile(join(DATA_PATH+fp+ p, f))]\n            for n in onlyfiles:\n                with open(f'{DATA_PATH}{fp}{p}/{n}') as json_data:\n                    this_file = json.load(json_data)\n\n                this_file = extract_values(this_file, 'title')\n                for l in this_file:\n                    if (\"Effect of temperature and relative humidity on\" in l):\n                        data_list.append(l)\n                        print(data_list)\n\n\noutput = []\nremoveNestings(data_list)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}