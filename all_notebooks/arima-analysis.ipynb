{"nbformat":4,"cells":[{"metadata":{"_cell_guid":"108c893e-a44b-4802-9685-d0894dfffe25","_uuid":"9550e2ff36603671cf2134d136ad6e32766831dc"},"source":"# Bitcoin ARIMA analysis\nAbstract: this analysis is an attempt to use ARIMA in analyzing bitcoin prices from the Bitstamp exchange. The objective is to create a model that is able to forecast future prices, identify trends, seasonality, and other remarkable properties. Theoretically, analysis like this could be used in trading. Bitstamp's data was made stationary by using log-diff followed by rolling average diff techniques; achieving a p-value of 7.659524e-26 on the Dickey-Fuller test. Through ACF and PACF an ARIMA model was built with (p,d,q) of (2,1,2) with an RSS of 0.235. Overall, the model was not a good predictor of Bitcoin's price.","cell_type":"markdown"},{"metadata":{"_cell_guid":"71a6596b-8039-452e-bd16-1e49855a29e5","_uuid":"cc72072871ea06f6e5c929a30f69188e4fdf5ae8"},"execution_count":null,"outputs":[],"source":"%matplotlib inline\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport seaborn as sns\nimport datetime\nfrom datetime import date\nimport random\n\nimport statsmodels.api as sm\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom statsmodels.tsa.stattools import acf, pacf\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom statsmodels.tsa.stattools import acf, pacf\nfrom statsmodels.graphics.tsaplots import plot_acf\nfrom statsmodels.graphics.tsaplots import plot_pacf\n\nimport gc\n\nimport warnings\nwarnings.filterwarnings('ignore')","cell_type":"code"},{"metadata":{"_cell_guid":"c4948538-6357-4b4a-b191-05f6995abde4","_uuid":"3bf693d9377d6a001f674bf6df1ca36b933d3b9c"},"source":"# Load the data","cell_type":"markdown"},{"metadata":{"_cell_guid":"763e74a6-5476-4a58-9791-fa4c6a2ed6ef","collapsed":true,"_uuid":"c93232cb94a40968060fb6b1d647931dac82e546"},"execution_count":null,"outputs":[],"source":"def load_data(filename):\n    df = pd.read_csv('../input/{0}'.format(filename))\n    df['Seconds'] = df.Timestamp.values.astype(int) # rename field\n    df.Timestamp = pd.to_datetime(df.Timestamp, unit='s') # true timestamp\n    df = df[df.Open.notnull()] # remove fields w/o data to lower memory requirements\n\n    df = df.reset_index().drop('index', axis=1).reset_index()\n    df['counter'] = df.index\n    df = df.drop('index', axis=1)\n    df = df.set_index('Seconds')\n    df_original = df.copy()\n    \n    # downsample to days\n    df = df.reset_index().set_index('Timestamp').resample('D').mean()\n    df = pd.DataFrame(df)\n    return (df,df_original)","cell_type":"code"},{"metadata":{"_cell_guid":"d7d83512-c222-490b-96e6-b957373a7589","_uuid":"c12d36d516c6f9e3c1f6cafabbb5fa79f8e53dea"},"source":"Summary: data from Bitstamp is the most complete, but there are three missing rows. BTC-e has the most volume and price stability during the identified periods. Therefore, use Bitstamp as our base and backfill it with BTC-e.\n\nData given from the exchanges is on a per multiple second resolution. The candlestick graph of their data shows high volitility and swings within short periods of time. Projects goal is for create a timeseries on a per day basis, hence it is necessary to transforming the data using a smoothing technique to both improve the models predictability and lower the data size.","cell_type":"markdown"},{"metadata":{"_cell_guid":"bccc3cd5-265d-40fa-9920-b10a20d74311","_uuid":"e33d793f1a5975d2cfb81251e226d136ba5f93f2"},"execution_count":null,"outputs":[],"source":"!ls ../input","cell_type":"code"},{"metadata":{"_cell_guid":"a8eaf6ab-364c-489c-a64e-8622818e9f9f","_uuid":"db76902c10b03d976c7cc9acd90a8fbe5aefee59"},"execution_count":null,"outputs":[],"source":"# df1,df1_original = load_data('../input/btceUSD_1-min_data_2012-01-01_to_2017-05-31.csv')\ndf2,_ = load_data('coinbaseUSD_1-min_data_2014-12-01_to_2018-01-08.csv')\n# df3,_ = load_data('../input/krakenUSD_1-min_data_2014-01-07_to_2017-05-31.csv')\ndf4,_ = load_data('bitstampUSD_1-min_data_2012-01-01_to_2018-01-08.csv')\n# print('entries missing in df1', sum(df1.Weighted_Price.isnull()))\nprint('entries missing in df2', sum(df2.Weighted_Price.isnull()))\n# print('entries missing in df3', sum(df3.Weighted_Price.isnull()))\nprint('entries missing in df4', sum(df4.Weighted_Price.isnull()))\n","cell_type":"code"},{"metadata":{"_cell_guid":"bbc3164f-ddd0-4f21-a814-17ad38ee5581","_uuid":"11a2228263c84c16cc5ef9ac7282b7f0131757d6"},"execution_count":null,"outputs":[],"source":"len(df4), len(df2)","cell_type":"code"},{"metadata":{"_cell_guid":"9d81c22e-e8e8-49a9-9c5c-dc7cc4410e5d","_uuid":"d18f72c313069fb8b5172b72c64a44fa2170a994"},"execution_count":null,"outputs":[],"source":"df4.head()","cell_type":"code"},{"metadata":{"scrolled":true,"_cell_guid":"2c45e198-95f0-439e-8f99-c51cc6aceaca","_uuid":"2d2b7102795b15eb5b44f965a7c14c20f4997be5"},"execution_count":null,"outputs":[],"source":"df2.head()","cell_type":"code"},{"metadata":{"_cell_guid":"4eb3e46e-7eeb-497c-b15d-65a231536029","collapsed":true,"_uuid":"cd2eb09585c03e38daa09fda757453e7772ff921"},"execution_count":null,"outputs":[],"source":"","cell_type":"code"},{"metadata":{"_cell_guid":"add88f44-3007-4c41-a11e-68fba5ab23ba","_uuid":"f6abf85d615537e1497ead1c2e45d51e41de7b06"},"execution_count":null,"outputs":[],"source":"_ = df4.reset_index().Timestamp.map(lambda y: y.to_datetime().date())\n_ = np.asarray(_, dtype=date)\ndf4['Date'] = _\ndf4.head()","cell_type":"code"},{"metadata":{"scrolled":true,"_cell_guid":"e7d5b139-7119-4e5e-99bd-8411dfaa7211","collapsed":true,"_uuid":"f5a222690351615f3c84b5350e4c2246371086eb"},"source":"df4 is the best datasource for having all dates. Confirm whether which of the other df's are the base to use to fill in the missing days. From the data below we can see that df1 is the best choise due to it's volume. Finally, confirm that there are no missing entries in df4","cell_type":"markdown"},{"metadata":{"_cell_guid":"f48c379c-2e0a-4007-8d91-84543b21049e","_uuid":"5f454897a876edc1973629a484304beab0a891e9"},"execution_count":null,"outputs":[],"source":"missing_entries_timestamp = df4[df4.Weighted_Price.isnull()].index\nmissing_entries_timestamp","cell_type":"code"},{"metadata":{"_cell_guid":"fbd6b55b-8193-4d6e-b770-630b4b6ae05b","_uuid":"6747c4f261814b9aa5b20c4f9b1031c1c7ed97ef"},"source":"> # EDA\nsummary: The exchanges data range is from 2011-12-31 to 2017-10-20. Although the beginning of bitcoin appears overall calm at first, we see after zooming in that is not the case; the first 500 days are just as volitile. A plot of these dates shows around 2016 the price goes expoentially upwards. The early days of Bitcoin are more suitable for time series analysis, we will analyze the first 380 days.\n\nTime Series analysis typically requires data to be stationary. Just by looking at the graph we notice that it is not stationary. Per the Dickey-Fuller test we cannot reject the null hypothesis with the given p-value of 0.925053.\n\nMaking the data stationary was accomplished by taking the log-difference followed by the rolling average, producing a 'p-value' of 7.659524e-26 and 'Test Statistic' of -10.382883 which is far below it's 'Critical Value (1%)' of -3.448052.\n","cell_type":"markdown"},{"metadata":{"_cell_guid":"8362042a-9105-4b94-b81c-2788c7b5253f","_uuid":"1e2ea4f1b68b74bc09b8844693895d8776da25f2"},"execution_count":null,"outputs":[],"source":"sns.boxplot(x=\"Date\", y=\"Weighted_Price\", data=df4, palette=\"PRGn\")\nsns.despine(offset=10, trim=True)\nplt.show()","cell_type":"code"},{"metadata":{"_cell_guid":"e9b41f8c-4f4a-4533-bd05-e1bdf4085619","_uuid":"5b2952ea19369d025960766a61e37401743ed5dc"},"execution_count":null,"outputs":[],"source":"sns.boxplot(x=\"Date\", y=\"Weighted_Price\", data=df4[:500], palette=\"PRGn\")\nsns.despine(offset=10, trim=True)\nplt.show()","cell_type":"code"},{"metadata":{"_cell_guid":"1f622b3a-2a80-4e9d-a5af-cb08236d042b","_uuid":"866cb6838457e53df0a306f11b5abd0b285fd1f2"},"source":"### what are the date ranges we are dealing with?","cell_type":"markdown"},{"metadata":{"_cell_guid":"ab76c883-22f3-439f-be45-bf0c55a30f80","_uuid":"34a94f957c3d0987ca50cd5e23a83f5f03d651fd"},"execution_count":null,"outputs":[],"source":"df = df4.Weighted_Price\ndf = pd.DataFrame(df)\ndf.index.min(), df.index.max()","cell_type":"code"},{"metadata":{"_cell_guid":"806b2d09-06d2-4f01-a841-310907ad139f","_uuid":"bb10073f9185f161a5921795a6ac36335dd28571"},"source":"### Plot out what we got so far...","cell_type":"markdown"},{"metadata":{"_cell_guid":"58ea387c-fda0-4ea4-bd1d-e7d2f79e9c64","_uuid":"a59ade7537ee1ac9fb4531f9570e12ff82a0bd16"},"source":"its quite clear that its not stationary. Starting from the beginning of 1012 to end of 2013 its fairly linear, and again from 2015 to 2016. Thereafter it appears to be squared.","cell_type":"markdown"},{"metadata":{"_cell_guid":"44dc61e5-46e4-4be3-90a4-cbf121107378","_uuid":"e026e699253654f63ec657db988f70c5f38907ad"},"execution_count":null,"outputs":[],"source":"plt.figure(figsize=(15,6))\nplt.plot(df)\nplt.show()","cell_type":"code"},{"metadata":{"_cell_guid":"d6bb5517-ec96-40c5-aae4-6019939ae16e","_uuid":"bf60ec8281e02e17954e93f9b4af567589851519"},"source":"Hence, let's first limit our TS to what we know will work; the first xxx days.","cell_type":"markdown"},{"metadata":{"_cell_guid":"1732312e-ca5a-4ccb-bb96-e4a21322c2a3","_uuid":"396ff1e3139bf203e4d35d57c7e3f39ea2ff3562"},"execution_count":null,"outputs":[],"source":"df = df[:380] # take the first xxx days\nplt.figure(figsize=(15,6))\nplt.plot(df)\nplt.show()","cell_type":"code"},{"metadata":{"_cell_guid":"6a6b574a-16ee-4869-b72d-345062b7450f","_uuid":"85783b66f06d452df5d7cec7add218f7a6e2edd6"},"source":"# Make it stationary","cell_type":"markdown"},{"metadata":{"_cell_guid":"6f1ea40e-32ff-41e6-83a8-74df4ec89968","_uuid":"79ca3234ca8be4de8ccbae2619334562401bbf9e"},"source":"Our time series is not stationary - for it to be stationary it requires that the mean and variance remain constant over time. Dickey-Fuller test is the math way of determining whether it's stationary or not, let's run that now so we have a baseline for future comparisons.","cell_type":"markdown"},{"metadata":{"_cell_guid":"c3c45979-4a30-4bfb-ba3d-d3fb412acb11","_uuid":"c6e3da2544a93e55c0c3ba2c898cc790e6fcce23"},"execution_count":null,"outputs":[],"source":"# source: https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/ \ndef test_stationarity(timeseries):\n    #Determing rolling statistics\n    rolmean = pd.rolling_mean(timeseries, window=12)\n    rolstd = pd.rolling_std(timeseries, window=12)\n\n    #Plot rolling statistics:\n    plt.figure(figsize=(15,6))\n    orig = plt.plot(timeseries, color='blue',label='Original')\n    mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n    std = plt.plot(rolstd, color='black', label = 'Rolling Std')\n    plt.legend(loc='best')\n    plt.title('Rolling Mean & Standard Deviation')\n    plt.show(block=False)\n    Dickey_Fuller_test(timeseries)\n    \ndef Dickey_Fuller_test(timeseries):\n    #Perform Dickey-Fuller test:\n    print('Results of Dickey-Fuller Test:')\n    dftest = adfuller(timeseries, autolag='AIC')\n    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n    for key,value in dftest[4].items():\n        dfoutput['Critical Value (%s)'%key] = value\n    print(dfoutput)\ntest_stationarity(df.Weighted_Price)","cell_type":"code"},{"metadata":{"_cell_guid":"6bf86726-10eb-408b-9468-55842b6b5ba6","_uuid":"8148bae6c4e6813ee6ec9c5018b05522f218f59b"},"source":"### The p-value is too high to reject the null hypothesis.\n\nBased on the initial curve of the graph, the data needs to be transformed to get it stationary. First try transforming the data with log to remove the trend.","cell_type":"markdown"},{"metadata":{"_cell_guid":"e18f492b-94bd-40a4-b9c2-6a92e7eab216","_uuid":"92f96a822dbe9c3a75b281842e09501e8100d890"},"source":"### take the log\nSummary: Taking the log will flatten the curve to a near linear line.","cell_type":"markdown"},{"metadata":{"scrolled":false,"_cell_guid":"bb587245-cf50-47c7-9411-4012b2058271","_uuid":"9b11deb005c8b2d1fda56e5bd7fce48ea1791bf0"},"execution_count":null,"outputs":[],"source":"ts_df_log = np.log(df)\n#test_stationarity(ts_df_log.Weighted_Price)\nplt.figure(figsize=(15,6))\nplt.plot(df, color='blue', label='original')\nplt.plot(ts_df_log, color='red', label='log')\nplt.title('original (blue) vs log (red)')\nplt.legend(loc='best')\nplt.show()\nDickey_Fuller_test(ts_df_log.Weighted_Price)","cell_type":"code"},{"metadata":{"_cell_guid":"07338472-80bb-4865-b4c6-c1faa1d5e2ca","_uuid":"7d286510119a6dffd20f0ac982d3e4a0303f0397"},"source":"### Rolling average\nSummary: linear regression and rolling average can be used to remove the trend, here we can see a positive upwards trend. Removing the trend should help up","cell_type":"markdown"},{"metadata":{"scrolled":false,"_cell_guid":"f9929096-6391-414e-a9cb-73840049c606","_uuid":"4fff8089836e5af6c5b5cc13ab376b47ed7cdc32"},"execution_count":null,"outputs":[],"source":"window = 7\nRolling_average = ts_df_log.rolling(window = window, center= False).mean()\nts_df_log_rolling = Rolling_average.dropna()\nplt.figure(figsize=(15,6))\nplt.plot(ts_df_log, label = 'Log Transformed')\nplt.plot(ts_df_log_rolling, color = 'red', label = 'Rolling Average')\nplt.legend(loc = 'best')\nplt.show()","cell_type":"code"},{"metadata":{"_cell_guid":"a71dc781-d067-4587-9e95-1de1f0d05c8a","_uuid":"23963b99c0ffae8afcc5aacb3f9e1313f7ff2415"},"source":"Notice that the RA is off, lets fix that to improve our representation of the data","cell_type":"markdown"},{"metadata":{"_cell_guid":"cbadf557-de28-48d1-a59e-9f3bf64fee3d","_uuid":"ccaf8704d9a86ea856163d3d54a381d5e7b2fb8b"},"execution_count":null,"outputs":[],"source":"window = 7\nshift_by_days = -2\nRolling_average = ts_df_log.rolling(window = window, center= False).mean()\nts_df_log_rolling_temp = Rolling_average.shift(shift_by_days).dropna()\nplt.figure(figsize=(15,6))\nplt.plot(ts_df_log, label = 'Log Transformed')\nplt.plot(ts_df_log_rolling_temp, color = 'red', label = 'Rolling Average')\nplt.legend(loc = 'best')\nplt.show()","cell_type":"code"},{"metadata":{"_cell_guid":"25f7769f-cfd4-4211-9abb-e1b2a4cfae99","_uuid":"4694b12c06f0b99fbc667feed9350678eb8ac142"},"source":"MUCH BETTER! Notice how the peaks in both are consistent. Let's do a diff and figure out our new p-value.","cell_type":"markdown"},{"metadata":{"_cell_guid":"13be6fa0-35b5-41fe-9380-ab8f6f91c323","_uuid":"71038f4d59a2c9dcc672082af2a6889e6c9d82ad"},"execution_count":null,"outputs":[],"source":"ts_df_log_rolling = (ts_df_log - ts_df_log_rolling_temp).dropna()\nplt.figure(figsize=(15,6))\nplt.plot(ts_df_log, label = 'Log Transformed')\nplt.plot(ts_df_log_rolling, color = 'red', label = 'Log and Rolling Average Transformed')\nplt.legend(loc = 'best')\nplt.show()\nDickey_Fuller_test(ts_df_log_rolling.Weighted_Price)","cell_type":"code"},{"metadata":{"_cell_guid":"c169d451-7ce6-49ac-b56a-942587b81d3f","_uuid":"d77ba7395b4d743e216b7bf88dcfd9ed0cd54b60"},"source":"BAM!!! \n\np-value 7.659524e-26 is less than our alpha of 0.05 - per this test it is stationary! 'Test Statistic' is significantly below the 'Critical Value (1%)' indicating stationary. In addition, just looking at the line above (red), it appears stationary.\n<br/>\n<br/>\n<br/>\n","cell_type":"markdown"},{"metadata":{"_cell_guid":"ab853b0f-a7db-458c-b895-ea4d34443bea","_uuid":"ae87360aab419114996a2cbdfc0f176de597fb23"},"source":"# Building a model\nSummary: Now that we have achieved stationarity, the next step is to build an ARIMA model. In building a model three terms are needed p,q,d: p = # of AR term using PACF, d = # of differences, q = # of MA term using ACF. \n\nPer https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/ our next step is to build ACF and PACF to justify using either AR, MA, ARMA, or ARIMA. \"The ARIMA forecasting for a stationary time series is nothing but a linear (like a linear regression) equation.\" We need to calculate out the p,q, and d.\n\nAFC bars fall within the 95% confidence inteval at the 2nd bar implying that the first bar (t) impact reaches through the second (t-1) and onwards to the third bar (t-2). Question is whether this is truly due to correlation or the remaining 5% probability. I would argue that it is due to correlation because remaining bars have a sine-wave pattern and are not due to a random walk. We can also see that the coefficients are positive.\n\nPACF bars fall within the 95% condifence interval at the 2nd bar implying that each bar has a correlation with the prior bar and not ancestor bars. It's sine-like wave indicates that it might be an AR(2+) process.","cell_type":"markdown"},{"metadata":{"_cell_guid":"9f4a1324-55d4-46a5-aa62-1ae0611f8630","collapsed":true,"_uuid":"1f89fa7876531aa2aa08530eae42617d6bb03459"},"execution_count":null,"outputs":[],"source":"# ACF and PACF plots\nlag = 20\nlag_pacf = pacf(ts_df_log_rolling, nlags=lag, method='ols')\nlag_acf = acf(ts_df_log_rolling, nlags=lag)","cell_type":"code"},{"metadata":{"_cell_guid":"1682bf76-bb51-46fa-bd64-3b65fb6ad30b","_uuid":"6d462c6307beb2a46ef84d8a42783d8348a356f2"},"execution_count":null,"outputs":[],"source":"#Plot ACF: \nplt.figure(figsize=(15,3))\nplt.plot(lag_acf)\nplt.axhline(y=0,linestyle='--',color='gray')\nplt.axhline(y=-1.96/np.sqrt(len(ts_df_log_rolling)),linestyle='--',color='gray')\nplt.axhline(y=1.96/np.sqrt(len(ts_df_log_rolling)),linestyle='--',color='gray')\nplt.title('ACF')\nplt.tight_layout()\nplt.show()\n\nplt.figure(figsize=(15,3))\nplot_acf(ts_df_log_rolling, ax=plt.gca(),lags=lag)\nplt.show()","cell_type":"code"},{"metadata":{"_cell_guid":"3fedd0a6-e358-4a16-be7e-a8f91a65b6d6","_uuid":"7e3d85430f51d4115a1e6b36a547bee8f06688ab"},"execution_count":null,"outputs":[],"source":"#Plot PACF:\nplt.figure(figsize=(15,3))\nplt.plot(lag_pacf)\nplt.axhline(y=0,linestyle='--',color='gray')\nplt.axhline(y=-1.96/np.sqrt(len(ts_df_log_rolling)),linestyle='--',color='gray')\nplt.axhline(y=1.96/np.sqrt(len(ts_df_log_rolling)),linestyle='--',color='gray')\nplt.title('PACF')\nplt.tight_layout()\nplt.show()\n\nplt.figure(figsize=(15,3))\nplot_pacf(ts_df_log_rolling, ax=plt.gca(), lags=lag)\nplt.tight_layout()\nplt.show()","cell_type":"code"},{"metadata":{"_cell_guid":"2dde8fe3-37b5-4b81-a8b2-6acebb3caeb9","_uuid":"6d53bb9ed58653bb642e6a38ba01aeab946a0f0b"},"source":"Notice that the first entry to break the upper confidence interval is the second dot (zero based).","cell_type":"markdown"},{"metadata":{"_cell_guid":"2efe77ca-f240-4c8e-a203-332c92df9ff7","collapsed":true,"_uuid":"bd23490bb7a80a70f1fe810a0937cb28ad7391a4"},"execution_count":null,"outputs":[],"source":"p=2","cell_type":"code"},{"metadata":{"_cell_guid":"923fb25d-0c8f-4d15-a1ef-20cc7c4afb61","collapsed":true,"_uuid":"3b96193f75a2235759147215227d5e2bd610ec63"},"execution_count":null,"outputs":[],"source":"q=2","cell_type":"code"},{"metadata":{"_cell_guid":"91ce3248-0a9f-4f48-9ad8-076eb6d5a485","_uuid":"50e0405968a0d1303d6b49fbcc6f69e365aa213c"},"source":"Above graph tells us our p and q values:\n\nUsing the above information, lets build a pure AR, MA, and then ARIMA models.","cell_type":"markdown"},{"metadata":{"_cell_guid":"ee335e18-b4f4-4f79-8fdc-6912fdfc6828","collapsed":true,"_uuid":"3953e128f74b21387cebd25de158187259b5debe"},"execution_count":null,"outputs":[],"source":"d=1","cell_type":"code"},{"metadata":{"_cell_guid":"9f2aaec2-ccd2-4e23-bfd2-3d152d5dea6a","_uuid":"ce6ba585ededd4c53eafbf6c693d5459cc79b683"},"source":"### AR","cell_type":"markdown"},{"metadata":{"_cell_guid":"c812c89d-36d1-4cbe-b5b0-c1c9954043f2","_uuid":"382ca3d22a74d4b5f3f45fb99433056ba49ed6af"},"execution_count":null,"outputs":[],"source":"# AR\nmodel = ARIMA(ts_df_log_rolling, order=(p, d, 0))  \nresults_AR = model.fit(disp=-1)\nplt.figure(figsize=(15,6))\nplt.plot(ts_df_log_rolling)\nplt.plot(results_AR.fittedvalues, color='red')\nplt.title('RSS: %.4f'% sum((results_AR.fittedvalues-ts_df_log_rolling.Weighted_Price).dropna()**2))\nplt.show()","cell_type":"code"},{"metadata":{"_cell_guid":"b3b96eec-7d43-4fe3-96fc-25d02a5d197f","_uuid":"2e2dbbef21a15346539ed6f29072b67eb62148f1"},"execution_count":null,"outputs":[],"source":"results_AR.summary()","cell_type":"code"},{"metadata":{"_cell_guid":"3fb58b30-7460-4fa8-9b57-225ac23e8ed8","_uuid":"e8fc2593685d616c37e8387d62da8459b229c1dd"},"source":"### MA","cell_type":"markdown"},{"metadata":{"_cell_guid":"83b738bf-2239-4e53-97aa-715c41b196d8","_uuid":"cde20e1f8d261d209e41253497197adfda52f768"},"execution_count":null,"outputs":[],"source":"model = ARIMA(ts_df_log_rolling, order=(0, d, q))  \nresults_MA = model.fit(disp=-1) \nplt.figure(figsize=(15,6))\nplt.plot(ts_df_log_rolling)\nplt.plot(results_MA.fittedvalues, color='red')\nplt.title('RSS: %.4f'% sum((results_MA.fittedvalues-ts_df_log_rolling.Weighted_Price).dropna()**2))\nplt.show()","cell_type":"code"},{"metadata":{"_cell_guid":"c50bb2c8-8a95-4a66-95ed-59d118835726","_uuid":"d7862e39442e9a81b923a0fc23662bd76b06e1ab"},"execution_count":null,"outputs":[],"source":"results_MA.summary()","cell_type":"code"},{"metadata":{"_cell_guid":"03691a06-4938-4177-9641-3ee117db93c3","_uuid":"99d9114c3fbd3630b71f4fe5d5d5fd50a804b565"},"source":"### ARIMA","cell_type":"markdown"},{"metadata":{"_cell_guid":"76e52a95-7002-47e7-a224-c1a8ff854a44","_uuid":"3dc008c00046a331e0c7f91ffa503ae246a92ba5"},"execution_count":null,"outputs":[],"source":"# ARIMA\nmodel = ARIMA(ts_df_log, order=(p, d, q))  \nresults_ARIMA = model.fit(disp=-1, trend='nc')\nplt.figure(figsize=(15,6))\nplt.plot(ts_df_log_rolling, label='ts_df_log_rolling')\nplt.plot(results_ARIMA.fittedvalues, color='red')\nplt.title('RSS: %.4f'% sum((results_ARIMA.fittedvalues-ts_df_log_rolling.Weighted_Price).dropna()**2))\nplt.legend(loc='best')\nplt.show()","cell_type":"code"},{"metadata":{"_cell_guid":"e031f41c-23f8-4eca-897f-6bcc306f384b","_uuid":"91718ad07b11b860d157e6436938b0398bf3cc9f"},"source":"### plot out the residuals - a good model will have residuals that look like white noise","cell_type":"markdown"},{"metadata":{"scrolled":false,"_cell_guid":"2c563619-2275-46c9-b92e-35e3476d39ed","_uuid":"9925d6206c25c0fbd27da7b174857190ec9555d1"},"execution_count":null,"outputs":[],"source":"x = pd.DataFrame(results_ARIMA.fittedvalues)\nx.columns = ts_df_log_rolling.columns\nx = x - ts_df_log_rolling\n# x = x.cumsum()\nplt.plot(x, label='residuals')\nplt.legend(loc='best')\nplt.show()","cell_type":"code"},{"metadata":{"_cell_guid":"9c3811ab-228a-4cdc-aff0-2478269ece3f","_uuid":"5c757033de88ac5524e2077c6f50cda6b6399d28"},"source":"Conclusion: I don't think this is completely white noise as what a good model should have, I think there is signal coming through. Future: why is the predictor so bad. NLP weighting? If this is a signal then that means there are features in here that have yet to be discovered.","cell_type":"markdown"},{"metadata":{"_cell_guid":"2fcf8433-4d7a-4867-a94f-83936dc0c447","_uuid":"b1a2d0b888dd90851397f02584dc94f08935d3ac"},"source":" ","cell_type":"markdown"},{"metadata":{"_cell_guid":"84369435-4959-4a9b-ac53-d54b77749438","_uuid":"6469eb4416f80fad9cf131e37407f919ad94543f"},"source":"## Forecast\nsummary: Obviously our forecast is not good at all. Bitcoin, like the stock market, under the assumption of no other factors is a day to day random walk. With out data that random walk happens to have an upwards trend most of the time. And this makes sense because if other traders had a way to predict the future price they would place a trade and a new equilibrium would set it. That being said the story of 'Black-Scholes formula' and 'Long-Term Capital Management' is a great story about a system in transition to a new equilibriums.","cell_type":"markdown"},{"metadata":{"_cell_guid":"7cf1d7e3-08f1-4d63-aebd-690c80febf9c","_uuid":"5a68690c5d23066966c05ee930015f9ab5a2ae16"},"execution_count":null,"outputs":[],"source":"predictions_ARIMA_diff = pd.Series(results_ARIMA.fittedvalues, copy=True)\npredictions_ARIMA_diff_cumsum = predictions_ARIMA_diff.cumsum()\npredictions_ARIMA_log = pd.Series(ts_df_log.Weighted_Price, index=ts_df_log.index)\npredictions_ARIMA = np.exp(predictions_ARIMA_log)\n\nplt.figure(figsize=(15,3))\nplt.plot(df, label='first 380 days')\nplt.plot(predictions_ARIMA, 'r+', label='predicted')\nplt.legend(loc='best')\nplt.show()","cell_type":"code"},{"metadata":{"_cell_guid":"888c5253-e79e-4dbe-abd0-0713ea4402de","_uuid":"e76d3c7778e3d60b1828271fdd44acd455b5776b"},"execution_count":null,"outputs":[],"source":"start = 360\nend = 400\nforecast = results_ARIMA.predict(start=start, end=end)\nf = (forecast + forecast.shift(-1))\nf = f.shift(-3).dropna()\nforecast = f\n\nplt.figure(figsize=(15,3))\nplt.plot(df[:end].Weighted_Price, label='original data')\nplt.show()\nplt.plot(forecast, color='red', label='predicted')\nplt.legend(loc='best')\nplt.show()\nplt.plot(df4[start:end].Weighted_Price, label='actual')\nplt.legend(loc='best')\nplt.show()","cell_type":"code"},{"metadata":{"_cell_guid":"bd871bb9-2441-4da6-9ee7-e1588217535a","collapsed":true,"_uuid":"3fa7c71e9e6ad40db8d1cf8dc3f99036c05026b2"},"execution_count":null,"outputs":[],"source":"","cell_type":"code"},{"metadata":{"_cell_guid":"bd408464-9856-40ec-b236-1d2e15d565ca","collapsed":true,"_uuid":"dd76c791ed06302a67c6023810a54c659656db7a"},"execution_count":null,"outputs":[],"source":"","cell_type":"code"},{"metadata":{"_cell_guid":"2ceee941-77aa-4701-baff-e17800a9d3f5","collapsed":true,"_uuid":"c35306ed7f35f37b71fb20ade226b41c1c1290cc"},"execution_count":null,"outputs":[],"source":"","cell_type":"code"},{"metadata":{"_cell_guid":"e6c294ce-ed01-44df-8430-c057841e5657","collapsed":true,"_uuid":"baeac88c77657744cc9543886c694374e691c3f3"},"execution_count":null,"outputs":[],"source":"","cell_type":"code"},{"metadata":{"collapsed":true},"execution_count":null,"outputs":[],"source":"","cell_type":"code"},{"metadata":{"collapsed":true},"execution_count":null,"outputs":[],"source":"","cell_type":"code"},{"metadata":{"collapsed":true},"execution_count":null,"outputs":[],"source":"","cell_type":"code"}],"metadata":{"kernelspec":{"name":"python3","language":"python","display_name":"Python 3"},"language_info":{"file_extension":".py","nbconvert_exporter":"python","version":"3.6.4","pygments_lexer":"ipython3","name":"python","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3}}},"nbformat_minor":1}