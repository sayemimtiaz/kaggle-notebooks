{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Pandas 101: One-stop Shop for Data Science\n\n### This notebook can be treated as pandas cheatsheet or a beginner-friendly guide to learn from basics.\n\nLast updated on 24-May-2020 (Appending & Concatenating Series)\n\n[1. Creating DataFrames](#Creating-DataFrames)<br>\n[2. Reading and writing CSVs](#Reading-and-writing-CSVs)<br>\n[3. Some useful pandas function](#Some-useful-pandas-function)<br>\n[4. Appending & Concatenating Series](#Appending-Concatenating-Series)<br>\n[5. Sorting](#Sorting)<br>\n[6. Subsetting](#Subsetting)<br>\n[7. Subsetting using .isin()](#Subsetting-using)<br>\n[8. Detecting missing values .isna()](#Detecting-missing-values)<br>\n[9. Counting missing values](#Counting-missing-values)<br>\n[10. Removing missing values](#Removing-missing-values)<br>\n[11. Adding a new column](#Adding-a-new-column)<br>\n[12. Deleting columns in DataFrame](#Deleting-columns-in-DataFrame)<br>\n[13. Summary statistics](#Summary-statistics)<br>\n[14. agg() method](#.agg-method)<br>\n[15. Dropping duplicate names](#Dropping-duplicate-names)<br>\n[16. Count categorical data](#Count-categorical-data)<br>\n[17. Grouped summaries](#Grouped-summaries)<br>\n[18. Pivot table](#Pivot-table)<br>\n[19. Explicit indexes](#Explicit-indexes)<br>\n[20. Visualizing your data](#Visualizing-your-data)<br>\n[21. Arithmetic with Series & DataFrames](#Arithmetic-with-Series-DataFrames)<br>\n[21. Merge DataFrames](#Merge-DataFrames)<br>\n[23. What next?](#What-next)<br>\n\n\"Avocado Prices\" dataset is used in this notebook :)","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n%matplotlib inline\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"Creating-DataFrames\"></a>\n# Creating DataFrames\n* From a list of dictionaries (constructed row by row)","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"list_of_dicts = [ \n     {\"name\": \"Ginger\", \"breed\": \"Dachshund\", \"height_cm\": 22,\"weight_kg\": 10, \"date_of_birth\": \"2019-03-14\"},\n    {\"name\": \"Scout\", \"breed\": \"Dalmatian\", \"height_cm\": 59,\"weight_kg\": 25, \"date_of_birth\": \"2019-05-09\"}\n]\nnew_dogs = pd.DataFrame(list_of_dicts)\nnew_dogs","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* From a dictionary of lists (constructed column by column)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dict_of_lists = { \n     \"name\": [\"Ginger\", \"Scout\"], \n     \"breed\": [\"Dachshund\", \"Dalmatian\"], \n     \"height_cm\": [22, 59], \n     \"weight_kg\": [10, 25], \n     \"date_of_birth\": [\"2019-03-14\",\"2019-05-09\"]  } \nnew_dogs = pd.DataFrame(dict_of_lists) \nnew_dogs","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"Reading-and-writing-CSVs\"></a>\n# Reading and writing CSVs\n* CSV = comma-separated values \n* Designed for DataFrame-like data \n* Most database and spreadsheet programs can use them or create them","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# read CSV from using pandas\navocado = pd.read_csv(\"../input/avocado-prices/avocado.csv\")\n# print the first few rows of the dataframe\navocado.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Read CSV and assign index\n<p>You can assign columns as index using \"index_col\" attribute.</p>\n<p>Since I want to index Date there is another helpful function called \"parse_date\" which will parse the date in the rows such that we can perform more complex subsetting(eg monthly, weekly etc).</p>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# read CSV from using pandas and assigning Date as index of the dataframe\navocado = pd.read_csv(\"../input/avocado-prices/avocado.csv\",parse_dates=True, index_col='Date')\n# print the first few rows of the dataframe\navocado.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Remove index from dataframe .reset_index(drop)\n\nTo reset the index use this function","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"avocado = avocado.reset_index(drop=True)\navocado.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To write a CSV file function dataframe.to_csv(FILE_NAME)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"avocado.to_csv(\"test_write.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Some useful pandas function\n\n* **.head()** or **.head(x)** is used to get the first x rows of the DataFrame (x = 5 by default)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"avocado = pd.read_csv(\"../input/avocado-prices/avocado.csv\")\navocado.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **.tail()** or **.tail(x)** is used to get the last x rows of the DataFrame (x = 5 by default)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"avocado.tail(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **.info()** is used to get a concise summary of the DataFrame","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"avocado.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **.shape** is used to get the dimensions of the DataFrame","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(avocado.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **.describe()** is used to view some basic statistical details like percentile, mean, std etc. of a DataFrame","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"avocado.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **.values** this attribute return a Numpy representation of the given DataFrame","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"avocado.values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **.columns** this attribute return a Numpy representation of columns in the DataFrame","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(avocado.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"Appending-Concatenating-Series\"></a>\n# Appending & Concatenating Series\n\nappend(): Series & DataFrame method\n* Invocation:\n* s1.append(s2)\n* Stacks rows of s2 below s1 \n<br>\n<br>\n<br>\nconcat(): pandas module function<br>\n* Invocation:\n* pd.concat([s1, s2, s3])\n* Can stack row-wise or column-wise","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"even = pd.Series([2,4,6,8,10])\nodd = pd.Series([1,3,5,7,9])\n\nres = even.append(odd)\nres","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Observe index got messed up\n\nYou can use .reset_index(drop=True) to fix it<br>\nNote: if drop = False then previous index will be added as a column","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"res.reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"Sorting\"></a>\n# Sorting\nsyntax:<br>\n> DataFrame.sort_values(by, axis=0, ascending=True, inplace=False, kind=’quicksort’, na_position=’last’)\n\n* by: Single/List of column names to sort Data Frame by.\n* axis: 0 or ‘index’ for rows and 1 or ‘columns’ for Column.\n* ascending: Boolean value which sorts Data frame in ascending order if True.\n* inplace: Boolean value. Makes the changes in passed data frame itself if True.\n* kind: String which can have three inputs(‘quicksort’, ‘mergesort’ or ‘heapsort’) of algorithm used to sort data frame.\n* na_position: Takes two string input ‘last’ or ‘first’ to set position of Null values. Default is ‘last’.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# sort values based on \"AveragePrice\" (ascending) and \"year\" (descending)\navocado.sort_values([\"AveragePrice\", \"year\"], ascending=[True, False]) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Sorting by index\n\nuse df.sort_index(ascending=True/False)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id=\"Subsetting\"></a>\n# Subsetting\n\nSubsetting is used to get a slice of the original dataframe","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Subsetting columns\navocado[\"AveragePrice\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Subsetting multiple columns","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Subsetting multiple columns\navocado[[\"AveragePrice\",\"Date\"]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Subsetting rows","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Subsetting rows\navocado[\"AveragePrice\"]<1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"and then using it for subsetting the original dataframe","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# This will print only the rows with price < 1\navocado[avocado[\"AveragePrice\"]<1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Subsetting based on text data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# it will print all the rows with \"type\" = \"organic\"\navocado[avocado[\"type\"]==\"organic\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Subsetting based on dates","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# it will print all the rows with \"Date\" <= 2015-02-04\navocado[avocado[\"Date\"]<=\"2015-02-04\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Subsetting based on multiple conditions\nYou can use the logical operators to define a complex condition<br>\n* \"&\" and\n* \"|\" or\n* \"~\" not\n\n> ** SEPERATE EACH CONDITION WITH PARENTHESES TO AVOID ERRORS**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# it will print all the rows with \"Date\" before 2015-02-04 and \"type\" == \"organic\"\navocado[(avocado[\"Date\"]<\"2015-02-04\") & (avocado[\"type\"]==\"organic\")]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"Subsetting-using\"></a>\n# Subsetting using .isin()\nisin() method helps in selecting rows with having a particular(or Multiple) value in a particular column\n\n> Syntax: DataFrame.isin(values)\n> \n> Parameters:\n> values: iterable, Series, List, Tuple, DataFrame or dictionary to check in the caller Series/Data Frame.\n> \n> Return Type: DataFrame of Boolean of Dimension.\n> ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# subset the avocado in the region Boston or SanDiego\nregionFilter = avocado[\"region\"].isin([\"Boston\", \"SanDiego\"])\navocado[regionFilter]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Multiple parameter Filtering\nUse logical operators to combine different filters","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# subset the avocado in the region Boston or SanDiego in the year 2016 or 2017\nregionFilter = avocado[\"region\"].isin([\"Boston\", \"SanDiego\"])\nyearFilter = avocado[\"year\"].isin([\"2016\", \"2017\"])\navocado[regionFilter & yearFilter]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"Detecting-missing-values\"></a>\n# Detecting missing values .isna()\n\n.isna() is a method used to find is there exist any NaN values in the DataFrame\n\nIt will give a True bool value if a cell has a NaN value","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"avocado.isna()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### We can use .any() function to get a consise info","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"avocado.isna().any()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"Counting-missing-values\"></a>\n# Counting missing values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"avocado.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"Removing-missing-values\"></a>\n# Removing missing values\n* Drop NaN ** .dropna() **\n* Fill NaN with value x ** .fillna(x) **","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Luckily we don't have any NaN but if we have we can use any of the two methods\n\navocado.dropna()\n\n# ****  OR  ****\n\nmeanVal = avocado[\"AveragePrice\"].mean()\navocado.fillna(meanVal)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"Adding-a-new-column\"></a>\n# Adding a new column\nIt can easily be done using the [ ] brackets\n\nLets add a new column to our dataframe called AveragePricePer100","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"avocado[\"AveragePricePer100\"] = avocado[\"AveragePrice\"] * 100\navocado","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"Deleting-columns-in-DataFrame\"></a>\n# Deleting columns in DataFrame .drop(lst,axis = 1)\n> dataFrame.drop(['COLUMN_NAME'], axis = 1)\n* the first parameter is a list of columns to be deleted\n* axis = 1 means delete column\n* axis = 0 means delete row","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"avocado.drop([\"AveragePricePer100\"],axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"Summary-statistics\"></a>\n# Summary statistics\nSome of the functions availabe in pandas are:\n\n> .median() .mode() .min() .max() .var() .std() .sum() .quantile()","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# mean of the AveragePrice of avocado\navocado[\"AveragePrice\"].mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Summarizing dates\n\nTo find the min or max date in a dataframe","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"avocado[\"Date\"].max()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\".agg-method\"></a>\n# .agg() method\n\nPandas Series.agg() is used to pass a function or list of function to be applied on a series or even each element of series separately.\n\n> Syntax: Series.agg(func, axis=0)\n> \n> Parameters:\n> func: Function, list of function or string of function name to be called on Series.\n> axis:0 or ‘index’ for row wise operation and 1 or ‘columns’ for column wise operation.\n> \n> Return Type: The return type depends on return type of function passed as parameter.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def pct30(column):     \n    #return the 0.3 quartile\n    return column.quantile(0.3)\ndef pct50(column):     \n    #return the 0.5 quartile\n    return column.quantile(0.5)\n\navocado[[\"AveragePrice\",\"Total Bags\"]].agg([pct30,pct50])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"Dropping-duplicate-names\"></a>\n# Dropping duplicate names .drop_duplicates(lst)\nDelete all the duplicate names from the dataframe\n\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = avocado.drop_duplicates(subset=[\"year\"])\ntemp","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"Count-categorical-data\"></a>\n# Count categorical data .value_counts()\n\nPandas Series.value_counts() function return a Series containing counts of unique values.\n\n> Syntax: Series.value_counts(normalize=False, sort=True, ascending=False, bins=None, dropna=True)\n> \n> Parameter :\nnormalize : If True then the object returned will contain the relative frequencies of the unique values.\nsort : Sort by values.\nascending : Sort in ascending order.\nbins : Rather than count values, group them into half-open bins, a convenience for pd.cut, only works with numeric data.\ndropna : Don’t include counts of NaN.\n> \n> Returns : counts : Series","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# count number of avocado in each year in descending order\navocado[\"year\"].value_counts(sort=True, ascending = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"Grouped-summaries\"></a>\n# Grouped summaries .groupby(col)\nThis function will group similar categories into one and then we can perform some summary statistics\n\n> Syntax: DataFrame.groupby(by=None, axis=0, level=None, as_index=True, sort=True, group_keys=True, squeeze=False, **kwargs)\n> \n> Parameters :\n> by : mapping, function, str, or iterable<br>\n> axis : int, default 0<br>\n> level : If the axis is a MultiIndex (hierarchical), group by a particular level or levels<br>\n> as_index : For aggregated output, return object with group labels as the index. Only relevant for DataFrame input. as_index=False is effectively “SQL-style” grouped output<br>\n> sort : Sort group keys. Get better performance by turning this off. Note this does not influence the order of observations within each group. groupby preserves the order of rows within each group.<br>\n> group_keys : When calling apply, add group keys to index to identify pieces<br>\n> squeeze : Reduce the dimensionality of the return type if possible, otherwise return a consistent type<br>\n> \n> Returns : GroupBy object","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# group by multiple columns and perform multiple summary statistic operations\navocado.groupby([\"year\",\"type\"])[\"AveragePrice\"].agg([min,max,np.mean,np.median])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"Pivot-table\"></a>\n# Pivot table\nA pivot table is a table of statistics that summarizes the data of a more extensive table.\n\nIMPORRANT parements to remember are<br>\n\"index\": it is the value that appeares on the left most side of the table (it can be a list)<br>\n\"columns\": these are the column you want to add to the pivot table<br>\n\"aggfunc\": it will call the function (it can be a list)<br>\n\"values\": it is the attribute which will be summarized in the table (values inside the table)<br>\n\n> Syntax<br>\n> pandas.pivot_table(data, values=None, index=None, columns=None, aggfunc=’mean’, fill_value=None, margins=False, dropna=True, margins_name=’All’)<br>\n> \n> Parameters:<br>\ndata : DataFrame<br>\nvalues : column to aggregate, optional<br>\nindex: column, Grouper, array, or list of the previousv\ncolumns: column, Grouper, array, or list of the previous<br>\n> \n> aggfunc: function, list of functions, dict, default numpy.mean<br>\n....If list of functions passed, the resulting pivot table will have hierarchical columns whose top level are the function names.<br>\n....If dict is passed, the key is column to aggregate and value is function or list of functions<br>\nfill_value[scalar, default None] : Value to replace missing values with<br>\nmargins[boolean, default False] : Add all row / columns (e.g. for subtotal / grand totals)<br>\ndropna[boolean, default True] : Do not include columns whose entries are all NaN<br>\nmargins_name[string, default ‘All’] : Name of the row / column that will contain the totals when margins is True.<br>\n> \n> Returns: DataFrame","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# this is the same table we build in the previous cell but using pivot table\navocado.pivot_table(index=[\"year\",\"type\"], aggfunc=[min,max,np.mean,np.median], values=\"AveragePrice\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"Explicit-indexes\"></a>\n# Explicit indexes\nIndexes make subsetting simpler using .loc and .iloc","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Setting column as the index","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"regionIndex = avocado.set_index([\"region\"])\nregionIndex","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Insted of doing this\navocado[avocado[\"region\"].isin([\"Albany\", \"WestTexNewMexico\"])]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# we can simply do\nregionIndex.loc[[\"Albany\", \"WestTexNewMexico\"]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"Visualizing-your-data\"></a>\n# Visualizing your data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Histograms\nuse the function .hist()","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"avocado[\"AveragePrice\"].hist(bins=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Bar plots","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"regionFilter = avocado.groupby(\"region\")[\"AveragePrice\"].mean().head(10)\nregionFilter","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"regionFilter.plot(kind = \"bar\",rot=45,title=\"Average price in 10 regions\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Scatter plot","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"avocado.plot(x=\"AveragePrice\", y=\"Total Volume\", kind=\"scatter\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"Arithmetic-with-Series-DataFrames\"></a>\n# Arithmetic with Series & DataFrames\n\nYou can use arithmetic operators directly on series but sometimes you need more control while performing these operations, here is where these explicit arithmetic functions come into the picture\n\nAdd/Subtract function (just replece add with sub)\n```\nSyntax: Series.add(other, level=None, fill_value=None, axis=0)\n\nParameters:\nother: other series or list type to be added into caller series\nfill_value: Value to be replaced by NaN in series/list before adding\nlevel: integer value of level in case of multi index\n\nReturn type: Caller series with added values\n```\n\nMultiplication function\n```\nSyntax: Series.mul(other, level=None, fill_value=None, axis=0)\n\nParameters:\nother: other series or list type to be added into caller series\nfill_value: Value to be replaced by NaN in series/list before adding\nlevel: integer value of level in case of multi index\n\nReturn type: Caller series with added values\n```\n\nDivision function\n```\nSyntax: Series.div(other, level=None, fill_value=None, axis=0)\n\nParameters:\nother: other series or list type to be divided by the caller series\nfill_value: Value to be replaced by NaN in series/list before division\nlevel: integer value of level in case of multi index\n\nReturn type: Caller series with divided values\n```","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# subtract AveragePrice with AveragePrice :P\n# Dah its 0\navocado[\"AveragePrice\"].sub(avocado[\"AveragePrice\"]) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"Merge-DataFrames\"></a>\n# Merge DataFrames\n\nSyntax:\n> DataFrame.merge(self, right, how='inner', on=None, left_on=None, right_on=None, left_index=False, right_index=False, sort=False, suffixes=('_x', '_y'), copy=True, indicator=False, validate=None) → 'DataFrame'[source]¶\nMerge DataFrame or named Series objects with a database-style join.\n\nThe join is done on columns or indexes. If joining columns on columns, the DataFrame indexes will be ignored. Otherwise if joining indexes on indexes or indexes on a column or columns, the index will be passed on.\n\nParameters\nright: DataFrame or named Series\nObject to merge with.\n\nhow{‘left’, ‘right’, ‘outer’, ‘inner’}, default ‘inner’\n\non: label or list\nColumn or index level names to join on. These must be found in both DataFrames. If on is None and not merging on indexes then this defaults to the intersection of the columns in both DataFrames.\n\nleft_on: label or list, or array-like\nColumn or index level names to join on in the left DataFrame. Can also be an array or list of arrays of the length of the left DataFrame. These arrays are treated as if they are columns.\n\nright_on: label or list, or array-like\nColumn or index level names to join on in the right DataFrame. Can also be an array or list of arrays of the length of the right DataFrame. These arrays are treated as if they are columns.\n\nleft_index: bool, default False\nUse the index from the left DataFrame as the join key(s). If it is a MultiIndex, the number of keys in the other DataFrame (either the index or a number of columns) must match the number of levels.\n\nright_index: bool, default False\nUse the index from the right DataFrame as the join key. Same caveats as left_index.\n\nsort: bool, default False\nSort the join keys lexicographically in the result DataFrame. If False, the order of the join keys depends on the join type (how keyword).\n\nsuffixes: tuple of (str, str), default (‘_x’, ‘_y’)\nSuffix to apply to overlapping column names in the left and right side, respectively. To raise an exception on overlapping columns use (False, False).","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Join\n> DataFrame.merge(self, right, how='inner', on=None, left_on=None, right_on=None, left_index=False, right_index=False, sort=False, suffixes=('_x', '_y'), copy=True, indicator=False, validate=None) → 'DataFrame'[source]¶\nMerge DataFrame or named Series objects with a database-style join.\n\nThe join is done on columns or indexes. If joining columns on columns, the DataFrame indexes will be ignored. Otherwise if joining indexes on indexes or indexes on a column or columns, the index will be passed on.\n\nParameters\nrightDataFrame or named Series\nObject to merge with.\n\nhow{‘left’, ‘right’, ‘outer’, ‘inner’}, default ‘inner’\non: label or list\nColumn or index level names to join on. These must be found in both DataFrames. If on is None and not merging on indexes then this defaults to the intersection of the columns in both DataFrames.\n\nleft_on: label or list, or array-like\nColumn or index level names to join on in the left DataFrame. Can also be an array or list of arrays of the length of the left DataFrame. These arrays are treated as if they are columns.\n\nright_on: label or list, or array-like\nColumn or index level names to join on in the right DataFrame. Can also be an array or list of arrays of the length of the right DataFrame. These arrays are treated as if they are columns.\n\nleft_index: bool, default False\nUse the index from the left DataFrame as the join key(s). If it is a MultiIndex, the number of keys in the other DataFrame (either the index or a number of columns) must match the number of levels.\n\nright_index: bool, default False\nUse the index from the right DataFrame as the join key. Same caveats as left_index.\n\nsort: bool, default False\nSort the join keys lexicographically in the result DataFrame. If False, the order of the join keys depends on the join type (how keyword).\n\nsuffixes: tuple of (str, str), default (‘_x’, ‘_y’)\nSuffix to apply to overlapping column names in the left and right side, respectively. To raise an exception on overlapping columns use (False, False).","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id=\"What-next\"></a>\n# What next?\n\nTry to use your skills on some other dataset<br>\n\nHave a look at my analysis of some other datasets :P\n* [Android App Market on Google Play](https://www.kaggle.com/mohammedmurtuzalabib/android-app-market-on-google-play-analysis)\n* [MNIST Ensemble of 5 CNNS to get 0.99742 score!!](https://www.kaggle.com/mohammedmurtuzalabib/mnist-ensemble-of-5-cnns-0-99742)\n* [Titanic Survival](https://www.kaggle.com/mohammedmurtuzalabib/titanic-survival-analysis)\n\nPlease upvote if you find it helpful :D","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"More updates will come soon, please wait :)","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}