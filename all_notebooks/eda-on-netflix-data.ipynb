{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"#import all neccesary libraries\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport matplotlib\nfrom scipy.stats import norm\nimport numpy as np\n%config Completer.use_jedi = False      #active autocomplete in jupyter","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploring dataset at high level"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Load the data and visualizate it at high level\nnetflix_data=pd.read_csv('../input/netflix-shows/netflix_titles.csv')\nnetflix_data=netflix_data[netflix_data['type']=='Movie']\nnetflix_data.head(2)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"netflix_data.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Describing all the variables within the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"#As all variables are objetcs, let's keep exploring that at a high level\nnetflix_data.describe(include='object')\n#We can already appreciate some inconsistencies within the dataset that may require some treatment depending on the typ\n#of analysis that we want to perform.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **We can already appreciate some inconsistencies within the dataset that may require some treatment depending on the  type of analysis that we want to perform.**\n### **One of the things that i noticed is that liste_in column contains several movies subjetcs, let's split that in a few extra columns to perform some analysis.**"},{"metadata":{},"cell_type":"markdown","source":"### **Preparing extra columns for further analysis and visualizations**"},{"metadata":{},"cell_type":"markdown","source":"#### Creating 3 extra columns from listed_in as it contains several subjects.\n#### Then, those columns are append as rows for the dataset, so each id now has 4 observations."},{"metadata":{"trusted":true},"cell_type":"code","source":"#want to know maximum of listed in items to split columns\ndata=netflix_data['listed_in'].str.count(',')\nmax(data)\n#there are max(data)+1 total items\nnetflix_data2=netflix_data.copy()\nnetflix_data2[['1st_listed','2nd_listed','3rd_listed']]=netflix_data['listed_in'].str.split(\",\",expand=True)\n#df_test=netflix_data.copy()\ncol_list=['1st_listed','2nd_listed','3rd_listed']\nnum_columns=len(col_list)\nnew_df=netflix_data2.drop(col_list,axis=1)\nnew_df=new_df.drop('description',axis=1)\nfor t in range(0,len(netflix_data)):\n                       for k in range(1,len(col_list)+1):\n                            new_row=netflix_data2.iloc[t:t+1,:len(netflix_data2.columns)-k+1:len(netflix_data2.columns)-k]\n                            new_row_info=new_df.iloc[t:t+1,:].values.tolist()[0]\n                            new_item=new_row.values.tolist()[0]\n                            new_row_info.append(new_item[-1])\n                            del(new_row_info[-2])\n                            row_fixed={new_df.columns.values[i]:new_row_info[i] for i in range(0,len(new_row_info))}\n                            new_df=new_df.append(row_fixed,ignore_index=True)\n                            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df[new_df['show_id']=='s2'].head(4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploring the dataset through visualizations"},{"metadata":{"trusted":true},"cell_type":"code","source":"movies_per_year=netflix_data['release_year'].value_counts().reset_index()\nmovies_per_year.columns.values[0]='Year'\nmovies_per_year.columns.values[1]='Count'\nplt.figure(figsize=[20,8])\nmovies_per_year2=movies_per_year[movies_per_year['Year']<2019].copy()\nmovies_per_year2.sort_values(by='Year',inplace=True)\nsns.barplot(data=movies_per_year2,x='Year',y='Count')\nplt.title('Movies produce by year',fontsize=16)\nplt.xlabel('Year')\nplt.ylabel('Movies_Per_Year')\nplt.xticks(rotation=90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **As we can see, movies produce by year has been growing exponentially**"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"new_df_nonull=new_df[(new_df['listed_in'] !=\"\")& (new_df['type']=='Movie')].iloc[5377:,:].copy()                \nmoviestype_by_year=new_df_nonull[['listed_in','release_year']].copy()\nmoviestype_by_year['Counts'] = np.zeros(len(moviestype_by_year))\nmoviestype_by_year['listed_in']=moviestype_by_year['listed_in'].str.strip()\nmoviestype_by_year2=moviestype_by_year.groupby(['listed_in','release_year']).count().reset_index()\nhex_colors=['#C1E1A7','#F9C1BD','#06ABC6','#622D24','#ABB5CD','#057129','#003366','#DDDDDD','#000000','#5B9BD5','#7030A0','#A2AE02','#00B050','#FFFF99','#FF3300','#FF66FF','#800000','#FF9900','#9900CC','#66FFFF','#FFFF00','#00FF00','#3366CC','#FFCCFF','#CC0066','#5F5F5F','#66FFCC','#B2B2B2','#0D8571','#FF5D5D','#B8ADF9','#F4DB9E','#D88C26','#0000CC','#D490FA',]\nmoviestype_by_year3=moviestype_by_year2[~moviestype_by_year2['listed_in'].isnull()]\nmoviestype_by_year3=moviestype_by_year3[(moviestype_by_year3['release_year']<=2018)]\nplt.figure(figsize=[14,14])\n\nsummary=moviestype_by_year3[~moviestype_by_year3['listed_in'].str.contains(\"TV|Docu\")].groupby('listed_in')['Counts'].sum().reset_index().sort_values('Counts',ascending=False).head()\nsummary.set_index('listed_in',inplace=True)\nsummary\nsns.lineplot(x='release_year',y='Counts',hue='listed_in',\n             data=moviestype_by_year3[~moviestype_by_year3['listed_in'].str.contains(\"TV|Docu\")],\n                                      palette=sns.set_palette(sns.color_palette(hex_colors[0:21]))\n            ,dashes=False)\nplt.table(cellText=summary.values,colWidths = [0.05]*len(summary.columns),\n          rowLabels=summary.index,\n          colLabels=summary.columns,\n          cellLoc = 'center', rowLoc = 'left',\n          loc='upper center',\n          bbox=[1.15 ,0.34, 0.1, 0.2])\nplt.grid(False)          \nplt.title('Movies per year by Movie-Type',fontsize=16)\nplt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.xticks(rotation=90)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"country2=netflix_data.dropna()\ncountry2=country2[~country2['country'].str.contains(\",\")]\nx=country2['country'].value_counts().reset_index()\ntitles=['country','Counts']\nx.columns.values[1]=titles[1]\nx.columns.values[0]=titles[0]\nplt.figure(figsize=[14,10])\nsns.barplot(x='country',y='Counts',data=x.sort_values(by='Counts',ascending=True),orientation=\"vertical\")\nplt.xticks(rotation=90)\nplt.title('Movies by Country',fontsize=16)\nplt.grid(False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **It's not a surprise for no one that USA is the one that has produced more within, almost duplicating the second highest producer, which is India.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"collab=netflix_data.dropna()\ncollab=collab[collab['type']=='Movie']\ncollaborations=collab[collab['country'].str.contains(\",\")]\ncolnames=['coll_'+str(i) for i in range(0,8)]\ncollaborations[colnames]=collaborations['country'].str.split(\",\",expand=True)\nx2=collaborations.groupby(colnames[0], as_index=False)[colnames[0]].size()\nfor i in range(1,len(colnames)):\n    to_append=collaborations.groupby(colnames[i], as_index=False)[colnames[i]].size()\n    to_append.columns.values[0]='coll_0'\n    x2=x2.append(to_append)\n\nplt.figure(figsize=[30,16])\nx2['coll_0']=x2['coll_0'].str.strip()\nx3=x2.groupby('coll_0', as_index=False)['size'].sum().sort_values('size',ascending=False)\nplt.xticks(rotation=90)\nplt.xlabel('Country')\nplt.title('Movies collaboration per country',fontsize=22)\nsns.barplot(x='coll_0',y='size',data=x3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Also USA is the country that has produced more movies in collaboration with other countries, followed by UK.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"netflix_data[['time_duration','mins']]=netflix_data['duration'].str.split(\" \",expand=True)\nnetflix_data.drop(columns='mins',inplace=True)\nnetflix_data = netflix_data.astype({\"time_duration\": int})\nplt.figure(figsize=[10,5])\nmean,std=norm.fit(netflix_data['time_duration'].dropna())\nsns.histplot(x='time_duration',data=netflix_data)\nplt.axvline(x=mean, color='r', linestyle='-')\nplt.title('Distribution of movie duration, average is'+ ' ' + 'mean=%.1f,std=%.1f' %(mean,std))\nplt.grid(False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **In average a movie duration is about 100 mins, plot look kind of a normal distribution so we have almost all data points within 2 standard deviations from the mean, excluding some outliers mainly on the right side of the plot.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(5, 3, figsize=(30, 20), sharey=False)\nfig.suptitle('Movie duration distribution by rating', fontsize=30)\ntotal_it=0\nfor i in range(0,5):\n    for k in range(0,3):\n        mean,std=norm.fit(netflix_data['time_duration'][netflix_data['rating']==netflix_data['rating'].unique()[total_it]].dropna())\n        sns.histplot(ax=axes[i][k],x='time_duration',\n                     data=netflix_data[netflix_data['rating']==netflix_data['rating'].unique()[total_it]],\n                     color=hex_colors[(i+2)*(k+1)])\n        axes[i][k].axvline(x=mean, color='r', linestyle='-')\n        axes[i][k].set_title('Distribution of rating type:'+str(netflix_data['rating'].unique()[total_it])+' '+ 'mean=%.1f,std=%.1f' %(mean,std),fontsize=16)\n        total_it+=1\n    fig.tight_layout(pad=3.0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **From the plots we could say that in average the longer movies are the one reltade to type: **PG-13**\n\n### **While the ones with highest average distance between each dot and the mean (variance) are  **NC-17******"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}