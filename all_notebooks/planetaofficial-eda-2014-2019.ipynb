{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Background\n\n**Background:**\n>**Bulgarian pop-folk** (hereinafter referred to as **chalga**) is a dance genre, stemming from ethno-pop, with strong hints of Oriental rhythms and instrumentals.  Chalga is one of many branches of Balkan folk throughout the peninsula (turbofolk in Serbia, manele in Romania etc.) After the fall of communism in 1989 in Central and Eastern Europe, chalga rapidly found place in everyday life. <br>\n\n>Chalga relies on provocativity, and tracks commonly contain sexually explicit lyrics. Because of this, it causes much controversy in society and there is sparse scientific work in the field. Nevertheless, chalga becomes an increasingly popular musical style. As such, we believe it must be subject to development. Finding its 'evolution' constitutes the main scientific motivation behind this study.\n\n**This work serves the purpose of providing a general Exploratory Data Analysis (EDA) of the [Bulgarian popfolk songs](https://www.kaggle.com/astronasko/payner) dataset.**\n\n## Preliminary\nThe main visualisation tools in the present notebook are ``matplotlib`` and ``seaborn``. Please note that you may have to install the ``transliterate`` package manually.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"!pip install transliterate\n\n# Including main libraries\nimport numpy as np\nimport pandas as pd\nimport scipy.stats as stats\nimport matplotlib.pyplot as plt\nimport matplotlib.colors\nfrom matplotlib.ticker import AutoMinorLocator\nimport seaborn as sns\nfrom transliterate import translit\nimport datetime as dt\n\ndef shorten_name(name):\n    '''Shortens the artist name for visualisation. Keeps the artist's first name unchanged.'''\n    # Splits the input string in words\n    name_count = len(name.split())\n    \n    if (name_count==1 or name==\"Desi Slava\"):\n        return name\n    \n    # Keeps the first two names only\n    forename, surname = name.split()[:2]\n    #  Abbreviates the surname\n    shortened_name = \"{0:} {1:}.\".format(forename, surname[0])\n    return shortened_name\n    \ndef top_feature_songs(data, n, feature):\n    '''Returns the first n songs, sorted by the feature in question.'''\n    columns = columns = ['artist_1','artist_2','artist_3','track_name', feature]\n    \n    out = data.nlargest(n, columns=feature,keep='all')[columns].style.hide_index()\n    \n    display(out)\n\n# Load the entire dataset in data\ndata = pd.read_csv(\"/kaggle/input/payner/payner.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Pre-processing\nThe pre-processing of this EDA consists in:\n- **Taking into account the year of release only**, as tracks are subject to periodic tendencies per calendar year (e.g. more upbeat songs during summer). In this analysis, songs do not fall to be assessed in terms in higher temporal resolution than a year.\n- **Disregarding Spotify popularity**, as tracks are uploaded at different times, and this may bias towards older songs.\n- **Disregarding instrumentalness** (whether a track contains no vocals), as all tracks have vocal content.\n- **Disregarding liveness** (confidence measure of live audience presence), as all tracks have been assumed to be recorded in a studio.\n- **Disregarding mode, key and time signature** because of my lack of technical competence in the field.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Get year of release\ndata['year'] = data.datetime.apply(lambda x: x[0:4]).astype(int)\n\n# Disregard aforementioned columns\ndata = data.drop(\n    columns=[\n        'track_id',\n        'popularity',\n        'mode',\n        'key',\n        'time_signature',\n        'instrumentalness',\n        'liveness',\n        'datetime'\n    ])\n\n# Reorder remaining columns\nnew_cols = ['track_name', 'year', 'artist_1', 'artist_2', 'artist_3',\n            'danceability', 'energy', 'loudness', 'speechiness', 'acousticness',\n            'valence', 'tempo', 'duration']\n\ndata = data[new_cols]\n\n#Shorten artist names\ndata.artist_1 = data.artist_1.apply(shorten_name)\ndata.artist_2 = data.artist_2.apply(shorten_name)\ndata.artist_3 = data.artist_3.apply(shorten_name)\n\n# Transform duration in minutes\ndata.duration = data.duration.apply(lambda x: x/1000/60)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Artist-specific statistics\n\n### Artists with most resolved tracks.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"first_second_third = pd.concat([data.artist_1,data.artist_2,data.artist_3])\n\ndata_artists = pd.DataFrame({\n    'artist_1': data.artist_1.value_counts(dropna=False),\n    'artist_2': data.artist_2.value_counts(dropna=False),\n    'artist_3': data.artist_3.value_counts(dropna=False)\n}).fillna(0)\n\nkey = first_second_third.value_counts().index[1:16].tolist()\n\ndata_artists.reindex(key).plot(\n    kind='bar',\n    stacked=True,\n    figsize=(12, 4),\n    color=['gold','darkgray','saddlebrown'],\n    edgecolor=\"black\",\n    linewidth=0.5,\n    zorder=2)\n\nplt.title(\"Most prevalent artists, PlanetaOfficial, 2014-2019\",fontsize=14)\nplt.legend(labels=['First', 'Second', 'Third'], title=\"Order in track\", loc='best')\nplt.grid(axis='y', linewidth=0.5, zorder=0)\nplt.xticks(rotation='horizontal', wrap=True)\nplt.ylim(0,30)\nplt.ylabel(\"Track count\")\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Colour coding is added, so to follow what is the distribution of songs by order of mention in the track.\n\n### Artists with most resolved solo tracks.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Artists by solo songs - important for correlation matrices!\n# Get only solo tracks\ndata_solo = data[(data.artist_2=='None')&(data.artist_3=='None')].drop(columns=['artist_2','artist_3'])\n\n# Get all authors by solo track count\ncount_solo = pd.DataFrame({\n    'solist': data_solo.artist_1.value_counts(dropna=False),\n})\n\n# Get names of first 10 authors by solo track count\nkey_solo = data_solo.artist_1.value_counts().index[0:10].tolist()\n\n# Plot only first 10 authors from all authors\ncount_solo.reindex(key_solo).plot(\n    kind='bar',\n    figsize=(12, 4),\n    color='tab:blue',\n    edgecolor=\"black\",\n    linewidth=0.5,\n    zorder=2)\n\nplt.title(\"Top authors by solo tracks, Planeta Payner, 2014-2019\",fontsize=14)\nplt.legend(labels=['Solo tracks'], loc='best')\nplt.xticks(rotation='horizontal', wrap=True)\nplt.grid(axis='y', linewidth=0.5, zorder=0)\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Solo songs are extremely important for further individual analysis of artists, as they may indicate individual trends and correlations in artists' discography. Naturally, artists with more solo songs will be of greater interest. As an example of the importance of solo tracks, we will further focus on the top three artists: **Dzhena**, **Maria** and **Preslava**.\n\n## Dataset statistics\n> **After random sampling (n=100), it may be inferred that the purity of this dataset is (0.87, 0.97), 95% C.I.**\n\nIn order to minimise noise tracks from the dataset, a certain form of data filtering must be conducted. In this work, the filtering condition is if an artist was mentioned first in at least three tracks. Although it is a rather aggressive method of filtering, this would increase the purity of data. Furthermore, it ensures selecting only 'representative' tracks, and in turn increases the confidence of subsequent findings. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Has this artist got at least 3 tracks in which they are mentioned first?\n# Preparing a boolean mask of the condition\nmask = data.artist_1.map(data.artist_1.value_counts())  >= 3\n# Applying this boolean mask to data\ndata = data[mask]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature analysis\n\n### Danceability\n> Danceability describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity. A value of 0.0 is least danceable and 1.0 is most danceable.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"top_feature_songs(data, n=5, feature='danceability')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The track with highest resolved danceability is ['Yako mi e'](https://www.youtube.com/watch?v=M3m4GMSckgE) by Dzhena (0.883). Tracks ranked second and third are ['Angelat'](https://youtu.be/NkbpLaMF_yo) (0.869) and ['Nyama da te bavya'](https://www.youtube.com/watch?v=XGhkY80Ddg4) (0.864). Two tracks split fourth place with danceability of 0.860: ['Blokiran'](https://youtu.be/IaZ07L2xdRA) and ['Sto nyuansa rozovo'](https://youtu.be/sx8ytImqjiI).\n\n### Energy\n> Energy is a measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale. Perceptual features contributing to this attribute include dynamic range, perceived loudness, timbre, onset rate, and general entropy.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"top_feature_songs(data, n=5, feature='energy')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The track with highest resolved energy is ['Noshtta garmi'](https://youtu.be/D3vBCYwS34Y?t=1) by Galin and Lorena, scoring 0.995! Tracks ranked second and third are both by Roksana: ['Ot gordost da boli'](https://youtu.be/QsKkHFRXdAw), duet with Toni S. (0.993) and ['Selfi'](https://youtu.be/eCaXDlqmYgM) (0.989). Track ranked fourth is Galin's ['Gotina kola'](https://youtu.be/K9iEjkmoR3A?t=1) (0.984). Two songs share the fifth place of 0.982 energy: ['Roka-laka'](https://youtu.be/n9HclKtkV04) and ['Neka da e tayno'](https://youtu.be/pNCdXt1MXps).\n\n### Loudness\n> The overall loudness of a track in decibels (dB). Loudness values are averaged across the entire track and are useful for comparing relative loudness of tracks. Loudness is the quality of a sound that is the primary psychological correlate of physical strength (amplitude).\n\nIt is important to note that the decibel scale is logarithmic, as human hearing responds logarithmically to auditory stimuli by the [Weber-Fechner's law](https://en.wikipedia.org/wiki/Weber%E2%80%93Fechner_law?oldformat=true).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"top_feature_songs(data, n=5, feature='loudness')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The loudest resolved song by PlanetaOfficial in 2012-2019 is ['Noshtta garmi'](https://youtu.be/D3vBCYwS34Y?t=1) by Galin and Lorena. Please note again that the same song scored first in ``energy``. Second in loudness comes Roksana's ['Selfi'](https://youtu.be/eCaXDlqmYgM), which scored third in ``energy``. A good question arises: **Are energy and loudness correlated?**\n\n### Speechiness\n> Speechiness detects the presence of spoken words in a track. The more exclusively speech-like the recording (e.g. talk show, audio book, poetry), the closer to 1.0 the attribute value. Values above 0.66 describe tracks that are probably made entirely of spoken words. Values between 0.33 and 0.66 describe tracks that may contain both music and speech, either in sections or layered, including such cases as rap music. Values below 0.33 most likely represent music and other non-speech-like tracks.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"top_feature_songs(data, n=5, feature='speechiness')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The song with most speech detected is ['Chuzda staya'](https://youtu.be/OUyolqrl-OM), scoring 32.8 per cent. This comes to no surprise, as main artist is Ustata, a rapper associated with the Payner Ltd record label. Nevertheless, no track exceeds the threshold of 33 percent, as expected.\n\nIt is also interesting to see that the artist Galin is also well represented in terms of speechiness: ['Vse napred'](https://youtu.be/YafXXQeBnaI) and ['112'](https://youtu.be/gq0QbIHycg4) are ranked second and third among all tracks.\n\n### Acousticness\n> A confidence measure from 0.0 to 1.0 of whether the track is acoustic. 1.0 represents high confidence the track is acoustic. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"top_feature_songs(data, n=5, feature='acousticness')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The track with highest resolved acousticness is Fiki's ['Is This Love'](https://youtu.be/MZSEnQJsRms) (0.811), well above the rest. The runner-up track is ['Spomeni'](https://youtu.be/8_boh8HoIZQ) by Roxana (0.731). Extra Nina's ['Molitva'](https://youtu.be/9kf0Es25zio) (0.689) wins third place in acousticness.\n\n### Valence\n> A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"top_feature_songs(data, n=5, feature='valence')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The Christmas-themed song ['Koledni zhelaniya'](https://youtu.be/5H5bwR1Ly-g) by Tedi A. is the most valent resolved track, scoring 0.970. The second most danceable song, ['Angelat'](https://youtu.be/NkbpLaMF_yo) by Tsvetelina Y., is also the second most valent in the dataset (0.969). Two tracks share third place: ['Profesor'](https://youtu.be/NzpdukkDn5U) by Milko K. and ['Umna i krasiva'](https://youtu.be/l44EVvCurak) by Veselin M.\n\n### Tempo\n> The overall estimated tempo of a track in beats per minute (BPM). In musical terminology, tempo is the speed or pace of a given piece and derives directly from the average beat duration.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"top_feature_songs(data, n=5, feature='tempo')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The song wit highest resolved tempo is ['La Vida Amiga'](https://youtu.be/UYN53ZHUxN8) by Avi B., with almost 200 BPM. Interestingly enough, this song does not follow the characteristics of a Bulgarian pop-folk, and in fact, is entirely in Spanish. A worthy oponent is the ['S teb ili s nikoy'](https://youtu.be/AeYnY-aW_m0) duet by Preslava and Fiki (198 BPM), reaching over 17 million views in YouTube.\n\n## Feature correlations\n\n### Global feature correlations","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"f, axes = plt.subplots(1, 2, figsize=(12, 6), sharex=True)\n\nmask = np.triu(np.ones_like(data.drop(columns=['year']).corr(), dtype=np.bool))\n\nax_pearson = sns.heatmap(\n    data.drop(columns=['year']).corr(method='pearson'),\n    mask=mask,\n    vmax=1,\n    vmin=-1,\n    square=True,\n    annot=True,\n    fmt=\".2f\",\n    cbar=False,\n    cmap=\"RdBu_r\",\n    ax=axes[0])\n\nax_pearson.set_title('Pearson',fontsize=14)\n\nax_spearman = sns.heatmap(\n    data.drop(columns=['year']).corr(method='spearman'),\n    mask=mask,\n    vmax=1,\n    vmin=-1,\n    square=True,\n    annot=True,\n    fmt=\".2f\",\n    cbar=False,\n    cmap=\"RdBu_r\",\n    ax=axes[1])\n\nax_spearman.set_title('Spearman',fontsize=14)\n\nplt.tight_layout()\nplt.suptitle(\"Features correlation of tracks, PlanetaOfficial, 2014-2019\", fontsize=18, y=1.10)\nplt.subplots_adjust(hspace = 0.10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The correlation matrix proves to be an incredibly powerful tool. In our case, it hints that the energy-loudness correlation has linear (Pearson) coefficient of 0.68 and monotonous (Spearman) coefficient of 0.63. This is expected, as loudness is an argument in the energy function, according to the Spotify API documentation. Plotting all points on a energy-loudness diagram for confirmation:","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(9, 6))\nplt.title(\"Co-dependency of energy and loudness, PlanetaOfficial, 2014-2019\", fontsize=14, y=1.04)\nplt.xlabel(\"Energy coefficient\")\nplt.ylabel(\"Loudness (dB)\")\nsns.scatterplot(x=\"energy\", y=\"loudness\", data=data, alpha=0.3);\nsns.regplot(x=\"energy\", y=\"loudness\", data=data, scatter=False);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Artist-specific feature correlations\nAlternatively, several individual correlation matrices for each artist may be constructed. **This can highlight specific artist-wise trends throughout solo songs, and allows such trends to be compared to the global dataset.** Here, outliers further than 3$\\sigma$ were discarded in correlation calculations. Let us return back to **Dzhena**, **Maria** and **Preslava**, as discussed.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"f, axes = plt.subplots(3, 2, figsize=(12, 14), sharex=True)\nmask = np.triu(np.ones_like(data_solo.corr(), dtype=np.bool))\n\nfor i in range(3):\n    \n    artist = key_solo[i]\n    \n    data_artist = data_solo.loc[data_solo.artist_1 == artist].drop(columns=['track_name','year', 'artist_1'])\n    data_artist = data_artist[(np.abs(stats.zscore(data_artist)) < 3).all(axis=1)]\n    \n    mask = np.triu(np.ones_like(data_artist.corr(), dtype=np.bool))\n    # Pearson\n    sns.heatmap(\n        data=data_artist.corr(method='pearson'),\n        mask=mask,\n        vmax=1,\n        vmin=-1,\n        ax=axes[i, 0],\n        square=True,\n        annot=True,\n        fmt=\".2f\",\n        cbar=False,\n        cmap=\"RdBu_r\"\n    )\n    # Spearman\n    sns.heatmap(\n        data=data_artist.corr(method='spearman'),\n        mask=mask,\n        vmax=1,\n        vmin=-1,\n        ax=axes[i, 1],\n        square=True,\n        annot=True,\n        fmt=\".2f\",\n        cbar=False,\n        cmap=\"RdBu_r\"\n    )\n    # Left-hand-side labels\n    pop_size = count_solo.solist[i]\n    sam_size = len(data_artist)\n    \n    axes[i, 0].set_ylabel(\n        '{0:}, n={1:}\\n({2:} solo tracks)'.format(artist, sam_size, pop_size),\n        fontsize=14,\n        rotation=0,\n        labelpad=80,\n        va='center',\n        linespacing=1.4\n        \n    )\n    \n    axes[i,0].set_title('Pearson', fontsize=14)\n    axes[i,1].set_title('Spearman', fontsize=14)\n\nplt.suptitle(\"Features correlation of artists, PlanetaOfficial, 2014-2019\", fontsize=18, y=1.04)\nplt.subplots_adjust(hspace = 0.15)\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This set of 6 correlation matrices provides a wealth of information, if one is interested in artist-specific trends in discography. **Suppose we compare the **duration-speechiness Pearson correlation coefficient of **Dzhena (-0.45)** with that of **Preslava (0.50)**. Let us plot their solo tracks on a duration-speechiness diagram, against the whole PlanetaOfficial collection.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"f, axes = plt.subplots(1, 2, figsize=(12, 4), sharey=True, sharex=True)\n\nplt.suptitle(\"Tendencies of artists, PlanetaOfficial, 2014-2019\", fontsize=16, y=1.05)\nplt.xlim(2.5, 5)\nplt.ylim(0, 0.3)\nplt.xticks(\n    ticks = np.linspace(2.5,5,6),\n    labels = ['2:30','3:00','3:30','4:00','4:30','5:00'])\n\n# DZHENA\naxes[0].set_title(\"Solo tracks by Dzhena\")\n# All dots\nsns.scatterplot(\n    x=\"duration\",\n    y=\"speechiness\",\n    data=data,\n    alpha=0.15,\n    color='gray',\n    ax=axes[0])\n# Dzhena scatter\nsns.scatterplot(\n    x=\"duration\",\n    y=\"speechiness\",\n    data = data_solo[data_solo['artist_1']==\"Dzhena\"],\n    color=\"tab:blue\",\n    ax=axes[0])\n# Dzhena reg\nsns.regplot(\n    x=\"duration\",\n    y=\"speechiness\",\n    data=data_solo[data_solo['artist_1']==\"Dzhena\"],\n    color=\"tab:blue\",\n    scatter=False,\n    ax=axes[0])\n\n# PRESLAVA\naxes[1].set_title(\"Solo tracks by Preslava\")\n# All dots\nsns.scatterplot(\n    x=\"duration\",\n    y=\"speechiness\",\n    data=data,\n    alpha=0.15,\n    color='gray',\n    ax=axes[1])\n# Scatter\nsns.scatterplot(\n    x=\"duration\",\n    y=\"speechiness\",\n    data = data_solo[data_solo['artist_1']==\"Preslava\"],\n    color=\"tab:orange\",\n    ax=axes[1])\n# Reg\nsns.regplot(\n    x=\"duration\",\n    y=\"speechiness\",\n    data=data_solo[data_solo['artist_1']==\"Preslava\"],\n    color=\"tab:orange\",\n    scatter=False,\n    ax=axes[1]);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It may be deducted that as Dzhena tends to speak proportionally less in her longer songs. On the contrary, Preslava tends to speak proportionally more with the increase of track duration. Please note again - this was inferred just by using the artist-specific correlation matrix, which is clear evidence of its importance in tendency search.\n\n## Change of tracks over time\nThe great question certainly was if tracks are subject to changes over time. For presentation purposes, tracks are binned in three by their year of release; that is, they were split to **'old' (2014-2015), 'medium' (2016-2017) and 'new' (2018-2019) songs.**","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Three-fold binning of data\ndata_old = data[data.year.isin([2014,2015])]\ndata_med = data[data.year.isin([2016,2017])]\ndata_new = data[data.year.isin([2018,2019])]\n\n# Providing axis limits for features\nfeature_limits = {\n    'danceability': (0.4, 0.9),\n    'energy': (0.6, 1),\n    'loudness': (-8, 0),\n    'speechiness': (0, 0.3),\n    'acousticness': (0, 0.3),\n    'liveness': (0, 0.6),\n    'valence': (0.2, 1),\n    'tempo': (50, 250)\n}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Change of track duration over time\nConsider the kernel density estimate (KDE) of tracks by duration in the three categories.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"f, axes = plt.subplots(3, 1, figsize=(8, 8), sharex='all', sharey='all')\n\nbins = np.linspace(2.5,5,31)\n\nrow = 0\nfor data in [data_old, data_med, data_new]:\n\n    ax = sns.distplot(\n    data.duration,\n    norm_hist=True,\n    ax=axes[row],\n    color='tab:blue',\n    bins=bins)\n        \n    ax.grid(axis='y', which='major', color='k', linestyle='-', alpha=0.2, zorder=100)\n    ax.grid(axis='x', which='major', color='k', linestyle='-', alpha=0.2, zorder=100)\n    \n    ax.set_xlim(2.5, 5)\n    ax.set_xticklabels(['2:30','3:00','3:30','4:00','4:30','5:00'])\n    ax.minorticks_on()\n    ax.xaxis.set_minor_locator(AutoMinorLocator(6))\n    \n    ax.set_xlabel(\"Track duration\")\n    ax.set_ylabel(\"KDE\")\n\n    row += 1\n    \n\naxes[0].set_title(r\"2014-2015 $(n=131)$\")\naxes[1].set_title(r\"2016-2017 $(n=122)$\")\naxes[2].set_title(r\"2018-2019 $(n=104)$\")\n\nplt.suptitle(\"Tempo of tracks by PlanetaOfficial, 2014-2019\", fontsize=14, y=1.02)\nplt.subplots_adjust(top=0.99)\nplt.grid(axis='x', linewidth=0.5, zorder=0)\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In 2014 and 2015, a distribution plateau can be observed between 3:30 and 3:50. Since then, the distribution maximum is slowly moving to the leftm as time goes on. In 2018-2019, there is a clear prevalence of songs between 3:30 and 3:35 long. **It can be argued that songs from 2018-2019 are slightly shorter than ones several years ago.**\n\n## Change of features over time\n\nA good way to represent feature changes over time is to draw heatmaps of each feature against duration, for all three time periods. In these heatmaps, regions with more tracks present are redder. In this way, we can view these heatmaps as colour-coded two-dimensional KDE. For completeness, all feature heatmaps are displayed over the three time intervals. Again, outliers further than $3\\sigma$ are disregarded.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"f, axes = plt.subplots(7, 3, figsize=(9, 21),sharey='row', sharex='row')\n\nrow = 0\n\nfor feature in data_old.columns[5:-1]: #['danceability',...'duration']\n    \n    ax_old = sns.kdeplot(\n        data_old['duration'],\n        data_old[feature],\n        shade=True,\n        ax=axes[row,0],\n        shade_lowest=False, \n        cmap=\"YlOrRd\")\n\n    ax_med= sns.kdeplot(\n        data_med['duration'],\n        data_med[feature],\n        shade=True,\n        ax=axes[row,1],\n        shade_lowest=False, \n        cmap=\"YlOrRd\")\n    \n    ax_new = sns.kdeplot(\n        data_new['duration'],\n        data_new[feature],\n        shade=True,\n        ax=axes[row,2],\n        shade_lowest=False, \n        cmap=\"YlOrRd\")\n    \n    ax_old.set_xlim(2.5, 5)\n    ax_old.set_xticklabels(['2:30','3:00','3:30','4:00','4:30','5:00'])\n    \n    ax_old.set_ylim(*feature_limits[feature])\n        \n    axes[0,0].set_title(r\"2014-2015 $(n=131)$\")\n    axes[0,1].set_title(r\"2016-2017 $(n=122)$\")\n    axes[0,2].set_title(r\"2018-2019 $(n=104)$\")\n    \n    row += 1\n\nplt.suptitle(\"Feature heatmaps over time, PlanetaOfficial, 2014-2019\", fontsize=16, y=1.02)\nplt.subplots_adjust(top=0.95)\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In this EDA, the two heatmaps that indicate the most change, are discussed: the **duration-tempo** and **duration-loudness** heatmaps.\n\n### Change of tempo over time","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"f, axes = plt.subplots(1, 3, figsize=(12, 4),sharey='row', sharex=True)\n\nax_old = sns.kdeplot(\n    data_old['duration'],\n    data_old['tempo'],\n    shade=True,\n    ax=axes[0],\n    shade_lowest=False, \n    cmap=\"YlOrRd\")\n\nax_med= sns.kdeplot(\n    data_med['duration'],\n    data_med['tempo'],\n    shade=True,\n    ax=axes[1],\n    shade_lowest=False, \n    cmap=\"YlOrRd\")\n\nax_new = sns.kdeplot(\n    data_new['duration'],\n    data_new['tempo'],\n    shade=True,\n    ax=axes[2],\n    shade_lowest=False, \n    cmap=\"YlOrRd\")\n\nax_old.set_xlim(2.5, 5)\nax_old.set_xticklabels(['2:30','3:00','3:30','4:00','4:30','5:00'])\n\nax_old.set_ylim(*feature_limits['tempo'])\n\naxes[0].set_title(r\"2014-2015 $(n=131)$\")\naxes[1].set_title(r\"2016-2017 $(n=122)$\")\naxes[2].set_title(r\"2018-2019 $(n=104)$\")\n\nplt.suptitle(\"Duration-tempo over time, PlanetaOfficial, 2014-2019\", fontsize=14, y=1.02)\nplt.subplots_adjust(top=0.95)\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Throughout all intervals, it can be seen that most songs are clustered by tempo in two main regions - around 90 BPM (*slow group*) and around 175 BPM (*fast group*). \n\n**During 2014-2015, the slow group dominates in count.** It is interesting to see the core of the slow group is elongated horizontally; this indicates the presence of *long* and *short* tracks that are in the slow group. Later on, the slow group retains dominance, but songs are more centered around the 3:30 mark. **Suddenly, in 2018-2019 the fast group becomes at least as big as the slow group in count! We can deduce that in 2018-2019 PlanetaOfficial relies on more songs in the fast group.** However, their mean tempo is slightly lower (about 160 BPM).\n\n**ThÐµ finding of this duration-tempo trend is the main achievement of this EDA.**\n### Change of loudness over time","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"f, axes = plt.subplots(1, 3, figsize=(12, 4),sharey='row', sharex=True)\n\nax_old = sns.kdeplot(\n    data_old['duration'],\n    data_old['loudness'],\n    shade=True,\n    ax=axes[0],\n    shade_lowest=False, \n    cmap=\"YlOrRd\")\n\nax_med= sns.kdeplot(\n    data_med['duration'],\n    data_med['loudness'],\n    shade=True,\n    ax=axes[1],\n    shade_lowest=False, \n    cmap=\"YlOrRd\")\n\nax_new = sns.kdeplot(\n    data_new['duration'],\n    data_new['loudness'],\n    shade=True,\n    ax=axes[2],\n    shade_lowest=False, \n    cmap=\"YlOrRd\")\n\nax_old.set_xlim(2.5, 5)\nax_old.set_xticklabels(['2:30','3:00','3:30','4:00','4:30','5:00'])\n\nax_old.set_ylim(*feature_limits['loudness'])\n\naxes[0].set_title(r\"2014-2015 $(n=131)$\")\naxes[1].set_title(r\"2016-2017 $(n=122)$\")\naxes[2].set_title(r\"2018-2019 $(n=104)$\")\n\nplt.suptitle(\"Duration-loudness over time, PlanetaOfficial, 2014-2019\", fontsize=14, y=1.02)\nplt.subplots_adjust(top=0.95)\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Another observation is that the distribution of songs by loudness shrinks over time in size and moves downwards. **In other words, tracks are becoming a bit more silent and more normalised.** This is very likely due to the introduction of the [Spotify Normalization](https://artists.spotify.com/faq/mastering-and-loudness#what-is-loudness-normalization-and-why-is-it-used) in later years:\n> Audio files are delivered to Spotify from distributors all over the world and are often mixed/mastered at different volume levels. We want to ensure the best listening experience for users, so we apply Loudness Normalization to create a balance.\n>It also levels the playing field between soft and loud masters. Louder tracks have often been cited as sounding better to listeners, so Loudness Normalization removes any unfair advantage.\n\nThere are indications that loudness may have correlated with duration in 2014-2015, judging by the shape of the core. That is to say, tracks around the 4:00 mark may have been marginally louder than ones around the 3:00 mark, on average.  It is interesting to see that in the intermediate period, 2016-2017, a subset of tracks have moved rightwards and downwards. In 2018-2019, tracks are distributed in a well-defined center.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Conclusion\nThroghout this work, several conclusions could be drawn out:\n* **There is strong correlation between loudness and energy**, likely because energy takes loudness as an argument in Spotify API;\n* **Artists have unique feature correlations in their solo songs**, e.g. Dzhena vs Preslava. This is in favour of the 'Every artist is unique!' idea. Moreover, these artist-specific tendencies in solo songs are recognised as a good opportunity for future machine learning (artist classification);\n* **PlanetaOfficial seems to have three short-term changes in tracks**:\n    1. **Duration of songs was slightly lowered in the 2018-2019,** though still kept to the industrial standard (around 3:30);\n    2. **Songs are grouped in two main groups by tempo: high-tempo (>125 BPM) and low-tempo (<125 BPM). High-tempo songs rose much in count in 2018-2019,** compared to 2014-2017. This gives reason to think such transition was intentional by PlanetaOfficial;\n    3. **Songs became more quiet.** Their overall loudness was normalised, as a consequence of the Spotify Normalization campaign.\n\n**To the best of our knowledge, this is the first quantitative analysis of Bulgarian pop-folk that is publically available.**\n\nPlease note that this is an ongoing project. Feedback and constructive criticism are very much appreciated! :)","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}