{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Imports"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport altair as alt\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n%matplotlib inline\nimport seaborn as sns\nimport os\nimport sklearn.preprocessing\n# type artefacts\nfrom typing import Tuple, List, Union\nfrom pandas import DataFrame\n\n# min-max scaler\nscaler = sklearn.preprocessing.MinMaxScaler()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Utility"},{"metadata":{"trusted":true},"cell_type":"code","source":"# interested in x, y, z and anomaly label\nFEATURES = [\"x\", \"y\", \"z\", \"anomaly\"]\n\ndef get_file_list_from_directory(directory_path: str) -> List[str]:\n    \"\"\"\n    Returns a List of filename paths\n        :param directory_path: string of a path to recursively search through\n        :return: List(filename_paths)\n    \"\"\"\n    datasets = []\n    for subdir, dirs, files in os.walk(directory_path):\n        for file in files:\n            if file.find('.csv') != -1:\n                datasets.append(os.path.join(subdir, file))\n    return datasets\n\n\ndef get_frames_from_file_list(filelist: List[str], columns: Union[List[int], None],\n                              seperator: str = \",\") -> List[\n    DataFrame]:\n    \"\"\"\n    This method returns a List of DataFrames and eventually stores it as pickle file\n        :param filelist: List(paths)\n        :param columns: List(indices)\n        :param name: filename to be, if None the dataframes will not be stored\n        :param seperator: ; or ,\n        :return:\n    \"\"\"\n    dataframes = []\n    scaler = sklearn.preprocessing.MinMaxScaler()\n    for i in range(len(filelist)):\n        if not columns:\n            series = pd.read_csv(filelist[i], header=0, sep=seperator)\n            # comment line below to get first column as a feature\n            series = series.drop(series.columns[0], axis=1)\n        else:\n            # read from column list input\n            series = pd.read_csv(filelist[i], usecols=columns, header=0, sep=seperator)\n        dataframes.append(series)\n    # fit features for all dataframes\n    dataframes = fit_min_max_frames(dataframes)\n    return dataframes\n\ndef fit_min_max_frames(frames: List[DataFrame]) -> List[DataFrame]:\n    \"\"\"\n    Performs a Min/Max Scaling on a List of DataFrames (between 0, 1)\n        :param frames: List(pandas.DataFrame)\n        :return: List(pandas.DataFrame)\n    \"\"\"\n    for i, frame in enumerate(frames):\n        for column in frame:\n            if frame[column].dtype == np.float64 or frame[column].dtype == np.int64:\n                scaler.fit(np.array(frame[column]).reshape(-1, 1))\n                frame[column] = scaler.fit_transform(frame[[column]])\n    return frames\n\ndef get_basic_info_from_frames(frames: List[DataFrame]) -> int:\n    \"\"\"\n    Get the sum of all samples in the list of dataframes\n        :param frames: List(pandas.DataFrame)\n        :return: int\n    \"\"\"\n    sum = 0\n    anomalies = 0\n    normal = 0\n    for frames in frames:\n        sum += len(frames)\n        anomalies += frames.anomaly.value_counts()[1]\n        normal += frames.anomaly.value_counts()[0]\n    return sum, anomalies, normal\n\ndef join_frames_from_list(frames: List[DataFrame]) -> DataFrame:\n    \"\"\"\n    Joins a list of dataframes by appending them\n        :param frames: List(pandas.DataFrame)\n        :return: pandas.DataFrame\n    \"\"\"\n    result = pd.concat(frames)\n    assert result is not None\n    return result\n\ndef train_model(model, model_name):\n    \"\"\"\n    Model Training cycle requires sklearn Model as input\n        :param model: sklearn.Model\n        :param model_name: str\n        :return: str\n    \"\"\"\n    print(model_name)\n    accuracy = {}\n    \n    # Fitting model\n    model = model.fit(X_train, y_train)\n    pred = model.predict(X_test)\n    \n    #Model accuracy\n    acc = accuracy_score(y_test, pred)*100\n    accuracy[model_name] = acc\n    print('accuracy_score',acc)\n    print()\n    \n    # Classification Report\n    print('Classification Report')\n    print(classification_report(y_test, pred))\n    return \"Done\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading"},{"metadata":{"trusted":true},"cell_type":"code","source":"# load the file paths\ntrain_paths = get_file_list_from_directory('../input/anomaly-detection-falling-people-events/data/train')\ntest_paths = get_file_list_from_directory('../input/anomaly-detection-falling-people-events/data/test')\n# load the data in pandas\ntrain_frames = get_frames_from_file_list(train_paths, columns=FEATURES)\ntest_frames = get_frames_from_file_list(test_paths, columns=FEATURES)\n# assert loading is done\nassert len(train_frames) == 20\nassert len(test_frames) == 5","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploration"},{"metadata":{"trusted":true},"cell_type":"code","source":"# basic info\ntrain_count, train_anomaly_count, train_normal_count = get_basic_info_from_frames(train_frames)\ntest_count, test_anomaly_count, test_normal_count = get_basic_info_from_frames(test_frames)\n# distribution info\ntrain_normal_dist = round((train_count - train_anomaly_count) / train_count, 3)\ntest_normal_dist = round((test_count - test_anomaly_count) / test_count, 3)\ntrain_anomaly_dist = round(train_anomaly_count / train_count, 3)\ntest_anomaly_dist = round(test_anomaly_count / test_count, 3)\n# output info\nprint(f\"\\n training samples => \\n\\t overall: {train_count}, \\n\\t normal: {train_normal_count}, \\n\\t anomalous: {train_anomaly_count}\")\nprint(f\"\\n training distribution => \\n\\t normal: {train_normal_dist}, \\n\\t anomalous: {train_anomaly_dist}\")\nprint(f\"\\n testing samples => \\n\\t overall: {test_count}, \\n\\t normal: {test_normal_count}, \\n\\t anomalous: {test_anomaly_count}\")\nprint(f\"\\n testing distribution => \\n\\t normal: {test_normal_dist}, \\n\\t anomalous: {test_anomaly_dist}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**choose example frames and explore**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# get the first frame\ntrain_example = train_frames[0]\ntest_example = test_frames[0]\n# output info\nprint(\"TRAINING\\n\")\nprint(train_example.info())\nprint(train_example.describe())\nprint(\"TESTING\\n\")\nprint(test_example.info())\nprint(test_example.describe())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Visualizing**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# configure seaborn\nsns.set(rc={'figure.figsize':(12, 6)})\nsns.set_theme()\nsns.set_style(\"dark\")","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"sns.lineplot(data=train_example).set_title('Training Example Frame')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.lineplot(data=test_example).set_title('Testing Example Frame')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Joining"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = join_frames_from_list(train_frames)\ntest = join_frames_from_list(test_frames)\nprint(\"Training shape: \", train.shape)\nprint(\"Testing shape: \", test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Visualize some random sample**"},{"metadata":{"trusted":true},"cell_type":"code","source":"chart = alt.Chart(train.sample(n=1000)).mark_circle().encode(\n    alt.X(alt.repeat(\"column\"), type='quantitative'),\n    alt.Y(alt.repeat(\"row\"), type='quantitative'),\n    color='anomaly:N'\n).properties(\n    width=150,\n    height=150\n).repeat(\n    row=['x', 'y', 'z'],\n    column=['z', 'y', 'x']\n).interactive()\nchart","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Learning"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Importing Machine Learning Model\nfrom sklearn.ensemble import RandomForestClassifier\nfrom catboost import CatBoostClassifier\nfrom xgboost import XGBClassifier\n\n#statistical Tools\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = train.drop(columns=[\"anomaly\"], axis=1)\ny_train = train[\"anomaly\"]\nX_test = test.drop(columns=[\"anomaly\"], axis=1)\ny_test = test[\"anomaly\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat = CatBoostClassifier(verbose = 0, n_estimators = 1000)\n\ntrain_model(cat, \"Cat Boost\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc = RandomForestClassifier(n_estimators = 1500, n_jobs=-1, max_depth=15, \n                             min_samples_split=5, min_samples_leaf=3)\n\ntrain_model(rfc, 'Random Forest Classifier')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb = XGBClassifier(n_estimators = 1500, nthread  = 4, max_depth = 15, min_child_weight = 5, learning_rate=0.01)\n\ntrain_model(xgb, 'XGBClassifier')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}