{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt \n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A few days ago, I watched a documentary called 'The Pharmacist' and it was a dark but riveting account of how a father (Dan Schneider) lost his son due to addiction and then made it his personal mission to take down pill mills at Lousiana so that young lives do not have to be wrongfully taken. He was at the forefront of combating the nation's devastating opioid epidemic. He inspired me and made me want to have a glimpse into how he saw the opioid epidemic before anyone else did.\n\nIn this exploratory data analysis, my aim is to: \n* Understand the trend behind the opioid-related deaths and the prescriptions dispensed by US retailers averagely acrosss the states\n* Know which state is at of highest risk - also known as, crude rate\n* Understand trend or growth in the amount of prescription dispensed by US retailers from 1999 to 2014\n* Generate and understand the Opioid Prescribing Rate per person across the states\n* Determine how many states are at a high risk of high OPR \n* Generate a heatmap based on the opioid prescribing rate\n\nIt took me some time to find a suitable dataset mainly because of the following reasons:\n* There are a couple of state-only prescription-related data, but it was not easy to find the entire nation's data\n* I managed to find an entire nation's data but it was not available in csv and only available via SPSS, SAS, R etc. which I do not know how to do the convert, nor do I have the tools to open those data source at the moment\n* There was a good data source, however, it was already in Kaggle and I wanted to explore extracting data that is not in Kaggle at the moment. \n\nI found the following dataset from the open source data.world and further cleaned it up so that we can explore and work on some useful analysis from it."},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"# original data \n\ndataset = pd.read_csv(\"../input/opioid-overdose-deaths/Multiple Cause of Death 1999-2014 v1.1.csv\")\ndf = pd.DataFrame(dataset)\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Firstly, I want to drill down to just knowing the states, year, deaths, population, crude rate and prescriptions dispensed by US retailers in that year (millions). "},{"metadata":{"trusted":true},"cell_type":"code","source":"# cleaned up and renamed one of the columns to make it cleaner and readable\nupdated_df = df.rename(columns={\"Prescriptions Dispensed by US Retailers in that year (millions)\": \"Prescriptions (mils)\"})\n\n# drop the columns on confidence intervals \ndf = updated_df.drop(columns=['Crude Rate Lower 95% Confidence Interval','Crude Rate Upper 95% Confidence Interval'])\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In some of the fields, the field only shows 'Surpressed' or 'Unreliable' and having these data might not be very useful to get a descriptive understanding of the trend. Hence, I deleted the rows that mentioned any of the terms. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# delete all rows in Deaths and Crude Rate if it contains 'Suppressed' and 'Unreliable'\ndrop_rows = df[ (df['Deaths'] == 'Suppressed') | (df['Deaths'] == 'Unreliable') | (df['Crude Rate'] == 'Suppressed') | (df['Crude Rate'] == 'Unreliable') ].index\ndf.drop(drop_rows , inplace=True)\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now lets take a look at how the opioid deaths are distributed over this 15 years generally. It gives a broad understanding of the trend in general.\nThe thing behind this data table is that it is non-linear in a sense that it by states and separated into years. To give me an understanding about the general trend of opioid deaths over the 15 years period, I need to group or categorized all the states and sum the values in each columns of Deaths, Population & Prescriptions."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use('seaborn-dark')\n\n# plotting a bar chart that compares opioid deaths by segmenting states over the 15 years period\ndf[['Deaths', 'Population','Crude Rate','Prescriptions (mils)']] = df[['Deaths', 'Population','Crude Rate','Prescriptions (mils)']].apply(pd.to_numeric)\navg_deaths = df.groupby('State')['Deaths','Prescriptions (mils)'].mean().sort_values(by='Deaths', ascending=False)\navg_deaths.head(10) # top 10 states that has the highest average deaths due to opioid","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Scarily from the above, Washington state, unfortunately, took the 9th spot in the top average Opioid-related deaths over the 15 years data in the nation. Note that the interesting findings from this averaged values is how similar the average precriptions of opioids are across many of the states over the 15 years period. I actually tried to average it out manually in the CSV file as I thought it was some error, but in fact, the numbers are correct I think. This made me think whether the data has an issue, or where did the opioid users get their drugs from if the prescriptions distributions are roughly the same across every state. \n\n**Exploration (1) \nI decided to plot a horizontal bar to understand the trend behind the average opioid-related deaths across states in the nation and the prescriptions dispensed by US retailers (in millions) over 15 years. From the bar below, its interesting to see how the average prescriptions are very much similar across the states, but yet the average death rates have a vast difference throughout. **"},{"metadata":{"trusted":true},"cell_type":"code","source":"# plotting the average deaths with states in a horizontal bar chart\nax = avg_deaths.plot(kind = 'barh', figsize=(20,20))\nplt.title('Annual Average Opioid-related Deaths Across States',fontsize = 25, fontweight='bold')\nplt.ylabel('States',fontsize = 18, fontweight='bold')\nplt.xlabel('Average Number of Deaths due to Opioid', fontsize = 18, fontweight='bold')\n\n# display the value of each state's death numbers\n# reference: https://stackoverflow.com/questions/30228069/how-to-display-the-value-of-the-bar-on-each-bar-with-pyplot-barh\nfor i, v in enumerate(avg_deaths['Deaths'].round()):\n    ax.text(v + 3, i - .35, str(v), color='black', fontweight='regular')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"However, although that gives me a perspective across states, it might not paint a full comparative picture because different states have different populations relative to each other and that would also affect how many people in comparison to the large population that might be at risk. For this exploration, we will be using the crude rate data. **A crude rate is the number of new cases (or deaths) occurring in a specified population per year, usually expressed as the number of cases per 100,000 population at risk.  **\n\n**Exploration (2) \n**Using each state's average crude rate data to determine which state is at the highest risk. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# store the dataframe of grouped state vs average crude rates in avg_crude df\navg_crude = df.groupby('State')['Crude Rate'].mean().sort_values(ascending=False)\ncrude_bar = avg_crude.plot(kind = 'bar', figsize=(20,5), legend = True)\n\n# plot the bar chart to show the average crude rate across states  \nplt.title('Average no. of new cases/deaths per 100,000 people in each state in a year',fontsize = 25, fontweight='bold')\nplt.ylabel('No. of deaths/100,000 people',fontsize = 18, fontweight='bold')\nplt.xlabel('States', fontsize = 18, fontweight='bold')\nplt.xticks(rotation=75)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Surprisingly, as you can see above, West Virginia is in fact the highest at risk state, while California, although has the highest number of opioid death numbers, is far behind relative to West Virginia. \n\n**Exploration (3) \n**Understand trend or growth in the amount of prescription dispensed by US retailers from 1999 to 2014.\nThis would give us a glimpse into how the amount of prescription dispensed might have an effect in the death rates in the nation. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# store the dataframe of grouped years vs prescriptions in millions & deaths across states over the years \navg_prescrip = df.groupby('Year')['Deaths','Prescriptions (mils)'].sum().sort_values(by = 'Year', ascending=False)\nprescrip_effect = avg_prescrip.plot(kind = 'line', figsize=(20,10), legend = True, linewidth=10)\n\n# plot the line graph  \nplt.title('No. of Opiate-related Deaths & Prescription (Millions) over 15 years',fontsize = 25, fontweight='bold')\nplt.ylabel('No. of opiate deaths & opiate prescription',fontsize = 18, fontweight='bold')\nplt.xlabel('Year 1994 to 2014', fontsize = 18, fontweight='bold')\nplt.xticks(rotation=75)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Just as the documentary was explaining, the number of opiate-related deaths were very much caused or started by the rise in unnecessary prescription of opiates by doctors and clinics, leading to addiction and abuse of painkillers. \n\n**Exploration (4) \n**Generate and understand the Opioid Prescribing Rate per 100 across the states. This will take into account the population density in the state and how much opiate was prescribed to."},{"metadata":{"trusted":true},"cell_type":"code","source":"# to calculate the Opioid Prescribing Rate per 100, \n# i would need to take the Prescription (in mils) divide by the the population and then divide it by 100\n\n# create a new column that calculates OPR per person\ndf['OPR'] = df['Prescriptions (mils)'] * 1000000 / df['Population']\ndf['OPR'] = df['OPR'].round(decimals=2)\ndf.sort_values(by = 'OPR', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The data above looks like something is amissed California has the highest number of opiate-related death rates but it has the lowest OPR per person. Whereas Wyoming did not leave a mark in the top 5 list of opiate-related deaths but instead has the top OPR rates. At this point, I am wondering if the prescriptions data is amissed (or my calculations are wrong), or is it just simply opiate users in various states, like California, perhaps gotten their opiate from other sources or the environmental context causes increased drug abuse, or the population that has lower death rates do succumb to lower risk of drug abuse even though they may have a high prescription rate of opiates. This really got me thinking hard about reliance to data purely as it might not be wise to simply view prescriptions and opiate abuse correlation. \n\n**Exploration (5) \n**Determine how many states are at a high risk of high OPR "},{"metadata":{"trusted":true},"cell_type":"code","source":"# create opr ranking system\ndef opr_rates(opr):\n    if opr > 300:\n        return \"Too High Prescription\"\n    elif opr < 300 and opr >= 100:\n        return \"High Prescription\"\n    elif opr < 100 and opr >= 50:\n        return \"Moderate Prescription\"\n    elif opr < 50:\n        return \"Low Prescription\"\n    \n# store the dataframe of grouped states vs OPR across states over the years \navg_opr = df.groupby('State')['OPR','Deaths'].mean().sort_values(by = 'State', ascending=False)\navg_opr['OPR'].apply(opr_rates)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# if we visualize the average OPR across different states over the 15 years in a piechart\nplt.title('Nation OPR Ratings',fontsize = 18, fontweight='bold')\nopr_pie = avg_opr['OPR'].apply(opr_rates).value_counts()\nopr_pie.plot(kind='pie',figsize=(10,8))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# to have a more in-depth comparison across the two variables, OPR & opiate-related deaths, we plot a hbar across all the states\n\nopr_effect = avg_opr.plot(kind = 'barh', figsize=(20,10), legend = True, linewidth=20)\n\n# plot the bar chart\nplt.title('OPR vs Opiate-Death Levels Across States',fontsize = 18, fontweight='bold')\nplt.ylabel('States',fontsize = 18, fontweight='bold')\nplt.xlabel('Average Opiate Prescription Per Person & Opiate-related Death Numbers ',fontsize = 18, fontweight='bold')\nplt.xticks(rotation=75)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I am also interested to find out how the crude rate is compared across states and years over a heatmap. \n\n**Exploration (6) \n**Generate a heatmap based on the opioid prescribing rate.\nI thought this would be a good way to sum up the exploratory data analysis! \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# reshaping the table to be a pandas pivot table \nheatmap_data = pd.pivot_table(df, values='OPR', index=['State'], columns=['Year'])\nheatmap_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sb\n# plotting a heatmap based on the pivot table \nfig, ax = plt.subplots(figsize=(20,15))\nsb.heatmap(heatmap_data, cmap=\"BuGn\",linewidths=.5, ax=ax)\n\n# putting titles and labels \nplt.title('OPR Values Across States and Years',fontsize = 18, fontweight='bold')\nplt.ylabel('States',fontsize = 18, fontweight='bold')\nplt.xlabel('Years ',fontsize = 18, fontweight='bold')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Below code is to test exporting the heatmap on the google maps. Just exploring around! "},{"metadata":{"trusted":true},"cell_type":"code","source":"# pip install opencage # also added in the console","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # pip installed geopy and gmplot via the console already\n# import gmplot\n# # For improved table display in the notebook\n# from IPython.display import display\n\n# from kaggle_secrets import UserSecretsClient\n# user_secrets = UserSecretsClient()\n# secret_value_1 = user_secrets.get_secret(\"opencage\") # make sure this matches the Label of your key\n# key1 = secret_value_1\n\n# from opencage.geocoder import OpenCageGeocode\n# geocoder = OpenCageGeocode(key1)\n\n# for i in df['State']:\n#     query = i  \n#     results = geocoder.geocode(query)\n#     lat = str(results[0]['geometry']['lat'])\n#     lng = str(results[0]['geometry']['lng'])\n    \n\n\n# gmap = gmplot.GoogleMapPlotter(34.0522, -118.2437, 10)\n# gmap.draw(\"my_heatmap.html\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}