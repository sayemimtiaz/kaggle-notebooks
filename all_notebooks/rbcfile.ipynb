{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport numpy as np\nimport os\nfrom matplotlib import pyplot as plt\nimport cv2\nimport random\nimport pickle\n\n\nfile_list = []\nclass_list = []\n\nDATADIR = \"../input/mendeleydatabloodsmearanalysis/PBC_dataset_normal_DIB/PBC_dataset_normal_DIB\"\n\n# All the categories you want your neural network to detect\nCATEGORIES = [\"basophil\",\"eosinophil\",\"erythroblast\",\"ig\",\"lymphocyte\",\"monocyte\",\"neutrophil\",\"platelet\"]\n\n# The size of the images that your neural network will use\nIMG_SIZE = 359\n\n# Checking or all images in the data folder\n'''for category in CATEGORIES :\n    path = os.path.join(DATADIR, category)\n    for img in os.listdir(path):\n        img_array = cv2.imread(os.path.join(path, img))'''\n        \n\ntraining_data = []\n\ndef create_training_data():\n    for category in CATEGORIES :\n        path = os.path.join(DATADIR, category)\n        class_num = CATEGORIES.index(category)\n        m = 0\n        print(category)\n        for imagename in os.listdir(path):\n            if m<200:\n                print(os.path.join(path, imagename))\n                final_img = preprocessing_img(cv2.cvtColor(cv2.imread(os.path.join(path, imagename)), cv2.COLOR_BGR2RGB))\n                plt.imshow(return_crop(final_img))\n                plt.show()\n                training_data.append([return_crop(final_img), class_num])\n                m+=1\n                print(m)\n            else:\n                break\n\n            \n\ncreate_training_data()\n\nrandom.shuffle(training_data)\n\nX1 = [] #features\ny1 = [] #labels\n\nfor features, label in training_data:\n\tX1.append(features)\n\ty1.append(label)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X1 = np.array(X1).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n\n# Creating the files containing all the information about your model\npickle_out = open(\"X1.pickle\", \"wb\")\npickle.dump(X1, pickle_out)\npickle_out.close()\n\npickle_out = open(\"y1.pickle\", \"wb\")\npickle.dump(y1, pickle_out)\npickle_out.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_tr, x_te, y_tr, y_te = train_test_split(X1, y1, )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv3D, MaxPooling2D\nimport pickle\nfrom keras.models import model_from_json\nfrom keras.models import load_model\nimport matplotlib.pyplot as plt\n\n# Opening the files about data\n\n#data from threshold preprocessing\nX = pickle.load(open(\"../input/pickled-mendeley/X.pickle\", \"rb\"))\ny = pickle.load(open(\"../input/pickled-mendeley/y.pickle\", \"rb\"))\n\n#data from mask preprocessing \nX1 = pickle.load(open(\"../input/new-data/X1.pickle\", \"rb\"))\ny1 = pickle.load(open(\"../input/new-data/y1.pickle\", \"rb\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport keras\nimport pandas as pd\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, BatchNormalization, Dropout, MaxPool2D, Input, Softmax, Activation, Flatten, \nconcatenate,AveragePooling2D\nfrom keras.models import Model\nfrom keras import optimizers\nimport os\nprint(os.listdir(\"../input\"))\nimport cv2\nimport scipy\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.utils.vis_utils import plot_model\nfrom keras.utils.np_utils import to_categorical\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = np.array(X)\ny = np.array(y)\nxtr, xte, ytr, yte = train_test_split(X, y,test_size = 0.3, shuffle = True)\n\ny_trainHot = to_categorical(ytr, num_classes = 8)\ny_testHot = to_categorical(yte, num_classes = 8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def keras_model(block_num=2):\n    inp = Input(shape=(200,200,3))\n    k = BatchNormalization()(inp)\n    k = Conv2D(32, (7,7), padding=\"same\",activation=\"relu\",strides=(2,2))(k)\n    k = MaxPool2D(pool_size=(3, 3), padding=\"same\",strides=(2,2))(k) \n    k = Conv2D(32, (3,3), padding=\"same\",activation=\"relu\",strides=(1,1))(k)\n    k = MaxPool2D(pool_size=(3, 3), padding=\"same\",strides=(2,2))(k)\n    for j in range(1,block_num+1):\n        out_conv = []\n        for i in [(1,1),(3,3),(5,5),(0,0)]:\n            p = k\n            if i == (1,1):\n                p = Conv2D(32, (1,1), padding=\"same\",activation=\"relu\")(p)\n                out_conv.append(Conv2D(32, (1,1), padding=\"same\",activation=\"relu\")(p))\n            elif i == (0,0):\n                p = MaxPool2D(pool_size=(2, 2), padding=\"same\",strides=(1,1))(p)\n                out_conv.append(Conv2D(32, (1,1), padding=\"same\",activation=\"relu\")(p))\n            else:\n                p = Conv2D(32, (1,1), padding=\"same\",activation=\"relu\")(p)\n                p = Conv2D(32, i, padding=\"same\",activation=\"relu\")(p)\n                out_conv.append(Conv2D(32, i, padding=\"same\",activation=\"relu\")(p))\n        x = concatenate(out_conv, axis = -1)\n        k = x\n    x = MaxPool2D(pool_size=(7, 7), padding=\"same\",strides=(2,2))(x)\n    x = Flatten()(x)\n    y = Dense(8 ,activation=\"softmax\")(x)\n    model = Model(inp, y)\n    opt = optimizers.Adam(lr=0.01,decay=0.0001)\n    model.compile(loss='categorical_crossentropy',\n                  optimizer=\"adam\",\n                  metrics=['accuracy'])\n    return model\nmodel = keras_model(4)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filepath = \"./cells.h5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\ncallbacks_list = [checkpoint]\nhistory = model.fit(xtr,\n         y_trainHot,\n         epochs = 40,\n         batch_size = 32,\n         validation_data = (xte,y_testHot),\n         callbacks = callbacks_list,\n         verbose = 1)\nmodel.save(\"cells.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\n# \"bo\" is for \"blue dot\"\nplt.plot(epochs, loss, label='Training loss')\n# b is for \"solid blue line\"\nplt.plot(epochs, val_loss, label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_dict = history.history\nhistory_dict.keys()\nplt.clf()   # clear figure\nacc_values = history_dict['accuracy']\nval_acc_values = history_dict['val_accuracy']\n\nplt.plot(epochs, acc, label='Training acc')\nplt.plot(epochs, val_acc, label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_weights(filepath)\nfrom keras.preprocessing.image import ImageDataGenerator\ndatagentrain = ImageDataGenerator(featurewise_center=False,\n                samplewise_center=False,\n                featurewise_std_normalization=False,\n                samplewise_std_normalization=False,\n                zca_whitening=False, zca_epsilon=1e-06,\n                rotation_range=5, width_shift_range=0.0,\n                height_shift_range=0.0, brightness_range=None,\n                shear_range=0, zoom_range=0.0,\n                channel_shift_range=0.0, fill_mode='nearest',\n                cval=0.0, horizontal_flip=True, vertical_flip=True,\n                rescale=None, preprocessing_function=None,\n                data_format=None, validation_split=0.0)\ndatagentrain.fit(xtr)\nhistory = model.fit_generator(datagentrain.flow(xtr, y_trainHot, batch_size=32),\n                    steps_per_epoch=64,\n                    epochs=45,\n                    workers=4,\n                    use_multiprocessing=True,validation_data = (xte,y_testHot),\n         callbacks = callbacks_list,)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\n# \"bo\" is for \"blue dot\"\nplt.plot(epochs, loss, label='Training loss')\n# b is for \"solid blue line\"\nplt.plot(epochs, val_loss, label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Accuracy Plot\nhistory_dict = history.history\nhistory_dict.keys()\nplt.clf()   # clear figure\nacc_values = history_dict['accuracy']\nval_acc_values = history_dict['val_accuracy']\n\nplt.plot(epochs, acc, label='Training acc')\nplt.plot(epochs, val_acc, label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict(xte)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"CATEGORIES = [\"basophil\",\"eosinophil\",\"erythroblast\",\"ig\",\"lymphocyte\",\"monocyte\",\"neutrophil\",\"platelet\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig=plt.figure(figsize=(20,5))\ncolumns = 8\nrows = 3\nax = []\n\nfor i in range(columns*rows):\n    img = xte[i-1].copy()\n    ax.append(fig.add_subplot(rows, columns, i+1))\n    ax[-1].set_title(str(CATEGORIES[list(predictions[i-1][:]).index(max(np.array(predictions)[i-1,:]))]))\n    plt.axis('off')\n    plt.imshow(img)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing Functions Explained"},{"metadata":{"trusted":true},"cell_type":"code","source":"import glob\nimport cv2\nimport numpy as np\nimport skimage\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy import ndimage as ndi\nimport time\nfrom skimage import (\n    color, feature, filters, io, measure, morphology, segmentation, util\n)\nimage = cv2.cvtColor(cv2.imread('../input/mendeleydatabloodsmearanalysis/PBC_dataset_normal_DIB/PBC_dataset_normal_DIB/monocyte/MO_103089.jpg'), cv2.COLOR_BGRA2RGB)\nplt.imshow(image)\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_norm_img(a, display = False):\n    img = a.copy()\n    norm_img= cv2.merge((np.divide(img[:,:,0],np.sum(img, axis = 2))*255\n               ,np.divide(img[:,:,1],np.sum(img, axis = 2))*255\n               ,np.divide(img[:,:,2],np.sum(img, axis = 2))*255))\n    norm_img = norm_img.astype(np.uint8)\n    \n    if display:\n        plt.imshow(norm_img)\n        plt.title('Normalised Image')\n        plt.axis('off')\n        plt.show()\n    return norm_img.copy()\n\nnorm_image = get_norm_img(image.copy(), True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def contrast_enhance(img, x = 1, display = False):\n    #-----Converting image to LAB Color model----------------------------------- \n    norm_img = img.copy()\n    try:\n        lab = cv2.cvtColor(norm_img.copy(), cv2.COLOR_RGB2LAB)\n    except:\n        lab = cv2.cvtColor(cv2.cvtColor(norm_img.copy(), cv2.COLOR_GRAY2RGB), cv2.COLOR_RGB2LAB)\n    #-----Splitting the LAB image to different channels-------------------------\n    l, a, b = cv2.split(lab.copy())\n    #-----Applying CLAHE to L-channel-------------------------------------------\n    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n    if(x == 1):\n        cl = clahe.apply(l.copy())\n    else:\n        cl = clahe.apply(a.copy())\n    #-----Merge the CLAHE enhanced L-channel with the a and b channel-----------\n    limg = cv2.merge((cl.copy(),a.copy(),b.copy()))\n    #-----Converting image from LAB Color model to RGB model--------------------\n    final = cv2.cvtColor(limg.copy(), cv2.COLOR_LAB2RGB)\n    if display:\n        res_1 = np.hstack((l,a,b,cl))\n        res_2 = np.hstack((lab,limg,final))\n        plt.figure(figsize=(20,40))\n        plt.axis('off')\n        plt.imshow(res_1)\n        plt.show()\n        plt.figure(figsize=(20,40))\n        plt.axis('off')\n        plt.imshow(res_2)\n        plt.show()\n    return final\n    #_____END_____#\nfinal = contrast_enhance(norm_image.copy(), 1, True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def wbc_rgb_man(img, display = False):\n    final = img.copy()\n    final = cv2.merge((np.add(final[:,:,0], final[:,:,2])//2, final[:,:,1:])).astype(np.uint8)\n    if(display):\n        plt.axis('off')\n        plt.title('rgb manipulated, contrast enhanced, norm image')\n        plt.imshow(final)\n        plt.show()\n    return final\nfinal = wbc_rgb_man(final.copy(), True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"invert_contrast_img = cv2.bitwise_not(final.copy())\nplt.imshow(invert_contrast_img)\nplt.axis('off')\nplt.title('inverted image')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = ['RED','GREEN','BLUE']\nprint(a)\nred_channel_img = invert_contrast_img[:,:,0]\ngreen_channel_img = invert_contrast_img[:,:,1]\nblue_channel_img = invert_contrast_img[:,:,2]\nres = np.hstack((red_channel_img,green_channel_img,blue_channel_img)) #stacking images side-by-side\nplt.figure(figsize=(20,40))\nplt.axis('off')\nplt.imshow(res, 'gray')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_channel_histogram(img_input, display = False):\n    histogram_data = np.array(np.unique(img_input, return_counts=True))\n    indices = list(histogram_data[0])\n    values = list(histogram_data[1])\n    bins = range(256)\n    hist_values = []\n    for i in range(256):\n        if i in indices:\n            hist_values.append(values[indices.index(i)])\n        else:\n            hist_values.append(0)\n    if display:\n        fig = plt.figure()\n        ax = fig.add_axes([0,0,1,1])\n        ax.bar(bins,hist_values)\n        plt.title('COLOR HISTOGRAM')\n        plt.show()\n    return dict({'indices':indices, 'values':values})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_orig = plot_channel_histogram(blue_channel_img.copy(), True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def find_nearest(array, value):\n    array = np.asarray(array)\n    idx = (np.abs(array - value)).argmin()\n    return array[idx]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_thresh(data, display = False):\n    indices = data['indices']\n    values = data['values']\n    avg_px = np.sum(np.multiply(indices, values))//np.sum(values)\n    \n    avg_px = find_nearest(indices, avg_px)\n    UT = np.sum(np.multiply(indices[indices.index(avg_px):],values[indices.index(avg_px):]))//np.sum(values[indices.index(avg_px):])\n    \n    LT = np.sum(np.multiply(indices[0:indices.index(avg_px)+1],values[0:indices.index(avg_px)+1]))//np.sum(values[0:indices.index(avg_px)+1])\n    if display:\n        print('LT = ',LT)\n        print('avg = ',avg_px)\n        print('UT = ',UT)\n    return dict({'avg':avg_px,'UT':UT,'LT':LT})\nthresholds_orig = get_thresh(data_orig.copy(), True) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def foreground_enhancement(channel_img,thresh, n = 1, display = False):\n    avg_px = thresh['avg']\n    UT = thresh['UT']\n    LT = thresh['LT']\n    frgnd_enhanced_1 = channel_img.copy()\n    frgnd_enhanced_2 = channel_img.copy()\n    frgnd_enhanced_3 = channel_img.copy()\n    frgnd_enhanced_1[channel_img>(avg_px+LT)//2] = 0\n    frgnd_enhanced_2[channel_img>avg_px//2] = 0\n    frgnd_enhanced_3[channel_img>(avg_px+UT)//2] = 0\n    for i in range(channel_img.shape[0]):\n        for j in range(channel_img.shape[1]):\n            if channel_img[i,j]<=(avg_px+LT)//2:\n                frgnd_enhanced_1[i,j] = channel_img[i,j]\n            else:\n                frgnd_enhanced_1[i,j] = 0\n            if channel_img[i,j]<=avg_px:\n                frgnd_enhanced_2[i,j] = channel_img[i,j]\n            else:\n                frgnd_enhanced_2[i,j] = 0\n            if channel_img[i,j]<=(avg_px+UT)//2:\n                frgnd_enhanced_3[i,j] = channel_img[i,j]\n            else:\n                frgnd_enhanced_3[i,j] = 0\n    if display:\n        res = np.hstack((frgnd_enhanced_1,frgnd_enhanced_2,frgnd_enhanced_3))\n        plt.imshow(res, 'gray')\n        plt.axis('off')\n        plt.show()\n    if n==1:\n        return frgnd_enhanced_1\n    elif n==2:\n        return frgnd_enhanced_2\n    elif n==3:\n        return frgnd_enhanced_3\nbg_region = foreground_enhancement(blue_channel_img.copy(),thresholds_orig, 1, True)\nplt.imshow(bg_region, 'gray')\nplt.title('selected background region')\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def binarizing_img(enh_reg,n = 1,display = False):\n    gray_img = enh_reg.copy()\n    plt.imshow(gray_img,'gray')\n\n    blur_img = cv2.medianBlur(gray_img.copy(),5)\n\n    ret,th1 = cv2.threshold(blur_img,127,255,cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n    '''th2 = cv2.adaptiveThreshold(blur_img,255,cv2.ADAPTIVE_THRESH_MEAN_C,\\\n                cv2.THRESH_BINARY,11,2)\n    th3 = cv2.adaptiveThreshold(blur_img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n                cv2.THRESH_BINARY,11,2)'''\n\n    images = [blur_img, th1]\n    if display:\n        titles = ['Original Image', 'Global Thresholding (v = 127)']\n        for i in range(2):\n            plt.subplot(2,2,i+1),plt.imshow(images[i],'gray')\n            plt.title(titles[i])\n            plt.xticks([]),plt.yticks([])\n        plt.show()\n    return images[n]\nbg_region_binary = binarizing_img(bg_region.copy(), 1, True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Getting the WBC inner region"},{"metadata":{"trusted":true},"cell_type":"code","source":"def morph_img(gray, n = 1):\n    # noise removal\n    kernel = np.ones((3,3),np.uint8)\n    opening = cv2.morphologyEx(gray.copy(),cv2.MORPH_OPEN,kernel, iterations = 6)\n    # sure background area\n    sure_bg = cv2.dilate(opening,kernel,iterations=8)\n    if n==1:\n        return opening\n    elif n==2:\n        return sure_bg\n#opening = morph_img(bg_region_binary.copy())\n#plt.imshow(opening, 'gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_orig = plot_channel_histogram(green_channel_img.copy(), True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"thresholds_orig = get_thresh(data_orig.copy(), True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fg_region = foreground_enhancement(green_channel_img.copy(),thresholds_orig,1, True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fg_reg_binary = binarizing_img(fg_region.copy())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def filling_holes(morphed_img, display = False):\n    #filling holes\n    des = cv2.bitwise_not(morphed_img.copy())\n    contour,hier = cv2.findContours(des,cv2.RETR_CCOMP,cv2.CHAIN_APPROX_SIMPLE)\n\n    for cnt in contour:\n        cv2.drawContours(des,[cnt],0,255,-1)\n\n    gray = cv2.bitwise_not(des)\n    if display:\n        plt.imshow(np.hstack((morphed_img,des,gray)), 'gray')\n        plt.axis('off')\n        plt.title('Images From the Process')\n        plt.show()\n\n        plt.imshow(gray, 'gray')\n        plt.axis('off')\n        plt.title('Holes Filled')\n        plt.show()\n   \n    return gray","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def draw_contours(image, filled):\n    contours, hierarchy = cv2.findContours(filled.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n    test_img = image.copy()\n    for i in range(len(contours)):\n        color_contours = (0, 0, 0) # green - color for contours\n        # draw ith contour\n        cv2.drawContours(test_img, np.array(contours), i, color_contours, 2, 8, hierarchy)\n    #plt.imshow(test_img)\n    return test_img, contours","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def return_reg_3d(imgr, reg):\n    return_img = imgr.copy()\n    return_img[reg == 0] = 0\n    #plt.imshow(return_img)\n    return return_img\n#return_img = return_reg_3d(image.copy(), bg_region_binary.copy())\n                ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def return_reg_2d(img2, reg):\n    return_img1 = img2.copy()\n    return_img1[reg == 0] = 0\n    plt.imshow(return_img1)\n    return return_img1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_logic_area(main_cell, new_contours):\n    m,n,c = 0,0,0\n    for i in range(np.array(new_contours).shape[0]):\n        if m<np.array(new_contours)[i].shape[0]:\n            m=np.array(new_contours)[i].shape[0]\n            n = i\n            \n    img = main_cell.copy()\n    cv2.drawContours(img, new_contours, n, 255, -1) # Draw filled contour in mask\n    out = np.zeros_like(img) # Extract out the object and place into output image\n    out[img == 255] = img[img == 255]\n    mask = cv2.subtract(out[:,:,0], out[:,:,1])\n    final_cell = main_cell.copy()\n    for i in range(mask.shape[0]):\n        for j in range(mask.shape[1]):\n            if mask[i,j] == 255:\n                final_cell[i,j] = main_cell[i,j]\n            else:\n                final_cell[i,j] = 0\n    return final_cell, mask","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def return_relevant(im1,filled_img):\n    img11 = im1.copy()\n    img11[filled_img == 255] = 0\n    return img11\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filled_img = return_reg_2d(filling_holes(fg_reg_binary.copy()),bg_region_binary.copy())\nplt.imshow(filled_img)\nplt.axis('off')\nplt.show()\nmain_cell = return_reg_3d(image.copy(), bg_region_binary.copy())\nplt.imshow(main_cell)\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"main_cell1 = return_relevant(main_cell.copy(), filled_img.copy())\nplt.imshow(main_cell1)\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = main_cell[:,:,0].copy()\narr = main_cell[:,:,0].copy().reshape(-1)[::-1]\narr[::-1].sort()\nval = int(np.mean(arr[0:10000]))\nfor i in range(main_cell[:,:,0].shape[0]):\n    for j in range(main_cell[:,:,0].shape[1]):\n        if test[i,j] >= val:\n            test[i,j] = 0\nplt.imshow(test)\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_wbc = return_reg_3d(image.copy(), test.copy())\ncontoured_img,contours = draw_contours(final_wbc.copy(), filled_img.copy())\nfinal_cell, mask = get_logic_area(contoured_img, contours)\n\nplt.imshow(np.hstack((final_wbc, contoured_img, final_cell)))\nplt.figure(figsize=(15, 30))\nplt.axis('off')\nplt.show()\n\n\nplt.imshow(final_cell)\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getting_maincell(img_channel, img12, mode = 1,display = False, bg = 1, fg = 1):\n    red_channel_img = img_channel[:,:,0]\n    green_channel_img = img_channel[:,:,1]\n    blue_channel_img = img_channel[:,:,2]\n    if display:\n        a = ['RED','GREEN','BLUE']\n        print(a)\n        res = np.hstack((red_channel_img,green_channel_img,blue_channel_img)) #stacking images side-by-side\n        plt.figure(figsize=(20,40))\n        plt.axis('off')\n        plt.imshow(res, 'gray')\n        plt.show()\n    \n    data_bg = plot_channel_histogram(blue_channel_img.copy())\n    data_fg = plot_channel_histogram(green_channel_img.copy())\n\n    \n    thresholds_bg = get_thresh(data_bg)\n    thresholds_fg = get_thresh(data_fg)\n    \n    \n    bg_region = foreground_enhancement(blue_channel_img.copy(),thresholds_bg, bg)\n    fg_region = foreground_enhancement(green_channel_img.copy(),thresholds_fg,fg)\n    if display:\n        bg_fg = np.hstack((bg_region, fg_region))\n        plt.imshow(bg_fg,'gray')\n        plt.show()\n\n    bg_reg_binary = binarizing_img(bg_region.copy())\n    fg_reg_binary = binarizing_img(fg_region.copy())\n    \n    if display:\n        bg_fg_binary = np.hstack((bg_reg_binary,fg_reg_binary))\n        plt.imshow(bg_fg_binary, 'gray')\n        plt.axis('off')\n        plt.show()\n\n    filled_img = return_reg_2d(filling_holes(fg_reg_binary.copy()),bg_reg_binary.copy())\n    #plt.imshow(filled_img)\n    #plt.show()\n    main_cell = return_reg_3d(img12.copy(), bg_reg_binary.copy())\n    '''plt.imshow(main_cell)\n    plt.axis('off')\n    plt.show()'''\n    if mode == 1:\n        test = main_cell[:,:,0].copy()\n        arr = main_cell[:,:,0].copy().reshape(-1)[::-1]\n        arr[::-1].sort()\n        val = int(np.mean(arr[0:10000]))\n        for i in range(main_cell[:,:,0].shape[0]):\n            for j in range(main_cell[:,:,0].shape[1]):\n                if test[i,j] >= val:\n                    test[i,j] = 0\n    else:\n        final_cell = return_relevant(main_cell.copy(), filled_img.copy())\n        plt.imshow(final_cell)\n        plt.show()\n        return final_cell\n    final_wbc = return_reg_3d(img12.copy(), test.copy())\n    '''contoured_img,contours = draw_contours(final_wbc.copy(), filled_img.copy())\n    final_cell, n_mask = get_logic_area(contoured_img, contours)'''\n    plt.imshow(final_wbc)\n    plt.axis('off')\n    plt.show()\n    return final_wbc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocessing_img(img, mode = 1):\n    norm_img = get_norm_img(img.copy())\n    final = contrast_enhance(norm_img.copy())\n    final = wbc_rgb_man(final.copy())\n    invert_contrast_img = cv2.bitwise_not(final.copy())\n    final_wbc = getting_maincell(invert_contrast_img.copy(), img.copy(), mode, True)\n    return final_wbc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_wbc = preprocessing_img(image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_wbc = preprocessing_img(image, 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_mask(final_wbc, display = False):\n    w_mask = final_wbc.copy()\n    w_mask[final_wbc != [0,0,0]] = 255\n    w_mask = cv2.cvtColor(w_mask, cv2.COLOR_RGB2GRAY)\n    if display:\n        plt.imshow(w_mask)\n        plt.title('WBC MASK')\n        plt.axis('off')\n        plt.show()\n    return w_mask","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def return_crop(final_wbc, mode = 1, display = False):\n    if mode == 1:\n        return final_wbc[0:359,0:359]\n    else:\n        w_mask = get_mask(final_wbc)\n        x,y,w,h = cv2.boundingRect(w_mask.copy())\n        if display:\n            plt.imshow(final_wbc[y:y+200,x:x+200])\n    return final_wbc[y:y+200,x:x+200]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_wbc = preprocessing_img(image, 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"w_mask = get_mask(final_wbc.copy(), True)\nw_mask = cv2.morphologyEx(w_mask, cv2.MORPH_OPEN, cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(7,7)), iterations = 2)\nw_mask = cv2.morphologyEx(w_mask, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(7,7)), iterations = 7)\nplt.imshow(w_mask)\nplt.title('mask after closing')\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x,y,w,h = cv2.boundingRect(w_mask.copy())\nfinal_img = cv2.rectangle(image.copy(), (x-25,y-25),(x+175, y+175), (255,0,0), 3)\nplt.imshow(np.hstack((final_img, cv2.cvtColor(cv2.rectangle(w_mask.copy(), (x-25,y-25),(x+175, y+175), (255,0,0), 3), cv2.COLOR_GRAY2RGB))))\nplt.title('Drawing a bounding box around wbc')\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# RBC COUNTING"},{"metadata":{"trusted":true},"cell_type":"code","source":"[x,y,w,h] = cv2.boundingRect(w_mask.copy())\ncropped_img = image[y:y+3*h//2, x:x+3*w//2].copy()\ncropped_mask = w_mask[y:y+3*h//2, x:x+3*w//2].copy()\nintensity = cropped_img.sum(axis=2)\n#print(intensity)\nintensity_val = np.max(intensity)\n#print(intensity_val)\nprint('THRESHOLD INTENSITY VALUE'+str(intensity_val))\nresult = np.where(intensity == intensity_val)\n#print(result)\nval = cropped_img[result].mean(axis = 0).astype(int)\nprint(val)\nfor i in range(cropped_mask.shape[0]):\n    for j in range(cropped_mask.shape[1]):\n        if cropped_mask[i,j] != 0:\n            cropped_img[i,j,:] = val\nplt.imshow(cropped_img)\nplt.title('after removing non rbc region')\nplt.axis('off')\nplt.show()\ncropped_img[:,:,2] = cv2.GaussianBlur(cropped_img[:,:,2].copy(),(5,5),8)\nplt.imshow(cropped_img)\nplt.title('after applying gaussian blur')\nplt.axis('off')\nplt.show()\nclean_image = image.copy()\nclean_image[y:y+3*h//2, x:x+3*w//2] = cropped_img\nplt.imshow(clean_image)\nplt.title('final clean image')\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"red = contrast_enhance(clean_image.copy(),2, True)\nplt.imshow(red)\nplt.title('contrast enhancement of TYPE 2 applied on clean image')\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = ['RED','GREEN','BLUE']\nprint(a)\nred_invert = cv2.bitwise_not(clean_image.copy())\nred_channel_img = red_invert[:,:,0]\ngreen_channel_img = red_invert[:,:,1]\nblue_channel_img = red_invert[:,:,2]\nres = np.hstack((red_channel_img,green_channel_img,blue_channel_img)) #stacking images side-by-side\nplt.figure(figsize=(20,40))\nplt.axis('off')\nplt.imshow(res, 'gray')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"green_channel_img = cv2.cvtColor(contrast_enhance(green_channel_img.copy()), cv2.COLOR_RGB2GRAY)\nplt.imshow(green_channel_img, 'gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_red = plot_channel_histogram(green_channel_img.copy())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gray = foreground_enhancement(green_channel_img.copy(),get_thresh(data_red), 2)\nplt.imshow(gray, 'gray')\nplt.title('foreground enhancement for rbcs')\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"binary_img = binarizing_img(gray, 1)\nplt.imshow(binary_img, 'gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"binary_img = filling_holes(binary_img.copy())\nplt.imshow(binary_img, 'gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"binary_img = cv2.morphologyEx(binary_img, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(5,5)), iterations = 7)\nplt.imshow(binary_img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from skimage import measure\nlabels = measure.label(cv2.bitwise_not(binary_img),connectivity = 2)\ndistance = ndi.distance_transform_edt(labels.copy())\nlocal_maxi = feature.peak_local_max(distance, indices=False,\n                                    min_distance=10)\nmarkers = measure.label(local_maxi)\nsegmented_cells = segmentation.watershed(-distance, markers, mask=labels, watershed_line = True)\n\nfig, ax = plt.subplots(ncols=2, figsize=(10, 5))\nax[0].imshow(binary_img.copy(), cmap='gray')\nax[0].set_title('Overlapping nuclei')\nax[0].axis('off')\nax[1].imshow(color.label2rgb(segmented_cells, bg_label=0))\nax[1].set_title('Segmented nuclei')\nax[1].axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"props = measure.regionprops(segmented_cells)\nar = 0\nc = 0\nfor prop in props:\n    final_img = cv2.rectangle(final_img, (prop.bbox[1], prop.bbox[0]), (prop.bbox[3],prop.bbox[2]), (0,255,0), 3) \n    c+=1\nprint('RBC COUNT: '+str(c))\nplt.imshow(final_img)\nplt.title('Labeled RBCs')\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**END OF RBC COUNTING**"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}