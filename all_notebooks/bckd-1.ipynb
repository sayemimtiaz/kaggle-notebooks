{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np\nfrom math import sqrt as s\nimport pandas as pd\nimport matplotlib as ml\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\n\n# Sklearn libraries\nfrom sklearn.model_selection import train_test_split,GridSearchCV,cross_val_score\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LinearRegression,Lasso\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.preprocessing import StandardScaler,PolynomialFeatures,LabelEncoder\nimport statsmodels.api as sm\nfrom sklearn.metrics import r2_score,mean_squared_error\n\n# Serializing\nimport pickle as pkl\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/quikr_car - quikr_car.csv')\nprint(\"Data shape : \",data.shape)\nprint(\"\\nInformation :\")\nprint(data.info())\nprint(\"\\nDescription :\")\nprint(data.describe(),\"\\n\")\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature Engineering 1 : Company names","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# data['company_new'] = np.nan\nnames,models = list(data.name.values),list(data.company.values)\nmodel_types = list(data.company.unique())\nerronous = ['I','selling','URJENT','Used','Sale','very','i','2012','7','9','well','all','scratch','urgent','sell','Any',7,9,'']\n# lower = list(map(lambda x : x.lower(), models))\nfiltered = list(map(lambda x : x.lower(),list(filter(lambda y : y not in erronous,model_types))))\nsplt,models_new = [],[]\nfor entry in names:\n    splt.append(entry.split())\nflag = 0\nfor i in range(len(splt)):\n    if models[i] in erronous:\n        for word in splt[i]:\n            if word.lower() in filtered or word in filtered:\n                models_new.append(word)\n                break\n            else:\n                flag = flag + 1\n                continue\n        if flag == len(splt[i]):\n            models_new.append('BrandX')\n    else:\n        models_new.append(models[i])\nfor _ in range(6):\n    item = filtered[np.random.randint(0,len(filtered))]\n    models_new.append(item)\n\n'''print(len(filtered))\nprint(len(models_new))'''\n\ndata['company_new'] = models_new\ndata.drop(columns=['company'],axis=1,inplace=True)\ndata","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature Engineering 2 : Year of Purchase","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pattern = r'[1-3][0-9]{3}'\nyrs = list(data.year.values)\nnumbers_no = list(filter(lambda n : len(re.findall(pattern, n))==0, yrs))\nnumbers_yes = list(filter(lambda n : re.findall(pattern, n), yrs))\nfor i in range(len(yrs)):\n    if yrs[i] in numbers_no:\n        yrs[i] = int(numbers_yes[np.random.randint(0,len(numbers_yes))])\n    else:\n        yrs[i] = int(yrs[i])\n\ndata['year_new'] = yrs\ndata.drop(columns=['year'],axis=1,inplace=True)\ndata","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature Engineering 3 : Price and Fuel type","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Price\nprice_actual = list(filter(lambda s : len(s.split())==1, list(data.Price.values)))\nprice_no = list(filter(lambda s : len(s.split())!=1, list(data.Price.values)))\n\nfor i in range(len(price_actual)):\n    price_actual[i] = int(price_actual[i].replace(',',''))\n\nfor i in range(len(price_no)):\n    price_no[i] = price_actual[np.random.randint(0,len(price_actual))]\n\nprice_actual.extend(price_no)\n\n# Distance covered\ndist = list(data.kms_driven.values)\nfilter1 = list(filter(lambda t1 : type(t1)==float, dist))\nfilter2 = list(filter(lambda t1 : type(t1)!=float and len(t1.split())==1, dist))\nstore = filter2\nfilter3 = list(filter(lambda t1 : type(t1)!=float and len(t1.split())!=1, dist))\nfor i in range(len(filter3)):\n    try:\n        filter3[i] = int((filter3[i].replace(' kms','')).replace(',',''))\n    except:\n        pass\nfilter3\nfor j in range(len(filter1)):\n    filter1[j] = filter3[np.random.randint(0,len(filter3))]\nfor k in range(len(filter2)):\n    filter2[k] = filter3[np.random.randint(0,len(filter3))]\nfilter3.extend(filter1)\nfilter3.extend(filter2)\n\n\ndata['price'] = price_actual\ndata['new_dist'] = filter3\ndata.drop(columns=['Price','kms_driven'],axis=1,inplace=True)\ndata","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Preprocessing 1 : Replace NaN values in fuel_type","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"types = ['Petrol','Diesel','LPG']\ndata.fuel_type.fillna(types[np.random.randint(0,len(types))],inplace=True)\ndata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fd,cd = {},{}\nle = LabelEncoder()\ndata['fuel_type'] = le.fit_transform(data['fuel_type'])\nfuel = le.inverse_transform(data['fuel_type'])\nfor i in range(len(fuel)):\n    fd[fuel[i]] = data['fuel_type'].values[i]\ndata['company_new'] = le.fit_transform(data['company_new'])\ncompany = le.inverse_transform(data['company_new'])\nfor i in range(len(company)):\n    cd[company[i]] = data['company_new'].values[i]\ndata_orig = data\ndata_orig","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ohe = pd.get_dummies(data,columns=['fuel_type','company_new'],drop_first=True)\nohe.head(12)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting the values for the form.\npkl.dump(fd,open('fuel2.pkl','wb'))\npkl.dump(cd,open('company2.pkl','wb'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### VISUALIZING RELATION","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initializing fig and axes\nfig = plt.figure(figsize=(10,5))\nax = fig.add_subplot(111,projection='3d')\n# Scatter plot\nax.scatter(data.company_new.values, data.new_dist.values, data.price.values, zdir='z', s = 180, c = 'red', depthshade=True)\nax.set_xlabel('COMPANY')\nax.set_ylabel('DISTANCE')\nax.set_zlabel('PRICE')\nax.set_title('3D REPRESENTATION OF THE DATA')\nplt.show()\n\nfig = plt.figure(figsize=(10,5))\nax = fig.add_subplot(111,projection='3d')\n# Scatter plot\nax.scatter(data.year_new.values, data.new_dist.values, data.price.values, zdir='z', s = 180, c = 'red', depthshade=True)\nax.set_xlabel('YEAR')\nax.set_ylabel('DISTANCE')\nax.set_zlabel('PRICE')\nax.set_title('3D REPRESENTATION OF THE DATA')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(data.year_new,data.price,c='red')\nplt.show()\nplt.scatter(data.price,data.new_dist,c='red')\nplt.show()\nsns.distplot(data.price)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Building the model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Y = np.array(data.iloc[:,2].values)\nX = np.array(data.drop(columns=['price'],axis=1).iloc[:,1:].values)\n\n# Train test split\ntrainx,testx,trainy,testy = train_test_split(X,Y,test_size = 0.2, random_state = 12)\nprint(\"TRAINING PHASE : trainx.shape = {} , trainy.shape = {}\".format(trainx.shape,trainy.shape))\nprint(\"TESTING PHASE : testx.shape = {} , testy.shape = {}\".format(testx.shape,testy.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y2 = np.array(ohe.iloc[:,2].values)\nX2 = np.array(ohe.drop(columns=['price'],axis=1).iloc[:,1:].values)\n\n# Train test split\ntrainx2,testx2,trainy2,testy2 = train_test_split(X2,Y2,test_size = 0.2, random_state = 12)\nprint(\"TRAINING PHASE : trainx.shape = {} , trainy.shape = {}\".format(trainx2.shape,trainy2.shape))\nprint(\"TESTING PHASE : testx.shape = {} , testy.shape = {}\".format(testx2.shape,testy2.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\ntrainx = scaler.fit_transform(trainx)\ntestx = scaler.fit_transform(testx)\n\n# Linear Regression\nlr = LinearRegression()\nlr.fit(trainx, trainy)\ny_pred1 = lr.predict(testx)\nr2_score(testy,y_pred1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\ntrainx2 = scaler.fit_transform(trainx2)\ntestx2 = scaler.fit_transform(testx2)\n\n# Linear Regression\nlr2 = LinearRegression()\n'''lr.fit(trainx, trainy)\ny_pred1 = lr.predict(testx)'''\nr2_score(testy2,y_pred1)\ncross_val_score(lr2,X2,Y2,cv=45)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lasso Regression\nlasso = Lasso(alpha=0.3)\ncross_val_score(lasso,X,Y,cv=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# MLPRegressor\nmlp = MLPRegressor()\nparam_grid = {'hidden_layer_sizes': [i for i in range(2,20)],\n              'activation': ['relu'],\n              'solver': ['adam'],\n              'learning_rate': ['constant'],\n              'learning_rate_init': [0.01],\n              'power_t': [0.5],\n              'alpha': [0.0001],\n              'max_iter': [1000],\n              'early_stopping': [True],\n              'warm_start': [False]}\nmlp_GS = GridSearchCV(mlp, param_grid=param_grid, \n                   cv=10, verbose=True, pre_dispatch='2*n_jobs')\nmlp_GS.fit(trainx,trainy)\ny_pred2 = mlp_GS.predict(testx)\nr2_score(testy,y_pred2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pkl.dump(lr,open('linreg2.pkl','wb'))\npkl.dump(mlp_GS,open('mlp3.pkl','wb'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}