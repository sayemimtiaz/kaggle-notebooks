{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"country_data = pd.read_csv('/kaggle/input/unsupervised-learning-on-country-data/Country-data.csv')\ndata_dictionary = pd.read_csv('/kaggle/input/unsupervised-learning-on-country-data/data-dictionary.csv')\ncountry_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"country_data.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"country_data.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"country_data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data Visualization**","metadata":{}},{"cell_type":"code","source":"dataset = country_data.iloc[:,1:]\ndataset.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Importing necessary libraries for Visualization\nfrom matplotlib import pyplot as plt\nimport seaborn as sns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8,8))\ncorr = dataset.corr()\nsns.heatmap(dataset.corr(),annot=True)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pos_ =  corr[corr >= 0.80]\nneg_ = corr[corr <= -0.80]\nprint(pos_)\nprint(neg_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**As observed, more that 80 % data are correlated for below features:**\n1. Negatively Correlated : \"child_mort\" <=> \"life_expec\"\n2. Positively Correlated : \"income\" <=> \"gdpp\" and \"child_mort\" <=> \"total_fer\"","metadata":{}},{"cell_type":"code","source":"sns.color_palette()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.set_theme(style=\"ticks\")\nsns.pairplot(dataset,palette='red')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"KMeans, HSCAN, DBSCAN","metadata":{}},{"cell_type":"markdown","source":"1. Choose Number of Clusters i.e. k.\n2. Valtidate the chosen k using Clustering Validation : Sillhoute","metadata":{}},{"cell_type":"code","source":"X = dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#elbow method\nfrom sklearn.cluster import KMeans\nwcss=[]\nK = range(1,11)\nfor i in K:\n    kmeans=KMeans(n_clusters=i,init='k-means++',random_state=42)\n    kmeans.fit(X)\n    wcss.append(kmeans.inertia_)\nplt.plot(K,wcss,marker='o')\nplt.plot(range(1,11),wcss)\nplt.title('The Elbow Method')\nplt.xlabel('Number of clusters')\nplt.ylabel('WCSS')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As per Elbow graph, \"3\" should be the Number of Cluster.\nLets validate using Silhoute Score","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import silhouette_samples, silhouette_score\nimport matplotlib.cm as cm\n\n\nrange_n_clusters = [2,3,4,5,6]\n\nfor n_clusters in range_n_clusters:\n    # Create a subplot with 1 row and 1 column\n    fig, (ax1) = plt.subplots(1)\n    fig.set_size_inches(10, 5)\n\n    # The 1st subplot is the silhouette plot\n    # The silhouette coefficient can range from -1, 1 but in this example all\n    # lie within [-0.1, 1]\n    ax1.set_xlim([-0.1, 1])\n    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n    # plots of individual clusters, to demarcate them clearly.\n    ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n\n    # Initialize the clusterer with n_clusters value and a random generator\n    # seed of 10 for reproducibility.\n    clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n    cluster_labels = clusterer.fit_predict(X)\n\n    # The silhouette_score gives the average value for all the samples.\n    # This gives a perspective into the density and separation of the formed\n    # clusters\n    silhouette_avg = silhouette_score(X, cluster_labels)\n    print(\"For n_clusters =\", n_clusters,\n          \"The average silhouette_score is :\", silhouette_avg)\n\n    # Compute the silhouette scores for each sample\n    sample_silhouette_values = silhouette_samples(X, cluster_labels)\n\n    y_lower = 10\n    for i in range(n_clusters):\n        # Aggregate the silhouette scores for samples belonging to\n        # cluster i, and sort them\n        ith_cluster_silhouette_values = \\\n            sample_silhouette_values[cluster_labels == i]\n\n        ith_cluster_silhouette_values.sort()\n\n        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n        y_upper = y_lower + size_cluster_i\n\n        color = cm.nipy_spectral(float(i) / n_clusters)\n        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n                          0, ith_cluster_silhouette_values,\n                          facecolor=color, edgecolor=color, alpha=0.7)\n\n        # Label the silhouette plots with their cluster numbers at the middle\n        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n\n        # Compute the new y_lower for next plot\n        y_lower = y_upper + 10  # 10 for the 0 samples\n\n    ax1.set_title(\"The silhouette plot for the various clusters.\")\n    ax1.set_xlabel(\"The silhouette coefficient values\")\n    ax1.set_ylabel(\"Cluster label\")\n\n    # The vertical line for average silhouette score of all the values\n    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n\n    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n    plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n                  \"with n_clusters = %d\" % n_clusters),\n                 fontsize=14, fontweight='bold')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**As observed For cluster 2, we've highest Silhouette Score but it do have negative values so, it can't be consider.\nHence, 3 is the optimal value of K.**","metadata":{}},{"cell_type":"markdown","source":"Now Apply K-Means clustering with number of cluster = 3","metadata":{}},{"cell_type":"code","source":"# Fitting K-Means to the dataset\nkmeans = KMeans(n_clusters = 3, init = 'k-means++', random_state = 42)\ny_kmeans = kmeans.fit_predict(X)\nprint(y_kmeans)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Count of records in each cluster\npd.Series(kmeans.labels_).value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.options.display.max_rows = None\nClusterNumber = pd.DataFrame(kmeans.labels_)\nCountry = country_data['country']\ndf1 = pd.concat([ClusterNumber,Country],axis=1)\ndf1\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}