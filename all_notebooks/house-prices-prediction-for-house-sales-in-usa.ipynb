{"metadata":{"language_info":{"name":"python","version":"3.6.3","nbconvert_exporter":"python","pygments_lexer":"ipython3","mimetype":"text/x-python","file_extension":".py","codemirror_mode":{"name":"ipython","version":3}},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"cells":[{"cell_type":"code","metadata":{"_uuid":"49f6869e5dffd5011f271c555ebdec51d12d2fbf","collapsed":true,"_cell_guid":"64f5ac15-8e68-4c51-b53a-bbe8731eb9fb"},"source":"import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom sklearn.feature_selection import RFE, f_regression\nfrom sklearn.linear_model import (LinearRegression, Ridge, Lasso, RandomizedLasso)\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.ensemble import RandomForestRegressor","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"_uuid":"b39a78955edaf20bdac3bbe14c88487693158fce","_cell_guid":"9dbd3ced-56f3-4fd6-b65e-f5d1e19fdb5f"},"source":"house = pd.read_csv(\"../input/kc_house_data.csv\")\nhouse.head()","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"24e7ffc0a41d20e1b8d46ad7017729f9a5c240ca","_cell_guid":"fa4d6bd2-e048-4c9a-9eca-ed3d741a15bc"},"source":"### **To see the distribution id and the price we used the Barplot of id vs price**"},{"cell_type":"code","metadata":{"_uuid":"21d6c711a6043b60be2dfb03a6089f8a1d5ff6e5","collapsed":true,"_cell_guid":"a78acc59-23f7-47a7-bce2-cdd092e24776"},"source":"\nplt.figure(figsize = (12,6))\nsns.barplot(house['id'],house['price'], alpha = 0.9,color = 'darkorange')\nplt.xticks(rotation = 'vertical')\nplt.xlabel('id', fontsize =14)\nplt.ylabel('price', fontsize = 14)\nplt.show()","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"_uuid":"78a61422e3306a4852430c0e772c83824797baf3","_cell_guid":"cb1a9152-cf6a-414d-af7b-2de477c868c1"},"source":"# Checking the null values\nprint(house.isnull().sum())","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"c6a810ed9aef94e8010f9363d94101d52aa470c9","_cell_guid":"b15d965f-a9ce-429f-96dd-ee43bd4c777f"},"source":"**Calculating age of house for better analysis**\n\n**Creating another column named age_of_house for visualization**"},{"cell_type":"code","metadata":{"_uuid":"565134b94d6f1dc31c065bd939598989a8643225","_cell_guid":"f6ea810b-b79a-4d0d-be2a-6f60bf9e20ab"},"source":"import datetime\ncurrent_year = datetime.datetime.now().year\nhouse[\"age_of_house\"] = current_year - pd.to_datetime(house[\"date\"]).dt.year\nhouse.head()","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"4a42ceb902e7192f2b001e0fb64f5981cb50fced","_cell_guid":"5f121e07-be1d-45fe-aacd-52a74cbdae27"},"source":""},{"cell_type":"markdown","metadata":{"_uuid":"66931976bf3533e6d77f31af627fc7e33ee968b8","_cell_guid":"e4ea5fde-f1bd-4986-9c2c-7f67ef03dc9b"},"source":"## **Checking the info of the house data**"},{"cell_type":"code","metadata":{"_uuid":"cca91ac3479c81d4727d681382396d5aaf03bc6c","_cell_guid":"bef085c2-b229-47a9-b606-181c0cb11e95"},"source":"house.info()","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"7c1a893e5335949c8db9c9feea8c569daa33b663","_cell_guid":"51b59e5d-f107-4a9a-bce8-8cb093570ad2"},"source":"##  **checking the columns names**"},{"cell_type":"code","metadata":{"_uuid":"27daf51d002fe0fe0c2341153e976189b91006f7","_cell_guid":"b2afed1e-3023-4039-bb05-168c7eb2d314"},"source":"house.columns","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"4fe6f58534f75c73bc14c6f453b2e4405a759454","_cell_guid":"4ce445f3-5b9e-456a-a3ef-f76db69b9842"},"source":"## Selecting features and target"},{"cell_type":"code","metadata":{"_uuid":"68505ab89227acbbdf6e282127af9f15a648a527","collapsed":true,"_cell_guid":"bfe1b237-15b3-4d29-b7be-3e3704178489"},"source":"feature_cols = [ u'age_of_house',  u'bedrooms', u'bathrooms', u'sqft_living',\n       u'sqft_lot', u'floors', u'waterfront', u'view', u'condition', u'grade',\n       u'sqft_above', u'sqft_basement', u'yr_built', u'yr_renovated']\nx = house[feature_cols]\ny = house[\"price\"]","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"ecf12f744b1b34e80b55750cae465599b94c1d55","_cell_guid":"69015b1f-f15f-4a8b-8474-1838d4447811"},"source":"## Splitting Training and Test Data"},{"cell_type":"code","metadata":{"_uuid":"84fff0a4bc6b125199de83b54c63930f6bbffa76","collapsed":true,"_cell_guid":"c15a70a7-cdef-45c2-852b-b04fc4512ea4"},"source":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x, y, random_state=3)","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"_uuid":"2a71d3f0725e35f031b563f998525e0dc139ebb3","_cell_guid":"d5f3427a-a1ba-42c0-85bd-cf714de5d0a6"},"source":"# Fitting Data to Linear Regressor using scikit\nfrom sklearn.linear_model import LinearRegression\nregressor = LinearRegression()\nregressor.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"_uuid":"fae82a29a1909ff6b3ab0a13673e211e30e9e472","_cell_guid":"405d972f-4ec3-4371-afbe-c029d8bbc778"},"source":"accuracy = regressor.score(x_test, y_test)\n\"Accuracy: {}%\".format(int(round(accuracy * 100)))","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"d4a3a232a37343fa368682f907e73e92f58e5391","collapsed":true,"_cell_guid":"0fb9e4a7-ac5c-4e49-9f7a-c02d083dfa09"},"source":"## **The above Accuracy was not so good it is coming like 66% so we are taking the Lasso Regression, Random Forest feature ranking, Linear Model Feature Ranking**\n\n** Before that we will use the Seaborn Pairplot to check the classical linear distribution of the data points , then we used the correlation heatmap **\n\n**method: indicates the correlation coefficient to be computed. The default is pearson correlation coefficient which measures the linear dependence between two variables. kendall and spearman correlation methods are non-parametric rank-based correlation test**\n"},{"cell_type":"code","metadata":{"_uuid":"078e05072f68caecc846ca210ddd5c466890d471","_cell_guid":"471ffbbc-3a7f-471f-91f8-140358c4fb5f"},"source":"# Pairplot\ng = sns.pairplot(house[['sqft_lot','sqft_above','price','sqft_living','bedrooms']], hue='bedrooms', palette='Blues',size=4)\ng.set(xticklabels=[])","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"_uuid":"6e2d072314592e792ae43c17c14e8918cb596826","_cell_guid":"41702bf0-16d6-41fa-bab1-8eed70356d00"},"source":"str_list = [] # empty list to contain columns with strings (words)\nfor colname, colvalue in house.iteritems():\n    if type(colvalue[1]) == str:\n         str_list.append(colname)\n# Get to the numeric columns by inversion            \nnum_list = house.columns.difference(str_list) \n# Create Dataframe containing only numerical features\nhouse_num = house[num_list]\nf, ax = plt.subplots(figsize=(16, 12))\nplt.title('Pearson Correlation of features')\n# Draw the heatmap using seaborn\nsns.heatmap(house_num.astype(float).corr(),linewidths=0.25,vmax=1.0, square=True, cmap=\"gist_rainbow\", linecolor='k', annot=True)","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"d2e999a6b75ef58e9ec22d54306765d463c26d51","_cell_guid":"f21a9931-8465-4fa2-8d69-d0b4b49160ce"},"source":"**The data is pretty clean. There are no pesky nulls which we need to treat and most of the features are in numeric format. Let's go ahead and drop the \"id\" and \"date\" columns as these 2 features will not be used in this analysis.**"},{"cell_type":"code","metadata":{"_uuid":"4a639b6479272611574bf72542a68a7161d08665","collapsed":true,"_cell_guid":"2ee3f2c6-6eba-43e0-abf2-161116e57bd7"},"source":"# Dropping the id and date columns\nhouse = house.drop(['id', 'date'],axis=1)","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"1e769977320b5baa4314eef217d9f8e0f88b93ce","_cell_guid":"c5bc98ad-6548-4171-97da-267308da3624"},"source":"***Again we will do Pairplot Visualisation without id and date in the house data**"},{"cell_type":"code","metadata":{"_uuid":"67f771426a99c0bd45ac92f7ce4837d2b70175e6","_cell_guid":"70e7e22c-2d73-4412-9c41-5f4d7be7dcbc"},"source":"str_list = [] # empty list to contain columns with strings (words)\nfor colname, colvalue in house.iteritems():\n    if type(colvalue[1]) == str:\n         str_list.append(colname)\n# Get to the numeric columns by inversion            \nnum_list = house.columns.difference(str_list) \n# Create Dataframe containing only numerical features\nhouse_num = house[num_list]\nf, ax = plt.subplots(figsize=(16, 12))\nplt.title('Pearson Correlation of features')\n# Draw the heatmap using seaborn\nsns.heatmap(house_num.astype(float).corr(),linewidths=0.25,vmax=1.0, square=True, cmap=\"PuBuGn\", linecolor='k', annot=True)","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"3f2e01213294982634c767f80fd98b1710b27df9","_cell_guid":"18d5637a-a2ae-459c-b3ad-bcde1b0c0956"},"source":""},{"cell_type":"code","metadata":{"_uuid":"346a8b37c92d7a277e0e3531909f366d5d4ffa2e","collapsed":true,"_cell_guid":"94973f93-d0ab-48b7-9b3e-f577a56cb1e9"},"source":"# First extract the target variable which is our House prices\nY = house.price.values\n# Drop price from the house dataframe and create a matrix out of the house data\nhouse = house.drop(['price'], axis=1)\nX = house.as_matrix()\n# Store the column/feature names into a list \"colnames\"\ncolnames = house.columns ","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"_uuid":"f972514b8aca3759e2b98cc3078839647db51828","collapsed":true,"_cell_guid":"84e557f5-5978-4175-acb9-bfab8d25022f"},"source":"# Define dictionary to store our rankings\nranks = {}\n# Create our function which stores the feature rankings to the ranks dictionary\ndef ranking(ranks, names, order=1):\n    minmax = MinMaxScaler()\n    ranks = minmax.fit_transform(order*np.array([ranks]).T).T[0]\n    ranks = map(lambda x: round(x,2), ranks)\n    return dict(zip(names, ranks))","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"_uuid":"d8f1f43b1abf6dce725626aaeadcda71f0cb943a","_cell_guid":"5aed370a-56d5-42be-946b-f2c00b87b74c"},"source":"# Finally let's run our Selection Stability method with Randomized Lasso\nrlasso = RandomizedLasso(alpha=0.04)\nrlasso.fit(X, Y)\nranks[\"rlasso/Stability\"] = ranking(np.abs(rlasso.scores_), colnames)\nprint('finished')","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"0fd3b0d226d14b3c78fa853485fa26257f4d721d","_cell_guid":"e79866d1-8000-40ff-8425-6800607b903d"},"source":" ### **Randomized Lasso value for the all variables in the Datasets**"},{"cell_type":"code","metadata":{"_uuid":"90430034988c3e3150b00360dde1f2fe8f9364ac","_cell_guid":"7eb354ee-9f80-40e4-b6db-f1a0cf28f1ad"},"source":"print(ranks[\"rlasso/Stability\"])","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"_uuid":"6331d733c5c98925c91314bf8ec50111489e0b6d","collapsed":true,"_cell_guid":"a983f9e1-7183-49c7-8aaa-7d8f47fb927a"},"source":"","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"_uuid":"6cd4619f93d53d80b34a3fa55875d5fc9f9566dc","_cell_guid":"ce12054b-808f-4c71-a349-de8be2ed856d"},"source":"# Using Linear Regression\nlr = LinearRegression(normalize=True)\nlr.fit(X,Y)\nranks[\"LinReg\"] = ranking(np.abs(lr.coef_), colnames)\n\n# Using Ridge \nridge = Ridge(alpha = 7)\nridge.fit(X,Y)\nranks['Ridge'] = ranking(np.abs(ridge.coef_), colnames)\n\n# Using Lasso\nlasso = Lasso(alpha=.05)\nlasso.fit(X, Y)\nranks[\"Lasso\"] = ranking(np.abs(lasso.coef_), colnames)\n","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"32b8142e81b34a934f455466df9b474a9362f0ec","_cell_guid":"b64c58ae-4b94-4344-815f-faf9d1b57ca4"},"source":"### **To select either the best or worst-performing feature we can use the Recursive Feature Elimination or RFE Sklearn conveniently possesses a RFE function via the sklearn.feature_selection call**"},{"cell_type":"code","metadata":{"_uuid":"7a428161eab196ad16ac2cc8992b743e4a6cd7ab","_cell_guid":"45a05010-a0b1-493e-bf29-de45481e1b8c"},"source":"# Construct our Linear Regression model\nlr = LinearRegression(normalize=True)\nlr.fit(X,Y)\n#stop the search when only the last feature is left\nrfe = RFE(lr, n_features_to_select=1, verbose =3 )\nrfe.fit(X,Y)\nranks[\"RFE\"] = ranking(list(map(float, rfe.ranking_)), colnames, order=-1)","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"e9e670989acb499a742c533510f2bd1fa7489b6e","_cell_guid":"de79a1b2-92d2-4817-a7f7-5adf5e3bf135"},"source":"### **Now, with the matrix above, the numbers and layout does not seem very easy or pleasant to the eye. Therefore, let's just collate the mean ranking score attributed to each of the feature and plot that via Seaborn's factorplot.**"},{"cell_type":"code","metadata":{"_uuid":"a199e448dc28f48bba644ba50a49b90065fffeba","_cell_guid":"ed6f74e3-e399-4c70-8853-ba6b9e3d4916"},"source":"# Create empty dictionary to store the mean value calculated from all the scores\nr = {}\nfor name in colnames:\n    r[name] = round(np.mean([ranks[method][name] \n                             for method in ranks.keys()]), 2)\n \nmethods = sorted(ranks.keys())\nranks[\"Mean\"] = r\nmethods.append(\"Mean\")\n \nprint(\"\\t%s\" % \"\\t\".join(methods))\nfor name in colnames:\n    print(\"%s\\t%s\" % (name, \"\\t\".join(map(str, \n                         [ranks[method][name] for method in methods]))))","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"_uuid":"c58ea7ed20a213fc0981d7248a706103de7d36be","_cell_guid":"77cddeec-4e45-4813-a1f2-4702fdd52ac8"},"source":"# Put the mean scores into a Pandas dataframe\nmeanplot = pd.DataFrame(list(r.items()), columns= ['Feature','Mean Ranking'])\n\n# Sort the dataframe\nmeanplot = meanplot.sort_values('Mean Ranking', ascending=False)\n# Let's plot the ranking of the features\nsns.factorplot(x=\"Mean Ranking\", y=\"Feature\", data = meanplot, kind=\"bar\", size=4, aspect=1.9, palette='rainbow')","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"1dc134b9126330533785d02f592db3c17dd4222c","_cell_guid":"a33eefce-3922-47e7-9d94-f61707e106b2"},"source":"## **** Now we selecting the best features and fit the model, here we are again loading the datasets because we are preprocessed the data so we need some features to select in order that we need to load data****"},{"cell_type":"code","metadata":{"_uuid":"3a00bcde0536970f7a1f884f7ca127eb066135a9","collapsed":true,"_cell_guid":"4dd4a290-75d8-4161-afca-96e38924650b"},"source":"house1 = pd.read_csv(\"../input/kc_house_data.csv\")","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"_uuid":"a05f0732c1805a6de1a35e4b5b83cc0c34344dcc","_cell_guid":"ed4505e2-bd4f-4cc5-a06a-d4763621a772"},"source":"import datetime\ncurrent_year = datetime.datetime.now().year\nhouse1[\"age_of_house\"] = current_year - pd.to_datetime(house1[\"date\"]).dt.year\nhouse1.head()","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"64d7de91288d2043d90cffa6038ab4f31121b4da","_cell_guid":"3d5fbdf6-dcc1-44c3-a3ca-8bf5413c3088"},"source":"### **Below we selected the best features what we obtained from the ranking of the features table and graph**\n"},{"cell_type":"code","metadata":{"_uuid":"2b01e28004a228a5cf7bf71aa19bcad87ac4eb4c","collapsed":true,"_cell_guid":"8be8548f-9c42-40fd-a595-87bb5c605258"},"source":"feature_cols = [ u'bedrooms', u'bathrooms', u'sqft_living',\n       u'sqft_lot', u'floors', u'waterfront', u'view', u'condition', u'grade',\n       u'sqft_above', u'sqft_basement', u'yr_built', u'yr_renovated',u'lat']\nx = house1[feature_cols]\ny = house1[\"price\"]","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"_uuid":"588d52936e51a14d4c8d95abe073f167f002973c","collapsed":true,"_cell_guid":"5f854e91-3370-4667-8f66-230d0ed7350d"},"source":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x, y, random_state=3)","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"_uuid":"0c5ffb013d5ad067cd81aaca7e48b90f34398e41","_cell_guid":"51def453-9209-4153-894d-687224587cf3"},"source":"# Fitting Data to Linear Regressor using scikit\nfrom sklearn.linear_model import LinearRegression\nregressor = LinearRegression()\nregressor.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"_uuid":"b5ddaef82c1a170d526fb6479c5a5a880c3bb865","_cell_guid":"c7d9e6f8-3fa5-4ecb-a71f-53921723a74a"},"source":"accuracy = regressor.score(x_test, y_test)\n\"Accuracy: {}%\".format(int(round(accuracy * 100)))","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"c89b08d709bb92cf4f1c1796037d08c73c22c464","_cell_guid":"96f8494c-dfc4-44fc-9e50-196a389140d7"},"source":"## ** We are following the backward elimination procedure we will check the accuracy every time**"},{"cell_type":"code","metadata":{"_uuid":"edebf067814a47d6a18d889ec6da2ad8fd9e3f4a","collapsed":true,"_cell_guid":"fb401274-ecd6-4da2-bbc3-574a7b171b7d"},"source":"feature_cols1 = [ u'bedrooms', u'bathrooms', u'sqft_living',\n       u'sqft_lot', u'waterfront', u'view', u'grade',\n       u'sqft_above', u'sqft_basement',u'lat']\nx1 = house1[feature_cols1]","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"_uuid":"7bcebfa6ec41df4a837acb93f25282aec0fa834e","_cell_guid":"1f8805f4-0815-4c97-b4b3-b46630c30b6a"},"source":"from sklearn.model_selection import train_test_split\nx_train1,x_test1,y_train1,y_test1 = train_test_split(x1, y, random_state=3)\n# Fitting Data to Linear Regressor using scikit\nfrom sklearn.linear_model import LinearRegression\nregressor1 = LinearRegression()\nregressor1.fit(x_train1, y_train1)","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"_uuid":"ce3267ab7623e6a98a6e953bc2e593fe69e1a89e","_cell_guid":"e1d50f0c-0799-4f1c-a886-b5036556e0fa"},"source":"accuracy1 = regressor1.score(x_test1, y_test1)\n\"Accuracy: {}%\".format(int(round(accuracy1 * 100)))","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"_uuid":"65a29cb56c5b6d6b256c4af7b290104c061b9bad","_cell_guid":"3cc58f64-7dd0-4424-b706-11334adbf68d"},"source":"feature_cols3 = [u'age_of_house',  u'bedrooms', u'bathrooms',\n                 u'floors', u'waterfront', u'view', u'condition',\n                 u'grade',u'zipcode', u'yr_built']\nx3 = house1[feature_cols3]\nfrom sklearn.model_selection import train_test_split\nx_train3,x_test3,y_train3,y_test3 = train_test_split(x3, y, random_state=3)\n# Fitting Data to Linear Regressor using scikit\nfrom sklearn.linear_model import LinearRegression\nregressor3 = LinearRegression()\nregressor3.fit(x_train3, y_train3)\naccuracy3 = regressor3.score(x_test3, y_test3)\n\"Accuracy: {}%\".format(int(round(accuracy3 * 100)))","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"f5adc9d8891fe8ffd2551a9723f938156b8eaf9b","_cell_guid":"06400a90-c05b-4bc7-ae42-e235c7e0fb55"},"source":"## ** So we conclude that Top 6 and last 3 or 4 variables will affect tha accuracy**"}],"nbformat_minor":1,"nbformat":4}