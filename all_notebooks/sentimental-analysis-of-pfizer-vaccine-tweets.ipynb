{"cells":[{"metadata":{},"cell_type":"markdown","source":"# <u>About</u>\n\nThe Pfizer–BioNTech COVID‑19 vaccine, sold under the brand name Comirnaty, is a COVID-19 vaccine developed by BioNTech in cooperation with Pfizer. It is both the first COVID-19 vaccine to be authorized by a stringent regulatory authority for emergency use and the first cleared for regular use. In December of 2020, the United Kingdom was the first country to authorize the vaccine on an emergency basis, soon followed by the United States, the European Union and several other countries globally.\n\n<br>\n    <figure>\n        <center>\n            <img src=\"https://d1e00ek4ebabms.cloudfront.net/production/4319492f-2f82-445b-9fef-ae8deda455bb.jpg\" width=500 height=500/>\n            <figcaption>Pfizer-BioNTech Vaccine</figcaption>\n        </center>\n    </figure>\n<br>\n\n<u>Problem statement</u>: Study the subjects of recent tweets about the vaccine made in collaboration by Pfizer and BioNTech, perform various NLP tasks on this data source.<br>\n<u>Data source</u>: https://www.kaggle.com/gpreda/pfizer-vaccine-tweets\n\nIn this notebook, I have covered 4 important things:\n- Classified tweets based on Valence Aware Dictionary and sentiment Reasoner. \n- Extracted top 25 negative and positive sentimental words.\n- Analyzed positive and negative tweet counts over a period of 3 months.\n- Countries that are leading the vaccination drive."},{"metadata":{},"cell_type":"markdown","source":"## *Loading Pfizer Tweets Dataset*"},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\nfrom nltk.corpus import stopwords\nfrom nltk.stem import SnowballStemmer\nfrom nltk.sentiment import SentimentIntensityAnalyzer\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/pfizer-vaccine-tweets/vaccination_tweets.csv').fillna('')\n\nprint(f'No. of records: {data.shape[0]}')\nprint(f'No. of columns: {data.shape[1]}\\n')\nprint(f'Column names:\\n {data.columns.values}')\ndata.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## *Data Preprocessing*"},{"metadata":{"trusted":true},"cell_type":"code","source":"stop_words = (set(stopwords.words('english')))\nsno = SnowballStemmer('english')\n\ndef remove_html_tags(sentence):\n    regex = re.compile(pattern='<.*?>')\n    clean_text = re.sub(regex, ' ', sentence)\n    return clean_text\n\ndef remove_punctuations(word):\n    cleaned_sentence = re.sub(pattern=r'[?|!|\\|\"|#|\\']', repl=r'', string=word)\n    cleaned_sentence = re.sub(pattern=r'[.|,|)|(|\\|/]', repl=r'', string=cleaned_sentence)\n    return cleaned_sentence\n\ndef get_preprocessed_data(data, feature, cleaned_feature):\n        \n        i = 0\n        final_string = []\n\n        sentences = data[feature].values\n        for sentence in sentences:\n            filtered_sentence = []\n            sentence = remove_html_tags(sentence)\n            for word in sentence.split():\n                for clean_word in remove_punctuations(word).split():\n                    if clean_word.isalpha() and len(clean_word) > 2:\n                        if clean_word.lower() not in stop_words:\n                            s = (sno.stem(clean_word.lower()))\n                            filtered_sentence.append(s)\n\n            string = \" \".join(filtered_sentence)\n            final_string.append(string)\n            i += 1\n        data[cleaned_feature] = final_string\n        return data\n\ndata = get_preprocessed_data(data, 'text', 'Tidy Tweet')\ndata = get_preprocessed_data(data, 'hashtags', 'Tidy hashtags')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## *Analyzing sentiments using pretrained sentiment analyzer: Valence Aware Dictionary and sentiment Reasoner (VADER)*\n\nVADER is a lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments expressed in social media. VADER uses a combination of A sentiment lexicon is a list of lexical features (e.g., words) which are generally labelled according to their semantic orientation as either positive or negative.\n\n<br>\n    <figure>\n        <center>\n            <img src=\"https://www.tertiarycourses.com.sg/media/catalog/product/cache/1/image/650x/040ec09b1e35df139433887a97daa66f/n/a/natural-language-processing-nlp-python-nltk-training.jpg\" \n                      width=200 height=200/>\n            <img src=\"https://miro.medium.com/max/860/1*Xj8-Jpi5TppZHA8dFRml6A.jpeg\" width=200 height=200/>\n        </center>\n    </figure>\n<br>\n\nFor more info: https://www.nltk.org/_modules/nltk/sentiment/vader.html"},{"metadata":{"trusted":true},"cell_type":"code","source":"sentiment = SentimentIntensityAnalyzer()\n\ndef get_sentiment(data):\n    sentiment_list = []\n    for text in list(data['Tidy Tweet'].values):\n        if sentiment.polarity_scores(text)[\"compound\"] > 0:\n            sentiment_list.append(\"Positive\")\n        elif sentiment.polarity_scores(text)[\"compound\"] < 0:\n            sentiment_list.append(\"Negative\")\n        else:\n            sentiment_list.append(\"Neutral\")\n    return sentiment_list\n        \ndata['Sentiment'] = get_sentiment(data)\nsns.countplot(x=\"Sentiment\", data=data, palette=\"Set3\")\nprint(data.Sentiment.value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## *Word Cloud on Tweets*"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_word_cloud(sentiment):\n    stop_words = (set(stopwords.words('english')))\n    remove_words = ['vaccin', 'pfizerbiontech', 'coronavirus', 'pfizer', 'covid', 'covidvaccin', 'pfizervaccin']\n    stop_words = remove_words + list(stop_words)\n    plt.figure(figsize=[15,15])\n    clean_tweets= \"\".join(list(data[data['Sentiment']==sentiment]['Tidy Tweet'].values))\n    wordcloud = WordCloud(width=700,height=400, background_color='white',colormap='plasma', max_words=50, stopwords=stop_words, collocations=False).generate(clean_tweets)\n    plt.title(f\"Top 50 {sentiment} words used in tweets\", fontsize=20)\n    plt.imshow(wordcloud)\n    return plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_word_cloud(sentiment='Negative')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Based Valence Aware Dictionary and sentiment Reasoner (VADER) classification in analyzing tweets as negative have given us good results. Few of the words which represent negative sentiments are *death, die, sore, risk, dead, serious, delay, risk, allergy etc*"},{"metadata":{"trusted":true},"cell_type":"code","source":"get_word_cloud(sentiment='Positive')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Based Valence Aware Dictionary and sentiment Reasoner (VADER) classification in analyzing tweets as positive have given us good results. Few of the words which represent negative sentiments are *thank, like, new, good, hope, health, approve, receive, help, need etc*"},{"metadata":{},"cell_type":"markdown","source":"## *Tweet Count w.r.t Date*"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['date'] = pd.to_datetime(data['date']).dt.date\nnegative_data = data[data['Sentiment']=='Negative'].reset_index()\npositive_data = data[data['Sentiment']=='Positive'].reset_index()\ngrouped_data_neg = negative_data.groupby('date')['Sentiment'].count().reset_index()\ngrouped_data_pos = positive_data.groupby('date')['Sentiment'].count().reset_index()\nmerged_data = pd.merge(grouped_data_neg, grouped_data_pos, left_on='date', right_on='date', suffixes=(' Negative', ' Positive'))\n\nmerged_data.plot(x='date', y=['Sentiment Negative', 'Sentiment Positive'], figsize=(14, 7), marker='o', xlabel='Date', ylabel='Count', title='Tweet count over a period of time')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### From the above graph it can be observed that for over a period of 3 months people were optimistic about the pfizer vaccine. Graph also shows that for any given day, positive tweets dominated negative tweets. This indicates that people are hopeful and have high expectation from pfizer vaccine."},{"metadata":{},"cell_type":"markdown","source":"## *Tweets per Country/City*"},{"metadata":{"trusted":true},"cell_type":"code","source":"loc_df = data['user_location'].str.split(',',expand=True)\nloc_df=loc_df.rename(columns={0:'fst_loc',1:'snd_loc'})\nloc_df['snd_loc'] = loc_df['snd_loc'].str.strip()\n\nstate_fix = {'Ontario': 'Canada','United Arab Emirates': 'UAE','TX': 'USA','NY': 'USA','FL': 'USA','England': 'UK','Watford': 'UK','GA': 'USA','IL': 'USA', 'NY':'USA','United Kingdom':'UK', \n             'Alberta': 'Canada','WA': 'USA','NC': 'USA','British Columbia': 'Canada','MA': 'USA','ON':'Canada','OH':'USA','MO':'USA','AZ':'USA','NJ':'USA','London':'UK',\n             'CA':'USA','DC':'USA','AB':'USA','PA':'USA','SC':'USA','VA':'USA','TN':'USA','New York':'USA','Dubai':'UAE','CO':'USA', 'MI':'USA', 'LA':'USA', 'MD':\"USA\"}\ncountry = loc_df.replace({\"snd_loc\": state_fix}) \ntop_tweets = loc_df['snd_loc'].value_counts()[:20]\ntweet_df = pd.DataFrame(top_tweets)\ntweet_df.reset_index(level=0, inplace=True)\ntweet_df.columns = ['Country', 'Count']\ntweet_df['Country'] = tweet_df['Country'].replace(state_fix, regex=False)\ntweets_per_country = tweet_df.groupby('Country')['Count'].sum().reset_index().sort_values(by='Count')\ntweets_per_country.plot.bar(x='Country', figsize=(14, 7), xlabel='Country', ylabel='Count', title='Tweet count per country')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Maximum tweets were done by USA, UK and India. These 3 countries are leading the vaccination drive. This [article](https://timesofindia.indiatimes.com/life-style/health-fitness/health-news/coronavirus-5-countries-which-are-leading-the-race/photostory/78844240.cms) by Times of India mentions that USA, UK, China, India and Russia are playing a crucial role in vaccine manufacturing and production. Since twitter is banned(blocked) in China and Russia, therefore the number don't come into the picture."},{"metadata":{},"cell_type":"markdown","source":"<br>\n    <figure>\n        <center>\n            <img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSr0hAXZpPjP6H_SLVhBBZQ0t8lDLMGvk8ZTA&usqp=CAU\" width=200 height=200/>\n            <figcaption>If you liked my worked please upvote it.</figcaption>\n        </center>\n    </figure>\n<br>"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}