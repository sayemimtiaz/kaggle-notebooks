{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"# French car insurance claims: Model comparisons\nComparing models built to predict car insurance claim frequencies. The models are from:\n- Poisson Generalised Linear Model (GLM): <https://www.kaggle.com/btw78jt/models-of-french-motor-claims>\n- Gradient Boosting Maching (GBM) using `xgboost`: <https://www.kaggle.com/chun88/chuns-french-motor-claims-project>\n- Random Forest: <https://www.kaggle.com/alexanderfarquharson/alex-f-french-motor-claims-analysis>\n\nThe modelling data is from: <https://www.kaggle.com/floser/french-motor-claims-datasets-fremtpl2freq>"},{"metadata":{},"cell_type":"markdown","source":"<!-- This table of contents is updated *manually* -->\n# Contents\n1. [Setup](#Setup): Import packages, Config variables\n1. [Load data](#Load-data): Modelling data, Split for modelling, Model predictions, Join data\n1. [Visualise fit](#Visualise-fit): Lift\n1. [Rough work only](#Rough-work-only): Specifying exposure for `xgboost`, Function that can also return its code"},{"metadata":{},"cell_type":"markdown","source":"<div align=\"right\" style=\"text-align: right\"><a href=\"#Contents\">Back to Contents</a></div>\n\n# Setup"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set warning messages\nimport warnings\n# Show all warnings in IPython\nwarnings.filterwarnings('always')\n# Ignore specific numpy warnings (as per <https://github.com/numpy/numpy/issues/11788#issuecomment-422846396>)\nwarnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\nwarnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")\n# Other warnings that sometimes come up\nwarnings.filterwarnings(\"ignore\", message=\"unclosed file <_io.TextIOWrapper\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import built-in modules\nimport sys\nimport platform\nimport os\nfrom pathlib import Path\n\n# Import external modules\nfrom IPython import __version__ as IPy_version\nimport IPython.display as ipyd\nimport numpy as np\nimport pandas as pd\nfrom sklearn import __version__ as skl_version\nfrom sklearn.model_selection import train_test_split\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom bokeh import __version__ as bk_version\nfrom scipy import __version__ as scipy_version\nfrom statsmodels import __version__ as sm_version\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nimport xgboost as xgb\nimport scipy.stats as sps\n\n# Import project modules\nfrom bucketplot import __version__ as bplt_version\nimport bucketplot as bplt\n\n# Check they have loaded and the versions are as expected\nassert platform.python_version_tuple() == ('3', '6', '6')\nprint(f\"Python version:\\t\\t{sys.version}\")\nassert IPy_version == '7.13.0'\nprint(f'IPython version:\\t{IPy_version}')\nassert np.__version__ == '1.18.2'\nprint(f'numpy version:\\t\\t{np.__version__}')\nassert pd.__version__ == '0.25.3'\nprint(f'pandas version:\\t\\t{pd.__version__}')\nassert skl_version == '0.22.2.post1'\nprint(f'sklearn version:\\t{skl_version}')\nassert mpl.__version__ == '3.2.1'\nprint(f'matplotlib version:\\t{mpl.__version__}')\nassert sns.__version__ == '0.10.0'\nprint(f'seaborn version:\\t{sns.__version__}')\nassert bk_version == '2.0.1'\nprint(f'bokeh version:\\t\\t{bk_version}')\nassert scipy_version == '1.4.1'\nprint(f'scipy version:\\t\\t{scipy_version}')\nassert sm_version == '0.11.0'\nprint(f'statsmodels version:\\t{sm_version}')\nassert bplt_version == '0.0.2'\nprint(f'bucketplot version:\\t{bplt_version}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bokeh imports\nfrom bokeh.layouts import gridplot\nfrom bokeh.plotting import figure, output_file, show, output_notebook\nfrom bokeh.models.ranges import Range1d\nfrom bokeh.models.axes import LinearAxis\n\n# Load Bokeh for use in a notebook\nfrom bokeh.io import output_notebook\noutput_notebook()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Output exact environment specification, in case it is needed later\nprint(\"Capturing full package environment spec\")\nprint(\"(But note that not all these packages are required)\")\n!pip freeze > requirements_Kaggle.txt\n!jupyter --version > jupyter_versions.txt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Config variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"input_folder_path = Path('/kaggle/input')\nclaims_data_filepath = (\n    input_folder_path / 'french-motor-claims-datasets-fremtpl2freq' / 'freMTPL2freq.csv'\n)\n\nGLM_folder_path = input_folder_path / 'models-of-french-motor-claims'\nassert GLM_folder_path.is_dir()\nGLM_data_filepath = GLM_folder_path / 'df_validation_GLM_preds.gzip'\nassert GLM_data_filepath.is_file()\n\nRF_folder_path = input_folder_path / 'alex-f-french-motor-claims-analysis'\nassert RF_folder_path.is_dir()\nRF_data_filepath = RF_folder_path / 'Alex_Farquharson_rf_dataframe.gzip'\nassert RF_data_filepath.is_file()\n\nXGB_folder_path = input_folder_path / 'chuns-french-motor-claims-project'\nassert XGB_folder_path.is_dir()\nXGB_data_filepath = XGB_folder_path / 'xgb_filtered_pred_valid_set_new.gzip'\nassert XGB_data_filepath.is_file()\n\nprint(\"Correct: All locations are available as expected\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div align=\"right\" style=\"text-align: right\"><a href=\"#Contents\">Back to Contents</a></div>\n\n# Load data"},{"metadata":{},"cell_type":"markdown","source":"## Modelling data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Load full modelling data set\nexpected_dtypes = {\n    **{col: np.dtype('int64') for col in [\n        'IDpol', 'ClaimNb', 'VehPower', 'VehAge', 'DrivAge', 'BonusMalus', 'Density']},\n    **{col: np.dtype('float64') for col in ['Exposure']},\n    **{col: np.dtype('O') for col in ['Area', 'VehBrand', 'VehGas', 'Region']},\n}\ndf_raw = pd.read_csv(claims_data_filepath, delimiter=',', dtype=expected_dtypes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check it has loaded OK\nnRows, nCols = (678013, 12)\nassert df_raw.shape == (nRows, nCols)\nprint(f\"Correct: Shape of DataFrame is as expected: {nRows} rows, {nCols} cols\")\nassert df_raw.dtypes.equals(pd.Series(expected_dtypes)[df_raw.columns])\nprint(\"Correct: Data types are as expected\")\nassert df_raw.isna().sum().sum() == 0\nprint(\"Correct: There are no missing values in the raw dataset\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Split for modelling\nFor this kernel, we want the validation data."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get index sorted with ascending IDpol, just in case it is out or order\ndf_all = df_raw.sort_values('IDpol').reset_index(drop=True)\n\n# Proportions we want to split in (must sum to 1)\nsplit_props = pd.Series({\n    'train': 0.7,\n    'validation': 0.15,\n    'holdout': 0.15\n})\n\n# Split out training data\ndf_train, df_not_train = train_test_split(\n    df_all, test_size=(1 - split_props['train']), random_state=51, shuffle=True\n)\n# Split remaining data between validation and holdout\ndf_validation, df_holdout = train_test_split(\n    df_not_train, test_size=split_props['holdout'] / (1 - split_props['train']), random_state=13, shuffle=True\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check all rows have been accounted for\npd.concat([df_train, df_validation, df_holdout]).sort_index().equals(df_all)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sort to make it easier to compare\n# We know that IDpol is unique\ndf_validation = df_validation.sort_values('IDpol')\nact_ClaimNb_validation = df_validation.ClaimNb.sum()\n\n# Print number of rows and fields\ndf_validation.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"expl_var_names = [\n    col_name for col_name in df_validation.columns.to_list() \n     if col_name not in ['IDpol', 'ClaimNb', 'Exposure', 'Frequency']\n]\nprint(\"Explanatory variables\\n\" + '\\t'.join(expl_var_names))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Model predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"# From GLM\ndf_GLM_preds = pd.read_pickle(\n    GLM_data_filepath\n).sort_values('IDpol')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reasonableness checks\nassert df_GLM_preds.shape[0] == df_validation.shape[0]\nassert (df_validation.IDpol == df_GLM_preds.IDpol).all()\nassert (df_validation.ClaimNb == df_GLM_preds.ClaimNb).all()\nassert df_GLM_preds.iloc[:,:12].equals(df_validation)\nprint(\"Correct: Reasonableness checks have passed for the GLM data\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_ClaimNb_GLM = (df_GLM_preds.pred_freq * df_validation.Exposure).sum()\nprint(f\"GLM predicted total number of claims:\\t{pred_ClaimNb_GLM:.1f}\")\nprint(f\"Actual total number of claims:\\t\\t{act_ClaimNb_validation:.1f}\")\nprint(f\"Difference:\\t\\t\\t\\t{pred_ClaimNb_GLM - act_ClaimNb_validation:.1f}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# From GBM (i.e. xgboost)\ndf_XGB_preds = pd.read_pickle(\n    XGB_data_filepath\n).sort_values('IDpol').reset_index(drop=True)\n# Cast IDpol to integer to match modelling data\ndf_XGB_preds.IDpol = df_XGB_preds.IDpol.astype(np.dtype('int64'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reasonableness checks\nassert df_XGB_preds.shape[0] == df_validation.shape[0]\nassert (df_validation.reset_index(\n    drop=True).IDpol == df_XGB_preds.IDpol).all()\nassert (df_validation.reset_index(\n    drop=True).ClaimNb == df_XGB_preds.ClaimNb).all()\nassert df_validation.reset_index(drop=True)[\n    ['IDpol', 'ClaimNb', 'Exposure']].equals(df_XGB_preds.iloc[:,:3])\nprint(\"Correct: Reasonableness checks have passed for the XGB data\")\nprint(\n    \"Note that, for the XGB data:\\n\"\n    \"\\t-The index has been reset, but we can match to the validation data by IDpol\"\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_ClaimNb_XGB = (df_XGB_preds.pred_ClaimNb * df_validation.reset_index().Exposure).sum()\nprint(f\"XGB predicted total number of claims:\\t{pred_ClaimNb_XGB:.1f}\")\nprint(f\"Actual total number of claims:\\t\\t{act_ClaimNb_validation:.1f}\")\nprint(f\"Difference:\\t\\t\\t\\t{pred_ClaimNb_XGB - act_ClaimNb_validation:.1f}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# From RF\ndf_RF_preds = pd.read_pickle(RF_data_filepath)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assert df_RF_preds.shape[0] == df_validation.shape[0]\nassert (df_RF_preds.index == df_validation.index).all()\nassert (df_RF_preds.ClaimNb == df_validation.ClaimNb).all()\nassert np.max(np.abs(\n    df_RF_preds.Exposure - df_validation.assign(\n        Exp_4dps=lambda x: np.round(x.Exposure, 4)\n    ).Exp_4dps\n)) < 1e-14\nprint(\"Correct: Reasonableness checks have passed for the RF data\")\nprint(\n    \"Note that, for the RF data:\\n\"\n    \"\\t-IDpol is not included but we can match to the validation data by index\\n\"\n    \"\\t-The Exposure field on the RF is rounded to 4dps\"\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_ClaimNb_RF = df_RF_preds['Random Forest Predictions'].sum()\nprint(f\"RF predicted total number of claims:\\t{pred_ClaimNb_RF:.1f}\")\nprint(f\"Actual total number of claims:\\t\\t{act_ClaimNb_validation:.1f}\")\nprint(f\"Difference:\\t\\t\\t\\t{pred_ClaimNb_RF - act_ClaimNb_validation:.1f}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Join data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_validation_all = df_validation.assign(\n    act_freq=lambda x: x.ClaimNb / x.Exposure\n).merge(\n    df_RF_preds.assign(\n        RF_pred_freq=lambda x: x['Random Forest Predictions'] / x.Exposure\n    )[['RF_pred_freq']],\n    how='inner', left_index=True, right_index=True\n).merge(\n    df_GLM_preds.rename(columns={\n        'pred_freq': 'GLM_pred_freq'\n    })[['IDpol', 'GLM_pred_freq']],\n    how='inner', left_on='IDpol', right_on='IDpol'\n).merge(\n    df_XGB_preds.assign(\n        XGB_pred_freq=lambda x: x.pred_ClaimNb / x.Exposure\n    )[['IDpol', 'XGB_pred_freq']],\n    how='inner', left_on='IDpol', right_on='IDpol'\n)\n# Reasonableness checks on the result\nassert df_validation_all.shape[0] == df_validation.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Look at result (excluding explanatory variables)\ndf_validation_all.loc[:, ~df_validation_all.columns.isin(expl_var_names)].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div align=\"right\" style=\"text-align: right\"><a href=\"#Contents\">Back to Contents</a></div>\n\n# Visualise fit"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Lift"},{"metadata":{"trusted":true},"cell_type":"code","source":"stat_cols = ['GLM_pred_freq', 'act_freq']\nlift_plt_data_df = bplt.get_agg_plot_data(\n    df_validation_all,\n    stat_cols=stat_cols,\n    stat_wgt='Exposure',\n    bucket_wgt='Exposure',\n    set_config=\"lift\",\n    n_bins=10\n)\nlift = {\n    stat_col: lift_plt_data_df[stat_col + \"_wgt_av\"].agg(\n        lambda x: x.iloc[-1] / x.iloc[0])\n    for stat_col in stat_cols\n}\nprint(f'Lift on predicted:\\t{lift[stat_cols[0]]:.3f}')\nprint(f'Lift on actuals:\\t{lift[stat_cols[1]]:.3f}')\nlift_plt = bplt.create_plot(lift_plt_data_df, stat_cols=stat_cols)\nshow(lift_plt)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stat_cols = ['RF_pred_freq', 'act_freq']\nlift_plt_data_df = bplt.get_agg_plot_data(\n    df_validation_all,\n    stat_cols=stat_cols,\n    stat_wgt='Exposure',\n    bucket_wgt='Exposure',\n    set_config=\"lift\",\n    n_bins=10\n)\nlift = {\n    stat_col: lift_plt_data_df[stat_col + \"_wgt_av\"].agg(\n        lambda x: x.iloc[-1] / x.iloc[0])\n    for stat_col in stat_cols\n}\nprint(f'Lift on predicted:\\t{lift[stat_cols[0]]:.3f}')\nprint(f'Lift on actuals:\\t{lift[stat_cols[1]]:.3f}')\nlift_plt = bplt.create_plot(lift_plt_data_df, stat_cols=stat_cols)\nshow(lift_plt)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stat_cols = ['XGB_pred_freq', 'act_freq']\nlift_plt_data_df = bplt.get_agg_plot_data(\n    df_validation_all,\n    stat_cols=stat_cols,\n    stat_wgt='Exposure',\n    bucket_wgt='Exposure',\n    set_config=\"lift\",\n    n_bins=10\n)\nlift = {\n    stat_col: lift_plt_data_df[stat_col + \"_wgt_av\"].agg(\n        lambda x: x.iloc[-1] / x.iloc[0])\n    for stat_col in stat_cols\n}\nprint(f'Lift on predicted:\\t{lift[stat_cols[0]]:.3f}')\nprint(f'Lift on actuals:\\t{lift[stat_cols[1]]:.3f}')\nlift_plt = bplt.create_plot(lift_plt_data_df, stat_cols=stat_cols)\nshow(lift_plt)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Recreate Alex F's plots to debug"},{"metadata":{"trusted":true},"cell_type":"code","source":"stat_cols = ['RF_pred_Nb', 'ClaimNb']\nlift_plt_data_df = bplt.get_agg_plot_data(\n    df_validation_all.assign(\n        GLM_pred_Nb=lambda x: x.GLM_pred_freq * x.Exposure,\n        RF_pred_Nb=lambda x: x.RF_pred_freq * x.Exposure,\n        XGB_pred_Nb=lambda x: x.XGB_pred_freq * x.Exposure,\n    ),\n    stat_cols=stat_cols,\n    stat_wgt=None,\n    bucket_wgt='Exposure',\n    order_by=stat_cols[0],\n    cut_by='cum_wgt',\n    #x_axis_var=stat_cols[1],\n    n_bins=10\n)\n\n# Plot actual average against predicted average\nlift_plt = bplt.create_plot(lift_plt_data_df.assign(\n    x_left=lambda x: x[stat_cols[1] + '_wgt_av'],\n    x_right=lambda x: x[stat_cols[1] + '_wgt_av'],\n    x_mid=lambda x: x[stat_cols[1] + '_wgt_av'],\n), stat_cols=stat_cols)\nshow(lift_plt)\n\n# Plot lines of actual average and predicted average\nlift_plt = bplt.create_plot(lift_plt_data_df, stat_cols=stat_cols)\nshow(lift_plt)\n\n# Calculate lift\nlift = {\n    stat_col: lift_plt_data_df[stat_col + \"_wgt_av\"].agg(\n        lambda x: x.iloc[-1] / x.iloc[0])\n    for stat_col in stat_cols\n}\nprint(f'Lift on predicted:\\t{lift[stat_cols[0]]:.3f}')\nprint(f'Lift on actuals:\\t{lift[stat_cols[1]]:.3f}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions_df = df_validation_all.assign(\n    GLM_pred_Nb=lambda x: x.GLM_pred_freq * x.Exposure,\n    RF_pred_Nb=lambda x: x.RF_pred_freq * x.Exposure,\n    XGB_pred_Nb=lambda x: x.XGB_pred_freq * x.Exposure,\n)\nweights_colm = 'Exposure'\npredicted_colm, actual_colm = stat_cols\nq = 10\n\n# Get weighted quantiles and add grouping to the DataFrame\norder = predictions_df[\n    weights_colm  # bucket_wgt\n].iloc[predictions_df[\n    predicted_colm  # order_by\n].argsort()].cumsum()\nquantiles = np.linspace(0, 1, q + 1)\nbins = pd.cut(order / order.iloc[-1], quantiles, labels=False).sort_index()\npredictions_df['weighted_cut'] = bins\npredictions_df.head()\n\npredicted_mean = []\nactual_mean = []\nfor x in np.arange(10):\n    pred = predictions_df[predictions_df['weighted_cut'] == x][predicted_colm].mean()\n    predicted_mean.append(pred)\n    actual = predictions_df[predictions_df['weighted_cut'] == x][actual_colm].mean()\n    actual_mean.append(actual)\n\n# Check on the above\nassert (predictions_df.groupby('weighted_cut').agg(\n    pred=(predicted_colm, 'mean'),\n    actual=(actual_colm, 'mean'),\n    n_rows=('IDpol', 'size'),\n    pred_sum=(predicted_colm, 'sum'),\n    actual_sum=(actual_colm, 'sum'),\n).assign(\n    pred_mean=lambda x: x.pred_sum / x.n_rows,\n    actual_mean=lambda x: x.actual_sum / x.n_rows,\n    diff_pred=lambda x: x.pred_mean - predicted_mean,\n    diff_actual=lambda x: x.actual_mean - actual_mean,\n)[['diff_pred', 'diff_actual']].sum() == [0,0]).all()\n\nmeans = pd.DataFrame(data = list(zip(predicted_mean,actual_mean)), columns = ['predicted','actual'])\n\n# Plot actual average against predicted average\nsns.scatterplot(data=means,x='actual',y='actual')\nsns.scatterplot(data=means, x='actual',y='predicted')\n\n# Calculate lift\na = means.iloc[9]['actual'] / means.iloc[0]['actual']\nb = means.iloc[9]['predicted'] / means.iloc[0]['predicted']\nprint(predicted_colm[:-12], 'actual differentiation', a)\nprint(predicted_colm[:-12], 'model differentiation', b)\nprint(predicted_colm[:-12], 'factor', b/a)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div align=\"right\" style=\"text-align: right\"><a href=\"#Contents\">Back to Contents</a></div>\n\n## Rough work only"},{"metadata":{"trusted":true},"cell_type":"code","source":"stat_cols = ['RF_pred_Nb', 'ClaimNb']\nlift_plt_data_df = bplt.get_agg_plot_data(\n    df_validation_all.assign(\n        GLM_pred_Nb=lambda x: x.GLM_pred_freq * x.Exposure,\n        RF_pred_Nb=lambda x: x.RF_pred_freq * x.Exposure,\n        XGB_pred_Nb=lambda x: x.XGB_pred_freq * x.Exposure,\n    ),\n    stat_cols=stat_cols,\n    stat_wgt=None,\n    bucket_wgt='Exposure',\n    order_by=stat_cols[0],\n    cut_by='cum_wgt',\n    #x_axis_var=stat_cols[1],\n    n_bins=10\n)\n\n# Plot actual average against predicted average\nlift_plt = bplt.create_plot(lift_plt_data_df.assign(\n    x_left=lambda x: x[stat_cols[1] + '_wgt_av'],\n    x_right=lambda x: x[stat_cols[1] + '_wgt_av'],\n    x_mid=lambda x: x[stat_cols[1] + '_wgt_av'],\n), stat_cols=stat_cols)\nshow(lift_plt)\n\n# Plot lines of actual average and predicted average\nlift_plt = bplt.create_plot(lift_plt_data_df, stat_cols=stat_cols)\nshow(lift_plt)\n\n# Calculate lift\nlift = {\n    stat_col: lift_plt_data_df[stat_col + \"_wgt_av\"].agg(\n        lambda x: x.iloc[-1] / x.iloc[0])\n    for stat_col in stat_cols\n}\nprint(f'Lift on predicted:\\t{lift[stat_cols[0]]:.3f}')\nprint(f'Lift on actuals:\\t{lift[stat_cols[1]]:.3f}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Specifying exposure for `xgboost`\nExamples adapted from here: <https://stackoverflow.com/questions/35660588/xgboost-poisson-distribution-with-varying-exposure-offset>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Packages needed for this section\nimport xgboost as xgb\nimport scipy.stats as sps","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Simulate data\nsize = 10000\n\ndf = pd.DataFrame({\n    'x1': sps.randint(low=0, high=2).rvs(size=size, random_state=67),\n    'x2': sps.randint(low=0, high=2).rvs(size=size, random_state=92),\n    'exposure': sps.uniform(loc=1, scale=9).rvs(size=size, random_state=67) * 0.3,\n}).assign(\n    frequency=lambda x: np.where((x.x1 == 1) & (x.x2 == 1), 2, 1),\n    claims=lambda x: sps.poisson(mu=x.frequency * x.exposure).rvs(size=size, random_state=14),\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# xgboost: set up\nparam0 = {\n    \"objective\": \"count:poisson\",\n    \"eval_metric\": \"poisson-nloglik\",\n    \"eta\": 1,\n    \"subsample\": 1,\n    \"colsample_bytree\": 1,\n    \"min_child_weight\": 1,\n    \"max_depth\": 2,\n    \"lambda\": 0,\n}\n\n# It is a simple pattern in the data, \n# so should be able to get close with few rounds\nnum_boost_round = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 1: Try to use the 'weight' argument\nxgtrain1 = xgb.DMatrix(\n    df[['x1', 'x2']],\n    label = df.claims,\n    weight = df.exposure\n)\nxgb_mod1 = xgb.train(\n    dtrain=xgtrain1, params=param0,\n    num_boost_round=num_boost_round,\n)\ndf = df.assign(\n    XGB_P1_Freq=xgb_mod1.predict(xgtrain1),\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 2: Try to set an offset in the DMatrix\nxgtrain2 = xgb.DMatrix(\n    df.assign(\n        offset=lambda x: np.log(x.exposure)\n    )[['x1', 'x2', 'offset']],\n    label = df.claims,\n)\nxgb_mod2 = xgb.train(\n    dtrain=xgtrain2, params=param0,\n    num_boost_round=num_boost_round,\n)\ndf = df.assign(\n    XGB_P2_Freq=xgb_mod2.predict(xgtrain2),\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 3: Try to set base margin as exposure\nxgtrain3 = xgb.DMatrix(\n    df[['x1', 'x2']],\n    label = df.claims,\n)\n\nxgtrain3_w_bm = xgb.DMatrix(\n    df[['x1', 'x2']],\n    label = df.claims,\n)\nxgtrain3_w_bm.set_base_margin(np.log(df.exposure))\n\nassert xgtrain3.get_base_margin().shape[0] == 0\nassert np.max(np.abs(xgtrain3_w_bm.get_base_margin() - np.log(df.exposure))) < 1e-6\n\nxgb_mod3 = xgb.train(\n    dtrain=xgtrain3_w_bm, params=param0,\n    num_boost_round=num_boost_round,\n)\n\ndf = df.assign(\n    # If you do *not* set base margin, the assumption is 0.5 *not* 1\n    XGB_P3_Freq_no_exp=lambda x: xgb_mod3.predict(xgtrain3) / 0.5,\n    XGB_P3_Freq_w_exp=lambda x: xgb_mod3.predict(xgtrain3_w_bm) / x.exposure,\n    \n    XGB_P3_Nb_no_exp=lambda x: x.XGB_P3_Freq_no_exp * x.exposure,\n    XGB_P3_Nb_w_exp=lambda x: x.XGB_P3_Freq_w_exp * x.exposure,\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby(['x1', 'x2']).mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(20, 10))\nxgb.plot_tree(xgb_mod3, num_trees=0, ax=ax)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Conclusions\n- The first two methods (using `weight` or putting the offset in the `DMatrix`) are not the correct way of specifying that the model should use exposure.\n- `base_margin` is the correct way of doing it.\n- With this very simple pattern, `xgboost` would need multiple boosting rounds to replicate it (even though we've set the parameters to try to use the least possible number of rounds).\n- The `base_margin` that is associated with the `DMatrix` *is* considered when passing it to the `xgb.predict()` method. That is, the result is:\n    $$\n    \\exp(\\ln(e_i) + \\eta_i) = \\hat{y}_i\n    $$\n    where $\\ln(e_i)$ is the `base_margin`. This is the number of claims predicted on that obseration. So get the predicted frequency, we therefore need to divide by $e_i$.\n- If no `base_margin` is specified, then the default is **0.5**, not 1 as you might expect."},{"metadata":{},"cell_type":"markdown","source":"## Function that can also return its code"},{"metadata":{"trusted":true},"cell_type":"code","source":"import inspect\nimport textwrap\nimport re\nimport functools","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Example data\nsize = 20\nexample_df = pd.DataFrame({\n    'cat': pd.Series(['A','B'])[sps.randint(low=0, high=2).rvs(size=size, random_state=67)],\n    'field1': np.linspace(1, 10, size),\n    'field2': np.linspace(10, -70, size),\n    'exp': sps.uniform(loc=1, scale=9).rvs(size=size, random_state=67) * 0.3,\n})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We want to put the following into a function with variables.\n# But we also want to be able to extract this query as code.\nexample_df.assign(\n    wgt=lambda x: x.exp,\n    field1_x_exp=lambda x: x.field1 * x.wgt\n).groupby('cat').agg(\n    wgt_sum=('wgt', 'sum'),\n    field1_wgt_sum=('field1_x_exp', 'sum'),\n).assign(\n    field1_wgt_av=lambda x: x.field1_wgt_sum / x.wgt_sum\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Here is the parametrised query\ndf = example_df\nwgt_col = 'exp'\nstat_cols = ['field1']\ncut_by = 'cat'\n\ndf.assign(\n    wgt=lambda x: x[wgt_col],\n    **{\n        stat_col + '_x_exp': \n        lambda x, stat_col=stat_col: x[stat_col] * x.wgt \n        for stat_col in stat_cols\n    },\n).groupby(cut_by).agg(\n    wgt_sum=('wgt', 'sum'),\n    **{\n        stat_col + '_wgt_sum': (\n            stat_col + '_x_exp',\n            'sum'\n        ) for stat_col in stat_cols\n    },\n).assign(\n    **{\n        stat_col + '_wgt_av': \n        lambda x, stat_col=stat_col: x[stat_col + '_wgt_sum'] / x.wgt_sum \n        for stat_col in stat_cols\n    },\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_assign_dict(assign_dict, dict_name, replacement_dict):\n    replace = \"**\" + dict_name\n    replace_with = ',\\n    '.join([\n        key + \"=\" + inspect.getsource(val).strip(\n        ).replace(\n            \"stat_col\", f\"'{key}'\"\n        ).replace(\n            f\", '{key}'='{key}'\", \"\"\n        )\n        for key, val in assign_dict.items()\n    ])\n    replacement_dict[replace] = replace_with\n    return(assign_dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_inner_code(\n    func,\n    from_after_re=r'#\\s*<Query begin>.*\\n',\n    to_before_re=r'\\n\\s*#\\s*<Query end>',\n):\n    code_raw_str = inspect.getsource(get_wgt_av)\n    \n    # Remove the first row, and de-indent the remainder\n    code_body_str = textwrap.dedent(\n        re.sub(r'.+:\\n', r'', code_raw_str)\n    )\n    \n    # Find the specified start and end patterns\n    from_idx = re.search(from_after_re, code_body_str).end()\n    to_idx = re.search(to_before_re, code_body_str).start()\n    \n    return(code_body_str[from_idx:to_idx])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Put it in a function\ndef get_wgt_av(df, wgt_col, stat_cols, cut_by=None, return_code=False):\n    # Capture the arg names. Must do this first\n    arg_names = list(locals().keys())\n    \n    # Set default parameter values\n    if cut_by is None:\n        cut_by = 'cat'\n    \n    # Create dictionary to map argument names to string values\n    replacement_dict = dict()\n    for var_name in arg_names:\n        var_val = locals()[var_name]\n        if var_name in ['df']:\n            continue\n        if isinstance(var_val, str):\n            replacement_dict[var_name] = f\"'{var_val}'\"\n            continue\n        replacement_dict[var_name] = var_val\n    \n    # Unpack iterable arguments\n    extra_cols_on_input_df = {\n        stat_col + '_x_exp': \n        lambda x, stat_col=stat_col: x[stat_col] * x.wgt \n        for stat_col in stat_cols\n    }\n    replacement_dict['**extra_cols_on_input_df'] = ',\\n    '.join([\n        f\"{stat_col}_x_exp=\"\n        f\"lambda x: x['{stat_col}'] * x.wgt\"\n        for stat_col in stat_cols\n    ])\n    \n    agg_cols = {\n        stat_col + '_wgt_sum': (\n            stat_col + '_x_exp', 'sum'\n        ) for stat_col in stat_cols\n    }\n    replacement_dict['**agg_cols'] = ',\\n    '.join([\n        f\"{stat_col}_wgt_sum=\"\n        f\"('{stat_col}_x_exp', 'sum')\"\n        for stat_col in stat_cols\n    ])\n    \n    extra_cols_on_result = {\n        stat_col + '_wgt_av': \n        lambda x, stat_col=stat_col: x[stat_col + '_wgt_sum'] / x.wgt_sum \n        for stat_col in stat_cols\n    }\n    replacement_dict['**extra_cols_on_result'] = ',\\n    '.join([\n        f\"{stat_col}_wgt_av=\"\n        f\"lambda x: x['{stat_col}_wgt_sum'] / x.wgt_sum\"\n        for stat_col in stat_cols\n    ])\n    \n    # If we're just getting the code, no need to run the query below\n    if return_code:\n        query_code = get_inner_code(get_wgt_av)\n        code_w_vals = functools.reduce(\n            lambda code_str, arg_item: code_str.replace(*arg_item),\n            {key: str(val) for key, val in replacement_dict.items()}.items(),\n            query_code\n        )\n        return(code_w_vals)\n    \n    # <Query begin> # (This is a special command, do not modify)\n    res = df.assign(\n        wgt=lambda x: x[wgt_col],\n        **extra_cols_on_input_df,\n    ).groupby(cut_by).agg(\n        wgt_sum=('wgt', 'sum'),\n        **agg_cols,\n    ).assign(\n        **extra_cols_on_result,\n    )\n    # <Query end> # (This is a special command, do not modify)\n    return(res)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Test it works\ncode_example = get_wgt_av(\n    df = example_df,\n    wgt_col = 'exp',\n    stat_cols = ['field1'],\n    cut_by = 'cat',\n    return_code=True\n)\nprint(code_example)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"run_this_chunk = True\nif run_this_chunk:\n    exec(code_example)\n    assert res.equals(get_wgt_av(\n        df = example_df,\n        wgt_col = 'exp',\n        stat_cols = ['field1'],\n        cut_by = 'cat',\n    ))\n    print(\"Correct: Evaluated string equals function result\")\n    display(res)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Another test\nparams = {\n    'wgt_col': 'exp',\n    'stat_cols': ['field1', 'field2'],\n    'cut_by': 'cat'\n}\ncode_example2 = get_wgt_av(\n    df = example_df,\n    **params,\n    return_code=True\n)\nprint(code_example2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"run_this_chunk = True\nif run_this_chunk:\n    exec(code_example2)\n    assert res.equals(get_wgt_av(\n        df = example_df,\n        **params,\n    ))\n    print(\"Correct: Evaluated string equals function result\")\n    display(res)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div align=\"right\" style=\"text-align: right\"><a href=\"#Contents\">Back to Contents</a></div>"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}