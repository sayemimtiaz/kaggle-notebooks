{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h1>Mall customers dataset </h1>\n\n<h4> The aim of this exercise is to segment the customers based on their age, gender, and interest. This is called \"Customer segmentation\" and is an important practise of dividing customers based on individual groups that are similar. It is useful in customised marketing.</h4>\n\n<h4>Customer segmentation</h4>\n<p>Customer Segmentation is the process of division of customer base into several groups of individuals that share a similarity in different ways that are relevant to marketing such as gender, age, interests, and miscellaneous spending habits.\n\nCompanies that deploy customer segmentation are under the notion that every customer has different requirements and require a specific marketing effort to address them appropriately. Companies aim to gain a deeper approach of the customer they are targeting. Therefore, their aim has to be specific and should be tailored to address the requirements of each and every individual customer. Furthermore, through the data collected, companies can gain a deeper understanding of customer preferences as well as the requirements for discovering valuable segments that would reap them maximum profit. This way, they can strategize their marketing techniques more efficiently and minimize the possibility of risk to their investment.\n\nThe technique of customer segmentation is dependent on several key differentiators that divide customers into groups to be targeted. Data related to demographics, geography, economic status as well as behavioral patterns play a crucial role in determining the company direction towards addressing the various segments.</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt \nfrom sklearn.cluster import KMeans \nfrom sklearn.metrics import silhouette_score\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cust = pd.read_csv('/kaggle/input/mall-customers/Mall_Customers.csv')\ncust.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Let's fist do basic visualisation to understand the data and the distribution of the different variables"},{"metadata":{},"cell_type":"markdown","source":"#### Gender"},{"metadata":{"trusted":true},"cell_type":"code","source":"#let's look at the men and women via histogram\n\nsns.countplot(x='Genre', data=cust)\nplt.title('Customer Gender')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#to make a piechart:\ngender=cust.Genre.value_counts()\ngender_label=['Female','Male']\nplt.pie(gender, labels=gender_label, autopct='%0.2f%%',startangle=90)\nplt.title('Distribution of men and women within the customers of the JCPenney')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Age distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"#let's see the max and min of ages\ncust.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p>The minimum age is 18 and the maximum is 70. We can create 6 bins to group people by age group. Each bin could represent 10 years</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"bin_list=[10,20,30,40,50,60,70]\nplt.hist(cust['Age'], bins=bin_list, rwidth=0.9)\nplt.xlabel('Age')\nplt.ylabel('frequency')\nplt.title('Age distribution of customers')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Annual income of customers"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(cust['Annual Income (k$)'], bins=12, rwidth=0.9)\nplt.xlabel(\"Income in 1000's of $\")\nplt.ylabel(\"frequency\")\nplt.title('Annual income of customers')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Spending score of the customers"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(cust['Spending Score (1-100)'], bins=[0,10,20,30,40,50,60,70,80,90,100], rwidth=0.9)\nplt.xlabel(\"Spending score\")\nplt.ylabel(\"frequency\")\nplt.title('Spending Score of customers')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p>The gender in this dataset is a categorical variable. k-means algorithm isn't directly applicable to categorical variables because Euclidean distance function isn't really meaningful for discrete variables. So, lets change these variables and transform them to an indicator variable (or dummy variable). This is a numerical variable used to label categories. They are called 'dummies' because the numbers themselves don't have inherent meaning. In our case, let's change male to \"0\" and female to \"1\".</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#let's also drop the customer ID because it's not important\ncust.drop(\"CustomerID\", axis = 1, inplace=True)\n#cust.drop(\"Genre\", axis = 1, inplace=True)\n\n\ncust[\"Genre\"].replace(\"Male\", 0, inplace=True)\ncust[\"Genre\"].replace(\"Female\", 1, inplace=True)\ncust","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Modelling"},{"metadata":{},"cell_type":"markdown","source":"### Let's start by visualising the relationship between different variable groups.\n<p>We are interested primarily in those who have a high spending score because this is the category we want to keep as customers for the mall. So let's check if there is a relationship between age and spending score, and annual income and spending score.</p>"},{"metadata":{},"cell_type":"markdown","source":"### Gender and spending"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(cust['Genre'], cust['Spending Score (1-100)'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p>It's hard to see clusters or relationships in this graph. That's mainly because the gender category has two distinct variables. Therefore, we will remove the gender from our analysis in order to make it simpler.</p>"},{"metadata":{},"cell_type":"markdown","source":"### Age and spending"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(cust['Age'], cust['Spending Score (1-100)'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p>It appears that there is some sort of correlation between being younger (less than 35 yo) and spending more, while the relatively older people are spending less than 60%. This graphs shows therefore 2 clusters.\n</p>"},{"metadata":{},"cell_type":"markdown","source":"### Income and spending"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(cust['Annual Income (k$)'], cust['Spending Score (1-100)'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p>In this graph, however, it's obvious that there are 5 groups, or clusters, in this dataset if we compare annual income and the spending score, and this is probably what we are interested in seing. Let's evaluate this more below.</p>"},{"metadata":{},"cell_type":"markdown","source":"## K-mean clustering\n\n<p>Lets apply k-means on our dataset, and take look at cluster labels.</p>\n\nThe KMeans class has many parameters that can be used, but we will be using these three:\n\n<ul>\n    <li> <b>init</b>: Initialization method of the centroids. </li>\n    <ul>\n        <li> Value will be: \"k-means++\" </li>\n        <li> k-means++: Selects initial cluster centers for k-mean clustering in a smart way to speed up convergence.</li>\n    </ul>\n    <li> <b>n_clusters</b>: The number of clusters to form as well as the number of centroids to generate. </li>\n    <ul> <li> Value will be: 5 (we can change this anytime if we want to test more values)</li> </ul>\n    <li> <b>n_init</b>: Number of time the k-means algorithm will be run with different centroid seeds. The final results will be the best output of n_init consecutive runs in terms of inertia. </li>\n    <ul> <li> Value will be: automatic but can be chosen if needed </li> </ul>\n</ul>\n\nLet's initialize KMeans with these parameters, where the output parameter is called <b>k_means</b>."},{"metadata":{},"cell_type":"markdown","source":"### Age vs spending clustering\n<p>Let's test cluster number 2 to verify what we saw in the 'Age' vs 'Spending score' graph.\nFirst, we will only keep the Age and the Spending score column to simplify the dimensions and keep them in 2D.\n</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's have a new dataframe first with only the Age and the spending score\n\ncust_age=cust.drop([\"Annual Income (k$)\", \"Genre\"], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#we can test a cluster number 2 to verify what we saw in the 'Age' vs 'Spending score' graph. \n#However, we will use 4 clusters here as we saw in the elbow plot that 4 is the optimal number. See below\n\nk_means_age=KMeans(n_clusters=4)\n\n#We can also use this code below in case we want to determine the n_init number\n#k_means = KMeans(init = \"k-means++\", n_clusters = clusterNum, n_init = 20)\n\nk_means_age.fit(cust_age)\nlabels = k_means_age.labels_\nprint(labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p>Let's see where is the location of the centers"},{"metadata":{"trusted":true},"cell_type":"code","source":"centers_age=k_means_age.cluster_centers_\ncenters_age","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p>Let's plot a graph to visualise this relationship "},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 8))\n\nplt.scatter(cust_age['Age'], \n            cust_age['Spending Score (1-100)'], \n            c=k_means_age.labels_, s=100)\n\nplt.scatter(centers_age[:,0], centers_age[:,1], color='blue', marker='s', s=200) \n\nplt.xlabel('Age')\nplt.ylabel('Spending Score')\nplt.title('K-Means with 2 clusters')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's measure the silhouette score of this clustering:\n\nThe silhouette value is a measure of how similar an object is to its own cluster (cohesion) compared to other clusters (separation). The silhouette ranges from âˆ’1 to +1, where a high value indicates that the object is well matched to its own cluster and poorly matched to neighboring clusters. If most objects have a high value, then the clustering configuration is appropriate. If many points have a low or negative value, then the clustering configuration may have too many or too few clusters."},{"metadata":{"trusted":true},"cell_type":"code","source":"score = silhouette_score (cust_age, k_means_age.labels_)\n\nprint(\"The score is = \", score)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p>This graph shows that we can have 4 clusters based on the Age and the spending score. Therefore, we can have 4 groups:\n    <ul>\n        <li>Younger people with high spending score</li>\n        <li>younger people with average spending score</li>\n        <li>People with low spending score of less that 60 that belong to all age groups</li>\n        <li>Older people with average spending score.</li>\n    </ul>\nThe score of 0.5 is good. Let's see if we can get it higher."},{"metadata":{},"cell_type":"markdown","source":"Let's what is the optimal number of clusters by constructing an elbow plot"},{"metadata":{"trusted":true},"cell_type":"code","source":"elbowlist1 = []\nfor i in range(1,15): \n    k_means_age = KMeans(n_clusters=i, init=\"k-means++\",random_state=0)\n    k_means_age.fit(cust_age)\n    elbowlist1.append(k_means_age.inertia_)  \n\nplt.plot(range(1,15),elbowlist1,marker=\"*\",c=\"black\")\nplt.title(\"Elbow plot for optimal number of clusters: age and spending\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we can make sure that the cluster number 4 that we chose is correct. The elbow plot has a distinct slope break at 4 indicating that 4 is the optimal cluster number when comparing between age and spending. It's good to construct this plot to make sure that the analysis is ok. We can rerun our analysis by updating the number of clusters based on this plot."},{"metadata":{},"cell_type":"markdown","source":"### Annual income vs spending clustering\n<p>Let's test now cluster number 5 to verify what we saw in the 'Annual income' vs 'Spending score' graph.\nFirst, we will only keep the Annual income and the Spending score columns to simplify the dimensions and keep them in 2D.\n</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#we drop the annual income column\ncust_income=cust.drop([\"Age\", \"Genre\"], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#let's test cluster number 2 to verify what we saw in the 'Age' vs 'Spending score' graph.\n\nk_means_income=KMeans(n_clusters=5)\n\n#We can also use this code below in case we want to determine the n_init number\n#k_means = KMeans(init = \"k-means++\", n_clusters = clusterNum, n_init = 20)\n\nk_means_income.fit(cust_income)\nlabels = k_means_income.labels_\nprint(labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p>Let's see where is the location of the centers"},{"metadata":{"trusted":true},"cell_type":"code","source":"centers_income=k_means_income.cluster_centers_\ncenters_income","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p>Let's plot a graph to visualise this relationship "},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 8))\n\nplt.scatter(cust_income['Annual Income (k$)'], \n            cust_income['Spending Score (1-100)'], \n            c=k_means_income.labels_, s=100)\n\nplt.scatter(centers_income[:,0], centers_income[:,1], color='blue', marker='s', s=200) \n\nplt.xlabel('Annual Income in K$')\nplt.ylabel('Spending Score')\nplt.title('K-Means with 5 clusters')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score_2 = silhouette_score (cust_income, k_means_income.labels_)\n\nprint(\"The score is = \", score_2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p>Here we can see in a much clearer way that there are 5 different clusters belonging to five different groups:\n    <ul>\n        <li>Low annual income and high spending score --> Interesting category</li>\n        <li>High annual income and high spending score --> interesting category</li>\n        <li>Low annual income and low spending score --> Not interesting at all </li>\n        <li>High annual income and low spending score </li>\n        <li>Middge annual income and middle spending score </li>\n    </ul>\n    \nHere we have silhouette score of 0.55 which is better than before. That means that this clustering fits better than the age vs spending one calculated above.\n</p>"},{"metadata":{},"cell_type":"markdown","source":"Let's just make sure that 5 is a good number of clusters by constructing an elbow plot"},{"metadata":{"trusted":true},"cell_type":"code","source":"elbowlist2 = []\nfor i in range(1,15): \n    k_means_income = KMeans(n_clusters=i, init=\"k-means++\",random_state=0)\n    k_means_income.fit(cust_income)\n    elbowlist2.append(k_means_income.inertia_)  \n\nplt.plot(range(1,15),elbowlist2,marker=\"*\",c=\"black\")\nplt.title(\"Elbow plot for optimal number of clusters: income and spending\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we can make sure that the cluster number 5 that we chose is correct. The elbow plot has a distinct slope break at 5 indicating that 5 is the optimal cluster number when comparing between income and spending."},{"metadata":{},"cell_type":"markdown","source":"#### Visualise the gender distribution in this clustering\n<p>However, we might be interested to see if gender plays a role in this classification. We will therefore color some blobs by gender."},{"metadata":{"trusted":true},"cell_type":"code","source":"ax=plt.figure(figsize=(10, 8))\n\nscatter=plt.scatter(cust_income['Annual Income (k$)'], \n            cust_income['Spending Score (1-100)'], \n            c=cust['Genre'], s=100)\n\nplt.scatter(centers_income[:,0], centers_income[:,1], color='blue', marker='s', s=200) \n\nlegend1 = ax.legend(*scatter.legend_elements(), loc=\"right\", title=\"Gender\")\nax.add_artist(legend1)\n\nplt.xlabel('Annual Income in K$')\nplt.ylabel('Spending Score')\nplt.title('K-Means with 5 clusters')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<P>There isn't much difference between gender. One can argue that females might have a higher spending score than men because there are relatively more yellow than purple in the high spending score categories. However, note that there are more females in this dataset than men (56% against 44%) so it's normal to have more females in this graph. Therefore, the gender does not have a noticeable role in this classification.\n    \nRemember:\n<ul>\n    <li>male = 0 </li>\n    <li>Female = 1 </li>"},{"metadata":{},"cell_type":"markdown","source":"### Evaluating both age and annual income on clustering\n\n<p>We will use three dimensions for this analysis and visualise results in a 3D graph. We will have an interactive 3D graph to help with visualisation."},{"metadata":{"trusted":true},"cell_type":"code","source":"#we drop the gender column\n\ncust_3D=cust.drop(\"Genre\", axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"k_means_3D=KMeans(n_clusters=5)\n\n#We can also use this code below in case we want to determine the n_init number\n#k_means = KMeans(init = \"k-means++\", n_clusters = clusterNum, n_init = 20)\n\nk_means_3D.fit(cust_3D)\nlabels = k_means_3D.labels_\nprint(labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"centers_3D=k_means_3D.cluster_centers_\ncenters_3D","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib import interactive\ninteractive(True)\n\n%matplotlib qt\n\nfrom mpl_toolkits.mplot3d import Axes3D \nfig = plt.figure(1, figsize=(8, 6))\nplt.clf()\nax = Axes3D(fig, rect=[0, 0, .95, 1], elev=48, azim=134)\n\nplt.cla()\n#plt.ylabel('Age', fontsize=18)\n#plt.xlabel('Income', fontsize=16)\n#plt.zlabel('Education', fontsize=16)\nax.set_xlabel('Age')\nax.set_ylabel('Income in 1000s $')\nax.set_zlabel('Spending')\n\nax.scatter(cust_3D['Age'], cust_3D['Annual Income (k$)'], cust_3D['Spending Score (1-100)'], c= labels.astype(np.float), s=200)\n\n#note that it will open in a separate window. Drag the graph and rotate with your mouse to see the results interactively.\n\n#better to download it to your own computer to visualise it properly\n\n#%matplotlib inline    #to add after finishing to go back to charts inside the notebook.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's just make sure that 5 is the optimal number of clusters by constructing an elbow plot"},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline   \n\nelbowlist3 = []\nfor i in range(1,15): \n    k_means_3D = KMeans(n_clusters=i, init=\"k-means++\",random_state=0)\n    k_means_3D.fit(cust_income)\n    elbowlist3.append(k_means_3D.inertia_)  \n\nplt.plot(range(1,15),elbowlist3,marker=\"*\",c=\"black\")\nplt.title(\"Elbow plot for optimal number of clusters: age, income and spending\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here as well we can notice that the cluster number 5 that we chose is correct. The elbow plot has a distinct slope break at 5 indicating that 5 is the optimal cluster number when comparing between age, income and spending."},{"metadata":{"trusted":true},"cell_type":"code","source":"score_3 = silhouette_score (cust_3D, k_means_3D.labels_)\n\nprint(\"The score is = \", score_3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p>The 3D graph is highly informative because we can visualise 3 dimensions in a single graph. Usually, using multiple dimensions in clustering is very challeging, but here we succeeded in visualising 3 dimensions by using a 3D graph. In this case, we linked the age, the income and the spending and we got better results. The 5 customer segments that use the mall are as follow:    \n    <ul>\n        <li>Young (20-40 yo) , high income and high spending (yellow)</li>\n        <li>Young (15 to 30 yo), low income and high spending (purple)</li>\n        <li>High income and low spending, they don't have a specific age group (light blue)</li>\n        <li>Low income and low spending, they don't have a specific age group (green)</li>\n        <li>Average income, average spending, they don't have a specific age group (dark blue)</li>\n    </ul>\n        \n*note that young is considered here as being less than 40\n\nIn this cluster model, we have a silhouete score of 0.44. This is less than the previous scores we had. This might be, however, due to the fact that we are measuring in a 3D environment, where the distance between the data points and the origin of the coordinate system grows as a square root of the number of dimensions D. Consequently, the mean distance between data points diverges and looses its meaning which in turn leads to the divergence of the Euclidean distance, the most common distance used for clustering. Therefore, it is better to neglect the fact that this score is the least in our examples. \n\n--> --> --> Check that nice article by Nikolay Oskolkov on high dimension clustering: https://towardsdatascience.com/how-to-cluster-in-high-dimensions-4ef693bacc6\n\n        "},{"metadata":{},"cell_type":"markdown","source":"## Summary\n\n<p>K-mean clustering has been performed over a mall customer dataset to classify customers into different segments. Five customer segments were found having different age, income and spending trends. In order to make it better for the mall management to retain customers and increase sales, it is recommended that management focuses on retaining the following segments:\n<ul>\n    <li>Rich and high spending people between their 20 and 40's</li>\n    <li>Relatively poor and high spending people between their 15 and 30's</li>\n    </ul>"},{"metadata":{},"cell_type":"markdown","source":"## If you like this notebook, please upvote"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}