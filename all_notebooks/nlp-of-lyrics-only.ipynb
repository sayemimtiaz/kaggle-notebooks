{"cells":[{"metadata":{},"cell_type":"markdown","source":"#### In this project, I scraped a popular guitar tab website, Ultimate-Guitar.com, to analyze lyrics and chords from popular songs in various genres. \n\n#### I have a few dozen guitar students, and when songwriting comes up, I always stipulate that I am not great at writing lyrics. I usually try to help the students find a variety of words or phrases that they can later begin to stitch together into something cohesive.  \n\n#### The goal of this project was to analyze popular lyrics in order to find a set of lyric writing \"parameters\". \n#### For example: \"A verse usually has x number of words, k fraction of are usually nouns, j fraction are verbs, ect. You want so many of them to be objective, so many of them positive. Here are some examples of objective or positive words, here are some examples of common verbs, nouns, etc. that are used in a song, are here are some common 'filler' phrases.\" \n\n#### I analyzed all the collected lyrics together, then analyzed them by genre to see if there were any genre-specific patterns. I found the number of unique words per song-part to be the biggest statistical difference (e.g. Hip-hop lyrics uses many more unique words in a verse than Pop lyrics). However, the differences in sentiment and part of speech (p.o.s.) content to be minute. This may be an artifact of the TextBlob dictionary, or might be a reflection of the English language. There was a significant difference in the unique common words and phrases, and the examples for subjectivity and polarity. \n\n#### After finding these 'parameters', I will create a sort of lyric-writing check list, which a student can fill out to help generate more words on a page to start stitching together into more complete lyrics. \n\n#### Improvements can be made. The genre for many chord charts on Ultimate-Guitar.com aren't labeled correctly ('Somewhere Over the Rainbow' is NOT a Country song). In the future I plan to try to find another resource to get the genre labels for specific artists and replace the current ones. I also plan to add the ability to scrape all the songs for a specific artist so I can analyze their writing style"},{"metadata":{},"cell_type":"markdown","source":"## Load and install necessary packages"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport matplotlib.gridspec as gridspec\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n\n!pip install requests-html\n!pip install -U textblob\n!python -m textblob.download_corpora\n!pip install wordcloud\n\nfrom requests_html import AsyncHTMLSession, HTMLSession\nfrom textblob import TextBlob\nimport nltk\nfrom nltk.corpus import stopwords\nfrom wordcloud import WordCloud, STOPWORDS\n\n\nnltk.download('wordnet')\nnltk.download('brown')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Functions to be used"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create function that scrapes links to songs\n\n\nasync def get_song_links(song_html):\n    '''Takes in a list of links that point to \n       Ultimate Guitar's top searched songs, \n       returns a list of links to specific songs.'''\n    \n    \n    #grabs html elements\n    asession = AsyncHTMLSession()\n\n    r = await asession.get(song_html)\n    await r.html.arender()\n    links = r.html.find('a[href*=\"tabs.\"]')\n\n\n    #parses out links and adds them to list\n    list_o_links = []\n\n    for elem in links:\n        link = str(elem).split(\"'\")[-2]\n        list_o_links.append(link)\n    \n    #closes\n    await asession.close()\n\n    return list_o_links","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def split_lyrics_chords(html_main_body, all_chords):\n    \n    \"\"\"Takes html of main body of the chord chart, \n    separates the html into the parts for each song, \n    then separates the chords from the lyrics\"\"\"\n    \n    #Grab name of each part, then lyrics and chords in each part\n    song_part = []\n    part_range = []\n    part_body = []\n    part_chords = []\n    part_lyrics = []\n\n    for i, item in enumerate(html_main_body):\n        part_body = []\n        #Grabs part name, and the index of that part name\n        if not item.find(\"[\"):\n            song_part.append(item.replace('[', '').replace(']', ''))\n            part_range.append(i)\n        else: continue\n\n    #Use the index of each part name to grab lines between them       \n    for i in range(len(part_range)):\n\n\n        low_range = part_range[i]+1\n\n        if i+1 < len(part_range):\n            high_range = part_range[i+1]\n            part_body.append(html_main_body[low_range:high_range])\n        else:\n            part_body.append(html_main_body[low_range:])\n\n    #Separates chords from lyrics        \n    for part in part_body:\n        chords = []\n        lyrics = []\n        for i, line in enumerate(part):\n            line_list = line.split(' ')\n\n            crd = [x for x in all_chords if x in line_list] \n\n            if len(crd) > 0:\n                fixed_list = []\n                for chord in line.split(' '):\n\n\n                    if \"/\" in chord:\n                        fixed_list.append(chord.split('/')[0])\n                    else:\n                        fixed_list.append(chord)\n\n                fixed_line = ' '.join(fixed_list)\n\n                chords.append(fixed_line)\n\n            else:     \n\n                lyrics.append(line)\n\n        #removes unnecessary symbols\n        chords = \" \".join(chords).replace(',', '').replace('|', '').replace('*', '').replace('/', '')\n        lyrics = \" \".join(lyrics).replace(',', '').replace('|', '').replace(\"'\", '')\n\n        part_chords.append(chords)\n\n        if '---' in lyrics:\n\n            part_lyrics.append('')\n        else:\n            part_lyrics.append(lyrics)\n                \n                \n    return {'Part': song_part, 'Chords': part_chords, 'Lyrics': part_lyrics }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"async def get_song_dataframe(html, genre):\n    \n    \"\"\"Takes in html for a song's chord chart and the genre of the song,\n    parses out the song's title, artist, lyrics, chords, and the \n    part-of-song labels, combines with song genre and returns a dataframe\"\"\"\n    \n    #Grab html from javascript page\n    asession = AsyncHTMLSession()\n\n    r = await asession.get(html)\n    await r.html.arender(timeout=20)\n    \n\n    #Extract the main body of text\n\n    elements = r.html.find(\"span._1zlI0\")\n    \n    await asession.close()\n    main_body = []\n    for elem in elements:\n        main_body.append(elem.text)\n        \n    #Extract list of all the chords in the song\n    elements = r.html.find('header._2jxI1')\n    \n    song_chordlist = []\n    for elem in elements:\n        song_chordlist.append(elem.text)\n    song_chordlist.append('N.C.')\n\n    #Extract Title and Artist of the song\n    header = r.html.find('title')[0].text\n    song_title = header.split(' CHORDS')[0]\n    song_artist = header.split('by ')[1].split(' @')[0]\n\n\n    parts_chords_lyrics = split_lyrics_chords(main_body, song_chordlist)\n    song_part = parts_chords_lyrics['Part']\n    part_chords = parts_chords_lyrics['Chords']\n    part_lyrics = parts_chords_lyrics['Lyrics']\n\n    #Create dataframe\n    song_list = []\n\n    for i, part in enumerate(song_part):\n        if part_chords[i]:\n\n            partchords = part_chords[i]\n\n\n\n        else:\n            partchords = ''\n\n\n        song_dict = {'Song Artist':song_artist, 'Song Title': song_title, 'Part': part.lower(), 'Chords':partchords, 'Lyrics':part_lyrics[i].replace(\"â€™\", ''), 'Genre': genre}  \n        song_list.append(song_dict)\n\n        \n    dflist = pd.DataFrame(song_list)\n\n    return dflist.replace('  ', np.nan).replace(' ', np.nan).replace('', np.nan)\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef get_pol_sub_scores(lyric_list):\n    \n    \"\"\"Takes in a list of lyrics, then uses TextBlob\n    to analyze the sentiment of the lyrics, returns dataframe\n    with: \n    \n    Polarity - 1 for positive lyrics, -1 for negative lyrics\n    \n    Subjectivity - 0 for facts, 1 for opinions\n    \n    Words- the words analyzed for the scoring, and their respective scores\"\"\"\n    \n    \n    sentiments_list_of_dicts = []\n    \n    \n    for lyrics in lyric_list:\n        blob = TextBlob(str(lyrics))\n        sentiment = blob.sentiment_assessments\n        pol = sentiment[0]\n        sub = sentiment[1]\n        words = sentiment[2]\n\n        sentiment_dict = {'Polarity':pol, \"Subjectivity\":sub, \"Words\":words}\n        \n        sentiments_list_of_dicts.append(sentiment_dict)\n        \n    return  pd.DataFrame(sentiments_list_of_dicts)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ndef get_pos_tags(lyric_list):\n    \n    \"\"\"Takes a list of lyrics, removes common words, \n    then tags each word with its part of speech (p.o.s.) label,\n    returns a dataframe with the word and its label.\"\"\"\n    \n    #list of common words in english\n    stop_words = stopwords.words('english')\n    \n    tags_list_of_dicts = []\n    \n    for lyrics in lyric_list:\n        blob = TextBlob(str(lyrics))\n        part_tags = blob.tags\n        \n        for tags in part_tags:\n        \n            word = tags[0].lower()\n            tag = tags[1]\n\n\n            if word in stop_words:\n                continue\n\n            elif len(tags_list_of_dicts) > 0:\n                if word.lower() == tags_list_of_dicts[-1]['Word'].lower():\n                    continue\n                else:\n                    tag_dict = {'Word': word, 'Tag': tag}\n                    tags_list_of_dicts.append(tag_dict)\n            else:\n                tag_dict = {'Word': word, 'Tag': tag}\n                tags_list_of_dicts.append(tag_dict)\n\n    return pd.DataFrame(tags_list_of_dicts)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_pos_count_df(lyric_list):\n    \n    \"\"\"Takes a list of lyrics, counts instances of \n    nouns, verbs, adjectives, and adverbs. \n    Returns a dataframe with the percentage of \n    each part of speech in the total words counted.\"\"\"\n    \n    #list of words to skip over\n    stop_words = stopwords.words('english')\n    \n    \n    #selection of p.o.s. tags to count\n    noun_list = ['NN', 'NNS']\n    verb_list = [ 'VB', 'VBD', 'VBG', 'VBN', ]\n    adj_list = ['JJ', 'JJR', 'JJS',]\n    adverb_list = ['RB', 'RBR', 'RBS']\n\n\n    tags_list_of_dicts = []\n\n    for lyrics in lyric_list:\n\n        nouncount = 0\n        verbcount = 0\n        adjcount = 0\n        adverbcount = 0\n        \n        #Create textblob object to access tags\n        blob = TextBlob(str(lyrics))\n        part_tags = blob.tags\n\n        for tags in part_tags:\n\n            word = tags[0].lower()\n            tag = tags[1]\n\n            #Don't count if word is in stopwords\n            if (word in stop_words):\n                continue\n\n            else :\n                if tag in noun_list:\n                    nouncount = nouncount + 1\n\n                elif tag in verb_list:\n                    verbcount = verbcount + 1\n\n                elif tag in adj_list:\n                    adjcount = adjcount + 1\n\n                elif tag in adverb_list:\n                    adverbcount = adverbcount + 1\n        \n        total = nouncount + verbcount + adjcount + adverbcount \n        \n        #avoid division by zero\n        if total > 0:\n            \n            total_words_counted = total\n        else:\n            total_words_counted = 1\n            \n              \n\n        #create dictionary and append it to list\n        tag_dict = { 'Noun':nouncount/total_words_counted , 'Verb': verbcount/total_words_counted, 'Adjective': adjcount/total_words_counted, 'Adverb': adverbcount/total_words_counted}\n        tags_list_of_dicts.append(tag_dict)\n        \n    #Create data frame from list of dictionaries\n    df = pd.DataFrame(tags_list_of_dicts)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_common_pos_df(tags_df, sample_size=5, genre=np.nan):\n    \n    \"\"\"\"This function takes in a dataframe of words and their part of speech tag, and returns a dataframe \n    where each row contains the word, the frequency of the word, the p.o.s. tag, and the genre of the song \"\"\"\n    \n    #filters specific pos tags\n    noun = tags_df[(tags_df.Tag == 'NN') | (tags_df.Tag == 'NNS')]\n    verb = tags_df[(tags_df.Tag == 'VB') | (tags_df.Tag == 'VBD') | (tags_df.Tag == 'VBG') | (tags_df.Tag == 'VBN')]\n    adjective = tags_df[(tags_df.Tag == 'JJ') | (tags_df.Tag == 'JJR') | (tags_df.Tag == 'JJS')]\n    adverb = tags_df[(tags_df.Tag == 'RB') | (tags_df.Tag == 'RBR') | (tags_df.Tag == 'RBS')]\n    \n    pos_list = [noun, verb, adjective, adverb]\n    pos_names = ['noun', 'verb', 'adjective', 'adverb']\n    \n    list_of_dicts = []\n    \n   \n    for pos, name in zip(pos_list, pos_names):\n        \n        \n        top_list = pos.Word.value_counts().head(sample_size)\n        for i in range(len(top_list)):\n            word = top_list.index.values[i]\n            count = top_list[i]\n            \n            pos_dict = {'Word': word, 'Count':count, 'POS': name, 'Genre': genre}\n            list_of_dicts.append(pos_dict)\n            \n    return pd.DataFrame(list_of_dicts)\n \n\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_sentiment_examples(df, sentiment,  statistic):\n    \"\"\"Takes a dataframe and choice of statistic, \n    returns a string of lyrics that matches the score\n    of the specified statistic (min, mean, or max)\"\"\"\n    \n    df = df\n    \n    if sentiment == 'Subjectivity':\n        \n        series_sent = df.Subjectivity\n        \n        if statistic == 'min':\n        \n            value = series_sent.min()\n            \n        elif statistic == 'max':\n        \n            value = series_sent.max()\n            \n        elif statistic == 'mean':\n            \n            value = series_sent.mean()\n            \n        else: return \"check statistic argument\"\n            \n            \n        new_df = df[(df.Subjectivity >= (value - 0.3)) & (df.Subjectivity <= (value + 0.3)) ].reset_index(drop = True)\n        \n        words = ''\n        for lists in new_df.Words:\n            for wordlist in lists:\n                for word in wordlist[0]:\n                    words = words + word + ' '\n\n\n        return words\n    \n    elif sentiment == 'Polarity':\n        \n        series_sent = df.Polarity\n        \n        if statistic == 'min':\n        \n            value = series_sent.min()\n            \n        elif statistic == 'max':\n        \n            value = series_sent.max()\n            \n        elif statistic == 'mean':\n            \n            value = series_sent.mean()\n            \n        else: return \"check statistic argument\"\n            \n        new_df = df[(df.Polarity >= (value - 0.3)) & (df.Polarity <= (value + 0.3)) ].reset_index(drop = True)\n        \n        words = ''\n        for lists in new_df.Words:\n            for wordlist in lists:\n                for word in wordlist[0]:\n                    words = words + word + ' '\n        \n\n        return words\n        \n    else: return \"check sentiment argument\"\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Scraping lyrics and chords from Ultimate-Guitar"},{"metadata":{"trusted":true},"cell_type":"code","source":"pop1 = 'https://www.ultimate-guitar.com/explore?type[]=Chords&tuning[]=1&genres[]=14&page=1'\npop2 = 'https://www.ultimate-guitar.com/explore?type[]=Chords&tuning[]=1&genres[]=14&page=2'\npop2010_1 = 'https://www.ultimate-guitar.com/explore?type[]=Chords&tuning[]=1&genres[]=14&decade[]=2010&page=1'\npop2010_2 = 'https://www.ultimate-guitar.com/explore?type[]=Chords&tuning[]=1&genres[]=14&decade[]=2010&page=2'\npop2010_3 = 'https://www.ultimate-guitar.com/explore?type[]=Chords&tuning[]=1&genres[]=14&decade[]=2010&page=3'\n\nrock1 = 'https://www.ultimate-guitar.com/explore?type[]=Chords&tuning[]=1&genres[]=4&page=1'\nrock2 = 'https://www.ultimate-guitar.com/explore?type[]=Chords&tuning[]=1&genres[]=4&page=2'\nrock2010_1 = 'https://www.ultimate-guitar.com/explore?type[]=Chords&tuning[]=1&genres[]=4&decade[]=2010&page=1'\nrock2010_2 = 'https://www.ultimate-guitar.com/explore?type[]=Chords&tuning[]=1&genres[]=4&decade[]=2010&page=2'\nrock2010_3 = 'https://www.ultimate-guitar.com/explore?type[]=Chords&tuning[]=1&genres[]=4&decade[]=2010&page=3'\n\ncountry1 = 'https://www.ultimate-guitar.com/explore?type[]=Chords&tuning[]=1&genres[]=49&page=1'\ncountry2 = 'https://www.ultimate-guitar.com/explore?type[]=Chords&tuning[]=1&genres[]=49&page=2'\ncountry2010_1 = 'https://www.ultimate-guitar.com/explore?type[]=Chords&tuning[]=1&genres[]=49decade[]=2010&page=1'\ncountry2010_2 = 'https://www.ultimate-guitar.com/explore?type[]=Chords&tuning[]=1&genres[]=49decade[]=2010&page=2'\ncountry2010_3 = 'https://www.ultimate-guitar.com/explore?type[]=Chords&tuning[]=1&genres[]=49decade[]=2010&page=3'\n\nrnb1  = 'https://www.ultimate-guitar.com/explore?type[]=Chords&tuning[]=1&genres[]=1787&page=1'\nrnb2  = 'https://www.ultimate-guitar.com/explore?type[]=Chords&tuning[]=1&genres[]=1787&page=2'\nrnb2010_1 = 'https://www.ultimate-guitar.com/explore?type[]=Chords&tuning[]=1&genres[]=1787&decade[]=2010&page=1'\nrnb2010_2 = 'https://www.ultimate-guitar.com/explore?type[]=Chords&tuning[]=1&genres[]=1787&decade[]=2010&page=2'\nrnb2010_3 = 'https://www.ultimate-guitar.com/explore?type[]=Chords&tuning[]=1&genres[]=1787&decade[]=2010&page=3'\n\n\nhiphop1 = 'https://www.ultimate-guitar.com/explore?type[]=Chords&tuning[]=1&genres[]=45&page=1'\nhiphop2 = 'https://www.ultimate-guitar.com/explore?type[]=Chords&tuning[]=1&genres[]=45&page=2'\nhiphop2010_1 = 'https://www.ultimate-guitar.com/explore?type[]=Chords&tuning[]=1&decade[]=2010&genres[]=45&page=1'\nhiphop2010_2 = 'https://www.ultimate-guitar.com/explore?type[]=Chords&tuning[]=1&decade[]=2010&genres[]=45&page=2'\nhiphop2010_3 = 'https://www.ultimate-guitar.com/explore?type[]=Chords&tuning[]=1&decade[]=2010&genres[]=45&page=3'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#List of links to most viewed songs, but filtered by genre, and a list of the genre names\n#Chose to sample songs from the last decade, otherwise \"The Beatles\" would be in every genre\n\ngenre_list = [pop2010_1, pop2010_2, pop2010_3, rock2010_1, rock2010_2, rock2010_3, \n              country2010_1, country2010_2, country2010_3, rnb2010_1, rnb2010_2, rnb2010_3, \n              hiphop2010_1, hiphop2010_2, hiphop2010_3]\n\ngenre_names = ['pop', 'pop', 'pop', 'rock', 'rock', 'rock', 'country', 'country', 'country', \n               'rnb', 'rnb', 'rnb', 'hiphop', 'hiphop', 'hiphop']\n\ngenre_list_test = [pop2010_1, pop2010_2, rock2010_1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### The scraped data was exported, so I've commented out the following and loaded in the .csv files later."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create dataframe of all song links, and their respective genre\n\nlinks_list_dicts = []\nlinks_list = []\n\n\nfor address, name in zip(genre_list, genre_names):\n    \n    #Downloads HTML\n    links = await get_song_links(address)\n    \n    #Only add link to list if it isn't already in there\n    for link in links:\n        \n        if link in links_list:\n            continue\n        else:\n            link_dict = {'Link': link, 'Genre': name}\n            links_list_dicts.append(link_dict)\n            links_list.append(link)\n    \nlinks_df = pd.DataFrame(links_list_dicts)    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pop_links = links_df[links_df.Genre == 'pop'].reset_index(drop = True)\nrock_links = links_df[links_df.Genre == 'rock'].reset_index(drop = True)\ncountry_links = links_df[links_df.Genre == 'country'].reset_index(drop = True)\nrnb_links = links_df[links_df.Genre == 'rnb'].reset_index(drop = True)\nhiphop_links = links_df[links_df.Genre == 'hiphop'].reset_index(drop = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#get dataframe for pop songs\n\nlist_o_dfs = []\n\nfor i in range(len(pop_links)):\n    link = pop_links.Link[i]\n    genre = pop_links.Genre[i]\n    song_df = await get_song_dataframe(link, genre)\n    list_o_dfs.append(song_df)\n    \npop_df = pd.concat(list_o_dfs, axis = 0).reset_index(drop = True)\n\npop_df.to_csv('poplyricsraw2.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#get dataframe for rock songs\nlist_o_dfs = []\n\nfor i in range(len(rock_links)):\n    link = rock_links.Link[i]\n    genre = rock_links.Genre[i]\n    song_df = await get_song_dataframe(link, genre)\n    list_o_dfs.append(song_df)\n    \nrock_df = pd.concat(list_o_dfs, axis = 0).reset_index(drop = True)\n\nrock_df.to_csv('rocklyricsraw2.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#get dataframe for country songs\n\nlist_o_dfs = []\n\nfor i in range(len(country_links)):\n    link = country_links.Link[i]\n    genre = country_links.Genre[i]\n    song_df = await get_song_dataframe(link, genre)\n    list_o_dfs.append(song_df)\n    \ncountry_df = pd.concat(list_o_dfs, axis = 0).reset_index(drop = True)\n\ncountry_df.to_csv('countrylyricsraw2.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#get dataframe for rnb songs\n\nlist_o_dfs = []\n\nfor i in range(len(rnb_links)):\n    link = rnb_links.Link[i]\n    genre = rnb_links.Genre[i]\n    song_df = await get_song_dataframe(link, genre)\n    list_o_dfs.append(song_df)\n    \nrnb_df = pd.concat(list_o_dfs, axis = 0).reset_index(drop = True)\n\nrnb_df.to_csv('rnblyricsraw2.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#get dataframe for hip hop songs\n\nlist_o_dfs = []\n\nfor i in range(len(hiphop_links)):\n    link = hiphop_links.Link[i]\n    genre = hiphop_links.Genre[i]\n    song_df = await get_song_dataframe(link, genre)\n    list_o_dfs.append(song_df)\n    \nhiphop_df = pd.concat(list_o_dfs, axis = 0).reset_index(drop = True)\n\nhiphop_df.to_csv('hiphoplyricsraw2.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load data and combine"},{"metadata":{"trusted":true},"cell_type":"code","source":"# #load in csv files of lyrics from different genres\n# country_df = pd.read_csv('../input/lyrics-and-chords-from-ultimateguitar/country_lyrics_df.csv', index_col = 0)\n# pop_df = pd.read_csv('../input/lyrics-and-chords-from-ultimateguitar/pop_lyrics_df.csv', index_col = 0)\n# rock_df = pd.read_csv('../input/lyrics-and-chords-from-ultimateguitar/rock_lyrics_df.csv', index_col = 0)\n# rnb_df = pd.read_csv('../input/lyrics-and-chords-from-ultimateguitar/rnb_lyrics_df.csv', index_col = 0)\n# hiphop_df = pd.read_csv('../input/lyrics-and-chords-from-ultimateguitar/hiphop_lyrics_df.csv', index_col = 0)\n\ngenre_df_list = [country_df, pop_df, rock_df, rnb_df, hiphop_df]\n\nmain_df = pd.concat(genre_df_list).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rock_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Cleaning data"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Attempt to clean the part-of-song labels\n\nfor i, name, label in zip(main_df.index, main_df.Part, main_df.Genre):\n    \n    \n    if ('verse' in name) or ('rap'in name) or ('part'in name):\n        main_df.loc[i, 'Part'] = main_df.Part[i].replace(name, 'Verse')\n        \n        \n    elif ('pre' in name) & ('chorus' in name):        \n        main_df.loc[i, 'Part'] = main_df.Part[i].replace(name, 'Pre-Chorus')\n        \n        \n    elif ('pre' in name) & ('hook' in name):        \n        main_df.loc[i, 'Part'] = main_df.Part[i].replace(name, 'Pre-Chorus')\n           \n            \n    elif ('chorus' in name) or ('refrain' in name) or ('hook' in name):        \n        main_df.loc[i, 'Part'] = main_df.Part[i].replace(name, 'Chorus')\n        \n        \n    elif ('bridge' in name):        \n        main_df.loc[i, 'Part'] = main_df.Part[i].replace(name, 'Bridge')\n        \n        \n    elif ('intro' in name):       \n        main_df.loc[i, 'Part'] = main_df.Part[i].replace(name, 'Intro')\n        \n        \n    elif ('instrumental' in name) or ('break' in name) or ('interlude' in name) or ('riff' in name) or ('solo' in name) or ('lead' in name):        \n        main_df.loc[i, 'Part'] = main_df.Part[i].replace(name, 'Interlude')\n        \n        \n    elif ('outro' in name) or ('end' in name) or ('coda' in name):       \n        main_df.loc[i, 'Part'] = main_df.Part[i].replace(name, 'Outro')\n    \n    \n    elif ('chords' in name) or ('tuning' in name) or ('picking pattern' in name) or ('note' in name) or ('2x' in name):        \n        main_df = main_df.drop([i])\n        \n    else:\n        main_df.loc[i, 'Part'] = np.nan \n        \n#Clean genre labels\n    if label == 'rnb':\n        main_df.loc[i, 'Genre'] = 'RnB'\n    else:\n        new_label = label.capitalize()\n        main_df.loc[i, 'Genre'] = new_label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop rows without lyrics and duplicate parts\nmain_df_dropped = main_df.dropna(subset=['Lyrics'])\nmain_df_dropped  = main_df_dropped.drop_duplicates(subset=['Lyrics']).reset_index(drop = True)\nmain_df_dropped","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Adding Features"},{"metadata":{"trusted":true},"cell_type":"code","source":"#add sentiment scores to dataframe\nsentiments_df = get_pol_sub_scores(main_df_dropped.Lyrics)\nmain_df_clean = main_df_dropped.join(sentiments_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Count number of unique words in each lyric and add column to main dataframe\n\nunique_words_count = []\n\nfor lyric in main_df_clean.Lyrics:\n    words = pd.Series(lyric.lower().split(' '))\n    count = len(words.unique())\n    \n    unique_words_count.append(count)\n\nmain_df_clean['Unique Words'] = pd.Series(unique_words_count)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"main_df_clean","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Add columns for part of speech counts\ncount_df = get_pos_count_df(main_df_clean.Lyrics)\nmain_df_clean = pd.concat([main_df_clean, count_df], axis = 1)\nmain_df_clean","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Split clean df into genre-specific dfs\nclean_popdf = main_df_clean[main_df_clean.Genre == 'Pop']\nclean_rockdf = main_df_clean[main_df_clean.Genre == 'Rock']\nclean_countrydf = main_df_clean[main_df_clean.Genre == 'Country']\nclean_rnbdf = main_df_clean[main_df_clean.Genre == 'RnB']\nclean_hiphopdf = main_df_clean[main_df_clean.Genre == 'Hiphop']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Adding stopwords for the Word Cloud\nstopwords2 = set(STOPWORDS) \nstopwords2.add('ill')\nstopwords2.add( 'na')\nstopwords2.add( 'shit')\nstopwords2.add( 'fuck')\nstopwords2.add( 'fucking')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_repeating_sections(df):\n    \n    \"\"\"Removes repeated instances of chorus and pre-chorus in each song,\n    returns a dataframe with one chorus and pre-chorus per song\"\"\"\n    \n    #filter out repetitive sections\n    chorus = df[df.Part == 'Chorus']\n    prechorus = df[df.Part == 'Pre-Chorus']\n    other = df[(df.Part != 'Chorus') & (df.Part != 'Pre-Chorus')]\n\n    #Create dataframe of single chorus from each song\n    list_of_chorus = []\n\n    for songtitle in chorus['Song Title'].unique():\n\n        songdf = chorus[chorus['Song Title'] == songtitle]\n        songdf_reset = songdf.reset_index(drop = True)\n        instance = songdf_reset.iloc[0, :]\n        list_of_chorus.append(instance)\n\n    single_chorusdf = pd.DataFrame(list_of_chorus)\n\n    #Create dataframe of single pre-chorus from each song\n    list_of_prechorus = []\n\n    for songtitle in prechorus['Song Title'].unique():\n\n        songdf = prechorus[prechorus['Song Title'] == songtitle]\n        songdf_reset = songdf.reset_index(drop = True)\n        instance = songdf_reset.iloc[0, :]\n        list_of_prechorus.append(instance)\n\n    single_prechorusdf = pd.DataFrame(list_of_prechorus)\n\n    return pd.concat([other, single_chorusdf, single_prechorusdf]).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_common_phrases(lyric_list):\n    \n    \"\"\"Creates a dataframe with columns \n    for the phrase, and the number of counts\"\"\"\n    \n#Filters out repetition of lyrics\n    sampled_lyrics = []\n    for lyric in lyric_list: \n        ngram_check = []\n        blob = TextBlob(lyric)\n        for wordlist in blob.ngrams(5):\n\n            if wordlist not in ngram_check:\n\n                ngram_check.append(wordlist)\n            else: break\n\n        lyric_split = lyric.split(' ')[:len(ngram_check)]\n        lyric_sample = \" \".join(lyric_split)\n\n        sampled_lyrics.append(lyric_sample)\n\n    sampled_lyrics_series = pd.Series(sampled_lyrics)\n\n    #Get 3-gram chunks, ignore 3-grams with two words in a row\n    all_phrases = []\n    for lyric in sampled_lyrics_series.drop_duplicates(): \n        sentences = []\n        blob = TextBlob(lyric)\n        for wordlist in blob.ngrams(3):\n            if wordlist[0].lower() == wordlist[1].lower():\n                continue\n            elif wordlist[-1].lower() == wordlist[-2].lower():\n                continue\n            else:\n\n                sentence = \"\"\n                for word in wordlist:\n\n\n                    sentence = sentence + \" \" + str(word)\n\n                all_phrases.append(sentence)\n\n\n    #Get the top 15 instances, store in dataframe \n    common_phrase2 = pd.Series(all_phrases).value_counts().head(12)\n    common_phrases = pd.DataFrame()\n    common_phrases['Phrase'] = common_phrase2.index\n    common_phrases['Count'] = common_phrase2.values\n\n    return common_phrases","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Function for generating plots\n\ndef get_genre_analysis(df):\n    \"\"\"Takes the main dataframe, returns a figure with various analyses of the lyrics provided.\"\"\"\n    \n    #Remove repeated sections of each song\n    df = remove_repeating_sections(df)\n\n\n    #filter out default sentiment scores\n    analyzed_words = df[[(len(x) != 0) for x in df.Words]]\n\n    polarity_list = analyzed_words.Polarity\n    subjectivity_list = analyzed_words.Subjectivity\n\n\n    #find most common words for each part of speech tag\n    df_tags = get_pos_tags(df.Lyrics)\n    df_top = get_common_pos_df(df_tags, 5, df.Genre)\n\n    with sns.color_palette('tab10'), sns.axes_style(\"darkgrid\"):\n\n        #Create figure and grid\n        fig = plt.figure(figsize=(16, 16)) \n        gs = gridspec.GridSpec(4, 3, hspace=.4, wspace = .25)\n\n\n        #Violin plot of Subjectivity and Polarity\n\n        sub_pol_melt = pd.melt(df[['Polarity', 'Subjectivity']], var_name='Sentiment', value_name='Sentiment Value')\n        ax = plt.subplot(gs[0, 0])\n        ax = sns.violinplot(x = 'Sentiment', y = 'Sentiment Value', data =sub_pol_melt)\n        ax.set_title('Distribution of sentiment values') \n\n        #Violinplots of unique words in each part of the song\n        ax2 = plt.subplot(gs[0, 1])\n        ax2 = sns.violinplot(x = 'Part', y = 'Unique Words', data = df, order = ['Verse', 'Chorus', 'Pre-Chorus', 'Intro', 'Interlude', 'Outro'])\n        plt.xticks(rotation = 10, size = 7)\n        ax2.set_title('Distribution of unique words in each part')\n\n\n        #Violin plot for part of speech instance in each song\n        pos_count_melt = pd.melt(df.iloc[:, -4:], var_name='Parts of Speech', value_name='Fraction of total words')\n        ax3 = plt.subplot(gs[0, 2])\n        ax3 = sns.violinplot(x = 'Parts of Speech', y = 'Fraction of total words', data = pos_count_melt)\n        ax3.set_title('Distribution of P.O.S. for each song')\n\n        #Create Wordcloud\n\n        cloud = WordCloud(width = 2000, height = 1200, stopwords = stopwords2, background_color ='white',  min_font_size = 12, colormap = 'tab10', collocations = False,  repeat = True)\n        pad = .01\n\n        ##Subjectivity Examples\n        # min\n\n        min_sub = get_sentiment_examples(analyzed_words, sentiment = 'Subjectivity', statistic = 'min')\n\n        sub_min_cloud = cloud\n        sub_min_cloud.generate(min_sub)\n\n        ax4 = plt.subplot(gs[1, 0])\n        ax4 = plt.axis(\"off\") \n        ax4 = plt.title('Examples of low subjectivity')\n        ax4 = plt.imshow(sub_min_cloud, aspect='auto').axes\n\n        \n        #mean\n\n        mean_sub = get_sentiment_examples(analyzed_words, sentiment = 'Subjectivity', statistic = 'mean')\n\n        sub_mean_cloud = cloud\n        sub_mean_cloud.generate(mean_sub)\n\n        ax5 = plt.subplot(gs[1, 1])\n        ax5 = plt.axis(\"off\")  \n        ax5 = plt.title('Examples of average subjectivity')\n        ax5 = plt.imshow(sub_mean_cloud, aspect='auto').axes\n\n        \n        #max\n\n        max_sub = get_sentiment_examples(analyzed_words, sentiment = 'Subjectivity', statistic = 'max')\n\n        sub_max_cloud = cloud\n        sub_max_cloud.generate(max_sub)\n\n        ax6 = plt.subplot(gs[1, 2])\n        ax6 = plt.axis(\"off\")         \n        ax6 = plt.title('Examples of high subjectivity')\n        ax6 = plt.imshow(sub_max_cloud, aspect='auto').axes\n\n\n        ##Polarity Examples\n\n        #min\n\n        min_pol = get_sentiment_examples(analyzed_words, sentiment = 'Polarity', statistic = 'min')\n\n        pol_min_cloud = cloud\n        pol_min_cloud.generate(min_pol)\n\n        ax7 = plt.subplot(gs[2, 0])\n        ax7 = plt.axis(\"off\") \n        ax7 = plt.title('Examples of low polarity')\n        ax7 = plt.imshow(pol_min_cloud, aspect='auto').axes\n\n        ##mean\n\n        mean_pol = get_sentiment_examples(analyzed_words, sentiment = 'Polarity', statistic = 'mean')\n\n        pol_mean_cloud = cloud\n        pol_mean_cloud.generate(mean_pol)\n\n        ax8 = plt.subplot(gs[2, 1])\n        ax8 = plt.axis(\"off\") \n        ax8 = plt.title('Examples of average polarity')\n        ax8 = plt.imshow(pol_mean_cloud, aspect='auto').axes\n\n        ##max\n\n        max_pol = get_sentiment_examples(analyzed_words, sentiment = 'Polarity', statistic = 'max')\n\n        pol_max_cloud = cloud\n        pol_max_cloud.generate(max_pol)\n\n        ax9 = plt.subplot(gs[2, 2])\n        ax9 = plt.axis(\"off\") \n        ax9 = plt.title('Examples of high polarity' )\n        ax9 = plt.imshow(pol_max_cloud, aspect='auto').axes\n\n        #Barplot of parts of speech\n        ax10 = plt.subplot(gs[3, 0])\n        ax10 = sns.barplot(y=\"Word\", x=\"Count\", hue=\"POS\", data=df_top, dodge=False)\n        ax10.set_title('Common words') \n\n        ##Common 3 word Phrases\n\n        common_phrasesdf = get_common_phrases(df.Lyrics)\n\n        #Plot and add to figure\n        ax12 = plt.subplot(gs[3, 2])\n        ax12 = sns.barplot(y='Phrase', x='Count', data=common_phrasesdf, dodge=False, palette=\"tab10\")\n        ax12.set_title('Common phrases')\n        \n    #Add title to the Grid, shows genre and number of lyrics that were analyzed    \n    if len(df.Genre.unique()) > 1: \n        selection = 'all'\n    else: \n        selection = str(df.Genre[0])\n    lyric_count = str(len(df))    \n    plt.suptitle('Analysis of '+ selection +  ' lyrics  (Count: ' + lyric_count + ') ',fontsize=20)\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Just to break \"Run All\"\n#3 = 2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Results"},{"metadata":{},"cell_type":"markdown","source":"### Analysis of all collected data"},{"metadata":{"trusted":true},"cell_type":"code","source":"get_genre_analysis(main_df_clean)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Analysis generated for each genre"},{"metadata":{"trusted":true},"cell_type":"code","source":"get_genre_analysis(clean_popdf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_genre_analysis(clean_rockdf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_genre_analysis(clean_countrydf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_genre_analysis(clean_rnbdf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_genre_analysis(clean_hiphopdf)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}