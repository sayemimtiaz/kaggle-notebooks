{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt# for Plotting graphs\nimport seaborn as sns# same as matplotlib but to make life easier\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#loading the dataset\ndf=pd.read_csv(\"/kaggle/input/indian-liver-patient-records/indian_liver_patient.csv\")\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Analyzing The dataset","metadata":{}},{"cell_type":"code","source":"#describing the data\ndf.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#printing the shape of data\nprint(df.shape)\ndf.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#encoding the Gender attribute\ndf['Gender'].replace({'Male':1,'Female':0},inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Starting with EDA","metadata":{}},{"cell_type":"code","source":"#plotting Correlation\nplt.figure(figsize=(10,10))\nsns.heatmap(df.corr(),cmap='Greens',annot=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.pairplot(df, hue='Dataset')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# visualize number of patients diagonised with liver diesease\nsns.countplot(data = df, x = 'Dataset');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Visualizing data with liver disease along with Gender\nplt.figure(figsize=(6,6))\nax = sns.countplot(x = df['Dataset'].apply(lambda x:'Normal' if x == 1 else 'Liver Disease'), hue=df['Gender'])\nax.set_xlabel('Patient Condition')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Starting Data Preprocessing","metadata":{}},{"cell_type":"code","source":"#checking for missing values as per column\ndf.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking the rows with the missing values\ndf[df['Albumin_and_Globulin_Ratio'].isna()]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Lets have a look for correlation of Albumin_and_Globulin_Ratio with other columns\nplt.figure(figsize=(15,10))\nsns.heatmap(df.corr(),cmap='Greens',annot=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#As seen above Albumin_and_Globulin_Ratio is highly correlated with Albumin\n# we apply binning to Albumin and will fill the values in Albumin_and_Globulin_Ratio using median of the bin value\ndf[\"binned_Albumin\"]=pd.cut(df['Albumin'],bins=10,labels=list(range(10)))\n#checking the rows with the missing values\ndf[df['Albumin_and_Globulin_Ratio'].isna()]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#seprating dataframe as per bins of missing data\ndf_bin6=df[df['binned_Albumin']==6]\ndf_bin4=df[df['binned_Albumin']==4]\ndf_bin3=df[df['binned_Albumin']==3]\ndf_bin8=df[df['binned_Albumin']==8]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#filling na values for bin 6\ndf_bin6['Albumin_and_Globulin_Ratio'].fillna(df_bin6['Albumin_and_Globulin_Ratio'].median(),inplace=True)\nprint(\"Median for Albumin Globumin Ratio for bin 6: \",df_bin6['Albumin_and_Globulin_Ratio'].median())\n#adding the replaced values\ndf.drop(df[df['binned_Albumin']==6].index, inplace = True)\ndf=df.append(df_bin6,ignore_index=True)\n\n#filling na values for bin 4\ndf_bin4['Albumin_and_Globulin_Ratio'].fillna(df_bin4['Albumin_and_Globulin_Ratio'].median(),inplace=True)\nprint(\"Median for Albumin Globumin Ratio for bin 4: \",df_bin4['Albumin_and_Globulin_Ratio'].median())\n#adding the replaced values\ndf.drop(df[df['binned_Albumin']==4].index, inplace = True)\ndf=df.append(df_bin4,ignore_index=True)\n\n#filling na values for bin 3\ndf_bin3['Albumin_and_Globulin_Ratio'].fillna(df_bin3['Albumin_and_Globulin_Ratio'].median(),inplace=True)\nprint(\"Median for Albumin Globumin Ratio for bin 3: \",df_bin3['Albumin_and_Globulin_Ratio'].median())\n#adding the replaced values\ndf.drop(df[df['binned_Albumin']==3].index, inplace = True)\ndf=df.append(df_bin3,ignore_index=True)\n\n#filling na values for bin 8\ndf_bin8['Albumin_and_Globulin_Ratio'].fillna(df_bin8['Albumin_and_Globulin_Ratio'].median(),inplace=True)\nprint(\"Median for Albumin Globumin Ratio for bin 8: \",df_bin8['Albumin_and_Globulin_Ratio'].median())\n#adding the replaced values\ndf.drop(df[df['binned_Albumin']==8].index, inplace = True)\ndf= df.append(df_bin8,ignore_index=True)\n#Printing Shape of Dataset\nprint(df.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#remove the binned albumin column\ndf.drop(columns=['binned_Albumin'], inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Scaling the dataset using Min Max scaler:\n#Getting Numerical Columns\ncols=df.columns.to_list()\ncols.remove('Gender')\ncols.remove('Dataset')\nprint(\"Columns with numerical data:\")\ncols","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#getting Numerical columns:\ndf_numerical=df[cols]\n\n#starting scaling process:\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nscaler.fit(df_numerical)\nscaled=scaler.transform(df_numerical) #the variable scaled will be in numpy array \nx=pd.DataFrame(scaled, columns=cols) #converting the variable to dataframe.\nx['Gender']=df['Gender']# adding Gender to X or attribute list\ny=df['Dataset']# Getting the labels\nx","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#moving for feature selection\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.feature_selection import SelectFromModel\nclf = ExtraTreesClassifier(n_estimators=50)\nclf = clf.fit(x, y)\nprint(\"Showing feature importance values\")\nprint(clf.feature_importances_) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=SelectFromModel(clf, prefit=True) #getting features from  the above classifer as per the importances\ncols=x.columns.to_list()#getting list of columns\ntf=model.get_support()#getting which features are important\nselectedcols=[]\nfor i in range(len(cols)):\n    if tf[i]:\n        selectedcols.append(cols[i])\nprint(\"showing selected columns\")\nprint(selectedcols)\n#converting the data\nX_new = model.transform(x)\nX_new.shape ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Applying ML Algorithms","metadata":{}},{"cell_type":"code","source":"#splitting the dataset for Training and testing and using 5-fold Cross validation.\nfrom sklearn.model_selection import KFold\nkf = KFold(n_splits=5)\nkf.get_n_splits(X_new)\n\n#making a comparative study of 3 different ML Algorithms namely SVM, Random Forest, KNN\n#metrics for SVM\nSVM_accuracy=[]\nSVM_precision=[]\nSVM_recall=[]\nSVM_f1_score=[]\n\n#metrics for Random Forest\nRF_accuracy=[]\nRF_precision=[]\nRF_recall=[]\nRF_f1_score=[]\n\n#metrics for KNN\nKNN_accuracy=[]\nKNN_precision=[]\nKNN_recall=[]\nKNN_f1_score=[]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#initializing the models\n#importing libraries of the selected algorithms\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\n#importing libraries of performance Metrics\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\n\n#Making the classifier Objects\nclf_svm=SVC() #SVM object\nclf_rf=RandomForestClassifier(max_depth=5, random_state=0)#Random Forest Object\nclf_knn = KNeighborsClassifier(n_neighbors=3)#KNN object","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"i=1# count the number of folds\n#starting the 5 fold cross valivation\nfor train_index, test_index in kf.split(X_new):\n    print(\"%d Number of fold\"%i)\n    i+=1\n    #Splitting the data\n    X_train, X_test = X_new[train_index], X_new[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n    \n    #Training and Evaluating SVM\n    model=clf_svm.fit(X_train,y_train)\n    y_pred=model.predict(X_test)\n    SVM_accuracy.append(accuracy_score(y_test,y_pred))\n    SVM_precision.append(precision_score(y_test,y_pred))\n    SVM_recall.append(recall_score(y_test,y_pred))\n    SVM_f1_score.append(f1_score(y_test,y_pred))\n    \n    #Training and Evaluating Random Forest\n    model=clf_rf.fit(X_train,y_train)\n    y_pred=model.predict(X_test)\n    RF_accuracy.append(accuracy_score(y_test,y_pred))\n    RF_precision.append(precision_score(y_test,y_pred))\n    RF_recall.append(recall_score(y_test,y_pred))\n    RF_f1_score.append(f1_score(y_test,y_pred))\n    \n    #Training and Evaluating KNN\n    model=clf_knn.fit(X_train,y_train)\n    y_pred=model.predict(X_test)\n    KNN_accuracy.append(accuracy_score(y_test,y_pred))\n    KNN_precision.append(precision_score(y_test,y_pred))\n    KNN_recall.append(recall_score(y_test,y_pred))\n    KNN_f1_score.append(f1_score(y_test,y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Analyzing the performance","metadata":{}},{"cell_type":"code","source":"#visualizing results of SVM per fold\nx=list(range(1,6))\nplt.plot(x,SVM_accuracy,label='Accuracy')\nplt.plot(x,SVM_precision,label='Precision')\nplt.plot(x,SVM_recall, label='Recall')\nplt.plot(x,SVM_f1_score,label='F1 Score')\nplt.title(\"Performance of SVM\")\nplt.legend()\nplt.xlabel(\"Cross Validation Fold\")\nplt.ylabel(\"performace\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#visualizing results of Random Forest per fold\nplt.plot(x,RF_accuracy,label='Accuracy')\nplt.plot(x,RF_precision,label='Precision')\nplt.plot(x,RF_recall, label='Recall')\nplt.plot(x,RF_f1_score,label='F1 Score')\nplt.title(\"Performance of Random Forest\")\nplt.xlabel(\"Cross Validation Fold\")\nplt.ylabel(\"performace\")\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#visualizing results of KNN per epoch\nx=list(range(1,6))\nplt.plot(x,KNN_accuracy,label='Accuracy')\nplt.plot(x,KNN_precision,label='Precision')\nplt.plot(x,KNN_recall, label='Recall')\nplt.plot(x,KNN_f1_score,label='F1 Score')\nplt.title(\"Performance of KNN\")\nplt.xlabel(\"Cross Validation Fold\")\nplt.ylabel(\"performace\")\nplt.legend()\nplt.show","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#visualizing average results:\nSVM=[\"SVM \", (sum(SVM_accuracy)/len(SVM_accuracy)), (sum(SVM_precision)/len(SVM_precision)), \n     (sum(SVM_recall)/len(SVM_recall)), (sum(SVM_f1_score)/len(SVM_f1_score))]\n\nRF=[\"RF \", (sum(RF_accuracy)/len(RF_accuracy)), (sum(RF_precision)/len(RF_precision)), \n     (sum(RF_recall)/len(RF_recall)), (sum(RF_f1_score)/len(RF_f1_score))]\n\nKNN=[\"KNN \", (sum(KNN_accuracy)/len(KNN_accuracy)), (sum(KNN_precision)/len(KNN_precision)), \n     (sum(KNN_recall)/len(KNN_recall)), (sum(KNN_f1_score)/len(KNN_f1_score))]\ndata=[]\ndata.append(SVM)\ndata.append(RF)\ndata.append(KNN)\n#converting results to dataframe\nresults=pd.DataFrame(data,columns=[\"Algorithms\",\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"])\nresults","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}