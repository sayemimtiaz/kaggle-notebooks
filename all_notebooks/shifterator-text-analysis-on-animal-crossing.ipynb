{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Shifterator text analysis on Animal Crossing reviews\n\nI saw a tweet from [Ryan J. Gallagher](https://twitter.com/ryanjgallag) about his new Python package for people who hate wordclouds called \"Shifterator\". From his GitHub repo:\n\n> _The Shifterator package provides functionality for constructing word shift graphs, vertical bart charts that quantify which words contribute to a pairwise difference between two texts and how they contribute. By allowing you to look at changes in how words are used, word shifts help you to conduct analyses of sentiment, entropy, and divergence that are fundamentally more interpretable._\n\nI decided to try out this new package on this week's TidyTuesday dataset on [Animal Crossing](https://www.kaggle.com/jessemostipak/animal-crossing). I'm definitely more of an #rstats person where I'm a huge fan of Dr. Julia Silge and David Robinson's [TidyText package](https://www.tidytextmining.com/). But Shifterator looked intriguing enough for me to dust off my rusty Python skills (or lack thereof). Anyway, so apologies if my Python code looks terrible. Let me know in the comments what I should fix.","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"!pip install shifterator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import packages\n\nimport pandas as pd\nimport numpy as np\nimport itertools\nimport collections\nimport nltk\nfrom nltk.corpus import stopwords\nimport re\n\nfrom shifterator import relative_shift as rs\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(font_scale=1.5)\nsns.set_style(\"whitegrid\")","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def remove_punctuation(txt:str):\n    \"\"\"Replace URLs and other punctuation found in a text string with nothing \n    (i.e. it will remove the URL from the string).\n\n    Parameters\n    ----------\n    txt : string\n        A text string that you want to parse and remove urls.\n\n    Returns\n    -------\n    The same txt string with URLs and punctuation removed.\n    \"\"\"\n\n    return \" \".join(re.sub(\"([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \"\", txt).split())\n\ndef clean_text(txt:str) -> {}:\n    \"\"\"Removes punctuation, changes to lowercase, removes\n        stopwords, removes \"animal\" and \"crossing\", and\n        calculates word frequencies (as counts).\n\n    Parameters\n    ----------\n    txt : string\n        A text string that you want to clean.\n\n    Returns\n    -------\n    Words and frequency counts\n    \"\"\"\n    \n    tmp = [remove_punctuation(t) for t in txt]\n    tmp = [t.lower().split() for t in tmp]\n    \n    tmp = [[w for w in t if not w in stop_words]\n              for t in tmp]\n#     tmp = [[w for w in t if not w in ['animal', 'crossing']]\n#                      for t in tmp]\n    \n    tmp = list(itertools.chain(*tmp))\n    tmp = collections.Counter(tmp)\n        \n    return tmp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load the review CSV\nreviews = pd.read_csv(\"../input/animal-crossing/user_reviews.csv\", encoding='utf-8')\nprint(reviews.shape)\nreviews.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(reviews.drop_duplicates(\"text\").shape[0]) # 3 duplicate reviews. ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# do some text normalization to filter out more duplicate reviews , regardless of subsequent filtering\nreviews[\"text\"] = reviews[\"text\"].str.lower().str.replace(\"([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \"\", case=False,regex=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reviews = reviews.drop_duplicates(\"text\")\nprint(reviews.shape[0]) # 6 duplicate reviews. ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Each review has the following columns: the date, a review, and the review text.\n\nMy research question will be: How do negative and positive reviews compare in the words they use?","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Inspect and prepare the data\n\nThe first thing I'm going to do is have a look at some of the data to get a bit of a feel for it.\n\nLet's look at average review grades over time.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"reviews['date'] = pd.to_datetime(reviews['date'])\nreviews.index = reviews['date'] \n\nfig, ax = plt.subplots(figsize=(12, 8))\n\nmean_daily_grades = reviews.resample('D', on='date').mean().reset_index('date')\n\n# Plot horizontal bar graph\nmonthly_plot = sns.lineplot(data = mean_daily_grades,\n                      x = 'date',\n                      y = 'grade',\n                      color=\"purple\"\n                      )\n\nax.set_title(\"Average daily grade\")\nx_dates = mean_daily_grades['date'].dt.strftime('%m-%d').sort_values().unique()\nax.set_xticklabels(labels=x_dates, rotation=45, ha='right')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It looks like reviews started off pretty positively and declined steeply after which the average has been bouncing between 2 and almost 7.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"reviews.grade.hist();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Divide reviews into positive and negative based on the average OR median grade for the dataset.\n* Original notebook used median. I try the mean here","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_grade = reviews.grade.mean()\nprint(f\"Average grade {mean_grade}\")\n\nmedian_grade = reviews.grade.median()\nprint(f\"Median grade {median_grade}\")\n\n\nreviews.loc[reviews['grade'] <= mean_grade, 'review_category'] = 'Negative' \nreviews.loc[reviews['grade'] > mean_grade, 'review_category'] = 'Positive' \n\nreviews_neg = reviews[reviews['review_category'] == 'Negative']\nreviews_pos = reviews[reviews['review_category'] == 'Positive']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"texts = reviews['text'].tolist()\ntexts_neg = reviews_neg['text'].tolist()\ntexts_pos = reviews_pos['text'].tolist()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I learned how to clean the review text data and calculate frequencies using [this tutorial](https://www.earthdatascience.org/courses/use-data-open-source-python/intro-to-apis/calculate-tweet-word-frequencies-in-python/). The next few cells will clean and prepare the data by removing punctuation, stop words, change everything to lower case, etc so we can calculate frequencies.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extend with custom stop words + animal + crossing\nstop_words = set(stopwords.words('english'))\nstop_words.update(['animal', 'crossing', \"game\"])\n# stop_words","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Clean up the review texts\nclean_texts_neg = clean_text(texts_neg)\nclean_texts_pos = clean_text(texts_pos)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clean_texts_neg","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plot data in a boring way\n\nFirst, I thought it would be interesting to make more boring graphs of the data to compare to the cool ones with Shifterator.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dataframes for most frequent common words in positive and negative reviews\ncommon_neg = pd.DataFrame(clean_texts_neg.most_common(15),\n                             columns=['words', 'count'])\ncommon_pos = pd.DataFrame(clean_texts_pos.most_common(15),\n                             columns=['words', 'count'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(8, 8))\n\n# Plot horizontal bar graph\ncommon_neg.sort_values(by='count').plot.barh(x='words',\n                      y='count',\n                      ax=ax,\n                      color=\"red\")\n\nax.set_title(\"Common Words Found in Negative Reviews\")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(8, 8))\n\n# Plot horizontal bar graph\ncommon_pos.sort_values(by='count').plot.barh(x='words',\n                      y='count',\n                      ax=ax,\n                      color=\"green\")\n\nax.set_title(\"Common Words Found in Positive Reviews\")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Yes, these plots are very boring. Common words between negative and positive reviews are pretty similar. For something a bit more nuanced I'd normally look to calculate something like tf-idf, but again, [I'd be a lot more at home doing that in R with TidyText](https://www.tidytextmining.com/tfidf.html). Tf-idf would tell you more about a words' relative importance in a corpus taking frequency into account.\n\nOkay, thought you'd get away without seeing a word cloud? Not so fast. ;) Let's do one for good measure. I'll spare you and just plot one for the negative reviews.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# From https://www.kaggle.com/prakashsadashivappa/word-cloud-of-abstracts-cord-19-dataset\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n\nwordcloud = WordCloud(\n    width = 3000,\n    height = 2000,\n    background_color = 'black',\n    ).generate(str(texts_neg))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(\n    figsize = (10, 8),\n    facecolor = 'k',\n    edgecolor = 'k')\nplt.imshow(wordcloud, interpolation = 'bilinear')\nplt.axis('off')\nplt.tight_layout(pad=0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create word shift graphs with Shifterator\n\nTime to finally use the Shifterator package! We could compare negative and positive Animal Crossing reviews based on both frequency and sentiment (or other values) using this package, but I've only calculated frequencies, so we'll just try plotting that.\n\n\n### Entropy shift\n\nThe first graph is an entropy shift graph. [See the GitHub repo for more details](https://github.com/ryanjgallagher/shifterator#entropy-and-kullback-leibler-divergence-shifts).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get an entropy shift\nentropy_shift = rs.EntropyShift(reference=clean_texts_neg,\n                                comparison=clean_texts_pos,\n                                base=2)\nentropy_shift.get_shift_graph() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It looks like the negative reviews are in purple and positive ones are in yellow. It looks like feedback about the whole \"one island per Switch\" dominates. Fortunately my husband doesn't play so we don't have to deal with that. I wonder if \"fix\", \"ridiculous\", \"experience\" refers to some of the goofy, clunky UX. At least I think it's pretty goofy and clunky. A lot of the words are nouns and verbs like \"console\", \"family\", \"money\", \"fix\", \"save\".\n\nAmong the positive reviews, there are more adjectives pulled out. For example, \"best\", \"fun\", \"amazing\", \"relaxing, \"perfect\". I wonder what \"bombing\" refers to in the positive reviews?","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Jensen-Shannon divergence shifts\n\nThe second graph is an Jensen-Shannon divergence shift graph. [See the GitHub repo for more details](https://github.com/ryanjgallagher/shifterator#jensen-shannon-divergence-shifts).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get a Jensen-Shannon divergence shift\nfrom shifterator import symmetric_shift as ss\njsd_shift = ss.JSDivergenceShift(system_1=clean_texts_neg,\n                                 system_2=clean_texts_pos,\n                                 base=2)\njsd_shift.get_shift_graph()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Conclusion\n\nIt definitely seems much more promising than a word cloud, to say the least. If you fork this notebook and do something cool to extend and improve this analysis (especially if you add sentiment scores), let me know in the comments! \nThanks again to Ryan Gallagher for [Shifterator](https://github.com/ryanjgallagher/shifterator).","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}