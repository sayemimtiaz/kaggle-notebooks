{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport csv as csv \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom pandas import datetime\nfrom matplotlib.ticker import FuncFormatter\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Importing all data and combining it"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Defining a helper function to import, reformat the excel file and return a dataframe\ndef import_df(path, column, new_col_name, formatting=0, remove_unnamed=True):\n    df=pd.read_excel((\"/kaggle/input/airline-data-project-mit-1995-2019/Original MIT data/Original MIT data/\"+path))\n    if remove_unnamed==True:\n        df=df.drop([\"Unnamed: 1\"],axis=1) #removing empty column\n    else:\n        pass\n    df=df[4:] #deleting unwanted row\n    df=df.transpose() #transposing data frame\n    df=pd.DataFrame(df.iloc[1:,column])\n    df[\"Year\"]=np.arange(1995,2019,1) #make a series to fill in year column\n    df.reset_index(drop=True, inplace=True) #reset index\n    df.set_index(\"Year\", inplace=True) #make year the new index\n    df=df*(10**(formatting))\n    df.rename(columns={(column+4):new_col_name}, inplace=True)#renaming column\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#each dataframe will form a single column for the final dataframe\n\n## Revenues\n\n#Importing and creating a dataframe of all revenue related metric totals (Domestic + International + Others)\n#total system revenue\ntotal_revenue = import_df(path = 'Total revenue/System Total Operating Revenue.xls',column = 25, new_col_name = 'Total Operating Revenue ($)',formatting = 9)\n#revenue per asm\nrev_per_asm = import_df('Total revenue/System Total Revenue (Ex- Transport Related) per ASM.xls', 23, 'System Revenue Per ASM (exc-transport) ($ per ASM)', -2)\n#System Passenger revenue\nsys_pass_rev = import_df('Total revenue/System Passenger Revenue.xls', 25, \"System Passenger Revenue ($)\", 9 )\n#PRASM\nPRASM = import_df('Total revenue/System Passenger Revenue per Available Seat Mile (PRASM).xls', 23, 'System Passenger Revenue per ASM ($)', 9)\n#System Passenger yield, revenue per mile\npass_yield = import_df('Total revenue/System Passenger Yield.xls', 23, 'System Passenger Yield ($ per RPM)', -2)\n#System Total transport related revenue\ntrans_rev = import_df('Total revenue/System Total Transport Related Revenue.xls', 25, 'System Total Transport Related Revenue ($)', 9)\n#Ancillary fees revenue\nancillary = import_df('Total revenue/Ancillary Fee Revenue.xls', 23, 'Ancillary Fees ($)', 3)\n#all Revenues table\nrevenue=pd.concat([total_revenue,sys_pass_rev,trans_rev,PRASM,rev_per_asm,pass_yield,ancillary], axis=1)\nrevenue=revenue.astype('float64')\n\n\n# Employee compensation\n\n#full time employee equivalents\nFT_equiv = import_df('Total employee compensation/Total Full-time Employee Equivalents.xls', 23, 'Full Time Employees Equivalents')\n#full time non cockpit employee equivalents\nFT_NC_equiv = import_df('Total employee compensation/Total Full-time Employee Non Cockpit Equivalents.xls', 23, 'Full Time Non Cockpit Employees Equivalents')\n#all employees Avg wage\nall_wages_avg = import_df('Total employee compensation/Average Annual Wages and Salaries - All Employees.xls', 24, 'All Employees Avg Wage ($)', )\n#non cockpit employees Avg wage.\nNC_wages_avg = import_df('Total employee compensation/Average Annual Wages and Salaries - All Non-Cockpit Employees.xls', 24, 'Non Cockpit Employees Avg Wage ($)')\n#all employees avg benefits\nall_benefits = import_df('Total employee compensation/Average Pension and Benefit Package - ALL EMPLOYEES.xls', 24, 'All Employees average benefits and pensions ($)')\n#Non cockpit employees avg benefits\nNC_benefits = import_df('Total employee compensation/Average Pension and Benefit Package - ALL NON-COCKPIT EMPLOYEES.xls', 24, 'Non-Cockpit Employees average benefits and pensions ($)')\n#Pilot employee equivalents\npilot_equiv = import_df('Total employee compensation/Total Pilot and Copilot Employee Equivalents.xls', 23, 'Pilot and Co-Pilot equivalents')\n#Pilot employee wages\npilot_wage = import_df('Total employee compensation/Average Annual Wages and Salaries - PILOT AND CO-PILOT PERSONNEL.xls', 24, 'Average Pilot and Co-Pilot wages ($)')\n#flight attendant equivalents\nFA_equiv = import_df('Total employee compensation/Total Flight Attendant Employee Equivalents.xls', 23,'Flight Attendant Employee Equivalents')\n#flight attendant wages\nFA_wage = import_df('Total employee compensation/Average Annual Wages and Salaries - FLIGHT ATTENDANT PERSONNEL.xls', 24, 'Average Flight Attendant Employee Wage ($)')\n#ground staff equivalents\nground_equiv = import_df('Total employee compensation/Total In-House Passenger, Cargo and Aircraft Handling Employee Equivalents.xls', 23, 'Ground Staff Employee Equivalents')\n#average ground staff wages\navg_ground_wage = import_df('Total employee compensation/Average Annual Wages and Salaries - INHOUSE PASSENGER, CARGO AND AIRCRAFT HANDLING PERSONNEL.xls', 24, 'Average Ground Staff Employee Wage ($)')\n#maintenance employee equivalents\nmaint_equiv = import_df('Total employee compensation/Total In-House Maintenance Employee Equivalents.xls', 23, 'Maintenance Staff Equivalents')\n#average maintenance employee wage\nmaint_wage = import_df('Total employee compensation/Average Annual Wages and Salaries - INHOUSE MAINTENANCE PERSONNEL.xls', 24, 'Average Maintenance Staff Wage ($)')\n#Management equivalents\nmgmnt_equiv = import_df('Total employee compensation/Total Management and Other Employee Equivalents.xls', 23, 'Management and Others Equivalents')\n#Management wage\nmgmnt_wage = import_df('Total employee compensation/Average Annual Wages and Salaries - GENERAL MANAGEMENT AND OTHER PERSONNEL.xls', 24, 'Average Management and Others Wage ($)')\n#all compensations table\ncompensation=pd.concat([all_wages_avg,NC_wages_avg,FT_equiv,FT_NC_equiv,all_benefits,NC_benefits,pilot_equiv,pilot_wage,FA_equiv,FA_wage,ground_equiv,avg_ground_wage,maint_equiv,maint_wage,mgmnt_equiv,mgmnt_wage], axis=1)\ncompensation=compensation.astype('float64')\n\n# Productivity\n#ASM per $ employee compensation\nasm_per_comp = import_df('Total employees and productivity/Total ASMs Produced per Dollar of Employee Compensation.xls', 23, 'ASM Prodcued per Dollar Employee Compensation')\n#ASM produced per equivalent employee\nasm_per_equiv = import_df('Total employees and productivity/Total ASMs Produced per Employee Equivalent.xls', 23, 'ASM Prodcued per Employee Equivalent')\n#ASM produced per dollar pilot compensation \nasm_per_pilot_comp = import_df('Total employees and productivity/Total ASMs Produced per Dollar of Total Pilot Compensation.xls', 24, 'ASM Prodcued per Dollar Pilot Compensation')\n#Flight Attendant average block hours per month\nFA_avg_hours = import_df('Total employees and productivity/Total Flight Attendant Average Block Hours per Month.xls', 24, 'Total Flight Attendant Block Hours per Month')\n# % of maintenance expense outsource\nmaint_out = import_df('Total employees and productivity/Percent of Maintenance Expenses Outsourced.xls', 24, 'Percentage of maintenance expense outsourced')\n#Handling employees per a/c\nhandling_per_ac = import_df('Total employees and productivity/Passenger, Cargo and Aircraft Handling Employees per Aircraft.xls', 24, 'Handling Employees per Aircraft')\n#all productivity table\nproductivity=pd.concat([asm_per_equiv,asm_per_comp,asm_per_pilot_comp,FA_avg_hours,maint_out,handling_per_ac], axis=1)\nproductivity=productivity.astype('float64')\n\n# Expenses\n\n#total operating expenses\ntotal_op_expense = import_df('Total Expenses related/System Total Operating Expenses.xls', 25, 'Total Operating Expenses ($)', 9)\n#labour expenses\nlabour_exp = import_df('Total Expenses related/System Total Labor and Related Expenses.xls', 23, 'Total Labour Operating Expenses ($)', 9)\n#labour expenses per ASM (LCASM)\nLCASM = import_df('Total Expenses related/System Total Labor and Related Expense per Available Seat Mile (LCASM).xls', 23, ' Total Labour Operating Expenses per ASM($)', 9)\n#Total Fuel expense\nfuel_exp = import_df('Total Expenses related/Total Fuel Expense.xls', 23, 'Total Fuel Expenses ($)', 6)\n#Total gallons of fuel\nfuel_gallons = import_df('Total Expenses related/Total Gallons of Fuel.xls', 23, 'Total Fuel in Gallons', 6)\n#Price per gallon fuel \nfuel_price = import_df('Total Expenses related/Total Price per Gallon of Fuel.xls', 23, 'Fuel price per Gallon ($)')\n#fuel expenses per ASM\nfuel_asm = import_df('Total Expenses related/Fuel Expense per ASM.xls', 23, 'Total Fuel Expense per ASM')\n#fuel expense per passenger\nfuel_per_pass = import_df('Total Expenses related/Fuel Expense per Enplaned Passenger.xls', 23, 'Fuel Expense per Enplaned Passenger ($)')\n#CASM ex transport\ncasm_ex_trans = import_df('Total Expenses related/System Total Expense per Available Seat Mile (CASM ex Transport Related).xls', 23, 'CASM excluding Transport ($ per ASM)', -2)\n#CASM ex transport, fuel\ncasm_ex_trans_fuel = import_df('Total Expenses related/System Total Expense per Available Seat Mile (CASM ex fuel and Transport Related).xls', 23, 'CASM excluding Transport and Fuel ($ per ASM)', -2)                         \n#CASM ex transport, fuel, labour\ncasm_ex_trans_fuel_lab = import_df('Total Expenses related/System Non-Labor Expense per Available Seat Mile (CASM ex fuel, Transport Related and Labor).xls', 23, 'CASM excluding Transport Fuel and labour ($ per ASM)', -2)                          \n#transport related \ntransport_exp = import_df('Total Expenses related/Transport Related Expenses.xls', 23, 'Transport Related Expenses ($)', 6)\n#other outsourcing \noutsource_exp = import_df('Total Expenses related/Total Other Outsourcing Expense.xls', 23, 'Other Outsourcing Expenses ($)', 6)\n#management and other \nmgmnt_exp = import_df('Total Expenses related/System Total Management and Other.xls', 23, 'Management and Other Expenses ($)', 9)\n#mgmnt and other per ASM\nmgmnt_asm = import_df('Total Expenses related/System Management and Other Expense per Available Seat Mile.xls', 23, 'Management and Other Expenses per ASM')\n#flight equipment maintenance \nequip_maint_exp = import_df('Total Expenses related/Total Flight Equipment Maintenance Expense.xls', 23, 'Flight Equipment Maintenance Expense ($)', 6)\n#outsource flight equipment maintenance\nouts_equip_maint = import_df('Total Expenses related/Total Outsourced Flight Equipment Maintenance Expense.xls', 23, 'Outsourced Flight Equipment Maintenance Expense ($)', 6)\n#all expenses table\nexpenses=pd.concat([total_op_expense,labour_exp,LCASM,fuel_exp,fuel_asm,fuel_per_pass,fuel_gallons,fuel_price,transport_exp,outsource_exp,mgmnt_exp,mgmnt_asm,equip_maint_exp,outs_equip_maint, casm_ex_trans,casm_ex_trans_fuel,casm_ex_trans_fuel_lab], axis=1)\nexpenses=expenses.astype('float64')\n\n# Fleet\n\n#total operating fleet\nop_fleet = import_df('Total fleet/Total Operating Fleet.xls', 23, 'Total operating fleet numbers')\n#aircraft block hours\nac_block_hours = import_df('Total fleet/Total Aircraft Block Hours - ALL AIRCRAFT.xls', 24, 'Total Aircraft Block Hours')\n#aircraft airborne hours\nac_airborne_hours = import_df('Total fleet/Total Aircraft Airborne Hours - ALL AIRCRAFT.xls', 24, 'Total Aircraft Airborne Hours')\n#Gallons of fuel per block hour\ngallons_per_block_hour = import_df('Total fleet/Gallons of Fuel per Block Hour - ALL AIRCRAFT.xls', 24, 'Gallons Fuel per Block Hour')\n#Average stage length flown\navg_stage_length = import_df('Total fleet/Average Stage Length Flown of Total Operating Fleet.xls', 23, 'Average Stage Length Flown')\n#Average seat capacity \navg_seat_capacity = import_df('Total fleet/Average Seat Capacity of Total Operating Fleet.xls', 23, 'Average Seat Capacity per Aircraft')\n#Departure per aircraft day\ndep_per_ac = import_df('Total fleet/Departure per Aircraft Day - ALL AIRCRAFT.xls', 21, 'Departure per Aircraft Day', remove_unnamed= False)\n#all total fleet data\nfleet=pd.concat([op_fleet,ac_block_hours,ac_airborne_hours,gallons_per_block_hour,avg_stage_length,avg_seat_capacity,dep_per_ac], axis=1)\nfleet=fleet.astype('float64')\n\n# Traffic and Capacity\n\n#total asm\ntotal_asm = import_df('Total traffic and capacity by op region/Total System Available Seat Miles.xls', 25, 'Total Available Seat Miles (ASM)', 6)\n#total rpm\ntotal_rpm = import_df('Total traffic and capacity by op region/Total System Revenue Passenger Miles.xls', 25, 'Total Revenue Passenger Mile (RPM)', 6)\n#total enplaned passengers\ntotal_pass = import_df('Total traffic and capacity by op region/System Total Enplaned Passengers.xls', 23, 'Total Enplaned Passengers', 3)\n#total load factor\ntotal_load = import_df('Total traffic and capacity by op region/Total System Load Factor.xls', 23, 'Total Load Factor (%)', 2)\n#total passenger yield\ntotal_yield = import_df('Total traffic and capacity by op region/Total System Passenger Yield.xls', 23, 'Total Passenger Yield ($ per RPM)', -2)\n#total passenger revenue per asm\ntotal_rev_per_asm = import_df('Total traffic and capacity by op region/Total System Passenger Revenue per ASM.xls', 23, 'Total Passenger RPM per ASM ($ per ASM)', -2)\n#departed seats\ndep_seats = import_df('Total traffic and capacity by op region/Departed Seats.xls', 21, 'Total Departed Seats', 3, remove_unnamed=False)\ntotal_traffic=pd.concat([total_asm,total_rpm,total_pass,total_yield,total_rev_per_asm,total_load,dep_seats], axis=1)\ntotal_traffic=total_traffic.astype('float64')\n\n\n# Domestic \n#asm\ndom_asm = import_df('Total traffic and capacity by op region/Domestic Available Seat Miles .xls', 25, 'Domestic ASM')\n#asm % total asm\ndom_asm_perc = import_df('Total traffic and capacity by op region/Domestic Available Seat Miles as  a Percent of Total System Available Seat Miles.xls', 23, 'Domestic ASM as % of total ASM', 2)\n#revenue % total revenue\ndom_rev_perc = import_df('Total traffic and capacity by op region/Domestic Passenger Revenue as a Percent of Total System Revenue.xls', 23, 'Domestic Revenue as % of total Revenue', 2)\n#revenue per asm\ndom_rev_per_asm = import_df('Total traffic and capacity by op region/Domestic Passenger Revenue per ASM.xls', 23, 'Domestic Revenue ($) per ASM', -2)\n#passenger yeild\ndom_pass_yield = import_df('Total traffic and capacity by op region/Domestic Passenger Yield.xls', 23, 'Domestic Passenger Yield ($ per RPM)', -2)  \n#RPM\ndom_rpm = import_df('Total traffic and capacity by op region/Domestic Revenue Passenger Miles.xls', 25, 'Domestic RPM', 6)\n#rpm % total rpm\ndom_rpm_perc = import_df('Total traffic and capacity by op region/Domestic Revenue Passenger Miles as a Percent of Total System Revenue Passenger Miles.xls', 23, 'Domestic RPM as % of total RPM', 2)\n#revenue\ndom_rev = import_df('Total traffic and capacity by op region/Passenger Revenue -- Domestic Operations.xls', 25, 'Domestic Passenger Revenue ($)', 6)\n#load factor\ndom_load_factor = import_df('Total traffic and capacity by op region/Domestic Load Factor.xls', 23, 'Domestic Load Factor (%)', 2)\n#all domestic data\ndom_traffic=pd.concat([dom_asm,dom_asm_perc,dom_rev_perc,dom_rev_per_asm,dom_pass_yield, dom_rpm,dom_rpm_perc,dom_rev,dom_load_factor], axis=1)\ndom_traffic=dom_traffic.astype('float64')\n\n#International\n#asm\ninter_asm = import_df('Total traffic and capacity by op region/International Available Seat Miles .xls', 25,'International ASM', 6)\n#asm % total asm\ninter_asm_perc = import_df('Total traffic and capacity by op region/International Available Seat Miles as  a Percent of Total System Available Seat Miles.xls', 23, 'Internation ASM as % of total ASM', 2)\n#revenue % total revenue\ninter_rev_perc = import_df('Total traffic and capacity by op region/International Passenger Revenue as a Percent of Total System Revenue.xls', 23, 'International Revenue as % of total Revenue', 2)\n#revenue per asm\ninter_rev_per_asm = import_df('Total traffic and capacity by op region/International Passenger Revenue per ASM.xls', 23, 'International Revenue ($) per ASM',-2)\n#passenger yeild\ninter_pass_yield = import_df('Total traffic and capacity by op region/International Passenger Yield.xls', 23, 'International Passenger Yield ($ per RPM)', -2)\n#RPM\ninter_rpm = import_df('Total traffic and capacity by op region/International Revenue Passenger Miles.xls', 25, 'International RPM', 6)\n#rpm % total rpm\ninter_rpm_perc = import_df('Total traffic and capacity by op region/International Revenue Passenger Miles as a Percent of Total System Revenue Passenger Miles.xls', 23, 'International RPM as % of total RPM', 2)\n#revenue\ninter_rev = import_df('Total traffic and capacity by op region/Passenger Revenue -- International Operations.xls', 25, 'International Passenger Revenue ($)', 6)\n#load factor\ninter_load_factor = import_df('Total traffic and capacity by op region/International Load Factor .xls', 23, 'International Load Factor', 2)\ninter_traffic=pd.concat([inter_asm,inter_asm_perc,inter_rev_perc,inter_rev_per_asm,inter_pass_yield,inter_rpm,inter_rpm_perc,inter_rev,inter_load_factor], axis=1)\ninter_traffic=inter_traffic.astype('float64')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Revenue - recreate table with individual airlines and their types\nairline_rev=pd.read_excel(\"/kaggle/input/airline-data-project-mit-1995-2019/Original MIT data/Original MIT data/Total revenue/System Total Operating Revenue.xls\")\nairline_rev=airline_rev.drop([\"Unnamed: 1\"],axis=1) #removing empty column\nairline_rev=airline_rev.transpose() #transposing data frame \nheader=airline_rev.iloc[0] #make new list of header _revfrom airline names\nairline_rev=airline_rev[1:] #deleting unwanted row\nairline_rev=airline_rev.rename(columns = header) #replacing the column headers with list header we just made\nYear=np.arange(1995,2019,1)\nairline_rev[\"Year\"]=Year #make a series to fill in year column\nairline_rev=airline_rev.loc[:,[\"Year\",\"American\",\"Delta\",\"United\",\" --sub Network\",\"Southwest\",\"Frontier\",\"Alaska\",\n                               \" -- sub LCC\",\"Hawaiian\",\"Spirit\",\" -- sub Other\",\"Total Industry\"]] #take relevant columns only\n\nairline_rev.reset_index(drop=True, inplace=True) #reset index\nairline_rev.set_index(\"Year\", inplace=True) #make year the new index\nairline_rev=airline_rev*10**9\nairline_rev.astype('float64')\n\n# Revenue Individual airlines\nAmerican_rev=airline_rev[\"American\"].sum()\nDelta_rev=airline_rev[\"Delta\"].sum()\nUnited_rev=airline_rev[\"United\"].sum()\nSouthwest_rev=airline_rev[\"Southwest\"] .sum()\nFrontier_rev=airline_rev[\"Frontier\"].sum()\nAlaska_rev=airline_rev[\"Alaska\"].sum()\nHawaiian_rev=airline_rev[\"Hawaiian\"].sum()\nSpirit_rev=airline_rev[\"Spirit\"].sum()\n\nairlines_rev=np.array([American_rev,Delta_rev,United_rev,Southwest_rev,Frontier_rev,Alaska_rev,Hawaiian_rev,Spirit_rev])\nLabels1=[\"\",\"American\",\"Delta\",\"United\",\"Southwest\",\"Frontier\",\"Alaska\",\"Hawaiian\",\"Spirit\"]\n\n#airline types\nnetwork_rev=airline_rev[\" --sub Network\"].sum()\nLCC_rev=airline_rev[\" -- sub LCC\"].sum()\nOther_rev=airline_rev[\" -- sub Other\"].sum()\n\nairline_types_rev=[network_rev, LCC_rev, Other_rev]\nLabels2=[\"\",\"Network\",\"LCC\",\"Other\"]\n\n#Expenses - recreate table with individual airlines and their types\nairline_exp=pd.read_excel(\"/kaggle/input/airline-data-project-mit-1995-2019/Original MIT data/Original MIT data/Total Expenses related/System Total Operating Expenses.xls\")\nairline_exp=airline_exp.transpose() #transposing data frame \nheader=airline_exp.iloc[0] #make new list of header from airline names\nairline_exp=airline_exp.rename(columns = header) #replacing the column headers with list header we just made\nairline_exp=airline_exp[2:]\nYear=np.arange(1995,2019,1)\nairline_exp[\"Year\"]=Year #make a series to fill in year column\nairline_exp=airline_exp.loc[:,[\"Year\",\"American\",\"Delta\",\"United\",\" --sub Network\",\"Southwest\",\"Frontier\",\"Alaska\",\n                               \" -- sub LCC\",\"Hawaiian\",\"Spirit\",\" -- sub Other\",\"Total Industry\"]] #take relevant columns only\nairline_exp.reset_index(drop=True, inplace=True) #reset index\nairline_exp.set_index(\"Year\", inplace=True) #make year the new index\nairline_exp=airline_exp*10**9\nairline_exp.astype('float64')\n\n#Expenses - Individual airlines\nAmerican_exp=airline_exp[\"American\"].sum()\nDelta_exp=airline_exp[\"Delta\"].sum()\nUnited_exp=airline_exp[\"United\"].sum()\nSouthwest_exp=airline_exp[\"Southwest\"] .sum()\nFrontier_exp=airline_exp[\"Frontier\"].sum()\nAlaska_exp=airline_exp[\"Alaska\"].sum()\nHawaiian_exp=airline_exp[\"Hawaiian\"].sum()\nSpirit_exp=airline_exp[\"Spirit\"].sum()\n\nairlines_exp=np.array([American_exp,Delta_exp,United_exp,Southwest_exp,Frontier_exp,Alaska_exp,Hawaiian_exp,Spirit_exp])\nLabels3=[\"\",\"American\",\"Delta\",\"United\",\"Southwest\",\"Frontier\",\"Alaska\",\"Hawaiian\",\"Spirit\"]\n\nnetwork_exp=airline_exp[\" --sub Network\"].sum()\nLCC_exp=airline_exp[\" -- sub LCC\"].sum()\nOther_exp=airline_exp[\" -- sub Other\"].sum()\n\nairline_types_exp=np.array([network_exp,LCC_exp ,Other_exp])\nairline_types_rev=np.array([airline_rev[\" --sub Network\"].sum(), airline_rev[\" -- sub LCC\"].sum(),airline_rev[\" -- sub Other\"].sum()])\n\nLabels4=[\" \",\"Network\",\"LCC\",\"Other\"]\n\n# profits\nairlines_prof=airlines_rev-airlines_exp\n\nairline_types_prof=airline_types_rev-airline_types_exp\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#passengers enplaned - recreate table with individual airlines and their types\nairline_pass=pd.read_excel(\"/kaggle/input/airline-data-project-mit-1995-2019/Original MIT data/Original MIT data/Total traffic and capacity by op region/System Total Enplaned Passengers.xls\")\nairline_pass=airline_pass.drop([\"Unnamed: 1\"],axis=1) #removing empty column\nairline_pass=airline_pass.transpose() #transposing data frame \nheader=airline_pass.iloc[0] #make new list of header _revfrom airline names\nairline_pass=airline_pass[1:] #deleting unwanted row\nairline_pass=airline_pass.rename(columns = header) #replacing the column headers with list header we just made\n\n#airline_pass.reindex(columns=filtered_columns)\nYear=np.arange(1995,2019,1)\nairline_pass[\"Year\"]=Year #make a series to fill in year column\n\nairline_pass=airline_pass.loc[:,[\"Year\",\"American\",\"Delta\",\"United\",\" --sub Network\",\"Southwest\",\"Frontier\",\"Alaska\",\n                               \" --sub LCC\",\"Hawaiian\",\"Spirit\",\" -- sub Other\",\"Total All Sectors\"]] #take relevant columns only\n\nairline_pass.reset_index(drop=True, inplace=True) #reset index\nairline_pass.set_index(\"Year\", inplace=True) #make year the new index\nairline_pass=airline_pass*10**3\nairline_pass.astype('float64')\n\n# Revenue Individual airlines\nAmerican_pass=airline_rev[\"American\"].sum()\nDelta_pass=airline_rev[\"Delta\"].sum()\nUnited_pass=airline_rev[\"United\"].sum()\nSouthwest_pass=airline_rev[\"Southwest\"] .sum()\nFrontier_pass=airline_rev[\"Frontier\"].sum()\nAlaska_pass=airline_rev[\"Alaska\"].sum()\nHawaiian_pass=airline_rev[\"Hawaiian\"].sum()\nSpirit_pass=airline_rev[\"Spirit\"].sum()\n\nairlines_pass=np.array([American_pass,Delta_pass,United_pass,Southwest_pass,Frontier_pass,Alaska_pass,Hawaiian_pass,Spirit_pass])\npass_labels=[\"American\",\"Delta\",\"United\",\"Southwest\",\"Frontier\",\"Alaska\",\"Hawaiian\",\"Spirit\"]\n\n#airline types\nnetwork_pass=airline_pass[\" --sub Network\"].sum()\nLCC_pass=airline_pass[\" --sub LCC\"].sum()\nOther_pass=airline_pass[\" -- sub Other\"].sum()\n\nairline_types_pass=[network_pass, LCC_pass, Other_pass]\npass_type_labels=[\"Network\",\"LCC\",\"Other\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Collecting variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.concat([revenue,inter_traffic,dom_traffic,total_traffic,fleet,expenses,productivity,compensation], axis=1)\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Engineering\nTotal Profits and the number of flights are very important metrics that are relevant to our research questions and tell us alot about the industry but they are not implicitly specified in the data set."},{"metadata":{"trusted":true},"cell_type":"code","source":"#profits\ndf[\"Total Profits\"] = df[\"Total Operating Revenue ($)\"]- df[\"Total Operating Expenses ($)\"]\n\n#Number of flights per year and day\ndf[\"Flights per Year\"]=(df[\"Total Departed Seats\"]/df[\"Average Seat Capacity per Aircraft\"])/1000\ndf[\"Flights per day\"]=(df[\"Total Departed Seats\"]/df[\"Average Seat Capacity per Aircraft\"])/(365)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dimension Reduction and Feature Selection\n\n### PCA\n\nThere is a large number of features present in the data set. Reducing the number of dimensions and looking into the principle components can help us understand which features are important and if there is any underlying structure to the data set. "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\nfrom sklearn import preprocessing\n\nScaler = preprocessing.MinMaxScaler(feature_range=(0,1))\ndf_scaled = Scaler.fit_transform(df)\ndf_normal = pd.DataFrame(df_scaled)\n\npca = PCA(n_components=2)\npca.fit(df_normal)\nprint(\"First principle component accounts for \",pca.explained_variance_ratio_[0], \"of all variance\")\nprint(\"Second principle component accounts for \",pca.explained_variance_ratio_[1], \"of all variance\")\ndf_normal.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_projected=pca.transform(df_normal)\nprint(df_projected.shape)\nplt.figure(figsize=(8,8))\nplt.suptitle('First two components')\nplt.xlabel('PC_1')\nplt.ylabel('PC_2')\nplt.scatter(df_projected[:,0], df_projected[:,1], c = \"#D06B36\", s = 50, linewidth=0)\n#need to normalise range normalise, scale with min and max or wrt to std with z scores for more robust","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Theres seems to be no clear relationship between principle components"},{"metadata":{"trusted":true},"cell_type":"code","source":"column_names=np.asarray(df.columns.values)\n#show top 10 loadings of PC 1  \npc_1_loadings = np.asarray(pca.components_[0])[np.argsort( np.abs(pca.components_[0]))[::-1]][0:10]\npc_1_names = np.asarray(column_names)[np.argsort( np.abs(pca.components_[0]))[::-1]][0:10]\n\nfor i in range(0, 10):\n    print ( \"Column \\\"\" , pc_1_names[i] , \"\\\" has a loading of: \", pc_1_loadings[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#show top 10 loadings of PC 2  \npc_2_loadings = np.asarray(pca.components_[1])[np.argsort( np.abs(pca.components_[1]))[::-1]][0:10]\npc_2_names = np.asarray(column_names)[np.argsort( np.abs(pca.components_[1]))[::-1]][0:10]\n\nfor i in range(0, 10):\n    print ( \"Column \\\"\" , pc_2_names[i] , \"\\\" has a loading of: \", pc_2_loadings[i])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Further PCA\n\nWe can attempt try to do a more local PCA analysis to see if the components can be better interpreted :\n\n#### Local Analysis:"},{"metadata":{"trusted":true},"cell_type":"code","source":"#select first component \ncolumns_selected = np.argsort( np.abs(pca.components_[0]))[::-1][0:10]\ncolumn_names_selected = column_names[columns_selected]\ndf_selected = df_normal[:][columns_selected]\ndf_selected=pd.DataFrame(df_selected)\ndf_selected.columns=column_names_selected","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build a model that will return two principal components\npca_selected = PCA(n_components=2)\n\n# We first fit a PCA model to the data\npca_selected.fit(df_selected)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"projected_df_selected = pca_selected.transform(df_selected)\n\nplt.figure(figsize=(8,8))\nplt.suptitle('PCs for Ailine Capacity and Income Variable')\nplt.xlabel('PC_1')\nplt.ylabel('PC_2')\nplt.scatter(projected_df_selected[:,0], projected_df_selected[:,1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (\"--- Firstly, the first component: \")\npc_1_loadings = np.asarray(pca_selected.components_[0])[np.argsort( np.abs(pca_selected.components_[0]))[::-1]][0:10]\npc_1_names = np.asarray(column_names_selected)[np.argsort( np.abs(pca_selected.components_[0]))[::-1]][0:10]\n\nfor i in range(0, 10):\n    print ( \"Column \\\"\" , pc_1_names[i] , \"\\\" has a loading of: \", pc_1_loadings[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (\"--- Secondly, the second component: \")\npc_2_loadings = np.asarray(pca_selected.components_[1])[np.argsort( np.abs(pca_selected.components_[1]))[::-1]][0:10]\npc_2_names = np.asarray(column_names_selected)[np.argsort( np.abs(pca_selected.components_[1]))[::-1]][0:10]\n\nfor i in range(0, 10):\n    print ( \"Column \\\"\" , pc_2_names[i] , \"\\\" has a loading of: \", pc_2_loadings[i])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Both components from a locally selected dataset return similar results. We have not been able to derive any further detail or structure from this further analysis. "},{"metadata":{},"cell_type":"markdown","source":"# Correlations accross all features with Revenue and Profits"},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = df.corr()\n#print(corr.head())\n\nplt.figure(figsize = (15,15))\nimport seaborn as sns\n\nmask=np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)]=True\n\nax = sns.heatmap(\n    corr, \n    mask=mask,\n    vmax=1, center=0,\n    cmap=sns.diverging_palette(20, 220, n=200))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = df.corr()\n\n#sort by the amount of correlation\nrevenue_corr = corr[[\"Total Operating Revenue ($)\"]]\nrevenue_corr=revenue_corr.sort_values(by =[\"Total Operating Revenue ($)\"],ascending=False)\n\nprofit_corr = corr[[\"Total Profits\"]]\nprofit_corr=profit_corr.sort_values(by =[\"Total Profits\"],ascending=False)\n\nplt.figure(figsize = (20,20))\n\nax=plt.subplot(121)\n\nimport seaborn as sns\nax = sns.heatmap(\n    revenue_corr, \n    vmin=-1, vmax=1, center=0,\n    cmap=sns.diverging_palette(20, 220, n=200),\n    square=True)\nax.set_title(\"Revenue Correlation Bar\", fontsize=15, color='dimgrey')\n\nax1=plt.subplot(122)\n\nax1 = sns.heatmap(\n    profit_corr, \n    vmin=-1, vmax=1, center=0,\n    cmap=sns.diverging_palette(20, 220, n=200),\n    square=True)\nax1.set_title(\"Profits Correlation Bar\", fontsize=15, color='dimgrey')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = df[column_names_selected].corr()\n#print(corr.head())\n\nplt.figure(figsize = (5,5))\nimport seaborn as sns\n\nmask=np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)]=True\n\nax = sns.heatmap(\n    corr, \n    mask=mask,\n    vmax=1, center=0,\n    cmap=sns.diverging_palette(20, 220, n=200)\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Summary statistics of top PCA loading feautres\ndf[column_names_selected].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Pair Plot of selected features"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(df[column_names_selected])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The selected features are dominated by a mix of strong positive or negative correlations between them as demonstrated by the correlation heat map prior."},{"metadata":{},"cell_type":"markdown","source":"# Feature Importance"},{"metadata":{},"cell_type":"markdown","source":"# EDA"},{"metadata":{},"cell_type":"markdown","source":"# Revenue, Expenses and Profit\nLooking at trends in Revenue, Expenses and Profits across the industry, and in it's subsets."},{"metadata":{"trusted":true},"cell_type":"code","source":"color = sns.color_palette(\"RdBu\")\n#sns.palplot(color)\n\n#tick formatter \ndef billions(x, pos):\n    return '$%1.1fB' % (x*1e-9)\nformatter = FuncFormatter(billions)\n\nplt.figure(figsize=(15, 7.5)) \nax1 = plt.subplot(111)  \n\nYear=np.arange(1995,2019,1)\n\n#turn off axis spines\nax1.spines[\"top\"].set_visible(False)    \nax1.spines[\"bottom\"].set_visible(False)    \nax1.spines[\"right\"].set_visible(False)    \nax1.spines[\"left\"].set_visible(False) \n\n#share x axis\nax2 = ax1.twinx()\n\n#turn off axis spines\nax2.spines[\"top\"].set_visible(False)    \nax2.spines[\"bottom\"].set_visible(False)    \nax2.spines[\"right\"].set_visible(False)    \nax2.spines[\"left\"].set_visible(False)\n\n#x axis tick parameters\nax1.xaxis.set_tick_params(labelsize=10, rotation=45)\nax1.xaxis.set_ticks(np.arange(1995, 2018, 1))\n\nax1.tick_params(axis=\"both\", which=\"both\", bottom=False, top=False, labelbottom=True, left=False, right=False, labelleft=True)    \nax2.tick_params(right=False) \n\nax1.set_ylabel(\"Profit\", fontsize=12, rotation=0)\n\nax2.set_ylabel(\"Revenues \\nand \\nExpenses\",fontsize=12,rotation=0)\nax2.yaxis.set_label_coords(1.1,0.5)\n\n#plot data on axis\nax1.bar(Year, df[\"Total Profits\"], label= \"Profit/Loss\", alpha=0.5, color=(df[\"Total Profits\"] > 0).map({True: 'g', False: 'r'}))\n\nax2.plot(df[\"Total Operating Revenue ($)\"], label =\"Revenue\",color =color[-1],ls=\"--\", lw=2.5)\nax2.plot((df[\"Total Operating Expenses ($)\"]), label =\"Expenses\",color =color[0],ls=\"--\", lw=2.5)\n\n#format y ticks to billions\nax1.yaxis.set_major_formatter(formatter)\nax2.yaxis.set_major_formatter(formatter)\nax2.set_ylim(0,230e9 )\n\n#add legend\nax1.legend(bbox_to_anchor=(0.13, 0.9))\nax2.legend(bbox_to_anchor=(0.125, 1))\nax1.grid(False)\nax2.grid(False)\nax1.xaxis.grid(which=\"major\")\n\n#font parameters\ntitle_font = {'family': 'sans-serif','color':  'dimgrey','weight': 'normal','size': 15,}#title font\nplt.title(\"Total Industry Profits - 1995 to 2018 \", loc='center',fontdict=title_font, fontsize=15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"color = sns.color_palette(\"tab20c\")\nsns.palplot(color)\n\nbarwidth1=0.2\nbarwidth2=0.2\n\nplt.figure(figsize=(17.5,15))\n\nax1=plt.subplot(211)\n\nclrs1=[color[0],color[0],color[0],color[4],color[4],color[8],color[8],color[8]]\nclrs2=[color[1],color[5],color[9]]\n\nclrs3=[color[2],color[2],color[2],color[6],color[6],color[10],color[10],color[10]]\nclrs4=[color[0],color[4],color[8]]\n\nclrs5=[color[1],color[1],color[1],color[5],color[5],color[9],color[9],color[9]]\nclrs6=[color[1],color[5],color[9]]\n\nrev_x1=(np.arange(1,9))-0.25\nexp_x1=(np.arange(1,9))\nrev_x2=np.arange(1,4)-0.25\nexp_x2=np.arange(1,4)\n\nprof_x1=(np.arange(1,9))+0.25\nprof_x2=np.arange(1,4)+0.25\n\nax1.bar(rev_x1, airlines_rev, color=clrs1,width=barwidth1)\nax1.bar(exp_x1, airlines_exp, color=clrs3, width=barwidth1)\nax1.bar(prof_x1, airlines_prof, color=clrs5, width=barwidth1)\nax1.yaxis.set_major_formatter(formatter)\nax1.set_ylabel(\"Dollars ($)\")\nax1.set_xlabel(\"Airline\")\nax1.set_xticklabels(Labels1)\nax1.set_title(\"Cumulative Revenue-Expense-Profits of Airlines 1995-2018\")\nax1.grid(axis='y')\n\nax2=plt.subplot(212)\n\nax2.bar(rev_x2,airline_types_rev, color=clrs2,alpha=0.8,width=barwidth2)\nax2.bar(exp_x2,airline_types_exp, color=clrs4,alpha=0.8,width=barwidth2)\nax2.bar(prof_x2,airline_types_prof, color=clrs6,alpha=0.8,width=barwidth2)\nax2.yaxis.set_major_formatter(formatter)\nax2.set_ylabel(\"Dollars ($)\")\nax2.set_xlabel(\"Airline Type\")\nax2.set_xticks((np.arange(4)))\nax2.set_xticklabels(Labels4)\nax2.set_xlim(0.4,3.6)\nax2.set_title(\"Cumulative Revenue-Expense-Profits of Airline types 1995-2018\")\nax2.grid(axis='y')\n\nprint(\"Network carrier produce\",(airline_types_prof/airline_types_rev)[0]*100, \"% profit\")\nprint(\"Low cost carrier produce\",(airline_types_prof/airline_types_rev)[1]*100, \"% profit\")\nprint(\"Other airlines produce\",(airline_types_prof/airline_types_rev)[2]*100, \"% profit\")\n\n\nprint(airline_types_prof)\nprint(\"ratio of Network profit vs LCC \",(airline_types_prof[0]/airline_types_prof[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,15))\nLabels=[\"Network\",\"LCC\",\"Other\"]\nax1=plt.subplot(121)\nax1.pie(airline_types_rev, labels=Labels, autopct='%1.1f%%')\nax1.set_title(\"Airline Revenue\")\n\nax2=plt.subplot(122)\nax2.pie(airline_types_exp, labels=Labels, autopct='%1.1f%%')\nax2.set_title(\"Airline Expense\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Domestic vs International \n\n### differences and importance"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['International ASM']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#tick formatter \ndef billions(x, pos):\n    return '%1.1fB' % (x*1e-9)\nformatter = FuncFormatter(billions)\n\nplt.figure(figsize=(12.5,10))\nax1=plt.subplot(221)\n\np1=plt.bar(Year, df[\"Domestic ASM\"], label=\"Domestic\")\np2=plt.bar(Year, df[\"International ASM\"], label=\"International\")\nax1.yaxis.set_major_formatter(formatter)\nplt.title(\"Available Seat Miles (ASM)\")\nplt.legend()\n\nax2=plt.subplot(222)\n\np3=plt.bar(Year, df[\"Domestic RPM\"],label=\"Domestic\")\np4=plt.bar(Year, df[\"International RPM\"],label=\"International\")\nax2.yaxis.set_major_formatter(formatter)\nplt.title(\"Revenue Per Mile (RPM)\")\nplt.legend()\n\nax3=plt.subplot(223)\n\np5=plt.bar(Year, df[\"Domestic Load Factor (%)\"],label=\"Domestic\")\np6=plt.bar(Year, df[\"International Load Factor\"],label=\"International\", alpha=0.5)\nplt.title(\"Load Factor\")\nplt.legend()\n\nax4=plt.subplot(224)\n\np7=plt.bar(Year, df[\"Domestic Passenger Revenue ($)\"],label=\"Domestic\")\np8=plt.bar(Year, df[\"International Passenger Revenue ($)\"],label=\"International\")\nax4.yaxis.set_major_formatter(formatter)\nplt.title(\"Passenger Revenue\")\nplt.legend()           \nplt.show()\n           \nprint(\"Avg Domestic ASM % of total: \",np.mean(df[\"Domestic ASM as % of total ASM\"]))\nprint(\"Avg International ASM % of total: \", np.mean(df[\"Internation ASM as % of total ASM\"]))\nprint(\"\")\n\nprint(\"Avg Domestic RPM % of total: \",np.mean(df[\"Domestic RPM as % of total RPM\"]))\nprint(\"Avg International RPM % of total: \", np.mean(df[\"International RPM as % of total RPM\"]))\nprint(\"\")\n\nprint(\"Avg Domestic Load factor\", np.mean(df[\"Domestic Load Factor (%)\"]))\nprint(\"Avg International Load Factor\", np.mean(df[\"International Load Factor\"]))\nprint(\"\")           \n\nprint(\"Avg Domestic Revenue % of total: \", np.mean(df[\"Domestic Revenue as % of total Revenue\"]))\nprint(\"Avg International Revenue % of total: \", np.mean(df[\"International Revenue as % of total Revenue\"]))\nprint(\"\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#airline types\nnetwork_rev=airline_rev[\" --sub Network\"]\nLCC_rev=airline_rev[\" -- sub LCC\"]\nOther_rev=airline_rev[\" -- sub Other\"]\n\nairline_types_rev=[network_rev, LCC_rev, Other_rev]\nLabels2=[\"Network Airlines\",\"LCC Airlines\",\"Other Airlines\"]\n\nplt.figure(figsize=(10,5))\nax1=plt.subplot(111)\nax1.plot(network_rev,label=Labels2[0])\nax1.plot(LCC_rev,label=Labels2[1])\nax1.plot(Other_rev,label=Labels2[2])\nax1.set_xlabel(\"Year\")\nax1.set_ylabel(\"Revenue\")\nax1.grid(axis='x')\nax1.set_title(\"Revenue of Different Airline Business models\")\nax1.yaxis.set_major_formatter(formatter)\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nax1=plt.subplot(111)\nax1.plot(df[\"Domestic Passenger Revenue ($)\"], label=\"Domestic Flights\")\nax1.plot(df[\"International Passenger Revenue ($)\"], label=\"International Flights\")\nax1.grid(axis='x')\nax1.set_xlabel(\"Year\")\nax1.set_ylabel(\"Revenue\")\nax1.set_title(\"Revenue of Different flight types\")\nax1.yaxis.set_major_formatter(formatter)\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(df[\"Domestic Revenue as % of total Revenue\"])\nplt.plot(df[\"International Revenue as % of total Revenue\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Flight Traffic\n\n### Flights and Passengers\n\nASM describes the capacity to generate revenue so it would make sense to look into to traffic metrics as this is what gives rise to the available capacity. \nWe will look into number of flights, number of total passengers against revenue as well as ASM and RPM:"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12.5, 12.5)) \ncolor = sns.color_palette(\"RdBu\")\nax1 = plt.subplot(211)  \n\nax1.spines[\"top\"].set_visible(False)    \nax1.spines[\"bottom\"].set_visible(False)    \nax1.spines[\"right\"].set_visible(False)    \nax1.spines[\"left\"].set_visible(False) \n\nax2 = ax1.twinx()\n\nax2.spines[\"top\"].set_visible(False)    \nax2.spines[\"bottom\"].set_visible(False)    \nax2.spines[\"right\"].set_visible(False)    \nax2.spines[\"left\"].set_visible(False)\n\nax1.xaxis.set_tick_params(labelsize=10)\nax1.xaxis.set_ticks(np.arange(1995, 2018, 2))\n\n\nax1.tick_params(axis=\"both\", which=\"both\", bottom=False, top=False, labelbottom=True, left=False, right=False, labelleft=True)    \nax2.tick_params(right=False) \n\nax1.set_ylabel(\"Flights Per Day (Thousand)\",color=\"dimgrey\")\nax2.set_ylabel(\"Revenue ($)\",color=\"dimgrey\")\n\nax1.plot(df[\"Flights per day\"],ls=\":\",lw=2.5,color=color[-1],label=\"Industry Flights Per Day\")\nax2.plot(total_revenue,color =color[0],ls=\":\", lw=2.5, label=\"Industry Total Revenue\")\n\nax1.legend(bbox_to_anchor=(0.1, 0.08), loc=2,)\nax2.legend(bbox_to_anchor=(0.1, 0.13), loc=2,)\nax1.grid(False)\nax2.grid(False)\nax1.xaxis.grid(which=\"major\")\n\n#format y ticks to billions for axis 2\n\nax2.yaxis.set_major_formatter(formatter)\n\ntitle_font = {'family': 'sans-serif','color':  'dimgrey','weight': 'normal','size': 12,}#title font\nplt.title(\"Flights per Day vs Revenue - 1995 to 2018 \", loc='center',fontdict=title_font, fontsize=15)\n\nax3 = plt.subplot(212)  \n\nax3.spines[\"top\"].set_visible(False)    \nax3.spines[\"bottom\"].set_visible(False)    \nax3.spines[\"right\"].set_visible(False)    \nax3.spines[\"left\"].set_visible(False) \n\nax4 = ax3.twinx()\n\nax4.spines[\"top\"].set_visible(False)    \nax4.spines[\"bottom\"].set_visible(False)    \nax4.spines[\"right\"].set_visible(False)    \nax4.spines[\"left\"].set_visible(False)\n\nax3.xaxis.set_tick_params(labelsize=10)\nax3.xaxis.set_ticks(np.arange(1995, 2018, 2))\n\n\nax3.tick_params(axis=\"both\", which=\"both\", bottom=False, top=False, labelbottom=True, left=False, right=False, labelleft=True)    \nax4.tick_params(right=False) \n\nax3.set_ylabel(\"Enplaned Passengers\",color=\"dimgrey\")\nax4.set_ylabel(\"Revenue ($)\",color=\"dimgrey\")\n\nax3.plot((total_traffic[\"Total Enplaned Passengers\"]/365),ls=\":\",lw=2.5,color=color[-1],label=\"Total Enpland Passengers\")\nax4.plot(total_revenue,color =color[0],ls=\":\", lw=2.5, label=\"Industry Total Revenue\")\n\nax3.legend(bbox_to_anchor=(0.1, 0.08), loc=2,)\nax4.legend(bbox_to_anchor=(0.1, 0.13), loc=2,)\nax3.grid(False)\nax4.grid(False)\nax3.xaxis.grid(which=\"major\")\n\n#format y ticks to billions for axis 2\n\nax4.yaxis.set_major_formatter(formatter)\n\ntitle_font = {'family': 'sans-serif','color':  'dimgrey','weight': 'normal','size': 12,}#title font\nplt.title(\"Passengers per day vs Revenue - 1995 to 2018 \", loc='center',fontdict=title_font, fontsize=15)\nimport scipy as sp\nprint(\"Correlaion of number of passengers with revenue\", sp.stats.pearsonr(df[\"Total Enplaned Passengers\"],df[\"Total Operating Revenue ($)\"] )[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Very strong correlation between number of enplaned passengers with revenue. The divergence or convergence between the two variables can indicate a rise or drop in how much revenue per passenger is made. External events will have a big influence on how people travel and this shown with the way the dips coincide with said events. It is through the passengers through which external events can shock the operating revenues."},{"metadata":{"trusted":true},"cell_type":"code","source":"#tick formatter \ndef billions(x, pos):\n    return '%1.1fB' % (x*1e-9)\nformatter = FuncFormatter(billions)\n\nplt.figure(figsize=(17.5,7.5))\nax1=plt.subplot(121)\nax1.bar(pass_labels,airlines_pass, color=clrs1)\nax1.set_title(\"Total Number of Enplaned Passengers per Airline\")\nax1.set_ylabel(\"Enplaned Passengers\")\nax1.set_xlabel(\"Airline\")\nax1.yaxis.set_major_formatter(formatter)\nax1.grid(axis='y')\n\nax2=plt.subplot(122)\nax2.bar(pass_type_labels,airline_types_pass,color=clrs4)\nax2.set_title(\"Total Number of Enplaned Passengers per Airline Type\")\nax2.set_ylabel(\"Enplaned Passengers\")\nax2.set_xlabel(\"Airline Type\")\nax2.yaxis.set_major_formatter(formatter)\nax2.grid(axis='y')\n\nplt.figure()\nax3=plt.subplot(111)\nax3.set_title(\"Market share of Passengers\")\nax3.pie(airline_types_pass,labels=Labels, autopct='%1.1f%%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"color = sns.color_palette(\"Paired\")\nsns.palplot(color)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Relative Change in ASM and RPM over the years is very small\n#Calculate the percentage change and plot that instead of actual values\nYear=np.arange(1995,2019,1)\n\n#Percentage change ASM\ndf[\"% ASM Change\"]=total_asm.pct_change()\ndf[\"% RPM Change\"]=total_rpm.pct_change()\n\n#fill first gap with 0\ndf[\"% RPM Change\"]=df[\"% RPM Change\"].fillna(0)\ndf[\"% ASM Change\"]=df[\"% ASM Change\"].fillna(0)\n\n#define bar height variables\nASM=df[\"% ASM Change\"].fillna(0)\nRPM=df[\"% RPM Change\"].fillna(0)\n\n#set bar width\nbarwidth=0.35\n\n#create figure\nplt.figure(figsize=(10,12.5))\nax1=plt.subplot(311)\nplt.subplots_adjust(hspace=0.4)\n\n#x position of bars (asm at x and rpm at x + barwidth)\nasm_x=Year\nrpm_x=[x+barwidth for x in asm_x]\n\n#plot bars\nax1.bar(asm_x,ASM,width=barwidth,color =color[1],alpha=0.8, label=\"Available Seat Miles\" )\nax1.bar(rpm_x,RPM,width=barwidth, color=color[5],alpha=0.8, label=\"Revenue Per Mile\")\n\n\n#configure axis, ticks and legend\nax1.set_xlabel(\"Year\")\nax1.set_ylabel(\"% Change\")\nax1.set_title(\"Year-on-Year Percentage change of ASM and RPM\")\n#ax1.set_xticks(rotation=45)\nax1.set_xlim(1997,2019)\nplt.xticks(rotation=45)\nax1.set_xticks(Year)\nax1.grid(axis='x')\nax1.legend()\n\nax2=plt.subplot(312)\n\nflights=df[\"Flights per Year\"]\n\n\nflights_x=Year\n\nplt.bar(flights_x, flights, width=barwidth,color=color[3], alpha=0.8, label=\"Flights per Day\")\n\n#configure axis, ticks and legend\nplt.xlabel(\"Year\")\nplt.ylabel(\"Number of Flights\")\nplt.title(\"Number of Flights per Year\")\nplt.xticks(rotation=45)\nplt.xlim(1995,2019)\nax2.xaxis.set_ticks(Year)\nplt.grid(axis='x')\nplt.legend()\n\nax3=plt.subplot(313)\n\npassengers=(df[\"Total Enplaned Passengers\"])\n\npass_x=Year\n\nplt.bar(pass_x, passengers, width=barwidth,color=color[7], alpha=0.8, label=\"Passengers per Year\")\n\n#configure axis, ticks and legend\nplt.xlabel(\"Year\")\nplt.ylabel(\"Passengers\")\nplt.title(\"Number of Passengers per Year\")\nplt.xticks(rotation=45)\nplt.xlim(1995,2019)\nax3.xaxis.set_ticks(Year)\nplt.grid(axis='x')\nplt.legend()\n\nprint(\"ASM recovered from 2008 by \", (ASM[2018]-ASM[2009]))\nprint(\"RPM recovered from 2008 by \", (RPM[2018]-RPM[2009]))\nprint(\"\")\nprint(\"No. of Passengers recovered from 2008 by\",((flights[2018]-flights[2009])/flights[2009])*100, \"%\")\nprint(\"No. of Passengers recovered from 2008 by\",((passengers[2018]-passengers[2009])/passengers[2009])*100, \"%\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- RPM lags behind ASM, however the % change in RPM is amplified in comparison to ASM.\n- a larger ASM indicates larger capacity to generate revenue from more seats.\n- In 2001 and 2002 ASM growth was reversed, possibly due to the events of 9/11. The growth in RPM dropped but was still positive in 2001 but shrunk drastically in the following year. This again shows the influence of external events on the US Commercial airline Industry.\n- between 2003 to 2007 and 2010 to 2018 there is a positive trend in ASM and RPM however 2010 to 2018 has a lesser rate, possibly due to the longer lasting effects of the financial crisis. \n- flights and pasengers numbers generally follow the pattern as ASM and RPM but the increase in passengers in the latter years increased more sharply than number of flights. this would indicate are carrying more passengers on average but RPM and ASM did not increase as you might expect. This could mean a increase in a cost counteracted the expected effect.\n\nLooking into the cost per available seat miles (CASM), as suggested by our PCA, will give us a clearer picture of whats going on."},{"metadata":{},"cell_type":"markdown","source":"### Cost per Available Seat Mile (CASM)"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,7.5))\n\ncasm1=df[\"CASM excluding Transport ($ per ASM)\"]\ncasm2=df[\"CASM excluding Transport and Fuel ($ per ASM)\"]\ncasm3=df[\"CASM excluding Transport Fuel and labour ($ per ASM)\"]\n\np1=plt.bar(Year,casm1, label=\"CASM excluding transport\")\np2=plt.bar(Year,casm2, label=\"CASM excluding transport and fuel\")\np3=plt.bar(Year,casm3, label=\"CASM exlcuding transport fuel and labour\")\n\nplt.title(\"Cost per Available Seat Mile\")\nplt.ylabel(\"$ \\nper \\nASM\", rotation=0)\nplt.xlabel(\"Year\")\nplt.xticks(Year, rotation=45)\nplt.grid(axis='x')\nplt.legend(loc='upper left')\n\nplt.show()\nprint(\"overall increase of CASM with labour,excluding transport and fuel is \",casm2[2018] - casm2[1995])\nprint(\"overall increase of CASM with labour and fuel excluding transport is \",casm1[2018] - casm1[1995])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Expenses Breakdown"},{"metadata":{"trusted":true},"cell_type":"code","source":"#stack plot of expenses table. \nlabels=[\"Labor\",\"Fuel\", \"Transport\", \"Outsourcing\",\"Management and Other\", \"Maintenance\", \"Outsourced Maintenance\"]\n\nplt.figure(figsize=(10,7.5))\nax=plt.subplot(111)\n\nax.stackplot(Year, expenses[\"Total Fuel Expenses ($)\"],expenses[\"Transport Related Expenses ($)\"],\n              expenses[\"Other Outsourcing Expenses ($)\"],expenses[\"Management and Other Expenses ($)\"],\n             expenses[\"Flight Equipment Maintenance Expense ($)\"], \n              expenses[\"Outsourced Flight Equipment Maintenance Expense ($)\"], labels=labels)\n\n\nax.yaxis.set_major_formatter(formatter)\nax.set_ylabel(\"Cumulative Expense $\")\nax.set_xlabel(\"Year\")\n\nplt.legend(loc=\"upper left\")\nprint(expenses[\"Total Fuel Expenses ($)\"][2018])\nprint(expenses[\"Transport Related Expenses ($)\"][2018])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All expenses follow the same shape with dips at 2001 and 2008 as total revenue and exepnse do shown earlier. in general the proportion of each expenses remains relatively consistent across the years."},{"metadata":{"trusted":true},"cell_type":"code","source":"# take average percentage of total expenses and plot against each feature selected\nplt.figure(figsize=(20,7.5))\n\nax1=plt.subplot(121)\n\ntotal=expenses[\"Total Operating Expenses ($)\"]\n\nlabor_perc=np.mean((expenses[\"Total Labour Operating Expenses ($)\"]/total)*100)\nfuel_perc= np.mean((expenses[\"Total Fuel Expenses ($)\"]/total)*100)\ntrans_perc=np.mean((expenses[\"Transport Related Expenses ($)\"]/total)*100)\noutsource_perc= np.mean((expenses[\"Other Outsourcing Expenses ($)\"]/total)*100)\nmgmnt_perc= np.mean((expenses[\"Management and Other Expenses ($)\"]/total)*100)\nmaint_perc= np.mean((expenses[\"Flight Equipment Maintenance Expense ($)\"]/total)*100)\nouts_maint_perc= np.mean((expenses[\"Outsourced Flight Equipment Maintenance Expense ($)\"]/total)*100)\n\nexpense_percentages=[labor_perc,fuel_perc, trans_perc,outsource_perc,mgmnt_perc,maint_perc,outs_maint_perc]\n\nax1=sns.barplot(labels, expense_percentages)\n\nplt.grid(axis='y')\nplt.title(\"Operating Expenses as Average Percentage of Total\")\nplt.ylabel(\"%\")\nplt.xticks(rotation=45)\n\nax2=plt.subplot(122)\n\nexplode = (0.1, 0, 0, 0,0,0,0)  # explode 1st slice\n\nplt.pie(expense_percentages,explode=explode, labels=labels, startangle=52.5)\n\nplt.axis('equal')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Breakdown of Labour expenses through Employee Compensation"},{"metadata":{"trusted":true},"cell_type":"code","source":"#sankey diagram 1st layer connections \nprint(\"All expenses fraction of revenue:\")\n\nprint((df[\"Total Labour Operating Expenses ($)\"]).sum()/(df[\"Total Operating Revenue ($)\"].sum()))\nprint((df[\"Total Fuel Expenses ($)\"]).sum()/(df[\"Total Operating Revenue ($)\"].sum()))\nprint((df[\"Transport Related Expenses ($)\"]).sum()/(df[\"Total Operating Revenue ($)\"].sum()))\nprint((df[\"Other Outsourcing Expenses ($)\"]).sum()/(df[\"Total Operating Revenue ($)\"].sum()))\nprint((df[\"Management and Other Expenses ($)\"]).sum()/(df[\"Total Operating Revenue ($)\"].sum()))\nprint((df[\"Flight Equipment Maintenance Expense ($)\"]).sum()/(df[\"Total Operating Revenue ($)\"].sum()))\nprint((df[\"Outsourced Flight Equipment Maintenance Expense ($)\"]).sum()/(df[\"Total Operating Revenue ($)\"].sum()))\nprint((df[\"Total Profits\"]).sum()/(df[\"Total Operating Revenue ($)\"].sum()))\n\n\navg_emp_exp=np.mean(df[\"Total Labour Operating Expenses ($)\"]/df[\"Full Time Employees Equivalents\"])\n\n# sankey 2nd layer - labour expenses to compensation\n\nprint(\"Compensation fraction of revenue:\")\nprint((df[\"Non Cockpit Employees Avg Wage ($)\"]/df[\"Total Operating Revenue ($)\"]).sum())\nprint((df[\"All Employees average benefits and pensions ($)\"]/df[\"Total Operating Revenue ($)\"]).sum())\nprint((df[\"Average Pilot and Co-Pilot wages ($)\"]/df[\"Total Operating Revenue ($)\"]).sum())\nprint((df[\"Average Flight Attendant Employee Wage ($)\"]/df[\"Total Operating Revenue ($)\"]).sum())\nprint((df[\"Average Ground Staff Employee Wage ($)\"]/df[\"Total Operating Revenue ($)\"]).sum())\nprint((df[\"Average Maintenance Staff Wage ($)\"]/df[\"Total Operating Revenue ($)\"]).sum())\nprint((df[\"Average Management and Others Wage ($)\"]/df[\"Total Operating Revenue ($)\"]).sum())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Sankey diagram of all cash flow for total industry\n\nimport plotly.graph_objects as go\n\nfig = go.Figure(data=[go.Sankey(\n    node = dict(\n      pad = 10,\n      thickness = 20,\n      line = dict(color = \"black\", width = 0.5),\n      label = [\"Total System Revenue\", \"Labor Expenses\",\"Fuel Expenses\", \"Transport Expenses\", \"OutSourcing Expenses\", \n               \"Management Expenses\", \"Flight Equipment Maintenance\", \"Flight Equipment OutSourcing Expenses\", \"Profits\",\n              \"Non Cockput Employee Wage\", \"All Employee Benefits\", \"Pilot Wage\", \"Flight Attendant Wage\",\n               \"Ground Staff Wage\",\"Maintenance Wage\", \"Management/Other Wage\"],\n      color = [\"dodgerblue\", \"red\",\"blueviolet\",\"gold\",\"orchid\",\"teal\", \"gray\",\"orange\",\"limegreen\",\n               \"red\",\"red\",\"red\",\"red\",\"red\",\"red\",\"red\",]\n    ),\n    link = dict(\n      source = [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1], # indices correspond to labels, eg A1, A2, A2, B1, ...\n      target = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15],\n      value =  [210000, 150000, 80000, 60000, 30000, 60000, 30000, 40000, 6000, 3000, 30000, 7000,7000,10000,12000]\n  ))])\n\nfig.update_layout(title_text=\"Sankey Diagram of Cumulative Cash Flow in US Commercial Airline Industry\", font_size=12.5)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"employee_change=compensation[\"Full Time Employees Equivalents\"].pct_change()\nYear=np.arange(1995,2019,1)\n\nfig, ax = plt.subplots(figsize=(15,7))\n\n\nax.bar(Year,employee_change, alpha=0.75, color = 'g')\nplt.title(\"Recruitment Drives/Cuts\")\nax.set_ylabel(\"% change of Full time employee equivalents\")\nplt.xticks(rotation=45)\n\n\nax2 = ax.twinx()\n\nax2.plot(df[\"Total Operating Expenses ($)\"], lw=1, ls='--', color='r')\nax2.yaxis.set_major_formatter(formatter)\nax2.set_ylabel(\"Expenses ($)\")\nax.grid(axis='x')\n\nimport scipy as sp\nprint(\"Pearsons Correlation between No. employees and Total Profits is: \", \n      sp.stats.pearsonr(compensation[\"Full Time Employees Equivalents\"],\n                        df[\"Total Profits\"])[0])\n\nprint(\"Pearsons Correlation between No. employees and Total system Revenue is: \", \n      sp.stats.pearsonr(compensation[\"Full Time Employees Equivalents\"],\n                        df[\"Total Operating Revenue ($)\"])[0])\n\nprint(\"Pearsons Correlation between No. employees and Total system Expenses is: \", \n      sp.stats.pearsonr(compensation[\"Full Time Employees Equivalents\"],\n                        -1*df[\"Total Operating Expenses ($)\"])[0])\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Forecasting and Modelling\nARIMA Forescasting on major features"},{"metadata":{},"cell_type":"markdown","source":"ARIMA on Revenue, Expenses, Profits, Flights per Day or passengers\n\n- Model can be created using statsmodels library as follows:\n\n1) Define model by calling ARIMA() and passing p, d, q parameters and using the Augmented Dickey-Fuller test to determine these values.\n\n2) model is prepared on the training data by calling the fit() function\n\n3) predictions can be made by calling the forecast() function and specifying the index of time period to be predicted\n\nThis process will be repeated for series being modelled.\n\nIt must be noted that we do not expect spectacular results since the data is presented on a year-by-year basis and there are only 24 data points to work with, rather this is a demonstration of how to implement and assess the components of ARIMA forecasting. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# need to check if stationary first, two ways: rolling statistics and augmented dickey-fuller test (ADF). \n# we will be using dickey-fuller. series will be considered stationary if the p-value is low (according to null hypothesis)\n# and the critical values at 1% 5% 10% confidence intervals are as close as possible to ADF stats.\n\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom statsmodels.tsa.arima_model import ARIMAResults\nfrom pandas.plotting import register_matplotlib_converters\nregister_matplotlib_converters","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Checking series for stationarity and determining a suitable d value (for the I parameter).","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# a function to run the two tests which determine whether a given time series is stationary.\n\ndef get_stationarity(timeseries):\n    \n    # rolling statistics\n    rolling_mean = timeseries.rolling(window=5).mean()\n    rolling_std = timeseries.rolling(window=5).std()\n    \n    # rolling statistics plot\n    original = plt.plot(timeseries, color='blue', label='Original')\n    mean = plt.plot(rolling_mean, color='red', label='Rolling Mean')\n    std = plt.plot(rolling_std, color='black', label='Rolling Std')\n    plt.legend(loc='best')\n    plt.title('Rolling Mean & Standard Deviation')\n    plt.show(block=False)\n    \n    # DickeyFuller test:\n    result = adfuller(timeseries)\n    print('ADF Statistic: {}'.format(result[0]))\n    print('p-value: {}'.format(result[1]))\n    print('Critical Values:')\n    for key, value in result[4].items():\n        print('\\t{}: {}'.format(key, value))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rev = df['Total Operating Revenue ($)'] \nrolling_mean = rev.rolling(window=5).mean()\nrev_minus_mean = rev - rolling_mean\nrev_minus_mean.dropna(inplace=True)    \n\nget_stationarity(rev_minus_mean)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"taking 1 difference of the mean from the revenue made the p value small and brought the value of the Augmented Dickey-Fuller stat close to the required thresholds. we can conclude that the series is stationary. When making our model we now know that a d value of 1 should make the series stationary. "},{"metadata":{},"cell_type":"markdown","source":"### Finding a starting point for the p value (AR parameter)"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.plotting.autocorrelation_plot(rev)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"significant positive correlation for for first 4 or 5 lags. 4 may be a good place to start AR parameter (p value) from.\n\nTo make a starting guess, a difference order of 1 for the I parameter (d value) will be used to achieve stationarity and a moving average model, the MA parameter (q vaule) of 0 will be used. \n\n(4,1,0) will be used as a baseline."},{"metadata":{"trusted":true},"cell_type":"code","source":"model=ARIMA(rev, order=(1,1,0))\nmodel_fit=model.fit(disp=0)\nprint(model_fit.summary())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot residual errors\n\nresiduals=pd.DataFrame(model_fit.resid)\nresiduals.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"residuals.plot(kind='kde')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"error denisty plot results show that the errors are gaussain and there is a bias in prediction (non-zero mean).\n"},{"metadata":{},"cell_type":"markdown","source":"### Rolling forecast ARIMA model:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# using predict() on ARIMA results to make predictions\n#train to test split will approx. be 2/3 to 1/3\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\n\n\nX = rev.values\nsize = int(len(X) * 0.66)\ntrain, test = X[0:size], X[size:len(X)]\ntrain_years, test_years  = (1995 + np.arange(0,size)) , (1995 + np.arange(size,len(X)))\nhistory = [x for x in train]\npredictions = list()\nfor t in range(len(test)):\n    model = ARIMA(history, order=(1,1,0))\n    model_fit = model.fit(disp=0)\n    output = model_fit.forecast()\n    yhat = output[0]\n    predictions.append(yhat)\n    obs = test[t]\n    history.append(obs)\n    print('predicted=%f, expected=%f' % (yhat, obs))\n\nerror = mean_squared_error(test, predictions)\nprint('Test MSE: %.3f' % error)\n\nr_sq=r2_score(test, predictions)\nprint('R squared: ', r_sq)\n\n# plot\n#\nplt.plot(test_years, test, label=\"Test Set\")\nplt.plot(test_years, predictions, color='red', label=\"Prediction\")\nplt.plot(train_years, train, label=\"Train Set\")\nplt.grid(axis='x')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = rev.values\nsize = int(len(X))\nhistory = [x for x in X]\npredictions = list()\nfor t in range(10):\n    model = ARIMA(history, order=(2,1,0))\n    model_fit = model.fit(disp=0)\n    output = model_fit.forecast()\n    yhat = output[0]\n    history.append(yhat)\n    print('predicted=%f' % (yhat))\n    \nplt.plot(history)\nprint(len(history))\nprint(len(X))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(9,3))\n\nax1=plt.subplot(111)\n\npx = np.arange(1995,2029)\n\nax1.plot(px,history, label=\"Total Industry Revenue\")\nax1.vlines(x=2018, ymin=0, ymax=(300*10**11), ls='dashed', color='r')\nax1.set_ylim(min(history), max(history))\n\nc = np.polyfit(Year, rev, 1)\nprint(c)\np = np.poly1d(c)\n\npy = p(px)\nax1.plot(px, py, lw=0.5, ls='--', label=\"Linear Fit of Initial Trend\")\nax1.set_xlim(1994,2028)\nax1.grid(axis='x')\nax1.yaxis.set_major_formatter(formatter)\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ARIMA for No. of Passengers Enplaned"},{"metadata":{"trusted":true},"cell_type":"code","source":"passengers=df[\"Total Enplaned Passengers\"]\nrolling_mean = passengers.rolling(window=5).mean()\npassengers_minus_mean = passengers - rolling_mean\npassengers_minus_mean.dropna(inplace=True)    \n\nget_stationarity(passengers_minus_mean)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.plotting.autocorrelation_plot(passengers)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model1=ARIMA(passengers, order=(1,1,0))\nmodel_fit1=model1.fit(disp=0)\nprint(model_fit1.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot residual errors\n\nresiduals1=pd.DataFrame(model_fit1.resid)\nresiduals1.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"residuals1.plot(kind='kde')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Evidence of a slight positive bias"},{"metadata":{"trusted":true},"cell_type":"code","source":"# using predict() on ARIMA results to make predictions\n#train to test split will approx. be 2/3 to 1/3\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\n\nX1 = passengers.values\nsize1 = int(len(X1) * 0.66)\ntrain1, test1 = X1[0:size1], X1[size1:len(X1)]\ntrain_years1, test_years1  = (1995 + np.arange(0,size1)) , (1995 + np.arange(size1,len(X1)))\nhistory1 = [x for x in train1]\npredictions1 = list()\nfor t in range(len(test1)):\n    model1 = ARIMA(history1, order=(1,1,0))\n    model_fit1 = model1.fit(disp=0)\n    output1 = model_fit1.forecast()\n    yhat1 = output1[0]\n    predictions1.append(yhat1)\n    obs1 = test1[t]\n    history1.append(obs1)\n    print('predicted=%f, expected=%f' % (yhat1, obs1))\n\nerror1 = mean_squared_error(test1, predictions1)\nprint('Test MSE: %.3f' % error1)\n\n\nr_sq1=r2_score(test1, predictions1)\nprint('R squared: ', r_sq1)\n\n# plot\n#\nplt.plot(test_years1, test1, label=\"Test Set\")\nplt.plot(test_years1, predictions1, color='red', label=\"Prediction\")\nplt.plot(train_years1, train1, label=\"Train Set\")\nplt.grid(axis='x')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X1 = passengers.values\nsize1 = int(len(X1))\nhistory1 = [x for x in X1]\npredictions1 = list()\nfor t in range(10):\n    model1 = ARIMA(history1, order=(2,1,0))\n    model_fit1 = model1.fit(disp=0)\n    output1 = model_fit1.forecast()\n    yhat1 = output1[0]\n    history1.append(yhat1)\n    print('predicted=%f' % (yhat1))\n    \nplt.plot(history1)\nprint(len(history1))\nprint(len(X1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,3))\n\nax1=plt.subplot(111)\npx = np.arange(1995,2029)\nax1.plot(px,history1, label=\"Total Industry Passengers\")\nax1.vlines(x=2018, ymin=0, ymax=(300*10**11), ls='dashed', color='r')\nax1.set_ylim(min(history1), max(history1))\n\nc = np.polyfit(Year, passengers, 1)\nprint(c)\np = np.poly1d(c)\n\npy = p(px)\nax1.plot(px, py, lw=0.5, ls='--', label=\"Linear Fit of Initial Trend\")\nax1.set_xlim(1994,2028)\nax1.grid(axis='x')\nax1.yaxis.set_major_formatter(formatter)\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ARIMA for expenses"},{"metadata":{"trusted":true},"cell_type":"code","source":"exp=df[\"Total Operating Expenses ($)\"]\nrolling_mean = exp.rolling(window=5).mean()\nexp_minus_mean = exp - rolling_mean\nexp_minus_mean.dropna(inplace=True)    \n\nget_stationarity(exp_minus_mean)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.plotting.autocorrelation_plot(exp)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Starting p value of 2 seems reasonable"},{"metadata":{"trusted":true},"cell_type":"code","source":"model2=ARIMA(exp, order=(2,1,0))\nmodel_fit2=model2.fit(disp=0)\nprint(model_fit2.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot residual errors\n\nresiduals2=pd.DataFrame(model_fit2.resid)\nresiduals2.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"residuals2.plot(kind='kde')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# using predict() on ARIMA results to make predictions\n#train to test split will approx. be 2/3 to 1/3\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\n\nX2 = exp.values\nsize2 = int(len(X2) * 0.66)\ntrain2, test2 = X2[0:size2], X2[size2:len(X2)]\ntrain_years2, test_years2  = (1995 + np.arange(0,size2)) , (1995 + np.arange(size2,len(X2)))\nhistory2 = [x for x in train2]\npredictions2 = list()\nfor t in range(len(test2)):\n    model2 = ARIMA(history2, order=(2,1,0))\n    model_fit2 = model2.fit(disp=0)\n    output2 = model_fit2.forecast()\n    yhat2 = output2[0]\n    predictions2.append(yhat2)\n    obs2 = test2[t]\n    history2.append(obs2)\n    print('predicted=%f, expected=%f' % (yhat2, obs2))\n\nerror2 = mean_squared_error(test2, predictions2)\nprint('Test MSE: %.3f' % error2)\n\n\nr_sq2=r2_score(test2, predictions2)\nprint('R squared: ', r_sq2)\n\n# plot\n#\nplt.plot(test_years2, test2, label=\"Test Set\")\nplt.plot(test_years2, predictions2, color='red', label=\"Prediction\")\nplt.plot(train_years2, train2, label=\"Train Set\")\nplt.grid(axis='x')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"High, positive R squared shows that ARIMA model is a very good fit and that 94% of the variance is explained"},{"metadata":{"trusted":true},"cell_type":"code","source":"X2 = exp.values\nsize2 = int(len(X2))\nhistory2 = [x for x in X2]\npredictions2 = list()\nfor t in range(10):\n    model2 = ARIMA(history2, order=(2,1,0))\n    model_fit2 = model2.fit(disp=0)\n    output2 = model_fit2.forecast()\n    yhat2 = output2[0]\n    history2.append(yhat2)\n    print('predicted=%f' % (yhat2))\n    \nplt.plot(history2)\nprint(len(history2))\nprint(len(X2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction_years=np.arange(1995, 2029)\nlen(prediction_years)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,3))\n\nax1=plt.subplot(111)\n\n#ax1.plot(test_years2, test2, label=\"Test Set\")\nax1.plot(prediction_years,history2, label=\"Total Industry Expenses\")\nax1.vlines(x=2018, ymin=0, ymax=(300*10**11), ls='dashed', color='r')\nax1.set_ylim(min(history2), max(history2))\n\nc = np.polyfit(Year, exp, 1)\nprint(c)\np = np.poly1d(c)\npx = np.arange(1995,2025)\npy = p(px)\nax1.plot(px, py, lw=0.5, ls='--', label=\"Linear Fit of Initial Trend\")\n\nax1.grid(axis='x')\nax1.yaxis.set_major_formatter(formatter)\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ARIMA for Profits"},{"metadata":{"trusted":true},"cell_type":"code","source":"prof=df[\"Total Profits\"]\nrolling_mean = prof.rolling(window=5).mean()\nprof_minus_mean = prof - rolling_mean\nprof_minus_mean.dropna(inplace=True)    \n\nget_stationarity(prof_minus_mean)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.plotting.autocorrelation_plot(prof)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model3=ARIMA(exp, order=(1,1,0))\nmodel_fit3=model3.fit(disp=0)\nprint(model_fit3.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot residual errors\n\nresiduals3=pd.DataFrame(model_fit3.resid)\nresiduals3.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"residuals3.plot(kind='kde')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# using predict() on ARIMA results to make predictions\n#train to test split will approx. be 2/3 to 1/3\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\n\nX3 = prof.values\nsize3 = int(len(X3) * 0.66)\ntrain3, test3 = X3[0:size3], X3[size3:len(X3)]\ntrain_years3, test_years3  = (1995 + np.arange(0,size3)) , (1995 + np.arange(size3,len(X3)))\nhistory3 = [x for x in train3]\npredictions3 = list()\nfor t in range(len(test3)):\n    model3 = ARIMA(history3, order=(2,1,0))\n    model_fit3 = model3.fit(disp=0)\n    output3 = model_fit3.forecast()\n    yhat3 = output3[0]\n    predictions3.append(yhat3)\n    obs3 = test3[t]\n    history3.append(obs3)\n    print('predicted=%f, expected=%f' % (yhat3, obs3))\n\nerror3 = mean_squared_error(test3, predictions3)\nprint('Test MSE: %.3f' % error3)\n\n\nr_sq3=r2_score(test3, predictions3)\nprint('R squared: ', r_sq3)\n\n# plot\n#\nplt.plot(test_years3, test3, label=\"Test Set\")\nplt.plot(test_years3, predictions3, color='red', label=\"Prediction\")\nplt.plot(train_years3, train3, label=\"Train Set\")\nplt.grid(axis='x')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X3 = prof.values\nsize3 = int(len(X3))\nhistory3 = [x for x in X3]\npredictions3 = list()\nfor t in range(10):\n    model3 = ARIMA(history3, order=(2,1,0))\n    model_fit3 = model3.fit(disp=0)\n    output3 = model_fit3.forecast()\n    yhat3 = output3[0]\n    history3.append(yhat3)\n    print('predicted=%f' % (yhat3))\n    \nplt.plot(history3)\nprint(len(history3))\nprint(len(X3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\n\nax1=plt.subplot(111)\npx = np.arange(1995,2029)\n#ax1.plot(test_years2, test2, label=\"Test3Set\")\nax1.plot(px,history3, label=\"10 Year Forecast\")\nax1.vlines(x=2018, ymin=min(history3), ymax=(300*10**11), ls='dashed', color='r')\nax1.hlines(y=0, xmin=1990, xmax=2030, ls='dashed', lw=0.5)\nax1.set_ylim(min(history3), max(history3))\nax1.set_xlim(min(prediction_years), max(prediction_years))\n\nc = np.polyfit(Year, prof, 1)\nprint(c)\np = np.poly1d(c)\n\npy = p(px)\nax1.plot(px, py, lw=0.5, ls='--', label=\"Linear Fit of Initial Trend\")\n\nax1.grid(axis='x')\nax1.yaxis.set_major_formatter(formatter)\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prof_alternate=np.array(history)-np.array(history2)\nplt.plot(prof_alternate)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,3))\n\nax1=plt.subplot(111)\n\n#ax1.plot(test_years2, test2, label=\"Test3Set\")\nax1.plot(prediction_years,history3, label=\"Total Industry Profits\")\nplt.plot(prediction_years[23:], prof_alternate[23:], label='Profits caluculated from revenue and expenses')\nax1.vlines(x=2018, ymin=min(history3), ymax=(300*10**11), ls='dashed', color='r')\nax1.hlines(y=0, xmin=1990, xmax=2030, ls='dashed', lw=0.5)\nax1.set_ylim(min(history3), max(history3))\nax1.set_xlim(min(prediction_years), max(prediction_years))\n\nc = np.polyfit(Year, prof, 1)\nprint(c)\np = np.poly1d(c)\npx = np.arange(1995,2030)\npy = p(px)\nax1.plot(px, py, lw=0.5, ls='--', label=\"Linear Fit of Initial Trend\")\n\nax1.grid(axis='x')\nax1.yaxis.set_major_formatter(formatter)\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}