{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Install library"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install tensorflow-gpu==1.14.0\n!pip install Keras==2.2.4\n!pip install efficientnet","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Import library"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfrom sklearn.metrics import precision_recall_curve\nimport cv2\nimport numpy as np\nimport argparse\nfrom keras.utils import np_utils\nfrom keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.pyplot as plt\nfrom keras import layers\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\nimport pickle\nimport efficientnet.keras as efn\nfrom keras import Model\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint,ReduceLROnPlateau,EarlyStopping,CSVLogger\nfrom keras.optimizers import Adam\nfrom keras import models\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Define"},{"metadata":{"trusted":true},"cell_type":"code","source":"def new_listdir(path):\n    return [f for f in os.listdir(path) if not f.startswith('.')]\n\ndef compressArr(a):\n    d = np.array(a)\n    d[d<12] = 0\n    d[(d<=18)&(d>=12)] = 1\n    d[(d<=25)&(d>=19)] = 2\n    d[(d<=32)&(d>=26)] = 3\n    d[(d<=39)&(d>=33)] = 4\n    d[d>=40] = 5\n    \n    return d","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fb_dir = '../input/facebookdata/fbdata/fbdata'\ninsta_dir = '../input/instagram/ig_ava/image'\nid_fb_dir = '../input/train-fb-id'\nid_insta_dir = '../input/insta-pred'\n\nfb = pd.read_csv('../input/facebookdata/age_gender_fb.csv')\nfb['compress_age'] = compressArr(2019-fb.birthday_from_fb)\n\nma_train_dir = '../input/megaage/megaage_asian/megaage_asian/train'\nma_test_dir = '../input/megaage/megaage_asian/megaage_asian/test'\nma_age = np.array(open('../input/megaage/train_age2.txt','r').read().split()).reshape(-1,2).astype(int)\ny_test_ma = np.array(open('../input/megaage/test_age2.txt','r').read().split()).reshape(-1,2).astype(int)\nma_name = np.array(open('../input/megaage/megaage_asian/megaage_asian/list/train_name.txt','r').read().split())\nma_age[:,0] = compressArr(ma_age[:,0])\nX_test_ma = np.array(open('../input/megaage/megaage_asian/megaage_asian/list/test_name.txt','r').read().split())\ny_test_ma[:,0] = compressArr(y_test_ma[:,0])\n\nprint(ma_age.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prepare dataset for train"},{"metadata":{"trusted":true},"cell_type":"code","source":"fb_name1,fb_age,fb_gender,insta_name,insta_age = [],[],[],[],[]\nr = np.random.RandomState(23)\n\nwith open('../input/gender-insta-pred/gender_insta_pred.pickle','rb') as f:\n    gender_insta_pred = pickle.load(f)\nfor a in range(6):\n    with open(os.path.join(id_insta_dir,'insta_ids_'+str(a)),'rb') as f:\n        name = pickle.load(f) \n        for n in name:\n            g = gender_insta_pred[n]\n            insta_age.append([a,g])\n        insta_name += name\n    with open(os.path.join(id_fb_dir,'train3_ids_'+str(a)+'.pickle'),'rb') as f:\n        name = pickle.load(f) \n        fb_age += [a]*len(name)\n        fb_name1 += name\n\nwith open(os.path.join(id_insta_dir,'insta_ids_'+str(6)),'rb') as f:\n    name = pickle.load(f) \n    insta_age += [[6,2]]*len(name)\n    insta_name += name\n    \nfb_name2 = []\nfor a in range(2):\n    with open(os.path.join(id_fb_dir,'gender_ids_'+str(a)+'.pickle'),'rb') as f:\n        name = pickle.load(f) \n        fb_gender += [a]*len(name)\n        fb_name2 += name\n\nwith open(os.path.join(id_fb_dir,'d00.pickle'),'rb') as f:\n    name = pickle.load(f)[:8000]\n    fb_age += [6]*len(name)\n    fb_name1 += list(name)\n    fb_name2 += list(name)\n    fb_gender += [2]*len(name)\n\nfb_age_d = {x:y for x,y in zip(fb_name1,fb_age)}\nfb_gender_d = {x:y for x,y in zip(fb_name2,fb_gender)}\nprint(len(fb_name1))\nprint(len(fb_name2))\nfb_name = list(set(fb_name1)&set(fb_name2))\nfb_gender = [fb_gender_d[x] for x in fb_name]\nfb_age = [fb_age_d[x] for x in fb_name]\n\nprint(len(fb_name))\nfb_name = np.array(fb_name)\nfb_name = np.array([str(x)+'.jpg' for x in fb_name])\nfb_age = np.array(fb_age).reshape(1,-1)\nfb_gender = np.array(fb_gender).reshape(1,-1)\nfb_age = np.vstack((fb_age,fb_gender)).transpose()\n\ninsta_name = np.array(insta_name)\ninsta_age = np.array(insta_age)\n#pd.Series(insta_age).value_counts().plot('bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_fb,X_test_fb,y_train_fb,y_test_fb = train_test_split(fb_name,fb_age,stratify=fb_age,test_size=0.15,random_state=23)\nX_train_fb,X_val_fb,y_train_fb,y_val_fb = train_test_split(X_train_fb,y_train_fb,stratify=y_train_fb,test_size=0.15,random_state=23)\n\nX_train_insta,X_test_insta,y_train_insta,y_test_insta = train_test_split(insta_name,insta_age,stratify=insta_age,test_size=0.15,random_state=23)\nX_train_insta,X_val_insta,y_train_insta,y_val_insta = train_test_split(X_train_insta,y_train_insta,stratify=y_train_insta,test_size=0.15,random_state=23)\n\nX_train_ma,X_val_ma,y_train_ma,y_val_ma = train_test_split(ma_name,ma_age,test_size=0.15,random_state=23)\n\nX_val = np.array(list([os.path.join(fb_dir,x) for x in X_val_fb]) + list([os.path.join(ma_train_dir,x) for x in X_val_ma])+list(X_val_insta))\nX_train = np.array(list([os.path.join(fb_dir,x) for x in X_train_fb]) + list([os.path.join(ma_train_dir,x) for x in X_train_ma])+list(X_train_insta))\ny_val = np.concatenate((y_val_fb , y_val_ma,y_val_insta))\ny_train = np.concatenate((y_train_fb , y_train_ma,y_train_insta))\n\nX_test_fb = np.array(list([os.path.join(fb_dir,x) for x in X_test_fb]))\nX_test_ma = np.array(list([os.path.join(ma_test_dir,x) for x in X_test_ma]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_size=320","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Function"},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen1 = ImageDataGenerator(\n            width_shift_range=0.1,\n            height_shift_range=0.1,\n            rotation_range=15,\n            #zoom_range=(0.8,1.9),\n            #zoom_range=(0.8,2.5),\n            brightness_range= (0.9,1.1),\n            horizontal_flip=True)\n\n\ndef cv2_clipped_zoom(img, zoom_factor):\n    height, width = img.shape[:2] # It's also the final desired shape\n    new_height, new_width = int(height * zoom_factor), int(width * zoom_factor)\n    y1, x1 = max(0, new_height - height) // 2, max(0, new_width - width) // 2\n    y2, x2 = y1 + height, x1 + width\n    bbox = np.array([y1,x1,y2,x2])\n    bbox = (bbox / zoom_factor).astype(np.int)\n    y1, x1, y2, x2 = bbox\n    cropped_img = img[y1:y2, x1:x2]\n    resize_height, resize_width = min(new_height, height), min(new_width, width)\n    pad_height1, pad_width1 = (height - resize_height) // 2, (width - resize_width) //2\n    pad_height2, pad_width2 = (height - resize_height) - pad_height1, (width - resize_width) - pad_width1\n    pad_spec = [(pad_height1, pad_height2), (pad_width1, pad_width2)] + [(0,0)] * (img.ndim - 2)\n\n    result = cv2.resize(cropped_img, (resize_width, resize_height),interpolation=cv2.INTER_LINEAR)\n    result = np.pad(result, pad_spec, mode='constant')\n    assert result.shape[0] == height and result.shape[1] == width\n    return result\n\ndef generate_data(name,age,batch_size=8,is_train=True):\n  while True:\n    if is_train:\n      indices = np.random.permutation(len(name))\n    else:\n      indices = np.arange(len(name))\n    n_batch = int(np.ceil(len(name)/batch_size))\n    j = 0\n    X,y,g = [],[],[]\n    for i in range(len(name)):\n      j += 1\n    \n      filename = name[indices[i]]\n      img = cv2.imread(filename)\n      if filename.find('megaage')!=-1:\n        h,w,c = img.shape\n        t,l = (max(h,w)-h)//2,(max(h,w)-w)//2\n        img = cv2.copyMakeBorder(img,t,t,l,l,cv2.BORDER_CONSTANT,value=[0,0,0])\n      \n        \n      if is_train:\n        if filename.find('megaage')!=-1:\n            s = np.random.uniform(0.37,1.2)\n        else:\n            s = np.random.uniform(0.8,1.2)\n        img = cv2_clipped_zoom(img,s)\n        img = datagen1.random_transform(img)\n      img = cv2.resize(img,(img_size,img_size),interpolation = cv2.INTER_AREA)\n      X.append(img/255)\n      y.append(age[indices[i]][0])\n      g.append(age[indices[i]][1])\n      if j>=batch_size:\n        yield np.array(X),[np.array(y)]*5+[np.array(g)]*5\n        X,y,g = [],[],[]\n        j = 0\n    if j >0:\n      yield np.array(X),[np.array(y)]*5+[np.array(g)]*5\n\nfor X,y in generate_data(X_train,y_train,32):\n    plt.imshow(X[8][:,:,(2,1,0)])\n    print(y)\n    break","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Build Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"\npath = '../input/agegender320/model.h5'\n\nmodel = models.load_model(path)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluate"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nfrom sklearn.utils.multiclass import unique_labels\n\ndef plot_confusion_matrix(y_true, y_pred, classes,\n                          normalize=False,\n                          title=None,\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n\n    # Compute confusion matrix\n    cm = confusion_matrix(y_true, y_pred)\n    # Only use the labels that appear in the data\n    classes = classes[unique_labels(y_true, y_pred)]\n\n#     print(cm)\n\n    fig, ax = plt.subplots(figsize=(6,6))\n    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n    ax.figure.colorbar(im, ax=ax)\n    # We want to show all ticks...\n    ax.set(xticks=np.arange(cm.shape[1]),\n           yticks=np.arange(cm.shape[0]),\n           # ... and label them with the respective list entries\n           xticklabels=classes, yticklabels=classes,\n           title=title,\n           ylabel='True label',\n           xlabel='Predicted label')\n\n    # Rotate the tick labels and set their alignment.\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n             rotation_mode=\"anchor\")\n\n    # Loop over data dimensions and create text annotations.\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            ax.text(j, i, format(cm[i, j], fmt),\n                    ha=\"center\", va=\"center\",\n                    color=\"white\" if cm[i, j] > thresh else \"black\")\n    fig.tight_layout()\n    return ax, cm\n\ndef pr_curve(y_true,prob):\n    # precision recall curve\n    plt.figure(figsize=(8,8))\n    precision = dict()\n    recall = dict()\n    threshold = dict()\n    n_values = np.max(y_true) + 1\n    y = np.eye(n_values)[y_true]\n    for i in range(n_values):\n        precision[i], recall[i],threshold[i] = precision_recall_curve(y[:, i],\n                                                        prob[:, i])\n        plt.plot(recall[i], precision[i], lw=2, label='class {}'.format(i))\n    plt.xlabel(\"recall\")\n    plt.ylabel(\"precision\")\n    plt.legend(loc=\"best\")\n    plt.title(\"precision vs. recall curve\")\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict(X_test,y_test):\n    y_pred_a = []\n    y_pred_g = []\n    \n    batch_size=32\n    n_test_batchs = int(np.ceil(len(X_test)/batch_size))\n    i=0\n    for X,y in generate_data(X_test,y_test,batch_size,is_train=False):\n        p = model.predict(X)\n        p_a = np.transpose(p[:5],(1,0,2))\n        p_g = np.transpose(p[5:],(1,0,2))\n        y_pred_a.extend(p_a)\n        y_pred_g.extend(p_g)\n        i+=1\n        if i==n_test_batchs:\n            break\n    y_pred_a = np.array(y_pred_a)\n    y_pred_g = np.array(y_pred_g)\n    prob_a = np.mean(y_pred_a*np.reshape([1.2,1.1,1,0.9,0.8],(-1,5,1)),1)\n    pred_a = np.argmax(prob_a,-1)\n    prob_g = np.mean(y_pred_g*np.reshape([1.2,1.1,1,0.9,0.8],(-1,5,1)),1)\n    pred_g = np.argmax(prob_g,-1)\n    return pred_a,prob_a,pred_g,prob_g","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fb_pred_a,fb_prob_a,fb_pred_g,fb_prob_g = predict(X_test_fb,y_test_fb)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\n\nids = np.array([int(re.findall('\\d+',x)[0]) for x in X_test_fb])\nids[10:40]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def report_a(y_true,y_pred,prob):\n    \n    print(classification_report(y_true,y_pred))\n    _, cm = plot_confusion_matrix(y_true,y_pred, classes=np.array([\"range1\", \"range2\", \"range3\", \"range4\", \"range5\", \"range6\",\"undefined\"]))\n    plt.show()\n    pr_curve(y_true,prob)\n    plt.show()\n    \ndef report_g(y_true,y_pred,prob):\n    \n    print(classification_report(y_true,y_pred))\n    _, cm = plot_confusion_matrix(y_true, y_pred, classes=np.array([\"female\", \"male\", \"undefined\"]), title='Confusion matrix')\n    plt.show()\n    pr_curve(y_true,prob)\n    plt.show()\n        \nreport_a(y_test_fb[:,0],fb_pred_a,fb_prob_a)\nreport_g(y_test_fb[:,1],fb_pred_g,fb_prob_g)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ma_pred_a,ma_prob_a,ma_pred_g,ma_prob_g = predict(X_test_ma,y_test_ma)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"report_a(y_test_ma[:,0],ma_pred_a,ma_prob_a)\nreport_g(y_test_ma[:,1],ma_pred_g,ma_prob_g)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"insta_pred_a,insta_prob_a,insta_pred_g,insta_prob_g = predict(X_test_insta,y_test_insta)\nreport_a(y_test_insta[:,0],insta_pred_a,insta_prob_a)\nreport_g(y_test_insta[:,1],insta_pred_g,insta_prob_g)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualize"},{"metadata":{"trusted":true},"cell_type":"code","source":"#insta_train_pred = predict(X_train_insta,y_train_insta)\n#report(y_train_insta,insta_train_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Random visualize image Ã²f ids\ndef visualize(ids,labels=None,size=None,n_imgs=16):\n    plt.figure(figsize=(15,15))\n    for k in range(n_imgs):\n        i = np.random.randint(len(ids))\n        id = ids[i]\n        img = cv2.imread(id)\n        if size:\n            img = cv2.resize(img,(size,size))\n        plt.subplot(4,4,k+1)\n        plt.imshow(img[:,:,[2,1,0]])\n        if labels is not None:\n            plt.title(labels[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label = np.array([str(x) +' vs '+str(y) for x,y in zip(y_test_insta[:,1],insta_pred_g)])\nidx = y_test_insta[:,1]!=insta_pred_g\nvisualize(X_test_insta[idx],label[idx])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label = np.array([str(x) +' vs '+str(y) for x,y in zip(y_test_insta[:,0],insta_pred_a)])\nidx = y_test_insta[:,0]!=insta_pred_a\nvisualize(X_test_insta[idx],label[idx])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#label = np.array([str(x) +' vs '+str(y) for x,y in zip(y_train_insta,insta_train_pred)])\n#idx = (y_train_insta!=insta_train_pred)&(insta_train_pred==4)\n#print(np.sum(idx))\n#visualize(X_train_insta[idx],label[idx])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label = np.array([str(x) +' vs '+str(y) for x,y in zip(y_test_fb[:,1],fb_pred_g)])\nidx = y_test_fb[:,1]!=fb_pred_g\nvisualize(X_test_fb[idx],label[idx])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label = np.array([str(x) +' vs '+str(y) for x,y in zip(y_test_fb[:,0],fb_pred_a)])\nidx = y_test_fb[:,0]!=fb_pred_a\nvisualize(X_test_fb[idx],label[idx])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label = np.array([str(x) +' vs '+str(y) for x,y in zip(compressArr(y_test_ma[:,1]),ma_pred_g)])\nidx = compressArr(y_test_ma[:,1])!=ma_pred_g\nvisualize(X_test_ma[idx],label[idx])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label = np.array([str(x) +' vs '+str(y) for x,y in zip(compressArr(y_test_ma[:,0]),ma_pred_a)])\nidx = compressArr(y_test_ma[:,0])!=ma_pred_a\nvisualize(X_test_ma[idx],label[idx])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}