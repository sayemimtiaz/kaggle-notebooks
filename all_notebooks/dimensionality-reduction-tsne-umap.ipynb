{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nfrom glob import glob\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.graph_objects as go\n%matplotlib inline\nfrom IPython.display import Audio, display, HTML\nimport itertools\nfrom tqdm.notebook import tqdm\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\nimport umap.umap_ as umap\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\nfrom librosa import load\n\ndef standardize(f):\n    return StandardScaler( # z = (x - mean) / stddev\n        #with_std=False, #z = (x - mean) if False\n        #with_mean=False,#z = x/stddev if False\n    ).fit_transform(f)\n\ndef get_pca(features, n_components=2):\n    pca = PCA(n_components=n_components)\n    comp = pca.fit(features).transform(standardize(features))\n    return MinMaxScaler().fit_transform(comp)\n\n\n\ndef get_tsne_embeddings(features, n_components=2, perplexity=15, iteration=20000):\n    tsne_embedding = TSNE(n_components=n_components,\n                     perplexity=perplexity,\n                     verbose=0,\n                     n_iter=iteration).fit_transform(standardize(features))\n    return MinMaxScaler().fit_transform(tsne_embedding)\n\n\ndef get_umap_embeddings(features, n_components=2, neighbor=15, distance=0.1):\n    umap_embedding = umap.UMAP(n_neighbors=neighbor,\n                               min_dist=distance,\n                               n_epochs=5000,\n                               metric='correlation', \n                               n_components=n_components, \n                               verbose=False).fit_transform(standardize(features))\n    return MinMaxScaler().fit_transform(umap_embedding)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dimensionality reduction using t-SNE and UMAP\n\n### Load features \n\nLoad data from ````features_3_sec.csv````. Keep only features associated with first 3sec (0th segment). Discard features from other clips from the same song.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"df = pd.read_csv(\"../input/gtzan-dataset-music-genre-classification/Data/features_3_sec.csv\")\ndf = df[df.filename.apply(lambda x: x.split(\".\")[-2]=='0')].copy().reset_index(drop=True)\nfeatures = df.iloc[:,2:-1]\nle = LabelEncoder()\ntarget = le.fit_transform(df.iloc[:,-1])\ndf.sample(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Get t-SNE embeddings for selected clips\nExtract t-SNE embeddings for two components over multiple perplexity settings and epochs.","execution_count":null},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"tsne_embeddings = dict()\nperplexities = [10,15,20,25,30]\niterations = [5000,10000,15000,20000,25000]\nfor perplexity, iteration in tqdm(list(itertools.product(perplexities,iterations))): #for a prettier progress bar\n    tsne_embedding = get_tsne_embeddings(features,\n                                         perplexity=perplexity,\n                                         iteration=iteration)\n    tsne_embeddings[f\"{perplexity}_{iteration}\"]= tsne_embedding","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plot t-SNE results\n","execution_count":null},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"color_scheme = {\n 'classical': '#FE88FC',\n 'jazz': '#F246FE',\n 'blues': '#BF1CFD', \n 'metal': '#6ECE58',\n 'rock': '#35B779',\n 'disco': '#1F9E89',\n 'pop': '#Fb9B06',\n 'reggae': '#ED6925',\n 'hiphop': '#CF4446',   \n 'country': '#000004',   \n }\n\ndef plot_components(embeddings, n_rows, n_cols, title, suptitle):\n    \"\"\"helper function to plot embeddings\"\"\"\n    fig, ax = plt.subplots(n_rows, n_cols, sharex=True, sharey=True, figsize=(20,20))\n    r=0\n    c=0\n    for i in embeddings:\n        df_ = pd.DataFrame(embeddings[i])\n        df_.columns = [f'pc{i}' for i in range(1, len(df_.columns)+1)]\n        df_['genre'] = df.iloc[:,-1]\n        genres = df_.genre.unique()\n        if c>n_cols-1: c=0; r+=1\n        if r> n_rows-1: break\n        for genre in genres:\n            ax[r,c].scatter(df_[df_.genre==genre]['pc1'],\n                            df_[df_.genre==genre]['pc2'], \n                            color=color_scheme[genre],\n                            s=1\n                           )\n        ax[r,c].set_title(title.format(i.split('_')[0],i.split('_')[1]))\n        ax[r,c].axis('off')\n        c+=1\n\n    plt.figlegend(df_.genre.unique(), loc='center right', prop={'size': 18}, markerscale=10);\n    plt.suptitle(suptitle,fontsize=24);","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plot_components(tsne_embeddings, len(perplexities), len(iterations), \"perplexity={}\\nepochs={}\",\"t-SNE\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Get UMAP embeddings\nExtract UMAP embeddings for 2 components over multiple neighbor and min distance settings","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"umap_embeddings = dict()\nneighbors = list(range(10,31,5))\ndistances = [0.01, 0.02, 0.03, 0.04, 0.05]\nfor neighbor, distance in tqdm(list(itertools.product(neighbors,distances))):#for a prettier progress bar\n    umap_embedding = get_umap_embeddings(features,\n                                         neighbor=neighbor,\n                                         distance=distance)\n    umap_embeddings[f\"{neighbor}_{distance}\"]= umap_embedding","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plot UMAP results","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plot_components(umap_embeddings, len(neighbors), len(distances), \"neighbors={}\\nmin distance={}\",\"UMAP\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### t-SNE with 3 components","execution_count":null},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"tsne_embedding = get_tsne_embeddings(features,\n                                     n_components=3,\n                                     perplexity=30,\n                                     iteration=20000)\ndf_tsne = pd.DataFrame(tsne_embedding)\ndf_tsne.columns = ['pc1','pc2','pc3']\ndf_tsne['genre'] = df.iloc[:,-1]\ndf_tsne['text'] = df[['filename','label']].apply(lambda x: f'{x[0]}<br>{x[1]}', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"import plotly.graph_objects as go\n\ndata = []\nfor g in df_tsne.genre.unique():\n    trace = go.Scatter3d(\n    x=df_tsne[df_tsne.genre==g].pc1.values,\n    y=df_tsne[df_tsne.genre==g].pc2.values,\n    z=df_tsne[df_tsne.genre==g].pc3.values,\n    mode='markers',\n    text=df_tsne[df_tsne.genre==g].text.values,\n    hoverinfo = 'text',\n    name=g,\n    marker=dict(\n            size=3,\n            color=color_scheme[g],                \n            opacity=0.9,\n        )\n    )\n    data.append(trace)\nfig = go.Figure(data=data)\n\nfig.update_layout(title=f'TSNE', autosize=False,\n                      width=600, height=600,\n                      margin=dict(l=50, r=50, b=50, t=50),\n                      scene=dict(xaxis=dict(title='pc1'), yaxis=dict(title='pc2'), zaxis=dict(title='pc3'))\n                     )\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### UMAP with 3 components","execution_count":null},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"umap_embedding = get_umap_embeddings(features,\n                                     n_components=3,\n                                     neighbor=20,\n                                     distance=0.05)\ndf_umap = pd.DataFrame(umap_embedding)\ndf_umap.columns = ['pc1','pc2','pc3']\ndf_umap['genre'] = df.iloc[:,-1]\ndf_umap['text'] = df[['filename','label']].apply(lambda x: f'{x[0]}<br>{x[1]}', axis=1)\ndf_umap['color'] = df_umap.genre.apply(lambda x: color_scheme[x])","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"data = []\nfor g in df_umap.genre.unique():\n    trace = go.Scatter3d(\n    x=df_umap[df_umap.genre==g].pc1.values,\n    y=df_umap[df_umap.genre==g].pc2.values,\n    z=df_umap[df_umap.genre==g].pc3.values,\n    mode='markers',\n    text=df_umap[df_umap.genre==g].text.values,\n    hoverinfo = 'text',\n    name=g,\n    marker=dict(\n            size=3,\n            color=color_scheme[g],                \n            opacity=0.9,\n        )\n    )\n    data.append(trace)\nfig = go.Figure(data=data)\n\n# tight layout\nfig.update_layout(title=f'UMAP (Unsupervised)', autosize=False,\n                      width=600, height=600,\n                      margin=dict(l=50, r=50, b=50, t=50),\n                      scene=dict(xaxis=dict(title='pc1'), yaxis=dict(title='pc2'), zaxis=dict(title='pc3'))\n                     )\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### What do songs in a cluster sound like?\n\n* Pick a random point from UMAP embeddings.\n* Find 5 nearest neighbors (by Euclidean distance) of that point.\n* Listen to corresponding audio files.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# pick a random point\na_pt = umap_embedding[np.random.randint(0,len(umap_embedding))]\n# compute euclidean distances from all points to this point. Get sorted indices of top 6. The first one being the original point.\nidx = np.argsort(np.linalg.norm(umap_embedding-a_pt, axis=1))[:6]\n\n# display and play\npath = \"../input/gtzan-dataset-music-genre-classification/Data/genres_original/{}/{}.wav\"\nfor i, k in enumerate(idx):\n    # \"filename\" in the dataset is not a real file. Following lines involve some skulduggery to get correct audio segment from file. \n    fname = path.format(df.iloc[k,:]['label'],\".\".join(df.iloc[k,:]['filename'].split(\".\")[:-2]))\n    segment_index = int(df.iloc[k,:]['filename'].split(\".\")[-2])\n    y, sr = load(fname, mono=True)\n    start = segment_index*sr\n    end = start+(sr*3)\n    y = y[start:end]\n    \n    if i==0: display(HTML(f\"<p>Original:{df.iloc[k,:]['label']}</p><p>{fname}</p>\"), Audio(y, rate=sr))\n    else: display(HTML(f\"<p>Neighbor {i}:{df.iloc[k,:]['label']}</p><p>{fname}</p>\"), Audio(y, rate=sr))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Supervised UMAP","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"umap_embedding = umap.UMAP(n_neighbors=30,\n                               min_dist=0.4,\n                               metric='correlation', \n                               n_components=3,\n                               set_op_mix_ratio=0.25,\n                               verbose=False).fit_transform(standardize(features), y=target)\numap_embedding = MinMaxScaler().fit_transform(umap_embedding)\ndf_umap = pd.DataFrame(umap_embedding)\ndf_umap.columns = ['pc1','pc2','pc3']\ndf_umap['genre'] = df.iloc[:,-1]\ndf_umap['text'] = df[['filename','label']].apply(lambda x: f'{x[0]}<br>{x[1]}', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"data = []\nfor g in df_umap.genre.unique():\n    trace = go.Scatter3d(\n    x=df_umap[df_umap.genre==g].pc1.values,\n    y=df_umap[df_umap.genre==g].pc2.values,\n    z=df_umap[df_umap.genre==g].pc3.values,\n    mode='markers',\n    text=df_umap[df_umap.genre==g].text.values,\n    hoverinfo = 'text',\n    name=g,\n    marker=dict(\n            size=3,\n            color=color_scheme[g],                \n            opacity=0.9,\n        )\n    )\n    data.append(trace)\nfig = go.Figure(data=data)\n\n# tight layout\nfig.update_layout(title=f'UMAP (Supervised)', autosize=False,\n                      width=600, height=600,\n                      margin=dict(l=50, r=50, b=50, t=50),\n                      scene=dict(xaxis=dict(title='pc1'), yaxis=dict(title='pc2'), zaxis=dict(title='pc3'))\n                     )\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}