{"cells":[{"metadata":{"_uuid":"a7bdd93ed8478235c2a290608f69054dd90df29d"},"cell_type":"markdown","source":"![](https://diginomica.com/wp-content/uploads/2015/10/american-airlines1.jpg)"},{"metadata":{"_uuid":"1b69186dc6ab9470dcbbef3451d55824b888f8af"},"cell_type":"markdown","source":"# 1. Import"},{"metadata":{"trusted":true,"_uuid":"e8f35d2c74c370d4b01dc540862a67254031e8b5"},"cell_type":"code","source":"# System\nimport os\n\n# Time\nimport time\nimport datetime\n\n# Numerical\nimport numpy as np\nimport pandas as pd\n\n# Tools\nimport itertools\nfrom collections import Counter\n\n# NLP\nimport re\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize \nfrom nltk.stem import SnowballStemmer\nfrom nltk.stem import PorterStemmer\nfrom nltk.stem import WordNetLemmatizer\n# from pywsd.utils import lemmatize_sentence\n\n# Preprocessing\nfrom sklearn import preprocessing\nfrom sklearn.utils import class_weight as cw\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom bs4 import BeautifulSoup\n\n# Model Selection\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n\n# Machine Learning Models\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import svm\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, BaggingClassifier, ExtraTreesClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Evaluation Metrics\nfrom sklearn import metrics \nfrom sklearn.metrics import f1_score, accuracy_score,confusion_matrix,classification_report\n\n# Deep Learing Preprocessing - Keras\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing import sequence\nfrom keras.utils import to_categorical\n\n# Deep Learning Model - Keras\nfrom keras.models import Model\nfrom keras.models import Sequential\n\n# Deep Learning Model - Keras - CNN\nfrom keras.layers import Conv1D, Conv2D, Convolution1D, MaxPooling1D, SeparableConv1D, SpatialDropout1D, \\\n    GlobalAvgPool1D, GlobalMaxPool1D, GlobalMaxPooling1D \nfrom keras.layers.pooling import _GlobalPooling1D\nfrom keras.layers import MaxPooling2D, GlobalMaxPooling2D, GlobalAveragePooling2D\n\nfrom keras.layers import MaxPooling3D, GlobalMaxPooling3D, GlobalAveragePooling3D\n\n\n\n# Deep Learning Model - Keras - RNN\nfrom keras.layers import Embedding, LSTM, Bidirectional\n\n# Deep Learning Model - Keras - General\nfrom keras.layers import Input, Add, concatenate, Dense, Activation, BatchNormalization, Dropout, Flatten\nfrom keras.layers import LeakyReLU, PReLU, Lambda, Multiply\n\n\n\n# Deep Learning Parameters - Keras\nfrom keras.optimizers import RMSprop, Adam\n\n# Deep Learning Callbacs - Keras\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, ReduceLROnPlateau\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline\n\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bcf244fb2623377e6c472520181f55b570f22225"},"cell_type":"code","source":"# print date and time for given type of representation\ndef date_time(x):\n    if x==1:\n        return 'Timestamp: {:%Y-%m-%d %H:%M:%S}'.format(datetime.datetime.now())\n    if x==2:    \n        return 'Timestamp: {:%Y-%b-%d %H:%M:%S}'.format(datetime.datetime.now())\n    if x==3:  \n        return 'Date now: %s' % datetime.datetime.now()\n    if x==4:  \n        return 'Date today: %s' % datetime.date.today() ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f9941e463091c0974df63b98ddf42ef039d07044"},"cell_type":"markdown","source":"# 2. Read Data"},{"metadata":{"trusted":true,"_uuid":"24a1fce867bde9c19af86e6ad3fdcc9368db4907"},"cell_type":"code","source":"input_directory = r\"../input/\"\noutput_directory = r\"../output/\"\n\nif not os.path.exists(output_directory):\n    os.mkdir(output_directory)\n    \nfigure_directory = \"../output/figures\"\nif not os.path.exists(figure_directory):\n    os.mkdir(figure_directory)\n    \n    \nfile_name_pred_batch = figure_directory+r\"/result\"\nfile_name_pred_sample = figure_directory+r\"/sample\"","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/Tweets.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"82c38ef0a849c0e1b35dfaa6609497033690ecb3"},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5cf2744b1ea01acdb6e9100bba9c3e2a41833de0","_kg_hide-input":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cd9d8e8cccbe7be826ff80ebba85c94059b19d81","_kg_hide-input":true},"cell_type":"code","source":"columns = df.columns\ncolumns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"13bfcbe5c9e172fad039501b7c6604dc81abe010"},"cell_type":"markdown","source":"# 3. Visualize Data"},{"metadata":{"trusted":true,"_uuid":"0ffeb6d063fb09a80db926657faddf0c719333b5"},"cell_type":"code","source":"figsize=(20, 5)\n\nticksize = 14\ntitlesize = ticksize + 8\nlabelsize = ticksize + 5\n\nparams = {'figure.figsize' : figsize,\n          'axes.labelsize' : labelsize,\n          'axes.titlesize' : titlesize,\n          'xtick.labelsize': ticksize,\n          'ytick.labelsize': ticksize}\n\nplt.rcParams.update(params)\n\nplt.subplot(121)\ncol = \"airline\"\nxlabel = \"Airlines\"\nylabel = \"Count\"\n\nsns.countplot(x=df[col])\nplt.title(\"Airlines Review Count\")\nplt.xticks(rotation=90)\nplt.xlabel(xlabel)\nplt.ylabel(ylabel)\n\n\nplt.subplot(122)\ncol = \"airline_sentiment\"\nxlabel = \"Sentiment\"\nylabel = \"Count\"\nsns.countplot(df[col])\nplt.title(\"Review Sentiment Count\")\nplt.xlabel(xlabel)\nplt.ylabel(ylabel)\nplt.xticks(rotation=90)\nplt.plot()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d9ccaeb7b9230429515785e84ae9b36d15e1ac70"},"cell_type":"markdown","source":"Note:\n1. Most of the review present here are negative.\n2. Highest number of tweets are about \"United Airlines\", \"US Airlines\" and \"American Airlines\""},{"metadata":{"trusted":true,"_uuid":"6415fba24b67ddc166a43327d1327bc8c75f7f2c"},"cell_type":"code","source":"figsize=(20, 5)\n\nticksize = 14\ntitlesize = ticksize + 8\nlabelsize = ticksize + 5\n\nxlabel = \"Negative Reason\"\nylabel = \"Count\"\n\ntitle = \"Negative Reason Per Airlines\"\n\n\nparams = {'figure.figsize' : figsize,\n          'axes.labelsize' : labelsize,\n          'axes.titlesize' : titlesize,\n          'xtick.labelsize': ticksize,\n          'ytick.labelsize': ticksize}\n\nplt.rcParams.update(params)\n\ncol1 = \"negativereason\"\ncol2 = \"airline\"\nsns.countplot(x=df[col1], hue=df[col2])\nplt.title(title)\nplt.xlabel(xlabel)\nplt.ylabel(ylabel)\nplt.xticks(rotation=90)\nplt.plot()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0ee91b5d86edbe0bd0e18faf300fcfd53c3e4ad4"},"cell_type":"markdown","source":"Note:\n1. Most of the negative tweets are about \"Customer Service Issue\"."},{"metadata":{"trusted":true,"_uuid":"120e55e73a76526029cb3ffd648980ce11d8c8d5"},"cell_type":"code","source":"figsize=(20, 5)\n\nticksize = 14\ntitlesize = ticksize + 8\nlabelsize = ticksize + 5\n\nxlabel = \"Airlines\"\nylabel = \"Count\"\n\n\nparams = {'figure.figsize' : figsize,\n          'axes.labelsize' : labelsize,\n          'axes.titlesize' : titlesize,\n          'xtick.labelsize': ticksize,\n          'ytick.labelsize': ticksize}\n\nplt.rcParams.update(params)\n\nplt.figure(figsize=figsize)\ncol1 = \"airline\"\ncol2 = \"airline_sentiment\"\nsns.countplot(x=df[col1], hue=df[col2])\nplt.xlabel(xlabel)\nplt.ylabel(ylabel)\nplt.xticks(rotation=90)\nplt.plot()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1176c686fb26135f757d5fc98d264fffecee47aa"},"cell_type":"code","source":"x = df[\"negativereason_confidence\"].fillna(-1)\n\nfigsize=(18, 5)\n\nticksize = 12\ntitlesize = ticksize + 8\nlabelsize = ticksize + 5\n\nparams = {'figure.figsize' : figsize,\n          'axes.labelsize' : labelsize,\n          'axes.titlesize' : titlesize,\n          'xtick.labelsize': ticksize,\n          'ytick.labelsize': ticksize}\n\nplt.rcParams.update(params)\nsns.distplot(x)\nplt.plot()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f0d7b703a2c86d3a4652e52f62957078b078fb0f"},"cell_type":"markdown","source":"Note:\n1. Most of negative confidence values are centered around 0.6-0.9"},{"metadata":{"trusted":true,"_uuid":"dbbb6aef2c299642ab26cadaa3778c804bc8c4cb"},"cell_type":"code","source":"figsize=(18, 30)\n\nticksize = 12\ntitlesize = ticksize + 8\nlabelsize = ticksize + 5\n\nxlabel = \"Airlines\"\nylabel = \"Count\"\n\n\nparams = {'figure.figsize' : figsize,\n          'axes.labelsize' : labelsize,\n          'axes.titlesize' : titlesize,\n          'xtick.labelsize': ticksize,\n          'ytick.labelsize': ticksize}\n\nplt.rcParams.update(params)\n\ncol = \"user_timezone\"\ncol2 = \"airline_sentiment\"\nsns.countplot(y=df[col], hue=df[col2])\nplt.xticks(rotation=90)\nplt.plot()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"498ac53969f7c96c9b4ada819fa65d80b95dacd0"},"cell_type":"markdown","source":"## 4. Training Model"},{"metadata":{"trusted":true,"_uuid":"94b58472944a5843de64f63e1624b757abb06bc1"},"cell_type":"code","source":"from nltk.corpus import stopwords\n\nX = df\n\nX[\"text\"] = X[\"text\"].apply(lambda x: BeautifulSoup(x, \"lxml\").get_text())\nX[\"text\"] = X[\"text\"].apply(lambda x: x.lower())\nX[\"text\"] = X[\"text\"].apply(lambda x: re.sub(\"[^a-zA-Z]\", \" \", x))\nX[\"text\"] = X[\"text\"].apply(lambda x: re.sub(\"\\s+\", \" \", x))\n\nX = X[X[\"airline_sentiment_confidence\"]>0.5]\n\ny = X[\"airline_sentiment\"]\nX = X[\"text\"]\n\nstopwords = stopwords.words('english')\n# vectorizer = TfidfVectorizer()\nvectorizer = CountVectorizer(stop_words=stopwords)\n\nX = vectorizer.fit_transform(X)\n\nmodel = RandomForestClassifier(n_estimators=5, n_jobs=-1, class_weight='balanced', random_state=0)\n# model = SVC()\n\nprint(cross_val_score(model, X, y, cv=3))  ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"63bd6eb6b6e61629f6584772897655d98fa4253e"},"cell_type":"markdown","source":"## 5. Deep Learning"},{"metadata":{"_uuid":"727e5f0c3130d2df7403d96c743c8d4f4c3b7c4d"},"cell_type":"markdown","source":"### 5.1 Output Configuration"},{"metadata":{"trusted":true,"_uuid":"c8703accc04a96fda2e561b6e66e474a23dde81a"},"cell_type":"code","source":"main_model_dir = output_directory + r\"models/\"\nmain_log_dir = output_directory + r\"logs/\"\n\ntry:\n    os.mkdir(main_model_dir)\nexcept:\n    print(\"Could not create main model directory\")\n    \ntry:\n    os.mkdir(main_log_dir)\nexcept:\n    print(\"Could not create main log directory\")\n\n\n\nmodel_dir = main_model_dir + time.strftime('%Y-%m-%d %H-%M-%S') + \"/\"\nlog_dir = main_log_dir + time.strftime('%Y-%m-%d %H-%M-%S')\n\n\ntry:\n    os.mkdir(model_dir)\nexcept:\n    print(\"Could not create model directory\")\n    \ntry:\n    os.mkdir(log_dir)\nexcept:\n    print(\"Could not create log directory\")\n    \nmodel_file = model_dir + \"{epoch:02d}-val_acc-{val_acc:.2f}-val_loss-{val_loss:.2f}.hdf5\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0eeca633f28358dbfafd3db7fd22518fc77a276a"},"cell_type":"code","source":"print(\"Settting Callbacks\")\n\ncheckpoint = ModelCheckpoint(\n    model_file, \n    monitor='val_acc', \n    save_best_only=True)\n\nearly_stopping = EarlyStopping(\n    monitor='val_loss',\n    patience=3,\n    verbose=1,\n    restore_best_weights=True)\n\n\nreduce_lr = ReduceLROnPlateau(\n    monitor='val_loss',\n    factor=0.5,\n    patience=1,\n    verbose=1)\n\n\ncallbacks = [checkpoint, reduce_lr, early_stopping]\n\n# callbacks = [early_stopping]\n\nprint(\"Set Callbacks at \", date_time(1))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"42410b8507438ce15c28b5e9778908515dfaeb51"},"cell_type":"markdown","source":"### 5.2. Preprocessing"},{"metadata":{"trusted":true,"_uuid":"c97ce5c809f58080f13ab1da76fbeff96817a321"},"cell_type":"code","source":"X = df.text\nY = df.airline_sentiment\n\nlabel_encoder = LabelEncoder()\n\nY = label_encoder.fit_transform(Y)\n\nY = to_categorical(Y)\n\n# Y = Y.reshape(-1, 1)\nY","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"972b31926122af0747be40fa2b5d3bf14dcbe16a"},"cell_type":"code","source":"X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15)\n\nmax_words = len(set(\" \".join(X_train).split()))\nmax_len = X_train.apply(lambda x: len(x)).max()\n\n# max_words = 1000\n# max_len = 150\nmax_words, max_len","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6f82546a785e1eba0e6df397078497dffc94e902"},"cell_type":"code","source":"tokenizer = Tokenizer(num_words=max_words)\n\ntokenizer.fit_on_texts(X_train)\n\nX_train_seq = tokenizer.texts_to_sequences(X_train)\nX_train_seq = sequence.pad_sequences(X_train_seq, maxlen=max_len)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"15756f1979d321902f18964c00c515fb31342613"},"cell_type":"code","source":"# Calculate Class Weights\ndef get_weight(y):\n    class_weight_current =  cw.compute_class_weight('balanced', np.unique(y), y)\n    return class_weight_current","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f65f33959fa6abe41bfea8c660414a757ac048bf"},"cell_type":"code","source":"class_weight = get_weight(Y_train.flatten())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"19a3f4532b9398234b6f78e758688d7903d6b66b"},"cell_type":"markdown","source":"### 5.3 Model"},{"metadata":{"trusted":true,"_uuid":"ffc3ae3a4fb844cd20a9cb33750de42b2c71392d"},"cell_type":"code","source":"def get_rnn_model(num_class=2):\n    model = Sequential()\n    \n    model.add(Embedding(max_words, 100, input_length=max_len))\n    model.add(LSTM(256))\n    \n    model.add(Dropout(0.5))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    \n    model.add(Dense(512, activation='relu'))\n    \n    model.add(Dropout(0.5))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    \n    if num_class>2:\n        model.add(Dense(num_class, activation='softmax'))\n    else:\n        model.add(Dense(1, activation='sigmoid'))\n    \n    model.summary()\n    \n    return model\n\n\ndef get_cnn_model(num_class=2):   \n    model = Sequential()\n    \n    model.add(Embedding(max_words, 100, input_length=max_len))\n    \n    model.add(Conv1D(1024, 3, padding='valid', activation='relu', strides=1))\n    model.add(GlobalMaxPooling1D())\n    \n    \n    model.add(Dropout(0.5))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    \n    model.add(Dense(2048, activation='relu'))\n    \n    model.add(Dropout(0.5))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    \n    if num_class>2:\n        model.add(Dense(num_class, activation='softmax'))\n    else:\n        model.add(Dense(1, activation='sigmoid'))\n    \n    model.summary()\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a5472569b1c7c8f13fe14c9dcac3a7957db1300e"},"cell_type":"code","source":"def plot_performance(history=None, figure_directory=None, ylim_pad=[0, 0]):\n    xlabel = 'Epoch'\n    legends = ['Training', 'Validation']\n\n    plt.figure(figsize=(20, 5))\n\n    y1 = history.history['acc']\n    y2 = history.history['val_acc']\n\n    min_y = min(min(y1), min(y2))-ylim_pad[0]\n    max_y = max(max(y1), max(y2))+ylim_pad[0]\n\n\n    plt.subplot(121)\n\n    plt.plot(y1)\n    plt.plot(y2)\n\n    plt.title('Model Accuracy\\n'+date_time(1), fontsize=17)\n    plt.xlabel(xlabel, fontsize=15)\n    plt.ylabel('Accuracy', fontsize=15)\n    plt.ylim(min_y, max_y)\n    plt.legend(legends, loc='upper left')\n    plt.grid()\n\n    y1 = history.history['loss']\n    y2 = history.history['val_loss']\n\n    min_y = min(min(y1), min(y2))-ylim_pad[1]\n    max_y = max(max(y1), max(y2))+ylim_pad[1]\n\n\n    plt.subplot(122)\n\n    plt.plot(y1)\n    plt.plot(y2)\n\n    plt.title('Model Loss\\n'+date_time(1), fontsize=17)\n    plt.xlabel(xlabel, fontsize=15)\n    plt.ylabel('Loss', fontsize=15)\n    plt.ylim(min_y, max_y)\n    plt.legend(legends, loc='upper left')\n    plt.grid()\n    if figure_directory:\n        plt.savefig(figure_directory+\"/history\")\n\n    plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b424eb9a6e314ef397df89dcfeffc4c9c15839ee"},"cell_type":"code","source":"num_class = 3\nmodel1 = get_rnn_model(num_class=num_class)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"72903b1167548759e416d9b8ba643fdf90305e06"},"cell_type":"code","source":"loss = 'categorical_crossentropy'\n# loss = 'binary_crossentropy'\nmetrics = ['accuracy']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2bd1166ccac602ca7d908e9f9b17c8ffb2a1f92c"},"cell_type":"markdown","source":"## 10.3. Model Trainning"},{"metadata":{"_uuid":"a1ce715c032b60131950b0946776b41040ec97f4"},"cell_type":"markdown","source":"### 10.3.1. RNN"},{"metadata":{"trusted":true,"_uuid":"3499506821ecfcfa499a1195742796152939cc94"},"cell_type":"code","source":"print(\"Starting...\\n\")\n\nstart_time = time.time()\nprint(date_time(1))\n\nprint(\"\\n\\nCompliling Model ...\\n\")\nlearning_rate = 0.001\noptimizer = Adam(learning_rate)\n# optimizer = Adam()\n\nmodel1.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n\nverbose = 1\nepochs = 100\nbatch_size = 128\nvalidation_split = 0.2\n\nprint(\"Trainning Model ...\\n\")\n\nhistory1 = model1.fit(\n    X_train_seq,\n    Y_train,\n    batch_size=batch_size,\n    epochs=epochs,\n    verbose=verbose,\n    callbacks=callbacks,\n    validation_split=validation_split,\n    class_weight =class_weight\n    )\n\nelapsed_time = time.time() - start_time\nelapsed_time = time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time))\n\nprint(\"\\nElapsed Time: \" + elapsed_time)\nprint(\"Completed Model Trainning\", date_time(1))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"174b2e76795372f6e7d09d6fa48579f782609b78"},"cell_type":"markdown","source":"#### 10.3.1.2  Visualization"},{"metadata":{"trusted":true,"_uuid":"5e6865d7574bb08bfc6e20ce51c8c0a6ab39ef4c"},"cell_type":"code","source":"plot_performance(history=history1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"29bb4e66b2f030e88d88ca12d48209a93991647c"},"cell_type":"markdown","source":"### 10.3.1. RNN"},{"metadata":{"trusted":true,"_uuid":"106063a66e2031658fd6649c2bc68ff54a2d6e9a"},"cell_type":"code","source":"num_class = 3\nmodel2 = get_cnn_model(num_class=num_class)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f15fae20f343530b2e83e9c890fe674fc0d3ea1a","scrolled":false},"cell_type":"code","source":"print(\"Starting...\\n\")\n\nstart_time = time.time()\nprint(date_time(1))\n\nprint(\"\\n\\nCompliling Model ...\\n\")\nlearning_rate = 0.001\noptimizer = Adam(learning_rate)\n# optimizer = Adam()\n\nmodel2.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n\nverbose = 1\nepochs = 100\nbatch_size = 128\nvalidation_split = 0.2\n\nprint(\"Trainning Model ...\\n\")\n\nhistory2 = model2.fit(\n    X_train_seq,\n    Y_train,\n    batch_size=batch_size,\n    epochs=epochs,\n    verbose=verbose,\n    callbacks=callbacks,\n    validation_split=validation_split,\n    class_weight =class_weight\n    )\n\nelapsed_time = time.time() - start_time\nelapsed_time = time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time))\n\nprint(\"\\nElapsed Time: \" + elapsed_time)\nprint(\"Completed Model Trainning\", date_time(1))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"357b590e09d3e623822c3e68b280ef42db952075"},"cell_type":"markdown","source":"#### 10.3.1.2 Visualization"},{"metadata":{"trusted":true,"_uuid":"50d81ffc4f78b45a59b7f08ec404d008a3c63f94"},"cell_type":"code","source":"plot_performance(history=history2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b64920b6ac5a1bb4e60f1d937245007292dd1681"},"cell_type":"markdown","source":"## 10.5 Inference/ Prediction"},{"metadata":{"trusted":true,"_uuid":"a6e1d8e3639c5e739a67c484b00faf148fa6edd4"},"cell_type":"code","source":"test_X_seq = tokenizer.texts_to_sequences(X_test)\ntest_X_seq = sequence.pad_sequences(test_X_seq, maxlen=max_len)\naccuracy1 = model1.evaluate(test_X_seq, Y_test)\naccuracy2 = model2.evaluate(test_X_seq, Y_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"08c78c65d45aaa855de2d16533dc5ddeb1a52c9b"},"cell_type":"markdown","source":"### 10.5.1 Evaluation"},{"metadata":{"trusted":true,"_uuid":"fd3d9e8a332ab50eb69d3995fa0847c642ca942d"},"cell_type":"code","source":"print(\"Model Performance of RNN (Test Accuracy):\")\nprint('Accuracy: {:0.2f}%\\nLoss: {:0.3f}\\n'.format(accuracy1[1]*100, accuracy1[0]))\n\nprint(\"\\nModel Performance of RNN (Test Accuracy):\")\nprint('v: {:0.2f}%\\nLoss: {:0.3f}\\n'.format(accuracy2[1]*100, accuracy2[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"68d1b5720cecae415e852c1f35563da08cfea2b5"},"cell_type":"code","source":"ypreds1 = model1.predict_classes(test_X_seq, verbose=1)\nypreds2 = model2.predict_classes(test_X_seq, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3feb7baf3e5658dce6bdcf929af34676b5f23fd7"},"cell_type":"code","source":"def plot_model_performace(result):\n    sns.set_style(\"ticks\")\n    figsize=(22, 6)\n\n    ticksize = 12\n    titlesize = ticksize + 8\n    labelsize = ticksize + 5\n\n    xlabel = \"Model\"\n    ylabel = \"Score\"\n\n    title = \"Model Performance\"\n\n    params = {'figure.figsize' : figsize,\n              'axes.labelsize' : labelsize,\n              'axes.titlesize' : titlesize,\n              'xtick.labelsize': ticksize,\n              'ytick.labelsize': ticksize}\n\n    plt.rcParams.update(params)\n\n    col1 = \"model\"\n    col2 = \"score\"\n    sns.barplot(x=col1, y=col2, data=result)\n    plt.title(title.title())\n    plt.xlabel(xlabel)\n    plt.ylabel(ylabel)\n    plt.xticks(rotation=90)\n    plt.grid()\n    plt.plot()\n    plt.show()\n    print(result)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dc19b344d18b16e4f15d4b21eb86bf6acde8c2f0"},"cell_type":"code","source":"# print(classification_report(Y_test, ypreds1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"47e7e60a9e06662083a4971f84589129d307be40"},"cell_type":"code","source":"plot_confusion_matrix(Y_test, ypreds1, title=\"RNN\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0fc73dddd076f5c15ff41a9dff2abf47d7126589"},"cell_type":"code","source":"# print(classification_report(Y_test, ypreds2))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"73e7f87fdfb70dd3eddabd607a9eefb96a086831"},"cell_type":"markdown","source":"#### 10.5.1.2 Visualization"},{"metadata":{"trusted":true,"_uuid":"675a75e41d24b34491a9b9e310b30803b90e9188"},"cell_type":"code","source":"# plot_confusion_matrix(Y_test, ypreds2, title=\"CNN\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6679f27d3d8d66fcc4c99d3183821051f823f688"},"cell_type":"code","source":"result = pd.DataFrame({'model': 'RNN', 'score': accuracy1[1]*100}, index=[-1])\nrow2 = pd.DataFrame({'model': 'CNN', 'score': accuracy2[1]*100}, index=[-1])\nresult = pd.concat([row2, result.ix[:]]).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fa8ce5f06a1b2884dd5b1c113dcd041c86aa26bb"},"cell_type":"code","source":"plot_model_performace(result)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"abb7d608d7ed5bcd412125d31d176a022d599444"},"cell_type":"markdown","source":"# Reference:\n1. [Text Preprocessing and Machine Learning Modeling](https://www.kaggle.com/futurist/text-preprocessing-and-machine-learning-modeling)\n2. [keras mlp cnn test for text classification](https://www.kaggle.com/jacklinggu/keras-mlp-cnn-test-for-text-classification)"},{"metadata":{"trusted":true,"_uuid":"4508c011e7f7449b027acc000decbf6561e69ca0"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a44c65a66fdfbf03738c03f4eaeb90c2166a45d2"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}