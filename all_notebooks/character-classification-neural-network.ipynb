{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Classify English Handwritten Characters through CNN","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Problem statement\nThe dataset contains 3410 images containing handwritten letters (0-9 numbers, a-z alphabets small and in caps)\nThe goal is to train the model to recognize and predict the characters efficiently and categorize between 62 unique characters\n\nI'm trying the classification through CNN\n","metadata":{}},{"cell_type":"markdown","source":"**import the libraries**","metadata":{}},{"cell_type":"code","source":"import pandas\nimport random\nfrom keras_preprocessing.image import ImageDataGenerator\nimport tensorflow as tf\nimport matplotlib.image as img\nimport matplotlib.pyplot as plt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Split the dataset\nIn this step, we'll split the data into 3 datasets - training set, validation test and test set\nOut of total 3410 images, 2910 to training set, 490 added to validation set, 5 to test set\nRemoved the images added to validation, test set from training set to test its accuracy","metadata":{}},{"cell_type":"code","source":"data_path = r\"/kaggle/input/english-handwritten-characters-dataset\"\n\ndataset = pandas.read_csv(data_path + '/english.csv')\nrand = random.sample(range(len(dataset)), 500)\nvalidation_set = pandas.DataFrame(dataset.iloc[rand, :].values, columns=['image', 'label'])\n# remove the added data\ndataset.drop(rand, inplace=True)\n\nrand = random.sample(range(len(validation_set)), 5)\ntest_set = pandas.DataFrame(validation_set.iloc[rand, :].values, columns=['image', 'label'])\n# remove the added data\nvalidation_set.drop(rand, inplace=True)\n\nprint(test_set)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data preprocessing\nNow that the data is split, lets start with preprocessing step\n\nLoad the images through **flow_from_dataframe** method\nThis method is convinient since the data file (english.csv) contains the image names along with the classification class details","metadata":{}},{"cell_type":"code","source":"train_data_generator = ImageDataGenerator(rescale=1/255, shear_range=0.2, zoom_range=0.2)\ndata_generator = ImageDataGenerator(rescale=1/255)\ntraining_data_frame = train_data_generator.flow_from_dataframe(dataframe=dataset, directory=data_path, x_col='image', y_col='label', \n                                                               target_size=(64, 64), class_mode='categorical')\nvalidation_data_frame = data_generator.flow_from_dataframe(dataframe=validation_set, directory=data_path, x_col='image', y_col='label', \n                                                           target_size=(64, 64), class_mode='categorical')\ntest_data_frame = data_generator.flow_from_dataframe(dataframe=test_set, directory=data_path, x_col='image', y_col='label', \n                                                     target_size=(64, 64), class_mode='categorical', shuffle=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Building the CNN model\nWe are about to build CNN model using libraries provided through **TensorFlow**\n\nCode block breakdown:\n* Create Convolution layer: to read/process the image, one feature or one part at a time\n* Create Pooling layer: used to reduce the spatial size of convolved image\n* Create Flattening layer: used to flatten the result, whose output would be the input for the neural network \n\nWe can create multiple convolution and pooling layer depending upon the need/complexity of the dataset","metadata":{}},{"cell_type":"code","source":"cnn = tf.keras.models.Sequential()\n\n# add convolutional and pooling layer\ncnn.add(tf.keras.layers.Conv2D(filters=30, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))\ncnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n\ncnn.add(tf.keras.layers.Conv2D(filters=30, kernel_size=3, activation='relu'))\ncnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n\ncnn.add(tf.keras.layers.Conv2D(filters=30, kernel_size=3, activation='relu'))\ncnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n\ncnn.add(tf.keras.layers.Flatten())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Building, compiling and training the neural network\n\nFrom the above step we have received the flattened matrix of the images that we processed\nWe are going to feed it to our neural network and train it\n\nIn this section, created fully connected Neural network aka Dense network, chosen sigmoid function for activation type\nIn below the model will learn from the training set and predicts the data from validation set\n\nThe model accuracy improves as the epochs iteration progresses","metadata":{}},{"cell_type":"code","source":"# add full connection, output layer\ncnn.add(tf.keras.layers.Dense(units=600, activation='relu'))\ncnn.add(tf.keras.layers.Dense(units=62, activation='sigmoid'))\n\n# compile cnn\ncnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\ncnn.fit(x=training_data_frame, validation_data=validation_data_frame, epochs=30)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predicting the testset images\n\nSince the model is trained, lets pass the testset images and see how well our model predicts\nclass_indices function gives us the neural network mapping for our 62 characters\n\nThe result image's name is the predicted character by our model","metadata":{}},{"cell_type":"code","source":"print(\"Prediction mapping: \", training_data_frame.class_indices)\npred = cnn.predict(test_data_frame)\n\n# switcher shows our network mapping to the prediction\nswitcher = {\n            0: \"0\", 1: \"1\", 2: \"2\", 3: \"3\", 4: \"4\", 5: \"5\", 6: \"6\", 7: \"7\", 8: \"8\", 9: \"9\", 10: \"A\",\n            11: \"B\", 12: \"C\", 13: \"D\", 14: \"E\", 15: \"F\", 16: \"G\", 17: \"H\", 18: \"I\", 19: \"J\", 20: \"K\",\n            21: \"L\", 22: \"M\", 23: \"N\", 24: \"O\", 25: \"P\", 26: \"Q\", 27: \"R\", 28: \"S\", 29: \"T\", 30: \"U\",\n            31: \"V\", 32: \"W\", 33: \"X\", 34: \"Y\", 35: \"Z\", 36: \"a\", 37: \"b\", 38: \"c\", 39: \"d\", 40: \"e\",\n            41: \"f\", 42: \"g\", 43: \"h\", 44: \"i\", 45: \"j\", 46: \"k\", 47: \"l\", 48: \"m\", 49: \"n\", 50: \"o\",\n            51: \"p\", 52: \"q\", 53: \"r\", 54: \"s\", 55: \"t\", 56: \"u\", 57: \"v\", 58: \"w\", 59: \"x\", 60: \"y\",\n            61: \"z\"}\n\noutputDf = pandas.DataFrame(pred)\nmaxIndex = list(outputDf.idxmax(axis=1))\nprint(\"Max index: \", maxIndex)\nfor i in range(len(test_set)):\n    image = img.imread(data_path + '/' + test_set.at[i, 'image'])\n    plt.title(switcher.get(maxIndex[i], \"error\"))\n    plt.imshow(image)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Final thoughts\n\n1. The model accuracy differs every time as validation and testset images are picked at random, random pick impacts the number of images available for each character in a training set\n2. We can increase the trainingset images by adding distortions, image flips, zoom\n3. Model's accuracy can be improved through updating image size we are feeding, it would also affect the model's speed\n4. We can also experiment by varying \n    * the number of featues\n    * kernel dimension\n    * number of convolution\n    * pooling layers\n    * epochs count\n    * fixing the learning rate\n    \n","metadata":{}}]}