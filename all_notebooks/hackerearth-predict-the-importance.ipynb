{"cells":[{"metadata":{},"cell_type":"markdown","source":"- Problem description: https://www.hackerearth.com/challenges/competitive/hackerearth-machine-learning-challenge-predict-grievance-importance/"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn import preprocessing\nle = preprocessing.LabelEncoder()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrain = pd.read_csv('../input/resolving-citizens-grievances-v1/dataset/train.csv')\ntest = pd.read_csv('../input/resolving-citizens-grievances-v1/dataset/test.csv')\ntrain.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# combining test and train to do feature engineering.\ntest['importance']=-1\ntrain['label'] = 'train'\ntest['label'] = 'test'\ncombined = pd.concat([train,test],axis=0)\ncombined.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in combined.columns:\n    print(col,'unique values-> ',combined[col].nunique(), 'null values--> ', combined[col].isnull().sum())\n\n#     a lot of features have multiple empty values and single constant value.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def combine_issues(df):\n#     combining all the issues columns to form one issue column\n    issue_columns = [\n        'issue.0', 'issue.1', 'issue.2', 'issue.3', 'issue.4', 'issue.5', 'issue.6', 'issue.7', 'issue.8', \n        'issue.9', 'issue.10', 'issue.11', 'issue.12', 'issue.13', 'issue.14', 'issue.15', 'issue.16', \n        'issue.17', 'issue.18', 'issue.19', 'issue.20', 'issue.21', 'issue.22', 'issue.23']\n    issue_df = combined[issue_columns]\n    issue_df.fillna('',inplace=True)\n    issue_df['issues'] = issue_df[issue_columns].apply(lambda x: '. '.join([val for val in x if val != '']), axis=1)\n    df.drop(issue_columns, axis=1, inplace=True)\n    issue_df.drop(issue_columns, axis=1, inplace=True)\n    df = pd.concat([df, issue_df], axis=1)\n    return df\n\n\ndef lowercase_texts(df):\n    print('converting all text columns in lowercase.',)\n    for col in combined.columns:\n        if combined[col].dtype=='object':\n            combined[col] = combined[col].str.lower()\n    return df\n\n\ndef universalize_countries(df):\n#     converting all the countries to single symbolic numerical value.(eg - Albania, albania, abl, ab -> 1)\n    country_dict_A = df[['respondentOrderEng','country.name']].set_index('country.name').T.to_dict('list')\n    country_dict_C = df[['respondentOrderEng','respondent.0']].set_index('respondent.0').T.to_dict('list')    \n    country_dict = {}\n    for d in (country_dict_A, country_dict_C):#, country_dict_C): #, country_dict_D, country_dict_E, country_dict_F): \n        country_dict.update(d)\n        \n    country_dict = {k: v for k, v in country_dict.items() if pd.notna(k)}\n    df['respondent.0'] = df['respondent.0'].apply(lambda x: country_dict[x][0])\n    df['respondent.1'] = df['respondent.1'].apply(lambda x: country_dict[x][0] if pd.notnull(x) else x)\n    df['respondent.2'] = df['respondent.2'].apply(lambda x: country_dict[x][0] if pd.notnull(x) else x)\n    df['respondent.3'] = df['respondent.3'].apply(lambda x: country_dict[x][0] if pd.notnull(x) else x)\n    df['respondent.4'] = df['respondent.4'].apply(lambda x: country_dict[x][0] if pd.notnull(x) else x)\n    del df['respondentOrderEng']\n    return df\n\ndef remove_constant_values(df):\n#     this function removes redundant constant features.\n    print('Removing constant columns -> ',)\n    for col in df.columns:\n        if df[col].nunique()==1:\n            print(col,end=', ' )\n            del df[col]\n    return df\n\ndef remove_unwanted_features(df):\n#     these features dont add any valueable signal to the data.\n    remove_cols =['parties.0', 'country.alpha2', 'parties.1', 'country.name', 'docname', 'appno', 'ecli', 'kpdate', 'originatingbody_name']\n    for col in remove_cols:\n        if col in df.columns:\n            df.drop(col, axis=1, inplace=True)\n    return df\n\n  \ndef featurize_columns(df):\n#     making new columns.\n    df['itemid'] = df['itemid'].apply(lambda x: x[4:7])\n    df['sharepointid'] = df['sharepointid'].apply(lambda x: str(x)[:3])\n    df['total_respondents'] = 5- df[['respondent.0','respondent.1','respondent.2','respondent.3','respondent.4']].isna().sum(axis=1)\n\n    return df\n\ndef featurize_date_columns(df):\n    #     making new columns based on dates.\n    df['daysbetween_intro_decision'] = (pd.to_datetime(df['decisiondate']) - pd.to_datetime(df['introductiondate'])).dt.days\n    df['daysbetween_intro_judgement'] = (pd.to_datetime(df['judgementdate']) - pd.to_datetime(df['introductiondate'])).dt.days\n    df['daysbetween_decision_judgement'] = (pd.to_datetime(df['judgementdate']) - pd.to_datetime(df['decisiondate'])).dt.days\n    df.drop(['decisiondate','introductiondate','judgementdate'], axis=1, inplace=True)\n    return df\n\ndef encoding(df):\n    df['doctypebranch'] = le.fit_transform(df['doctypebranch'])\n    df['separateopinion'] = le.fit_transform(df['separateopinion'])\n    df['typedescription'] = le.fit_transform(df['typedescription'])\n    return df\n\ndef fill_missing(df):\n    for col in df.columns:\n        if col not in ['label', 'issues']:\n            df[col].fillna(0,inplace=True)\n            df[col] = df[col].astype('int')\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"combined.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pd.set_option('display.max_colwidth', -1)\n# combined[['issues']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"combined = combine_issues(combined)\nprint('combined shape after combining issues ->', combined.shape)\ncombined = lowercase_texts(combined)\ncombined = universalize_countries(combined)\ncombined = featurize_columns(combined)\ncombined = featurize_date_columns(combined)\ncombined = encoding(combined)\ncombined = remove_constant_values(combined)\nprint('\\ncombined shape after removing constant features->', combined.shape)\ncombined = remove_unwanted_features(combined)\ncombined = fill_missing(combined)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"combined.head()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"combined.to_csv('combined_inbetween.csv',index=False)\n","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# for col in combined.columns:\n#     print(col,'unique values-> ',combined[col].nunique(), 'null values--> ', combined[col].isnull().sum(), 'type-> ',combined[col].dtype)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# before making the model, delete label column, delete issues column.\n# separate test and train, delete output of test.\n# explore blackstone - https://spacy.io/universe/project/blackstone for making new features from issues.\n# test filling missing values using different stratergies.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from lightgbm import LGBMClassifier\nfrom sklearn.model_selection import GridSearchCV \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_col = 'importance'\ncombined.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"combined_train = combined.query('label == \"train\"').drop(['issues', 'label'] , axis=1)\ncombined_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# split test and train\nX_train, X_test, Y_train, Y_test = \\\n    train_test_split(combined_train.drop([target_col], axis=1), \n                     combined_train[target_col], \n                     test_size=0.2, \n                     stratify=combined_train[target_col])\nprint(len(X_train),' samples in training data\\n',\n      len(X_test),' samples in test data\\n', )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# choosing different hyperparameters and select the best one\nclf_dict = {\"LGBM Classifier\": \n            {'classifier': LGBMClassifier(),\n                 'params': [\n                            {\n                             'learning_rate': [0.01, 0.1, 1.0],\n                             'n_estimators' :[10, 50, 500, 1000],\n                             'max_depth':[5, 3,7],\n                             'max_features' : [3, 5, 7, 11]\n                            }\n                           ]\n            },\n           }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res_df  = pd.DataFrame()\nnum_clf = len(clf_dict.keys())\nres_df = pd.DataFrame(\n    data=np.zeros(shape=(num_clf, 3)),\n    columns = ['classifier',\n                   'train_score', \n                   'test_score',\n            ]\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ncount = 0\n#training the model\nfor key, clf in clf_dict.items():\n    print(key, clf)\n\n    grid = GridSearchCV(clf[\"classifier\"],\n                        clf[\"params\"],\n                        refit=True,\n                        cv=10,\n                        scoring = 'accuracy',\n                        n_jobs = -1,\n                        verbose=0\n                        \n                       )\n    estimator = grid.fit( X_train,Y_train)\n    \n    train_score = estimator.score(X_train,Y_train)\n    \n    test_score = estimator.score(X_test,Y_test)\n    \n    count+=1\n    \n    res_df.loc[count,'classifier'] = key\n    res_df.loc[count,'train_score'] = train_score\n    res_df.loc[count,'test_score'] = test_score\n    print(f\"{key} best params: {grid.best_params_}\")\n    \nres_df.iloc[1:, :]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Light Gradient Boosting Machine ensemble machine learning algorithm\nxgbm = LGBMClassifier(max_depth=6, learning_rate=0.1, n_estimators=500,\n                         min_child_weight=100, subsample=1.0, \n                         colsample_bytree=0.8, colsample_bylevel=0.8,\n                         random_state=42, n_jobs=-1)\n\n\nprint(\"Cross Validating...\")\noof_preds = cross_val_predict(xgbm, X_train, Y_train, cv=5, \n                                  n_jobs=-1, method=\"predict\")\nprint(\"cv score: \", accuracy_score(oof_preds, Y_train) * 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"tst = combined.query('label == \"test\"').drop(['issues', 'label', target_col] , axis=1)\n#prediction\npreds = pred.predict(tst)\npreds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"sub = pd.DataFrame(columns=[\"appno\",\"importance\"])\nsub[\"appno\"] = test.appno\nsub[\"importance\"] = preds\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv(\"submission2.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}