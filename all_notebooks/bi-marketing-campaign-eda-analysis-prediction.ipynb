{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Dr. Maryam Khanian\n# Date: 18.07.2021","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:04:53.98436Z","iopub.execute_input":"2021-07-20T05:04:53.984794Z","iopub.status.idle":"2021-07-20T05:04:53.988915Z","shell.execute_reply.started":"2021-07-20T05:04:53.984732Z","shell.execute_reply":"2021-07-20T05:04:53.988142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Project Explanation\n\n\n### Introduction\n\nIn every data analysis project, we need a solid foundation to succeed. Such a foundation consist of specific steps that we need to perform necessary actions, gather the required information, and finally perform a well-structured and holistic data analysis.\n\n#### Problem Identification/ Problem statement\n\nAt the first step, we should understand what exactly the problem is, which logics exist behind the problem, how does it affect all the involved parties, and what are clarified points of the main objective in the current data science project.\n\n\nThe main idea of this project is to extract actionable insights from the given data of a company that improves their decision-making process. Furthermore, we want to provide the best possible predictive model for the marketing campaign of their new product which shows if a customer buys the new product or not and how much is the possibility of the purchase.\n\n\n#### Data Description\n\nThe provided data is split into two CSV files containing the training (`train.csv`), and the test data (`test.csv`). The **training date set** includes **31480 records**, containing customer and operational features. Customer features cover master data of customers such as their `age`, `gender`, `occupation`, `marital status`, `education level` and `account balance`, while operational features are related to the last campaign activities including `last campaign result`, `contact date`, `contact duration`, etc. The **test date set** consists of **13732 samples** containing all the provided features in training data except the target value. In general, we have **19 features and one target variable**\nthat should be predicted. These features can be described as follows:\n\n| Feature                       | Type      | Description                                                |\n| :--                           | :--       | :--                                                        |\n| id                            | Numerical | record ID                                                  |\n| target                        | Nominal   | target value (customer response to the marketing campaign) |\n| day                           | Numerical | contact day in previous campaign                           |\n| month                         | Nominal   | contact month in previous campaign                         |\n| duration                      | Numerical | contact duration in previous campaign                      |\n| contactId                     | Numerical | contact ID                                                 |\n| age                           | Numerical | age of the customer                                        |\n| gender                        | Nominal   | customer gender                                            |\n| job                           | Nominal   | customer occupation                                        |\n| maritalStatus                 | Nominal   | customer marital status                                    |\n| education                     | Nominal   | customer educational degree                                |\n| craditFailure                 | Nominal   | if the customer has a default credit                       |\n| accountBalance                | Numerical | customer account balance                                   |\n| house                         | Nominal   | if the customer owns a house                               |\n| credit                        | Nominal   | if the customer has a credit                               |\n| contactType                   | Nominal   | contact media                                              |\n| numberOfContacts              | Numerical | number of contacts during the current campaign             |\n| daySinceLastCampaign          | Numerical | days after the last contact of the previous campaign       |\n| numberOfContactsLastCampaign  | Numerical | number of contacts during the previous campaign            |\n| lastCampaignResult            | Nominal   | result of the previous campaign                            |\n\n\n#### Brainstorming\n\nDuring the brainstorming, we need to ask some interesting questions that we can try to answer during our data analysis process. This step is really useful for providing meaningful and actionable insights for the customer. Here we might ask:\n\n- What are the most important factors that influence the success rate of the campaign?\n- What is the amount of correlation between the given features and target value? \n- Does the age, gender, education level, and other individual properties of each customer affect the campaign result? \n- Does the campaign performance vary in different seasons?\n- Does the time of contacts and their frequencies affect the result?\n- Is there any correlation between results of the previous campaign and the current one? \n- How can we detect our most loyal and most unsatisfied customers?\n- Is there any relationship between the contact type and the campaign result?","metadata":{}},{"cell_type":"markdown","source":"### Exploratory Data Analysis - Business Intelligence\n\nExploratory Data Analysis (EDA) is an important primary step in each data analytics process. This step can be difined as the application of different data visualization techniques on the data to achieve all or some of the following objectives.\n\n1. Gaining new insights about the data\n2. Identifying important chracteristics of the data \n3. Discovering the hidden relations among the data\n4. Detecting outliers and anomalies of the data\n5. Testing primary assumptions about the data\n\nand much more.\n\nActually, EDA is an open-ended process where we make plots and perform statistical analysis to explore the data. For example, finding a correlation between two variables (bi-variate analysis). In short, the goal of EDA is to determine what our data can tell us! EDA generally starts out with a high-level overview, and then narrows in to specific parts of the dataset once as we find interesting areas to examine. \n\nLet's start our interesting journey with **importing some necessary libraries**:","metadata":{}},{"cell_type":"code","source":"# Pandas and numpy for data manipulation\nimport pandas as pd\nimport numpy as np\n\n# No warnings about setting value on copy of slice\npd.options.mode.chained_assignment = None\n\n# Truncated floating point formatting\npd.options.display.float_format = '{:.2f}'.format\n\n# turning off the warnings\nimport warnings\nwarnings.filterwarnings('ignore')\nwarnings.simplefilter('ignore')\n\nfrom sklearn.exceptions import DataConversionWarning\nwarnings.filterwarnings(action='ignore', category=DataConversionWarning)\n\n\n# Display up to 60 columns of a dataframe\npd.set_option('display.max_columns', 60)\n\n# Matplotlib visualization\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Set default font size\nplt.rcParams['font.size'] = 14\n\n# Internal ipython tool for setting figure size\nfrom IPython.core.pylabtools import figsize\n\n# Seaborn for visualization\nimport seaborn as sns\nsns.set(font_scale = 1.5)\n\n# Splitting data into training and testing\nfrom sklearn.model_selection import train_test_split\n\nimport plotly.express as px\nimport plotly.graph_objs as go\nfrom plotly.subplots import make_subplots","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:04:53.992968Z","iopub.execute_input":"2021-07-20T05:04:53.993365Z","iopub.status.idle":"2021-07-20T05:04:55.412933Z","shell.execute_reply.started":"2021-07-20T05:04:53.993335Z","shell.execute_reply":"2021-07-20T05:04:55.411841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Getting Familiar with the data","metadata":{}},{"cell_type":"markdown","source":"### Data manipulation with Pandas:\n\nFor the import and manipulation of the data, I use `pandas` package due to the following reason:\n\n1.  Pandas has a well-designed data structure called *dataframe* with column names that can help a lot in keeping track of our data.  \n2.  The provided training data is a kind of heterogeneous data including nummeric as well as categorial values. With a pandas dataframe, we are able to work with different data types (float, int, string, datetime, etc) all in one place.\n3.  Pandas has some very useful built-in functionalities for a lot of common data-processing applications. For example, easy group by syntax, easy joins, etc.\n4.  Pandas has a good IO capabilities.\n\n### Data visualization with Seaborn & Plotly:\n\nFor Data visualization, I use `seaborn` & `plotly` packages of Python. These packages provide an API on top of traditional *Matplotlib* package that offers simple high-level functions for common statistical plot types, and integrates with the functionality provided by Pandas DataFrames. In addition, `plotly` is an interactive, open-source, and browser-based graphic library for Python that provides over 30 chart types, including scientific charts, 3D graphs, statistical charts, SVG maps, financial charts that can be viewed in Jupyter notebooks and standalone HTML files.","metadata":{}},{"cell_type":"code","source":"# Loading the provided training data from the csv file into a pandas dataframe (df)\nData = pd.read_csv('../input/marketing-campaign-analysis-data/train.csv')\n# take a look at the first five rows of the imported data\nData.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:04:55.414923Z","iopub.execute_input":"2021-07-20T05:04:55.415291Z","iopub.status.idle":"2021-07-20T05:04:55.545338Z","shell.execute_reply.started":"2021-07-20T05:04:55.415257Z","shell.execute_reply":"2021-07-20T05:04:55.544136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As the first step in our Exploratory Data Analysis (EDA) process, `dataframe.info()` method is a quick way to assess the data by displaying the data types of each column and the number of non-missing values.","metadata":{}},{"cell_type":"code","source":"Data.info()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:04:55.546887Z","iopub.execute_input":"2021-07-20T05:04:55.547237Z","iopub.status.idle":"2021-07-20T05:04:55.715582Z","shell.execute_reply.started":"2021-07-20T05:04:55.547202Z","shell.execute_reply":"2021-07-20T05:04:55.714314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As can be seen, the training data contains **31480 samples** and **20 features** in which **9 features** have **numerical** values and the rest (**11 features**) are **nominal**. Since we are going to work with mathematical models, we should work only with numbers. So, the values of all the **nominal (object)** columns should be converted into numerical values. But, at the moment, such a conversion, drastically decrease the readabilirty of our diagrmas during the EDA process. Therefore, we should postpone this conversion to the **preprocessing step** that takes place after the EDA process and just before feeding the data to the models.\n\nIn addition, the result of the `info()` function shows `daySinceLastCampaign ` column is the only column that has less number of values (**5738 vlaues**). So, we can conclude this column has **31480-5738 = 25742 missing values**: ","metadata":{}},{"cell_type":"code","source":"# take a look to see how is the situation of missing data:\nmissing_data = pd.DataFrame({'total_missing': Data.isnull().sum(), 'perc_missing': (Data.isnull().sum()/len(Data))*100}).round(2)\n\n# Print some summary information\nprint (\"Our dataframe has \" + str(Data.shape[1]) + \" column(s).\\n\"\n        \"There is/are \" + str(len(missing_data.loc[missing_data['total_missing'] > 0])) +\n              \" column(s) that has/have missing values.\")\nmissing_data","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-07-20T05:04:55.717225Z","iopub.execute_input":"2021-07-20T05:04:55.717681Z","iopub.status.idle":"2021-07-20T05:04:55.817735Z","shell.execute_reply.started":"2021-07-20T05:04:55.717635Z","shell.execute_reply":"2021-07-20T05:04:55.816712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Data[Data['daySinceLastCampaign'].isnull()]['numberOfContactsLastCampaign'].unique()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:04:55.819114Z","iopub.execute_input":"2021-07-20T05:04:55.819418Z","iopub.status.idle":"2021-07-20T05:04:55.832903Z","shell.execute_reply.started":"2021-07-20T05:04:55.819391Z","shell.execute_reply":"2021-07-20T05:04:55.831775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As can be seen above, for customers whose `daySinceLastCampaign` column is `Null`, the value of the `numberOfContactsLastCampaign` columns is **exclusively zero**. It means, these customers are customers to which we made no contact in the previous campaign. We can replace these `Null` values with a more meaningful numeric value such as `-1` that can be interpreted as \"**no contact in the previous campaign**\":","metadata":{}},{"cell_type":"code","source":"Data['daySinceLastCampaign'].fillna(-1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:04:55.836001Z","iopub.execute_input":"2021-07-20T05:04:55.836316Z","iopub.status.idle":"2021-07-20T05:04:55.841493Z","shell.execute_reply.started":"2021-07-20T05:04:55.836287Z","shell.execute_reply":"2021-07-20T05:04:55.84042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, evrything seems perfect:","metadata":{}},{"cell_type":"code","source":"missing_data = pd.DataFrame({'total_missing': Data.isnull().sum(),\n                             'perc_missing': (Data.isnull().sum()/len(Data))*100}).round(2)\nmissing_data","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:04:55.843982Z","iopub.execute_input":"2021-07-20T05:04:55.844254Z","iopub.status.idle":"2021-07-20T05:04:55.932718Z","shell.execute_reply.started":"2021-07-20T05:04:55.844228Z","shell.execute_reply":"2021-07-20T05:04:55.931672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Label balance check:\n\nAt this point, we need to check how is the distribution of our labels among the training data. It may have a big influence on the performance of our models as it will be discussed later. ","metadata":{}},{"cell_type":"code","source":"# Plotting the distribution of labels\nLabels = ['Campaign Success', 'Campaign Failure']\n\nsuccesses = len(Data[Data['target'] == 'yes'])\nfailures = len(Data[Data['target'] == 'no'])\n\ns_color = 'green' \nf_color = 'red'\n\nValues = [successes, failures]\n\nfig = px.pie(Data,\n             values=Values,\n             color_discrete_sequence=[f_color, s_color],\n             hover_name = Labels,\n             names = Labels,\n             title= 'Label distribution among the training data',\n             hole = 0.5\n            )\n\nfig.show()\n","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-07-20T05:04:55.934979Z","iopub.execute_input":"2021-07-20T05:04:55.935405Z","iopub.status.idle":"2021-07-20T05:04:56.20752Z","shell.execute_reply.started":"2021-07-20T05:04:55.935362Z","shell.execute_reply":"2021-07-20T05:04:56.206524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It seems there is an **imbalance** among the training data with respect to the target value. In other words, there are many observations of **No Events (Campaign Failures)** and only a few observations of **Yes Event (Campaign Successes')**. So, we should consider this imbalance in our models and approaches.","metadata":{}},{"cell_type":"markdown","source":"Now, we can check the mean value of each feature w.r.t. our labels to see the difference between two groups of customers in each feature:","metadata":{}},{"cell_type":"code","source":"# Grouping the data based on the 'target value' into 'positive' and 'negative' customers\n# and taking the maen value of nummerical features w.r.t. those groups\nnumericFeatures = ['day', \n                   'duration',\n                   'age',\n                   'accountBalance',\n                   'numberOfContacts',\n                   'daySinceLastCampaign',\n                   'numberOfContactsLastCampaign']\n\nnumericFeaturesPlusTarget = numericFeatures + ['target']\n\nData[numericFeaturesPlusTarget].groupby('target').mean()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:04:56.208821Z","iopub.execute_input":"2021-07-20T05:04:56.2091Z","iopub.status.idle":"2021-07-20T05:04:56.234482Z","shell.execute_reply.started":"2021-07-20T05:04:56.209074Z","shell.execute_reply":"2021-07-20T05:04:56.233616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So, we can see:\n\n1. The average call duration of positive customers (535.54) is longer than the average duration of negative customers (221.60).\n2. The average age of the positive customers (41.73) is slightly higher than the aveage age of negative ones (40.83).\n2. The average account balance of the positive customers (1807.03) is higher than the average account balance of the negative customers (1287.47).\n3. It is more likely to receive a positive answer when the time gap between the current and the previous campaign grows.\n4. We called positive customers more frequently in the last campaign.\n5. We called negative customers more frequently in the current campaign (possibly due to the aforementioned imbalance of the training data).\n","metadata":{}},{"cell_type":"markdown","source":"We can do this for other features, for example by grouping on `maritalStatus` and `gender`, we are able to observe the difference between customers w.r.t. that specific feature:","metadata":{}},{"cell_type":"code","source":"# checking customers' properties w.r.t. their marital status\nnumericFeaturesPlusMS = numericFeatures + ['maritalStatus']\nData[numericFeaturesPlusMS].groupby('maritalStatus').mean()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:04:56.235697Z","iopub.execute_input":"2021-07-20T05:04:56.235966Z","iopub.status.idle":"2021-07-20T05:04:56.257215Z","shell.execute_reply.started":"2021-07-20T05:04:56.235941Z","shell.execute_reply":"2021-07-20T05:04:56.256463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here, from the field `numberOfContactsLastCampaign`and its reported statistical values, we can conclude the majority of the previous campaign contacts were toward single customers, while the provided information of the `numberOfContacts` column show, in the current campaign, we mostly contact married customers.\n\nNext, let's see if there is a meaningfull correlation between **(`contactType`)** of the customers and their feedback to the campaign: ","metadata":{}},{"cell_type":"code","source":"cellphone = Data[Data['contactType'] == 'cellPhone']\nG0 = cellphone['target'].value_counts().sort_index().tolist()\n\nlandline = Data[Data['contactType'] == 'landline']\nG1 = landline['target'].value_counts().sort_index().tolist()\n\nGroups = sorted(Data['target'].unique().tolist())\n\nfig = go.Figure(data=[\n    go.Bar(name='cellphone', x= Groups, y=G0, marker_color='#1a8cff'),\n    go.Bar(name='landline' , x= Groups, y=G1, marker_color='#884dff')\n])\n\nfig.update_layout(\n    xaxis = dict(\n        tickmode = 'array',\n        tickvals = Groups,\n        ticktext = ['Campaign Failures', 'Campaign Successes']),\n        xaxis_title_text='target', # xaxis label\n        yaxis_title_text='Number of Contacts', # yaxis label\n        barmode='group' # change the barchart mode\n    )\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:04:56.258317Z","iopub.execute_input":"2021-07-20T05:04:56.258736Z","iopub.status.idle":"2021-07-20T05:04:56.306938Z","shell.execute_reply.started":"2021-07-20T05:04:56.258706Z","shell.execute_reply":"2021-07-20T05:04:56.306238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As you can see, **we contacted customers much more through their cellphones (blue bars) than calling their landline numbers (purple bars)**. So, to fairly answer the previous question, we need to extract the **success rate of each contact type** instead:","metadata":{}},{"cell_type":"code","source":"cellphone_successes  = len(cellphone[cellphone['target'] == 'yes'])\ncellphone_failures = len(cellphone[cellphone['target'] == 'no'])\n\nlandline_successes  = len(landline[landline['target'] == 'yes'])\nlandline_failures = len(landline[landline['target'] == 'no'])\n\nfig = make_subplots(rows=1,\n                    cols=2,\n                    specs=[[{'type':'domain'},{'type':'domain'}]],\n                    column_titles=['Campaign success and failure rates for each contact type'])\n\nfig.add_trace(\n    go.Pie(labels=['Campaign Success', 'Campaign Failure'], values=[cellphone_successes, cellphone_failures],\n           title='<b>cellphone</b>', hole=0.3, name = 'cellphone'), row=1, col=1)\nfig.update_traces(textfont_size=20, marker=dict(colors=['green', 'red']))\n\nfig.add_trace(\n    go.Pie(labels=['Campaign Success', 'Campaign Failure'], values=[landline_successes, landline_failures],\n           title='<b>landline</b>', hole=0.3, name = 'landline'), row=1, col=2)\nfig.update_traces(textfont_size=20,\n                  marker=dict(colors=['green', 'red']))\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:04:56.307914Z","iopub.execute_input":"2021-07-20T05:04:56.308341Z","iopub.status.idle":"2021-07-20T05:04:56.358338Z","shell.execute_reply.started":"2021-07-20T05:04:56.308311Z","shell.execute_reply":"2021-07-20T05:04:56.35763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So, as you can see, despite of our primary assumption based on previous diagram, the above charts illustrate there is no meaningfull difference between the success and failure rates of campaign with respect to the contact type.\n\nLet's see the influence of the customers' education on the campaign result:","metadata":{}},{"cell_type":"code","source":"se_successes  = len(Data[(Data['target'] == 'yes') & (Data['education'] == 'secondarySchool')])\nse_failures  = len(Data[(Data['target'] == 'no') & (Data['education'] == 'secondarySchool')])\n\nhigh_successes  = len(Data[(Data['target'] == 'yes') & (Data['education'] == 'highSchool')])\nhigh_failures  = len(Data[(Data['target'] == 'no') & (Data['education'] == 'highSchool')])\n\nuni_successes  = len(Data[(Data['target'] == 'yes') & (Data['education'] == 'uniGraduated')])\nuni_failures  = len(Data[(Data['target'] == 'no') & (Data['education'] == 'uniGraduated')])\n\nfig = make_subplots(rows=1,\n                    cols=3,\n                    specs=[[{'type':'domain'},{'type':'domain'}, {'type':'domain'}]],\n                    column_titles=['           Customer\\'s education influence on the campaign result'])\n\nfig.add_trace(\n    go.Pie(labels=['Campaign Success', 'Campaign Failure'], values=[se_successes, se_failures],\n           title='<b>secondary school</b>', hole=0.3, name = 'secondary school'), row=1, col=1)\n\n                                   \nfig.add_trace(\n    go.Pie(labels=['Campaign Success', 'Campaign Failure'], values=[high_successes, high_failures],\n           title='<b>highschool</b>', hole=0.3, name = 'high school'), row=1, col=2)\n\n\nfig.add_trace(\n    go.Pie(labels=['Campaign Success', 'Campaign Failure'], values=[uni_successes, uni_failures],\n           title='<b>uni graduate</b>', hole=0.3, name = 'uni graduated'), row=1, col=3)\nfig.update_traces(textfont_size=20,\n                  marker=dict(colors=['green', 'red']))\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:04:56.359478Z","iopub.execute_input":"2021-07-20T05:04:56.359848Z","iopub.status.idle":"2021-07-20T05:04:56.469313Z","shell.execute_reply.started":"2021-07-20T05:04:56.359814Z","shell.execute_reply":"2021-07-20T05:04:56.468263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we can see **the campaign success rate among the customers with university degrees is higher than other two groups**. So we may conclude the level of education has an influence on the campaign result.","metadata":{}},{"cell_type":"markdown","source":"Next, we investigate the influence of the time of the year on the campaign result:","metadata":{}},{"cell_type":"code","source":"feature = 'month'\n\ntemp= pd.crosstab(Data['month'],Data['target'])\ntemp['idx'] = [4, 8, 12, 2, 1, 7, 6, 3, 5, 11, 10, 9]\ntemp.sort_values(by=['idx'], inplace=True)\n\nmo_successes =  temp['yes'].values.tolist()\nmo_failures  =  temp['no'].values.tolist()\nmo_names     =  temp.index.tolist()\n\nfig = go.Figure(data=[\n    go.Bar(name='Success', x = mo_names, y = mo_successes, marker_color= 'green'),\n    go.Bar(name='Failure' , x = mo_names, y = mo_failures, marker_color= 'red')\n]\n               )\n\nfig.update_layout(\n    title = 'Campaign success/failure quantities during months of the year',\n    xaxis = dict(\n        tickmode = 'array',\n        tickvals = mo_names,\n        ticktext = mo_names),\n        xaxis_title_text='month', # xaxis label\n        yaxis_title_text='Number of contacts', # yaxis label\n        barmode='group' # change the barchart mode\n    )\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:04:56.470894Z","iopub.execute_input":"2021-07-20T05:04:56.471482Z","iopub.status.idle":"2021-07-20T05:04:56.516792Z","shell.execute_reply.started":"2021-07-20T05:04:56.471434Z","shell.execute_reply":"2021-07-20T05:04:56.516078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Looking at this bar chart, we can see the highest values belong to **may**, while the lowest values can be seen in **December**. Since, the contact distribution is not uniform along the year, again we should <u>normalize the result</u> for a fair comparison of the success rate in different months.","metadata":{}},{"cell_type":"code","source":"'''\nNormalizing formula:\nFor each month:\nyes = yes / (yes+no)\nno  = no  / (yes+no)\n'''\ntemp = temp.div(temp.sum(1).astype(float), axis=0)\n\nmo_successes =  temp['yes'].values.tolist()\nmo_failures  =  temp['no'].values.tolist()\n\nfig = go.Figure(data=[\n    go.Bar(name='Success', x = mo_names, y = mo_successes, marker_color= 'green'),\n    go.Bar(name='Failure' , x = mo_names, y = mo_failures, marker_color= 'red')\n]\n               )\n\nfig.update_layout(\n    title = 'Campaign success/failure normalized rates during months of the year',\n    xaxis = dict(\n        tickmode = 'array',\n        tickvals = mo_names,\n        ticktext = mo_names),\n        xaxis_title_text='month', # xaxis label\n        yaxis_title_text='Campaign success/failure rates', # yaxis label\n        barmode='group' # change the barchart mode\n    )\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:04:56.517795Z","iopub.execute_input":"2021-07-20T05:04:56.518199Z","iopub.status.idle":"2021-07-20T05:04:56.540263Z","shell.execute_reply.started":"2021-07-20T05:04:56.518171Z","shell.execute_reply":"2021-07-20T05:04:56.539467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, we have a completely different view on the success rate of months. Although **May** has the highest number of contacts, the success rate of **May** is the lowest one (**6.7 %**). On the other hand, for months in which we have the lowest number of contacts (e.g. **Mars**, **September**, **October** and **December**), the success rate is high.\n","metadata":{}},{"cell_type":"markdown","source":"Now, it is a good idea to see, how is the age distribution of the customers:","metadata":{}},{"cell_type":"code","source":"def plot_histogram(data, col, color, title, shade=False, shade_options=[]):\n    '''\n    This fuctions plot the histogram of the [col] feature of the [data] data frame in [color] color with the [title] title\n    '''    \n    fig = go.Figure()\n    fig.add_trace(go.Histogram(\n        x=data[col],\n        name=col,\n        xbins=dict(\n            start=data[col].min(),\n            end=data[col].max(),\n            size=1\n        ),\n\n        marker_color=color,\n        opacity=0.75,\n    ))\n\n    fig.update_layout(\n        title_text= title, # title of plot\n        xaxis_title_text=col, # xaxis label\n        yaxis_title_text='Quantity', # yaxis label\n        bargap=0.2, # gap between bars of adjacent location coordinates\n    )\n    \n    if shade:\n        fig.add_vrect(\n            x0=shade_options[0], x1=shade_options[1],\n            fillcolor=shade_options[2], opacity=0.5,\n            layer=\"below\", line_width=0,\n            )\n    fig.update_layout(xaxis_range=[data[col].min(),data[col].max()]) # to force all figures to have equal x-axis range\n    fig.show()\n    \nplot_histogram(Data, 'age', 'navy', 'Age Distribution of customers:', shade=True, shade_options=[30, 61, 'dimgray'])","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:04:56.541424Z","iopub.execute_input":"2021-07-20T05:04:56.54186Z","iopub.status.idle":"2021-07-20T05:04:56.588119Z","shell.execute_reply.started":"2021-07-20T05:04:56.541819Z","shell.execute_reply":"2021-07-20T05:04:56.586976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As illustrated, the age distribution has a *right (positive) skewed* shape that does not show a normal distribution. It is also clear that the <u>majority of customers are **30-60 years old**</u>. Let's take a look at a more accurate age distribution in which we can see its correlation with Campaign result as well:","metadata":{}},{"cell_type":"code","source":"import plotly.figure_factory as ff\n\nfeature = 'age'\nbinsize = 1\nrug = False\ncurve = True\n\nsuccesses = Data[Data['target'] == 'yes'][feature]\nfailures = Data[Data['target'] == 'no'][feature]\n\nhist_data = [successes, failures]\n\ngroup_labels = ['Success', 'Failure']\n\nfig = ff.create_distplot(hist_data,\n                         group_labels,\n                         bin_size=[binsize, binsize],\n                         colors=['green', 'red'],\n                         show_hist =True,\n                         curve_type='kde',\n                         show_curve=curve,\n                         show_rug = rug , \n                         rug_text=['Success', 'Failure']\n                        )\n\nfig.update_layout(  \n        xaxis_title_text = feature + ' Distribution',\n        yaxis_title_text = 'Probability density of the campaign success/failure rates',\n        title = 'Probability density of the campaign success/failure rates over the age of customers'\n    )\n\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:04:56.589882Z","iopub.execute_input":"2021-07-20T05:04:56.590304Z","iopub.status.idle":"2021-07-20T05:04:57.366146Z","shell.execute_reply.started":"2021-07-20T05:04:56.590258Z","shell.execute_reply":"2021-07-20T05:04:57.364873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As can be seen in the aboved diagram, changes in the probability density (KDE curves) of both success (green) and failure (red) rate have almost the same pattern for the customers with the age under 60 years. **By the way, the rate of success is higher than the failure rate for the customers with the age under 30 and higher than 60 years**. So, **it can be suggested to more concentrate on the customer younger than 30 years old or older than 60 years old to increase the success rate of the campaign**. ","metadata":{}},{"cell_type":"markdown","source":"## Adding the 'Day' attribute to the data:\n\nIn order to analyze the data in the shape of a time series, feature engineering is necessary to add a continuous time variable to the data. To this aim, two features of **day** and **month** are used to generate the new feature of **dayNum** which is the sequential number of the day in the year. For example, for August 13th, we should add the number of the days in all the previous months (212) to the date: 212+13 = 225. \n\nDoing so, we can use the **dayNum** feature to illustrate the campaign trend along the year:","metadata":{}},{"cell_type":"code","source":"# Acceptance/Rejection trends along the year\n\nData['dayNum'] = Data['day']\n\nmonths = ['feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec']\ndays   = [31, 59, 90, 120, 151, 181, 212, 243, 273, 304, 334]\n\nfor m, d in zip(months, days):\n    Data['dayNum'] = np.where(Data['month'] == m, Data['day'] +  d, Data['dayNum'] )","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-07-20T05:04:57.36777Z","iopub.execute_input":"2021-07-20T05:04:57.368086Z","iopub.status.idle":"2021-07-20T05:04:57.444713Z","shell.execute_reply.started":"2021-07-20T05:04:57.368051Z","shell.execute_reply":"2021-07-20T05:04:57.44367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature = 'dayNum'\nbinsize = 1\nrug = False\ncurve = True\n\nmonths = ['feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec']\ndays   = [31, 59, 90, 120, 151, 181, 212, 243, 273, 304, 334]\n\nx_tick_location = [1] + days + [365] \nx_tick_labels = [mon for mon in months]\nx_tick_labels = ['jan'] + x_tick_labels + ['']\n\nsuccesses = Data[Data['target'] == 'yes'][feature]\nfailures = Data[Data['target'] == 'no'][feature]\n\nhist_data = [successes, failures]\n\ngroup_labels = ['Success', 'Failure']\n\nfig = ff.create_distplot(hist_data,\n                         group_labels,\n                         bin_size=[binsize, binsize],\n                         colors=['green', 'red'],\n                         show_hist =True,\n                         curve_type='kde',\n                         show_curve=curve,\n                         show_rug = rug , \n                         rug_text=['Success', 'Failure']\n                        )\n\nfig.update_layout(\n        xaxis = dict(\n        tickmode = 'array',\n        tickvals = x_tick_location,\n        ticktext = x_tick_labels\n        )\n)\n\nfig.update_layout(\n        xaxis_title_text = 'time of the year',\n        yaxis_title_text = 'Probability density of the campaign success/failure rates',\n        title = 'Probability density of the campaign success/failure rates along the year'\n    )\n\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:04:57.44601Z","iopub.execute_input":"2021-07-20T05:04:57.446313Z","iopub.status.idle":"2021-07-20T05:04:57.939775Z","shell.execute_reply.started":"2021-07-20T05:04:57.446283Z","shell.execute_reply":"2021-07-20T05:04:57.938628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(successes)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:04:57.941102Z","iopub.execute_input":"2021-07-20T05:04:57.941513Z","iopub.status.idle":"2021-07-20T05:04:57.9482Z","shell.execute_reply.started":"2021-07-20T05:04:57.941466Z","shell.execute_reply":"2021-07-20T05:04:57.947525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As it can be seen, our time series does not have an obvious trend, while a weekly seasonality is visible in the form of the campaign stops on weekends that is more observable between weeks with the high number of contacts (e.g. August weeks). Again, it is also visible, when the number of contacts decreases, the campaign success rate (green curve) goes beyond the campaign failure rate (red curve) for example during March, April, September, October, and December. The possible reason behind such a behaviour could be that marketing agents are mainly concentrated on loyal customers during these months. \n\nIn addition, the number of campaign contacts increases significantly during February, May, June, July, August and the *Black Friday* week in November in which the campaign failure rate (red curve) surpasses the campaign success rate (green curve). As described earlier, this can be due to a change in marketing strategy (contacting new customers more than the loyal ones to attract more new customers) during those periods.   \n\nFor a better visualization of these insights, I divided the year into 4 quarters and showed the result for each quarter separately.","metadata":{}},{"cell_type":"markdown","source":"### Campaign Cumulative Flow Diagram(CFD)\n\nIn this part, the Cumulative Flow Diagram (CFD) of the both success and failure rates of the campaign is used as a valuable tool for tracking the performance of the campaign: ","metadata":{}},{"cell_type":"code","source":"# cumulative results of the campaign along the year\n\nmonths = ['feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec']\ndays   = [31, 59, 90, 120, 151, 181, 212, 243, 273, 304, 334]\n\nsuccesses = Data.loc[Data['target'] == 'yes'][['dayNum', 'target']]\ns_acc = successes.groupby('dayNum').count()\ns_acc['yes'] = s_acc['target'].cumsum()\ns_acc['dayN'] = s_acc.index\n\nfailures = Data.loc[Data['target'] == 'no'][['dayNum', 'target']]\nf_acc = failures.groupby('dayNum').count()\nf_acc['no'] = f_acc['target'].cumsum()\nf_acc['dayN'] = f_acc.index\n\nacc= pd.merge(f_acc, s_acc, how='inner', on='dayN')\n\nsuccesses = acc['yes'].fillna(0).astype('int16')\nfailures = acc['no'].fillna(0).astype('int16')\ndayNums = acc['dayN'].astype('int16')\n\nx_tick_location = [min(dayNums)] + days + [365] \nx_tick_labels = [mon for mon in months]\nx_tick_labels = ['jan'] + x_tick_labels + ['']\n\n\nhist_data = [successes, failures]\n\ngroup_labels = ['Success', 'Failure']\n\nfig = go.Figure(data=[\n    go.Line(name='Success', x= dayNums, y=successes, line=dict(color='green')),\n    go.Line(name='Failure', x= dayNums, y=failures, line=dict(color='red'))\n]\n               )\n\n\nfig.update_layout(\n        xaxis = dict(\n        #tickmode = 'array',\n        tickvals = x_tick_location,\n        ticktext = x_tick_labels\n        )\n)\n\nfig.update_layout(\n        xaxis_title_text = 'time of the year',\n        yaxis_title_text = 'campaign success/failure quantity',\n        title = 'Cumulative campaign success/failure rates along the year'\n    )\n\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:04:57.949323Z","iopub.execute_input":"2021-07-20T05:04:57.949778Z","iopub.status.idle":"2021-07-20T05:04:58.013106Z","shell.execute_reply.started":"2021-07-20T05:04:57.949733Z","shell.execute_reply":"2021-07-20T05:04:58.011986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, we can see the cumulative illustration of the campaign results along the year showing how fast the number of negative feedbacks grows in comparison with the positive answers. The number of negative results red line) is growing drastically at the high seasons of the campaign (e.g. during May, June and Black friday week of November), while its growth rate is constant when the campaign subsides (e.g. during March, April and October) . On the other hand, the growth speed of the positive feedbacks (the green line) is somehow gradual along the year.\n\nThe shape of this diagram is a measure of the campaign performance. The current situation shows a negative balance in the campaign result. The outcome of any successful attempt to change this situation should be visible in this diagram as the increase of the success quantity (green line) and the decrease of the failure quantity (red line) in the future.\n\n**It is worth mentioning that the negative balance of the campaign does not mean the campaign has a negative influence on the sale of the product. The positive feedbacks of the customers in the campaign will definitely increase the sell. But the most important thing about the campaign is the *expected outcome* that can be defined as the expected growth in selling the product which is unknown in the problem description.**\n\nIn the following steps, this information is provided for all the year quarters in more details separately:","metadata":{}},{"cell_type":"code","source":"Q_months = ['jan'] + months[0:2]\nQ_days = [min(dayNums)] + days[0:2]\nQuarter = Data.loc[Data['month'].isin(Q_months)]\n\nx_tick_location = Q_days \nx_tick_labels = [mon for mon in Q_months]\nx_tick_labels =  Q_months\n\nsuccesses = Data[(Data['target'] == 'yes') & ((Data['month'] == 'jan') |\n                                              (Data['month'] == 'feb') | \n                                              (Data['month'] == 'mar'))]['dayNum']\n\nfailures  = Data[(Data['target'] == 'no' ) & ((Data['month'] == 'jan') |\n                                              (Data['month'] == 'feb') | \n                                              (Data['month'] == 'mar'))]['dayNum']\n\nhist_data = [successes, failures]\n\ngroup_labels = ['Success', 'Failure']\n\nfig = ff.create_distplot(hist_data,\n                         group_labels,\n                         bin_size=[binsize, binsize],\n                         colors=['green', 'red'],\n                         show_hist =True,\n                         curve_type='kde',\n                         show_curve=curve,\n                         show_rug = rug , \n                         rug_text=['Success', 'Failure']\n                        )\n\nfig.update_layout(\n        xaxis = dict(\n        tickmode = 'array',\n        tickvals = x_tick_location,\n        ticktext = x_tick_labels\n        )\n)\n\nfig.update_layout(\n        xaxis_title_text = 'time of the year',\n        yaxis_title_text = 'Probability density of the campaign success/failure rates',\n        title = 'Probability density of the campaign success/failure rates during the first quarter of the year'\n    )\n\n\nfig.show()\n\n# cumulative results of the campaign along the first quarter of the year\n\nsuccesses = Data[(Data['target'] == 'yes') & ((Data['month'] == 'jan') |\n                                              (Data['month'] == 'feb') | \n                                              (Data['month'] == 'mar'))][['dayNum', 'target']]\n\ns_acc = successes.groupby('dayNum').count()\ns_acc['yes'] = s_acc['target'].cumsum()\ns_acc['dayN'] = s_acc.index\n\nfailures = Data[(Data['target'] == 'no')  & ((Data['month'] == 'jan') |\n                                             (Data['month'] == 'feb') | \n                                             (Data['month'] == 'mar'))][['dayNum', 'target']]\n\nf_acc = failures.groupby('dayNum').count()\nf_acc['no'] = f_acc['target'].cumsum()\nf_acc['dayN'] = f_acc.index\n\nacc= pd.merge(f_acc, s_acc, how='inner', on='dayN')\n\nsuccesses = acc['yes'].fillna(0).astype('int16')\nfailures = acc['no'].fillna(0).astype('int16')\ndayNums = acc['dayN'].astype('int16')\n\n\nhist_data = [successes, failures]\n\ngroup_labels = ['Success', 'Failure']\n\nfig = go.Figure(data=[\n    go.Line(name='Success', x= dayNums, y=successes, line=dict(color='green')),\n    go.Line(name='Failure', x= dayNums, y=failures, line=dict(color='red'))\n]\n               )\n\n\nfig.update_layout(\n        xaxis = dict(\n        #tickmode = 'array',\n        tickvals = x_tick_location,\n        ticktext = x_tick_labels\n        )\n)\n\nfig.update_layout(\n        xaxis_title_text = 'time of the year',\n        yaxis_title_text = 'campaign success/failure quantity',\n        title = 'Cumulative campaign success/failure rates during the first quarter of the year'\n    )\n\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:04:58.014458Z","iopub.execute_input":"2021-07-20T05:04:58.014811Z","iopub.status.idle":"2021-07-20T05:04:58.218907Z","shell.execute_reply.started":"2021-07-20T05:04:58.014778Z","shell.execute_reply":"2021-07-20T05:04:58.217869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In the first quarter of the year, the campaign has been started in the second week of January. The high season of the campaign in this quarter begins in the final week of January and lasts around 3 weeks. In other weeks of the quarter, the campaign activities subsides.\n\nThe cumulative diagram shows the balance of the campaign result was positive in first three weeks of January before the high season of the campaign. But this balance turned to negative when campaign activities grows. So, applying more efficient customer intelligent strategies during the campaign may improve the obtained result. ","metadata":{}},{"cell_type":"code","source":"Q_months = months[2:5]\nQ_days = days[2:5]\nQuarter = Data.loc[Data['month'].isin(Q_months)]\n\nx_tick_location = Q_days \nx_tick_labels = [mon for mon in Q_months]\nx_tick_labels =  Q_months\n\nsuccesses = Data[(Data['target'] == 'yes') & ((Data['month'] == 'apr') |\n                                              (Data['month'] == 'may') | \n                                              (Data['month'] == 'jun'))]['dayNum']\n\nfailures  = Data[(Data['target'] == 'no' ) & ((Data['month'] == 'apr') |\n                                              (Data['month'] == 'may') | \n                                              (Data['month'] == 'jun'))]['dayNum']\n\nhist_data = [successes, failures]\n\ngroup_labels = ['Success', 'Failure']\n\nfig = ff.create_distplot(hist_data,\n                         group_labels,\n                         bin_size=[binsize, binsize],\n                         colors=['green', 'red'],\n                         show_hist =True,\n                         curve_type='kde',\n                         show_curve=curve,\n                         show_rug = rug , \n                         rug_text=['Success', 'Failure']\n                        )\n\nfig.update_layout(\n        xaxis = dict(\n        tickmode = 'array',\n        tickvals = x_tick_location,\n        ticktext = x_tick_labels\n        )\n)\n\nfig.update_layout(\n        xaxis_title_text = 'time of the year',\n        yaxis_title_text = 'Probability density of the campaign success/failure rates',\n        title = 'Probability density of the campaign success/failure rates during the second quarter of the year'\n    )\n\n\nfig.show()\n\n# cumulative results of the campaign along the first quarter of the year\n\nsuccesses = Data[(Data['target'] == 'yes') & ((Data['month'] == 'apr') |\n                                              (Data['month'] == 'mai') | \n                                              (Data['month'] == 'jun'))][['dayNum', 'target']]\n\ns_acc = successes.groupby('dayNum').count()\ns_acc['yes'] = s_acc['target'].cumsum()\ns_acc['dayN'] = s_acc.index\n\nfailures = Data[(Data['target'] == 'no')  & ((Data['month'] == 'apr') |\n                                             (Data['month'] == 'mai') | \n                                             (Data['month'] == 'jun'))][['dayNum', 'target']]\n\nf_acc = failures.groupby('dayNum').count()\nf_acc['no'] = f_acc['target'].cumsum()\nf_acc['dayN'] = f_acc.index\n\nacc= pd.merge(f_acc, s_acc, how='inner', on='dayN')\n\nsuccesses = acc['yes'].fillna(0).astype('int16')\nfailures = acc['no'].fillna(0).astype('int16')\ndayNums = acc['dayN'].astype('int16')\n\n\nhist_data = [successes, failures]\n\ngroup_labels = ['Success', 'Failure']\n\nfig = go.Figure(data=[\n    go.Line(name='Success', x= dayNums, y=successes, line=dict(color='green')),\n    go.Line(name='Failure', x= dayNums, y=failures, line=dict(color='red'))\n]\n               )\n\n\nfig.update_layout(\n        xaxis = dict(\n        #tickmode = 'array',\n        tickvals = x_tick_location,\n        ticktext = x_tick_labels\n        )\n)\n\nfig.update_layout(\n        xaxis_title_text = 'time of the year',\n        yaxis_title_text = 'campaign success/failure quantity',\n        title = 'Cumulative campaign success/failure rates during the second quarter of the year'\n    )\n\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:04:58.220611Z","iopub.execute_input":"2021-07-20T05:04:58.221019Z","iopub.status.idle":"2021-07-20T05:04:58.633995Z","shell.execute_reply.started":"2021-07-20T05:04:58.220977Z","shell.execute_reply":"2021-07-20T05:04:58.633054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The high season of the campaign along the second quarter of the year is in May which is the peak of the year as well. As it discussed earlier, although this month has the highest number of contacts, its success rate barely grows and has the lowest value which reveals the poor performance of the campaign in \n\n1. selecting the target customers properly \n\n**AND/OR**\n\n2. effective execution of business intelligence strategies","metadata":{}},{"cell_type":"code","source":"Q_months = months[5:8]\nQ_days = days[5:8]\nQuarter = Data.loc[Data['month'].isin(Q_months)]\n\nx_tick_location = Q_days \nx_tick_labels = [mon for mon in Q_months]\nx_tick_labels =  Q_months\n\nsuccesses = Data[(Data['target'] == 'yes') & ((Data['month'] == 'jul') |\n                                              (Data['month'] == 'aug') | \n                                              (Data['month'] == 'sep'))]['dayNum']\n\nfailures  = Data[(Data['target'] == 'no' ) & ((Data['month'] == 'jul') |\n                                              (Data['month'] == 'aug') | \n                                              (Data['month'] == 'sep'))]['dayNum']\n\nhist_data = [successes, failures]\n\ngroup_labels = ['Success', 'Failure']\n\nfig = ff.create_distplot(hist_data,\n                         group_labels,\n                         bin_size=[binsize, binsize],\n                         colors=['green', 'red'],\n                         show_hist =True,\n                         curve_type='kde',\n                         show_curve=curve,\n                         show_rug = rug , \n                         rug_text=['Success', 'Failure']\n                        )\n\nfig.update_layout(\n        xaxis = dict(\n        tickmode = 'array',\n        tickvals = x_tick_location,\n        ticktext = x_tick_labels\n        )\n)\n\nfig.update_layout(\n        xaxis_title_text = 'time of the year',\n        yaxis_title_text = 'Probability density of the campaign success/failure rates',\n        title = 'Probability density of the campaign success/failure rates during the third quarter of the year'\n    )\n\n\nfig.show()\n\n# cumulative results of the campaign along the first quarter of the year\n\nsuccesses = Data[(Data['target'] == 'yes') & ((Data['month'] == 'jul') |\n                                              (Data['month'] == 'aug') | \n                                              (Data['month'] == 'sep'))][['dayNum', 'target']]\n\ns_acc = successes.groupby('dayNum').count()\ns_acc['yes'] = s_acc['target'].cumsum()\ns_acc['dayN'] = s_acc.index\n\nfailures = Data[(Data['target'] == 'no')  & ((Data['month'] == 'jul') |\n                                             (Data['month'] == 'aug') | \n                                             (Data['month'] == 'sep'))][['dayNum', 'target']]\n\nf_acc = failures.groupby('dayNum').count()\nf_acc['no'] = f_acc['target'].cumsum()\nf_acc['dayN'] = f_acc.index\n\nacc= pd.merge(f_acc, s_acc, how='inner', on='dayN')\n\nsuccesses = acc['yes'].fillna(0).astype('int16')\nfailures = acc['no'].fillna(0).astype('int16')\ndayNums = acc['dayN'].astype('int16')\n\n\nhist_data = [successes, failures]\n\ngroup_labels = ['Success', 'Failure']\n\nfig = go.Figure(data=[\n    go.Line(name='Success', x= dayNums, y=successes, line=dict(color='green')),\n    go.Line(name='Failure', x= dayNums, y=failures, line=dict(color='red'))\n]\n               )\n\n\nfig.update_layout(\n        xaxis = dict(\n        #tickmode = 'array',\n        tickvals = x_tick_location,\n        ticktext = x_tick_labels\n        )\n)\n\nfig.update_layout(\n        xaxis_title_text = 'time of the year',\n        yaxis_title_text = 'campaign success/failure quantity',\n        title = 'Cumulative campaign success/failure rates during the third quarter of the year'\n    )\n\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:04:58.635476Z","iopub.execute_input":"2021-07-20T05:04:58.636057Z","iopub.status.idle":"2021-07-20T05:04:58.914818Z","shell.execute_reply.started":"2021-07-20T05:04:58.636015Z","shell.execute_reply":"2021-07-20T05:04:58.91356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Again, during the third quarter of the year, whenever we have an increase in the number of contacts, the success rate of the campaign falls below the failure rate, although both success and failure rates are increased but as can be seen in the cumulative diagram, the growth of the campaign failure rate (red line slope) is higher than the growth of the campaign success rate (green line slope).","metadata":{}},{"cell_type":"code","source":"Q_months = months[8:11]\nQ_days = days[8:11]\nQuarter = Data.loc[Data['month'].isin(Q_months)]\n\nx_tick_location = Q_days \nx_tick_labels = [mon for mon in Q_months]\nx_tick_labels =  Q_months\n\nsuccesses = Data[(Data['target'] == 'yes') & ((Data['month'] == 'oct') |\n                                              (Data['month'] == 'nov') | \n                                              (Data['month'] == 'dec'))]['dayNum']\n\nfailures  = Data[(Data['target'] == 'no' ) & ((Data['month'] == 'oct') |\n                                              (Data['month'] == 'nov') | \n                                              (Data['month'] == 'dec'))]['dayNum']\n\nhist_data = [successes, failures]\n\ngroup_labels = ['Success', 'Failure']\n\nfig = ff.create_distplot(hist_data,\n                         group_labels,\n                         bin_size=[binsize, binsize],\n                         colors=['green', 'red'],\n                         show_hist =True,\n                         curve_type='kde',\n                         show_curve=curve,\n                         show_rug = rug , \n                         rug_text=['Success', 'Failure']\n                        )\n\nfig.update_layout(\n        xaxis = dict(\n        tickmode = 'array',\n        tickvals = x_tick_location,\n        ticktext = x_tick_labels\n        )\n)\n\nfig.update_layout(\n        xaxis_title_text = 'time of the year',\n        yaxis_title_text = 'Probability density of the campaign success/failure rates',\n        title = 'Probability density of the campaign success/failure rates during the last quarter of the year'\n    )\n\n\nfig.show()\n\n# cumulative results of the campaign along the first quarter of the year\n\nsuccesses = Data[(Data['target'] == 'yes') & ((Data['month'] == 'oct') |\n                                              (Data['month'] == 'nov') | \n                                              (Data['month'] == 'dec'))][['dayNum', 'target']]\n\ns_acc = successes.groupby('dayNum').count()\ns_acc['yes'] = s_acc['target'].cumsum()\ns_acc['dayN'] = s_acc.index\n\nfailures = Data[(Data['target'] == 'no')  & ((Data['month'] == 'oct') |\n                                             (Data['month'] == 'nov') | \n                                             (Data['month'] == 'dec'))][['dayNum', 'target']]\n\nf_acc = failures.groupby('dayNum').count()\nf_acc['no'] = f_acc['target'].cumsum()\nf_acc['dayN'] = f_acc.index\n\nacc= pd.merge(f_acc, s_acc, how='inner', on='dayN')\n\nsuccesses = acc['yes'].fillna(0).astype('int16')\nfailures = acc['no'].fillna(0).astype('int16')\ndayNums = acc['dayN'].astype('int16')\n\n\nhist_data = [successes, failures]\n\ngroup_labels = ['Success', 'Failure']\n\nfig = go.Figure(data=[\n    go.Line(name='Success', x= dayNums, y=successes, line=dict(color='green')),\n    go.Line(name='Failure', x= dayNums, y=failures, line=dict(color='red'))\n]\n               )\n\n\nfig.update_layout(\n        xaxis = dict(\n        #tickmode = 'array',\n        tickvals = x_tick_location,\n        ticktext = x_tick_labels\n        )\n)\n\nfig.update_layout(\n        xaxis_title_text = 'time of the year',\n        yaxis_title_text = 'campaign success/failure quantity',\n        title = 'Cumulative campaign success/failure rates during the last quarter of the year'\n    )\n\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:04:58.920505Z","iopub.execute_input":"2021-07-20T05:04:58.920843Z","iopub.status.idle":"2021-07-20T05:04:59.127716Z","shell.execute_reply.started":"2021-07-20T05:04:58.920811Z","shell.execute_reply":"2021-07-20T05:04:59.126877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Surprisingly, during the last quarter of the year, the campaign activities reduced intensively with the exception of the third week in November (Black Friday week).  ","metadata":{}},{"cell_type":"markdown","source":"### Grouping customers based on their feedback to the last two campaigns for further analysis and comparisons:\n\nIn the original training data, there is some information about the feedback of the current customers to the last campaign as well. Combination of this information with the result of the current campaign gives us this opportunity to **know our customers at a granular level based on their mind direction** in the following groups:\n\n1. **Super Positive Customers**: are the customers who accepted both previous and the current campaigns.\n\n2. **New Positive Customers**: are the customers who did not participate in the previous campaign and accepted the current campaigns.\n\n3. **Negative to Positive Customers**: are the customers who refused the previous campaign but turned to positive answer in the current campaigns.\n\n\n\n4. **Positive to Negative Customers**: are the customers who accepted the previous campaign but turned to negative answer in the current campaigns.\n\n5. **New Negative Customers**: are the customers who did not participate in the previous campaign and refused the current campaigns.\n\n6. **Super Negative Customers**: are the customers who refused both previous and the current campaigns.\n\n\n7. **Unknown Customers**: Any other customers.","metadata":{}},{"cell_type":"code","source":"# Grouping the customers based on thier feedbacks to the previous and the current campaigns (thier mind direction)\nData['group'] = 'Unknown'\n\nData.group[(Data['target'] == 'yes') & (Data['lastCampaignResult'] == 'success')] = 'Super Positive'\nData.group[(Data['target'] == 'yes') & (Data['lastCampaignResult'] == 'unknown')] = 'New Positive'\nData.group[(Data['target'] == 'yes') & (Data['lastCampaignResult'] == 'failure')] = 'Negative to Positive'\nData.group[(Data['target'] == 'no')  & (Data['lastCampaignResult'] == 'success')] = 'Positive to Negative'\nData.group[(Data['target'] == 'no')  & (Data['lastCampaignResult'] == 'unknown')] = 'New Negative'\nData.group[(Data['target'] == 'no')  & (Data['lastCampaignResult'] == 'failure')] = 'Super Negative'","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:04:59.131278Z","iopub.execute_input":"2021-07-20T05:04:59.131601Z","iopub.status.idle":"2021-07-20T05:04:59.218522Z","shell.execute_reply.started":"2021-07-20T05:04:59.131542Z","shell.execute_reply":"2021-07-20T05:04:59.217774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Comparison of the groups quantities\nfig, ax = plt.subplots(figsize=(9,7))\n\norder = ['Super Positive', 'New Positive', 'Negative to Positive', 'Unknown',\n         'Positive to Negative', 'New Negative', 'Super Negative']\n\nsns.set_context(rc = {'patch.linewidth': 0.1})\nsns.countplot(y='group', data=Data, palette=sns.color_palette(\"RdBu_r\", 7), order=order, linewidth=1, edgecolor='k')\n\nplt.title('Customer Type Distribution')\nplt.ylabel('')\nplt.xlabel('Quantity')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:04:59.22079Z","iopub.execute_input":"2021-07-20T05:04:59.221212Z","iopub.status.idle":"2021-07-20T05:04:59.470611Z","shell.execute_reply.started":"2021-07-20T05:04:59.221167Z","shell.execute_reply":"2021-07-20T05:04:59.469671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here, we can see the biggest category of the customers is the **New Negative group** followed by **Super Negatives** and **New Positives**.\n\nNow we can explore other features whithin provided customer groups:\n\nFor example, let us see how the account balance varies within different groups:","metadata":{}},{"cell_type":"code","source":"# Variation of account balance in different groups\ntemp = Data.groupby('group', as_index=False)['accountBalance'].mean()\nfig, ax = plt.subplots(figsize=(9,7))\nsns.set_context(rc = {'patch.linewidth': 0.1})\nsns.barplot(y='group', x='accountBalance', data=temp, palette=sns.color_palette(\"RdBu_r\", 7), order=order, linewidth=1, edgecolor='k')\n\nplt.title('Average account balance for different types of customers')\nplt.ylabel('')\nplt.xlabel('Account balance ()')\nplt.xlim(1200,2100)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:04:59.4719Z","iopub.execute_input":"2021-07-20T05:04:59.472198Z","iopub.status.idle":"2021-07-20T05:04:59.917425Z","shell.execute_reply.started":"2021-07-20T05:04:59.472169Z","shell.execute_reply":"2021-07-20T05:04:59.916394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"OK, it can be seen the positive customers have a higher account balance than the negative clients.\n\nLets see what is their difference in age:","metadata":{}},{"cell_type":"code","source":"# Age variation in different groups\ntemp = Data.groupby('group', as_index=False)['age'].mean()\nfig, ax = plt.subplots(figsize=(9,7))\nsns.set_context(rc = {'patch.linewidth': 0.1})\nsns.barplot(y='group', x='age', data=temp, palette=sns.color_palette(\"RdBu_r\", 7), order=order, linewidth=1, edgecolor='k')\n\nplt.title('Average age of different types of customers')\nplt.ylabel('')\nplt.xlabel('Average age')\nplt.xlim(39,45)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:04:59.918532Z","iopub.execute_input":"2021-07-20T05:04:59.918874Z","iopub.status.idle":"2021-07-20T05:05:00.165355Z","shell.execute_reply.started":"2021-07-20T05:04:59.918844Z","shell.execute_reply":"2021-07-20T05:05:00.16436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The diagram shows positive clients are in average older than the negative customers.\n\nSo, the combination of our insights from last two diagrams may lead to this conclusion that **our best customers are not so young and their account status is better than the others**.","metadata":{}},{"cell_type":"markdown","source":"### Discovering who are these lovely super positive customers:\n\nI this step, we can focus on **Super Positive Customers** to see what are their characteristics and if required make a comparion with the other groups w.r.t. that feature:\n\nAs an example, we can check job distribution in Super Positive Customers and compare it with Super Negative group:","metadata":{}},{"cell_type":"code","source":"# Comparion of two groups based on their job\ntemp = Data[(Data['group'] == 'Super Positive') | (Data['group'] == 'Super Negative')]\npd.crosstab(temp['job'],temp.group).plot(kind='barh', figsize=(12,7), color=['r', 'b'])\nplt.title('occupation distribution comparison between Super Positive/Negative Customers')\nplt.xlabel('Quantity')\nplt.ylabel('');","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:05:00.166773Z","iopub.execute_input":"2021-07-20T05:05:00.167056Z","iopub.status.idle":"2021-07-20T05:05:00.607899Z","shell.execute_reply.started":"2021-07-20T05:05:00.167029Z","shell.execute_reply":"2021-07-20T05:05:00.606907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we can see, the **<span style=\"color:green\">'manager'</span>** is the top ranked occupation of **Super Positive Customers**, while  the **<span style=\"color:red\">'worker'</span>** is the top ranked occupation of **Super Negative clients**.\n\nWe can also compare these two group based on the levels of education:","metadata":{}},{"cell_type":"code","source":"# Comparion of two groups based on their educational level\n# Comparion of two groups based on their job\ntemp = Data[(Data['group'] == 'Super Positive') | (Data['group'] == 'Super Negative')]\npd.crosstab(temp['education'],temp.group).plot(kind='barh', figsize=(12,7), color=['r', 'b'])\nplt.title('Educational level comparison between Super Positive/Negative Customers')\nplt.xlabel('Quantity')\nplt.ylabel('');","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:05:00.609099Z","iopub.execute_input":"2021-07-20T05:05:00.609378Z","iopub.status.idle":"2021-07-20T05:05:00.944742Z","shell.execute_reply.started":"2021-07-20T05:05:00.609352Z","shell.execute_reply":"2021-07-20T05:05:00.943679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Some textual information about educational levels in Super positive/negative customers\nsumP = len(Data.loc[Data['group'] == 'Super Positive', :])\nhighSchoolP = len(Data.loc[(Data['group'] == 'Super Positive') & (Data['education'] == 'highSchool'), :])\nsumN = len(Data.loc[Data['group'] == 'Super Negative', :])\nhighSchoolN = len(Data.loc[(Data['group'] == 'Super Negative') & (Data['education'] == 'highSchool'), :])\n\nprint('Percentage of Super positive customers with high school degree: {:.2f}%'.format(highSchoolP/(sumP)*100))\nprint('Percentage of Super Negative customers with high school degree: {:.2f}%\\n'.format(highSchoolN/(sumN)*100))\n\n\nuniP = len(Data.loc[(Data['group'] == 'Super Positive') & (Data['education'] == 'uniGraduated'), :])\nuniN = len(Data.loc[(Data['group'] == 'Super Negative') & (Data['education'] == 'uniGraduated'), :])\n\nprint('Percentage of Super positive customers with a kind of university degree: {:.2f}%'.format(uniP/(sumP)*100))\nprint('Percentage of Super Negative customers with a kind of university degree: {:.2f}%'.format(uniN/(sumN)*100))","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:05:00.945929Z","iopub.execute_input":"2021-07-20T05:05:00.9462Z","iopub.status.idle":"2021-07-20T05:05:01.014985Z","shell.execute_reply.started":"2021-07-20T05:05:00.946174Z","shell.execute_reply":"2021-07-20T05:05:01.014221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As it can be seen, while the majority (54.15 %) of **Super Negative clients** have the **high school** certificate, a higher number of **Super Positive Customers** have an academic certificate (41.72 % in Super Positive customers versus 28.91% in Super Negative clients).","metadata":{}},{"cell_type":"code","source":"# Dropping the columns that we add to the data for visualization purposes.\n# The information provided in these columns are extracted from the original columns so dropping them is not harmful\nData.drop(['dayNum'], axis = 1, inplace = True)\nData.drop(['group'], axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:05:01.016145Z","iopub.execute_input":"2021-07-20T05:05:01.016646Z","iopub.status.idle":"2021-07-20T05:05:01.034268Z","shell.execute_reply.started":"2021-07-20T05:05:01.016614Z","shell.execute_reply":"2021-07-20T05:05:01.032976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Preprocessing:\n\nAs one the objectives of the project is to define, train and evaluate some predictive models on the data and most of those models are just able to understand and work with *numerical values*, in this step we convert our categorical fields with '**object**' data type into most proper numerical values. In the following steps we'll perform such a conversion:","metadata":{}},{"cell_type":"markdown","source":"### Conversion of `target` feature into numerical representation of binary values {0,1}\n\nSince we would like to plot the relationship between our target value and some other features, we need to convert target values into numerical representation of binary labels:\n\n**target**:\n\nno $\\Longrightarrow$ 0\n\nyes $\\Longrightarrow$ 1","metadata":{}},{"cell_type":"code","source":"target_conversion = {\"target\": {\"no\": 0, \"yes\": 1}}\nData.replace(target_conversion, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:05:01.035672Z","iopub.execute_input":"2021-07-20T05:05:01.035957Z","iopub.status.idle":"2021-07-20T05:05:01.065507Z","shell.execute_reply.started":"2021-07-20T05:05:01.035931Z","shell.execute_reply":"2021-07-20T05:05:01.064465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### one-hot-encoding of the field `month`:\n---\n\nA possible approach to convert the data type of the field `month` from categorial to numercal data type is to use **naive variable encoding** technique as follows: \n\n**month**:\n\njan $\\Longrightarrow$ 1\n\nfeb $\\Longrightarrow$ 2\n\nmar $\\Longrightarrow$ 3\n\napr $\\Longrightarrow$ 4\n\nmay $\\Longrightarrow$ 5\n\njun $\\Longrightarrow$ 6\n\njul $\\Longrightarrow$ 7\n\naug $\\Longrightarrow$ 8\n\nsep $\\Longrightarrow$ 9\n\noct $\\Longrightarrow$ 10\n\nnov $\\Longrightarrow$ 11\n\ndec $\\Longrightarrow$ 12\n\nBut this may lead to misinterpretation of those values by machine learning models such that the model would think that for example the category of apr is greater than jan that obviously has no sense.\n\nTo prevent such a misinterpretation, we use **one hot encoding** to convert `month` values into numerical ones:","metadata":{}},{"cell_type":"code","source":"### month one-hot Encoding ###\n\n# Get one hot encoding of columns 'month'\nmonth_one_hot = pd.get_dummies(Data.month)\n# Drop column 'month' as it is now encoded\nData.drop('month',axis = 1, inplace=True)\n# Join the encoded month fields\nData = Data.join(month_one_hot)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:05:01.066763Z","iopub.execute_input":"2021-07-20T05:05:01.067042Z","iopub.status.idle":"2021-07-20T05:05:01.087929Z","shell.execute_reply.started":"2021-07-20T05:05:01.067015Z","shell.execute_reply":"2021-07-20T05:05:01.086839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The same can be done with `job`, `maritalStatus` and `education` fields: ","metadata":{}},{"cell_type":"code","source":"###  one-hot encoding of the fields:\n### 'job', 'maritalStatus', 'education', 'contactType' & 'lastCampaignResult'\n\n# make a difference between 'job_unknown', 'education_unknown' and 'contactType_unknown'\nData.loc[Data['job'] == 'unknown', 'job'] = 'job_unknown'\nData.loc[Data['education'] == 'unknown', 'education'] = 'education_unknown'\nData.loc[Data['contactType'] == 'unknown', 'contactType'] = 'contactType_unknown'\n\n# for more clarification of values in 'lastCampaignResult' field we change them as follows\nData.loc[Data['lastCampaignResult'] == 'unknown', 'lastCampaignResult'] = 'lastCampaignResult_unknown'\nData.loc[Data['lastCampaignResult'] == 'failure', 'lastCampaignResult'] = 'lastCampaignResult_failure'\nData.loc[Data['lastCampaignResult'] == 'other'  , 'lastCampaignResult'] = 'lastCampaignResult_other'\nData.loc[Data['lastCampaignResult'] == 'success', 'lastCampaignResult'] = 'lastCampaignResult_success'\n\n\ncolumns = ['job', 'maritalStatus', 'education', 'contactType', 'lastCampaignResult']\n\nfor col in columns: \n    # Get one hot encoding of the column\n    col_one_hot = pd.get_dummies(Data[col])\n    # Drop column as it is now encoded\n    Data.drop(col,axis = 1, inplace=True)\n    # Join the encoded Monat fields\n    Data = Data.join(col_one_hot)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:05:01.089281Z","iopub.execute_input":"2021-07-20T05:05:01.089654Z","iopub.status.idle":"2021-07-20T05:05:01.234638Z","shell.execute_reply.started":"2021-07-20T05:05:01.089621Z","shell.execute_reply":"2021-07-20T05:05:01.233857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Variable Encoding of the fields 'gender', 'creditFailure', 'credit', 'house' as we did for 'target' before\n\nGeschlecht_conversion = {\"gender\": {\"female\": 0, \"male\": 1}} \nData.replace(Geschlecht_conversion, inplace=True)\n\ncolumns = ['creditFailure', 'credit', 'house']\n\nfor col in columns: \n    conversion = {col: {\"no\": 0, \"yes\": 1}} \n    Data.replace(conversion, inplace=True)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-07-20T05:05:01.235876Z","iopub.execute_input":"2021-07-20T05:05:01.236458Z","iopub.status.idle":"2021-07-20T05:05:01.342101Z","shell.execute_reply.started":"2021-07-20T05:05:01.236398Z","shell.execute_reply":"2021-07-20T05:05:01.340638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Selection and Feature Engineering:\n\nThis step often has the highest returns on time invested in a machine learning problem. It can take quite a while to get right, but is often more important than the exact algorithm and hyperparameters used for the model. If we don't feed the model the correct data, then we are setting it up to fail and we should not expect it to learn. \n\n1. **Feature Selection**: is the process of choosing the most relevant features in the data. \"Most relevant\" can depend on many factors, but it might be something as simple as the highest correlation with the target, or the features with the most variance. In feature selection, we remove features that do not help our model to learn the relationship between features and the target. This can help the model generalize better to new data and results in a more interpretable model. Generally, the feature selection is the process of __subtracting__ less important features.\n\n\n2. **Feature Engineering**: is defined as the process of taking raw data and extracting or creating new features that allow a machine learning model to learn a mapping between these features and the target. This means taking transformations of variables, such as we did with the one-hot encoding categorical variables so they can be used in a model. Generally, one may think of the feature engineering as __adding__ additional features derived from the raw data.","metadata":{}},{"cell_type":"markdown","source":"### Feature Selection","metadata":{}},{"cell_type":"markdown","source":"`id` and `contactId` fields have unique or near unique values and as we know due to high variance of its values, such an information does not help any model to make a reliable prediction. So we can remove them from our training data.","metadata":{}},{"cell_type":"code","source":"Data.drop(['id'], axis = 1, inplace = True)\nData.drop(['contactId'], axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:05:01.343549Z","iopub.execute_input":"2021-07-20T05:05:01.343891Z","iopub.status.idle":"2021-07-20T05:05:01.358248Z","shell.execute_reply.started":"2021-07-20T05:05:01.343861Z","shell.execute_reply":"2021-07-20T05:05:01.35676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Removing Multi-colinearities:\n\nCorrelated features in general don't improve models (although it depends on the specifics of the problem like the number of variables and the degree of correlation), but they affect specific models in different ways and to varying extents:\n\n* For linear models (e.g., linear regression or logistic regression), multicolinearity can yield solutions that are wildly varying and possibly numerically unstable.\n\n* Random forests can be good at detecting interactions between different features, but highly correlated features can mask these interactions.\n\nMore generally, a simpler model is preferable, and, in some sense, a model with fewer features is simpler.","metadata":{}},{"cell_type":"markdown","source":"### Collineararity Ellimination\n\nWhile variables in a dataset are usually correlated to a small degree, highly collinear variables can be redundant in the sense that we only need to retain one of the features to give our model the necessary information.\n\nRemoving collinear features is a method to reduce model complexity by decreasing the number of features and can help to increase model generalization. It can also help us to interpret the model because we only have to worry about less variables.\n\nThere are a number of methods for removing collinear features, such as using the [Variance Inflation Factor](http://www.statisticshowto.com/variance-inflation-factor/). We will use a simple metric, and remove features that have a correlation coefficient above a certain threshold (in our case 0.5) with each other (not with the target variable because we want variables that are highly correlated with the target variable)\n\nThe following function prints out all the collinear features based on a threshold we select for the correlation coefficients.","metadata":{}},{"cell_type":"code","source":"def show_collinear_features(x, threshold):\n    '''\n    Objective:\n        Remove collinear features in a dataframe with a correlation coefficient\n        greater than the threshold. Removing collinear features can help a model\n        to generalize and improves the interpretability of the model.\n        \n    Inputs: \n        threshold: any features with correlations greater than this value are removed\n    \n    Output: \n        dataframe that contains only the non-highly-collinear features\n    '''\n    \n    # Dont want to remove correlations that are realted to the target variable\n    x = x.drop(columns = ['target'])\n    \n    # Calculate the correlation matrix\n    corr_matrix = x.corr()\n    iters = range(len(corr_matrix.columns) - 1)\n    drop_cols = []\n\n    # Iterate through the correlation matrix and compare correlations\n    for i in iters:\n        for j in range(i):\n            item = corr_matrix.iloc[j:(j+1), (i+1):(i+2)]\n            col = item.columns\n            row = item.index\n            val = abs(item.values)\n            \n            # If correlation exceeds the threshold\n            if val >= threshold:\n                # Print the correlated features and the correlation value\n                print(col.values[0], \"|\", row.values[0], \"|\", round(val[0][0], 2))\n                drop_cols.append(col.values[0])\n               \n    return 0","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:05:01.360143Z","iopub.execute_input":"2021-07-20T05:05:01.360546Z","iopub.status.idle":"2021-07-20T05:05:01.37185Z","shell.execute_reply.started":"2021-07-20T05:05:01.360502Z","shell.execute_reply":"2021-07-20T05:05:01.370581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_collinear_features(Data, 0.5);","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:05:01.373977Z","iopub.execute_input":"2021-07-20T05:05:01.37454Z","iopub.status.idle":"2021-07-20T05:05:01.721402Z","shell.execute_reply.started":"2021-07-20T05:05:01.374389Z","shell.execute_reply":"2021-07-20T05:05:01.7205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Based on what we see here, `uniGraduated` field has strong correlations with `manager` and `highSchool` features. That sounds reasonable because it is very likely that managers are high-educated (positive correlation) and customers who are high-educated can not be `highSchool` graduated (negative correlation).\n\nSo, we may remove `uniGraduated` feature, since it seems it duplicates the information that we have in other features.\n\nIn addition, `lastCampaignResult_unknown` feature is in a high correlation with three other features. So, we can remove it as well.","metadata":{}},{"cell_type":"code","source":"Data.drop(['uniGraduated'], axis = 1, inplace = True)\nData.drop(['lastCampaignResult_unknown'], axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:05:01.7226Z","iopub.execute_input":"2021-07-20T05:05:01.722873Z","iopub.status.idle":"2021-07-20T05:05:01.731691Z","shell.execute_reply.started":"2021-07-20T05:05:01.722846Z","shell.execute_reply":"2021-07-20T05:05:01.730735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Correlation Discovery:\n\nNow that our training data is ready for more numerical analysis, we can take a look at the **corrlation strength** between all the features and the target value:","metadata":{}},{"cell_type":"code","source":"Data.corr()['target'][1:].sort_values(ascending=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:05:01.732924Z","iopub.execute_input":"2021-07-20T05:05:01.73331Z","iopub.status.idle":"2021-07-20T05:05:01.949131Z","shell.execute_reply.started":"2021-07-20T05:05:01.733273Z","shell.execute_reply":"2021-07-20T05:05:01.948256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It is more interesting to plot those values in a bar chart:","metadata":{}},{"cell_type":"code","source":"fig = Data.corr()['target'][1:].sort_values(ascending=True).plot(kind='barh', figsize = (15,20))\nfig.set(xlabel='Correlation with the target feature', ylabel='');","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:05:01.950711Z","iopub.execute_input":"2021-07-20T05:05:01.951146Z","iopub.status.idle":"2021-07-20T05:05:02.94724Z","shell.execute_reply.started":"2021-07-20T05:05:01.951102Z","shell.execute_reply":"2021-07-20T05:05:02.946096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The following insights can be understood from our correlation bar chart:\n\n1. The <span style=\"color:green\">**call duration (duration)**</span> has a positive influence on response of the customer to the campaign. The longer we talk to the customer, the higher the possibility of his/her positive feedback to the campaign.\n\n2. <span style=\"color:green\">**lastCampaignResult_success**</span> has an strong correlation with the target. So, the likelihood of the campaign success is more for the customers who have <span style=\"color:green\">**accepted the previous campaign**</span>, too (remeber those lovely super positive clients?).\n\n3. Concering the correlation of the contact type, <span style=\"color:black\">**cellPhone>landline>unknown**</span>. It's a good idea, to call the customers on their <span style=\"color:green\">**cell phone**</span> rather than a <span style=\"color:red\">**landline number**</span>. But remember, during the campaign, we contacted the vast majority of the customers through their cellphone. So, there is a bias on contact type of the customers and so, such a conclusion does not provide a real benefit. \n\n4. Some months of the year such as <span style=\"color:green\">**March, October** </span>and <span style=\"color:green\">**September**</span> are the best time to call the customers. But again, we remember that those months are the time in which our contact numbers were low and possibly limited to our loyal customers, so the campaign success rate growed due to less number of contacts not the time of the year. But still, let's ask our employees to be more active during those months. :) \n\n5. Since both the <span style=\"color:green\">**daySinceLastCampaign & numberOfContactsLastCampaign**</span> have a positive correlations with the target, it's a good idea to call the customers whom we did not call for a while and were strongly involved in the last campaign.\n\n6. It's beneficial to concentrate on <span style=\"color:green\">**retired customers**</span> as well as customers who are <span style=\"color:green\">**student**</span>.\n\n7. For <span style=\"color:green\">**single customers**</span> it's more likely to accept the campaign than the ones who are <span style=\"color:red\">**married**</span> (being single has a positive correlation with the target, while being married has a negative correlation)\n\n8. Customers with <span style=\"color:green\">**higher account balance**</span> are easier to be convinced.\n\n9. <span style=\"color:green\">**Older**</span> customers may accept the campaign more than the <span style=\"color:red\">**young**</span> ones.\n\n10. There is not much difference between men and women. So, the customer <span style=\"color:blue\">**gender**</span> is not the point and can be removed.\n\n11. The call at the <span style=\"color:green\">**begining of the month**</span> is more likely to be successful. Maybe at that time people have more money in their pocket and are more likely to buy our product.\n\n12. Having <span style=\"color:red\">**a negative credit history**</span> in the past has a negative influence on the target achievement.\n\n13. <span style=\"color:red\">**Calling**</span> the customer <span style=\"color:red\">**several times**</span>, may have a bad influence on the customer's opinion about the campaign.\n\n14. It is more likely to be successful when the customer does not <span style=\"color:red\">**own a house**</span>.\n\n15. Calling <span style=\"color:green\">**managers**</span> directly is a better idea than calling their <span style=\"color:red\">**employees**</span>.","metadata":{}},{"cell_type":"markdown","source":"Since both the positive and negative correlations indicate a relation between the associated feature and the target, we should consider the absolute value of correlations:","metadata":{}},{"cell_type":"code","source":" Data.corr()['target'][1:].abs().sort_values(ascending=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:05:02.948842Z","iopub.execute_input":"2021-07-20T05:05:02.949241Z","iopub.status.idle":"2021-07-20T05:05:03.162553Z","shell.execute_reply.started":"2021-07-20T05:05:02.949203Z","shell.execute_reply":"2021-07-20T05:05:03.161677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Again we can take a look at the bar chart to see the importance order of the features:","metadata":{}},{"cell_type":"code","source":"fig = Data.corr()['target'][1:].abs().sort_values(ascending=True).plot(kind='barh', figsize = (15,20))\nfig.set(xlabel='Absolute correlation with the target feature', ylabel='');","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:05:03.16554Z","iopub.execute_input":"2021-07-20T05:05:03.165846Z","iopub.status.idle":"2021-07-20T05:05:04.210533Z","shell.execute_reply.started":"2021-07-20T05:05:03.165818Z","shell.execute_reply":"2021-07-20T05:05:04.209635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In order to select most important features, we use the following function to set a threshold (here 0.05) and choose all the features that their importance coefficients is above the threshold:","metadata":{}},{"cell_type":"code","source":"def high_features(data, threshold):\n    names = []\n    for idx , val in ranking.iteritems():\n        if val >= threshold:\n            names.append(idx)\n    return names     ","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:05:04.211894Z","iopub.execute_input":"2021-07-20T05:05:04.21218Z","iopub.status.idle":"2021-07-20T05:05:04.216918Z","shell.execute_reply.started":"2021-07-20T05:05:04.212151Z","shell.execute_reply":"2021-07-20T05:05:04.21612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ranking = Data.corr()['target'][1:].abs().sort_values(ascending=False)\nmyCols = high_features(ranking, 0.05)\nmyCols   ","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:05:04.217835Z","iopub.execute_input":"2021-07-20T05:05:04.218161Z","iopub.status.idle":"2021-07-20T05:05:04.437352Z","shell.execute_reply.started":"2021-07-20T05:05:04.218132Z","shell.execute_reply":"2021-07-20T05:05:04.43645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The above selection of the features is our selection based on **correlation coefficients** of the features with the target. We will refer to this set of features as <span style=\"color:red\">**myCols**</span> in the following sections. ","metadata":{}},{"cell_type":"markdown","source":"### Normalization\n\nIt is important to normalize our features so that they can have approximately same scale and be comparable. This also prevents high values dominate the low values so, the model can learn from all the features. Normalization specially helps the convergence of the optimization process within the models. This is also more important for some model such as SVM, neural network and KNN.","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\n# Create the scaler object with a range of 0-1\nscaler = MinMaxScaler(feature_range=(0, 1))\n\nX = Data.drop(columns='target')\ny = pd.DataFrame(Data['target'])\ndataCols = X.columns\n\nscaler.fit(X)\nX = scaler.transform(X)\n\nData = pd.DataFrame(X, columns=dataCols)\nData['target'] = y","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:05:04.438722Z","iopub.execute_input":"2021-07-20T05:05:04.438998Z","iopub.status.idle":"2021-07-20T05:05:04.469161Z","shell.execute_reply.started":"2021-07-20T05:05:04.438972Z","shell.execute_reply":"2021-07-20T05:05:04.468288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# decreasing binary features type accuracy for a more efficient memory usage\nfor col in Data.columns:\n    if len(Data[col].unique()) == 2:\n        Data[col]= Data[col].astype('uint8') ","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:05:04.470435Z","iopub.execute_input":"2021-07-20T05:05:04.470751Z","iopub.status.idle":"2021-07-20T05:05:04.562795Z","shell.execute_reply.started":"2021-07-20T05:05:04.470721Z","shell.execute_reply":"2021-07-20T05:05:04.56171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n\n## Splitting the data Into Training and Test Sets\n\nIn machine learning, we always need to separate our features into two sets:\n\n1. __Training set__ which we provide to our model during training along with the answers so it can learn a mapping between the features and the target. \n2. __Test (validation) set__ which we use to evaluate the mapping learned by the model. The model has never seen the answers on the test set, but instead, must make predictions using only the features. As we know the true answers for the test set, we can then compare the test predictions to the true test targets to ghet an estimate of how well our model will perform when deployed in the real world. ","metadata":{}},{"cell_type":"code","source":"# Separate out the features and targets\n# on the original data\ndef orgData(Data):\n    X = Data.drop(columns='target')\n    y = pd.DataFrame(Data['target'])\n    dataCols = X.columns\n\n    X_values = X.values\n    y_values = np.array(y).reshape((-1,))\n\n    X_train, X_test, y_train, y_test = train_test_split(X_values, y_values, test_size = 0.2, random_state = 0)\n    return [dataCols, X_train, X_test, y_train, y_test]","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:05:04.564283Z","iopub.execute_input":"2021-07-20T05:05:04.564724Z","iopub.status.idle":"2021-07-20T05:05:04.571817Z","shell.execute_reply.started":"2021-07-20T05:05:04.564679Z","shell.execute_reply":"2021-07-20T05:05:04.570805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Separate out the features and targets\n# on the data that includes only 'myCols' features\ndef myData(Data):\n    X = pd.DataFrame(Data[myCols])\n    y = pd.DataFrame(Data['target'])\n    dataCols = X.columns\n\n    X_values = X.values\n    y_values = np.array(y).reshape((-1,))\n\n    X_train, X_test, y_train, y_test = train_test_split(X_values, y_values, test_size = 0.2, random_state = 0)\n    return [X_train, X_test, y_train, y_test]","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:05:04.573113Z","iopub.execute_input":"2021-07-20T05:05:04.573406Z","iopub.status.idle":"2021-07-20T05:05:04.584042Z","shell.execute_reply.started":"2021-07-20T05:05:04.573377Z","shell.execute_reply":"2021-07-20T05:05:04.583039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Using Synthetic Minority Over-sampling Technique (SMOTE) to overcome the imbalanced label problem\n\nTo overcome the previously discovered label imbalance problem in the training data, we can use the **Synthetic Minority Over-sampling Technique (SMOTE)** algorithm to create synthetic samples from the minor class.","metadata":{}},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\n\ndef smoteData(Data):\n    [dataCols, X_train, X_test, y_train, y_test] = orgData(Data)\n\n    smote = SMOTE(random_state=0)\n\n    smote_data_X,smote_data_y = smote.fit_resample(X_train, y_train)\n\n    smote_data_X = pd.DataFrame(data=smote_data_X,columns=dataCols)\n    smote_data_y = pd.DataFrame(data=smote_data_y,columns=['target'])\n\n    X_train_smote = smote_data_X.values\n    y_train_smote = smote_data_y.values\n    y_train_smote = y_train_smote.reshape((-1,))\n\n    return [X_train_smote, X_test, y_train_smote, y_test]","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:05:04.585498Z","iopub.execute_input":"2021-07-20T05:05:04.585842Z","iopub.status.idle":"2021-07-20T05:05:04.681944Z","shell.execute_reply.started":"2021-07-20T05:05:04.585811Z","shell.execute_reply":"2021-07-20T05:05:04.68082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Note:** In this function, oversampling is performed while the test data is excluded, So, no test data information is exploited for model training.","metadata":{}},{"cell_type":"markdown","source":"So we have three functions that can be used to split different kinds of the data into training and test sets:\n\n1. **orgData** that splits the original version of the data into training and test samples.\n\n2. **myData** that splits a version of the data into training and test samples that includes only **myCols** features (features that are chosen based oh their correlations with the target).\n\n3. **smoteData** that splits a version of the data into training and test samples that includes over-sampled minority class and is balanced w.r.t. our binary labels.\n\nAt the beginning of each training process, one of these functions will be used to prepare the data.","metadata":{}},{"cell_type":"markdown","source":"## Training some models (binary classifiers) on the data:\n\nIn this part, we train some models such as logistic regression and Random Forest to see how much better do they perform than our baseline random guess:","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.feature_selection import RFE,RFECV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, recall_score, precision_score, make_scorer\nfrom sklearn.metrics import roc_curve, precision_recall_curve, auc, confusion_matrix, classification_report\nfrom sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:05:04.683484Z","iopub.execute_input":"2021-07-20T05:05:04.68395Z","iopub.status.idle":"2021-07-20T05:05:04.696397Z","shell.execute_reply.started":"2021-07-20T05:05:04.683907Z","shell.execute_reply":"2021-07-20T05:05:04.695275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Baseline establishment:","metadata":{}},{"cell_type":"markdown","source":"It's important to establish a naive baseline before we training machine learning models. If the models we build cannot outperform a naive guess then we might have to admit that machine learning is not suited for this problem. Possible reasons for such a situation would be not using the right models, need for more data, existence of a simpler solution that does not require machine learning.\n\nFor a binary classification task, a good naive baseline is to select one of two possible labels with the probability of 50%. This is simple to implement and sets a relatively low bar for our models: if they cannot do better than guessing the medin value, then we will need to rethink our approach.","metadata":{}},{"cell_type":"markdown","source":"To be sure that our data is splitted correctly, we may check if two sets of training and test data have an equal proportion of positive samples:","metadata":{}},{"cell_type":"code","source":"[dataCols, X_train, X_test, y_train, y_test] = orgData(Data)\n\nprint('percentage of positive labels in training data: {:.2f}%' . format(sum(y_train)/len(y_train)*100))\nprint('percentage of positive labels in test data: {:.2f}%' . format(sum(y_test)/len(y_test)*100))","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:05:04.698282Z","iopub.execute_input":"2021-07-20T05:05:04.698735Z","iopub.status.idle":"2021-07-20T05:05:04.744163Z","shell.execute_reply.started":"2021-07-20T05:05:04.698691Z","shell.execute_reply":"2021-07-20T05:05:04.743171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_baseline = np.random.randint(2, size=len(y_test))","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:05:04.745489Z","iopub.execute_input":"2021-07-20T05:05:04.745813Z","iopub.status.idle":"2021-07-20T05:05:04.750766Z","shell.execute_reply.started":"2021-07-20T05:05:04.74578Z","shell.execute_reply":"2021-07-20T05:05:04.749914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Before going further we have to think about the meaning and the importance of two concepts in our problem:\n\n1. **False Positive predictions (Type I error)**: means we wrongly classified negative customers (who will reject the campaign) as positive customers (who will accept the campaign). The consequence of such a wrong prediction, is to waste our time to contact those customers and get a rejection. Not so bad.\n\n\n2. **False Negative predictions (Type II error)**: means we wrongly classified positive customers (who will accept the campaign) as negative customers (who will reject the campaign). The consequence of such a wrong prediction, is to not contact good customers and lose an excellent sale opportunity. That is not the situation that your manager wants to deal with. Too dangerous!\n\nSo, we should take a measure that is cautious about the **False Negative** rate which is **recall**.\n\nNow, we can evaluate the baseline guess recall score on the test set: ","metadata":{}},{"cell_type":"code","source":"recall = recall_score(y_test, y_baseline)\nprint(\"Baseline Performance on the test set: %.2f%%\" % (recall * 100.0))","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:05:04.752116Z","iopub.execute_input":"2021-07-20T05:05:04.752398Z","iopub.status.idle":"2021-07-20T05:05:04.767254Z","shell.execute_reply.started":"2021-07-20T05:05:04.752371Z","shell.execute_reply":"2021-07-20T05:05:04.76628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we introduce some extra fuctions that are reponsible for the rest of the process:","metadata":{}},{"cell_type":"code","source":"from sklearn.utils.multiclass import unique_labels\n\ndef plot_confusion_matrix(y_true, y_pred, classes,\n                          normalize=False,\n                          title=None,\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if not title:\n        if normalize:\n            title = 'Normalized confusion matrix'\n        else:\n            title = 'Confusion matrix, without normalization'\n\n    # Compute confusion matrix\n    cm = confusion_matrix(y_true, y_pred)\n    cm[[0, 1]] = cm[[1, 0]] # swapping rows\n    cm[:,[1,0]] = cm[:,[0,1]] # swapping cols\n    # Only use the labels that appear in the data\n    classes = classes[unique_labels(y_true, y_pred)]\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        #print(\"Normalized confusion matrix\")\n    #else:\n        #print('Confusion matrix, without normalization')\n\n    #print(cm)\n\n    fig, ax = plt.subplots()\n    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n    ax.figure.colorbar(im, ax=ax)\n    # We want to show all ticks...\n    ax.set(xticks=np.arange(cm.shape[1]),\n           yticks=np.arange(cm.shape[0]),\n           # ... and label them with the respective list entries\n           xticklabels=classes, yticklabels=classes,\n           title=title,\n           ylabel='True label',\n           xlabel='Predicted label')\n\n    # Rotate the tick labels and set their alignment.\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n             rotation_mode=\"anchor\")\n\n    # Loop over data dimensions and create text annotations.\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            ax.text(j, i, format(cm[i, j], fmt),\n                    ha=\"center\", va=\"center\",\n                    color=\"white\" if cm[i, j] > thresh else \"black\")\n    fig.tight_layout()\n    return ax","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:05:04.768802Z","iopub.execute_input":"2021-07-20T05:05:04.769122Z","iopub.status.idle":"2021-07-20T05:05:04.783034Z","shell.execute_reply.started":"2021-07-20T05:05:04.769092Z","shell.execute_reply":"2021-07-20T05:05:04.781984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_cmap(n, name='hsv'):\n    '''Returns a function that maps each index in 0, 1, ..., n-1 to a distinct \n    RGB color; the keyword argument name must be a standard mpl colormap name.'''\n    return plt.cm.get_cmap(name, n)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:05:04.784781Z","iopub.execute_input":"2021-07-20T05:05:04.785467Z","iopub.status.idle":"2021-07-20T05:05:04.797492Z","shell.execute_reply.started":"2021-07-20T05:05:04.78542Z","shell.execute_reply":"2021-07-20T05:05:04.796276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_and_evaluate(model, X_train, y_train, X_test, y_test):\n    \"\"\"\n    This function trains the input model on the data, evaluates the model performance on the test set,\n    plots the confusion matrix of the model and finally reports the model recall score on the test data\n    \"\"\"\n    model.fit(X_train,y_train)\n    y_pred = model.predict(X_test)\n    plot_confusion_matrix(y_test, y_pred, classes=np.array(['yes', 'no']), normalize=True)\n    plt.grid(None)\n    print('\\n', classification_report(y_test, y_pred, target_names=np.array(['yes', 'no']), labels = [1, 0]))\n\n    print(\"Dimensions of training data: {}\" .format(X_train.shape))\n    \n    recall = recall_score(y_test, y_pred)\n    print(\"Recall: %.2f%%\" % (recall * 100.0))\n    \n    return model, (recall * 100.0)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:05:04.798991Z","iopub.execute_input":"2021-07-20T05:05:04.799314Z","iopub.status.idle":"2021-07-20T05:05:04.811672Z","shell.execute_reply.started":"2021-07-20T05:05:04.799286Z","shell.execute_reply":"2021-07-20T05:05:04.81059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def grid_search_wrapper(clf, X_train, y_train, X_test, y_test, param_grid, scorers, refit_score):\n    \"\"\"\n    fits a GridSearchCV classifier using refit_score for optimization\n    prints classifier performance metrics\n    \"\"\"\n    skf = StratifiedKFold(n_splits=5)\n    grid_search = GridSearchCV(clf, param_grid, scoring=scorers, refit=refit_score,\n                           cv=skf, return_train_score=True, n_jobs=-1)\n    \n    \n    grid_search.fit(X_train, y_train)\n\n    # make the predictions\n    y_pred = grid_search.predict(X_test)\n\n    print('Best params for {}'.format(refit_score))\n    print(grid_search.best_params_)\n    \n    return grid_search","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:05:04.8131Z","iopub.execute_input":"2021-07-20T05:05:04.813397Z","iopub.status.idle":"2021-07-20T05:05:04.823004Z","shell.execute_reply.started":"2021-07-20T05:05:04.81337Z","shell.execute_reply":"2021-07-20T05:05:04.821952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plotROC(model, X_train, y_Train, X_test, y_Test, typ=1):\n    \"\"\"\n    this function plots the ROC curve of a trained model on the test data\n    and reports the Area Under Curve (AUC) for it.\n    \"\"\"\n    if typ == 1:\n        y_pred = model.predict_proba(X_test)\n        # keep probabilities for the positive outcome only\n        y_pred = y_pred[:, 1]\n    else:\n        y_pred = model.decision_function(X_test)\n    \n    \n    \n    fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n    roc_auc = auc(fpr, tpr)\n\n    fig, ax = plt.subplots(figsize=(9,6))\n    lw = 2\n    ax.plot(fpr, tpr, color='darkorange',\n             lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n    ax.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n    ax.plot([0, 0], [0, 1], 'k-') # right\n    ax.plot([1, 0], [0, 0], 'k-') # down\n    ax.plot([1, 1], [0, 1], 'k-') # left\n    ax.plot([1, 0], [1, 1], 'k-') # up\n    plt.xlim([-0.1, 1.1])\n    plt.ylim([-0.1, 1.1])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('ROC curve of the current classifier')\n    plt.legend(loc=\"lower right\")\n    plt.show()  ","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:05:04.824488Z","iopub.execute_input":"2021-07-20T05:05:04.824856Z","iopub.status.idle":"2021-07-20T05:05:04.837737Z","shell.execute_reply.started":"2021-07-20T05:05:04.824824Z","shell.execute_reply":"2021-07-20T05:05:04.836951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc\n\ndef checkThresh(clf, X_test, y_test, typ = 1, prt=0):\n    \n    \"\"\"\n    this function plots the ROC curve of a trained model on the test data\n    against nine different thresholds {0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9} for classification probability thresholding \n    \"\"\"\n    \n    TSs = []\n    TPs = []\n    FPs = []\n    for threshold in np.arange(0.1, 1, 0.1):\n        TSs.append(round(threshold,2))\n        \n        if typ == 1:\n            predicted_proba = clf.predict_proba(X_test)\n            y_pred = (predicted_proba [:,1] >= threshold).astype('int')\n        else:\n            predicted_proba = clf.decision_function(X_test)\n            y_pred = (predicted_proba >= threshold).astype('int')\n       \n    \n        cm = confusion_matrix(y_test, y_pred)\n        \n        FN = cm[0][0] / (cm[0][0] + cm[0][1])\n        FP = cm[0][1] / (cm[0][0] + cm[0][1])\n        FPs.append(FP)\n        TN = cm[1][0] / (cm[1][0] + cm[1][1])\n        TP = cm[1][1] / (cm[1][0] + cm[1][1])\n        TPs.append(TP)\n        \n        if prt:\n            print('Threshold: {:.1f}, TP: {:.2f}, TN: {:.2f} , FP: {:.2f}, FN: {:.2f} %' \n              .format(threshold, TP, FN, FP, TN))\n\n    fig, ax = plt.subplots(figsize=(9,6))\n    ax.scatter( x=FPs, y=TPs , label='ROC Convex Hall')\n    ax.plot([0, 1], [0, 1], 'k--') # diag\n    ax.plot([0, 0], [0, 1], 'k-') # right\n    ax.plot([1, 0], [0, 0], 'k-') # down\n    ax.plot([1, 1], [0, 1], 'k-') # left\n    ax.plot([1, 0], [1, 1], 'k-') # up\n    plt.xlim([-0.1, 1.1])\n    plt.ylim([-0.1, 1.1])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('ROC convex hull for different thresholds on the current classifier')\n\n    for i, label in enumerate(TSs):\n        ax.annotate(label, (FPs[i]+0.01, TPs[i]+ 0.005), fontsize=14)\n\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:05:04.839087Z","iopub.execute_input":"2021-07-20T05:05:04.839663Z","iopub.status.idle":"2021-07-20T05:05:04.856248Z","shell.execute_reply.started":"2021-07-20T05:05:04.839616Z","shell.execute_reply":"2021-07-20T05:05:04.85536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# A Dataframe to hold the results\nresults = pd.DataFrame({'model': ['Logistic Regression', 'Random Forest', 'Support Vector Machine', 'Extra Trees', \n                                           'Gradient Boosting', 'Xgboost'] })\nresults['orgDataDefault'] = ''\nresults['myColsDefault'] = ''\nresults['orgDataOptimal'] = ''\nresults['myColsOptimal'] = ''\nresults['orgDataOptimalRFE'] = ''\nresults['smoteDataDefault'] = ''\nresults['smoteDataOptimal'] = ''\nresults['smoteDataOptimalRFE'] = ''","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:05:04.857637Z","iopub.execute_input":"2021-07-20T05:05:04.858029Z","iopub.status.idle":"2021-07-20T05:05:04.875451Z","shell.execute_reply.started":"2021-07-20T05:05:04.857997Z","shell.execute_reply":"2021-07-20T05:05:04.874515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training steps for each model:\n\nIn the following section, I train several machine learning models including:\n\n1. Logistic Regression (LR) *\n2. Random Forest Classifier (RFC) *\n3. Support Vector Classifier (SVC) *\n4. Extra Trees Classifier (ETC) *\n5. Gradient Boosting Classifier (GBC) +\n6. eXtreme Gradient Boosting (XGBoost) +\n\n(*): models that have an explicit parameter to handle imbalanced label problem (class_weight='balanced')\n\n(+): models that don't have an explicit parameter to handle imbalanced label problem\n\nProcessing steps on (*) models:\n\n1. Training the model with the default hyper parameters on the original Data (orgData) and plotting the results.\n2. Training the model with the default hyper parameters on previously selected features (myData) and plotting the results.\n3. Execution of the Grid Search Cross Validation technique for tuning model hyper parameters (finding optimal hyper parameters).\n4. Training the model with the optimal hyper parameters on the original Data (orgData) and plotting the results.\n5. Training the model with the optimal hyper parameters on previously selected features (myData) and plotting the results.\n6. Runnig the Recursive Feature Elimination (RFE) method with cross-validation as the second feature selection approach.\n7. Training the model with the optimal hyper parameters on the resulting features of the RFE process on orgData and plotting the results.\n\n\n\nProcessing steps on (+) models:\n\n1. Training the model with the default hyper parameters on the balanced Data (smoteData) and plotting the results.\n2. Execution of the Grid Search Cross Validation technique for tuning model hyper parameters (finding optimal hyper parameters).\n3. Training the model with the optimal hyper parameters on the balanced Data (smoteData) and plotting the results.\n4. Running the Recursive Feature Elimination (RFE) method with cross-validation as the second feature selection approach.\n5. Training the model with the optimal hyper parameters on the resulting features of the RFE process on the balanced Data (smoteData) and plotting the results.","metadata":{}},{"cell_type":"markdown","source":"### Model # 1: Logistic Regression","metadata":{}},{"cell_type":"code","source":"# First model (Logistic Regression) definition, training and evaluation \n# on the original data (orgData)\n# with default hyper parameters\n\n[dataCols, X_train, X_test, y_train, y_test] = orgData(Data)\n\nlogreg = LogisticRegression(random_state=0, class_weight='balanced')\n\nlogreg, results.at[0, 'orgDataDefault']  = train_and_evaluate(logreg, X_train, y_train, X_test, y_test)\n\nplotROC(logreg, X_train, y_train, X_test, y_test)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-07-20T05:05:04.876946Z","iopub.execute_input":"2021-07-20T05:05:04.877298Z","iopub.status.idle":"2021-07-20T05:05:05.99298Z","shell.execute_reply.started":"2021-07-20T05:05:04.877268Z","shell.execute_reply":"2021-07-20T05:05:05.992288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# First model (Logistic Regression) definition, training and evaluation \n# on previously selected features (myData)\n# with default hyper parameters\n\n[X_train, X_test, y_train, y_test] = myData(Data)\n\nlogreg = LogisticRegression(random_state=0, class_weight='balanced')\n\nlogreg, results.at[0, 'myColsDefault'] = train_and_evaluate(logreg, X_train, y_train, X_test, y_test)\n\nplotROC(logreg, X_train, y_train, X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:05:05.993976Z","iopub.execute_input":"2021-07-20T05:05:05.994353Z","iopub.status.idle":"2021-07-20T05:05:07.067277Z","shell.execute_reply.started":"2021-07-20T05:05:05.994325Z","shell.execute_reply":"2021-07-20T05:05:07.066222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# GridSearchCV for tuning hyper parameters of the first model (Logistic Regression)\n\n[X_train, X_test, y_train, y_test] = myData(Data)\n\nclf = LogisticRegression(class_weight= 'balanced', verbose=0, max_iter=1000)\n\nparam_grid = {\n    'solver': ['lbfgs', 'newton-cg'], \n    'C' : [0.5, 1, 2, 10, 100, 1000, 10000],\n    'tol' : [1e-6, 1e-5, 1e-4, 1e-3, 1e-2]\n}\n\nscorers = {\n    'precision_score': make_scorer(precision_score),\n    'recall_score': make_scorer(recall_score),\n    'accuracy_score': make_scorer(accuracy_score)\n}\n\ngrid_search_clf = grid_search_wrapper(clf, X_train, y_train, X_test, y_test, param_grid, scorers, 'recall_score')","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:05:07.068847Z","iopub.execute_input":"2021-07-20T05:05:07.069285Z","iopub.status.idle":"2021-07-20T05:06:00.163999Z","shell.execute_reply.started":"2021-07-20T05:05:07.06924Z","shell.execute_reply":"2021-07-20T05:06:00.162786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CVresults = pd.DataFrame(grid_search_clf.cv_results_)\nCVresults = CVresults.sort_values(by='mean_test_recall_score', ascending=False)\nCVresults[['mean_test_precision_score', 'mean_test_recall_score',\n         'mean_test_accuracy_score', 'param_C',\n         'param_tol', 'param_solver']].round(3).head()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:06:00.16589Z","iopub.execute_input":"2021-07-20T05:06:00.166626Z","iopub.status.idle":"2021-07-20T05:06:00.202214Z","shell.execute_reply.started":"2021-07-20T05:06:00.16654Z","shell.execute_reply":"2021-07-20T05:06:00.201145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# First model (Logistic Regression) definition, training and evaluation \n# on the original data (orgData)\n# with optimal hyper parameters\n\n[dataCols, X_train, X_test, y_train, y_test] = orgData(Data)\n\nlogreg = LogisticRegression(random_state=0, class_weight='balanced', C=100, solver='lbfgs', tol=1e-06, max_iter=1000)\n\nlogreg, results.at[0, 'orgDataOptimal']  = train_and_evaluate(logreg, X_train, y_train, X_test, y_test)\n\nplotROC(logreg, X_train, y_train, X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:06:00.204041Z","iopub.execute_input":"2021-07-20T05:06:00.204789Z","iopub.status.idle":"2021-07-20T05:06:01.912221Z","shell.execute_reply.started":"2021-07-20T05:06:00.204741Z","shell.execute_reply":"2021-07-20T05:06:01.911128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# First model (Logistic Regression) definition, training and evaluation \n# on previously selected features (myData)\n# with optimal hyper parameters\n\n[X_train, X_test, y_train, y_test] = myData(Data)\n\nlogreg = LogisticRegression(random_state=0, class_weight='balanced', C=100, solver='lbfgs', tol=1e-06, max_iter=1000)\n\nlogreg, results.at[0, 'myColsOptimal'] = train_and_evaluate(logreg, X_train, y_train, X_test, y_test)\n\nplotROC(logreg, X_train, y_train, X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:06:01.913588Z","iopub.execute_input":"2021-07-20T05:06:01.913883Z","iopub.status.idle":"2021-07-20T05:06:03.669511Z","shell.execute_reply.started":"2021-07-20T05:06:01.913853Z","shell.execute_reply":"2021-07-20T05:06:03.668444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Recursive feature elimination with cross-validation for the first model (Logistic regression)\n\n[dataCols, X_train, X_test, y_train, y_test] = orgData(Data)\n\nrfecv = RFECV(estimator=logreg, step=1, cv=StratifiedKFold(3), scoring='recall')\nrfecv.fit(X_train, y_train)\n\nprint(\"Optimal number of features : %d\" % rfecv.n_features_)\nQty = rfecv.n_features_\n\n# Get numerical feature importances\nimportances = list(rfecv.ranking_)\n# Saving feature names for later use\nfeature_list = list(dataCols)\n\n# List of tuples with variable and importance\nfeature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n# Sort the feature importances by most important first\nfeature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = False)\n# Print out the feature and importances \nprint('\\nFeature Ranking:\\n')\n[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances]\n\n# Plot number of features VS. cross-validation scores\nplt.figure(figsize=(15,10))\nplt.xlabel(\"Number of features selected\")\nplt.ylabel(\"Cross validation score\")\nplt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:06:03.670826Z","iopub.execute_input":"2021-07-20T05:06:03.671089Z","iopub.status.idle":"2021-07-20T05:07:28.612366Z","shell.execute_reply.started":"2021-07-20T05:06:03.671063Z","shell.execute_reply":"2021-07-20T05:07:28.611344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here, the trend of scores becomes relatively flat from about 27 features. So, we can try with 27 features with highest ranking.","metadata":{}},{"cell_type":"code","source":"# Plotting feature importances based on RFE selection approach\nMAX_score = feature_importances[-1:][0][1] + 1\n\nimport importlib\n\nplot_data = {}\n\nfor i in feature_importances:\n    plot_data[i[0]] = MAX_score - i[1] \ncolors = ['red'] * (Qty)    \ncmap = get_cmap(len(plot_data), name = 'autumn')\nfor i in range(Qty, len(plot_data)+1):\n    colors.append(cmap(i))\nplt.figure(figsize=(15,10))   \nplt.bar(plot_data.keys(), plot_data.values(), color = colors)\nplt.xticks(rotation=90)\nplt.title('Feature importance')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:07:28.613785Z","iopub.execute_input":"2021-07-20T05:07:28.614357Z","iopub.status.idle":"2021-07-20T05:07:29.415016Z","shell.execute_reply.started":"2021-07-20T05:07:28.614313Z","shell.execute_reply":"2021-07-20T05:07:29.413864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Determining indices of the features that should be dropped\nremoving_idx = []\n\nidx = 0\nfor feature in feature_importances:\n    if feature[1] > 1:\n        removing_idx.append(idx)\n    idx += 1   ","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:07:29.416608Z","iopub.execute_input":"2021-07-20T05:07:29.417026Z","iopub.status.idle":"2021-07-20T05:07:29.421893Z","shell.execute_reply.started":"2021-07-20T05:07:29.416984Z","shell.execute_reply":"2021-07-20T05:07:29.421266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# First model (Logistic Regression) definition, training and evaluation \n# on the original data (orgData)\n# with optimal hyper parameters\n# using RFE feature selection \n\nX_train = np.delete(X_train,np.s_[removing_idx],axis=1)\nX_test = np.delete(X_test,np.s_[removing_idx],axis=1)\n\n\nlogreg = LogisticRegression(random_state=0, class_weight='balanced', C=100, solver='lbfgs', tol=1e-06, max_iter=1000)\n\nlogreg, results.at[0, 'orgDataOptimalRFE'] = train_and_evaluate(logreg, X_train, y_train, X_test, y_test)\n\nplotROC(logreg, X_train, y_train, X_test, y_test)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-07-20T05:07:29.422997Z","iopub.execute_input":"2021-07-20T05:07:29.423449Z","iopub.status.idle":"2021-07-20T05:07:30.651228Z","shell.execute_reply.started":"2021-07-20T05:07:29.423419Z","shell.execute_reply":"2021-07-20T05:07:30.650161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:07:30.652644Z","iopub.execute_input":"2021-07-20T05:07:30.652922Z","iopub.status.idle":"2021-07-20T05:07:30.670905Z","shell.execute_reply.started":"2021-07-20T05:07:30.652894Z","shell.execute_reply":"2021-07-20T05:07:30.670011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model # 2: Random Forest","metadata":{}},{"cell_type":"code","source":"# Second model (Random Forest) definition, train and evaluation:\n# on the original data (orgData)\n# with default hyper parameters\n\n[dataCols, X_train, X_test, y_train, y_test] = orgData(Data)\n\nforest = RandomForestClassifier(random_state=0, class_weight='balanced')\n\nforest, results.at[1, 'orgDataDefault'] = train_and_evaluate(forest, X_train, y_train, X_test, y_test)\n\nplotROC(forest, X_train, y_train, X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:07:30.67218Z","iopub.execute_input":"2021-07-20T05:07:30.672474Z","iopub.status.idle":"2021-07-20T05:07:34.157156Z","shell.execute_reply.started":"2021-07-20T05:07:30.672445Z","shell.execute_reply":"2021-07-20T05:07:34.156198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Second model (Random Forest) definition, train and evaluation:\n# on previously selected features (myData)\n# with default hyper parameters\n\n[X_train, X_test, y_train, y_test] = myData(Data)\n\nforest = RandomForestClassifier(random_state=0, class_weight='balanced')\n\nforest, results.at[1, 'myColsDefault'] = train_and_evaluate(forest, X_train, y_train, X_test, y_test)\n\nplotROC(forest, X_train, y_train, X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:07:34.15846Z","iopub.execute_input":"2021-07-20T05:07:34.158806Z","iopub.status.idle":"2021-07-20T05:07:37.173905Z","shell.execute_reply.started":"2021-07-20T05:07:34.158764Z","shell.execute_reply":"2021-07-20T05:07:37.172874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# GridSearchCV for tuning hyper parameters of the second model (Random Forest)\n\n[X_train, X_test, y_train, y_test] = myData(Data)\n\n\nstage = 5\n\nif stage == 1:\n    # In order to decide on boosting parameters, we need to set some 'initial values' of other parameters.\n    # all of these values are just initial estimates and will be tuned later.\n    \n    # Here, we try to choose some initial values for parameters that do not decrease the recall score that we had\n    # with the default values of the parameters\n    clf = RandomForestClassifier(max_depth=10,random_state=0, class_weight='balanced')\n    \n    # Now, we check the optimum number of trees. \n    # For this purpose, we can do a grid search and test out values from 20 to 100 in steps of 20.\n    param_grid = {\n        'n_estimators' : range(60, 150, 20) # 80\n    }\n\n    scorers = {\n        'precision_score': make_scorer(precision_score),\n        'recall_score': make_scorer(recall_score),\n        'accuracy_score': make_scorer(accuracy_score)\n    }\n\n    grid_search_clf = grid_search_wrapper(clf, X_train, y_train, X_test, y_test, param_grid, scorers, 'recall_score')\n    \nif stage == 2:\n    # Tuning tree-specific parameters, The order of tuning variables should be decided carefully.\n    # We should take the variables with a higher impact on outcome first.\n    clf = RandomForestClassifier(n_estimators=80, random_state=0, class_weight='balanced')\n\n    param_grid = {\n        'max_depth' : range(2,15,2) # 6\n    }\n\n    scorers = {\n        'precision_score': make_scorer(precision_score),\n        'recall_score': make_scorer(recall_score),\n        'accuracy_score': make_scorer(accuracy_score)\n    }\n\n    grid_search_clf = grid_search_wrapper(clf, X_train, y_train, X_test, y_test, param_grid, scorers, 'recall_score')\n    \nif stage == 3:\n    # Tuning tree-specific parameters, The order of tuning variables should be decided carefully.\n    # We should take the variables with a higher impact on outcome first.\n    clf = RandomForestClassifier(n_estimators=80, max_depth=6, random_state=0, class_weight='balanced')\n\n    param_grid = {\n        'min_samples_split' : range(2,15,2) # 4\n    }\n\n    scorers = {\n        'precision_score': make_scorer(precision_score),\n        'recall_score': make_scorer(recall_score),\n        'accuracy_score': make_scorer(accuracy_score)\n    }\n\n    grid_search_clf = grid_search_wrapper(clf, X_train, y_train, X_test, y_test, param_grid, scorers, 'recall_score')    \n    \nif stage == 4:\n    # Tuning tree-specific parameters, The order of tuning variables should be decided carefully.\n    # We should take the variables with a higher impact on outcome first.\n    clf = RandomForestClassifier(n_estimators=80, max_depth=6,\n                               random_state=0, class_weight='balanced', min_samples_split=4)\n\n    param_grid = {\n        'min_samples_leaf' : range(2,15,2) # 12\n    }\n\n    scorers = {\n        'precision_score': make_scorer(precision_score),\n        'recall_score': make_scorer(recall_score),\n        'accuracy_score': make_scorer(accuracy_score)\n    }\n\n    grid_search_clf = grid_search_wrapper(clf, X_train, y_train, X_test, y_test, param_grid, scorers, 'recall_score')\n    \nif stage == 5:\n    # Tuning tree-specific parameters, The order of tuning variables should be decided carefully.\n    # We should take the variables with a higher impact on outcome first.\n    clf = RandomForestClassifier(n_estimators=80, max_depth=6,random_state=0, \n                                class_weight='balanced', min_samples_split=4, min_samples_leaf=12)\n\n    param_grid = {\n        'max_features' : [3, 4, 5, 6, 7, 8] # 5 , here dafault value (sqrt) works well, no need to add the parameter explicitly\n    }\n\n    scorers = {\n        'precision_score': make_scorer(precision_score),\n        'recall_score': make_scorer(recall_score),\n        'accuracy_score': make_scorer(accuracy_score)\n    }\n\n    grid_search_clf = grid_search_wrapper(clf, X_train, y_train, X_test, y_test, param_grid, scorers, 'recall_score')    ","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:07:37.175678Z","iopub.execute_input":"2021-07-20T05:07:37.176131Z","iopub.status.idle":"2021-07-20T05:07:51.374431Z","shell.execute_reply.started":"2021-07-20T05:07:37.176084Z","shell.execute_reply":"2021-07-20T05:07:51.37321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Second model (Random Forest) definition, training and evaluation \n# on the original data (orgData)\n# with optimal hyper parameters\n\n[dataCols, X_train, X_test, y_train, y_test] = orgData(Data)\n\nforest = RandomForestClassifier(n_estimators=80, max_depth=6,random_state=0, \n                                class_weight='balanced', min_samples_split=4, min_samples_leaf=12)\n\nforest, results.at[1, 'orgDataOptimal'] = train_and_evaluate(forest, X_train, y_train, X_test, y_test)\n\nplotROC(forest, X_train, y_train, X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:07:51.375975Z","iopub.execute_input":"2021-07-20T05:07:51.376393Z","iopub.status.idle":"2021-07-20T05:07:53.030371Z","shell.execute_reply.started":"2021-07-20T05:07:51.37635Z","shell.execute_reply":"2021-07-20T05:07:53.029648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Second model (Random Forest) definition, train and evaluation:\n# on previously selected features (myData)\n# with optimal hyper parameters\n\n[X_train, X_test, y_train, y_test] = myData(Data)\n\nforest = RandomForestClassifier(n_estimators=80, max_depth=6,random_state=0, \n                                class_weight='balanced', min_samples_split=4, min_samples_leaf=12)\n\nforest, results.at[1, 'myColsOptimal'] = train_and_evaluate(forest, X_train, y_train, X_test, y_test)\n\nplotROC(forest, X_train, y_train, X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:07:53.038254Z","iopub.execute_input":"2021-07-20T05:07:53.03855Z","iopub.status.idle":"2021-07-20T05:07:54.530263Z","shell.execute_reply.started":"2021-07-20T05:07:53.038521Z","shell.execute_reply":"2021-07-20T05:07:54.529397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Recursive feature elimination with cross-validation for the second model (Random Forest)\n\n[dataCols, X_train, X_test, y_train, y_test] = orgData(Data)\n\nforest = RandomForestClassifier(n_estimators=80, max_depth=6,random_state=0, \n                                class_weight='balanced', min_samples_split=4, min_samples_leaf=12)\n\nrfecv = RFECV(estimator=forest, step=1, cv=StratifiedKFold(3), scoring='recall')\nrfecv.fit(X_train, y_train)\n\nprint(\"Optimal number of features : %d\" % rfecv.n_features_)\nQty = rfecv.n_features_\n\n# Get numerical feature importances\nimportances = list(rfecv.ranking_)\n# Saving feature names for later use\nfeature_list = list(dataCols)\n\n# List of tuples with variable and importance\nfeature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n# Sort the feature importances by most important first\nfeature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = False)\n# Print out the feature and importances \nprint('\\nFeature Ranking:\\n')\n[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances]\n\n# Plot number of features VS. cross-validation scores\nplt.figure(figsize=(15,10))\nplt.xlabel(\"Number of features selected\")\nplt.ylabel(\"Cross validation score\")\nplt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:07:54.532742Z","iopub.execute_input":"2021-07-20T05:07:54.533022Z","iopub.status.idle":"2021-07-20T05:10:08.984236Z","shell.execute_reply.started":"2021-07-20T05:07:54.532995Z","shell.execute_reply":"2021-07-20T05:10:08.9833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting feature importances based on RFE selection approach\n\nMAX_score = feature_importances[-1:][0][1] + 1\n\nimport importlib\n\nplot_data = {}\n\nfor i in feature_importances:\n    plot_data[i[0]] = MAX_score - i[1] \ncolors = ['red'] * (Qty)    \ncmap = get_cmap(len(plot_data), name = 'autumn')\nfor i in range(Qty, len(plot_data)+1):\n    colors.append(cmap(i))\nplt.figure(figsize=(15,10))   \nplt.bar(plot_data.keys(), plot_data.values(), color = colors)\nplt.xticks(rotation=90)\nplt.title('Feature importance')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:10:08.985362Z","iopub.execute_input":"2021-07-20T05:10:08.985638Z","iopub.status.idle":"2021-07-20T05:10:09.812365Z","shell.execute_reply.started":"2021-07-20T05:10:08.985613Z","shell.execute_reply":"2021-07-20T05:10:09.811642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Determining indices of the features that should be dropped\n\nremoving_idx = []\n\nidx = 0\nfor feature in feature_importances:\n    if feature[1] > 1:\n        removing_idx.append(idx)\n    idx += 1   ","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:10:09.813464Z","iopub.execute_input":"2021-07-20T05:10:09.813812Z","iopub.status.idle":"2021-07-20T05:10:09.818873Z","shell.execute_reply.started":"2021-07-20T05:10:09.813781Z","shell.execute_reply":"2021-07-20T05:10:09.817864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Second model (Random Forest) definition, training and evaluation \n# on the original data (orgData)\n# with optimal hyper parameters\n# using RFE feature selection \n\n[dataCols, X_train, X_test, y_train, y_test] = orgData(Data)\n\nX_train = np.delete(X_train,np.s_[removing_idx],axis=1)\nX_test = np.delete(X_test,np.s_[removing_idx],axis=1)\n\nforest = RandomForestClassifier(n_estimators=80, max_depth=6,random_state=0, \n                                class_weight='balanced', min_samples_split=4, min_samples_leaf=12)\n\nforest, results.at[1, 'orgDataOptimalRFE'] = train_and_evaluate(forest, X_train, y_train, X_test, y_test)\n\nplotROC(forest, X_train, y_train, X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:10:09.820252Z","iopub.execute_input":"2021-07-20T05:10:09.820653Z","iopub.status.idle":"2021-07-20T05:10:11.425818Z","shell.execute_reply.started":"2021-07-20T05:10:09.82062Z","shell.execute_reply":"2021-07-20T05:10:11.424738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:10:11.42744Z","iopub.execute_input":"2021-07-20T05:10:11.427893Z","iopub.status.idle":"2021-07-20T05:10:11.444912Z","shell.execute_reply.started":"2021-07-20T05:10:11.42785Z","shell.execute_reply":"2021-07-20T05:10:11.44378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model # 3: SVM","metadata":{}},{"cell_type":"code","source":"# Third model (SVM) definition, definition, training and evaluation \n# on the original data (orgData)\n# with default hyper parameters\n\n[dataCols, X_train, X_test, y_train, y_test] = orgData(Data)\n\nfrom sklearn.svm import SVC\n\nsvc = SVC(random_state=0, class_weight='balanced')\n\nsvc, results.at[2, 'orgDataDefault'] = train_and_evaluate(svc, X_train, y_train, X_test, y_test)\n\nplotROC(svc, X_train, y_train, X_test, y_test, typ=2)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:10:11.446491Z","iopub.execute_input":"2021-07-20T05:10:11.446934Z","iopub.status.idle":"2021-07-20T05:11:00.665278Z","shell.execute_reply.started":"2021-07-20T05:10:11.446891Z","shell.execute_reply":"2021-07-20T05:11:00.664273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Third model (SVM) definition, training and evaluation \n# on previously selected features (myData)\n# with default hyper parameters\n\n[X_train, X_test, y_train, y_test] = myData(Data)\n\nfrom sklearn.svm import SVC\n\nsvc = SVC(random_state=0, class_weight='balanced')\n\nsvc, results.at[2, 'myColsDefault'] = train_and_evaluate(svc, X_train, y_train, X_test, y_test)\n\nplotROC(svc, X_train, y_train, X_test, y_test, typ=2)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:11:00.666844Z","iopub.execute_input":"2021-07-20T05:11:00.667416Z","iopub.status.idle":"2021-07-20T05:11:40.619616Z","shell.execute_reply.started":"2021-07-20T05:11:00.667367Z","shell.execute_reply":"2021-07-20T05:11:40.618652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# GridSearchCV for tuning the parameters of the third model (SVC)\n# on myCols\n\n[X_train, X_test, y_train, y_test] = myData(Data)\n\nfrom sklearn.svm import SVC\n\nclf = SVC(kernel = 'linear', class_weight='balanced')\n\nparam_grid = {\n    'C' : [0.5, 1],\n    'gamma' : [0.1, 0.2, 0.5]\n}\n\nscorers = {\n    'precision_score': make_scorer(precision_score),\n    'recall_score': make_scorer(recall_score),\n    'accuracy_score': make_scorer(accuracy_score)\n}\n\ngrid_search_clf = grid_search_wrapper(clf, X_train, y_train, X_test, y_test, param_grid, scorers, 'recall_score')","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:11:40.620866Z","iopub.execute_input":"2021-07-20T05:11:40.62118Z","iopub.status.idle":"2021-07-20T05:16:33.823373Z","shell.execute_reply.started":"2021-07-20T05:11:40.621152Z","shell.execute_reply":"2021-07-20T05:16:33.822087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CVresults = pd.DataFrame(grid_search_clf.cv_results_)\nCVresults = CVresults.sort_values(by='mean_test_recall_score', ascending=False)\nCVresults[['mean_test_precision_score', 'mean_test_recall_score',\n         'mean_test_accuracy_score', 'param_C',\n         'param_gamma']].round(3).head(10)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:16:33.824966Z","iopub.execute_input":"2021-07-20T05:16:33.825278Z","iopub.status.idle":"2021-07-20T05:16:33.852245Z","shell.execute_reply.started":"2021-07-20T05:16:33.825247Z","shell.execute_reply":"2021-07-20T05:16:33.850998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Third model (SVM) definition, definition, training and evaluation \n# on the original data (orgData)\n# with optimal hyper parameters\n\n[dataCols, X_train, X_test, y_train, y_test] = orgData(Data)\n\nfrom sklearn.svm import SVC\n\nsvc = SVC(kernel='linear', class_weight='balanced', C=1, random_state=0, gamma=0.1)\n\nsvc, results.at[2, 'orgDataOptimal'] = train_and_evaluate(svc, X_train, y_train, X_test, y_test)\n\nplotROC(svc, X_train, y_train, X_test, y_test, typ=2)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:16:33.853672Z","iopub.execute_input":"2021-07-20T05:16:33.853994Z","iopub.status.idle":"2021-07-20T05:17:02.325092Z","shell.execute_reply.started":"2021-07-20T05:16:33.853964Z","shell.execute_reply":"2021-07-20T05:17:02.323939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Third model (SVM) definition, training and evaluation \n# on previously selected features (myData)\n# with optimal hyper parameters\n\n[X_train, X_test, y_train, y_test] = myData(Data)\n\nfrom sklearn.svm import SVC\n\nsvc = SVC(kernel='linear', class_weight='balanced', C=1, random_state=0, gamma=0.1)\n\nsvc, results.at[2, 'myColsOptimal'] = train_and_evaluate(svc, X_train, y_train, X_test, y_test)\n\nplotROC(svc, X_train, y_train, X_test, y_test, typ=2)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:17:02.326595Z","iopub.execute_input":"2021-07-20T05:17:02.326904Z","iopub.status.idle":"2021-07-20T05:17:25.219821Z","shell.execute_reply.started":"2021-07-20T05:17:02.326865Z","shell.execute_reply":"2021-07-20T05:17:25.218828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Third model (SVM) definition, training and evaluation \n# on the original data (orgData)\n# with optimal hyper parameters\n# using RFE feature selection (on Random Forest) (Running RFE on SVM is too expensive)\n\n\n[dataCols, X_train, X_test, y_train, y_test] = orgData(Data)\n\nX_train = np.delete(X_train,np.s_[removing_idx],axis=1)\nX_test = np.delete(X_test,np.s_[removing_idx],axis=1)\n\n\nsvc = SVC(kernel='linear', class_weight='balanced', C=1, random_state=0, gamma=0.1)\n\nsvc, results.at[2, 'orgDataOptimalRFE'] = train_and_evaluate(svc, X_train, y_train, X_test, y_test)\n\nplotROC(svc, X_train, y_train, X_test, y_test, typ=2)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:17:25.22145Z","iopub.execute_input":"2021-07-20T05:17:25.221897Z","iopub.status.idle":"2021-07-20T05:17:51.20884Z","shell.execute_reply.started":"2021-07-20T05:17:25.221852Z","shell.execute_reply":"2021-07-20T05:17:51.208047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:17:51.209915Z","iopub.execute_input":"2021-07-20T05:17:51.210348Z","iopub.status.idle":"2021-07-20T05:17:51.226063Z","shell.execute_reply.started":"2021-07-20T05:17:51.210317Z","shell.execute_reply":"2021-07-20T05:17:51.225308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model # 4: Extra Trees","metadata":{}},{"cell_type":"code","source":"# Fourth model (Extra Trees Classifier) definition, definition, training and evaluation \n# on the original data (orgData)\n# with default hyper parameters\n\nfrom sklearn.ensemble import ExtraTreesClassifier as ETC\n\n[dataCols, X_train, X_test, y_train, y_test] = orgData(Data)\n\nxTrees = ETC(random_state=0, class_weight = 'balanced')\n\nxTrees, results.at[3, 'orgDataDefault'] = train_and_evaluate(xTrees, X_train, y_train, X_test, y_test)\n\nplotROC(xTrees, X_train, y_train, X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:17:51.227119Z","iopub.execute_input":"2021-07-20T05:17:51.227496Z","iopub.status.idle":"2021-07-20T05:17:54.921755Z","shell.execute_reply.started":"2021-07-20T05:17:51.227468Z","shell.execute_reply":"2021-07-20T05:17:54.920693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fourth model (Extra Trees Classifier) definition, training and evaluation \n# on previously selected features (myData)\n# with default hyper parameters\n\n[X_train, X_test, y_train, y_test] = myData(Data)\n\nxTrees = ETC(random_state=0, class_weight = 'balanced')\n\nxTrees, results.at[3, 'myColsDefault'] = train_and_evaluate(xTrees, X_train, y_train, X_test, y_test)\n\nplotROC(xTrees, X_train, y_train, X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:17:54.923075Z","iopub.execute_input":"2021-07-20T05:17:54.923396Z","iopub.status.idle":"2021-07-20T05:17:57.9878Z","shell.execute_reply.started":"2021-07-20T05:17:54.923365Z","shell.execute_reply":"2021-07-20T05:17:57.986606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# GridSearchCV for tuning the parameters of the fourth model (Extra Trees Classifier)\n# on myCols\n\n[X_train, X_test, y_train, y_test] = myData(Data)\n\nfrom sklearn.ensemble import ExtraTreesClassifier as ETC\n\nclf = ETC(class_weight = 'balanced')\n\nparam_grid = {\n    'n_estimators' : [50, 100, 200],\n    'max_depth' : [5, 10, 15, 20],\n    'min_samples_split': [5, 10, 20], \n    'max_features': ['auto', 'sqrt', 'log2']\n}\n\nscorers = {\n    'precision_score': make_scorer(precision_score),\n    'recall_score': make_scorer(recall_score),\n    'accuracy_score': make_scorer(accuracy_score)\n}\n\ngrid_search_clf = grid_search_wrapper(clf, X_train, y_train, X_test, y_test, param_grid, scorers, 'recall_score')","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:17:57.989338Z","iopub.execute_input":"2021-07-20T05:17:57.989711Z","iopub.status.idle":"2021-07-20T05:23:21.985873Z","shell.execute_reply.started":"2021-07-20T05:17:57.989678Z","shell.execute_reply":"2021-07-20T05:23:21.984661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CVresults = pd.DataFrame(grid_search_clf.cv_results_)\nCVresults = CVresults.sort_values(by='mean_test_recall_score', ascending=False)\nCVresults[['mean_test_precision_score', 'mean_test_recall_score',\n         'mean_test_accuracy_score', 'param_n_estimators',\n         'param_max_depth', 'param_min_samples_split', 'param_max_features']].round(3).head(10)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:23:21.987318Z","iopub.execute_input":"2021-07-20T05:23:21.987689Z","iopub.status.idle":"2021-07-20T05:23:22.018271Z","shell.execute_reply.started":"2021-07-20T05:23:21.987652Z","shell.execute_reply":"2021-07-20T05:23:22.017111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fourth model (Extra Trees Classifier) definition, definition, training and evaluation \n# on the original data (orgData)\n# with optimal hyper parameters\n\nfrom sklearn.ensemble import ExtraTreesClassifier as ETC\n\n[dataCols, X_train, X_test, y_train, y_test] = orgData(Data)\n\nxTrees = ETC(n_estimators=200, max_depth=20, max_features='log2', min_samples_split= 20,\n                               random_state=0, class_weight = 'balanced')\n\nxTrees, results.at[3, 'orgDataOptimal'] = train_and_evaluate(xTrees, X_train, y_train, X_test, y_test)\n\nplotROC(xTrees, X_train, y_train, X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:23:22.019609Z","iopub.execute_input":"2021-07-20T05:23:22.019906Z","iopub.status.idle":"2021-07-20T05:23:27.264037Z","shell.execute_reply.started":"2021-07-20T05:23:22.019878Z","shell.execute_reply":"2021-07-20T05:23:27.262866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fourth model (Extra Trees Classifier) definition, training and evaluation \n# on previously selected features (myData)\n# with optimal hyper parameters\n\n[X_train, X_test, y_train, y_test] = myData(Data)\n\nxTrees = ETC(n_estimators=200, max_depth=20, max_features='log2', min_samples_split= 20,\n                               random_state=0, class_weight = 'balanced')\n\nxTrees, results.at[3, 'myColsOptimal'] = train_and_evaluate(xTrees, X_train, y_train, X_test, y_test)\n\nplotROC(xTrees, X_train, y_train, X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:23:27.265623Z","iopub.execute_input":"2021-07-20T05:23:27.265959Z","iopub.status.idle":"2021-07-20T05:23:31.213079Z","shell.execute_reply.started":"2021-07-20T05:23:27.265926Z","shell.execute_reply":"2021-07-20T05:23:31.211977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fourth model (Extra Trees Classifier) definition, definition, training and evaluation \n# on the original data (orgData)\n# with optimal hyper parameters\n# using RFE feature selection (on Random Forest) (Running RFE on ETC is too expensive)\n\n[dataCols, X_train, X_test, y_train, y_test] = orgData(Data)\n\nX_train = np.delete(X_train,np.s_[removing_idx],axis=1)\nX_test = np.delete(X_test,np.s_[removing_idx],axis=1)\n\nxTrees = ETC(n_estimators=200, max_depth=20, max_features='log2', min_samples_split= 20,\n                               random_state=0, class_weight = 'balanced')\n\nxTrees, results.at[3, 'orgDataOptimalRFE'] = train_and_evaluate(xTrees, X_train, y_train, X_test, y_test)\n\nplotROC(xTrees, X_train, y_train, X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:23:31.214416Z","iopub.execute_input":"2021-07-20T05:23:31.214771Z","iopub.status.idle":"2021-07-20T05:23:35.380445Z","shell.execute_reply.started":"2021-07-20T05:23:31.214742Z","shell.execute_reply":"2021-07-20T05:23:35.379664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:23:35.381628Z","iopub.execute_input":"2021-07-20T05:23:35.382135Z","iopub.status.idle":"2021-07-20T05:23:35.398367Z","shell.execute_reply.started":"2021-07-20T05:23:35.382086Z","shell.execute_reply":"2021-07-20T05:23:35.397421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model # 5: Gradient Boosting","metadata":{}},{"cell_type":"markdown","source":"Gradient Boosting is a sequential process and thus every time it makes an incorrect prediction, it focuses more on that incorrectly predicted data point. So, if the first iteration gave you an accuracy of 80 %, the second iteration would focus on the remaining 20%.","metadata":{}},{"cell_type":"markdown","source":"Since Garient Boosting Classifier has no **class_weight** parameter to be able to handle **class imbalance problem**, we use our balanced data (smoteData) on it:","metadata":{}},{"cell_type":"code","source":"# Fifth model (Gradient Boosting Classifier) definition, definition, training and evaluation \n# on the balanced Data (smoteData)\n# with default hyper parameters\n\nfrom sklearn.ensemble import GradientBoostingClassifier as GBC\n\n[X_train, X_test, y_train, y_test] = smoteData(Data)\n\ngBoosting = GBC(random_state=0)\n\ngBoosting,  results.at[4, 'smoteDataDefault'] = train_and_evaluate(gBoosting, X_train, y_train, X_test, y_test)\n\nplotROC(gBoosting, X_train, y_train, X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:23:35.400015Z","iopub.execute_input":"2021-07-20T05:23:35.400495Z","iopub.status.idle":"2021-07-20T05:23:51.350145Z","shell.execute_reply.started":"2021-07-20T05:23:35.400441Z","shell.execute_reply":"2021-07-20T05:23:51.349118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# GridSearchCV for tuning the parameters of the fifth model (Gradient Boosting Classifier)\n# on smoteData\n\n[X_train, X_test, y_train, y_test] = smoteData(Data)\n\nfrom sklearn.ensemble import GradientBoostingClassifier as GBC\n\nstage = 4\n\nif stage == 1:\n    # In order to decide on boosting parameters, we need to set some 'initial values' of other parameters.\n    # all of these values are just initial estimates and will be tuned later.\n    # min_samples_split => 0.5~1% of total samples\n    # min_sample_leaf = 50 => selected based on intuition\n    # max_depth = 5 => Should be chosen (5-8) based on the number of samples and features\n    # max_featres = 'sqrt'\n    # subsample = 0.8 => commonly used start value\n    # random_state = 10 => shoulb be always the same for keeping he results comparible in different executions\n    # learning_rate = 0.1 => default value\n    \n    # Here, we try to choose some initial values for parameters that do not decrease the recall score that we had\n    # with the default values of the parameters\n    clf = GBC(min_samples_split=200, min_samples_leaf=20, max_depth=5, max_features='sqrt',  \n                subsample=0.8, random_state=10, learning_rate=0.1)\n    \n    # Now, we check the optimum number of trees. \n    # For this purpose, we can do a grid search and test out values from 20 to 100 in steps of 10.\n    param_grid = {\n        'n_estimators' : range(20,201,10) # 150\n    }\n\n    scorers = {\n        'precision_score': make_scorer(precision_score),\n        'recall_score': make_scorer(recall_score, greater_is_better=False),\n        'accuracy_score': make_scorer(accuracy_score)\n    }\n\n    grid_search_clf = grid_search_wrapper(clf, X_train, y_train, X_test, y_test, param_grid, scorers, 'recall_score')\n    \nif stage == 2:\n    # Tuning tree-specific parameters, The order of tuning variables should be decided carefully.\n    # We should take the variables with a higher impact on outcome first.\n    clf = GBC(learning_rate=0.1, n_estimators=90, max_features='sqrt', subsample=0.8, random_state=10)\n\n    param_grid = {\n        'max_depth' : range(5,16,5), # 5\n    }\n\n    scorers = {\n        'precision_score': make_scorer(precision_score),\n        'recall_score': make_scorer(recall_score, greater_is_better=False),\n        'accuracy_score': make_scorer(accuracy_score)\n    }\n\n    grid_search_clf = grid_search_wrapper(clf, X_train, y_train, X_test, y_test, param_grid, scorers, 'recall_score')\n    \nif stage == 3: \n    clf = GBC(max_depth=5, learning_rate=0.1, n_estimators=90,\n              max_features='sqrt', subsample=0.8, random_state=10)\n\n    param_grid = {\n        'min_samples_split' : range(200,1001,200), #300\n        'min_samples_leaf' : range(30,71,10) # 50\n    }\n\n    scorers = {\n        'precision_score': make_scorer(precision_score),\n        'recall_score': make_scorer(recall_score, greater_is_better=False),\n        'accuracy_score': make_scorer(accuracy_score)\n    }\n\n    grid_search_clf = grid_search_wrapper(clf, X_train, y_train, X_test, y_test, param_grid, scorers, 'recall_score') \n       \nif stage == 4: \n    clf = GBC(max_features='sqrt', min_samples_leaf= 50, min_samples_split=400, max_depth=5, learning_rate=0.1, n_estimators=90\n              , random_state=10)\n\n    param_grid = {\n        'subsample' : [0.6,0.7,0.75,0.8,0.85,0.9] # 0.75\n    }\n\n    scorers = {\n        'precision_score': make_scorer(precision_score),\n        'recall_score': make_scorer(recall_score, greater_is_better=False),\n        'accuracy_score': make_scorer(accuracy_score)\n    }\n\n    grid_search_clf = grid_search_wrapper(clf, X_train, y_train, X_test, y_test, param_grid, scorers, 'recall_score') \n    ","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:23:51.351618Z","iopub.execute_input":"2021-07-20T05:23:51.351926Z","iopub.status.idle":"2021-07-20T05:24:29.611938Z","shell.execute_reply.started":"2021-07-20T05:23:51.351895Z","shell.execute_reply":"2021-07-20T05:24:29.610603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CVresults = pd.DataFrame(grid_search_clf.cv_results_)\nCVresults = CVresults.sort_values(by='mean_test_recall_score', ascending=False)\nCVresults[['mean_test_precision_score', 'mean_test_recall_score',\n         'mean_test_accuracy_score', 'param_subsample']].round(3)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:24:29.613764Z","iopub.execute_input":"2021-07-20T05:24:29.614219Z","iopub.status.idle":"2021-07-20T05:24:29.637397Z","shell.execute_reply.started":"2021-07-20T05:24:29.61417Z","shell.execute_reply":"2021-07-20T05:24:29.636049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fifth model (Gradient Boosting Classifier) definition, definition, training and evaluation \n# on the balanced Data (smoteData)\n# with optimal hyper parameters\n\n[X_train, X_test, y_train, y_test] = smoteData(Data)\n\ngBoosting = GBC(max_features='sqrt', min_samples_leaf= 50, min_samples_split=300, max_depth=5, learning_rate=0.01\n                , n_estimators=150, subsample=0.75, random_state=10)\n\ngBoosting,  results.at[4, 'smoteDataOptimal'] = train_and_evaluate(gBoosting, X_train, y_train, X_test, y_test)\n\nplotROC(gBoosting, X_train, y_train, X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:24:29.638896Z","iopub.execute_input":"2021-07-20T05:24:29.639234Z","iopub.status.idle":"2021-07-20T05:24:36.358752Z","shell.execute_reply.started":"2021-07-20T05:24:29.6392Z","shell.execute_reply":"2021-07-20T05:24:36.357525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fifth model (Gradient Boosting Classifier) definition, training and evaluation \n# on the balanced Data (smoteData)\n# with optimal hyper parameters\n# using RFE feature selection (on Random Forest) (Running RFE on Gradient Boosting Classifier is too expensive)\n\n[X_train, X_test, y_train, y_test] = smoteData(Data)\n\nX_train = np.delete(X_train,np.s_[removing_idx],axis=1)\nX_test = np.delete(X_test,np.s_[removing_idx],axis=1)\n\ngBoosting = GBC(max_features='sqrt', min_samples_leaf= 50, min_samples_split=300, max_depth=5, learning_rate=0.01\n                , n_estimators=150, subsample=0.75, random_state=10)\n\ngBoosting,  results.at[4, 'smoteDataOptimalRFE'] = train_and_evaluate(gBoosting, X_train, y_train, X_test, y_test)\n\nplotROC(gBoosting, X_train, y_train, X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:24:36.36078Z","iopub.execute_input":"2021-07-20T05:24:36.361237Z","iopub.status.idle":"2021-07-20T05:24:42.699749Z","shell.execute_reply.started":"2021-07-20T05:24:36.361189Z","shell.execute_reply":"2021-07-20T05:24:42.69888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:24:42.701116Z","iopub.execute_input":"2021-07-20T05:24:42.701706Z","iopub.status.idle":"2021-07-20T05:24:42.717612Z","shell.execute_reply.started":"2021-07-20T05:24:42.701665Z","shell.execute_reply":"2021-07-20T05:24:42.716615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model # 6: XGBoost","metadata":{}},{"cell_type":"markdown","source":"Since XGBoost Classifier has no **class_weight** parameter to be able to handle **class imbalance problem**, we use our balanced data (smoteData) on it:","metadata":{}},{"cell_type":"code","source":"# Sixth model (Xgboost) definition, definition, training and evaluation \n# on the balanced Data (smoteData)\n# with default hyper parameters\n\nfrom xgboost import XGBClassifier\n\n[X_train, X_test, y_train, y_test] = smoteData(Data)\n\nxgb = XGBClassifier(random_state=0)\n\nxgb,  results.at[5, 'smoteDataDefault'] = train_and_evaluate(xgb, X_train, y_train, X_test, y_test)\n\nplotROC(xgb, X_train, y_train, X_test, y_test)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-07-20T05:24:42.718911Z","iopub.execute_input":"2021-07-20T05:24:42.719239Z","iopub.status.idle":"2021-07-20T05:24:49.724184Z","shell.execute_reply.started":"2021-07-20T05:24:42.719209Z","shell.execute_reply":"2021-07-20T05:24:49.722504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# GridSearchCV for tuning the parameters of the sixth model (XGBoost Classifier)\n# on the balanced Data (smoteData)\n\n[X_train, X_test, y_train, y_test] = smoteData(Data)\n\nfrom xgboost import XGBClassifier\n\nstage = 6\n\nif stage == 1:\n    # In order to decide on boosting parameters, we need to set some 'initial values' of other parameters.\n    # all of these values are just initial estimates and will be tuned later.\n    \n    # Here, we try to choose some initial values for parameters that do not decrease the recall score that we had\n    # with the default values of the parameters\n    clf = XGBClassifier(objective= 'binary:logistic', random_state=0)\n    \n    # Now, we check the optimum number of trees. \n    # For this purpose, we can do a grid search and test out values from 20 to 100 in steps of 20.\n    param_grid = {\n        'n_estimators' : range(10, 101, 20) # 90\n    }\n\n    scorers = {\n        'precision_score': make_scorer(precision_score),\n        'recall_score': make_scorer(recall_score),\n        'accuracy_score': make_scorer(accuracy_score)\n    }\n\n    grid_search_clf = grid_search_wrapper(clf, X_train, y_train, X_test, y_test, param_grid, scorers, 'recall_score')\n    \nif stage == 2:\n    # Tuning tree-specific parameters, The order of tuning variables should be decided carefully.\n    # We should take the variables with a higher impact on outcome first.\n    clf = XGBClassifier(objective= 'binary:logistic', n_estimators=90)\n\n    param_grid = {\n        'max_depth' : range(2,10,1) # 2\n    }\n\n    scorers = {\n        'precision_score': make_scorer(precision_score),\n        'recall_score': make_scorer(recall_score, greater_is_better=False),\n        'accuracy_score': make_scorer(accuracy_score)\n    }\n\n    grid_search_clf = grid_search_wrapper(clf, X_train, y_train, X_test, y_test, param_grid, scorers, 'recall_score')\n    \nif stage == 3: \n    clf = XGBClassifier(objective= 'binary:logistic',  n_estimators=90, max_depth=2)\n\n    param_grid = {\n        'min_child_weight':range(1,10,1) # No difference (default value works well, do not add this parameter)\n    }\n\n    scorers = {\n        'precision_score': make_scorer(precision_score),\n        'recall_score': make_scorer(recall_score, greater_is_better=False),\n        'accuracy_score': make_scorer(accuracy_score)\n    }\n\n    grid_search_clf = grid_search_wrapper(clf, X_train, y_train, X_test, y_test, param_grid, scorers, 'recall_score') \n       \nif stage == 4: \n    clf = XGBClassifier(objective= 'binary:logistic',  n_estimators=90, max_depth=2)\n\n    param_grid = {\n        'gamma':[i/10.0 for i in range(0,5)] # No difference (default value works well, do not add this parameter)\n    }\n\n    scorers = {\n        'precision_score': make_scorer(precision_score),\n        'recall_score': make_scorer(recall_score),\n        'accuracy_score': make_scorer(accuracy_score)\n    }\n\n    grid_search_clf = grid_search_wrapper(clf, X_train, y_train, X_test, y_test, param_grid, scorers, 'recall_score') \n \nif stage == 5: \n    clf = XGBClassifier(objective= 'binary:logistic',  n_estimators=90, max_depth=2)\n\n    param_grid = {\n        #'subsample':[i/10.0 for i in range(6,10)], # No difference (default value works well, do not add this parameter)\n        'colsample_bytree':[i/10.0 for i in range(6,10)] # 0.6\n    }\n\n    scorers = {\n        'precision_score': make_scorer(precision_score),\n        'recall_score': make_scorer(recall_score, greater_is_better=False),\n        'accuracy_score': make_scorer(accuracy_score)\n    }\n\n    grid_search_clf = grid_search_wrapper(clf, X_train, y_train, X_test, y_test, param_grid, scorers, 'recall_score')\n    \nif stage == 6: \n    clf = XGBClassifier(objective= 'binary:logistic',  n_estimators=90, max_depth=2, colsample_bytree=0.6)\n\n    param_grid = {\n        'reg_alpha':[0, 0.001, 0.005, 0.01, 0.05] # 0.05\n    }\n\n    scorers = {\n        'precision_score': make_scorer(precision_score),\n        'recall_score': make_scorer(recall_score),\n        'accuracy_score': make_scorer(accuracy_score)\n    }\n\n    grid_search_clf = grid_search_wrapper(clf, X_train, y_train, X_test, y_test, param_grid, scorers, 'recall_score')  ","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:24:49.72556Z","iopub.execute_input":"2021-07-20T05:24:49.725858Z","iopub.status.idle":"2021-07-20T05:27:32.333009Z","shell.execute_reply.started":"2021-07-20T05:24:49.72583Z","shell.execute_reply":"2021-07-20T05:27:32.332144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CVresults = pd.DataFrame(grid_search_clf.cv_results_)\nCVresults = CVresults.sort_values(by='mean_test_recall_score', ascending=False)\nCVresults[['mean_test_precision_score', 'mean_test_recall_score',\n         'mean_test_accuracy_score', 'param_reg_alpha']].round(3)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:27:32.334452Z","iopub.execute_input":"2021-07-20T05:27:32.335026Z","iopub.status.idle":"2021-07-20T05:27:32.357447Z","shell.execute_reply.started":"2021-07-20T05:27:32.334989Z","shell.execute_reply":"2021-07-20T05:27:32.356764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sixth model (Xgboost) definition, training and evaluation \n# on the balanced Data (smoteData)\n# with optimal hyper parameters\n# increasing reg_alpha from 0.05 to 2 without recall loss to force classifier to do more feature selection\n\nfrom xgboost import XGBClassifier\n\n[X_train, X_test, y_train, y_test] = smoteData(Data)\n\nxgb = XGBClassifier(objective= 'binary:logistic',  n_estimators=90, max_depth=2, colsample_bytree=0.6, reg_alpha=2\n                   , learning_rate=0.011)\n\nxgb,  results.at[5, 'smoteDataOptimal'] = train_and_evaluate(xgb, X_train, y_train, X_test, y_test)\n\nplotROC(xgb, X_train, y_train, X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:27:32.35862Z","iopub.execute_input":"2021-07-20T05:27:32.359074Z","iopub.status.idle":"2021-07-20T05:27:34.367259Z","shell.execute_reply.started":"2021-07-20T05:27:32.359043Z","shell.execute_reply":"2021-07-20T05:27:34.363221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sixth model (Xgboost) definition, training and evaluation \n# on the balanced Data (smoteData)\n# with optimal hyper parameters\n# using RFE feature selection (on Random Forest) (Running RFE on Xgboost classifier is too expensive)\n\n[X_train, X_test, y_train, y_test] = smoteData(Data)\n\nX_train = np.delete(X_train,np.s_[removing_idx],axis=1)\nX_test = np.delete(X_test,np.s_[removing_idx],axis=1)\n\nxgb = XGBClassifier(objective= 'binary:logistic',  n_estimators=90, max_depth=2, colsample_bytree=0.6, reg_alpha=2\n                   , learning_rate=0.011)\n\ngBoosting,  results.at[5, 'smoteDataOptimalRFE'] = train_and_evaluate(xgb, X_train, y_train, X_test, y_test)\n\nplotROC(xgb, X_train, y_train, X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:27:34.369277Z","iopub.execute_input":"2021-07-20T05:27:34.369762Z","iopub.status.idle":"2021-07-20T05:27:36.029999Z","shell.execute_reply.started":"2021-07-20T05:27:34.369717Z","shell.execute_reply":"2021-07-20T05:27:36.02901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:27:36.031332Z","iopub.execute_input":"2021-07-20T05:27:36.031628Z","iopub.status.idle":"2021-07-20T05:27:36.047451Z","shell.execute_reply.started":"2021-07-20T05:27:36.031592Z","shell.execute_reply":"2021-07-20T05:27:36.046353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Running the best Model on the test data:","metadata":{}},{"cell_type":"code","source":"# reading the test data from csv file:\ntData = pd.read_csv('../input/marketing-campaign-analysis-data/test.csv')\ntData.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:27:36.049189Z","iopub.execute_input":"2021-07-20T05:27:36.049666Z","iopub.status.idle":"2021-07-20T05:27:36.143149Z","shell.execute_reply.started":"2021-07-20T05:27:36.049622Z","shell.execute_reply":"2021-07-20T05:27:36.142075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dropping the 'Zilevariable' that has no data:\ntData.drop(['target'], axis=1, inplace=True);","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:27:36.144447Z","iopub.execute_input":"2021-07-20T05:27:36.144749Z","iopub.status.idle":"2021-07-20T05:27:36.151732Z","shell.execute_reply.started":"2021-07-20T05:27:36.144722Z","shell.execute_reply":"2021-07-20T05:27:36.150578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tData.info()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:27:36.153024Z","iopub.execute_input":"2021-07-20T05:27:36.153315Z","iopub.status.idle":"2021-07-20T05:27:36.188718Z","shell.execute_reply.started":"2021-07-20T05:27:36.153289Z","shell.execute_reply":"2021-07-20T05:27:36.187756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Next, we take a look to see if there is any missing data in our Training data:\nmissing_data = pd.DataFrame({'total_missing': tData.isnull().sum(), 'perc_missing': (tData.isnull().sum()/len(tData))*100}).round(2)\n\n# Print some summary information\nprint (\"Our dataframe has \" + str(tData.shape[1]) + \" column(s).\\n\"\n        \"There is/are \" + str(len(missing_data.loc[missing_data['total_missing'] > 0])) +\n              \" column(s) that has/have missing values.\")\nmissing_data","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:27:36.189941Z","iopub.execute_input":"2021-07-20T05:27:36.190241Z","iopub.status.idle":"2021-07-20T05:27:36.239678Z","shell.execute_reply.started":"2021-07-20T05:27:36.190213Z","shell.execute_reply":"2021-07-20T05:27:36.238703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tData['daySinceLastCampaign'].fillna(-1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:27:36.240833Z","iopub.execute_input":"2021-07-20T05:27:36.24119Z","iopub.status.idle":"2021-07-20T05:27:36.245864Z","shell.execute_reply.started":"2021-07-20T05:27:36.24116Z","shell.execute_reply":"2021-07-20T05:27:36.244834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"missing_data = pd.DataFrame({'total_missing': tData.isnull().sum(), 'perc_missing': (tData.isnull().sum()/len(tData))*100}).round(2)\nmissing_data","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:27:36.24755Z","iopub.execute_input":"2021-07-20T05:27:36.248132Z","iopub.status.idle":"2021-07-20T05:27:36.296949Z","shell.execute_reply.started":"2021-07-20T05:27:36.248082Z","shell.execute_reply":"2021-07-20T05:27:36.295844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Monat one-hot Encoding ###\n\n# Get one hot encoding of columns 'Monat'\nmonth_one_hot = pd.get_dummies(tData.month)\n# Drop column 'Monat' as it is now encoded\ntData.drop('month',axis = 1, inplace=True)\n# Join the encoded Monat fields\ntData = tData.join(month_one_hot)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:27:36.298419Z","iopub.execute_input":"2021-07-20T05:27:36.298831Z","iopub.status.idle":"2021-07-20T05:27:36.313044Z","shell.execute_reply.started":"2021-07-20T05:27:36.29879Z","shell.execute_reply":"2021-07-20T05:27:36.312122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"###  one-hot encoding of the fields:\n### 'job', 'maritalStatus', 'education', 'contactType' & 'lastCampaignResult'\n\n# make a difference between 'job_unknown', 'education_unknown' and 'contactType_unknown'\ntData.loc[tData['job'] == 'unknown', 'job'] = 'job_unknown'\ntData.loc[tData['education'] == 'unknown', 'education'] = 'education_unknown'\ntData.loc[tData['contactType'] == 'unknown', 'contactType'] = 'contactType_unknown'\n\n# for more clarification of values in 'lastCampaignResult' field we change them as follows\ntData.loc[tData['lastCampaignResult'] == 'unknown', 'lastCampaignResult'] = 'lastCampaignResult_unknown'\ntData.loc[tData['lastCampaignResult'] == 'failure', 'lastCampaignResult'] = 'lastCampaignResult_failure'\ntData.loc[tData['lastCampaignResult'] == 'other'  , 'lastCampaignResult'] = 'lastCampaignResult_other'\ntData.loc[tData['lastCampaignResult'] == 'success', 'lastCampaignResult'] = 'lastCampaignResult_success'\n\n\ncolumns = ['job', 'maritalStatus', 'education', 'contactType', 'lastCampaignResult']\n\nfor col in columns: \n    # Get one hot encoding of the column\n    col_one_hot = pd.get_dummies(tData[col])\n    # Drop column as it is now encoded\n    tData.drop(col,axis = 1, inplace=True)\n    # Join the encoded Monat fields\n    tData = tData.join(col_one_hot)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:27:36.31446Z","iopub.execute_input":"2021-07-20T05:27:36.314751Z","iopub.status.idle":"2021-07-20T05:27:36.388672Z","shell.execute_reply.started":"2021-07-20T05:27:36.314724Z","shell.execute_reply":"2021-07-20T05:27:36.387717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Variable Encoding of the fields 'gender', 'creditFailure', 'credit', 'house' as we did for 'target' before\n\nGeschlecht_conversion = {\"gender\": {\"female\": 0, \"male\": 1}} \ntData.replace(Geschlecht_conversion, inplace=True)\n\ncolumns = ['creditFailure', 'credit', 'house']\n\nfor col in columns: \n    conversion = {col: {\"no\": 0, \"yes\": 1}} \n    tData.replace(conversion, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:27:36.389863Z","iopub.execute_input":"2021-07-20T05:27:36.390126Z","iopub.status.idle":"2021-07-20T05:27:36.438056Z","shell.execute_reply.started":"2021-07-20T05:27:36.390101Z","shell.execute_reply":"2021-07-20T05:27:36.437125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dropping ID-like columns\nIDs = tData['id']\ntData.drop(['id'], axis = 1, inplace = True)\ntData.drop(['contactId'], axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:27:36.441406Z","iopub.execute_input":"2021-07-20T05:27:36.441711Z","iopub.status.idle":"2021-07-20T05:27:36.450335Z","shell.execute_reply.started":"2021-07-20T05:27:36.441683Z","shell.execute_reply":"2021-07-20T05:27:36.449527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# removing multi colinear features\ntData.drop(['uniGraduated'], axis = 1, inplace = True)\ntData.drop(['lastCampaignResult_unknown'], axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:27:36.452018Z","iopub.execute_input":"2021-07-20T05:27:36.452439Z","iopub.status.idle":"2021-07-20T05:27:36.460558Z","shell.execute_reply.started":"2021-07-20T05:27:36.4524Z","shell.execute_reply":"2021-07-20T05:27:36.459708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# applying the same normalizazion process on the test data\n\ntCols = tData.columns\n\ntData = scaler.transform(tData)\n\ntData = pd.DataFrame(tData, columns=tCols);","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:27:36.462141Z","iopub.execute_input":"2021-07-20T05:27:36.462601Z","iopub.status.idle":"2021-07-20T05:27:36.477506Z","shell.execute_reply.started":"2021-07-20T05:27:36.462535Z","shell.execute_reply":"2021-07-20T05:27:36.476508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# decreasing binary features type accuracy for a more efficient memory usage\nfor col in tData.columns:\n    if len(tData[col].unique()) == 2:\n        tData[col]= tData[col].astype('uint8') ","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:27:36.478923Z","iopub.execute_input":"2021-07-20T05:27:36.479213Z","iopub.status.idle":"2021-07-20T05:27:36.534558Z","shell.execute_reply.started":"2021-07-20T05:27:36.479186Z","shell.execute_reply":"2021-07-20T05:27:36.533597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preparing the best experienced model\nmodel = RandomForestClassifier(n_estimators=80, max_depth=6,random_state=0, \n                                class_weight='balanced', min_samples_split=4, min_samples_leaf=12)\n\n# data preparation\n[dataCols, X_train, X_test, y_train, y_test] = orgData(Data)\n\n# training the model\nmodel.fit(X_train,y_train)\n\n# recheck the model performance on the training data\ny_pred = model.predict(X_test)\nplot_confusion_matrix(y_test, y_pred, classes=np.array(['yes', 'no']), normalize=True)\nplt.grid(None)\nprint('\\n', classification_report(y_test, y_pred, target_names=np.array(['yes', 'no']), labels = [1, 0]))\n\nprint(\"Dimensions of training data: {}\" .format(X_train.shape))\n\nrecall = recall_score(y_test, y_pred)\nprint(\"Recall: %.2f%%\" % (recall * 100.0))\n\nplotROC(model, X_train, y_train, X_test, y_test)\n\ncheckThresh(model, X_test, y_test, typ = 1, prt=0)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:27:36.535901Z","iopub.execute_input":"2021-07-20T05:27:36.536302Z","iopub.status.idle":"2021-07-20T05:27:39.041575Z","shell.execute_reply.started":"2021-07-20T05:27:36.536262Z","shell.execute_reply":"2021-07-20T05:27:39.040638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Taking the probabilities of the test data\nfinalProbs = model.predict_proba(tData)\n\n# taking the probabilities of the second label (positive answer of the customers to the campaign)\nres = finalProbs[:,1]\n\n# Stammnummer of the test samples\nIDs_ = IDs.values\n\n# creating a dataframe, saving the information inside it and save it into a csv file\ntOutput = pd.DataFrame(columns=['ID', 'Expected'])\ntOutput['ID'] = IDs_\ntOutput['Expected'] = res\ntOutput.to_csv('tOutput.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T05:27:39.044461Z","iopub.execute_input":"2021-07-20T05:27:39.044763Z","iopub.status.idle":"2021-07-20T05:27:39.208056Z","shell.execute_reply.started":"2021-07-20T05:27:39.044734Z","shell.execute_reply":"2021-07-20T05:27:39.206971Z"},"trusted":true},"execution_count":null,"outputs":[]}]}