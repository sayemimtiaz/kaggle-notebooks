{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Import necessary libraries"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom scipy import stats\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Read Input file"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read CSV file\ndata = pd.read_csv(\"/kaggle/input/ibm-hr-analytics-attrition-dataset/WA_Fn-UseC_-HR-Employee-Attrition.csv\")\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Identify NA Values (if any)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Identify NULL Values if any\ndata.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Identify Columns which can be removed"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Observations - \n\n\n* Constant data Columns (Can be removed) - EmployeeCount, StandardHours\n* Category-type variables - EnvironmentSatisfaction, JobInvolvement, JobLevel, RelationshipSatisfaction, WorkLifeBalance\n* Unique Identifiers - EmployeeNumber\n\nNow let's check for categorical variables if they have uniqueness or not:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check Unique Values for Categorical data\nprint('Unique Attrition Values: ' + str(data.Attrition.unique()) + '\\n')\nprint('Unique Business Travel Values: ' + str(data.BusinessTravel.unique()) + '\\n')\nprint('Unique Dept Values: ' + str(data.Department.unique()) + '\\n')\nprint('Unique Education Field Values: ' + str(data.EducationField.unique()) + '\\n')\nprint('Unique Gender Values: ' + str(data.Gender.unique()) + '\\n')\nprint('Unique Job Role Values: ' + str(data.JobRole.unique()) + '\\n')\nprint('Unique Marital Status Values: ' + str(data.MaritalStatus.unique()) + '\\n')\nprint('Unique Over18 Values: ' + str(data.Over18.unique()) + '\\n')\nprint('Unique OverTime Values: ' + str(data.OverTime.unique()) + '\\n')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Observations - \n\n* Constant data Columns (Can be removed) - Over18\n* Can be converted from Categorical - Numerical - Attrition, BusinessTravel, Dept, Gender, MaritalStatus, OverTime\n\n"},{"metadata":{},"cell_type":"markdown","source":"### Remove unnecessary columns & identify the total no. of remaining columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove unnecessary columns\ndata.drop(columns=[\"EmployeeCount\", \"StandardHours\", \"Over18\", \"EmployeeNumber\"], inplace=True)\ndata.shape  # Now we have 31 columns only","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Replace Categorical - Numerical (wherever needed)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert Columns - Attrition, BusinessTravel, Dept, Gender, MaritalStatus, OverTime\ndata.Attrition.replace({'Yes': 1, 'No': 0}, inplace=True)\ndata.BusinessTravel.replace({'Non-Travel': 0, 'Travel_Rarely': 1, 'Travel_Frequently': 2}, inplace=True)\ndata.Department.replace({'Sales': 0, 'Research & Development': 1, 'Human Resources': 2}, inplace=True)\ndata.Gender.replace({'Female': 0, 'Male': 1}, inplace=True)\ndata.MaritalStatus.replace({'Single': 0,'Married': 1, 'Divorced': 2}, inplace=True)\ndata.OverTime.replace({'No': 0, 'Yes': 1}, inplace=True)\ndata.EducationField.replace({'Life Sciences': 0, 'Medical': 1, 'Marketing': 2, 'Technical Degree': 3, 'Human Resources': 4, 'Other': 5}, inplace=True)\ndata.JobRole.replace({\n    'Sales Executive': 0, \n    'Research Scientist': 1, \n    'Laboratory Technician': 2,\n    'Manufacturing Director': 3,\n    'Healthcare Representative': 4,\n    'Manager': 5,\n    'Sales Representative': 6,\n    'Research Director': 7,\n    'Human Resources': 8\n}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Describe our data and confirm whether changes are reflected"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploratory Data Analysis"},{"metadata":{},"cell_type":"markdown","source":"Identify Difference between mean and median values.\n[This helps to understand whether columns are skewed or not]"},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = None\ntemp = pd.DataFrame({\n    \"Median Values\": data.median(), \n    \"Mean Values\": data.mean(), \n    \"Standard Deviation\": data.std(),\n    \"Skewness\": data.skew() # Ideal range: -1 to +1\n})\n\n# Sort values based on skewness\ntemp = temp.sort_values(by='Skewness')\n\ntemp.head(50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Let us identify whether our target variable is biased or not. If yes, then by how much"},{"metadata":{"trusted":true},"cell_type":"code","source":"total_rows = data.shape[0]\nno_val = data.Attrition.value_counts()[0]\nyes_val = data.Attrition.value_counts()[1]\nprint('Percentage of NO Values: ' + str((no_val/total_rows) * 100))\nprint('Percentage of YES Values: ' + str((yes_val/total_rows) * 100))\n\nplt.figure(figsize = (7, 7))\nplt.pie([yes_val, no_val], labels=['YES', 'NO'], autopct='%1.0f%%', colors = ['lightgreen','#66b3ff'])\nplt.title(\"Observed Class Imbalance in Attrition values\", fontsize=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Let us identify whether our dataset is gender biased or not. If yes, then by how much"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data.Gender.value_counts())\n\ntotal = data.Gender.value_counts()[0] + data.Gender.value_counts()[1]\nper_men_data = (data.Gender.value_counts()[1] / total) * 100 \nper_women_data = (data.Gender.value_counts()[0] / total) * 100 \n\nplt.figure(figsize = (7, 7))\nplt.pie([per_men_data, per_women_data], labels=['Men', 'Women'], autopct='%1.0f%%')\nplt.title('Gender wise Data Biasness', fontsize=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Women are not willing to switch jobs more often as men do. Also, their work-life balance is very low as compared to men."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8, 5))\nax = sns.barplot(x = data.Gender , y = data.WorkLifeBalance, estimator = np.sum, hue = data.Attrition)\nax.set_xticklabels(('Women', 'Men'))\nplt.title('How Worklife Balance affects Attrition Rate')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Married people have a maximum Work-Life Balance rate than others."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8, 5))\nax = sns.barplot(x = data.Gender , y = data.WorkLifeBalance, estimator = np.sum, hue = data.MaritalStatus)\nax.set_xticklabels(('Women', 'Men'))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### More men do Business Travels than women. Also, as seen above their Work-Life Balance is higher than women."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8, 5))\nax = sns.barplot(x = data.Gender , y = data.BusinessTravel, estimator = np.sum, hue = data.Attrition)\nax.set_xticklabels(('Women', 'Men'))\nplt.title('How Business Travel affects Attrition Rate')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Let's see how Age affects Attrition Rate:\n* Women within 25-35 age have more attrition rate, whereas men show higher attrition rates until late 40s\n* Later, it is only after women reach their 50s, they show higher attrition rates and start switching jobs"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nax = sns.boxplot(x=data.Gender, y=data.Age, hue=data.Attrition, data=data, linewidth=2.5)\nax.set_xticklabels(('Women', 'Men'))\nplt.title('Age-wise Attrition Rate')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Attrition Rate is higher in people who are Non-Business Travelers  and who stay far from office"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nplt.title('How Distance from Home affects Attrition Rate')\nax = sns.barplot(x = data.BusinessTravel , y = data.DistanceFromHome, estimator = np.median, hue = data.Attrition, palette='Set1')\nax.set_xticklabels(('Non-Travel', 'Travel_Rarely', 'Travel_Frequently'))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Sales Dept has lowest employee retention rate, since most attrition rate is observed in this dept.\n* R&D Dept has the highest employee retention rate, since least attrition rate is seen in this dept."},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nplt.title('Department wise Attrition Rate')\nax = sns.barplot(x=data.Department, y=data.JobRole, hue=data.Attrition, orient='v', palette='Set2')\nax.set_xticklabels(('Sales', 'Research & Development', 'Human Resources'))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Sales Employees have the highest paid Jobs\n* R&D Dept Employees have mid-pay jobs\n* The lesser the Salaries, the more their Attrition Rate\n* The amount of people residing in the higher-salary segment are more in Sales Dept and least in the R&D Dept"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nax = sns.boxplot(x=data.Department, y=data.MonthlyIncome, hue=data.Attrition, data=data, linewidth=2.5, palette='Set2')\nax.set_xticklabels(('Sales', 'Research & Development', 'Human Resources'))\nplt.title('Department wise Monthly Income')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Identifying Correlation furthermore using Correlation plot"},{"metadata":{},"cell_type":"markdown","source":"### Observations - \n\n* Job-Level, Monthly Income increases as Age and the total number of working years (i.e. Work Experience) increases.\n* The more the amount of Over Time employees do, that more their chances of switching jobs\n* Salary Hike is observed the most among those who have the highest performance ratings"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(30, 20))\nplt.title('Correlation between variables')\nsns.heatmap(data.corr(), annot=True, cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Development"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ndata_x = data.iloc[:, 0:30]\ndata_y = data.iloc[:, 1]\n\ndata_x.drop(columns=[\"Attrition\"], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Resolving Target Class Imbalance using SMOTE"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_x_train, data_x_test, data_y_train, data_y_test = train_test_split(data_x, data_y, test_size = .2, random_state=20)\nprint(\"-----------------------\")\nprint(data_x_train.shape)\nprint(data_y_train.shape)\nprint(\"-----------------------\")\nprint(data_x_test.shape)\nprint(data_y_test.shape)\nprint(\"-----------------------\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Before OverSampling, counts of label '1': {}\".format(sum(data_y_train == 1))) \nprint(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(data_y_train == 0))) \n  \n# import SMOTE module from imblearn library \nfrom imblearn.over_sampling import SMOTE\n\nsm = SMOTE(random_state=0)\noversampled_x_train, oversampled_y_train = sm.fit_resample(data_x_train, data_y_train)\n\nprint(\"After OverSampling, the shape of oversampled_x_train: {}\".format(oversampled_x_train.shape))\nprint(\"After OverSampling, the shape of oversampled_y_train: {} \\n\".format(oversampled_y_train.shape))\n  \nprint(\"After OverSampling, counts of label '1': {}\".format(sum(oversampled_y_train == 1))) \nprint(\"After OverSampling, counts of label '0': {}\".format(sum(oversampled_y_train == 0))) \n\noversampled_y_train = pd.Series(oversampled_y_train)\n\n\n# Plot on a Pie chart\ntotal_rows = data.shape[0]\n\nplt.figure(figsize = (7, 7))\nplt.pie([sum(oversampled_y_train == 1), sum(oversampled_y_train == 0)], labels=['YES', 'NO'], autopct='%1.0f%%', colors = ['lightgreen','#66b3ff'])\nplt.title(\"Resolved Class Imbalance in Attrition values\", fontsize=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"oversampled_x_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlog_reg = LogisticRegression(class_weight='balanced')\n\nlog_reg.fit(oversampled_x_train, oversampled_y_train)\n\n# Predict values based on this fittest model\nlog_pred = log_reg.predict(data_x_test)\n\nfrom sklearn.metrics import confusion_matrix, roc_auc_score\nlog_conf = confusion_matrix(data_y_test, log_pred)\n\n# Visulize this Confusion Matrix neatly using seaborn\nplt.figure(figsize = (8,5))\nsns.heatmap(log_conf, annot=True, cmap='Blues', linewidths=.5)\n\nlog_accuracy = log_conf.diagonal().sum() / log_conf.sum()\nprint(\"Accuracy: \" + str(log_accuracy))\n\nlog_prec = log_conf[1,1] / (log_conf[0,1] + (log_conf[1,1]))\nprint(\"Precision: \" + str(log_prec))\n\nlog_sens = log_conf[1,1] / (log_conf[1,0] + (log_conf[1,1]))\nprint(\"Sensitivity: \" + str(log_sens))\n\nlog_spec = log_conf[0,0] / (log_conf[0,0] + (log_conf[0,1]))\nprint(\"Specificity: \" + str(log_spec))\n\nlog_roc_auc_score = roc_auc_score(data_y_test, log_pred)\nprint(\"ROC AUC Score: \" + str(log_roc_auc_score))\n\nlog_F1 = 2 * (log_prec * log_sens) / (log_prec + log_sens)\nprint('F1 Score: ' + str(log_F1))\n\nresults_normalized = pd.DataFrame({\"Actual Values\":data_y_test,\"Predicted Values\":log_pred})\nresults_normalized.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Improving Accuracy of Logistic Regression using XGBoost"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Applying XGBoost to Logistic Regression\n\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score\n\n\n# fit model no training data\nxg_model = XGBClassifier()\nxg_model.fit(oversampled_x_train, oversampled_y_train)\n\n\n# Prediction using XGBoost\ny_pred = xg_model.predict(data_x_test)\npredictions = [round(value) for value in y_pred]\n\n\n# Evaluate predictions\nxg_log_conf = confusion_matrix(data_y_test, predictions)\n\n# Visulize this Confusion Matrix neatly using seaborn\nplt.figure(figsize = (8,5))\nsns.heatmap(xg_log_conf, annot=True, cmap='Blues', linewidths=.5)\n\nxg_log_accuracy = xg_log_conf.diagonal().sum() / log_conf.sum()\nprint(\"Accuracy: \" + str(xg_log_accuracy))\n\nxg_log_prec = xg_log_conf[1,1] / (xg_log_conf[0,1] + (xg_log_conf[1,1]))\nprint(\"Precision: \" + str(xg_log_prec))\n\nxg_log_sens = xg_log_conf[1,1] / (xg_log_conf[1,0] + (xg_log_conf[1,1]))\nprint(\"Sensitivity: \" + str(xg_log_sens))\n\nxg_log_spec = xg_log_conf[0,0] / (xg_log_conf[0,0] + (xg_log_conf[0,1]))\nprint(\"Specificity: \" + str(xg_log_spec))\n\nxg_log_roc_auc_score = roc_auc_score(data_y_test, log_pred)\nprint(\"ROC AUC Score: \" + str(xg_log_roc_auc_score))\n\nxg_log_F1 = 2 * (xg_log_prec * xg_log_sens) / (xg_log_prec + xg_log_sens)\nprint('F1 Score: ' + str(xg_log_F1))\n\nresults_normalized = pd.DataFrame({\"Actual Values\":data_y_test,\"Predicted Values\":log_pred})\nresults_normalized.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Decision Tree"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\ndt = DecisionTreeClassifier()\ndt.fit(oversampled_x_train, oversampled_y_train)\n\ndt_pred = dt.predict(data_x_test)\ndt_conf = confusion_matrix(data_y_test, dt_pred)\n\n# Visulize this Confusion Matrix neatly using seaborn\nplt.figure(figsize = (8, 5))\nsns.heatmap(dt_conf, annot=True, cmap='Blues', linewidths=.5)\n\ndt_accuracy = dt_conf.diagonal().sum() / dt_conf.sum()\nprint(\"Accuracy: \" + str(dt_accuracy))\n\ndt_prec = dt_conf[1,1] / (dt_conf[0,1] + (dt_conf[1,1]))\nprint(\"Precision: \" + str(dt_prec))\n\ndt_sens = dt_conf[1,1] / (dt_conf[1,0] + (dt_conf[1,1]))\nprint(\"Sensitivity: \" + str(dt_sens))\n\ndt_spec = dt_conf[0,0] / (dt_conf[0,0] + (dt_conf[0,1]))\nprint(\"Specificity: \" + str(dt_spec))\n\ndt_roc_auc_score = roc_auc_score(data_y_test, dt_pred)\nprint(\"ROC AUC Score: \" + str(dt_roc_auc_score))\n\ndt_F1 = 2 * (dt_prec * dt_sens) / (dt_prec + dt_sens)\nprint('F1 Score: ' + str(dt_F1))\n\nresults_normalized = pd.DataFrame({\"Actual Values\":data_y_test,\"Predicted Values\":dt_pred})\nresults_normalized.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier()\nrf.fit(oversampled_x_train, oversampled_y_train)\n\nrf_pred = rf.predict(data_x_test)\nrf_conf = confusion_matrix(data_y_test, rf_pred)\n\n# Visulize this Confusion Matrix neatly using seaborn\nplt.figure(figsize = (8,5))\nsns.heatmap(rf_conf, annot=True, cmap='Blues', linewidths=.5)\n\nrf_accuracy = rf_conf.diagonal().sum() / rf_conf.sum()\nprint(\"Accuracy: \" + str(rf_accuracy))\n\nrf_prec = rf_conf[1,1] / (rf_conf[0,1] + (rf_conf[1,1]))\nprint(\"Precision: \" + str(rf_prec))\n\nrf_sens = rf_conf[1,1] / (rf_conf[1,0] + (rf_conf[1,1]))\nprint(\"Sensitivity: \" + str(rf_sens))\n\nrf_spec = rf_conf[0,0] / (rf_conf[0,0] + (rf_conf[0,1]))\nprint(\"Specificity: \" + str(rf_spec))\n\nrf_roc_auc_score = roc_auc_score(data_y_test, rf_pred)\nprint(\"ROC AUC Score: \" + str(rf_roc_auc_score))\n\nrf_F1 = 2 * (rf_prec * rf_sens) / (rf_prec + rf_sens)\nprint('F1 Score: ' + str(rf_F1))\n\nresults_normalized = pd.DataFrame({\"Actual Values\":data_y_test,\"Predicted Values\":rf_pred})\nresults_normalized.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model output parameters comparison"},{"metadata":{"trusted":true},"cell_type":"code","source":"results = [\n    [\"Logistic Regression\", log_accuracy, log_spec, log_prec, log_sens, log_roc_auc_score, log_F1],\n    [\"XGBoost\", xg_log_accuracy, xg_log_spec, xg_log_prec, xg_log_sens, xg_log_roc_auc_score, xg_log_F1],\n    [\"Decision Tree\", dt_accuracy, dt_spec, dt_prec, dt_sens, dt_roc_auc_score, dt_F1],\n    [\"Random Forest\", rf_accuracy, rf_spec, rf_prec, rf_sens, rf_roc_auc_score, rf_F1],\n]\n\nresults_df = pd.DataFrame(results, columns=[\"Name\", \"Accuracy\", \"Specificity\", \"Precision\", \"Sensitivity\", \"ROC AUC Score\", \"F1 Score\"])\nresults_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualizing AUROC Curve"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve\n\n# Calculate FPR, TPR, THRESHOLD for Logistic Regression Model \nlog_pred_prob = log_reg.predict_proba(data_x_test)  # Build on our Test data\nlog_fpr, log_tpr, log_thre = roc_curve(data_y_test, log_pred_prob[:, 1])\n\n# Calculate FPR, TPR, THRESHOLD for Decision Tree Model \ndt_pred_prob = dt.predict_proba(data_x_test)  # Build on our Test data\ndt_fpr, dt_tpr, dt_thre = roc_curve(data_y_test, dt_pred_prob[:, 1])\n\n# Calculate FPR, TPR, THRESHOLD for Random Forest Model \nrf_pred_prob = rf.predict_proba(data_x_test)  # Build on our Test data\nrf_fpr, rf_tpr, rf_thre = roc_curve(data_y_test, rf_pred_prob[:, 1])\n\nroc_plot_df = pd.DataFrame({\n    \"FPR\": [log_fpr, dt_fpr, rf_fpr],\n    \"TPR\": [log_tpr, dt_tpr, rf_tpr],\n})\n\n\nfig, ax = plt.subplots(figsize=(12, 8))\nax.plot(log_fpr,log_tpr)\nax.plot(dt_fpr,dt_tpr)\nax.plot(rf_fpr,rf_tpr)\n\nax.grid(True)\nax.set_title('Fpr vs Tpr on the Attrition Dataset')\nax.legend(['XGBoost', 'Decision Tree', 'Random Forest'])\nax.xaxis.set_label_text('Fpr Value')\nax.yaxis.set_label_text('Tpr Value')\n\nplt.show()\n\n\nprint(\"AUCROC Score using XGBoost: \" + str(log_roc_auc_score))\nprint(\"AUCROC Score for Decision Tree: \" + str(dt_roc_auc_score))\nprint(\"AUCROC Score for Random Forest: \" + str(rf_roc_auc_score))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Further comparison using Cross-Validation of scores"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\ntemp_df = []\n\n################ Calculate Score for Logistic Regression\nscore_log_reg = cross_val_score(log_reg, data_x, data_y, scoring='accuracy', cv=5)\n\n\n################ Calculate Score for XGBoost\nscore_xg_reg = cross_val_score(xg_model, data_x, data_y, scoring='accuracy', cv=5)\n\n\n################ Calculate Score for Decision Tree\nscore_dt = cross_val_score(dt, data_x, data_y, scoring='accuracy', cv=5)\n\n\n############### Calculate Score for Random Forest\nscore_rf = cross_val_score(rf, data_x, data_y, scoring='accuracy', cv=5)\n\n\n# Create a Dataframe\nresults = [\n    [\"Logistic Regression\", score_log_reg.mean(), score_log_reg.min(), score_log_reg.max()],\n    [\"XGBoost\", score_xg_reg.mean(), score_xg_reg.min(), score_xg_reg.max()],\n    [\"Decision Tree\", score_dt.mean(), score_dt.min(), score_dt.max()],\n    [\"Random Forest\", score_rf.mean(), score_rf.min(), score_rf.max()],\n]\n\nresults_df = pd.DataFrame(results, columns=[\"Name\", \"Mean Accuracy\", \"Minimum Accuracy\", \"Maximum Accuracy\"])\nresults_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Conclusion: Logistic Regression using XGBoost seems to be the best fit"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}