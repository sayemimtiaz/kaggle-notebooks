{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import shutil\nimport errno\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# data generator\n# source from https://medium.com/@ensembledme/writing-custom-keras-generators-fe815d992c5a\nfrom skimage.io import imread\n\ndef get_input(path):\n    \"\"\"get specific image from path\"\"\"\n    img = imread(path)\n    return img\n\ndef get_output(path, label_file = None):\n    \"\"\"get all the labels relative to the image of path\"\"\"\n    img_id = path.split('/')[-1]\n    labels = label_file.loc[img_id].values\n    return labels\n\ndef preprocess_input(img):\n    # convert between 0 and 1\n    return img.astype('float32') / 127.5 -1\n\ndef image_generator(files, label_file, batch_size = 32):\n    while True:\n\n        batch_paths = np.random.choice(a = files, size = batch_size)\n        batch_input = []\n        batch_output = []\n\n        for input_path in batch_paths:\n\n            input = get_input(input_path)\n            input = preprocess_input(input)\n            output = get_output(input_path, label_file = label_file)\n            batch_input += [input]\n            batch_output += [output]\n        batch_x = np.array(batch_input)\n        batch_y = np.array(batch_output)\n\n        yield batch_x, batch_y\n\ndef auto_encoder_generator(files, batch_size = 32):\n    while True:\n        batch_paths = np.random.choice(a = files, size = batch_size)\n        batch_input = []\n        batch_output = []\n\n        for input_path in batch_paths:\n            input = get_input(input_path)\n            input = preprocess_input(input)\n            output = input\n            batch_input += [input]\n            batch_output += [output]\n        batch_x = np.array(batch_input)\n        batch_y = np.array(batch_output)\n\n        yield batch_x, batch_y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nattr = pd.read_csv('../input/celeba-dataset/list_attr_celeba.csv')\nattr = attr.set_index('image_id')\n\n# check if attribute successful loaded\nattr.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom sklearn.model_selection import train_test_split\nIMG_NAME_LENGTH = 6\nfile_path = \"../input/celeba-dataset/img_align_celeba/img_align_celeba/\"\nimg_id = np.arange(1,len(attr.index)+1)\nimg_path = []\nfor i in range(len(img_id)):\n    img_path.append(file_path + (IMG_NAME_LENGTH - len(str(img_id[i])))*'0' + str(img_id[i]) + '.jpg')\n# pick 80% as training set and 20% as validation set\ntrain_path = img_path[:int((0.8)*len(img_path))]\nval_path = img_path[int((0.8)*len(img_path)):]\ntrain_generator = auto_encoder_generator(train_path,32)\nval_generator = auto_encoder_generator(val_path,32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, 5, figsize=(12, 4))\nfor i in range(5):    \n    ax[i].imshow(get_input(img_path[i]))\n    ax[i].axis('off')\n    ax[i].set_title(img_path[i][-10:])\nplt.show()\n    \nattr.iloc[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (20,20))\nsns.heatmap(attr.corr())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Initial Assessment of Dataset\nSo being male has no correlation with being attractive - fair enough <br>\nSurprising Bangs and Bald are correlated - <br>\nWait what!! <br>\nAnyways,"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Dropout, Flatten, Dense, Conv2D, MaxPooling2D, Input, Reshape, UpSampling2D, InputLayer, Lambda, ZeroPadding2D, Cropping2D, Conv2DTranspose, BatchNormalization\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.losses import binary_crossentropy\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.losses import mse, binary_crossentropy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_sample=get_input(img_path[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Due to improper config of tensorflow and keras\n## had to combine the cells to run in a single session.\n## Below is the collapsed markdown for it."},{"metadata":{},"cell_type":"markdown","source":"b_size = 128\nn_size = 512\n\n\ndef sampling(args):\n    z_mean, z_log_sigma = args\n    epsilon = K.random_normal(shape = (n_size,) , mean = 0, stddev = 1)\n    return z_mean + K.exp(z_log_sigma/2) * epsilon\n  \ndef build_conv_vae(input_shape, bottleneck_size, sampling, batch_size = 32):\n    \n    # ENCODER\n    input = Input(shape=(input_shape[0],input_shape[1],input_shape[2]))\n    x = Conv2D(32,(3,3),activation = 'relu', padding = 'same')(input)    \n    x = BatchNormalization()(x)\n    x = MaxPooling2D((2,2), padding ='same')(x)\n    x = Conv2D(64,(3,3),activation = 'relu', padding = 'same')(x)\n    x = BatchNormalization()(x)\n    x = MaxPooling2D((2,2), padding ='same')(x)\n    x = Conv2D(128,(3,3), activation = 'relu', padding = 'same')(x)\n    x = BatchNormalization()(x)\n    x = MaxPooling2D((2,2), padding ='same')(x)\n    x = Conv2D(256,(3,3), activation = 'relu', padding = 'same')(x)\n    x = BatchNormalization()(x)\n    x = MaxPooling2D((2,2), padding ='same')(x)\n    \n    # Latent Variable Calculation\n    shape = K.int_shape(x)\n    flatten_1 = Flatten()(x)\n    dense_1 = Dense(bottleneck_size, name='z_mean')(flatten_1)\n    z_mean = BatchNormalization()(dense_1)\n    flatten_2 = Flatten()(x)\n    dense_2 = Dense(bottleneck_size, name ='z_log_sigma')(flatten_2)\n    z_log_sigma = BatchNormalization()(dense_2)\n    z = Lambda(sampling)([z_mean, z_log_sigma])\n    encoder = Model(input, [z_mean, z_log_sigma, z], name = 'encoder')\n    \n    # DECODER\n    latent_input = Input(shape=(bottleneck_size,), name = 'decoder_input')\n    x = Dense(shape[1]*shape[2]*shape[3])(latent_input)\n    x = Reshape((shape[1],shape[2],shape[3]))(x)\n    x = UpSampling2D((2,2))(x)\n    x = Cropping2D([[0,0],[0,1]])(x)\n    x = Conv2DTranspose(256,(3,3), activation = 'relu', padding = 'same')(x)\n    x = BatchNormalization()(x)\n    x = UpSampling2D((2,2))(x)\n    x = Cropping2D([[0,1],[0,1]])(x)\n    x = Conv2DTranspose(128,(3,3), activation = 'relu', padding = 'same')(x)\n    x = BatchNormalization()(x)\n    x = UpSampling2D((2,2))(x)\n    x = Cropping2D([[0,1],[0,1]])(x)\n    x = Conv2DTranspose(64,(3,3), activation = 'relu', padding = 'same')(x)\n    x = BatchNormalization()(x)\n    x = UpSampling2D((2,2))(x)\n    x = Conv2DTranspose(32,(3,3), activation = 'relu', padding = 'same')(x)\n    x = BatchNormalization()(x)\n    output = Conv2DTranspose(3,(3,3), activation = 'tanh', padding ='same')(x)\n    decoder = Model(latent_input, output, name = 'decoder')\n\n    output_2 = decoder(encoder(input)[2])\n    vae = Model(input, output_2, name ='vae')\n    return vae, encoder, decoder, z_mean, z_log_sigma\n\nvae_2, encoder, decoder, z_mean, z_log_sigma = build_conv_vae(img_sample.shape, n_size, sampling, batch_size = b_size)\nprint(\"encoder summary:\")\nencoder.summary()\nprint(\"decoder summary:\")\ndecoder.summary()\nprint(\"vae summary:\")\nvae_2.summary()"},{"metadata":{},"cell_type":"markdown","source":"def vae_loss(input_img, output):\n    # Compute error in reconstruction\n    reconstruction_loss = mse(K.flatten(input_img) , K.flatten(output))\n    \n    # Compute the KL Divergence regularization term\n    kl_loss = - 0.5 * K.sum(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma), axis = -1)\n    \n    # Return the average loss over all images in batch\n    total_loss = (reconstruction_loss + 0.0001 * kl_loss)    \n    return total_loss"},{"metadata":{},"cell_type":"markdown","source":"vae_2.compile(optimizer='rmsprop', loss= vae_loss)\nencoder.compile(optimizer = 'rmsprop', loss = vae_loss)\ndecoder.compile(optimizer = 'rmsprop', loss = vae_loss)"},{"metadata":{},"cell_type":"markdown","source":"import tensorflow as tf\ntf.config.run_eagerly(True)\nvae_2.fit_generator(train_generator, steps_per_epoch = 4000, validation_data = val_generator, epochs=7, validation_steps= 500)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport random\n#tf.config.run_eagerly(True)\nwith tf.compat.v1.Session() as sess:\n    b_size = 128\n    n_size = 512\n    def sampling(args):\n        z_mean, z_log_sigma = args\n        epsilon = K.random_normal(shape = (n_size,) , mean = 0, stddev = 1)\n        return z_mean + K.exp(z_log_sigma/2) * epsilon\n  \n    def build_conv_vae(input_shape, bottleneck_size, sampling, batch_size = 32):\n    \n        # ENCODER\n        input = Input(shape=(input_shape[0],input_shape[1],input_shape[2]))\n        x = Conv2D(32,(3,3),activation = 'relu', padding = 'same')(input)    \n        x = BatchNormalization()(x)\n        x = MaxPooling2D((2,2), padding ='same')(x)\n        x = Conv2D(64,(3,3),activation = 'relu', padding = 'same')(x)\n        x = BatchNormalization()(x)\n        x = MaxPooling2D((2,2), padding ='same')(x)\n        x = Conv2D(128,(3,3), activation = 'relu', padding = 'same')(x)\n        x = BatchNormalization()(x)\n        x = MaxPooling2D((2,2), padding ='same')(x)\n        x = Conv2D(256,(3,3), activation = 'relu', padding = 'same')(x)\n        x = BatchNormalization()(x)\n        x = MaxPooling2D((2,2), padding ='same')(x)\n    \n        # Latent Variable Calculation\n        shape = K.int_shape(x)\n        flatten_1 = Flatten()(x)\n        dense_1 = Dense(bottleneck_size, name='z_mean')(flatten_1)\n        z_mean = BatchNormalization()(dense_1)\n        flatten_2 = Flatten()(x)\n        dense_2 = Dense(bottleneck_size, name ='z_log_sigma')(flatten_2)\n        z_log_sigma = BatchNormalization()(dense_2)\n        z = Lambda(sampling)([z_mean, z_log_sigma])\n        encoder = Model(input, [z_mean, z_log_sigma, z], name = 'encoder')\n    \n        # DECODER\n        latent_input = Input(shape=(bottleneck_size,), name = 'decoder_input')\n        x = Dense(shape[1]*shape[2]*shape[3])(latent_input)\n        x = Reshape((shape[1],shape[2],shape[3]))(x)\n        x = UpSampling2D((2,2))(x)\n        x = Cropping2D([[0,0],[0,1]])(x)\n        x = Conv2DTranspose(256,(3,3), activation = 'relu', padding = 'same')(x)\n        x = BatchNormalization()(x)\n        x = UpSampling2D((2,2))(x)\n        x = Cropping2D([[0,1],[0,1]])(x)\n        x = Conv2DTranspose(128,(3,3), activation = 'relu', padding = 'same')(x)\n        x = BatchNormalization()(x)\n        x = UpSampling2D((2,2))(x)\n        x = Cropping2D([[0,1],[0,1]])(x)\n        x = Conv2DTranspose(64,(3,3), activation = 'relu', padding = 'same')(x)\n        x = BatchNormalization()(x)\n        x = UpSampling2D((2,2))(x)\n        x = Conv2DTranspose(32,(3,3), activation = 'relu', padding = 'same')(x)\n        x = BatchNormalization()(x)\n        output = Conv2DTranspose(3,(3,3), activation = 'tanh', padding ='same')(x)\n        decoder = Model(latent_input, output, name = 'decoder')\n\n        output_2 = decoder(encoder(input)[2])\n        vae = Model(input, output_2, name ='vae')\n        return vae, encoder, decoder, z_mean, z_log_sigma\n\n    vae_2, encoder, decoder, z_mean, z_log_sigma = build_conv_vae(img_sample.shape, n_size, sampling, batch_size = b_size)\n    print(\"encoder summary:\")\n    encoder.summary()\n    print(\"decoder summary:\")\n    decoder.summary()\n    print(\"vae summary:\")\n    vae_2.summary()\n    \n    def vae_loss(input_img, output):\n        # Compute error in reconstruction\n        reconstruction_loss = mse(K.flatten(input_img) , K.flatten(output))\n    \n        # Compute the KL Divergence regularization term\n        kl_loss = - 0.5 * K.sum(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma), axis = -1)\n    \n        # Return the average loss over all images in batch\n        total_loss = (reconstruction_loss + 0.0001 * kl_loss)    \n        return total_loss\n    vae_2.compile(optimizer='rmsprop', loss= vae_loss)\n    encoder.compile(optimizer = 'rmsprop', loss = vae_loss)\n    decoder.compile(optimizer = 'rmsprop', loss = vae_loss)\n    vae_2.fit_generator(train_generator, steps_per_epoch = 4000, validation_data = val_generator, epochs=7, validation_steps= 500)\n    \n    \n    x_test = []\n    for i in range(64):\n        x_test.append(get_input(img_path[random.randint(0,len(img_id))]))\n    x_test = np.array(x_test)\n    figure_Decoded = vae_2.predict(x_test.astype('float32')/127.5 -1, batch_size = b_size)\n    figure_original = x_test[0]\n    figure_decoded = (figure_Decoded[0]+1)/2\n    for i in range(4):\n        plt.axis('off')\n        plt.subplot(2,4,1+i*2)\n        plt.imshow(x_test[i])\n        plt.axis('off')\n        plt.subplot(2,4,2 + i*2)\n        plt.imshow((figure_Decoded[i]+1)/2)\n        plt.axis('off')\n    plt.show()\n    \n    # Choose two images of different attributes, and plot the original and latent space of it\n    \n    x_test1 = []\n    for i in range(64):\n        x_test1.append(get_input(img_path[np.random.randint(0,len(img_id))]))\n    x_test1 = np.array(x_test)\n    x_test_encoded = np.array(encoder.predict(x_test1/127.5-1, batch_size = b_size))\n    figure_original_1 = x_test[0]\n    figure_original_2 = x_test[1]\n    Encoded1 = (x_test_encoded[0,0,:].reshape(32, 16,)+1)/2 \n    Encoded2 = (x_test_encoded[0,1,:].reshape(32, 16)+1)/2\n    \n    plt.figure(figsize=(8, 8))\n    plt.subplot(2,2,1)\n    plt.imshow(figure_original_1)\n    plt.subplot(2,2,2)\n    plt.imshow(Encoded1)\n    plt.subplot(2,2,3)\n    plt.imshow(figure_original_2)\n    plt.subplot(2,2,4)\n    plt.imshow(Encoded2)\n    filename = 'Fig_001.png'\n    plt.savefig(filename)\n    plt.show()\n    plt.close()\n    # Randomly generated 15 images from 15 series of noise information\n    n = 3\n    m = 5\n    digit_size1 = 218\n    digit_size2 = 178\n    figure = np.zeros((digit_size1 * n, digit_size2 * m,3))\n     \n    for i in range(3):\n        for j in range(5):\n            z_sample = np.random.rand(1,512)\n            x_decoded = decoder.predict([z_sample])\n            figure[i * digit_size1: (i + 1) * digit_size1,\n                   j * digit_size2: (j + 1) * digit_size2,:] = (x_decoded[0]+1)/2 \n    plt.figure(figsize=(10, 10))\n    plt.imshow(figure)\n    filename = 'Fig_002.png'\n    plt.savefig(filename)\n    plt.show()\n    plt.close()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"import random\nx_test = []\nfor i in range(64):\n    x_test.append(get_input(img_path[random.randint(0,len(img_id))]))\nx_test = np.array(x_test)\nfigure_Decoded = vae_2.predict(x_test.astype('float32')/127.5 -1, batch_size = b_size)\nfigure_original = x_test[0]\nfigure_decoded = (figure_Decoded[0]+1)/2\nfor i in range(4):\n    plt.axis('off')\n    plt.subplot(2,4,1+i*2)\n    plt.imshow(x_test[i])\n    plt.axis('off')\n    plt.subplot(2,4,2 + i*2)\n    plt.imshow((figure_Decoded[i]+1)/2)\n    plt.axis('off')\nplt.show()"},{"metadata":{},"cell_type":"markdown","source":"# Choose two images of different attributes, and plot the original and latent space of it\n\nx_test1 = []\nfor i in range(64):\n    x_test1.append(get_input(img_path[np.random.randint(0,len(img_id))]))\nx_test1 = np.array(x_test)\nx_test_encoded = np.array(encoder.predict(x_test1/127.5-1, batch_size = b_size))\nfigure_original_1 = x_test[0]\nfigure_original_2 = x_test[1]\nEncoded1 = (x_test_encoded[0,0,:].reshape(32, 16,)+1)/2 \nEncoded2 = (x_test_encoded[0,1,:].reshape(32, 16)+1)/2\n\nplt.figure(figsize=(8, 8))\nplt.subplot(2,2,1)\nplt.imshow(figure_original_1)\nplt.subplot(2,2,2)\nplt.imshow(Encoded1)\nplt.subplot(2,2,3)\nplt.imshow(figure_original_2)\nplt.subplot(2,2,4)\nplt.imshow(Encoded2)\nplt.show()"},{"metadata":{},"cell_type":"markdown","source":"# We randomly generated 15 images from 15 series of noise information\nn = 3\nm = 5\ndigit_size1 = 218\ndigit_size2 = 178\nfigure = np.zeros((digit_size1 * n, digit_size2 * m,3))\n \nfor i in range(3):\n    for j in range(5):\n        z_sample = np.random.rand(1,512)\n        x_decoded = decoder.predict([z_sample])\n        figure[i * digit_size1: (i + 1) * digit_size1,\n               j * digit_size2: (j + 1) * digit_size2,:] = (x_decoded[0]+1)/2 \nplt.figure(figsize=(10, 10))\nplt.imshow(figure)\nplt.show()"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}