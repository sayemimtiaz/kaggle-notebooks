{"cells":[{"metadata":{},"cell_type":"markdown","source":"# stock price prediction\n![](https://miro.medium.com/max/2560/0*R5pC0bAlYxH_nTlF.jpg)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"ğŸ‘**ã“ã®notebookãŒå½¹ã«ç«‹ã£ãŸæ–¹ã¯æ˜¯éã„ã„ã­ã‚’ãŠé¡˜ã„ã—ã¾ã™**ğŸ‘  \nğŸ‘**please upvote**ğŸ‘  \nthis notebook is created from https://www.kaggle.com/takahiro1127/topix-prediction-of-topix-stock-price  \nã“ã®notebookã¯ã“ã¡ã‚‰ã®notebook https://www.kaggle.com/takahiro1127/topix-prediction-of-topix-stock-price ã®ç™ºå±•ç³»ã¨ã—ã¦ä½œæˆã—ã¾ã—ãŸã€‚","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport xgboost as xgb\nimport collections\nimport seaborn as sns\nfrom xgboost import DMatrix\nimport matplotlib.pyplot as plt\nfrom xgboost import plot_importance, plot_tree\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import confusion_matrix, recall_score\nfrom sklearn.metrics import cohen_kappa_score\nimport lightgbm as lgb\nfrom sklearn.metrics import accuracy_score\nfrom tqdm import tqdm\nfrom scipy import signal\nimport matplotlib.pyplot as plt\nimport random\nimport numpy as np\nfrom statistics import mean, mode\n# ãƒãƒ£ãƒ¼ãƒˆç”¨è¨­å®š\n# setting for chart\nimport plotly as py\nimport plotly.io as pio\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nfrom warnings import simplefilter\nsimplefilter(action='ignore', category=FutureWarning)\nsimplefilter(action='ignore', category=DeprecationWarning)\n\ninit_notebook_mode(connected=True)\nlayout=go.Layout(paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(250,250,250,0.8)')\nfig = go.Figure(layout=layout)\ntemplated_fig = pio.to_templated(fig)\npio.templates['my_template'] = templated_fig.layout.template\npio.templates.default = 'my_template'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## EDA / ãƒ‡ãƒ¼ã‚¿æ¢ç´¢\ndata visualization and data analysis is here https://www.kaggle.com/takahiro1127/topix-prediction-of-topix-stock-price  \nãƒ‡ãƒ¼ã‚¿æ¢ç´¢ã¨å¯è¦–åŒ–ã¯ã“ã¡ã‚‰ã®note bookã«ã‚ã‚Šã¾ã™ã€‚ã€€https://www.kaggle.com/takahiro1127/topix-prediction-of-topix-stock-price \n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## æ–¹é‡\néå»250æ—¥é–“ã®ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦xgbã‚’å­¦ç¿’ã—251æ—¥ç›®ã®æ ªä¾¡ã®å¤‰åŒ–ã‚’äºˆæ¸¬ã™ã‚‹ã€‚  \nâ†’ã“ã‚Œã‚’äºˆæ¸¬ã—ãŸã„æ—¥æ•°åˆ†ç¹°ã‚Šè¿”ã™\nä»¥ä¸‹åŒæ§˜ã«  \n```\npredict = []\nfor (int i = first_predict_day; i < final_day; i++) {\n  model.train(data[(i - 251) ~ i - 1])\n  predict[i] = model.predict(data[i])\n}\n```\nã®ã‚ˆã†ãªå½¢ã§è¡Œã†\n\n## plan\ntrain XGB by recent (i - 250)~ i days data and predict (i+1)-day Change rate  \nâ†’train XGB by recent (i - 251 + 1)~ (i + 1) days data and predict (i + 1 + 1)-day Change rate  \nâ†’predict all day as above\n```\npredict = []\nfor (int i = first_predict_day; i < final_day; i++) {\n  model.train(data[(i - 251) ~ i - 1])\n  predict[i] = model.predict(data[i])\n}\n```","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## åˆæœŸè¨­å®š/setting\nç›´è¿‘150æ—¥é–“ã®äºˆæ¸¬ã‚’è¡Œã†ã“ã¨ã«ã™ã‚‹ã€‚  \npredict 150days","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/topix4/TOPIX4.csv\", names=(\"Date\", \"Open\", \"High\", \"Low\", \"Close\")).drop(0)\nprediction_day_count = 150\ntrain_day_count = 250\ndf = df.loc[len(df) - prediction_day_count - train_day_count - 34:].reset_index().drop('index', 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ãã®ä»–ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ•ã‚¡ãƒ³ãƒ‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹/prepare other index-fund\ntopixä»¥å¤–ã®dataã‚‚äºˆæ¸¬ã«ç”¨ã„ã‚‹ã“ã¨ã«ã™ã‚‹ã€‚  \nã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã‚’ã™ã‚‹ã‹ã€ã—ãªã„ã‹ã«ã‚ˆã£ã¦ç”¨ã„ã‚‹ã‹ã©ã†ã‹ã‚’æ±ºå®šã™ã‚‹ã€‚  \nuse other index-fund data  \nswitch use or unuse by comment-out","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# df = df.loc[len(df) - prediction_day_count - train_day_count - 34 -1:].reset_index().drop('index', 1)\n# index_funds = ['N225', 'GSPC', 'EZU']\nindex_funds = []\n# columns_added_by_index_funds = ['N225_Close', 'GSPC_Close', 'EZU_Close']\n# columns_added_by_index_funds = ['N225_Close', 'GSPC_Close', 'EZU_Close', 'N225_RSI', 'GSPC_RSI', 'EZU_RSI']\ncolumns_added_by_index_funds = []\n# for index_fund in index_funds:\n#     index_df = pd.read_csv(\"/kaggle/input/stock-price-datas/\" + index_fund + \".csv\", names=(\"Date\", \"Open\", \"High\", \"Low\", index_fund+\"_Close\", \"Adj Close\", \"Volume\")).drop(0)\n#     index_df = index_df.drop([\"Open\", \"High\", \"Low\", \"Adj Close\", \"Volume\"], 1)\n#     index_df[\"Date\"] = index_df[\"Date\"].str.replace('-', '/')\n#     df = pd.merge(df, index_df, on=\"Date\", how='left')\n#     if (index_fund != 'N225'):\n#         df[index_fund+\"_Close\"] = df[index_fund+\"_Close\"].shift()\n# df = df[1:]      # Because of shifting close price\n# df = df.reset_index().drop(\"index\", 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ready features","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### ãƒ•ãƒ©ã‚°ã®ä½œæˆ / make flag\nã‚´ãƒ¼ãƒ«ãƒ‡ãƒ³ã‚¯ãƒ­ã‚¹ã®ç°¡æ˜“ç‰ˆã§ã™  \nsimple version of golden cross  ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def flag_features(df):\n    for num in ['5', '10', '15', '30']:\n        # ç§»å‹•å¹³å‡ç·šã¨ç§»å‹•æ¨™æº–åå·®\n        # moving average and std of it\n        df['SMA_' + num] = df['Close'].rolling(int(num)).mean().shift() / df['Close']\n        df['SMA_' + num + '_std'] = df['Close'].rolling(int(num)).std().shift() / df['Close']\n        col_name = 'SMA_' + num + '_sub'\n        today_col_name = 'flag_today_sma_' + num\n        yesterday_col_name = 'flag_yesterday_sma_' + num\n        df[col_name] = df['Close'].rolling(int(num)).mean().shift()\n        df.loc[df[col_name] < df['Close'], today_col_name] = 1\n        df.loc[df[col_name] >= df['Close'], today_col_name] = 0\n        df[yesterday_col_name] = df[today_col_name].shift(1)\n        # ãƒ•ãƒ©ã‚°ã‚’ä½œæˆ\n        # make flag\n        df.loc[(df[yesterday_col_name] == 0) & (df[today_col_name] == 1), \"flag_sma_under_\" + num] = 1\n        df.loc[~((df[yesterday_col_name] == 0) & (df[today_col_name] == 1)), \"flag_sma_under_\" + num] = 0\n        df.loc[(df[yesterday_col_name] == 1) & (df[today_col_name] == 0), \"flag_sma_over_\" + num] = 1\n        df.loc[~((df[yesterday_col_name] == 1) & (df[today_col_name] == 0)), \"flag_sma_over_\" + num] = 0\n        df = df.drop([col_name, yesterday_col_name, today_col_name], 1)\n    up_flag = {'5' : 0, '10': 0, '15' : 0, '30' : 0}\n    down_flag = {'5' : 0, '10': 0, '15' : 0, '30' : 0}\n    # ãƒ•ãƒ©ã‚°ã‹ã‚‰ç‰¹å®šã®è·é›¢ã«ã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯\n    # check distance from flag\n    for i in range(len(df)):\n        for num in ['5', '10', '15', '30']:\n            up_column = \"up_flag_distance_\" + num\n            down_column = \"down_flag_distance_\" + num\n            df.loc[i, up_column] = 0\n            df.loc[i, down_column] = 0\n            if up_flag[num] > int(num):\n                up_flag[num] = 0\n                df.loc[i, \"up_flag_distance_\" + num] = 0\n            elif up_flag[num] > 0:\n                df.loc[i, \"up_flag_distance_\" + num] = up_flag[num]\n                up_flag[num] += 1\n\n            if down_flag[num] > int(num):\n                down_flag[num] = 0\n                df.loc[i, \"down_flag_distance_\" + num] = 0\n            elif down_flag[num] > 0:\n                df.loc[i, \"down_flag_distance_\" + num] = down_flag[num]\n                down_flag[num] += 1\n\n            if df.loc[i, \"flag_sma_under_\" + num] == 1:\n                df.loc[i, \"down_flag_distance_\" + num] = 1\n                down_flag[num] = 2\n            if df.loc[i, \"flag_sma_over_\" + num] == 1:\n                df.loc[i, \"up_flag_distance_\" + num] = 1\n                up_flag[num] = 2\n    for num in ['5', '10', '15', '30']:\n        df = df.drop([\"flag_sma_over_\" + num, \"flag_sma_under_\" + num], 1)\n    return df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### RSI / ç›¸å¯¾åŠ›æŒ‡æ•°\nç›¸å¯¾çš„ã«ä¸Šæ˜‡æ–¹å‘ãªã®ã‹ä¸‹é™æ–¹å‘ãªã®ã‹ã‚’ç¤ºã™æŒ‡æ•°ã§ã™ã€‚  \nrelative strength of up or down","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def relative_strength_idx(df, close_column = \"Close\", n=14):\n    close = df[close_column]\n    delta = close.diff()\n    delta = delta[1:]\n    pricesUp = delta.copy()\n    pricesDown = delta.copy()\n    pricesUp[pricesUp < 0] = 0\n    pricesDown[pricesDown > 0] = 0\n    rollUp = pricesUp.rolling(n).mean()\n    rollDown = pricesDown.abs().rolling(n).mean()\n    rs = rollUp / rollDown\n    rsi = 100.0 - (100.0 / (1.0 + rs))\n    return rsi","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### wavelet analysis / ã‚¦ã‚§ãƒ¼ãƒ–ãƒ¬ãƒƒãƒˆè§£æ\nWavelet coefficient represents periodic nature of time-series data.  \nã‚¦ã‚§ãƒ¼ãƒ–ãƒ¬ãƒƒãƒˆä¿‚æ•°ã¯æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®å‘¨æœŸçš„ãªæ€§è³ªã‚’è¡¨ã—ã¦ã„ã¾ã™ã€‚","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def wt( data ):\n    widths = np.arange(1, 100)\n    return signal.cwt( data, signal.ricker, widths )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### make objective variable / ç›®çš„å¤‰æ•°ã«ä½œæˆ\nmake objective variable and assign weight based on objective variable(change label)  \nç›®çš„é–¢æ•°ã‚’ä½œæˆã—ã¾ã™ã€‚ã¾ãŸã€å¤‰åŒ–ç‡ã«åŸºã¥ã„ã¦å­¦ç¿’ã®é‡ã¿ä»˜ã‘ã‚’è¡Œã„ã¾ã™ã€‚\n\n#### weight\nbig change rate gives me big profit(or loss).  \nwe must focus on big change.  \nset heavy weight on big change.  \n\nå¤§ããªå¤‰åŒ–ã¯å¤§ããªåˆ©ç›Šã‚„æå¤±ã‚’ã‚‚ãŸã‚‰ã™ãŸã‚ã€é–“é•ãˆãŸæ™‚ã®ãƒªã‚¹ã‚¯ãŒå¤§ãã„ã§ã™ã€‚  \nã‚ˆã£ã¦ã€å¤§ããªå¤‰åŒ–ã»ã©äºˆæ¸¬æ€§èƒ½ãŒã‚ãŒã‚‹ã‚ˆã†ã«é‡ã¿ä»˜ã‘ã‚’ã—ã¾ã™ã€‚","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def change_rate(df):\n    # è©•ä¾¡ã«çµ‚å€¤ã®å¤‰åŒ–ç‡ã‚’ä½¿ã†ãŸã‚\n    # qualtile([0.2, 0.4, 0.6, 0.8])ã§é–¾å€¤ã‚’æ±ºå®š\n    # å¤§ããªãƒ—ãƒ©ã‚¹ã‚’2ã¨ã—ã¦ã€å°ã•ãªãƒ—ãƒ©ã‚¹ã‚’1 â†’ã€€å¤§ããªãƒã‚¤ãƒŠã‚¹ã‚’-2\n    \n    # objective variable is change rate of close\n    # devide change rate to label by quantile\n    # big plus is 2 and small plus is 1 ... bug minus is -2\n    df['Change_rate'] = df['Close'].pct_change()\n    divide = df['Change_rate'].quantile([0, 0.2, 0.4, 0.6, 0.8, 1.0])\n    df.loc[(df['Change_rate'] > divide[0.4]) & (df['Change_rate'] < divide[0.6]), 'Change_label'] = 0\n    df.loc[(df['Change_rate'] > divide[0.4]) & (df['Change_rate'] < divide[0.6]), 'weight'] = 1\n    df.loc[(df['Change_rate'] >= divide[0.2]) & (df['Change_rate'] <= divide[0.4]), 'Change_label'] = -1\n    df.loc[(df['Change_rate'] >= divide[0.2]) & (df['Change_rate'] <= divide[0.4]), 'weight'] = 1.2\n    df.loc[df['Change_rate'] < divide[0.2], 'Change_label'] = -2\n    df.loc[df['Change_rate'] < divide[0.2], 'weight'] = 1.5\n    df.loc[(df['Change_rate'] <= divide[0.8]) & (df['Change_rate'] >= divide[0.6]), 'Change_label'] = 1\n    df.loc[(df['Change_rate'] <= divide[0.8]) & (df['Change_rate'] >= divide[0.6]), 'weight'] = 1.2\n    df.loc[df['Change_rate'] > divide[0.8], 'Change_label'] = 2\n    df.loc[df['Change_rate'] > divide[0.8], 'weight'] = 1.5\n    df = df.reset_index()\n    return df.drop('index', 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ready simple features / å˜ç´”ãªèª¬æ˜å¤‰æ•°ã®ä½œæˆ\nMACD and EMA... is very easy to create.\nIn this method we make easy features.\n\nç°¡å˜ã«ä½œæˆã§ãã‚‹ç‰¹å¾´é‡ã¯ã“ã“ã§ä½œæˆã—ã¦ã„ã¾ã™ã€‚","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def ready_features(df):\n    # ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿\n    # read csv and modify type of columns\n    df['Date'] = pd.to_datetime(df['Date'])\n    df[\"Open\"] = df['Open'].astype(float)\n    df[\"Close\"] = df['Close'].astype(float)\n    df[\"High\"] = df['High'].astype(float)\n    df[\"Low\"] = df['Low'].astype(float)\n    for index_fund in index_funds:\n        df[index_fund+\"_Close\"] = df[index_fund+\"_Close\"].astype(float)\n    # æŒ‡æ•°å¹³æ»‘ç§»å‹•å¹³å‡\n    # Exponential Moving Average\n    # æŒ‡æ•°å¹³æ»‘ç§»å‹•å¹³å‡ã®æ—¥æœ¬èªã®èª¬æ˜â†“\n    # https://media-kojirokousi.com/exponential-moving-average/#:~:text=%E6%8C%87%E6%95%B0%E5%B9%B3%E6%BB%91%E7%A7%BB%E5%8B%95%E5%B9%B3%E5%9D%87%E7%B7%9A(EMA)%E3%81%AF%E3%80%81%E5%BE%93%E6%9D%A5%E3%81%AE,EMA%E3%81%A8%E5%91%BC%E3%81%B0%E3%82%8C%E3%81%BE%E3%81%99%E3%80%82\n    df['EMA_9'] = df['Close'].ewm(9).mean().shift() / df['Close']\n    df['EMA_9_std'] = df['Close'].ewm(9).std().shift() / df['Close']\n    # MACD\n    # MACDã®æ—¥æœ¬èªã®èª¬æ˜â†“\n    # https://www.sevendata.co.jp/shihyou/technical/macd.html\n    EMA_12 = pd.Series(df['Close'].ewm(span=12, min_periods=12).mean())\n    EMA_26 = pd.Series(df['Close'].ewm(span=26, min_periods=26).mean())\n    df['MACD'] = pd.Series(EMA_12 - EMA_26)/ df['Close']\n    df['MACD_signal'] = pd.Series(df.MACD.ewm(span=9, min_periods=9).mean())/ df['Close']\n    df['RSI'] = relative_strength_idx(df).fillna(0)\n    df = flag_features(df)\n    df = change_rate(df)\n    #â†“ä»–ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ•ã‚¡ãƒ³ãƒ‰ã®ãƒ‡ãƒ¼ã‚¿ã‚‚åŒæ§˜ã®ç‰¹å¾´é‡ã‚’ç”Ÿæˆã—ã¦ã„ã‚‹\n    #â†“create same features from other index-fund data\n    for index_fund in index_funds:\n        close_column = index_fund+\"_Close\"\n        rsi_column = index_fund +\"_RSI\"\n        df[index_fund + '_EMA_9'] = df[close_column].ewm(9).mean().shift() / df[close_column]\n        df[index_fund + '_EMA_9_std'] = df[close_column].ewm(9).std().shift() / df[close_column]\n        EMA_12 = pd.Series(df[close_column].ewm(span=12, min_periods=12).mean())\n        EMA_26 = pd.Series(df[close_column].ewm(span=26, min_periods=26).mean())\n        df[rsi_column] = relative_strength_idx(df, close_column).fillna(0)\n        column_wave = wt(df[close_column])\n        for num in ['5', '10', '15', '30']:\n            df[close_column + '_wave_' + num] = column_wave[int(num)]\n        rsi_wave = wt(df[rsi_column])\n        for num in ['5', '10', '15', '30']:\n            df[rsi_column + '_wave_' + num] = rsi_wave[int(num)]\n\n    # waveletè§£æ\n    # wavelet\n    for column in ['Close', 'RSI']:\n        column_wave = wt(df[column])\n        for num in ['5', '10', '15', '30', '45', '50', '75','98']:\n            df[column + '_wave_' + num] = column_wave[int(num)]\n    return df\n\n\ndf = ready_features(df)\ndf.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ready data for train / trainç”¨ã«ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def ready_data_for_train(df_for_ready, day_count): \n    df_for_ready = modify_weight_based_on_day_count(df_for_ready, day_count)\n    df_for_ready, train_df, valid_df, test_df = modify_and_split_data_for_xgb(df_for_ready, day_count)\n    X_train, y_train = get_label_and_explanatory_variable(train_df)\n    X_valid, y_valid = get_label_and_explanatory_variable(valid_df)\n    X_test, y_test = get_label_and_explanatory_variable(test_df)\n    eval_set = [(X_train, y_train), (X_valid, y_valid)]\n    weights = X_train[\"weight\"].astype('float')\n    X_train = X_train.drop(\"weight\", axis=1)\n    X_valid = X_valid.drop(\"weight\", axis=1)\n    X_test = X_test.drop(\"weight\", axis=1)\n    eval_set = [(X_train, y_train), (X_valid, y_valid)]\n    return eval_set, X_train, y_train, X_valid, y_valid, X_test, y_test, weights, df_for_ready, test_df\n    \ndef modify_weight_based_on_day_count(df_for_ready, day_count):\n    df_for_ready = df_for_ready.reset_index()\n    df_for_ready.loc[df_for_ready['weight'] - 0.5 > df_for_ready['weight'] - 0.7 + 1.2 * df_for_ready['index']/len(df_for_ready), 'weight'] = df_for_ready['weight'] - 0.5\n    df_for_ready.loc[df_for_ready['weight'] - 0.5 <= df_for_ready['weight'] - 0.7 + 1.2 * df_for_ready['index']/len(df), 'weight'] = df_for_ready['weight'] - 0.7 + 1.2 * df_for_ready['index']/len(df_for_ready)\n    return df_for_ready.drop('index', 1)\n    \ndef modify_and_split_data_for_xgb(df_for_ready, day_count):\n    # å‰æ—¥ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€ç¿Œæ—¥ã®çµ‚å€¤ã‚’äºˆæ¸¬ã™ã‚‹ãŸã‚ã€closeã‚’shiftã—ã¦ã„ã‚‹ã€‚\n    # â†“we would like to predict tommorow's movement\n    df_for_ready['Change_label'] = df_for_ready['Change_label'].shift(-1)\n    df_for_ready['Change_rate'] = df_for_ready['Change_rate'].shift(-1)\n    df_for_ready['weight'] = df_for_ready['weight'].shift(-1)\n\n    df_for_ready = df_for_ready.iloc[33:] # Because of moving averages and MACD line\n    df_for_ready = df_for_ready[:-1]      # Because of shifting close price\n    df_for_ready[\"Change_label\"] = df_for_ready[\"Change_label\"].astype('int')\n    df_for_ready = df_for_ready.reset_index()\n    df_for_ready = df_for_ready.drop(['index'], 1)\n    test_df = df_for_ready.loc[len(df_for_ready) - prediction_day_count + day_count: len(df_for_ready) - prediction_day_count + day_count].copy()\n    train_df = df_for_ready.loc[: len(df_for_ready) - prediction_day_count + day_count - 1].copy()\n    train_df, valid_df = train_test_split(train_df, test_size=0.19, stratify=train_df.Change_label)\n    return df_for_ready,train_df, valid_df, test_df\ndef get_label_and_explanatory_variable(df_for_ready):\n    drop_cols = ['Date', 'Open', 'Low', 'High', 'Close', 'Change_rate']\n    df_for_ready = df_for_ready.drop(drop_cols, 1)\n    df_for_ready = df_for_ready.drop(columns_added_by_index_funds, 1)\n    label = df_for_ready['Change_label'].copy()\n    explanatory = df_for_ready.drop(columns='Change_label')\n    return explanatory, label","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## å­¦ç¿’ã¨äºˆæ¸¬/train and prediction\nxgbã‚’ç”¨ã„ã¦å­¦ç¿’ã™ã‚‹ã€‚  \nã¾ãŸã€åˆæœŸçŠ¶æ…‹ã«ä¾å­˜ã—ã¦ã—ã¾ã†ã“ã¨ã‹ã‚‰ã€ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’ã‚’è¡Œã†ã“ã¨ã«ã™ã‚‹ã€‚  \npredict by xgb  \nprediction is influenced by initial state, prevent influence by using ensemble learning","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"result = df[df.Date == \"aa\"].copy().reset_index().drop(['index'], 1)\n#â†‘ãƒ‡ãƒ¼ã‚¿ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã¿ã‚’ã‚³ãƒ”ãƒ¼\n#â†‘copy frame only\nensemble_count = 10\nfor i in tqdm(range(prediction_day_count)):\n    predicts = []\n    for j in range(ensemble_count):\n        eval_set, X_train, y_train, X_valid, y_valid, X_test, y_test, weights, ans_df, test_df = ready_data_for_train(df.loc[i:].copy(), i)\n        model = xgb.XGBClassifier(n_estimators=200, \n            learning_rate=0.05,\n            max_depth= 8,\n            gamma=0.02,\n            random_state= 42,\n            num_class =5,\n            objective='multi:softprob')\n        model.fit(X_train, y_train, eval_set=eval_set, verbose=False, sample_weight = weights)\n        predicts.append(model.predict(X_test)[0])\n        if ensemble_count - 1 == j:\n            test_df['pred'] = collections.Counter(predicts).most_common()[0][0]\n    result = pd.concat([result, test_df.reset_index()])\nresult = result.reset_index().drop(['index', 'level_0'], 1)\nacc = accuracy_score(result['Change_label'], result['pred'])\nprint(acc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ / simulation\næç›Šã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä»¥ä¸‹ã®å½¢ã§è¡Œã†  \nsimulate profit and loss as below  \n\nW_0 = 1\n\nW_{t+1} =  ( 1 + r_{t+1} * w_t ) W_t\n\n### è¨˜å·\n\n* W_t : æ™‚åˆ»tã§ã®ä¿æœ‰è³‡ç”£é¡ / money at t-time  \n* r_t : æ™‚åˆ»{t-1} ã‹ã‚‰ æ™‚åˆ»tã¾ã§ã®TOPIXå¤‰åŒ–ç‡ / change rate from (t-1)-time to t-time  \n* w_t : è‡ªåˆ†ã®æŠ•è³‡æ¯”ç‡ / investment rate  \n\n### äºˆæ¸¬ã¨æŠ•è³‡æ¯”ç‡ã®é–¢ä¿‚ / decide investment rate by prediction\n* +2 : å¤§å¹…ãªTOPIXä¸Šæ˜‡/big plus  => w_t =  1.0 \n* +1 : å°å¹…ãªTOPIXä¸Šæ˜‡/small plus  => w_t =  0.5\n*  0 : TOPIXå¤‰åŒ–ãªã—/no channge  ã€€=> w_t =  0.0\n* -1 : å°å¹…ãªTOPIXä¸‹è½/small minus  => w_t = -0.5\n* -2 : å¤§å¹…ãªTOPIXä¸‹è½/big minus  => w_t = -1.0","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def simulate_based_on_predict(sim_data):\n    money_his = pd.DataFrame(columns = ['Date', 'money'])\n    money = 1\n    for i in range(0, len(result)):\n        data = sim_data.loc[i].copy()\n        today_pred = data.pred\n        Change_rate = data.Change_rate\n        if (today_pred == -2):\n            money = (1 + Change_rate * -1) * money\n        elif (today_pred == -1):\n            money = (1 + Change_rate * -0.5) * money\n        elif (today_pred == 1):\n            money = (1 + Change_rate * 0.5) * money\n        elif (today_pred == 2):\n            money = (1 + Change_rate * 1) * money\n        money_his.loc[data.Date] = [data.Date, money]\n    return money, money_his\nmoney, money_his = simulate_based_on_predict(result.copy())\nprint(money)\nfig = go.Figure(go.Scatter(x=money_his.Date, y=money_his.money, name='money_history'))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(confusion_matrix(result['Change_label'], result['pred']))\nsns.heatmap(confusion_matrix(result['Change_label'], result['pred']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1,1,figsize=(10, 10))\nplot_importance(booster=model, ax=ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = make_subplots(rows=1, cols=1)\nfig.add_trace(go.Scatter(x=result.Date, y=result.Change_label,\n                         name='Truth'), row=1, col=1)\n\nfig.add_trace(go.Scatter(x=result.Date,\n                         y=result.pred,\n                         name='Prediction'), row=1, col=1)\n\nfig.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}