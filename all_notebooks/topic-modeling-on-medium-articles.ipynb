{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h1 align=\"center\">Topic modeling on Medium articles</h1>"},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"## All minimum setup and libraries required\n\nimport numpy as np\nimport pandas as pd \nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n## TENSORFLOW        \nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.text import Tokenizer   ## Generate dictionary of word encodings\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\n## GENSIM and NLTK\nimport gensim\nfrom gensim.utils import simple_preprocess\nfrom gensim.parsing.preprocessing import STOPWORDS\nfrom nltk.stem import WordNetLemmatizer, SnowballStemmer\nfrom nltk.stem.porter import *\nimport nltk\nnltk.download('wordnet')\n\n# SKLEARN\nfrom sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.model_selection import GridSearchCV\nfrom pprint import pprint\n\nprint(\"Tensorflow\\t-\\t\",tf.__version__)\nprint(\"NLTK\\t\\t-\\t\",nltk.__version__)\nprint(\"Gensim\\t\\t-\\t\",nltk.__version__)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"path = \"../input/medium-articles-with-content/Medium_AggregatedData.csv\"\ndataframe_full = pd.read_csv(path)\ndataframe_imp = pd.read_csv(path)\nprint(\"Dataset have been read\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataframe_full.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = dataframe_full['name'][10]\ny = dataframe_full['publicationdescription'][15]\nprint(x)\nprint(y)\nprint(dataframe_full.shape)\nprint(dataframe_full['name'][10])\nprint(dataframe_full['name'][11])\nprint(dataframe_full['name'][12])\nprint(dataframe_full['title'][10])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Step_1: Preprocessing and cleaning"},{"metadata":{},"cell_type":"markdown","source":"**There are ~300000 entries**"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(dataframe_full.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The required columns are:\n* language\n* subTitle\n* tagsCount\n* text\n* title\n* url\n* wordCount\n* publicationdescription\n* tag_name\n* name\n\nbut the most important columns are primarily:\n* subTitle\n* text\n* title"},{"metadata":{"trusted":true},"cell_type":"code","source":"required_col = ['language','subTitle','tagsCount','text','title','url','wordCount','publicationdescription'\n               ,'tag_name','name']\nmost_imp_col = ['subTitle','text','title']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# article_titles = dataframe_full['title']\n# art_grp_1 = article_titles[16:25]\n# print(art_grp_1)\nprint(dataframe_full.language.unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Number of rows english rows\n\nenglish_titles = dataframe_full[dataframe_full['language'] == 'en']\n# english_titles.head()\nprint(english_titles.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Number of rows dropped after removing null value rows\n\nprint(dataframe_imp.shape)\ndataframe_imp.dropna(how = 'all')\nprint(dataframe_imp.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So nothing is missing in any rows"},{"metadata":{"trusted":true},"cell_type":"code","source":"## After dropping non-english and columns that are not required really\n\ndataframe_imp.drop(dataframe_imp[dataframe_imp['language'] != 'en'].index, inplace = True)\n\ndataframe_imp = dataframe_imp.drop(['audioVersionDurationSec', 'codeBlock', 'codeBlockCount',\n       'collectionId', 'createdDate', 'createdDatetime', 'firstPublishedDate',\n       'firstPublishedDatetime', 'imageCount', 'isSubscriptionLocked',\n       'language', 'latestPublishedDate', 'latestPublishedDatetime',\n       'linksCount', 'postId', 'readingTime', 'recommends',\n       'responsesCreatedCount', 'socialRecommendsCount','tagsCount','totalClapCount', 'uniqueSlug',\n       'updatedDate', 'updatedDatetime', 'url', 'vote', 'wordCount',\n       'publicationdescription', 'publicationdomain',\n       'publicationfacebookPageName', 'publicationfollowerCount',\n       'publicationname', 'publicationpublicEmail', 'publicationslug',\n       'publicationtags', 'publicationtwitterUsername', 'tag_name', 'slug',\n       'name', 'postCount', 'author', 'bio', 'userId', 'userName',\n       'usersFollowedByCount', 'usersFollowedCount', 'scrappedDate'], axis=1)\n\ndataframe_imp['index'] = dataframe_imp.index\n\ndataframe_imp.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Reduced dataset with 3col and ~20000 rows for reff.\nRun these cells only to produce the reduced and compact dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Run these cell to export the new trimmed down dataset\n\n# dataframe_imp.to_csv(\"medium_dataset.csv\",sep=\",\")\n# new_ds_size = os.stat(\"medium_dataset.csv\").st_size\n# new_ds_size = new_ds_size / 1000000\n# print(\"New dataset size in MB = \",new_ds_size)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***Choose one among the two in the cell below***"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Keeping 170000 rows greatly reduces the dataset size to around 100MB\n\nvery_reduced_dataset = dataframe_imp[:17000]\n# very_reduced_dataset.to_csv(\"very_reduced_dataset.csv\",sep=\",\")\n# print(\"New dataset size in MB = \",os.stat(\"very_reduced_dataset.csv\").st_size / 1000000)\n\n# from IPython.display import FileLink\n# FileLink(r'very_reduced_dataset.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataframe_imp.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(dataframe_imp.title[15])\nprint(dataframe_imp.subTitle[15])\n# print(dataframe_imp.text[15])      ## Text is too huge to be displayed\nprint(dataframe_imp.index[15])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**after dropping all the non english rows and after dropping all non essential columns `dataframe_imp` is the required dataframe****"},{"metadata":{},"cell_type":"markdown","source":"### Perform lemmatization and stem preprocessing steps on the data set"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Stemmer initialization for english\nstemmer = SnowballStemmer(\"english\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Functions for lemmatization, removal of Stopwords\n\ndef lemmatize_stemming(text):\n    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\ndef preprocess(text):\n    result = []\n    for token in gensim.utils.simple_preprocess(text):\n        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n            result.append(lemmatize_stemming(token))\n    return result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Code to check the function\n\n## Run this for faster execution time wiht less acuracy\ndoc_sample = very_reduced_dataset[very_reduced_dataset['index'] == 1000].values[0][2]\n\n## Run this for slower execution but better accuracy\n# doc_sample = dataframe_imp[dataframe_imp['index'] == 1000].values[0][2]\n\nprint('original document: ')\nwords = []\nfor word in doc_sample.split(' '):\n    words.append(word)\n    \nprint(dataframe_imp[dataframe_imp['index'] == 1000].values[0][2])\nprint(words)\nprint('\\n\\n tokenized and lemmatized document: ')\nprint(preprocess(doc_sample))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Processed titles"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Use this to reduce the training time at the cost of loss of rows and some accuracy.\ntitle_list = very_reduced_dataset['title'].astype(str)\n\n## Use this for higher model accuracy but very slow operating time. \n# title_list = dataframe_imp['title'].astype(str)   ## using astype(str) eliminates the floting type error\ntitle_list.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## The titles are preprocessed and saved into processd_titles\n## The map function applies the preprocess method on each of the list entries\n\nprocessed_titles = title_list.map(preprocess)\nprocessed_titles[30:40]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Step_2: Creation of the Bag of words\nBag of words is a frequency count of the words occuring in the `preprocessed_docs`"},{"metadata":{"trusted":true},"cell_type":"code","source":"## bow --> Bag of Words\n\nbow = gensim.corpora.Dictionary(processed_titles)\n\n## Finding out words with a min_occurance = 10\n\nmin_occurance = 10\ncount = 0\nfor k, v in bow.iteritems():\n    print(k, v)\n    count += 1\n    if count > min_occurance:    # We can limit the selection based on the frequency\n        break","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Filtering tokens based on\n* less than 15 occurances in titles\n* more than 0.5 of total titles\n* after the above two steps, keep only the first 100000 most frequent tokens.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"bow.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)\nprint(bow)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Generating the doc2bow dictionary"},{"metadata":{},"cell_type":"markdown","source":"For each title we create a dictionary reporting how many words and how many times those words appear. This is saved to the `bow_corpus`.\n\n##### **NOTE:** This step gives a simmillar result for a very small corpus such as title of the articles, but it is important while working on the actual body of the articles."},{"metadata":{"trusted":true},"cell_type":"code","source":"bow_corpus = [bow.doc2bow(doc) for doc in processed_titles]\nbow_corpus[:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Preview of the BOW for the preprocessed titles"},{"metadata":{"trusted":true},"cell_type":"code","source":"## A example of the BOW for the 1000th title\n\nbow_example = bow_corpus[1000]\nfor i in range(len(bow_example)):\n    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_example[i][0], \n           bow[bow_example[i][0]], \n           bow_example[i][1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Step_3: TF-IDF \nTF-IDF stands for ***term frequency–inverse document frequency***. The higher the TF-IDF score the rarer a word is in a given corpus and vice-versa. We will be using the TF-IDF model for the gensim models library."},{"metadata":{"trusted":true},"cell_type":"code","source":"from gensim import corpora, models\n\ntfidf = models.TfidfModel(bow_corpus)\ncorpus_tfidf = tfidf[bow_corpus]\n\n# from pprint import pprint\n\nfor i in corpus_tfidf:\n    print(i)\n    break","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Step_4: Running LDA algo on the bag of words\nTesting LDA(Latent Dirichlet allocation) on the BOW. We will be training our LDA model using `gensim.models.LdaMulticore` and save it to `lda_model`"},{"metadata":{},"cell_type":"markdown","source":"### Creating the base model"},{"metadata":{"trusted":true},"cell_type":"code","source":"## LDA when the num_topics = 10\n\n# lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=bow, passes=5, workers=3)\nlda_model = gensim.models.LdaMulticore(corpus=bow_corpus,\n                                       id2word=bow,\n                                       num_topics=10, \n                                       random_state=100,\n                                       chunksize=100,\n                                       passes=10,\n                                       per_word_topics=True)\nprint(lda_model)\n# For optimal performance time set the workers as no of CPU cores-1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**For each topic, we will explore the words occuring in that topic and its relative weight.**"},{"metadata":{},"cell_type":"markdown","source":"### Topic distribution generated by the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"for idx, topic in lda_model.print_topics(-1):\n    print('\\nTopic: {} \\nWords: {}'.format(idx, topic))\ndoc_lda = lda_model[bow_corpus]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"topics = lda_model.show_topics(formatted=False)\ntopic_words = dict(topics[1][1])\nprint(\"For topic 1, the words are: \",topic_words)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3 style=\"color:blue;\">Here each topic can be visualized as recipie of the probability of the words that can appear in it.</h3>In geometry, a simplex is a generalization of the notion of a triangle or tetrahedron to arbitrary dimensions [source] (https://en.wikipedia.org/wiki/Simplex). LDA space is a simplex since we are dealing wiht probability distributions here. Dimensionality of the space depends on the number of topics we ask the model to make."},{"metadata":{},"cell_type":"markdown","source":"# Step_5: Visualization \n1. Topic modeling with LDA\n2. Visualizing topic models with pyLDAvis\n3. Visualizing LDA results with t-SNE and bokeh"},{"metadata":{"trusted":true},"cell_type":"code","source":"%pylab inline\n\nimport pandas as pd\nimport pickle as pk\nfrom scipy import sparse as sp","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Wordcloud of Top N words in each topic"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Wordcloud of Top N words in each topic\nfrom matplotlib import pyplot as plt\nfrom wordcloud import WordCloud, STOPWORDS\nimport matplotlib.colors as mcolors\n\ncols = [color for name, color in mcolors.TABLEAU_COLORS.items()]  # more colors: 'mcolors.XKCD_COLORS'\n\ncloud = WordCloud(\n                  background_color='white',\n                  width=2500,\n                  height=1800,\n                  max_words=10,\n                  colormap='tab10',\n                  color_func=lambda *args, **kwargs: cols[i],\n                  prefer_horizontal=1.0)\n\ntopics = lda_model.show_topics(formatted=False)\n\nfig, axes = plt.subplots(2, 5, figsize=(18,10), sharex=True, sharey=True)\n\nfor i, ax in enumerate(axes.flatten()):\n    fig.add_subplot(ax)\n    topic_words = dict(topics[i][1])\n    cloud.generate_from_frequencies(topic_words, max_font_size=300)\n    plt.gca().imshow(cloud)\n    plt.gca().set_title('Topic ' + str(i), fontdict=dict(size=16))\n    plt.gca().axis('off')\n\n\nplt.subplots_adjust(wspace=0, hspace=0)\nplt.axis('off')\nplt.margins(x=0, y=0)\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Word count vs Weights of topics"},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import Counter\ntopics = lda_model.show_topics(formatted=False)\ndata_flat = [w for w_list in dataframe_imp for w in w_list]\ncounter = Counter(data_flat)\n\nout = []\nfor i, topic in topics:\n    for word, weight in topic:\n        out.append([word, i , weight, counter[word]])\n\ndf = pd.DataFrame(out, columns=['word', 'topic_id', 'importance', 'word_count'])        \n\n# Plot Word Count and Weights of Topic Keywords\nfig, axes = plt.subplots(2, 5, figsize=(18,10), sharey=True, dpi=160)\ncols = [color for name, color in mcolors.TABLEAU_COLORS.items()]\nfor i, ax in enumerate(axes.flatten()):\n    ax.bar(x='word', height=\"word_count\", data=df.loc[df.topic_id==i, :], color=cols[i], width=0.5, alpha=0.3, label='Word Count')\n    ax_twin = ax.twinx()\n    ax_twin.bar(x='word', height=\"importance\", data=df.loc[df.topic_id==i, :], color=cols[i], width=0.2, label='Weights')\n    ax.set_ylabel('Word Count', color=cols[i])\n    ax_twin.set_ylim(0, 0.08); ax.set_ylim(0, 3500)\n    ax.set_title('Topic: ' + str(i), color=cols[i], fontsize=16)\n    ax.tick_params(axis='y', left=False)\n    ax.set_xticklabels(df.loc[df.topic_id==i, 'word'], rotation=30, horizontalalignment= 'right')\n    ax.legend(loc='upper left'); ax_twin.legend(loc='upper right')\n\nfig.tight_layout(w_pad=2)    \nfig.suptitle('Word Count and Importance of Topic Keywords', fontsize=22, y=1.05)    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pyLDAvis.gensim\npyLDAvis.enable_notebook()\nvis = pyLDAvis.gensim.prepare(lda_model, bow_corpus, dictionary=lda_model.id2word)\nvis","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Step_6: Coherence score (base model)\n> ****Topic Coherence**** measures score a single topic by measuring the degree of semantic similarity between high scoring words in the topic. These measurements help distinguish between topics that are semantically interpretable topics and topics that are artifacts of statistical inference.\n\n> A set of statements or facts is said to be ****coherent****, if they support each other. Thus, a coherent fact set can be interpreted in a context that covers all or most of the facts. An example of a coherent fact set is “the game is a team sport”, “the game is played with a ball”, “the game demands great physical efforts”"},{"metadata":{},"cell_type":"markdown","source":"## Using c_v measure"},{"metadata":{"trusted":true},"cell_type":"code","source":"from gensim.models import CoherenceModel\n# Compute Coherence Score\ncoherence_model_lda = CoherenceModel(model=lda_model, texts=processed_titles, dictionary=lda_model.id2word, coherence='c_v')\ncoherence_lda = coherence_model_lda.get_coherence()\nprint('\\nCoherence Score: ', coherence_lda)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Using UMass Measure"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compute Coherence Score using UMass\ncoherence_model_lda = CoherenceModel(model=lda_model, texts=processed_titles, dictionary=lda_model.id2word, coherence=\"u_mass\")\ncoherence_lda = coherence_model_lda.get_coherence()\nprint('\\nCoherence Score: ', coherence_lda)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"These are the base scores for the default model"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Step_6: Hyperparameter tuning\nThe model hyperparameters to be determined are:\n* num_topics (k)\n* alpha (document density)\n* beta (Word-Topic Density)"},{"metadata":{"trusted":true},"cell_type":"code","source":"def compute_coherence_values(dictionary, corpus, texts, limit,cs_type, start=2, step=3):\n    \"\"\"\n    Compute c_v coherence for various number of topics\n\n    Parameters:\n    ----------\n    dictionary : Gensim dictionary\n    corpus : Gensim corpus\n    texts : List of input texts\n    limit : Max num of topics\n\n    Returns:\n    -------\n    model_list : List of LDA topic models\n    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n    \"\"\"\n    coherence_values = []\n    model_list = []\n    for num_topics in range(start, limit, step):\n        model=gensim.models.LdaMulticore(corpus=corpus, id2word=dictionary, num_topics=num_topics)\n        model_list.append(model)\n        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence=cs_type)\n        coherence_values.append(coherencemodel.get_coherence())\n\n    return model_list, coherence_values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### CASE_1: With c_v coherence score and num_topics"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_list, coherence_values = compute_coherence_values(dictionary=bow, corpus=bow_corpus, texts=processed_titles, start=2, limit=100, step=5,cs_type = 'c_v')\n# Show graph\nimport matplotlib.pyplot as plt\nlimit=100; start=2; step=5;\nx = range(start, limit, step)\nplt.plot(x, coherence_values, marker='o')\nplt.xlabel(\"Num Topics\")\nplt.ylabel(\"Coherence score\")\nplt.legend((\"coherence_values\"), loc='best')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above plot it is evident that coherence score increases\nwith respect to the `num_topics` till it reaches somewhere\nbetween 55 to 65 and declines thereafter. A `num_topics` value of 60\nwill have a good coherence score"},{"metadata":{},"cell_type":"markdown","source":"### CASE_2: With u_mass coherence score and num_topics"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_list, coherence_values = compute_coherence_values(dictionary=bow, corpus=bow_corpus, texts=processed_titles, start=2, limit=100, step=5,cs_type = 'u_mass')\n# Show graph\nimport matplotlib.pyplot as plt\nlimit=100; start=2; step=5;\nx = range(start, limit, step)\nplt.plot(x, coherence_values,marker = 'o')\nplt.xlabel(\"Num Topics\")\nplt.ylabel(\"Coherence score\")\nplt.legend((\"coherence_values\"), loc='best')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Grid search on the three hyper parameters wrt c_v Coherence score"},{"metadata":{"trusted":true},"cell_type":"code","source":"## supporting function with num_topics = 60\n\ndef compute_coherence_values(corpus, dictionary, k, a, b):\n    \n    lda_model = gensim.models.LdaMulticore(corpus=corpus,\n                                           id2word=bow,\n                                           num_topics=60, \n                                           random_state=100,\n                                           chunksize=100,\n                                           passes=10,\n                                           alpha=a,\n                                           eta=b,\n                                           per_word_topics=True)\n    \n    coherence_model_lda = CoherenceModel(model=lda_model, texts=processed_titles, dictionary=lda_model.id2word, coherence='c_v')\n    \n    return coherence_model_lda.get_coherence()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport tqdm\ngrid = {}\ngrid['Validation_Set'] = {}\n# Topics range\n# min_topics = 2\n# max_topics = 11\n# step_size = 1\n# topics_range = range(min_topics, max_topics, step_size)\n\n# Alpha parameter\n# alpha = list(np.arange(0.01, 1, 0.3))\nalpha = np.array([0.05,0.1,0.5,1,5,10])\n# alpha.append('symmetric')\n# alpha.append('asymmetric')\n\n# Beta parameter\n# beta = list(np.arange(0.01, 1, 0.3))\nbeta = np.array([0.05,0.1,0.5,1,5,10])\n# beta.append('symmetric')\n\n# Validation sets\nnum_of_docs = len(bow_corpus)\ncorpus_sets = [# gensim.utils.ClippedCorpus(corpus, num_of_docs*0.25), \n               # gensim.utils.ClippedCorpus(corpus, num_of_docs*0.5), \n               gensim.utils.ClippedCorpus(bow_corpus, int(num_of_docs*0.75)), \n               bow_corpus]\ncorpus_title = ['75% Corpus', '100% Corpus']\nmodel_results = {'Validation_Set': [],\n                 'Topics': [],\n                 'Alpha': [],\n                 'Beta': [],\n                 'Coherence': []\n                }\nk = 45\n# Can take a long time to run\n# if 1 == 1:\npbar = tqdm.tqdm(total=200, position=0, leave=True)\n\n\n# iterate through validation corpuses\nfor i in range(len(corpus_sets)):\n    # iterate through alpha values\n    for a in alpha:\n        # iterare through beta values\n        for b in beta:\n            # get the coherence score for the given parameters\n            cv = compute_coherence_values(corpus=corpus_sets[i], dictionary=lda_model.id2word, \n                                          k=k, a=a, b=b)\n            # Save the model results\n            model_results['Validation_Set'].append(corpus_title[i])\n            model_results['Topics'].append(k)\n            model_results['Alpha'].append(a)\n            model_results['Beta'].append(b)\n            model_results['Coherence'].append(cv)\n            pbar.update(1)\npd.DataFrame(model_results).to_csv('lda_tuning_results.csv', index=False)\npbar.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataframe_results = pd.read_csv(\"./lda_tuning_results.csv\")\ndataframe_results\ntopics = dataframe_results['Topics']\ncoherence_values = dataframe_results['Coherence']\ndataframe_results['Topics'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimal = dataframe_results[dataframe_results['Validation_Set'] == '100% Corpus']\nmax_coherence_val = optimal['Coherence'].max()\noptimal = dataframe_results[dataframe_results['Coherence'] == max_coherence_val]\nprint(optimal)\n# print(val_set)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### The row with the max Coherence Score(c_v) of 0.63341 has `beta = 0.1` and `alpha = 0.5`"},{"metadata":{},"cell_type":"markdown","source":"# Step_7: Final Model\nThe row with the max Coherence Score(c_v) of 0.631025 has `beta = 0.1` and `alpha = 0.5`\nNow training the new model with these values"},{"metadata":{"trusted":true},"cell_type":"code","source":"final_lda_model = gensim.models.LdaMulticore(corpus=bow_corpus,\n                                             id2word=bow,\n                                             num_topics=60,\n                                             random_state=100,\n                                             chunksize=100,\n                                             passes=10,\n                                             alpha = 0.5,\n                                             eta=0.1, \n                                             per_word_topics=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_coherence_model_lda = CoherenceModel(model=final_lda_model, texts=processed_titles, dictionary=lda_model.id2word, coherence='c_v')\nfinal_coherence_score = final_coherence_model_lda.get_coherence()\nprint('\\nCoherence Score: ',final_coherence_score )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is a little improvement of the coherence score of the final model over the base model"},{"metadata":{},"cell_type":"markdown","source":"### LDA visualization on the final model"},{"metadata":{"trusted":true},"cell_type":"code","source":"pyLDAvis.enable_notebook()\nvis = pyLDAvis.gensim.prepare(final_lda_model, bow_corpus, dictionary=bow)\nvis","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}