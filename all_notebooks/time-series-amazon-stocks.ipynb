{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Time Series Project: Amazon Stock Data"},{"metadata":{},"cell_type":"markdown","source":"Coded by Luna McBride\n\nThis is a project meant to mess with time series data. I will be using the opening rate as the key metric, as it is consistent. The below sources are ones I am using to get an idea of the functions and concepts behind the practice. \n\nSources: https://www.kaggle.com/gayatry/population-prediction-ar-vs-arima , https://www.youtube.com/watch?v=e8Yw4alG16Q"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt #Plotting\n%matplotlib inline\n\nimport warnings #What to do with warnings\nwarnings.filterwarnings(\"ignore\") #Ignore the warnings\n\nplt.rcParams[\"figure.figsize\"] = (10,10) #Make the plots bigger by default\nplt.rcParams[\"lines.linewidth\"] = 2 #Setting the default line width\nplt.style.use(\"ggplot\") #Define the style of the plot\n\nfrom statsmodels.tsa.seasonal import seasonal_decompose #Describes the time data\nfrom statsmodels.tsa.stattools import adfuller #Check if data is stationary\nfrom statsmodels.graphics.tsaplots import plot_acf #Compute lag for ARIMA\nfrom statsmodels.graphics.tsaplots import plot_pacf #Compute partial lag for ARIMA\nfrom statsmodels.tsa.arima_model import ARIMA #Predictions and Forecasting\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"amazon = pd.read_csv(\"../input/amazon-stock-price-1997-to-2020/Amazon.csv\") #Get our stock data from the CSV\namazon.head(10) #Take a peek at the Amazon data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"# Check for Null Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(amazon.isnull().any()) #Check for null values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are no null values."},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"# Create Subset for Values I Want"},{"metadata":{"trusted":true},"cell_type":"code","source":"amazonOpen = amazon[[\"Date\", \"Open\"]].copy() #Get the date and open columns\namazonOpen[\"Date\"] = pd.to_datetime(amazonOpen[\"Date\"]) #Ensure the date data is in datetime format\namazonOpen.set_index(\"Date\", inplace = True) #Set the date to the index\namazonOpen = amazonOpen.asfreq(\"b\") #Set the frequency\namazonOpen = amazonOpen.fillna(method  = \"bfill\") #Fill null values with future values\n\n#amazonOpen.index #Make sure the frequency remains intact\namazonOpen.head(12) #Take a peek at the open data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = amazonOpen.plot(title = \"Amazon Stocks (Open)\") #Get an idea of the data\ny.set(ylabel = \"Price at Open\") #Set the y label to open\nplt.show() #Show the plot","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"# Check Trend/Seasonality"},{"metadata":{"trusted":true},"cell_type":"code","source":"decomp = seasonal_decompose(amazonOpen, model = \"multiplicative\") #Decompose the data\nx = decomp.plot() #Plot the decomposed data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The seasonal looks like a red blob, but the trend is positive."},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"# Check if Data is Stationary"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"ADFuller Test; Significance: 0.05\") #Print the significance level\nadf = adfuller(amazonOpen[\"Open\"]) #Call adfuller to test\nprint(\"ADF test static is {}\".format(adf[1])) #Print the adfuller results","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ADFuller gave a clean 1.0. That means this data is not stationary, even for huge significance values."},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"# Make the Data Stationary"},{"metadata":{"trusted":true},"cell_type":"code","source":"openLog = np.log(amazonOpen) #Take the log of the set for normalization\nopenStationary = openLog - openLog.shift() #Get a stationary set by subtracting the shifted set\nopenStationary = openStationary.dropna() #Drop generated null values from the set\nopenStationary.plot(title = \"Stationary Amazon Stocks\") #Plot the stationary set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"ADFuller Test; Significance: 0.05\") #Print the significance level\nadf = adfuller(openStationary[\"Open\"]) #Call adfuller to test\nprint(\"ADF test static is {}\".format(adf[1])) #Print the adfuller results","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ADFuller is now below significance. The data is now stationary."},{"metadata":{"trusted":true},"cell_type":"code","source":"decomp = seasonal_decompose(openStationary) #Decompose the stationary data\nx = decomp.plot() #Plot the decomposition","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"# Preparation for ARIMA"},{"metadata":{},"cell_type":"markdown","source":"## Differencing Term D"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,axes = plt.subplots(2,2) #Set a subset for the data visualizations\n\na = axes[0,0].plot(amazonOpen[\"Open\"]) #Plot the original data\na = axes[0,0].set_title(\"Original Data\") #Give the original data a name\nb = plot_acf(amazonOpen[\"Open\"],ax=axes[0,1]) #Plot the ACF of the original data\n\nx = axes[1,0].plot(openStationary[\"Open\"]) #Plot the stationary data\nx = axes[1,0].set_title(\"Stationary Data\") #Give the stationary data a name\ny = plot_acf(openStationary[\"Open\"],ax=axes[1,1]) #Plot the ACF of the stationary data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The Stationary data appears to be mostly in the fair range, with some variance due to the large jump in the data. 1 appears to be a good number for D."},{"metadata":{},"cell_type":"markdown","source":"## AR Lag (P)"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,axes = plt.subplots(1,2) #Create a subplot for the Partial ACF\n\na = axes[0].plot(openStationary[\"Open\"]) #Plot the stationary data\na = axes[0].set_title(\"Stationary\") #Ensure the stationary data is named\nb = plot_pacf(openStationary[\"Open\"], ax = axes[1], method = \"ols\") #Plot the partial ACF","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"5 appears to be a good number for P."},{"metadata":{},"cell_type":"markdown","source":"## MA Lag (Q)"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,axes = plt.subplots(1,2) #Create a subplot for the ACF\n\na = axes[0].plot(openStationary[\"Open\"])#Plot the stationary data\na = axes[0].set_title(\"Stationary\") #Ensure the stationary data is named\nb = plot_acf(openStationary[\"Open\"], ax = axes[1]) #Plot the ACF","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"5 appears to be a good number for the Q metric as well."},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"# Train the ARIMA"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = ARIMA(openStationary, order = (5, 1, 5)) #Build the ARIMA model\nfitModel = model.fit(disp = 1) #Fit the ARIMA model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"# Predict with ARIMA"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams.update({\"figure.figsize\" : (12,6), \"lines.linewidth\" : 0.05, \"figure.dpi\" : 100}) #Fix the look of the graph, dimming it to show the red\n\nx = fitModel.plot_predict(dynamic = False) #Fit the ARIMA model\nx = plt.title(\"Forecast Fitting\") #Add a stock title\nplt.show() #Show the ARIMA plot","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"# Validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams.update({\"figure.figsize\" : (12,5), \"lines.linewidth\": 2}) #Fix the line width\nlength = int((len(amazonOpen)*9)/10) #Get 9/10 of the length of the data\nprint(length) #Print the length to make sure it actually is an int","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = amazonOpen[:length] #Use 9/10 of the data for the train set\ntest = amazonOpen[length:] #Use the rest for testing\nmodelValid = ARIMA(train,order=(5,1,5)) #Create a model for the train set\nfitModelValid = modelValid.fit(disp= -1) #Fit the model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fc,se,conf = fitModelValid.forecast(len(amazonOpen) - length) #Forcast over the test area\nforecast = pd.Series(fc, index = test.index) #Get the forecast for the area","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Add labels for the train, test, and forecast\nplt.plot(train,label = \"Training Data\") \nplt.plot(test,label = \"Actual Continuation\")\nplt.plot(forecast,label = \"Forecasted Continuation\", color = \"g\")\n\nplt.title(\"ARIMA Forecast\") #Add the Forecast title\nplt.legend(loc = \"upper left\") #Put the legend in the top left\nplt.xlabel(\"Year\") #Add the year label to the bottom\nplt.ylabel(\"Open Price\") #Add the open price to the y axis","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Putting 1/10 of the test data for the stocks appears to show a fair prediction for the open price. It had to go far enough to account for the massive growth in the late 2010's. It does not account for the massive jump in 2020, but 2020 is an anomoly for Amazon stocks, given Covid."},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"# Predicting"},{"metadata":{"trusted":true},"cell_type":"code","source":"modelPred = ARIMA(amazonOpen,order=(5,1,5)) #Create a model for the whole data\nfitModelPred = modelPred.fit(disp= -1) #Fit the model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fitModelPred.plot_predict(1,len(amazonOpen) + 1000) #Plot predictions for the next thousand days\nx = fitModelPred.forecast(1000) #Forecast the prediction for the next thousand days.\nx = plt.title(\"Amazon Stock Forecast\") #Add a stock title\nx = plt.xlabel(\"Year\") #Add the year label to the bottom\nx = plt.ylabel(\"Open Price\") #Add the open price to the y axis","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The model predicts an overall increase in stock price. The slope of the prediction is more akin to how level the majority of the graph is, but the confidence interval is wide to account for variance. In this case, the spike caused by Covid is likely the big indicator for why in the interval is so large. In general, it is fair to assume Amazon stocks will continue to rise given previous trends, but we need to keep in mind we are coming out of a pandemic. We will likely continue to feel its wrath linger long after it is handled, which could cause unexpected spikes or dips from people getting back to life and deciding whether or not to continue using Amazon services as much as they have. At the current moment, however, this feels like a fair prediction."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}