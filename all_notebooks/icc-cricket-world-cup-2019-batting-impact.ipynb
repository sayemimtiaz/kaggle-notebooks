{"cells":[{"metadata":{},"cell_type":"markdown","source":"# ICC Cricket World Cup 2019 - Batting Impact\nI have recently been thinking about cricket metrics, and the best way that we can measure how impactful a batsman is. This comes from recently seeing a fantastic thread on Twitter from [Dan Weston](https://twitter.com/SAAdvantage) about the PSL, as well as the recent discussions about where Moeen Ali should bat for England given his power hitting against spin, and where most of the spin overs are in a T20 match.  \n\nI thought that I would apply these ideas and metrics to the top 50 run scorers from last year's ICC Cricket World Cup.  \n\nI got these summary statistics from [ESPNCricInfo](http://stats.espncricinfo.com/ci/engine/records/batting/most_runs_career.html?id=12357;type=tournament). I have written a web scraper that pulls the data from that page and saves it as a csv so it is easier for me to import into Kaggle.  \n\nAll the details about the web scraper can be found in my [Cricketer Analysis repository](https://github.com/willcanniford/cricketer-analysis) on Github. "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Imports for loading and cleaning data\nimport pandas as pd\nimport re\nimport numpy as np\n\n# Imports for visualisations and displaying tables\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport seaborn as sns\nfrom IPython.display import HTML, display\n\n# Imports for batsman grouping and classification\nfrom sklearn.cluster import KMeans\nfrom sklearn import preprocessing \nfrom sklearn.metrics import silhouette_score, silhouette_samples\nfrom scipy.cluster.hierarchy import linkage, dendrogram, fcluster\nfrom sklearn.manifold import TSNE","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Loading and preparing the data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"world_cup_batting_raw = pd.read_csv(\"../input/world_cup_2019_batting_raw.csv\")\ndf = world_cup_batting_raw.loc[:, ['Player','Runs', 'BF','SR','4s','6s']].copy()\ndf.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Clean `Player` column\nIn the raw form, straight from the website, the `Player` column contains the country in brackets after the player's name. I'd like to separate that out into its own column (`Country`) and remove that from `Player`. I'm going to write 2 simple regex functions that we can `apply` to the `pd.Series` to achieve this. "},{"metadata":{"trusted":true},"cell_type":"code","source":"def extract_country(player_string):\n    regex = re.compile(r'.* \\(([A-Z]*)\\)')\n    return(regex.search(player_string).group(1))\n\ndef clean_player_name(player_string):\n    regex = re.compile(r'([a-zA-Z \\-]*)\\s\\([A-Z]*\\)')\n    return(regex.search(player_string).group(1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Country'] = df.Player.apply(extract_country) # Create separate `Country` column\ndf['Player'] = df.Player.apply(clean_player_name) # Clean and replace `Player`\ndf.head(3) # Inspect new format ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Derive boundary-related metrics\nThe data as it currently stands just has the basic summary statistics for those individuals so I am going to derive some new ones that are based around the boundary hitting (using 4s and 6s), and work out the strike rate of the batsman if you remove the boundary balls from their stats.  \n\nWe will use some of these metrics later to classify the batsman into groups using `sklearn`. "},{"metadata":{"trusted":true},"cell_type":"code","source":"df['BoundaryRuns'] = df['4s'] * 4 + df['6s'] * 6\ndf['NonBoundaryRuns'] = df['Runs'] - df['BoundaryRuns']\ndf['TotalBoundaries'] = df['4s'] + df['6s']\ndf['NonBoundaryBalls'] = df['BF'] - df['TotalBoundaries']\ndf['RunsFromBoundary %'] = round(df['BoundaryRuns'] / df['Runs'] * 100, 2)\ndf['Boundary %'] = round(df['TotalBoundaries'] / df['BF'] * 100, 2)\ndf['NonBoundaryStrikeRate'] = round(df['NonBoundaryRuns'] / df['NonBoundaryBalls'] * 100, 2)\ndf['Boundary6 %'] = round(df['6s'] / (df['6s'] + df['4s']) * 100, 2)\ndf.head(3) # Inspect new format ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualising Batsman\nComparing the percentage of the balls that a batsman faced that were hit for boundaries, and the strike rate of the batsman in balls that weren't boundaries can give us a slight indication of how they approach the game.  \n\nFor example, Chris Gayle is known for his power hitting, and also his lack of running between the wickets. It therefore makes sense that his `NonBoundaryStrikeRate` is lowest of any batsman in this dataset.  \n\nIn this particular visualisation, you want to be aiming for the top right, as this indicates a lot of boundaries hit, as well as the ability to score off the balls that you don't connect with. Unfortunately this doesn't have context to the runs, as late over hitting yields both more aggressive batting, but also spread fields that allow for easy singles if you don't fully connect with the ball. "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig = px.scatter(df, \n                 x='Boundary %', \n                 y='NonBoundaryStrikeRate', \n                 color='Country', \n                 hover_name='Player', \n                 size='Runs')\n\nfig.update_layout(\n    height=500,\n    title_text='ICC Cricket World Cup 2019 - Boundary Impact'\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looking at both `Boundary %` and the `Boundary6 %` you can see the prolific 6 hitters, and the risk takers. Those that are scoring boundaries frequently, and big hits when they do go for it.  \n\nChris Gayle rises here, as his strong arms allow for more than average 6 hitting in the top half of the graph. Morgan sits at the very top of the graph, and his big hitting over the leg side is well known in international cricket; he was at it again in [South Africa](https://www.espncricinfo.com/series/19286/scorecard/1185315/south-africa-vs-england-3rd-t20i-england-in-sa-2019-20)."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = px.scatter(df, \n                 x='Boundary %', \n                 y='Boundary6 %', \n                 color='Country', \n                 hover_name='Player', \n                 size='Runs')\n\nfig.update_layout(\n    height=500,\n    title_text='ICC Cricket World Cup 2019 - 6 Hitting Impact'\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Scaling and classifying batsman data\nFirstly, I need to decide which metrics that we have defined are going to help us to group the batsman into their groups. I don't think any of the summary statistics are appropriate here, as we are trying to define the style in which the batsman performs, rather than the amount of runs that they happened to score in this tournament.  \n\nI have decided that I will work with just 3 groups in this example, which might not be the optimal grouping but I am working with only 50 players. "},{"metadata":{"trusted":true},"cell_type":"code","source":"grouping_columns = ['SR', 'RunsFromBoundary %', 'Boundary %', 'NonBoundaryStrikeRate', 'Boundary6 %']\ndf_chosen = df.loc[:,grouping_columns]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- `SR` - What is the general pace of the batsman's scoring? \n- `RunsFromBoundary %` - How reliant is the player on hitting boundaries for their runs? \n- `Boundary %` - How frequently do they find the rope? \n- `NonBoundaryStrikeRate` - Do they have other options and still able to score when not hitting boundaries?\n- `Boundary6 %` - Do they take risks to gain maximum runs for a delivery? "},{"metadata":{"trusted":true},"cell_type":"code","source":"df_scaled = pd.DataFrame(preprocessing.StandardScaler().fit_transform(df_chosen))\ndf_scaled.columns = grouping_columns\ndf_scaled.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(1)\n\n# Instantiate a model with 3 centers\nkmeans = KMeans(3)\n\n# Then fit the model to your data using the fit method\nmodel = kmeans.fit(df_scaled)\n\n# Finally predict the labels on the same data to show the category that point belongs to\nlabels = model.predict(df_scaled)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels_group = pd.Series(labels, dtype=\"category\").map({0:'A', 1:'B',2:'C'})\ndf['Batting Classification'] = labels_group","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.scatter(df, \n                 x='Boundary %', \n                 y='NonBoundaryStrikeRate', \n                 color='Batting Classification', \n                 hover_name='Player', \n                 size='Runs')\n\nfig.update_layout(\n    height=500,\n    title_text='ICC Cricket World Cup 2019 - Batting Classifications'\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_pair = df_chosen.copy()\ndf_pair['Batting Classification'] = labels_group\nsns.pairplot(df_pair, hue='Batting Classification')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The fairly simply batting classification seems to have grouped them fairly sensibly (when looking at the visuals) when we use those 5 metrics but there are some plots where all the groups are muddied in the water, the `Boundary6 %` doesn't seem to separate out the batsman as well as the `Boundary %` for example. \n\n**Group A**  \nDA Warner, Shakib Al Hasan, JE Root, Babar Azam, BA Stokes, V Kohli, F du Plessis, SPD Smith, Mushfiqur Rahim, UT Khawaja, JC Buttler, van der Dussen, MDKJ Perera, MS Dhoni, Mohammad Hafeez, HH Pandya, Mahmudullah, C de Grandhomme\n\n**Group B**  \nRG Sharma, JM Bairstow, AJ Finch, JJ Roy, AT Carey, EJG Morgan, N Pooran, Q de Kock, SO Hetmyer, CH Gayle, Zadran, WIA Fernando, Fakhar Zaman, MJ Guptill, Liton Das, GJ Maxwell, JO Holder, Soumya Sarkar\n\n**Group C**  \nKS Williamson, KL Rahul, LRPL Taylor, Imam-ul-Haq, SD Hope, Rahmat Shah, AD Mathews, Tamim Iqbal, JDS Neesham, FDM Karunaratne, HM Amla, Hashmatullah Shahidi, Gulbadin Naib"},{"metadata":{},"cell_type":"markdown","source":"### Attempting to find a better `K` value\nI'm not convinced of the value of `K` being 3. Let's use the Elbow Method and the Silhouette method to try and determine what the optimal value of `K` is.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = []\nclusters = [x for x in range(2,10)]\nfor i in clusters:\n    kmeans = KMeans(i)\n    model = kmeans.fit(df_scaled)\n    scores.append(np.abs(model.score(df_scaled)))\n    \nplt.plot(clusters, scores)  \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sil = []\n\n# dissimilarity would not be defined for a single cluster, thus, minimum number of clusters should be 2\nfor k in clusters:\n  kmeans = KMeans(n_clusters = k).fit(df_scaled)\n  labels = kmeans.labels_\n  sil.append(silhouette_score(df_scaled, labels, metric = 'euclidean'))\n\nplt.plot(clusters, sil)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The elbow method hasn't told us what the optimal level is, and the Silhouette method is just showing us that maybe more clusters would be better. I'm going to try with 8, but given the small sample size that we are clustering here, this may be too granular. "},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans = KMeans(8)\nmodel = kmeans.fit(df_scaled)\nlabels = model.predict(df_scaled)\ndf_8_clusters = df.copy()\nlabels_group = pd.Series(labels, dtype=\"category\").map({0:'A',1:'B',2:'C',3:'D',4:'E',5:'F',6:'G',7:'H'})\ndf_8_clusters['Batting Classification'] = labels_group\ndf_8_clusters['Batting Labels'] = labels\nfig = px.scatter(df_8_clusters, \n                 x='Boundary %', \n                 y='NonBoundaryStrikeRate', \n                 color='Batting Classification', \n                 hover_name='Player', \n                 size='Runs')\n\nfig.update_layout(\n    height=500,\n    title_text='ICC Cricket World Cup 2019 - Batting Classifications'\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_pair = df_chosen.copy()\ndf_pair['Batting Classification'] = labels_group\nsns.pairplot(df_pair, hue='Batting Classification')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I suppose the most notable difference here is that this has completely isolated Maxwell.\n\n- - -\n\nI think when you get the point where you have that overlap with so many of the metrics that we are looking at then we have reached a point where K means clustering isn't necessarily the ideal method here. It really only benefits groups that are circular ultimately, and that doesn't immediately appear to be the case here. It is probably also worth considering removing some variables that don't seem to add any particular variation to the scores, as they are being judged equally thanks to our scaling. Taking a quick look at the variables (pre-scaling obviously) we can see that some variables aren't as varied as each other, and above is showing that we might be better performing a PCA analysis to group together variables that are correlated to get better clusters overall. "},{"metadata":{"trusted":true},"cell_type":"code","source":"df[grouping_columns].std() / df[grouping_columns].mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- - -\n### Outliers within clusters\n\nWe can explore this further by taking a look at the indiviual silhouette scores for each of the players and seeing where the overall values lies even though the average is good with the higher number of clusters. Using those scores we can take a further look at the players that aren't clearly in one cluster or the other. "},{"metadata":{"trusted":true},"cell_type":"code","source":"silhouette_scores = silhouette_samples(df_scaled, labels)\ndf.iloc[np.where(silhouette_scores < 0)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Visualising these players might show us a bit more clearly why they could belong to multiple clusters under the current circumstances."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(df_8_clusters.loc[:, 'Boundary %'], \n            df_8_clusters.loc[:, 'NonBoundaryStrikeRate'], \n            c=df_8_clusters.loc[:, 'Batting Labels'])\ncluster_outliers = np.where(silhouette_scores < 0)\ncluster_outliers_index = df_8_clusters.index[cluster_outliers]\nplt.scatter(df_8_clusters.loc[cluster_outliers_index, 'Boundary %'], \n            df_8_clusters.loc[cluster_outliers_index, 'NonBoundaryStrikeRate'], \n            c='black', \n            s=100, alpha=0.25)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"While difficult to tell from a single graphic why these are excluded, we at least get a quick look at how those batsman could belong to more than a single cluster that we have identified. Another layer deeper into this investigation, we can take a look at the distances to the cluster centroids for these players and see if they are close to numerous other clusters. "},{"metadata":{"trusted":true},"cell_type":"code","source":"distances_to_clusters = model.transform(df_scaled)\npd.DataFrame(distances_to_clusters).join(\n    pd.Series(silhouette_scores, name='SilhouetteScore')).join(\n    pd.Series(labels, name='Group')).sort_values('SilhouetteScore').head(6)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is confusion for these values about which group they should be in. While the distances have assigned them to a particular group, the silhouette score indicates that they may be in the wrong group. It might be that they are more alike a different cluster that they are near and there was an issue with the initial random selection of the centroids at the beginning of the calculations. It may be assigned to cluster A, but might be nearer to all other points in cluster B, hence a negative silhouette score; an individual might be nearer to the centroid of its own cluster but nearer, on average, to the members of another cluster. "},{"metadata":{},"cell_type":"markdown","source":"- - - \n### Hierarchical Clustering using `scipy`\n\nTrying hierarchical clustering using `scipy.cluster.hierarchy` can yield us differnt results, ones that aren't defined using the centroids and a predetermined number of clusters. This has its benefits and we can see that we have a 4 cluster result, with Maxwell as an outlier cluster and then the main body of the results split into 3 categories; with the first cluster you can see that it is close to being 2 clusters based on the dendrogram.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"mergings = linkage(df_scaled, method='complete')\n\nfig, ax = plt.subplots(nrows = 1, ncols = 1, figsize = (9, 9))\n\ndendrogram(mergings,\n           labels=np.array(df['Player']),\n           leaf_font_size=9,\n           orientation='right',\n           ax=ax)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using different methods of clustering here can yield vastly different results. You can read about the different types of hierarchical clustering on the [scipy documentation](https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html?highlight=linkage#scipy.cluster.hierarchy.linkage) and this [good article by John Clements](https://towardsdatascience.com/introduction-hierarchical-clustering-d3066c6b560e). I will illustrate the differences below. "},{"metadata":{"trusted":true},"cell_type":"code","source":"methods = ['complete', 'single', 'average', 'centroid']\nfig, axes = plt.subplots(nrows=2, ncols=2, figsize=(11, 11))\n\nfor i, method in enumerate(methods):\n    ax = axes.flatten()[i]\n    mergings = linkage(df_scaled, method=method)\n    dendrogram(mergings,\n           labels=np.array(df['Player']),\n           leaf_font_size=7,\n           orientation='right',\n           ax=ax)\n    ax.set_title(method)\n    \nfig.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On the face of the above, you might say that Maxwell is such an outlier that the algorithms are just creating two clusters because he is so far away from them (Gayle does sneak in on the single method). Looking closer, however you can see that the order of the names and how they have been joined for the visual is indicative of how the underlying function is working in each case. Each player starts as an individual cluster and then, using the function, it joins the two nearest clusters together into a single cluster. \n\nLet's have a look and see what the results of these dendrograms look like when we remove Maxwell... "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove Maxwell \nindexes = df[df['Player'] != 'GJ Maxwell'].index\ndf_scaled_without_maxwell = df_scaled.iloc[indexes, :]\nnames = df[df['Player'] != 'GJ Maxwell'].Player\n\n# Run the visualisation again\nmethods = ['complete', 'single', 'average', 'centroid']\nfig, axes = plt.subplots(nrows=2, ncols=2, figsize=(11, 11))\n\nfor i, method in enumerate(methods):\n    ax = axes.flatten()[i]\n    mergings = linkage(df_scaled_without_maxwell, method=method)\n    dendrogram(mergings,\n           labels=np.array(names),\n           leaf_font_size=7,\n           orientation='right',\n           ax=ax)\n    ax.set_title(method)\n    \nfig.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We get much more varied results here and some interesting results. 'centroid' and 'average' are very similar with smaller clusters around the base of the visuals. 'single' is the same but with a shift of the smaller group. Whereas, 'complete' has remained essentially the same as it has made it groups with Maxwell being too far away to realistically be part of any of the existing groups. \n\nWe can generate our final resting clusters here by taking a clustering and picking a height that we can 'cut off' the dendrogram off at. In this instance, the height that you choose to cut the dendrogram off at to generate the clusters specifies the max distance between merging clusters; it says that the hierarchical clustering should stop merging clusters when all the clusters are at least this value apart. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Use fcluster to generate a set of cluster labels using a set of heights\n# NB: include Maxwell again for this\nmergings = linkage(df_scaled, method='complete')\n\nfig, ax = plt.subplots(nrows = 1, ncols = 1, figsize = (6, 6))\n\ndendrogram(mergings,\n           labels=np.array(df['Player']),\n           leaf_font_size=7,\n           orientation='right',\n           ax=ax)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Defining a height for generating cluster labels using `fcluster`\n\nYou can imagine that choosing a point to 'cut' the dendrogram is important here. The lower the value then the more clusters that we are going to have as you have a lower tolerance for the clusters to have larger distance metrics between them. If you're happy for the tolerance to be higher then the clusters will be larger. \n\nJust eye-balling the dendrogram, I'm going to pick 4 values to show the impact that picking those height metrics can have. I have then printed the dendrogram again, but with the added height thresholds for ease. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Pick a range of heights \nheights = [2.75, 4.1, 5, 8]\n\nfig, ax = plt.subplots(nrows = 1, ncols = 1, figsize = (6, 6))\n\ndendrogram(mergings,\n           labels=np.array(df['Player']),\n           leaf_font_size=7,\n           orientation='right',\n           ax=ax)\n\ncolumns = ['SR', 'RunsFromBoundary %', 'Boundary %', 'NonBoundaryStrikeRate', 'Boundary6 %', 'label']\n\nfor height in heights: \n    ax.axvline(height, c='orange')\n    labels = fcluster(mergings, height, criterion='distance')\n    display(HTML(f'<hr><h3>Height: {height} - {max(labels)} clusters</h3>'))\n    df['label'] = labels\n    display(HTML(df.loc[:, columns].groupby('label').mean().to_html()))\n    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Even with a lot if clusters at a cut-off height of 2.75, we can start to see the separation in the average stats of those with that group. As we start to allow more distance within the clusters by raising the height, we can see the clusters start to become more defined towards a 'play style'. It is only at the very end that we see Maxwell join into a cluster to create two more generic clusters, that represent those that more runs from boundaries and hit more boundaries and those that have a higher strike rate off balls that aren't boundaries, i.e. strike rotational players. "},{"metadata":{"trusted":true},"cell_type":"code","source":"df_pair = df_chosen.copy()\ndf_pair['Cluster Label'] = fcluster(mergings, 5, criterion='distance')\nsns.pairplot(df_pair, hue='Cluster Label')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### TSNE\nWe can use `TSNE` to approximate the distance of our scaled data from a higher dimension into a 2D format. I've done this below using some basic code just to illustrate the process and what the end result is. Note that I've hidden the x and y labels as they don't mean anything in this instance and add confusion to the plot in my opinion."},{"metadata":{"trusted":true},"cell_type":"code","source":"tsne_model = TSNE(learning_rate=100)\ntsne_features = tsne_model.fit_transform(df_scaled)\nx = tsne_features[:, 0]\ny = tsne_features[:, 1]\nlabels = fcluster(mergings, 5, criterion=\"distance\")\nplt.scatter(x, y, c=labels)\nplt.tick_params(axis=\"x\", which=\"both\", bottom=False, top=False, labelbottom=False)\nplt.tick_params(axis=\"y\", which=\"both\", right=False, left=False, labelleft=False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- - -\n\nI want to continue to develop this clustering and add additional methods, visualisations and try my best to explain the concepts of each method.  \n\nIf you've got any **suggestions** then please let me know, or any ideas or tips about how I can improve this kernel then I would love to hear them.  \n\nIf you've enjoyed reading this then please consider **upvoting** this kernel! "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}