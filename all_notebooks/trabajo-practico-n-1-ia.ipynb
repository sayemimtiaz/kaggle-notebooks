{"cells":[{"metadata":{},"cell_type":"markdown","source":"![](https://i.imgur.com/WEqQ4Cn.png)\n\n# √çndice\n* [Introducci√≥n](#introduccion)\n* [Explicaci√≥n de Variables](#explicacion-variables)\n* [Visualizaci√≥n de Datos](#visualizaci√≥n-datos)\n    - [Conclusi√≥n](#conclusion-datos)\n    - [An√°lisis de Datos](#analisis-datos)\n* [Selecci√≥n de Variables](#seleccion-variables)\n* [Normalizaci√≥n de los Datos](#normalizacion-datos) \n* [Clasificadores Vanilla](#clasificadores-vanilla)\n    - [Resultados](#resultados-vanilla)\n        + [Definici√≥n de M√©tricas](#metricas)\n* [Aplicando GridSearch + Cross Validation](#grid-search)\n    - [Clasificadores](#clasificadores-grid)\n    - [Resultados](#resultados-grid)\n* [Aplicando PCA + GridSearch + Cross Validation](#pca)\n    - [Implementando PCA de Scikit-Learn](#implementar-pca)\n    - [Clasificadores](#clasificadores-pca)\n    - [Resultados](#resultados-pca)\n* [Conclusi√≥n](#conclusion)\n    - [Tabla de M√©tricas](#tabla-metricas)\n* [Bibliograf√≠a](#bibliografia)\n\n<a id=\"introduccion\"></a>\n# Introducci√≥n\n\n## Contexto\n\nEl presente dataset trata sobre un videojuego del g√©nero MOBA (multijugador de arena de batalla en l√≠nea) denominado **\"League of Legends\"**, abreviado **\"LoL\"**, en donde se enfrentan **2 equipos**, uno azul y otro rojo, en un mapa que contiene **3 carriles y una jungla**, que se encuentra entre los mismos. Cada equipo posee **5 integrantes** y cada uno ocupa un rol particular dentro del mismo, siendo el objetivo el destruir el **\"nexo\"**, un edificio cr√≠tico, del otro equipo para ganar la partida.\n\n## Dataset\n\nEspec√≠ficamente, este dataset contiene diferentes estad√≠sticas de los **primeros 10 minutos** de juego de alrededor **10 mil partidas** de jugadores con **\"High Elo\"**, es decir, jugadores que alcanzaron un nivel alto dentro de la clasificaci√≥n del juego. \n\n## Objetivo\n\nLa columna **'blueWins'** es el valor objetivo (el valor que estamos tratando de predecir). Un valor de 1 significa que el equipo azul gan√≥ partida, por otro lado, un valor de 0 indica que el equipo azul perdi√≥.","execution_count":null},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":false},"cell_type":"code","source":"# Importamos algunas librer√≠as que vamos a utilizar a lo largo de este trabajo.\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\n# Importamos el dataset previamente descrito.\npath = \"../input/league-of-legends-diamond-ranked-games-10-min\"\n\ndf = pd.read_csv(path + \"/high_diamond_ranked_10min.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Como no nos va a servir para el an√°lisis de los datos, eliminamos la siguiente columna:\n* **'gameId':** identificador √∫nico utilizado en la API del juego para acceder a los datos espec√≠ficos de una partida.","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"# Eliminamos la columna 'gameId'\ndf = df.drop('gameId',  axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Una vez quitadas las columnas redundantes e innecesarias, una buena pr√°ctica es generar una matriz de correlaci√≥n. Esta matriz nos permitir√° conocer el grado de correlaci√≥n que existe entre las diferentes variables que pueblan el dataset. Pero...\n\n### Qu√© significa esto? \n\nLa matriz de correlaci√≥n muestra los **valores de correlaci√≥n de Pearson**, que miden el grado de relaci√≥n lineal entre cada par de elementos o variables. Los valores de correlaci√≥n se pueden ubicar entre -1 y +1. Sin embargo, en la pr√°ctica, los elementos por lo general tienen correlaciones positivas. Si los dos elementos tienden a aumentar o disminuir al mismo tiempo, el valor de correlaci√≥n es positivo.\n\n#### Interpretaci√≥n\n\n**Se utiliza la matriz de correlaci√≥n para evaluar la fuerza y direcci√≥n de la relaci√≥n entre dos variables.** Un valor de correlaci√≥n alto y positivo indica que los elementos miden la misma destreza o caracter√≠stica. Si los elementos no est√°n altamente correlacionados, entonces los elementos pudieran medir diferentes caracter√≠sticas o no estar claramente definidos.\n\n### Aplicado a nuestro caso\n\nPor lo tanto, aplicaremos la matriz de correlaci√≥n para observar que variables del dataset son candidatas a salir del modelo, ya que explican o miden las mismas caracter√≠sticas. Esto lo realizaremos con el siguiente c√≥digo:","execution_count":null},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"plt.figure(figsize=(20,15))\nsns.heatmap(round(df.corr(),1), cmap=\"coolwarm\", annot=True, linewidths=.5)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Conclusi√≥n de Matriz de Correlaci√≥n\n\nComo podemos observar en la matriz, existen variables que est√°n altamente correlacionadas, es decir, explican las mismas cosas. Por lo tanto, no ayudan a clasificar mejor, si no que muestran los mismos datos que otra columna. Esto ocurre, por ejemplo, con las columnas:\n* **\"RedKills\":** cantidad de asesinatos del equipo rojo.\n* **\"BlueDeaths\":** cantidad de muertes del equipo azul.\nLa cantidad de asesinatos del equipo rojo son la cantidad de muertes que tiene el equipo azul. Por lo tanto, lo acertado seria eliminar una columna, ya que una explica la otra.\n> _**Aclaraci√≥n:** dentro del juego, un jugador puede morir sin haber sido asesinado por un miembro del otro equipo, es decir, no sumar√≠a a la cantidad de kills, como por ejemplo, morir a causa de un **\"monstruo neutral\"**. Sin embargo, estamos hablando de partidas de **\"high elo\"**, en otras palabras, partidas con jugadores poseen un nivel muy alto de juego, por lo que es poco probable que ocurra. Cosas como estas deberian ser tomadas en cuenta para la selecci√≥n de variables._\n\n<a id=\"explicacion-variables\"></a>\n# Explicaci√≥n de Variables\n\n## Principales variables dentro del Juego\n\n### Experiencia\n\nDentro de **League of Legends** los jugadores utilizan a personajes, denominados **\"campeones\"**, los cuales poseen un nivel y determinadas habilidades y estad√≠sticas. Un personaje puede subir de nivel obteniendo experiencia, y hacerlo le permite mejorar sus habilidades y stats, lo que le otorga una ventaja frente al enemigo.\n\n### Oro\n\nPor otro lado, tenemos el oro, que es √∫nico en la partida y se usa para comprar objetos. Estos √∫ltimos permiten a los personajes incrementar a√∫n m√°s sus estad√≠sticas, as√≠ como obtener habilidades especiales.\n\n## Como obtenerlos?\n\nSe obtiene experiencia y oro asesinando o destruyendo diferentes objetos dentro del juego, como son:\n* **Creeps:** NPCs que pertenecen a ambos equipos. Dan oro cuando los jugadores los matan.\n* **Mostruos de Elite:** Monstruos con alto HP (Health Points) y da√±o que otorgan una bonificaci√≥n masiva de oro, XP y estad√≠sticas cuando son asesinados por un equipo, estos son:\n    * Dragones: Monstruo de √©lite que otorga bonificaciones al equipo cuando es asesinado. El 4to drag√≥n asesinado por un equipo otorga una bonificaci√≥n de estad√≠sticas masivas. El 5to drag√≥n (Elder Dragon) ofrece una gran ventaja para el equipo.\n    * Heraldos: Monstruo de √©lite que otorga bonificaci√≥n de estad√≠sticas cuando es asesinado por un jugador. Ayuda a empujar un carril y destruye estructuras.\n* **Jungle Creeps:** NPCs que no pertenecen a NING√öN EQUIPO. Dan oro y experiencia cuando los jugadores los matan.\n* **Estructuras enemigas:** Se deben destruir para llegar al \"Nexo\" enemigo. Otorgan oro al ser destruidas. Estas estructuras son:\n    * Torres\n    * Inhibidores.\n* **Campeones enemigos:** personajes del juego utulizados por los miembros del equipo opuesto.\n* **Wards:** Elemento que un jugador puede poner en el mapa para revelar el √°rea cercana. Muy √∫til para el control de mapas y objetivos, ya que la visibilidad se ve afectada por la **‚Äúniebla de guerra‚Äù.**\n\n<a id=\"visualizaci√≥n-datos\"></a>\n# Visualizaci√≥n de Datos\n\nPara ver de una manera m√°s clara que variables contribuyen menos o mas a la victoria del equipo azul, podemos realizar diferentes gr√°ficos y observar como est√°n distribuidos los datos:","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"data = df\nsns.set(font_scale=1.5)\n\nplt.figure(figsize=(20,20))\nsns.set_style(\"whitegrid\")\n\n# Cantidad de kills de cada equipo\nplt.subplot(321)\nsns.scatterplot(x='blueKills', y='redKills', hue='blueWins', data=data)\nplt.title('KILLS totales de cada equipo')\nplt.xlabel('Equipo Azul')\nplt.ylabel('Equipo Rojo')\nplt.grid(True)\n\n# Cantidad de asistencias de cada equipo\nplt.subplot(322)\nsns.scatterplot(x='blueAssists', y='redAssists', hue='blueWins', data=data)\nplt.title('ASISTENCIAS totales de cada equipo')\nplt.xlabel('Equipo Azul')\nplt.ylabel('Equipo Rojo')\nplt.tight_layout(pad=1.5)\nplt.grid(True)\n\n# Cantidad total de oro de cada equipo\nplt.subplot(323)\nsns.scatterplot(x='blueTotalGold', y='redTotalGold', hue='blueWins', data=data)\nplt.title('ORO total de de cada equipo')\nplt.xlabel('Equipo Azul')\nplt.ylabel('Equipo Rojo')\nplt.tight_layout(pad=1.5)\nplt.grid(True)\n\n# Cantidad total de experiencia de cada equipo\nplt.subplot(324)\nsns.scatterplot(x='blueTotalExperience', y='redTotalExperience', hue='blueWins', data=data)\nplt.title('EXPERIENCIA total de de cada equipo')\nplt.xlabel('Equipo Azul')\nplt.ylabel('Equipo Rojo')\nplt.tight_layout(pad=1.5)\nplt.grid(True)\n\n# Cantidad total de Wards colocadas por cada equipo\nplt.subplot(325)\nsns.scatterplot(x='blueWardsPlaced', y='redWardsPlaced', hue='blueWins', data=data)\nplt.title('WARDs totales colocadas de cada equipo')\nplt.xlabel('Equipo Azul')\nplt.ylabel('Equipo Rojo')\nplt.tight_layout(pad=1.5)\nplt.grid(True)\n\n# Juntamos la cantidad total de minions por equipo\ndata['blueMinionsTotales'] = df['blueTotalMinionsKilled'] + df['blueTotalJungleMinionsKilled']\ndata['redMinionsTotales'] = df['redTotalMinionsKilled'] + df['redTotalJungleMinionsKilled']\n\n# Total de minions asesinados por cada equipo\nplt.subplot(326)\nsns.scatterplot(x='blueMinionsTotales', y='redMinionsTotales', hue='blueWins', data=data)\nplt.title('MINIONs totales asesinados de cada equipo')\nplt.xlabel('Equipo Azul')\nplt.ylabel('Equipo Rojo')\nplt.tight_layout(pad=1.5)\nplt.grid(True)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"conclusion-datos\"></a>\n## Conclusi√≥n de visualizaci√≥n de datos\n\nDe los gr√°ficos previamente visualizados podemos decir que:\n* A mayor cantidad de **kills** y **asistencias totales** se incrementan las posibilidades de ganar.\n* Esto tambi√©n se verifica con la cantidad total de **experiencia** y **oro** por equipo, ya que a mayor cantidad de **kills** y **asistencias totales**, mayor cantidad de los primeros valores. La tendencia dice que mientras m√°s **experiencia** y **oro** tenga un equipo, mayores ser√°n sus posibilidades de ganar.\n* Las **wards** totales colocadas por equipo no parecen afectar tanto la posibilidad de que un equipo gane como las variables anteriores.\n* Lo mismo se repite con los **minions totales asesinados** por equipo.\n\n### Diferencias de Oro y Experiencia de un equipo\n\nPara ver de una manera m√°s expl√≠cita como contribuyen la **experiencia** y el **oro** a la victoria de un equipo podemos graficar la diferencia de estos valores en cada equipo:","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(20,20))\nsns.set_style(\"whitegrid\")\n\n# Diferencia de experiencia y oro\nplt.subplot(311)\nsns.scatterplot(x='blueExperienceDiff', y='blueGoldDiff', hue='blueWins', data=data)\nplt.title('Diferencia de ORO y EXPERIENCIA ')\nplt.xlabel('Diferencia de Experiencia')\nplt.ylabel('Diferencia de Oro')\nplt.grid(True)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"analisis-datos\"></a>\n## An√°lisis de Datos\n\n### Oro y Experiencia\n\nSiguiendo estas explicaciones, podemos deducir que:\n\n> _A mayor cantidad de **kills** y **asistencias**_ ü°≤ _Mayor cantidad de oro y experiencia para el equipo_ \n\n> _A mayor cantidad de **oro** y **experiencia**_ ü°≤ _Mayor ventaja sobre el equipo enemigo_ ü°≤ _Mayor probabilidad de ganar la partida_\n\nPor lo tanto, podemos decir que el **oro** y la **experiencia** que posee un equipo respecto del otro, son variables **influyen enormemente** en las posibilidades de un equipo de ganar.  \n\n### Dragones y Heraldos\n\nComo se hab√≠a descrito anteriormente, estos **monstruos de elite** otorgan **oro** y **experiencia** al equipo que los destruya, aunque tambi√©n otorgan estad√≠sticas permanentes que se van acumulando y potenciando a medida que el equipo destruya m√°s, por lo que son un objetivo prioritario.\n\n> _A mayor cantidad de **dragones** y **heraldos** asesinados_ ü°≤ _Mejores estad√≠sticas para el equipo_ ü°≤ _Mayor probabilidad de ganar la partida_\n\n### Torretas\n\nLas torretas, asi como los inhibidores, son estructuras criticas que el equipo debe destruir si quiere ganar la partida. Ademas de que otorgan **oro** y **experiencia**.\n\n### Wards\n\nComo se observaban en los gr√°ficos de las variables, la cantidad de **wards** colocadas no tienen un impacto muy grande dentro de lo que son las probabilidades de un equipo de ganar.\n\n<a id=\"seleccion-variables\"></a>\n# Selecci√≥n de Variables\n\nDadas las conclusiones obtenidas en el apartado de an√°lisis de datos, luego de haber observado los gr√°ficos, incluiremos las siguientes variables dentro del modelo, ya que son las que mas afectan las posibilidades de un equipo de ganar:\n* **Diferencia de Kills.**\n* **Diferencia de Asistencias.**\n* **Diferencia de Heraldos.**\n* **Diferencia de Dragones.**\n* **Diferencia de Torres Destruidas.**\n* **Diferencia de Oro.**\n* **Diferencia de Experiencia.**","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"# Generamos las columnas de datos que vamos a utilizar de acuerdo a lo propuesto anteriormente.\ndf['blueKillsDiff'] = df['blueKills'] - df['redKills']\ndf['blueAssistsDiff'] = df['blueAssists'] - df['redAssists']\ndf['blueHeraldsDiff'] = df['blueHeralds'] - df['redHeralds']\ndf['blueDragonsDiff'] = df['blueDragons'] - df['redDragons']\ndf['blueTowersDestroyedDiff'] = df['blueTowersDestroyed'] - df['redTowersDestroyed']\n\n# Asignamos las columnas previamente generadas en una tabla nueva lista para ser usada por los clasificadores.\nX = df[['blueKillsDiff', 'blueAssistsDiff', 'blueHeraldsDiff', 'blueDragonsDiff', \n        'blueTowersDestroyedDiff', 'blueGoldDiff', 'blueExperienceDiff']]\n\n# Asignamos la variable objetivo.\ny = df['blueWins']\n\n# Imprimimos la tabla\nX.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"normalizacion-datos\"></a>\n# Normalizaci√≥n de los datos\n\nDado que existe una gran variaci√≥n dentro del dataset en los valores que pueden tomar las diferentes variables, procederemos a normalizar los datos. Normalizar significa, en este caso, comprimir o extender los valores de la variable para que est√©n en un rango definido.\n\n## Escalado Est√°ndar (Standard Scaler)\n\nEn este caso, utilizaremos el **Escalado Est√°ndar**, en donde a cada dato se le resta la **media** de la variable y se le divide por la **desviaci√≥n t√≠pica**, segun la siguiente formula:\n\n$$Xnormalized = \\frac{X - Xmean}{Xstddev}$$","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, recall_score, precision_score, confusion_matrix\nfrom prettytable import PrettyTable\n\n# Creamos la tabla que nos permitir√° mostrar las m√©tricas obtenidas.\nmetricas = PrettyTable()\nmetricas.field_names = ['Clasificador', 'Exactitud', 'Recall', 'Precisi√≥n']\n\n# Guardaremos los resultados en un vector para ser mostrados en la conclusi√≥n del trabajo.\nresultados = []\n\n# Normalizamos los datos\nX = StandardScaler().fit(X).transform(X)\n\n# Asignamos los valores de entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state = 4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"clasificadores-vanilla\"></a>\n# Clasificadores Vanilla\n\nEn primer lugar, utilizaremos los siguientes clasificadores usando los par√°metros que vienen por defecto:\n* Regresi√≥n Log√≠stica.\n* K-Nearest Neighbours.\n* Decision Tree.\n* Random Forest.\n\n## Regresi√≥n Log√≠stica\n\n### Definici√≥n\n\nEs un tipo de an√°lisis de regresi√≥n utilizado para predecir el resultado de una variable categ√≥rica (una variable que puede adoptar un n√∫mero limitado de categor√≠as) en funci√≥n de las variables independientes o predictoras. Es √∫til para modelar la probabilidad de un evento ocurriendo como funci√≥n de otros factores. ","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\n# Instanciamos el clasificador\nLR = LogisticRegression()\n\n# Hacemos fit a los datos y realizamos la predicci√≥n.\ny_pred = LR.fit(X_train, y_train).predict(X_test)\n\n# M√©tricas de evaluaci√≥n\nexactitud = accuracy_score(y_test,y_pred)\nrecall = recall_score(y_test,y_pred)\nprecision = precision_score(y_test,y_pred)\nLR_confusion_matrix = confusion_matrix(y_test,y_pred)\n\n# Anexamos los resultados para ser mostrados posteriormente\nresultados.append(exactitud)\n\n# Formateamos los datos para mostrarlos como % en la tabla.\nexactitud = str(round(exactitud * 100, 2)) + \" %\"\nrecall = str(round(recall * 100, 2)) + \" %\"\nprecision = str(round(precision * 100, 2)) + \" %\"\n\nmetricas.add_row(['Regresi√≥n Log√≠stica', exactitud, recall, precision])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## K-Nearest Neighbours\n\n### Definici√≥n\n\nEs un algoritmo usado como m√©todo de clasificaci√≥n de elementos, basado en un entrenamiento mediante ejemplos cercanos en el espacio que existe entre estos.","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\n# Instanciamos el clasificador\nKNN = KNeighborsClassifier()\n\n# Hacemos fit a los datos y realizamos la predicci√≥n.\ny_pred = KNN.fit(X_train, y_train).predict(X_test)\n\n# M√©tricas de evaluaci√≥n\nexactitud = accuracy_score(y_test,y_pred)\nrecall = recall_score(y_test,y_pred)\nprecision = precision_score(y_test,y_pred)\nKNN_confusion_matrix = confusion_matrix(y_test,y_pred)\n\n# Anexamos los resultados para ser mostrados posteriormente\nresultados.append(exactitud)\n\n# Formateamos los datos para mostrarlos como % en la tabla.\nexactitud = str(round(exactitud * 100, 2)) + \" %\"\nrecall = str(round(recall * 100, 2)) + \" %\"\nprecision = str(round(precision * 100, 2)) + \" %\"\n\nmetricas.add_row(['K-Nearest Neighbours', exactitud, recall, precision])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Decision Tree\n\n### Definici√≥n\n\nDado un conjunto de datos, se fabrican diagramas de reglas, que sirven para representar y categorizar una serie de condiciones que ocurren de forma sucesiva, para la resoluci√≥n de un problema.","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\n# Instanciamos el clasificador\nDT = DecisionTreeClassifier()\n\n# Hacemos fit a los datos y realizamos la predicci√≥n.\ny_pred = DT.fit(X_train, y_train).predict(X_test)\n\n# M√©tricas de evaluaci√≥n\nexactitud = accuracy_score(y_test,y_pred)\nrecall = recall_score(y_test,y_pred)\nprecision = precision_score(y_test,y_pred)\nDT_confusion_matrix = confusion_matrix(y_test,y_pred)\n\n# Anexamos los resultados para ser mostrados posteriormente\nresultados.append(exactitud)\n\n# Formateamos los datos para mostrarlos como % en la tabla.\nexactitud = str(round(exactitud * 100, 2)) + \" %\"\nrecall = str(round(recall * 100, 2)) + \" %\"\nprecision = str(round(precision * 100, 2)) + \" %\"\n\nmetricas.add_row(['Decision Tree', exactitud, recall, precision])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random Forest\n\n### Definici√≥n\n\nEs una combinaci√≥n de √°rboles de decisi√≥n tal que cada √°rbol depende de los valores de un vector aleatorio probado independientemente y con la misma distribuci√≥n para cada uno de estos.","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\n# Instanciamos el clasificador\nRF = RandomForestClassifier()\n\n# Hacemos fit a los datos y realizamos la predicci√≥n.\ny_pred = RF.fit(X_train, y_train).predict(X_test)\n\n# M√©tricas de evaluaci√≥n\nexactitud = accuracy_score(y_test,y_pred)\nrecall = recall_score(y_test,y_pred)\nprecision = precision_score(y_test,y_pred)\nRF_confusion_matrix = confusion_matrix(y_test,y_pred)\n\n# Anexamos los resultados para ser mostrados posteriormente\nresultados.append(exactitud)\n\n# Formateamos los datos para mostrarlos como % en la tabla.\nexactitud = str(round(exactitud * 100, 2)) + \" %\"\nrecall = str(round(recall * 100, 2)) + \" %\"\nprecision = str(round(precision * 100, 2)) + \" %\"\n\nmetricas.add_row(['Random Forest', exactitud, recall, precision])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"resultados-vanilla\"></a>\n## Resultados\n\n<a id=\"metricas\"></a>\n### M√©tricas \n\n* **Accuracy (Exactitud):** Es el porcentaje total de elementos clasificados correctamente. Es la medida m√°s directa de la calidad de los clasificadores. Es un valor entre 0 y 1. Cuanto m√°s alto, mejor.\n\n* **Recall (Tasa de True Positive):** Es el n√∫mero de elementos identificados correctamente como positivos del total de positivos verdaderos.\n\n* **Precision:** Es el n√∫mero de elementos identificados correctamente como positivo de un total de elementos identificados como positivos.\n\n* **Confusion Matrix (Matriz de Confusi√≥n):** Es una tabla que describe el rendimiento de un modelo supervisado de Machine Learning en los datos de prueba, donde se desconocen los verdaderos valores.","execution_count":null},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"# Imprimimos el t√≠tulo de la tabla.\nprint(\"Clasificadores Vanilla (Ordenados por Exactitud)\")\n\n# Ordenamos la tabla por la columna \"Exactitud\"\nmetricas.sortby = \"Exactitud\"\n\n# Colocamos las filas en orden descendiente.\nmetricas.reversesort = True\n\n# Imprimimos la tabla\nprint(metricas)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Matrices de Confusi√≥n","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(20,10))\n\n# Ploteamos la matriz de confusi√≥n de la 'Regresi√≥n Logistica'\nplt.subplot(221)\nsns.heatmap(LR_confusion_matrix, cmap=\"coolwarm\", fmt=\".0f\",annot=True, linewidths=.5, annot_kws={\"size\": 16})\nplt.xlabel(\"Prediccion\")\nplt.ylabel(\"Verdadero\")\nplt.title('Regresi√≥n Logistica')\nplt.tight_layout(pad=1.5)\n\n# Ploteamos la matriz de confusi√≥n de la 'K-Nearest Neighbours'\nplt.subplot(222)\nsns.heatmap(KNN_confusion_matrix, cmap=\"coolwarm\", fmt=\".0f\",annot=True, linewidths=.5, annot_kws={\"size\": 16})\nplt.xlabel(\"Prediccion\")\nplt.ylabel(\"Verdadero\")\nplt.title('K-Nearest Neighbours')\nplt.tight_layout(pad=1.5)\n\n# Ploteamos la matriz de confusi√≥n de la 'Decision Tree'\nplt.subplot(223)\nsns.heatmap(DT_confusion_matrix, cmap=\"coolwarm\", fmt=\".0f\",annot=True, linewidths=.5, annot_kws={\"size\": 16})\nplt.xlabel(\"Prediccion\")\nplt.ylabel(\"Verdadero\")\nplt.title('Decision Tree')\nplt.tight_layout(pad=1.5)\n\n# Ploteamos la matriz de confusi√≥n de la 'Random Forest'\nplt.subplot(224)\nsns.heatmap(RF_confusion_matrix, cmap=\"coolwarm\", fmt=\".0f\",annot=True, linewidths=.5, annot_kws={\"size\": 16})\nplt.xlabel(\"Prediccion\")\nplt.ylabel(\"Verdadero\")\nplt.title('Random Forest')\nplt.tight_layout(pad=1.5)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"grid-search\"></a>\n# Aplicando GridSearch + Cross Validation\n\n## GridSearchCV\n\nEs una clase disponible en **scikit-learn** que permite evaluar y seleccionar de forma sistem√°tica los par√°metros de un modelo. Indic√°ndole un modelo y los par√°metros a probar, puede evaluar el rendimiento del primero en funci√≥n de los segundos mediante validaci√≥n cruzada. \n\n## Validaci√≥n Cruzada\n\nAl hacer uso de esta tecnica, el conjunto de datos de entrenamiento se divide en grupos de igual tama√±o. Una vez realizada la partici√≥n se procede a entrenar el modelo una vez por cada uno de los grupos. Utilizando todos los grupos menos el de la iteraci√≥n para entrenar y este para validar los resultados. Como se aprecia en al siguiente imagen:\n\n![](https://www.analyticslane.com/wp-content/uploads/2018/07/validacion_cruzada.jpeg.webp)","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"# Importamos la clase de scikit-learn\nfrom sklearn.model_selection import GridSearchCV\n\n# Creamos la tabla que nos permitir√° mostrar las m√©tricas obtenidas.\nmetricas_grid_search = PrettyTable()\nmetricas_grid_search.field_names = ['Clasificador', 'Exactitud', 'Recall', 'Precisi√≥n']\n\n# Guardaremos los resultados en un vector para ser mostrados en la conclusi√≥n del trabajo.\nresultados_grid_search = []","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"clasificadores-grid\"></a>\n## Clasificadores\n\n### Regresi√≥n Log√≠stica","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"# Colocamos los valores de par√°metros que queremos que GridSearchCV pruebe por nosotros\ngrid_values = {'penalty': ['l1', 'l2'],\n               'C':[.001,.009,0.01,.09,1,2,3,4,5,7,10,25],\n               'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n               'fit_intercept' : [True, False]}\n\n# Instanciamos la clase con los par√°metros previamente asignados\ngrid_clf_acc = GridSearchCV(LogisticRegression(), param_grid = grid_values, scoring = 'accuracy', verbose=False, n_jobs=-1)\n\n# Seleccionamos la tabla entera, ya que el m√©todo se encargar√° de realizar la t√©cnica de Cross-Validation\ngrid_clf_acc.fit(X, y)\n\n# Imprimimos los mejores par√°metros seleccionados por GridSearchCV\nprint(\"Par√°metros elegidos: \" + str(grid_clf_acc.best_params_) + \"\\n\")\n\n# Predecimos los valores\ny_pred_acc = grid_clf_acc.predict(X)\n\n# M√©tricas de evaluaci√≥n\nexactitud = accuracy_score(y,y_pred_acc)\nrecall = recall_score(y,y_pred_acc)\nprecision = precision_score(y,y_pred_acc)\nLR_confusion_matrix = confusion_matrix(y,y_pred_acc)\n\n# Anexamos los resultados para ser mostrados posteriormente\nresultados_grid_search.append(exactitud)\n\n# Formateamos los datos para mostrarlos como % en la tabla.\nexactitud = str(round(exactitud * 100, 2)) + \" %\"\nrecall = str(round(recall * 100, 2)) + \" %\"\nprecision = str(round(precision * 100, 2)) + \" %\"\n\nmetricas_grid_search.add_row(['Regresi√≥n Log√≠stica', exactitud, recall, precision])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### K-Nearest Neighbours","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"# Colocamos los valores de par√°metros que queremos que GridSearchCV pruebe por nosotros\ngrid_values = {\"n_neighbors\": [3, 4, 5, 6, 7],\n                 \"weights\": [\"uniform\",\"distance\"],\n                 \"metric\":[\"euclidean\",\"manhattan\"]}\n\n# Instanciamos la clase con los par√°metros previamente asignados\ngrid_clf_acc = GridSearchCV(KNeighborsClassifier(), param_grid = grid_values, scoring = 'accuracy', verbose=False, n_jobs=-1)\n\n# Seleccionamos la tabla entera, ya que el m√©todo se encargar√° de realizar la t√©cnica de Cross-Validation\ngrid_clf_acc.fit(X, y)\n\n# Imprimimos los mejores par√°metros seleccionados por GridSearchCV\nprint(\"Par√°metros elegidos: \" + str(grid_clf_acc.best_params_) + \"\\n\")\n\n# Predecimos los valores\ny_pred_acc = grid_clf_acc.predict(X)\n\n# M√©tricas de evaluaci√≥n\nexactitud = accuracy_score(y,y_pred_acc)\nrecall = recall_score(y,y_pred_acc)\nprecision = precision_score(y,y_pred_acc)\nKNN_confusion_matrix = confusion_matrix(y,y_pred_acc)\n\n# Anexamos los resultados para ser mostrados posteriormente\nresultados_grid_search.append(exactitud)\n\n# Formateamos los datos para mostrarlos como % en la tabla.\nexactitud = str(round(exactitud * 100, 2)) + \" %\"\nrecall = str(round(recall * 100, 2)) + \" %\"\nprecision = str(round(precision * 100, 2)) + \" %\"\n\nmetricas_grid_search.add_row(['K-Nearest Neighbours', exactitud, recall, precision])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Decision Tree","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"# Colocamos los valores de par√°metros que queremos que GridSearchCV pruebe por nosotros\ngrid_values = {'max_depth': np.arange(1, 21),\n               'min_samples_leaf': [1, 5, 10, 20, 50, 100]}\n\n# Instanciamos la clase con los par√°metros previamente asignados\ngrid_clf_acc = GridSearchCV(DecisionTreeClassifier(), param_grid = grid_values, scoring = 'accuracy', verbose=False, n_jobs=-1)\n\n# Seleccionamos la tabla entera, ya que el m√©todo se encargar√° de realizar la t√©cnica de Cross-Validation\ngrid_clf_acc.fit(X, y)\n\n# Imprimimos los mejores par√°metros seleccionados por GridSearchCV\nprint(\"Par√°metros elegidos: \" + str(grid_clf_acc.best_params_) + \"\\n\")\n\n# Predecimos los valores\ny_pred_acc = grid_clf_acc.predict(X)\n\n# M√©tricas de evaluaci√≥n\nexactitud = accuracy_score(y,y_pred_acc)\nrecall = recall_score(y,y_pred_acc)\nprecision = precision_score(y,y_pred_acc)\nDT_confusion_matrix = confusion_matrix(y,y_pred_acc)\n\n# Anexamos los resultados para ser mostrados posteriormente\nresultados_grid_search.append(exactitud)\n\n# Formateamos los datos para mostrarlos como % en la tabla.\nexactitud = str(round(exactitud * 100, 2)) + \" %\"\nrecall = str(round(recall * 100, 2)) + \" %\"\nprecision = str(round(precision * 100, 2)) + \" %\"\n\nmetricas_grid_search.add_row(['Decision Tree', exactitud, recall, precision])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Random Forest","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"# Colocamos los valores de par√°metros que queremos que GridSearchCV pruebe por nosotros\ngrid_values = {'max_features': ['auto', 'sqrt', 'log2'],\n                'max_depth' : [4, 5, 6, 7, 8],\n                'criterion' :['gini', 'entropy']}\n\n# Instanciamos la clase con los par√°metros previamente asignados\ngrid_clf_acc = GridSearchCV(RandomForestClassifier(), param_grid = grid_values, scoring = 'accuracy', verbose=False, n_jobs=-1)\n\n# Seleccionamos la tabla entera, ya que el m√©todo se encargar√° de realizar la t√©cnica de Cross-Validation\ngrid_clf_acc.fit(X, y)\n\n# Imprimimos los mejores par√°metros seleccionados por GridSearchCV\nprint(\"Par√°metros elegidos: \" + str(grid_clf_acc.best_params_) + \"\\n\")\n\n# Predecimos los valores\ny_pred_acc = grid_clf_acc.predict(X)\n\n# M√©tricas de evaluaci√≥n\nexactitud = accuracy_score(y,y_pred_acc)\nrecall = recall_score(y,y_pred_acc)\nprecision = precision_score(y,y_pred_acc)\nRF_confusion_matrix = confusion_matrix(y,y_pred_acc)\n\n# Anexamos los resultados para ser mostrados posteriormente\nresultados_grid_search.append(exactitud)\n\n# Formateamos los datos para mostrarlos como % en la tabla.\nexactitud = str(round(exactitud * 100, 2)) + \" %\"\nrecall = str(round(recall * 100, 2)) + \" %\"\nprecision = str(round(precision * 100, 2)) + \" %\"\n\nmetricas_grid_search.add_row(['Random Forest', exactitud, recall, precision])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"resultados-grid\"></a>\n## Resultados\n\n### M√©tricas","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"print(\"Clasificadores con GridSearchCV (Ordenados por Exactitud)\")\nmetricas_grid_search.sortby = \"Exactitud\"\nmetricas_grid_search.reversesort = True\nprint(metricas_grid_search)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Matrices de Confusi√≥n","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(20,10))\n\nplt.subplot(221)\nsns.heatmap(LR_confusion_matrix, cmap=\"coolwarm\", fmt=\".0f\",annot=True, linewidths=.5, annot_kws={\"size\": 16})\nplt.xlabel(\"Prediccion\")\nplt.ylabel(\"Verdadero\")\nplt.title('Regresi√≥n Logistica')\nplt.tight_layout(pad=1.5)\n\nplt.subplot(222)\nsns.heatmap(KNN_confusion_matrix, cmap=\"coolwarm\", fmt=\".0f\",annot=True, linewidths=.5, annot_kws={\"size\": 16})\nplt.xlabel(\"Prediccion\")\nplt.ylabel(\"Verdadero\")\nplt.title('K-Nearest Neighbours')\nplt.tight_layout(pad=1.5)\n\nplt.subplot(223)\nsns.heatmap(DT_confusion_matrix, cmap=\"coolwarm\", fmt=\".0f\",annot=True, linewidths=.5, annot_kws={\"size\": 16})\nplt.xlabel(\"Prediccion\")\nplt.ylabel(\"Verdadero\")\nplt.title('Decision Tree')\nplt.tight_layout(pad=1.5)\n\nplt.subplot(224)\nsns.heatmap(RF_confusion_matrix, cmap=\"coolwarm\", fmt=\".0f\",annot=True, linewidths=.5, annot_kws={\"size\": 16})\nplt.xlabel(\"Prediccion\")\nplt.ylabel(\"Verdadero\")\nplt.title('Random Forest')\nplt.tight_layout(pad=1.5)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"pca\"></a>\n# Aplicando PCA + GridSearch + Cross Validation\n\n## An√°lisis de Componentes Principales (PCA)\n\nEs una t√©cnica de selecci√≥n de caracter√≠sticas, que utiliza una transformaci√≥n ortogonal para convertir un conjunto de observaciones de variables, posiblemente correlacionadas, en un conjunto m√°s reducido de variables que ya no guardan correlaci√≥n y que se conocen como **componentes principales**. \n\nAl realizar este an√°lisis, intentamos buscar cuantos par√°metros m√≠nimos son necesarios para explicar una cantidad significativa de variaci√≥n en los datos, es decir, valorar cu√°nta informaci√≥n nos podemos permitir descartar al eliminar ciertos par√°metros y, de esta manera, obtener un modelo m√°s r√°pido y eficiente. \n\nEn este caso, podemos deconstruir un conjunto de datos en:\n* **Autovectores:** es una direcci√≥n.\n* **Autovalores:**: es un n√∫mero que representa el valor de la varianza en esa direcci√≥n.\n\nPor lo tanto, el componente principal ser√° el autovector con mayor autovalor. En un conjunto de datos hay tantas parejas autovector/autovalor como dimensiones. \n\n### Aplicado a nuestro caso\n\nEn nuestro caso en espec√≠fico, tenemos 7 dimensiones, dadas por cada uno de los features que hemos elegido previamente. Por lo que vamos a proceder a calcular los **autovalores** y **autovectores** de los datos, ver cuanta covarianza explica cada uno y, de esta manera, buscar reducir la dimensionalidad del conjunto de datos para obtener un modelo m√°s r√°pido, eficiente y con la m√≠nima perdida de informaci√≥n posible.","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"# Calculamos la matriz de covarianza\nmatriz_covarianza = np.cov(X.T)\n\n# Calculamos los autovalores y autovectores de la matriz\nauto_valores, auto_vectores = np.linalg.eig(matriz_covarianza)\n                                  \n# A partir de los autovalores, calculamos la varianza explicada individual y la acumulada\ntotal = sum(auto_valores)\nvarianza_explicada = [(i / total) * 100 for i in sorted(auto_valores, reverse=True)]\nvarianza_explicada_acumulada = np.cumsum(varianza_explicada)\n\n# Graficamos la varianza explicada por cada autovalor, y la acumulada\nplt.figure(figsize=(20,10))\n\nplt.bar(range(7), varianza_explicada, alpha=0.5, align='center',label='Varianza individual explicada', color='b')\nplt.step(range(7), varianza_explicada_acumulada, where='mid', linestyle='-', label='Varianza explicada acumulada', color='r')\nplt.ylabel('Varianza Explicada')\nplt.xlabel('Componentes Principales')\nplt.legend(loc='best')\nplt.tight_layout()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Evaluaci√≥n del Gr√°fico\n\nComo podemos advertir en el grafico anterior, las primeras 4 componentes explican, por lo menos, el 90% de la varianza de los datos. Por lo que procederemos a reducir la dimensionalidad de los datos utilizando estas 4 componentes.\n\n<a id=\"implementar-pca\"></a>\n## Implementando PCA de Scikit-Learn","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"# Importamos la clase de scikit-learn\nfrom sklearn.decomposition import PCA\n\n# Creamos la tabla que nos permitir√° mostrar las m√©tricas obtenidas.\nmetricas_pca = PrettyTable()\nmetricas_pca.field_names = ['Clasificador', 'Exactitud', 'Recall', 'Precisi√≥n']\n\n# Guardaremos los resultados en un vector para ser mostrados en la conclusi√≥n del trabajo.\nresultados_pca = []\n\n# Instanciamos una clase de PCA indicandole que utilizaremos 4 componentes principales\npca = PCA(n_components = 4)\nX_PCA = pca.fit(X).transform(X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"clasificadores-pca\"></a>\n## Clasificadores\n\n### Regresi√≥n Log√≠stica","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"# Colocamos los valores de par√°metros que queremos que GridSearchCV pruebe por nosotros\ngrid_values = {'penalty': ['l1', 'l2'],\n               'C':[.001,.009,0.01,.09,1,2,3,4,5,7,10,25],\n               'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n               'fit_intercept' : [True, False]}\n\n# Instanciamos la clase con los par√°metros previamente asignados\ngrid_clf_acc = GridSearchCV(LogisticRegression(), param_grid = grid_values, scoring = 'accuracy', verbose=False, n_jobs=-1)\n\n# Seleccionamos la tabla entera, ya que el m√©todo se encargar√° de realizar la t√©cnica de Cross-Validation\ngrid_clf_acc.fit(X_PCA, y)\n\n# Imprimimos los mejores par√°metros seleccionados por GridSearchCV\nprint(\"Par√°metros elegidos: \" + str(grid_clf_acc.best_params_) + \"\\n\")\n\n# Predecimos los valores\ny_pred_acc = grid_clf_acc.predict(X_PCA)\n\n# M√©tricas de evaluaci√≥n\nexactitud = accuracy_score(y,y_pred_acc)\nrecall = recall_score(y,y_pred_acc)\nprecision = precision_score(y,y_pred_acc)\nLR_confusion_matrix = confusion_matrix(y,y_pred_acc)\n\n# Anexamos los resultados para ser mostrados posteriormente\nresultados_pca.append(exactitud)\n\n# Formateamos los datos para mostrarlos como % en la tabla.\nexactitud = str(round(exactitud * 100, 2)) + \" %\"\nrecall = str(round(recall * 100, 2)) + \" %\"\nprecision = str(round(precision * 100, 2)) + \" %\"\n\nmetricas_pca.add_row(['Regresi√≥n Log√≠stica', exactitud, recall, precision])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### K-Nearest Neighbours","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"# Colocamos los valores de par√°metros que queremos que GridSearchCV pruebe por nosotros\ngrid_values = {\"n_neighbors\": [3, 4, 5, 6, 7],\n                 \"weights\": [\"uniform\",\"distance\"],\n                 \"metric\":[\"euclidean\",\"manhattan\"]}\n\n# Instanciamos la clase con los par√°metros previamente asignados\ngrid_clf_acc = GridSearchCV(KNeighborsClassifier(), param_grid = grid_values, scoring = 'accuracy', verbose=False, n_jobs=-1)\n\n# Seleccionamos la tabla entera, ya que el m√©todo se encargar√° de realizar la t√©cnica de Cross-Validation\ngrid_clf_acc.fit(X_PCA, y)\n\n# Imprimimos los mejores par√°metros seleccionados por GridSearchCV\nprint(\"Par√°metros elegidos: \" + str(grid_clf_acc.best_params_) + \"\\n\")\n\n# Predecimos los valores\ny_pred_acc = grid_clf_acc.predict(X_PCA)\n\n# M√©tricas de evaluaci√≥n\nexactitud = accuracy_score(y,y_pred_acc)\nrecall = recall_score(y,y_pred_acc)\nprecision = precision_score(y,y_pred_acc)\nKNN_confusion_matrix = confusion_matrix(y,y_pred_acc)\n\n# Anexamos los resultados para ser mostrados posteriormente\nresultados_pca.append(exactitud)\n\n# Formateamos los datos para mostrarlos como % en la tabla.\nexactitud = str(round(exactitud * 100, 2)) + \" %\"\nrecall = str(round(recall * 100, 2)) + \" %\"\nprecision = str(round(precision * 100, 2)) + \" %\"\n\nmetricas_pca.add_row(['K-Nearest Neighbours', exactitud, recall, precision])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Decision Tree","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"# Colocamos los valores de par√°metros que queremos que GridSearchCV pruebe por nosotros\ngrid_values = {'max_depth': np.arange(1, 21),\n               'min_samples_leaf': [1, 5, 10, 20, 50, 100]}\n\n# Instanciamos la clase con los par√°metros previamente asignados\ngrid_clf_acc = GridSearchCV(DecisionTreeClassifier(), param_grid = grid_values, scoring = 'accuracy', verbose=False, n_jobs=-1)\n\n# Seleccionamos la tabla entera, ya que el m√©todo se encargar√° de realizar la t√©cnica de Cross-Validation\ngrid_clf_acc.fit(X_PCA, y)\n\n# Imprimimos los mejores par√°metros seleccionados por GridSearchCV\nprint(\"Par√°metros elegidos: \" + str(grid_clf_acc.best_params_) + \"\\n\")\n\n# Predecimos los valores\ny_pred_acc = grid_clf_acc.predict(X_PCA)\n\n# M√©tricas de evaluaci√≥n\nexactitud = accuracy_score(y,y_pred_acc)\nrecall = recall_score(y,y_pred_acc)\nprecision = precision_score(y,y_pred_acc)\nDT_confusion_matrix = confusion_matrix(y,y_pred_acc)\n\n# Anexamos los resultados para ser mostrados posteriormente\nresultados_pca.append(exactitud)\n\n# Formateamos los datos para mostrarlos como % en la tabla.\nexactitud = str(round(exactitud * 100, 2)) + \" %\"\nrecall = str(round(recall * 100, 2)) + \" %\"\nprecision = str(round(precision * 100, 2)) + \" %\"\n\nmetricas_pca.add_row(['Decision Tree', exactitud, recall, precision])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Random Forest","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"# Colocamos los valores de par√°metros que queremos que GridSearchCV pruebe por nosotros\ngrid_values = {'max_features': ['auto', 'sqrt', 'log2'],\n                'max_depth' : [4, 5, 6, 7, 8],\n                'criterion' :['gini', 'entropy']}\n\n# Instanciamos la clase con los par√°metros previamente asignados\ngrid_clf_acc = GridSearchCV(RandomForestClassifier(), param_grid = grid_values, scoring = 'accuracy', verbose=False, n_jobs=-1)\n\n# Seleccionamos la tabla entera, ya que el m√©todo se encargar√° de realizar la t√©cnica de Cross-Validation\ngrid_clf_acc.fit(X_PCA, y)\n\n# Imprimimos los mejores par√°metros seleccionados por GridSearchCV\nprint(\"Par√°metros elegidos: \" + str(grid_clf_acc.best_params_) + \"\\n\")\n\n# Predecimos los valores\ny_pred_acc = grid_clf_acc.predict(X_PCA)\n\n# M√©tricas de evaluaci√≥n\nexactitud = accuracy_score(y,y_pred_acc)\nrecall = recall_score(y,y_pred_acc)\nprecision = precision_score(y,y_pred_acc)\nRF_confusion_matrix = confusion_matrix(y,y_pred_acc)\n\n# Anexamos los resultados para ser mostrados posteriormente\nresultados_pca.append(exactitud)\n\n# Formateamos los datos para mostrarlos como % en la tabla.\nexactitud = str(round(exactitud * 100, 2)) + \" %\"\nrecall = str(round(recall * 100, 2)) + \" %\"\nprecision = str(round(precision * 100, 2)) + \" %\"\n\nmetricas_pca.add_row(['Random Forest', exactitud, recall, precision])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"resultados-pca\"></a>\n## Resultados\n\n### M√©tricas ","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"print(\"Clasificadores con PCA + GridSearch + Cross Validation (Ordenados por Exactitud)\")\nmetricas_pca.sortby = \"Exactitud\"\nmetricas_pca.reversesort = True\nprint(metricas_pca)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Matrices de Confusi√≥n","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(20,10))\n\nplt.subplot(221)\nsns.heatmap(LR_confusion_matrix, cmap=\"coolwarm\", fmt=\".0f\",annot=True, linewidths=.5, annot_kws={\"size\": 16})\nplt.xlabel(\"Prediccion\")\nplt.ylabel(\"Verdadero\")\nplt.title('Regresi√≥n Logistica')\nplt.tight_layout(pad=1.5)\n\nplt.subplot(222)\nsns.heatmap(KNN_confusion_matrix, cmap=\"coolwarm\", fmt=\".0f\",annot=True, linewidths=.5, annot_kws={\"size\": 16})\nplt.xlabel(\"Prediccion\")\nplt.ylabel(\"Verdadero\")\nplt.title('K-Nearest Neighbours')\nplt.tight_layout(pad=1.5)\n\nplt.subplot(223)\nsns.heatmap(DT_confusion_matrix, cmap=\"coolwarm\", fmt=\".0f\",annot=True, linewidths=.5, annot_kws={\"size\": 16})\nplt.xlabel(\"Prediccion\")\nplt.ylabel(\"Verdadero\")\nplt.title('Decision Tree')\nplt.tight_layout(pad=1.5)\n\nplt.subplot(224)\nsns.heatmap(RF_confusion_matrix, cmap=\"coolwarm\", fmt=\".0f\",annot=True, linewidths=.5, annot_kws={\"size\": 16})\nplt.xlabel(\"Prediccion\")\nplt.ylabel(\"Verdadero\")\nplt.title('Random Forest')\nplt.tight_layout(pad=1.5)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"conclusion\"></a>\n# Conclusi√≥n","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(20,15))\nsns.set_style(\"whitegrid\")\n\nmodelos = [\"Regresi√≥n Log√≠stica\", \"K-Nearest Neighbours\", \"Decision Tree\", \"Random Forest\"]\ngrafico_resultados = pd.DataFrame({\"Puntuaci√≥n\": resultados, \"Modelos\": modelos})\ngrafico_resultados_grid_search = pd.DataFrame({\"Puntuaci√≥n\": resultados_grid_search, \"Modelos\": modelos})\ngrafico_resultados_pca = pd.DataFrame({\"Puntuaci√≥n\": resultados_pca, \"Modelos\": modelos})\n\nplt.subplot(311)\nsns.barplot(\"Puntuaci√≥n\", \"Modelos\", data = grafico_resultados)\nplt.ylabel(\"\")\nplt.title('Clasificadores Vanilla')\nplt.tight_layout(pad=2)\n\nplt.subplot(312)\nsns.barplot(\"Puntuaci√≥n\", \"Modelos\", data = grafico_resultados_grid_search)\nplt.ylabel(\"\")\nplt.title('Clasificadores con GridSearch + Cross Validation')\nplt.tight_layout(pad=2)\n\nplt.subplot(313)\nsns.barplot(\"Puntuaci√≥n\", \"Modelos\", data = grafico_resultados_pca)\nplt.title('Clasificadores con PCA + GridSearch + Cross Validation')\nplt.ylabel(\"\")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Observaci√≥n de los Gr√°ficos\n\nGracias a los graficos previos, podemos observar que:\n* La **Regresi√≥n Log√≠stica** tiene una mayor exactitud si lo comparamos al resto de clasificadores utilizando los par√°metros por defecto.\n* Cuando aplicamos **Grid Search** y **PCA**, podemos observar que el algoritmo de **KNN** tiende a precedir mejor los resultados que el resto de los m√©todos.\n* Tambien podemos notar que los dem√°s metodos, como son **Decision Tree** y **Random Forest**, que antes tenian un porcentaje de exactitud menor, han aumentado dicha metrica y se han colocado por encima del algoritmo que antes se encontraba liderando, es decir, la **Regresi√≥n Log√≠stica.**\n\n<a id=\"tabla-metricas\"></a>\n## Tabla de M√©tricas","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"metricas.sortby = \"Clasificador\"\nmetricas_grid_search.sortby = \"Clasificador\"\nmetricas_pca.sortby = \"Clasificador\"\n\nprint(\"Clasificadores Vanilla\")\nprint(metricas)\nprint(\"\")\nprint(\"Clasificadores con GridSearch + Cross Validation\")\nprint(metricas_grid_search)\nprint(\"\")\nprint(\"Clasificadores con PCA + GridSearch + Cross Validation\")\nprint(metricas_pca)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"bibliografia\"></a>\n# Bibliograf√≠a\n\n## Uso de Herramientas y Clasificadores\n\n* [matplotlib](https://matplotlib.org/3.2.1/api/index.html)\n* [numpy](https://numpy.org/doc/1.18/reference/index.html)\n* [pandas](https://pandas.pydata.org/docs/reference/frame.html)\n* [seaborn](https://seaborn.pydata.org/api.html)\n* [scikit-learn](https://scikit-learn.org/stable/modules/classes.html)\n\n## Conceptos Teoricos\n* [Concepto y uso de GridSearchCV](https://www.analyticslane.com/2018/07/02/gridsearchcv/)\n* [Matriz de Correlaci√≥n](https://support.minitab.com/es-mx/minitab/18/help-and-how-to/modeling-statistics/multivariate/how-to/item-analysis/interpret-the-results/all-statistics-and-graphs/)\n* [Matriz de Confusi√≥n](https://empresas.blogthinkbig.com/ml-a-tu-alcance-matriz-confusion/)\n* [GitHub de la c√°tedra](https://github.com/inteligenciafrvm/inteligenciafrvm)\n* [Normalizaci√≥n de los datos](https://empresas.blogthinkbig.com/precauciones-la-hora-de-normalizar/)\n* [M√©tricas de Clasificaci√≥n](https://sitiobigdata.com/2019/01/19/machine-learning-metrica-clasificacion-parte-3/#)\n* [An√°lisis de Componentes Principales (PCA)](https://empresas.blogthinkbig.com/python-para-todos-que-es-el-pca/)","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}