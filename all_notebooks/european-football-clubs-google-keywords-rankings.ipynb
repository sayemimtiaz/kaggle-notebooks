{"cells":[{"metadata":{},"cell_type":"markdown","source":"# European Football Clubs Google Keywords Rankings\n\nThe most popular European Football clubs are some of the most searched keywords in many places. This is a quick overview of the domains that rank for those clubs' keywords. \n\n## Methodology\n\n- **Club selection:** I got the top clubs from the Wikipedia list, containing all [clubs that won at least one UEFA championship](https://en.wikipedia.org/wiki/List_of_UEFA_club_competition_winners)\n- **Keyword selection:** Every club name was appended with the word \"football\" to make it explicit and clear that it is the club and not the city (where applicable). I also did the same for seven of the top languages (based on the top seven countries who's clubs won the most championships). As a result the same keyword was requested seven times.  \nExample:\n'real madrid football', 'real madrid fútbol', 'real madrid fußball', 'milan football, 'milan fútbol', 'milan fußball', etc.\n\n- **Resulting data set:**  \nclubs: 79  \nlanguages: 7  \nqueries: 79 x 7 = 553  \nresults: 10 x 553 = 5,530  "},{"metadata":{},"cell_type":"markdown","source":"### Packages and versions"},{"metadata":{"pycharm":{"is_executing":false},"trusted":true},"cell_type":"code","source":"import advertools as adv\nimport pandas as pd\npd.options.display.max_columns = None\nfrom plotly.tools import make_subplots\nimport plotly.graph_objs as go\nimport plotly\nfrom plotly.offline import iplot, init_notebook_mode\ninit_notebook_mode()\n\nprint('Package         Version')\nprint('=' * 25)\nfor package in [plotly, pd, adv]:\n    print(f'{package.__name__:<15}', ': ', package.__version__, sep='')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Generating the data\nThe following code was used to generate the dataset.  \nFirst we get two tables from the Wikpedia article and save them as CSV files: "},{"metadata":{"pycharm":{"is_executing":false},"trusted":true},"cell_type":"code","source":"# page = 'https://en.wikipedia.org/wiki/List_of_UEFA_club_competition_winners'\n# column_key = pd.read_html(page)[0]\n# column_key = column_key.rename(columns={0: 'abbreviation', 1: 'tournament'})\n# column_key.to_csv('column_key.csv', index=False)\n# clubs = pd.read_html(page)[1]\n# clubs.to_csv('clubs.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"`column_key` is a table that simply lists the abbreviations in the bigger table and their expansions."},{"metadata":{"trusted":true},"cell_type":"code","source":"column_key = pd.read_csv('../input/column_key.csv')\ncolumn_key","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"`clubs` is the DataFrame that we will be working with, and below is a sample."},{"metadata":{"pycharm":{"is_executing":false,"metadata":false,"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"clubs = pd.read_csv('../input/clubs.csv')\nclubs.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A quick exploration of the data set. "},{"metadata":{"pycharm":{"is_executing":false,"metadata":false,"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"top_countries = (clubs\n                 .groupby('Country')\n                 .agg({'Total': 'sum'})\n                 .sort_values('Total', ascending=False)\n                 .reset_index()\n                 .head(10))\ntop_countries","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"is_executing":false,"metadata":false,"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"(clubs\n .groupby(['Country'])\n .agg({'Club': 'count', 'Total': 'sum'})\n .sort_values('Club', ascending=False)\n .reset_index()\n .head(9)\n .set_axis(['country', 'num_clubs', 'total_wins'], axis=1, inplace=False)\n .assign(wins_per_club=lambda df: df['total_wins'].div(df['num_clubs']))\n .style.background_gradient(high=0.2))\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* More English teams won tournaments than any other country, while Spanish teams won more tournaments per club (and more tournaments overall). \n\nThe names of the clubs will be used to run the requests to Google."},{"metadata":{"pycharm":{"is_executing":false,"metadata":false,"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"clubs_list = clubs['Club'].str.lower().tolist()\nclubs_list[:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"`lang_football` is a simple dictionary listting the seven languages, and the word 'football' in that language. "},{"metadata":{"trusted":true},"cell_type":"code","source":"lang_football = {'en': 'football',\n                 'fr': 'football',\n                 'de': 'fußball',\n                 'es': 'fútbol',\n                 'it': 'calcio',\n                 'pt-BR': 'futebol',\n                 'nl': 'voetbal'}\nlang_football","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The code in the following cell generates the data set. There is some setup that needs to be done if you want to run the code yourself.\n\n1. [Create a custom search engine.](https://cse.google.com/cse/) At first, you might be asked to enter a site to search. Enter any domain, then go to the control panel and remove it. Make sure you enable \"Search the entire web\" and image search. You will also need to get your search engine ID, which you can find on the control panel page.\n2. [Enable the custom search API.](https://console.cloud.google.com/apis/library/customsearch.googleapis.com) The service will allow you to retrieve and display search results from your custom search engine programmatically. You will need to create a project for this first.\n3. [Create credentials for this project](https://console.developers.google.com/apis/api/customsearch.googleapis.com/credentials) so you can get your key.\n4. [Enable billing for your project](https://console.cloud.google.com/billing/projects) if you want to run more than 100 queries per day. The first 100 queries are free; then for each additional 1,000 queries, you pay USD $5.\n\nThe [`advertools`](https://github.com/eliasdabbas/advertools) function `serp_goog` can take several possible parameters to customize the search query, and for this one we will be using two only: \n\n* `q`: The query we are searching for. Note that this can be a list of queries, and the looping is done for you, as in this case. \n* `hl`: The interface language (human-language). This tells Google to return results for a user who is using a computer/browser in this specific interface language. Like all other parameters of the function, `hl` can also be provided as a list of languages. When running hundreds of queries I like to split them into a few chunks, just in case something goes wrong (a connection error for example). But you can actually generate the whole data set with one function call. "},{"metadata":{"pycharm":{"is_executing":false,"metadata":false,"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"# cx = 'YOUR_CX_FROM_GOOGLE'\n# key = 'YOUR_GOOGLE_DEV_KEY'\n\n# serp_dfs = []\n# for lang, q in lang_football.items():\n#     temp_serp = adv.serp_goog(cx=cx, key=key, \n#                               hl=lang,\n#                               q=[club + ' ' + q for club in clubs_list])\n#     serp_dfs.append(temp_serp)\n\n# serp_clubs = pd.concat(serp_dfs, sort=False)\n# serp_clubs.to_csv('serp_clubs.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"is_executing":false,"metadata":false,"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"serp_clubs = pd.read_csv('../input/serp_clubs.csv', parse_dates=['queryTime'])\nprint(serp_clubs.shape)\nserp_clubs.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I think it's a good idea to have the country of each club, and the club itself, as separate columns so we can group and analyze by country and club.  \nWe first create the `club_country` dictionary, which simply maps the clubs to their respective countries from our `clubs` DataFrame.  \nThen we create our regular expression to remove all the 'football' words. This way we can get the corresponding country for each extracted club. The same dictionary can be used to extract clubs. "},{"metadata":{"trusted":true},"cell_type":"code","source":"club_country = {club.lower(): country.lower() for club, country in zip(clubs['Club'], clubs['Country'])}\nfootball_multi = '|'.join([' ' + football for football in lang_football.values()])\n\nserp_clubs['country'] = [club_country[club].title()\n                         for club in serp_clubs['searchTerms'].str.replace(football_multi, '')]\nserp_clubs['club'] = serp_clubs['searchTerms'].str.replace(football_multi, '').str.title()\nserp_clubs[['searchTerms', 'country', 'club']].sample(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Top domains"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('unique domains:', serp_clubs['displayLink'].nunique())\nprint('number of results:', serp_clubs.__len__())\nserp_clubs['displayLink'].value_counts().reset_index()[:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you can see the top domains ranking for these keywords are dominated by Wikipedia. This is is not surprising, because the keywords are quite generic. Also, these are the top domains for the whole data set. It would be better to check the same for each language, country, or club, to get a more meaningful summary. \n\n#### Top domains for Barcelona:"},{"metadata":{"trusted":true},"cell_type":"code","source":"serp_clubs[serp_clubs['club']=='Barcelona']['displayLink'].value_counts().reset_index()[:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Top domains for German keywords:"},{"metadata":{"trusted":true},"cell_type":"code","source":"serp_clubs[serp_clubs['hl']=='de']['displayLink'].value_counts().reset_index()[:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Top domains for Italian clubs:"},{"metadata":{"trusted":true},"cell_type":"code","source":"serp_clubs[serp_clubs['country']=='Italy']['displayLink'].value_counts().reset_index()[:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Either Italian sites need to focus on their SEO or Italian teams are extremely popular in other languages! \nThe above can be run for any other parameter, or combination of parameters as well.  \n\nI think it's also good to see if there are certain URLs that are dominant. The `link` column shows the actual landing page that the user will be directed to. "},{"metadata":{"trusted":true},"cell_type":"code","source":"serp_clubs['link'].value_counts().reset_index()[:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It seems seven is the highest number of appearances on SERPs for any particular URL. So we don't have any dominant landing pages, as we do with domains.  \n"},{"metadata":{},"cell_type":"markdown","source":"## Top-level domains (TLDs)\n\nSince we are researching clubs that belong to national leagues, and we are also searching in different languages, it might be interesting as well to check for the most used TLDs. Are they mostly .com or is there a big percentage that is on a local domain?\n\n[`advertools`](https://github.com/eliasdabbas/advertools) provides the `extract_urls` function among other `extract_` functions that help in getting data on hashtags, mentions, URLs, and more. In our case we would be interested in the `top_tlds` key in the resulting dictionary:"},{"metadata":{"trusted":true},"cell_type":"code","source":"adv.extract_urls(serp_clubs['link'])['top_tlds'][:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can also expand this to see totals, percentages, cumulative sums, and cumulative percentages for each of the TLDs in our data set: "},{"metadata":{"trusted":true},"cell_type":"code","source":"(pd.DataFrame({\n    'tld': [x[0] for x in  adv.extract_urls(serp_clubs['link'])['top_tlds']],\n    'freq': [x[1] for x in  adv.extract_urls(serp_clubs['link'])['top_tlds']]\n}).assign(percentage=lambda df: df['freq'].div(df['freq'].sum()),\n          cumsum=lambda df: df['freq'].cumsum(), \n          cum_perc=lambda df: df['cumsum'].div(df['freq'].sum()))\n .head(15)\n .style.format({'percentage': '{:.2%}', 'cumsum': '{:,}', 'cum_perc': '{:.2%}'}))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Word frequency \nChecking the most commonly used words in a text list can help us in understanding what this list is about. A simple way is to use the `word_frequency` function from `advertools`.\n\nHere I check the word counts in the titles of those pages: "},{"metadata":{"trusted":true},"cell_type":"code","source":"adv.word_frequency(serp_clubs['title'],\n                   rm_words=adv.stopwords['english'].union(['-', '|', '  ', ''])).head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Nothing surprising here. Mostly the generic words that you would expect to see.  \nThe same can be done by getting a subset of the data set, for example, these are the most used words in titles in Dutch: "},{"metadata":{"trusted":true},"cell_type":"code","source":"adv.word_frequency(serp_clubs[serp_clubs['hl']=='nl']['title'],\n                   rm_words=adv.stopwords['english'].union(['-', '|', '  ', ''])).head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some websites don't expose their snippets to search engines, and it's good to see if we have a lot of those: "},{"metadata":{"trusted":true},"cell_type":"code","source":"serp_clubs['snippet'].isna().sum(), serp_clubs['title'].isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"serp_clubs[serp_clubs['snippet'].isna()]['displayLink'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Only three domains are doing this, on a total of thirty one landing pages. Not a big issue.  \nWe can also check if there are any interesting words used in the snippets:"},{"metadata":{"trusted":true},"cell_type":"code","source":"adv.word_frequency(serp_clubs['snippet'].fillna(''),\n                   rm_words=adv.stopwords['english'].union(['-', '|', '  ','·', '', 'de'])).head(15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Word counts in snippets in English:"},{"metadata":{"trusted":true},"cell_type":"code","source":"adv.word_frequency(serp_clubs[serp_clubs['hl']=='en']['snippet'].fillna(''),\n                   rm_words=adv.stopwords['english'].union(['-', '|', '  ','·', '', 'de'])).head(15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now it is a bit more specific, and you might want to dig deeper and see which domains focus on what kind of words; statistics, results, fixtures, etc.  \nCounting words can also be in the form of short phrases. For example, here we count the 2-word phrases used in the snippets of all SERPs for Liverpool.  \nWe only have to specify the `phrase_len` parameter to any length we want. "},{"metadata":{"trusted":true},"cell_type":"code","source":"adv.word_frequency(serp_clubs[serp_clubs['club']=='Liverpool']['snippet'].fillna(''),\n                   phrase_len=2,\n                   rm_words=adv.stopwords['english'].union([ '|', '', 'de'])).head(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Competitiveness: number of available results\nAs you know it's also very important to know how competitive your keywords are. One of the measures is how many pages are eligible to appear for a particular keyword. More pages usually means more competition, but not necessarily. A small number of domains might be doing very high quality/aggressive SEO, which would make it more competitive. But the number is still a good measure, because usually if a keyword is worth competing for, it is usually a popular topic and many websites would be writing about it. \n\n#### Total results by keyword:"},{"metadata":{"trusted":true},"cell_type":"code","source":"(serp_clubs\n .drop_duplicates(['searchTerms'])\n .groupby('searchTerms', as_index=False)\n .agg({'totalResults': 'sum'})\n .sort_values('totalResults', ascending=False)\n .reset_index(drop=True)\n [:10]\n .style.format({'totalResults': '{:,}'}))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Total results by club (across all languages):"},{"metadata":{"trusted":true},"cell_type":"code","source":"(serp_clubs\n .drop_duplicates(['searchTerms'])\n .groupby('club', as_index=False)\n .agg({'totalResults': 'sum'})\n .sort_values('totalResults', ascending=False)\n .reset_index(drop=True)\n [:10]\n .style.format({'totalResults': '{:,}'}))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Good luck trying to rank for any of those keywords! \n\n## Top domains per language"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = make_subplots(1, 7, print_grid=False, shared_yaxes=True)\nfor i, lang in enumerate(serp_clubs['hl'].unique()[:7]):\n    df = serp_clubs[serp_clubs['hl']==lang]\n    \n    fig.append_trace(go.Bar(y=df['displayLink'].value_counts().values[:8], \n                            x=df['displayLink'].value_counts().index.str.replace('www.', '')[:8],\n                            name=lang,\n                            orientation='v'), row=1, col=i+1)\n\n\nfig.layout.margin = {'b': 150, 'r': 30}\nfig.layout.legend.orientation = 'h'\nfig.layout.legend.y = -0.5\nfig.layout.legend.x = 0.15\nfig.layout.title = 'Top Domains by Language of Search'\nfig.layout.yaxis.title = 'Number of Appearances on SERPs'\nfig.layout.plot_bgcolor = '#eeeeee'\nfig.layout.paper_bgcolor = '#eeeeee'\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = make_subplots(1, 7, shared_yaxes=True, print_grid=False)\nfor i, country in enumerate(serp_clubs['country'].unique()[:7]):\n    if country in top_countries['Country'][:7].values:\n        df = serp_clubs[serp_clubs['country']==country]\n\n        fig.append_trace(go.Bar(y=df['displayLink'].value_counts().values[:8], \n                                x=df['displayLink'].value_counts().index.str.replace('www.', '')[:8],\n                                name=country,\n                                orientation='v'), row=1, col=i+1)\n\nfig.layout.margin = {'b': 150, 'r': 0}\nfig.layout.legend.orientation = 'h'\nfig.layout.legend.y = -0.5\nfig.layout.legend.x = 0.15\nfig.layout.title = 'Top Domains by Country of Club'\nfig.layout.yaxis.title = 'Number of Appearances on SERPs'\nfig.layout.plot_bgcolor = '#eeeeee'\nfig.layout.paper_bgcolor = '#eeeeee'\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the last two charts a higher number of appearances shows that for that language, there is more concentration of ranking in a few domains. \n\n## SERP summary/visualization\n\nFinally, we can visually summarize the results by showing which domain appeared, on each position, and how many times each. The follosing function is copied from a recipe I created to [visualize and summarize SERPs.](https://www.kaggle.com/eliasdabbas/coffee-and-cafe-search-engine-rankings-on-google)"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_serps(df, opacity=0.1, num_domains=10, width=None, height=700):\n    \"\"\"\n    df: a DataFrame resulting from running advertools.serp_goog\n    opacity: the opacity of the markers [0, 1]\n    num_domains: how many domains to plot\n    \"\"\"\n    top_domains = df['displayLink'].value_counts()[:num_domains].index.tolist()\n    top_df = df[df['displayLink'].isin(top_domains)]\n    top_df_counts_means = (top_df\n                       .groupby('displayLink', as_index=False)\n                       .agg({'rank': ['count', 'mean']})\n                       .set_axis(['displayLink', 'rank_count', 'rank_mean'],\n                                 axis=1, inplace=False))\n    top_df = (pd.merge(top_df, top_df_counts_means)\n          .sort_values(['rank_count', 'rank_mean'],\n                       ascending=[False, True]))\n    rank_counts = (top_df\n               .groupby(['displayLink', 'rank'])\n               .agg({'rank': ['count']})\n               .reset_index()\n               .set_axis(['displayLink', 'rank', 'count'],\n                         axis=1, inplace=False))\n    num_queries = df['queryTime'].nunique()\n    fig = go.Figure()\n    fig.add_scatter(x=top_df['displayLink'].str.replace('www.', ''),\n                    y=top_df['rank'], mode='markers',\n                    marker={'size': 35, 'opacity': opacity},\n                    showlegend=False)\n    fig.layout.height = 600\n    fig.layout.yaxis.autorange = 'reversed'\n    fig.layout.yaxis.zeroline = False\n    fig.add_scatter(x=rank_counts['displayLink'].str.replace('www.', ''),\n                y=rank_counts['rank'], mode='text',\n                marker={'color': '#000000'},\n                text=rank_counts['count'], showlegend=False)\n    for domain in rank_counts['displayLink'].unique():\n        rank_counts_subset = rank_counts[rank_counts['displayLink']==domain]\n        fig.add_scatter(x=[domain.replace('www.', '')],\n                        y=[11], mode='text',\n                        marker={'size': 50},\n                        text=str(rank_counts_subset['count'].sum()))\n        fig.add_scatter(x=[domain.replace('www.', '')],\n                        y=[12], mode='text',\n                        text=format(rank_counts_subset['count'].sum() / num_queries, '.1%'))\n        fig.add_scatter(x=[domain.replace('www.', '')],\n                        y=[13], mode='text',\n                        marker={'size': 50},\n                        text=str(round(rank_counts_subset['rank']\n                                       .mul(rank_counts_subset['count'])\n                                       .sum() / rank_counts_subset['count']\n                                       .sum(),2)))\n#     fig.layout.title = ('Google Search Results Rankings<br>keyword(s): ' + \n#                         ', '.join(list(df['searchTerms'].unique()[:5])) + \n#                         str(df['queryTime'].nunique()) + ' Football (Soccer) Queries')\n    fig.layout.hovermode = False\n    fig.layout.yaxis.autorange = 'reversed'\n    fig.layout.yaxis.zeroline = False\n    fig.layout.yaxis.tickvals = list(range(1, 14))\n    fig.layout.yaxis.ticktext = list(range(1, 11)) + ['Total<br>appearances','Coverage', 'Avg. Pos.'] \n    fig.layout.height = height\n    fig.layout.width = width\n    fig.layout.yaxis.title = 'SERP Rank (number of appearances)'\n    fig.layout.showlegend = False\n    fig.layout.paper_bgcolor = '#eeeeee'\n    fig.layout.plot_bgcolor = '#eeeeee'\n    return fig","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plot_serps(serp_clubs, opacity=0.05)\nfig.layout.title = 'SERPs for \"<club_name> football\" (79 clubs)'\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plot_serps(serp_clubs[serp_clubs['hl']=='es'], opacity=0.15)\nfig.layout.title = 'SERPs for \"<club_name> fútbol\" in Spanish (79 clubs)'\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plot_serps(serp_clubs[serp_clubs['hl']=='en'], opacity=0.15)\nfig.layout.title = 'SERPs for \"<club_name> football\" in English (79 clubs)'\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plot_serps(serp_clubs[serp_clubs['hl']=='de'], opacity=0.15)\nfig.layout.title = 'SERPs for \"<club_name> fußball\" in German (79 clubs)'\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plot_serps(serp_clubs[serp_clubs['club']=='Liverpool'], opacity=0.15, num_domains=15)\nfig.layout.title = 'SERPs for \"liverpool football\"'\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Many other options can be explored: \n* Try with other more specific keywords. <club_name> tickets, results, transfers, etc. \n* Summarize/visualize other combinations of languages, clubs, countries. \n* Try other search parameters like user geo-location, search type, etc.\n\n## Further resources for getting, visualizing, and analyzing Google SERPs:\n\n\n* [A tutorial on how to use the `serp_goog`](https://www.kaggle.com/eliasdabbas/search-engine-results-pages-serps-research) function and how the different parameters work: \n* [Analyze flights and tickets SERPs](https://www.semrush.com/blog/analyzing-search-engine-results-pages/) (article on SEMrush)\n* [Analyze Google and YouTube SERPs for the same keywords](https://www.kaggle.com/eliasdabbas/recipes-keywords-ranking-on-google-and-youtube)\n* [Documentation of the `serp_goog` function](https://advertools.readthedocs.io/en/master/advertools.html#module-advertools.serp)\n* [Text analysis for online marketing](https://www.semrush.com/blog/text-analysis-for-online-marketers) is a tutorial to explains the `word_freq` function and what can be done to count words on an absolute and weighted basis. "}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"}},"nbformat":4,"nbformat_minor":1}