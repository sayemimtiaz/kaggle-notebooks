{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Prototype: Machine Learning Phase\n\n# Correlations between demographic and socio-economic factors and incidence of Covid 19 infection and mortality in U.S. Counties\n\n#### Objective\nGain a greater understanding of the relationship between race/ethnicity, gender, poverty and severe health conditions and Covid 19 morbidity and mortality.\nApply skills recently acquired via part-time Data Science course at General Assembly Australia.\n\n#### Method\nPrevious project phases completed:\n1. Source data on race/ethnicity, gender, poverty and severe health conditions and Covid 19 morbidity and mortality at the U.S county level\n2. Clean and pre-process data according to unique identifiers\n3. Conduct exploratory data analysis\n4. Test hypothesis that no relationship exists between features using statistical regression (Ordinary Least Squares).\n\nIn this phase:\n5. Test hypothesis that features with highest importance are <b>unable</b> to predict Covid 19 morbidity and mortality using machine learning (Random Forest).\n6. Compare accuracy of Random Forest algorhythm against an alternative algorhythm.\n7. Articulate conclusions and next steps.\n\n### Data Sources\nData for this prototype was sourced and cleaned from the following sources:\n1. Covid 19 Morbidity by U.S Count (USA Facts/U.S CDC, 2020): timeseries from 22/01/2020 to 31/07/2020 \n2. Covide 19 Mortality by U.S. County (USA Facts/U.S. CDC, 2020): timeseries from 22/01/2020 to 31/07/2020\n3. Poverty Universe, All ages, by U.S County (SAIPE, U.S Census, 2019)\n4. Annual County Resident Population Estimates by Age, Sex, Race, and Hispanic Origin (U.S Census, 2019)\n5. Severe COVID-19 Health Risk Index by U.S County (Policy Map/NY Times/2017 SMART-BRFSS, U.S CDC, 2017) \n\n### Acknowledgments\n- Thanks to my instructors Andrew Worsely, Lydia Peabody, the team at General Assembly and my peers in GA Data Science June-August 2020.\n- Julian Hatwell"},{"metadata":{},"cell_type":"markdown","source":"## Model 1: Predicting Morbidity\n\nApply statistical insights to create and test a machine learning model where y = morbitity (cases) using Random Forest algorithm as a baseline.\n\n### Iteration 1A: All Features Used\n\n### Feature & Target Selection\n\nPre-processed data from Prototype Phase 1 imported where all population values and values for Risk Index are log-transformed.  "},{"metadata":{"trusted":false},"cell_type":"code","source":"import pandas as pd\n\nall_data_4 = pd.read_csv(\"../input/covid-19-race-gender-poverty-risk-us-county/covid_data_log_200922.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Input and output variable defined. Non-numerical features dropped. "},{"metadata":{"trusted":false},"cell_type":"code","source":"y = all_data_4[\"Cases\"]\n\nX = all_data_4.drop([\"Deaths\", \"Cases\", \"FIPS\", \"stateFIPS\"\n                     , \"countyFIPS_2d\", \"County\", \"State\", \"Risk_Cat\"],  axis=1)\n\nX","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train / Test Split"},{"metadata":{"trusted":false},"cell_type":"code","source":"# train-test split\nfrom sklearn.model_selection import train_test_split\n\n# allocate 70% at random to training data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Algorithm Selected\n\nRandom Forest Regressor selected due to likelihood that it handles non-normalised population data that has an extremely large range with greater efficiency, plus feature importance evaluation.\n\nUse the features importance methods in Random Forest (out-of-bag=TRUE), look for variable importance results, test and evaluate."},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\nreg = RandomForestRegressor(max_depth=2, random_state=10, oob_score=True, bootstrap=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model Fitting"},{"metadata":{"trusted":false},"cell_type":"code","source":"reg.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature Importances"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Get numerical feature importances\nimportances = list(reg.feature_importances_)\n\n# List of tuples with variable and importance\nfeature_importances = [(feature, round(importance, 2)) for feature, importance in zip(X_train, importances)]\n\n# Sort the feature importances by most important first\nfeature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n\n# Print out the feature and importances \n[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model Evaluation"},{"metadata":{"trusted":false},"cell_type":"code","source":"preds = reg.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"evaluate = pd.DataFrame({\n    \"actual\" : y_test\n    , \"predicted\" : preds\n})\n\nevaluate[\"error\"] = evaluate[\"actual\"] - evaluate[\"predicted\"]\n\nevaluate.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"import numpy as np\n\n# Calculate the absolute errors\nerrors = abs(preds - y_test)\n\n# Print out the mean absolute error (mae)\nprint('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Iteration 1B: Most Important Features Only\n\n### Feature & Target Selection\n\nSecond model iteration guided by feature importance data from 1st Iteration. Input and output variable defined. Non-numeric features dropped."},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"all_data_5 = all_data_4.copy()\n\ny = all_data_5[\"Cases\"]\n\nX = all_data_5.drop([\"Deaths\", \"Cases\", \"FIPS\", \"stateFIPS\", \"countyFIPS_2d\", \"County\"\n                     , \"State\", \"Risk_Cat\", \"Risk_Index\", \"H_Male\", \"H_Female\", \"I_Male\", \"I_Female\"\n                    , \"A_Male\", \"A_Female\", \"NH_Male\", \"NH_Female\"],  axis=1)\n\nX","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train / Test Split"},{"metadata":{"trusted":false},"cell_type":"code","source":"# train-test split\nfrom sklearn.model_selection import train_test_split\n\n# allocate 70% at random to training data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Use the features importance methods in Random Forest (out-of-bag=TRUE), look for variable importance results, test and evaluate."},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\nreg = RandomForestRegressor(max_depth=2, random_state=10, oob_score=True, bootstrap=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"reg.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature Importance"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Get numerical feature importances\nimportances = list(reg.feature_importances_)\n\n# List of tuples with variable and importance\nfeature_importances = [(feature, round(importance, 2)) for feature, importance in zip(X_train, importances)]\n\n# Sort the feature importances by most important first\nfeature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n\n# Print out the feature and importances \n[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Prediction"},{"metadata":{"trusted":false},"cell_type":"code","source":"preds = reg.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Evaluation"},{"metadata":{"trusted":false},"cell_type":"code","source":"evaluate = pd.DataFrame({\n    \"actual\" : y_test\n    , \"predicted\" : preds\n})\n\nevaluate[\"error\"] = evaluate[\"actual\"] - evaluate[\"predicted\"]\n\nevaluate.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Calculate the absolute errors\nerrors = abs(preds - y_test)\n\n# Print out the mean absolute error (mae)\nprint('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Conclusion (Morbidity)\n\nThere is no difference in MAE between Model Iteration 1A and 1B. The high importance ranking of Black Females and Poverty supports advocacy that promotes universal access health care for Black women and people living in poverty as essential intervention that may contribute to the reduction of Covid 19 morbidity. "},{"metadata":{},"cell_type":"markdown","source":"## Model 2: Predicting Mortality\n\nApply statistical insights to create and test a machine learning model where y = mortality (deaths) using Random Forest algorithm as a baseline.\n\n### Iteration 2A: All Features\n\n### Feature & Target Selection\n\nPre-processed data from Prototype Phase 1 imported where all population values and values for Risk Index are log-transformed.  "},{"metadata":{"trusted":false},"cell_type":"code","source":"all_data_6 = all_data_4.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y = all_data_6[\"Deaths\"]\n\nX = all_data_6.drop([\"Deaths\", \"FIPS\", \"stateFIPS\"\n                     , \"countyFIPS_2d\", \"County\", \"State\", \"Risk_Cat\"],  axis=1)\n\nX","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# train-test split\nfrom sklearn.model_selection import train_test_split\n\n# allocate 70% at random to training data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Use the features importance methods in Random Forest (out-of-bag=TRUE), look for variable importance results, test and evaluate."},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\nreg = RandomForestRegressor(max_depth=2, random_state=10, oob_score=True, bootstrap=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fit Training Data"},{"metadata":{"trusted":false},"cell_type":"code","source":"reg.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature Importance"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Get numerical feature importances\nimportances = list(reg.feature_importances_)\n\n# List of tuples with variable and importance\nfeature_importances = [(feature, round(importance, 2)) for feature, importance in zip(X_train, importances)]\n\n# Sort the feature importances by most important first\nfeature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n\n# Print out the feature and importances \n[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Prediction"},{"metadata":{"trusted":false},"cell_type":"code","source":"preds = reg.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Evaluation"},{"metadata":{"trusted":false},"cell_type":"code","source":"evaluate = pd.DataFrame({\n    \"actual\" : y_test\n    , \"predicted\" : preds\n})\n\nevaluate[\"error\"] = evaluate[\"actual\"] - evaluate[\"predicted\"]\n\nevaluate.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Calculate the absolute errors\nerrors = abs(preds - y_test)\n\n# Print out the mean absolute error (mae)\nprint('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Iteration 2B: Important Features (with Cases)\n\n### Feature & Target Selection"},{"metadata":{"trusted":false},"cell_type":"code","source":"all_data_7 = all_data_4.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y = all_data_7[\"Deaths\"]\n\nX = all_data_7.drop([\"Deaths\", \"FIPS\", \"stateFIPS\", \"countyFIPS_2d\", \"County\"\n                     , \"State\", \"Risk_Cat\", \"I_Male\", \"I_Female\"\n                    , \"A_Male\", \"A_Female\", \"NH_Male\", \"NH_Female\"],  axis=1)\n\nX","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# train-test split\nfrom sklearn.model_selection import train_test_split\n\n# allocate 70% at random to training data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Use the features importance methods in Random Forest (out-of-bag=TRUE), look for variable importance results, test and evaluate."},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\nreg = RandomForestRegressor(max_depth=2, random_state=10, oob_score=True, bootstrap=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fitting Training Data"},{"metadata":{"trusted":false},"cell_type":"code","source":"reg.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature Importances"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Get numerical feature importances\nimportances = list(reg.feature_importances_)\n\n# List of tuples with variable and importance\nfeature_importances = [(feature, round(importance, 2)) for feature, importance in zip(X_train, importances)]\n\n# Sort the feature importances by most important first\nfeature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n\n# Print out the feature and importances \n[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Prediction"},{"metadata":{"trusted":false},"cell_type":"code","source":"preds = reg.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Evaluation"},{"metadata":{"trusted":false},"cell_type":"code","source":"evaluate = pd.DataFrame({\n    \"actual\" : y_test\n    , \"predicted\" : preds\n})\n\nevaluate[\"error\"] = evaluate[\"actual\"] - evaluate[\"predicted\"]\n\nevaluate.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Calculate the absolute errors\nerrors = abs(preds - y_test)\n\n# Print out the mean absolute error (mae)\nprint('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Iteration 2B: Female Population Features (without cases)\n\n### Feature & Target Selection"},{"metadata":{"trusted":false},"cell_type":"code","source":"all_data_8 = all_data_4.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y = all_data_8[\"Deaths\"]\n\nX = all_data_8.drop([\"Cases\", \"Deaths\", \"FIPS\", \"stateFIPS\", \"countyFIPS_2d\", \"County\"\n                     , \"State\", \"Risk_Cat\", \"W_Male\", \"B_Male\", \"H_Male\"\n                     , \"I_Male\", \"A_Male\", \"NH_Male\"],  axis=1)\n\nX","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# train-test split\nfrom sklearn.model_selection import train_test_split\n\n# allocate 70% at random to training data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\nreg = RandomForestRegressor(max_depth=2, random_state=10, oob_score=True, bootstrap=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fitting Training Data"},{"metadata":{"trusted":false},"cell_type":"code","source":"reg.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature Importances"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Get numerical feature importances\nimportances = list(reg.feature_importances_)\n\n# List of tuples with variable and importance\nfeature_importances = [(feature, round(importance, 2)) for feature, importance in zip(X_train, importances)]\n\n# Sort the feature importances by most important first\nfeature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n\n# Print out the feature and importances \n[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Prediction"},{"metadata":{"trusted":false},"cell_type":"code","source":"preds = reg.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Evaluation"},{"metadata":{"trusted":false},"cell_type":"code","source":"evaluate = pd.DataFrame({\n    \"actual\" : y_test\n    , \"predicted\" : preds\n})\n\nevaluate[\"error\"] = evaluate[\"actual\"] - evaluate[\"predicted\"]\n\nevaluate.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Calculate the absolute errors\nerrors = abs(preds - y_test)\n\n# Print out the mean absolute error (mae)\nprint('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Conclusion (Mortality)\nThe presence of Covid Case data diminished the importance of race, gender and poverty in this model. However, when Cases are not a constant, the importance of Black Females in determining mortality outcomes was significantly more significant than other features. Risk Index did not play an important role in the model, possibly due to the potential Poisson Distribution that was observed in Phase 2 of this project."},{"metadata":{},"cell_type":"markdown","source":"# Next Steps (Machine Learning)\n1. Produce Mean Squared Error (MSE) metrics for all models and create a comparsion table\n2. Compare model using alternative algorithms and illustrate finding using MSE metrics.\n3. Test model with fresh morbitity and mortality data from the period (1 August to 30 September)\n4. Present prototype and seek out peer reviewers and collaborators \n5. Replicate for other geographies."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}