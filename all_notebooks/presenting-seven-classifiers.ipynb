{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"ed90a97c-db49-08fa-ad38-7812143922a8"},"source":"# A pipeline for predictive analytics using text data"},{"cell_type":"markdown","metadata":{"_cell_guid":"25269837-97b9-e4a4-15ed-5f11058a4656"},"source":"## Before we start"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"568cc4f2-d603-356d-404a-4b7182516e1e"},"outputs":[],"source":"import numpy as np \nimport pandas as pd \nimport sklearn\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.cross_validation import train_test_split\nfrom wordcloud import WordCloud,STOPWORDS\nimport re\nimport nltk\nfrom nltk.corpus import stopwords\ndf = pd.read_csv('../input/Combined_News_DJIA.csv')\nprint(df.shape)\nimport matplotlib\nmatplotlib.rcParams[\"figure.figsize\"] = \"8, 8\""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f4146ff8-6427-906e-5737-0608e9287583"},"outputs":[],"source":"df.head(5)"},{"cell_type":"markdown","metadata":{"_cell_guid":"8f17b4a1-285b-cd07-24e0-6848de22581f"},"source":"Credits to **Kate**, for the great method of combining all headlines."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8e0cc03b-79ff-d3ed-26ed-ba0d85e9284e"},"outputs":[],"source":"df['Combined']=df.iloc[:,2:27].apply(lambda row: ''.join(str(row.values)), axis=1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3d6c99ae-c180-ad8a-59cf-35fed9ed7928"},"outputs":[],"source":"train,test = train_test_split(df,test_size=0.2,random_state=42)"},{"cell_type":"markdown","metadata":{"_cell_guid":"41156b20-23b2-723a-88a1-af5a53e5ee29"},"source":"## Simple EDA"},{"cell_type":"markdown","metadata":{"_cell_guid":"1b7363b6-b7ff-1669-c1c5-52444a786ff7"},"source":"We first have a quick look at the text, looking for words that can be the indicator of decrease on stock price."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"38acab01-47eb-6f15-46e9-339873debc09"},"outputs":[],"source":"non_decrease = train[train['Label']==1]\ndecrease = train[train['Label']==0]\nprint(len(non_decrease)/len(df))"},{"cell_type":"markdown","metadata":{"_cell_guid":"708699e0-eba0-5444-9694-99853ffd5b00"},"source":"We can see that the occurrence of non-decrease situation is almost the **same** as that of a decrease market. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dcb87cfe-cfc6-9468-5a61-3845ec3aaa05"},"outputs":[],"source":"def to_words(content):\n    letters_only = re.sub(\"[^a-zA-Z]\", \" \", content) \n    words = letters_only.lower().split()                             \n    stops = set(stopwords.words(\"english\"))                  \n    meaningful_words = [w for w in words if not w in stops] \n    return( \" \".join( meaningful_words )) "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"57b78e88-5a85-77da-c1c8-6b32d240675a"},"outputs":[],"source":"non_decrease_word=[]\ndecrease_word=[]\nfor each in non_decrease['Combined']:\n    non_decrease_word.append(to_words(each))\n\nfor each in decrease['Combined']:\n    decrease_word.append(to_words(each))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4da1e092-1aaf-357c-d34d-f7e8ff68d162"},"outputs":[],"source":"wordcloud1 = WordCloud(background_color='black',\n                      width=3000,\n                      height=2500\n                     ).generate(decrease_word[0])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ad657f1f-4f6c-7d39-1668-9c3b16a918a2"},"outputs":[],"source":"plt.figure(1,figsize=(8,8))\nplt.imshow(wordcloud1)\nplt.axis('off')\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"246cd815-d945-b2d3-5a67-612eb539f619"},"outputs":[],"source":"wordcloud2 = WordCloud(background_color='white',\n                      width=3000,\n                      height=2500\n                     ).generate(non_decrease_word[0])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b183a274-8301-587a-debe-7be03d4ae710"},"outputs":[],"source":"plt.figure(1,figsize=(8,8))\nplt.imshow(wordcloud2)\nplt.axis('off')\nplt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"6778e1c2-6b5e-ea73-1a90-db189ed24893"},"source":"If you look at two word clouds, you may find that even in the case of non-decreased situation the **Political sensitive words** are dominant.  Therefore, I have a feeling that the overall results of the classification may not be quite good since the features of two classes are **not that distinct**."},{"cell_type":"markdown","metadata":{"_cell_guid":"4bf6e36d-9ef9-067f-0494-9a881631bc25"},"source":"## Feature extraction"},{"cell_type":"markdown","metadata":{"_cell_guid":"a1e6b4ea-258b-60a2-a676-4e35a115a744"},"source":"I choose to use **tf-idf** model for feature extraction as it can make the informative features weighted enough."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d515a6cf-0a26-ac0b-d2d6-b10d82785ce1"},"outputs":[],"source":"from sklearn.feature_extraction.text import TfidfVectorizer\ntfidf=TfidfVectorizer()\ntrain_text = []\ntest_text = []\nfor each in train['Combined']:\n    train_text.append(to_words(each))\n\nfor each in test['Combined']:\n    test_text.append(to_words(each))\ntrain_features = tfidf.fit_transform(train_text)\ntest_features = tfidf.transform(test_text)"},{"cell_type":"markdown","metadata":{"_cell_guid":"59201790-7841-da44-04de-ada5436ccafc"},"source":"## Model fitting"},{"cell_type":"markdown","metadata":{"_cell_guid":"1abb84a3-67e1-1f5b-5765-a03d73c94b03"},"source":"`In this part, I will fit seven different classifiers on the training set. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6086feaa-ac14-ee51-4511-981484eef54a"},"outputs":[],"source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import roc_curve\nfrom ggplot import *"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d047899b-af56-c55d-9398-336d892644b0"},"outputs":[],"source":"Classifiers = [\n    LogisticRegression(C=0.000000001,solver='liblinear',max_iter=200),\n    KNeighborsClassifier(3),\n    SVC(kernel=\"rbf\", C=0.025, probability=True),\n    DecisionTreeClassifier(),\n    RandomForestClassifier(n_estimators=200),\n    AdaBoostClassifier(),\n    GaussianNB()]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1d9edb07-b840-ed14-3840-51c426fb3fe7"},"outputs":[],"source":"dense_features=train_features.toarray()\ndense_test= test_features.toarray()\nAccuracy=[]\nModel=[]\nfor classifier in Classifiers:\n    try:\n        fit = classifier.fit(train_features,train['Label'])\n        pred = fit.predict(test_features)\n        prob = fit.predict_proba(test_features)[:,1]\n    except Exception:\n        fit = classifier.fit(dense_features,train['Label'])\n        pred = fit.predict(dense_test)\n        prob = fit.predict_proba(dense_test)[:,1]\n    accuracy = accuracy_score(pred,test['Label'])\n    Accuracy.append(accuracy)\n    Model.append(classifier.__class__.__name__)\n    print('Accuracy of '+classifier.__class__.__name__+' is '+str(accuracy))\n    fpr, tpr, _ = roc_curve(test['Label'],prob)\n    tmp = pd.DataFrame(dict(fpr=fpr, tpr=tpr))\n    g = ggplot(tmp, aes(x='fpr', y='tpr')) +geom_line() +geom_abline(linetype='dashed')+ ggtitle('Roc Curve of '+classifier.__class__.__name__)\n    print(g)"},{"cell_type":"markdown","metadata":{"_cell_guid":"da665177-8979-8c22-74c4-2faefacd83d1"},"source":"## Conclusion"},{"cell_type":"markdown","metadata":{"_cell_guid":"db557c90-4aec-7cf9-d29d-d33daa5d5043"},"source":"Obviously, the overall performances of seven models are not quite good. The features are not distinct enough, therefore resulting in a bad model fitting."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7456e452-245f-509d-59e5-53730aeb2ced"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}