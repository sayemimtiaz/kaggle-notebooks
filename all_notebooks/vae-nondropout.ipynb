{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Link to dataset\n- MovieLens20M: https://www.kaggle.com/ntnhan54/movielens20m\n- MillionSong: https://www.kaggle.com/danh99/millionsong","metadata":{}},{"cell_type":"code","source":"\nfrom torch import nn, optim\nfrom torch.nn import functional as F\nimport torch\nfrom torch import nn\nfrom torch.utils.data import TensorDataset\nfrom torch.utils.data import DataLoader\nimport numpy as np\nimport  pandas as pd\nimport os\nfrom scipy import sparse\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom tqdm import tqdm_notebook as tqdm\n\nimport seaborn as sn\nsn.set()\n\n\nimport sys\nimport warnings; \nwarnings.simplefilter('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-24T16:15:25.480365Z","iopub.execute_input":"2021-06-24T16:15:25.480764Z","iopub.status.idle":"2021-06-24T16:15:27.696069Z","shell.execute_reply.started":"2021-06-24T16:15:25.480684Z","shell.execute_reply":"2021-06-24T16:15:27.695252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\ndevice","metadata":{"execution":{"iopub.status.busy":"2021-06-24T16:15:27.697607Z","iopub.execute_input":"2021-06-24T16:15:27.697915Z","iopub.status.idle":"2021-06-24T16:15:27.770011Z","shell.execute_reply.started":"2021-06-24T16:15:27.697882Z","shell.execute_reply":"2021-06-24T16:15:27.769173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DATA_DIR = '../input/millionsong'\n# path = 'MSD-nonDropout.pt'\n# train_path = 'MSD-nonDropout-training.pt'\n# metrics_path = 'history_MSD_VAEnonDropout.csv'\n\nDATA_DIR = '../input/movielens20m'\npath = 'movielens-nonDropout.pt'\ntrain_path = 'movielens-nonDropout-training.pt'\nmetrics_path = 'history_MovieLens_VAEnonDropout.csv'","metadata":{"execution":{"iopub.status.busy":"2021-06-24T16:15:27.771966Z","iopub.execute_input":"2021-06-24T16:15:27.772506Z","iopub.status.idle":"2021-06-24T16:15:27.779675Z","shell.execute_reply.started":"2021-06-24T16:15:27.772434Z","shell.execute_reply":"2021-06-24T16:15:27.778729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cp ../input/vae-nondropout/history_MovieLens_VAEnonDropout.csv history_MSD_VAEnonDropout.csv\n!cp ../input/vae-nondropout/movielens-nonDropout-training.pt movielens-nonDropout-training.pt\n!cp ../input/vae-nondropout/movielens-nonDropout.pt movielens-nonDropout.pt","metadata":{"execution":{"iopub.status.busy":"2021-06-24T16:15:27.781375Z","iopub.execute_input":"2021-06-24T16:15:27.781798Z","iopub.status.idle":"2021-06-24T16:15:36.09408Z","shell.execute_reply.started":"2021-06-24T16:15:27.781759Z","shell.execute_reply":"2021-06-24T16:15:36.093093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv(DATA_DIR + '/train.csv')\nval_data = pd.read_csv(DATA_DIR + '/val.csv')\ntest_data = pd.read_csv(DATA_DIR + '/test.csv')\n","metadata":{"execution":{"iopub.status.busy":"2021-06-24T16:15:36.095806Z","iopub.execute_input":"2021-06-24T16:15:36.096161Z","iopub.status.idle":"2021-06-24T16:15:43.312751Z","shell.execute_reply.started":"2021-06-24T16:15:36.096119Z","shell.execute_reply":"2021-06-24T16:15:43.311731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nItems = train_data.sid.nunique()\nnItems","metadata":{"execution":{"iopub.status.busy":"2021-06-24T16:15:43.314081Z","iopub.execute_input":"2021-06-24T16:15:43.314412Z","iopub.status.idle":"2021-06-24T16:15:43.381159Z","shell.execute_reply.started":"2021-06-24T16:15:43.314374Z","shell.execute_reply":"2021-06-24T16:15:43.380429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = sparse.csr_matrix((np.ones_like(train_data.uid), (train_data.uid.values, train_data.sid.values)), \n                             dtype='float64',\n                             shape=(train_data.uid.nunique(),nItems))\n\n\nval_data = sparse.csr_matrix((np.ones_like(val_data.uid), (val_data.uid.values, val_data.sid.values)), \n                             dtype='float64',\n                             shape=(val_data.uid.nunique(), nItems))\n\ntest_data = sparse.csr_matrix((np.ones_like(test_data.uid), (test_data.uid.values, test_data.sid.values)), \n                             dtype='float64',\n                             shape=(test_data.uid.nunique(), nItems))","metadata":{"execution":{"iopub.status.busy":"2021-06-24T16:15:43.382372Z","iopub.execute_input":"2021-06-24T16:15:43.382684Z","iopub.status.idle":"2021-06-24T16:15:43.940409Z","shell.execute_reply.started":"2021-06-24T16:15:43.382657Z","shell.execute_reply":"2021-06-24T16:15:43.939577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class netflixDataset(torch.utils.data.Dataset):\n    def __init__(self, scr_matrix, eval = False,prop=0.2):\n        self.scr_matrix = scr_matrix\n        self.eval = eval\n        self.prop = prop\n      \n          \n    def __getitem__(self, idx):\n      \n      item = {}\n        \n      \n\n      if self.eval:\n        u_items = self.scr_matrix[idx,:].toarray()[0]\n        \n        nu_items = u_items.sum()       \n        val_size = int(nu_items*self.prop)\n        idx_labels = np.where(u_items == 1)[0]\n        data = np.ones_like(u_items)\n        \n        \n                \n        val_idx = np.random.choice(idx_labels, size=val_size, replace=False)                   \n        data[val_idx] = 0\n         \n        \n        \n        \n        item['data'] = torch.tensor(u_items*data,dtype=torch.float64)     \n        \n        item['ground_truth'] = torch.tensor(np.logical_not(data),dtype=torch.float64)             \n        \n        \n       \n      else:\n        item['data'] = torch.tensor(self.scr_matrix[idx,:].toarray(),dtype=torch.float64)\n      return item\n        \n\n    def __len__(self):\n        return self.scr_matrix.shape[0]","metadata":{"execution":{"iopub.status.busy":"2021-06-24T16:15:43.943278Z","iopub.execute_input":"2021-06-24T16:15:43.943677Z","iopub.status.idle":"2021-06-24T16:15:43.95329Z","shell.execute_reply.started":"2021-06-24T16:15:43.943639Z","shell.execute_reply":"2021-06-24T16:15:43.952441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class VAE(nn.Module):\n    def __init__(self,n_Items, hidden=600, dimz= 200, p=0.5):\n        super(VAE, self).__init__()\n\n        self.n_Items = n_Items\n        self.dimz = dimz\n        self.hidden = hidden\n        self.p = p\n\n        self.inference = nn.Sequential(\n           \n#             nn.Dropout(self.p),\n            nn.Linear(self.n_Items,self.hidden),\n            nn.Tanh(),\n            nn.Linear(self.hidden,2*self.dimz)          \n        )\n        self.generative = nn.Sequential(\n            nn.Linear(self.dimz,self.hidden),\n            nn.Tanh(),\n            nn.Linear(self.hidden,self.n_Items),\n            \n        )\n  \n        \n\n    def reparameterize(self, mu, logvar):\n        std = torch.exp(0.5*logvar)\n        eps = torch.randn_like(std)\n        \n        return mu + std*eps* ( 1 if self.Mode =='train' else 0)\n\n\n    def forward(self, x,Mode='train'):       \n        self.Mode = Mode\n        x = F.normalize(x, p=2, dim=1)  \n        distribution = self.inference(x)\n\n\n\n        mu, logvar = distribution[:, :self.dimz], distribution[:, self.dimz:]\n        z = self.reparameterize(mu, logvar)\n        logit = self.generative(z)\n\n        \n        return logit, mu, logvar","metadata":{"execution":{"iopub.status.busy":"2021-06-24T16:15:43.955216Z","iopub.execute_input":"2021-06-24T16:15:43.955775Z","iopub.status.idle":"2021-06-24T16:15:43.966325Z","shell.execute_reply.started":"2021-06-24T16:15:43.955736Z","shell.execute_reply":"2021-06-24T16:15:43.965377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def loss_function(recon_x, x, mu, logvar,beta):\n\n#    # BCE = F.binary_cross_entropy(recon_x.view(-1,n_items), x.view(-1,n_items), reduction='sum')\n#     c = (torch.ones_like(x)*5*x +1) /2\n \n    \n#     LL = torch.mean(torch.sum(c * (x-recon_x)**2  ,-1))\n  \n    \n    CE = -torch.mean(torch.sum(F.log_softmax(recon_x, 1) * x, -1))\n    KLD = -0.5 * torch.mean(torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=1))\n\n   \n    return LL + beta*KLD ","metadata":{"execution":{"iopub.status.busy":"2021-06-24T16:15:43.967245Z","iopub.execute_input":"2021-06-24T16:15:43.968303Z","iopub.status.idle":"2021-06-24T16:15:43.978335Z","shell.execute_reply.started":"2021-06-24T16:15:43.968274Z","shell.execute_reply":"2021-06-24T16:15:43.97762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def NDCG_at_k(labels, scores, k = 100):\n    device = scores.device\n    arg_sort_scores = torch.argsort(scores,1,descending=True)\n    arg_sort_labels = torch.argsort(labels,1,descending=True)\n\n\n    pred_labels = torch.gather(labels,1,arg_sort_scores[:,:k]).to(device)\n\n\n    tp = (1. /torch.log(torch.arange(2,2+k).float())).to(device)\n\n\n    dcg = (tp * pred_labels).sum(axis = 1)\n\n    idcg = torch.Tensor([tp[:min(int(n),k)].sum() for n in labels.sum(1)]).to(device)\n\n    ndcg = (dcg/idcg).mean()\n\n    return ndcg","metadata":{"execution":{"iopub.status.busy":"2021-06-24T16:15:43.981432Z","iopub.execute_input":"2021-06-24T16:15:43.981762Z","iopub.status.idle":"2021-06-24T16:15:43.990282Z","shell.execute_reply.started":"2021-06-24T16:15:43.981737Z","shell.execute_reply":"2021-06-24T16:15:43.989504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Recall_at_k(labels, scores, k = 20):\n    device = scores.device\n    arg_sort_scores = torch.argsort(scores,1,descending=True)\n    arg_sort_labels = torch.argsort(labels,1,descending=True)\n\n    pred_labels = torch.gather(labels,1,arg_sort_scores[:,:k]).to(device)\n\n    denominator = labels.sum(1)\n    denominator[denominator > k] = k\n\n    return (pred_labels.sum(1) / denominator).mean()","metadata":{"execution":{"iopub.status.busy":"2021-06-24T16:15:43.993315Z","iopub.execute_input":"2021-06-24T16:15:43.993588Z","iopub.status.idle":"2021-06-24T16:15:44.000175Z","shell.execute_reply.started":"2021-06-24T16:15:43.993565Z","shell.execute_reply":"2021-06-24T16:15:43.999403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@torch.no_grad()\ndef evaluate(model, val_loader, ndcg_k = [100], recall_k = [20,50]):\n    '''Evaluate model at Recall and NDCG metrics'''\n    metrics = {}\n    for k in ndcg_k:\n        metrics[f'ndcg@{k}'] = []\n    for k in recall_k:\n        metrics[f'recall@{k}'] = []\n    for data in val_loader:\n        X = data['data'].float().to(device)  \n        X = X.squeeze(1)\n\n\n        ground_truth = torch.stack([data['ground_truth'][i,:] for i in range(X.shape[0])])\\\n                      .squeeze(1).to(device)\n\n        pred ,_,_= model(X,Mode ='eval')\n\n        pred = pred.detach()\n\n\n        pred[X!=0] = -np.inf\n        for k in ndcg_k:\n            ndcg = NDCG_at_k(ground_truth,pred, k)\n            metrics[f'ndcg@{k}'] += [ndcg.item()]\n        for k in recall_k:\n            recall = Recall_at_k(ground_truth,pred, k)\n            metrics[f'recall@{k}'] += [recall.item()]\n    \n    for k in ndcg_k:\n        metrics[f'ndcg@{k}'] = np.mean(metrics[f'ndcg@{k}'])\n#         metrics[f'ndcg@{k}'] = torch.stack(metrics[f'ndcg@{k}']).mean().item()\n    for k in recall_k:\n#         metrics[f'recall@{k}'] = torch.stack(metrics[f'recall@{k}']).mean().item()\n        metrics[f'recall@{k}'] = np.mean(metrics[f'recall@{k}'])\n    return metrics","metadata":{"execution":{"iopub.status.busy":"2021-06-24T16:15:44.001375Z","iopub.execute_input":"2021-06-24T16:15:44.001836Z","iopub.status.idle":"2021-06-24T16:15:44.016301Z","shell.execute_reply.started":"2021-06-24T16:15:44.0018Z","shell.execute_reply":"2021-06-24T16:15:44.015485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## New model","metadata":{}},{"cell_type":"code","source":"# # Declare Model\n# model = VAE(nItems).to(device)\n# n_Epochs = 200\n\n# # KL-Annealing for new training\n# anneal = 0\n# anneal_cap = 1\n# anneal_steps = 1.0/200_000\n\n# # prepare Data\n# train_ds = netflixDataset(train_data)\n\n\n# val_ds = netflixDataset(val_data,eval=True)\n# val_dl = DataLoader(val_ds, batch_size=500)\n\n\n# optimizer = optim.AdamW(model.parameters(), lr=1e-3,weight_decay=0.01)\n# cur_metric = -np.inf","metadata":{"execution":{"iopub.status.busy":"2021-06-24T16:15:44.01772Z","iopub.execute_input":"2021-06-24T16:15:44.017968Z","iopub.status.idle":"2021-06-24T16:15:44.025876Z","shell.execute_reply.started":"2021-06-24T16:15:44.017938Z","shell.execute_reply":"2021-06-24T16:15:44.024872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load training model","metadata":{}},{"cell_type":"code","source":"model = VAE(nItems).to(device)\nn_Epochs = 50\n\n# # KL-Annealing for new training\nanneal = 0\nanneal_cap = 1\nanneal_steps = 1.0/200_000\n\n# # prepare Data\ntrain_ds = netflixDataset(train_data)\ntrain_dl = DataLoader(train_ds, batch_size=500,shuffle=True)\n\n\nval_ds = netflixDataset(val_data,eval=True)\nval_dl = DataLoader(val_ds, batch_size=500)\n\n\noptimizer = optim.AdamW(model.parameters(), lr=1e-3,weight_decay=0.01)\n\ncheckpoint = torch.load(train_path)\n\nmodel.load_state_dict(checkpoint['model_state_dict'])\noptimizer.load_state_dict(checkpoint['optimizer_state_dict'])\ncur_metric = list(checkpoint['evaluate'].values())[0]\nanneal = checkpoint['beta']\nanneal, cur_metric, checkpoint['epoch']","metadata":{"execution":{"iopub.status.busy":"2021-06-24T16:15:44.027203Z","iopub.execute_input":"2021-06-24T16:15:44.027616Z","iopub.status.idle":"2021-06-24T16:15:48.704626Z","shell.execute_reply.started":"2021-06-24T16:15:44.027543Z","shell.execute_reply":"2021-06-24T16:15:48.703753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open(metrics_path, 'a') as f:\n    \n    pbar = tqdm(range(n_Epochs),total = n_Epochs)\n    for epoch in pbar:\n        metrics = {}\n        train_loss =  []\n        # train phase\n        model.train()\n        train_phase = tqdm(train_dl,total = len(train_dl))\n        for data in train_phase:\n            x = data['data'].float().to(device)\n            x = x.squeeze(1)\n            optimizer.zero_grad()  \n\n\n            recon_x, mu, logvar = model(x)   \n\n\n            CE = -torch.mean(torch.sum(F.log_softmax(recon_x, 1) * x, -1))\n            KLD = -0.5 * torch.mean(torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=1))\n\n            loss =  CE + anneal * KLD            \n            anneal = min(anneal+anneal_steps,anneal_cap)   \n            loss.backward()      \n\n            optimizer.step()\n            train_loss.append(loss.item())\n            metrics['loss'] = train_loss[-1]\n            train_phase.set_postfix(metrics)\n\n        # Eval phases\n        model.eval()\n        metrics = evaluate(model, val_dl)\n        metrics['train_loss'] = np.mean(train_loss)\n\n        ndcg = list(metrics.values())[0]\n        if ndcg > cur_metric:\n            cur_metric = ndcg\n            torch.save({\n                    'epoch': epoch,\n                    'model_state_dict': model.state_dict(),\n                    'optimizer_state_dict': optimizer.state_dict(),\n                    'loss': metrics['train_loss'],\n                    'evaluate': metrics,\n                    'beta': anneal\n                    }, path)\n        pbar.set_postfix(metrics)\n        # write metrics to file\n        s = ['{:.3f}'.format(v) for v in metrics.values()]\n        f.write(','.join(s) + '\\n')","metadata":{"execution":{"iopub.status.busy":"2021-06-24T16:57:08.518053Z","iopub.execute_input":"2021-06-24T16:57:08.518358Z","iopub.status.idle":"2021-06-24T17:35:36.873379Z","shell.execute_reply.started":"2021-06-24T16:57:08.51833Z","shell.execute_reply":"2021-06-24T17:35:36.872539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save({\n                    'epoch': n_Epochs,\n                    'model_state_dict': model.state_dict(),\n                    'optimizer_state_dict': optimizer.state_dict(),\n                    'loss': metrics['train_loss'],\n                    'evaluate': metrics,\n                    'beta': anneal\n                    }, train_path)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T17:35:36.874941Z","iopub.execute_input":"2021-06-24T17:35:36.875458Z","iopub.status.idle":"2021-06-24T17:35:37.99008Z","shell.execute_reply.started":"2021-06-24T17:35:36.875417Z","shell.execute_reply":"2021-06-24T17:35:37.988986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(metrics_path, header = None, names = metrics.keys(),index_col = False)\ndf","metadata":{"execution":{"iopub.status.busy":"2021-06-24T17:35:37.992262Z","iopub.execute_input":"2021-06-24T17:35:37.992867Z","iopub.status.idle":"2021-06-24T17:35:38.012676Z","shell.execute_reply.started":"2021-06-24T17:35:37.992822Z","shell.execute_reply":"2021-06-24T17:35:38.011755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1 = pd.read_csv('../input/vae-nondropout/history_MovieLens_VAEnonDropout.csv', header = None, names = metrics.keys(),index_col = False)\ndf = df1.append(df).reset_index()","metadata":{"execution":{"iopub.status.busy":"2021-06-24T17:35:38.014462Z","iopub.execute_input":"2021-06-24T17:35:38.014852Z","iopub.status.idle":"2021-06-24T17:35:38.028486Z","shell.execute_reply.started":"2021-06-24T17:35:38.014806Z","shell.execute_reply":"2021-06-24T17:35:38.027687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 3))\nplt.plot(df['train_loss'], '-')\nplt.ylabel(\"loss\")\nplt.xlabel(\"Epochs\")\npass","metadata":{"execution":{"iopub.status.busy":"2021-06-24T17:35:38.02977Z","iopub.execute_input":"2021-06-24T17:35:38.030318Z","iopub.status.idle":"2021-06-24T17:35:38.201429Z","shell.execute_reply.started":"2021-06-24T17:35:38.03028Z","shell.execute_reply":"2021-06-24T17:35:38.200476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 3))\nplt.plot(df['ndcg@100'],'-')\nplt.ylabel(\"ndcg@100\")\nplt.xlabel(\"Epochs\")\npass","metadata":{"execution":{"iopub.status.busy":"2021-06-24T17:35:38.202848Z","iopub.execute_input":"2021-06-24T17:35:38.203194Z","iopub.status.idle":"2021-06-24T17:35:38.374725Z","shell.execute_reply.started":"2021-06-24T17:35:38.203158Z","shell.execute_reply":"2021-06-24T17:35:38.372629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 3))\nplt.plot(df['recall@20'], 'x-')\nplt.ylabel(\"recall@20\")\nplt.xlabel(\"Epochs\")\npass","metadata":{"execution":{"iopub.status.busy":"2021-06-24T17:35:38.376126Z","iopub.execute_input":"2021-06-24T17:35:38.376472Z","iopub.status.idle":"2021-06-24T17:35:38.551165Z","shell.execute_reply.started":"2021-06-24T17:35:38.376437Z","shell.execute_reply":"2021-06-24T17:35:38.550254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 3))\nplt.plot(df['recall@50'], '-')\nplt.ylabel(\"recall@50\")\nplt.xlabel(\"Epochs\")\npass","metadata":{"execution":{"iopub.status.busy":"2021-06-24T17:35:38.554051Z","iopub.execute_input":"2021-06-24T17:35:38.554414Z","iopub.status.idle":"2021-06-24T17:35:38.735086Z","shell.execute_reply.started":"2021-06-24T17:35:38.554385Z","shell.execute_reply":"2021-06-24T17:35:38.734251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_ds = netflixDataset(test_data,eval=True)\ntest_dl = DataLoader(test_ds, batch_size=512, shuffle = False, pin_memory = True)\nmodel.eval()\nevaluate(model, test_dl)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T17:35:38.736935Z","iopub.execute_input":"2021-06-24T17:35:38.737276Z","iopub.status.idle":"2021-06-24T17:35:48.92889Z","shell.execute_reply.started":"2021-06-24T17:35:38.737239Z","shell.execute_reply":"2021-06-24T17:35:48.927464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# best model\nmodel1 = VAE(nItems).to(device)\ncheckpoint = torch.load(path)\n\nmodel1.load_state_dict(checkpoint['model_state_dict'])","metadata":{"execution":{"iopub.status.busy":"2021-06-24T17:35:48.930229Z","iopub.execute_input":"2021-06-24T17:35:48.930599Z","iopub.status.idle":"2021-06-24T17:35:49.252356Z","shell.execute_reply.started":"2021-06-24T17:35:48.930562Z","shell.execute_reply":"2021-06-24T17:35:49.251401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_ds = netflixDataset(test_data,eval=True)\ntest_dl = DataLoader(test_ds, batch_size=500)\nmodel1.eval()\nevaluate(model1, test_dl)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T17:35:49.253732Z","iopub.execute_input":"2021-06-24T17:35:49.254085Z","iopub.status.idle":"2021-06-24T17:35:59.000143Z","shell.execute_reply.started":"2021-06-24T17:35:49.254047Z","shell.execute_reply":"2021-06-24T17:35:58.999288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# # evaluate before training\n# test_ds = netflixDataset(test_data,eval=True)\n# test_dl = DataLoader(test_ds, batch_size=500)\n# evaluate(model, test_dl)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T17:35:59.001492Z","iopub.execute_input":"2021-06-24T17:35:59.001863Z","iopub.status.idle":"2021-06-24T17:35:59.005952Z","shell.execute_reply.started":"2021-06-24T17:35:59.001816Z","shell.execute_reply":"2021-06-24T17:35:59.004758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# with open(metrics_path, 'a') as f:\n    \n#     pbar = tqdm(range(n_Epochs),total = n_Epochs)\n#     for epoch in pbar:\n#         metrics = {}\n#         train_loss =  []\n#         # train phase\n#         model.train()\n#         train_dl = DataLoader(train_ds, batch_size=500,shuffle=True)\n#         train_phase = tqdm(train_dl,total = len(train_dl))\n#         for data in train_phase:\n#             x = data['data'].float().to(device)\n#             x = x.squeeze(1)\n#             optimizer.zero_grad()  \n\n        \n#             recon_x, mu, logvar = model(x)   \n            \n#             loss = loss_function(recon_x, x, mu, logvar,anneal)\n            \n#             anneal = min(anneal+anneal_steps,anneal_cap)   \n#             loss.backward()      \n\n#             optimizer.step()\n#             train_loss.append(loss.item())\n#             metrics['loss'] = train_loss[-1]\n#             train_phase.set_postfix(metrics)\n\n#         # Eval phases\n#         metrics = evaluate(model, val_dl)\n#         metrics['train_loss'] = np.mean(train_loss)\n\n#         ndcg = list(metrics.values())[0]\n#         if ndcg > cur_metric:\n#             cur_metric = ndcg\n#             torch.save({\n#                     'epoch': epoch,\n#                     'model_state_dict': model.state_dict(),\n#                     'optimizer_state_dict': optimizer.state_dict(),\n#                     'loss': metrics['train_loss'],\n#                     'evaluate': metrics,\n#                     'beta': anneal\n#                     }, 'log'+path)\n#         pbar.set_postfix(metrics)\n#         # write metrics to file\n#         s = ['{:.3f}'.format(v) for v in metrics.values()]\n#         f.write(','.join(s) + '\\n')","metadata":{"execution":{"iopub.status.busy":"2021-06-24T17:35:59.007603Z","iopub.execute_input":"2021-06-24T17:35:59.008121Z","iopub.status.idle":"2021-06-24T17:35:59.01586Z","shell.execute_reply.started":"2021-06-24T17:35:59.007965Z","shell.execute_reply":"2021-06-24T17:35:59.014981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# torch.save({\n#                     'epoch': n_Epochs-1,\n#                     'model_state_dict': model.state_dict(),\n#                     'optimizer_state_dict': optimizer.state_dict(),\n#                     'loss': metrics['train_loss'],\n#                     'evaluate': metrics,\n#                     'beta': anneal\n#                     }, 'log' + train_path)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T17:35:59.017045Z","iopub.execute_input":"2021-06-24T17:35:59.017367Z","iopub.status.idle":"2021-06-24T17:35:59.02847Z","shell.execute_reply.started":"2021-06-24T17:35:59.017342Z","shell.execute_reply":"2021-06-24T17:35:59.027637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df = pd.read_csv(metrics_path, header = None, names = metrics.keys(),index_col = False)\n# df","metadata":{"execution":{"iopub.status.busy":"2021-06-24T17:35:59.029696Z","iopub.execute_input":"2021-06-24T17:35:59.030225Z","iopub.status.idle":"2021-06-24T17:35:59.040933Z","shell.execute_reply.started":"2021-06-24T17:35:59.030186Z","shell.execute_reply":"2021-06-24T17:35:59.040113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plt.figure(figsize=(12, 3))\n# plt.plot(df['train_loss'], '-')\n# plt.ylabel(\"loss\")\n# plt.xlabel(\"Epochs\")\n# pass","metadata":{"execution":{"iopub.status.busy":"2021-06-24T17:35:59.04232Z","iopub.execute_input":"2021-06-24T17:35:59.042714Z","iopub.status.idle":"2021-06-24T17:35:59.050774Z","shell.execute_reply.started":"2021-06-24T17:35:59.042676Z","shell.execute_reply":"2021-06-24T17:35:59.049955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plt.figure(figsize=(12, 3))\n# plt.plot(df['ndcg@100'],'-')\n# plt.ylabel(\"ndcg@100\")\n# plt.xlabel(\"Epochs\")\n# pass","metadata":{"execution":{"iopub.status.busy":"2021-06-24T17:35:59.052084Z","iopub.execute_input":"2021-06-24T17:35:59.052663Z","iopub.status.idle":"2021-06-24T17:35:59.060066Z","shell.execute_reply.started":"2021-06-24T17:35:59.052624Z","shell.execute_reply":"2021-06-24T17:35:59.059231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plt.figure(figsize=(12, 3))\n# plt.plot(df['recall@20'], 'x-')\n# plt.ylabel(\"recall@20\")\n# plt.xlabel(\"Epochs\")\n# pass","metadata":{"execution":{"iopub.status.busy":"2021-06-24T17:35:59.061343Z","iopub.execute_input":"2021-06-24T17:35:59.061918Z","iopub.status.idle":"2021-06-24T17:35:59.069702Z","shell.execute_reply.started":"2021-06-24T17:35:59.061878Z","shell.execute_reply":"2021-06-24T17:35:59.068787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plt.figure(figsize=(12, 3))\n# plt.plot(df['recall@50'], '-')\n# plt.ylabel(\"recall@50\")\n# plt.xlabel(\"Epochs\")\n# pass","metadata":{"execution":{"iopub.status.busy":"2021-06-24T17:35:59.071037Z","iopub.execute_input":"2021-06-24T17:35:59.071575Z","iopub.status.idle":"2021-06-24T17:35:59.078598Z","shell.execute_reply.started":"2021-06-24T17:35:59.071534Z","shell.execute_reply":"2021-06-24T17:35:59.07784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # best model\n# model = VAE(nItems).to(device)\n# checkpoint = torch.load( 'log'+train_path)\n\n# model.load_state_dict(checkpoint['model_state_dict'])","metadata":{"execution":{"iopub.status.busy":"2021-06-24T17:35:59.080037Z","iopub.execute_input":"2021-06-24T17:35:59.080449Z","iopub.status.idle":"2021-06-24T17:35:59.088095Z","shell.execute_reply.started":"2021-06-24T17:35:59.080411Z","shell.execute_reply":"2021-06-24T17:35:59.087087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_ds = netflixDataset(test_data,eval=True)\n# test_dl = DataLoader(test_ds, batch_size=500)\n# model.eval()\n# evaluate(model, test_dl)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T17:35:59.089959Z","iopub.execute_input":"2021-06-24T17:35:59.090223Z","iopub.status.idle":"2021-06-24T17:35:59.097339Z","shell.execute_reply.started":"2021-06-24T17:35:59.090198Z","shell.execute_reply":"2021-06-24T17:35:59.096561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_ds = netflixDataset(test_data,eval=True)\n# test_dl = DataLoader(test_ds, batch_size=512, shuffle = False, pin_memory = True)\n# model.eval()\n# evaluate(model, test_dl)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T17:35:59.099095Z","iopub.execute_input":"2021-06-24T17:35:59.099812Z","iopub.status.idle":"2021-06-24T17:35:59.106281Z","shell.execute_reply.started":"2021-06-24T17:35:59.099772Z","shell.execute_reply":"2021-06-24T17:35:59.105405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # best model\n# model1 = VAE(nItems).to(device)\n# checkpoint = torch.load( 'log' + path)\n\n# model1.load_state_dict(checkpoint['model_state_dict'])","metadata":{"execution":{"iopub.status.busy":"2021-06-24T17:35:59.10992Z","iopub.execute_input":"2021-06-24T17:35:59.11021Z","iopub.status.idle":"2021-06-24T17:35:59.115539Z","shell.execute_reply.started":"2021-06-24T17:35:59.110187Z","shell.execute_reply":"2021-06-24T17:35:59.114678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %%time\n# test_dl = DataLoader(test_ds, batch_size=500, shuffle = False, pin_memory = True)\n# model1.eval()\n# evaluate(model1, test_dl)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T17:35:59.117402Z","iopub.execute_input":"2021-06-24T17:35:59.118174Z","iopub.status.idle":"2021-06-24T17:35:59.12409Z","shell.execute_reply.started":"2021-06-24T17:35:59.118135Z","shell.execute_reply":"2021-06-24T17:35:59.123143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %%time\n# test_dl = DataLoader(test_ds, batch_size=500, shuffle = False, pin_memory = False)\n# model1.eval()\n# evaluate(model1, test_dl)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T17:35:59.125836Z","iopub.execute_input":"2021-06-24T17:35:59.126513Z","iopub.status.idle":"2021-06-24T17:35:59.132378Z","shell.execute_reply.started":"2021-06-24T17:35:59.126474Z","shell.execute_reply":"2021-06-24T17:35:59.131499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}