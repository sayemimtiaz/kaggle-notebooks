{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Life Expectancy (WHO)\n* Statistical Analysis on factors influencing Life Expectancy\n\n\n\n## Context\n\nAlthough there have been lot of studies undertaken in the past on factors affecting life expectancy considering demographic variables, income composition and mortality rates. It was found that affect of immunization and human development index was not taken into account in the past. Also, some of the past research was done considering multiple linear regression based on data set of one year for all the countries. Hence, this gives motivation to resolve both the factors stated previously by formulating a regression model based on mixed effects model and multiple linear regression while considering data from a period of 2000 to 2015 for all the countries. Important immunization like Hepatitis B, Polio and Diphtheria will also be considered. In a nutshell, this study will focus on immunization factors, mortality factors, economic factors, social factors and other health related factors as well. Since the observations this dataset are based on different countries, it will be easier for a country to determine the predicting factor which is contributing to lower value of life expectancy. This will help in suggesting a country which area should be given importance in order to efficiently improve the life expectancy of its population.\n\n\n## Content\n\nThe project relies on accuracy of data. The Global Health Observatory (GHO) data repository under World Health Organization (WHO) keeps track of the health status as well as many other related factors for all countries The data-sets are made available to public for the purpose of health data analysis. The data-set related to life expectancy, health factors for 193 countries has been collected from the same WHO data repository website and its corresponding economic data was collected from United Nation website. Among all categories of health-related factors only those critical factors were chosen which are more representative. It has been observed that in the past 15 years , there has been a huge development in health sector resulting in improvement of human mortality rates especially in the developing nations in comparison to the past 30 years. Therefore, in this project we have considered data from year 2000-2015 for 193 countries for further analysis. The individual data files have been merged together into a single data-set. On initial visual inspection of the data showed some missing values. As the data-sets were from WHO, we found no evident errors. Missing data was handled in R software by using Missmap command. The result indicated that most of the missing data was for population, Hepatitis B and GDP. The missing data were from less known countries like Vanuatu, Tonga, Togo, Cabo Verde etc. Finding all data for these countries was difficult and hence, it was decided that we exclude these countries from the final model data-set. The final merged file(final dataset) consists of 22 Columns and 2938 rows which meant 20 predicting variables. All predicting variables was then divided into several broad categories:​Immunization related factors, Mortality factors, Economical factors and Social factors.\n\n\n## Acknowledgements\n\nThe data was collected from WHO and United Nations website with the help of Deeksha Russell and Duan Wang.\n\n\n## Inspiration\n\nThe data-set aims to answer the following key questions:\n\n   - Does various predicting factors which has been chosen initially really affect the Life expectancy? What are the predicting variables actually affecting the life expectancy?\n   - Should a country having a lower life expectancy value(<65) increase its healthcare expenditure in order to improve its average lifespan?\n   - How does Infant and Adult mortality rates affect life expectancy?\n   - Does Life Expectancy has positive or negative correlation with eating habits, lifestyle, exercise, smoking, drinking alcohol etc.\n   - What is the impact of schooling on the lifespan of humans?\n   - Does Life Expectancy have positive or negative relationship with drinking alcohol?\n   - Do densely populated countries tend to have lower life expectancy?\n   - What is the impact of Immunization coverage on life Expectancy?\n\n\n### Note: This study created simple visualizations dont forget it but for basic levels!"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nimport seaborn as sns\nfrom sklearn.preprocessing import scale \nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\nfrom sklearn.metrics import roc_auc_score,roc_curve\nimport statsmodels.formula.api as smf\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import mean_squared_error, r2_score                # we are using this for model tunning\n\nfrom warnings import filterwarnings\nfilterwarnings('ignore')\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Life_Expectancy_Data = pd.read_csv(\"../input/life-expectancy-who/Life Expectancy Data.csv\")\ndata = Life_Expectancy_Data.copy()\ndata = data.dropna()            # If there is a missing or empty observation, delete it. Or 'data.fillna(data.mean(), inplace=True)' with this make NaN values take mean\n\nlindata = data.copy()\nmultidata = data.copy()\npolydata = data.copy()\nRFdata = data.copy()\nlogdata = data.copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Linear Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"lindata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lindata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lindata.corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looking at heatmap, there is a good relationship (correlation exists) between the best 'GDP' and 'percentage expenditure' in the Life Expectation data.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot the heatmap\ncorr = lindata.corr()\nsns.heatmap(corr, \n        xticklabels=corr.columns,\n        yticklabels=corr.columns)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here it is better to establish a linear model between 'GDP' and 'percentage expenditure'. Let's see what our spending percentages are compared to the \"GDP\" increase. Let's create and fit our linear model."},{"metadata":{"trusted":true},"cell_type":"code","source":"linear_reg = LinearRegression()\nx = lindata.GDP.values.reshape(-1,1)\ny = lindata['percentage expenditure'].values.reshape(-1,1)          \n\nlinear_reg.fit(x,y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## y = b0 + b1*x is our linear regression model.\nLet's see estimated percentage of expenditure in GDP 10 thousand:"},{"metadata":{"trusted":true},"cell_type":"code","source":"b0 = linear_reg.predict(([[10000]]))       \nprint(\"b0: \", b0)\n\nb1 = linear_reg.coef_\nprint(\"b1: \", b1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_array = np.arange(min(lindata.GDP),max(lindata.GDP)).reshape(-1,1)  # this for information about the line to be predicted\n\nplt.scatter(x,y)\ny_head = linear_reg.predict(x_array)                                 # this is predict percentage of expenditure\nplt.plot(x_array,y_head,color=\"red\")\nplt.show()\n\nfrom sklearn import metrics\nprint(\"Mean Absolute Error: \", metrics.mean_absolute_error(x_array,y_head))\nprint(\"Mean Squared Error: \", metrics.mean_squared_error(x_array,y_head))\nprint(\"Root Mean Squared Error: \", np.sqrt(metrics.mean_squared_error(x_array, y_head)))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(r2_score(y, linear_reg.predict(x)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### The conclusion here is: the estimate made has 92% accuracy."},{"metadata":{},"cell_type":"markdown","source":"# Multi Linear Regression\n\n* Here, let's take a look at the variable that depends on Life Expectancy.\n* If there is missing observation or empty, delete it. Or 'data.fillna (data.mean (), inplace = True)' with this make NaN values averaged.\n* When we look at the data, Country and Status columns are composed of objects. Because we need to be int or float.\n* and let's take the last two columns (Income composition of resources, schooling) as independent variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"Life_Expectancy_Data = pd.read_csv(\"../input/life-expectancy-who/Life Expectancy Data.csv\")\ndata = Life_Expectancy_Data.copy()\ndata = data.dropna()\n\nmultidata = data.copy()\n\nmultidata.drop([\"Country\", \"Status\"], axis=1, inplace=True)             # When we look at the data, Country and Status columns are composed of objects. Because we need to be int or float.\n\nx = multidata.iloc[:, [-2,-1]].values                                   # I took the last two columns (Income composition of resources, schooling) as independent variables.\ny = multidata[\"percentage expenditure\"].values.reshape(-1,1)            # our independent variable\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state= 42)\nlm = LinearRegression()\nmodel = lm.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"b0: \", lm.intercept_)\nprint(\"b1,b2: \", lm.coef_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We look at what the data set we created here will affect how much it will affect our survival."},{"metadata":{"trusted":true},"cell_type":"code","source":"new_data = [[0.4,8], [0.5,10]]   \nnew_data = pd.DataFrame(new_data).T       # .T is transfor the chart.\nmodel.predict(new_data) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Now let's look at the correctness of the evaluation we made. If the difference between the train error and the test error is not much, modeling is good."},{"metadata":{"trusted":true},"cell_type":"code","source":"rmse = np.sqrt(mean_squared_error(y_train, model.predict(x_train)))\nrmse","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.score(x_train, y_train) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### CV $r^2$ value of the model:"},{"metadata":{"trusted":true},"cell_type":"code","source":"cross_val_score(model, x_train,  y_train, cv= 10, scoring=\"r2\").mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Predicts of Train set values:"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_head = model.predict(x_test)\ny_head[0:5]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"y_test_1 =np.array(range(0,len(y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# r2 value: \nr2_degeri = r2_score(y_test, y_head)\nprint(\"Test r2 error = \",r2_degeri) \n\nplt.plot(y_test_1,y_test,color=\"r\")\nplt.plot(y_test_1,y_head,color=\"blue\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Polynomial Regression\n\nWe will use the same data set."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import PolynomialFeatures     # this gives properties of polynomial\n\nLife_Expectancy_Data = pd.read_csv(\"../input/life-expectancy-who/Life Expectancy Data.csv\")\ndata = Life_Expectancy_Data.copy()\ndata = data.dropna()        \n\npolydata = data.copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's see what our spending percentages are compared to the \"GDP\" increase. Let's create and fit our linear model."},{"metadata":{"trusted":true},"cell_type":"code","source":"linear_reg = LinearRegression()\nx = polydata.GDP.values.reshape(-1,1)\ny = polydata['percentage expenditure'].values.reshape(-1,1)          \n\nlinear_reg.fit(x,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state= 42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's look at the 15th degree. If it's not, we should change it."},{"metadata":{"trusted":true},"cell_type":"code","source":"polynomial_regression = PolynomialFeatures(degree = 15)    \nx_polynomial = polynomial_regression.fit_transform(x)\n\nlinear_reg2 = LinearRegression()\nlinear_reg2.fit(x_polynomial,y)\n\ny_head = linear_reg2.predict(x_polynomial)\n\nplt.plot(x,y_head,color=\"green\",label=\"poly\")\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With degree we determine the precision of our forecast. If it is too large, it will deteriorate, so it is necessary to determine according to the data."},{"metadata":{"trusted":true},"cell_type":"code","source":"pol_reg = PolynomialFeatures(degree = 8)                    \n\nlevel_poly = pol_reg.fit_transform(x_train)                 # According to the polynomial, x_train is defined\n\nlm = LinearRegression()                                     \nlm.fit(level_poly,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_head = lm.predict(pol_reg.fit_transform(x_train))\ny_test =np.array(range(0,len(y_train)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Consistency and scatter drawing of $r^2$ model:"},{"metadata":{"trusted":true},"cell_type":"code","source":"r2 = r2_score(y_train, y_head)\nprint(\"r2 value: \", r2)                               # percentage of significance\n\n\nplt.scatter(y_test, y_train, color=\"red\")\nplt.scatter(y_test, y_head, color = \"g\")\nplt.xlabel(\"GDP\")\nplt.ylabel(\"percentage expenditure\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(y_test,y_train, color=\"red\")\nplt.plot(y_test, y_head, color = \"blue\")\nplt.xlabel(\"GDP\")\nplt.ylabel(\"percentage expenditure\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Decision Tree Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor               # for our predict model\n\nLife_Expectancy_Data = pd.read_csv(\"../input/life-expectancy-who/Life Expectancy Data.csv\")\ndata = Life_Expectancy_Data.copy()\ndata = data.dropna()                                         # same is done \n\nDTdata = data.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = polydata.GDP.values.reshape(-1,1)\ny = polydata['percentage expenditure'].values.reshape(-1,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state= 42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's see Expenditure percentage estimation of the country with \"GDP\" value of 1000:"},{"metadata":{"trusted":true},"cell_type":"code","source":"DT_reg = DecisionTreeRegressor()           # created model\nDT_reg.fit(x_train,y_train)                # fitted model according to train values\n\nprint(DT_reg.predict([[1000]]))            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_array = np.arange(min(x),max(x),0.01).reshape(-1,1)   # line information to be drawn as a predict\ny_head = DT_reg.predict(x_array)                        # percentage of spend estimate\n\nplt.scatter(x,y, color=\"red\")\nplt.plot(x_array,y_head,color=\"blue\")\nplt.xlabel(\"GDP\")\nplt.ylabel(\"percentage expenditure\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Result: See how it is nice picture and very successful accuracy score."},{"metadata":{},"cell_type":"markdown","source":"# Random Forest Regression\n* A logic of DecisionTree. For example, 3000 sample data is selected from 100 thousand data and the result is obtained."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor           # for our predict model\n\nLife_Expectancy_Data = pd.read_csv(\"../input/life-expectancy-who/Life Expectancy Data.csv\")\ndata = Life_Expectancy_Data.copy()\ndata = data.dropna()                                         # same is done \n\nRFdata = data.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = polydata.GDP.values.reshape(-1,1)\ny = polydata['percentage expenditure'].values.reshape(-1,1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create regression with 5 DecisionTreeReg in the sklearn RandomForestRegressor model. We can do as many as we want. Giving random_state does not change the outcome. When we say 1, it should not change once."},{"metadata":{"trusted":true},"cell_type":"code","source":"RF_reg = RandomForestRegressor(n_estimators=100, random_state=42)          \nRF_reg.fit(x,y)                                                # the best fit line is drawn","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Expenditure percentage estimation of the country with \"GDP\" value of 1000:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(RF_reg.predict([[1000]]))            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_array = np.arange(min(x),max(x),0.01).reshape(-1,1)   # line information to be drawn as a predict\ny_head = RF_reg.predict(x_array)                        # percentage of spend predict\n\nplt.scatter(x,y, color=\"red\")\nplt.plot(x_array,y_head,color=\"blue\")\nplt.xlabel(\"GDP\")\nplt.ylabel(\"percentage expenditure\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Result: This result good but not so good as BEFORE."},{"metadata":{},"cell_type":"markdown","source":"# Logistic Regression Model\n\n* The aim is to reveal the class that will occur when a set of x values that have not yet been observed, to predict a classifier.\n* For the classification problem, to establish a linear model that defines the relationship between dependent and independent variables.\n* Regarding whether the dependent variable is 1 or 0 or yes or no status\n\n\n** In this data, we will examine the states of Developed countries (Developed) = 0 and Developing = 1. I want to find the level of development I want, so close to 1!"},{"metadata":{},"cell_type":"markdown","source":"When we look at the country column data, it consists of objects, let's drop it. Because we need int or float values."},{"metadata":{"trusted":true},"cell_type":"code","source":"logdata.drop([\"Country\"], axis=1, inplace=True)  \nlogdata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Our variable class, which is 1 to 0, let's examine this."},{"metadata":{"trusted":true},"cell_type":"code","source":"logdata[\"Status\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's continue with the review."},{"metadata":{"trusted":true},"cell_type":"code","source":"logdata[\"Status\"].value_counts().plot.barh();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We need to create binary, that is, from 0 to 1. Let's do the necessary transformations."},{"metadata":{"trusted":true},"cell_type":"code","source":"logdata.Status = [1 if each == \"Developing\" else 0 for each in logdata.Status]   ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's look at their general statistical properties."},{"metadata":{"trusted":true},"cell_type":"code","source":"\nlogdata.describe().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's create our variables now."},{"metadata":{"trusted":true},"cell_type":"code","source":"y = logdata[\"Status\"]\nX_data = logdata.drop([\"Status\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's do normalization in our data."},{"metadata":{"trusted":true},"cell_type":"code","source":"#*** Normalize ***#\n\nX = (X_data - np.min(X_data))/(np.max(X_data) - np.min(X_data)).values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's build a model through statsmodels and make it fit. Here, the meaning of the model and how much of this variable affects us, comes from this table."},{"metadata":{"trusted":true},"cell_type":"code","source":"loj = sm.Logit(y, X)\nloj_model= loj.fit()\nloj_model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Then see model:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nloj = LogisticRegression(solver = \"liblinear\")\nloj_model = loj.fit(X,y)\nloj_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# constant value\nloj_model.intercept_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Coefficient values of all independent variables:"},{"metadata":{"trusted":true},"cell_type":"code","source":"loj_model.coef_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# PREDICT and MODEL TUNNING"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = loj_model.predict(X)              # predict","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Confusion Matrix: Those that are 1 (PP) when it is 1 in reality, 0 (PN) when it is 1, 1 (NP) when it is 0 when it is 0 (NN) when it is 0."},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(y, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"See accuracy score:"},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(y, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"One of the outputs that will evaluate the results of a most detailed classification algorithm."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"See top 10 model predict values:"},{"metadata":{"trusted":true},"cell_type":"code","source":"loj_model.predict(X)[0:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Using the 'predict_proba' module if we want to give the noble values rather than the values given above 1 and 0.\n\n\n* Returns the values of 0 in the index or left side of 0, and values of 1 in the index 1 or of the right side of the matrix."},{"metadata":{"trusted":true},"cell_type":"code","source":"\nloj_model.predict_proba(X)[0:10][:,0:2]                # Top 10","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now let's try to model the ten prediction probability values above 'predict_proba'."},{"metadata":{"trusted":true},"cell_type":"code","source":"\ny_probs = loj_model.predict_proba(X)\ny_probs = y_probs[:,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_probs[0:10]               # top 10","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Put our guess values here in the loop and give it 1 to 0.5 and 0 to the little ones."},{"metadata":{"trusted":true},"cell_type":"code","source":"\ny_pred = [1 if i > 0.5 else 0 for i in y_probs]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"When we look at the value above, we notice the change. Our purpose to do this is to verify our model."},{"metadata":{"trusted":true},"cell_type":"code","source":"\ny_pred[0:10]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nconfusion_matrix(y, y_pred)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(y, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's do one more look at the top 5 elements we did above."},{"metadata":{"trusted":true},"cell_type":"code","source":"\nloj_model.predict_proba(X)[:,1][0:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logit_roc_auc = roc_auc_score(y, loj_model.predict(X))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fpr, tpr, thresholds = roc_curve(y, loj_model.predict_proba(X)[:,1])\nplt.figure()\nplt.plot(fpr, tpr, label='AUC (area = %0.2f)' % logit_roc_auc)\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Oranı')\nplt.ylabel('True Positive Oranı')\nplt.title('ROC')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here, \n\n- blueline: The graphic of our success regarding the model we have established.\n- redline: If we don't do anything, our model will be this way. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# test train is subjected to separation\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Let's create and fit our model."},{"metadata":{"trusted":true},"cell_type":"code","source":"\nloj = LogisticRegression(solver = \"liblinear\")\nloj_model = loj.fit(X_train,y_train)\nloj_model\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's see accuracy score:"},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(y_test, loj_model.predict(X_test))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finally Tunned model score:"},{"metadata":{"trusted":true},"cell_type":"code","source":"cross_val_score(loj_model, X_test, y_test, cv = 10).mean()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Result: From this data, we understand: 89% of the countries that are developing are developing countries, and the effects of the variables that will question life expectancies can be examined."},{"metadata":{},"cell_type":"markdown","source":"# Conclusion\nWe examined the **Life Expectancy (WHO)** data set with the basic models in Machine Learing and made some comments.\n\nNote:\n\n   - After this notebook, my aim is to prepare 'kernel' which is 'not clear' data set.\n\n   - If you have any suggestions, please could you write for me? I wil be happy for comment and critics!\n\n   - Thank you for your suggestion and votes ;)\n"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}