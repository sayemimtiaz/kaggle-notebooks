{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport sqlite3 as sql\nimport csv # what is this?\n\nlimitResults = 72\nlimitFormatTypes = True\n\ndbName = \"bookdepo.db\"\nconn = sql.connect(dbName) \ndoesTableExist = \"SELECT count(*) FROM sqlite_master WHERE type='table' AND name='books';\"\ndf = pd.read_sql(doesTableExist, conn)\ntableExists = df.values.any()\nif (tableExists != True):\n    print(\"- - table does not exist yet\")\n    print(\"- - read csv\")\n    fileIn = \"/kaggle/input/book-depository-dataset/dataset.csv\"\n    df = pd.read_csv(fileIn, thousands=None)\n    print(\"- - remove commas from bestsellers col\")\n    # df[\"bestsellers-rank\"] = pd.to_numeric(df[\"bestsellers-rank\"])\n    # df.astype({'bestsellers-rank': 'int32'})\n    df['bestsellers-rank'] = df['bestsellers-rank'].str.replace(',', '')\n    print(\"- - create 'books' table\")\n    df.to_sql('books', conn)\nelse:\n    print(\"- - books table found in \" + dbName)\n\nlimitString = str(limitResults)\ncol1 = '\"authors\", \"bestsellers-rank\", \"categories\", \"description\", \"dimension-x\"'\ncol2 = '\"dimension-y\", \"dimension-z\", \"edition\", \"edition-statement\", \"for-ages\"'\ncol3 = '\"format\", \"id\", \"illustrations-note\", \"imprint\", \"index-date\"'\ncol4 = '\"isbn10\", \"isbn13\", \"lang\", \"publication-date\", \"publication-place\"'\ncol5 = '\"rating-avg\", \"rating-count\", \"title\", \"url\", \"weight\"'\nseperator = ', '\ns = seperator\ncols = col1 + s + col2 + s + col3 + s + col4 + s + col5\nqFormatIn = ' AND format IN (1,2,3,13,15,26)'\nqueryStart = 'SELECT ' + cols + ' FROM books WHERE lang = \"en\" AND description IS NOT NULL'\n# distinct ids\n# queryStart = 'SELECT COUNT(\"id\"), id FROM books WHERE lang = \"en\" AND description IS NOT NULL GROUP BY title'\nif (limitResults > 0):\n    limsql = ' LIMIT '\n    queryEnd = limsql + limitString\nelse:\n    limitString = \"\"\n    queryEnd = \"\"\n\nif (limitFormatTypes == True):\n    query = queryStart + qFormatIn + queryEnd\nelse: \n    query = queryStart + queryEnd\n\nprint(\"- - running query\")\nprint(query)\nprint(\" \")\ndf = pd.read_sql(query, conn)\n\nfileNameStart = \"booksEng\"\nfileNameLimit = limitString\nfileNameExt = \".csv\"\nfileName = fileNameStart + fileNameLimit + fileNameExt\nfileOut = fileName\n\nprint(\"- - writing to file\")\nprint(fileOut)\nprint(\" \")\ndf.to_csv(fileOut,index=False,quoting=csv.QUOTE_ALL,line_terminator='\\r\\n')\nprint (\"- - done\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The code above is an amateur example of how to run sql queries on a csv dataset.\n\nDespite my best efforts, this code might not do what I intended it to do, which is provide an SQL query tool for convenience in slicing up the (1m x 25) dataset.csv of the Book Depository Dataset *(from bookdepository.com)* provided by Panagiotis Simakis. If you look at the version history you'll notice a bunch of rookie mistakes and clumsiness. Swim at your own risk."},{"metadata":{},"cell_type":"markdown","source":"## Thanks to: \n\n* https://www.kaggle.com/diamazov/export-usa-names-into-csv - for showing me how to export files to csv.\n* https://stackoverflow.com/questions/41433269/pandas-write-csv-file-with-windows-line-ending - solution for busted line endings in windows\n* Panagiotis Simakis and BookDepository for dataset"},{"metadata":{},"cell_type":"markdown","source":"## TODO:\n\n* ~~remove thousands comma separator from bestseller-rank and similar~~\n* ~~It tooks like a column called index was added to my db, and then the output adds another unnamed (!) column with the exact same autoincrementing index - so I need to adjust the output to not return the  (two?) index columns~~\n* ~~I need to create the books table if books does not exist...~~"},{"metadata":{},"cell_type":"markdown","source":"## db\n\nfor better worse I created an actual file, and didn't not use this *(which I believe is a temp db that lives, like, in memory or something like that)*"},{"metadata":{},"cell_type":"markdown","source":"Create an in-memory SQLite database.\n\n<pre>\nfrom sqlalchemy import create_engine\nengine = create_engine('sqlite://', echo=False)\n</pre>"},{"metadata":{},"cell_type":"markdown","source":"## Probably not the best way to determine if table exists...\n\nbut this is how I determine if table exists"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport sqlite3 as sql\nconn = sql.connect(\"mydb.db\") \ndoesTableExist = \"SELECT count(*) FROM sqlite_master WHERE type='table' AND name='books';\"\ndf = pd.read_sql(doesTableExist, conn)\ndf.values.any()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Show Columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Show Columns\nimport pandas as pd\nimport sqlite3 as sql\nconn = sql.connect(\"mydb.db\")\nq = \"PRAGMA table_info(books)\"\nout = pd.read_sql(q, conn)\nprint(out)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Datatypes\n\nthis displays the datatypes of the dataframe (df)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}