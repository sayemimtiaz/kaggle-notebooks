{"cells":[{"metadata":{"_uuid":"3e31b44d0a51ce86eddf4487c2e63a99e9128742"},"cell_type":"markdown","source":"# Lung segmentation from Chest X-Ray dataset\n\n**About the data**:\n- The dataset is made up of images and segmentated mask from two diffrent sources.\n- There is a slight abnormality in naming convention of masks.\n- Some images don't have their corresponding masks.\n- Images from the Shenzhen dataset has apparently smaller lungs as compared to the Montgomery dataset.\n\n### the data set and code used in this worked is taken from [here](https://www.kaggle.com/nikhilpandey360/chest-xray-masks-and-labels) \n\n## Take a look at the dataset"},{"metadata":{},"cell_type":"markdown","source":"## I have commented out these lines because there are lots of images"},{"metadata":{"trusted":true},"cell_type":"code","source":"'''import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n'''","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### let us import all the libraries "},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import numpy as np \nimport tensorflow as tf\nimport pandas as pd\nfrom tqdm import tqdm\nimport os\nfrom cv2 import imread, createCLAHE \nimport cv2\nfrom glob import glob\n%matplotlib inline\nimport matplotlib.pyplot as plt\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2252420ebc0208a088b2efaea43acf460adea99b"},"cell_type":"markdown","source":"### we have 704 masks but 800 images. Hence we are going to\n### make a 1-1 correspondance from mask to images, not the usual other way."},{"metadata":{"_uuid":"76354e77262b9d98b50eabc96ef25d4885f3ca97","trusted":true},"cell_type":"code","source":"\nimage_path = os.path.join(\"../input/chest-xray-masks-and-labels/Lung Segmentation/CXR_png/\")\nmask_path = os.path.join(\"../input/chest-xray-masks-and-labels/data/Lung Segmentation/masks/\")\nimages = os.listdir(image_path)\nmask = os.listdir(mask_path)\n\nmask = [fName.split(\".png\")[0] for fName in mask] # name of the mask or segment \nimage_file_name = [fName.split(\"_mask\")[0] for fName in mask] # name of the image file ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e92365a3eb0b6d6e312a21b2134a95a477b8eaba","trusted":true},"cell_type":"code","source":"check = [i for i in mask if \"mask\" in i]\nprint(\"Total mask that has modified name:\",len(check))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testing_files = set(os.listdir(image_path)) & set(os.listdir(mask_path))\ntraining_files = check","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c06c55ad639d173daa4bce514a3c1771c3ecb960","trusted":true},"cell_type":"code","source":"# define the function to get data \n\ndef getData(X_shape, flag = \"test\"):\n    im_array = []\n    mask_array = []\n    \n    if flag == \"test\":\n        for i in tqdm(testing_files): \n            im = cv2.resize(cv2.imread(os.path.join(image_path,i)),(X_shape,X_shape))[:,:,0]\n            mask = cv2.resize(cv2.imread(os.path.join(mask_path,i)),(X_shape,X_shape))[:,:,0]\n            \n            im_array.append(im)\n            mask_array.append(mask)\n        \n        return im_array,mask_array\n    \n    if flag == \"train\":\n        for i in tqdm(training_files): \n            im = cv2.resize(cv2.imread(os.path.join(image_path,i.split(\"_mask\")[0]+\".png\")),(X_shape,X_shape))[:,:,0]\n            mask = cv2.resize(cv2.imread(os.path.join(mask_path,i+\".png\")),(X_shape,X_shape))[:,:,0]\n\n            im_array.append(im)\n            mask_array.append(mask)\n\n        return im_array,mask_array","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8adb79d0acf0b5ed3f1b65910d6f8f5e2512773a","trusted":true},"cell_type":"code","source":"#perform sanity check\n\ndef plotMask(X,y):\n    sample = []\n    \n    for i in range(6):\n        left = X[i]\n        right = y[i]\n        combined = np.hstack((left,right))\n        sample.append(combined)\n        \n        \n    for i in range(0,6,3):\n\n        plt.figure(figsize=(25,10))\n        \n        plt.subplot(2,3,1+i)\n        plt.imshow(sample[i])\n        \n        plt.subplot(2,3,2+i)\n        plt.imshow(sample[i+1])\n        \n        \n        plt.subplot(2,3,3+i)\n        plt.imshow(sample[i+2])\n        \n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b362629edae52f8ca2b558ff621bb50565cbedc4","trusted":true},"cell_type":"code","source":"# Load training and testing data\ndim = 256*2\nX_train,y_train = getData(dim,flag=\"train\")\nX_test, y_test = getData(dim)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dbd0220555c692baee8ea509403d64364e2ae439"},"cell_type":"markdown","source":"# Perform Sanity Check\n\nIt is prudent to perform sanity check of the data correspondance. It become a routine check-up after a while but it is very crucial to check if we had made a mistake in loading the data."},{"metadata":{"_uuid":"73be5055a2bf24f67eaf01fe18d0f590ad219553","trusted":true},"cell_type":"code","source":"print(\"training set\")\nplotMask(X_train,y_train)\nprint(\"testing set\")\nplotMask(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a5a309b299cfe2aaa36abd4d175d75f64acba18f"},"cell_type":"markdown","source":"Both the sets looks correct. Let's combine them and further use them as a unified dataset."},{"metadata":{"_uuid":"a65cc256944bf247e150dff8006990d8dafd2185","trusted":true},"cell_type":"code","source":"X_train = np.array(X_train).reshape(len(X_train),dim,dim,1)\ny_train = np.array(y_train).reshape(len(y_train),dim,dim,1)\nX_test = np.array(X_test).reshape(len(X_test),dim,dim,1)\ny_test = np.array(y_test).reshape(len(y_test),dim,dim,1)\nassert X_train.shape == y_train.shape\nassert X_test.shape == y_test.shape\nimages = np.concatenate((X_train,X_test),axis=0)\nmask  = np.concatenate((y_train,y_test),axis=0)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"04229b3b71c9791087a6d646d49ba213a4211093"},"cell_type":"markdown","source":"## Define  the network and callbacks\n\nI am going to use my favourite segmentation network - U-Nets. You can read about them [here](https://arxiv.org/abs/1505.04597)."},{"metadata":{"_uuid":"4030463057053ed34371466a0b51584b0310685f","trusted":true},"cell_type":"code","source":"from keras.models import *\nfrom keras.layers import *\nfrom keras.optimizers import *\nfrom keras import backend as keras\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler\n\n\ndef dice_coef(y_true, y_pred):\n    y_true_f = keras.flatten(y_true)\n    y_pred_f = keras.flatten(y_pred)\n    intersection = keras.sum(y_true_f * y_pred_f)\n    return (2. * intersection + 1) / (keras.sum(y_true_f) + keras.sum(y_pred_f) + 1)\n\ndef dice_coef_loss(y_true, y_pred):\n    return -dice_coef(y_true, y_pred)\n\ndef unet(input_size=(256,256,1)):\n    inputs = Input(input_size)\n    \n    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n\n    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n\n    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n\n    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n\n    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n\n    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n\n    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n\n    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n\n    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n\n    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n\n    return Model(inputs=[inputs], outputs=[conv10])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"06d702f1b3957412bb2025c1b4fb3b2a322735d7"},"cell_type":"markdown","source":"#### Compile and train the Unet Model"},{"metadata":{"_uuid":"37e9815e1fbb5ff29d7ffab156541df200e94e2b","trusted":true},"cell_type":"code","source":"model = unet(input_size=(512,512,1))\nmodel.compile(optimizer=Adam(lr=1e-5), loss=dice_coef_loss,\n                  metrics=[dice_coef, 'binary_accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## plot the model "},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.keras.utils.plot_model(model, to_file='model.png')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9884bf48369bf28f4b0fcb9eb1a1fa4cc4bdd17c"},"cell_type":"markdown","source":"## Callbacks, Early Stopping and Reduced LR\n"},{"metadata":{"_uuid":"6819a68ded3a727ded1b2103b44cd4b8a4988f0f","trusted":true},"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\nweight_path=\"{}_weights.best.hdf5\".format('cxr_reg')\n\ncheckpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n                             save_best_only=True, mode='min', save_weights_only = True)\n\nreduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.5, \n                                   patience=3, \n                                   verbose=1, mode='min', epsilon=0.0001, cooldown=2, min_lr=1e-6)\nearly = EarlyStopping(monitor=\"val_loss\", \n                      mode=\"min\", \n                      patience=15) # probably needs to be more patient, but kaggle time is limited\ncallbacks_list = [checkpoint, early, reduceLROnPlat]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"103a3c9167431a0f4a8279de220fb0f598c11337"},"cell_type":"markdown","source":"#### Train the model\n\nI intially used a 60-40 train-test spit and got a loss of -0.97. However, the better way to do it is 80-10-10 train-test-validation spit. Below I am roughly doing the later."},{"metadata":{"_uuid":"ddebe9df6f56549a3897fdbfe35a0014eb12040c","scrolled":false,"trusted":true},"cell_type":"code","source":"from IPython.display import clear_output\nfrom keras.optimizers import Adam \nfrom sklearn.model_selection import train_test_split\n\nmodel.compile(optimizer=Adam(lr=2e-4), \n              loss=[dice_coef_loss], \n           metrics = [dice_coef, 'binary_accuracy'])\n\ntrain_vol, validation_vol, train_seg, validation_seg = train_test_split((images-127.0)/127.0, \n                                                            (mask>127).astype(np.float32), \n                                                            test_size = 0.1,random_state = 2018)\n\ntrain_vol, test_vol, train_seg, test_seg = train_test_split(train_vol,train_seg, \n                                                            test_size = 0.1, \n                                                            random_state = 2018)\n\nloss_history = model.fit(x = train_vol,\n                       y = train_seg,\n                         batch_size = 16,\n                  epochs = 50,\n                  validation_data =(test_vol,test_seg) ,\n                  callbacks=callbacks_list)\n\nmodel.save('my_model.h5') \n#clear_output()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"98f61cff65c365a3811d7bc7803a516b98b3d8b9"},"cell_type":"markdown","source":"## Plot the metric and evaluate "},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('my_model.h5') ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bb888c80a41662480c712552196e9257bddd3767","trusted":true},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (10, 5))\nax1.plot(loss_history.history['loss'], '-', label = 'Loss')\nax1.plot(loss_history.history['val_loss'], '-', label = 'Validation Loss')\nax1.legend()\n\nax2.plot(100*np.array(loss_history.history['binary_accuracy']), '-', \n         label = 'Accuracy')\nax2.plot(100*np.array(loss_history.history['val_binary_accuracy']), '-',\n         label = 'Validation Accuracy')\nax2.legend()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0b1f54886e584980665a3ee6c64b1d5afbdab681"},"cell_type":"markdown","source":"## Test the model"},{"metadata":{"_uuid":"99a79de377e4f0ef780fb99b710081b81fbd31d9","trusted":true},"cell_type":"code","source":"pred_candidates = np.random.randint(1,validation_vol.shape[0],10)\npreds = model.predict(validation_vol)\n\nplt.figure(figsize=(20,10))\n\nfor i in range(0,9,3):\n    plt.subplot(3,3,i+1)\n    \n    plt.imshow(np.squeeze(validation_vol[pred_candidates[i]]))\n    plt.xlabel(\"Base Image\")\n    \n    \n    plt.subplot(3,3,i+2)\n    plt.imshow(np.squeeze(validation_seg[pred_candidates[i]]))\n    plt.xlabel(\"Mask\")\n    \n    plt.subplot(3,3,i+3)\n    plt.imshow(np.squeeze(preds[pred_candidates[i]]))\n    plt.xlabel(\"Pridiction\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}