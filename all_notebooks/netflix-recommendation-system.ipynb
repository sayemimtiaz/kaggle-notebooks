{"cells":[{"metadata":{},"cell_type":"markdown","source":"![](https://logos-download.com/wp-content/uploads/2016/03/Netflix_logo_red.png)\n\n# Introduction\n\nNetflix was conceived in 1997 by Reed Hastings (the current CEO) and Marc Randolph. Both had previous in the West Coast tech scene â€“ Hastings was the owner of debugging software firm Pure Atria, while Randolph had cofounded, and then sold computer mail order company MicroWarehouse for $700 million.\nNetflix.com started life as a DVD rental service in 1998; an online rival to the then dominant Blockbuster Video. \n\nAt the end of 2019, Netflix subscribers numbered 167.1 million. Of these, 61 million accounts were registered in the US, with the remaining 106.1 million (63%) spread over the rest of the globe.\nInternational growth in Netflix subscriptions has far outpaced domestic growth in recent years, since international users first came to account for the greatest proportion of international users as recently as 2017. Since 2015 the number of international Netflix users has increased nearly fourfold, while domestic users have increased by less than 50%.\n\nOne of the technologies that made netflix the technological giant, that it is today, is recommendations engine.\nA recommendations engine, in simple words, is a piece of code which can recommend users the most related item based on their current item choice or their previous history of choices. In this notebook, I have tried to create a simple recommendations engine based on weighted averages technique and Content based filtering.  "},{"metadata":{},"cell_type":"markdown","source":"# NOTE\n\nI have used some sections of code from Krish Naik's notebook and would like to give credits to him. This project is made for study and learning purposes. I have added my own changes and work as well to make the recommendations system more efficient and useful. The data that I have used is available on Kaggle and I have engineered features according to my needs. "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport pickle","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"imdb_df = pd.read_csv('/kaggle/input/netflix-data/IMDb movies.csv')\nnetflix_df = pd.read_csv('/kaggle/input/netflix-data/netflix_titles.csv')\nnetflix_df2 = pd.read_csv('/kaggle/input/netflix-data/NetflixViewingHistory.csv')\nstreaming_platforms_df = pd.read_csv('/kaggle/input/movies-on-netflix-prime-video-hulu-and-disney/MoviesOnStreamingPlatforms_updated.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data-Engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"streaming_platforms_df['title']=streaming_platforms_df['Title']\ndrop=['Unnamed: 0', 'ID','Year', 'Age','Type','Directors','Genres', 'Country', 'Language', 'Runtime','Title','Rotten Tomatoes','IMDb']\nstreaming_platforms_df.drop(drop, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"netflix_df2['title']=netflix_df2.Title","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drop=['Title','Date']\nnetflix_df2.drop(drop, axis=1,inplace=True)\nnetflix_df2 = netflix_df2.drop_duplicates()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imdb_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drop = ['imdb_title_id','original_title','worlwide_gross_income','metascore','usa_gross_income','budget',\n       'writer', 'duration', 'country', 'language', 'director','year', 'date_published']\nimdb_df.drop(drop, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imdb_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"netflix_df = netflix_df[netflix_df['type']=='Movie']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drop = ['show_id', 'cast', 'country','listed_in','rating','release_year','type','date_added','duration','description']\nnetflix_df.drop(drop, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"netflix_df = pd.merge(netflix_df, netflix_df2, how='outer', on='title')\nnetflix_df = netflix_df.drop_duplicates()\ndataset = pd.merge(imdb_df,netflix_df, how='inner',on='title')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Weighted Averages Method\n\nIn weighted averages method, I will be recommending movies based on votes polled by users and average votes(IMDb Score). I could have just recommended movies based on highest IMDb scores but some movies are just not famous or maybe they are newly released and thus it would be more suitable to take user votes into consideration as well."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate all the components based on the weighted averages formula\nv=dataset['votes']\nR=dataset['avg_vote']\nC=dataset['avg_vote'].mean()\nm=dataset['votes'].quantile(0.70)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['weighted_average']=((R*v)+ (C*m))/(v+m)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sorted=dataset.sort_values('weighted_average',ascending=False)\ndf_sorted[['title', 'votes', 'avg_vote', 'weighted_average']].head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style=\"whitegrid\")\nweight_average=df_sorted.sort_values('weighted_average',ascending=False)\nplt.figure(figsize=(12,6))\naxis1=sns.barplot(x=weight_average['weighted_average'].head(20), y=weight_average['title'].head(20), data=weight_average)\nplt.xlim(4, 10)\nplt.title('Best Movies on Netflix by average votes(on IMDb)', weight='bold')\nplt.xlabel('Weighted Average Score', weight='bold')\nplt.ylabel('Movie Title', weight='bold')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Content Filtering Method\n\nIn content based filtering, I will be using certain features related to the content of movie like genre, actors, description etc to find out the similarity of any given movie with respect to all the other movies. After that, I will be selecting top 10 movies after based on the similarity values. There are certain advantages and disadvantages related to content based filtering method. They are:\n\n### Advantages\n1. Content based filtering does not require user history for making a recommendation. It can just examine the content of the movie to make recommendations. In other words, even if a user if first time using the recommendation system, the recommendation system will work just fine.\n\n### Disadvantages\n1. Content based filtering requires a lot of time to examine all the content of the movies. Since, it is based on content filtering, it needs to process all the movie and their contents in order to make a recommendation. \n2. To examine huge amount of data, it requires a lot of memory which again is a drawback."},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['IMDb Score']=dataset['avg_vote']\ndataset.drop('avg_vote',axis=1, inplace=True)\ndataset.head(1)['description']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def augmentation(df, col1, col2, col3, col4, col5):\n    index_col1 = df.columns.get_loc(col1)\n    index_col2 = df.columns.get_loc(col2)\n    index_col3 = df.columns.get_loc(col3)\n    index_col4 = df.columns.get_loc(col4)\n    index_col5 = df.columns.get_loc(col5)\n    \n    for row in range(len(df)):\n        count=0\n        cast = str(df.iat[row, index_col2])\n        main_cast = \"\"\n        for i in range(len(cast)):\n            if cast[i]!=',':\n                if count!=3:\n                    main_cast = main_cast+cast[i]\n                else:\n                    break\n            else:\n                count=count+1\n        df.iat[row,index_col3] = str(str(df.iat[row,index_col1])+str(main_cast)+str(df.iat[row,index_col4])+str(df.iat[row, index_col5]))\n        \ndataset[\"Information\"]=\"\"\n\naugmentation(dataset,'description','actors','Information','genre','director')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def case_conversion(df, col1, col2):\n    index_col1 = df.columns.get_loc(col1)\n    index_col2 = df.columns.get_loc(col2)\n    \n    for rows in range(len(df)):\n        df.iat[rows, index_col2] = df.iat[rows, index_col1].lower()\n        \ndataset['title_lower'] = \"\"\ncase_conversion(dataset, \"title\", \"title_lower\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\ntfv = TfidfVectorizer(min_df=3,  max_features=None, \n            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n            ngram_range=(1, 6),\n            stop_words = 'english')\n\n# Filling NaNs with empty string\ndataset['Information'] = dataset['Information'].fillna('')\ndataset['description'] = dataset['description'].fillna('None')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.to_csv('movie_dataset.csv', header=True, index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fitting the TF-IDF on the 'Information' text\ntfv_matrix = tfv.fit_transform(dataset['Information'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics.pairwise import sigmoid_kernel\n\n# Compute the sigmoid kernel\nsig = sigmoid_kernel(tfv_matrix, tfv_matrix)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reverse mapping of indices and movie titles\nindices = pd.Series(dataset.index, index=dataset['title_lower']).drop_duplicates()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef recommendations(title, sig=sig):\n    # Get the index corresponding to original_title\n    title = title.lower()\n    idx = indices[title]\n\n    # Get the pairwsie similarity scores \n    sig_scores = list(enumerate(sig[idx]))\n\n    # Sort the movies \n    sig_scores = sorted(sig_scores, key=lambda x: x[1], reverse=True)\n\n    # Scores of the 10 most similar movies\n    sig_scores = sig_scores[1:11]\n\n    # Movie indices\n    movie_indices = [i[0] for i in sig_scores]\n\n    # Top 10 most similar movies\n    return dataset.iloc[movie_indices]\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = recommendations(\"the green mile\")\ndata = df[['title','genre','description','IMDb Score','actors']].head(10)\ndata","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusion\n\nIn this project, I tried to study, understand and implement some algorithms which are used in modern day recommendations engine. In future, I will be trying to use other techniques out there like Collaborative based RecSys and Hybrid RecSys. Though this notebook, I tried to explain the theoritical aspects along with the practical implementations of what I learned while working on this project. I hope this notebook helps you in some way. Thanks for your time."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}