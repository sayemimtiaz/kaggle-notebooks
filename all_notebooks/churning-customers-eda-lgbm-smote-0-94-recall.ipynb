{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"# Credit Card customers\n## Predict Churning customers\n\n#### Background: \n- A manager at the bank is disturbed with more and more customers leaving their credit card services. They would really appreciate if one could predict for them who is gonna get churned so they can proactively go to the customer to provide them better services and turn customers' decisions in the opposite direction.\n\n#### Data: \n- This dataset consists of 10,000 customers mentioning their age, salary, marital_status, credit card limit, credit card category, etc. There are nearly 18 features.\n\n- Only 16.07% of customers who have churned. Thus, it's a bit difficult to train our model to predict churning customers.\n\n#### Columns:\n- Clientnum\n- Attrition_Flag\n- Customer_Age\n- Gender\n- Dependent_count: Number of dependents\n- Education_Level:Demographic variable - Educational Qualification of the account holder (example: high school, college graduate, etc.)\n- Marital_Status: Demographic variable - Married, Single, Divorced, Unknown\n- Income_Category: Demographic variable - Annual Income Category of the account holder (< $40K, $40K - 60K, $60K - $80K, $80K-$120K, > $120K, Unknown)\n- Card_Category: Product Variable - Type of Card (Blue, Silver, Gold, Platinum)\n- Months_on_book: Period of relationship with bank\n- Total_Relationship_Count: Total no. of products held by the customer\n- Months_Inactive_12_mon: No. of months inactive in the last 12 months\n- Contacts_Count_12_mon: No. of Contacts in the last 12 months\n- Credit_Limit: Credit Limit on the Credit Card\n- Total_Revolving_Bal: Total Revolving Balance on the Credit Card\n- Avg_Open_To_Buy: Open to Buy Credit Line (Average of last 12 months)\n- Total_Amt_Chng_Q4_Q1: Change in Transaction Amount (Q4 over Q1)\n- Total_Trans_Amt:Total Transaction Amount (Last 12 months)\n- Total_Trans_Ct:Total Transaction Count (Last 12 months)\n- Total_Ct_Chng_Q4_Q1 :Change in Transaction Count (Q4 over Q1)\n\n- Avg_Utilization_Ratio: Average Card Utilization Ratio\n\n- Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1\n- Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# import the tools for data analysis\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pprint as pp\nsns.set_style('darkgrid')\nsns.set_palette('Dark2')\n\n# import the csv\ndf = pd.read_csv('../input/credit-card-customers/BankChurners.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check for missing data\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets drop some unused columns\ndf.drop(['CLIENTNUM',\n         'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1',\n         'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2'],\n        axis=1,\n        inplace=True\n       )\n\n# Map our target feature to 1 or 0\ndf.Attrition_Flag = df.Attrition_Flag.map({'Existing Customer':0, 'Attrited Customer':1})\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df.Attrition_Flag)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show the heatmap of correlation between targat column and other numeric features,\nplt.figure(figsize=(10,4))\nsns.heatmap(df.corr(),cmap='Reds')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the heatmap above it is found that no numeric feature have strong negative or positive correlation with the target column. But it is ok I will explore it one by one.\n\nI will start with categorical columns first.\n\nQuestions\n    1. Is male or female has high chance to become Attrited customer than other?\n    2. What is the distribution of education level of those attrited customer ?\n    3. Is matrial status an important factor? Alone > married?\n    4. Is high income customer has higher chance to leave than low income customer?\n    5. Which category of card has the highest number of attrited customer?"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df.select_dtypes(exclude=['int64','float64']).columns)\nfigsize = (7,3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#1. Gender\nax = pd.crosstab(df.Gender, df['Attrition_Flag']).plot.bar(stacked=True)\nplt.xticks(rotation=None)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- It seems there is no huge difference between male and female"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 2, Education level\npd.crosstab(df['Education_Level'], df['Attrition_Flag']).plot.bar(stacked=True,figsize=figsize)\nplt.xticks(rotation=None)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Many Affrated customers are graudated, but it might beacause of most of the customer in dataset are graduated. So , no obviious relationship found."},{"metadata":{"trusted":true},"cell_type":"code","source":"# 3, Matrial status\npd.crosstab(df['Attrition_Flag'],df['Marital_Status']).plot.bar(stacked=False,figsize=figsize)\nplt.xticks(rotation=None)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- The number of married and single are very similar, same as education level, no obvious relatioship found."},{"metadata":{"trusted":true},"cell_type":"code","source":"#4. Income_Category\npd.crosstab(df['Attrition_Flag'],df['Income_Category']).plot.bar(stacked=False,figsize=figsize)\nplt.xticks(rotation=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#5. Card_Category\nfig, (ax1,ax2) = plt.subplots(1,2,figsize=figsize)\npd.crosstab(df['Attrition_Flag'],df['Card_Category'] ).plot.bar(stacked=False, ax=ax1)\nsns.countplot(df[df.Attrition_Flag == 1]['Card_Category'],ax=ax2)\nax2.set_title('Churned Customer in different card categories')\nplt.xticks(rotation=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Most of the churned customer are in Blue card category. Now we go to explore the numeric features"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df.select_dtypes(exclude=['object']).columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 1. Age\n\"\"\"\nAre churned customers older than the other customer in average?\n\"\"\"\nfig, [[ax1,ax3],[ax2,ax4]] = plt.subplots(2,2,figsize=(13,5))\nsns.boxplot(df.Customer_Age,ax=ax1)\nsns.distplot(df.Customer_Age,ax=ax2)\nsns.boxplot(x=df.Attrition_Flag,y=df.Customer_Age,ax=ax3, width=0.3)\nsns.distplot(df[df.Attrition_Flag==1]['Customer_Age'],ax=ax4)\nsns.distplot(df[df.Attrition_Flag==0]['Customer_Age'],ax=ax4)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 2. Dependent count, Total relationship\n\"\"\"\n1. Are the churned customers have lesser dependents?\n2. Are the churned customers holding lesser product?\n\"\"\"\nfig, (ax1,ax2) = plt.subplots(1,2 ,figsize=(12,3))\npd.crosstab(df.Attrition_Flag,df.Dependent_count).plot.bar(ax=ax1)\npd.crosstab(df.Total_Relationship_Count, df.Attrition_Flag).plot.bar(stacked=True,ax=ax2)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- The ratio of churned customer is a little bit higher in the group with lesser holding products."},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(df.Months_on_book, df.Attrition_Flag).plot.bar(stacked=True,figsize=(15,4))\nplt.xticks(rotation=None)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#3. Months_Inactive_12_mon, Contacts_Count_12_mon\nfig, ([ax1,ax2],[ax3,ax4]) = plt.subplots(2,2 ,figsize=(15,10))\npd.crosstab(df.Months_Inactive_12_mon,df.Attrition_Flag).plot.bar(ax=ax1)\npd.crosstab(df.Contacts_Count_12_mon,df.Attrition_Flag).plot.bar(ax=ax2)\nsns.heatmap(pd.crosstab(df[df.Attrition_Flag==1]['Months_Inactive_12_mon'],df[df.Attrition_Flag==1]['Contacts_Count_12_mon']),fmt='g',cmap='Reds',annot=True,ax=ax3)\nsns.heatmap(pd.crosstab(df[df.Attrition_Flag==0]['Months_Inactive_12_mon'],df[df.Attrition_Flag==0]['Contacts_Count_12_mon']),fmt='g',cmap='Reds',annot=True,ax=ax4)\nax3.set_title('Churned customers')\nax4.set_title('Remained customers')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- From the heatmap, it is found that the churned customer are concentrate in the middle (with medium inactive months and medium number of contacts in last 12 month)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 4. Creadit limit\nfig,(ax1,ax2) = plt.subplots(1,2,figsize=(17,3))\nsns.boxplot(df.Credit_Limit,ax=ax1)\nsns.distplot(df[df.Attrition_Flag==0]['Credit_Limit'])\nsns.distplot(df[df.Attrition_Flag==1]['Credit_Limit'])\nax2.legend(['Remained Customer','Churned Customer'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- No big difference on credit limit between two groups, but there are many outliers in this feature, which might affect the model performance, I will decide whether to filer out some of the data later."},{"metadata":{"trusted":true},"cell_type":"code","source":"# 5. Total_Revolving_Bal\n\nplt.figure(figsize=(12,3))\nsns.distplot(df[df.Attrition_Flag==0]['Total_Revolving_Bal'])\nsns.distplot(df[df.Attrition_Flag==1]['Total_Revolving_Bal'])\nplt.legend(['Remained Customer','Churned Customer'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- The distribution of Churned customer and Remainder customer are quite different, most of the churned card holders are with low revolving balance, while a little of them have a extreme high balance (outliers). It is a question to whether filter it out or not, because they might be meaningful when combining with other features."},{"metadata":{"trusted":true},"cell_type":"code","source":"# 6. Avg_Open_To_Buy\nfig,(ax1,ax2) = plt.subplots(1,2,figsize=(17,3))\nsns.boxplot(df.Credit_Limit,ax=ax1)\nsns.distplot(df[df.Attrition_Flag==0]['Avg_Open_To_Buy'])\nsns.distplot(df[df.Attrition_Flag==1]['Avg_Open_To_Buy'])\nax2.legend(['Remained Customer','Churned Customer'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Similar to credit limit, No big difference between two groups, but many outliers in this feature."},{"metadata":{"trusted":true},"cell_type":"code","source":"# 7.  'Total_Amt_Chng_Q4_Q1', 'Total_Trans_Amt','Total_Trans_Ct', 'Total_Ct_Chng_Q4_Q1'\n\"\"\"\nIt is expected that the number of transaction and amounts of churning customer will be lower than other customers.\n\"\"\"\nfig,([ax1,ax2],[ax3,ax4],[ax5,ax6],[ax7,ax8]) = plt.subplots(4,2,figsize=(20,14))\n\nsns.boxplot(df.Total_Trans_Amt,ax=ax1)\nsns.distplot(df[df.Attrition_Flag==0]['Total_Trans_Amt'],ax=ax2)\nsns.distplot(df[df.Attrition_Flag==1]['Total_Trans_Amt'],ax=ax2)\nax2.legend(['Remained Customer','Churned Customer'])\n\nsns.boxplot(df.Total_Amt_Chng_Q4_Q1,ax=ax3)\nsns.distplot(df[df.Attrition_Flag==0]['Total_Amt_Chng_Q4_Q1'],ax=ax4)\nsns.distplot(df[df.Attrition_Flag==1]['Total_Amt_Chng_Q4_Q1'],ax=ax4)\nax4.legend(['Remained Customer','Churned Customer'])\n\nsns.boxplot(df.Total_Trans_Ct,ax=ax5)\nsns.distplot(df[df.Attrition_Flag==0]['Total_Trans_Ct'],ax=ax6)\nsns.distplot(df[df.Attrition_Flag==1]['Total_Trans_Ct'],ax=ax6)\nax6.legend(['Remained Customer','Churned Customer'])\n\nsns.boxplot(df.Total_Ct_Chng_Q4_Q1,ax=ax7)\nsns.distplot(df[df.Attrition_Flag==0]['Total_Ct_Chng_Q4_Q1'],ax=ax8)\nsns.distplot(df[df.Attrition_Flag==1]['Total_Ct_Chng_Q4_Q1'],ax=ax8)\nax8.legend(['Remained Customer','Churned Customer'])\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- As I expected, both number of transactions and amount of churned customers are lower than others obviously."},{"metadata":{"trusted":true},"cell_type":"code","source":"#8. Avg_Utilization_Ratio\nfig,([ax1,ax2]) = plt.subplots(1,2,figsize=(17,2))\nsns.boxplot(df.Avg_Utilization_Ratio,ax=ax1,width=0.3)\nsns.distplot(df[df.Attrition_Flag==0]['Avg_Utilization_Ratio'],ax=ax2)\nsns.distplot(df[df.Attrition_Flag==1]['Avg_Utilization_Ratio'],ax=ax2)\nax2.legend(['Remained Customer','Churned Customer'])\nax1.set_title('Avg_Utilization_Ratio distribution')\nax2.set_title('Avg_Utilization_Ratio distribution (Chruned vs other)')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data formatting\n- Now it's time to format all the data before fitting the model."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Store the numeric columns into a list\nnumeric_cols = df.select_dtypes(exclude=['object']).columns.tolist()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Label encoding\n- Since I will use tree-based model for training, one-hot encoding is not necessary."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Gender\ndf.Gender = df.Gender.map({'M':1,'F':0})\n# Education_level\ndf.Education_Level = df.Education_Level.map({'Unknown':0,\n                       'Uneducated':1,\n                       'High School':2,\n                       'Graduate':3,\n                       'College':4,\n                       'Post-Graduate':5,\n                       'Doctorate':6})\n# Marital status\ndf.Marital_Status = df.Marital_Status.map({'Unknown':0,\n                      'Single':1,\n                      'Married':2,\n                      'Divorced':3})\n# Income Category\ndf.Income_Category = df.Income_Category.map({'Unknown':0,\n                       'Less than $40K':1,\n                       '$40K - $60K':2,\n                       '$60K - $80K':3,\n                       '$80K - $120K':4,\n                       '$120K +':5})\n# Card category\ndf.Card_Category = df.Card_Category.map({'Blue':0,\n                                        'Silver':1,\n                                        'Gold':2,\n                                        'Platinum':3})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Filter outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show the boxplot of all numeric data\ni = 1\nplt.figure(figsize=(15,25))\nfor col in numeric_cols[1:]: # Skip the first column because it is the label (Attrition_Flag)\n    plt.subplot(7,2,i)\n    sns.boxplot(df[col],width=0.2)\n    i+=1\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fiter out outliers\nfrom scipy.stats import iqr\n\ndef filter_outliers(df,col):\n    copy_df = df.copy()\n    col_iqr = iqr(copy_df[col])\n    upper_limit = copy_df[col].quantile(0.75) + 1.5 * col_iqr\n    lower_limit = copy_df[col].quantile(0.25) - 1.5 * col_iqr\n    #num_rows =  copy_df[(copy_df[col]>upper_limit) | (copy_df[col]<lower_limit)].shape[0]\n    copy_df = copy_df[(copy_df[col]<=upper_limit) & (copy_df[col]>=lower_limit)]\n    return copy_df\n\n# Since I don't want to drop to much data, I just drop the outliers of these three columns after testing.\ndf2 = filter_outliers(df,'Total_Trans_Amt')\ndf2= filter_outliers(df2,'Credit_Limit')\ndf2= filter_outliers(df2,'Avg_Open_To_Buy')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dateset prepration\n- Split the dataframe into x(features) and y(label)\n- Standardize all the features\n- Split into training set and test set, Take 20% data for test set."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\nx , y = df2.drop('Attrition_Flag',axis=1),df2['Attrition_Flag']\nx = StandardScaler().fit_transform(x)\n\nx_train,x_test, y_train,y_test = train_test_split(x,y,test_size=0.2, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Start Training model\n\n- We will train a baseline model without oversampling / undersampling first , then see what can we do to improve the performance"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold,cross_validate\nfrom lightgbm import LGBMClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.pipeline import Pipeline\n\n# Tools for oversampling and undersampling\nfrom imblearn.over_sampling import BorderlineSMOTE\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.pipeline import Pipeline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LGBMClassifier()\nkfold = RepeatedStratifiedKFold(n_splits=10, n_repeats=5, random_state=2)\ncv = cross_validate(model,x_train,y_train,cv=kfold,n_jobs=-1,scoring=['recall','roc_auc'],verbose=1)\nplt.figure(figsize=(13,2))\nplt.subplot(1,2,1)\nsns.boxplot(cv['test_recall'])\nplt.subplot(1,2,2)\nsns.boxplot(cv['test_roc_auc'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- The recall score is not bad, Now lets tune the hyperparameters of the model."},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\n    'n_estimators':[50,100,200,500],\n    'max_depth':[3,6,9],\n    'learning_rate':[0.0001,0.001,0.01,0.1],\n    'boosting_type':['gbdt','goss','dart'],\n    'sub_sample':[0.3,0.5,0.7,1],\n    'colsample_bytree':[0.3,0.5,0.7,1],\n}\nkfold = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=2)\nmodel = LGBMClassifier(random_state=2)\ngrid_model = GridSearchCV(model,params,cv=kfold,n_jobs=-1,verbose=1,scoring='recall')\ngrid_model.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- After two hours.....\n\n### Evaluation on Base model\n- Classification report and confusion matrix would be enough to see the performance"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = grid_model.predict(x_test)\nprint(classification_report(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- The model is doing quite well, both preicision and recall score are very close ~90. "},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(confusion_matrix(y_test,y_pred),cmap='Reds',annot=True,fmt='d')\nplt.xlabel('Prediction')\nplt.ylabel('True')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- The number of false negative and false positive are very close, the balance of the base model is quite well!"},{"metadata":{},"cell_type":"markdown","source":"# Modify data using Oversampling (SMOTE)\n- I will use SMOTE for data oversampling and see whether the model will be improved or not"},{"metadata":{"trusted":true},"cell_type":"code","source":"smote = BorderlineSMOTE()\nx_smote, y_smote = smote.fit_resample(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using the hyperparameters we have trained above\nmodel_smote = LGBMClassifier(boosting_type='goss',\n                       colsample_bytree=0.5,\n                       learning_rate=0.1,\n                       max_depth=6,\n                       n_estimators=200,\n                       sub_sample= 0.3)\nmodel_smote.fit(x_smote, y_smote)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model_smote.predict(x_test)\nprint(classification_report(y_test,y_pred))\nsns.heatmap(confusion_matrix(y_test,y_pred),cmap='Reds',annot=True,fmt='d')\nplt.xlabel('Prediction')\nplt.ylabel('True')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- The recall score is a little bit higher than before while at the same time the precision is down\n- Let see what will happen if I use both oversampling and undersampling to the data."},{"metadata":{},"cell_type":"markdown","source":"# Modify data using Oversampling and Undersampling (SMOTE)"},{"metadata":{"trusted":true},"cell_type":"code","source":"smote = BorderlineSMOTE(sampling_strategy=0.5)\nunder = RandomUnderSampler()\n\npipe = Pipeline(steps=[('smote',smote),\n                      ('under',under)])\nx_smote, y_smote = pipe.fit_resample(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_ou = LGBMClassifier(boosting_type='goss',\n                       colsample_bytree=0.5,\n                       learning_rate=0.1,\n                       max_depth=6,\n                       n_estimators=200,\n                       sub_sample= 0.3)\nmodel_ou.fit(x_smote, y_smote)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model_ou.predict(x_test)\nprint(classification_report(y_test,y_pred))\nsns.heatmap(confusion_matrix(y_test,y_pred),cmap='Reds',annot=True,fmt='d')\nplt.xlabel('Prediction')\nplt.ylabel('True')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- The recall is much more high than before, as a cost, the precision become lower, so it is a trade-off between recall and precision score. "},{"metadata":{},"cell_type":"markdown","source":"# Thank you very much"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}