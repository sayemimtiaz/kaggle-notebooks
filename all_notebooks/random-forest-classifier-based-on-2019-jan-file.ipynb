{"cells":[{"metadata":{},"cell_type":"markdown","source":"**SCOPE**\n\nSince there it is not very clear of what \"predict delays in flights\" means,\nI am assuming here a generic model where I don't know exaclty which flight or company I will take,\nbut I want to know if I have to expect delays due to the time slot in which I decide to flight\n(example: 7 to 8 AM). Of course, departure and arrival airports will be a feature as well.\n\nAlso, I don't care whether I will have delays in departure, but only if I will arrive late.\n\nGiven that, the target of my classifier will be the \"ARR_DEL15\" columns.\n\nMy features will be:\n\nARR_TIME_BLK: the time slot in which the flight will departure (i.e. 0700-0759)\nDAY_OF_WEEK: meant to be \"working day\" or \"weekend\"\nDEP_TIME_BLK:  the time slot in which the flight will arrive (i.e. 0700-0759)\nDEST_AIRPORT_ID\tDISTANCE: the distance between the two airports\nORIGIN_AIRPORT_ID: the origin airport\nDEST_AIRPORT_ID: the destination airport\n\nn.b. I will consider only the Jan 2019 file","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# import stuff\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\nimport math\nimport pandas_datareader.data as web\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler, LabelEncoder\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# read the csv\ndf = pd.read_csv('/kaggle/input/flight-delay-prediction/Jan_2019_ontime.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# original data length = \noriginal_len_dataset = len(df)\noriginal_len_dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# columns with missing values are: 'TAIL_NUM', 'DEP_TIME', 'DEP_DEL15', 'ARR_TIME', 'ARR_DEL15', 'Unnamed: 21'\ndf.columns[df.isna().sum() != 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Are ORIGIN_AIRPORT_ID and ORIGIN_AIRPORT_SEQ_ID  a duplication/different coding of ORIGIN ?\nlen(df[['ORIGIN','ORIGIN_AIRPORT_ID','ORIGIN_AIRPORT_SEQ_ID']].sort_values(by='ORIGIN')) == len(df.ORIGIN)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Are DEST_AIRPORT_ID and DEST_AIRPORT_SEQ_ID are a duplication/different coding of DEST ?\nlen(df[['DEST','DEST_AIRPORT_ID','DEST_AIRPORT_SEQ_ID']].sort_values(by='DEST')) == len(df.DEST)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# it looks like not all the flights without departure or arrival time has been cancelled\nprint (len(df[df.CANCELLED == 1]), len(df[np.isnan(df.DEP_TIME)]) , len(df[np.isnan(df.ARR_TIME)]))\nprint ('percentage of cancelled flights:%.4f' %(len(df[df.CANCELLED == 1])*100/original_len_dataset))\nprint ('percentage of missing departure time: %.4f' %(len(df[np.isnan(df.DEP_TIME)])*100/original_len_dataset))\nprint ('percentage of missing arrival time: %.4f' %(len(df[np.isnan(df.ARR_TIME)])*100/original_len_dataset))\nprint ('percentage of missing arrival time delay: %.4f' %(len(df[np.isnan(df.ARR_DEL15)])*100/original_len_dataset))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# to generalize the data, I made this assumptions\n# want to keep:\n# 'DAY_OF_WEEK' because delay could depend on traffic in specific days: change to weekend, holiday, working_day\n# 'ORIGIN_AIRPORT_ID'  because uniquely identify the origin airport (no need to encode)\n# 'DEST_AIRPORT_ID' because uniquely identify the dest airport (no need to encode)\n# 'DEP_TIME_BLK' it is full hour step\n# 'ARR_TIME' must be generalized with the full hour step\n# 'ARR_DEL15' this is the target value: who cares if the airplane departure is delayed: in real life the arrival time is what really matters\n#\n\n# want to remove:\n# 'DAY_OF_MONTH' since all occurs in the same month\n# 'ORIGIN_AIRPORT_SEQ_ID' \n# 'ORIGIN'\n# 'OP_UNIQUE_CARRIER','OP_CARRIER_AIRLINE_ID', 'OP_CARRIER', 'TAIL_NUM', 'OP_CARRIER_FL_NUM' because are company dependent\n# 'DEP_DEL15' doesn't care: the important is to arrive in time\n# 'DEP_TIME' because we will provide DEP_TIME_BLK :the time block in which the flight departures\n# 'CANCELLED' if it is canceled the target (delay) makes no sense\n# 'DIVERTED' if it is diverted the target (delay) makes no sense","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# start cleanup things:\n\n# since all missing values are at most around 10% and the dataset is quite big, drop flights with missing data\ndf = df[ (df.CANCELLED != 1) & (df.DEP_TIME.isna() == False) & (df.ARR_TIME.isna() == False)]\nlen(df.CANCELLED.isna()), len(df.DEP_TIME.isna()), len(df.ARR_TIME.isna()), len(df)\n\n# drop when target is NAN\ndf = df[ (df.ARR_DEL15.isna() == False)]\n\n# drop 'Unnamed: 21' column since it is just full of NaN (why do I get this column?)\nprint(df['Unnamed: 21'].unique())\ndf.drop(['Unnamed: 21'], inplace=True, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#'DAY_OF_WEEK' because delay could depend on traffic in specific days: classify it to weekend or working day\ndef get_day_category(day_of_week):\n    if day_of_week <= 5:\n        return 0 #'working day'\n    elif day_of_week > 5:\n        return 1 #'weekend'\n    \ndf.DAY_OF_WEEK = df.DAY_OF_WEEK.apply(get_day_category)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# CREATE ARR_TIME_BLK ('ARR_TIME' must be generalized with the full hour step)\n\n#generate block hours\nblocks = []\nfor hour in range(0,24):\n    hour_part = ('%02d' %(hour))\n    blocks.append(hour_part + '00-' + hour_part + '59')\nblocks\n\ndef get_arrival_time_blk(arr_time):\n    arr_hour = str('%04d' %(arr_time))[:2]\n    arr_block = None\n    for block in blocks:\n        #print (block,arr_hour)\n        if block.startswith(arr_hour):\n            arr_block = block\n            break\n    if arr_block == None and str(arr_time) == '2400.0':\n        arr_block = '0000-0059'\n        #print('Cannot find block for #' + str(arr_time) + '#: set block to #' + arr_block + '#')\n    return arr_block\n\ndf['ARR_TIME_BLK'] = df.ARR_TIME.apply(get_arrival_time_blk)\n# drop the no more useful ARR_TIME\ndf.drop(['ARR_TIME'], inplace=True, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#it looks like some target values are set to NaN, so for those we assume that if the airplane departed in late,\n#then it arrived in late (strong assumption)\n\ndef assume_arrival_delay(dep_delay, arr_delay):\n    if np.isnan(arr_delay):\n        return dep_delay\n    else:\n        return arr_delay\n\ndf['ARR_DEL15'] = df.apply(lambda row :assume_arrival_delay(row['DEP_DEL15'],row['ARR_DEL15']), axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop all other feature I said I do not consider meaningful\nfeatures_to_be_dropped = ['DAY_OF_MONTH','ORIGIN_AIRPORT_SEQ_ID','ORIGIN','DEST', 'DEST_AIRPORT_SEQ_ID', 'OP_UNIQUE_CARRIER','OP_CARRIER_AIRLINE_ID', 'OP_CARRIER', 'TAIL_NUM', 'OP_CARRIER_FL_NUM','DEP_DEL15','DEP_TIME','DIVERTED','CANCELLED']\ndf.drop(features_to_be_dropped, inplace=True, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# looks like DEP_TIME_BLK contains an invalid label (got ValueError: y contains previously unseen labels: '0001-0559')\n# there is no reason why this should be treated differently so fix it to 0500-0559\ndf.loc[df['DEP_TIME_BLK'] == '0001-0559', 'DEP_TIME_BLK'] = '0500-0559'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sort out columns\ndf = df.reindex(sorted(df.columns), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# label encode ARR_TIME_BLK and DEP_TIME_BLK\nle = LabelEncoder()\nle.fit(blocks)\nle.classes_\ndf['ARR_TIME_BLK'] = le.transform(df.ARR_TIME_BLK.values)\ndf['DEP_TIME_BLK'] = le.transform(df.DEP_TIME_BLK.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# show the head of the final dataset\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# split in train and test\nY = df['ARR_DEL15'].values\nX = df.drop(['ARR_DEL15'], axis=1).values\n\nX_train, X_test, Y_train, Y_test =  train_test_split(X,Y, test_size=0.3, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc = RandomForestClassifier(n_estimators=20)\nrfc.fit(X_train,Y_train)\n\nY_train_pred = rfc.predict(X_train)\nY_test_pred = rfc.predict(X_test)\n\nprint('ACCURACY train: %.4f, test: %.4f' %(accuracy_score(Y_train,Y_train_pred), accuracy_score(Y_test,Y_test_pred)))\n\n# On my pc I get ACCURACY train: 0.9328, test: 0.8969","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}