{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Import lib"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nimport tensorflow as tf\nfrom tensorflow.compat.v1 import ConfigProto\nfrom tensorflow.compat.v1 import InteractiveSession\n\n\nconfig = ConfigProto()\nconfig.gpu_options.allow_growth = True\nsession = InteractiveSession(config=config)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Check FIle Directory"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"# Loading Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/heartbeat/mitbih_train.csv\", header=None)\ntest_df = pd.read_csv(\"/kaggle/input/heartbeat/mitbih_test.csv\", header=None)\n\nprint(train_df.shape)\nprint(test_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_df[train_df.columns[-1]].unique())\nprint(train_df[test_df.columns[-1]].unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Split data set"},{"metadata":{},"cell_type":"markdown","source":"In our dataset, last column has target index ['N': 0, 'S': 1, 'V': 2, 'F': 3, 'Q': 4]"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x = np.array(train_df[train_df.columns[0:-1]], dtype=np.float32)\ntrain_y = np.array(train_df[train_df.columns[-1:]], dtype=np.float32)\n\ntest_x = np.array(train_df[test_df.columns[0:-1]], dtype=np.float32)\ntest_y = np.array(train_df[test_df.columns[-1:]], dtype=np.float32)\n\nprint(\"print train set is : x = {} y = {}\".format(train_x.shape, train_y.shape))\nprint(\"print test set is : x = {} y = {}\".format(test_x.shape, test_y.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature engineering?"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(20,5))\nax = fig.add_subplot(1,1,1)\nax.plot(train_x[0], color=\"r\")\nax.plot(train_x[1], color=\"g\")\nax.plot(train_x[2], color=\"b\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Our data set looks like signal data(time series)"},{"metadata":{},"cell_type":"markdown","source":"### Calculate difference between t(unit time) with t+1\n\nWe usually analyze signal data using data's amplitude, frequency and shape of signal.\n\nNow, Let's use shape of graph as feature. So I assumed that difference between time interval(t and t+1 (t is unit time)) can be used.\n\n(x(t+1) - x(t)) / unit time -> means  gradient of graph.\n\nHow about we use this with value of specific time point?\n\nBecause graph can be drawed with value and gradient, we can assume that will be fitted to use."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Return difference array\ndef return_diff_array_table(array, dur):\n  for idx in range(array.shape[1]-dur):\n    before_col = array[:,idx]\n    after_col = array[:,idx+dur]\n    new_col = ((after_col - before_col)+1)/2\n    new_col = new_col.reshape(-1,1)\n    if idx == 0:\n      new_table = new_col\n    else :\n      new_table = np.concatenate((new_table, new_col), axis=1)\n#For concat add zero padding\n  padding_array = np.zeros(shape=(array.shape[0],dur))\n  new_table = np.concatenate((padding_array, new_table), axis=1)\n  return new_table\n#Concat\ndef return_merge_diff_table(df, diff_dur):\n  fin_table = df.reshape(-1,187,1,1)\n  for dur in diff_dur:\n    temp_table = return_diff_array_table(df, dur)\n    fin_table = np.concatenate((fin_table, temp_table.reshape(-1,187,1,1)), axis=2)\n  return fin_table\n\n#Use \"stratify\" option\nx_train, x_val, y_train, y_val = train_test_split(train_x, train_y, test_size=0.2, stratify=train_y)\n\n#Add Data\nx_train = return_merge_diff_table(df=x_train, diff_dur=[1])\nx_val = return_merge_diff_table(df=x_val, diff_dur=[1])\n\nprint(x_train.shape, y_train.shape, x_val.shape, y_val.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Make Model 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"#For see a model's result\ndef return_result(model, x_train, x_test, y_train, y_test):\n    y_pred = model.predict(x_test)\n    train_pred = model.predict(x_train)\n    pred_list=[]\n    for x in y_pred:\n        pred_list.append(np.argmax(x))\n    train_pred_list=[]\n    for x in train_pred:\n        train_pred_list.append(np.argmax(x))\n    test_mat = confusion_matrix(y_test, pred_list)\n    train_mat = confusion_matrix(y_train, train_pred_list)\n    print(\"In train\")\n    print(accuracy_score(y_train, train_pred_list))\n    print(train_mat)\n    print(\"In test\")\n    print(accuracy_score(y_test, pred_list))\n    print(test_mat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def return_model1():\n    input_tens = tf.keras.Input(shape=(187,2,1))\n    x = tf.keras.layers.Conv2D(256, kernel_size=(10,2), strides=(5,1),padding='valid')(input_tens)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.ReLU()(x)\n    x = tf.keras.layers.Dropout(rate=0.5)(x)\n    x = tf.keras.layers.Conv2D(512, kernel_size=(5,1), padding='valid')(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.ReLU()(x)\n    x = tf.keras.layers.Dropout(rate=0.5)(x)\n    x = tf.keras.layers.Conv2D(512, kernel_size=(5,1), padding='valid')(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.ReLU()(x)\n    x = tf.keras.layers.Dropout(rate=0.5)(x)\n    x = tf.keras.layers.Conv2D(128, kernel_size=(5,1), padding='valid')(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.ReLU()(x)\n    x = tf.keras.layers.Dropout(rate=0.5)(x)\n    x = tf.keras.layers.Conv2D(64, kernel_size=(5,1), padding='valid')(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.ReLU()(x)\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    x = tf.keras.layers.Dense(5, activation=\"softmax\")(x)\n    model = tf.keras.Model(inputs=input_tens, outputs=x)\n    model.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=[\"accuracy\"])\n    print(model.summary())\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model1 = return_model1()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#For saving best model\ncheckpoint_path_best = \"./best_acc_v01.ckpt\"\ncp_callback_best = tf.keras.callbacks.ModelCheckpoint(checkpoint_path_best,monitor=\"val_accuracy\",save_weights_only=True,verbose=1,save_best_only=True)\n\nmodel1.fit(x_train,y_train, epochs=200, batch_size=128, validation_data=(x_val,y_val),callbacks=[cp_callback_best])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Result is ========","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"return_result(model1, x_train=x_train, x_test=x_val, y_train=y_train, y_test=y_val)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Make Model 2"},{"metadata":{"trusted":true},"cell_type":"code","source":"def return_model2():\n    input_tens = tf.keras.Input(shape=(187,2,1))\n    x = tf.keras.layers.Conv2D(256, kernel_size=(10,2), strides=(5,1),padding='valid')(input_tens)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.ReLU()(x)\n    x = tf.keras.layers.Dropout(rate=0.5)(x)\n    x = tf.keras.layers.Conv2D(512, kernel_size=(5,1), padding='valid')(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.ReLU()(x)\n    x = tf.keras.layers.Dropout(rate=0.5)(x)\n    x = tf.keras.layers.Conv2D(512, kernel_size=(5,1), padding='valid')(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.ReLU()(x)\n    x = tf.keras.layers.Dropout(rate=0.5)(x)\n    x = tf.keras.layers.Reshape((x.shape[1], x.shape[3]))(x)\n    x = tf.keras.layers.LSTM(64)(x)\n    x = tf.keras.layers.Dense(5, activation=\"softmax\")(x)\n    model = tf.keras.Model(inputs=input_tens, outputs=x)\n    model.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=[\"accuracy\"])\n    print(model.summary())\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model2 = return_model2()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#For saving best model\ncheckpoint_path_best2 = \"./best_acc_v02.ckpt\"\ncp_callback_best2 = tf.keras.callbacks.ModelCheckpoint(checkpoint_path_best2, monitor=\"val_accuracy\", save_weights_only=True, verbose=1, save_best_only=True)\n\nmodel2.fit(x_train,y_train, epochs=200, batch_size=128, validation_data=(x_val,y_val), callbacks=[cp_callback_best2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"return_result(model2, x_train=x_train, x_test=x_val, y_train=y_train, y_test=y_val)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Ensemble"},{"metadata":{"trusted":true},"cell_type":"code","source":"model1.load_weights(checkpoint_path_best)\nmodel2.load_weights(checkpoint_path_best2)\n\nreturn_result(model1, x_train=x_train, x_test=x_val, y_train=y_train, y_test=y_val)\nreturn_result(model2, x_train=x_train, x_test=x_val, y_train=y_train, y_test=y_val)\n\ntest_input = np.array(test_df[test_df.columns[0:-1]], dtype=np.float32)\ntest_target = np.array(test_df[test_df.columns[-1:]], dtype=np.float32)\n\ntest_input = return_merge_diff_table(df=test_input, diff_dur=[1])\n\nprint(test_input.shape, test_target.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_1 = model1.predict(test_input)\npred_2 = model2.predict(test_input)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_tot = (pred_1+pred_2)/2\n\npred_idx_list=[]\nfor pred in pred_tot:\n    pred_idx_list.append(np.argmax(pred))\n    \npred_idx_arr = np.array(pred_idx_list, dtype=np.float32)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Printing result"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(accuracy_score(test_target, pred_idx_arr))\nprint(confusion_matrix(test_target, pred_idx_arr))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\n#From https://www.kaggle.com/agungor2/various-confusion-matrix-plots\ndef plot_cm(y_true, y_pred, figsize=(10,10)):\n    cm = confusion_matrix(y_true, y_pred, labels=np.unique(y_true))\n    cm_sum = np.sum(cm, axis=1, keepdims=True)\n    cm_perc = cm / cm_sum.astype(float) * 100\n    annot = np.empty_like(cm).astype(str)\n    nrows, ncols = cm.shape\n    for i in range(nrows):\n        for j in range(ncols):\n            c = cm[i, j]\n            p = cm_perc[i, j]\n            if i == j:\n                s = cm_sum[i]\n                annot[i, j] = '%.1f%%\\n%d/%d' % (p, c, s)\n            elif c == 0:\n                annot[i, j] = ''\n            else:\n                annot[i, j] = '%.1f%%\\n%d' % (p, c)\n    col = ['N','S','V','F','Q']\n    cm = pd.DataFrame(cm, index=col, columns=col)\n    cm.index.name = 'Actual'\n    cm.columns.name = 'Predicted'\n    fig, ax = plt.subplots(figsize=figsize)\n    sns.heatmap(cm, cmap= \"YlGnBu\", annot=annot, fmt='', ax=ax)\n    \nplot_cm(test_target, pred_idx_arr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}