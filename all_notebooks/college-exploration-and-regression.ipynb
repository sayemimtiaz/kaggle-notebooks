{"cells":[{"metadata":{},"cell_type":"markdown","source":"# College Data Exploration and Regression"},{"metadata":{},"cell_type":"markdown","source":"Coded by Luna McBride"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt #Plotting\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split #Split the data into train and test\nfrom sklearn.ensemble import RandomForestRegressor #Forest for regression\nfrom sklearn.metrics import mean_squared_error #Error testing\n\nplt.rcParams['figure.figsize'] = (15,10) #Set the default figure size\nplt.style.use('ggplot') #Set the plotting method\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"college = pd.read_csv(\"../input/us-college-data/College_Data.csv\") #Load the college data into a dataframe\ncollege.head() #Take a peek at the data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"# Fix the Column Names"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Names to rename the columns to\nnewNames = [\"collegeName\", \"isPrivate\", \"numApps\", \"numAccept\", \"numEnroll\", \"top10Stud\", \"top25Stud\", \"fulltime\",\n            \"parttime\", \"outstateCost\", \"roomCost\", \"bookCost\", \"personalCost\", \"teachWithPHD\", \"teachWithTerminal\",\n           \"studFacRatio\", \"alumWhoDonate%\", \"expendPerStud\", \"gradRate\"]\n\noldNames = college.columns #Get the old columns\nnameCombos = dict(zip(oldNames, newNames)) #Combine the old and new into a dictionary\ncollege = college.rename(columns = nameCombos) #Rename the columns\ncollege.head() #Take a peek at the dataset","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"# Check for Null Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(college.isnull().any()) #Check for null values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are no null values."},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"# Create New Fields"},{"metadata":{},"cell_type":"markdown","source":"## Overall Cost"},{"metadata":{"trusted":true},"cell_type":"code","source":"#GetOverallCosts: Calculates the overall costs based on all cost fields in the dataset (out of state only, there is no in state)\n#Input: the college dataframe\n#Output: all overall cost values\ndef getOverallCost(df):\n    overallCost = [] #Create a list to hold the overall costs\n    \n    #For each column, get the college's overall costs\n    for index, row in df.iterrows():\n        #print(row)\n        overallCost.append(row[9] + row[10] \n        + row[11] + row[12]) #Append the sum of all cost fields\n        \n    return overallCost #Return the list of overall costs\n        \ncollege[\"overallCost\"] = getOverallCost(college) #Fill overall costs\ncollege.head() #Take a peek at the dataset","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Acceptance Rate"},{"metadata":{"trusted":true},"cell_type":"code","source":"college[\"acceptRate\"] =  round(college[\"numAccept\"] / college[\"numApps\"], 2) #Get the acceptance rate\ncollege.head() #Take a peek at the dataset","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Set Index as Institutions"},{"metadata":{"trusted":true},"cell_type":"code","source":"college = college.set_index(\"collegeName\") #Set the names to the index\ncollege.head() #Take a peek at the data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"# Data Exploration"},{"metadata":{},"cell_type":"markdown","source":"I am also only limiting the fields to a couple entries, as this is to show how the data is structured. It is hard to see that when all colleges are in the image (just by the sheer number)"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (15,4) #Set the figure size\n\n#For every column in the college dataset, plot a graph with a few entries\nfor column in college:\n    \n    #If the column is one of the numeric columns\n    if column != \"collegeName\" and column != \"isPrivate\":\n        col = college[column][:5] #Get the information for this column for the first few colleges\n        plt.figure() #Pull the figure so they plot on separate graphs\n        col.plot.bar(title = column, rot = 0) #Plot the column\n        \n    #If the column is \"isPrivate\", the boolean column. This one needs to be aggregated with the value_counts function.\n    elif column == \"isPrivate\":\n        col = college[column] #Get the information for this column\n        plt.figure() #Pull the figure so it plots on separate graphs\n        col.value_counts().plot.bar(title = column, rot = 0) #Plot the column, aggregating for the no/yes values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#For each college, print the available ranges for the columns\nfor column in college:\n    \n    #If the column is not \"isPrivate\", since we are looking specifically at the numeric columns\n    if column != \"isPrivate\":\n        col = college[column] #Pull the data for the column\n        maxx = max(col) #Take the max value of the column\n        minn = min(col) #Take the min value of the column\n        print(\"The values for the {} column range from {} to {}\".format(column, minn, maxx)) #Print the ranges","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(college.loc[college[\"gradRate\"] > 100]) #Show where the graduation rate is greater than 100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(college.loc[college[\"acceptRate\"] == 1]) #Print the colleges with 100% acceptance rates","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The number of applicants range from 81 to 48094 for the period presented, meaning there are both large and small colleges within this dataset. The min and max values for the Acceptance and Enrollment columns are both less than the number of applications, which makes sense given that the colleges will not accept everyone. \n\nTop10Stud and Top25Stud, representing students from top high schools, make up a small number of applicants to each college. This means that they are usually applying to colleges besides those in this dataset.  \n\nFulltime and Parttime minimums add up to lower than the lowest total number of applicants, which tells me this is for the college as a whole rather than just incoming students. Both of these values range from small numbers to huge numbers, which tells me that there is dataset holds various colleges that can fit different lifestyles. \n\nThe cost metrics (roomCost, outstateCost, bookCost, and personalCost) here are added together into the overallCost field. There is no in state tuition listed, so the overallCost goes off the assumption that this is the base cost. The dataset does not say whether this cost is yearly or by semester, so I will assume this is a semester tuition by using knowledge of US college prices.\nThese cost columns come together to an overall range of 6604-29095, which is not really all too crazy in the context of US colleges, sadly. These are actually closer to what is considered affordably in this context, which is actually pretty impressive.\n\nTeachers with terminal degrees/PHD's have some pretty strong ranges here, especially when student to faculty ratios are considered. There is no field here for total teacher numbers, so it is hard to compute the percentage of well educated teachers. Terminal degree teachers do not necessarily mean good teachers, but it can be said that these colleges have some knowledgeable teachers with some pretty direct teaching methods.\n\nThe percent of alumni who donate range from 0% to 64%. I should stress is not inherently necessary, as donations are entirely voluntary. Yet, at most 64% of people decided their education was good enough to donate to the college so they can continue to educate. Of course this could be a school culture issue like with places like Harvard, but this is an interesting thing to note nonetheless.\n\nExpenditure per student has a pretty big range here, but this does not necessarily point to good or bad schools. The interesting thing is that this range has both a minimum lower and a maximum higher than the overall cost metric. This means that some schools spend more on their students than what the students are paying, while others are putting less into the students than what they are paying (likely keeping the rest for other projects or profit).\n\nThe graduation rate here is strange, since it ranges from 10 to 118 percent. This is quite odd, since what does a 118% graduation rate mean? Are there more people graduating than are enrolled?\nSome further digging showed that only Cazenovia College had a rate above 100%, meaning this one specifically either had an error or might be incorrectly reporting their rates for some unknown reason.\n\nAcceptance rates range from 15% to 100%. A smaller rate is not necessarily bad, given that schools like Harvard have acceptance rates in the single digits. The 100% acceptance rate is a bit weird, though, meaning they have no true filter on who gets in."},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"# Regression for Acceptance Rate"},{"metadata":{"trusted":true},"cell_type":"code","source":"#GetChara: Get the most important characteristics to the regression\n#Input: the characteristics, the model\n#Output: None\ndef getChara(characteristics, forest):\n    attributes = characteristics.columns #Get the tested attributes\n    attributes = list(zip(attributes, forest.feature_importances_)) #Zip the attributes together with their coefficient\n    sortAtt = sorted(attributes, key = lambda x: x[1], reverse = True) #Sort the zipped attributes by their coefficients\n\n    print(\"According to the Random Forest, the most important factors for acceptance are: \") #Start printing the most important labels\n    i = 0 #Counter variable so only the top five are printed\n\n    #For each attribute in the sorted attributes\n    for label, coef in sortAtt:\n        if i < 5: #If there has not been five printed yet\n            print(label) #Print the label as an important factor\n        i += 1 #Increase i by 1\n\n#AcceptanceRegression: Get an idea of what goes into the acceptance rate\n#Input: The dataframe for the colleges\n#Output: None\ndef acceptanceRegression(college):\n    accept = college[\"acceptRate\"].copy() #Get the acceptance rate for our regression\n\n    characteristics = college.drop(columns = {\"acceptRate\"}).copy() #Get the characteristics used for the regression\n    characteristics = pd.get_dummies(characteristics) #Pad non-numeric characteristics\n    \n    charaTrain, charaTest, accTrain, accTest = train_test_split(characteristics, accept, test_size = 0.1) #Split the dataset\n    \n    forest = RandomForestRegressor(n_estimators = 100) #Build a forest\n    forest.fit(charaTrain, accTrain) #Fit the forest model\n    \n    predict = forest.predict(charaTest) #Get a list of predictions\n    \n    print(\"Forest Accuracy: \", forest.score(charaTest, accTest)) #Print the accuracy\n    print(\"Root Mean Square Error: \", np.sqrt(mean_squared_error(accTest, predict))) #Print the root mean square error\n    \n    getChara(characteristics, forest) #Get the important Characteristics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col = college.drop(columns = {\"numAccept\", \"numEnroll\"}) #Remove the number accepted, since the number accepted of course correlates to the rate\n\n#Run the regression a few times to show variance\nfor i in range(0,5):\n    acceptanceRegression(col) #Perform the regression","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I had this run a few times to show the variety in the models. The best I have been able to get is around a 65% accuracy, which I am going to assume is due to the small number of colleges (relatively speaking) and the amount of factors not in the dataset that could define the acceptance rate (such as staff numbers, budget, and a variety of other factors). The mean square error is very small despite this, so I feel this is the highest possible with the given characteristics. The mean square error represents the distance away from the actual values, so the fact that it is low means the predictions, while not exact, are pretty darn close.\n\nDespite all of this, a few characteristics keep showing up on top. The number of applications, which in itself does not show acceptance, but rather the scale in which people are applying. There is also top10Stud and top25Stud, which says that the locations where higher end students go to have a potential correlation between acceptance rates (likely with lower ones meaning higher end schools). There are others that pop in and out depending on the run, but these seem to be the ones the models are finding consistent."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}