{"cells":[{"metadata":{},"cell_type":"markdown","source":"# **For more details and tutorial on this notebook , feel free to click [here](https://medium.com/@karthikayanmailsamy/action-certainer-using-transfer-learning-in-pytorch-d3fb41a21a09?source=your_stories_page---------------------------).**\n","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"id":"bgAFFbnyg6pB"},"cell_type":"code","source":"#Importing the necessary modulues beforehand is a good practice\nimport os\nimport torch\nimport pandas as pd\nimport numpy as np\nimport math\nfrom torch.utils.data import DataLoader\nfrom PIL import Image\nimport torchvision.models as models\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\nimport torchvision.transforms as T\nimport torch.nn.functional as F\nimport torch.nn as nn\nfrom torchvision.datasets import ImageFolder\nfrom torchvision.utils import make_grid\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"id":"zXUGsihYLjoM","trusted":true},"cell_type":"code","source":"#Classes of the dataset should be defined explicitly\nlabels_str={\n0:\"Hit\",\n1:\"Kick\",\n2:\"Punch\",\n3:\"Push\",\n4:\"ridehorse\",\n5:\"shootgun\",\n6:\"stand\",\n7:\"wave\"}","execution_count":null,"outputs":[]},{"metadata":{"id":"0yw1aTxxg6pU"},"cell_type":"markdown","source":"## Preparing the Data","execution_count":null},{"metadata":{"trusted":true,"id":"AlSmaq2Wg6pb"},"cell_type":"code","source":"DATA_DIR = \"../input/fight-dataset/actions (2)/actions\" #root directory comtaning the dataset.\n\nTRAIN_DIR = DATA_DIR + '/train'                           # Sub-directory containing training images\nTEST_DIR = DATA_DIR + '/test'                             # Sub-directory containing test images","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"1zcSgTg_g6rV"},"cell_type":"code","source":"#Initializing the values needed.\nbatch_size = 64 \nstats = ([0.485, 0.456, 0.406] #mean value of each channel in imagenet dataset.\n         , [0.229, 0.224, 0.225]) #standard deviation value of each channel in imagenet dataset.\nimage_size=224 #size of the image required. ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"fVvIXZx5g6rf"},"cell_type":"code","source":"#ImageFolder is very useful for image datasets as it takes the labels from the folder names and sends the images accordingly to the model.\ntrain_ds = ImageFolder(TRAIN_DIR, transform=T.Compose([\n    T.Resize((image_size,image_size)), #getting all the iamges of unique size as the images in the dataset may be of different sizes.\n    T.ToTensor(), #converts the arrays to tensor.\n    T.Normalize(*stats)])) #Normalizing the data which will be very useful for early convergence during training.\n#val denotes validation set.Here we will use our test data as validation data.\nval_ds = ImageFolder(TEST_DIR, transform=T.Compose([\n    T.Resize((image_size,image_size)),\n    T.ToTensor(),\n    T.Normalize(*stats)])) #'*' will make the tuple values according to arguements.\n\ntrain_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=3, pin_memory=True) #The last two parameters are used to optimize the loading of the data to the gpu.\nval_dl = DataLoader(val_ds, batch_size*2, num_workers=2, pin_memory=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"EU4N8Jd5g6ro"},"cell_type":"code","source":"#The below function is used to renormalize the image for visualization of the dataset.\ndef denorm(img_tensors):\n    return img_tensors * stats[1][0] + stats[0][0] \n#The below 2 functions are used for visualizing the images in grid form.\ndef show_images(images, nmax=64):\n    fig, ax = plt.subplots(figsize=(8, 8))\n    ax.set_xticks([]); ax.set_yticks([])\n    ax.imshow(make_grid(denorm(images.detach()[:nmax]), nrow=8).permute(1, 2, 0))\ndef show_batch(dl, nmax=64):\n    for images, _ in dl:\n        show_images(images, nmax)\n        break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"TBBkEJWjg6rx","outputId":"ad932b80-4073-4597-f308-7d86f6d779ba"},"cell_type":"code","source":"show_batch(train_dl)","execution_count":null,"outputs":[]},{"metadata":{"id":"e63WKtM4g6r6"},"cell_type":"markdown","source":"## Model - Transfer Learning","execution_count":null},{"metadata":{"trusted":true,"id":"3b1NSEn9g6r8"},"cell_type":"code","source":"#FBeta Score is an evaluation metric used for complex datasets which is used to determine the performance of the model.\ndef F_score(output, label, threshold=0.5, beta=1):\n    prob = torch.argmax(torch.exp(output)/sum(torch.exp(output)),axis=-1).view(1,-1) #don't forget about axis and view.\n\n    TP = (prob & label).sum(1).float() #True Positive -> Total number of True predictions that are actually True.\n    TN = ((~prob) & (~label)).sum(1).float() #True Negative -> Total number of False predictions that are actually False.\n    FP = (prob & (~label)).sum(1).float() #False Positive -> Total number of False prdictions that are actually True.\n    FN = ((~prob) & label).sum(1).float() #False Negative -> Total number of True predictions that are actually False\n\n    precision = torch.mean(TP / (TP + FP + 1e-12)) #Predictions that are True among the Total Predicted True values.\n    recall = torch.mean(TP / (TP + FN + 1e-12)) #Predictions that are True among the Total actual True values.\n    F2 = (1 + beta**2) * precision * recall / (beta**2 * precision + recall + 1e-12)\n    return F2.mean(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"SDIH421Gg6sD"},"cell_type":"code","source":"#This class is used for training and validation purposes which i have explained in my previous posts. For clarification you can refer there which I will linking down.\nclass ImageClassificationBase(nn.Module):\n    def training_step(self, batch):\n        images, targets= batch \n        out = self(images)                      \n        loss = F.cross_entropy(out, targets)      \n        return loss\n    \n    def validation_step(self, batch):\n        images, targets = batch \n        out = self(images)                           # Generate predictions\n        loss = F.cross_entropy(out, targets)  # Calculate loss\n        score = F_score(out, targets)\n        return {'val_loss': loss.detach(), 'val_score': score }\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_scores = [x['val_score'] for x in outputs]\n        epoch_score = torch.stack(batch_scores).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_score': epoch_score.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], last_lr: {:.4f}, train_loss: {:.4f}, val_loss: {:.4f}, val_score: {:.4f}\".format(\n            epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_score']))","execution_count":null,"outputs":[]},{"metadata":{"id":"x0jWVGILg6sK"},"cell_type":"markdown","source":"[Learn about ResNets.](https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035)\n\nCheck out torchvision models: https://pytorch.org/docs/stable/torchvision/models.html","execution_count":null},{"metadata":{"trusted":true,"id":"8zE1F1vTg6sL","outputId":"11bcb081-761a-40aa-8908-6d844efd00a1"},"cell_type":"code","source":"#There are more State-of-the-Art pre-trained models which are mostly trained on ImageNet dataset. ResNet is one of them.\nresnet34 = models.resnet34(pretrained=True)\nresnet34","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"8SUM1t5ig6sT"},"cell_type":"code","source":"class ActionResNet(ImageClassificationBase):\n    def __init__(self):\n        super().__init__()\n        # Using a pretrained model\n        self.network = models.resnet34(pretrained=True) #pretrained states that the model is taken with trained weights.\n        # Replace last layer\n        num_ftrs = self.network.fc.in_features\n        self.network.fc = nn.Linear(num_ftrs, 256)\n        #Adding top layers for better performance.\n        self.network1=nn.Linear(256,8)\n        self.networkact=nn.ReLU()\n        self.softmax=nn.Softmax(dim=1)\n    \n    def forward(self, xb):\n        out=self.network(xb)\n        out=self.networkact(out)\n        out=self.network1(out)\n        return self.softmax(out) #for matrices dimension is 1 as we say to model to do softmax to the last dimension(i.e vectors)\n    #the below function will make only the top layers to be available for training i.e the layers we added.\n    def freeze(self):\n        # To freeze the residual layers\n        for param in self.network.parameters():\n            param.require_grad = False\n        for param in self.network.fc.parameters():\n            param.require_grad = True\n    #the below function will make the entire model trainable.\n    def unfreeze(self):\n        # Unfreeze all layers\n        for param in self.network.parameters():\n            param.require_grad = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"49sdPsccg6sb"},"cell_type":"code","source":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"9julc15pg6si","outputId":"e0a212df-781c-459d-cce0-dd58bae57947"},"cell_type":"code","source":"device = get_default_device()\ndevice","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"NRjTXWNig6st"},"cell_type":"code","source":"train_dl = DeviceDataLoader(train_dl, device)\nval_dl = DeviceDataLoader(val_dl, device)","execution_count":null,"outputs":[]},{"metadata":{"id":"D0uNX48Dg6sz"},"cell_type":"markdown","source":"## Training","execution_count":null},{"metadata":{"trusted":true,"id":"tGouB1CTg6s0"},"cell_type":"code","source":"@torch.no_grad() #Not to perform any backprop calculation during this cell is running.\ndef evaluate(model, val_loader):\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n#the below function is used to get the learning_rate from the optimizer.\ndef get_lr(optimizer):\n    for param_group in optimizer.param_groups:\n        return param_group['lr']\n#Fit function for one-cyclical-learningrate-scheduler.\ndef fit_one_cycle(epochs, max_lr, model, train_loader, val_loader, \n                  weight_decay=0.1, grad_clip=True, opt_func=torch.optim.SGD):\n    torch.cuda.empty_cache() #To clear unwanted training data from memory\n    history = []\n    \n    # Set up custom optimizer with weight decay where weight decay is a type of regularization technique which is used to reduce overfitting.\n    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay) \n    # Set up one-cycle learning rate scheduler\n    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, \n                                                steps_per_epoch=len(train_loader))\n    \n    for epoch in range(epochs):\n        # Training Phase \n        model.train()\n        train_losses = []\n        lrs = []\n        for batch in tqdm(train_loader):\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            \n            # Gradient clipping which is used to prevent exploding gradients i.e gradient values which will go very high.\n            #Here gradient values will be cutted off to a value when it goes beyond that value i.e if value>1,then value=1.\n            if grad_clip: \n                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n            \n            optimizer.step()\n            optimizer.zero_grad()\n            \n            # Record & update learning rate\n            lrs.append(get_lr(optimizer))\n            sched.step()\n        \n        # Validation phase\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        result['lrs'] = lrs\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"z7xY5bc_g6s8"},"cell_type":"code","source":"#Fit function for Learning_rate_finder\ndef fit(epochs, start_lr,end_lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    history = []\n    lrs=[]\n    \n    # LR function lambda\n\n    lr_lambda = lambda x: math.exp(x * math.log(end_lr / start_lr) / (epochs * len( train_dl))) \n\n    optimizer = opt_func(model.parameters(), start_lr )\n    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n    for epoch in range(epochs):\n        # Training Phase \n        model.train()\n        train_losses = []\n        for batch in tqdm(train_loader):\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            #Updating gradients\n            optimizer.step()\n            optimizer.zero_grad()\n            scheduler.step()\n        #logging lr at each epoch end.\n        lr_step = optimizer.state_dict()[\"param_groups\"][0][\"lr\"]\n\n        # Validation phase\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        result['lrs'] = [lr_step]\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"bxJ0uymig6tC"},"cell_type":"code","source":"model = to_device(ActionResNet(), device) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"qEccPaBROKoC"},"cell_type":"code","source":"model.unfreeze() #unfreezing to get the optimal learning rate.","execution_count":null,"outputs":[]},{"metadata":{"id":"w69byZu4NwjG","trusted":true},"cell_type":"code","source":"#Initializing the required values for learning_rate_finder.\nepochs = 10\nstart_lr = 1e-7\nend_lr = 0.1\nopt_func = torch.optim.Adam","execution_count":null,"outputs":[]},{"metadata":{"id":"xQROxeWEJXDf","trusted":true},"cell_type":"code","source":"%%time\nhistory = fit(epochs, start_lr,end_lr, model, train_dl, val_dl, \n                         opt_func=opt_func)","execution_count":null,"outputs":[]},{"metadata":{"id":"Z_c-c9uWVTOB","trusted":true,"outputId":"e84faddc-18ab-4ef1-c2de-af1e42c31e00"},"cell_type":"code","source":"#Plotting Learning_rate vs Training_Loss\nimport matplotlib.pyplot as plt\nplt.semilogx([x.get('lrs') for x in history],[x.get('train_loss') for x in history])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"CXLqhztpO1VE"},"cell_type":"code","source":"model = to_device(ActionResNet(), device) #Re-initializing the model to start training.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"HQwJWOD2pMlv"},"cell_type":"code","source":"#If you want load the weights and start testing the model,you can uncomment the below 2 lines and directly go to prediction section\n#model.load_state_dict(torch.load(\"./savemodelweights.pth\"))\n#model.eval()","execution_count":null,"outputs":[]},{"metadata":{"id":"_B8zZvaOpMl1"},"cell_type":"markdown","source":"First, freeze the ResNet layers and train some epochs. This only trains the final layer to start classifying the images.","execution_count":null},{"metadata":{"trusted":true,"id":"-zCNnjflg6tR"},"cell_type":"code","source":"model.freeze()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"_qRhoS3Eg6tX"},"cell_type":"code","source":"#Initializing the required values.\nepochs = 8\nmax_lr = 8e-5\ngrad_clip = 0.1\nweight_decay = 1e-4\nopt_func = torch.optim.Adam","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"UBhYcQJLg6td"},"cell_type":"code","source":"%%time \nhistory = fit_one_cycle(epochs, max_lr, model, train_dl, val_dl, \n                         grad_clip=grad_clip, \n                         weight_decay=weight_decay, \n                         opt_func=opt_func)","execution_count":null,"outputs":[]},{"metadata":{"id":"1smkPP9Qg6tr"},"cell_type":"markdown","source":"Now, unfreeze and train some more.","execution_count":null},{"metadata":{"trusted":true,"id":"yJGxUpSIg6ts"},"cell_type":"code","source":"model.unfreeze()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"QuDHwE5tg6tx"},"cell_type":"code","source":"%%time \nhistory += fit_one_cycle(epochs, 1e-4 , model, train_dl, val_dl, \n                         grad_clip=grad_clip, \n                         weight_decay=weight_decay, \n                         opt_func=opt_func )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"bNB0XI5Mg6uL"},"cell_type":"code","source":"#use the below line for saving the weights to a directory in pth format which you can use for next training i.e when you start again from the same spot you left training.\ntorch.save(model.state_dict(), \"savemodelweights.pth\")","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true,"id":"j59-QAvDpMma","outputId":"48ce0bb6-d33e-4158-ca6c-17ebe7ce7eac"},"cell_type":"code","source":"#Now let's evaluate the model to get final results on the performance.\nprint([evaluate(model, val_dl)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"tip1mP4Cg6uT"},"cell_type":"code","source":"#Let's now plot the validation F-beta scores.\ndef plot_scores(history):\n    scores = [x['val_score'] for x in history]\n    plt.plot(scores, '-x')\n    plt.xlabel('epoch')\n    plt.ylabel('score')\n    plt.title('F1 score vs. No. of epochs');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"YJcS5gEXg6uZ","outputId":"7308bc39-59ea-4449-fa7d-e03498a2b2e9"},"cell_type":"code","source":"plot_scores(history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"SWfpQIvag6ug"},"cell_type":"code","source":"#Here we plot train_loss and val_loss to check for overfitting.\ndef plot_losses(history):\n    train_losses = [x.get('train_loss') for x in history]\n    val_losses = [x['val_loss'] for x in history]\n    plt.plot(train_losses, '-bx')\n    plt.plot(val_losses, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend(['Training', 'Validation'])\n    plt.title('Loss vs. No. of epochs');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"lmig8Ya4g6uk","outputId":"64ee1fa6-d821-4afe-d995-4143111764ad"},"cell_type":"code","source":"plot_losses(history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"aE1Z1L0ng6up"},"cell_type":"code","source":"#This graph shows how learning rate values went through the training.\ndef plot_lrs(history):\n    lrs = np.concatenate([x.get('lrs', []) for x in history])\n    plt.plot(lrs)\n    plt.xlabel('Batch no.')\n    plt.ylabel('Learning rate')\n    plt.title('Learning Rate vs. Batch no.');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"IPHxaPneg6uu","outputId":"156e28bb-3629-48d2-dd81-0fe265d85ebc"},"cell_type":"code","source":"plot_lrs(history)","execution_count":null,"outputs":[]},{"metadata":{"id":"lvyPKOoeg6uz"},"cell_type":"markdown","source":"## Making predictions and submission","execution_count":null},{"metadata":{"trusted":true,"id":"t95zHWoDg6u3"},"cell_type":"code","source":"def predict_single(image,label):\n    xb = image.unsqueeze(0)\n    xb = to_device(xb, device)  #to load the image to the gpu memory.\n    preds = model(xb)\n    prediction = preds[0]\n    print(\"Actual Label: \",labels_str[label])\n    print(\"Prediction: \", labels_str[torch.argmax(prediction).tolist()]) #The predicted class is extracted from the predicted values.\n    show_images(image)","execution_count":null,"outputs":[]},{"metadata":{"id":"7fFs-QKbpMnD"},"cell_type":"markdown","source":"**Let us now predict using the model to see the performance.**","execution_count":null},{"metadata":{"trusted":true,"id":"OYVWMPrLpMnE","outputId":"9eaa1573-ed68-4fd3-c49a-069b1a3b500a"},"cell_type":"code","source":"predict_single(*val_ds[300])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"tigGY_QSg6vI","outputId":"35b3ae42-9e81-4aa4-9a04-fcbba04ae866"},"cell_type":"code","source":"predict_single(*val_ds[800])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"1HHBAZAHg6vP","outputId":"e7abd185-c802-418f-91bf-dc5b985f347d"},"cell_type":"code","source":"predict_single(*val_ds[1000])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"I8KGQU_YpMnU","outputId":"10fa74af-f809-4ec1-fef6-f7d41bf94d53"},"cell_type":"code","source":"predict_single(*val_ds[1250])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"UKmmAJxJpMna","outputId":"16bc3e75-3e64-4997-b64b-8c801d780a93"},"cell_type":"code","source":"predict_single(*val_ds[2000])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"CczCfmc_pMnf","outputId":"0b06caf0-1d90-4b6d-e587-f737fe740e5c"},"cell_type":"code","source":"predict_single(*val_ds[4000])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"iR9wF5jxpMnk","outputId":"ae5cfaf9-68e8-45d5-d6cd-aa1474181a9a"},"cell_type":"code","source":"predict_single(*val_ds[4500])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"Gr2_agwqpMnr","outputId":"462c6a6c-32f7-4f0c-e502-6677bff2a1fb"},"cell_type":"code","source":"predict_single(*val_ds[6200])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}