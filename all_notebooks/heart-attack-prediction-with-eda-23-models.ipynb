{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":" <div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:LightSlateGray;\n           font-size:150%;\n           text-align:center;\n           letter-spacing:0.5px\">\n    \n     Welcome\n</div>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:black;\n           display:fill;\n           border-radius:5px;\n           background-color:Beige;\n           font-size:110%;\n           letter-spacing:0.5px\">\n\n<p style=\"padding: 10px;\n              color:black;\">\n    \nHello Kagglers, <br>\n\nIn this notebook, I am going to predict the chance of a person suffering from a heart attack. But, first I am going to do deal with missing values in the dataset and then perform exploratory data analysis and learn more about the features. Then, I am going to use different classification models on our dataset and select the best performing one. <br>\n    So, let's get started.\n</p>\n</div> ","metadata":{}},{"cell_type":"markdown","source":" <div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:LightSlateGray;\n           font-size:150%;\n           text-align:center;\n           letter-spacing:0.5px\">\n    \n     Table of Contents\n</div>","metadata":{}},{"cell_type":"markdown","source":"1. [Importing Libraries](#1)<a href='1' ></a> <br>\n2. [Importing Dataset](#2)<a href='2' ></a> <br>\n3. [Exploratory Data Analysis](#3)<a href='3' ></a> <br>\n    3.1. [Heat Map Correlation](#3.1)<a href='3.1' ></a> <br>\n    3.2. [Pie Chart](#3.2)<a href='3.2' ></a> <br>\n    3.3. [Count Plot](#3.3)<a href='3.3' ></a> <br>\n    3.4. [Distribution Plot](#3.4)<a href='3.4' ></a> <br>\n    3.5. [Scatter Plot](#3.5)<a href='3.5' ></a> <br>\n    3.6. [Outliers](#3.6)<a href='3.6' ></a> <br>\n    &nbsp;&nbsp;&nbsp;&nbsp; a. [Detection](#3.6.1)<a href='3.6.1' ></a> <br>\n    &nbsp;&nbsp;&nbsp;&nbsp; b. [Removal](#3.6.2)<a href='3.6.2' ></a> <br>\n    3.7. [Pair Plot](#3.7)<a href='3.7' ></a> <br>\n4. [Data Preprocessing](#4)<a href='4' ></a> <br>\n5. [Models](#5)<a href='5' ></a> <br>\n    5.1. [Logistic Regression](#5.1)<a href='5.1' ></a> <br>\n    5.2. [Passive Aggressive Classifier](#5.2)<a href='5.2' ></a> <br>\n    5.3. [Ridge Classifier](#5.3)<a href='5.3' ></a> <br>\n    5.4. [K-Nearest Neighbors](#5.4)<a href='5.4' ></a> <br>\n    5.5. [Radius Neighbors Classifier](#5.5)<a href='5.5' ></a> <br>\n    5.6. [GaussianNB](#5.6)<a href='5.6' ></a> <br>\n    5.7. [BernoulliNB](#5.7)<a href='5.7' ></a> <br>\n    5.8. [SVM](#5.8)<a href='5.8' ></a> <br>\n    5.9. [Nu-SVC](#5.9)<a href='5.9' ></a> <br>\n    5.10. [Linear SVC](#5.10)<a href='5.10' ></a> <br>\n    5.11. [Decision Tree](#5.11)<a href='5.11' ></a> <br>\n    5.12. [Random Forest](#5.12)<a href='5.12' ></a> <br>\n    5.13. [Extra Trees](#5.13)<a href='5.13' ></a> <br>\n    5.14. [AdaBoost](#5.14)<a href='5.14' ></a> <br>\n    5.15. [Gradient Boosting](#5.15)<a href='5.15' ></a> <br>\n    5.16. [Bagging Classifier](#5.16)<a href='5.16' ></a> <br>\n    5.17. [XGBoost](#5.17)<a href='5.17' ></a> <br>\n    5.18. [LightGBM](#5.18)<a href='5.18' ></a> <br>\n    5.19. [Linear Discriminant Analysis](#5.19)<a href='5.19' ></a> <br>\n    5.20. [Quadratic Discriminant Analysis](#5.20)<a href='5.20' ></a> <br>\n    5.21. [MLPClassifier](#5.21)<a href='5.21' ></a> <br>\n    5.22. [H2O AutoML](#5.22)<a href='5.22' ></a> <br>\n    5.23. [TPOT](#5.23)<a href='5.23' ></a> <br>\n6. [Conclusion](#6)<a href='6' ></a> <br>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:LightSlateGray;\n           font-size:150%;\n           text-align:center;\n            letter-spacing:0.5px\"> <a id='1'></a>\n    \n    Importing Libraries \n</div>","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.linear_model import LogisticRegression, PassiveAggressiveClassifier, RidgeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier, RadiusNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.svm import SVC, NuSVC, LinearSVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier, BaggingClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\nfrom sklearn.neural_network import MLPClassifier\n\nfrom sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, ConfusionMatrixDisplay, precision_score, classification_report, roc_curve, plot_roc_curve, auc, precision_recall_curve, plot_precision_recall_curve, average_precision_score\nfrom sklearn.model_selection import cross_val_score\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:LightSlateGray;\n           font-size:150%;\n           text-align:center;\n           letter-spacing:0.5px\"> <a id = '2'></a>\n    \n    Importing Dataset \n</div>","metadata":{}},{"cell_type":"code","source":"dataset = pd.read_csv('/kaggle/input/heart-attack-analysis-prediction-dataset/heart.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"üìå We have 303 rows and 14 columns in our dataset. <br>\nüìå We can see that the dataset contains *numerical* variables. <br>","metadata":{}},{"cell_type":"code","source":"dataset.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"üìå There are no missing values present in our dataset.","metadata":{}},{"cell_type":"code","source":"dataset.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"üìå The above command df.describe() helps us to view the statistical properties of numerical variables. It excludes character variables.","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:LightSlateGray;\n           font-size:150%;\n           text-align:center;\n            letter-spacing:0.5px\"> <a id='3'></a>\n    \n    Exploratory Data Analysis\n</div>","metadata":{}},{"cell_type":"code","source":"# Renaming columns.\ndataset.columns = ['Age', 'Sex', 'Chest Pain Type', 'Resting Blood Pressure', 'Cholesterol', 'Fasting Blood Sugar', 'Resting ECG', 'Max. Heart Rate',\n       'Exercise Induced Angina', 'Previous Peak', 'Slope', 'No. Major Blood Vessels', 'Thal Rate', 'Condition']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"numerical = ['Age','Resting Blood Pressure','Cholesterol','Max. Heart Rate','Previous Peak']\ncategorical= ['Sex','Chest Pain Type','Fasting Blood Sugar','Resting ECG','Exercise Induced Angina','Slope','No. Major Blood Vessels','Thal Rate']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Heat Map Correlation** <a id='3.1' ></a>","metadata":{}},{"cell_type":"code","source":"# Compute the correlation matrix\ncorr = dataset.corr()\n\n# Generate a mask for the upper triangle\nmask = np.triu(np.ones_like(corr, dtype=bool))\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(8, 8))\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(230, 20, as_cmap=True)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0, square=True, linewidths=.5, cbar_kws={\"shrink\": .5})","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(14,12))\nax = sns.heatmap(corr, square=True, annot=True, fmt='.2f')\nax.set_xticklabels(ax.get_xticklabels(), rotation=90)          \nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"üìå From the above correlation matrix, we can see that the correlation between features is less. <br>\nüìå *Chest Pain Type* with *Condition* and *Max. Heart Rate* with *Condition* have high correlated features in our dataset; Correlation Coefficient of 0.43 and 0.42 respectively. <br>\nüìå Our features have a lot of negative correlation coefficient indicating that two individual variables have a statistical relationship such that generally move in opposite directions from one another.","metadata":{}},{"cell_type":"markdown","source":"## **Pie Chart** <a id='3.2' ></a>","metadata":{}},{"cell_type":"code","source":"labels = ['More Chance of Heart Attack', 'Less Chance of Heart Attack']\nsizes = dataset['Condition'].value_counts(sort = True)\n\ncolors = [\"#ffb3b3\",\"#C2C4E2\"]\nexplode = (0.05,0) \n \nplt.figure(figsize=(7,7))\nplt.suptitle(\"Number of Targets in the dataset\",y=0.9, family='Sherif', size=18, weight='bold')\nplt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%', shadow=True, startangle=90,)\n\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"üìå From the above pie chart, we can see that we have relatively more people who have more chances of having a Heart Attack. <br>\nüìå We can also see that the our dataset is balanced.","metadata":{}},{"cell_type":"markdown","source":"## **Count Plot** <a id='3.3' ></a>","metadata":{}},{"cell_type":"code","source":"# Count Plot of Categorical Data w/o Condition\ncolors = [\"#D0DBEE\", \"#C2C4E2\", \"#EED4E5\", \"#D1E6DC\", \"#BDE2E2\"]\nj=0\nfig=plt.figure(figsize=(10,10),constrained_layout =True)\nplt.suptitle(\"Count of the Categorical Variables\",y=1.07, family='Sherif', size=18, weight='bold')\nfig.text(0.31,1.02,\"Categorical Data without Condition\", size=13, fontweight='light', fontfamily='monospace')\nfor i in dataset[categorical]:\n    ax=plt.subplot(241+j)\n    ax.set_aspect('auto')\n    ax.grid(color='gray', linestyle=':', axis='y', zorder=0, dashes=(1,5))\n    ax=sns.countplot(data=dataset, x=i, palette=colors, alpha=1)\n    for s in ['left','right','top','bottom']:\n        ax.spines[s].set_visible(False)\n    j=j+1","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"üìå From the above plots, we can see that we have different features which have a common and uncommon type of categories in our dataset. <br>\nüìå But, It is not enough to tell us about the features. Let's compare all the categorical features with the target column of *Condition*.","metadata":{}},{"cell_type":"code","source":"# Count Plot of Categorical Data with Condition\ncolors = ['#ccccff','#ffcccc']\nj=0\nfig=plt.figure(figsize=(10,10),constrained_layout =True)\nplt.suptitle(\"Count of the Categorical Variables\",y=1.07, family='Sherif', size=18, weight='bold')\nfig.text(0.33,1.02,\"Categorical Data with Condition\", size=13, fontweight='light', fontfamily='monospace')\nfor i in dataset[categorical]:\n    ax=plt.subplot(241+j)\n    ax.set_aspect('auto')\n    ax.grid(color='gray', linestyle=':', axis='y', zorder=0,  dashes=(1,5))\n    ax=sns.countplot(data=dataset, x=i, hue='Condition', palette=colors, alpha=1)\n    for s in ['left','right','top','bottom']:\n        ax.spines[s].set_visible(False)\n    j=j+1","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From above categorical plots we can see that: <br>\nüìå In *Chest Pain*, Type 0 has the highest number of people who have less chance of suffering from a heart attack. <br>\nüìå *Fasting Blood Sugar* and *Resting ECG* doesn't have much difference in their respective conditions. <br>\nüìå In *Exercise-Induced Angina*, Type 0 has the highest number of people who are likely to suffer a heart attack. <br>\nüìå *Slope* has Type 2, *No. of Major Blood Vessels* has Type 0 and *Thal Rate* has Type 2 which shows people who are likely to suffer from a heart attack.","metadata":{}},{"cell_type":"markdown","source":"## **Distribution Plot** <a id='3.4' ></a>","metadata":{}},{"cell_type":"code","source":"# Distribution Plot of Numerical Data w/o Condition\nj=0\nfig=plt.figure(figsize=(10,10),constrained_layout =True)\nplt.suptitle(\"Distribution of the Numeric Variables\",y=1.07, family='Sherif', size=18, weight='bold')\nfig.text(0.315,1.02,\"Numerical Data without Condition\", size=13, fontweight='light', fontfamily='monospace')\nfor i in dataset[numerical]:\n    ax=plt.subplot(321+j)\n    ax.set_aspect('auto')\n    ax.grid(color='gray', linestyle=':', axis='x', zorder=0,  dashes=(1,5))\n    ax=sns.kdeplot(data=dataset, x=i, color='#D0DBEE', fill=True, edgecolor='black', alpha=1)\n    for s in ['left','right','top','bottom']:\n        ax.spines[s].set_visible(False)\n    j=j+1","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"üìå From the above plots, we can see that the distribution density of different features them being skew. Let's also compare them with the target column of *Condition* to see how to perform.","metadata":{}},{"cell_type":"code","source":"# Distribution Plot of Numerical Data with Condition\ncolors = ['#D0DBEE','#ffcccc']\nj=0\nfig=plt.figure(figsize=(10,10),constrained_layout =True)\nplt.suptitle(\"Distribution of the Numeric Variables\",y=1.07, family='Sherif', size=18, weight='bold')\nfig.text(0.333,1.02,\"Numerical Data with Condition\", size=13, fontweight='light', fontfamily='monospace')\nfor i in dataset[numerical]:\n    ax=plt.subplot(321+j)\n    ax.set_aspect('auto')\n    ax.grid(color='gray', linestyle=':', axis='x', zorder=0,  dashes=(1,5))\n    ax=sns.kdeplot(data=dataset, x=i, hue='Condition', palette=colors, fill=True, edgecolor='black', alpha=1)\n    for s in ['left','right','top','bottom']:\n        ax.spines[s].set_visible(False)\n    j=j+1","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"üìå From the above distribution plot, we can see that, *Age* and *Max. Heart Rate* is Negative Skewed and *Resting Blood Pressure*, *Cholesterol*, and *Previous Peak* are Positive Skewed.","metadata":{}},{"cell_type":"markdown","source":"## **Scatter Plot** <a id='3.5' ></a>","metadata":{}},{"cell_type":"code","source":"# Scatter Plot of Numerical Data with Condition\ncolors = ['#D0DBEE','#ff3333']\nnum_cols = ['Resting Blood Pressure','Cholesterol','Max. Heart Rate','Previous Peak']\nj=0\nfig=plt.figure(figsize=(10,10),constrained_layout =True)\nplt.suptitle(\"Scatter Plot of the Numeric Variables\",y=1.07, family='Sherif', size=18, weight='bold')\nfig.text(0.333,1.02,\"Numerical Data with Condition\", size=13, fontweight='light', fontfamily='monospace')\nfor i in dataset[num_cols]:\n    ax=plt.subplot(321+j)\n    ax.set_aspect('auto')\n    ax.grid(color='gray', linestyle=':', axis='x', zorder=0,  dashes=(1,5))\n    ax=sns.scatterplot(data=dataset,x=dataset['Age'],y=i,hue=dataset['Condition'],ec='black',palette=colors)\n    for s in ['left','right','top','bottom']:\n        ax.spines[s].set_visible(False)\n    j=j+1","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"üìå From the above plot, we can see that the relationship between *Age* and different numerical features in our dataset with *Condition*. We can also few Outliers in our plot.","metadata":{}},{"cell_type":"markdown","source":"## **Outliers** <a id='3.6' ></a>","metadata":{}},{"cell_type":"markdown","source":"üìå An outlier is an observation that lies an abnormal distance from other values in a random sample from a population.","metadata":{}},{"cell_type":"markdown","source":"### Detection <a id='3.6.1' ></a>","metadata":{}},{"cell_type":"markdown","source":"üìå In this notebook, we are using Boxen Plot to detect the outliers of each features in our dataset, where any point above or below the whiskers represent an outlier. This is also known as ‚ÄúUnivariate method‚Äù as here we are using one variable outlier analysis.","metadata":{}},{"cell_type":"code","source":"# Outliers Detection\ncolors = ['#CBE4F9','#CDF5F6','#EFF9DA','#F9EBDF','#F9D8D6']\nplt.figure(figsize=(9,9))\nplt.suptitle(\"Outliers of Numeric Variables\",y=0.94, family='Sherif', size=18, weight='bold')\nplt.text(-0.4, 1.64, 'Detecting Outliers in Numerical Columns', horizontalalignment='center',verticalalignment='center', transform=ax.transAxes,size=14,fontweight='light', fontfamily='monospace')\nsns.boxenplot(data = dataset[numerical],palette = colors)\nplt.grid(color='gray', linestyle=':', axis='y', zorder=0,  dashes=(1,5))\nplt.xticks(rotation=45)\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Removal <a id='3.6.2' ></a>","metadata":{}},{"cell_type":"markdown","source":"üìå After detecting, we are using Median Imputation to take care of outliers. In this technique, we replace the extreme values with median values. <br>\nüìå It is represented by the formula IQR = Q3 ‚àí Q1. The lines of code below calculate and print the interquartile range for each of the variables in the dataset. <br>\nüìå It is advised to not use mean values as they are affected by outliers.","metadata":{}},{"cell_type":"code","source":"# Removing Outliers\nfor i in dataset[numerical]:\n    q1 = dataset[i].quantile(0.25)\n    q3 = dataset[i].quantile(0.75)\n    iqr = q3-q1\n    Lower_tail = q1 - 1.5 * iqr\n    Upper_tail = q3 + 1.5 * iqr\n    med = np.median(dataset[i])\n    for j in dataset[i]:\n        if j > Upper_tail or j < Lower_tail:\n            dataset[i] = dataset[i].replace(j, med)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"colors = ['#CBE4F9','#CDF5F6','#EFF9DA','#F9EBDF','#F9D8D6']\nplt.figure(figsize=(9,9))\nplt.suptitle(\"Outliers of Numeric Variables\",y=0.94, family='Sherif', size=18, weight='bold')\nplt.text(-0.405, 1.64, 'Removing Outliers in Numerical Columns', horizontalalignment='center',verticalalignment='center', transform=ax.transAxes,size=14,fontweight='light', fontfamily='monospace')\nsns.boxenplot(data = dataset[numerical],palette = colors)\nplt.grid(color='gray', linestyle=':', axis='y', zorder=0,  dashes=(1,5))\nplt.xticks(rotation=45)\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Pair Plot** <a id='3.7' ></a>","metadata":{}},{"cell_type":"code","source":"colors = ['#80d4ff','#ff3333']\nsns.pairplot(data=dataset,hue='Condition',diag_kind='kde',palette=colors)\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"üìå The above graphs produce a matrix of relationships between each variable in your data for an instant examination of our data. We can see that the outliers in our dataset have been taken care of.","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:LightSlateGray;\n           font-size:150%;\n           text-align:center;\n            letter-spacing:0.5px\"> <a id='4'></a>\n    \n    Data Preprocessing\n</div>","metadata":{}},{"cell_type":"code","source":"x = dataset.iloc[:, :-1].values\ny = dataset.iloc[:, -1].values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Splitting Data into Train and Test Set\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size= 0.2, random_state= 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Number transactions x_train dataset: \", x_train.shape)\nprint(\"Number transactions y_train dataset: \", y_train.shape)\nprint(\"Number transactions x_test dataset: \", x_test.shape)\nprint(\"Number transactions y_test dataset: \", y_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Feature Scaling with StandardScaler\nfrom sklearn.preprocessing import StandardScaler \nsc = StandardScaler()\nx_train = sc.fit_transform(x_train)\nx_test = sc.transform(x_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:LightSlateGray;\n           font-size:150%;\n           text-align:center;\n            letter-spacing:0.5px\"> <a id='5'></a>\n    \n    Models\n</div>","metadata":{}},{"cell_type":"markdown","source":"üìå **True Positives (TP)** - These are the correctly predicted positive values which means that the value of actual class is yes and the value of predicted class is also yes. <br>\nüìå **True Negatives (TN)** - These are the correctly predicted negative values which means that the value of actual class is no and value of predicted class is also no. <br>\nüìå **False Positives (FP)** ‚Äì When actual class is no and predicted class is yes. <br>\nüìå **False Negatives (FN)** ‚Äì When actual class is yes but predicted class in no. <br>\nüìå **Accuracy** - Accuracy is the most intuitive performance measure and it is simply a ratio of correctly predicted observation to the total observations. `Accuracy = TP+TN/TP+FP+FN+TN` <br>\nüìå **Precision** - Precision is the ratio of correctly predicted positive observations to the total predicted positive observations. `Precision = TP/TP+FP` <br>\nüìå **Recall (Sensitivity)** - Recall is the ratio of correctly predicted positive observations to the all observations in actual class - yes. `Recall = TP/TP+FN` <br>\nüìå **F1 score** - F1 Score is the weighted average of Precision and Recall. Therefore, this score takes both false positives and false negatives into account.  `F1 Score = 2(Recall Precision) / (Recall + Precision)` <br>\nüìå **Support** - Support is the number of actual occurrences of the class in the specified dataset. Support doesn‚Äôt change between models but instead diagnoses the evaluation process.","metadata":{}},{"cell_type":"markdown","source":"## **Logistic Regression** <a id='5.1' ></a>","metadata":{}},{"cell_type":"markdown","source":"üìå *Logistic Regression assumes a Gaussian distribution for the numeric input variables and can model binary classification problems. You can construct a logistic regression model using the LogisticRegression class.*","metadata":{}},{"cell_type":"code","source":"#Fitting Logistic Regression Model\nclassifier = LogisticRegression(random_state= 0)\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ny_prob = classifier.predict_proba(x_test)[:,1]\ncm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {roc_auc_score(y_test, y_prob)}')\nprint('Accuracy Score: ',accuracy_score(y_test, y_pred))\n\n# Visualizing Confusion Matrix\nplt.figure(figsize = (6, 6))\nsns.heatmap(cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15})\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc AUC Curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nplt.figure(figsize = (6, 6))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC AUC Curve')\nplt.legend()\nplt.show()\n\n#Precision Recall Curve\nplt.figure(figsize = (6, 6))\naverage_precision = average_precision_score(y_test, y_prob)\ndisp = plot_precision_recall_curve(classifier, x_test, y_test)\nplt.title('Precision-Recall Curve')\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Passive Aggressive Classifier** <a id='5.2' ></a>","metadata":{}},{"cell_type":"markdown","source":"üìå *Like MultinomialNB, this classifier is suitable for discrete data. The difference is that while MultinomialNB works with occurrence counts, BernoulliNB is designed for binary/boolean features. The Passive-Aggressive algorithms are a family of Machine learning algorithms that are not very well known by beginners and even intermediate Machine Learning enthusiasts. However, they can be very useful and efficient for certain applications.*","metadata":{}},{"cell_type":"code","source":"#Fitting PassiveAggressiveClassifier Model\nclassifier = PassiveAggressiveClassifier()\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ny_prob = classifier._predict_proba_lr(x_test)[:,1]\ncm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {roc_auc_score(y_test, y_prob)}')\nprint('Accuracy Score: ',accuracy_score(y_test, y_pred))\n\n# Visualizing Confusion Matrix\nplt.figure(figsize = (6, 6))\nsns.heatmap(cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15})\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc AUC Curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nplt.figure(figsize = (6, 6))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC AUC Curve')\nplt.legend()\nplt.show()\n\n#Precision Recall Curve\naverage_precision = average_precision_score(y_test, y_prob)\ndisp = plot_precision_recall_curve(classifier, x_test, y_test)\nplt.title('Precision-Recall Curve')\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Ridge Classifier** <a id='5.3' ></a>","metadata":{}},{"cell_type":"markdown","source":"üìå *Classifier using Ridge regression. This classifier first converts the target values into {-1, 1} and then treats the problem as a regression task (multi-output regression in the multiclass case).*","metadata":{}},{"cell_type":"code","source":"#Fitting RidgeClassifier Model\nclassifier = RidgeClassifier()\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ny_prob = classifier._predict_proba_lr(x_test)[:,1]\ncm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {roc_auc_score(y_test, y_prob)}')\nprint('Accuracy Score: ',accuracy_score(y_test, y_pred))\n\n# Visualizing Confusion Matrix\nplt.figure(figsize = (6, 6))\nsns.heatmap(cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15})\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc AUC Curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nplt.figure(figsize = (6, 6))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC AUC Curve')\nplt.legend()\nplt.show()\n\n#Precision Recall Curve\naverage_precision = average_precision_score(y_test, y_prob)\ndisp = plot_precision_recall_curve(classifier, x_test, y_test)\nplt.title('Precision-Recall Curve')\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **K-Nearest Neighbors** <a id='5.4' ></a>","metadata":{}},{"cell_type":"markdown","source":"üìå *The k-nearest neighbors (KNN) algorithm is a simple, easy-to-implement supervised machine learning algorithm that can be used to solve both classification and regression problems*","metadata":{}},{"cell_type":"code","source":"#Fitting KNeighborsClassifier Model\nclassifier = KNeighborsClassifier()\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ny_prob = classifier.predict_proba(x_test)[:,1]\ncm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {roc_auc_score(y_test, y_prob)}')\nprint('Accuracy Score: ',accuracy_score(y_test, y_pred))\n\n# Visualizing Confusion Matrix\nplt.figure(figsize = (6, 6))\nsns.heatmap(cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15})\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc AUC Curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nplt.figure(figsize = (6, 6))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC AUC Curve')\nplt.legend()\nplt.show()\n\n#Precision Recall Curve\naverage_precision = average_precision_score(y_test, y_prob)\ndisp = plot_precision_recall_curve(classifier, x_test, y_test)\nplt.title('Precision-Recall Curve')\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Radius Neighbors Classifier** <a id='5.5' ></a>","metadata":{}},{"cell_type":"markdown","source":"üìå Classifier implementing a vote among neighbors within a given radius","metadata":{}},{"cell_type":"code","source":"#Fitting RadiusNeighborsClassifier Model\nclassifier = RadiusNeighborsClassifier(outlier_label=1,radius=6)\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ny_prob = classifier.predict_proba(x_test)[:,1]\ncm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {roc_auc_score(y_test, y_prob)}')\nprint('Accuracy Score: ',accuracy_score(y_test, y_pred))\n\n# Visualizing Confusion Matrix\nplt.figure(figsize = (6, 6))\nsns.heatmap(cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15})\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc AUC Curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nplt.figure(figsize = (6, 6))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC AUC Curve')\nplt.legend()\nplt.show()\n\n#Precision Recall Curve\naverage_precision = average_precision_score(y_test, y_prob)\ndisp = plot_precision_recall_curve(classifier, x_test, y_test)\nplt.title('Precision-Recall Curve')\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **GaussianNB** <a id='5.6' ></a>","metadata":{}},{"cell_type":"markdown","source":"üìå *A Gaussian Naive Bayes algorithm is a special type of NB algorithm. It's specifically used when the features have continuous values. It's also assumed that all the features are following a gaussian distribution i.e, normal distribution.*","metadata":{}},{"cell_type":"code","source":"#Fitting GaussianNB Model\nclassifier = GaussianNB()\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ny_prob = classifier.predict_proba(x_test)[:,1]\ncm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {roc_auc_score(y_test, y_prob)}')\nprint('Accuracy Score: ',accuracy_score(y_test, y_pred))\n\n# Visualizing Confusion Matrix\nplt.figure(figsize = (6, 6))\nsns.heatmap(cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15})\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc AUC Curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (6, 6))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC AUC Curve')\nplt.legend()\nplt.show()\n\n#Precision Recall Curve\naverage_precision = average_precision_score(y_test, y_prob)\ndisp = plot_precision_recall_curve(classifier, x_test, y_test)\nplt.title('Precision-Recall Curve')\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **BernoulliNB** <a id='5.7' ></a>","metadata":{}},{"cell_type":"markdown","source":"üìå *Like MultinomialNB, this classifier is suitable for discrete data. The difference is that while MultinomialNB works with occurrence counts, BernoulliNB is designed for binary/boolean features.*","metadata":{}},{"cell_type":"code","source":"#Fitting BernoulliNB Model\nclassifier = BernoulliNB()\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ny_prob = classifier.predict_proba(x_test)[:,1]\ncm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {roc_auc_score(y_test, y_prob)}')\nprint('Accuracy Score: ',accuracy_score(y_test, y_pred))\n\n# Visualizing Confusion Matrix\nplt.figure(figsize = (6, 6))\nsns.heatmap(cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15})\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc AUC Curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (6, 6))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC AUC Curve')\nplt.legend()\nplt.show()\n\n#Precision Recall Curve\naverage_precision = average_precision_score(y_test, y_prob)\ndisp = plot_precision_recall_curve(classifier, x_test, y_test)\nplt.title('Precision-Recall Curve')\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **SVM** <a id='5.8' ></a>","metadata":{}},{"cell_type":"markdown","source":"üìå *Support Vector Machines (or SVM) seek a line that best separates two classes. Those data instances that are closest to the line that best separates the classes are called support vectors and influence where the line is placed. SVM has been extended to support multiple classes Of particular importance is the use of different kernel functions via the kernel parameter .A powerful Radial Basis Function is used by default. You can construct an SVM model using the SVC class.*","metadata":{}},{"cell_type":"code","source":"#Fitting SVC Model\nclassifier = SVC(probability=True)\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ny_prob = classifier.predict_proba(x_test)[:,1]\ncm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {roc_auc_score(y_test, y_prob)}')\nprint('Accuracy Score: ',accuracy_score(y_test, y_pred))\n\n# Visualizing Confusion Matrix\nplt.figure(figsize = (6, 6))\nsns.heatmap(cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15})\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc AUC Curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (6, 6))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC AUC Curve')\nplt.legend()\nplt.show()\n\n#Precision Recall Curve\naverage_precision = average_precision_score(y_test, y_prob)\ndisp = plot_precision_recall_curve(classifier, x_test, y_test)\nplt.title('Precision-Recall Curve')\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Nu-SVC** <a id='5.9' ></a>","metadata":{}},{"cell_type":"markdown","source":"üìå *Similar to SVC but uses a parameter to control the number of support vectors.*","metadata":{}},{"cell_type":"code","source":"#Fitting Nu-SVC Model\nclassifier = NuSVC(nu=0.3,probability=True)\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ny_prob = classifier.predict_proba(x_test)[:,1]\ncm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {roc_auc_score(y_test, y_prob)}')\nprint('Accuracy Score: ',accuracy_score(y_test, y_pred))\n\n# Visualizing Confusion Matrix\nplt.figure(figsize = (6, 6))\nsns.heatmap(cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15})\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc AUC Curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (6, 6))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC AUC Curve')\nplt.legend()\nplt.show()\n\n#Precision Recall Curve\naverage_precision = average_precision_score(y_test, y_prob)\ndisp = plot_precision_recall_curve(classifier, x_test, y_test)\nplt.title('Precision-Recall Curve')\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Linear SVC** <a id='5.10' ></a>","metadata":{}},{"cell_type":"markdown","source":"üìå *Similar to SVC with parameter kernel=‚Äôlinear‚Äô, but implemented in terms of liblinear rather than libsvm, so it has more flexibility in the choice of penalties and loss functions and should scale better to large numbers of samples.*","metadata":{}},{"cell_type":"code","source":"#Fitting LinearSVC Model\nclassifier = LinearSVC()\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ny_prob = classifier._predict_proba_lr(x_test)[:,1]\ncm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {roc_auc_score(y_test, y_prob)}')\nprint('Accuracy Score: ',accuracy_score(y_test, y_pred))\n\n# Visualizing Confusion Matrix\nplt.figure(figsize = (6, 6))\nsns.heatmap(cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15})\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc AUC Curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (6, 6))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC AUC Curve')\nplt.legend()\nplt.show()\n\n#Precision Recall Curve\naverage_precision = average_precision_score(y_test, y_prob)\ndisp = plot_precision_recall_curve(classifier, x_test, y_test)\nplt.title('Precision-Recall Curve')\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Decision Tree** <a id='5.11' ></a>","metadata":{}},{"cell_type":"markdown","source":"üìå *Classification and Regression Trees (CART or just decision trees) construct a binary tree from the training data. Split points are chosen greedily by evaluating each attribute and each value of each attribute in the training data in order to minimize a cost function (like the Gini index). You can construct a CART model using the DecisionTreeClassifier class*","metadata":{}},{"cell_type":"code","source":"#Fitting DecisionTreeClassifier Model\nclassifier = DecisionTreeClassifier(criterion= 'gini',random_state= 0)\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ny_prob = classifier.predict_proba(x_test)[:,1]\ncm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {roc_auc_score(y_test, y_prob)}')\nprint('Accuracy Score: ',accuracy_score(y_test, y_pred))\n\n# Visualizing Confusion Matrix\nplt.figure(figsize = (6, 6))\nsns.heatmap(cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15})\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc AUC Curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (6, 6))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC AUC Curve')\nplt.legend()\nplt.show()\n\n#Precision Recall Curve\naverage_precision = average_precision_score(y_test, y_prob)\ndisp = plot_precision_recall_curve(classifier, x_test, y_test)\nplt.title('Precision-Recall Curve')\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Random Forest** <a id='5.12' ></a>","metadata":{}},{"cell_type":"markdown","source":"üìå *Random Forests is an extension of bagged decision trees. Samples of the training dataset are taken with replacement, but the trees are constructed in a way that reduces the correlation between individual classifiers. Specifically, rather than greedily choosing the best split point in the construction of each tree, only a random subset of features are considered for each split. You can construct a Random Forest model for classification using the RandomForestClassifier class.*","metadata":{}},{"cell_type":"code","source":"#Fitting RandomForestClassifier Model\nclassifier = RandomForestClassifier(criterion= 'entropy', n_estimators= 200,random_state= 0)\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ny_prob = classifier.predict_proba(x_test)[:,1]\ncm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {roc_auc_score(y_test, y_prob)}')\nprint('Accuracy Score: ',accuracy_score(y_test, y_pred))\n\n# Visualizing Confusion Matrix\nplt.figure(figsize = (6, 6))\nsns.heatmap(cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15})\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc AUC Curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (6, 6))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC AUC Curve')\nplt.legend()\nplt.show()\n\n#Precision Recall Curve\naverage_precision = average_precision_score(y_test, y_prob)\ndisp = plot_precision_recall_curve(classifier, x_test, y_test)\nplt.title('Precision-Recall Curve')\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Extra Trees** <a id='5.13' ></a>","metadata":{}},{"cell_type":"markdown","source":"üìå *Extra Trees are another modification of bagging where random trees are constructed from samples of the training dataset. You can construct an Extra Trees model for classification using the ExtraTreesClassifier class.*","metadata":{}},{"cell_type":"code","source":"#Fitting ExtraTreesClassifier Model\nclassifier = ExtraTreesClassifier(criterion= 'gini',n_estimators= 100,random_state= 0)\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ny_prob = classifier.predict_proba(x_test)[:,1]\ncm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {roc_auc_score(y_test, y_prob)}')\nprint('Accuracy Score: ',accuracy_score(y_test, y_pred))\n\n# Visualizing Confusion Matrix\nplt.figure(figsize = (6, 6))\nsns.heatmap(cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15})\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc AUC Curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (6, 6))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC AUC Curve')\nplt.legend()\nplt.show()\n\n#Precision Recall Curve\naverage_precision = average_precision_score(y_test, y_prob)\ndisp = plot_precision_recall_curve(classifier, x_test, y_test)\nplt.title('Precision-Recall Curve')\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **AdaBoost** <a id='5.14' ></a>","metadata":{}},{"cell_type":"markdown","source":"üìå *AdaBoost was perhaps the first successful boosting ensemble algorithm. It generally works by weighting instances in the dataset by how easy or difficult they are to classify, allowing the algorithm to pay or less attention to them in the construction of subsequent models. You can construct an AdaBoost model for classification using the AdaBoostClassifier class*","metadata":{}},{"cell_type":"code","source":"#Fitting AdaBoostClassifier Model\nclassifier = AdaBoostClassifier(algorithm= 'SAMME', learning_rate= 0.1, n_estimators= 100,random_state= 0)\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ny_prob = classifier.predict_proba(x_test)[:,1]\ncm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {roc_auc_score(y_test, y_prob)}')\nprint('Accuracy Score: ',accuracy_score(y_test, y_pred))\n\n# Visualizing Confusion Matrix\nplt.figure(figsize = (6, 6))\nsns.heatmap(cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15})\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc AUC Curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (6, 6))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC AUC Curve')\nplt.legend()\nplt.show()\n\n#Precision Recall Curve\naverage_precision = average_precision_score(y_test, y_prob)\ndisp = plot_precision_recall_curve(classifier, x_test, y_test)\nplt.title('Precision-Recall Curve')\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Gradient Boosting** <a id='5.15' ></a>","metadata":{}},{"cell_type":"markdown","source":"üìå *Stochastic Gradient Boosting (also called Gradient Boosting Machines) are one of the most sophisticated ensemble techniques. It is also a technique that is proving to be perhaps one of the best techniques available for improving performance via ensembles. You can construct a Gradient Boosting model for classification using the GradientBoostingClassifier class*","metadata":{}},{"cell_type":"code","source":"#Fitting GradientBoostingClassifier Model\nclassifier = GradientBoostingClassifier(criterion= 'mse', learning_rate= 0.1, loss= 'exponential', n_estimators= 100,random_state= 0)\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ny_prob = classifier.predict_proba(x_test)[:,1]\ncm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {roc_auc_score(y_test, y_prob)}')\nprint('Accuracy Score: ',accuracy_score(y_test, y_pred))\n\n# Visualizing Confusion Matrix\nplt.figure(figsize = (6, 6))\nsns.heatmap(cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15})\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc AUC Curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (6, 6))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC AUC Curve')\nplt.legend()\nplt.show()\n\n#Precision Recall Curve\naverage_precision = average_precision_score(y_test, y_prob)\ndisp = plot_precision_recall_curve(classifier, x_test, y_test)\nplt.title('Precision-Recall Curve')\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Bagging Classifier** <a id='5.16' ></a>","metadata":{}},{"cell_type":"markdown","source":"üìå *A Bagging classifier is an ensemble meta-estimator that fits base classifiers each on random subsets of the original dataset and then aggregate their individual predictions (either by voting or by averaging) to form a final prediction. Such a meta-estimator can typically be used as a way to reduce the variance of a black-box estimator (e.g., a decision tree), by introducing randomization into its construction procedure and then making an ensemble out of it.*","metadata":{}},{"cell_type":"code","source":"#Fitting BaggingClassifier Model\nclassifier = BaggingClassifier(random_state= 0)\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ny_prob = classifier.predict_proba(x_test)[:,1]\ncm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {roc_auc_score(y_test, y_prob)}')\nprint('Accuracy Score: ',accuracy_score(y_test, y_pred))\n\n# Visualizing Confusion Matrix\nplt.figure(figsize = (6, 6))\nsns.heatmap(cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15})\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc AUC Curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (6, 6))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC AUC Curve')\nplt.legend()\nplt.show()\n\n#Precision Recall Curve\naverage_precision = average_precision_score(y_test, y_prob)\ndisp = plot_precision_recall_curve(classifier, x_test, y_test)\nplt.title('Precision-Recall Curve')\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **XGBoost** <a id='5.17' ></a>","metadata":{}},{"cell_type":"markdown","source":"üìå *XGBoost stands for Extreme Gradient Boosting, it is a performant machine learning library based on the paper Greedy Function Approximation: A Gradient Boosting Machine, by Friedman. XGBoost implements a Gradient Boosting algorithm based on decision trees.*","metadata":{}},{"cell_type":"code","source":"#Fitting XGBClassifier Model\nclassifier = XGBClassifier(eval_metric= 'error', learning_rate= 0.1)\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ny_prob = classifier.predict_proba(x_test)[:,1]\ncm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {roc_auc_score(y_test, y_prob)}')\nprint('Accuracy Score: ',accuracy_score(y_test, y_pred))\n\n# Visualizing Confusion Matrix\nplt.figure(figsize = (6, 6))\nsns.heatmap(cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15})\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc AUC Curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (6, 6))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC AUC Curve')\nplt.legend()\nplt.show()\n\n#Precision Recall Curve\naverage_precision = average_precision_score(y_test, y_prob)\ndisp = plot_precision_recall_curve(classifier, x_test, y_test)\nplt.title('Precision-Recall Curve')\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **LightGBM** <a id='5.18' ></a>","metadata":{}},{"cell_type":"markdown","source":"üìå *LightGBM is a gradient boosting framework that uses tree based learning algorithms. It is designed to be distributed and efficient with the following advantages: Faster training speed and higher efficiency, Lower memory usage, Better accuracy, Support of parallel and GPU learning, Capable of handling large-scale data.*","metadata":{}},{"cell_type":"code","source":"#Fitting LGBMClassifier Model\nclassifier = LGBMClassifier(learning_rate= 0.1, n_estimators= 100, random_state= 0)\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ny_prob = classifier.predict_proba(x_test)[:,1]\ncm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {roc_auc_score(y_test, y_prob)}')\nprint('Accuracy Score: ',accuracy_score(y_test, y_pred))\n\n# Visualizing Confusion Matrix\nplt.figure(figsize = (6, 6))\nsns.heatmap(cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15})\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc AUC Curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (6, 6))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC AUC Curve')\nplt.legend()\nplt.show()\n\n#Precision Recall Curve\naverage_precision = average_precision_score(y_test, y_prob)\ndisp = plot_precision_recall_curve(classifier, x_test, y_test)\nplt.title('Precision-Recall Curve')\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Linear Discriminant Analysis** <a id='5.19' ></a>","metadata":{}},{"cell_type":"markdown","source":"üìå *Linear Discriminant Analysis or LDA is a statistical technique for binary and multiclass classification. It too assumes a Gaussian distribution for the numerical input variables. You can construct an LDA model using the LinearDiscriminantAnalysis class.*","metadata":{}},{"cell_type":"code","source":"#Fitting LinearDiscriminantAnalysis Model\nclassifier = LinearDiscriminantAnalysis()\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ny_prob = classifier.predict_proba(x_test)[:,1]\ncm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {roc_auc_score(y_test, y_prob)}')\nprint('Accuracy Score: ',accuracy_score(y_test, y_pred))\n\n# Visualizing Confusion Matrix\nplt.figure(figsize = (6, 6))\nsns.heatmap(cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15})\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc AUC Curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (6, 6))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC AUC Curve')\nplt.legend()\nplt.show()\n\n#Precision Recall Curve\naverage_precision = average_precision_score(y_test, y_prob)\ndisp = plot_precision_recall_curve(classifier, x_test, y_test)\nplt.title('Precision-Recall Curve')\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Quadratic Discriminant Analysis** <a id='5.20' ></a>","metadata":{}},{"cell_type":"markdown","source":"üìå *A classifier with a quadratic decision boundary, generated by fitting class conditional densities to the data and using Bayes‚Äô rule. The model fits a Gaussian density to each class.*","metadata":{}},{"cell_type":"code","source":"#Fitting QuadraticDiscriminantAnalysis Model\nclassifier = QuadraticDiscriminantAnalysis()\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ny_prob = classifier.predict_proba(x_test)[:,1]\ncm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {roc_auc_score(y_test, y_prob)}')\nprint('Accuracy Score: ',accuracy_score(y_test, y_pred))\n\n# Visualizing Confusion Matrix\nplt.figure(figsize = (6, 6))\nsns.heatmap(cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15})\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc AUC Curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (6, 6))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC AUC Curve')\nplt.legend()\nplt.show()\n\n#Precision Recall Curve\naverage_precision = average_precision_score(y_test, y_prob)\ndisp = plot_precision_recall_curve(classifier, x_test, y_test)\nplt.title('Precision-Recall Curve')\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **MLPClassifier** <a id='5.21' ></a>","metadata":{}},{"cell_type":"markdown","source":"üìå *MLPClassifier stands for Multi-layer Perceptron classifier which in the name itself connects to a Neural Network. Unlike other classification algorithms such as Support Vectors or Naive Bayes Classifier, MLPClassifier relies on an underlying Neural Network to perform the task of classification.*","metadata":{}},{"cell_type":"code","source":"#Fitting MLPClassifier Model\nclassifier = MLPClassifier()\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ny_prob = classifier.predict_proba(x_test)[:,1]\ncm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {roc_auc_score(y_test, y_prob)}')\nprint('Accuracy Score: ',accuracy_score(y_test, y_pred))\n\n# Visualizing Confusion Matrix\nplt.figure(figsize = (6, 6))\nsns.heatmap(cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15})\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc AUC Curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (6, 6))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC AUC Curve')\nplt.legend()\nplt.show()\n\n#Precision Recall Curve\naverage_precision = average_precision_score(y_test, y_prob)\ndisp = plot_precision_recall_curve(classifier, x_test, y_test)\nplt.title('Precision-Recall Curve')\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **H2O AutoML** <a id='5.22' ></a>","metadata":{}},{"cell_type":"markdown","source":"üìå *The H2O AutoML interface is designed to have as few parameters as possible so that all the user needs to do is point to their dataset, identify the response column and optionally specify a time constraint or limit on the number of total models trained.* <br>\nüìå *In both the R and Python API, AutoML uses the same data-related arguments, x, y, training_frame, validation_frame, as the other H2O algorithms. Most of the time, all you‚Äôll need to do is specify the data arguments. You can then configure values for max_runtime_secs and/or max_models to set explicit time or number-of-model limits on your run.*","metadata":{}},{"cell_type":"code","source":"# Starting H2O\nimport h2o\nfrom h2o.automl import H2OAutoML\n\nh2o.init(nthreads = -1)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import Dataset\ndataset = h2o.import_file('/kaggle/input/heart-attack-analysis-prediction-dataset/heart.csv')","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Identify predictors and response\nx = dataset.columns\ny = \"output\"\nx.remove(y)\n\ndataset[y] = dataset[y].asfactor()\n\n# Run AutoML for 20 base models (limited to 1 hour max runtime by default)\naml = H2OAutoML(max_models=20, seed=11)\naml.train(x=x, y=y, training_frame=dataset)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lb = aml.leaderboard\nlb.head()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Best Model\naml.leader ","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Variable Importance Plot\naml.leader.varimp_plot()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"üìå Variable Importance shows the relative importance of the most important variables in the model. H2O displays each feature‚Äôs importance after scaling between 0 and 1. <br>\nüìå It is straightforward to interpret this graph. Variable with the longest bar (aka the topmost one) is the most important and the one with the shortest bar (aka the bottom-most one) is the least important.","metadata":{}},{"cell_type":"code","source":"# SHAP Summary Plot\naml.leader.shap_summary_plot(dataset)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"üìå SHAP value which is an acronym for **SHapley Additive exPlanations** interprets the impact of having a particular value for a given variable compared to the prediction we would make if that variable took some baseline value instead. <br>\nüìå The y-axis indicates the variable name, usually in the descending order of importance from top to bottom. <br>\nüìå SHAP value on the x-axis indicates the change in log-odds. From this value, we can extract the probability of an event (*Condition* in this case). <br>\nüìå Gradient color indicates the original value for that variable. In binary classification problems(as in our case), it will take two colors, but it can contain the whole spectrum for numeric target variables(regression problems). <br>\nüìå Each point in the plot represents a record from the original dataset.","metadata":{}},{"cell_type":"code","source":"# Partial Dependence Plot\naml.pd_multi_plot(dataset, column='caa')","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"üìå Partial dependence plot (PDP) gives a graphical depiction of the marginal effect of a variable on the response. <br>\nüìå The effect of a variable is measured in change in the mean response. PDP assumes independence between the feature for which is the PDP computed and the rest.","metadata":{}},{"cell_type":"markdown","source":"## **TPOT** <a id='5.23' ></a>","metadata":{}},{"cell_type":"markdown","source":"üìå *TPOT is meant to be an assistant that gives you ideas on how to solve a particular machine learning problem by exploring pipeline configurations that you might have never considered, then leaves the fine-tuning to more constrained parameter tuning techniques such as grid search.*","metadata":{}},{"cell_type":"code","source":"from tpot import TPOTClassifier\n\ntpot = TPOTClassifier(generations=5, verbosity=2)\ntpot.fit(x_train,y_train)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = tpot.predict(x_test)\ny_prob = tpot.predict_proba(x_test)[:,1]\ncm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {roc_auc_score(y_test, y_prob)}')\nprint('Accuracy Score: ',accuracy_score(y_test, y_pred))\n\n# Visualizing Confusion Matrix\nplt.figure(figsize = (6, 6))\nsns.heatmap(cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15})\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc AUC Curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (6, 6))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC AUC Curve')\nplt.legend()\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:LightSlateGray;\n           font-size:150%;\n           text-align:center;\n            letter-spacing:0.5px\"> <a id='6'></a>\n    \n    Conclusion\n</div>","metadata":{}},{"cell_type":"markdown","source":"üìå After extensive data analysis and I tried different classification models to see how it performs on the dataset. I got pretty good results with classification report. <br>\nüìå Also, I plotted ROC and Precision-Recall Curve for classification models also Variable Importance, SHAP Summary and Partial Dependenced Plot for H2O AutoML. <br>\nüìå Note that all models are used with default parameters, we can also tune the models and see how they perform.","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:black;\n           display:fill;\n           border-radius:5px;\n           border:2px solid DodgerBlue;\n           background-color:white;\n           font-size:150%;\n           text-align:center;\n           letter-spacing:0.5px\">\n    \n    Thank You!\n</div>","metadata":{}}]}