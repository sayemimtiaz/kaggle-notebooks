{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Story of New York Jobs\n\n![New York Jobs](https://kuwaitjobvacancy.com/wp-content/uploads/2017/07/New-York-JOBS.png)"},{"metadata":{},"cell_type":"markdown","source":"1. [Introduction](#Introduction)\n2. [Loading Packages and Data](#Loading)\n3. [Data Structure and Content](#DSC)\n4. [Data Analysis](#DataAnalysis)"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"Introduction\"></a>\n## Introduction\n\nThis data contains current job posting available on the City of New Yorkâ€™s official jobs site."},{"metadata":{},"cell_type":"markdown","source":"<a id=\"Loading\"></a>\n## Loading Packages and Data"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt #Data Ploting\nimport seaborn as sns #Data Ploting\nimport operator\nimport math\nfrom wordcloud import WordCloud, STOPWORDS\nfrom nltk import pos_tag, sent_tokenize, word_tokenize, BigramAssocMeasures,\\\n    BigramCollocationFinder, TrigramAssocMeasures, TrigramCollocationFinder\nfrom nltk import WordNetLemmatizer\nfrom nltk.corpus import stopwords\nimport string\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"df = pd.read_csv(\"../input/nyc-jobs.csv\",index_col='Posting Date', parse_dates=['Posting Date'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"DSC\"></a>\n## Data Structure and Content\n\nLet's first chech the dataset structure. No. or rows and features it contains."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, there are 3096 rows and 27 columns or featueres are there.\n\nLet's check what are the features we got."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"list(df.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's check is there any null present in this dataset."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df.isnull().values.any()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"yess...the dataset contains null. But we don't know where, let's check onece again..."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"for column in df.columns:\n    if df[column].isnull().any():\n       print('{0} has {1} null values'.format(column, df[column].isnull().sum()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that Hours/Shift, Work Location, and Post Until contains lot of null values. And Recruitment Contact has no value at all in the dataset. Job Category contains only 2 null values, which we will try to impute and all the other features contains relatively less null's.\n\nLet's check the Job Category, where there are null."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df[df['Job Category'].isnull().values]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can try to find the pattern using other columns like Agency, Civil Service Title along with level to find the correct value for the nulls."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df[(df['Business Title']==\"Account Manager\")]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using Business Title to find pattern is not going to work here as there is only one row, that contains Nan as Job Category. Let's try some other columns."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df[(df['Civil Service Title']==\"CONTRACT REVIEWER (OFFICE OF L\")]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we can impute our first row as \"*Constituent Services & Community Programs*\",as the Civil Service Title, Title no. and other columns are giving us the indication for the right value.\n\nNow, let's look for another one..."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df[(df['Civil Service Title']==\"ADMINISTRATIVE BUSINESS PROMOT\") & (df['Level'] == 'M3')]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we are getting three options for imputing our value as \"Constituent Services & Community Programs\", \"Public Safety, Inspections, & Enforcement\" and \"Administration & Human Resources Communication\" but if we can take Agency into context we can impute the first option for time being.\n\nSo, Let's impute \"Constituent Services & Community Programs\" in Job Category"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df[\"Job Category\"] = df[\"Job Category\"].fillna(\"Constituent Services & Community Programs\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"DataAnalysis\"></a>\n## Data Analysis"},{"metadata":{},"cell_type":"markdown","source":"Now,as we have already seen the data content and structure, lets find some insights from it.\n\n### No. of jobs produced over the years"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df[[\"Job ID\"]].resample('M').count().plot(figsize=(20,10), linewidth=3, fontsize=20)\nplt.xlabel('Year', fontsize=20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hmm...The No. of jobs starts growing exponentionally after 2016. Good for New york but is the no. of opportunities also increased as the job are increasing? let's check"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df[[\"# Of Positions\"]].resample('M').sum().plot(figsize=(20,10), linewidth=3, fontsize=20)\nplt.xlabel('Year', fontsize=20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Yes, the Opportunities also grows with job, but there is a small glich in 2019, otherwise looking good...\n\nNow, Let's check which category has picked up over the years"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df['year'] = pd.DatetimeIndex(df.index).year\ndef parse_categories(index,x):\n    l = x.replace('&', ',').split(',')\n    l = [x.strip().rstrip(',') for x in l]\n    for category in l:\n        if index in key_categories:\n            if category in key_categories[index]:\n                key_categories[index][category] +=1\n            else:\n                key_categories[index][category] = 1\n        else:\n            key_categories[index] = {}\n\nkey_categories = {}\nfor index, rows in df.iterrows():\n    if type(rows['Job Category']) is str:\n        parse_categories(rows['year'],rows['Job Category'])\n\nfor index,item in key_categories.items():\n    if '' in item:\n        item.pop('', None)\n\nsorted_x = {}\nfor index,item in key_categories.items():\n    sorted_x[index] = (sorted(item.items(), key=operator.itemgetter(1)))[-5:]\n    \ntempList = []\nfor index,y in sorted_x.items():\n    for i in range(len(y)):\n        temp={}\n        temp['year'] = index\n        temp['Category'] = y[i][0]\n        temp['Count'] = y[i][1]\n        tempList.append(temp)\n\ndf2 = pd.DataFrame(tempList)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"sns.set_style('darkgrid')\nsns.set_context(\"talk\")\nfig, ax = plt.subplots()\nfig.set_size_inches(15, 9)\nax = sns.lineplot(x=\"year\", y=\"Count\", hue=\"Category\",data=df2)\nsns.despine()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, Engineering and Architecture is at top in 2019, Planning and inspection can also be a good pick. IT and Telecommunication is somwhere lost after 2015."},{"metadata":{},"cell_type":"markdown","source":"Nnow Let's Check the salary growth wrt top Civil Service Title"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"title = [\"COMMUNITY COORDINATOR\",\"CIVIL ENGINEER\",\"AGENCY ATTORNEY\",\"CITY RESEARCH SCIENTIST\",\"ADMINISTRATIVE PROJECT MANAGER\",\"CLERICAL ASSOCIATE\"]\ndf4 = df[(df['Full-Time/Part-Time indicator']=='F') & df[\"Civil Service Title\"].isin(title)][[\"Civil Service Title\",\"Level\",\"Salary Range From\"]]\ndf4 = df4.reset_index()\nfig, ax = plt.subplots(nrows=3,ncols=2,figsize=(15,15))\nk=0\nfor i in range(3):\n    for j in range(2):\n        levelList = list(df4[(df4['Civil Service Title']==title[k])][\"Level\"].unique())\n        for level in levelList:\n            tempDF = df4[(df4['Civil Service Title']==title[k]) & (df4.Level == level)]\n            ax[i,j].plot(tempDF['Posting Date'], tempDF[\"Salary Range From\"])\n            ax[i,j].title.set_text(title[k])\n            ax[i,j].legend(levelList,loc=\"upper left\")\n        k+=1\nplt.gcf().autofmt_xdate()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"let's check each graph one-by-one:\n\n**Community Cordinator** - only one level. And for most of the years it goes desent, till 2019.\n\n**Civil Engineer** - Three levels, all have distingushiable difference between them. Also all of them get a raise in mid 18.\n\n**Agency Atorny** - Four Levels, difference in the salaries are descent. Every level is smooth with time except level four which has some downshift in 2019.\n\n**City Research Scientist** - Four Levels, again easily distinguishable with levels, Although 4B might be very less to be visiable on chart. Also level one jobs have occured in 2018 for the first time.\n\n**Administrative Project Manager** - Five levels, and its all over the chart :D . Seems like M3 and M4 level opportunities have occurred rescently. And Level M3 got more salary than M4 in 19, it can be assumed then that M4 will get a great boost up.\n\n**Clerical Associate** - Four Levels, Got descent salary wrt other profession.\n\n\n### highest and lowest posting dates (Average)."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df5 = df[[\"Civil Service Title\",\"Post Until\"]]\ndf5 = df5.dropna()\ndf5 = df5.reset_index()\ndf5['Posting Date'] = df5['Posting Date'].astype('datetime64[ns]')\ndf5['Post Until'] = df5['Post Until'].astype('datetime64[ns]')\ndf5[\"Posted_Days\"] = (df5['Post Until'] - df5['Posting Date']).dt.days\ndf5 = round(df5.groupby(['Civil Service Title'], as_index=False)['Posted_Days'].mean(),2)\ndf5 = df5.sort_values([\"Posted_Days\"],ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(10,10))\nsns.barplot(y=df5[\"Civil Service Title\"][:10],x=df5.Posted_Days[:10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(10,10))\nsns.barplot(y=df5[\"Civil Service Title\"][-10:],x=df5.Posted_Days[-10:])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"These are the average no. of days the job is posted over the portal. Looks like Correctional Standard Review has been posted for vary long time wrt others.\n\nand Child welfare specialist has been posted for seven days average. seems they can be found easily.\n\n\nNow, Lets check the jobs or category that require residency requirment"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df.loc[df['Residency Requirement'].str.contains(\"not required\"), 'Residency_Required'] = 'No'\ndf.loc[df['Residency Requirement'].str.contains(\"no residency requirement\"), 'Residency_Required'] = 'No'\ndf.loc[df['Residency Requirement'].str.contains(\"no residency requirements\"), 'Residency_Required'] = 'No'\ndf[\"Residency_Required\"].fillna(\"Yes\", inplace=True)\ndf7 = df[[\"Civil Service Title\",\"Residency_Required\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"((pd.crosstab(index=df7[\"Civil Service Title\"], columns=df7[\"Residency_Required\"]))).sort_values(['Yes', 'No'], ascending=[False, True])[:10].T.plot.bar(figsize=(13,10))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Categories which do not require residency"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"((pd.crosstab(index=df7[\"Civil Service Title\"], columns=df7[\"Residency_Required\"]))).sort_values(['Yes', 'No'], ascending=[False, True])[-10:].T.plot.bar(figsize=(13,10))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Most preferred skills for Jobs**"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def get_bitrigrams(full_text, threshold=30):\n    if isinstance(full_text, str):\n        text = full_text\n    else:\n        text = \" \".join(full_text)\n    bigram_measures = BigramAssocMeasures()\n    trigram_measures = TrigramAssocMeasures()\n    finder = BigramCollocationFinder.from_words(text.split())\n    finder.apply_freq_filter(3)\n    bigrams = {\" \".join(words): \"_\".join(words)\n               for words in finder.above_score(bigram_measures.likelihood_ratio, threshold)}\n    finder = TrigramCollocationFinder.from_words(text.split())\n    finder.apply_freq_filter(3)\n    trigrams = {\" \".join(words): \"_\".join(words)\n                for words in finder.above_score(trigram_measures.likelihood_ratio, threshold)}\n    return bigrams, trigrams\n\ndef process_text(text, lemmatizer, translate_table, stopwords):\n    processed_text = \"\"\n    for sentence in sent_tokenize(text):\n        tagged_sentence = pos_tag(word_tokenize(sentence.translate(translate_table)))\n        for word, tag in tagged_sentence:\n            word = word.lower()\n            if word not in stopwords:\n                if tag[0] != 'V':\n                    processed_text += lemmatizer.lemmatize(word) + \" \"\n    return processed_text\n\nwordnet_lemmatizer = WordNetLemmatizer()\nnewStopWords = [\"new\",\"skill\",\"york\",\"city\",\"new york\",\"new york city\"]\n#stopwords = stopwords.extend(newStopWords)\nstop = set(stopwords.words('english'))\nstop1 = stop.union(newStopWords)\ntranslate_table = dict((ord(char), \" \") for char in string.punctuation)\n\ndef use_ngrams_only(texts, lemmatizer, translate_table, stopwords):\n    processed_texts = []\n    for index, doc in enumerate(texts):\n        if type(doc) is str:\n            processed_texts.append(process_text(doc, wordnet_lemmatizer, translate_table, stop))\n    bigrams, trigrams = get_bitrigrams(processed_texts)\n    indexed_texts = []\n    for doc in processed_texts:\n        current_doc = []\n        for k, v in trigrams.items():\n            c = doc.count(k)\n            if c > 0:\n                current_doc += [v] * c\n                doc = doc.replace(k, v)\n        for k, v in bigrams.items():\n            current_doc += [v] * doc.count(\" \" + k + \" \")\n        indexed_texts.append(\" \".join(current_doc))\n    return \" \".join(indexed_texts)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"wordcloud = WordCloud(stopwords=stop1, background_color=\"white\").\\\n    generate(use_ngrams_only(df['Preferred Skills'], wordnet_lemmatizer, translate_table, stop))\nplt.figure(figsize=(8, 5))\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, Verbal and communication skills are the most important, But its generalized with all the job category. We have to look into specific job category if we needs to find out the actual skills.\n"},{"metadata":{},"cell_type":"markdown","source":"**Job Description word cloud**"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"wordcloud = WordCloud(stopwords=stop1, background_color=\"white\").\\\n    generate(use_ngrams_only(df['Job Description'], wordnet_lemmatizer, translate_table, stop))\nplt.figure(figsize=(8, 5))\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It seems that work for enviroment and its related area are in most of the discription./"},{"metadata":{},"cell_type":"markdown","source":"**Minimum requirment**"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"wordcloud = WordCloud(stopwords=stop, background_color=\"white\").\\\n    generate(use_ngrams_only(df['Minimum Qual Requirements'], wordnet_lemmatizer, translate_table, stop))\nplt.figure(figsize=(8, 5))\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, A full time diploma is at least required for the job to be offered."},{"metadata":{},"cell_type":"markdown","source":"Thanks,\n\nDo upvote if feel helpful"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}