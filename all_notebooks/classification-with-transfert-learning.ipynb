{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"from glob import glob\nimport pandas as pd\nimport torch, pydicom, torchvision, time, os, cv2, copy\nimport torch.utils.data\nimport torch.utils.data.dataloader\nfrom collections import defaultdict, deque\nfrom torchvision import transforms, utils\nfrom torch.utils.data.sampler import SubsetRandomSampler\nimport numpy as np\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dataset class declaration"},{"metadata":{"trusted":true},"cell_type":"code","source":"input_size = 512\n\nclass SIIMDataset(torch.utils.data.Dataset):\n    \"\"\"SIIM Pneumothorax dataset.\"\"\"\n\n    def __init__(self, csv_file, root_dir, transform=None):\n        self.masks = pd.read_csv(csv_file)\n        self.masks = self.masks.drop_duplicates('ImageId', keep='last').reset_index(drop=True)\n        self.images = glob(os.path.join(root_dir,'*/*/*.dcm'))\n        self.transform = transform\n        self.width = input_size\n        self.height = input_size\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        img_path = self.images[idx]\n        img_file_name = os.path.basename(img_path)\n        img_name = os.path.splitext(img_file_name)[0]\n        image_infos = pydicom.dcmread(img_path)\n        \n        image_full = np.expand_dims(image_infos.pixel_array, axis=2)\n        image_cv2 = cv2.resize(image_full, (input_size,input_size), interpolation=cv2.INTER_CUBIC)\n        image = np.expand_dims(image_cv2, axis=2)\n        \n        mask_serie = self.masks.loc[self.masks[\"ImageId\"] == img_name]\n        mask_rle = mask_serie[\" EncodedPixels\"].tolist()\n        mask = np.zeros((input_size, input_size))\n        img_class = np.zeros((1))\n        \n        for mask_i in mask_rle:\n            if mask_i != \" -1\":\n                mask += rle2mask(mask_i, self.width, self.height)\n                img_class = np.array([1])\n            else:\n                img_class = np.array([0])\n\n        sample = {\"image\": image , \"mask\": mask, \"class\":img_class }\n\n\n        if self.transform:\n            sample = self.transform(sample)\n\n        return sample\n\n    \nclass ToTensor(object):\n    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n\n    def __call__(self, sample):\n        image, mask, img_class = sample['image'], sample['mask'], sample['class']\n\n        # swap color axis because\n        # numpy image: H x W x C\n        # torch image: C X H X W\n        image_np = image.transpose((2, 0, 1))\n        image = np.repeat(image_np , 3, 0)\n        sample['image'] = torch.from_numpy(image).float()\n        sample['mask'] = torch.from_numpy(mask).float()\n        sample['class'] = torch.from_numpy(img_class).long()\n        return sample ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img = '../input/pneumothorax/dicom-images-train/1.2.276.0.7230010.3.1.2.8323329.5296.1517875187.462352/1.2.276.0.7230010.3.1.3.8323329.5296.1517875187.462351/1.2.276.0.7230010.3.1.4.8323329.5296.1517875187.462353.dcm'\nimg_file_name = os.path.basename(img)\nimg_name = os.path.splitext(img_file_name)[0]\nimage_infos = pydicom.dcmread(img)\nprint(\"ok\")\nimage_full = np.expand_dims(image_infos.pixel_array, axis=2)\nprint(image_full.shape)\nimage = cv2.resize(image_full, (input_size,input_size), interpolation=cv2.INTER_CUBIC)\nimg1 = np.expand_dims(image, axis=2)\nimg2 = img1.transpose((2, 0, 1)) \nimg3 = np.repeat(img2, 3, 0)\nprint( img2.shape)\nprint(img3.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Convert RLE to mask"},{"metadata":{"trusted":true},"cell_type":"code","source":"def rle2mask(rle, width, height):\n    mask= np.zeros(width* height)\n    array = np.asarray([int(x) for x in rle.split()])\n    starts = array[0::2]\n    lengths = array[1::2]\n\n    current_position = 0\n    for index, start in enumerate(starts):\n        current_position += start\n        mask[current_position:current_position+lengths[index]] = 1\n        current_position += lengths[index]\n\n    return mask.reshape(width, height)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading a processing data"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom albumentations import (\n    HorizontalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, RandomBrightnessContrast, IAAPiecewiseAffine,\n    IAASharpen, IAAEmboss, Flip, OneOf, Compose\n)\n\ndef strong_aug(p=0.5):\n    return Compose([\n        RandomRotate90(),\n        Flip(),\n        Transpose(),\n        OneOf([\n            IAAAdditiveGaussianNoise(),\n            GaussNoise(),\n        ], p=0.2),\n        OneOf([\n            MotionBlur(p=0.2),\n            MedianBlur(blur_limit=3, p=0.1),\n            Blur(blur_limit=3, p=0.1),\n        ], p=0.2),\n        ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=45, p=0.2),\n        OneOf([\n            OpticalDistortion(p=0.3),\n            GridDistortion(p=0.1),\n            IAAPiecewiseAffine(p=0.3),\n        ], p=0.2),\n        OneOf([\n            CLAHE(clip_limit=2),\n            IAASharpen(),\n            IAAEmboss(),\n            RandomBrightnessContrast(),\n        ], p=0.3),\n        HueSaturationValue(p=0.3),\n    ], p=p)\n\n\n\n\n\n\ndataset = SIIMDataset('../input/pneumothorax/train-rle.csv','../input/pneumothorax/dicom-images-train', transform=data_transform)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_workers = 4\nbatch_size = 16\nvalidation_split = 0.2\n\ndataset_size = len(dataset)\nindices = list(range(dataset_size))\nsplit = int(np.floor(validation_split * dataset_size))\ntrain_indices, val_indices = indices[split:], indices[:split]\n\n# Creating PT data samplers and loaders:\ntrain_sampler = SubsetRandomSampler(train_indices)\nvalid_sampler = SubsetRandomSampler(val_indices)\n\ntrain_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, sampler=train_sampler)\nvalidation_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, num_workers=num_workers,sampler=valid_sampler)\n\ndataloaders = {'train': train_loader,'val': validation_loader}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Define model"},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\n#Importing Resnet50 with pretrained weights\nmodel = torchvision.models.resnet50(pretrained=True)\n\nfor param in model.parameters():\n    param.requires_grad = False\n\nfc_in = model.fc.in_features\nfc_layers = nn.Sequential(\n                nn.Linear(fc_in, 2),\n                nn.Dropout(0.3),\n                nn.Softmax(),\n            )\n\n\n\nmodel.fc = fc_layers\nmodel","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(model, dataloaders, criterion, optimizer, num_epochs=25):\n    since = time.time()\n\n    val_acc_history = []\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for i,data in enumerate(dataloaders[phase]):\n                inputs = data['image'].to(device)\n                labels = data['class'].to(device)\n                \n                labels = labels.squeeze(1)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    # Get model outputs and calculate loss\n                    \n                    outputs = model(inputs)\n                    if (i<5):\n                        print(labels)\n                        print(torch.max(outputs,1))\n                    loss = criterion(outputs, labels)\n\n                    _, preds = torch.max(outputs, 1)\n                    \n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n            print(\">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n\n            # deep copy the model\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n            if phase == 'val':\n                val_acc_history.append(epoch_acc)\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model, val_acc_history","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\ntorch.cuda.empty_cache()\nmodel = model.to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(),  lr=0.0001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)\nmodel_final, val_acc_history = train_model(model, dataloaders, criterion, optimizer, num_epochs=10)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.2"}},"nbformat":4,"nbformat_minor":1}