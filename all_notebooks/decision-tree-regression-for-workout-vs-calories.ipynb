{"cells":[{"metadata":{},"cell_type":"markdown","source":"Tree Model for predicting the continuous variable target"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\n# importing libraries \nfrom sklearn.ensemble import VotingClassifier ,BaggingClassifier, ExtraTreesClassifier, RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier,GradientBoostingClassifier\nfrom sklearn.metrics import accuracy_score \nfrom numpy import mean,std\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import cross_val_score,RepeatedStratifiedKFold,train_test_split\nfrom sklearn.linear_model import LogisticRegression,RidgeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom matplotlib import pyplot\nfrom sklearn.datasets import load_wine,load_iris\nfrom matplotlib.pyplot import figure\nfigure(num=2, figsize=(16, 12), dpi=80, facecolor='w', edgecolor='k')\nimport xgboost as xgb\nfrom sklearn.feature_selection import SelectKBest,f_regression\nfrom sklearn.linear_model import LinearRegression,BayesianRidge,ElasticNet,Lasso,SGDRegressor,Ridge\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.preprocessing import LabelEncoder,OneHotEncoder,RobustScaler,StandardScaler\nfrom sklearn.pipeline import make_pipeline,Pipeline\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.decomposition import PCA,KernelPCA\nfrom sklearn.ensemble import ExtraTreesRegressor,GradientBoostingRegressor,RandomForestRegressor,VotingClassifier\nfrom sklearn.model_selection import cross_val_score,KFold,GridSearchCV,RandomizedSearchCV,StratifiedKFold,train_test_split\nfrom sklearn.base import BaseEstimator,clone,TransformerMixin,RegressorMixin\nfrom sklearn.svm import LinearSVR,SVR\n#import xgboost \nfrom xgboost import XGBRegressor\n#Import Pandas\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom scipy.stats import skew\nfrom scipy.stats.stats import pearsonr\n%matplotlib inline\nseed = 1075\nnp.random.seed(seed)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"\nexercise_data = pd.read_csv( '../input/exercise.csv' )\ncalories_data = pd.read_csv( '../input/calories.csv' )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"exercise_data.head() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"calories_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.merge(exercise_data,calories_data,on='User_ID', how='left')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To determine whether this is a regression problem we should first determine whether the relationship is linear"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(df,kind = \"scatter\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"94c72204-5d35-4e38-b95e-b66d9b9b1afe","_uuid":"7361785c7681e524d69d1c731634addbac974964","trusted":true},"cell_type":"code","source":"# in the scatter plot of duration vs calories and heart rate vs calories the relationship\n# was curved upward (not linear)\n# feature engineering:  add squared duration and heart rate to try a better fit with calories\ndf = df.assign( squared_duration = df[ 'Duration' ] ** 2 )\ndf = df.assign( squared_heart_rate = lambda x: x[ 'Heart_Rate' ] ** 2 )\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(df,kind = \"scatter\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4f54bd7f-734b-4ce9-abfb-9517f8776ecd","_uuid":"a7c4ca707fc60eb061e33a0384c55c7ed862ed63","trusted":true},"cell_type":"code","source":"# since we don't want the prediction to be negative calories, \n# convert calories to natural logarithm to always get a positive number\nimport numpy as np\ndf = df.assign( log_Calories = lambda x: \n                                 np.log( x[ 'Calories' ] ) )\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"585cc43a-0948-4061-9d29-305b36480c03","_uuid":"dcc6abaeb4243dd2c2ccb4b431e50130dde6d347","trusted":true},"cell_type":"code","source":"# scale numbers with normal distribution using z-score\nfrom scipy.stats import zscore\n\ndf = df.assign( zscore_body_temp = zscore( df[ 'Body_Temp' ] ) )\ndf = df.assign( zscore_height = zscore( df[ 'Height' ] ) )\ndf = df.assign( zscore_weight = zscore( df[ 'Weight' ] ) )\ndf = df.assign( zscore_squared_heart_rate = zscore( df[ 'squared_heart_rate' ] ) )\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b5135feb-8971-48de-ba98-ee577dd6a05b","_uuid":"2e06322f833a5772f1531c91831b24f68bdb52d9","trusted":true},"cell_type":"code","source":"# scale non-normal columns (age, squared_duration) using Min-Max \nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\n\n# NOTE:  joined_data[ ['Age', 'squared_duration'] ] produces a copy, loc doesn't\nminMaxData = pd.DataFrame( scaler.fit_transform( df.loc[ :, ['Age','squared_duration'] ] )\n                         , columns = [ 'minMaxAge', 'minMaxSquaredDuration' ] )\ndf = pd.concat( [ df, minMaxData ], axis = 1, join = 'inner' )\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"77d73a52-3791-4e79-b23e-caa4ea23a72a","_uuid":"f0b6f304ad763846f67d8a4051be5c76935fa094","trusted":true},"cell_type":"code","source":"# what to do with Gender (string binary categorical variable)?\n# convert to zero (male) and one (female)\n# trick:  first convert to boolean (Gender==female) , then to int by adding 0\ndf = df.assign( numeric_gender = 0 + ( df[ 'Gender' ] == 'female' ) )\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"dd3911c9-efcf-4b4a-8fc9-347a56760029","_uuid":"e82bf7e4d053e9d87c376260b22b8b35e4614561","trusted":true},"cell_type":"code","source":"# exclude User_ID and log_Calories from the prediction model (they're not features)\ndel df[ 'User_ID' ]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0eea91ae-98b9-4dcf-9306-258e10f62627","_uuid":"26701aea8c41f0935b32a9085d7396b1cb2c5539","trusted":true},"cell_type":"code","source":"ageDF = df[ 'Age' ]\nheartRateDF = df[ 'Heart_Rate' ]\n\n# remove unneeded columns\n\n# remove Duration and Heart_Rate\ndel df[ 'Duration' ]\ndel df[ 'Heart_Rate' ]\ndel df[ 'Calories' ]\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.pop( 'Body_Temp' )\ndf.pop( 'Height' )\ndf.pop( 'Weight' )\ndf.pop( 'squared_heart_rate' )\ndf.pop( 'Age' )\ndf.pop( 'squared_duration' )\ndf.pop( 'Gender' )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"568781a2-8f24-4f51-adf3-0767cd5e2e0f","_uuid":"5c941bc0f5e5cb9950976d1b32690d8d40f9180a","trusted":true},"cell_type":"code","source":"# split data into test and training\n\nfrom sklearn.model_selection import train_test_split\nX = df.drop('log_Calories',axis = 1)\ny = df['log_Calories']\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.6, random_state=42)\nX_train.shape, X_test.shape\n\n#train_X,test_X,train_Y,test_Y = train_test_split( df, test_size = 0.3 )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\ndt_model = DecisionTreeRegressor(random_state=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dt_model.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dt_model.score(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dt_model.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = dt_model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predctn =pd.DataFrame({'Actual':y_test, 'Predicted':y_pred})\npredctn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"As you can compare the predicted and actual target variables are very closer. The model is said to perform well on unseen data. "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_model = RandomForestRegressor()\nrf_model.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_model.score(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_model.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_rf = rf_model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_pred =pd.DataFrame({'Actual':y_test, 'Predicted':y_pred_rf})\nrf_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Random forest is also said to give maximum accuracy of predictions"},{"metadata":{},"cell_type":"markdown","source":"The model evaluation metrics for regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error, r2_score\n# The mean squared error, The MSE is a measure of the quality of an estimatorâ€”it is always non-negative, and values closer to zero are better.\nprint(\"Mean squared error Random Forest: %.2f\"% mean_squared_error(y_test, y_pred_rf))\nprint(\"Mean squared error Decision Tree: %.2f\"% mean_squared_error(y_test, y_pred))\n\n# Explained variance score: 1 is perfect prediction\nprint('Test Variance score Random Forest: %.2f' % r2_score(y_test, y_pred_rf))\nprint('Test Variance score Decision Tree: %.2f' % r2_score(y_test, y_pred))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}