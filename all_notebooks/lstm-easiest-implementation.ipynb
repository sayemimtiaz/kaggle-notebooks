{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Stock Market Prediction And Forecasting Using Stacked LSTM"},{"metadata":{},"cell_type":"markdown","source":"### Stock Price Prediction by using L.S.T.M  (univariate)\n1. #### Preparing the most Recent data for stock price prediction\n2. #### Understanding L.S.T.M\n3. #### Preparing the data in L.S.T.M format (with 60 days lookback)\n4. #### Creating L.S.T.M netword using Keras \n5. #### Creating a Training and Test and Validation Data\n6. #### Future prediction for 30 upcoming days \n\n##### Author - Abhishek Jaiswal"},{"metadata":{"trusted":true},"cell_type":"code","source":"# importing the necessary library\n%config Completer.use_jedi = False # if autocompletion doesnot work in kaggle notebook | hit tab\nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nsns.set()\nplt.style.use('fivethirtyeight')\n%config InlineBackend.figure_format = 'retina'\nimport warnings\nwarnings.filterwarnings('ignore') # igoring any kind of warning if comes \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas_datareader as web\ndf = web.DataReader('AAPL', data_source='yahoo',start = '2013-01-01',end = '2018-01-01')\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From here we can see our data has 6 columns:\n\nDate: The date of recorded data\n\nOpen: The price when stock market open\n\nHigh: The highest price price of date\n\nLow: The lowest price point of date\n\nVolumn: Total Sale of stock on that date\n\nFrom this point we going to define our goal is to predict the close price of the given date from test data"},{"metadata":{},"cell_type":"markdown","source":"### Visualisation "},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (15,5))\nax.plot(df['Open'])\nax.set_title(\"Google Opening Prices\")\nax.set_xlabel(\"Time (oldest -> latest)\")\nax.set_ylabel(\"Stock Opening Price\")\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nplt.figure(figsize=(18, 8))\nplt.plot(df['Close'])\nplt.title(\"Google Closing Prices\")\nplt.xlabel(\"Time (oldest-> latest)\")\nplt.ylabel(\"Stock Hightest Points\")\nplt.show()\n# here between  graphs we have 180 days gap\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(18, 8))\nplt.plot(df['Volume'])\nplt.title(\"Volume of stocks sold\")\nplt.xlabel(\"Time (oldest-> latest)\")\nplt.ylabel(\"Volume of stocks traded\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nplt.figure(figsize=(15,5))\nsns.lineplot(data=df[['High','Low']],linewidth=2)\nplt.grid(True)\nplt.show","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Here we have to predict closing price so first we will train closing price sequence into lstm"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"data = df['Close'].values\nlen(data)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# splitting the data for training and prediction purpose \ntrain_len = int(np.ceil(len(data)*0.9))\ntrain_data = data[0:train_len]\nlen(train_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Scaling the data by using min max scaler "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range=(0,1))\ntrain_data_scaled = scaler.fit_transform(train_data.reshape(-1,1))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# so far we have scaled our data for training and left one part for prediction \n# now lets prepare the data for lstm format \n# now lets make a lookup data for rnn with 100 days lookback \n# creating a lookback data of 100 days\nX_input = []\ny_input = []\n\nfor i in range(100, len(train_data_scaled)):\n    X_input.append(train_data_scaled[i-100:i,0])\n    y_input.append(train_data_scaled[i,0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_input,y_input = np.array(X_input),np.array(y_input) # converting into arrays \nX_input.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### from training data we are taking out 20 samples for validation data which we gonna use while training our model"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = X_input[20:]\ny_train = y_input[20:]\nX_valid = X_input[:20] # validation data of 10 values \ny_valid = y_input[:20] # validation data of 10 samples which will be used while training","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"print(X_train.shape,X_valid.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Here training data is in 2D we have to convert into 3D for R.N.N lstm\n3rd axis will be the number of features are we taking"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = np.reshape(X_train,(X_train.shape[0],X_train.shape[1],1)) # 1 means 1 feature we are taking\nX_valid = np.reshape(X_valid,(X_valid.shape[0],X_valid.shape[1],1))\nprint(X_train.shape,X_valid.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Now lets create L.S.T.M model by using keras"},{"metadata":{"trusted":true},"cell_type":"code","source":"# now creating L.S.T.M \nfrom keras import Sequential\nfrom keras.layers import Dense, LSTM\n\nmodel = Sequential()\nmodel.add(LSTM(50, return_sequences= True, activation='relu', input_shape=(X_train.shape[1], 1)))\nmodel.add(LSTM(50, return_sequences=True, activation='relu'))\nmodel.add(LSTM(50))\nmodel.add(Dense(1))\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n\ncallbacks = [\n    EarlyStopping(patience=10, verbose=1),\n    ReduceLROnPlateau(factor=0.1, patience=3, min_lr=0.00001, verbose=1),\n    ModelCheckpoint('model.h5', verbose=1, save_best_only=True, save_weights_only=True)\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_valid, y_valid), callbacks=callbacks)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Now lets predict by our model \nbefore prediction we have to prepare our testing data which will be again with past 60 days lookback\n\nSteps involving for prediction of test data\n\nHere input data is just a past 100 days history \n\nwe will need past 100 days to predict one future day\n"},{"metadata":{},"cell_type":"markdown","source":"#### lets suppose we have no future data and only we have past 100 days data and on the basic of past data we will predict future"},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets first predict for single point daata\nlen(data[:train_len][-100:]) # this is how we can access last 100 days from our training data ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_point =  train_data_scaled[-100:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_point = np.array(test_point).reshape(1,100,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.predict(X_test_point)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_predicted_point = scaler.inverse_transform(model.predict(X_test_point))\ny_predicted_point","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Testing on the test data\n"},{"metadata":{},"cell_type":"markdown","source":"#### for one data prediction of future we need 60 days of past \n#### if we will predict one day by 60 days and if we try to predict more days on the past 60 days error will get increased over prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data  =  data[train_len-100:]\ntest_data_scaled = scaler.transform(np.array(test_data).reshape(-1,1))\nX_test = []\nfor i in range(100,len(test_data_scaled)):\n    X_test.append(test_data_scaled[i-100:i,0])\nX_test = np.array(X_test)\nX_test = X_test.reshape((X_test.shape[0],X_test.shape[1],1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = scaler.inverse_transform(model.predict(X_test))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"\n#Plot the data\ntrain = df[:train_len]\ntest = df[train_len:]\ntest['Prediction'] = prediction\n# visualisation \nplt.figure(figsize = (16,8))\nplt.title('Model')\nplt.ylabel('Close Price USD', fontsize = 18)\nplt.plot(train['Close'])\nplt.plot(test[['Close','Prediction']])\nplt.legend(['Train','Test','Prediction'], loc = 'lower right')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (16,8))\nplt.title('Model')\nplt.plot(test[['Close','Prediction']])\nplt.legend(['Test','Prediction'], loc = 'lower right')\nplt.show()\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}