{"cells":[{"metadata":{},"cell_type":"markdown","source":"# How to Create a Regular Expression to Extract Emoji in Python\n(Updated with version 13.1)\n\nA quick journey from the [raw emoji-test](\nhttps://unicode.org/Public/emoji/13.1/emoji-test.txt) text file, to a Python regular expression to extract all emoji. And yes, a CSV file that can be imported as a DataFrame for general use.\n\nThe dataset also provides additional functionality for emoji for the [advertools online marketing package](https://github.com/eliasdabbas/advertools): \n* As a DataFrame `emoji_df`\n* As a search option to search for emoji [`advertools.emoji_search`](https://advertools.readthedocs.io/en/master/advertools.emoji.html)\n* One of the `extract_` functions that [extract emoji](https://advertools.readthedocs.io/en/master/advertools.extract.html#advertools.extract.extract_emoji) from a text list, together with statistics about their occurences, categories, and sub-categories.\n\nHow they were extracted...\n\nI manually downloaded the file, and here we can open and inspect the first rows."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import re\nfrom collections import namedtuple, Counter\n\nwith open('../input/emoji-data-descriptions-codepoints/emoji-test.txt', 'rt') as file:\n    emoji_raw = file.read()\nprint(emoji_raw[:2800])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The first few lines explain some details about the file and how the data are represented. The remainder is like the last lines. Each line represents an emoji, and whenever there is a new group and/or sub-group, those are listed (on a line starting with # and the name of the group/sub-group), to show to group/sub-group, the following emoji belong to. \n\nWe will go through the lines, one by one, and extract the information that we need and then put them in an easy-to-use format (`namedtuple`) so we can then use them to create the regex and the CSV file.  \n\nA few things about emoji that need to be understood in order to get what we want done. \n\n# Single and multi code point emoji\n\nSome emoji can simply be thought of as regular characters."},{"metadata":{"trusted":true},"cell_type":"code","source":"print('\\U00000063')  # the lower-cae letter \"c\" for example","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('\\U0001F44D')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"But what about the similar emoji üëçüèø?  \nLet's first compare the two."},{"metadata":{"trusted":true},"cell_type":"code","source":"len('üëç'), len('üëçüèø')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ü§î"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('üëçüèø'[0], 'üëçüèø'[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import unicodedata\nunicodedata.name('üëç'), unicodedata.name('üëçüèø'[0]), unicodedata.name('üëçüèø'[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The generic yellow-colored emoji is basically one character. The others (with different skin tones), are two characters; the first is the same generic emoji, and the second is simply a coloring square. There are five skin tones available. \n\n# Long and short words in regular expressions \nAn important aspect of how regular expressions find their matches is that they are \"greedy\" (this mainly applies to regex-directed, and not text directed regex engines, which is what Python uses). One of the things that this means, is that when presented with several options, the regex is happy to find the first match and return it.  \nLet's say you want to find the words \"rest\", and \"restaurant\" in a document.  \nThe regex is striaghtforward. `rest|restaurant`. \nLet's see greediness in action:"},{"metadata":{"trusted":true},"cell_type":"code","source":"s = 'The rest of my friends are at the restaurant.'\nregex = re.compile('rest|restaurant')\nregex.findall(s)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The regex goes through the options from left to right, and returns the match if it finds one immediately. In this example, it found a match for \"rest\" in the second word of the sentence, and then found another match for \"rest\" in the last word. After finding the second match, the regex is now at the first \"a\" in \"restaurant\", because the regex has already 'consumed' the \"rest\" part of \"restaurant\".  \nIn a large text, you would get the false impression that there is no occurrence of the word \"restaurant\". The fix is easy. We simply put the long word(s) first, so the regex can check for their matches first. If it doesn't find a match (as it won't find in the first \"rest\"), then the regex will go on to try to match the second available option."},{"metadata":{"trusted":true},"cell_type":"code","source":"regex2 = re.compile('restaurant|rest')\nregex2.findall(s)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"thumbs_sentence = 'This is thumbs up: üëç, and this is thumbs up with dark skin tone: üëçüèø'\nthumbs_regex = re.compile('üëç|üëçüèø')\n\nthumbs_regex.findall(thumbs_sentence)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"thumbs_regex2 = re.compile('üëçüèø|üëç')\nthumbs_regex2.findall(thumbs_sentence)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since the dark tone thumbs up emoji is made up of two code points, and since the first one is made of one, we are faced with the same case of \"rest\" and \"restaurant\". The regex finds the first word from left to right, and returns it. As in the previous example, putting the longer word first, made sure that we check for it first, and solves the issue. \n\n\nHere are the two emoji represented by code points. You can see that the first part of each of the 'words' is the same. "},{"metadata":{"trusted":true},"cell_type":"code","source":"print('\\U0001F44D', '\\U0001F44D\\U0001F3FF')  # the U0001F44D code point exists in both","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are five skin tones, as well as four hair types. All of those fall under the group \"component\". Those emoji are not supposed to appear on their own, because they really don't mean anything. They function mainly as modifiers for the previous emoji, appearing right before them.  \nHere they are, and we will be skipping them when creating the final regex. "},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, line in enumerate(emoji_raw.splitlines()):\n    if '; component' in line:\n        print(i, line)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we create the data structure that will hold our emoji entries. We will use the `namedtuple` because it has a nice representation, telling us exactly what each element means, as well as giving us the ability to extract those elements by name, using dot notation `entry.name` or `entry.group` for example. "},{"metadata":{"trusted":true},"cell_type":"code","source":"EmojiEntry = namedtuple('EmojiEntry', ['codepoint', 'status', 'emoji', 'name', 'group', 'sub_group'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The following code goes through lines one by one, extracting the information that is needed, and appending each entry to `emoji_entries` which will be a list containing all of them.  \nI have annotated the code with some comments, and below elaborated a little more to clarify."},{"metadata":{"trusted":true},"cell_type":"code","source":"E_regex = re.compile(r' ?E\\d+\\.\\d+ ') # remove the pattern E<digit(s)>.<digit(s)>\nemoji_entries = []\n\nfor line in emoji_raw.splitlines()[32:]:  # skip the explanation lines\n    if line == '# Status Counts':  # the last line in the document\n        break\n    if 'subtotal:' in line:  # these are lines showing statistics about each group, not needed\n        continue\n    if not line:  # if it's a blank line\n        continue\n    if line.startswith('#'):  # these lines contain group and/or sub-group names\n        if '# group:' in line:\n            group = line.split(':')[-1].strip()\n        if '# subgroup:' in line:\n            subgroup = line.split(':')[-1].strip()\n    if group == 'Component':  # skin tones, and hair types, skip, as mentioned above\n        continue\n    if re.search('^[0-9A-F]{3,}', line):  # if the line starts with a hexadecimal number (an emoji code point)\n        # here we define all the elements that will go into emoji entries\n        codepoint = line.split(';')[0].strip()  # in some cases it is one and in others multiple code points\n        status = line.split(';')[-1].split()[0].strip() # status: fully-qualified, minimally-qualified, unqualified\n        if line[-1] == '#':\n            # The special case where the emoji is actually the hash sign \"#\". In this case manually assign the emoji\n            if 'fully-qualified' in line:\n                emoji = '#Ô∏è‚É£'\n            else:\n                emoji = '#‚É£'  # they look the same, but are actually different \n        else:  # the default case\n            emoji = line.split('#')[-1].split()[0].strip()  # the emoji character itself\n        if line[-1] == '#':  # (the special case)\n            name = '#'\n        else:  # extract the emoji name\n            split_hash = line.split('#')[1]\n            rm_capital_E = E_regex.split(split_hash)[1]\n            name = rm_capital_E\n        templine = EmojiEntry(codepoint=codepoint,\n                              status=status,\n                              emoji=emoji,\n                              name=name,\n                              group=group,\n                              sub_group=subgroup)\n        emoji_entries.append(templine)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"emoji_dict = {x.emoji: x for x in emoji_entries}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"emoji_dict['üòÜ'].emoji","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"emoji_entries[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"emoji_entries[0].emoji","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"emoji_entries[0].group, emoji_entries[0].sub_group","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here is a quick summary of the counts of the groups, sub-groups, and all group/sub-group combinations:"},{"metadata":{"trusted":true},"cell_type":"code","source":"Counter([x.group for x in emoji_entries])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sorted(Counter([x.sub_group for x in emoji_entries]).items(), key=lambda x: x[1], reverse=True)[:30]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Counter([' | '.join([x.group, x.sub_group]) for x in emoji_entries])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Emoji status\nIn case you are wondering about the status column, this is the explanation from the\n[Unicode official documentation:](http://unicode.org/reports/tr51/#def_qualified_emoji_character) \n\n>ED-17a. qualified emoji character ‚Äî An emoji character in a string that (a) has default emoji presentation or (b) is the first character in an emoji modifier sequence or (c) is not a default emoji presentation character, but is the first character in an emoji presentation sequence.  \n>ED-18. fully-qualified emoji ‚Äî A qualified emoji character, or an emoji sequence in which each emoji character is qualified.  \n>ED-18a. minimally-qualified emoji ‚Äî An emoji sequence in which the first character is qualified but the sequence is not fully qualified.  \n>ED-19. unqualified emoji ‚Äî An emoji that is neither fully-qualified nor minimally qualified."},{"metadata":{},"cell_type":"markdown","source":"As mentioned above, we need to handle single and multiple code point emoji slightly differently.  \nWe start by extracting the multi code points."},{"metadata":{"trusted":true},"cell_type":"code","source":"multi_codepoint_emoji = []\n\nfor code in [c.codepoint.split() for c in emoji_entries]:\n    if len(code) > 1:\n        # turn to a hexadecimal number zfilled to 8 zeros e.g: '\\U0001F44D'\n        hexified_codes = [r'\\U' + x.zfill(8) for x in code]  \n        hexified_codes = ''.join(hexified_codes)  # join all hexadecimal components \n        multi_codepoint_emoji.append(hexified_codes)\n\n# sorting by length in decreasing order is extremely important as demonstrated above\nmulti_codepoint_emoji_sorted = sorted(multi_codepoint_emoji, key=len, reverse=True)\n\n# join with a \"|\" to function as an \"or\" in the regex\nmulti_codepoint_emoji_joined = '|'.join(multi_codepoint_emoji_sorted)  \nmulti_codepoint_emoji_joined[:400]  # sample","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"single_codepoint_emoji = []\n\nfor code in [c.codepoint.split() for c in emoji_entries]:\n    if len(code) == 1:\n        single_codepoint_emoji.append(code[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Regex character ranges\n\nSince the single code point emoji are basically one character each, they can be treated as normal letters or numbers in the regex.  \nOne important feature of character classes is their ability to contain character ranges. \nIf I want to match a character that falls between A and F, there are two ways to define the character class: \n\n- `[ABCDEF]`\n- `[A-F]`\n\nThey effectively mean the same thing. The advantage of the second is that it is much more readable (imagine wanting to match the letters from A to T for example). It would be very difficult to read through and understand which letters are included. `[A-T]` is very easy to read.  \nI also believe there might be a slight performance boost with character ranges. Some regex engines do certain optimizations on their own, and I'm not aware of those details. But in general making two comparisons is way more efficient than making fifty.  \nFor example, you have the number 42, and want to check if it falls between 1 and 100. \nIn the character class case, you make to comparisons. You check if 42 >= 1 and 42 <=100.  \nIf you have all the numbers listed from 1 to 100, then you will have to make 42 comparisons to find out. On average, if you have a range of 100 numbers, you will be making fifty comparisons to find out. With larger ranges, this can obviously go very big.  \n\nBelow is the function `get_ranges`. It takes a list of integers, and returns a list of tuples, each representing the local minimum and maximum for any number of contiguous integers (numbers differing by 1).  \nFor example if I have the list `[1, 2, 3, 4, 6 7, 8, 10, 20]`, it will return `[(1, 4), (6, 8), (10, 10), (20, 20)]`\n\nThe numbers 1, 2, 3, and 4, can converted into a character range `[1-4]`, so do the numbers 6, 7, and 8. 10 and 20 are not part of a series of integers differing by one, so they are represented as single-number ranges. Later they will be used as single characters in the regex."},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_ranges(nums):\n    \"\"\"Reduce a list of integers to tuples of local maximums and minimums.\n\n    :param nums: List of integers.\n    :return ranges: List of tuples showing local minimums and maximums\n    \"\"\"\n    nums = sorted(nums)\n    lows = [nums[0]]\n    highs = []\n    if nums[1] - nums[0] > 1:\n        highs.append(nums[0])\n    for i in range(1, len(nums)-1):\n        if (nums[i] - nums[i-1]) > 1:\n            lows.append(nums[i])\n        if (nums[i + 1] - nums[i]) > 1:\n            highs.append(nums[i])\n    highs.append(nums[-1])\n    if len(highs) > len(lows):\n        lows.append(highs[-1])\n    return [(l, h) for l, h in zip(lows, highs)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We first convert single_codepoint_emoji to integers to make calculations easier\nsingle_codepoint_emoji_int = [int(x, base=16) for x in single_codepoint_emoji]\nsingle_codepoint_emoji_ranges = get_ranges(single_codepoint_emoji_int)\nsingle_codepoint_emoji_ranges[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"single_codepoint_emoji_raw = r''  # start with an empty raw string\nfor code in single_codepoint_emoji_ranges:\n    if code[0] == code[1]:  # in this case make it a single hexadecimal character\n        temp_regex =  r'\\U' + hex(code[0])[2:].zfill(8)\n        single_codepoint_emoji_raw += temp_regex\n    else:\n        # otherwise create a character range, joined by '-'\n        temp_regex = '-'.join([r'\\U' + hex(code[0])[2:].zfill(8), r'\\U' + hex(code[1])[2:].zfill(8)])\n        single_codepoint_emoji_raw += temp_regex\n\nsingle_codepoint_emoji_raw[:100]  # sample","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Final regex\nNow that we have created our sorted multi-code point characters, and generated the ranges for the single-code point emoji, we need to combine them together.  \nThe regex wil start with the longer 'words', which are emoji, represented by more than one character. These have already been sorted by length, in descending order. \nSingle-code point emoji have already been made into a character class, where some values are single characters, and some are character ranges. \n\nThe final regex will look something like this: \n\n`multi_code_point_emoji|[character_class_of_single_code_points]`\n\nIn more detail, this is how the first `multi_code_point_emoji` part will look like:\n\n`longest_multi_code_point|shorter_multiple_code_point|...|shortest_multiple_code_point`\n\nThis is how the character class part `[character_class_of_single_code_points]` will look like: \nFor simplicity I refer to `single_code_point` as `sp`. \n\n`[sp1sp2sp3sp4-sp20sp25sp500-sp600]` and so on. \n\nBelow we concatenate both regexes into one, and show the first and last 500 characters as a sample. "},{"metadata":{"trusted":true},"cell_type":"code","source":"all_emoji_regex = re.compile(multi_codepoint_emoji_joined + '|' +  r'[' + single_codepoint_emoji_raw + r']')\nall_emoji_regex.pattern[:500], all_emoji_regex.pattern[-500:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Testing\nWe need to know that our work is correct. It is easy to get it wrong, especially when we are talking about 3k+ characters, and especially that many of them are combinations of the others. \n\nAs a quick sanity check, let see how many characters were actually in the initial text file. Each emoji entry contained a semicolon, so let's count those: "},{"metadata":{},"cell_type":"markdown","source":"![](https://drive.google.com/uc?id=1cR0fsIlSFjT5yNz9QbJ-_BpcoqbSuWgE)"},{"metadata":{},"cell_type":"markdown","source":"* There are 4,591 semicolons in the file. One of them is part of the explanation on the first line, and remember that there were nine characters that we omitted, because they were basically modifiers. So the final number should be 4,591 - 1 - 9 = 4,581. \n\nNow we run `findall` by the combined final regex on a string that we create.  \nThis string is all the emoji characters in `emoji_entries` separated by spaces. Their number needs to be exactly 4,581. "},{"metadata":{"trusted":true},"cell_type":"code","source":"all_emoji_regex.findall(' '.join([x.emoji for x in emoji_entries])).__len__()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So far so good. Let's get some more assurance.\n\nThe code below goes through all the lines of the raw text file, as downloaded from the Unicode site.  \nFirst we define `count` as zero, and increment its value, every time we find a new match. This should add up to the same number 3,287.  \nWe also create a set `found_emoji` where we add every emoji we find to it. If we match a certain emoji more than once and add it to the set, it will be discarded, because sets only contain unique values. Again the length of this set, should be equal to our magic number. If not, it means we found duplicates. Or it means we are matching other things, if we get a higher number. \n\nLines 6-8 check if the length of the match is more than one, meaning the regex found more than one match in the line. We might be wrongly matching something more than once. It actually broke a few times, when I first ran it, until I fixed the issues.  \nOne final test is asserting that the name of the emoji (which we extract from `emoji_entries` is contained in the line in the raw text file, making sure that the names also correspond to the correct value, and extracted correctly. "},{"metadata":{"trusted":true},"cell_type":"code","source":"count = 0\nfound_emoji = set()\nfor line in emoji_raw.splitlines()[30:]:\n    match = all_emoji_regex.findall(line)\n    if match:\n        if len(match) > 1:\n            break\n        count += 1\n        found_emoji.add(match[0])\n        temp_name = [x.name for x in emoji_entries if x.emoji == match[0]][0]\n        assert temp_name in line\n\ncount, found_emoji.__len__()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## üéâ üéâ üéâ üéä üéä üéä üëç üëè üòâ\n\nTo save as a DataFrame, we can run the following code.  \nI made it semicolon-separated, as there were commas in the descriptions so this is easier. The I let `pandas` do the heavy lifting of converting back to comma-separated format. "},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('emoji_df.csv', 'wt') as file:\n    print('emoji;name;group;sub_group;codepoints', file=file)\n    for i, em in enumerate(emoji_entries):\n        print(f\"{em.emoji};{em.name};{em.group};{em.sub_group};{em.codepoint}\", file=file)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\npd.options.display.max_columns = None\n\nemoji_df = pd.read_csv('emoji_df.csv', sep=';')\nemoji_df.to_csv('emoji_df.csv', index=False)\nemoji_df = pd.read_csv('emoji_df.csv')\nemoji_df[:35]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Emoji in Real-life Data\nLet's see how we can use this regex on a tweet dataset containing five thousand tweets that contain the hashtag #JustDoIt."},{"metadata":{"trusted":true},"cell_type":"code","source":"justdoit = pd.read_csv('../input/5000-justdoit-tweets-dataset/justdoit_tweets_2018_09_07_2.csv')\njustdoit.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"The `word_frequency` function in `advertools` extracts words and counts their occurrences on an absolute and weighted basis. The function takes an optional `regex` parameter, whereby the function counts occurrences of matches of the regex (and not all words).  \nWe can now use the regex created, to extract and count emoji in our dataset. "},{"metadata":{"trusted":true},"cell_type":"code","source":"import advertools as adv\njustdoit_emoji_freq = (adv.word_frequency(justdoit['tweet_full_text'],\n                                          justdoit['user_followers_count'],\n                                          regex=all_emoji_regex.pattern))\njustdoit_emoji_freq.head(15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The `abs_freq` column shows how many times each emoji was used (simply count). While `wtd_freq` counts the number of followers of the person who tweeted the tweet for each occurrence.  \nIn sample above you can see the monkey emoji being used only once, but since the user who tweeted has 2.9M followers, it has the highest `wtd_freq` of all emoji.  \n\nUsing the emoji_dict that we created we can show names, groups, and sub-groups of each emoji:"},{"metadata":{"trusted":true},"cell_type":"code","source":"justdoit_emoji_freq['name'] = [emoji_dict[word].name if word != 'Ô∏è' else '' for word in justdoit_emoji_freq['word']]\njustdoit_emoji_freq['group'] = [emoji_dict[word].group if word != 'Ô∏è' else '' for word in justdoit_emoji_freq['word']]\njustdoit_emoji_freq['sub_group'] = [emoji_dict[word].sub_group if word != 'Ô∏è' else '' for word in justdoit_emoji_freq['word']]\njustdoit_emoji_freq[:40]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The previous table shows the frequencies per emoji.  \nWhat about the groups and sub-groups? \n\nWe do this next: "},{"metadata":{"trusted":true},"cell_type":"code","source":"(justdoit_emoji_freq\n .groupby('group')\n .agg({'abs_freq': 'sum', 'wtd_freq': 'sum'})\n .sort_values('wtd_freq', ascending=False)\n .style.format({'wtd_freq': '{:,.0f}'}))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note here that again, even though \"Smileys & Emotion\" emoji have been used 1,440 times and \"Animals & Nature\" only 38, the latter still ranks higher on a weighted basis.  \nThis is typical on social media. We often get a dataset that gets skewed by one tweet/user. "},{"metadata":{"trusted":true},"cell_type":"code","source":"(justdoit_emoji_freq\n .groupby('sub_group')\n .agg({'abs_freq': 'sum', 'wtd_freq': 'sum'})\n .sort_values('wtd_freq', ascending=False)\n .head(20)\n .style.format({'wtd_freq': '{:,.0f}'}))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}