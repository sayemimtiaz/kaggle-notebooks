{"cells":[{"metadata":{},"cell_type":"markdown","source":"# \"Chainer\" doesn't work, use .....\n# [\"Predict the blossoming date by scikit-learn\"](https://www.kaggle.com/akioonodera/predict-the-blossoming-date-by-scikit-learn)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**1. Import training data**"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"import pandas as pd\ndata_csv = pd.read_csv(\"/kaggle/input/temperature-and-flower-status/hirosaki_temp_cherry_bloom.csv\")\ndf = pd.DataFrame(data_csv)\n\n# Split date into year,month,day\ndateList = df['date'].str.split('/', expand=True)\ndf['year'], df['month'], df['day'] = dateList[0], dateList[1], dateList[2]\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**2. Make up for missing 'flower_status' column**"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# o:Before blooming\n# 1:Bloom\n# 2:Full bloom\n# 3:Scatter\n\nnew_df = []\nfor i in range(len(df)):\n    year, month, day = df['year'][i], df['month'][i], df['day'][i]\n    temperature = df['temperature'][i]\n    flower_status = df['flower_status'][i]\n    if month == '1' and day == '1':\n        status = 0\n    else:\n        if flower_status == 'bloom':\n            status = 1\n        elif flower_status == 'full':\n            status = 2\n        elif flower_status == 'scatter':\n            status = 3\n    innerList = {'year':year, 'month':month, 'day':day, 'temperature':temperature, 'flower_status':status}\n    new_df.append(innerList)\nnew_df = pd.DataFrame(new_df)\nnew_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# Extract data from March 1 to May 31\nnew_df_2 = []\nfor i in range(len(new_df)):\n    month = new_df['month'][i]\n    if month == '3' or month == '4' or month == '5':\n        innerList = {'month':month, 'day':new_df['day'][i], 'temperature':new_df['temperature'][i], 'flower_status':new_df['flower_status'][i]}\n        new_df_2.append(innerList)\nnew_df_2 = pd.DataFrame(new_df_2)\nnew_df_2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# Add the cumulative temperature to the column\nnew_df_3 = []\nfor i in range(len(new_df_2)):\n    month, day = new_df_2['month'][i], new_df_2['day'][i]\n    if month == '3' and day == '1':\n        temp_accum = 0\n    temp = new_df_2['temperature'][i]\n    temp_accum += temp\n    status = new_df_2['flower_status'][i]\n    innerList = {'month':month, 'day':day, 'temperature':temp, 'temp_accum':temp_accum, 'flower_status':status}\n    new_df_3.append(innerList)\nnew_df_3 = pd.DataFrame(new_df_3)\nnew_df_3","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**3. Shape after dividing temperature data and flowering status**"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"x = pd.DataFrame(new_df_3.drop('flower_status', axis = 1))\nt = pd.DataFrame(new_df_3['flower_status'])\nx = np.array(x)\nt = np.array(t)\n\nt = t.ravel()\nx = x.astype('float32')\nt = t.astype('int32')\n\n# 中を確認\nprint('x shape:', x.shape) # (n, m)\nprint(x[:10])\nprint('t shape:', t.shape) # (n,)\nprint(t[:10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# TupleDataset\nfrom chainer.datasets import TupleDataset\ndataset = TupleDataset(x, t)\nfrom chainer.datasets import split_dataset_random\ntrain_val, test = split_dataset_random(dataset, int(len(dataset) * 0.8), seed=0)\ntrain, valid = split_dataset_random(train_val, int(len(train_val) * 0.7), seed=0)\n\nfrom chainer.iterators import SerialIterator\ntrain_iter = SerialIterator(train, batch_size=32, repeat=True, shuffle=True)\n\nprint(dataset[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**4. Learn with Chainer**"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"import chainer\nimport chainer.links as L\nimport chainer.functions as F\n\nclass Net(chainer.Chain):\n\n    def __init__(self, n_in=4, n_hidden=100, n_out=4):\n        super().__init__()\n        with self.init_scope():\n            self.l1 = L.Linear(n_in, n_hidden)\n            self.l2 = L.Linear(n_hidden, n_hidden)\n            self.l3 = L.Linear(n_hidden, n_out)\n\n    def forward(self, x):\n        h = F.relu(self.l1(x))\n        h = F.relu(self.l2(h))\n        h = self.l3(h)\n        return h\n\nnet = Net()\n\nfrom chainer import optimizers\nfrom chainer.optimizer_hooks import WeightDecay\noptimizer = optimizers.Adam(alpha=0.0001,\n                            beta1=0.9,\n                            beta2=0.999,\n                            eps=1e-08,\n                            eta=1.0,\n                            weight_decay_rate=0.00001,\n                            amsgrad=False,\n                            adabound=False,\n                            final_lr=0.1,\n                            gamma=0.001)\noptimizer.setup(net)\n\ngpu_id = 0\nn_epoch = 2500\n\nnet.to_gpu(gpu_id)\n\nresults_train, results_valid = {}, {}\nresults_train['loss'], results_train['accuracy'] = [], []\nresults_valid['loss'], results_valid['accuracy'] = [], []\n\ntrain_iter.reset()\n\ncount = 1\n\nfor epoch in range(n_epoch):\n    while True:\n        train_batch = train_iter.next()\n        x_train, t_train = chainer.dataset.concat_examples(train_batch, gpu_id)\n        y_train = net(x_train)\n        loss_train = F.softmax_cross_entropy(y_train, t_train)\n        acc_train = F.accuracy(y_train, t_train)\n        net.cleargrads()\n        loss_train.backward()\n        optimizer.update()\n        count += 1\n\n        if train_iter.is_new_epoch:\n            with chainer.using_config('train', False), chainer.using_config('enable_backprop', False):\n                x_valid, t_valid = chainer.dataset.concat_examples(valid, gpu_id)\n                y_valid = net(x_valid)\n                loss_valid = F.softmax_cross_entropy(y_valid, t_valid)\n                acc_valid = F.accuracy(y_valid, t_valid)\n            loss_train.to_cpu()\n            loss_valid.to_cpu()\n            acc_train.to_cpu()\n            acc_valid.to_cpu()\n            if epoch % 10 == 0:\n                print('epoch: {}, iteration: {}, loss(train): {:.4f}, loss(valid): {:.4f}, '\n                'acc(train): {:.4f}, acc(valid): {:.4f}'.format(\n                    epoch, count, loss_train.array.mean(),loss_valid.array.mean(),\n                    acc_train.array.mean(), acc_valid.array.mean()))\n    \n            results_train['loss'].append(loss_train.array)\n            results_train['accuracy'].append(acc_train.array)\n            results_valid['loss'].append(loss_valid.array)\n            results_valid['accuracy'].append(acc_valid.array)\n\n            break\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Graph\nimport matplotlib.pyplot as plt\n\n# lose\nplt.plot(results_train['loss'], label='train')\nplt.plot(results_valid['loss'], label='valid')\nplt.title('Graph(loss)')\nplt.xlabel('epoch')\nplt.ylabel('loss')\nplt.legend()\nplt.show()\n\n# accuracy\nplt.plot(results_train['accuracy'], label='train')\nplt.plot(results_valid['accuracy'], label='valid')\nplt.title('Graph(accuracy)')\nplt.xlabel('epoch')\nplt.ylabel('accuracy')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Calculate loss and accuracy\nx_test, t_test = chainer.dataset.concat_examples(test, device=gpu_id)\nwith chainer.using_config('train', False), chainer.using_config('enable_backprop', False):\n    y_test = net(x_test)\n    loss_test = F.softmax_cross_entropy(y_test, t_test)\n    acc_test = F.accuracy(y_test, t_test)\nprint('test loss: {:.4f}'.format(loss_test.array.get()))\nprint('test accuracy: {:.4f}'.format(acc_test.array.get()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# Save network\nnet.to_cpu()\nchainer.serializers.save_npz('net.npz', net)\n\n# Check\n!ls net.npz","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**5. Import data to predict**"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# data from Japan Meteorological Agency (Actual and 2-week forecast)\nimport pandas as pd\npre_csv = pd.read_csv('/kaggle/input/hirosaki-this-year/hirosaki_this_year.csv')\npre_df = pd.DataFrame(pre_csv)\n# Split date into year,month,day\ndateList = pre_df['date'].str.split('/', expand=True)\npre_df['year'], pre_df['month'], pre_df['day'] = dateList[0], dateList[1], dateList[2]\npre_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# Fill in missing values by predicting future temperatures from differences between past average and this year\nnew_df_4 = []\nfor i in range(len(new_df)):\n    year, month, day, temperature = new_df['year'][i], new_df['month'][i], new_df['day'][i], new_df['temperature'][i]\n    # cut Feb 29\n    if month == '2' and day == '29':\n        dummy = ''\n    else:\n        innerList = {'year':year, 'month':month, 'day':day, 'temperature':temperature}\n        new_df_4.append(innerList)\nnew_df_4 = pd.DataFrame(new_df_4)\nary_diff = []\nfor i in range(len(pre_df)):\n    m = pre_df['month'][i]\n    d = pre_df['day'][i]\n    if m == '2' and d == '29':\n        dummy = ''\n    else:\n        if pd.isnull(pre_df['temperature'][i]):\n            break\n        else:\n            # Temperature of this year\n            pre_temp = pre_df['temperature'][i]\n            # Average temperature of past year(Same month and same day)\n            df_m = new_df_4[new_df_4['month'] == m]\n            df_m_d = df_m[df_m['day'] == d]\n            temp_mean = df_m_d['temperature'].mean()\n            # Difference between this year and average\n            diff = pre_temp - temp_mean\n            ary_diff.append(diff)\nary_diff = pd.DataFrame(ary_diff)\n# Overall average of difference\ndiff_mean = ary_diff.mean()\npre_df_2 = []\nfor i in range(len(pre_df)):\n    y = pre_df['year'][i]\n    m = pre_df['month'][i]\n    d = pre_df['day'][i]\n    if pd.isnull(pre_df['temperature'][i]):\n        # Predicted temperature\n        df_m = new_df_4[new_df_4['month'] == m]\n        df_m_d = df_m[df_m['day'] == d]\n        temp_mean = df_m_d['temperature'].mean()\n\n\n#--------------------------------------------------------\n        weight = 1\n        # Change as needed\n        # Usually 1\n#--------------------------------------------------------\n\n\n        add = int(diff_mean * weight * 1000) / 1000\n        temperature = temp_mean + add\n    else:\n        # Actual temperature\n        temperature = pre_df['temperature'][i]\n    inner_dic = {'year':y, 'month':m, 'day':d, 'temperature':temperature}\n    pre_df_2.append(inner_dic)\npre_df_2 = pd.DataFrame(pre_df_2)\npre_df_2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print('Average temperature rise:', add)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# Add the cumulative temperature to the column\nnew_pre_df = []\ntemp_accum = 0\nfor i in range(len(pre_df)):\n    year, month, day = pre_df_2['year'][i], pre_df_2['month'][i], pre_df_2['day'][i]\n    if int(month) >= 3:\n        temperature = pre_df_2['temperature'][i]\n        temp_accum += temperature\n        innerList = [month, day, temperature, temp_accum]\n        new_pre_df.append(innerList)\nnew_pre_df = pd.DataFrame(new_pre_df)\nnew_pre_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**6. Predict using the network**"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":false},"cell_type":"code","source":"import chainer\nimport chainer.links as L\nimport chainer.functions as F\n\nclass newNet(chainer.Chain):\n    def __init__(self,n_in=4, n_hidden=100, n_out=4):\n        super().__init__()\n        with self.init_scope():\n            self.l1 = L.Linear(n_in, n_hidden)\n            self.l2 = L.Linear(n_hidden, n_hidden)\n            self.l3 = L.Linear(n_hidden, n_out)\n\n    def forward(self, x):\n        h = F.relu(self.l1(x))\n        h = F.relu(self.l2(h))\n        h = self.l3(h)\n        return h\n\nloaded_net = newNet()\n\nchainer.serializers.load_npz('net.npz', loaded_net)\n\nimport numpy as np\n\nnew_pre_df = np.array(new_pre_df)\nnew_pre_df = new_pre_df.astype('float32')\nwith chainer.using_config('train', False), chainer.using_config('enable_backprop', False):\n    result = loaded_net(new_pre_df)\n\n# If the status returns or jumps, it is judged as an error\n# If the learning rate is low, no results are displayed\ncount_bud, count_bloom, count_full, count_scatter = 0, 0, 0, 0\ndate_bloom, date_full, date_scatter = 'none', 'none', 'none'\nyear = pre_df['year'][0]\nfor i in range(len(new_pre_df)):\n    month = new_pre_df[i][0]\n    day = new_pre_df[i][1]\n    predict = np.argmax(result[i,:].array)\n    if i == 0:\n        count_bud += 1\n    else:\n        pre_predict = np.argmax(result[i - 1,:].array)\n        if predict != pre_predict:\n            if predict == 0:\n                count_bud += 1\n            elif predict == 1:\n                count_bloom += 1\n                date_bloom = '{}/{}/{}'.format(int(year), int(month), int(day))\n            elif predict == 2:\n                count_full += 1\n                date_full = '{}/{}/{}'.format(int(year), int(month), int(day))\n            elif predict == 3:\n                count_scatter += 1\n                date_scatter = '{}/{}/{}'.format(int(year), int(month), int(day))\n#    print(predict)\nif count_bud > 1:\n    print('ERROR !! (Over count \"Before blooming :', count_bud, '\")')\nif count_bloom > 1:\n    print('ERROR !! (Over count \"Bloom :', count_bloom, '\")')\nif count_full > 1:\n    print('ERROR !! (Over count \"Full :', count_full, '\")')\nif count_scatter > 1:\n    print('Error !! (Over count \"Scatter :', count_scatter, '\")')\nif count_bud == 1 and count_bloom == 1 and count_full == 1 and count_scatter == 1:\n    ratio_loss = loss_test.array.get()\n    ratio_acc = acc_test.array.get()\n    \n    # Set accuracy threshold\n    specified_loss = 0.1\n    specified_acc = 0.95\n    \n    if ratio_loss < specified_loss and ratio_acc > specified_acc:\n        print('Congratulations, the prediction is successful !!')\n        print('Bloom  :', date_bloom)\n        print('Full   :', date_full)\n        print('Scatter:', date_scatter)\n        # Time stamp\n        import time, datetime\n        today = datetime.datetime.fromtimestamp(time.time())\n        print(today.strftime('Time stamp: %Y/%m/%d %H:%M:%S (UTC)'))\n    else:\n        print('Low learning rate !!')\n        print('Accuracy rate :', ratio_acc, '(Specified rate :', specified_acc, ')')\n        print('Loss rate :', ratio_loss, '(Specified rate :', specified_loss, ')')\nelse:\n    print('ERROR !! (Missing status)')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}