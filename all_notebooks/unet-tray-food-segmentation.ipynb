{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nfrom keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization\nfrom keras.layers.merge import concatenate\nfrom keras.models import Model, load_model\nfrom keras.callbacks import LearningRateScheduler\nfrom keras import backend as K\nimport tensorflow as tf\n\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_path = sorted(os.listdir(\"../input/tray-food-segmentation/TrayDataset/TrayDataset/XTrain\"))\nlabel_path = sorted(os.listdir(\"../input/tray-food-segmentation/TrayDataset/TrayDataset/yTrain\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_images(inputdir, inputpath, imagesize):\n    imglist = []\n    \n    for i in range(len(inputpath)):\n        img = cv2.imread(inputdir+inputpath[i], cv2.IMREAD_COLOR) \n        img = cv2.resize(img, (imagesize, imagesize), interpolation = cv2.INTER_AREA)\n        img = img[::-1] \n        imglist.append(img)\n        \n    return imglist","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Enhance the shading of the original segmentation image"},{"metadata":{"trusted":true},"cell_type":"code","source":"def segment(label, img_size):\n    labels = []\n    \n    for i in range(len(label)):\n        tmp = label[i].flatten()\n        for j in range(len(tmp)):\n            if tmp[j] > 10:\n                tmp[j] = 200\n                \n        labels.append(tmp.reshape(img_size,img_size,3))\n        \n    return labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IMAGE_SIZE = 128\n\nimage = load_images(\"../input/tray-food-segmentation/TrayDataset/TrayDataset/XTrain/\", image_path, IMAGE_SIZE)\nbefore_label = load_images(\"../input/tray-food-segmentation/TrayDataset/TrayDataset/yTrain/\", label_path, IMAGE_SIZE)\n\nafter_label = segment(before_label, IMAGE_SIZE)\n\nimage /= np.max(image)\nafter_label /= np.max(after_label)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualize train images"},{"metadata":{"trusted":true},"cell_type":"code","source":"num = 50\n\nplt.figure(figsize=(14, 7))\n\nax = plt.subplot(1, 2, 1)\nplt.imshow(np.squeeze(image[num]))\n\nax = plt.subplot(1, 2, 2)\nplt.imshow(np.squeeze(after_label[num]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create model Unet"},{"metadata":{"trusted":true},"cell_type":"code","source":"def Unet():\n    input_img = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n\n    enc1 = Conv2D(128, kernel_size=3, strides=1, activation=\"relu\", padding=\"same\")(input_img)\n    enc1 = BatchNormalization()(enc1)\n    enc1 = Conv2D(128, kernel_size=3, strides=1, activation=\"relu\", padding=\"same\")(enc1)\n    enc1 = BatchNormalization()(enc1)\n    down1 = MaxPooling2D(pool_size=2, strides=2)(enc1)\n    \n    enc2 = Conv2D(256, kernel_size=3, strides=1, activation=\"relu\", padding=\"same\")(down1)\n    enc2 = BatchNormalization()(enc2)\n    enc2 = Conv2D(256, kernel_size=3, strides=1, activation=\"relu\", padding=\"same\")(enc2)\n    enc2 = BatchNormalization()(enc2)\n    down2 = MaxPooling2D(pool_size=2, strides=2)(enc2)\n\n    enc3 = Conv2D(512, kernel_size=3, strides=1, activation=\"relu\", padding=\"same\")(down2)\n    enc3 = BatchNormalization()(enc3)\n    enc3 = Conv2D(512, kernel_size=3, strides=1, activation=\"relu\", padding=\"same\")(enc3)\n    enc3 = BatchNormalization()(enc3)\n    down3 = MaxPooling2D(pool_size=2, strides=2)(enc3)\n    \n    enc4 = Conv2D(1024, kernel_size=3, strides=1, activation=\"relu\", padding=\"same\")(down3)\n    enc4 = BatchNormalization()(enc4)\n    enc4 = Conv2D(1024, kernel_size=3, strides=1, activation=\"relu\", padding=\"same\")(enc4)\n    enc4 = BatchNormalization()(enc4)\n    down4 = MaxPooling2D(pool_size=2, strides=2)(enc4)\n    \n    enc5 = Conv2D(2048, kernel_size=3, strides=1, activation=\"relu\", padding=\"same\")(down4)\n    enc5 = BatchNormalization()(enc5)\n    enc5 = Conv2D(2048, kernel_size=3, strides=1, activation=\"relu\", padding=\"same\")(enc5)\n    enc5 = BatchNormalization()(enc5)\n\n    up4 = UpSampling2D(size=2)(enc5)\n    dec4 = concatenate([up4, enc4], axis=-1)\n    dec4 = Conv2D(1024, kernel_size=3, strides=1, activation=\"relu\", padding=\"same\")(dec4)\n    dec4 = BatchNormalization()(dec4)\n    dec4 = Conv2D(1024, kernel_size=3, strides=1, activation=\"relu\", padding=\"same\")(dec4)\n    dec4 = BatchNormalization()(dec4)\n    \n    up3 = UpSampling2D(size=2)(dec4)\n    dec3 = concatenate([up3, enc3], axis=-1)\n    dec3 = Conv2D(512, kernel_size=3, strides=1, activation=\"relu\", padding=\"same\")(dec3)\n    dec3 = BatchNormalization()(dec3)\n    dec3 = Conv2D(512, kernel_size=3, strides=1, activation=\"relu\", padding=\"same\")(dec3)\n    dec3 = BatchNormalization()(dec3)\n\n    up2 = UpSampling2D(size=2)(dec3)\n    dec2 = concatenate([up2, enc2], axis=-1)\n    dec2 = Conv2D(256, kernel_size=3, strides=1, activation=\"relu\", padding=\"same\")(dec2)\n    dec2 = BatchNormalization()(dec2)\n    dec2 = Conv2D(256, kernel_size=3, strides=1, activation=\"relu\", padding=\"same\")(dec2)\n    dec2 = BatchNormalization()(dec2)\n    \n    up1 = UpSampling2D(size=2)(dec2)\n    dec1 = concatenate([up1, enc1], axis=-1)\n    dec1 = Conv2D(128, kernel_size=3, strides=1, activation=\"relu\", padding=\"same\")(dec1)\n    dec1 = BatchNormalization()(dec1)\n    dec1 = Conv2D(128, kernel_size=3, strides=1, activation=\"relu\", padding=\"same\")(dec1)\n    dec1 = BatchNormalization()(dec1)\n    \n    dec1 = Conv2D(3, kernel_size=1, strides=1, activation=\"sigmoid\", padding=\"same\")(dec1)\n    \n    model = Model(input=input_img, output=dec1)\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Unet()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Metrics Iou"},{"metadata":{"trusted":true},"cell_type":"code","source":"def castF(x):\n    return K.cast(x, K.floatx())\n\ndef castB(x):\n    return K.cast(x, bool)\n\ndef iou_loss_core(true,pred):  #this can be used as a loss if you make it negative\n    intersection = true * pred\n    notTrue = 1 - true\n    union = true + (notTrue * pred)\n\n    return (K.sum(intersection, axis=-1) + K.epsilon()) / (K.sum(union, axis=-1) + K.epsilon())\n\ndef competitionMetric2(true, pred): #any shape can go - can't be a loss function\n\n    tresholds = [0.5 + (i*.05)  for i in range(10)]\n\n    #flattened images (batch, pixels)\n    true = K.batch_flatten(true)\n    pred = K.batch_flatten(pred)\n    pred = castF(K.greater(pred, 0.5))\n\n    #total white pixels - (batch,)\n    trueSum = K.sum(true, axis=-1)\n    predSum = K.sum(pred, axis=-1)\n\n    #has mask or not per image - (batch,)\n    true1 = castF(K.greater(trueSum, 1))    \n    pred1 = castF(K.greater(predSum, 1))\n\n    #to get images that have mask in both true and pred\n    truePositiveMask = castB(true1 * pred1)\n\n    #separating only the possible true positives to check iou\n    testTrue = tf.boolean_mask(true, truePositiveMask)\n    testPred = tf.boolean_mask(pred, truePositiveMask)\n\n    #getting iou and threshold comparisons\n    iou = iou_loss_core(testTrue,testPred) \n    truePositives = [castF(K.greater(iou, tres)) for tres in tresholds]\n\n    #mean of thressholds for true positives and total sum\n    truePositives = K.mean(K.stack(truePositives, axis=-1), axis=-1)\n    truePositives = K.sum(truePositives)\n\n    #to get images that don't have mask in both true and pred\n    trueNegatives = (1-true1) * (1 - pred1) # = 1 -true1 - pred1 + true1*pred1\n    trueNegatives = K.sum(trueNegatives) \n\n    return (truePositives + trueNegatives) / castF(K.shape(true)[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Metrics Dice"},{"metadata":{"trusted":true},"cell_type":"code","source":"def dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_val, T_train, T_val = train_test_split(image, after_label, test_size=0.2)\n\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=[dice_coef])\n\ninitial_learningrate=2e-3\n\ndef lr_decay(epoch):\n    if epoch < 10:\n        return initial_learningrate\n    else:\n        return initial_learningrate * 0.99 ** epoch\n    \ntraining = model.fit(X_train, T_train,epochs=30, batch_size=12, shuffle=True, validation_data=(X_val, T_val), verbose=1,callbacks=[LearningRateScheduler(lr_decay,verbose=1)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save(\"best_model.h5\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predict"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_path = os.listdir(\"../input/tray-food-segmentation/TrayDataset/TrayDataset/XTest\")\ntest_image = load_images(\"../input/tray-food-segmentation/TrayDataset/TrayDataset/XTest/\", test_path, IMAGE_SIZE)\n\ntest_image /= np.max(test_image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = model.predict(test_image,verbose=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualize Results"},{"metadata":{"trusted":true},"cell_type":"code","source":"n = 7\n\nplt.figure(figsize=(14, 7))\n\nax = plt.subplot(1, 2, 1)\nplt.imshow(np.squeeze(test_image[n]))\n\nax = plt.subplot(1, 2, 2)\nplt.imshow(np.squeeze(results[n]))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}