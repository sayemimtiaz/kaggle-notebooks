{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport re\nimport json\nimport math\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import figure\nimport seaborn as sns\n\nimport spacy\nfrom spacy.matcher import Matcher\n\nfrom tqdm import tqdm\n\nnlp = spacy.load(\"en_core_web_sm\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"debug = False\narticles = {}\nstat = { }\nfor dirpath, subdirs, files in os.walk('/kaggle/input'):\n    for x in files:\n        if x.endswith(\".json\"):\n            articles[x] = os.path.join(dirpath, x)        \ndf = pd.read_csv('/kaggle/input/CORD-19-research-challenge/metadata.csv')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Current Research Status\n\nThe curent research notebook is focusin on understanding the behavior of the coronavirus by scraping the provided articles. The current version of the notebook is providing information about the following:\n* Symptoms\n* Incubation Period\n* Quarantine\n* Transmission Methods\n* Reported Gender Percentiles\n* Reported Fatality Rate\n* Relevant gene sequences, appearance in sentence and file\n* False Positives / Negatives\n* Antigen references / literature\n* Added Pandemic Simulator App\n\nThe mining is running on a custom rule matching engine built on top of Spacy in order to use POS in terms identification.\n* For performance concerns most of the searches were perfomed on a filtered dataset - if you wish to have a more accurate response replace filtered_df with df*"},{"metadata":{},"cell_type":"markdown","source":"# Simulator\n\nIn order to understand the importance of isolation I wrote a simulator that takes into account housing, commercial, virus characteristics and social interactions. [Link To Simulator](https://www.ascentcore.com/pages/pandemic.html).\n\n![Screenshot](https://www.ascentcore.com/assets/static/showcase_thumb-3-1.png)\n\nThe simulator was used to try out different scenarios in testing effectiveness of movement control strategies to prevent secondary transmission in health care and community settings.\nThe application will allow execution of predefined templates or you can configure your own scenario.\n\nSample videos on different simulated scenarios:\n- Environment with high vs. low employment rate (https://www.youtube.com/watch?v=QpB9hPaavf4&t=38s)\n- Environment with normal working schedule vs work from home (shopping allwed) (https://www.youtube.com/watch?v=chxFgObhcDQ)\n- Large office buildings vs multiple working locations (https://www.youtube.com/watch?v=HykbOsHWDSY)\n\n"},{"metadata":{},"cell_type":"markdown","source":"# Custom Rule Execution Sequence Engine\n\nIn order to perform a more refined search that takes into account various rules of execution a custom engine was designed such that it can combine Spacys Pattern Matcher strategy with a preffered sequence execution of the matchers.\n\nGiven the following example\n```\nrule = {    \n    \"Matchers\": [\n        (\"Incubation Matcher\", [\n            {\"LOWER\": \"incubation\"},\n            {\"LOWER\": \"period\", \"OP\": \"?\"}\n        ]),\n        (\"Mortality Rate Matcher\", [\n            {\"LOWER\": \"mortality\"},\n            {\"LOWER\": \"rate\", \"OP\": \"?\"}\n        ]),\n        (\"Percent Matcher\", matchers[\"Number Suffix Matcher\"]([\"%\", \"percent\"])),\n        (\"Time Matcher\", matchers[\"Number Suffix Matcher\"]([\"days\", \"weeks\"])),\n        (\"Time Interval Matcher\", matchers[\"Number Interval Matcher\"]([\"days\", \"weeks\"])),\n        (\"Year Matcher\", matchers[\"Number Suffix Matcher\"]([\"years old\"])),\n        (\"Year Interval Matcher\", matchers[\"Number Interval Matcher\"]([years old]))\n    ],\n    \"root\": {          \n        \"Incubation Matcher\": { \n            \"Time Matcher\": incubation_period_report ,\n            \"Time Interval Matcher\": incubation_period_report,\n        },\n        \"Mortality Rate Matcher\": { \n            \"Year Matcher\": {\n                \"Percent Matcher: mortality_report\n            },\n            \"Year Interval Matcher\": {\n                \"Percent Matcher: mortality_report\n            },\n        }\n    }\n}\n```\n\n(matchers are documented below)\n\nWill define a rule where the engine will look for the following:\n- Incubation Matcher: **incubation** **?period** terms in the sentence. Period is optional\n- Mortality Rate Matcher: **mortality** **?rate** terms in the sentence. Rate is optional\n- Percent matcher: will identify all percentile references in the code\n- Time Matcher: will identify all numeric terms like: 5 days, 1 day\n- Time Interval Matcher: will identify all numeric intervals in days/weeks: 4 to 6 days, 10-12 weeks\n- Year Matcher: will identify all numeric terms like: 60 years\n- Year Interval Matcher: will identify all numeric intervals in years: 56-80 years, 10 to 12 years.\n\nthe execution rules are defined under the **root** key:\n- Incubation Matcher -> Time Matcher will identify: The virus has an incubation period of 14 days\n- Incubation Matcher -> Time Interval Matcher will identify: The virus has an imbubation period of 10 to 14 days\n- Mortality Rate Matcher -> Year Matcher -> Percent Matcher will identify: The reported mortality rate for over 60 years old is 30%.\n- Mortality Rate Matcher -> Year Interval Matcher -> Percent Matcher will identify: The reported mortality rate for patients between 20 and 30 years old uis 0.5 percents\n\n"},{"metadata":{},"cell_type":"markdown","source":"# Prepare term libraries\n\nThe term libraries are taken from the medical literature and used to do seek or refine the searches in order to focus on the known terms\n\n* virus_ref - virus references in articles. is used to filter the dataset when specific referentiation is needed\n* symptoms - list of generic symptoms\n* organs - list of human organs\n* higher_terms - list of terms that are used to define the starting point of an age group\n* lower_terms - list of terms that are used to define the end of an age group"},{"metadata":{"trusted":true},"cell_type":"code","source":"virus_ref = ['covid-19', 'coronavirus', 'cov-2', 'sars-cov-2', 'sars-cov', 'hcov', '2019-ncov']\nsymptoms = ['weight loss','chills','shivering','convulsions','deformity','discharge','dizziness','vertigo','fatigue','malaise','asthenia','hypothermia','jaundice','muscle weakness','pyrexia','sweats','swelling','swollen','painful lymph node','weight gain','arrhythmia','bradycardia','chest pain','claudication','palpitations','tachycardia','dry mouth','epistaxis','halitosis','hearing loss','nasal discharge','otalgia','otorrhea','sore throat','toothache','tinnitus','trismus','abdominal pain','fever','bloating','belching','bleeding','blood in stool','melena','hematochezia', 'constipation','diarrhea','dysphagia','dyspepsia','fecal incontinence','flatulence','heartburn','nausea','odynophagia','proctalgia fugax','pyrosis','steatorrhea','vomiting','alopecia','hirsutism','hypertrichosis','abrasion','anasarca','bleeding into the skin','petechia','purpura','ecchymosis and bruising','blister','edema','itching','laceration','rash','urticaria','abnormal posturing','acalculia','agnosia','alexia','amnesia','anomia','anosognosia','aphasia and apraxia','apraxia','ataxia','cataplexy','confusion','dysarthria','dysdiadochokinesia','dysgraphia','hallucination','headache','akinesia','bradykinesia','akathisia','athetosis','ballismus','blepharospasm','chorea','dystonia','fasciculation','muscle cramps','myoclonus','opsoclonus','tic','tremor','flapping tremor','insomnia','loss of consciousness','syncope','neck stiffness','opisthotonus','paralysis and paresis','paresthesia','prosopagnosia','somnolence','abnormal vaginal bleeding','vaginal bleeding in early pregnancy', 'miscarriage','vaginal bleeding in late pregnancy','amenorrhea','infertility','painful intercourse','pelvic pain','vaginal discharge','amaurosis fugax','amaurosis','blurred vision','double vision','exophthalmos','mydriasis','miosis','nystagmus','amusia','anhedonia','anxiety','apathy','confabulation','depression','delusion','euphoria','homicidal ideation','irritability','mania','paranoid ideation','suicidal ideation','apnea','hypopnea','cough','dyspnea','bradypnea','tachypnea','orthopnea','platypnea','trepopnea','hemoptysis','pleuritic chest pain','sputum production','arthralgia','back pain','sciatica','Urologic','dysuria','hematospermia','hematuria','impotence','polyuria','retrograde ejaculation','strangury','urethral discharge','urinary frequency','urinary incontinence','urinary retention']\norgans = ['mouth','teeth','tongue','salivary glands','parotid glands','submandibular glands','sublingual glands','pharynx','esophagus','stomach','small intestine','duodenum','Jejunum','ileum','large intestine','liver','Gallbladder','mesentery','pancreas','anal canal and anus','blood cells','respiratory system','nasal cavity','pharynx','larynx','trachea','bronchi','lungs','diaphragm','Urinary system','kidneys','Ureter','bladder','Urethra','reproductive organs','ovaries','Fallopian tubes','Uterus','vagina','vulva','clitoris','placenta','testes','epididymis','vas deferens','seminal vesicles','prostate','bulbourethral glands','penis','scrotum','endocrine system','pituitary gland','pineal gland','thyroid gland','parathyroid glands','adrenal glands','pancreas','circulatory system','Heart','patent Foramen ovale','arteries','veins','capillaries','lymphatic system','lymphatic vessel','lymph node','bone marrow','thymus','spleen','tonsils','interstitium','nervous system','brain','cerebrum','cerebral hemispheres','diencephalon','the brainstem','midbrain','pons','medulla oblongata','cerebellum','the spinal cord','the ventricular system','choroid plexus','peripheral nervous system','nerves','cranial nerves','spinal nerves','Ganglia','enteric nervous system','sensory organs','eye','cornea','iris','ciliary body','lens','retina','ear','outer ear','earlobe','eardrum','middle ear','ossicles','inner ear','cochlea','vestibule of the ear','semicircular canals','olfactory epithelium','tongue','taste buds','integumentary system','mammary glands','skin','subcutaneous tissue']\nhigher_terms = ['over', 'above', 'higher', 'older', '>', 'over', 'less']\nlower_terms = ['under', 'below', 'fewer', 'younger', '<', 'under', 'more']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Defined generic Spacy pattern matchers and util library\n\nthe patterns will be used in order to assemble a set of rules to identify the desired sequence of patterns\n\n* matchers\n - Term Matcher - lookout for a single term\n - Terms Matcher - lookout in a list of terms\n - Number Suffix Matcher - search for numeric value preceeded by a time definition (parametrized, e.g: [\"day\", \"year\"])\n - Number Interval Matcher - search for numeric intervals of time definition (parametrized, e.g: [\"minute\", \"day\", \"year\"])\n \n \n* plot_dict - utility to plot a dictionary\n* dict_counter - increase or set the value of a key in the dictionary\n* day_value - report the time value in days\n* report_interval - populates dictionary with values for an interval (e.g. 4-7 => {4: 1, 5: 1, 6: 1, 7: 1})\n* virus_match - checks if any virus term is referenced in the text"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"matchers = {    \n    \"Term Matcher\": lambda term: [{'LOWER': t} for t in term.split(' ')],\n    \"Terms Matcher\": lambda terms: [{\"LOWER\": {\"IN\": terms } }],\n    \"Number Suffix Matcher\": lambda periods: [\n        {'LIKE_NUM': True},\n        {\"TEXT\": {\"REGEX\": f'({\"|\".join(periods)})'}}\n    ],\n    \"Number Interval Matcher\": lambda periods: [\n        {'POS': 'NUM',},\n        {'TEXT': {'REGEX': f'({\"|\".join(periods)})'}, 'OP': '?'},\n        {'DEP': 'quantmod', 'OP': '?'},\n        {'DEP': 'punct', 'OP': '?'},\n        {'DEP': 'prep', 'OP': '?'},\n        {'POS': 'NUM'},\n        {'TEXT': {'REGEX': f'({\"|\".join(periods)})'}},\n    ],\n    \"Group Matcher\": [\n        {\"TEXT\": {\"IN\": higher_terms+lower_terms }}\n    ]\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_dict(stat, t = 10, sort_values = False, barh = False, width = 20, height = 4, title = ''):\n    filtered = dict(stat)\n    to_delete = []\n    for key in filtered:\n        if filtered[key] < t:\n            to_delete.append(key)\n    for key in to_delete:\n        del filtered[key]\n\n    \n    if sort_values == False:\n        lists = sorted(filtered.items())\n    else:\n        if sort_values == True:\n            lists = sorted(filtered.items(), key = lambda item : item[1])\n        else:\n            lists = sorted(filtered.items(), key = sort_values)\n               \n    fig = figure(num=None, figsize=(width, height))\n    \n    if title != '':\n        fig.suptitle(title, fontsize=20)\n        \n    x, y = zip(*lists) \n    \n    if barh == True:\n        plt.barh(x, y)\n    else:\n        plt.bar(x, y)\n    plt.show()\n    \n\ndef merge_keys(mergers, obj):\n    result = dict(obj)\n    for key, arr in mergers:\n        if key not in result:\n            result[key] = 0\n        for merger in arr:\n            if merger in result:\n                result[key] = result[key] + result[merger]\n                del result[merger]\n    return result\n\ndef dict_counter(res, arg):\n    try:\n        key = str(arg)\n        res.setdefault(key, 0)\n        res[key] = res[key] + 1\n    except:\n        pass\n\ndef numval(val):\n    try:\n        return int(float(str(val))) \n    except:\n        return None\n    \ndef day_value(val, rep = None):\n    \n    if rep != None:\n        val = numval(val.text)\n        if val != None and 'week' in rep.text:\n            val = val * 7\n        return val\n    else:\n        return None\n\ndef report_interval(res, min_val, max_val):       \n    if min_val != None and max_val != None:\n        for key in range(min_val, max_val):\n            res.setdefault(key, 0)\n            res[key] = res[key] + 1    \n\ndef virus_match(text):\n    return len(re.findall(rf'({\"|\".join(virus_ref)})', text, flags=re.IGNORECASE)) > 0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Prepare COVID-19 Literature dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"literature = []\nfor index, row in tqdm(df.iterrows(), total=df.shape[0]):\n    sha = str(row['sha'])\n    if sha != 'nan':\n        sha = sha + '.json';\n        try:\n            found = False\n            with open(articles[sha]) as f:\n                data = json.load(f)\n                for key in ['abstract', 'body_text']:\n                    if found == False and key in data:\n                        for content in data[key]:\n                            text = content['text']\n                            if virus_match(text) == True:                                \n                                literature.append({'file': articles[sha], 'body': text})                                \n        except KeyError:\n            pass","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Define rule matching execution functions\n\nWhen executing a set of rules on a text body the order of the mathcers will be appended to the matching array that will allow the user to define conditional executions when rules match. \n\nRule example:\n```\nrule = {    \n    \"Matchers\": [\n        (\"Term Matcher\", [\n            {\"LOWER\": \"incubation\"},\n            {\"LOWER\": \"period\", \"OP\": \"?\"}\n        ]),\n        (\"Time Matcher\", matchers[\"Number Suffix Matcher\"]([\"days\", \"weeks\"])),\n        (\"Time Interval Matcher\", matchers[\"Number Interval Matcher\"]([\"days\", \"weeks\"]))\n    ],\n    \"root\": {          \n        \"Term Matcher\": { \n            \"execute\": lambda x: print(x),\n            \"Time Matcher\": incubation_period_report ,\n            \"Time Interval Matcher\": incubation_period_report,\n        }\n    }\n}\n```\n\nA rule is made of *Matchers* and *executors* - starting with **root executor**. The example above defines the following matchers:\n* Term Matcher -> looks for the term **incubation** and optionally **period**\n* Time Matcher -> matches all time references in days / weeks\n* Time Interval Matcher -> matches all time intervals in days / weeks\n\nThe next item in the dictionary is *root* that defines the preferred matching order execution (if the order is not satisfied then the matcher executor won't get called)\n* Term Matcher -> Time Matcher\n* Term Matcher -> Time Interval Matcher\n\nIf the matcher rule has the **execute** key present in the dictionary then the rule will get executed even if further specific matchers will get called later\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def execute_matches(match_arr, root, sentence, file, index = 0, execution = []):\n    key, result = match_arr[0]\n    rest = match_arr[1:]\n    next_exec = execution + [(key, result, index)]\n    if key in root:\n        rule = root[key]\n        if callable(rule):\n            rule( (result, next_exec, sentence, file) )            \n        else:\n            if 'execute' in rule:\n                rule['execute']( (result, next_exec, sentence, file) )\n            if len(rest) > 0:\n                execute_matches(rest, rule, sentence, file, index+1, next_exec)\n    \n    if len(rest) > 0:               \n        execute_matches(rest, root, sentence, file, index + 1, execution)\n        \ndef merge_dict_values(original, rules, drop = []):\n    result = {}\n    arr_map = {}\n    for key, values in rules:\n        for val in values:\n            arr_map[val] = key\n    \n    for key in original.keys():\n        new_key = key if key not in arr_map else arr_map[key]        \n        if key not in drop and new_key not in drop:\n            val = original[key]            \n            result[new_key] = val if new_key not in result else result[new_key] + val\n            \n    return result\n    \ndef merge_matches(matches, doc):\n    match_list = []\n    current = (None, None, None)\n    for match_id, start, end in matches:   \n        if match_id != current[0] or current[2] < start:\n            if current[0] != None:\n                match_list.append(current)\n            current = (match_id, start, end)\n        elif current[2] < end:\n            current = (match_id, current[1], end)\n        \n    match_list.append(current)\n    return match_list;\n\ndef match_parser(matcher, doc, rule, file):\n    matches = matcher(doc)\n    if len(matches)>0:\n        to_process = []\n        for match_id, start, end in merge_matches(matches, doc):\n            string_id = nlp.vocab.strings[match_id]  # Get string representation\n            span = doc[start:end]  # The matched span\n            to_process.append((string_id, span))\n        execute_matches(to_process, rule['root'], doc, file)\n\ndef parse_body(matcher, text, rule, file = None, sentence_level = False):\n    text = text.lower()\n    doc = nlp(text)\n    \n    if sentence_level == True:    \n        for sent in doc.sents:\n            sent_doc = nlp(sent.text)\n            match_parser(matcher, sent_doc, rule, file)\n    else:\n        match_parser(matcher, doc, rule, file)\n\ndef execute_ruleset(term, rule, sentence_level = False, literature = literature):\n    matcher = Matcher(nlp.vocab)\n    for name, m in rule[\"Matchers\"]:\n        matcher.add(name, None, m)\n    \n    for article in tqdm(literature):\n#     for article in literature:\n        text_list = re.compile(\"\\. \").split(article['body'])\n        file = article['file']\n        for text in text_list:\n            if callable(term):\n                allow = term(text)\n            else:\n                allow = term == None or term in text\n            if allow == True:\n                parse_body(matcher, text, rule, file, sentence_level)        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Virus Symptoms\n\nSearch for virus references and its symptoms in all articles that have a coronavirus reference and at least one term in symptoms dictionary\nSince is really important to understand the symptoms the search will be performed on the entire article dataset with no filter. "},{"metadata":{"trusted":true},"cell_type":"code","source":"stat['symptoms'] = {}\n\ndef match(text):\n    if virus_match(text) == True:\n        return len(re.findall(rf'\\ ({\"|\".join(symptoms)})\\ ', text)) > 0\n    else:\n        return False\n\ndef symptom(res):\n    ref, agregate, sentence, file = res\n    dict_counter(stat['symptoms'], ref.text)\n        \nrule = {    \n    \"Matchers\": [      \n       (\"Symptoms Reference\", matchers['Terms Matcher'](symptoms)),\n    ],\n    \"root\": {\n        \"Symptoms Reference\": symptom\n    }\n}\n\n\ndef symptom_match(text):\n    return len(re.findall(r'symptom', text)) > 0\n\nexecute_ruleset(symptom_match, rule)\nplot_dict(stat['symptoms'], 50, True, title = \"Manifested Symptoms\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Incubation Period\n\nThe first analysis is parsing filtered articles that might refer to COVID-19 incubation period. For the moment the term *incubation period* is searched in text abstract in order to identify the potential articles.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"stat['incubation_periods'] = {}\n\ndef incubation_period_report(x):\n    arr = x[1][-2:]\n    m1, v1, i1 = arr[0]\n    m2, v2, i2 = arr[1]\n    \n    if m1 == 'Term Matcher':\n        if m2 == 'Time Matcher':\n            report_interval(stat['incubation_periods'], 0, day_value(v2[0], v2[1]))            \n        elif m2 == 'Time Interval Matcher':\n            report_interval(stat['incubation_periods'], day_value(v2[0], v2[3]), day_value(v2[1], v2[1]))           \n    elif m2 == 'Term Matcher':\n        if m2 == 'Time Matcher':\n            report_interval(stat['incubation_periods'], 0, day_value(v2[0], v2[1]))\n        elif m2 == 'Time Interval Matcher':\n            report_interval(stat['incubation_periods'], day_value(v2[0], v2[3]), day_value(v2[1], v2[1]))      \n\nrule = {    \n    \"Matchers\": [\n        (\"Term Matcher\", [\n            {\"LOWER\": \"incubation\"},\n            {\"LOWER\": \"period\", \"OP\": \"?\"}\n        ]),\n        (\"Time Matcher\", matchers[\"Number Suffix Matcher\"]([\"days\", \"weeks\"])),\n        (\"Time Interval Matcher\", matchers[\"Number Interval Matcher\"]([\"days\", \"weeks\"]))\n    ],\n    \"root\": {          \n        \"Term Matcher\": { \n            \"Time Matcher\": incubation_period_report ,\n            \"Time Interval Matcher\": incubation_period_report,\n        },\n        \"Day Matcher\": { \"Term Matcher\": incubation_period_report },\n        \"Day Interval Matcher\": { \"Term Matcher\": incubation_period_report }\n    }\n}\n\nexecute_ruleset('incubation period', rule)\nplot_dict(stat['incubation_periods'], 15, title = 'Incubation Period')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Quarantine\n\nSearches for all quarantine recommendations in the articles where coronavirus term is present. The lookout will be performed at the sentence level and not at the full body level for a better approximation."},{"metadata":{"trusted":true},"cell_type":"code","source":"stat['quarantine'] = {}\n\ndef quarantine_matcher(text):\n    return virus_match(text) == True and 'quarantine' in text\n\ndef quarantine_report(x):\n    arr = x[1][-2:]\n    m1, v1, i1 = arr[0]\n    m2, v2, i2 = arr[1]\n    \n    if m1 == 'Quarantine Matcher':\n        if m2 == 'Time Matcher':\n            report_interval(stat['quarantine'], 0, day_value(v2[0], v2[1]))            \n        elif m2 == 'Time Interval Matcher':\n            report_interval(stat['quarantine'], day_value(v2[0], v2[3]), day_value(v2[1], v2[1]))           \n    elif m2 == 'Quarantine Matcher':\n        if m2 == 'Time Matcher':\n            report_interval(stat['quarantine'], 0, day_value(v2[0], v2[1]))\n        elif m2 == 'Time Interval Matcher':\n            report_interval(stat['quarantine'], day_value(v2[0], v2[3]), day_value(v2[1], v2[1]))      \n            \nrule = {    \n    \"Matchers\": [\n        (\"Quarantine Matcher\", [\n            {\"LOWER\": \"quarantine\"},\n        ]),\n        \n        (\"Time Matcher\", matchers[\"Number Suffix Matcher\"]([\"days\", \"weeks\"])),\n        (\"Time Interval Matcher\", matchers[\"Number Interval Matcher\"]([\"days\", \"weeks\"]))\n    ],\n    \"root\": {          \n        \"Quarantine Matcher\": { \n            \"Time Matcher\": quarantine_report ,\n            \"Time Interval Matcher\": quarantine_report,\n        },\n        \"Day Matcher\": { \"Quarantine Matcher\": quarantine_report },\n        \"Day Interval Matcher\": { \"Quarantine Matcher\": quarantine_report }\n    }\n}\n\nexecute_ruleset('quarantine', rule)\nplot_dict(stat['quarantine'], 10, title = 'Quarantine Period')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Transmission methods\n\nSearches for all transmission method (NOUNS) in articles where coronavirus is mentioned."},{"metadata":{"trusted":true},"cell_type":"code","source":"stat['transmission'] = {\n}\n\ndef report_term(x):\n    arr = x[1]\n    m1, v1, i1 = arr[0]\n    m2, v2, i2 = arr[1]\n    m3, v3, i3 = arr[2]\n    \n    if m1 == 'Term Matcher' and m2 == 'Form Matcher':\n        dict_counter(stat['transmission'], re.sub(r'[ ]?(-|the| a )[ ]?','', v3.text))\n\nterm_match = ['transmit','transmitted', 'spread', 'spreaded']\nrule = {    \n    \"Matchers\": [\n        (\"Term Matcher\", [{\"LOWER\": \"now\", \"OP\": \"!\"}] + matchers[\"Terms Matcher\"](term_match)),\n        (\"Form Matcher\", matchers[\"Terms Matcher\"](['through', 'by', 'via'])),\n        (\"Noun Matcher\", [\n            {\"POS\": \"VERB\", \"OP\": \"?\"},\n            {\"POS\": \"DET\", \"OP\": \"?\"},\n            {\"POS\": \"ADJ\", \"OP\": \"?\"},\n            {\"POS\": \"PUNCT\", \"OP\": \"?\"},\n            {\"POS\": \"ADJ\", \"OP\": \"?\"},\n            {\"POS\": \"NOUN\", \"OP\": \"+\"},\n        ])\n    ],\n    \"root\": {          \n        \"Term Matcher\": {\n            \"Form Matcher\": {\n                \"Noun Matcher\": report_term\n            }\n        }\n    }\n}\n\n\ndef transmission_match(text):\n    return len(re.findall(rf'({\"|\".join(term_match)})', text)) >0\n\nexecute_ruleset(transmission_match, rule, False)\n\nnew_dict = merge_dict_values(stat['transmission'], [\n    ('contact', ['direct contact', 'close contact', 'indirect contact', 'person contact']),\n    ('respiratory droplets/route', ['droplets','air', 'airborne route', 'aerosols', 'airborne transmission', 'respiratory route','respiratory droplets', 'droplet', 'respiratory secretions']),\n    ('surfaces/fomites', ['fomites', 'surfaces', 'environmental surfaces', 'environment']),\n    ('human transmission', ['human','humans','patient', 'patients','person', 'people']),\n    ('fecal-oral route', ['fecaloral route', 'faecaloral route'])\n], ['%', 'virus', 'viruses'])\n\n\nplot_dict(new_dict, 30, True, barh = True, height = 10, title = 'Transmission Routes')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Affected Organs\nSearch for list of possible human organs affected by COVID-19"},{"metadata":{"trusted":true},"cell_type":"code","source":"stat['organs'] = {}\n\ndef match(text):\n    if virus_match(text) == True:\n        return len(re.findall(rf'\\ ({\"|\".join(organs)})\\ ', text)) > 0\n    else:\n        return False\n\ndef organ_reference(res):\n    ref, agregate, sentence, file = res\n    dict_counter(stat['organs'], ref.text)\n        \nrule = {    \n    \"Matchers\": [      \n       (\"Organ Reference\", matchers['Terms Matcher'](organs)),\n    ],\n    \"root\": {\n        \"Organ Reference\": organ_reference\n    }\n}\n\n\ndef symptom_match(text):\n    res = re.findall(rf'\\ ({\"|\".join(organs)})\\ ', text, flags=re.IGNORECASE)    \n    return len(res) >0\n\nexecute_ruleset(symptom_match, rule)\nplot_dict(stat['organs'], 500, True, title = 'Affected Organs')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Gender Report\nMine for any gender age intervals reports"},{"metadata":{"trusted":true},"cell_type":"code","source":"stat['gender'] = {\n    'male': {},\n    'female': {}\n}\n\nresolution = 10\ncount = int(100 / resolution)\nfor val in range(0, count):\n    key = f'{val*resolution}-{val*resolution+resolution}'\n    stat['gender']['male'][key] = 0\n    stat['gender']['female'][key] = 0\n\ndef get_key(gender):\n    return 'female' if 'female' in gender else 'male'\n    \ndef percent_counter(x):\n    arr = x[1][-2:]\n    m1, v1, i1 = arr[0]\n    m2, v2, i2 = arr[1]\n   \n    if m1 != m2 and i1 == i2-1:\n        gender = get_key(v1.text if m1 == 'Gender Matcher' else v2.text)\n        percent = numval((v2 if m1 == 'Gender Matcher' else v1)[0])\n        if percent != None and percent >= 0 and percent <=100:\n            percent = int(percent / resolution) * resolution\n            dict_counter(stat['gender'][gender], f'{percent}-{percent+resolution}')\n\nrule = {    \n    \"Matchers\": [\n        (\"Gender Matcher\", matchers[\"Terms Matcher\"]([\"male\", \"males\", \"female\", \"females\"])),\n        (\"Percent Matcher\", matchers[\"Number Suffix Matcher\"]([\"%\", \"percent\"])),\n    ],\n    \"root\": {\n        \"Gender Matcher\": { \"Percent Matcher\":  percent_counter },\n        \"Percent Matcher\": { \"Gender Matcher\":  percent_counter },\n    }\n}\n\ndef gender_match(text):\n    return len(re.findall(rf'(male|female)', text, flags=re.IGNORECASE)) > 0\n\n\nexecute_ruleset(gender_match, rule, False)\n\nfinal_arr = []\n\nfor i, key in enumerate(stat['gender']['male'].keys()):\n    final_arr.append([i, key, stat['gender']['male'][key], 'male'])\n    \nfor i, key in enumerate(stat['gender']['female'].keys()):\n    final_arr.append([i, key, stat['gender']['female'][key], 'female'])\n    \ndf = pd.DataFrame(final_arr, columns = ['index', 'range', 'count', 'gender'])\nsns.barplot(x=\"range\", y=\"count\", hue=\"gender\", data=df)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Fatality Rate (%)\n\nReported fatality rates - scrape the COVID-19 reference literature for (mortality|fatality) rate matchers + percent reports. \n**Graph values represent reported percent**"},{"metadata":{"trusted":true},"cell_type":"code","source":"stat['fatality'] = {}\n\n    \ndef percent_counter(x):\n    arr = x[1][-2:]\n    m1, v1, i1 = arr[0]\n    m2, v2, i2 = arr[1]\n    val = numval(v2[0])\n    if val != None and m1 == 'Fatality Matcher' and i1 == i2 - 1:\n        dict_counter(stat['fatality'], val)   \n\nrule = {    \n    \"Matchers\": [\n        (\"Fatality Matcher\", matchers[\"Terms Matcher\"]([\"mortality\", \"fatality\"]) + [{\"LOWER\": \"rate\"}]),\n        (\"Percent Matcher\", matchers[\"Number Suffix Matcher\"]([\"%\", \"percent\"])),\n    ],\n    \"root\": {\n        \"Fatality Matcher\": {\n            \"Percent Matcher\":  percent_counter\n        }\n    }\n}\n\ndef fatality_match(text):\n    return len(re.findall(rf'(mortality|fatality) rate', text, flags=re.IGNORECASE)) > 0\n\n\nexecute_ruleset(fatality_match, rule, False)\nplot_dict(stat['fatality'], 25, sort_values = lambda item : float(item[0]), title=\"Fatality Rate Reports\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Genome sequences mining\nMine the text for genome sequences and report found sentence and the article file that contain the detail"},{"metadata":{"trusted":true},"cell_type":"code","source":"stat['genome'] = []\n\nregex = r' ([GTCA]{2,}[GTCA\\-\\~\\ ]{3,}[GTCA])\\W'\ndef sequence_matcher(x):\n    text, match, sent, file = x\n    name, found, index = match[0]\n    matches = re.finditer(regex, sent.text, re.MULTILINE | re.IGNORECASE)\n    genome = [match.group(0).strip() for matchNum, match in enumerate(matches, start=1)]\n    stat['genome'].append({'genome': genome, 'sentence': sent.text, 'file': file})\n\nrule = {    \n    \"Matchers\": [\n        ('Genome Matcher', [\n            {\"lower\": {\"regex\": regex}}\n        ])\n    ],\n    \"root\": {\n        \"Genome Matcher\": sequence_matcher\n    }\n}\n\ndef fatality_match(text):\n    return len(re.findall(regex, text, flags=re.IGNORECASE)) > 0\n\nexecute_ruleset(fatality_match, rule, False)\npd.DataFrame(stat['genome']) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Known Facts\n\n- Search the code for false positives/negatives in order to learn from other research. The plot will show most common NOUNS used to relate a false positive/negative and they are converted to a Pandas dataset along with the referencing literature"},{"metadata":{"trusted":true},"cell_type":"code","source":"stat['false_pos_neg'] = {\n    'words': {},\n    'refs': []\n}\n\n# regex = r' Â°[CF] '\nregex = r' false [negative|positive]'\n\nexclude = ['false', 'positive', 'positives', 'negative', 'negatives', 'value', 'values', 'number', 'use', 'fig', 'site'] + virus_ref\ndef fp_matcher(x):\n    text, match, sent, file = x\n    name, found, index = match[0]\n    for token in sent:\n        if token.pos_ in ['NOUN'] and token.is_punct == False and token.is_stop == False and token.text not in exclude:\n            dict_counter(stat['false_pos_neg']['words'], token.text)\n    stat['false_pos_neg']['refs'].append({'sentence': sent.text, 'file': file})\n\nrule = {    \n     \"Matchers\": [\n        ('Term Matcher', [\n            {\"lower\": {\"regex\": regex}}\n        ])\n    ],\n    \"root\": {\n        \"Term Matcher\": fp_matcher\n    }\n}\n\ndef regex_match(text):\n    return len(re.findall(regex, text, flags=re.IGNORECASE)) > 0\n\nexecute_ruleset(regex_match, rule, False)\nstat['false_pos_neg']['refs'] = pd.DataFrame(stat['false_pos_neg']['refs'])\nstat['false_pos_neg']['refs']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_dict = merge_dict_values(stat['false_pos_neg']['words'], [\n    ('tesst', ['testing', 'test']),\n    ('viruses', ['virus']),\n    ('values', ['value']),\n    ('studies', ['study']),\n    ('tests', ['test', 'tested']),\n    ('signales', ['signal']),\n    ('antibodies', ['antibody']),\n    ('specificity', ['specific'])\n])\nplot_dict(new_dict, 5, sort_values = True, title=\"False Positive/Negative Terms\", barh = True, height = 20,)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Antigen references"},{"metadata":{"trusted":true},"cell_type":"code","source":"stat['antigen'] = {\n    'count': {},\n    'refs': []\n}\n\n# regex = r' (antigen|antibod)'\nregex = r' antigen'\nexclude = []\n\ndef antigen_matcher(x):\n    text, match, sent, file = x\n    \n    if text.text != 'antigen':\n#         text = text.text.replace(.replace('antigens', '').replace('antigen', '').strip()        \n        text = re.sub(r'(antibodies|antibody|antigens|antigen)', '', text.text).strip()\n        if len(text) > 0:\n            dict_counter(stat['antigen']['count'], text)\n            stat['antigen']['refs'].append({'sentence': sent.text, 'file': file})\n\nrule = {    \n     \"Matchers\": [\n        ('Term Matcher', [\n            {\"POS\": \"PROPN\", \"op\": \"*\"},\n            {\"POS\": \"NOUN\", \"op\": \"*\"},\n            {\"POS\": \"VERB\", \"op\": \"*\"},\n            {\"LOWER\": {\"IN\": ['antigen', 'antigens'] }} #, 'antibody', 'antibodies'] } }\n        ])\n    ],\n    \"root\": {\n        \"Term Matcher\": antigen_matcher\n    }\n}\n\ndef regex_match(text):\n    return len(re.findall(regex, text, flags=re.IGNORECASE)) > 0\n\nexecute_ruleset(regex_match, rule, False)\nstat['antigen']['refs'] = pd.DataFrame(stat['antigen']['refs'])\nstat['antigen']['refs']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_dict = merge_dict_values(\n    stat['antigen']['count'], \n    [],\n    ['coronavirus', 'neutralizing', 'neutralising', 'hcv', 'cov', 'hcv core', 'hcv'])\nplot_dict(new_dict, 5, sort_values = True, title=\"Antigen References\", barh = True, height = 20,)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}