{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Airbnb Reviews Sentiment Analysis\n\n![image](https://www.kdnuggets.com/images/sentiment-fig-1-689.jpg)\n\nSentiment analysis is the process of detecting positive or negative sentiment in text. It’s often used by businesses to detect sentiment in social data, gauge brand reputation, and understand customers.\n\n### Why Is Sentiment Analysis Important?\nSentiment analysis is extremely important because it helps businesses quickly understand the overall opinions of their customers. By automatically sorting the sentiment behind reviews, social media conversations, and more, you can make faster and more accurate decisions.\n\nIt’s estimated that 90% of the world’s data is unstructured, in other words it’s unorganized. Huge volumes of unstructured business data are created every day: emails, support tickets, chats, social media conversations, surveys, articles, documents, etc). But it’s hard to analyze for sentiment in a timely and efficient manner.\n\n### Some Applications of Sentiment Analysis\nThe applications of sentiment analysis are endless and can be applied to any industry, from finance and retail to hospitality and technology. Below, we’ve listed some of the most popular ways that sentiment analysis is being used in business:\n\n1. Social Media Monitoring\n1. Brand Monitoring\n1. Voice of customer (VoC)\n1. Customer Service\n1. Market Research"},{"metadata":{"id":"PH4sIh2B9p3R"},"cell_type":"markdown","source":"## Import the necessary packages"},{"metadata":{"id":"sgPvBR6UlFdQ","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport plotly.graph_objects as go\nimport matplotlib.pyplot as plt\nimport spacy\nimport nltk","execution_count":null,"outputs":[]},{"metadata":{"id":"N7EQvd8PJo2_","outputId":"7e166248-f69b-45de-dc0c-19cf68e033c2","trusted":true},"cell_type":"code","source":"nltk.download('stopwords')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Sentiment Analysis Pipeline\n![pipeline](https://cdn-images-1.medium.com/max/361/0*ga5rNPmVYBsCm-lz.)"},{"metadata":{"id":"R-WY1QZa9r_n"},"cell_type":"markdown","source":"## Read the dataset and clean it"},{"metadata":{"id":"HsV84INsmKzB","outputId":"bad1c9e7-eb30-4203-a04f-d24868ebfdf1","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/trip-advisor-hotel-reviews/tripadvisor_hotel_reviews.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"Wc5tRh5dmVuj","outputId":"14242c35-f9f3-4b97-9ab8-5c002dad849d","trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"63EohW39nHtw","outputId":"b01f0f00-3ae2-4899-f9c2-b8334fff5d4c","trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"id":"TYug4RMe7srX","outputId":"8ee11d7a-5cb1-422d-9af6-33124da0ad50","trusted":true},"cell_type":"code","source":"df[\"Rating\"].value_counts() #Checks the rating values in case there is a weird value","execution_count":null,"outputs":[]},{"metadata":{"id":"P0252Ace7xbC","outputId":"459b20e2-d5d3-4502-c755-33a9419a7b43","trusted":true},"cell_type":"code","source":"df.loc[df[\"Review\"] == \"\"] #Checks for empty review strings","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Segregating and Encoding Positive, Neutral and Negative labels"},{"metadata":{"id":"1e5PBSm_nLvo","outputId":"13f649fb-db05-4b67-b752-2e687376bd67","trusted":true},"cell_type":"code","source":"pos = [5]\nneg = [1, 2]\nneu = [3, 4]\n\ndef sentiment(rating):\n  if rating in pos:\n    return 2\n  elif rating in neg:\n    return 0\n  else:\n    return 1  \ndf['Sentiment'] = df['Rating'].apply(sentiment)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Analysing Positive, Neutral and Negative Reviews"},{"metadata":{"id":"-xEohlvrnTOe","outputId":"5dd28c49-0831-4a83-a764-ff77f30c2246","trusted":true},"cell_type":"code","source":"fig = go.Figure([go.Bar(x=df.Sentiment.value_counts().index, y=df.Sentiment.value_counts().tolist())])\nfig.update_layout(\n    title=\"Values in each Sentiment\",\n    xaxis_title=\"Sentiment\",\n    yaxis_title=\"Values\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Text Preprocessing \n1. Tokenization\n2. Punctuation removal\n3. Stopword removal\n4. Removing HTML Tags\n5. Lower casing\n"},{"metadata":{"id":"3XgCAQwa_sZn","outputId":"064f49a5-c290-4778-c5bb-e0fcd2ceb972","trusted":true},"cell_type":"code","source":"from nltk.corpus import stopwords\nstopwords_list = set(stopwords.words(\"english\"))\npunctuations = \"\"\"!()-![]{};:,+'\"\\,<>./?@#$%^&*_~Â\"\"\" #List of punctuation to remove\n\ndef reviewParse(review):\n    splitReview = review.split() #Split the review into words\n    parsedReview = \" \".join([word.translate(str.maketrans('', '', punctuations)) + \" \" for word in splitReview]) #Takes the stubborn punctuation out\n    return parsedReview #Returns the parsed review\n  \ndef clean_review(review):\n    clean_words = []\n    splitReview = review.split()\n    for w in splitReview:\n        if w.isalpha() and w not in stopwords_list:\n            clean_words.append(w.lower())\n    clean_review = \" \".join(clean_words)\n    return clean_review\n\ndf[\"Review\"] = df[\"Review\"].apply(reviewParse).apply(clean_review) #Parse all the reviews for their punctuation and add it into a new column\n\ndf.head() #Take a peek at the dataset","execution_count":null,"outputs":[]},{"metadata":{"id":"wC8RaWLjIIok","outputId":"2073560e-1bb4-439e-80bb-e77981ec9b08","trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"ABptfWZlAiFe","trusted":true},"cell_type":"code","source":"docs = list(df['Review'])[:7000]","execution_count":null,"outputs":[]},{"metadata":{"id":"qC7Q2CYp913B"},"cell_type":"markdown","source":"## Create a TFIDF matrix out of it"},{"metadata":{"id":"ZzoM7SUJnkk9","trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer \n \n# settings that you use for count vectorizer will go here \ntfidf_vectorizer=TfidfVectorizer(use_idf=True, max_features = 20000) \n \n# just send in all your docs here \ntfidf_vectorizer_vectors=tfidf_vectorizer.fit_transform(docs)","execution_count":null,"outputs":[]},{"metadata":{"id":"u-uNEDCRAk6Q","trusted":true},"cell_type":"code","source":"#tfidf_vectorizer.get_feature_names()","execution_count":null,"outputs":[]},{"metadata":{"id":"dxq3VtFYBEKN","trusted":true},"cell_type":"code","source":"X = tfidf_vectorizer_vectors.toarray()\nY = df['Sentiment'][:7000]","execution_count":null,"outputs":[]},{"metadata":{"id":"0am6bcQgI5tY","outputId":"3e2ef195-5c29-430e-b3ce-59e1889798bf","trusted":true},"cell_type":"code","source":"len(X[0])","execution_count":null,"outputs":[]},{"metadata":{"id":"qtoBFNsl99XC"},"cell_type":"markdown","source":"### Divide the data into training and validation sets"},{"metadata":{"id":"p10D9acqBjms","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV \nfrom sklearn.metrics import mean_absolute_error, accuracy_score, confusion_matrix, classification_report, roc_auc_score,roc_curve,auc\nfrom sklearn.tree import DecisionTreeClassifier\n\nSEED=123\n\nX_train,X_test,y_train,y_test=train_test_split(X, Y, test_size=0.2, random_state=SEED, stratify=Y)","execution_count":null,"outputs":[]},{"metadata":{"id":"FeO2FAywDlZr","outputId":"0b89f32a-5d2e-46be-9918-fea3caf2f175","trusted":true},"cell_type":"code","source":"fig = go.Figure([go.Bar(x=Y.value_counts().index, y=Y.value_counts().tolist())])\nfig.update_layout(\n    title=\"Values in each Sentiment\",\n    xaxis_title=\"Sentiment\",\n    yaxis_title=\"Values\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"tq_RPRuA-BGl"},"cell_type":"markdown","source":"## Decision Tree Classifier"},{"metadata":{"id":"6hEjJoDJDE3i","outputId":"1b109ea1-c049-4a06-ae00-6c9579426c42","trusted":true},"cell_type":"code","source":"dt = DecisionTreeClassifier(random_state=SEED)\ndt.fit(X_train,y_train)\ny_pred_test = dt.predict(X_test)\nprint(\"Training Accuracy score: \"+str(round(accuracy_score(y_train,dt.predict(X_train)),4)))\nprint(\"Testing Accuracy score: \"+str(round(accuracy_score(y_test,dt.predict(X_test)),4)))","execution_count":null,"outputs":[]},{"metadata":{"id":"cJKX2R9l4ndV","outputId":"6127cc98-2c2f-406e-9966-e4594363b766","trusted":true},"cell_type":"code","source":"print(classification_report(y_test, y_pred_test, target_names=['positive', 'neutral', 'negative']))","execution_count":null,"outputs":[]},{"metadata":{"id":"N-alAhbw-Ocp","outputId":"cb09e51e-dbba-411a-a789-3b1f5549eb31","trusted":true},"cell_type":"code","source":"cm = confusion_matrix(y_test, y_pred_test)\n#print('Confusion matrix\\n', cm)\ncm_matrix = pd.DataFrame(data=cm, columns=['Actual Negative', 'Actual Neutral', 'Actual Positive'], \n                        index=['Predict Negative', 'Predict Neutral', 'Predict Positive'])\nsns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"XGYo2U5g_bbv"},"cell_type":"markdown","source":"## Naive Bayes Classifier"},{"metadata":{"id":"IYz0ijMmDL8Z","outputId":"1d7c3f9d-c582-46b7-b954-47b6435181b1","trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\ngnb = GaussianNB()\ngnb.fit(X_train, y_train)\ny_pred_train = gnb.predict(X_train)\ny_pred_test = gnb.predict(X_test)\nprint(\"Training Accuracy score: \"+str(round(accuracy_score(y_train,gnb.predict(X_train)),4)))\nprint(\"Testing Accuracy score: \"+str(round(accuracy_score(y_test,gnb.predict(X_test)),4)))","execution_count":null,"outputs":[]},{"metadata":{"id":"gPtt-ff54z7Z","outputId":"7739af02-0731-423b-b788-2925d7d954c9","trusted":true},"cell_type":"code","source":"print(classification_report(y_test, y_pred_test, target_names=['positive', 'neutral', 'negative']))","execution_count":null,"outputs":[]},{"metadata":{"id":"DnXH8OWA_f3H","outputId":"17d95e12-dd91-4f90-8dba-e3603fb32ae1","trusted":true},"cell_type":"code","source":"cm = confusion_matrix(y_test, y_pred_test)\n#print('Confusion matrix\\n', cm)\ncm_matrix = pd.DataFrame(data=cm, columns=['Actual Negative', 'Actual Neutral', 'Actual Positive'], \n                        index=['Predict Negative', 'Predict Neutral', 'Predict Positive'])\nsns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"b0fD714B_y56"},"cell_type":"markdown","source":"## Logistic Regression"},{"metadata":{"id":"YULb2wQEERyf","outputId":"91e63c7f-5e32-49e7-e92c-8c6550cdc490","trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlr = LogisticRegression(random_state=SEED).fit(X_train, y_train)\ny_pred_train = lr.predict(X_train)\ny_pred_test = lr.predict(X_test)\nprint(\"Training Accuracy score: \"+str(round(accuracy_score(y_train,lr.predict(X_train)),4)))\nprint(\"Testing Accuracy score: \"+str(round(accuracy_score(y_test,lr.predict(X_test)),4)))","execution_count":null,"outputs":[]},{"metadata":{"id":"PhTaev8j41pj","outputId":"ddd4e754-1d79-4563-a88d-1f3a4d972a55","trusted":true},"cell_type":"code","source":"print(classification_report(y_test, y_pred_test, target_names=['positive', 'neutral', 'negative']))","execution_count":null,"outputs":[]},{"metadata":{"id":"pnqjKxeK_xc-","outputId":"b9a4fb57-3426-4bf1-f6b4-799eba6f1a06","trusted":true},"cell_type":"code","source":"cm = confusion_matrix(y_test, y_pred_test)\n#print('Confusion matrix\\n', cm)\ncm_matrix = pd.DataFrame(data=cm, columns=['Actual Negative', 'Actual Neutral', 'Actual Positive'], \n                        index=['Predict Negative', 'Predict Neutral', 'Predict Positive'])\nsns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"W05IqtbMBNop"},"cell_type":"markdown","source":"## Random Forest Classifier"},{"metadata":{"id":"loW2p3LiTil8","outputId":"a78b4e37-bd66-4338-98a1-4bb90ad9e516","trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nclf = RandomForestClassifier()\nclf.fit(X_train, y_train)\ny_pred_train = clf.predict(X_train)\ny_pred_test = clf.predict(X_test)\nprint(\"Training Accuracy score: \"+str(round(accuracy_score(y_train,clf.predict(X_train)),4)))\nprint(\"Testing Accuracy score: \"+str(round(accuracy_score(y_test,clf.predict(X_test)),4)))","execution_count":null,"outputs":[]},{"metadata":{"id":"tJirhdrDBYjz","outputId":"39f95528-1cc3-4129-9b86-e8df1876dc26","trusted":true},"cell_type":"code","source":"print(classification_report(y_test, y_pred_test, target_names=['positive', 'neutral', 'negative']))","execution_count":null,"outputs":[]},{"metadata":{"id":"cD7xkjBCBaYa","outputId":"0deb71d1-606c-42d8-8c4b-5b5c02ffbac7","trusted":true},"cell_type":"code","source":"cm = confusion_matrix(y_test, y_pred_test)\n#print('Confusion matrix\\n', cm)\ncm_matrix = pd.DataFrame(data=cm, columns=['Actual Negative', 'Actual Neutral', 'Actual Positive'], \n                        index=['Predict Negative', 'Predict Neutral', 'Predict Positive'])\nsns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"6Q-xxBLh_526"},"cell_type":"markdown","source":"## Ensembling "},{"metadata":{"id":"9VJL5uI-Ejam","trusted":true},"cell_type":"code","source":"from sklearn.ensemble import VotingClassifier\n\nclassifiers = [('Decision Tree', dt),\n               ('Logistic Regression', lr),\n                ('Naive Bayes', gnb)\n              ]\nvc = VotingClassifier(estimators=classifiers)\n# Fit 'vc' to the traing set and predict test set labels\nvc.fit(X_train, y_train)\n\nprint(\"Training Accuracy score: \"+str(round(accuracy_score(y_train,vc.predict(X_train)),4)))\nprint(\"Testing Accuracy score: \"+str(round(accuracy_score(y_test,vc.predict(X_test)),4)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = pd.Series(lr.predict(X), name=\"sentiment\")\nresults = pd.concat([predictions],axis=1)\nresults.to_csv(\"airbnb-review-sentiment.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Conclusion\nHence we successfully studied various models like Decision Tree, SVM, Naive Bayes and Logistic Regression and implemented them for the given dataset as part of the experiment along with a comparative analysis of various metrics and made the following observations.\n\n1. Naïve Bayes and Decision Tree are susceptible to noise if present in the dataset because when we reduced the number of features by considering only the most frequent words the accuracy and AUC score increased significantly.\n2. Logistic Regression and SVM performed almost same for the given dataset even with the initial number of features.\n3. We can increase Accuracy marginally by removing Named Entities using spacy and performing Lemmatization on top of that on all the models mentioned above.\n\n### Final Note\nSentiment analysis can be applied to countless aspects of business, from brand monitoring and product analytics, to customer service and market research. By incorporating it into their existing systems and analytics, leading brands (not to mention entire cities) are able to work faster, with more accuracy, toward more useful ends.\n\nSentiment analysis has moved beyond merely an interesting, high-tech whim, and will soon become an indispensable tool for all companies of the modern age. Ultimately, sentiment analysis enables us to glean new insights, better understand our customers, and empower our own teams more effectively so that they do better and more productive work."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}