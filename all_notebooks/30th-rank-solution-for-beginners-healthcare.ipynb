{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Problem Statement : Janatahack: Healthcare Analytics II\n\nRecent Covid-19 Pandemic has raised alarms over one of the most overlooked area to focus: Healthcare Management. While healthcare management has various use cases for using data science, patient length of stay is one critical parameter to observe and predict if one wants to improve the efficiency of the healthcare management in a hospital. \n\nThis parameter helps hospitals to identify patients of high LOS risk (patients who will stay longer) at the time of admission. Once identified, patients with high LOS risk can have their treatment plan optimized to miminize LOS and lower the chance of staff/visitor infection. Also, prior knowledge of LOS can aid in logistics such as room and bed allocation planning.\n\nSuppose you have been hired as Data Scientist of HealthMan â€“ a not for profit organization dedicated to manage the functioning of Hospitals in a professional and optimal manner.\nThe task is to accurately predict the Length of Stay for each patient on case by case basis so that the Hospitals can use this information for optimal resource allocation and better functioning. The length of stay is divided into 11 different classes ranging from 0-10 days to more than 100 days.\n\n \n\nData Description\n\n\nTrain.zip contains 1 csv alongside the data dictionary that contains definitions for each variable\n\ntrain.csv â€“ File containing features related to patient, hospital and Length of stay on case basis\n\ntrain_data_dict.csv â€“ File containing the information of the features in train file\n\n\n\nTest Set\n\ntest.csv â€“ File containing features related to patient, hospital. Need to predict the Length of stay for each case_id\n\n\n\nSample Submission:\n\ncase_id: Unique id for each case\n\nStay: Length of stay for the patient w.r.t each case id in test data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### DATASET can be downloaded here -> https://www.kaggle.com/vetrirah/av-healthcare2/","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#!/usr/bin/env python\n# coding: utf-8\n\n# In[1]:\n\nimport numpy as np\nimport pandas as pd \nimport os\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import KFold,StratifiedKFold,RepeatedStratifiedKFold\nfrom lightgbm import LGBMClassifier\nimport warnings\nwarnings.filterwarnings('ignore')\n# import eli5\n# from eli5.sklearn import PermutationImportance\nfrom sklearn.preprocessing import LabelEncoder,OneHotEncoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df      = pd.read_csv('../input/av-healthcare2/train.csv')\ntest_df       = pd.read_csv('../input/av-healthcare2/test.csv')\nsubmission_df = pd.read_csv('../input/av-healthcare2/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating Addition Features\ncombine_set=pd.concat([train_df,test_df],axis=0)\ncombine_set['City_Code_Patient'].fillna(-99,inplace=True)\ncombine_set['Bed Grade'].fillna(5,inplace=True)\ncombine_set['Unique_Hospital_per_patient']=combine_set.groupby(['patientid'])['Hospital_code'].transform('nunique')\ncombine_set['Unique_patient_per_hospital']=combine_set.groupby(['Hospital_code'])['patientid'].transform('nunique')\ncombine_set['Unique_patient_per_Department']=combine_set.groupby(['Department'])['patientid'].transform('nunique')\ncombine_set['Total_deposit_paid_by_patient_in_each_hospital']=combine_set.groupby(['Hospital_code','patientid'])['Admission_Deposit'].transform('sum')\ncombine_set['Min_Severity_of_Illness'] = combine_set.groupby('patientid')['Severity of Illness'].transform('min')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# In[4]:\n\nle = LabelEncoder()\n#Encoding categorical variables by frequency encoding and label encoding\nfor col in combine_set.select_dtypes(include='object').columns:\n    if col not in ['Age','Stay']:\n        fe=combine_set.groupby([col]).size()/len(combine_set)\n        combine_set[col]=combine_set[col].apply(lambda x: fe[x])   \n        # combine_set[col]  = pd.get_dummies(combine_set[col].astype(str))         \n    elif col!='Stay':\n        combine_set[col]=le.fit_transform(combine_set[col].astype(str))\n    else:\n        pass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# In[5]:\n\n#Splitting train and test\n\nX=combine_set[combine_set['Stay'].isnull()==False].drop(['case_id','Stay'],axis=1)\ny=le.fit_transform(combine_set[combine_set['Stay'].isnull()==False]['Stay'])\ny=pd.DataFrame(y,columns=['Stay'])\nX_main_test=combine_set[combine_set['Stay'].isnull()==True].drop(['case_id','Stay'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# In[6]:\n\n# kf=KFold(n_splits=10,shuffle=True,random_state=294)\nkf=KFold(n_splits=5,shuffle=True)\n\npreds_1   = {}\ny_pred_1  = []\nacc_score = []\n\nfor i,(train_idx,val_idx) in enumerate(kf.split(X)):    \n    \n    X_train, y_train = X.iloc[train_idx,:], y.iloc[train_idx]\n    \n    X_val, y_val = X.iloc[val_idx, :], y.iloc[val_idx]\n   \n    print('\\nFold: {}\\n'.format(i+1))\n\n    lg=LGBMClassifier(device=\"gpu\", \n                      gpu_platform_id= 0,\n                      max_bin=63,#Theoretically best speeds using LGBM\n                      gpu_device_id= 0,\n                      boosting_type='gbdt',\n                      learning_rate=0.04,\n                      # max_depth=15,\n                      # num_leaves = 150,\n                      objective='multi_class',\n                      num_class=11,                      \n                      n_estimators=50000,\n                      metric='multi_error',\n                      colsample_bytree=0.8,\n                      min_child_samples=228,\n                      reg_alpha=1,\n                      reg_lambda=1,\n                      # random_state=294,\n                      n_jobs=-1,\n                     \n                      ) \n    \n    # lg.fit(X_train,y_train)\n    lg.fit(X_train, y_train\n#                         ,categorical_feature = categorical_features\n                        ,eval_metric='multi_error'\n                        ,eval_set=[(X_train, y_train),(X_val, y_val)]\n                        ,early_stopping_rounds=100\n                        ,verbose=50\n                       )\n    \n    print(accuracy_score(y_val,lg.predict(X_val))*100)\n    \n    acc = accuracy_score(y_val,lg.predict(X_val))*100\n    acc_score.append(acc)\n    print(\"Score : \",acc)    \n    y_pred_1.append(lg.predict_proba(X_main_test))\n    \n    # preds_1[i+1]=lg.predict_proba(X_main_test)\n    # y_pred_1.append(lg.predict_proba(X_main_test))\n\ny_pred_final_1          = np.mean(np.array(y_pred_1),axis=0)\n    \nprint('mean accuracy score: {}'.format((sum(acc_score)/10)))\n\npreds_1=np.argmax(y_pred_final_1,axis=1)\n\nprint(preds_1.shape)\nsubmission_df['Stay']=le.inverse_transform(preds_1.astype(int))\n# submission_df[0] = y_pred_final_1[:,0]\n# submission_df[1] =y_pred_final_1[:,1]\n\n# Download Submission File :\ndisplay(\"submission_df\",submission_df)\nsub_file_name_1 = \"BEST_11_CV=42.96_LB=WAIT_LGBM-1.csv\"\n\nsubmission_df.to_csv(sub_file_name_1,index=False)\nsubmission_df.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from catboost                         import CatBoostClassifier\nimport timeit\n\ncatboost = CatBoostClassifier(eval_metric='Accuracy', max_depth=4, task_type=\"GPU\", devices=\"0:1\", n_estimators=1000, verbose=500)\ncatboost.fit( X, y, verbose=10 )   \ny_pred_3  = []\ny_pred_3.append(catboost.predict_proba(X_main_test))\ny_pred_final_3          = np.mean(np.array(y_pred_3),axis=0)\n# gpu_time = timeit.timeit('train_on_gpu()', setup=\"from __main__ import train_on_gpu\", number=1)\n# print('Time to fit and predict model on GPU: {} sec'.format(int(gpu_time)))\n\npreds_3=np.argmax(y_pred_final_3,axis=1)\n\nsubmission_df['Stay']=le.inverse_transform(preds_3.astype(int))\n# submission_df[0] = y_pred_final_1[:,0]\n# submission_df[1] =y_pred_final_1[:,1]\n\n# Download Submission File :\ndisplay(\"submission_df\",submission_df)\nsub_file_name_3 = \"BEST_11_CV=42.96_LB=WAIT_LGBM-1.csv\"\n\nsubmission_df.to_csv(sub_file_name_3,index=False)\nsubmission_df.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Ensemble of LGBM + CatBoost :\n\npreds = (y_pred_final_1*0.2 + y_pred_final_3*0.8) /2\npreds=np.argmax(preds,axis=1)\nprint(preds)\n\n# In[9]:\n# Download Submission File :\nsubmission_df['Stay']=le.inverse_transform(preds.astype(int))\ndisplay(\"submission_df\",submission_df)\nsub_file_name = \"ENSEMBLE_1_CV=42.22_42.17_LB=WAIT_LGB-1_0.2_LBG-2_0.8.csv\"\n\nsubmission_df.to_csv(sub_file_name,index=False)\nsubmission_df.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **<center>ðŸ˜Š Reached Rank 30 in Public Leaderboard - Thanks for reading Friends. See you all in Part 2 for more Analysis and Modelling - ENCOURAGE if you liked this Notebook ðŸ˜Š</center>**\n\n### **<center>ðŸ˜Š For Learning Purpose - You can still participate in your free time to see your Public and Private Scores & Rank, though it won't reflect on Leaderboard ðŸ˜Š</center>**\n\n### **<center>ðŸ˜Š Ask your doubts & Share your thoughts, ideas & feedbacks in Comments below ðŸ˜Š</center>**","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}