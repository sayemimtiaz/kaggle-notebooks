{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Introduction"},{"metadata":{},"cell_type":"markdown","source":"HAM10000 dataset consists of 10015 dermatoscopic images which can serve as a training set for academic machine learning purposes. \n\nCases include a representative collection of all important diagnostic categories in the realm of pigmented lesions: \n\nActinic keratoses  \n\nBowen's disease (akiec), \n\nbasal cell carcinoma (bcc), \n\nbenign keratosis-like lesions (solar lentigines / seborrheic keratoses and lichen-planus like keratoses, bkl),\n\ndermatofibroma (df),\n\nmelanoma (mel), \n\nmelanocytic nevi (nv) and \n\nvascular lesions (angiomas, angiokeratomas, pyogenic granulomas and hemorrhage, vasc).\n\n**Original Data Source\n**\n\nhttps://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/DBW86T Tschandl, P., Rosendahl, C. & Kittler, H. The HAM10000 dataset, a large collection of multi-source dermatoscopic images of common pigmented skin lesions. Sci. Data 5, 180161 (2018). doi: 10.1038/sdata.2018.161"},{"metadata":{},"cell_type":"markdown","source":"In this notebook, I aim to use the HAM10000 Dataset to classify 7 types of skin diseases.\n\nThe accuracy reached 84-85% quite more than several previous work"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"os.listdir('../input/resnet50')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport keras\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing.image import load_img\nimport datetime\nimport sys\nfrom keras.utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, Flatten,Dropout,MaxPool2D\nfrom keras.applications import ResNet50\nfrom keras import optimizers\nimport math","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1 Constructing a model**"},{"metadata":{},"cell_type":"markdown","source":"Here we construct a model based on pretrained Resnet50 model. In  order to prevent overfitting we had 2 Dropout layers. \n\nSince we have 7 class, we use a Dense of 7 neurons"},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model = ResNet50(weights='../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5',\n                      include_top=False, input_shape=(224, 224, 3))\nmodel=Sequential()\nmodel.add(base_model)\n# Freeze the layers except the last 4 layers\nmodel.add(Dropout(0.40))\nmodel.add(Flatten())\nmodel.add(Dense(512,activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(7, activation='softmax'))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2: Constructing Data Flow"},{"metadata":{},"cell_type":"markdown","source":"Reading filenames of images and their label"},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv('../input/mnist1000-with-one-image-folder/HAM10000_metadata.csv')\ndf['file_name']=df['image_id']+'.jpg'\ndf=df[['file_name','dx','lesion_id']]\ndf.head()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, we split the data into training, validation and test set with stratitied methods"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nlabel_dataframe=df.pop('dx').to_frame()\nX_train, X_test, y_train, y_test = train_test_split(df, label_dataframe, test_size=0.2, random_state=42)\nX_train,X_val,y_train,y_val=train_test_split(X_train, y_train, test_size=0.25, random_state=42)\nprint(X_val.shape)\nprint(X_train.shape)\nprint(X_test.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Concat labels with filenames"},{"metadata":{"trusted":true},"cell_type":"code","source":"train=pd.concat([X_train,y_train],axis=1)\ntrain.head()\nval=pd.concat([X_val,y_val],axis=1)\nval.head()\ntest=pd.concat([X_test,y_test],axis=1)\ntest.head()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Convert string labels to int labels"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\nvle = preprocessing.LabelEncoder()\nvle.fit(val['dx'])\nlabel=vle.transform(val['dx']) \nprint(list(vle.classes_))\nval['label']=label\nprint(train.head())\nle_name_mapping = dict(zip(vle.classes_, vle.transform(vle.classes_)))\nprint(le_name_mapping)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trle = preprocessing.LabelEncoder()\ntrle.fit(train['dx'])\nlabel=trle.transform(train['dx']) \nprint(list(trle.classes_))\ntrain['label']=label\nprint(train.head())\nle_name_mapping = dict(zip(trle.classes_, trle.transform(trle.classes_)))\nprint(le_name_mapping)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"le = preprocessing.LabelEncoder()\nle.fit(test['dx'])\nlabel=le.transform(test['dx']) \nprint(list(le.classes_))\ntest['label']=label\nprint(test.head())\nle_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\nprint(le_name_mapping)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data Augmentation and prepare the flow of data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator = ImageDataGenerator(\nrescale = 1./255,\nfeaturewise_center=False,  # set input mean to 0 over the dataset\nsamplewise_center=False,  # set each sample mean to 0\nfeaturewise_std_normalization=False,  # divide inputs by std of the dataset\nsamplewise_std_normalization=False,  # divide each input by its std\nzca_whitening=False,  # apply ZCA whitening\nrotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\nzoom_range = 0.1, # Randomly zoom image \nwidth_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\nheight_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\nhorizontal_flip=False,  # randomly flip images\nvertical_flip=False)  # randomly flip images)\n\ntrain_data= train_generator.flow_from_dataframe(\ndataframe=train,\nx_col=\"file_name\",\ny_col=\"dx\",\nbatch_size=64,\nseed=311,\ndirectory=\"../input/mnist1000-with-one-image-folder/ham1000_images/HAM1000_images\",\nshuffle=True,\nclass_mode=\"categorical\",\ntarget_size=(224,224))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_generator=ImageDataGenerator(\nrescale = 1./255)\ntest_data= test_generator.flow_from_dataframe(\ndataframe=test,\nx_col=\"file_name\",\ny_col=\"dx\",\nseed=45,\ndirectory=\"../input/mnist1000-with-one-image-folder/ham1000_images/HAM1000_images\",\nshuffle=False,\nbatch_size=1,\nclass_mode=None,\ntarget_size=(224,224))\nval_data=test_generator.flow_from_dataframe(\ndataframe=val,\ndirectory=\"../input/mnist1000-with-one-image-folder/ham1000_images/HAM1000_images\",\nx_col=\"file_name\",\ny_col=\"dx\",\nbatch_size=64,\nseed=45,\nshuffle=False,\nclass_mode=\"categorical\",\ntarget_size=(224,224))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3.Combine and run"},{"metadata":{},"cell_type":"markdown","source":"Adding classweights"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.utils import class_weight\nclass_weight = np.round(class_weight.compute_class_weight('balanced',np.unique(y_train),y_train['dx']))\nprint(class_weight)\nprint(train_data.class_indices)\nprint(val_data.class_indices)\nprint(train['dx'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Automatically reducing the LR after 3 \"patient epochs\", then run"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.metrics import top_k_categorical_accuracy\n\nfrom keras.callbacks import ReduceLROnPlateau\n\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                    patience=3, \n                                    verbose=1, \n                                    factor=0.5, \n                                    min_lr=0.00001)\n\nmodel.compile(optimizer=optimizers.adam(lr=0.0001),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\nhistory=model.fit_generator(generator=train_data,\n                    steps_per_epoch=train_data.samples//train_data.batch_size,\n                            validation_data=val_data,\n                            verbose=1,\n                            validation_steps=val_data.samples//val_data.batch_size,\n                    epochs=35,class_weight=class_weight,callbacks=[learning_rate_reduction])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Evaluation and testing on validation set"},{"metadata":{"trusted":true},"cell_type":"code","source":"val_data.reset()\npredictions = model.predict_generator(val_data, steps=val_data.samples/val_data.batch_size,verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred= np.argmax(predictions, axis=1)\nprint(y_pred)\nground_truth=val_data.classes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint('Classification Report')\ntarget_names = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv','vasc']\nprint(classification_report(val_data.classes, y_pred, target_names=target_names))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5 Evaluation and testing on test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.reset()\npredictions = model.predict_generator(test_data, steps=test_data.samples/test_data.batch_size,verbose=1)\ny_pred= np.argmax(predictions, axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_pred)\nground_truth=test['label']\nfrom sklearn.metrics import classification_report\nprint('Classification Report')\ntarget_names = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv','vasc']\nprint(classification_report(ground_truth, y_pred, target_names=target_names))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}