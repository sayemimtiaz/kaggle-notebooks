{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Tennis Predictions with Catboost\n\nThe 2019 tennis season has ended, now is a few days before 2020 starts, and this is the time to another try to predict tennis match outcome.\n\nIt is always interesting to look into the future, to try to catch the tail of the determined future in this world full of lack of information.\n\nSo, let's try it with tennis matches. I suppose writing four articles, first about method, and others with analysis of results.\n\n#### Disclaimers\n1. The data in the dataset can be inaccurate in some cases. I checked it quite many, but no quarantee here.\n2. The odds in the dataset is average early odds. You can find worse and better 'cause lines move with time. So the numbers with profit no more than estimations. \n3. This predictions based on backward analysis. There is no quarantee models shows profit in the future.\n4. Wagering on sport is a very risky business, Please do not wager real money if you venturous person. "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom catboost import CatBoostClassifier,CatBoostRegressor, Pool\nfrom sklearn.metrics import accuracy_score, mean_squared_error\nfrom sklearn.model_selection import train_test_split\nfrom math import sqrt\nfrom datetime import datetime\npd.options.mode.chained_assignment = None","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## DataProvider class\nIt is useful to have such data provider, where you can easily filter data, check transformations and so on. \n\n- y_columns - Target variable(s)\n- gender - 'wta' or 'atp'\n- start_year - if you think to limit previous stats to 3 years etc you're welcome\n- test_year - whole year as test data, years from start_year till test_year are train data\n- test_date - single day for test, all data before can be used to train (this mode mimicks realtime everyday prediction)\n- oddsMode: \n> 'No' - No lines info; \n> 'Full' - Full lines info (drop nans); \n> 'Equal' - Equal odds only (.47 - .53)\n- diffsMode: \n> 'Time' - Last to Current; \n> 'Player' - One player via another; \n> 'Both' - Diffs on diffs\n- noStatsGenerated - if True do not generate diffs for stats columns\n- noStats - if True remove stats completely\n- diffs - list of columns for which diffs must be generated \n- isDropSources - if True drop columns after diffs calculated\n- verbose - if True prits out some info\n- isCatboost - if True do nothing with NaNs\n\n### What the diffs mean?\nWe have an opposition between two players, each of whom has own history. So, we can try to look at the difference between them. Just data of the 1st player minus data of the 2nd player. \n\nAlso we can look at history prospective. How the player showed himself on the last match? On the 5 last matches? What the difference with his/her averages?\n\nAnd, of course we can calc both diffs.\n\nWe can reduce amount of variables just to remove used in diffs calculation (if it worth to).\n\n"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"class DataProvider():\n    def __init__(self, y_columns, gender='wta', start_year=2011, test_year=None, test_date=None, oddsMode='No', diffsMode='No', \n                 noStatsGenerated=False, noStats=False, diffs=[], isDropSources=False, verbose=False, isCatboost=False):\n        self.gender = gender\n        self.start_year = start_year\n        self.test_year = test_year\n        self.test_date = test_date\n        self.y_columns = y_columns\n        self.verbose = verbose\n        self.isDropSources = isDropSources\n        self.isCatboost=isCatboost\n        # No - No lines info\n        # Full - Full lines info (drop nans)\n        # Equal - Equal odds only (.47 - .53)\n        self.oddsMode = oddsMode \n        \n        # Time - Last to Current\n        # Player - One player via another\n        # Both - Diffs on diffs\n        self.diffsMode = diffsMode \n        \n        self.noStatsGenerated = noStatsGenerated\n        self.noStats=noStats\n        self.diffs = diffs\n        \n        self.cols_info_orig=['TourRank','RID_CUR','TName','GameD','Year', 'Name_1','Name_2','Result_CUR_1','GRes_CUR_1','PS_CUR_1','TTL_CUR_1',\n                             'TPoints_CUR_1','K_CUR_1','K_CUR_2','F_CUR_1', 'F_CUR_2','SETS_CUR_1','K20_CUR_1','K20_CUR_2','K21_CUR_1','K21_CUR_2'] if isCatboost else ['TourRank','RID_CUR','TName','GameD',\n                                'Year', 'Name_1','Name_2','Result_CUR_1','GRes_CUR_1','PS_CUR_1','TTL_CUR_1', 'SETS_0-2_CUR_1','SETS_1-2_CUR_1','SETS_2-0_CUR_1','SETS_2-1_CUR_1',\n                                'TPoints_CUR_1','K_CUR_1','K_CUR_2','F_CUR_1', 'F_CUR_2'] \n        self.cols_info=['TourRank','RID','Tour','GameD','Year','Name_1','Name_2','Result','GRes','PS','TTL', 'TPoints','K1','K2', 'F1','F2','SETS',\n                        'K20','K02','K21','K12' ] if isCatboost else ['TourRank','RID','Tour','GameD','Year','Name_1','Name_2','Result','GRes','PS','TTL', 'SETS_0-2','SETS_1-2','SETS_2-0',\n                                                       'SETS_2-1','TPoints','K1','K2','F1','F2'] \n        self.cols_ex=['TourCountry','TName','GameD','Name_1','Name_2','Result_CUR_1','GRes_CUR_1','PS_CUR_1','TTL_CUR_1','StatsGenerated_CUR_1','StatsGenerated_CUR_2',\n                      'SETS_CUR_1', 'Unnamed: 0', 'Result_CUR_2', 'PS_CUR_2', 'Year'] if isCatboost else ['TourCountry','TName','GameD','Name_1','Name_2','Result_CUR_1','GRes_CUR_1','PS_CUR_1','TTL_CUR_1','StatsGenerated_CUR_1','StatsGenerated_CUR_2',\n                      'SETS_0-2_CUR_1','SETS_1-2_CUR_1','SETS_2-0_CUR_1','SETS_2-1_CUR_1', 'Unnamed: 0', 'Result_CUR_2', 'PS_CUR_2', 'Year']\n    \n    def load_data(self):\n        df=pd.read_csv(f'../input/tennis-20112019/{self.gender}.csv')\n\n        if self.isCatboost:\n            di = {'SETS_2-0_CUR_1' : 0, 'SETS_0-2_CUR_1' : 1, 'SETS_2-1_CUR_1' : 2, 'SETS_1-2_CUR_1' : 3}\n            df['SETS_CUR_1']=df[['SETS_0-2_CUR_1','SETS_1-2_CUR_1','SETS_2-0_CUR_1','SETS_2-1_CUR_1']].idxmax(axis=1)\n            df['SETS_CUR_1']=df['SETS_CUR_1'].map(di)\n\n            di = {'SETS_2-0_1' : 0, 'SETS_0-2_1' : 1, 'SETS_2-1_1' : 2, 'SETS_1-2_1' : 3}\n            df['SETS_1']=df[['SETS_2-0_1', 'SETS_0-2_1', 'SETS_2-1_1', 'SETS_1-2_1']].idxmax(axis=1)\n            df['SETS_1']=df['SETS_1'].map(di)\n            \n            di = {'SETS_2-0_2' : 0, 'SETS_0-2_2' : 1, 'SETS_2-1_2' : 2, 'SETS_1-2_2' : 3}\n            df['SETS_2']=df[['SETS_2-0_2', 'SETS_0-2_2', 'SETS_2-1_2', 'SETS_1-2_2']].idxmax(axis=1)\n            df['SETS_2']=df['SETS_2'].map(di)\n            df.drop(['SETS_0-2_CUR_1','SETS_1-2_CUR_1','SETS_2-0_CUR_1','SETS_2-1_CUR_1','SETS_0-2_1','SETS_1-2_1','SETS_2-0_1','SETS_2-1_1',\n                     'SETS_0-2_2','SETS_1-2_2','SETS_2-0_2','SETS_2-1_2'], axis=1, inplace=True)\n        \n        if self.verbose:\n            print(f'Set start to {self.start_year} year ({len(df)} records).')\n        \n        if self.noStatsGenerated:\n            df=df[(df['StatsGenerated_CUR_1']==0) & (df['StatsGenerated_CUR_2']==0)]\n            if self.verbose:\n                print(f'Remove generated stats ({len(df)} records).')\n        \n        if self.oddsMode=='No':\n            dfi = df[self.cols_info_orig]\n            df.drop(['K_CUR_1', 'TPoints_CUR_1', 'F_CUR_1','K_CUR_2', 'TPoints_CUR_2', 'F_CUR_2','K20_CUR_1','K21_CUR_1','K20_CUR_2','K21_CUR_2'], axis=1, inplace=True)\n        elif self.oddsMode=='Full':\n            if not self.isCatboost:\n                df.dropna(subset=['K_CUR_1', 'TPoints_CUR_1', 'F_CUR_1','K_CUR_2', 'TPoints_CUR_2', 'F_CUR_2'], inplace=True)\n            if self.verbose:\n                print(f'Full odds mode has applied ({len(df)} records).')\n        elif self.oddsMode=='Equal':\n            df=df[(df['K_CUR_1']>=0.47) & (df['K_CUR_1']<=0.53)]\n            if self.verbose:\n                print(f'Equal odds mode 2 has applied ({len(df)} records).')\n            \n        if self.oddsMode!='No':\n            dfi = df[self.cols_info_orig]\n        dfi.columns=self.cols_info\n        # ********* DIFFS CALCULATION *********\n        for diff in self.diffs:\n            if diff=='RID':\n                if self.diffsMode=='Time' or self.diffsMode=='Both':\n                    df[f'{diff}_DT_1']=df[f'{diff}_1']-df[f'{diff}_CUR']\n                    df[f'{diff}_DT_2']=df[f'{diff}_2']-df[f'{diff}_CUR']\n                if self.diffsMode=='Player' or self.diffsMode=='Both':\n                    df[f'{diff}_DP']=df[f'{diff}_1']-df[f'{diff}_2']\n                if self.diffsMode=='Both':\n                    df[f'{diff}_DTP']=df[f'{diff}_DT_1']-df[f'{diff}_DT_2']\n                    if self.isDropSources:\n                        df.drop([f'{diff}_DT_1',f'{diff}_DT_2'], axis=1, inplace=True)\n            elif diff=='TourRank':\n                if self.diffsMode=='Time' or self.diffsMode=='Both':\n                    df[f'{diff}_DT_1']=df[f'{diff}_1']-df[f'{diff}']\n                    df[f'{diff}_DT_2']=df[f'{diff}_2']-df[f'{diff}']\n                if self.diffsMode=='Player' or self.diffsMode=='Both':\n                    df[f'{diff}_DP']=df[f'{diff}_1']-df[f'{diff}_2']\n                if self.diffsMode=='Both':\n                    df[f'{diff}_DTP']=df[f'{diff}_DT_1']-df[f'{diff}_DT_2']\n                    if self.isDropSources:\n                        df.drop([f'{diff}_DT_1',f'{diff}_DT_2'], axis=1, inplace=True)\n            elif diff=='K' or diff=='F' or diff=='TPoints':\n                if self.diffsMode=='Time' or self.diffsMode=='Both':\n                    df[f'{diff}_DT1_1']=df[f'{diff}_CUR_1']-df[f'{diff}_1']\n                    df[f'{diff}_DT1_2']=df[f'{diff}_CUR_2']-df[f'{diff}_1']\n                    df[f'{diff}_DT5_1']=df[f'{diff}_CUR_1']-df[f'{diff}_L5_1']\n                    df[f'{diff}_DT5_2']=df[f'{diff}_CUR_2']-df[f'{diff}_L5_1']\n                    df[f'{diff}_DTA_1']=df[f'{diff}_CUR_1']-df[f'{diff}_A_1']\n                    df[f'{diff}_DTA_2']=df[f'{diff}_CUR_2']-df[f'{diff}_A_1']\n                if self.diffsMode=='Player' or self.diffsMode=='Both':\n                    df[f'{diff}_DP']=df[f'{diff}_CUR_1']-df[f'{diff}_CUR_2']\n                if self.diffsMode=='Both':\n                    df[f'{diff}_DTP1']=df[f'{diff}_DT1_1']-df[f'{diff}_DT1_2']\n                    df[f'{diff}_DTP5']=df[f'{diff}_DT5_1']-df[f'{diff}_DT5_2']\n                    df[f'{diff}_DTPA']=df[f'{diff}_DTA_1']-df[f'{diff}_DTA_2']\n                    if self.isDropSources:\n                        df.drop([f'{diff}_DT1_1',f'{diff}_DT1_2',f'{diff}_DT5_1',f'{diff}_DT5_2',f'{diff}_DTA_1',f'{diff}_DTA_2'], axis=1, inplace=True)\n            elif diff=='Age':\n                if self.diffsMode=='Player' or self.diffsMode=='Both':\n                    df[f'{diff}_DP']=df[f'{diff}_CUR_1']-df[f'{diff}_CUR_2']\n                    if self.isDropSources:\n                        df.drop([f'{diff}_CUR_1',f'{diff}_CUR_1'], axis=1, inplace=True)\n            else:\n                if self.diffsMode=='Time' or self.diffsMode=='Both':\n                    df[f'{diff}_DT1_1']=df[f'{diff}_1']-df[f'{diff}_A_1']\n                    df[f'{diff}_DT1_2']=df[f'{diff}_2']-df[f'{diff}_A_2']\n                    df[f'{diff}_DT5_1']=df[f'{diff}_L5_1']-df[f'{diff}_A_1']\n                    df[f'{diff}_DT5_2']=df[f'{diff}_L5_2']-df[f'{diff}_A_2']\n                if self.diffsMode=='Player' or self.diffsMode=='Both':\n                    df[f'{diff}_DP']=df[f'{diff}_1']-df[f'{diff}_2']\n                    df[f'{diff}_DP5']=df[f'{diff}_L5_1']-df[f'{diff}_L5_2']\n                    df[f'{diff}_DPA']=df[f'{diff}_A_1']-df[f'{diff}_A_2']\n                if self.diffsMode=='Both':\n                    df[f'{diff}_DT1P']=df[f'{diff}_DT1_1']-df[f'{diff}_DT1_2']\n                    df[f'{diff}_DT5P']=df[f'{diff}_DT5_1']-df[f'{diff}_DT5_2']\n                    if self.isDropSources:\n                        df.drop([f'{diff}_DT1_1',f'{diff}_DT1_2',f'{diff}_DT5_1',f'{diff}_DT5_2'], axis=1, inplace=True)\n                if self.isDropSources:\n                    df.drop([f'{diff}_1',f'{diff}_2',f'{diff}_L5_1',f'{diff}_L5_2',f'{diff}_A_1',f'{diff}_A_2'], axis=1, inplace=True)\n        return self.split_xy(df, dfi)\n        \n    def split_xy(self, df, dfi):\n        if self.test_year:\n            dfyr = df[df['Year'] == self.test_year]\n            df = df[df['Year'] < self.test_year]\n            dfyr_info = dfi[dfi['Year'] >= self.test_year]\n            df_info = dfi[dfi['Year'] < self.test_year]\n            if self.verbose:\n                print(f'Data was divided to main ({len(df)} rows) and {self.test_year} ({len(dfyr)} rows) parts.')\n        elif self.test_date:\n            dfyr = df[df['GameD'] == self.test_date]\n            df = df[df['GameD'] < self.test_date]\n            dfyr_info = dfi[dfi['GameD'] == self.test_date]\n            df_info = dfi[dfi['GameD'] < self.test_date]\n            \n        if self.noStats:\n            cols_Aces=[col for col in dfyr if col.startswith('Aces')]\n            cols_BreakPoints=[col for col in dfyr if col.startswith('BreakPoints')]\n            cols_DoubleFaults=[col for col in dfyr if col.startswith('DoubleFaults')]\n            cols_ReceivingPoints=[col for col in dfyr if col.startswith('ReceivingPoints')]\n            cols_TotalPoints=[col for col in dfyr if col.startswith('TotalPoints')]\n            cols_Serve=[col for col in dfyr if col.startswith('Serve')] # Both\n            cols_stats=cols_Aces+cols_BreakPoints+cols_DoubleFaults+cols_ReceivingPoints+cols_TotalPoints+cols_Serve\n        \n        df_y=df[self.y_columns]\n        df.drop(self.cols_ex, axis=1, inplace=True, errors='ignore')\n        dfyr_y=dfyr[self.y_columns]\n        dfyr.drop(self.cols_ex, axis=1, inplace=True, errors='ignore')\n        if self.noStats:\n            df.drop(cols_stats, axis=1, inplace=True, errors='ignore')\n            dfyr.drop(cols_stats, axis=1, inplace=True, errors='ignore')\n                \n        return (df_info, df, df_y, dfyr_info, dfyr, dfyr_y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Transformer class\nSuch class is useful for fill NaNs with means or medians, for work with categorical and binary features. But for catboost most of BasicTransformer potential is not necessary. So, the flag isCatboost=True switches off most of them."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.base import BaseEstimator\n\nclass BasicTransformer(BaseEstimator):\n    \n    def __init__(self, num_strategy='median',  return_df=False, isCatboost=True):\n        self.cols_cat=['RID_CUR','Surface','TourRank','Month','WeekDay','RID_1','TourRank_1','RID_2','TourRank_2',\n                       'SETS_1','SETS_2'] if isCatboost else ['RID_CUR','Surface','TourRank','Month','WeekDay','RID_1','TourRank_1','RID_2','TourRank_2']\n        self.cols_bin=['IsHome_CUR_1','IsBirthDay_CUR_1','IsLastRet_CUR_1','IsHome_1','HomeChanged_CUR_1','TourChanged_CUR_1','SurfaceChanged_CUR_1', 'GRes_1', 'IsHome_CUR_2',\n                       'IsBirthDay_CUR_2','IsLastRet_CUR_2','IsHome_2','HomeChanged_CUR_2','TourChanged_CUR_2','SurfaceChanged_CUR_2', 'GRes_2'] if isCatboost else ['IsHome_CUR_1',\n                       'IsBirthDay_CUR_1','IsLastRet_CUR_1','IsHome_1','HomeChanged_CUR_1','TourChanged_CUR_1','SurfaceChanged_CUR_1',\n                        'GRes_1','SETS_0-2_1','SETS_1-2_1','SETS_2-0_1','SETS_2-1_1',\n                        'IsHome_CUR_2','IsBirthDay_CUR_2','IsLastRet_CUR_2','IsHome_2','HomeChanged_CUR_2','TourChanged_CUR_2','SurfaceChanged_CUR_2',\n                        'GRes_2','SETS_0-2_2','SETS_1-2_2','SETS_2-0_2','SETS_2-1_2',]\n        \n        if num_strategy not in ['mean', 'median']:\n            raise ValueError('num_strategy must be either \"mean\" or \"median\"')\n        self.num_strategy = num_strategy\n        self.return_df = return_df\n        self.isCatboost = isCatboost\n\n    def transform(self, X):\n        # check that we have a DataFrame with same column names as the one we fit\n        if set(self._columns) != set(X.columns):\n            raise ValueError('Passed DataFrame has different columns than fit DataFrame')\n        elif len(self._columns) != len(X.columns):\n            raise ValueError('Passed DataFrame has different number of columns than fit DataFrame')\n            \n        # fill missing values\n        num_cols = self._column_dtypes['num']\n        X_num = X[num_cols] if self.isCatboost else X[num_cols].fillna(self._num_fill) \n        # Copy binary columns\n        X_bin=X[self._column_dtypes['bin']].values.astype(int)\n\n        if not self.isCatboost:\n            # Standardize numerics\n            std = X_num.std()\n            X_num = (X_num - X_num.mean()) / std\n            zero_std = np.where(std == 0)[0]\n\n            # If there is 0 standard deviation, then all values are the \n            # same. Set them to 0.\n            if len(zero_std) > 0:\n                X_num.iloc[:, zero_std] = 0\n        X_num = X_num.values\n        if self.isCatboost:\n            X_cat = X[self._column_dtypes['cat']].values.astype(int)\n        else:\n            # create separate array for new encoded categoricals\n            X_cat = np.empty((len(X), self._total_cat_cols), dtype='uint8')\n            i = 0\n            for col in self._column_dtypes['cat']:\n                vals = self._cat_cols[col]\n                for val in vals:\n                    X_cat[:, i] = X[col] == val\n                    i += 1\n            X_cat=X_cat.astype(int)\n        # concatenate transformed numeric and categorical arrays\n        data = np.column_stack((X_bin, X_num, X_cat))\n        # return either a DataFrame or an array\n        if self.return_df:\n            dfbin = pd.DataFrame(data=X_bin).astype('int32')\n            dfnum = pd.DataFrame(data=X_num)\n            dfcat = pd.DataFrame(data=X_cat).astype('int32')\n            df = pd.concat([dfbin, dfnum, dfcat], axis=1)\n            df.columns=self._feature_names\n            return df\n        else:\n            return np.column_stack((X_bin, X_num, X_cat))\n    \n    def fit_transform(self, X, y=None):\n        return self.fit(X).transform(X)\n    \n    def get_feature_names(self):\n        return self._feature_names\n\n    def fit(self, X, y=None):\n        # Assumes X is a DataFrame\n\n        # Set cat cols type to uint8\n        X=self.set_binary(X)\n        self._columns = X.columns.values\n\n        # Split data into categorical and numeric\n        self._dtypes = X.dtypes.values\n        self._kinds = np.array([dt.kind for dt in X.dtypes])\n        self._column_dtypes = {}\n        is_num = self._kinds == 'f'\n        self._column_dtypes['bin'] = np.intersect1d(self.cols_bin,X.columns)\n        self._column_dtypes['cat'] = np.intersect1d(self.cols_cat,X.columns)\n        self._column_dtypes['num'] = self._columns[is_num]\n        self._feature_names = np.append(self._column_dtypes['bin'],self._column_dtypes['num'])\n        if self.isCatboost:\n            self._feature_names = np.append(self._feature_names, self._column_dtypes['cat'] )\n        else:\n            # Create a dictionary mapping categorical column to unique \n            # values above threshold\n            self._cat_cols = {}\n            for col in self._column_dtypes['cat']:\n                vc = X[col].value_counts()\n                vals = vc.index.values\n                self._cat_cols[col] = vals\n                self._feature_names = np.append(self._feature_names, [f'{col}_{val}' for val in vals])\n\n            # get total number of new categorical columns    \n            self._total_cat_cols = sum([len(v) for col, v in self._cat_cols.items()])\n        \n        # get mean or median\n        num_cols = self._column_dtypes['num']\n        self._num_fill = X[num_cols].agg(self.num_strategy)\n        return self\n        \n\n    def set_binary(self,X):\n        cols=self.cols_bin+self.cols_cat\n        cols=np.intersect1d(cols,X.columns)\n        for c in cols:\n            X[c]=X[c].fillna(0).astype(np.uint8)\n        return X","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model for Moneylines\nMoneylines is a type of bookies lines on the match winner market. For a tennis match there are two outcomes: Player 1 won or Player 2 won.\nMatch winner is a big market and every bookie provide this. And bookies margin is quite small. But for the smallest tour ranks (in the database TourRank==0) not every bookmaker provides lines, and low limits."},{"metadata":{"trusted":true},"cell_type":"code","source":"dp=DataProvider(['GRes_CUR_1'], gender='atp', start_year=2011, test_year=2019, oddsMode='No', diffsMode='Both', noStatsGenerated=False,isCatboost=True,\n            diffs=['Age', 'RID', 'TourRank', 'GRes', 'TTL', 'PS', 'Aces', 'DoubleFaults', 'TotalPointsWon', 'ReceivingPointsWon', \n             'Serve1stPCT', 'Serve1stWonPCT', 'Serve2ndWonPCT', 'BreakPointsConvertedPCT', 'ReceivingPointsWonPCT'])\n            #diffs=['Age', 'RID', 'TourRank', 'GRes', 'TTL', 'PS'])\ndf_info, df_x, df_y, info_year, df_year, y_year=dp.load_data() \ndf_train, df_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.2, random_state=42) \nbt = BasicTransformer(return_df=True, num_strategy='mean',) \nX_train = bt.fit_transform(df_train) \nX_test=bt.transform(df_test) \nX_year=bt.transform(df_year) \ncate_features_index = np.where(X_train.dtypes != float)[0] \ntrain_pool = Pool(X_train,y_train,cat_features=cate_features_index) \ntest_pool = Pool(X_test,y_test,cat_features=cate_features_index)\n\nmodel = CatBoostClassifier(verbose=False, iterations=1000, loss_function= 'Logloss', eval_metric='AUC',use_best_model=True, random_seed=42, \n                           learning_rate=0.02, has_time=False, depth=8, l2_leaf_reg=5, random_strength=1, bagging_temperature=0)\n\nmodel.fit(train_pool,eval_set=test_pool) \npreds_class = model.predict(X_year) \natp_ml_acc=accuracy_score(preds_class,y_year)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dp=DataProvider(['GRes_CUR_1'], gender='wta', start_year=2011, test_year=2019, oddsMode='No', diffsMode='Both', noStatsGenerated=False,isCatboost=True,\n            diffs=['Age', 'RID', 'TourRank', 'GRes', 'TTL', 'PS', 'Aces', 'DoubleFaults', 'TotalPointsWon', 'ReceivingPointsWon', \n             'Serve1stPCT', 'Serve1stWonPCT', 'Serve2ndWonPCT', 'BreakPointsConvertedPCT', 'ReceivingPointsWonPCT'])\n            #diffs=['Age', 'RID', 'TourRank', 'GRes', 'TTL', 'PS'])\ndf_info, df_x, df_y, info_year, df_year, y_year=dp.load_data() \ndf_train, df_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.2, random_state=42) \nbt = BasicTransformer(return_df=True, num_strategy='mean',) \nX_train = bt.fit_transform(df_train) \nX_test=bt.transform(df_test) \nX_year=bt.transform(df_year) \ncate_features_index = np.where(X_train.dtypes != float)[0] \ntrain_pool = Pool(X_train,y_train,cat_features=cate_features_index) \ntest_pool = Pool(X_test,y_test,cat_features=cate_features_index)\n\nmodel = CatBoostClassifier(verbose=False, iterations=1000, loss_function= 'Logloss', eval_metric='AUC',use_best_model=True, random_seed=42, \n                           learning_rate=0.02, has_time=False, depth=8, l2_leaf_reg=5, random_strength=1, bagging_temperature=0)\n\nmodel.fit(train_pool,eval_set=test_pool) \npreds_class = model.predict(X_year) \nwta_ml_acc=accuracy_score(preds_class,y_year)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Accuracy of models above is {:.2%} for ATP and {:.2%} for WTA matches for 2019 year.'.format(atp_ml_acc, wta_ml_acc))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Look for accuracy, is it good or not? It is impossible to say now, because bookies probabilities from odds is not equal. \n\nFor analysis of results please read my other article [Tennis with Catboost: Moneylines](http://www.kaggle.com/hwaitt/tennis-with-catboost-moneylines)."},{"metadata":{},"cell_type":"markdown","source":"## Model for Totals\nIn total games lines bookies provide most important number - games total points and two odds (usually equal and vary because of margin depends from bookie, tour rank). \nYou should predict what outcome is more likely - games will be more then games total points or otherwise.\nThis matket is smaller then Moneylines, so lower limits and higher bookies matgin aplied here."},{"metadata":{"trusted":true},"cell_type":"code","source":"dp=DataProvider(['TTL_CUR_1'], gender='atp', start_year=2011, test_year=2019, oddsMode='No', diffsMode='Both', noStatsGenerated=False,\n            diffs=['Age', 'RID', 'TourRank', 'GRes', 'TTL', 'PS', 'Serve1stWonPCT','BreakPointsConvertedPCT', 'ReceivingPointsWonPCT'])\n            #diffs=['Age', 'RID', 'TourRank', 'GRes', 'TTL', 'PS'])\ndf_info, df_x, df_y, info_year, df_year, y_year=dp.load_data() \ndf_train, df_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.2, random_state=42) \nbt = BasicTransformer(return_df=True, num_strategy='mean') \nX_train = bt.fit_transform(df_train) \nX_test=bt.transform(df_test) \nX_year=bt.transform(df_year) \ncate_features_index = np.where(X_train.dtypes != float)[0] \ntrain_pool = Pool(X_train,y_train,cat_features=cate_features_index) \ntest_pool = Pool(X_test,y_test,cat_features=cate_features_index) \nmodel = CatBoostRegressor(verbose=False, iterations=500, loss_function= 'RMSE', eval_metric='RMSE',use_best_model=True, random_seed=42, \n                          learning_rate=0.03, has_time=False, depth=6, l2_leaf_reg=5, random_strength=0.5, bagging_temperature=0) \nmodel.fit(train_pool,eval_set=test_pool) \npreds_proba = model.predict(X_year)\natp_total=sqrt(mean_squared_error(preds_proba,y_year))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dp=DataProvider(['TTL_CUR_1'], gender='wta', start_year=2011, test_year=2019, oddsMode='No', diffsMode='Both', noStatsGenerated=False,\n            diffs=['Age', 'RID', 'TourRank', 'GRes', 'TTL', 'PS', 'Serve1stWonPCT','BreakPointsConvertedPCT', 'ReceivingPointsWonPCT'])\n            #diffs=['Age', 'RID', 'TourRank', 'GRes', 'TTL', 'PS'])\ndf_info, df_x, df_y, info_year, df_year, y_year=dp.load_data() \ndf_train, df_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.2, random_state=42) \nbt = BasicTransformer(return_df=True, num_strategy='mean') \nX_train = bt.fit_transform(df_train) \nX_test=bt.transform(df_test) \nX_year=bt.transform(df_year) \ncate_features_index = np.where(X_train.dtypes != float)[0] \ntrain_pool = Pool(X_train,y_train,cat_features=cate_features_index) \ntest_pool = Pool(X_test,y_test,cat_features=cate_features_index) \nmodel = CatBoostRegressor(verbose=False, iterations=500, loss_function= 'RMSE', eval_metric='RMSE',use_best_model=True, random_seed=42, \n                          learning_rate=0.03, has_time=False, depth=6, l2_leaf_reg=5, random_strength=0.5, bagging_temperature=0) \nmodel.fit(train_pool,eval_set=test_pool) \npreds_proba = model.predict(X_year)\nwta_total=sqrt(mean_squared_error(preds_proba,y_year))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Total mean error is {:.2} for ATP and {:.2} for WTA matches.'.format(atp_total,wta_total))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The error looks quite big, so probably no profit here. For more info please read this notebook."},{"metadata":{},"cell_type":"markdown","source":"## Model for Exact Scores\nExact scores is a market for four sets outcomes: 2-0, 2-1, 1-2 and 0-2\nThis market is much smaller then moneylines and totals. Not every bookie has lines on this market, margin is big and limits are low."},{"metadata":{"trusted":true},"cell_type":"code","source":"dp=DataProvider(['SETS_CUR_1'], gender='atp', start_year=2011, test_year=2019, oddsMode='No', diffsMode='Both', noStatsGenerated=False,isCatboost=True,\n            diffs=['Age', 'RID', 'TourRank', 'GRes', 'TTL', 'PS', 'Aces', 'DoubleFaults', 'TotalPointsWon', 'ReceivingPointsWon', \n            'Serve1stPCT', 'Serve1stWonPCT', 'Serve2ndWonPCT', 'BreakPointsConvertedPCT', 'ReceivingPointsWonPCT'])\n            #diffs=['Age', 'RID', 'TourRank', 'GRes', 'TTL', 'PS'])\n\ndf_info, df_x, df_y, info_year, df_year, y_year=dp.load_data() \ndf_train, df_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.2, random_state=42) \nbt = BasicTransformer(return_df=True, num_strategy='mean',) \nX_train = bt.fit_transform(df_train) \nX_test=bt.transform(df_test) \nX_year=bt.transform(df_year) \ncate_features_index = np.where(X_train.dtypes != float)[0] \ntrain_pool = Pool(X_train,y_train,cat_features=cate_features_index) \ntest_pool = Pool(X_test,y_test,cat_features=cate_features_index)\n\nmodel = CatBoostClassifier(verbose=False, iterations=250, loss_function= 'MultiClass', eval_metric='MultiClass',use_best_model=True, random_seed=42, \n                           learning_rate=0.2, has_time=False, depth=6, l2_leaf_reg=5, random_strength=1, bagging_temperature=0)\n\nmodel.fit(train_pool,eval_set=test_pool) \npreds_class = model.predict(X_year) \natp_sc=accuracy_score(preds_class,y_year)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dp=DataProvider(['SETS_CUR_1'], gender='wta', start_year=2011, test_year=2019, oddsMode='No', diffsMode='Both', noStatsGenerated=False,isCatboost=True,\n            diffs=['Age', 'RID', 'TourRank', 'GRes', 'TTL', 'PS', 'Aces', 'DoubleFaults', 'TotalPointsWon', 'ReceivingPointsWon', \n            'Serve1stPCT', 'Serve1stWonPCT', 'Serve2ndWonPCT', 'BreakPointsConvertedPCT', 'ReceivingPointsWonPCT'])\n            #diffs=['Age', 'RID', 'TourRank', 'GRes', 'TTL', 'PS'])\n\ndf_info, df_x, df_y, info_year, df_year, y_year=dp.load_data() \ndf_train, df_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.2, random_state=42) \nbt = BasicTransformer(return_df=True, num_strategy='mean',) \nX_train = bt.fit_transform(df_train) \nX_test=bt.transform(df_test) \nX_year=bt.transform(df_year) \ncate_features_index = np.where(X_train.dtypes != float)[0] \ntrain_pool = Pool(X_train,y_train,cat_features=cate_features_index) \ntest_pool = Pool(X_test,y_test,cat_features=cate_features_index)\n\nmodel = CatBoostClassifier(verbose=False, iterations=250, loss_function= 'MultiClass', eval_metric='MultiClass',use_best_model=True, random_seed=42, \n                           learning_rate=0.2, has_time=False, depth=6, l2_leaf_reg=5, random_strength=1, bagging_temperature=0)\n\nmodel.fit(train_pool,eval_set=test_pool) \npreds_class = model.predict(X_year) \nwta_sc=accuracy_score(preds_class,y_year)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Exact scores accuracy is {:.2%} for ATP and {:.2%} for WTA matches.'.format(atp_sc,wta_sc))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The results on 4 different outcomes looks promising."},{"metadata":{},"cell_type":"markdown","source":"## Predicted matches\nTo make analysis I decided to predict matches for every day three consecutive years - 2017, 2018 and 2019. For speed up the process I trained models every Sunday and used those models to predict further matches until next Sunday. There is no big problem to train models every day in real-time application. \n\nThere are two files in the dataset with predicted matches: atp_picks.csv and wta_picks.csv. "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}