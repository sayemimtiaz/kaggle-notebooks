{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set()\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR, CyclicLR\nimport torchvision\nfrom torchvision import datasets, models, transforms\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn.functional as F\n\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.utils.class_weight import compute_class_weight\n\n\nfrom glob import glob\nfrom skimage.io import imread\nfrom os import listdir\n\nimport time\nimport copy\nfrom tqdm import tqdm_notebook as tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"run_training = False\nretrain = False\nfind_learning_rate = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"files = listdir(\"../input/breast-histopathology-images/\")\nprint(len(files))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"files[0:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"files = listdir(\"../input/breast-histopathology-images/IDC_regular_ps50_idx5/\")\nlen(files)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_path = \"../input/breast-histopathology-images/IDC_regular_ps50_idx5/\"\nfolder = listdir(base_path)\nlen(folder)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"total_images = 0\nfor n in range(len(folder)):\n    patient_id = folder[n]\n    for c in [0, 1]:\n        patient_path = base_path + patient_id \n        class_path = patient_path + \"/\" + str(c) + \"/\"\n        subfiles = listdir(class_path)\n        total_images += len(subfiles)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_images","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"data = pd.DataFrame(index=np.arange(0, total_images), columns=[\"patient_id\", \"path\", \"target\"])\n\nk = 0\nfor n in range(len(folder)):\n    patient_id = folder[n]\n    patient_path = base_path + patient_id \n    for c in [0,1]:\n        class_path = patient_path + \"/\" + str(c) + \"/\"\n        subfiles = listdir(class_path)\n        for m in range(len(subfiles)):\n            image_path = subfiles[m]\n            data.iloc[k][\"path\"] = class_path + image_path\n            data.iloc[k][\"target\"] = c\n            data.iloc[k][\"patient_id\"] = patient_id\n            k += 1  \n\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ok, now for each patient we know the path for each patch as well as if it contains IDC or not (the target)."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"cancer_perc = data.groupby(\"patient_id\").target.value_counts()/ data.groupby(\"patient_id\").target.size()\ncancer_perc = cancer_perc.unstack()\n\nfig, ax = plt.subplots(1,3,figsize=(20,5))\nsns.distplot(data.groupby(\"patient_id\").size(), ax=ax[0], color=\"Orange\", kde=False, bins=30)\nax[0].set_xlabel(\"Number of patches\")\nax[0].set_ylabel(\"Frequency\");\nax[0].set_title(\"How many patches do we have per patient?\");\nsns.distplot(cancer_perc.loc[:, 1]*100, ax=ax[1], color=\"Tomato\", kde=False, bins=30)\nax[1].set_title(\"How much percentage of an image is covered by IDC?\")\nax[1].set_ylabel(\"Frequency\")\nax[1].set_xlabel(\"% of patches with IDC\");\nsns.countplot(data.target, palette=\"Set2\", ax=ax[2]);\nax[2].set_xlabel(\"no(0) versus yes(1)\")\nax[2].set_title(\"How many patches show IDC?\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.target = data.target.astype(np.int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pos_selection = np.random.choice(data[data.target==1].index.values, size=50, replace=False)\nneg_selection = np.random.choice(data[data.target==0].index.values, size=50, replace=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Cancer patches"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig, ax = plt.subplots(5,10,figsize=(20,10))\n\nfor n in range(5):\n    for m in range(10):\n        idx = pos_selection[m + 10*n]\n        image = imread(data.loc[idx, \"path\"])\n        ax[n,m].imshow(image)\n        ax[n,m].grid(False)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(5,10,figsize=(20,10))\n\nfor n in range(5):\n    for m in range(10):\n        idx = neg_selection[m + 10*n]\n        image = imread(data.loc[idx, \"path\"])\n        ax[n,m].imshow(image)\n        ax[n,m].grid(False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def extract_coords(df):\n    coord = df.path.str.rsplit(\"_\", n=4, expand=True)\n    coord = coord.drop([0, 1, 4], axis=1)\n    coord = coord.rename({2: \"x\", 3: \"y\"}, axis=1)\n    coord.loc[:, \"x\"] = coord.loc[:,\"x\"].str.replace(\"x\", \"\", case=False).astype(np.int)\n    coord.loc[:, \"y\"] = coord.loc[:,\"y\"].str.replace(\"y\", \"\", case=False).astype(np.int)\n    df.loc[:, \"x\"] = coord.x.values\n    df.loc[:, \"y\"] = coord.y.values\n    return df\n\ndef get_cancer_dataframe(patient_id, cancer_id):\n    path = base_path + patient_id + \"/\" + cancer_id\n    files = listdir(path)\n    dataframe = pd.DataFrame(files, columns=[\"filename\"])\n    path_names = path + \"/\" + dataframe.filename.values\n    dataframe = dataframe.filename.str.rsplit(\"_\", n=4, expand=True)\n    dataframe.loc[:, \"target\"] = np.int(cancer_id)\n    dataframe.loc[:, \"path\"] = path_names\n    dataframe = dataframe.drop([0, 1, 4], axis=1)\n    dataframe = dataframe.rename({2: \"x\", 3: \"y\"}, axis=1)\n    dataframe.loc[:, \"x\"] = dataframe.loc[:,\"x\"].str.replace(\"x\", \"\", case=False).astype(np.int)\n    dataframe.loc[:, \"y\"] = dataframe.loc[:,\"y\"].str.replace(\"y\", \"\", case=False).astype(np.int)\n    return dataframe\n\ndef get_patient_dataframe(patient_id):\n    df_0 = get_cancer_dataframe(patient_id, \"0\")\n    df_1 = get_cancer_dataframe(patient_id, \"1\")\n    patient_df = df_0.append(df_1)\n    return patient_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"example = get_patient_dataframe(data.patient_id.values[0])\nexample.head()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(5,3,figsize=(20, 27))\n\npatient_ids = data.patient_id.unique()\n\nfor n in range(5):\n    for m in range(3):\n        patient_id = patient_ids[m + 3*n]\n        example_df = get_patient_dataframe(patient_id)\n        \n        ax[n,m].scatter(example_df.x.values, example_df.y.values, c=example_df.target.values, cmap=\"coolwarm\", s=20);\n        ax[n,m].set_title(\"patient \" + patient_id)\n        ax[n,m].set_xlabel(\"y coord\")\n        ax[n,m].set_ylabel(\"x coord\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def visualise_breast_tissue(patient_id, pred_df=None):\n    example_df = get_patient_dataframe(patient_id)\n    max_point = [example_df.y.max()-1, example_df.x.max()-1]\n    grid = 255*np.ones(shape = (max_point[0] + 50, max_point[1] + 50, 3)).astype(np.uint8)\n    mask = 255*np.ones(shape = (max_point[0] + 50, max_point[1] + 50, 3)).astype(np.uint8)\n    if pred_df is not None:\n        patient_df = pred_df[pred_df.patient_id == patient_id].copy()\n    mask_proba = np.zeros(shape = (max_point[0] + 50, max_point[1] + 50, 1)).astype(np.float)\n    \n    broken_patches = []\n    for n in range(len(example_df)):\n        try:\n            image = imread(example_df.path.values[n])\n            \n            target = example_df.target.values[n]\n            \n            x_coord = np.int(example_df.x.values[n])\n            y_coord = np.int(example_df.y.values[n])\n            x_start = x_coord - 1\n            y_start = y_coord - 1\n            x_end = x_start + 50\n            y_end = y_start + 50\n\n            grid[y_start:y_end, x_start:x_end] = image\n            if target == 1:\n                mask[y_start:y_end, x_start:x_end, 0] = 250\n                mask[y_start:y_end, x_start:x_end, 1] = 0\n                mask[y_start:y_end, x_start:x_end, 2] = 0\n            if pred_df is not None:\n                \n                proba = patient_df[\n                    (patient_df.x==x_coord) & (patient_df.y==y_coord)].proba\n                mask_proba[y_start:y_end, x_start:x_end, 0] = np.float(proba)\n\n        except ValueError:\n            broken_patches.append(example_df.path.values[n])\n    \n    \n    return grid, mask, broken_patches, mask_proba","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"example = \"13616\"\ngrid, mask, broken_patches,_ = visualise_breast_tissue(example)\n\nfig, ax = plt.subplots(1,2,figsize=(20,10))\nax[0].imshow(grid, alpha=0.9)\nax[1].imshow(mask, alpha=0.8)\nax[1].imshow(grid, alpha=0.7)\nax[0].grid(False)\nax[1].grid(False)\nfor m in range(2):\n    ax[m].set_xlabel(\"y-coord\")\n    ax[m].set_ylabel(\"y-coord\")\nax[0].set_title(\"Breast tissue slice of patient: \" + patient_id)\nax[1].set_title(\"Cancer tissue colored red \\n of patient: \" + patient_id);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"broken_patches","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"BATCH_SIZE = 32\nNUM_CLASSES = 2\n\nOUTPUT_PATH = \"\"\nMODEL_PATH = \"../input/breastcancermodel/\"\nLOSSES_PATH = \"../input/breastcancermodel/\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.manual_seed(0)\nnp.random.seed(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()\ndata.loc[:, \"target\"] = data.target.astype(np.str)\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"patients = data.patient_id.unique()\n\ntrain_ids, sub_test_ids = train_test_split(patients,\n                                           test_size=0.05,\n                                           random_state=42)\ntest_ids, dev_ids = train_test_split(sub_test_ids, test_size=0.5, random_state=45)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(train_ids)/patients.shape[0]*100, len(dev_ids)/patients.shape[0]*100, len(test_ids)/patients.shape[0]*100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(train_ids), len(dev_ids), len(test_ids))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"train_df = data.loc[data.patient_id.isin(train_ids),:].copy()\ntest_df = data.loc[data.patient_id.isin(test_ids),:].copy()\ndev_df = data.loc[data.patient_id.isin(dev_ids),:].copy()\n\ntrain_df = extract_coords(train_df)\ntest_df = extract_coords(test_df)\ndev_df = extract_coords(dev_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig, ax = plt.subplots(1,3,figsize=(20,5))\nsns.countplot(train_df.target, ax=ax[0], palette=\"Reds\")\nax[0].set_title(\"Train data\")\nsns.countplot(dev_df.target, ax=ax[1], palette=\"Blues\")\nax[1].set_title(\"Dev data\")\nsns.countplot(test_df.target, ax=ax[2], palette=\"Greens\");\nax[2].set_title(\"Test data\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"def my_transform(key=\"train\", plot=False):\n    train_sequence = [transforms.Resize((50,50)),\n                      transforms.RandomHorizontalFlip(),\n                      transforms.RandomVerticalFlip()]\n    val_sequence = [transforms.Resize((50,50))]\n    if plot==False:\n        train_sequence.extend([\n            transforms.ToTensor(),\n            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n        val_sequence.extend([\n            transforms.ToTensor(),\n            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n        \n    data_transforms = {'train': transforms.Compose(train_sequence),'val': transforms.Compose(val_sequence)}\n    return data_transforms[key]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"class BreastCancerDataset(Dataset):\n    \n    def __init__(self, df, transform=None):\n        self.states = df\n        self.transform=transform\n      \n    def __len__(self):\n        return len(self.states)\n        \n    def __getitem__(self, idx):\n        patient_id = self.states.patient_id.values[idx]\n        x_coord = self.states.x.values[idx]\n        y_coord = self.states.y.values[idx]\n        image_path = self.states.path.values[idx] \n        image = Image.open(image_path)\n        image = image.convert('RGB')\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        if \"target\" in self.states.columns.values:\n            target = np.int(self.states.target.values[idx])\n        else:\n            target = None\n            \n        return {\"image\": image,\n                \"label\": target,\n                \"patient_id\": patient_id,\n                \"x\": x_coord,\n                \"y\": y_coord}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = BreastCancerDataset(train_df, transform=my_transform(key=\"train\"))\ndev_dataset = BreastCancerDataset(dev_df, transform=my_transform(key=\"val\"))\ntest_dataset = BreastCancerDataset(test_df, transform=my_transform(key=\"val\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_datasets = {\"train\": train_dataset, \"dev\": dev_dataset, \"test\": test_dataset}\ndataset_sizes = {x: len(image_datasets[x]) for x in [\"train\", \"dev\", \"test\"]}","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(3,6,figsize=(20,11))\n\ntrain_transform = my_transform(key=\"train\", plot=True)\nval_transform = my_transform(key=\"val\", plot=True)\n\nfor m in range(6):\n    filepath = train_df.path.values[m]\n    image = Image.open(filepath)\n    ax[0,m].imshow(image)\n    transformed_img = train_transform(image)\n    ax[1,m].imshow(transformed_img)\n    ax[2,m].imshow(val_transform(image))\n    ax[0,m].grid(False)\n    ax[1,m].grid(False)\n    ax[2,m].grid(False)\n    ax[0,m].set_title(train_df.patient_id.values[m] + \"\\n target: \" + train_df.target.values[m])\n    ax[1,m].set_title(\"Preprocessing for train\")\n    ax[2,m].set_title(\"Preprocessing for val\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\ndev_dataloader = DataLoader(dev_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=True)\ntest_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataloaders = {\"train\": train_dataloader, \"dev\": dev_dataloader, \"test\": test_dataloader}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(dataloaders[\"train\"]), len(dataloaders[\"dev\"]), len(dataloaders[\"test\"]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ndevice","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = torchvision.models.resnet18(pretrained=False)\nif run_training:\n    model.load_state_dict(torch.load(\"../input/pretrained-pytorch-models/resnet18-5c106cde.pth\"))\nnum_features = model.fc.in_features\nprint(num_features)\n\nmodel.fc = nn.Sequential(\n    nn.Linear(num_features, 512),\n    nn.ReLU(),\n    nn.BatchNorm1d(512),\n    nn.Dropout(0.5),\n    \n    nn.Linear(512, 256),\n    nn.ReLU(),\n    nn.BatchNorm1d(256),\n    nn.Dropout(0.5),\n    \n    nn.Linear(256, NUM_CLASSES))\n\ndef init_weights(m):\n    if type(m) == nn.Linear:\n        torch.nn.init.xavier_uniform_(m.weight)\n        m.bias.data.fill_(0.01)\n\nmodel.apply(init_weights)\nmodel = model.to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weights = compute_class_weight(y=train_df.target.values, class_weight=\"balanced\", classes=train_df.target.unique())    \nclass_weights = torch.FloatTensor(weights)\nif device.type==\"cuda\":\n    class_weights = class_weights.cuda()\nprint(class_weights)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.target.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"criterion = nn.CrossEntropyLoss(weight=class_weights)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"def f1_score(preds, targets):\n    \n    tp = (preds*targets).sum().to(torch.float32)\n    fp = ((1-targets)*preds).sum().to(torch.float32)\n    fn = (targets*(1-preds)).sum().to(torch.float32)\n    \n    epsilon = 1e-7\n    precision = tp / (tp + fp + epsilon)\n    recall = tp / (tp + fn + epsilon)\n    \n    f1_score = 2 * precision * recall/(precision + recall + epsilon)\n    return f1_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def train_loop(model, criterion, optimizer, lr_find=False, scheduler=None, num_epochs = 3, lam=0.0):\n    since = time.time()\n    if lr_find:\n        phases = [\"train\"]\n    else:\n        phases = [\"train\", \"dev\", \"test\"]\n    \n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n    \n    loss_dict = {\"train\": [], \"dev\": [], \"test\": []}\n    lam_tensor = torch.tensor(lam, device=device)\n    \n    running_loss_dict = {\"train\": [], \"dev\": [], \"test\": []}\n    \n    lr_find_loss = []\n    lr_find_lr = []\n    smoothing = 0.2\n    \n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n        \n        for phase in phases:\n            if phase == \"train\":\n                model.train()\n            else:\n                model.eval()\n\n            running_loss = 0.0\n            running_corrects = 0\n            \n            tk0 = tqdm(dataloaders[phase], total=int(len(dataloaders[phase])))\n\n            counter = 0\n            for bi, d in enumerate(tk0):\n                inputs = d[\"image\"]\n                labels = d[\"label\"]\n                inputs = inputs.to(device, dtype=torch.float)\n                labels = labels.to(device, dtype=torch.long)\n                \n                # zero the parameter gradients\n                optimizer.zero_grad()\n                \n                # forward\n                # track history if only in train\n                \n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n                \n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        \n                        #l2_reg = torch.tensor(0., device=device)\n                        #for param in model.parameters():\n                            #l2_reg = lam_tensor * torch.norm(param)\n                        \n                        #loss += l2_reg\n            \n                        optimizer.step()\n                        # cyclical lr schedule is invoked after each batch\n                        if scheduler is not None:\n                            scheduler.step() \n                            if lr_find:\n                                lr_step = optimizer.state_dict()[\"param_groups\"][0][\"lr\"]\n                                lr_find_lr.append(lr_step)\n                                if counter==0:\n                                    lr_find_loss.append(loss.item())\n                                else:\n                                    smoothed_loss = smoothing  * loss.item() + (1 - smoothing) * lr_find_loss[-1]\n                                    lr_find_loss.append(smoothed_loss)\n                            \n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)                      \n     \n                counter += 1\n                \n                \n                tk0.set_postfix({'loss': running_loss / (counter * dataloaders[phase].batch_size),\n                                 'accuracy': running_corrects.double() / (counter * dataloaders[phase].batch_size)})\n                running_loss_dict[phase].append(running_loss / (counter * dataloaders[phase].batch_size))\n                \n            epoch_loss = running_loss / dataset_sizes[phase]\n            loss_dict[phase].append(epoch_loss)\n            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n            \n            # deep copy the model\n            if phase == 'dev' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n        print()\n        \n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n    time_elapsed // 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))              \n    \n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    results = {\"model\": model,\n               \"loss_dict\": loss_dict,\n               \"running_loss_dict\": running_loss_dict,\n               \"lr_find\": {\"lr\": lr_find_lr, \"loss\": lr_find_loss}}\n    return results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"start_lr = 1e-6\nend_lr = 0.1","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def get_lr_search_scheduler(optimizer, min_lr, max_lr, max_iterations):\n    # max_iterations should be the number of steps within num_epochs_*epoch_iterations\n    # this way the learning rate increases linearily within the period num_epochs*epoch_iterations \n    scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer=optimizer, \n                                               base_lr=min_lr,\n                                               max_lr=max_lr,\n                                               step_size_up=max_iterations,\n                                               step_size_down=max_iterations,\n                                               mode=\"triangular\")\n    \n    return scheduler\n\ndef get_scheduler(optimiser, min_lr, max_lr, stepsize):\n    # suggested_stepsize = 2*num_iterations_within_epoch\n    stepsize_up = np.int(stepsize/2)\n    scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer=optimiser,\n                                               base_lr=min_lr,\n                                               max_lr=max_lr,\n                                               step_size_up=stepsize_up,\n                                               step_size_down=stepsize_up,\n                                               mode=\"triangular\")\n    return scheduler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import math\n\nif find_learning_rate:\n    lr_find_epochs=1\n    optimizer = optim.SGD(model.fc.parameters(), start_lr)\n    scheduler = get_lr_search_scheduler(optimizer, start_lr, end_lr, lr_find_epochs*len(train_dataloader))\n    results = train_loop(model, criterion, optimizer, lr_find=True, scheduler=scheduler, num_epochs=lr_find_epochs)\n    lr_find_lr, lr_find_loss = results[\"lr_find\"][\"lr\"], results[\"lr_find\"][\"loss\"]\n    \n    find_lr_df = pd.DataFrame(lr_find_loss, columns=[\"smoothed loss\"])\n    find_lr_df.loc[:, \"lr\"] = lr_find_lr\n    find_lr_df.to_csv(\"learning_rate_search.csv\", index=False)\nelse:\n    find_lr_df = pd.read_csv(MODEL_PATH + \"learning_rate_search.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1,2,figsize=(20,5))\nax[0].plot(find_lr_df.lr.values)\nax[1].plot(find_lr_df[\"smoothed loss\"].values)\nax[0].set_xlabel(\"Steps\")\nax[0].set_ylabel(\"Learning rate\")\nax[1].set_xlabel(\"Steps\")\nax[1].set_ylabel(\"Loss\");\nax[0].set_title(\"How the learning rate increases during search\")\nax[1].set_title(\"How the training loss evolves during search\")\n\nplt.figure(figsize=(20,5))\nplt.plot(find_lr_df.lr.values, find_lr_df[\"smoothed loss\"].values, '-', color=\"tomato\");\nplt.xlabel(\"Learning rate\")\nplt.xscale(\"log\")\nplt.ylabel(\"Smoothed Loss\")\nplt.title(\"Searching for the optimal learning rate\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"start_lr = 1e-6\nend_lr = 0.006","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"if run_training:\n    NUM_EPOCHS = 30\n    optimizer = optim.SGD(model.fc.parameters(), lr=0.01)\n    scheduler = get_scheduler(optimizer, start_lr, end_lr, 2*NUM_EPOCHS)\n    results = train_loop(model, criterion, optimizer, scheduler=scheduler, num_epochs = NUM_EPOCHS)\n    model, loss_dict, running_loss_dict = results[\"model\"], results[\"loss_dict\"], results[\"running_loss_dict\"]\n    \n    if device == \"cpu\":\n        OUTPUT_PATH += \".pth\"\n    else:\n        OUTPUT_PATH += \"_cuda.pth\"\n        \n    torch.save(model.state_dict(), OUTPUT_PATH)\n    \n    losses_df = pd.DataFrame(loss_dict[\"train\"],columns=[\"train\"])\n    losses_df.loc[:, \"dev\"] = loss_dict[\"dev\"]\n    losses_df.loc[:, \"test\"] = loss_dict[\"test\"]\n    losses_df.to_csv(\"losses_breastcancer.csv\", index=False)\n    \n    running_losses_df = pd.DataFrame(running_loss_dict[\"train\"], columns=[\"train\"])\n    running_losses_df.loc[0:len(running_loss_dict[\"dev\"])-1, \"dev\"] = running_loss_dict[\"dev\"]\n    running_losses_df.loc[0:len(running_loss_dict[\"test\"])-1, \"test\"] = running_loss_dict[\"test\"]\n    running_losses_df.to_csv(\"running_losses_breastcancer.csv\", index=False)\nelse:\n    if device == \"cpu\":\n        load_path = MODEL_PATH + \".pth\"\n    else:\n        load_path = MODEL_PATH + \"_cuda.pth\"\n    model.load_state_dict(torch.load(load_path, map_location='cpu'))\n    model.eval()\n    \n    losses_df = pd.read_csv(LOSSES_PATH + \"losses_breastcancer.csv\")\n    running_losses_df = pd.read_csv(LOSSES_PATH + \"running_losses_breastcancer.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(20,5))\n\nplt.plot(losses_df[\"train\"], '-o', label=\"train\")\nplt.plot(losses_df[\"dev\"], '-o', label=\"dev\")\nplt.plot(losses_df[\"test\"], '-o', label=\"dev\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Weighted x-entropy\")\nplt.title(\"Loss change over epoch\")\nplt.legend();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig, ax = plt.subplots(3,1,figsize=(20,15))\n\nax[0].plot(running_losses_df[\"train\"], '-o', label=\"train\")\nax[0].set_xlabel(\"Step\")\nax[0].set_ylabel(\"Weighted x-entropy\")\nax[0].set_title(\"Loss change over steps\")\nax[0].legend();\n\nax[1].plot(running_losses_df[\"dev\"], '-o', label=\"dev\", color=\"orange\")\nax[1].set_xlabel(\"Step\")\nax[1].set_ylabel(\"Weighted x-entropy\")\nax[1].set_title(\"Loss change over steps\")\nax[1].legend();\n\nax[2].plot(running_losses_df[\"test\"], '-o', label=\"test\", color=\"mediumseagreen\")\nax[2].set_xlabel(\"Step\")\nax[2].set_ylabel(\"Weighted x-entropy\")\nax[2].set_title(\"Loss change over steps\")\nax[2].legend();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def sigmoid(x):\n    return 1./(1+np.exp(-x))\n\ndef evaluate_model(model, predictions_df, key):\n    was_training = model.training\n    model.eval()\n\n    with torch.no_grad():\n        for i, data in enumerate(dataloaders[key]):\n            inputs = data[\"image\"].to(device)\n            labels = data[\"label\"].to(device)\n            \n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n            \n            proba = outputs.cpu().numpy().astype(np.float)\n            predictions_df.loc[i*BATCH_SIZE:(i+1)*BATCH_SIZE-1, \"proba\"] = sigmoid(proba[:, 1])\n            predictions_df.loc[i*BATCH_SIZE:(i+1)*BATCH_SIZE-1, \"true\"] = data[\"label\"].numpy().astype(np.int)\n            predictions_df.loc[i*BATCH_SIZE:(i+1)*BATCH_SIZE-1, \"predicted\"] = preds.cpu().numpy().astype(np.int)\n            predictions_df.loc[i*BATCH_SIZE:(i+1)*BATCH_SIZE-1, \"x\"] = data[\"x\"].numpy()\n            predictions_df.loc[i*BATCH_SIZE:(i+1)*BATCH_SIZE-1, \"y\"] = data[\"y\"].numpy()\n            predictions_df.loc[i*BATCH_SIZE:(i+1)*BATCH_SIZE-1, \"patient_id\"] = data[\"patient_id\"]\n            \n    predictions_df = predictions_df.dropna()\n    return predictions_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"if run_training:\n    dev_predictions = pd.DataFrame(index = np.arange(0, dataset_sizes[\"dev\"]), columns = [\"true\", \"predicted\", \"proba\"])\n    test_predictions = pd.DataFrame(index = np.arange(0, dataset_sizes[\"test\"]), columns = [\"true\", \"predicted\", \"proba\"])\n\n    dev_predictions = evaluate_model(model, dev_predictions, \"dev\")\n    test_predictions = evaluate_model(model, test_predictions, \"test\")\n    \n    dev_predictions.to_csv(\"dev_predictions.csv\", index=False)\n    test_predictions.to_csv(\"test_predictions.csv\", index=False)\n    \nelse:\n    \n    dev_predictions = pd.read_csv(LOSSES_PATH + \"dev_predictions.csv\")\n    test_predictions = pd.read_csv(LOSSES_PATH + \"test_predictions.csv\")\n    \n    dev_predictions.patient_id = dev_predictions.patient_id.astype(np.str)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig, ax = plt.subplots(3,3,figsize=(20,20))\n\nfor n in range(3):\n\n    idx = dev_predictions.patient_id.unique()[n]\n    grid, mask, broken_patches, mask_proba = visualise_breast_tissue(idx, pred_df=dev_predictions)\n\n\n    ax[n, 0].imshow(grid, alpha=0.9)\n    ax[n, 1].imshow(mask, alpha=0.8)\n    ax[n, 1].imshow(grid, alpha=0.7)\n    ax[n, 2].imshow(mask_proba[:,:,0], cmap=\"YlOrRd\")\n\n    for m in range(3):\n        ax[n, m].set_xlabel(\"y-coord\")\n        ax[n, m].set_ylabel(\"x-coord\")\n        ax[n, m].grid(False)\n        \n    ax[n, 0].set_title(\"Breast tissue slice of patient: \" + patient_id)\n    ax[n, 1].set_title(\"Cancer tissue colored red \\n of patient: \" + patient_id);\n    ax[n, 2].set_title(\"Cancer probability\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dev_predictions.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1,3,figsize=(20,5))\nsns.countplot(dev_predictions.true.astype(np.float), ax=ax[0], palette=\"Reds_r\")\nax[0].set_title(\"Target counts of dev data\");\nsns.distplot(dev_predictions.proba.astype(np.float), ax=ax[1], kde=False, color=\"tomato\")\nax[0].set_title(\"Predicted probability of cancer in dev\");\nsns.distplot(test_predictions.proba.astype(np.float), ax=ax[2], kde=False, color=\"mediumseagreen\");\nax[2].set_title(\"Predicted probability of cancer in test\");","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\ndef get_confusion_matrix(y_true, y_pred):\n    transdict = {1: \"cancer\", 0: \"no cancer\"}\n    y_t = np.array([transdict[x] for x in y_true])\n    y_p = np.array([transdict[x] for x in y_pred])\n    \n    labels = [\"no cancer\", \"cancer\"]\n    index_labels = [\"actual no cancer\", \"actual cancer\"]\n    col_labels = [\"predicted no cancer\", \"predicted cancer\"]\n    confusion = confusion_matrix(y_t, y_p, labels=labels)\n    confusion_df = pd.DataFrame(confusion, index=index_labels, columns=col_labels)\n    for n in range(2):\n        confusion_df.iloc[n] = confusion_df.iloc[n] / confusion_df.sum(axis=1).iloc[n]\n    return confusion_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}