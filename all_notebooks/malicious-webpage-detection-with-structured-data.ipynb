{"cells":[{"metadata":{},"cell_type":"markdown","source":"# <font style=\"color:red;\">Deep Learning Webpage Classification Model with Structured Data <br/> (Balanced Using Class Weights & Faster Convergence Using Initial Bias)</font>"},{"metadata":{},"cell_type":"markdown","source":"## Basic Initialisation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Installing mandatory libraries\n! pip install profanity_check \n! pip install tld","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# To support both python 2 and python 3\nfrom __future__ import division, print_function, unicode_literals\n\n# Load the TensorBoard notebook extension.\n%load_ext tensorboard\n\n# Clear any logs from previous runs\n!rm -rf ./logs/ \n\n# Common imports\nimport pandas as pd\nimport numpy as np\nimport time\nimport os\nimport sklearn\n\n# to make this notebook's output stable across runs\nnp.random.seed(42)\n\n# To plot figures\n%matplotlib inline\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nmpl.rc('axes', labelsize=14)\nmpl.rc('xtick', labelsize=12)\nmpl.rc('ytick', labelsize=12)\n\n# Where to save the figures\nPROJECT_ROOT_DIR = \".\"\nCHAPTER_ID = \"C3_Deep Learning Classification\"\nIMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"imgs\", CHAPTER_ID)\n\ndef image_path(fig_id):\n    return os.path.join(PROJECT_ROOT_DIR, \"imgs\", CHAPTER_ID, fig_id)\n\ndef save_fig(fig_id, tight_layout=True, fig_extension=\"svg\", resolution=300):\n    if not os.path.exists(IMAGES_PATH):\n        os.makedirs(IMAGES_PATH)\n    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n    print(\"Saving figure\", fig_id)\n    if tight_layout:\n        plt.tight_layout()\n    plt.savefig(path, format=fig_extension)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Loading Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verifying pathname of dataset before loading\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename));\n        print(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load Datasets\ndef loadDataset(file_name):\n    df = pd.read_csv(file_name,engine = 'python')\n    return df\n\ndf_train = loadDataset(\"/kaggle/input/dataset-of-malicious-and-benign-webpages/Webpages_Classification_train_data.csv/Webpages_Classification_train_data.csv\")\ndf_test = loadDataset(\"/kaggle/input/dataset-of-malicious-and-benign-webpages/Webpages_Classification_test_data.csv/Webpages_Classification_test_data.csv\")\n#Ensuring correct sequence of columns & dropping IP Address\ndf_train = df_train[['url','url_len','geo_loc','tld','who_is','https','js_len','js_obf_len','label']]\ndf_test = df_test[['url','url_len','geo_loc','tld','who_is','https','js_len','js_obf_len','label']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" ### Vectorizing URL Text Using Profanity Score"},{"metadata":{"trusted":true},"cell_type":"code","source":"#vectorising the URL Text\nfrom urllib.parse import urlparse\nfrom tld import get_tld\n\nstart_time= time.time()\n#Function for cleaning the URL text before vectorization\ndef clean_url(url):\n    url_text=\"\"\n    try:\n        domain = get_tld(url, as_object=True)\n        domain = get_tld(url, as_object=True)\n        url_parsed = urlparse(url)\n        url_text= url_parsed.netloc.replace(domain.tld,\" \").replace('www',' ') +\" \"+ url_parsed.path+\" \"+url_parsed.params+\" \"+url_parsed.query+\" \"+url_parsed.fragment\n        url_text = url_text.translate(str.maketrans({'?':' ','\\\\':' ','.':' ',';':' ','/':' ','\\'':' '}))\n        url_text.strip(' ')\n        url_text.lower()\n    except:\n        url_text = url_text.translate(str.maketrans({'?':' ','\\\\':' ','.':' ',';':' ','/':' ','\\'':' '}))\n        url_text.strip(' ')\n    return url_text\n\ndf_test['url'] = df_test['url'].map(clean_url)\ndf_train['url'] = df_train['url'].map(clean_url)\nprint(\"***Total Time taken --- %s seconds ---***\" % (time.time() - start_time))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# give profanity score to each URL using the Profanity_Check Library\nfrom profanity_check import predict_prob\n\nstart_time= time.time()\n#Function for calculating profanity in a dataset column\ndef predict_profanity(df):\n    arr=predict_prob(df['url'].astype(str).to_numpy())\n    arr= arr.round(decimals=3)\n    df['url'] = pd.DataFrame(data=arr,columns=['url'])\n    #df['url']= df_test['url'].astype(float).round(decimals=3) #rounding probability to 3 decimal places\n    return df['url']\n\ndf_train['url']= predict_profanity(df_train)\ndf_test['url']= predict_profanity(df_test)\n\nprint(\"***Total Time taken --- %s seconds ---***\" % (time.time() - start_time))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Looking for NaN, if any\nprint(df_train['url'].isnull().sum())\nprint(df_test['url'].isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Rename 'url' to 'url_vect'\ndf_train.rename(columns = {\"url\": \"url_vect\"}, inplace = True)\ndf_test.rename(columns = {\"url\": \"url_vect\"}, inplace = True)\ndf_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#converting 'label' values to numerical value for classification\nimport time\n\nstart_time= time.time()\n\ndf_test['label'].replace(to_replace =\"good\", value =1, inplace=True)\ndf_train['label'].replace(to_replace =\"good\", value =1, inplace=True)\ndf_test['label'].replace(to_replace =\"bad\", value =0, inplace=True)\ndf_train['label'].replace(to_replace =\"bad\", value =0, inplace=True)\n\nprint(\"***Total Time taken --- %s seconds ---***\" % (time.time() - start_time))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Analysis of Class Imbalance"},{"metadata":{"trusted":true},"cell_type":"code","source":"# No of Classes in Label\ndf_train['label'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Class Distribution of Labels\ndf_train.groupby('label').size()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Analysis of Postives and Negatives in the Dataset\nneg, pos = np.bincount(df_train['label'])\ntotal = neg + pos\nprint ('Total of Samples: %s'% total)\nprint('Positive: {} ({:.2f}% of total)'.format(pos, 100 * pos / total))\nprint('Negative: {} ({:.2f}% of total)'.format(neg, 100 * neg / total))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Class Labels shown in Histogram\ndf_train[\"label\"].hist()\n#save_fig(\"Fig2\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Representation of Labels in the Stack form\n\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as mtick\n\n# create dummy variable then group by that\n# set the legend to false because we'll fix it later\ndf_train.assign(dummy = 1).groupby(['dummy','label']).size().groupby(level=0).apply(\n    lambda x: 100 * x / x.sum()\n).to_frame().unstack().plot(kind='bar',stacked=True,legend=False, color={'grey','white'}, linewidth=0.50, ec='k')\n# or it'll show up as 'dummy' \nplt.xlabel('Benign/Malicious Webpages')\n# disable ticks in the x axis\nplt.xticks([])\n# fix the legend or it'll include the dummy variable\ncurrent_handles, _ = plt.gca().get_legend_handles_labels()\nreversed_handles = reversed(current_handles)\ncorrect_labels = reversed(['Malicious','Benign'])\nplt.legend(reversed_handles,correct_labels)\n\nplt.gca().yaxis.set_major_formatter(mtick.PercentFormatter())\n#save_fig(\"Fig3\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Earmarking Validation, Train & Test Sets"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Selection lower numbers as of now for fast testing\n\ntrain= df_train.iloc[:1000000,]\nval= df_train.iloc[1000001:,]\ntest= df_test.iloc[0:,]\n\nprint(len(train), 'train examples')\nprint(len(val), 'validation examples')\nprint(len(test), 'test examples')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Tensorflow TF Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"from __future__ import absolute_import, division, print_function, unicode_literals\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\n\nfrom tensorflow import feature_column\nfrom tensorflow.keras import layers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# A utility method to create a tf.data dataset from a Pandas Dataframe\ndef df_to_dataset(dataframe, shuffle=True, batch_size=32):\n  dataframe = dataframe.copy()\n  labels = dataframe.pop('label')\n  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n  if shuffle:\n    ds = ds.shuffle(buffer_size=len(dataframe))\n  ds = ds.batch(batch_size)\n  return ds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Using a Batch Size of 2048 and copying data to tf.data dataset\nbatch_size = 2048\ntrain_ds = df_to_dataset(train, batch_size=batch_size)\nval_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\ntest_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# For checking the batch\n#example_batch = next(iter(train_ds))[0]\n#example_batch","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Making the Feature Layer with Feature Columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_columns = []\n\n# numeric cols\nfor header in ['url_vect', 'url_len', 'js_len', 'js_obf_len']:\n  feature_columns.append(feature_column.numeric_column(header))\n\n#Categorical Columns\nwho_is = feature_column.categorical_column_with_vocabulary_list('who_is', ['complete', 'incomplete'])\nwho_is_one_hot = feature_column.indicator_column(who_is)\nhttps = feature_column.categorical_column_with_vocabulary_list('https', ['yes', 'no'])\nhttps_one_hot = feature_column.indicator_column(https)\nfeature_columns.append(https_one_hot)\nfeature_columns.append(who_is_one_hot)\n\n# Hashed Categorical Columns\ngeo_loc_hashed = feature_column.categorical_column_with_hash_bucket('geo_loc', hash_bucket_size=230)\ntld_hashed = feature_column.categorical_column_with_hash_bucket('tld', hash_bucket_size=1200)\ngeo_loc_indicator = feature_column.indicator_column(geo_loc_hashed)\ntld_indicator = feature_column.indicator_column(tld_hashed)\nfeature_columns.append(tld_indicator)\nfeature_columns.append(geo_loc_indicator)\n\n#Creating Feature Layer\nfeature_layer = tf.keras.layers.DenseFeatures(feature_columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Tensor Flow Model Building"},{"metadata":{},"cell_type":"markdown","source":"### Setting the Initial Bias"},{"metadata":{},"cell_type":"markdown","source":"\nThe correct bias to set can be derived from:\n\n$$ p_0 = pos/(pos + neg) = 1/(1+e^{-b_0}) $$\n$$ b_0 = -log_e(1/p_0 - 1) $$\n$$ b_0 = log_e(pos/neg)$$"},{"metadata":{},"cell_type":"markdown","source":"With this initialization the initial loss should be approximately:\n\n$$-p_0log(p_0)-(1-p_0)log(1-p_0) = 0.01317$$"},{"metadata":{},"cell_type":"markdown","source":"This loss is about 50 times less than a naive initialisation"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Using Initial Bias to overcome Class Imbalance\ninitial_bias = np.log([pos/neg])\ninitial_bias","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Making a Tensorflow Model\nfrom tensorflow import keras\n\nMETRICS = [\n      keras.metrics.TruePositives(name='tp'),\n      keras.metrics.FalsePositives(name='fp'),\n      keras.metrics.TrueNegatives(name='tn'),\n      keras.metrics.FalseNegatives(name='fn'), \n      keras.metrics.BinaryAccuracy(name='accuracy'),\n      keras.metrics.Precision(name='precision'),\n      keras.metrics.Recall(name='recall'),\n      keras.metrics.AUC(name='auc'),\n]\n\ndef make_model(metrics = METRICS, output_bias=None):\n    if output_bias is not None:\n        output_bias = tf.keras.initializers.Constant(output_bias)\n    model = keras.Sequential([\n        feature_layer,\n        layers.Dense(128, activation='relu'),\n        layers.Dense(32, activation='relu'),\n        keras.layers.Dropout(0.1),\n        keras.layers.Dense(1, activation='sigmoid',\n        bias_initializer=output_bias),\n    ])\n\n    model.compile(\n        optimizer=keras.optimizers.Adam(lr=1e-3),\n        loss=keras.losses.BinaryCrossentropy(from_logits=True),\n        metrics=metrics)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Initialize the Model\nmodel = make_model()\nmodel_initial_bias = make_model(output_bias = initial_bias)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Making Class Specific Weights"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scaling by total/2 helps keep the loss to a similar magnitude.\n# The sum of the weights of all examples stays the same.\nweight_for_0 = (1 / neg)*(total)/2.0 \nweight_for_1 = (1 / pos)*(total)/2.0\n\nclass_weight = {0: weight_for_0, 1: weight_for_1}\n\nprint('Weight for class 0: {:.2f}'.format(weight_for_0))\nprint('Weight for class 1: {:.2f}'.format(weight_for_1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Fitting the Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fitting the Model with Class Weights\nfrom datetime import datetime\n\n#Defining Early Stopping\nearly_stopping = tf.keras.callbacks.EarlyStopping(\n    monitor='val_accuracy', \n    verbose=1,\n    patience=20,\n    mode='max',\n    restore_best_weights=True)\n\n# Define the Keras TensorBoard callback.\nlogdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\ntensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n\nstart_time= time.time()\nzero_bias_history = model.fit(train_ds, epochs=40,validation_data=val_ds,\n          callbacks=[early_stopping,tensorboard_callback],\n          class_weight=class_weight\n         )\nprint(\"***Total Time taken --- %s seconds ---***\" % (time.time() - start_time))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fitting the Model with Class Weights & Inital Bias\nfrom datetime import datetime\n\nearly_stopping = tf.keras.callbacks.EarlyStopping(\n    monitor='val_accuracy', \n    verbose=1,\n    patience=20,\n    mode='max',\n    restore_best_weights=True)\n\n# Define the Keras TensorBoard callback.\nlogdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\ntensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n\nstart_time= time.time()\ninitial_bias_history = model_initial_bias.fit(train_ds, epochs=40,validation_data=val_ds,\n          callbacks=[early_stopping,tensorboard_callback],\n          class_weight=class_weight\n         )\nprint(\"***Total Time taken --- %s seconds ---***\" % (time.time() - start_time))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The final model Summary\nmodel_initial_bias.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Evaluation of Model & Results"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Accuracy & Loss - Class Weights w/o Initial Bias\nresults = model.evaluate(test_ds)\n#print(\"Accuracy\", accuracy)\nprint(\"Loss: {0}, Accuracy: {1}\".format(results[0],results[5]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Accuracy & Loss - Class Weights with Initial Bias\nstart_time= time.time()\nresults = model_initial_bias.evaluate(test_ds)\n#print(\"Accuracy\", accuracy)\nprint(\"Loss: {0}, Accuracy: {1}\".format(results[0],results[5]))\nprint(\"***Total Time taken --- %s seconds ---***\" % (time.time() - start_time))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"start_time= time.time()\nX_test, y_test = iter(test_ds).next()\nX_train, y_train = iter(train_ds).next()\nprint(\"***Total Time taken --- %s seconds ---***\" % (time.time() - start_time))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Confusion Matrix\n\nstart_time= time.time()\ny_pred=model_initial_bias.predict_classes(X_test)\ncon_mat = tf.math.confusion_matrix(labels=y_test, predictions=y_pred).numpy()\ncon_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=4)\ncon_mat_df = pd.DataFrame(con_mat_norm,index = ['Benign','Malicious'], columns = ['Benign','Malicious'])\nprint(\"***Total Time taken --- %s seconds ---***\" % (time.time() - start_time))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Confusion Matrix\ncon_mat_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting the Confusion Matrix Using Matploit & Seaborn\nimport seaborn as sns\n\nstart_time= time.time()\nfigure = plt.figure(figsize=(6,6))\nsns.heatmap(con_mat_df,annot=True,cmap=plt.cm.binary,fmt='g',linewidths=0.50,linecolor='black')\nplt.tight_layout()\nplt.ylabel('True label')\nplt.xlabel('Predicted label')\n#save_fig(\"Fig7\")\nplt.show()\n\nprint(\"***Total Time taken --- %s seconds ---***\" % (time.time() - start_time))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Showing the Influence of Initial Bias"},{"metadata":{"trusted":true},"cell_type":"code","source":"mpl.rcParams['figure.figsize'] = (12, 10)\ncolors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n\ndef plot_loss(history, label, n):\n    # Use a log scale to show the wide range of values.\n    plt.semilogy(history.epoch,  history.history['loss'],\n               color=colors[n], label='Train '+label)\n    plt.semilogy(history.epoch,  history.history['val_loss'],\n          color=colors[n], label='Val '+label,\n          linestyle=\"--\")\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_loss(zero_bias_history, \"Zero Bias\", 0)\nplot_loss(initial_bias_history, \"Initial Bias\", 1)\n#save_fig(\"Fig8\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plotting of Metrics: Loss, AUC, Precision & Recall"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_metrics(history):\n    metrics =  ['loss', 'auc', 'precision', 'recall']\n    for n, metric in enumerate(metrics):\n        name = metric.replace(\"_\",\" \").capitalize()\n        plt.subplot(2,2,n+1)\n        plt.plot(history.epoch,  history.history[metric], color=colors[0], label='Train')\n        plt.plot(history.epoch, history.history['val_'+metric],\n             color=colors[0], linestyle=\"--\", label='Val')\n        plt.xlabel('Epoch')\n        plt.ylabel(name)\n        if metric == 'loss':\n            plt.ylim([0, plt.ylim()[1]])\n        elif metric == 'auc':\n            plt.ylim([0.8,1])\n        else:\n            plt.ylim([0,1])\n\n        plt.legend()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_metrics(initial_bias_history)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### ROC Plot"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_roc(name, labels, predictions, **kwargs):\n    fp, tp, _ = sklearn.metrics.roc_curve(labels, predictions)\n\n    plt.plot(100*fp, 100*tp, label=name, linewidth=2, **kwargs)\n    plt.xlabel('False Positive Rate [%]')\n    plt.ylabel('True Positive Rate [%]')\n    plt.xlim([-0.5,20])\n    plt.ylim([80,100.5])\n    plt.grid(True)\n    ax = plt.gca()\n    ax.set_aspect('equal')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_predictions_baseline = model_initial_bias.predict(X_train, batch_size=2048)\ntest_predictions_baseline = model_initial_bias.predict(X_test, batch_size=2048)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_roc(\"Train\", y_train, train_predictions_baseline, color=colors[0])\nplot_roc(\"Test\", y_test, test_predictions_baseline, color=colors[0], linestyle='--')\nplt.legend(loc='lower right')\n#save_fig(\"Fig9\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Confusion Matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_cm(labels, predictions, p=0.5):\n    cm = tf.math.confusion_matrix(labels, predictions > p)\n    plt.figure(figsize=(5,5))\n    sns.heatmap(cm, annot=True, fmt=\"d\")\n    plt.title('Confusion matrix @{:.2f}'.format(p))\n    plt.ylabel('Actual label')\n    plt.xlabel('Predicted label')\n\n    print('True Negatives: ', cm[0][0])\n    print('False Positives: ', cm[0][1])\n    print('False Negatives: ', cm[1][0])\n    print('True Positives: ', cm[1][1])\n    print('Total : ', np.sum(cm[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#for name, value in zip(model.metrics_names, results):\n#    print(name, ': ', value)\n# print()\n# plot_cm(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tensorboard --logdir logs  --port=8021","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":4}