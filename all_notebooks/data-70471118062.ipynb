{"cells":[{"metadata":{},"cell_type":"markdown","source":"# <center>  MBA Tech Sem VI : Machine Learning \n#  Prepared by : Prof. Santosh Bothe </center>\n\nIn this session you will learn how you can prepare your data for machine learning in Python using scikit-learn. You now have recipes to:\n Rescale data.\n Standardize data.\n Normalize data.\n Binarize data."},{"metadata":{},"cell_type":"markdown","source":"# **1. Rescale Data**\nWhen your data is comprised of attributes with varying scales, many machine learning algorithms can bene\ft from rescaling the attributes to all have the same scale. Often this is referred to as normalization and attributes are often rescaled into the range between 0 and 1. This is  useful for optimization algorithms used in the core of machine learning algorithms like gradient\ndescent. It is also useful for algorithms that weight inputs like regression and neural networks and algorithms that use distance measures like k-Nearest Neighbors. You can rescale your data using scikit-learn using the MinMaxScaler class.\n\nReading\n\nhttp://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing\n\nhttp://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Rescale data (between 0 and 1)\nfrom pandas import read_csv\nfrom numpy import set_printoptions\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import Normalizer\nfrom sklearn.preprocessing import Binarizer\nfrom sklearn.preprocessing import StandardScaler\n\nfilename = '../input/cern-electron-collision-data/dielectron.csv'\ndataframe = read_csv(filename)\narray = dataframe.values\nprint(array[0])\n# separate array into input and output components\nX = array[:,0:8]\nY = array[:,8]\nprint(X)\nscaler = MinMaxScaler(feature_range=(0, 1))\nrescaledX = scaler.fit_transform(X)\n# summarize transformed data\nset_printoptions(precision=3)\nprint(rescaledX[0:5,:])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ** 2. Standardize Data**\n\nStandardization is a useful technique to transform attributes with a Gaussian distribution and differing means and standard deviations to a standard Gaussian distribution with a mean of 0 and a standard deviation of 1. It is most suitable for techniques that assume a Gaussian distribution in the input variables and work better with rescaled data, such as linear regression,\nlogistic regression and linear discriminate analysis. You can standardize data using scikit-learn with the StandardScaler class\n\nReading : http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.\nhtml"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Standardize data (0 mean, 1 stdev)\n# separate array into input and output components\nX = array[:,0:8]\nY = array[:,8]\nscaler = StandardScaler().fit(X)\nrescaledX = scaler.transform(X)\n# summarize transformed data\nset_printoptions(precision=3)\nprint(rescaledX[0:5,:])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Normalize Data\nNormalizing in scikit-learn refers to rescaling each observation (row) to have a length of 1 (called a unit norm or a vector with the length of 1 in linear algebra). This pre-processing method can be useful for sparse datasets (lots of zeros) with attributes of varying scales when using algorithms that weight input values such as neural networks and algorithms that use distance measures such as k-Nearest Neighbors. You can normalize data in Python with scikit-learn using the Normalizer class\n\n\nReading : http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Normalizer.html"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Normalize data (length of 1) separate array into input and output components\nX = array[:,0:8]\nY = array[:,8]\nscaler = Normalizer().fit(X)\nnormalizedX = scaler.transform(X)\n# summarize transformed data\nset_printoptions(precision=3)\nprint(normalizedX[0:5,:])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Binarize Data (Make Binary)\nYou can transform your data using a binary threshold. All values above the threshold are marked 1 and all equal to or below are marked as 0. This is called binarizing your data or thresholding your data. It can be useful when you have probabilities that you want to make into crisp values. It is also useful when feature engineering and you want to add new features that indicate something meaningful. You can create new binary attributes in Python using scikit-learn with the Binarizer class.\n\nReading: http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Binarizer.html"},{"metadata":{"trusted":true},"cell_type":"code","source":"# binarization separate array into input and output components\nX = array[:,0:8]\nY = array[:,8]\nbinarizer = Binarizer(threshold=0.0).fit(X)\nbinaryX = binarizer.transform(X)\n# summarize transformed data\nset_printoptions(precision=3)\nprint(binaryX[0:5,:])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Simple Linear Regression\nLinear regression is a prediction method that is more than 200 years old. Simple linear regression is a great first machine learning algorithm to implement as it requires you to estimate properties from your training dataset, but is simple enough for beginners to understand. In this tutorial, you will discover how to implement the simple linear regression algorithm from scratch in Python.\nAfter completing this tutorial you will know:\n How to estimate statistical quantities from training data.\n How to estimate linear regression coe\u000ecients from data.\n How to make predictions using linear regression for new data.\nLet's get started.\n"},{"metadata":{},"cell_type":"markdown","source":"Let's look at a normal distribution. Below is some code to generate and plot an idealized\nGaussian distribution.\n\nRunning the example generates a plot of an idealized Gaussian distribution. The x-axis are  the observations and the y-axis is the likelihood of each observation. In this case, observations around 0.0 are the most common and observations around -3.0 and 3.0 are rare or unlikely.Technically, this is called a probability density function"},{"metadata":{"trusted":true},"cell_type":"code","source":"# generate and plot an idealized gaussian\nfrom numpy import arange\nfrom matplotlib import pyplot\nfrom scipy.stats import norm\n# x-axis for the plot\nx_axis = arange(-3, 3, 0.001)\n# y-axis as the gaussian\ny_axis = norm.pdf(x_axis, 0, 1)\n# plot data\npyplot.plot(x_axis, y_axis)\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can almost see the Gaussian shape to the data, but it is blocky.\nThis highlights an important point. Sometimes, the data will not be a perfect Gaussian, but\nit will have a Gaussian-like distribution. It is almost Gaussian and maybe it would be more\nGaussian if it was plotted in a di\u000berent way, scaled in some way, or if more data was gathered.\nOften, when working with Gaussian-like data, we can treat it as Gaussian and use all of the\nsame statistical tools and get reliable results."},{"metadata":{},"cell_type":"markdown","source":"We can then plot the dataset using a histogram and look for the expected shape of the\nplotted data. The complete example is listed below "},{"metadata":{"trusted":true},"cell_type":"code","source":"# generate a sample of random gaussians\nfrom numpy.random import seed\nfrom numpy.random import randn\nfrom matplotlib import pyplot\n# seed the random number generator\nseed(1)\n# generate univariate observations\ndata = 5 * randn(10000) + 50\n# histogram of generated data\npyplot.hist(data)\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Example of calculating and plotting the sample of Gaussian random numbers with\nmore bins."},{"metadata":{"trusted":true},"cell_type":"code","source":"# generate a sample of random gaussians\nfrom numpy.random import seed\nfrom numpy.random import randn\nfrom matplotlib import pyplot\n# seed the random number generator\nseed(1)\n# generate univariate observations\ndata = 5 * randn(10000) + 50\n# histogram of generated data\npyplot.hist(data, bins=100)\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Central Tendency\nThe central tendency of a distribution refers to the middle or typical value in the distribution.\nThe most common or most likely value. In the Gaussian distribution, the central tendency is\ncalled the mean, or more formally, the arithmetic mean, and is one of the two main parameters\nthat de\fnes any Gaussian distribution."},{"metadata":{},"cell_type":"markdown","source":"Example of calculating the **mean** of a data sample."},{"metadata":{"trusted":true},"cell_type":"code","source":"# calculate the mean of a sample\nfrom numpy.random import seed\nfrom numpy.random import randn\nfrom numpy import mean\nfrom numpy import median\n# seed the random number generator\nseed(1)\n# generate univariate observations\ndata = 5 * randn(10000) + 50\n# calculate mean\nresult = mean(data)\nprint('Mean: %.3f' % result)\nresult = median(data)\nprint('Mean: %.3f' % result)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Variance\nThe variance of a distribution refers to how much on average that observations vary or di\u000ber\nfrom the mean value. It is useful to think of the variance as a measure of the spread of a\ndistribution. A low variance will have values grouped around the mean (e.g. a narrow bell\nshape), whereas a high variance will have values spread out from the mean (e.g. a wide bell\nshape.) We can demonstrate this with an example, by plotting idealized Gaussians with low\nand high variance. The complete example is listed below."},{"metadata":{"trusted":true},"cell_type":"code","source":"# generate and plot gaussians with different variance\nfrom numpy import arange\nfrom matplotlib import pyplot\nfrom scipy.stats import norm\n# x-axis for the plot\nx_axis = arange(-3, 3, 0.001)\n# plot low variance\npyplot.plot(x_axis, norm.pdf(x_axis, 0, 0.5))\n# plot high variance\npyplot.plot(x_axis, norm.pdf(x_axis, 0, 1))\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Example of calculating the variance of a data sample.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# calculate the variance of a sample\nfrom numpy.random import seed\nfrom numpy.random import randn\nfrom numpy import var\n# seed the random number generator\nseed(1)\n# generate univariate observations\ndata = 5 * randn(10000) + 50\n# calculate variance\nresult = var(data)\nprint('Variance: %.3f' % result)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Calculate the standard deviation of a sample"},{"metadata":{"trusted":true},"cell_type":"code","source":"# calculate the standard deviation of a sample\nfrom numpy.random import seed\nfrom numpy.random import randn\nfrom numpy import std\n# seed the random number generator\nseed(1)\n# generate univariate observations\ndata = 5 * randn(10000) + 50\n# calculate standard deviation\nresult = std(data)\nprint('Standard Deviation: %.3f' % result)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Example creating a line plot from data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# example of a line plot\nfrom numpy import sin\nfrom matplotlib import pyplot\n# consistent interval for x-axis\nx = [x*0.1 for x in range(100)]\n# function of x for y-axis\ny = sin(x)\n# create line plot\npyplot.plot(x, y)\n# show line plot\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Bar Chart \n\nbar chart is generally used to present relative quantities for multiple categories. The x-axis\nrepresents the categories and are spaced evenly. The y-axis represents the quantity for each\ncategory and is drawn as a bar from the baseline to the appropriate level on the y-axis. A\nbar chart can be created by calling the bar() function and passing the category names for the\nx-axis and the quantities for the y-axis."},{"metadata":{"trusted":true},"cell_type":"code","source":"# example of a bar chart\nfrom random import seed\nfrom random import randint\nfrom matplotlib import pyplot\n# seed the random number generator\nseed(1)\n# names for categories\nx = ['red', 'green', 'blue']\n# quantities for each category\ny = [randint(0, 100), randint(0, 100), randint(0, 100)]\n# create bar chart\npyplot.bar(x, y)\n# show line plot\n\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# A histogram plot \nA histogram plot is generally used to summarize the distribution of a data sample. The x-axis\nrepresents discrete bins or intervals for the observations. For example observations with values\nbetween 1 and 10 may be split into \fve bins, the values [1,2] would be allocated to the \frst bin,\n\n[3,4] would be allocated to the second bin, and so on. The y-axis represents the frequency or\ncount of the number of observations in the dataset that belong to each bin. Essentially, a data\nsample is transformed into a bar chart where each category on the x-axis represents an interval\nof observation values.\nHistograms are density estimates. A density estimate gives a good impression of\nthe distribution of the data.[...] The idea is to locally represent the data density by\ncounting the number of observations in a sequence of consecutive intervals (bins) ...\nExample creating a bar chart from data.****\n\nExample creating a histogram plot from data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# example of a histogram plot\nfrom numpy.random import seed\nfrom numpy.random import randn\nfrom matplotlib import pyplot\n# seed the random number generator\nseed(1)\n# random numbers drawn from a Gaussian distribution\nx = randn(1000)\n# create histogram plot\npyplot.hist(x)\n# show line plot\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# A box and whisker plot\nA box and whisker plot, or boxplot for short, is generally used to summarize the distribution of\na data sample. The x-axis is used to represent the data sample, where multiple boxplots can be\ndrawn side by side on the x-axis if desired.\nThe y-axis represents the observation values. A box is drawn to summarize the middle\n50% of the dataset starting at the observation at the 25th percentile and ending at the 75th\npercentile. The median, or 50th percentile, is drawn with a line. A value called the interquartile\nrange, or IQR, is calculated as 1.5 * the di\u000berence between the 75th and 25th percentiles. Lines\ncalled whiskers are drawn extending from both ends of the box with the length of the IQR to\n\ndemonstrate the expected range of sensible values in the distribution. Observations outside the\nwhiskers might be outliers and are drawn with small circles.\nExample creating a box and whisker plot from data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# example of a box and whisker plot\nfrom numpy.random import seed\nfrom numpy.random import randn\nfrom matplotlib import pyplot\n# seed the random number generator\nseed(1)\n# random numbers drawn from a Gaussian distribution\nx = [randn(1000), 5 * randn(1000), 10 * randn(1000)]\n# create box and whisker plot\npyplot.boxplot(x)\n# show line plot\npyplot.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Scatter plots are useful for showing the association or correlation between two variables. A\ncorrelation can be quanti\fed, such as a line of best first, that too can be drawn as a line plot on\nthe same chart, making the relationship clearer. A dataset may have more than two measures\n(variables or columns) for a given observation. A scatter plot matrix is a cart containing scatter\nplots for each pair of variables in a dataset with more than two variables. The example below\ncreates two data samples that are related. The first is a sample of random numbers drawn\nfrom a standard Gaussian. The second is dependent upon the first by adding a second random\nGaussian value to the value of the first measure."},{"metadata":{"trusted":true},"cell_type":"code","source":"# example of a scatter plot\nfrom numpy.random import seed\nfrom numpy.random import randn\nfrom matplotlib import pyplot\n# seed the random number generator\nseed(1)\n# first variable\nx = 20 * randn(1000) + 100\n# second variable\ny = x + (10 * randn(1000) + 50)\n# create scatter plot\npyplot.scatter(x, y)\n# show line plot\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Combining this with the functions to estimate the mean and standard deviation summary\nstatistics, we can standardize our contrived dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Example of standardizing a contrived dataset\nfrom math import sqrt\n# calculate column means\ndef column_means(dataset):\n    means = [0 for i in range(len(dataset[0]))]\n    for i in range(len(dataset[0])):\n        col_values = [row[i] for row in dataset]\n        means[i] = sum(col_values) / float(len(dataset))\n    return means\n# calculate column standard deviations\ndef column_stdevs(dataset, means):\n    stdevs = [0 for i in range(len(dataset[0]))]\n    for i in range(len(dataset[0])):\n        variance = [pow(row[i]-means[i], 2) for row in dataset]\n        stdevs[i] = sum(variance)\n    stdevs = [sqrt(x/(float(len(dataset)-1))) for x in stdevs]\n    return stdevs\n# standardize dataset\ndef standardize_dataset(dataset, means, stdevs):\n    for row in dataset:\n        for i in range(len(row)):\n            row[i] = (row[i] - means[i]) / stdevs[i]\n# Standardize dataset\ndataset = [[50, 30], [20, 90], [30, 50]]\nprint(dataset)\n# Estimate mean and standard deviation\nmeans = column_means(dataset)\nstdevs = column_stdevs(dataset, means)\nprint(means)\nprint(stdevs)\n# standardize dataset\nstandardize_dataset(dataset, means, stdevs)\nprint(dataset)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Simple Linear Regression\nLinear regression is a prediction method that is more than 200 years old. Simple linear regression\nis a great first machine learning algorithm to implement as it requires you to estimate properties\nfrom your training dataset, but is simple enough for beginners to understand. In this tutorial,\nyou will discover how to implement the simple linear regression algorithm from scratch in\nPython.\nAfter completing this tutorial you will know:\n How to estimate statistical quantities from training data.\n How to estimate linear regression coe\u000ecients from data.\n How to make predictions using linear regression for new data.\nLet's get started."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate the mean value of a list of numbers\ndef mean(values):\n    return sum(values) / float(len(values))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate the variance of a list of numbers\ndef variance(values, mean):\n    return sum([(x-mean)**2 for x in values])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#calculate mean and variance\ndataset = [[1, 1], [2, 3], [4, 3], [3, 2], [5, 5]]\nx = [row[0] for row in dataset]\ny = [row[1] for row in dataset]\nmean_x, mean_y = mean(x), mean(y)\nvar_x, var_y = variance(x, mean_x), variance(y, mean_y)\nprint('x stats: mean=%.3f variance=%.3f' % (mean_x, var_x))\nprint('y stats: mean=%.3f variance=%.3f' % (mean_y, var_y))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate covariance between x and y\ndef covariance(x, mean_x, y, mean_y):\n    covar = 0.0\n    for i in range(len(x)):\n        covar += (x[i] - mean_x) * (y[i] - mean_y)\n    return covar","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# calculate covariance\ndataset = [[1, 1], [2, 3], [4, 3], [3, 2], [5, 5]]\nx = [row[0] for row in dataset]\ny = [row[1] for row in dataset]\nmean_x, mean_y = mean(x), mean(y)\ncovar = covariance(x, mean_x, y, mean_y)\nprint('Covariance: %.3f' % (covar))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate coefficients\ndef coefficients(dataset):\n    x = [row[0] for row in dataset]\n    y = [row[1] for row in dataset]\n    x_mean, y_mean = mean(x), mean(y)\n    b1 = covariance(x, x_mean, y, y_mean) / variance(x, x_mean)\n    b0 = y_mean - b1 * x_mean\n    return [b0, b1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# calculate coefficients\ndataset = [[1, 1], [2, 3], [4, 3], [3, 2], [5, 5]]\nb0, b1 = coefficients(dataset)\nprint('Coefficients: B0=%.3f, B1=%.3f' % (b0, b1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def simple_linear_regression(train, test):\n    predictions = list()\n    b0, b1 = coefficients(train)\n    for row in test:\n        yhat = b0 + b1 * row[0]\n        predictions.append(yhat)\n    return predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def rmse_metric(actual, predicted):\n    sum_error = 0.0\n    for i in range(len(actual)):\n        prediction_error = predicted[i] - actual[i]\n        sum_error += (prediction_error ** 2)\n        mean_error = sum_error / float(len(actual))\n    return sqrt(mean_error)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluate regression algorithm on training dataset\ndef evaluate_algorithm(dataset, algorithm):\n    test_set = list()\n    for row in dataset:\n        row_copy = list(row)\n        row_copy[-1] = None\n        test_set.append(row_copy)\n        predicted = algorithm(dataset, test_set)\n    print(predicted)\n    actual = [row[-1] for row in dataset]\n    rmse = rmse_metric(actual, predicted)\n    return rmse","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Test simple linear regression\ndataset = [[1, 1], [2, 3], [4, 3], [3, 2], [5, 5]]\nrmse = evaluate_algorithm(dataset, simple_linear_regression)\nprint('RMSE: %.3f' % (rmse))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}