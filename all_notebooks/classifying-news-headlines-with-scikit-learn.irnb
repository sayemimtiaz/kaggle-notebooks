{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"e45fa26c-5b46-d737-6486-2b7f4de1c915"},"source":"The UCI ML News Aggregator Dataset contains headlines and categories for over 400k news articles. Let's see if we can accurately classify the news category based just on the headline.\n\nWe'll use a [Multinomial Naive Bayes](https://en.wikipedia.org/wiki/Naive_Bayes_classifier) model to classify the headlines. Multinomial Naive Bayes models are provided in Python by the [scikit-learn library](http://scikit-learn.org/stable/modules/naive_bayes.html)."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a12bb00d-8b76-ef20-38fd-8777b9c10cba"},"outputs":[],"source":"# get some libraries that will be useful\nimport re\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# the Naive Bayes model\nfrom sklearn.naive_bayes import MultinomialNB\n# function to split the data for cross-validation\nfrom sklearn.model_selection import train_test_split\n# function for transforming documents into counts\nfrom sklearn.feature_extraction.text import CountVectorizer\n# function for encoding categories\nfrom sklearn.preprocessing import LabelEncoder\n\n\n# grab the data\nnews = pd.read_csv(\"../input/uci-news-aggregator.csv\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0db96719-79c5-b270-a349-ed9723f8b838"},"outputs":[],"source":"# let's take a look at our data\nnews.head()"},{"cell_type":"markdown","metadata":{"_cell_guid":"85c96bd1-f6ac-99c5-383d-8f6e84f9093e"},"source":"One thing we'll want to do is normalize the TITLE column a bit: remove punctuation and lowercase everything. This will give us a smaller set of words, which will decrease the size of our model, and ensure that words are treated the same even if they occur capitalized at the beginning of the headline or lowercase in the middle."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0e2df6cf-eee7-0e5c-9000-bf624af694fa"},"outputs":[],"source":"def normalize_text(s):\n    s = s.lower()\n    \n    # remove punctuation that is not word-internal (e.g., hyphens, apostrophes)\n    s = re.sub('\\s\\W',' ',s)\n    s = re.sub('\\W\\s',' ',s)\n    \n    # make sure we didn't introduce any double spaces\n    s = re.sub('\\s+',' ',s)\n    \n    return s\n\nnews['TEXT'] = [normalize_text(s) for s in news['TITLE']]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b016b879-d3d3-9214-4e05-58ac253c5c3d"},"outputs":[],"source":"news.head()"},{"cell_type":"markdown","metadata":{"_cell_guid":"2850722b-ed92-ef0b-04c9-84841b2b0512"},"source":"Okay now let's get our data into a format where it will play nicely with the classifier."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"20de11e1-fddb-288f-de82-8a9cc15d9338"},"outputs":[],"source":"# pull the data into vectors\nvectorizer = CountVectorizer()\nx = vectorizer.fit_transform(news['TEXT'])\n\nencoder = LabelEncoder()\ny = encoder.fit_transform(news['CATEGORY'])\n\n# split into train and test sets\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n\n# take a look at the shape of each of these\nprint(x_train.shape)\nprint(y_train.shape)\nprint(x_test.shape)\nprint(y_test.shape)"},{"cell_type":"markdown","metadata":{"_cell_guid":"bd9d43dd-c7c6-47ab-0c15-6dd14b495b93"},"source":"So the x training vector contains 337935 observations of 54637 occurrences -- this latter number is the number of unique words in the entire collection of headlines. The x training vector contains the 337935 labels associated with each observation in the x training vector.\n\nSo we're ready to go. Let's make the classifier!"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"971e7969-766c-e75b-4ae8-b09ce26b33df"},"outputs":[],"source":"nb = MultinomialNB()\nnb.fit(x_train, y_train)"},{"cell_type":"markdown","metadata":{"_cell_guid":"e77ee291-1443-22fd-0f31-4405a4b271d1"},"source":"How well did it do?"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"62a469f2-6ac6-c5c5-a0c2-ccbd3e97489d"},"outputs":[],"source":"nb.score(x_test, y_test)"},{"cell_type":"markdown","metadata":{"_cell_guid":"246ecbbe-c3ae-13a9-74a3-cdeb4945443e"},"source":"Nice! Over 92% accuracy, just by using words as independent features"},{"cell_type":"markdown","metadata":{"_cell_guid":"4a02a410-2b9e-ee03-71d4-64770b47d161"},"source":"If you feel like exploring what words are characteristic of each category, you can pull out the coefficients of the Naive Bayes classifier:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"05f9d835-3c91-d134-0462-b53ed30597ff"},"outputs":[],"source":"coefs = nb.coef_\nprint(coefs.shape)\nprint(coefs)"},{"cell_type":"markdown","metadata":{"_cell_guid":"a2eedc65-df12-f305-a6bb-dd6a949094bb"},"source":"That's a matrix of the log probability of each word given each category. The usual way to find characteristic words for a category is to take those words with the largest log odds ratio per category, which is an exercise left to the reader.\n\nThe coefficients only give you log probabilities by index (which corresponds to whatever ordering the CountVectorizer decided on). To convert these indices back to words, you can pull out the vocabulary from the vectorizer:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"425058d7-ca67-6f2f-cb18-8daec419a3d7"},"outputs":[],"source":"def make_reverse_vocabulary(vectorizer):\n    revvoc = {}\n\n    vocab = vectorizer.vocabulary_\n    for w in vocab:\n        i = vocab[w]\n\n        revvoc[i] = w\n\n    return revvoc"},{"cell_type":"markdown","metadata":{"_cell_guid":"0b88bad7-4612-f6a3-0fa4-8861ac2e6974"},"source":"And you can do something similar with the LabelEncoder to match the model's output classifications back to the dataset's categories. Again, this is left to the reader.\n\nI hope this was helpful in learning how to classify text! Possible next steps: \n- figure out the most characteristic words for each news category (someone please do this and report back!)\n- figure out how accurately we can classify particular news items (STORY in the dataset) given headline text"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"R","language":"R","name":"ir"},"language_info":{"codemirror_mode":"r","file_extension":".r","mimetype":"text/x-r-source","name":"R","pygments_lexer":"r","version":"3.3.3"}},"nbformat":4,"nbformat_minor":0}