{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Models and Crossvalidation\nUsing the follow dataset [Hotel Booking Demand](https://www.kaggle.com/jessemostipak/hotel-booking-demand/tasks), I will try to answer the task, \"**Can we predict the possibility of a booking**?\", or better, \"**Can we predict if a booking will be cancelled or not?**\". Starting this notebook with an EDA, Exploratory Data Analysis, and after that, I'm going to test more than one classifier and compare the results. The models will be tested with cross-validation.\n\nShall we start? :D"},{"metadata":{},"cell_type":"markdown","source":"Starting all the libs and setting warnings..."},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport math","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Load all the dataset"},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"hotel_bookings = pd.read_csv(\"../input/hotel-booking-demand/hotel_bookings.csv\")\nhotel_bookings.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploratory Data Analysis"},{"metadata":{},"cell_type":"markdown","source":"As you can see, there is a lot of columns in this dataset and this is the first question, which ones have do I to use?\nI'll ignore the columns with data information such as: `arrival_date_month`, `arrival_date_day_of_month`, `stays_in_weekend_nights`, `stays_in_week_nights`. I had to keep the `arrival_date_week_number` because this column can preserve the all data information I need about the time of year. During part of the year, tourism is higher than others and this column will help me with that."},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel_bookings.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For this point, I wanna see the value impact in the label, where we correlate, by math with the action 'cancel a book'. Selecting only the numeric value columns, let's plot the matrix."},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = hotel_bookings[\n    ['is_repeated_guest', 'previous_cancellations', \n     'previous_bookings_not_canceled', 'booking_changes', \n     'days_in_waiting_list', 'lead_time', 'adults', \n     'children', 'babies','is_canceled']\n]\n\nwith sns.axes_style(\"white\"):\n    table = corr.corr()\n    mask = np.zeros_like(table)\n    mask[np.triu_indices_from(mask)] = True\n    plt.figure(figsize=(18,7))\n    sns.heatmap(table, cmap='Reds', mask=mask, vmax=.3, linewidths=0.5, annot=True,annot_kws={\"size\": 15})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The next pairplot with linear regression is another way to see the last graph. And there is some interesting information, for example, we can see who not cancelled a book before has a .42 to be a repeat guest. The lead time is important to a customer not to cancel a book."},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nsns.pairplot(corr, kind='reg', y_vars='is_canceled', x_vars=['is_repeated_guest', 'previous_cancellations', \n                                                             'previous_bookings_not_canceled', 'booking_changes', \n                                                             'lead_time', 'days_in_waiting_list', 'adults', 'children', \n                                                             'babies'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In this part, I will plot the cancel rate for four columns and see with some categories has a different cancel rate, what means could be a pattern for a specific category."},{"metadata":{"trusted":true},"cell_type":"code","source":"from plotly.subplots import make_subplots\nimport plotly.graph_objects as go\n\nfig = make_subplots(rows=2, cols=2, shared_yaxes=True)\n\ncustomer_type = hotel_bookings.groupby(['customer_type']).is_canceled.mean().round(2) * 100\nreservation_status = hotel_bookings.groupby(['reservation_status']).is_canceled.mean().round(2) * 100\narrival_date_year = hotel_bookings.groupby(['arrival_date_year']).is_canceled.mean().round(2) * 100\nhotel = hotel_bookings.groupby(['hotel']).is_canceled.mean().round(2) * 100\n\n# Plots\nfig.add_trace(go.Bar(x=customer_type.index, y=customer_type, text=customer_type, textposition='auto'),1, 1)\nfig.add_trace(go.Bar(x=reservation_status.index, y=reservation_status, text=reservation_status, textposition='auto'),1, 2)\nfig.add_trace(go.Bar(x=arrival_date_year.index, y=arrival_date_year, text=arrival_date_year, textposition='auto'),2, 1)\nfig.add_trace(go.Bar(x=hotel.index, y=hotel, text=hotel, textposition='auto'),2, 2)\n\nfig.update_layout(height=800, width=1000, title_text=\"Cancel rate by column\")\n\n# Update xaxis properties\nfig.update_xaxes(title_text=\"Customer Type\", row=1, col=1)\nfig.update_xaxes(title_text=\"Reservation Status\", row=1, col=2)\nfig.update_xaxes(title_text=\"Arrival Year\", row=2, col=1)\nfig.update_xaxes(title_text=\"Hotel Type\", row=2, col=2)\n\n# Update yaxis properties\nfig.update_yaxes(title_text=\"Cancel rate in percent (%)\", row=1, col=1)\nfig.update_yaxes(title_text=\"Cancel rate in percent (%)\", row=1, col=2)\nfig.update_yaxes(title_text=\"Cancel rate in percent (%)\", row=2, col=1)\nfig.update_yaxes(title_text=\"Cancel rate in percent (%)\", row=2, col=2)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Looking at the customer graph, we can see the group costumer has a low probability to cancel if you compare to another client type.\n- The reservation status... to be honest, seems nothing for me.\n- Analysing the years, I can affirm the year is not relevant to cancel, for this dataset guys.\n- The hotel type has a relevant difference rate. A city hotel is higher than a resort hotel. This graph makes sense because the resort hotel is more planned for vacation for example."},{"metadata":{},"cell_type":"markdown","source":"Now let's see with some epoch of this dataset has anomalies."},{"metadata":{"trusted":true},"cell_type":"code","source":"month = {\n    'January':'01',\n    'February':'02',\n    'March':'03',\n    'April':'04',\n    'May':'05',\n    'June':'06',\n    'July' :'07',\n    'August':'08',\n    'September':'09',\n    'October' :'10',\n    'November':'11',\n    'December': '12'\n}\n\ndef translate(data):\n    return month[data]\n\ndef plot_groupby(cancel, title, xaxis, yaxis, tt='%{text:.2s}'):\n    aux_dfs = []\n    for year in [2015,2016,2017]:\n        aux_df = pd.DataFrame(cancel.loc[year])\n        aux_df.index = [str(year) + '-' + translate(m) for m in aux_df.index]\n        aux_dfs.append(aux_df)\n\n    cancel_rate = pd.concat(aux_dfs)\n    cancel_rate['epoch'] = cancel_rate.index\n    cancel_rate.is_canceled = cancel_rate.is_canceled * 100\n    \n    fig = px.bar(cancel_rate, y='is_canceled', x='epoch', text='is_canceled')\n    \n    fig.update_xaxes(title_text=xaxis)\n    fig.update_yaxes(title_text=yaxis)\n    fig.update_traces(texttemplate=tt, textposition='outside')\n    fig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')\n    fig.update_layout(\n        height=450,\n        title_text=title\n    )\n    return fig","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cancel = hotel_bookings.groupby(['arrival_date_year','arrival_date_month']).is_canceled.mean()\nplot_groupby(cancel, \"Cancel rate per month-year (%)\", \"Months-Year\", \"Cancel rate in percent (%)\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looking by months-yers, our cancel rate don't show us some `seasonal` event, in November 2015 we have 21% but in November 2016 is 37%. May an isolated event happened in November 2015 and this one not happened in November 2016. Our worst epoch was July 2015, the best was November 2015."},{"metadata":{},"cell_type":"markdown","source":"## Prediction with 6 models"},{"metadata":{},"cell_type":"markdown","source":"As I said before, I will pick this follow columns and encoder the categorical columns. \n\nMy features are: \n- hotel \n- lead_time \n- arrival_date_week_number \n- adults\n- children \n- babies \n- meal \n- country \n- market_segment  \n- distribution_channel\n- is_repeated_guest \n- previous_cancellations\n- previous_bookings_not_canceled \n- reserved_room_type\n- assigned_room_type \n- booking_changes \n- deposit_type \n- days_in_waiting_list\n- customer_type \n- required_car_parking_spaces \n- total_of_special_requests\n- reservation_status\n\nMy label is:\n- is_canceled"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = hotel_bookings[[\n    'hotel', \n    'lead_time', \n    'arrival_date_week_number', \n    'adults',\n    'children', \n    'babies', \n    'meal', \n    'country', \n    'market_segment',  \n    'distribution_channel',\n    'is_repeated_guest', \n    'previous_cancellations',\n    'previous_bookings_not_canceled', \n    'reserved_room_type',\n    'assigned_room_type', \n    'booking_changes', \n    'deposit_type', \n    'days_in_waiting_list',\n    'customer_type', \n    'required_car_parking_spaces', \n    'total_of_special_requests',\n    'reservation_status',\n    'is_canceled'\n]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's encoder the categories, and to identify the columns, we can use the `dtypes` and take all the `object` columns."},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.dropna(inplace=True) # We will lose a few rows...\ndataset.children = dataset.children.astype('int64') # convert from float to int\ntypes = pd.DataFrame(dataset.dtypes, columns=['type']) # prepare the categorical columns\ncolumns = list(types[types.type == 'object'].index)  # making a list to the 'for' loop\n\nfrom sklearn.preprocessing import LabelEncoder \n\nlb_make = LabelEncoder()\nfor column in columns:\n    dataset[column] = lb_make.fit_transform(dataset[column])\n\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Our dataset now is ready to be used by predict models."},{"metadata":{"trusted":true},"cell_type":"code","source":"X = dataset[[\n    'hotel', \n    'lead_time', \n    'arrival_date_week_number', \n    'adults',\n    'children', \n    'babies', \n    'meal', \n    'country', \n    'market_segment',  \n    'distribution_channel',\n    'is_repeated_guest', \n    'previous_cancellations',\n    'previous_bookings_not_canceled', \n    'reserved_room_type',\n    'assigned_room_type', \n    'booking_changes', \n    'deposit_type', \n    'days_in_waiting_list',\n    'customer_type', \n    'required_car_parking_spaces', \n    'total_of_special_requests',\n    'reservation_status',\n]]\n\nY = dataset[['is_canceled']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I choose 6 Classifier inside the `sklearn` lib."},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import train_test_split\n\n# Models\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier, NearestCentroid\n\nmodels = [\n    # ('SVC', SVC()), # I change my mind, this model is taking too much time\n    ('RandomForestClassifier', RandomForestClassifier()),\n    ('SGDClassifier', SGDClassifier()),\n    ('MLPClassifier', MLPClassifier()),\n    ('Tree', DecisionTreeClassifier()),\n    ('NearestCentroid', NearestCentroid()),\n    ('KNeighborsClassifier', KNeighborsClassifier())\n]\n\ndef train_test_validation(model, name, X, Y):\n    print(f\"Starting {name}.\") # Debug\n    ini = time.time() # Start clock\n    scores = cross_val_score(model, X, Y, cv=4) # Cross-validation\n    fim = time.time() # Finish clock\n    print(f\"Finish {name}.\") # Debug\n    return (name,scores.mean(), scores.max(), scores.min(), fim-ini)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nresults = [ train_test_validation(model[1], model[0], X, Y) for model in models ] # Testing for all models\nresults = pd.DataFrame(results, columns=['Classifier', 'Mean', 'Max', 'Min', 'TimeSpend (s)']) # Making a data frame","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plotting the results and see the best model for this dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"from plotly.subplots import make_subplots\nimport plotly.graph_objects as go\n\nfig = make_subplots(rows=2, cols=1, shared_yaxes=True)\nx=results['Classifier']\ny=round(results['Mean'] * 100,2)\nz=round(results['TimeSpend (s)'],2)\n\n# Plots\nfig.add_trace(go.Bar(x=x, y=y, text=y, textposition='auto'),1, 1)\nfig.add_trace(go.Bar(x=x, y=z, text=z, textposition='auto'),2, 1)\n\nfig.update_layout(height=800, width=1000, title_text=\"Traing Models for Booking Hotel\")\n\n# Update xaxis properties\nfig.update_xaxes(title_text=\"Acurracy by Crossvalidation\", row=1, col=1)\nfig.update_xaxes(title_text=\"Time Spended by traing\", row=2, col=1)\n\n# Update yaxis properties\nfig.update_yaxes(title_text=\"Accurracy in percent (%)\", row=1, col=1)\nfig.update_yaxes(title_text=\"Time in seconds (s)\", row=2, col=1)\n\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The `DecisionTreeClassifier` for me is the best, got 100% accuracy and a sort of time spent to train. `MLPClassifier` is as good as `DecisionTreeClassifier` but spend so much time to train, which makes a bad choice."},{"metadata":{"trusted":true},"cell_type":"code","source":"results","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now I'll use the `DecisionTreeClassifier` and plot the model."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import export_graphviz\nimport graphviz\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20) # Split the dataset\n\nmodel_t = DecisionTreeClassifier(criterion='entropy')\nmodel_t.fit(X_train, y_train)\n\ny_pred = model_t.predict(X_test)\n\naccuracy = accuracy_score(y_pred, y_test) * 100\nprint(f'The tree model accuracy was {accuracy} %')\n\nfeatures = X.columns\ndot_data = export_graphviz(model_t, out_file=None,\n                           filled = True, rounded = True,\n                           feature_names = features,\n                           class_names = [\"no\", \"yes\"])\n\ngraphics = graphviz.Source(dot_data)\ngraphics","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finishing this notebook answering the question on the task dataset.\nCan we predict the possibility of a booking? Yes, we can."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}