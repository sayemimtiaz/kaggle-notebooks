{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Create Dataframe**"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport sklearn\nimport pandas as pd\nimport wave\nimport sys\nimport os\nimport librosa\nimport librosa.display\nimport xgboost as xgb\nfrom  sklearn.preprocessing import StandardScaler,MinMaxScaler\nfrom sklearn.cluster import KMeans\nfrom sklearn.model_selection import GridSearchCV \nfrom sklearn.metrics import accuracy_score, f1_score, classification_report\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nimport sklearn.naive_bayes as nb\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import BaggingClassifier,GradientBoostingClassifier\nfrom sklearn.neighbors import kd_tree\nimport seaborn as sn\nfrom sklearn.metrics import confusion_matrix\nfrom collections import Counter\nfrom sklearn.datasets import make_classification\nfrom imblearn.over_sampling import SMOTE # doctest: +NORMALIZE_WHITESPACE\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_dataframe(folder):\n    soundwav = []\n    for root, dirs, files in os.walk(folder):\n        for file in files:\n            if file.endswith('.wav'):\n                soundwav.append(file)\n    data = [];\n    \n    for file in soundwav:\n        if file[:3] not in data:\n            data.append(file[:3])\n    data = sorted(data)    \n    row =[]\n    \n    for i in data :\n        r1=[]\n        for file in soundwav:\n            if file[:3]==i:\n                r1.append(file)\n        row.append(r1)\n                \n    \n    df=pd.DataFrame(row,index=data)\n    col = []\n    for i in range(1,df.shape[1]+1):\n        col.append('soundtrack-'+str(i))\n    \n    df.columns = col\n\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"folder = \"/kaggle/input/respiratory-sound-database/respiratory_sound_database/Respiratory_Sound_Database/\"   \n\nsubfolder =folder  +'audio_and_txt_files/'\ndf = create_dataframe(subfolder)\ndf=df.rename_axis('ID')\nsoundpath=[]\nfor i in df.iloc[:,0]:\n    soundpath.append(subfolder+i)\ndiagnosis = pd.read_csv(folder+'patient_diagnosis.csv', names = ['Patient number', 'Diagnosis'])\nsoundtracks=df.count(axis=1)\nparent_dir = folder\ntr_sub_dirs = subfolder\nts_sub_dirs = subfolder+\"test/\"\n\ndf=df.rename_axis('ID')\nprint(df.head(10))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Load Sound data**\n"},{"metadata":{},"cell_type":"markdown","source":"based on the CNN: Detection of wheezes and crackles kernel"},{"metadata":{"trusted":true},"cell_type":"code","source":"import wave\nimport math\nimport scipy.io.wavfile as wf\nimport numpy as np\n#wave file reader\n\n#Will resample all files to the target sample rate and produce a 32bit float array\ndef read_wav_file(str_filename, target_rate):\n    wav = wave.open(str_filename, mode = 'r')\n    (sample_rate, data) = extract2FloatArr(wav,str_filename)\n    \n    if (sample_rate != target_rate):\n        ( _ , data) = resample(sample_rate, data, target_rate)\n        \n    wav.close()\n    return (target_rate, data.astype(np.float32))\n\ndef resample(current_rate, data, target_rate):\n    x_original = np.linspace(0,100,len(data))\n    x_resampled = np.linspace(0,100, int(len(data) * (target_rate / current_rate)))\n    resampled = np.interp(x_resampled, x_original, data)\n    return (target_rate, resampled.astype(np.float32))\n\n# -> (sample_rate, data)\ndef extract2FloatArr(lp_wave, str_filename):\n    (bps, channels) = bitrate_channels(lp_wave)\n    \n    if bps in [1,2,4]:\n        (rate, data) = wf.read(str_filename)\n        divisor_dict = {1:255, 2:32768}\n        if bps in [1,2]:\n            divisor = divisor_dict[bps]\n            data = np.divide(data, float(divisor)) #clamp to [0.0,1.0]        \n        return (rate, data)\n    \n    elif bps == 3: \n        #24bpp wave\n        return read24bitwave(lp_wave)\n    \n    else:\n        raise Exception('Unrecognized wave format: {} bytes per sample'.format(bps))\n        \n#Note: This function truncates the 24 bit samples to 16 bits of precision\n#Reads a wave object returned by the wave.read() method\n#Returns the sample rate, as well as the audio in the form of a 32 bit float numpy array\n#(sample_rate:float, audio_data: float[])\ndef read24bitwave(lp_wave):\n    nFrames = lp_wave.getnframes()\n    buf = lp_wave.readframes(nFrames)\n    reshaped = np.frombuffer(buf, np.int8).reshape(nFrames,-1)\n    short_output = np.empty((nFrames, 2), dtype = np.int8)\n    short_output[:,:] = reshaped[:, -2:]\n    short_output = short_output.view(np.int16)\n    return (lp_wave.getframerate(), np.divide(short_output, 32768).reshape(-1))  #return numpy array to save memory via array slicing\n\ndef bitrate_channels(lp_wave):\n    bps = (lp_wave.getsampwidth() / lp_wave.getnchannels()) #bytes per sample\n    return (bps, lp_wave.getnchannels())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_sound_files(file_paths):\n    raw_sounds = []\n    raw_sr = []\n    for fp in file_paths:\n        sr,X = read_wav_file(fp,22000)\n        #reduced_noise = nr.reduce_noise(audio_clip=X, noise_clip=X, verbose=False)# Visualize\n        raw_sr.append(sr)\n        raw_sounds.append(X)\n    return raw_sounds,raw_sr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def encode(line):\n    if line[0]==0:\n        if line[1]==0:\n            return 0\n        else: \n            return 2\n    if line[0]==1:\n        if line[1]==0:\n            return 1\n        else:\n            return 3\n        \ndef frame(lengths):\n    times=[]\n    labels=[]\n    for df in lengths:\n        l=df.iloc[:,0:2]\n        l=l.to_numpy();      \n        l=l.reshape(1,-1)\n        l=np.ceil(l*22050)\n        l=l.reshape(int(l.size/2),-1)\n        times.append(l)\n        # 0 present of crackle 1 present of wheeles 2 both\n        #0 0 0 or 0 0 1 or 0 1 0 or 1 0 0\n        k=df.iloc[:,2:4]\n        k=k.to_numpy()\n        z=[]\n        for i in k:\n            z.append(encode(i))\n        z=np.asarray(z)\n        z=z.reshape(-1,1)\n        labels.append(z)\n    return times,labels\ndef w_c_dataset(df,subfolder):\n    files=[]\n    lengths=[]\n    for i,j in df.iterrows():\n        for l in j:\n            if(l!=None):\n                files.append(subfolder+str(l))\n                a=str(l).replace('.wav','.txt')\n                tmp=pd.read_csv(subfolder+a,sep='\\t',header = None)\n                lengths.append(tmp)\n                times,labels=frame(lengths)    \n    [sound,sr] = load_sound_files(files)\n    return sound,sr,lengths,times,labels\ndef split_sounds(sounds,times,labels):\n    s=[]\n    l=[]\n    for i,sound in enumerate(sounds):\n        for t,label in zip(times[i],labels[i]):\n            s.append(sound[int(t[0]):int(t[1])])\n            if label==0:\n                a=np.array([1,0,0,0])\n            if label==1:\n                a=np.array([0,1,0,0])\n            if label==2:\n                a=np.array([0,0,1,0])    \n            if label==3:\n                a=np.array([0,0,0,1])\n            l.append(a)\n    return s,l","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"[sound,sr,lengths,times,labels] = w_c_dataset(df,subfolder)\n[data,label]=split_sounds(sound,times,labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Feature Extraction**\n\nWe take statistical features from MFCCs. The reason we do that is the different length of the audio clips.\nFor each clip we take 50 coefficients and we take std and mean for each band. Those are our features for the classifier.\nWe will upload a second approach with BOAW, but it didn't perform well."},{"metadata":{"trusted":true},"cell_type":"code","source":"import librosa\ndef extract_feature(X,sample_rate):\n    \n    n_fft=int(sample_rate*0.025)\n    hop_length=int(sample_rate*0.01)\n    \n    mfcc = librosa.feature.mfcc(y=X, sr=sample_rate,n_fft=n_fft,hop_length=hop_length,\n                                         n_mfcc=50)\n    mean_mfcc = np.mean(mfcc.T,axis=0)\n    std_mfcc = np.std(mfcc.T,axis=0)\n#    p10 = np.percentile(mfcc.T,10,axis=0)\n#    p25 = np.percentile(mfcc.T,25,axis=0)\n#    p50 = np.percentile(mfcc.T,50,axis=0)\n#    p75 = np.percentile(mfcc.T,75,axis=0)\n#    p90 = np.percentile(mfcc.T,90,axis=0)\n    \n\n    return np.vstack((mean_mfcc,std_mfcc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = []\nfor d in data:\n    a = extract_feature(d,sr[0])\n    dataset.append(a)\n\ndata=np.asarray(dataset)\ndata = data.reshape([6898,data.shape[1]*data.shape[2],])\n\nlabel=np.asarray(label)\na=np.zeros(label.shape[0])\nfor i in range(label.shape[0]):\n    for j in range(label.shape[1]):\n        if label[i][j]==1:\n            a[i]=j","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler=StandardScaler()\nx_train,x_test,y_train,y_test = sklearn.model_selection.train_test_split(data,a,test_size=0.3, random_state=42,stratify=a)\nscaler.fit(x_train)\nx_train=scaler.transform(x_train)\nx_test=scaler.transform(x_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**SVM Classifier**\n\nwith RBF kernel grid search and best hyperparameters"},{"metadata":{},"cell_type":"markdown","source":"grid search approach. For convenience in execution time we don't run it again."},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\n    Cs = [2**(-2),2**(-1), 1,2**(1),2**(2),2**(3),2**(4),2**(5),2**(6),2**(7),2**(8),2**(9),2**(10)]\n    gamma = [2**(-7),2**(-6),2**(-5),2**(-4),2**(-3),2**(-2),2**(-1),2**(0),2**(1),2**(2),2**(3)]\n\n\n    param_grid = {'C': Cs,  \n                  'gamma': gamma, \n                  'kernel': ['rbf'],\n                  'decision_function_shape':['ovr'],\n                  'class_weight': ['balanced']}  \n    grid1 = GridSearchCV(SVC(), param_grid,cv=3,n_jobs=-1, verbose = 3) \n\n    # fitting the model for grid search \n    grid1.fit(x_train, y_train)\n\n    # print best parameter after tuning \n    print(grid1.best_params_) \n    # print how our model looks after hyper-parameter tuning \n    print(grid1.best_estimator_)\n\n    grid_predictions = grid1.predict(x_test) \n\n    # print classification report \n    print(classification_report(y_test, grid_predictions))\n    print(accuracy_score(y_test,grid_predictions))\n\n    print(sklearn.metrics.confusion_matrix(y_test,grid_predictions))\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# best parameters\n#{'C': 4, 'class_weight': 'balanced', 'decision_function_shape': 'ovr', 'gamma': 0.03125, 'kernel': 'rbf'}\n\nmodel = SVC(kernel='rbf',class_weight='balanced',gamma=0.03125,C=4)\nmodel.fit(x_train,y_train)\ny_pred = model.predict(x_test)\nprint(classification_report(y_test,y_pred))\nprint(accuracy_score(y_test,y_pred))\n\nprint(sklearn.metrics.confusion_matrix(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"        \ndef onehenc(labels,classes=4):\n    r=np.zeros((labels.shape[0],classes))\n    for i in range(labels.shape[0]):\n        for j in range(classes):\n            if labels[i]==j:\n                r[i,j]=1\n    return r\ndef cm(y_test,y_pred):\n    classes = [\"none\", \"crackles\", \"wheezes\", \"both\"] # put your class labels\n    df_cm = pd.DataFrame(confusion_matrix(y_test, y_pred,labels=range(4)), index = [i for i in classes],\n                      columns = [i for i in classes])\n    plt.figure(figsize = (10,7))\n    plt.title('Confusion matrix')\n    sn.heatmap(df_cm, annot=True,annot_kws={\"size\": 12},fmt='d')\n    \n    \n    plt.show()\n    \ndef plot_roc(y_test,y_pred):\n    \n    test=onehenc(y_test,4)\n    pred=onehenc(y_pred,4)\n    \n    \n    # Compute ROC curve and ROC area for each class\n    from sklearn.metrics import roc_auc_score,roc_curve,auc\n    fpr = dict()\n    tpr = dict()\n    roc_auc = dict()\n    for i in range(4):\n        fpr[i], tpr[i], _ = roc_curve(test[:, i], pred[:, i])\n        roc_auc[i] = auc(fpr[i], tpr[i])\n    \n    plt.figure()\n    \n    # Plot of a ROC curve for a specific class\n    for i in range(4):\n        plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f)' % roc_auc[i])\n        plt.plot([0, 1], [0, 1], 'k--')\n        plt.plot([1,0],[1,1])\n        plt.xlim([0.0, 1.0])\n        plt.ylim([0.0, 1.05])\n        plt.xlabel('False Positive Rate')\n        plt.ylabel('True Positive Rate')\n        plt.title('Receiver operating characteristic example')\n        plt.legend(loc=\"best\")\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm(y_test,y_pred)\nplot_roc(y_test,y_pred)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}