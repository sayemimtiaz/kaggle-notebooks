{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn import preprocessing\nfrom sklearn.metrics import accuracy_score\nimport gc\nimport time\nfrom contextlib import contextmanager","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Helper Functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"@contextmanager\ndef timer(title):\n    t0 = time.time()\n    yield\n    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"def data_preprocessing():\n\n    print(\"Data Preprocessing Process Has Been Started\" \"\\n\")\n\n    train = pd.read_csv(\"../input/titanic/train.csv\")\n    test = pd.read_csv(\"../input/titanic/test.csv\")\n\n    train = train.drop(['Ticket'], axis = 1)\n    test = test.drop(['Ticket'], axis = 1)\n\n    train['Fare'] = train['Fare'].replace(512.3292, 300)\n    test['Fare'] = test['Fare'].replace(512.3292, 300)\n\n    train[\"Age\"] = train[\"Age\"].fillna(train[\"Age\"].median())\n    test[\"Age\"] = test[\"Age\"].fillna(test[\"Age\"].median())\n\n    # Fill NA with the most frequent value:\n    train[\"Embarked\"] = train[\"Embarked\"].fillna(\"S\")\n    test[\"Embarked\"] = test[\"Embarked\"].fillna(\"S\")\n\n    test[\"Fare\"] = test[\"Fare\"].fillna(12)\n\n    train[\"CabinBool\"] = train[\"Cabin\"].notnull().astype('int')\n    test[\"CabinBool\"] = test[\"Cabin\"].notnull().astype('int')\n\n    train = train.drop(['Cabin'], axis = 1)\n    test = test.drop(['Cabin'], axis = 1)\n\n    # Map each Embarked value to a numerical value:\n\n    embarked_mapping = {\"S\": 1, \"C\": 2, \"Q\": 3}\n\n    train['Embarked'] = train['Embarked'].map(embarked_mapping)\n    test['Embarked'] = test['Embarked'].map(embarked_mapping)\n\n\n    lbe = preprocessing.LabelEncoder()\n\n\n    train[\"Sex\"] = lbe.fit_transform(train[\"Sex\"])\n    test[\"Sex\"] = lbe.fit_transform(test[\"Sex\"])\n\n    train[\"Title\"] = train[\"Name\"].str.extract(' ([A-Za-z]+)\\.', expand=False)\n    test[\"Title\"] = test[\"Name\"].str.extract(' ([A-Za-z]+)\\.', expand=False)\n\n    train['Title'] = train['Title'].replace(['Lady', 'Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Jonkheer', 'Dona'], 'Rare')\n    train['Title'] = train['Title'].replace(['Countess', 'Lady', 'Sir'], 'Royal')\n    train['Title'] = train['Title'].replace('Mlle', 'Miss')\n    train['Title'] = train['Title'].replace('Ms', 'Miss')\n    train['Title'] = train['Title'].replace('Mme', 'Mrs')\n\n\n    test['Title'] = test['Title'].replace(['Lady', 'Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Jonkheer', 'Dona'], 'Rare')\n    test['Title'] = test['Title'].replace(['Countess', 'Lady', 'Sir'], 'Royal')\n    test['Title'] = test['Title'].replace('Mlle', 'Miss')\n    test['Title'] = test['Title'].replace('Ms', 'Miss')\n    test['Title'] = test['Title'].replace('Mme', 'Mrs')\n\n    # Map each of the title groups to a numerical value\n\n    title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Royal\": 5, \"Rare\": 5}\n    train['Title'] = train['Title'].map(title_mapping)\n    test['Title'] = test['Title'].map(title_mapping)\n\n    train = train.drop(['Name'], axis = 1)\n    test = test.drop(['Name'], axis = 1)\n\n\n    bins = [0, 5, 12, 18, 24, 35, 60, np.inf]\n\n    mylabels = ['Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Senior']\n\n\n    train['AgeGroup'] = pd.cut(train[\"Age\"], bins, labels = mylabels)\n    test['AgeGroup'] = pd.cut(test[\"Age\"], bins, labels = mylabels)\n\n\n    # Map each Age value to a numerical value:\n    age_mapping = {'Baby': 1, 'Child': 2, 'Teenager': 3, 'Student': 4, 'Young Adult': 5, 'Adult': 6, 'Senior': 7}\n    train['AgeGroup'] = train['AgeGroup'].map(age_mapping)\n    test['AgeGroup'] = test['AgeGroup'].map(age_mapping)\n\n    #dropping the Age feature for now, might change:\n    train = train.drop(['Age'], axis = 1)\n    test = test.drop(['Age'], axis = 1)\n\n    # Map Fare values into groups of numerical values:\n    train['FareBand'] = pd.qcut(train['Fare'], 4, labels = [1, 2, 3, 4])\n    test['FareBand'] = pd.qcut(test['Fare'], 4, labels = [1, 2, 3, 4])\n\n    # Drop Fare values:\n    train = train.drop(['Fare'], axis = 1)\n    test = test.drop(['Fare'], axis = 1)\n\n    print(\"Data Preprocessing Process Has Been Finished\" \"\\n\")\n    \n    return train, test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"def feature_engineering(train, test):\n\n    print(\"Feature Engineering Process Has Been Started\" \"\\n\")\n\n    train[\"FamilySize\"] = train[\"SibSp\"] + train[\"Parch\"] + 1\n    test[\"FamilySize\"] = train[\"SibSp\"] + train[\"Parch\"] + 1\n\n    # Create new feature of family size:\n\n    train['Single'] = train['FamilySize'].map(lambda s: 1 if s == 1 else 0)\n    train['SmallFam'] = train['FamilySize'].map(lambda s: 1 if  s == 2  else 0)\n    train['MedFam'] = train['FamilySize'].map(lambda s: 1 if 3 <= s <= 4 else 0)\n    train['LargeFam'] = train['FamilySize'].map(lambda s: 1 if s >= 5 else 0)\n\n    # Create new feature of family size:\n\n    test['Single'] = test['FamilySize'].map(lambda s: 1 if s == 1 else 0)\n    test['SmallFam'] = test['FamilySize'].map(lambda s: 1 if  s == 2  else 0)\n    test['MedFam'] = test['FamilySize'].map(lambda s: 1 if 3 <= s <= 4 else 0)\n    test['LargeFam'] = test['FamilySize'].map(lambda s: 1 if s >= 5 else 0)\n\n    # Convert Title and Embarked into dummy variables:\n\n    train = pd.get_dummies(train, columns = [\"Title\"], drop_first = True)\n    train = pd.get_dummies(train, columns = [\"Embarked\"], drop_first = True, prefix=\"Em\")\n\n    test = pd.get_dummies(test, columns = [\"Title\"], drop_first = True)\n    test = pd.get_dummies(test, columns = [\"Embarked\"], drop_first = True, prefix=\"Em\")\n\n    # Create categorical values for Pclass:\n    train[\"Pclass\"] = train[\"Pclass\"].astype(\"category\")\n    train = pd.get_dummies(train, columns = [\"Pclass\"],prefix=\"Pc\")\n\n    test[\"Pclass\"] = test[\"Pclass\"].astype(\"category\")\n    test = pd.get_dummies(test, columns = [\"Pclass\"],prefix=\"Pc\")\n\n    print(\"Feature Engineering Process Has Been Finished\" \"\\n\")\n    \n    \n    return train, test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modeling"},{"metadata":{"trusted":true},"cell_type":"code","source":"def modeling(train):\n\n    print(\"Modeling Process Has Been Started:\" \"\\n\")\n\n    X = train.drop(['Survived', 'PassengerId'], axis=1)\n    Y = train[\"Survived\"]\n\n    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.20, random_state = 17)\n\n    from sklearn.ensemble import GradientBoostingClassifier\n\n    gbm = GradientBoostingClassifier()\n\n    gbm_params = {\n            'n_estimators': [200, 500],\n            'subsample': [1.0],\n            'max_depth': [8],\n            'learning_rate': [0.01,0.02],\n            \"min_samples_split\": [10]}\n\n    gbm_cv_model = GridSearchCV(gbm, gbm_params, cv = 10, n_jobs = -1, verbose = 5)\n\n    gbm_cv_model.fit(x_train, y_train)\n\n    print(gbm_cv_model.best_params_ , \"\\n\")\n\n    gbm_tuned = GradientBoostingClassifier(learning_rate = gbm_cv_model.best_params_[\"learning_rate\"], \n                        max_depth = gbm_cv_model.best_params_[\"max_depth\"],\n                        min_samples_split = gbm_cv_model.best_params_[\"min_samples_split\"],\n                        n_estimators = gbm_cv_model.best_params_[\"n_estimators\"],\n                        subsample = gbm_cv_model.best_params_[\"subsample\"])\n\n    gbm_tuned.fit(x_train, y_train)\n\n    y_pred = gbm_tuned.predict(x_test)\n    print(\"Accuracy Score of Your Model:\")\n    print(round(accuracy_score(y_pred, y_test) * 100, 2))\n    \n    return gbm_tuned\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Deployment"},{"metadata":{"trusted":true},"cell_type":"code","source":"def submission(gbm_tuned, test):\n\n    #set ids as PassengerId and predict survival \n    ids = test['PassengerId']\n\n    predictions = gbm_tuned.predict(test.drop('PassengerId', axis=1))\n\n    #set the output as a dataframe and convert to csv file named submission.csv\n    output = pd.DataFrame({ 'PassengerId' : ids, 'Survived': predictions })\n    \n    output.to_csv('/input/titanic/gender_submission.csv', index=False)\n    print(\"Submission file has been created\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Main"},{"metadata":{"trusted":true},"cell_type":"code","source":"def main():\n    \n    with timer(\"Pre processing Time\"):\n        train, test = data_preprocessing()\n    \n    with timer(\"Feature Engineering\"):\n        train, test = feature_engineering(train, test)\n        \n    with timer(\"Modeling\"):\n        gbm_tuned = modeling(train)\n        \n    with timer(\"Submission\"):\n        submission(gbm_tuned, test)    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if __name__ == \"__main__\":\n    with timer(\"Full model run\"):\n        main()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":4}