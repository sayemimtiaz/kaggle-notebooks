{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import libraries what we will use in this notebook","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.animation as animation\n\nimport numpy as np\nimport struct\nimport pandas as pd\nimport argparse\nimport os\nimport random\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\n\nimport torchvision\nimport torchvision.datasets as dset\nimport torchvision.transforms as transforms\nimport torchvision.utils as vutils","metadata":{"_uuid":"74a3bec8-f4bb-4860-a306-0ab4dfecec0c","_cell_guid":"5a5d67dd-355d-488b-ae18-444997026ebf","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-08-11T19:24:49.273008Z","iopub.execute_input":"2021-08-11T19:24:49.273421Z","iopub.status.idle":"2021-08-11T19:24:49.7342Z","shell.execute_reply.started":"2021-08-11T19:24:49.273309Z","shell.execute_reply":"2021-08-11T19:24:49.733342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define global constants","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n# Noise shape for generator\nNOISE_SHAPE = 128\nBATCH_SIZE = 60\n# Image size and number of channels\nH, W, C = (28, 28, 1)\n\n# Its better then a number of images in dataset will be divided by batch size without remainder\n# So, algorithm below will print this numbers\n#for i in range(3, 100):\n#    if 60_000 % i == 0:\n#        print(i)","metadata":{"_uuid":"dbcd8b02-0e5e-40fd-bebb-6b109df46b7a","_cell_guid":"e7b2b974-a9e2-4b5f-a2e4-531c59305b85","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-08-11T19:24:50.779905Z","iopub.execute_input":"2021-08-11T19:24:50.780228Z","iopub.status.idle":"2021-08-11T19:24:50.805559Z","shell.execute_reply.started":"2021-08-11T19:24:50.780196Z","shell.execute_reply":"2021-08-11T19:24:50.804669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Read data from CSV file","metadata":{}},{"cell_type":"markdown","source":"### We will map it into numpy array for better usage","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/mnist-in-csv/mnist_train.csv')\n# Create np array from csv\ndf_as_np = np.asarray(df)\n# Wrap images and labels\nlabels_mnist, data = (\n    df_as_np[:, 0],                      # First row - labels\n    df_as_np[:, 1:].reshape(-1, H, W, C) # Other rows - images\n)","metadata":{"_uuid":"fecb8007-326b-4f27-bc8f-cfd947228ee2","_cell_guid":"313c48c2-ca5c-4ff4-8160-c818bca2439a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-08-11T19:24:51.377171Z","iopub.execute_input":"2021-08-11T19:24:51.377523Z","iopub.status.idle":"2021-08-11T19:24:54.744482Z","shell.execute_reply.started":"2021-08-11T19:24:51.377491Z","shell.execute_reply":"2021-08-11T19:24:54.743564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define image generator","metadata":{}},{"cell_type":"markdown","source":"### Define class for DataLoader in order to create image generator","metadata":{}},{"cell_type":"code","source":"# Define class with super-class Dataset\n# We must implement two methods: getitem__ and __len__, \n#     __getitem__ - gives possibility to apply indexing for the instance of class FashionDataset\n#     __len__ - gives possibility to take size of overall dataset\n# This methods need in order to use DataLoader\nclass FashionDataset(Dataset):\n\n    def __init__(self, data, transform = None, H = 28, W = 28, C = 1):\n        self._images = np.asarray(data, dtype=np.float32).reshape(-1, H, W, C)\n        self._transform = transform\n\n    def __getitem__(self, index):\n        image = self._images[index]\n        if self._transform is not None:\n            image = self._transform(image)\n        return image\n    \n    def __len__(self):\n        return len(self._images)\n\n# Create instaince of data loader in order to load and create batches of data\n# Also we can specify number of workers in loader which can speed up process of \n# preparing data. We leave it as it is, with default value.\n# For more info refer to original docs.\ntrain_set = FashionDataset(\n    data, transform=transforms.Compose(\n        # Transform data into Tensor that has values in a range from -1 to 1\n        [transforms.ToTensor(), transforms.Normalize(128, 128)]\n    ),\n    H=H, W=W, C=C\n)\n# Create data loader\ntrain_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)","metadata":{"_uuid":"b703a1f4-6a26-4677-b056-e479049cf7d4","_cell_guid":"cbd11a5e-cc02-42a6-8ad5-75d68abef635","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-08-11T19:24:54.745989Z","iopub.execute_input":"2021-08-11T19:24:54.746343Z","iopub.status.idle":"2021-08-11T19:24:54.836641Z","shell.execute_reply.started":"2021-08-11T19:24:54.746285Z","shell.execute_reply":"2021-08-11T19:24:54.83575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Test train loader. Print batch of images","metadata":{}},{"cell_type":"code","source":"# Test loader\nbatch_d = next(iter(train_loader))\ngrid = torchvision.utils.make_grid(batch_d, nrow=10)\n\nplt.figure(figsize=(15, 20))\nplt.imshow(np.transpose(grid, (1, 2, 0)).numpy().astype(np.uint8))","metadata":{"_uuid":"ec9e4dfb-9092-4ae0-8358-9ddaaf665ae2","_cell_guid":"88b4cce2-88eb-47aa-8580-73f6aaafd902","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-08-11T19:24:54.838482Z","iopub.execute_input":"2021-08-11T19:24:54.838797Z","iopub.status.idle":"2021-08-11T19:24:55.129601Z","shell.execute_reply.started":"2021-08-11T19:24:54.83877Z","shell.execute_reply":"2021-08-11T19:24:55.128815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define Models","metadata":{}},{"cell_type":"markdown","source":"### Define some utils for layers/models","metadata":{}},{"cell_type":"code","source":"# custom weights initialization called on netG and netD\ndef weights_init(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        nn.init.normal_(m.weight.data, 0.0, 0.02)\n    elif classname.find('BatchNorm') != -1:\n        nn.init.normal_(m.weight.data, 1.0, 0.02)\n        nn.init.constant_(m.bias.data, 0)","metadata":{"_uuid":"5da8ecf6-2a54-4137-b9d0-74eca7aa18da","_cell_guid":"74c10de6-e317-4a0c-a5e7-1d9ce8a73bac","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-08-11T19:24:55.130906Z","iopub.execute_input":"2021-08-11T19:24:55.131257Z","iopub.status.idle":"2021-08-11T19:24:55.137106Z","shell.execute_reply.started":"2021-08-11T19:24:55.131215Z","shell.execute_reply":"2021-08-11T19:24:55.136259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Define Generator model","metadata":{}},{"cell_type":"code","source":"class GeneratorNN(nn.Module):\n\n    def __init__(self):\n        super(GeneratorNN, self).__init__()\n        \n        self._model = nn.Sequential(\n            nn.Linear(NOISE_SHAPE, 256),\n            nn.ReLU(inplace=False),\n\n            nn.Linear(256, 512),\n            nn.BatchNorm1d(512, momentum=0.8, track_running_stats=False),\n            nn.ReLU(inplace=False),\n\n            nn.Linear(512, 1024),\n            nn.BatchNorm1d(1024, momentum=0.8, track_running_stats=False),\n            nn.ReLU(inplace=False),\n            \n            nn.Linear(1024, H * W * C),\n            nn.Tanh()\n        )\n    \n    def forward(self, x):\n        x = self._model(x)\n        x = x.view(-1, C, H, W)\n        return x","metadata":{"_uuid":"d58b4636-f649-43d4-86c5-87a5523997a9","_cell_guid":"97fbb608-64f6-4409-8fa7-7e46c699ddc5","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-08-11T19:24:55.311513Z","iopub.execute_input":"2021-08-11T19:24:55.311801Z","iopub.status.idle":"2021-08-11T19:24:55.320774Z","shell.execute_reply.started":"2021-08-11T19:24:55.311774Z","shell.execute_reply":"2021-08-11T19:24:55.319926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Create instance of generator model and test it with noise","metadata":{}},{"cell_type":"code","source":"# Generator\ngen_nn = GeneratorNN()\ngen_nn.to(device=device)\n# Init weights of the model with certain initialization\ngen_nn.apply(weights_init)\n# Turn on training mode\ngen_nn.train()","metadata":{"_uuid":"f4e902af-de54-4e09-8df4-4118f7c36fd6","_cell_guid":"80379bb0-5d20-443a-b8fe-a665c4f7a4e3","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-08-11T19:24:56.20295Z","iopub.execute_input":"2021-08-11T19:24:56.203302Z","iopub.status.idle":"2021-08-11T19:24:57.910424Z","shell.execute_reply.started":"2021-08-11T19:24:56.203269Z","shell.execute_reply":"2021-08-11T19:24:57.908777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check generator\narr = np.random.randn(BATCH_SIZE, NOISE_SHAPE).astype(np.float32)\nres = gen_nn(torch.tensor(arr).to(device=device))\nprint(res.shape)\nplt.imshow( ((res + 1.0) / 2.0)[0].cpu().detach().numpy().transpose(1, 2, 0)[..., 0])","metadata":{"_uuid":"15386b70-b512-41b0-8bbb-7266bac273d8","_cell_guid":"5f9c5434-8a88-4382-a8ed-91e9c54e8e61","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-08-11T19:24:57.911972Z","iopub.execute_input":"2021-08-11T19:24:57.91235Z","iopub.status.idle":"2021-08-11T19:24:58.304175Z","shell.execute_reply.started":"2021-08-11T19:24:57.912295Z","shell.execute_reply":"2021-08-11T19:24:58.30323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Define Discriminator model","metadata":{}},{"cell_type":"code","source":"class DiscriminatorNN(nn.Module):\n\n    def __init__(self):\n        super(DiscriminatorNN, self).__init__()\n\n        self._net = nn.Sequential(\n            nn.Linear(H * W * C, 1024),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Linear(1024, 512),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Linear(512, 256),\n            nn.LeakyReLU(0.2, inplace=True),\n            \n            nn.Dropout(p=0.75),\n            nn.Linear(256, 128),\n            nn.LeakyReLU(0.2, inplace=True),\n\n            nn.Dropout(p=0.7),\n            nn.Linear(128, 1),\n            nn.Sigmoid(),\n        )\n    \n    def forward(self, x):\n        b = x.shape[0]\n        return self._net(x.view(b, -1))","metadata":{"_uuid":"56571439-efc3-420f-b4c0-ecee8cd31197","_cell_guid":"3c1b3a2f-25f0-465a-a194-02549346103b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-08-11T19:24:58.306044Z","iopub.execute_input":"2021-08-11T19:24:58.306408Z","iopub.status.idle":"2021-08-11T19:24:58.314032Z","shell.execute_reply.started":"2021-08-11T19:24:58.306369Z","shell.execute_reply":"2021-08-11T19:24:58.313047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Create instance of discriminator model and test it with noise","metadata":{}},{"cell_type":"code","source":"# Discriminator\ndisc_nn = DiscriminatorNN()\ndisc_nn.to(device=device)\n# Init weights of the model with certain initialization\ndisc_nn.apply(weights_init)\n# Turn on training mode\ndisc_nn.train()","metadata":{"_uuid":"168fc792-724c-4fc7-8f1a-85dbc2f1db39","_cell_guid":"81913fdd-3a52-4bcc-bedf-3a3ad994af40","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-08-11T19:24:58.315527Z","iopub.execute_input":"2021-08-11T19:24:58.316012Z","iopub.status.idle":"2021-08-11T19:24:58.342982Z","shell.execute_reply.started":"2021-08-11T19:24:58.315975Z","shell.execute_reply":"2021-08-11T19:24:58.341845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check discriminator on noise data\narr = np.random.randn(BATCH_SIZE, C, H, W).astype(np.float32)\nprint(arr.shape)\nres = disc_nn(torch.tensor(arr, device=device))\nres.cpu().detach().numpy()[:5]","metadata":{"_uuid":"ac084dda-b32a-4fce-9ce6-6292df01a5a9","_cell_guid":"c2ccec04-8c92-4cee-8950-7f2502fe1aee","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-08-11T19:24:58.358179Z","iopub.execute_input":"2021-08-11T19:24:58.358564Z","iopub.status.idle":"2021-08-11T19:24:58.378565Z","shell.execute_reply.started":"2021-08-11T19:24:58.358527Z","shell.execute_reply":"2021-08-11T19:24:58.377584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check discriminator on real data from loaded test batch above\nprint(batch_d.shape)\nres = disc_nn(torch.tensor(batch_d, device=device))\nres.cpu().detach().numpy()[:5]","metadata":{"_uuid":"df9410db-8017-43cc-984d-4e4a58b2c66c","_cell_guid":"ead05aff-560a-4458-b528-b714721a1ba8","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-08-11T19:24:59.388875Z","iopub.execute_input":"2021-08-11T19:24:59.389273Z","iopub.status.idle":"2021-08-11T19:24:59.404234Z","shell.execute_reply.started":"2021-08-11T19:24:59.389237Z","shell.execute_reply":"2021-08-11T19:24:59.403478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"markdown","source":"### Define class which control training of GAN. \n### Main method: `fit` function which start training of a GAN","metadata":{}},{"cell_type":"code","source":"class TrainGANController:\n    \n    def __init__(self, disc_nn, gen_nn, batch_size, device = None):\n        self._disc_nn = disc_nn\n        self._gen_nn = gen_nn\n        self._batch_size = batch_size\n\n        self._is_compiled = False\n        self._opt_disc = None\n        self._opt_gen = None\n        self._loss = None\n        self._device = device\n    \n    def compile(\n            self, \n            lr_disc=2e-4, lr_gen=2e-4, \n            beta_params_disc=(0.5, 0.999), beta_params_gen=(0.5, 0.999)):\n        # Init opt\n        self._opt_disc = torch.optim.Adam(\n            self._disc_nn.parameters(), lr=lr_disc, betas=beta_params_disc\n        )\n        self._opt_gen = torch.optim.Adam(\n            self._gen_nn.parameters(), lr=lr_gen, betas=beta_params_gen\n        )\n        # Losses\n        self._loss = nn.BCELoss().to(device=self._device)\n        # Set flag, in order to start train\n        self._is_compiled = True\n    \n    def train_step_disc(self, real_data, real_label=0.9, fake_label=0.0):\n        # Set real label equal to 0.9 in order to use \"Label smoothing\"\n        # Discriminator can produce better gradients, then this technique is used\n        # For more detail—ã about label smoothing you can find in the internet \n        \n        # For easy access\n        device = self._device\n        # Train step for discriminator\n        # Zero grads\n        self._disc_nn.zero_grad()\n        self._opt_disc.zero_grad() # ????\n        # Forward pass for real data\n        label = torch.full((self._batch_size,), real_label, dtype=torch.float, device=device)\n        fake = torch.full((self._batch_size,), fake_label, dtype=torch.float, device=device)\n        # Generate fake stuf\n        noise = torch.randn(self._batch_size, NOISE_SHAPE, device=device)\n        generated_imgs = self._gen_nn(noise)\n        # Forward pass real batch through D\n        errD_real = self._loss(self._disc_nn(real_data).view(-1), label)\n        # Forward pass fake batch through D\n        errD_fake = self._loss(self._disc_nn(generated_imgs.detach()).view(-1), fake)\n        errD = (errD_fake + errD_real) / 2.0\n        errD.backward()\n        self._opt_disc.step()\n        return errD.cpu().detach().numpy()\n\n    def train_step_gen(self, fake_label=1.0):\n        # For easy access\n        device = self._device\n        # Train step for generator\n        # Zero grads\n        self._gen_nn.zero_grad()\n        self._opt_gen.zero_grad()\n        # fake labels are real for generator cost\n        label = torch.full((self._batch_size,), fake_label, dtype=torch.float, device=device)\n        # Since we just updated D, perform another forward pass of all-fake batch through D\n        # Generate batch of latent vectors\n        noise = torch.randn(self._batch_size, NOISE_SHAPE, device=device)\n        # Generate fake image batch with G\n        generated_imgs = self._gen_nn(noise)\n        # Calculate G's loss based on this output\n        errG = self._loss(self._disc_nn(generated_imgs).view(-1), label)\n        # Calculate gradients for G\n        errG.backward()\n        # Update G\n        self._opt_gen.step()\n        return errG.cpu().detach().numpy()\n\n    def fit(self, data_gen, epoch: int, print_it: int = 100):\n        for i_e in range(epoch):\n            for ii_it, single_data in enumerate(data_gen):\n                single_data = single_data.to(device=self._device)\n                # Train discriminator\n                err_d = self.train_step_disc(single_data)\n                # Train generator\n                err_g = self.train_step_gen()\n                if ii_it % print_it == 0:\n                    print(f'epoch: {i_e+1}/{epoch}, it: {ii_it}/{len(data_gen)}'\n                          f'|| Loss G: {err_g}, Loss D: {err_d}'\n                    )","metadata":{"_uuid":"5229d9e3-5b12-48b5-80d9-df1ffadbf411","_cell_guid":"95ad8e1a-eaaf-4721-8db3-edb2c4f717f1","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-08-11T19:25:01.329796Z","iopub.execute_input":"2021-08-11T19:25:01.33021Z","iopub.status.idle":"2021-08-11T19:25:01.346811Z","shell.execute_reply.started":"2021-08-11T19:25:01.330174Z","shell.execute_reply":"2021-08-11T19:25:01.345791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Create instance and compile controller","metadata":{}},{"cell_type":"code","source":"t_gan_c = TrainGANController(disc_nn, gen_nn, BATCH_SIZE, device=device)\nt_gan_c.compile()","metadata":{"_uuid":"3c1a908a-54a5-4e47-a17e-d29a28aec30e","_cell_guid":"468b2c10-26c9-421e-b0c6-d42a821bc411","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-08-11T19:25:01.912104Z","iopub.execute_input":"2021-08-11T19:25:01.912454Z","iopub.status.idle":"2021-08-11T19:25:01.917709Z","shell.execute_reply.started":"2021-08-11T19:25:01.912421Z","shell.execute_reply":"2021-08-11T19:25:01.916679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Start training","metadata":{}},{"cell_type":"code","source":"t_gan_c.fit(train_loader, epoch=10)","metadata":{"_uuid":"b7470eef-7066-4770-ad49-ddb2798ba79e","_cell_guid":"f8f4165c-e5e2-44df-9e86-8dc2f34bf013","execution":{"iopub.status.busy":"2021-08-11T19:25:02.914161Z","iopub.execute_input":"2021-08-11T19:25:02.91452Z","iopub.status.idle":"2021-08-11T19:27:40.566368Z","shell.execute_reply.started":"2021-08-11T19:25:02.914487Z","shell.execute_reply":"2021-08-11T19:27:40.56548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Generate digits with trained model","metadata":{}},{"cell_type":"code","source":"def visualise_sheets_of_images(\n    images, prefix_name, unique_index=0,\n    show_images=False, subplot_size=(10, 10),\n    figsize=(20, 20),use_BGR2RGB=False, use_grey=False):\n    \"\"\"\n    Plot sheets of images. Usually used for generated images from GANs.\n    Parameters\n    ----------\n    images : list or np.ndarray\n        List of images that should be plotted.\n    prefix_name : str\n        Prefix name for file with sheets of images.\n    unique_index : int\n        Unique number for name of file which consist of sheets of images,\n        usually this params used for showing at which epoch this result is.\n    show_images : bool\n        If true, sheets of images will be plotted.\n    subplot_size : tuple\n        Size of raw and columns. For more detail, see plt docs.\n    figsize : tuple\n        Size of figure. For more detail, see plt docs.\n    use_BGR2RGB : bool\n        If true, `images` will be converted into RGB format (if they have BGR format).\n    use_grey : bool\n        If true, `images` will be plotted as black-white images.\n    \n    \"\"\"\n    plt.figure(figsize=figsize)\n    for z in range(min(len(images), subplot_size[0] * subplot_size[1])):\n        plt.subplot(*subplot_size, z + 1)\n        if use_BGR2RGB:\n            plt.imshow(cv2.cvtColor(images[z], cv2.COLOR_BGR2RGB))\n        elif use_grey:\n            plt.imshow(images[z], cmap='gray')\n        else:\n            plt.imshow(images[z])\n        plt.axis('off')\n\n    plt.tight_layout()\n    plt.savefig(f'{prefix_name}_{unique_index}.png')\n    if show_images:\n        plt.show()\n\n    plt.close('all')","metadata":{"execution":{"iopub.status.busy":"2021-08-11T19:27:40.567993Z","iopub.execute_input":"2021-08-11T19:27:40.56836Z","iopub.status.idle":"2021-08-11T19:27:40.578017Z","shell.execute_reply.started":"2021-08-11T19:27:40.568305Z","shell.execute_reply":"2021-08-11T19:27:40.576788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check generator\narr = np.random.randn(BATCH_SIZE, NOISE_SHAPE).astype(np.float32)\nres = gen_nn(torch.tensor(arr).to(device=device))\n# Unnormed images and plot big figure\nres = ((res + 1.0) / 2.0).cpu().detach().numpy().transpose(0, 2, 3, 1)\nvisualise_sheets_of_images(res, \"generated_digits\", show_images=True, use_grey=True)","metadata":{"_uuid":"c8d78da7-349b-4d9f-98bf-b4d98121080c","_cell_guid":"c54edb92-a8fa-466e-b8d1-48de3e59e2bb","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-08-11T19:30:08.260338Z","iopub.execute_input":"2021-08-11T19:30:08.2607Z","iopub.status.idle":"2021-08-11T19:30:11.720478Z","shell.execute_reply.started":"2021-08-11T19:30:08.260669Z","shell.execute_reply":"2021-08-11T19:30:11.719269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TODO: Save model\n# TODO: Download model from this notebook","metadata":{}},{"cell_type":"markdown","source":"# TODO: Add FID metric","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}