{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns #visualization\nimport matplotlib.pyplot as plt #visualization\n%matplotlib inline\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.offline as py\nimport plotly.express as px\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","collapsed":true,"jupyter":{"outputs_hidden":true},"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **<span style=\"color:#7B68EE;\">Flying, I thought I'd never learn that flying. I thought I'd spend my whole life trying. For flying is that ancient art of keeping one foot on the ground.</span>**\n\nFlying - Songwriter: Chris de Burgh","metadata":{}},{"cell_type":"markdown","source":"<h1 style=\"background-color:#DC143C; font-family:'Brush Script MT',cursive;color:white;font-size:200%; text-align:center;border-radius: 50% 20% / 10% 40%\">Activity Recognition system based on Multisensor data fusion (AReM) Data Set</h1>\n\nCitation: F. Palumbo, C. Gallicchio, R. Pucci and A. Micheli, Human activity recognition using multisensor data fusion based on Reservoir Computing, Journal of Ambient Intelligence and Smart Environments, 2016, 8 (2), pp. 87-107.\n\nThis dataset represents a real-life benchmark in the area of Activity Recognition applications.\n\nThe classification tasks consist in predicting the activity performed by the user from time-series generated by a Wireless Sensor Network (WSN), according to the EvAAL competition technical annex.\n\nAbstract: That dataset contains temporal data from a Wireless Sensor Network worn by an actor performing the activities: bending, cycling, lying down, sitting, standing, walking.\n\nAttribute Information:\n\nFor each sequence, data is provided in comma separated value (csv) format.\n\nInput RSS streams are provided in files named datasetID.csv, where ID is the progressive numeric sequence ID for each repetition of the activity performed.\nIn each file, each row corresponds to a time step measurement (in temporal order) and contains the following information:\navg_rss12, var_rss12, avg_rss13, var_rss13, avg_rss23, var_rss23\nwhere avg and var are the mean and variance values over 250 ms of data, respectively.\n\nTarget data is provided as the containing folder name.\n\nFor each activity, we have the following parameters:\n\nFrequency (Hz): 20\n\nClock (millisecond): 250\n\nTotal duration (seconds): 120\n\nI removed those parameters with skiprows =4.\n\nhttps://archive.ics.uci.edu/ml/datasets/Activity+Recognition+system+based+on+Multisensor+data+fusion+(AReM)","metadata":{}},{"cell_type":"code","source":"#Code by Rawwar https://www.kaggle.com/rawwar/eda-pandas-profile-based-conclusions\ndf = pd.read_csv(\"../input/activity-recognition-data/lying/dataset4.csv\",skiprows=4, delimiter=',')\ndf.head()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#AVG and VAR are the mean and variance values over 250 ms of data,","metadata":{}},{"cell_type":"markdown","source":"# **<span style=\"color:#7B68EE;\">Lying, I thought I'd never keep from lying. I thought I'd lose it all by sighing. For lying is that ancient art of hiding words that will never be found.</span>**\n\nFlying - Songwriter: Chris de Burgh","metadata":{}},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Codes by Rishabh Raj Shukla https://www.kaggle.com/rajshukla1102/beginnernotebook/notebook","metadata":{}},{"cell_type":"code","source":"from pandas.plotting import scatter_matrix\nfrom sklearn.decomposition import PCA\nfrom sklearn import linear_model, decomposition\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.plot(subplots=True, sharex=True ,figsize=(20,50))\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.rename(columns={'# Columns: time':'time'})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop('time', axis=1).corrwith(df.time).plot(kind='bar', grid=True, figsize=(12, 8), color=['salmon'],\n                                                   title=\"Correlation with Time\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sc = StandardScaler()\nscale_var = ['avg_rss12', 'var_rss12', 'avg_rss13', 'var_rss13', 'avg_rss23', 'var_rss23']\ndf[scale_var] = sc.fit_transform(df[scale_var])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df.drop('time', axis=1)\ny = df.time\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"allAlgo = [('lr', LogisticRegression()),('knn', KNeighborsClassifier()),('dclf', DecisionTreeClassifier()),\n          ('svm', SVC()),('nb', GaussianNB())]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res = []\nnames = []\nfor name, algo in allAlgo:\n    kfold = KFold(n_splits=10, random_state=None)\n    cv_results = cross_val_score(algo, X_train, y_train, cv=kfold, scoring='accuracy')\n    res.append(cv_results)\n    names.append(name)\n    print(name, cv_results.mean(), cv_results.std())","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def print_score(clf, X_train, y_train, X_test, y_test, train=True):\n    if train:\n        pred = clf.predict(X_train)\n        clf_report = pd.DataFrame(classification_report(y_train, pred, output_dict=True))\n        print(\"Train Result:\\n**********************************************\")\n        print(f\"Accuracy Score: {accuracy_score(y_train, pred) * 100:.2f}%\")\n        print(\"_______________________________________________\")\n        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n        print(\"_______________________________________________\")\n        print(f\"Confusion Matrix: \\n {confusion_matrix(y_train, pred)}\\n\")\n        \n    elif train==False:\n        pred = clf.predict(X_test)\n        clf_report = pd.DataFrame(classification_report(y_test, pred, output_dict=True))\n        print(\"Test Result:\\n************************************************\")        \n        print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n        print(\"_______________________________________________\")\n        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n        print(\"_______________________________________________\")\n        print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred)}\\n\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr = LogisticRegression(solver='saga',penalty='elasticnet',l1_ratio=0.6,max_iter=1000)\nlr.fit(X_train, y_train)\n\nprint_score(lr, X_train, y_train, X_test, y_test, train=True)\nprint_score(lr, X_train, y_train, X_test, y_test, train=False)","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Applying PCA on Logistic Regression","metadata":{}},{"cell_type":"code","source":"#Applying PCA on Logistic Regression\n\npca = PCA(n_components=5) \nX_train_pca = pca.fit_transform(X_train)\nX_test_pca = pca.transform(X_test)\nexpained_variance = pca.explained_variance_ratio_\nclassifier = LogisticRegression(random_state = 1)\nclassifier.fit(X_train_pca, y_train)\nprint_score(classifier, X_train_pca, y_train, X_test_pca, y_test, train=True)\nprint_score(classifier, X_train_pca, y_train, X_test_pca, y_test, train=False)","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Support Vector Machine","metadata":{}},{"cell_type":"code","source":"sv = SVC(kernel='rbf',C=1)\nsv.fit(X_train, y_train)\nprint_score(sv, X_train, y_train, X_test, y_test, train=True)\nprint_score(sv, X_train, y_train, X_test, y_test, train=False)","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors=5)\nknn.fit(X_train, y_train)\nprint_score(knn, X_train, y_train, X_test, y_test, train=True)\nprint_score(knn, X_train, y_train, X_test, y_test, train=False)","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gn = GaussianNB()\ngn.fit(X_train, y_train)\nprint_score(gn, X_train, y_train, X_test, y_test, train=True)\nprint_score(gn, X_train, y_train, X_test, y_test, train=False)","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#DecisionTreeClassifier\n\ndc = DecisionTreeClassifier()\ndc.fit(X_train, y_train)\nprint_score(dc, X_train, y_train, X_test, y_test, train=True)\nprint_score(dc, X_train, y_train, X_test, y_test, train=False)","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code by Olga Belitskaya https://www.kaggle.com/olgabelitskaya/sequential-data/comments\nfrom IPython.display import display,HTML\nc1,c2,f1,f2,fs1,fs2=\\\n'#eb3434','#eb3446','Akronim','Smokum',30,15\ndef dhtml(string,fontcolor=c1,font=f1,fontsize=fs1):\n    display(HTML(\"\"\"<style>\n    @import 'https://fonts.googleapis.com/css?family=\"\"\"\\\n    +font+\"\"\"&effect=3d-float';</style>\n    <h1 class='font-effect-3d-float' style='font-family:\"\"\"+\\\n    font+\"\"\"; color:\"\"\"+fontcolor+\"\"\"; font-size:\"\"\"+\\\n    str(fontsize)+\"\"\"px;'>%s</h1>\"\"\"%string))\n    \n    \ndhtml('Thanks Rishabh Raj Shukla for the script' )","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]}]}