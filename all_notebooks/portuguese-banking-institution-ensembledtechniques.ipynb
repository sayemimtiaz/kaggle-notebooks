{"cells":[{"metadata":{},"cell_type":"markdown","source":"# DATA SET: bank-full.csv "},{"metadata":{},"cell_type":"markdown","source":"Data Description:\n\nThe data is related with direct marketing campaigns of a Portuguese\nbanking institution. The marketing campaigns were based on phone\ncalls. Often, more than one contact to the same client was required, in\norder to access if the product (bank term deposit) would be ('yes') or not\n('no') subscribed.\n\nDomain:Banking\n\nContext:\n\nLeveraging customer information is paramount for most businesses. In\nthe case of a bank, attributes of customers like the ones mentioned\nbelow can be crucial in strategizing a marketing campaign when\nlaunching a new product."},{"metadata":{},"cell_type":"markdown","source":"# 1. Import the necessary libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"# To enable plotting graphs in Jupyter notebook\n%matplotlib inline\n\n# Importing libraries\nimport pandas as pd\nfrom sklearn.linear_model import LogisticRegression\n\n# importing ploting libraries\nimport matplotlib.pyplot as plt   \n\n#importing seaborn for statistical plots\nimport seaborn as sns\n\n#Let us break the X and y dataframes into training set and test set. For this we will use\n#Sklearn package's data splitting function which is based on random function\n\nfrom sklearn.model_selection import train_test_split\n\nimport numpy as np\n#import os,sys\nfrom scipy import stats\n\n# calculate accuracy measures and confusion matrix\nfrom sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Read the data as a data frame "},{"metadata":{"trusted":true},"cell_type":"code","source":"datapath = '../input'\nmy_data = pd.read_csv(datapath+'/bank-full.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Basic EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"my_data.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"a.There are 7 Independent variables:\n\n    1.Age(Numeric)\n    2.Balance: average yearly balance, in euros (numeric)\n    3.Day: last contact day of the month (numeric 1 -31)\n    4.Duration: last contact duration, in seconds (numeric).\n    5.Campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact) \n    6.pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n    7.previous: number of contacts performed before this campaign and for this client (numeric)\n\nb.There are 8 Ordinal Categorical Variables:\n\n    1.Job : type of job \n    2.Marital : marital status \n    3.Education\n    4.Default: has credit in default? (categorical: 'no','yes','unknown')\n    5.Housing: has housing loan? (categorical: 'no','yes','unknown')\n    6.Loan: has personal loan? (categorical: 'no','yes','unknown')\n    7.Contact: contact communication type (categorical:'cellular','telephone')\n    8.poutcome: outcome of the previous marketing campaign(categorical: 'failure','nonexistent','success')\n\nc.And the Target variable is binary category variable(desired target):\n\n    Target:has the client subscribed a term deposit? (binary: 'yes', 'no')\n"},{"metadata":{},"cell_type":"markdown","source":"# 3.a. Shape of the data "},{"metadata":{"trusted":true},"cell_type":"code","source":"my_data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 45211 clients."},{"metadata":{"trusted":true},"cell_type":"code","source":"my_data.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3.b. Data type of each attribute "},{"metadata":{"trusted":true},"cell_type":"code","source":"my_data.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Some Attributes are having object data type and some are having integer data type.\n\n### Decision tree in Python can take only numerical / categorical colums. It cannot take string / obeject types. "},{"metadata":{},"cell_type":"markdown","source":"# 3.c. Checking the presence of missing values "},{"metadata":{"trusted":true},"cell_type":"code","source":"val=my_data.isnull().values.any()\n\nif val==True:\n    print(\"Missing values present : \", my_data.isnull().values.sum())\n    my_data=my_data.dropna()\nelse:\n    print(\"No missing values present\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Check for the null values "},{"metadata":{"trusted":true},"cell_type":"code","source":"#null values\nmy_data.isnull().values.any()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3.d. 5 point summary of numerical attributes "},{"metadata":{"trusted":true},"cell_type":"code","source":"my_data.describe().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Finding unique data "},{"metadata":{"trusted":true},"cell_type":"code","source":"my_data.apply(lambda x: len(x.unique()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Jobs:\\n',my_data['job'].unique())\nprint('Marital:\\n',my_data['marital'].unique())\nprint('Default:\\n',my_data['default'].unique())\nprint('Education:\\n',my_data['education'].unique())\nprint('Housing:\\n',my_data['housing'].unique())\nprint('Loan:\\n',my_data['loan'].unique())\nprint('Contact:\\n',my_data['contact'].unique())\nprint('Month:\\n',my_data['month'].unique())\nprint('Day:\\n',my_data['day'].unique())\nprint('Campaign:\\n',my_data['campaign'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Find Mean\nmy_data.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Find Median\nmy_data.median()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Find Standard Deviation\nmy_data.std()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Measure of skewness  "},{"metadata":{"trusted":true},"cell_type":"code","source":"my_data.skew(axis = 0, skipna = True) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Ploting histogram to check that if data columns are normal or almost normal or not"},{"metadata":{"trusted":true},"cell_type":"code","source":"my_data.hist(figsize=(10,10),color=\"blueviolet\",grid=False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# PairPlot "},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(my_data.iloc[:,1:])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Here we can see that distribution for  'Age','Day','Month' and 'Job' is almost normally distributed."},{"metadata":{},"cell_type":"markdown","source":"# 3.e. Checking the presence of outliers "},{"metadata":{},"cell_type":"markdown","source":"## AGE"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Min age: ', my_data['age'].max())\nprint('Max age: ', my_data['age'].min())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (30,12))\nsns.countplot(x = 'age',  palette=\"rocket\", data = my_data)\nplt.xlabel(\"Age\", fontsize=15)\nplt.ylabel('Count', fontsize=15)\nplt.title('Age Distribution', fontsize=15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x = 'age', data = my_data, orient = 'v')\nplt.ylabel(\"Age\", fontsize=15)\nplt.title('Age Distribution', fontsize=15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(my_data['age'])\nplt.xlabel(\"Age\", fontsize=15)\nplt.ylabel('Occurence', fontsize=15)\nplt.title('Age x Ocucurence', fontsize=15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Calculate the outliers of Age Attribute: "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Quartiles\nprint('1º Quartile: ', my_data['age'].quantile(q = 0.25))\nprint('2º Quartile: ', my_data['age'].quantile(q = 0.50))\nprint('3º Quartile: ', my_data['age'].quantile(q = 0.75))\nprint('4º Quartile: ', my_data['age'].quantile(q = 1.00))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"  # Interquartile range, IQR = Q3 - Q1\n  # lower 1.5*IQR whisker = Q1 - 1.5 * IQR \n  # Upper 1.5*IQR whisker = Q3 + 1.5 * IQR\n    \nprint('Ages above: ', my_data['age'].quantile(q = 0.75) + \n                      1.5*(my_data['age'].quantile(q = 0.75) - my_data['age'].quantile(q = 0.25)), 'are outliers')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Numerber of outliers: ', my_data[my_data['age'] > 70.5]['age'].count())\nprint('Number of clients: ', len(my_data))\n#Outliers in %\nprint('Outliers are:', round(my_data[my_data['age'] > 70.5]['age'].count()*100/len(my_data),2), '%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Just looking at the graphs we cannot conclude if age have a high effect to our Target variable.\n## Here we can see the percentage of the outliers is less, so we can  fit the model with and without them.\n"},{"metadata":{},"cell_type":"markdown","source":"## Job"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (30,12))\nsns.countplot(x = 'job',data = my_data)\nplt.xlabel(\"job\", fontsize=15)\nplt.ylabel('Count', fontsize=15)\nplt.title('Job Distribution', fontsize=20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###  The count of 'Blue-collar' is higher than the other .Also the count for 'Management' is noticeable."},{"metadata":{},"cell_type":"markdown","source":"##  Marital"},{"metadata":{"trusted":true},"cell_type":"code","source":"#plt.figure(figsize = (30,12))\nsns.countplot(x = 'marital',data = my_data)\nplt.xlabel(\"Marital\", fontsize=15)\nplt.ylabel('Count', fontsize=15)\nplt.title('Marital Distribution', fontsize=15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x='marital',y='age',hue='Target',data=my_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Here we can see the Mareied people are more subscribing a term deposit. But here is also 50 percente chances to suscribe by clients as we can see in graphs. "},{"metadata":{},"cell_type":"markdown","source":"## Married people are more ,we can see here clearly. "},{"metadata":{},"cell_type":"markdown","source":"## Education"},{"metadata":{"trusted":true},"cell_type":"code","source":"#plt.figure(figsize = (30,12))\nsns.countplot(x = 'education',data = my_data)\nplt.xlabel(\"Education\", fontsize=15)\nplt.ylabel('Count', fontsize=15)\nplt.title('Education Distribution', fontsize=15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## The clients having secondary education are more .And the clients having unknown eduction are less ."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x='education',y='age',hue='Target',data=my_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## There are outliers present in each education criteria . But the clients having primary education are more who have subscribed a term deposit."},{"metadata":{},"cell_type":"markdown","source":"## Default "},{"metadata":{"trusted":true},"cell_type":"code","source":"#plt.figure(figsize = (30,12))\nsns.countplot(x = 'default',data = my_data)\nplt.xlabel(\"Default\", fontsize=15)\nplt.ylabel('Count', fontsize=15)\nplt.title('Default Distribution', fontsize=15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x='default',y='age',hue='Target',data=my_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Default:\\n No credit in default:'     , my_data[my_data['default'] == 'no']     ['age'].count(),\n              '\\n Yes to credit in default:' , my_data[my_data['default'] == 'yes']    ['age'].count())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## The clients having bydefault credit are less than those who don't have bydefault credit. "},{"metadata":{},"cell_type":"markdown","source":"## Housing"},{"metadata":{"trusted":true},"cell_type":"code","source":"#plt.figure(figsize = (30,12))\nsns.countplot(x = 'housing',data = my_data)\nplt.xlabel(\"Housing\", fontsize=15)\nplt.ylabel('Count', fontsize=15)\nplt.title('Housing Distribution', fontsize=15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Housing:\\n No Housing:'     , my_data[my_data['housing'] == 'no']     ['age'].count(),\n              '\\n Yes Housing:' , my_data[my_data['housing'] == 'yes']    ['age'].count())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## The clients having Housing loan are more by almost 5000 count than the clients who don't have Housing Loan."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x='housing',y='age',hue='Target',data=my_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## The clients who don't have taken housing loan have subscribed a term deposite with more than 50% chances."},{"metadata":{},"cell_type":"markdown","source":"## Loan "},{"metadata":{"trusted":true},"cell_type":"code","source":"#plt.figure(figsize = (30,12))\nsns.countplot(x = 'loan',data = my_data)\nplt.xlabel(\"Loan\", fontsize=15)\nplt.ylabel('Count', fontsize=15)\nplt.title('Loan Distribution', fontsize=15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Loan:\\n No Personal loan:'     , my_data[my_data['loan'] == 'no']     ['age'].count(),\n              '\\n Yes Personal Loan:' , my_data[my_data['loan'] == 'yes']    ['age'].count())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## The clients having Personal loan are less than clients don't have Personal loan.Difference is almost 30000 count "},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x='loan',y='age',hue='Target',data=my_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Contact "},{"metadata":{"trusted":true},"cell_type":"code","source":"#plt.figure(figsize = (30,12))\nsns.countplot(x = 'contact',data = my_data)\nplt.xlabel(\"Contact\", fontsize=15)\nplt.ylabel('Count', fontsize=15)\nplt.title('Contact Distribution', fontsize=15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Contact:\\n Unknown Contact:'     , my_data[my_data['contact'] == 'unknown']     ['age'].count(),\n              '\\n Cellular Contact:'   , my_data[my_data['contact'] == 'cellular']    ['age'].count(),\n              '\\n Telephone Contact:'  , my_data[my_data['contact'] == 'telephone']   ['age'].count())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## The count of a clients who can be contacted by Cellular is high that the others. "},{"metadata":{},"cell_type":"markdown","source":"## Month"},{"metadata":{"trusted":true},"cell_type":"code","source":"#plt.figure(figsize = (30,12))\nsns.countplot(x = 'month',data = my_data)\nplt.xlabel(\"In which Month was a person contacted\", fontsize=15)\nplt.ylabel('Count', fontsize=15)\nplt.title('Monthly Distribution', fontsize=15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## The no. of contacts performed in May month is highest than the other months.But it is not sure as the year is not mentioned in the dataset. "},{"metadata":{},"cell_type":"markdown","source":"## Day "},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x=my_data[\"day\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Most of the contacts are done in between 8th-21st day of the particular month.And Also there is no outlier present. "},{"metadata":{},"cell_type":"markdown","source":"## Duration of a call "},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x=my_data[\"duration\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(my_data['duration'])\nplt.xlabel(\"duration\", fontsize=15)\nplt.ylabel('Count', fontsize=15)\nplt.title('Duration distribution', fontsize=15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Calculate the outliers of Duration of last contact:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Quartiles\nprint('1º Quartile: ', my_data['duration'].quantile(q = 0.25))\nprint('2º Quartile: ', my_data['duration'].quantile(q = 0.50))\nprint('3º Quartile: ', my_data['duration'].quantile(q = 0.75))\nprint('4º Quartile: ', my_data['duration'].quantile(q = 1.00))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"  # Interquartile range, IQR = Q3 - Q1\n  # lower 1.5*IQR whisker = Q1 - 1.5 * IQR \n  # Upper 1.5*IQR whisker = Q3 + 1.5 * IQR\n    \nprint('Duration above: ', my_data['duration'].quantile(q = 0.75) + \n                      1.5*(my_data['duration'].quantile(q = 0.75) - my_data['duration'].quantile(q = 0.25)), 'are outliers')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Numerber of outliers: ', my_data[my_data['duration'] > 643.0]['duration'].count())\nprint('Number of clients: ', len(my_data))\n#Outliers in %\nprint('Outliers are:', round(my_data[my_data['duration'] > 643.0]['duration'].count()*100/len(my_data),2), '%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Just looking at the graphs we cannot conclude if duration have a high effect to our Target variable.\n## Here we can see the percentage of the outliers is less.But count is high means 643 count is not less I think so.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Look, if the call duration is iqual to 0, then is obviously that this person didn't subscribed, \n# THIS LINES NEED TO BE DELETED LATER \nmy_data[(my_data['duration'] == 0)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_data[my_data['duration'] == 0]['duration'].count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##  Campaign"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (30,12))\nsns.countplot(x = 'campaign', data = my_data)\nplt.xlabel(\"Campaign\", fontsize=15)\nplt.ylabel('Count', fontsize=15)\nplt.title('Campaign Distribution', fontsize=15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x = 'campaign', data = my_data, orient = 'v')\nplt.ylabel(\"Campaign\", fontsize=15)\nplt.title('Campaign Distribution', fontsize=15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(my_data['campaign'])\nplt.xlabel(\"Campaign\", fontsize=15)\nplt.ylabel('Count', fontsize=15)\nplt.title('Campaign distribution', fontsize=15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Calculate the outliers for Campaign attribute: "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Quartiles\nprint('1º Quartile: ', my_data['campaign'].quantile(q = 0.25))\nprint('2º Quartile: ', my_data['campaign'].quantile(q = 0.50))\nprint('3º Quartile: ', my_data['campaign'].quantile(q = 0.75))\nprint('4º Quartile: ', my_data['campaign'].quantile(q = 1.00))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"  # Interquartile range, IQR = Q3 - Q1\n  # lower 1.5*IQR whisker = Q1 - 1.5 * IQR \n  # Upper 1.5*IQR whisker = Q3 + 1.5 * IQR\n    \nprint('Campaign above: ', my_data['campaign'].quantile(q = 0.75) + \n                      1.5*(my_data['campaign'].quantile(q = 0.75) - my_data['campaign'].quantile(q = 0.25)), 'are outliers')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Numerber of outliers: ', my_data[my_data['campaign'] > 6.0]['campaign'].count())\nprint('Number of clients: ', len(my_data))\n#Outliers in %\nprint('Outliers are:', round(my_data[my_data['campaign'] > 6.0]['campaign'].count()*100/len(my_data),2), '%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## The percentage of presence of outlier is less as we can see.So we can fit the model with or without this attribute. "},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x='campaign',y='age',hue='Target',data=my_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## pdays"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x = 'pdays', data = my_data, orient = 'v')\nplt.ylabel(\"pdays\", fontsize=15)\nplt.title('pdays Distribution', fontsize=15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Previous "},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x = 'previous', data = my_data, orient = 'v')\nplt.ylabel(\"Previous\", fontsize=15)\nplt.title('Previous', fontsize=15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## poutcome: "},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x = 'poutcome', data = my_data, orient = 'v')\nplt.ylabel(\"Poutcome\", fontsize=15)\nplt.title('Poutcome distribution', fontsize=15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('poutcome:\\n Unknown poutcome:'     , my_data[my_data['poutcome'] == 'unknown']   ['age'].count(),\n              '\\n Failure in  poutcome:'  , my_data[my_data['poutcome'] == 'failure']   ['age'].count(),\n              '\\n Other poutcome:'        , my_data[my_data['poutcome'] == 'other']     ['age'].count(),\n              '\\n Success in poutcome:'   , my_data[my_data['poutcome'] == 'success']   ['age'].count())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## The success of the previous marketing campaign is not noticeable as we can see in graph.But still I am not sure as there are so many unknown options present. "},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x='poutcome',y='age',hue='Target',data=my_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Target column "},{"metadata":{"trusted":true},"cell_type":"code","source":"my_data.boxplot(by = 'Target',  layout=(4,4), figsize=(20, 20))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x = 'Target', data = my_data, orient = 'v')\nplt.ylabel(\"Target\", fontsize=15)\nplt.title('Target distribution', fontsize=15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let us look at the target column which is \"Target\"(yes/no).\nmy_data.groupby([\"Target\"]).count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Calculate the correlation matrix "},{"metadata":{"trusted":true},"cell_type":"code","source":"cor=my_data.corr()\ncor","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Heatmap "},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplots(figsize=(10,8))\nsns.heatmap(cor,annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 11.Conclusion from EDA: "},{"metadata":{},"cell_type":"markdown","source":"### 1.The ages are not that much important and dont make sense relate with other variables will not tell any insight.Just looking at the graphs we cannot conclude if age have a high effect to our Target variable.\n### 2.Here we can see the percentage of the outliers for 'Age' is less, so we can fit the model with and without them.\n### 3.If we consider the Job attribute we can see the count of 'Blue-collar' is higher than the other .Also the count for 'Management' is noticeable.\n### 4.Married people are more ,we can see in graph clearly.\n### 5.The clients having secondary education are more .And the clients having unknown eduction are less .\n### 6.The clients having bydefault credit are less than those who don't have bydefault credit.\n### 7.The clients having Housing loan are more by almost 5000 count than the clients who don't have Housing Loan.\n### 8.The clients having Personal loan are less than clients don't have Personal loan.Difference is almost 30000 count.\n### 9.The count of a clients who can be contacted by Cellular is high that the others.\n### 10.The no. of contacts performed in May month is highest than the other months.But it is not sure as the year is not mentioned in the dataset.\n### 11.Most of the contacts are done in between 8th-21st day of the particular month.And Also there is no outlier present.\n### 12.Just looking at the graphs we cannot conclude if duration have a high effect to our Target variable.Here we can see the percentage of the outliers is less.But count is high means 643 count is not less I think so.\n### 13.The percentage of presence of outlier is less as we can see.So we can fit the model with or without this attribute.\n### 14.The success of the previous marketing campaign is not noticeable as we can see in graph.But still I am not sure as there are so many unknown options present.\n### 15.I think for the Jobs, Marital and Education  the best analisys is just the count of each variable, if we related with the other ones its is not conclusive.\n### 16.The Mareied people are more subscribing a term deposit. But here is also 50 percente chances to suscribe by clients as we can see in graphs.\n### 17.here are outliers present in each education criteria . But the clients having primary education are more who have subscribed a term deposit.\n### 18.The clients who don't have taken housing loan have subscribed a term deposite with more than 50% chances."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Prepare the data to train a model – check if data types areappropriate, get rid of the missing values etc "},{"metadata":{},"cell_type":"markdown","source":"### Converting catagorical attributes to continuous due the feature scaling will be applied later. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Label encoder order in alphabetical\nfrom sklearn.preprocessing import LabelEncoder\nlabelencoder_X = LabelEncoder()\nmy_data['job']      = labelencoder_X.fit_transform(my_data['job']) \nmy_data['marital']  = labelencoder_X.fit_transform(my_data['marital']) \nmy_data['education']= labelencoder_X.fit_transform(my_data['education']) \nmy_data['default']  = labelencoder_X.fit_transform(my_data['default']) \nmy_data['housing']  = labelencoder_X.fit_transform(my_data['housing']) \nmy_data['loan']     = labelencoder_X.fit_transform(my_data['loan']) \n\nmy_data['contact']     = labelencoder_X.fit_transform(my_data['contact']) \nmy_data['month']       = labelencoder_X.fit_transform(my_data['month']) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#function to creat group of ages, this helps because we have 78 differente values here\ndef age(dataframe):\n    dataframe.loc[dataframe['age'] <= 32, 'age'] = 1\n    dataframe.loc[(dataframe['age'] > 32) & (dataframe['age'] <= 47), 'age'] = 2\n    dataframe.loc[(dataframe['age'] > 47) & (dataframe['age'] <= 70), 'age'] = 3\n    dataframe.loc[(dataframe['age'] > 70) & (dataframe['age'] <= 98), 'age'] = 4\n           \n    return dataframe\n\nage(my_data);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(my_data.shape)\nmy_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def duration(data):\n\n    data.loc[data['duration'] <= 102, 'duration'] = 1\n    data.loc[(data['duration'] > 102) & (data['duration'] <= 180)  , 'duration']    = 2\n    data.loc[(data['duration'] > 180) & (data['duration'] <= 319)  , 'duration']   = 3\n    data.loc[(data['duration'] > 319) & (data['duration'] <= 644.5), 'duration'] = 4\n    data.loc[data['duration']  > 644.5, 'duration'] = 5\n\n    return data\nduration(my_data);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_data.loc[(my_data['pdays'] == 999), 'pdays'] = 1\nmy_data.loc[(my_data['pdays'] > 0) & (my_data['pdays'] <= 10), 'pdays'] = 2\nmy_data.loc[(my_data['pdays'] > 10) & (my_data['pdays'] <= 20), 'pdays'] = 3\nmy_data.loc[(my_data['pdays'] > 20) & (my_data['pdays'] != 999), 'pdays'] = 4 \nmy_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_data['poutcome'].replace(['unknown', 'failure','other', 'success'], [1,2,3,4], inplace  = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(my_data.shape)\nmy_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Final_data=my_data\nprint(Final_data.shape)\nFinal_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Train a few standard classification algorithms, note and comment on their performances along different metrics. "},{"metadata":{"trusted":true},"cell_type":"code","source":"Final_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5.A.Applying  the NB model and print the accuracy of NB model. "},{"metadata":{"trusted":true},"cell_type":"code","source":"#from sklearn.preprocessing import Imputer\nfrom sklearn import preprocessing\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = Final_data.values[:,0:15]  ## Features\nY = Final_data.values[:,16]  ## Target.values[:,10]  ## Target","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.30, random_state = 7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = GaussianNB()\nclf.fit(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_pred = clf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NB=accuracy_score(Y_test, Y_pred, normalize = True) #Accuracy of Naive Bayes' Model\nprint('Accuracy_score:',NB)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"print('Confusion_matrix of NB:')\nprint(metrics.confusion_matrix(Y_test,Y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5.B.Applying  the KNN model and print the accuracy of KNN model. "},{"metadata":{"trusted":true},"cell_type":"code","source":"final_data = Final_data[['age', 'job', 'marital', 'education', 'default', 'housing', 'loan',\n                     'contact', 'month', 'day', 'duration', 'campaign', 'pdays', 'previous', 'poutcome']]\nfinal_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc_X = StandardScaler()\nX_train = sc_X.fit_transform(X_train)\nX_test = sc_X.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_std = pd.DataFrame(StandardScaler().fit_transform(final_data))\nX_std.columns = final_data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#split the dataset into training and test datasets\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\n\n# Transform data into features and target\nX = np.array(my_data.iloc[:,1:16]) \ny = np.array(my_data['Target'])\n\n# split into train and test\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape)\nprint(y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# loading library\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import recall_score\n\n#Neighbors\nneighbors = np.arange(0,25)\n\nfor k in neighbors:\n    k_value = k+1\n    knn = KNeighborsClassifier(n_neighbors = k_value)\n    knn.fit(X_train, y_train)\n    y_pred = knn.predict(X_test)\n    print(accuracy_score(y_test, y_pred))\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"myList = list(range(1,30))\n\n# subsetting just the odd ones\nneighbors = list(filter(lambda x: x % 2 != 0, myList))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ac_scores = []\n\n# perform accuracy metrics for values from 1,3,5....19\nfor k in neighbors:\n    knn = KNeighborsClassifier(n_neighbors=k)\n    knn.fit(X_train, y_train)\n    # predict the response\n    y_pred = knn.predict(X_test)\n    # evaluate accuracy\n    scores = accuracy_score(y_test, y_pred)\n    ac_scores.append(scores)\n\n# changing to misclassification error\nMSE = [1 - x for x in ac_scores]\n\n# determining best k\noptimal_k = neighbors[MSE.index(min(MSE))]\nprint(\"The optimal number of neighbors is %d\" % optimal_k)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plot misclassification error vs k (with k value on X-axis) using matplotlib.\nimport matplotlib.pyplot as plt\n# plot misclassification error vs k\nplt.plot(neighbors, MSE)\nplt.xlabel('Number of Neighbors K')\nplt.ylabel('Misclassification Error')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Use k=23 as the final model for prediction\nknn = KNeighborsClassifier(n_neighbors = 23)\n\n# fitting the model\nknn.fit(X_train, y_train)\n\n# predict the response\ny_pred = knn.predict(X_test)\n\n# evaluate accuracy\nKNN=accuracy_score(y_test, y_pred)   #Accuracy of KNN model\nprint('Accuracy_score:',KNN)    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Confusion_matrix:')\nprint(metrics.confusion_matrix(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5.C.Applying Logistic Regression Model and Print accuracy and confusion matrix of Logistic Regression. "},{"metadata":{"trusted":true},"cell_type":"code","source":"array = my_data.values\nX = array[:,0:16] # select all rows and first 16 columns which are the attributes\nY = array[:,16]   # select all rows and the 17th column which is the classification \"yes\", \"no\"\ntest_size = 0.30 # taking 70:30 training and test set\nseed = 15  # Random numbmer seeding for reapeatability of the code\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed) # To set the random state\ntype(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fit the model on 30%\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\ny_predict = model.predict(X_test)\nLR = model.score(X_test, y_test)\nprint('Accuracy:',LR)\nprint('confusion_matrix:')\nprint(metrics.confusion_matrix(y_test, y_predict))\nA=LR  # Accuracy of Logistic regression model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6. Build the ensemble models and compare the results with the base models. "},{"metadata":{},"cell_type":"markdown","source":"# A.Decision Tree"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Decision tree in Python can take only numerical / categorical colums. It cannot take string / obeject types. \n# The following code loops through each column and checks if the column type is object then converts those columns\n# into categorical with each distinct value becoming a category or code.\n\nfor feature in my_data.columns: # Loop through all columns in the dataframe\n    if my_data[feature].dtype == 'object': # Only apply for columns with categorical strings\n        my_data[feature] = pd.Categorical(my_data[feature]).codes # Replace strings with an integer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_char_label = ['No', 'Yes']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.feature_extraction.text import CountVectorizer  #DT does not take strings as input for the model fit step....\n\n# splitting data into training and test set for independent attributes\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, train_labels, test_labels = train_test_split(X, y, test_size=.30, random_state=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# splitting data into training and test set for independent attributes in the ratio of 70:30 \nn=my_data['Target'].count()\ntrain_set = my_data.head(int(round(n*0.7))) # Up to the last initial training set row\ntest_set = my_data.tail(int(round(n*0.3))) # Past the last initial training set row\n\n# capture the target column (\"Target\") into separate vectors for training set and test set\ntrain_labels = train_set.pop(\"Target\")\ntest_labels = test_set.pop(\"Target\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# invoking the decision tree classifier function. Using 'entropy' method of finding the split columns. Other option \n# could be gini index.  Restricting the depth of the tree to 5 (no particular reason for selecting this)\n\n#dt_model = DecisionTreeClassifier(criterion = 'entropy' , max_depth = 5, random_state = 100)\n                                  \ndt_model = DecisionTreeClassifier(criterion = 'entropy' )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dt_model.fit(train_set, train_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Print the accuracy of the model & print the confusion matrix\ndt_model.score(test_set , test_labels)\ntest_pred = dt_model.predict(test_set)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (pd.DataFrame(dt_model.feature_importances_, columns = [\"Imp\"], index = train_set.columns))#Print the feature importance of the decision model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_predict = dt_model.predict(test_set)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(dt_model.score(train_set , train_labels))\nprint(dt_model.score(test_set , test_labels))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(metrics.confusion_matrix(test_labels, y_predict))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# I think the data is overfitted."},{"metadata":{},"cell_type":"markdown","source":"#  Regularising the Decision Tree"},{"metadata":{"trusted":true},"cell_type":"code","source":"reg_dt_model = DecisionTreeClassifier(criterion = 'entropy', max_depth = 7)\nreg_dt_model.fit(train_set, train_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (pd.DataFrame(dt_model.feature_importances_, columns = [\"Imp\"], index = train_set.columns))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_predict = reg_dt_model.predict(test_set)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DTC=reg_dt_model.score(test_set , test_labels)\nprint(DTC)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(metrics.confusion_matrix(test_labels, y_predict))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# B.Apply Bagging Classifier Algorithm and print the accuracy. "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import BaggingClassifier\n\nbgcl = BaggingClassifier(base_estimator=dt_model, n_estimators=50)\n\n#bgcl = BaggingClassifier(n_estimators=50)\nbgcl = bgcl.fit(train_set, train_labels)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_predict = bgcl.predict(test_set)\n\nBGC=bgcl.score(test_set , test_labels)\nprint(BGC)\n\nprint(metrics.confusion_matrix(test_labels, y_predict))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# C. Apply Adaboost Ensemble Algorithm for the same data and print the accuracy. "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\nabcl = AdaBoostClassifier(base_estimator=dt_model, n_estimators=10)\n#abcl = AdaBoostClassifier( n_estimators=50)\nabcl = abcl.fit(train_set, train_labels)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_predict = abcl.predict(test_set)\n\nADE=abcl.score(test_set , test_labels)\nprint(ADE)\n\nprint(metrics.confusion_matrix(test_labels, y_predict))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# D.Apply GradientBoost Classifier Algorithm for the same data and print the accuracy."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\ngbcl = GradientBoostingClassifier(n_estimators = 50)\ngbcl = gbcl.fit(train_set, train_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_predict = gbcl.predict(test_set)\nGBC=gbcl.score(test_set , test_labels)\nprint(GBC)\nprint(metrics.confusion_matrix(test_labels, y_predict))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# E. Apply the Random forest model and print the accuracy of Random forest Model"},{"metadata":{},"cell_type":"markdown","source":"## Note: Random forest can be used only with Decision trees. "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrfcl = RandomForestClassifier(n_estimators = 50)\nrfcl = rfcl.fit(train_set, train_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_predict = rfcl.predict(test_set)\nRFC=rfcl.score(test_set , test_labels)\nprint(RFC)\nprint(metrics.confusion_matrix(test_labels, y_predict))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 7. Compare performances of all the models"},{"metadata":{"trusted":true},"cell_type":"code","source":"models = pd.DataFrame({\n                'Models': [ 'Gausian NB','K-Near Neighbors','Logistic Model', 'Decision Tree Classifier',\n                            'Bagging Classifier ', 'Adaboost Ensemble ','GradientBoost Classifier ', 'Random Forest Classifier'],\n                'Score':  [NB, KNN, LR, DTC, BGC, ADE, GBC, RFC]})\n\nmodels.sort_values(by='Score', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusions : "},{"metadata":{},"cell_type":"markdown","source":"## 1.The classification goal is to predict if the client will subscribe (yes/no) a term deposit (variable y).\n## 2.A bank wants to know whether clients will subscribe a term deposit or not; so that they need information about the correlation between the variables given in the dataset.\n## 3.Here I used 7 classification models to study.\n## 4.From the accuracy scores , it seems like \"Logistic Regression\" algorithm have the highest accuracy and stability.\n## 5.But we can use \"KNN\" also as it has a good accuracy and stability as well than other models."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":4}