{"cells":[{"metadata":{},"cell_type":"markdown","source":"<a id='ToC'></a>\n\n----------\n\n# Table of contents\n\n- [Introduction](#introduction)\n- [Importing libraries and packages](#importing)\n- [Questions](#questions)\n    - [A filtered list of questions (suggestions from various sources)](#filteredList)\n    - [Selected questions](#selectedQuestions)\n      - [One perspective to the question \"What makes an interview bring more audience?\"](#onePerspective)\n- [My Approach](#myApproach)\n   - [Analysis of episode E1 (Abhishek Thakur and Sanyam Bhutani chatting away)](#nlpAnalysisE1)\n     - [Analysing the Sentiment analysis polarity score of the whole episode E1](#e1PolarityScore)\n        - [Analysing the Sentiment analysis polarity score of the host (Sanyam Bhutani) & guest (Abhishek Thakur)](#e1HostGuestPolarityScore)\n     - [Analysing the Sentiment subjectivity score of the whole episode E1](#e1SubjectivityScore)\n        - [Analysing the Sentiment analysis subjectivity score of the host (Sanyam Bhutani) & guest (Abhishek Thakur)](#e1HostGuestSubjectivityScore)       \n     - [Checking accuracies of these scores for episode E1](#e1Accuracies)\n     - [Finally concluding the episode E1](#e1Conclusion)\n- [Overall conclusion](#overallConclusion)\n- [Resources](#resources)"},{"metadata":{},"cell_type":"markdown","source":"<a id='introduction'></a>\n\n----------\n\n## Introduction"},{"metadata":{},"cell_type":"markdown","source":"### Chai Time Data Science Task kernel\n\n![](https://chaitimedatascience.com/content/images/2020/07/ctds-1.png)\n\nThis kernel has been created for the [Chai Time Data Science Task](https://www.kaggle.com/rohanrao/chai-time-data-science), this Kaggle Task has been kindly organised by our very own [Sanyam Bhutani](http://twitter.com/bhutanisanyam1). In short, we are doing story-telling about the video-cum-podcast show [Sanyam Bhutani](http://twitter.com/bhutanisanyam1) runs regularly where he interviews ML and DS professionals from the industry, academia and all walks of life - many of whom are his \"heroes\".\n\n\nThese are the high-level goals of the task:\n\n**Goals:**\n\n- Presentation: How well is the notebook written in terms of code quality, text description, and grammar?\n- Storytelling: Is there a natural flow of the story that connects various points?\n- Visualizations: Are the visualizations appealing, understandable, and aligned with the description?\n- Insights: Are the insights relevant, useful, and actionable?\n- Innovation: How novel and creative are the ideas and approaches?\n\n\n**Datasets:**\n\nThis kernel uses the original [dataset provided by the organisers](https://www.kaggle.com/rohanrao/chai-time-data-science) plus a few more from other participants who have kindly made them public for the task (see under the _Input_ folder of this kernel).\n\n\n**Inspiration:**\n\nI have been through many kernels posted under this task (30+ at the time of the writing) and a few discussion topics before starting this kernel. These have given me an idea of the trends to keep in mind but at the same time helped continue to develop my ideas along the way and present them below. I may include ideas or excerpts from other kernels (I will cite them when I do).\n\n**Utility script**\n\nAmong other `python` libraries, we will also be using the [NLP Profiler utility script](https://www.kaggle.com/neomatrix369/nlp-profiler-class) to analyse the text aspects of the provided datasets in this kernel. An implementation kernel showing how to use this utility script can be found [here](https://www.kaggle.com/neomatrix369/nlp-profiler-simple-dataset)."},{"metadata":{},"cell_type":"markdown","source":"<a href='#ToC'><span class=\"label label-info\" style=\"font-size: 125%\">Back to Table of Contents</span></a>"},{"metadata":{},"cell_type":"markdown","source":"<a id='importing'></a>\n\n---\n\n## Importing libraries and packages"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Installation using pip\n### import NLP Profiler after installing from the GitHub repo (master branch)\n!pip uninstall -qy typing\n!pip install git+https://github.com/neomatrix369/nlp_profiler.git@master\n# or ! pip install nlp_profiler==0.0.3\nimport nlp_profiler.core as NLPProfiler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n### import the utility script (see https://www.kaggle.com/neomatrix369/nlp-profiler-class)\n# from nlp_profiler_class import NLPProfiler ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\n# visualization tools\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly_express as px\nimport plotly.graph_objects as go\n\n# prettify plots\nplt.rcParams['figure.figsize'] = [20.0, 7.0]\n\nsns.set_palette(sns.color_palette(\"muted\"))\nsns.set_style(\"ticks\")\nsns.set(rc={'figure.figsize':(20.0, 20.0)})\nsns.set(style=\"whitegrid\")\nsns.set(font_scale=1.25)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a href='#ToC'><span class=\"label label-info\" style=\"font-size: 125%\">Back to Table of Contents</span></a>"},{"metadata":{},"cell_type":"markdown","source":"<a id='questions'></a>\n\n----------\n\n## Questions"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"<a id='filteredList'></a>\n\n----------\n\n### A filtered list of questions (suggestions from various sources)\n\nThese were a list of questions I gathered by going through various kernels and discussion points (although there were many more I have come across):\n\n- What makes an interview bring more audience?\n- Does the time of the day decide, whether an interview will be popular or not?\n- What pattern is seen in the likes and views of a particular episode?\n\t- So, using the twitter audience sizes would be an interesting feature that you can capture.\n\t- What is CTDS, exactly, categorise it?\n    - Repeated/Favourite Questions? \n\t- Has the question asking trend changed?\n\t- (Bad) Jokes over time (Hint: Marked with \"haha\"-> repetitions of ha might change ðŸ˜‰ )\n- How does the duration relate to reach? Do people avoid listening to over 90 minute long interviews? Do they easily click on interviews <45 min long?\n- CTDS has a huge part of Kaggle Heroes, is the audience more excited (like myself) when there is a Kaggle Hero interview?\n- has COVID-19 affected the interviews? Iâ€™d be curious to know if there was any effect on the audience. (Can you find my birthday via the data? ðŸ° )\n- I broke out 9 mini-series, did that end up annoying people? Annoying=leaving the Chai play button for good.\n- Did the thumbnails affect the listening?\n- As the trends of questions have changed, did it affect the audienceâ€™s interest?\n- How does the theme affect the audience?\n- find the dates when the releases were done Vs when they were recorded, how does the delay affect things. (loss of interest in topic)\n- How did the Chai consume come into the picture?Â \n- and many more..."},{"metadata":{},"cell_type":"markdown","source":"<a id='selectedQuestions'></a>\n\n----------\n\n### Selected questions\n\nFrom the above, I thought these are some of the reasonable ones to look into as they also seemed novel and not many were aiming to answer these.\n\n- What makes an interview bring more audience?\n- What is CTDS, exactly, categorise it?\n- How does the theme affect the audience?\n- CTDS has a huge part of Kaggle Heroes, is the audience more excited (like myself) when there is a Kaggle Hero interview?\n- Repeated/Favourite Questions? \n- Has the question asking trend changed?\n- (Bad) Jokes over time (Hint: Marked with \"haha\"-> repetitions of ha might change ðŸ˜‰ )\n\nAlthough I have selected these questions and I'm aiming to answer them in some form or other, I'm not necessarily going to be able to answer all of them or be able to give justifiable answers to many of them. But this is my narrowed down the list to start a discussion and layout the conjectures and findings.\n\nIf I had to start with one of the selected questions, then \"What makes an interview bring more audience?\" is a good candidate, although there have been some attempts by others to answer this, I'm going to do it a bit different."},{"metadata":{},"cell_type":"markdown","source":"<a href='#ToC'><span class=\"label label-info\" style=\"font-size: 125%\">Back to Table of Contents</span></a>"},{"metadata":{},"cell_type":"markdown","source":"<a id='onePerspective'></a>\n\n----------\n\n### One perspective to the question \"What makes an interview bring more audience?\"\n\n_Before I go about with my actual approach I wanted to share a viewpoint about the same question. In the below table, I'd like to illustrate the high-level factors that I think might help answer this question._\n\n_The factors might have been placed at the same level of abstraction, while in reality they may be subsets of one another or could have been placed at another level. One or more of them could even be impacting viewership marginally._ \n\n_It's also possible we might have missed out factors that impact viewership. Let's classify the missed ones as unknowns and to be on the safe-side using the Pareto Principle and say that 20% of the factors are unknown to us (while we have 80% known factors to hand to work with)._"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"data = {\n    \"viewers\": ['Viewer 1', 'Viewer 2', 'Viewer 3', 'Viewer 4', 'Viewer 5', 'Viewer 6'],\n    \"interest\": ['related','unrelated','exploring','open','focussed','curious',],\n    \"priority\": ['low','medium','high','medium','high','low',],\n    \"time-factor\": ['hardto make time','free','usually free','work-life busy','busy','free',],\n    \"knows-about-the-show\": ['yes, regular','no, firstime','yes','yes','no, firstime','no, firstime',],\n    \"thinks-about-the-show\": ['likes','dislikes','neutral','neutral','neutral','likes',],\n    \"knows-the-host\": ['yes','no','yes','yes','no','no',],\n    \"thinks-about-the-host\": ['likes','dislikes','neutral','neutral','neutral','likes',],\n    \"knows-the-speaker\": ['yes','no','yes','yes','no','no',],\n    \"thinks-about-the-speaker\": ['likes','dislikes','neutral','neutral','neutral','likes',],\n}\npd.DataFrame(data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> *Looking at this above table we can already see how the show, the host and the speakers bring in or drive away audience to themselves, and their work and this is an object view and not to be personalised in anyway. So the show, host and speakers may already have a fan-following which when put together has an impact on all metrics we have been calculating shown via the respective kernels.*\n\n> *I would like to bring forth another point: we don't have the above data (in some form) from the viewers although (maybe) we can conclude some of these from the different stats and metrics we have to hand so far. So this is one thing to look into as well.* \n\n> *Caveat: we would need to work on the above table to make it more sensible and realistic. Please note the above data is fictional in nature and only put together to illustrate my viewpoint and it would be great if we have such information from the viewers (somehow).*\n\n**If we reason we can find that there may be merit to the above table (data) and that they make logical sense. Then we maybe need to arrange/transform our datasets to match or map to these high-level features. Only then we can analyse the past and possibly predict the future (with better accuracy). And do some justice to the given question to hand.**"},{"metadata":{},"cell_type":"markdown","source":"<a href='#ToC'><span class=\"label label-info\" style=\"font-size: 125%\">Back to Table of Contents</span></a>"},{"metadata":{},"cell_type":"markdown","source":"<a id='myApproach'></a>\n\n----------\n\n## My approach\n\nSo now that I have explained my viewpoint in the above section and that I don't have that data, I have to work with what I have and we can see how far we get with it.\n\nGiven I had only the weekend and a day or two on top of that to work on this (even though I have been bookmarking the various resources related to the task for a week). And then going through 30+ kernels and understanding and aiming to meet the goals. Here is what I have done so far, you have already seen these above:\n- Highlight a list of [questions I gathered](#filteredQuestions)\n- Narrow them now to a [smaller list](#selectedQuestions) that seemed *reasonable* for me\n- Share a [perspective on how we can go about answering this one question](#onePerspective)\n\nAnd here is what we will be seeing going forwards:\n- start with one question and [see where it goes](#startQuestion), pick a specific angle and again see where it goes\n- [Apply the NLP Profiler on the transcripts of the episodes](#applyNLPProfiler)\n- [Analysis of episode E1 (Abhishek Thakur and Sanyam Bhutani chatting away)](#nlpAnalysisE1)\n  - [Analysing the Sentiment analysis polarity score of the whole episode E1](#e1PolarityScore)\n    - [Analysing the Sentiment analysis polarity score of the host (Sanyam Bhutani) & guest (Abhishek Thakur)](#e1HostGuestPolarityScore)\n  - [Analysing the Sentiment subjectivity score of the whole episode E1](#e1SubjectivityScore)\n    - [Analysing the Sentiment analysis subjectivity score of the host (Sanyam Bhutani) & guest (Abhishek Thakur)](#e1HostGuestSubjectivityScore)  \n  - [Checking accuracies of these scores for episode E1](#e1Accuracies)\n  - [Finally concluding the episode E1](#e1Conclusion)"},{"metadata":{},"cell_type":"markdown","source":"\n<a id='startQuestion'></a>\n\n----------\n\n### Start working on the question \"What makes an interview bring more audience?\"\n\n\nWe already have a lot of kernels (many of them) that have done EDA-like analysis on the datasets and provided us with various combination and permutations of the various metrics and stats drawn from the datasets provided. A small portion of them has done NLP like analysis and a few have shared some interesting angles as well.\n\nI will try to use high-level NLP concepts to answer this question as opposed using low-level/granular metrics about the text data to conclude. High-level NLP concepts meaning Sentiment analysis, and the likes, while low-level/granular metrics meaning the number of characters, or the number of words or most used words, etc... I'll explain later why I do that and what's the merit."},{"metadata":{},"cell_type":"markdown","source":"<a id='applyNLPProfiler'></a>\n\n----------\n\n\n### Apply the NLP Profiler on the transcripts of the episodes\n\n\nWhy are we doing this, simply because of what we saw in the [One perspective to the question \"What makes an interview bring more audience?\"](#onePerspective), and I will break this down into meaningful pieces as we go along.\n\nThe root idea is to know how the audience feels and thinks about:\n\n- the show in general\n- the specific talk or topic\n- the host\n- the speaker/guest\n- if their (audience's) friends/community are going to watch the show live or the recording\n\nand depending on the above, and how they have made up their minds, they do the following:\n\n- they come back to the show\n- they may be interested in the specific topic\n- they come back to hear the host talk \n  - they come back to hear the host talk about the topic\n- they come back to hear the speaker talk\n  - they come back to hear the speaker talk about the topic\n- bring their friends/community to the show or share the link via social media later on\n\nAnd some of these could be deduced by the [example data table shown in](#onePerspective). And like you, I'm also going to ask but \"Do we have all the data to hand to deduce this information?\" The answer is \"at the moment we may or may not have it\" but we may be able to deduce some of it from the previous show(s).\n\nBut then \"what about the very first show we broadcasted\", what is the answer to that, \"why did we get the number of views/visitors for it as we did?\" - again this is an open discuss (another conjecture point) but I can say these things about the first show:\n\n- our host Sanyam Bhutani had a good number of followers on Social media\n- many of whom he might have also know\n- they trusted him\n- they were interested in it out of curiosity\n- they wanted to learn from him and his show (including the guests)\n- they were happy to take a chance (as they had no previous experience with the above combinations)\n\nBut this would change with every show and probably changed a lot after the first show and thereafter.\n\n\n**For simplicity purpose, I will pick just one episode to analyse and illustrate my points and ideas.**"},{"metadata":{},"cell_type":"markdown","source":"_**<p style=\"font-size:18px\"> The below visual is from the <a href=https://www.kaggle.com/anshuls235/journey-of-ctds-show-through-visuals>Kernel: Journey of CTDS.showâ˜• through Visuals</a> by <a href=https://www.kaggle.com/anshuls235>Anshul Sharma</a>.</p>**_"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/chai-time-data-science/Episodes.csv')\ndf_yt = pd.read_csv('/kaggle/input/chai-time-data-science/YouTube Thumbnail Types.csv')\ndf_yt = pd.merge(df,df_yt,on='youtube_thumbnail_type')\ncolors = {0:'#FDE803',1:'#0080B7',2:'#FF3D09',3:'#7CBB15'}\ndf_yt['color'] = df_yt.youtube_thumbnail_type.map(colors)\ndf_yt['ep_no'] = df_yt.episode_id.apply(lambda x: int(x[1:]) if x[0]=='E' else 75+int(x[1:]))\ndf_yt.sort_values('ep_no',inplace=True)\ndf_yt['heroes'] = df_yt['heroes'].fillna('NaN')\ndf_yt['episode'] = df_yt.apply(lambda x: x['episode_id'] + ' | ' + x['heroes'] \n                               if x['heroes']!='NaN' else x['episode_id'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"PLOT_BGCOLOR='#DADEE3'\nPAPER_BGCOLOR='rgb(255,255,255)'\n\ny_avg = df_yt.youtube_impressions.mean()\ny_med = df_yt.youtube_impressions.median()\nfig = go.Figure()\nfig.add_trace(go.Bar(name='Impressions',x=df_yt.episode_id,y=df_yt.youtube_impressions,\n                     marker_line_width=1,marker_color='rgb(255,255,255)',marker_line_color='black',\n                    text=df_yt['episode'],showlegend=False))\nfig.add_trace(go.Scatter(name='Mean Impressions',x=df_yt.episode_id,\n                         y=[y_avg]*len(df_yt),mode='lines',marker_color='black',\n                        line = dict(dash='dash')))\nfig.add_trace(go.Scatter(name='Median Impressions',x=df_yt.episode_id,\n                         y=[y_med]*len(df_yt),mode='lines',marker_color='black',\n                        line = dict(dash='dot')))\n# Add image\nfig.add_layout_image(\n    dict(\n        source='https://cdn.icon-icons.com/icons2/1584/PNG/512/3721679-youtube_108064.png',\n        xref=\"paper\", yref=\"paper\",\n        x=1, y=1,\n        sizex=0.2, sizey=0.2,\n        xanchor=\"right\", yanchor=\"bottom\"\n    )\n)\nfig.update_layout(title='<b>Youtube Impressions</b> per Episode',\n                width=700,height=300, barmode='stack',\n                paper_bgcolor=PAPER_BGCOLOR,plot_bgcolor=PLOT_BGCOLOR,hovermode='x unified',\n                margin=dict(t=40,b=0,l=0,r=0),legend=dict(x=0.5,y=1,orientation='h',bgcolor=PLOT_BGCOLOR),\n                xaxis=dict(mirror=True,linewidth=2,linecolor='black',\n                showgrid=False,tickfont=dict(size=8)),\n                yaxis=dict(mirror=True,linewidth=2,linecolor='black',gridcolor='darkgray'))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- `Episode 27` with fast.ai founder **Jeremy Howard** as the guest has recorded the highest number of impressions followed by `Episode 1` featuring the world's first 4x kaggle grandmaster **Abhishek Thakur**. Rest all the episodes have recorded less than 20k impressions. \n- I will also add **Parul Pandey**, **Julien Chaumond**, **Rohan Rao**, **Goku Mohandas**, among many others who are bracing through the mean/median barrier, as they bring their brightness with them to the show\n\n_**<p style=\"font-size:16px\">(above narration (with some modifications from myself) is also from <a href=https://www.kaggle.com/anshuls235/journey-of-ctds-show-through-visuals>Kernel: Journey of CTDS.showâ˜• through Visuals</a> by <a href=https://www.kaggle.com/anshuls235>Anshul Sharma</a>) - Thank you Anshul for this amazing work.)</p>**_\n\n_**I have shown this to illustrate that the top audience attractors have also been guests or speakers with a background known and liked by many (a good fan-following) and many (if not all) of the points mentioned in [Apply the NLP Profiler on the transcripts of the episodes](#applyNLPProfiler) and [One perspective to the question \"What makes an interview bring more audience?\"](#onePerspective) could quite strongly apply to these individuals. And hence validate the factors to a good extent.**_\n\n_**<p style=\"font-size:16px\">If necessary we could find this out from analysing their social media stats, as a few other kernels have already done.</p>**_"},{"metadata":{},"cell_type":"markdown","source":"<a href='#myApproach'><span class=\"label label-info\" style=\"font-size: 125%\">Back to My Approach</span></a> <a href='#ToC'><span class=\"label label-info\" style=\"font-size: 125%\">Back to Table of Contents</span></a>"},{"metadata":{},"cell_type":"markdown","source":"<a id='nlpAnalysisE1'></a>\n\n----------\n\n\n### Analysis of episode E1 (Abhishek Thakur and Sanyam Bhutani chatting away)"},{"metadata":{},"cell_type":"markdown","source":"<i><b><p style=\"font-size:16px\">Thanks to <a href=https://kaggle.com/crazydiv>@crazydiv</a> for providing the `ctds-subtitles-exploration/subtitles_aggregated.csv` dataset to the community.</p></b></i>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"aggregated_subtitles = pd.read_csv('/kaggle/input/ctds-subtitles-exploration/subtitles_aggregated.csv')\naggregated_subtitles_sorted = aggregated_subtitles.sort_values(by=['episode_id', 'relative_index']).reset_index(drop=True)\nepisode_filter = aggregated_subtitles_sorted['episode_id'] == 'E1'\nfirst_episode = aggregated_subtitles_sorted[episode_filter].copy()\nprint(\"first_episode.shape:\", first_episode.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"%%time\nfirst_episode_nlp_profiled = NLPProfiler.apply_text_profiling(first_episode, 'Text', \n                                                                 params={'high_level': True, 'granular': False, \n                                                                         'spelling_check': True, 'grammar_check': True})\nprint(\"first_episode_nlp_profiled.shape:\", first_episode_nlp_profiled.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"first_episode_nlp_profiled = pd.concat([first_episode['timestamp_relative'], first_episode['Speaker'], first_episode_nlp_profiled], axis=1)\nfirst_episode_nlp_profiled","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"first_episode_nlp_profiled.to_csv('first_episode_nlp_profiled.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Note: the scores above have been converted into words using this idea called \"Words of Estimative Probability\" mentioned on [Wikipedia](https://en.wikipedia.org/wiki/Words_of_estimative_probability). You can also find the implementation in the [NLP Profiler Library](https://github.com/neomatrix369/nlp_profiler/) | [on PyPi](https://pypi.org/project/nlp-profiler/).**"},{"metadata":{},"cell_type":"markdown","source":"<a href='#myApproach'><span class=\"label label-info\" style=\"font-size: 125%\">Back to My Approach</span></a> <a href='#ToC'><span class=\"label label-info\" style=\"font-size: 125%\">Back to Table of Contents</span></a>"},{"metadata":{},"cell_type":"markdown","source":"<a id='e1PolarityScore'></a>\n\n----------\n\n### Analysing the Sentiment analysis polarity score of the whole episode E1\n\nMeaning what was the sentiment (positive, neutral, negative and all the scales in between) during the course of the show - start to finish. How did these conversations may have seemed to the audience based on what the host (Sanyam Bhutani) and guest (Abhishek Thakur) said or discussed?\n\nAnd this can also impact the interest and learning for the audience/viewers - as this is working on a slightly subtle level if we think about it."},{"metadata":{},"cell_type":"markdown","source":"_**<p style=\"font-size:18px\"> The below visualisation is from the \"code snippet\" provided in the <a href=https://www.kaggle.com/thedatabeast/making-perfect-chai-and-other-tales>Making perfect \"Chai\" and other tales :)</a> by <a href=https://www.kaggle.com/thedatabeast>Ramshankar Yadhunath</a>. I have made it generic and re-used it more than once in this kernel. Thanks for providing such crisp and inspiring visualisations.</p>**_"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def add_enhancements_to_chart(fig, plt_title, xaxis_title, yaxis_title, start_range, end_range, mean_val):\n    fig.update_layout(\n        hoverlabel=dict(bgcolor=\"white\", font_size=12, font_family=\"Rockwell\"),\n        xaxis_title = xaxis_title, yaxis_title = yaxis_title\n    )\n    \n    fig.add_shape(\n        # add a horizontal line\n        type=\"line\",\n        x0=start_range,\n        y0=mean_val,\n        x1=end_range,\n        y1=mean_val,\n        line=dict(color=\"black\", width=2, dash=\"dash\"),\n    )\n\n    # template enhancement\n    fig.update_layout(\n        template=\"ggplot2\",\n        title={\n            \"text\": plt_title,\n            \"font\": {\"family\": \"Rockwell\", \"size\": 20},\n            \"xanchor\": \"center\",\n            \"yanchor\": \"top\",\n        },\n        xaxis=dict(range=[start_range, end_range]),\n    )\n    return fig\n\ndef timeline_plot(df, feature, \n                  independent_feature=\"timestamp_relative\", \n                  xaxis_title='Timeline', \n                  yaxis_title='', \n                  hover_data=[], \n                  title=\"You forgot the title\"):\n    \"\"\"\n    Credits: original function can be found in Ramshankar Yadhunath's CTDS Show winning kernel: \n             https://www.kaggle.com/thedatabeast/making-perfect-chai-and-other-tales#notebook-container. \n             I have adapted the function and made it generic for repurposing it in this kernel.\n    \n    Plots an interactive line plot depicting the values of each episode\n    across a particular `feature` in the data\n    -----\n    \n    df: The dataframe\n    feature: The feature name from the relevant dataset\n    independent_feature: The independent feature across which the values were shown\n         `timestamp_relative` was the default\n    xaxis_title: title appearing on the x-axis, in the absence the default is 'Timeline'\n    yaxis_title: title appearing on the y-axis\n    hover_data: values of list of fields that appears when you hover over the timeline\n    title: Title of the plot\n    \"\"\"\n    \n    # find the mean value\n    min_val = round(df[feature].min(), 2)\n    max_val = round(df[feature].max(), 2)\n    mean_val = round(df[feature].mean(), 2)\n    margin = 25\n    start_range = str(df[independent_feature].min() - margin)\n    end_range =  str(df[independent_feature].max() + margin)\n\n    \n    # set the plot title\n    plt_title = f'{title} (Min={min_val}, Max={max_val}, Mean={mean_val})'\n\n    # plot the graph\n    fig = px.line(df, x=independent_feature, y=feature, hover_data=hover_data)\n    fig.update_traces(mode=\"lines+markers\", line_color=\"#e87d23\")\n    \n    fig = add_enhancements_to_chart(fig, plt_title, xaxis_title, yaxis_title, start_range, end_range, mean_val)\n    \n    # show plot\n    fig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"timeline_plot(first_episode_nlp_profiled, \n              'sentiment_polarity_score', \n              xaxis_title=\"Episode E1: Timeline\",\n              yaxis_title=\"Sentiment polarity score\",\n              hover_data=[\"sentiment_polarity\", \"sentiment_polarity_score\"],\n              title='Sentiment polarity: Episode E1')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Analysing the Sentiment analysis polarity of the whole episode E1 (in words)\n\nAs we all are not very number-friendly or mathematical, and a fractional/decimal number between `-1` and `1` or `0` and `1` and could mean nothing more than digits, converting them to human-readable and meaningful names help understand the context of those numbers better."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"chart = sns.catplot(x=\"sentiment_polarity\", data=first_episode_nlp_profiled, size=8, kind=\"count\")\nchart.despine(left=True)\nchart.set_ylabels(\"Sentiment polarity moments\", fontsize=16)\nchart.set_xlabels(\"Sentiment polarity (in words)\", fontsize=16)\nchart.fig.suptitle(' Positive, Neutral and Negative graphs with the scales in between')\nchart.set_xticklabels(rotation=30)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If we combine the scales for each of the three polarities i.e. positive, negative and neutral together we can see the below chart:"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"chart = sns.catplot(x=\"sentiment_polarity_summarised\", data=first_episode_nlp_profiled, size=8, kind=\"count\")\nchart.despine(left=True)\nchart.set_ylabels(\"Sentiment polarity moments\", fontsize=16)\nchart.set_xlabels(\"Sentiment polarity (in words)\", fontsize=16)\nchart.fig.suptitle('Positive, Neutral and Negative graphs (compact view)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"_**<p style=\"font-size:14px\">If you see from the above chart (positive: ~120 moments, neutral: ~70 moments and negative: ~30 moments), they have been negative with the discussions only ~13% of the time, while the rest of the ~87% the conversation was between Neutral to Positive sentiments.</p>**_"},{"metadata":{},"cell_type":"markdown","source":"<a href='#myApproach'><span class=\"label label-info\" style=\"font-size: 125%\">Back to My Approach</span></a> <a href='#ToC'><span class=\"label label-info\" style=\"font-size: 125%\">Back to Table of Contents</span></a>"},{"metadata":{},"cell_type":"markdown","source":"### Preparing Name filters for the Host and Speaker/Guest"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"abhishek_filter = first_episode_nlp_profiled['Speaker'] == 'Abhishek Thakur'\nsanyam_filter = first_episode_nlp_profiled['Speaker'] == 'Sanyam Bhutani'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='e1HostGuestPolarityScore'></a>\n\n----------\n\n### Analysing the Sentiment analysis polarity score of the host (Sanyam Bhutani) & guest (Abhishek Thakur)"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def speakers_timeline_plot(df1, df2, feature, \n                  independent_feature=\"timestamp_relative\", \n                  xaxis_title='Timeline', \n                  yaxis_title='', \n                  hover_data=[], \n                  title=\"You forgot the title\"):\n    \"\"\"\n    Credits: original function can be found in Ramshankar Yadhunath's CTDS Show winning kernel: \n             https://www.kaggle.com/thedatabeast/making-perfect-chai-and-other-tales#notebook-container. \n             I have adapted the function and made it generic for repurposing it in this kernel.\n    \n    Plots an interactive line plot depicting the values of each episode\n    across a particular `feature` in the data\n    -----\n    \n    df1, df2: The two dataframes containing the distinct information about the two speakers\n    feature: The feature name from the relevant dataset\n    independent_feature: The independent feature across which the values were shown\n         `timestamp_relative` was the default\n    xaxis_title: title appearing on the x-axis, in the absence the default is 'Timeline'\n    yaxis_title: title appearing on the y-axis\n    hover_data: values of list of fields that appears when you hover over the timeline\n    title: Title of the plot\n    \"\"\"\n    \n    margin = 25\n    combined_df = pd.concat([df1, df2], axis=0)\n    mean_val = round(combined_df[feature].mean(), 2)\n    start_range = str(combined_df[independent_feature].min() - margin)\n    end_range =  str(combined_df[independent_feature].max() + margin)\n    \n    # set the plot title\n    plt_title = f'{title} Mean: {mean_val}'\n    hovertemplate = xaxis_title + ': %{x} <br>' + yaxis_title + ': %{y}'\n\n    # plot the graph\n    fig = go.Figure()\n    fig.add_trace(go.Scatter(x=df1[independent_feature], y=df1[feature], \n                             mode=\"lines\", name=df1['Speaker'].values[0], \n                             hovertemplate=hovertemplate, line_color=\"#e87d23\"))\n\n    fig.add_trace(go.Scatter(x=df2[independent_feature], y=df2[feature], \n                             mode=\"lines\", name=df2['Speaker'].values[0], \n                             hovertemplate=hovertemplate, line_color=\"brown\"))\n    fig.update_traces(mode=\"lines+markers\")\n    \n    fig = add_enhancements_to_chart(fig, plt_title, xaxis_title, yaxis_title, start_range, end_range, mean_val)\n\n    \n    # show plot\n    fig.show()\n","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"speakers_timeline_plot(first_episode_nlp_profiled[sanyam_filter], \n                      first_episode_nlp_profiled[abhishek_filter],\n                      'sentiment_polarity_score',\n                      xaxis_title=\"Episode E1: Timeline\",\n                      yaxis_title=\"Sentiment polarity score\",\n                      hover_data=[\"sentiment_polarity\", \"sentiment_polarity_score\"],\n                      title='Sentiment polarity: Episode E1 (Host v/s Guest)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"_**<p style=\"font-size:14px\">From the above we can see there is nearly a good blend in sentiments, although a number of times they have gone opposite in direction with regards to the sentiment, when they have been talking about subject matters.</p>**_"},{"metadata":{},"cell_type":"markdown","source":"<a href='#myApproach'><span class=\"label label-info\" style=\"font-size: 125%\">Back to My Approach</span></a> <a href='#ToC'><span class=\"label label-info\" style=\"font-size: 125%\">Back to Table of Contents</span></a>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"chart = sns.catplot(y=\"sentiment_polarity\", hue=\"Speaker\", data=first_episode_nlp_profiled, size=8, kind=\"count\")\nchart.despine(left=True)\nchart.set_ylabels(\"Sentiment polarity moments\", fontsize=16)\nchart.set_xlabels(\"Sentiment polarity (in words)\", fontsize=16)\nchart.fig.suptitle('Host: Sanyam Bhutani & Guest: Abhishek Thakur')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Analysing the Sentiment analysis polarity of the host (Sanyam Bhutani) & guest (Abhishek Thakur) [in words]"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"chart = sns.catplot(y=\"sentiment_polarity_summarised\", hue=\"Speaker\", data=first_episode_nlp_profiled, size=8, kind=\"count\")\nchart.despine(left=True)\nchart.set_ylabels(\"Sentiment polarity moments\", fontsize=16)\nchart.set_xlabels(\"Sentiment polarity (in words)\", fontsize=16)\nchart.fig.suptitle('Host: Sanyam Bhutani & Guest: Abhishek Thakur (compact)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"_**<p style=\"font-size:14px\">Host (Sanyam Bhutani): If you see from the above chart (positive: ~61 moments, neutral: ~40 moments and negative: ~9 moments), the host has been negative with the discussions only ~8% of the time, while the rest of the ~92% the conversation was between Neutral to Positive sentiments.</p>**_\n\n_**<p style=\"font-size:14px\">Guest (Abhishek Thakur): If you see from the above chart (positive: ~59 moments, neutral: ~31 moments and negative: ~19 moments), the host has been negative with the discussions only ~17% of the time, while the rest of the ~83% the conversation was between Neutral to Positive sentiments.</p>**_"},{"metadata":{},"cell_type":"markdown","source":"<a href='#myApproach'><span class=\"label label-info\" style=\"font-size: 125%\">Back to My Approach</span></a> <a href='#ToC'><span class=\"label label-info\" style=\"font-size: 125%\">Back to Table of Contents</span></a>"},{"metadata":{},"cell_type":"markdown","source":"<a id='e1SubjectivityScore'></a>\n\n----------\n\n### Analysing the Sentiment subjectivity score of the whole episode E1\n\nWhat we mean here is how subjective or objective were the conversations between the host and the guest. And this can also impact the interest and learning for the audience/viewers - again this is working on a slightly subtle level than we think."},{"metadata":{},"cell_type":"markdown","source":"- [Meaning of Subjectivity](https://www.merriam-webster.com/dictionary/subjectivity)\n\n> Definition of subjectivity\n: the quality, state, or nature of being subjective\n\n> Any attempt to link landscapes and music together can suffer from some measure of subjectivity.\nâ€” David J. Keeling\n\n> He thinks that scientists and philosophers have unjustly neglected the subjectivity of conscious experience and that this has made it harder for them to explain some of the workings of the mind.\nâ€” Anthony Gottlieb\n\n- [Meaning of Objectivity](https://www.merriam-webster.com/dictionary/objectivity)\n\n> Definition of objectivity\n: the quality or character of being objective : lack of favoritism toward one side or another : freedom from bias\n\n> Many people questioned the selection committee's objectivity.\nIt can be difficult for parents to maintain objectivity about their children's accomplishments.\nMany critics disputed the objectivity and reliability of his field observations, foreshadowing current anthropological concerns about the ability of any fieldworker to rise above personal preconceptions and impartially describe another culture.\nâ€” Bruce Bower\n\n> In journalistic circles, there was a good deal of hand-wringing that the bonds forged between reporters and soldiers could threaten objectivity.\nâ€” Mark Jurkowitz"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"timeline_plot(first_episode_nlp_profiled, \n              'sentiment_subjectivity_score', \n              xaxis_title=\"Episode E1: Timeline\",\n              yaxis_title=\"Sentiment subjectivity score\",\n              hover_data=['sentiment_subjectivity', 'sentiment_subjectivity_score'],\n              title=\"Sentiment subjectivity: Episode E1\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"_**<p style=\"font-size:14px\">Observing the above rise and fall in the subjectivity/objectivity scales, it appears and we can say with some degree of confidence that the conversations have been of a balanced nature keeping everyone entertained, engaged and maintaining a good degree of harmony. Let's see further if this is true when we analyse them from higher-perspectives.</p>**_"},{"metadata":{},"cell_type":"markdown","source":"<a href='#myApproach'><span class=\"label label-info\" style=\"font-size: 125%\">Back to My Approach</span></a> <a href='#ToC'><span class=\"label label-info\" style=\"font-size: 125%\">Back to Table of Contents</span></a>"},{"metadata":{},"cell_type":"markdown","source":"### Analysing the Sentiment subjectivity of the whole episode E1 (in words)"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"chart = sns.catplot(x=\"sentiment_subjectivity\", data=first_episode_nlp_profiled, size=10, kind=\"count\")\nchart.despine(left=True)\nchart.set_ylabels(\"Sentiment subjectivity moments\", fontsize=16)\nchart.set_xlabels(\"Sentiment subjectivity (in words)\", fontsize=16)\nchart.fig.suptitle('Subjectivity, Subjectivity/Objectivity and Objectivity with scales in between')\nchart.set_xticklabels(rotation=30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"chart = sns.catplot(x=\"sentiment_subjectivity_summarised\", data=first_episode_nlp_profiled, size=8, kind=\"count\")\nchart.despine(left=True)\nchart.set_ylabels(\"Sentiment subjectivity moments\", fontsize=16)\nchart.set_xlabels(\"Sentiment subjectivity (in words)\", fontsize=16)\nchart.fig.suptitle('Subjectivity, Subjectivity/Objectivity and Objectivity (compact view)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"_**<p style=\"font-size:14px\">If you see from the above chart (subjective: ~45 moments, objective/subjective: ~85 moments, objective: ~90 moments) the two have been less Subjective with the discussions, and more Objective. While they also had moments where both had a more balanced stance with Subjective/Objectivity in the things they said. (My guess: being a technical topic, we may be seeing the dominance of Objectivity or Subjective/Objectivity over just Subjective). But this could also be a reflection on the personalities of the two individuals involved.</p>**_ "},{"metadata":{},"cell_type":"markdown","source":"<a href='#myApproach'><span class=\"label label-info\" style=\"font-size: 125%\">Back to My Approach</span></a> <a href='#ToC'><span class=\"label label-info\" style=\"font-size: 125%\">Back to Table of Contents</span></a>"},{"metadata":{},"cell_type":"markdown","source":"<a id='e1HostGuestSubjectivityScore'></a>\n\n----------\n\n### Analysing the Sentiment subjectivity score of the host (Sanyam Bhutani) & guest (Abhishek Thakur)"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"speakers_timeline_plot(first_episode_nlp_profiled[sanyam_filter], \n                      first_episode_nlp_profiled[abhishek_filter],\n                      'sentiment_subjectivity_score',\n                      xaxis_title=\"Episode E1: Timeline\",\n                      yaxis_title=\"Sentiment subjectivity score\",\n                      hover_data=[\"sentiment_subjectivity\", \"sentiment_subjectivity_score\"],\n                      title='Sentiment subjectivity: Episode E1 (Host v/s Guest)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"_**<p style=\"font-size:14px\">Same goes for this observation, we can see again there is nearly a good blend in subjectivity/objectivity in their conversations, but again a number of times they have gone opposite in direction with regards to this metric, when they have been talking about subject matters.</p>**_"},{"metadata":{},"cell_type":"markdown","source":"<a href='#myApproach'><span class=\"label label-info\" style=\"font-size: 125%\">Back to My Approach</span></a> <a href='#ToC'><span class=\"label label-info\" style=\"font-size: 125%\">Back to Table of Contents</span></a>"},{"metadata":{},"cell_type":"markdown","source":"### Analysing the Sentiment subjectivity of the host (Sanyam Bhutani) & guest (Abhishek Thakur) [in words]"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"chart = sns.catplot(y=\"sentiment_subjectivity\", hue=\"Speaker\", data=first_episode_nlp_profiled, size=10, kind=\"count\")\nchart.despine(left=True)\nchart.set_ylabels(\"Sentiment subjectivity moments\", fontsize=16)\nchart.set_xlabels(\"Sentiment subjectivity (in words)\", fontsize=16)\nchart.fig.suptitle('Host: Sanyam Bhutani & Guest: Abhishek Thakur')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"chart = sns.catplot(y=\"sentiment_subjectivity_summarised\", hue=\"Speaker\", data=first_episode_nlp_profiled, size=8, kind=\"count\")\nchart.despine(left=True)\nchart.set_ylabels(\"Sentiment subjectivity moments\", fontsize=16)\nchart.set_xlabels(\"Sentiment subjectivity (in words)\", fontsize=16)\nchart.fig.suptitle('Host: Sanyam Bhutani & Guest: Abhishek Thakur (compact)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"_**<p style=\"font-size:14px\">Host (Sanyam Bhutani): If you see from the above chart (subjective: ~25 moments, objective/subjective: ~40 moments and objective: ~44 moments), the host has been objective with the discussions ~40% of the time, while the rest of the ~60% the conversation was between Subjective to Objective/Subjective sentiments.</p>**_\n\n_**<p style=\"font-size:14px\">Guest (Abhishek Thakur): If you see from the above chart (subjective: ~20 moments, objective/subjective: ~43 moments and objective: ~45 moments), the host has been objective with the discussions ~41% of the time, while the rest of the ~59% the conversation was between Subjective to Objective/Subjective sentiments.</p>**_\n\n_**<p style=\"font-size:14px\">Thus we can conclude that both have contributed equally to the conversations, but how the audience took each of these facets is another question.</p>**_"},{"metadata":{},"cell_type":"markdown","source":"<a href='#myApproach'><span class=\"label label-info\" style=\"font-size: 125%\">Back to My Approach</span></a> <a href='#ToC'><span class=\"label label-info\" style=\"font-size: 125%\">Back to Table of Contents</span></a>"},{"metadata":{},"cell_type":"markdown","source":"\n<i><p style=\"font-size:18px; background-color: ##FF8C00; border: 2px solid black; margin: 20px; padding: 20px;\">Note: The above is no means to conclude anything personal about either the Host or Guest or judge them in any form or shape, it's just illustrating how the conversation sentiments were flowing. </br>This kernel is a material to study, analyse and understand these ideas and concepts and not meant personally in favour or against anyone or about them as an individual.</p></i>"},{"metadata":{},"cell_type":"markdown","source":"<a id='e1Accuracies'></a>\n\n----------\n\n\n### Checking accuracies of these scores for episode E1\nThe quality of these scores highly depends on the quality of the data provided, looking at the spell check and grammar check results we can see the below:"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"chart = sns.catplot(x=\"spelling_quality\", data=first_episode_nlp_profiled, size=10, kind=\"count\")\nchart.despine(left=True)\nchart.set_ylabels(\"Spoken moments\", fontsize=16)\nchart.set_xlabels(\"Spelling quality (in words)\", fontsize=16)\nchart.fig.suptitle('Spelling check of the transcripts (Episode E1)')\nchart.set_xticklabels(rotation=30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"chart = sns.catplot(x=\"grammar_check\", data=first_episode_nlp_profiled, size=10, kind=\"count\")\nchart.despine(left=True)\nchart.set_ylabels(\"Spoken moments\", fontsize=16)\nchart.set_xlabels(\"Grammar quality (in words)\", fontsize=16)\nchart.fig.suptitle('Grammar check of the transcripts (Episode E1)')\nchart.set_xticklabels(rotation=30)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The quality ratings of the spellings used (maybe because it's hand-curated), have been between Quite good to Very good - which also means the quality of the conclusions made from those texts are on the safe side. But from the Grammar checks we get a different idea about the quality of the text. We see that of the total moments, most of the time there were no issues with grammar. But it's understandable given when we speak we may not always be conscious of the semantics of our sentences and words spoken. As you may agree that from another perspective, the quality of the grammar can have an impact on these scores (within reasons). Also, it could lead to a further discussion about understandability of the words/sentences said by both the host and guest to the audience, given not everyone joining the show might be speaking/understanding English at the level as someone for whom English is their first language."},{"metadata":{},"cell_type":"markdown","source":"<i><p style=\"font-size:18px; background-color: #FFF1D7; border: 2px solid black; margin: 20px; padding: 20px;\">Note: The libraries used to compute sentiment analysis, subjectivity, spell check, etc... may not be fully accurate, although some literature say they could be 70%-80% accurate, so please take whatever mentioned about these concepts and metrics in the kernel with a pinch of salt. Verify and validate your results after checking with other sources as well.</p></i>"},{"metadata":{},"cell_type":"markdown","source":"<a href='#myApproach'><span class=\"label label-info\" style=\"font-size: 125%\">Back to My Approach</span></a> <a href='#ToC'><span class=\"label label-info\" style=\"font-size: 125%\">Back to Table of Contents</span></a>"},{"metadata":{},"cell_type":"markdown","source":"<a id='e1Conclusion'></a>\n\n----------\n\n### Finally concluding the episode E1"},{"metadata":{},"cell_type":"markdown","source":"_The audience enjoys, learns and makes opinions based on the flow of sentiments and subjectivity of the conversations (among other factors). The conversations were had on a multitude of topics related to subjects of the likings or less of likings or interest of the audience. The audience is unconsciously already making an opinion about the show at each moment. The net feeling/opinion at each moment is also deciding this. At the end of the show the net scores of the above components decide the following about for each of the individual members of the audience:_\n\n- they like the show by a specific time point in the video or not\n- they like the specific topic or not in general\n- they like the host or not in general\n- they like the host or not by a specific time point in the video or not\n- they like the speaker/guest or not in general\n- they like the speaker/guest or not by a specific time point in the video or not\n\n\"Like\" and \"dislike\" decides if they are \"enjoying or not\", \"learning or not\" - which may result in either a rewatch and/or sharing via social media. Clicking on the like/favourite/upvote buttons or downvote/dislike buttons (or all of them) or comments in the comment section of that nature. This all depends on the appetite of each individual to recognise or accept the \"Sentiment polarities\" and/or the \"Subjectivity\" mentioned in the visuals above (and other factors we haven't captured or discussed here).\n\nThey are forming opinions, likings, dislikes, learnings as the show goes along and their next visit will depend on these factors (not excluding the factors mentioned [in the table above](#onePerspective)).\n\nThey say the brain is the most attractive organ but it is the words that come out of us and the way we form and put them across to the other(s) - draw us towards or drive us away from the other(s). And in the light of the above concepts, this can play a compelling role in deciding future viewerships, fan clubs and all other related factors. That's why sometimes we re-watch or revisit the same topic or topics we have already read about from source/author A or source/Author B or source/Author C - each has their perception and method of delivery which draws us to them and binds us to them."},{"metadata":{},"cell_type":"markdown","source":"<a href='#myApproach'><span class=\"label label-info\" style=\"font-size: 125%\">Back to My Approach</span></a> <a href='#ToC'><span class=\"label label-info\" style=\"font-size: 125%\">Back to Table of Contents</span></a>"},{"metadata":{},"cell_type":"markdown","source":"<a id='overallConclusion'></a>\n\n----------\n\n## Overall conclusion"},{"metadata":{},"cell_type":"markdown","source":"<table border=1 bgcolor=\"#FF9F00\"><tr><td>\n<p style=\"font-size:16px\">I have only touched on one question and also only one episode among all the shows, and only using the high-level NLP concepts my library <a href=https://github.com/neomatrix369/nlp_profiler/>NLP Profiler</a> provides and some help from another kernel and dataset. Also, the ideas expressed above may need some validation and verification before we can answer the question with an even better degree of accuracy.</p>\n\n<p style=\"font-size:16px\">I did not take the route like the other approaches and examples we see in the Kernels section, simply because I could not reason the statistical outputs and link the threads to the threads from the questions we went about trying to answer (maybe the others could), in this case particularly the question <b>\"What makes an interview bring more audience?\"</b>. You see when we read or hear something or when another person does the same, neither of us conclude at any given moment or at the end of a series of moments: \"they said n words or m characters in this sentences\" - \"I like that person/show/topic\" or \"I dislike that person/show/topic because the term 'abc' wasn't used in this frequency across these moments\" and things like that, we pick much higher level signals and the above is an example in that direction.</p>\n\n<p style=\"font-size:16px\">Although I was tempted to use one or two of the NLP extractions and conclusions and blend it with my work here, although it's lower on my list as I want to make my approach and perspective clear to everyone and make them useful, before adding more layers to it.</p>\n\n<p style=\"font-size:16px\">Some reasoning, logical thinking and gut-feeling say the above might have some good substance but I will leave this to your judgement to decide what is more correct and fitting and what isn't. And also what is more practical and achievable and what isn't. I hope the arguments are clear and if not, please ask away. I will do my best to review and make things clearer with multiple iterations.</p>\n\n<p style=\"font-size:16px\">Once again thanks to those who provided such amazing kernels, visualisations and useful datasets that my work of explaining myself became easier.</p>\n</td></tr></table>"},{"metadata":{},"cell_type":"markdown","source":"<a href='#ToC'><span class=\"label label-info\" style=\"font-size: 125%\">Back to Table of Contents</span></a>"},{"metadata":{},"cell_type":"markdown","source":"<a id='resources'></a>\n\n----------\n\n## Resources\n\n- [Plotly/plotly express charts](https://plotly.com/python/line-charts/)\n- [Data Visualisation Catalogue](https://datavizcatalogue.com/index.html)\n  - [The R Graph Gallery â€“ Help and inspiration for R charts](https://www.r-graph-gallery.com/)\n- [NLP Profiler Resources](https://www.kaggle.com/general/166954) | [on PyPi](https://pypi.org/project/nlp-profiler/)\n- [Awesome AI-ML-DL: Better NLP library](https://bit.ly/better-nlp-launch)\n- [Awesome AI-ML-DL: NLP Resources](https://github.com/neomatrix369/awesome-ai-ml-dl/tree/master/natural-language-processing)\n- [Awesome AI-ML-DL Github](https://github.com/neomatrix369/awesome-ai-ml-dl/blob/)"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}