{"cells":[{"metadata":{},"cell_type":"markdown","source":"This kernel aims to provide implementations of NLP ML methods for a set of problems of practical value (so hopefully relevant for buisness applications)\n\nI've decided to analyse products (games) at Steam Store (arguably the most popular gaming platform and store), \nmostly because I know the domain quite well, and because Steam Store has good metadata ecosystem for NLP tasks \n(e.g. reviews have 'helpful' score, 'funny' score, number of hours the reviewer played the game)\n\n\n\n**The set of theoretial buisness problems includes:**\n* -Extracting nuances (strong/weak points of typical/specific products), which is useful for:\n    *    --game developers/publishers to better understand the demands of their customers and deliver higher quality, more competent products\n    *    --retailers selling Steam keys to optimise their key stocks based on customer demands and product specifics\n    *    --individual customers who'd like to know about pros/cons of a certain product relevant for many other customers before buying it\n* -Competitor/Similair products, which is useful for:\n    *    --retailers recommending games to individual customers with similair hidden features\n    *    --game developers/publishers optimizing game development/maintenance (i.e. focusing on more relevant game features/fixes)\n* -Extracting information about brand reputation, especially associated with certain buisness descisions or track of competent solutions, which is useful for:\n    *    --game developers/publishers optimising their buisness descisions, marketing\n    *    --retailers planning stocks/estimating sales for products by certain developers/publishers\n    *    --individual customers to better identifying untrustworthy game developers/publishers, or, on the contrary, solidifying trust/loyalty to specific game developers/publishers\n\n\n\n**To try to solve the above buisness problems the following set of NLP problems, among others, were considered:**\n1.  Feature/aspect-based Sentiment Analysis [for products/companies]\n1.  Topic modeling [for latent features of products]\n1.  Named Entity Recognition [for comparable products mentioned in specific context]\n\n\n\n\n**Results:**\n\nThe available dataset was found to have certain flaws for our problems \n(e.g. features only bestseller games, the amount of reviews included was not representative),\nbut those flaws were accounted for in some way or another\n\nPrototypes for solutions of problems 1) and 2) were developed somewhat successfully (one can certainly gain some insights from applying them)\n\nPrototype for solution of problem 3) could not be successfully developed in a reasonable timeframe\nand having reasonable amount of model generalization, even with use of additional dataset, largely due to\nhigh demands in entity matching.\n\nMore details about solution implementation and their results can be found in the comments to specific cells"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\nimport spacy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/steam-reviews-dataset/steam_reviews.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nSome basic EDA after which i've abandoned/alterated some of the initial ideas for this project (above is the final version)\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['review_length'] = data.apply(lambda row: len(str(row['review'])), axis=1)\n\ndata['recommendation_int'] = data['recommendation'] == 'Recommended'\ndata['recommendation_int'] = data['recommendation_int'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(data['title'].unique()), data['title'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reviews_count = data.groupby(['title'])['review'].count().sort_values(ascending=False)\n\nreviews_count = reviews_count.reset_index()\n\nsns.set(style=\"darkgrid\")\nplt.figure(figsize=(25,20))\nsns.barplot(y=reviews_count['title'], x=reviews_count['review'], data=reviews_count,\n            label=\"Total\", color=\"r\")\n\nreviews_count_pos = data.groupby(['title', 'recommendation_int'])['review'].count().sort_values(ascending=False)\nreviews_count_pos = reviews_count_pos.reset_index()\nreviews_count_pos = reviews_count_pos[reviews_count_pos['recommendation_int'] == 1]\nsns.barplot(y=reviews_count_pos['title'], x=reviews_count_pos['review'], data=reviews_count_pos,\n            label=\"Total\", color=\"b\")\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.groupby(['title', 'recommendation_int'])['review'].count()\ndata[data['title'] == \"Tom Clancy's Rainbow Six® Siege\"]\n\n# R6 Siege in reality has much more reviews and much more mixed score\n#=> *pos/neg reviews distribution is completely unrepresentative for some games\n#=> *quantity of  reviews distribution is completely unrepresentative for some games\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"polarity_count = data.groupby(['recommendation_int']).count()\npolarity_count = polarity_count.reset_index()\n\n\nax = sns.barplot(x=polarity_count['recommendation_int'], y=polarity_count['review'],\n            data=polarity_count, hue='recommendation_int')\n\n\n'''\n#Just a different take on visualization:\n\npolarity_count_pos = polarity_count[polarity_count['recommendation_int'] == 1]\nsns.barplot(x=polarity_count_pos['recommendation_int'], y=polarity_count_pos['review'], data=polarity_count_pos,\n            label=\"Total\", color=\"b\")\n\npolarity_count_neg = polarity_count[polarity_count['recommendation_int'] == 0]\nsns.barplot(x=polarity_count_neg['recommendation_int'], y=polarity_count_neg['review'], data=polarity_count_neg,\n            label=\"Total\", color=\"r\")\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"polarity_count = data[data['helpful'] > 50].groupby(['recommendation_int']).count()\npolarity_count = polarity_count.reset_index()\n\n\nax = sns.barplot(x=polarity_count['recommendation_int'], y=polarity_count['review'],\n            data=polarity_count, hue='recommendation_int')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Distribution of pos/neg ratio seems stable across the helpfulness scale"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\n This cell can be used to prepare reviews data for classifiers\n \n Can take data for all products in general (to analyze typical product reviews)\n Can also take data just for a specific product (e.g. 'Grand Theft Auto V')\n'''\n\nclean_data = data.dropna()\n\n#train = clean_data\ntrain = clean_data[clean_data['title'] == 'Grand Theft Auto V']\n\n\nX = train['review']\ny = train['recommendation_int']\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=273, stratify=y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nCustom tokenizer for lemmatization from spaCy tokenizer\n\nUsed in vectorizers in different tasks here\n\nPrefer using on small datasets, or else processing will take too long\n'''\n\nimport spacy\n\n# load spacy language model\nen_nlp = spacy.load('en', disable=['parser', 'ner'])\nspacy_tokenizer = en_nlp.tokenizer\n\n# create a custom tokenizer using the spaCy document processing pipeline\n# (now using our own tokenizer)\ndef custom_tokenizer(document):\n    doc_spacy = en_nlp(document)\n    return [token.lemma_ for token in doc_spacy]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\n This cell can be used to build classifiers of positive/negative reviews\n which can be inspected to get insights about why certain reviews are positive/negative\n \n Can be used to analyse what people like/dislike about certain product\n or a selection of products in general\n \n Can possibly be used to label unlabeled comments about the product (like comments on forums)\n \n Deep Learning alternative: LSTM(uni/bi-directional) / 1D-CNN / MLP / their combinations\n can be used, although my limited tests on IMDB dataset(which is quite similair to this Steam Reviews dataset)\n have not found any reasonable justification to use Deep Learning over plain LogisticRegression\n because loss of explainability is obvious, hypothesis space is drasticaly increased, so optimization is harder,\n and, most of all, accuracy gain is negliable (89 LogReg vs 89-90 DL with a lot of tweaking)\n'''\n\nfrom time import time\n\n#from sklearn.naive_bayes import MultinomialNB\n#from sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\n#from sklearn.linear_model import SGDClassifier\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n#from sklearn.feature_extraction.text import TfidfTransformer\n\n#from sklearn.model_selection import GridSearchCV\n#from sklearn.pipeline import make_pipeline\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import classification_report\n\n\n# Zoo of vectorizers inside a pipline, some include comments\nt0 = time()\ntext_clf = Pipeline([#('vect', CountVectorizer(min_df=5)),\n                     #('vect', TfidfTransformer(norm=None)),\n                     ('vect', TfidfVectorizer(max_df=0.99, norm='l2')), #< default, cuts some generic words\n                     #('vect', TfidfVectorizer(max_df=0.2, norm='l2')), #< default, leaves generic words\n                     #('vect', TfidfVectorizer(max_df=0.99, norm='l2', sublinear_tf=True, ngram_range=(2, 2), tokenizer=custom_tokenizer)), #500 sec journey\n                     #('vect', TfidfVectorizer(max_df=0.99, norm='l2', sublinear_tf=True, tokenizer=custom_tokenizer)),\n                     #('vect', TfidfVectorizer(max_df=0.99, norm='l2', ngram_range=(4, 4))), #< some useful info\n                     #('vect', TfidfVectorizer(min_df=5, norm='l2', tokenizer=custom_tokenizer)),\n                     #('vect', TfidfVectorizer(min_df=5, norm='l2', tokenizer=custom_tokenizer, max_features=10000)),\n                     #('clf', MultinomialNB())\n                     #('clf', LogisticRegression(solver='saga', fit_intercept=True, class_weight='balanced'))\n                     ('clf', LogisticRegression(solver='saga', fit_intercept=True, class_weight='balanced', C=0.1)) #< reasonable\n                     #('clf', SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, random_state=273, max_iter=5, tol=None)) #< SVM, SGD version, sometimes delivers good results\n                    ])\nprint(\"preprocessing done in %0.3fs.\" % (time() - t0))\n\n\nt0 = time()\ntext_clf.fit(X_train, y_train)\nprint(\"fitting done in %0.3fs.\" % (time() - t0))\n\nt0 = time()\ny_pred = text_clf.predict(X_test)\nprint(\"predicting done in %0.3fs.\" % (time() - t0))\n#target_names = ['class 0', 'class 1', 'class 2']\nprint(classification_report(y_test, y_pred)) #, target_names=target_names))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\n This cell can be used to visualize LogisticRegression coefficients attributed to the tokens,\n which should give an idea of what make a review positive/negative, why customers like/dislike the product, etc.\n'''\n\nimport eli5\n\neli5.show_weights(text_clf, vec=text_clf.named_steps[\"vect\"], top=40)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\n This cell can be used to setup data for topic modeling\n \n Designed to prepare a corpus of negative/positive reviews for certain product\n to further extract latent features via topic modeling methods (LDA/NMF) \n \n Train/test naming and split steps are present for cinsistency\n'''\n\nclean_data = data.dropna()\n\n# Example: here we want to find out why customers who left negative reviews for certain product are not satisfied, \ntrain = clean_data[(clean_data['title'] == 'Grand Theft Auto V') & (clean_data['recommendation_int'] == 0)]\n\nX = train['review']\ny = train['recommendation_int']\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=273, stratify=y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\n This cell can be used to visualize topics modeled by LDA/NMF.\n \n Designed to visualize hidden features of products which affect customer's satisfaction\n \n Default is the wordcloud visualization, \n although topics' contents can be printed as lists of tokens (uncomment the respective lines)\n \n For colormaps list google: \"Matplotlib colormap reference\", some examples:\n -colormap = 'summer' < suitable for positive reviews\n -colormap = 'inferno' < suitable for negative reviews\n \n'''\n\nfrom wordcloud import WordCloud, STOPWORDS\n\ndef print_top_words(model, feature_names, n_top_words, colormap='viridis'):\n    for topic_idx, topic in enumerate(model.components_):\n        \n        #to print topics' contents as lists of tokens\n        #message = \"Topic #%d: \" % topic_idx\n        \n        message = \" \".join([feature_names[i]\n                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n        \n        #to print topics' contents as lists of tokens\n        #print(message + '\\n')\n        \n        generate_wordcloud(message, colormap)\n    print()    \n\n\ndef generate_wordcloud(text, colormap='viridis'):\n    wordcloud = WordCloud(#font_path='/Library/Fonts/Verdana.ttf',\n                          relative_scaling = 1.0,\n                          colormap = colormap\n                          #colormap = 'summer', #< suitable for positive reviews\n                          #colormap = 'inferno', #< suitable for negative reviews\n                          #stopwords = STOPWORDS\n                          ).generate(text)\n    plt.imshow(wordcloud)\n    plt.axis(\"off\")\n    plt.show()\n\n# for testing the generate_wordcloud():\n#text = 'all your base are belong to us all of your base base base'\n#generate_wordcloud(text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nThis cell can be used for topic modeling w/ NMF\n\nFor the data used here NMF is often faster (so more preferable)\n'''\n\nfrom sklearn.decomposition import NMF\n\n# Zoo of tested vectorizers:\ntfidf_vect = TfidfVectorizer(max_df=.50) #< quick results\n#tfidf_vect = TfidfVectorizer(max_df=.50, tokenizer=custom_tokenizer) #< uses spaCy tokenizer w/ lemmatization, good for smaller datasets\n#tfidf_vect = TfidfVectorizer(ngram_range=(1, 2)) #< experimental, long to compute, questionable results, but can be insightful\n\n# Transform dataset, extract topics\nX_train_topical = tfidf_vect.fit_transform(X_train)\n\nnmf = NMF(n_components=5, random_state=273,\n          alpha=.1, l1_ratio=.5)\n\ndocument_topics_nmf = nmf.fit_transform(X_train_topical)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get topic contents and visualize the topics, example here - for negative reviews\ntfidf_vect_feature_names = tfidf_vect.get_feature_names()\nprint_top_words(nmf, tfidf_vect_feature_names, 100, colormap='inferno')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nHere's another data setup for topic modeling, but for different example:\nextract topics from positive reviews using LDA\n'''\n\nclean_data = data.dropna()\n\n# Example: here we want to find out why customers who left positive reviews for certain product are satisfied, \ntrain = clean_data[(clean_data['title'] == 'Grand Theft Auto V') & (clean_data['recommendation_int'] == 1)]\n\nX = train['review']\ny = train['recommendation_int']\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=273, stratify=y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nThis cell can be used for topic modeling w/ LDA\n\nFor the data used here NMF is often faster (so more preferable)\n\nFor unsupervised text document models, \nit is often good to remove very common words,\nas they might otherwise dominate the analysis. \nWe’ll remove words that appear in atleast  20  percent  of  the  documents,  \nand  we’ll  limit  the  bag-of-words  model  to  the\n10,000 words that are most common after removing the top 20 percent:\n'''\n\nfrom sklearn.decomposition import LatentDirichletAllocation\n\nvect = CountVectorizer(max_features=10000, max_df=.20)\nX_train_topical = vect.fit_transform(X_train)\n\nlda = LatentDirichletAllocation(n_components=5, learning_method=\"batch\",\n                                max_iter=25, random_state=273)\n# We build the model and transform the data in one step\n# Computing transform takes some time,\n# and we can save time by doing both at once\ndocument_topics = lda.fit_transform(X_train_topical)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vect_feature_names = vect.get_feature_names()\nprint_top_words(lda, vect_feature_names, 100, colormap='summer')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\n This cell can be used to calculate the strength of positive/negative association \n of the current product (e.g. 'Grand Theft Auto V') with other products\n being mentioned in the customers' reviews for this product\n \n Essentially it's an NER task with elements of Sentiment Analysis\n \n WIP, currently only shows entity counts from short handcrafted list\n across all the reviews\n  \n [Assumptions: \n     Customers tend to mention other products in positive reviews for this product\n     when they think this product is at least no worse than other products, \n     or maybe even better,\n     when they like certain positive features from other products are found in this product\n     etc.\n     \n     At the same time customers mention other products in negative reviews for this product\n     when they think this product is at least no better than other products,\n     or maybe even worse,\n     when they dislike certain negative features from other products are found in this product\n     etc.\n     \n     Ties can be broken based on majority ratio/percent difference threshold, etc.\n     Cool idea for breaking ties and visualization - LogisticRegression w/ eli5 visualizer\n     on both pos/neg reviews set for a preduct]\n     \n WORK IN PROGRESS: \n     Requires heavy entity matching, coz no one writes \n     full correct names of the products like they are in the database;\n     \n     Demo example is provided for the whole set of reviews(all products mixed)\n     with some custom entity matching\n     \n     Potentially cool implementation w/ LogisticRegression(see above)\n'''\n\n# Data preparation\nclean_data = data.dropna()\n\n# Usecase of the final version\n#train = clean_data[(clean_data['title'] == 'Grand Theft Auto V') \n                  # & (clean_data['recommendation_int'] == 1)]  #< pick one\n                  # & (clean_data['recommendation_int'] == 0)]  #  not both\n\n# Demo usecase\ntrain = clean_data\n\n# Routine split for potential use in logistic regression\nX = train['review']\ny = train['recommendation_int']\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=273, stratify=y)\n\n\n\n# Kind of a comprehensive list of entities (product names from Steam store), about 40k names,\n# Requires entity matching to be of practical value\n#steam_games = pd.read_csv(\"../input/steam-games-complete-dataset/steam_games.csv\")\n#ents = steam_games['name'].unique()\n\n# Demo list of entities with matching \nents = {'GTA': 0, 'GTA5':1, 'GTAV':2, 'GTA V':3, 'GTA 5':4, 'gta 5':5, 'gta5':6, 'PUBG':7, 'pubg':8}\n\n# Making custom vocabulary from entities to do NER via BoW\nner = CountVectorizer(vocabulary=ents)\nner_fit=ner.fit_transform(X_train)\n\n# Sum entity mentions across the corpus\ncounts = np.asarray(ner_fit.sum(axis=0)).ravel()\n\n# Output entity names and number of mentions across the corpus\nfor ent_idx, ent in enumerate(ents):\n    \n    #DEBUG\n    #print(ent_idx, ent)\n    \n    if (counts[ent_idx] != 0):\n        print(ent, counts[ent_idx])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}