{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Using Shotgun metagenomics for disease prediction\nShotgun metagenomic sequencing is a relatively new sequencing approach that allows insight to be gained into community biodiversity and function.<br>\nThe function of shotgun metagenomic sequencing is to sequence the genomes of untargeted cells in a community in order to elucidate community composition and function.<br>\nIn this notebook I depart from the discoveries made in the [dataset's creators research paper](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1004977), and therefore skip EDA. I wanted to expand on their work and first of all I approach prediction cirrhosis using XGBoost in 'synthetic pure' case of samples with cirrhosis against healthy samples. Creating binary classification problem this way, and comparing it with the result they achieved using RandomForest and SVM. <br>\nI'm also checking if the model trained on this dataset would be still able to make prediction if we given a dataset with other diseases mixed in. <br>\nAnd finally I want to check if the model will be able to distinguish cirrhosis from other diseases."},{"metadata":{},"cell_type":"markdown","source":"![](https://d3i71xaburhd42.cloudfront.net/fb32dc53b3f5c638d84fb02da7213863a27cee28/2-Figure1-1.png)"},{"metadata":{},"cell_type":"markdown","source":"\nA few useful articles:<br>\n[An introduction to the analysis of shotgun metagenomic data](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4059276/)<br>\n[Shotgun metagenomics, from sampling to analysis](https://pubmed.ncbi.nlm.nih.gov/28898207/)<br>\n[16S rRNA Gene Sequencing for Bacterial Identification in the Diagnostic Laboratory: Pluses, Perils, and Pitfalls](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2045242/)<br>\n[Then and now: use of 16S rDNA gene sequencing for bacterial identification and discovery of novel bacteria in clinical microbiology laboratories](https://pubmed.ncbi.nlm.nih.gov/18828852/)<br>\n[Direct 16S rRNA-seq from bacterial communities: a PCR-independent approach to simultaneously assess microbial diversity and functional activity potential of each taxon](https://www.nature.com/articles/srep32165#abstract)<br>\n"},{"metadata":{},"cell_type":"markdown","source":"Loading libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nfrom xgboost import XGBClassifier\nimport xgboost as xgb\n\nimport sklearn\nfrom sklearn import metrics\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score, roc_auc_score, confusion_matrix, precision_recall_curve, auc, roc_curve, recall_score\n\nimport seaborn as sns\nimport scikitplot as skplt\nimport matplotlib.pyplot as plt\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Metaparameters\nVERBOSE = 0\nFOLDS = 5\n\nshow_fold_stats = True\n# show_fold_stats = False # set to True if all OOF results wanted\n\ndo_plot_ROC = False # set to True to plot ROC when predicting cirrhosis\n\n# test_train_split_SEED = 1970\ntest_train_split_SEED = 1971","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def plot_ROC(fpr, tpr, m_name):\n    roc_auc = sklearn.metrics.auc(fpr, tpr)\n    plt.figure(figsize=(6, 6))\n    lw = 2\n    plt.plot(fpr, tpr, color='darkorange',\n             lw=lw, label='ROC curve (area = %0.2f)' % roc_auc, alpha=0.5)\n    \n    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--', alpha=0.5)\n    \n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xticks(fontsize=16)\n    plt.yticks(fontsize=16)\n    plt.grid(True)\n    plt.xlabel('False Positive Rate', fontsize=16)\n    plt.ylabel('True Positive Rate', fontsize=16)\n    plt.title('ROC for %s'%m_name, fontsize=20)\n    plt.legend(loc=\"lower right\", fontsize=16)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"My initial experiments with full dataset of species abundance features proved that XGB wasn't able to beat the original paper results. So I benefited from their analyses of features importance, and used the reduced dataset for ongoing experimentation. <br>\nI still plan on using markers in future experiments."},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"\n# pd_abundance = pd.read_csv('/kaggle/input/metagenomics/abundance.txt', sep='\\t', header=None, index_col=0, dtype=str)\npd_abundance = pd.read_csv('../input/human-metagenomics/abundance_stoolsubset.csv', dtype=str)\ndisease = pd_abundance.loc[:,'disease'] \nd_name = pd_abundance.loc[:,'dataset_name'] \nprint(disease.value_counts())\nprint(d_name.value_counts())\n\n# list of diseases we want to analyze and predict\ndiseases = ['obesity', 'cirrhosis', 't2d', 'cancer']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = pd_abundance.columns.tolist()\nspecies = [x for x in cols if x.startswith('k_')]\nmetadata = [x for x in cols if not x.startswith('k_')]\npd_abundance_conv = pd_abundance.copy()\npd_abundance_conv = pd_abundance_conv[species].astype('float64')\npd_abundance_conv = pd.concat([pd_abundance[metadata], pd_abundance_conv], axis = 1)\n\n# controls/healthy samples from Human Microbiome Project coded 'hmp' and 'hmpii'. \n# 't2d' stands for Type 2 Diabetes. We will combine a few studies into single dataset.\ndata_sets = {'control':['hmp', 'hmpii'],'t2d':['WT2D','t2dmeta_long','t2dmeta_short'], 'cirrhosis' : ['Quin_gut_liver_cirrhosis'], \n             'cancer' : ['Zeller_fecal_colorectal_cancer'], 'obesity' : ['Chatelier_gut_obesity']}\n# combine controls from different studies into one\npd_abundance_conv['disease'] = pd_abundance_conv['disease'].apply(lambda x: 'control' if ((x == 'n') or (x == 'nd') or (x == 'leaness')) else x)\n# separate controls and diseases into 2 dataframes\npd_control = pd_abundance_conv.loc[pd_abundance_conv['disease'] == 'control']\npd_disease = pd_abundance_conv.loc[pd_abundance_conv['disease'] != 'control']\n\n# we won't consider diseases from this list\nnot_disease = [d for d in pd_disease.disease.unique().tolist() if d not in diseases] \nfor d in not_disease:\n    pd_disease = pd_disease.drop(pd_disease.loc[pd_disease['disease'] == d].index, axis = 0)     ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Defining model"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def disease_distinction(d, counter_d):\n    print('-' * 80)\n    print('Discriminate %s from %s'%(d,counter_d))\n    \n    skf = StratifiedKFold(n_splits = FOLDS, shuffle = True, random_state = SEED)\n    oof_preds = []\n    oof_aucs = []\n    oof_scores= []\n    ds_names = data_sets[d]\n    if len(ds_names) == 1:\n        pd_cont = pd_control.loc[pd_control['dataset_name'] == ds_names[0]]\n        pd_dis = pd_disease.loc[pd_disease['dataset_name'] == ds_names[0]]\n    else:\n        pd_cont = pd_control.loc[pd_control['dataset_name'] == ds_names[0]]\n        pd_dis = pd_disease.loc[(pd_disease['disease'] == d) & (pd_disease['dataset_name'] == ds_names[0])]\n        for ds in ds_names[1:]:\n            pd_cont = pd.concat([pd_cont, pd_control.loc[pd_control['dataset_name'] == ds]], axis = 0)\n            pd_dis = pd.concat([pd_dis, pd_disease.loc[(pd_disease['disease'] == d) & (pd_disease['dataset_name'] == ds)]], axis = 0)\n                                 \n    #     create dataset with all other diseases, target set to 0\n    pd_others = pd_disease.loc[(pd_disease['disease'] == counter_d)]\n    target_others = pd_others['disease'].apply(lambda x: 1 if x == d else 0)\n    \n    pd_train = pd.concat([pd_cont, pd_dis], axis = 0)\n    #     adding control data from healthy subject, data by HMP\n    pd_train = pd.concat([pd_train, pd_control.loc[pd_control['dataset_name'] == 'hmp']], axis = 0)\n    pd_train = pd.concat([pd_train, pd_control.loc[pd_control['dataset_name'] == 'hmpii']], axis = 0)\n    target = pd_train['disease']\n    #     convert text target into binary\n    binary_target = target.apply(lambda x: 1 if x == d else 0)\n    # binary_target.value_counts()\n    #     use only abundance data for training\n    pd_others = pd_others[species] \n    pd_train  = pd_train[species] \n\n    #     this split provides us with preserved test set\n    disease_train, disease_test, disease_y_train, disease_y_test = train_test_split(pd_train, binary_target, test_size = 0.10, \n#                                                                                     stratify = binary_target,\n                                                                                    random_state = test_train_split_SEED)   \n\n    #     combining preserved test set with othere diseases samples\n    full_test = pd.concat([disease_test, pd_others])\n    full_y_test = pd.concat([disease_y_test, target_others])\n    \n    disease_y_test.value_counts()\n    disease_y_train.value_counts()\n    preds = np.zeros(disease_y_test.shape[0])\n    full_preds = np.zeros(full_y_test.shape[0])\n\n    for fold, (idxT,idxV) in enumerate(skf.split(disease_train, disease_y_train)):\n\n        X_train = disease_train.iloc[idxT]\n        X_val = disease_train.iloc[idxV]\n        y_train = disease_y_train.iloc[idxT]\n        y_val = disease_y_train.iloc[idxV]\n    \n        XGB_model = XGBClassifier(n_estimators=5000, max_depth=None, \n                            learning_rate=0.05,\n                            objective='binary:logistic', \n                            metric='auc',\n                            verbosity  = VERBOSE,\n                            n_jobs=-1, random_state  = SEED)\n        \n        if show_fold_stats:\n            print('-' * 80)\n            print('Fold : %s'%(fold+1))\n    \n        XGB_model.fit(X_train, y_train,\n                        eval_set = [(X_val, y_val)],\n                        eval_metric=['logloss'],\n                        early_stopping_rounds = 100, verbose = VERBOSE )\n            \n        XGB_preds = XGB_model.predict_proba(X_val)\n        XGB_score = metrics.roc_auc_score(y_val, XGB_preds[:,1])\n        XGB_class = XGB_model.predict(X_val)\n        \n        XGB_test = XGB_model.predict_proba(disease_test)\n        XGB_test_score = metrics.roc_auc_score(disease_y_test, XGB_test[:,1])\n        XGB_test_class = XGB_model.predict(disease_test)\n        \n        full_test_preds = XGB_model.predict_proba(full_test)\n        full_test_score = metrics.roc_auc_score(full_y_test, full_test_preds[:,1])\n        full_test_class = XGB_model.predict(full_test)\n               \n        f1s = f1_score(y_val, XGB_class)\n        recall = metrics.recall_score(y_val, XGB_class)\n        precision_score = metrics.precision_score(y_val, XGB_class)\n        \n        f1_test = f1_score(disease_y_test, XGB_test_class)\n        recall_test = metrics.recall_score(disease_y_test, XGB_test_class)\n        precision_score_test = metrics.precision_score(disease_y_test, XGB_test_class)\n        \n        f1_full_test = f1_score(full_y_test, full_test_class)\n        recall_full_test = metrics.recall_score(full_y_test, full_test_class)\n        precision_full_test = metrics.precision_score(full_y_test, full_test_class)\n\n        if show_fold_stats:        \n            print('ROC AUC score for XGBoost model valid set: %.4f'%XGB_score)\n            print('F1 score: %0.4f'%f1s)\n            print(confusion_matrix(y_val, XGB_class))\n    \n            print('ROC AUC score for XGBoost model test set: %.4f'%XGB_test_score)\n            print('F1 score: %0.4f'%f1_test)\n            print(confusion_matrix(disease_y_test, XGB_test_class))\n            \n            print('ROC AUC score for full test set including other diseases used as false controls: %.4f'%full_test_score)\n            print('F1 score: %0.4f'%f1_full_test)\n            print(confusion_matrix(full_y_test, full_test_class))\n        \n        preds += XGB_test[:,1] / FOLDS\n        full_preds += full_test_preds[:,1] / FOLDS\n        \n        fold_score = [XGB_score,f1s,recall,precision_score, XGB_test_score,f1_test,recall_test,precision_score_test]\n        oof_scores.append({fold : fold_score})\n    \n    avg_test_score = metrics.roc_auc_score(disease_y_test, preds)\n    avg_class = np.where(preds < 0.5, 0, 1)\n    avg_f1_test = f1_score(disease_y_test, avg_class)\n    avg_recall_test = metrics.recall_score(disease_y_test, avg_class)\n    avg_precision_score_test = metrics.precision_score(disease_y_test, avg_class)\n\n    avg_full_test_score = metrics.roc_auc_score(full_y_test, full_preds)\n    avg_class_full = np.where(full_preds < 0.5, 0, 1)\n    avg_f1_test_full = f1_score(full_y_test, avg_class_full)\n    avg_recall_full_test = metrics.recall_score(full_y_test, avg_class_full)\n    avg_precision_full_test = metrics.precision_score(full_y_test, avg_class_full)\n\n    if show_fold_stats:        \n        print('-' * 80)\n        print('ROC AUC score for %s averaged over %i folds: %.4f'%(d, FOLDS, avg_test_score))\n        print('F1 : %.4f, Recall : %.4f , Precision : %.4f'%(avg_f1_test, avg_recall_test, avg_precision_score_test))\n        print('Confusion matrix for %s averaged across %i folds '%(d,FOLDS))\n        print(confusion_matrix(disease_y_test, avg_class))\n\n    \n    print('ROC AUC score for %s against %s averaged over %i folds : %.4f'%(d, counter_d, FOLDS, avg_full_test_score ))\n    print('F1 : %.4f, Recall : %.4f , Precision : %.4f'%(avg_f1_test_full, avg_recall_full_test, avg_precision_full_test))\n    print('Confusion matrix for %s against %s averaged across %i folds'%(d, counter_d, FOLDS))\n    print(confusion_matrix(full_y_test, avg_class_full))\n    \n    return full_preds, full_y_test, {d : (avg_test_score, avg_f1_test, avg_recall_test, avg_precision_score_test, oof_scores)}\n\n\ndef disease_prediction(d):\n    print('-' * 80)\n    print('Disease : %s'%d)\n    \n    skf = StratifiedKFold(n_splits = FOLDS, shuffle = True, random_state = SEED)\n    oof_preds = []\n    oof_aucs = []\n    oof_scores= []\n    ds_names = data_sets[d]\n    if len(ds_names) == 1:\n        pd_cont = pd_control.loc[pd_control['dataset_name'] == ds_names[0]]\n        pd_dis = pd_disease.loc[pd_disease['dataset_name'] == ds_names[0]]\n    else:\n        pd_cont = pd_control.loc[pd_control['dataset_name'] == ds_names[0]]\n        pd_dis = pd_disease.loc[(pd_disease['disease'] == d) & (pd_disease['dataset_name'] == ds_names[0])]\n        for ds in ds_names[1:]:\n            pd_cont = pd.concat([pd_cont, pd_control.loc[pd_control['dataset_name'] == ds]], axis = 0)\n            pd_dis = pd.concat([pd_dis, pd_disease.loc[(pd_disease['disease'] == d) & (pd_disease['dataset_name'] == ds)]], axis = 0)\n                \n    #     create dataset with all other diseases, target set to 0\n    pd_others = pd_disease.loc[(pd_disease['disease'] != d)]\n    target_others = pd_others['disease'].apply(lambda x: 1 if x == d else 0)\n    \n    #     combine controls and this particular disease back into train dataset\n    pd_train = pd.concat([pd_cont, pd_dis], axis = 0)\n\n    #     adding control data from healthy subject, data by HMP\n    pd_train = pd.concat([pd_train, pd_control.loc[pd_control['dataset_name'] == 'hmp']], axis = 0)\n    pd_train = pd.concat([pd_train, pd_control.loc[pd_control['dataset_name'] == 'hmpii']], axis = 0)\n\n    target = pd_train['disease']\n    #     convert text target into binary\n    binary_target = target.apply(lambda x: 1 if x == d else 0)\n    # binary_target.value_counts()\n    #     use only abundance features data for training\n    pd_others = pd_others[species] \n    pd_train  = pd_train[species] \n    #     this split provides us with preserved test set\n    disease_train, disease_test, disease_y_train, disease_y_test = train_test_split(pd_train, binary_target, test_size = 0.10, \n#                                                                                     stratify = binary_target,\n                                                                                    random_state = test_train_split_SEED)   \n        \n    #     combining preserved test set with othere diseases samples\n    full_test = pd.concat([disease_test, pd_others])\n    full_y_test = pd.concat([disease_y_test, target_others])\n    \n    disease_y_test.value_counts()\n    disease_y_train.value_counts()\n    preds = np.zeros(disease_y_test.shape[0])\n    full_preds = np.zeros(full_y_test.shape[0])\n\n    for fold, (idxT,idxV) in enumerate(skf.split(disease_train, disease_y_train)):\n\n        X_train = disease_train.iloc[idxT]\n        X_val = disease_train.iloc[idxV]\n        y_train = disease_y_train.iloc[idxT]\n        y_val = disease_y_train.iloc[idxV]\n    \n        XGB_model = XGBClassifier(n_estimators=5000, max_depth=None, \n                            learning_rate=0.05,\n                            objective='binary:logistic', \n                            metric='auc',\n                            verbosity  = VERBOSE,\n                            n_jobs=-1, random_state  = SEED)\n        \n        if show_fold_stats:\n            print('-' * 80)\n            print('Fold : %s'%(fold+1))\n    \n        XGB_model.fit(X_train, y_train,\n                        eval_set = [(X_val, y_val)],\n                        eval_metric=['logloss'],\n                        # eval_metric=['auc','logloss'],\n                        early_stopping_rounds = 100, verbose = VERBOSE )\n            \n        XGB_preds = XGB_model.predict_proba(X_val)\n        XGB_score = metrics.roc_auc_score(y_val, XGB_preds[:,1])\n        XGB_class = XGB_model.predict(X_val)\n        \n        XGB_test = XGB_model.predict_proba(disease_test)\n        XGB_test_score = metrics.roc_auc_score(disease_y_test, XGB_test[:,1])\n        XGB_test_class = XGB_model.predict(disease_test)\n        \n        full_test_preds = XGB_model.predict_proba(full_test)\n        full_test_score = metrics.roc_auc_score(full_y_test, full_test_preds[:,1])\n        full_test_class = XGB_model.predict(full_test)\n              \n        f1s = f1_score(y_val, XGB_class)\n        recall = metrics.recall_score(y_val, XGB_class)\n        precision_score = metrics.precision_score(y_val, XGB_class)\n        \n        f1_test = f1_score(disease_y_test, XGB_test_class)\n        recall_test = metrics.recall_score(disease_y_test, XGB_test_class)\n        precision_score_test = metrics.precision_score(disease_y_test, XGB_test_class)\n        \n        f1_full_test = f1_score(full_y_test, full_test_class)\n        recall_full_test = metrics.recall_score(full_y_test, full_test_class)\n        precision_full_test = metrics.precision_score(full_y_test, full_test_class)\n        \n        if show_fold_stats:        \n            print('ROC AUC score for XGBoost model valid set: %.4f'%XGB_score)\n            print('F1 score: %0.4f'%f1s)\n            print(confusion_matrix(y_val, XGB_class))\n    \n            print('ROC AUC score for XGBoost model test set: %.4f'%XGB_test_score)\n            print('F1 score: %0.4f'%f1_test)\n            print(confusion_matrix(disease_y_test, XGB_test_class))\n            \n            print('ROC AUC score for full test set including other diseases used as false controls: %.4f'%full_test_score)\n            print('F1 score: %0.4f'%f1_full_test)\n            print(confusion_matrix(full_y_test, full_test_class))\n\n        preds += XGB_test[:,1] / FOLDS\n        full_preds += full_test_preds[:,1] / FOLDS\n        \n        fold_score = [XGB_score,f1s,recall,precision_score, XGB_test_score,f1_test,recall_test,precision_score_test]\n        oof_scores.append({fold : fold_score})\n    \n    avg_test_score = metrics.roc_auc_score(disease_y_test, preds)\n    avg_class = np.where(preds < 0.5, 0, 1)\n    avg_f1_test = f1_score(disease_y_test, avg_class)\n    avg_recall_test = metrics.recall_score(disease_y_test, avg_class)\n    avg_precision_score_test = metrics.precision_score(disease_y_test, avg_class)\n\n    avg_full_test_score = metrics.roc_auc_score(full_y_test, full_preds)\n    avg_class_full = np.where(full_preds < 0.5, 0, 1)\n    avg_f1_test_full = f1_score(full_y_test, avg_class_full)\n    avg_recall_full_test = metrics.recall_score(full_y_test, avg_class_full)\n    avg_precision_full_test = metrics.precision_score(full_y_test, avg_class_full)\n\n    print('-' * 80)\n    print('Averaged over %i folds ROC AUC score for %s: %.4f'%(FOLDS,d,avg_test_score))\n    print('F1 : %.4f, Recall : %.4f , Precision : %.4f'%(avg_f1_test, avg_recall_test, avg_precision_score_test))\n    print('Confusion matrix for %s averaged across %i folds '%(d,FOLDS))\n    print(confusion_matrix(disease_y_test, avg_class))\n\n    \n    print('Averaged over %i folds ROC AUC score for %s against full set of other diseases: %.4f'%(FOLDS,d,avg_full_test_score))\n    print('F1 : %.4f, Recall : %.4f , Precision : %.4f'%(avg_f1_test_full, avg_recall_full_test, avg_precision_full_test))\n    print('Confusion matrix for %s averaged across %i folds for full set'%(d,FOLDS))\n    print(confusion_matrix(full_y_test, avg_class_full))\n\n    if do_plot_ROC:\n        (fpr, tpr, thresholds) = metrics.roc_curve(disease_y_test, preds)\n        plot_ROC(fpr, tpr, d)\n\n    return preds, disease_y_test, full_preds, full_y_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predictions\nWe'll use multiple random seeds to have variations with model initialization, and data splits. We will check if ensembling these multiple predictions will give us a better prediction, of if there will be a better seed."},{"metadata":{"trusted":true},"cell_type":"code","source":"SEEDs = [42,1970,1971,2020,2021]        \nd = 'cirrhosis'\nd_preds = []\ndf_preds = []\ndc_preds = []\nfor SEED in SEEDs:\n    print('=' * 80)\n    print('Seed : %i'%SEED)\n    d_pred, y_true, full_preds, full_y_test = disease_prediction(d) \n    d_preds.append(d_pred)\n    df_preds.append(full_preds)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So the model is able to perfectly predict cirrhosis in 'sysnthetic' case when it has to distinguish between healthy samples and samples with the disease. However it gets really confused when we mix 3 unknown diseases to the controls.<br>\nThe best case scenario we get is with seeds 1971 and 2021 giving us F1 = 0.6129 and Precision = 0.4524.<br>\n<br>\n"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print('Averaged predictions across %i seeds'%len(SEEDs))\navg_pred = np.array(d_preds).mean(axis= 0)\navg_class = np.where(avg_pred < 0.65, 0, 1)\nprint('Averaged over %i seeds ROC AUC score for %s : %.4f'%(len(SEEDs),d, metrics.roc_auc_score(y_true, avg_pred)))\nprint('F1 score : %.4f'%f1_score(y_true, avg_class))\nprint('Confusion matrix for %s'%d)\nprint(confusion_matrix(y_true, avg_class))\n\navg_pred = np.array(df_preds).mean(axis= 0)\navg_class = np.where(avg_pred < 0.5, 0, 1)\nprint('Averaged over %i seeds ROC AUC score for %s against full set of other diseases: %.4f'%(len(SEEDs),d, metrics.roc_auc_score(full_y_test, avg_pred)))\nprint('Confusion matrix for %s against controls and other diseases combined'%d)\nprint(confusion_matrix(full_y_test, avg_class))\nprint('F1 score : %.4f'%f1_score(full_y_test, avg_class))\nprint('Recall : %.4f'%metrics.recall_score(full_y_test, avg_class))\nprint('Precision : %.4f'%metrics.precision_score(full_y_test, avg_class))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Averaging results across all variants does not improve prediction in this case, model with the seed 2021 is still the best. <br>\nWe need significantly less correlated models in the ensemble for it to enhance the prediction.<br>\n<br>\nHowever if we adjust threshold of class separation to 0.88 then we get much better F1 and Precision by virtually eliminating false positives (and increasing number of false negatives at the same time, with Recall worsening as well). So as usual it comes to the decision of what is more important - Precision or Recall."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"avg_class = np.where(avg_pred < 0.88, 0, 1)\nprint('Averaged over %i seeds ROC AUC score for %s against full set of other diseases: %.4f'%(len(SEEDs),d, metrics.roc_auc_score(full_y_test, avg_pred)))\nprint('Confusion matrix for %s against controls and other diseases combined'%d)\nprint(confusion_matrix(full_y_test, avg_class))\nprint('F1 score : %.4f'%f1_score(full_y_test, avg_class))\nprint('Recall : %.4f'%metrics.recall_score(full_y_test, avg_class))\nprint('Precision : %.4f'%metrics.precision_score(full_y_test, avg_class))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Discriminate cirrhosis from other diseases in pairs\nAs it was discovered in the original paper diabetes is the most difficult to predict based off the abundance features, and I suspect that is what prohibiting the model to discriminate cirrhosis from other samples, and generates false positives. And we are going to check it in the next step."},{"metadata":{"trusted":true},"cell_type":"code","source":"dc_preds = []\nSEED = 1970\nprint('=' * 80)\nprint('Seed : %i'%SEED)\n\nfor counter in diseases:\n    if counter != d:\n        dc_pred, y_preds, _ = disease_distinction(d, counter)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we see the model is capable to distinguish cirrhosis from obesity and cancer with high precision. However diabetes leads to a significant number of false positives, lowering precision to about 50%.<br>\nWe will need to work on feature engineering to improve diabetes prediction. There is hope in usage of markers instead of/in conjunction with abundance features will help, as it's been shown in the original paper.<br>\nAnd of course there is room for improvement in the XGB model's hyper-parameters tuning, as I've used it with basic default parameters only yet."},{"metadata":{},"cell_type":"markdown","source":"# Conclusion\nUsing XGBoost defintely provides significant boost in precision of predicting cirrhosis in comparison with RF results published in the paper. "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}