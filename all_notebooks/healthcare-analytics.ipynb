{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# data processing, CSV file I/O (e.g. pd.read_csv)\n\ntrain=pd.read_csv('../input/medical-data/train.csv')\n#train.info()\n#target=train['Stay']\n#train=train.drop(['Stay'],axis=1)\ntest=pd.read_csv('../input/medical-data/test.csv')\n#print(train)\n#print(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train['Department']\n#test=pd.read_csv('../input/medical-data/test.csv')\ntrain","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''dept_list = train['Department'].unique()\ndept_list.sort()\ndept_dict = dict(zip(dept_list, range(len(dept_list))))\ntrain['Department'].replace(dept_dict, inplace=True)\ntrain['Department']\n\n\n'''\n\na=train['City_Code_Patient'].isnull().sum()\nb=train['Bed Grade'].isnull().sum()\nprint(b)\nprint(a)\n\n#i#=''\n#i.null()\n#c=zip(a,b)\n#for i,j in c:\n#    print(i.null(),j)\n#print(a.isnull().sum())\n#print(b.isnull().sum())\n#a=train['City_Code_Patient'].isnull() and train['Bed Grade'].isnull()\n\ntrain=train.drop(train[(train['City_Code_Patient'].isnull())|(train['Bed Grade'].isnull())].index,axis=0)\n#a=aa.index\n#aa=aa.drop(,axis=0)\n#print(aa.index)\ntrain","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in train.columns:\n    print(train[i].unique())\n#len(train['patientid'].unique())\n\n#drop patientid as it doesn't contain usefull information","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns \n#fig, (ax1, ax2) = plt.subplots(2, 1, sharex = True, figsize=(6,3))\n#ax1.hist(train.Time_Hr[df.Class==0],bins=48,color='g',alpha=0.5)\n#ax1.set_title('Genuine')\nsns.pairplot(train.iloc[:,:2])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nfrom yellowbrick.target import ClassBalance \nimport matplotlib.pyplot as plt \nplt.style.use(\"ggplot\")\nplt.rcParams['figure.figsize'] = (8,8)\n\n\nvisualizer=ClassBalance().fit(train.Stay)\nvisualizer.show()\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train=train.drop(['Bed Grade'],axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#target\n#We have drop the columns so don't need to do this step \n#If want to do this step then undo the previous step where we have \n#drop aall the nan values\n\n'''\ndef fill_null(df):\n  train['Bed Grade'].fillna(train['Bed Grade'].value_counts().index[0],inplace=True)\n  train['City_Code_Patient'].fillna(train['City_Code_Patient'].value_counts().index[0],inplace=True)\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fill_null(train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fill_null(test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#It is like LabelEncodung of a column\ndef convert_to_numerical(train):\n  dept_list = train['Department'].unique()\n  dept_list.sort()\n  dept_dict = dict(zip(dept_list, range(len(dept_list))))\n  train['Department'].replace(dept_dict, inplace=True)\n\n\n  hrc_list = train['Hospital_region_code'].unique()\n  hrc_list.sort()\n  hrc_dict = dict(zip(hrc_list, range(len(hrc_list))))\n  train['Hospital_region_code'].replace(hrc_dict, inplace=True)\n\n  ward_list = train['Ward_Type'].unique()\n  ward_list.sort()\n  ward_dict = dict(zip(ward_list, range(len(ward_list))))\n  train['Ward_Type'].replace(ward_dict, inplace=True)\n\n  wfc_list = train['Ward_Facility_Code'].unique()\n  wfc_list.sort()\n  wfc_dict = dict(zip(wfc_list, range(len(wfc_list))))\n  train['Ward_Facility_Code'].replace(wfc_dict, inplace=True)\n\n  toa_list = train['Type of Admission'].unique()\n  toa_list.sort()\n  toa_dict = dict(zip(toa_list, range(len(toa_list))))\n  train['Type of Admission'].replace(toa_dict, inplace=True)\n\n  soi_list = train['Severity of Illness'].unique()\n  soi_list.sort()\n  soi_dict = dict(zip(soi_list, range(len(soi_list))))\n  train['Severity of Illness'].replace(soi_dict, inplace=True)\n\n  age_list = train['Age'].unique() \n  age_list.sort()\n  age_dict = dict(zip(age_list, range(len(age_list))))\n  train['Age'].replace(age_dict, inplace=True)\n\n  htc_list = train['Hospital_type_code'].unique()\n  htc_list.sort()\n  htc_dict = dict(zip(htc_list, range(len(htc_list))))\n  train['Hospital_type_code'].replace(htc_dict, inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"convert_to_numerical(train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"convert_to_numerical(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#As we have done label encoding above so don.t need to calculate further \n\n'''\n#train['Age'].unique()\nfrom sklearn.preprocessing import LabelEncoder\nlb=LabelEncoder()\nfor i in train.columns:\n    train[i]=lb.fit_transform(train[i])\n    test[i]=lb.transform(test[i])\n#train=pd.get_dummies(train,drop_first=True)\n#test=pd.get_dummies(test,drop_first=True)\n\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train.iloc[:,5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#As we have completed fill null function above so don't need to complete using Imputer \n'''\n#train.info()\n#print(train)\nfrom sklearn.impute import SimpleImputer\nmy_imputer = SimpleImputer(strategy='mean')\ntrain_new = my_imputer.fit_transform(train.iloc[:,5:6])\ntest_new = my_imputer.fit_transform(test.iloc[:,5:6])\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train['City_Code_Patient']=train_new\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test['City_Code_Patient']=test_new\n#test_new=test\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target=train['Stay']\ntrain=train.drop(['Stay'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nlb=LabelEncoder()\ntarget=lb.fit_transform(target)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=train.drop(['case_id','patientid'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train,X_test,y_train,y_test=train_test_split(train,target,test_size=0.2)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc=StandardScaler()\nX_train=sc.fit_transform(X_train)\nX_test=sc.transform(X_test)\n#test_new=sc.transform(test_new)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from sklearn.preprocessing import Normalizer\n#nm=Normalizer()\n#X_train=nm.fit_transform(X_train)\n#X_test=nm.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from sklearn.decomposition import PCA\n#pvc=PCA(n_components=1)\n#X_train=pvc.fit_transform(X_train)\n#X_test=pvc.transform(X_test)\n#X_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n#ld=LDA(n_components=3)\n#X_train=ld.fit_transform(X_train,y_train)\n#X_test=ld.transform(X_test)\n#test_new=ld.transform(test_new)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from sklearn.linear_model import LinearRegression\n#from math import sqrt\n#from sklearn.metrics import mean_squared_error\n#rc=LinearRegression()\n#rc.fit(X_train,y_train)\n#predic=rc.predict(X_test)\n#print(sqrt(mean_squared_error(y_test,predic)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost\nfrom math import sqrt\nfrom sklearn.metrics import confusion_matrix\n#from sklearn.metrics import confusion_matrix\nclf = xgboost.XGBClassifier()\nclf.fit(X_train,y_train)\ny_testpred= clf.predict(X_test)\n\nrms = confusion_matrix(y_test, y_testpred)\nprint(\"RMSE:\", rms)\n#y_pred = clf.predict(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"caseid=test['case_id']\ntest=test.drop(['case_id','patientid'],axis=1)\ntest=sc.transform(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\nprint(accuracy_score(y_test, y_testpred))\n\nprediction=clf.predict(test)\nprediction=lb.inverse_transform(prediction)\noutput = pd.DataFrame({'case_id': caseid, 'Stay': prediction})\noutput.to_csv('New_Submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}