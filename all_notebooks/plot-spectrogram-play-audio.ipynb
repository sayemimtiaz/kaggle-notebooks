{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nsongs = []\ncwd = '/kaggle/input/birdsongs-from-europe/mp3/'\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        #print(os.path.join(dirname, filename))\n        songs.append(filename)\ndata = pd.read_csv('/kaggle/input/birdsongs-from-europe/metadata.csv')\nsongs.pop(0)\n\nprint(data.head())\nprint(data.info(verbose=True))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Playing MP3\nLets install and use pydub to play the MP3 files.\nYou're notebook will need internet access (see settings)."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"! pip install pydub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pydub import AudioSegment\nimport IPython\n\n# We will listen to this file:\n# 213_1p5_Pr_mc_AKGC417L.wav\nfile = '/kaggle/input/birdsongs-from-europe/mp3/Hirundo-rustica-361750.mp3'\nprint(cwd+songs[0])\nIPython.display.Audio(cwd+songs[2])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Convert MP3 into WAVs.\nThis process is modeled after the notebook [here](https://www.kaggle.com/rakibilly/extract-audio-starter).  \nWe must include files from the ffmpeg-static-build into our notebook, and unpack them.  \nThen we use the subprocess module to use ffmpeg to convert them to WAV\n\n###### Because my notebook environment has limited memory, lets only convert the first 50"},{"metadata":{"trusted":true},"cell_type":"code","source":"# https://www.kaggle.com/rakibilly/extract-audio-starter\nimport subprocess\nimport glob\nimport os\nfrom pathlib import Path\nimport shutil\nfrom zipfile import ZipFile","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"! tar xvf ../input/ffmpeg-static-build/ffmpeg-git-amd64-static.tar.xz","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert MP3s to WAV for easy conversion to numpy arrays:\noutput_format = 'wav'  # can also use aac, wav, etc\noutput_dir = Path(f\"{output_format}s\")\nPath(output_dir).mkdir(exist_ok=True, parents=True)\n\n#Only do first 50 because notebook memory limitations...\nfor song in songs[:50]:\n    file = cwd+song\n    file_name = song.replace(\".mp3\",\"\")\n    command = f\"../working/ffmpeg-git-20191209-amd64-static/ffmpeg -i {file} -ab 192000 -ac 2 -ar 44100 -vn {output_dir/file_name}.{output_format}\"\n    subprocess.call(command, shell=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Convert WAVs to numpy arrays\nThese data objects will be dictionaries that include the name of the original mp3 file, the sample rate, and left & right audio data."},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.io.wavfile import read, write\n#a = read(\"adios.wav\")\nwavs = []\nnp_arrays = []\nfor dirname, _, filenames in os.walk('/kaggle/working/wavs/'):\n    for filename in filenames:\n        wav_file = dirname+filename\n        #print(wav_file)\n        wavs.append(wav_file)\n        try:\n            fs, io_file = read(wav_file)\n        except ValueError:\n            continue\n        data = np.array(io_file,dtype=float)\n        wav_info= {\n            'name': filename,\n            'fs' : fs,\n            'left': data[:,0],\n            'right': data[:,1]\n        }\n        \n        np_arrays.append(wav_info)\n\nprint(\"Succesfully converted: \"+str(len(np_arrays)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plot & Play \nPlot a sample using a spectrogram (should really use wavelets) and then play the selected sample.\nLoad the song data you want to play from the generated numpy arrays (np_arrays).\nSelect the starting time in seconds (start), and ending time in seconds (end), or set to None if you want to play the whole file."},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy import signal\nfrom scipy.fft import fftshift\nimport matplotlib.pyplot as plt\n\nsong_data = np_arrays[26]\nstart = 0\nend = 10\n\nif end != None:\n    wav = song_data['left'][fs*start:fs*end]\nelse:\n    wav = song_data['left'][fs*start:]\nfs = song_data['fs']\nplt.specgram(wav,Fs=fs)\nplt.ylim(top=15000)\nprint(song_data['name'].replace(\".wav\",\"\"))\nplt.show() \n\nIPython.display.Audio(wav, rate=fs)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## To-Do: Denoise\nI suspect this should definitely be done with wavelet decomposition, not fourier methods."},{"metadata":{"trusted":true},"cell_type":"code","source":"! pip install pyyawt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load a noisy signal\n# Phylloscopus-collybita-171141\n\nsong_data = np_arrays[4]\nstart = 1\nend = 12\n\nif end != None:\n    wav = song_data['left'][fs*start:fs*end]\nelse:\n    wav = song_data['left'][fs*start:]\nfs = song_data['fs']\nplt.specgram(wav,Fs=fs)\nplt.ylim(top=15000)\nprint(song_data['name'].replace(\".wav\",\"\"))\nplt.show() \n\nIPython.display.Audio(wav, rate=fs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport pywt\nimport pyyawt\n\nstds = []\nmeans = []\ndecomps = []\nthrs = []\nwavelets = pywt.wavedec(wav, 'db5', level=10)\n\nfor i, wavelet in enumerate(wavelets):\n    thrs.append(pyyawt.thselect(wavelet, 'heursure'))\n    stds.append(wavelet.std(0))\n    means.append(wavelet.mean(0))\n    decomps.append(wavelet)\n    \n    #ax[i+1,0].plot(wavelet)\n    #ax[i+1,0].plot(wavelet)\n    #sns.distplot(wavelet, ax=ax[i+1,1], hist=False, vertical=True)\n\nthresholded = []\n\nfig, ax = plt.subplots(len(wavelets), figsize=(20,20))\n\n\nfor i, decomp in enumerate(decomps):\n    thresh =((np.amax(decomp)-means[i])*thrs[i])\n    print(thrs[i], np.amax(decomp), thresh)\n    thresholded.append(pywt.threshold(decomp, thresh, 'soft'))\n    ax[i].plot(wavelets[i])\n    ax[i].plot(thresholded[i])\n\nprint(\"Denoised: \"+song_data['name'].replace(\".wav\",\"\"))\nreconstructed = pywt.waverec(thresholded, 'db5')\nplt.specgram(reconstructed,Fs=fs)\nplt.show()\nIPython.display.Audio(reconstructed, rate=fs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}