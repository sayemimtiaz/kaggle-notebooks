{"cells":[{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n!python pytorch-xla-env-setup.py --version nightly --apt-packages libomp5 libopenblas-dev","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!export XLA_USE_BF16=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"!pip install efficientnet_pytorch","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Import Packages","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\nimport os\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image, ImageFile\n\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\n\nfrom sklearn import metrics\nfrom sklearn import model_selection\n\nimport torch_xla\nimport torch_xla.core.xla_model as xm\nimport torch_xla.distributed.parallel_loader as pl\nimport torch_xla.distributed.xla_multiprocessing as xmp\n\nfrom joblib import Parallel, delayed\nimport efficientnet_pytorch\nimport albumentations\nfrom tqdm import tqdm\n\nImageFile.LOAD_TRUNCATED_IMAGES = True","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create Kfolds","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/jpeg-melanoma-256x256/train.csv\")\ndf[\"kfold\"] = -1\ndf = df.sample(frac=1).reset_index(drop=True)\ny = df.target.values\nkf = model_selection.StratifiedKFold(n_splits=8)\nfor fold_, (train_idx, test_idx) in enumerate(kf.split(X=df, y=y)):\n    df.loc[test_idx, \"kfold\"] = fold_\ndf.to_csv(\"train_folds.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dataloader","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class ClassificationDataset:\n    def __init__(self, image_paths, targets, resize, augmentations=None):\n        self.image_paths = image_paths\n        self.targets = targets\n        self.resize = resize\n        self.augmentations = augmentations\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, item):\n        image = Image.open(self.image_paths[item])\n        targets = self.targets[item]\n        if self.resize is not None:\n            image = image.resize(\n                (self.resize[1], self.resize[0]), resample=Image.BILINEAR\n            )\n        image = np.array(image)\n        targets = np.array(targets)\n        if self.augmentations is not None:\n            augmented = self.augmentations(image=image)\n            image = augmented[\"image\"]\n        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n        return {\n            \"image\": torch.tensor(image, dtype=torch.float),\n            \"targets\": torch.tensor(targets, dtype=torch.long),\n        }","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class EfficientNet(nn.Module):\n    def __init__(self):\n        super(EfficientNet, self).__init__()\n        self.base_model = efficientnet_pytorch.EfficientNet.from_pretrained(\n            'efficientnet-b7'\n        )\n        self.base_model._fc = nn.Linear(\n            in_features=2560,\n            out_features=1,\n            bias=True\n        )\n\n    def forward(self, image, targets):\n        out = self.base_model(image)\n        loss = nn.BCEWithLogitsLoss()(out, targets.view(-1, 1).type_as(out))\n        return out, loss","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train function","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(data_loader=None, model=None, optimizer=None, scheduler=None, device=None):\n    model.train()\n    para_loader = pl.ParallelLoader(data_loader, [device])\n    tk0 = para_loader.per_device_loader(device)\n    for b_idx, data in enumerate(tk0):\n        for key, value in data.items():\n            data[key] = value.to(device)\n        optimizer.zero_grad()\n        _, loss = model(**data)\n        loss.backward()\n        xm.optimizer_step(optimizer, barrier=True)\n        scheduler.step(loss)\n        return loss.item()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Eval function","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate(\n        data_loader,\n        model,\n        device,\n):\n    model.eval()\n    with torch.no_grad():\n        para_loader = pl.ParallelLoader(data_loader, [device])\n        tk0 = para_loader.per_device_loader(device)\n        for b_idx, data in enumerate(tk0):\n            for key, value in data.items():\n                data[key] = value.to(device)\n            predictions, loss = model(**data)\n            predictions = torch.sigmoid(predictions)\n    return loss.item(), predictions\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train loop","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def run(fold):\n    training_data_path = \"../input/siic-isic-224x224-images/train/\"\n    df = pd.read_csv(\"./train_folds.csv\")\n    device = xm.xla_device()\n    epochs = 5\n    train_bs = 32\n    valid_bs = 16\n    mean = (0.485, 0.456, 0.406)\n    std = (0.229, 0.224, 0.225)\n    \n    df_train = df[df.kfold != fold].reset_index(drop=True)\n    df_valid = df[df.kfold == fold].reset_index(drop=True)\n    \n    model = EfficientNet()\n    model.to(device)\n    \n    train_aug = albumentations.Compose(\n        [\n            albumentations.Normalize(\n                mean, \n                std, \n                max_pixel_value=255.0, \n                always_apply=True\n            ),\n            albumentations.ShiftScaleRotate(\n                shift_limit=0.0625, \n                scale_limit=0.1, \n                rotate_limit=15\n            ),\n            albumentations.Flip(p=0.5)\n        ]\n    )\n\n    valid_aug = albumentations.Compose(\n        [\n            albumentations.Normalize(\n                mean, \n                std, \n                max_pixel_value=255.0,\n                always_apply=True\n            )\n        ]\n    )\n    \n    train_images = df_train.image_name.values.tolist()\n    train_images = [\n        os.path.join(training_data_path, i + \".png\") for i in train_images\n    ]\n    train_targets = df_train.target.values\n\n    valid_images = df_valid.image_name.values.tolist()\n    valid_images = [\n        os.path.join(training_data_path, i + \".png\") for i in valid_images\n    ]\n    valid_targets = df_valid.target.values\n\n    train_dataset = ClassificationDataset(\n        image_paths=train_images,\n        targets=train_targets,\n        resize=None,\n        augmentations=train_aug\n    )\n    \n    train_sampler = torch.utils.data.distributed.DistributedSampler(\n      train_dataset,\n      num_replicas=xm.xrt_world_size(),\n      rank=xm.get_ordinal(),\n      shuffle=True\n    )\n    \n    train_loader = torch.utils.data.DataLoader(\n        train_dataset,\n        batch_size=train_bs,\n        sampler=train_sampler,\n        drop_last=True,\n        num_workers=0\n    )\n    \n    valid_dataset = ClassificationDataset(\n        image_paths=valid_images,\n        targets=valid_targets,\n        resize=None,\n        augmentations=valid_aug\n    )\n    \n    valid_sampler = torch.utils.data.distributed.DistributedSampler(\n      valid_dataset,\n      num_replicas=xm.xrt_world_size(),\n      rank=xm.get_ordinal(),\n      shuffle=True\n    )\n    \n    \n    valid_loader = torch.utils.data.DataLoader(\n        valid_dataset,\n        batch_size=valid_bs,\n        sampler=valid_sampler,\n        drop_last=False,\n        num_workers=0\n    )\n    \n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n        optimizer,\n        patience=3,\n        threshold=0.001,\n        mode=\"min\"\n    )\n    \n    for epoch in range(epochs):\n        training_loss = train(\n            data_loader=train_loader,\n            model=model,\n            optimizer=optimizer,\n            device=device,\n            scheduler=scheduler,\n        )\n        \n        valid_loss, predictions = evaluate(\n            valid_loader,\n            model,\n            device,\n        \n        )\n        \n        xm.master_print(f\"Epoch = {epoch}, LOSS = {valid_loss}\")\n        gc.collect()\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def _mp_fn(rank, flags):\n    torch.set_default_tensor_type('torch.FloatTensor')\n    a = run(0)\n    \n\nFLAGS={}\nxmp.spawn(_mp_fn, args=(FLAGS,), nprocs=8, start_method='fork')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}