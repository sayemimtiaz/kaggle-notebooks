{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# COVID-Net CT Inference and Grad-CAM\nThis notebook provides some basic inference and visualization code for COVID-Net CT models. In particular, it includes example code for:\n1. Loading and preprocessing images\n2. Running inference on single images\n3. Computing and displaying Grad-CAM visualizations of the predicitions","metadata":{}},{"cell_type":"markdown","source":"## Initial setup\nCOVID-Net CT models can be downloaded automatically by selecting the appropriate model name. The model will be downloaded from its location on Google Drive using gdown, and will be placed in the `/kaggle/working` directory","metadata":{}},{"cell_type":"code","source":"# Model name\nMODEL_NAME = 'COVID-Net CT-2 S'\n\n# Model location\nMODEL_DIR = '/kaggle/working'\nMETA_NAME = 'model.meta'\nCKPT_NAME = 'model'\n\n# Model IDs in Google Drive\nMODEL_IDS = {\n    'COVID-Net CT-2 L': (\n        '1YQxVRYJ37nPSCtjUU9WWlXWRWYvZkKPl',\n        '1EgelTN_fyku2m2fALqpJvfjkuQ7Wqqdg',\n        '12BhWk_KiQ-hX--Qb7ASdPQTUOfOPccQE'),\n    'COVID-Net CT-2 S': (\n        '1zKTSxAhRrFhJxUnCcAf73WEZ7OcqvMre',\n        '1CSYekjpU1qYXxuOkjL0fBuzBIkvFXAqw',\n        '12uiQc5QePuqg2ErRF8llrL1vD9aFIiiJ')\n}\n\n# Data location\nIMAGE_DIR = '/kaggle/input/covidxct/2A_images'\nLABEL_FILE = '/kaggle/input/covidxct/val_COVIDx_CT-2A.txt'\n\n# Tensor names\nIMAGE_INPUT_TENSOR = 'Placeholder:0'\nTRAINING_PH_TENSOR = 'is_training:0'\nFINAL_CONV_TENSOR = 'resnet_model/block_layer4:0'\nCLASS_PRED_TENSOR = 'ArgMax:0'\nCLASS_PROB_TENSOR = 'softmax_tensor:0'\nLOGITS_TENSOR = 'resnet_model/final_dense:0'\n\n# Class names, in order of index\nCLASS_NAMES = ('Normal', 'Pneumonia', 'COVID-19')","metadata":{"execution":{"iopub.status.busy":"2021-06-24T19:47:11.066493Z","iopub.execute_input":"2021-06-24T19:47:11.066972Z","iopub.status.idle":"2021-06-24T19:47:11.076499Z","shell.execute_reply.started":"2021-06-24T19:47:11.066872Z","shell.execute_reply":"2021-06-24T19:47:11.075041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install tensorflow==1.15\n\n!pip install gdown\n!gdown --id {MODEL_IDS[MODEL_NAME][0]}\n!gdown --id {MODEL_IDS[MODEL_NAME][1]}\n!gdown --id {MODEL_IDS[MODEL_NAME][2]}","metadata":{"execution":{"iopub.status.busy":"2021-06-24T19:47:11.078725Z","iopub.execute_input":"2021-06-24T19:47:11.079046Z","iopub.status.idle":"2021-06-24T19:48:44.39843Z","shell.execute_reply.started":"2021-06-24T19:47:11.079014Z","shell.execute_reply":"2021-06-24T19:48:44.397079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2021-06-24T19:48:44.402597Z","iopub.execute_input":"2021-06-24T19:48:44.402984Z","iopub.status.idle":"2021-06-24T19:48:47.664971Z","shell.execute_reply.started":"2021-06-24T19:48:44.402946Z","shell.execute_reply":"2021-06-24T19:48:47.664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Useful functions\nThe functions below provide model loading, data loading and preprocessing, Grad-CAM, and inference capabilities.","metadata":{}},{"cell_type":"code","source":"def create_session():\n    \"\"\"Helper function for session creation\"\"\"\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    sess = tf.Session(config=config)\n    return sess\n\ndef load_graph(meta_file):\n    \"\"\"Creates new graph and session\"\"\"\n    graph = tf.Graph()\n    with graph.as_default():\n        # Create session and load model\n        sess = create_session()\n\n        # Load meta file\n        print('Loading meta graph from ' + meta_file)\n        saver = tf.train.import_meta_graph(meta_file, clear_devices=True)\n    return graph, sess, saver\n\ndef load_ckpt(ckpt, sess, saver):\n    \"\"\"Helper for loading weights\"\"\"\n    # Load weights\n    if ckpt is not None:\n        print('Loading weights from ' + ckpt)\n        saver.restore(sess, ckpt)\n\ndef load_labels(label_file):\n    \"\"\"Loads image filenames, classes, and bounding boxes\"\"\"\n    fnames, classes, bboxes = [], [], []\n    with open(label_file, 'r') as f:\n        for line in f.readlines():\n            fname, cls, xmin, ymin, xmax, ymax = line.strip('\\n').split()\n            fnames.append(fname)\n            classes.append(int(cls))\n            bboxes.append((int(xmin), int(ymin), int(xmax), int(ymax)))\n    return fnames, classes, bboxes\n\ndef load_and_preprocess(image_file, bbox=None, width=512, height=512):\n    \"\"\"Loads and preprocesses images for inference\"\"\"\n    # Load and crop image\n    image = cv2.imread(image_file, cv2.IMREAD_GRAYSCALE)\n    if bbox is not None:\n        image = image[bbox[1]:bbox[3], bbox[0]:bbox[2]]\n    image = cv2.resize(image, (width, height), cv2.INTER_CUBIC)\n\n    # Convert to float in range [0, 1] and stack to 3-channel\n    image = image.astype(np.float32) / 255.0\n    image = np.expand_dims(np.stack((image, image, image), axis=-1), axis=0)\n    \n    return image\n\n\ndef make_gradcam_graph(graph):\n    \"\"\"Adds additional ops to the given graph for Grad-CAM\"\"\"\n    with graph.as_default():\n        # Get required tensors\n        final_conv = graph.get_tensor_by_name(FINAL_CONV_TENSOR)\n        logits = graph.get_tensor_by_name(LOGITS_TENSOR)\n        preds = graph.get_tensor_by_name(CLASS_PRED_TENSOR)\n\n        # Get gradient\n        top_class_logits = logits[0, preds[0]]\n        grads = tf.gradients(top_class_logits, final_conv)[0]\n\n        # Comute per-channel average gradient\n        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n        \n    return final_conv, pooled_grads\n    \n\ndef run_gradcam(final_conv, pooled_grads, sess, image):\n    \"\"\"Creates a Grad-CAM heatmap\"\"\"\n    with graph.as_default():\n        # Run model to compute activations, gradients, predictions, and confidences\n        final_conv_out, pooled_grads_out, class_pred, class_prob = sess.run(\n            [final_conv, pooled_grads, CLASS_PRED_TENSOR, CLASS_PROB_TENSOR],\n            feed_dict={IMAGE_INPUT_TENSOR: image, TRAINING_PH_TENSOR: False})\n        final_conv_out = final_conv_out[0]\n        class_pred = class_pred[0]\n        class_prob = class_prob[0, class_pred]\n        \n        # Compute heatmap as gradient-weighted mean of activations\n        for i in range(pooled_grads_out.shape[0]):\n            final_conv_out[..., i] *= pooled_grads_out[i]\n        heatmap = np.mean(final_conv_out, axis=-1)\n\n        # Convert to [0, 1] range\n        heatmap = np.maximum(heatmap, 0)/np.max(heatmap)\n        \n        # Resize to image dimensions\n        heatmap = cv2.resize(heatmap, (image.shape[2], image.shape[1]))\n        \n    return heatmap, class_pred, class_prob\n\n    \ndef run_inference(graph, sess, images, batch_size=1):\n    \"\"\"Runs inference on one or more images\"\"\"\n    # Create feed dict\n    feed_dict = {TRAINING_PH_TENSOR: False}\n\n    # Run inference\n    with graph.as_default():\n        classes, confidences = [], []\n        num_batches = int(np.ceil(images.shape[0]/batch_size))\n        for i in range(num_batches):\n            # Get batch and add it to the feed dict\n            feed_dict[IMAGE_INPUT_TENSOR] = images[i*batch_size:(i + 1)*batch_size, ...]\n\n            # Run images through model\n            preds, probs = sess.run([CLASS_PRED_TENSOR, CLASS_PROB_TENSOR], feed_dict=feed_dict)\n\n            # Add results to list\n            classes.append(preds)\n            confidences.append(probs)\n\n    classes = np.concatenate(classes, axis=0)\n    confidences = np.concatenate(confidences, axis=0)\n\n    return classes, confidences\n\n\ndef stacked_bar(ax, probs):\n    \"\"\"Creates a stacked bar graph of slice-wise predictions\"\"\"\n    x = list(range(probs.shape[0]))\n    width = 0.8\n    ax.bar(x, probs[:, 0], width, color='g')\n    ax.bar(x, probs[:, 1], width, bottom=probs[:, 0], color='r')\n    ax.bar(x, probs[:, 2], width, bottom=probs[:, :2].sum(axis=1), color='b')\n    ax.set_ylabel('Confidence')\n    ax.set_xlabel('Slice Index')\n    ax.set_title('Class Confidences by Slice')\n    ax.legend(CLASS_NAMES, loc='upper right')","metadata":{"execution":{"iopub.status.busy":"2021-06-24T19:48:47.667822Z","iopub.execute_input":"2021-06-24T19:48:47.668149Z","iopub.status.idle":"2021-06-24T19:48:47.69586Z","shell.execute_reply.started":"2021-06-24T19:48:47.668114Z","shell.execute_reply":"2021-06-24T19:48:47.694864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading the model and checkpoint\nThis cell loads the graph and checkpoint, and also adds additional ops for producing Grad-CAM visualizations.","metadata":{}},{"cell_type":"code","source":"# Create full paths\nmeta_file = os.path.join(MODEL_DIR, META_NAME)\nckpt = os.path.join(MODEL_DIR, CKPT_NAME)\n\n# Load metagraph and create session\ngraph, sess, saver = load_graph(meta_file)\n\n# Load checkpoint\nwith graph.as_default():\n    load_ckpt(ckpt, sess, saver)\nfinal_conv, pooled_grads = make_gradcam_graph(graph)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T19:48:47.698768Z","iopub.execute_input":"2021-06-24T19:48:47.700181Z","iopub.status.idle":"2021-06-24T19:48:49.063447Z","shell.execute_reply.started":"2021-06-24T19:48:47.700134Z","shell.execute_reply":"2021-06-24T19:48:49.062446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inference with Grad-CAM\nThe image files may be set to any images you wish to test. Grad-CAM heatmaps will be computed for the predicted class to show which regions are being leveraged by the model during inference.","metadata":{}},{"cell_type":"code","source":"# Select image file\nidx = 22585\nfilenames, classes, bboxes = load_labels(LABEL_FILE)\nimage_file = os.path.join(IMAGE_DIR, filenames[idx])\ncls = classes[idx]\nbbox = bboxes[idx]","metadata":{"execution":{"iopub.status.busy":"2021-06-24T19:48:49.065213Z","iopub.execute_input":"2021-06-24T19:48:49.065587Z","iopub.status.idle":"2021-06-24T19:48:49.163674Z","shell.execute_reply.started":"2021-06-24T19:48:49.065551Z","shell.execute_reply":"2021-06-24T19:48:49.162486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Prepare image\nimage = load_and_preprocess(image_file, bbox)\n\n# Run Grad-CAM\nheatmap, class_pred, class_prob = run_gradcam(\n    final_conv, pooled_grads, sess, image)\n\n# Show image\nfig, ax = plt.subplots(1, 2, figsize=(10, 5))\nplt.subplots_adjust(hspace=0.01)\nax[0].imshow(image[0])\nplt.suptitle('Predicted Class: {} ({:.3f} confidence)\\nTrue Class: {}'.format(CLASS_NAMES[class_pred], class_prob, CLASS_NAMES[cls]))\nax[1].imshow(image[0])\nax[1].imshow(heatmap, cmap='jet', alpha=0.4)\n\nprint('**DISCLAIMER**')\nprint('Do not use this prediction for self-diagnosis. '\n      'You should check with your local authorities for '\n      'the latest advice on seeking medical assistance.')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-24T19:48:49.165531Z","iopub.execute_input":"2021-06-24T19:48:49.165985Z","iopub.status.idle":"2021-06-24T19:48:50.901843Z","shell.execute_reply.started":"2021-06-24T19:48:49.165934Z","shell.execute_reply":"2021-06-24T19:48:50.900347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}