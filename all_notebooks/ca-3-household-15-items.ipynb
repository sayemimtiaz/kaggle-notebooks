{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Model building and preprocessing","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Importing libraries","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport datetime as dt\nimport warnings\nwarnings.filterwarnings('ignore')\nimport tensorflow as tf\nfrom sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Reading data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"os.chdir('/kaggle/input/wallmart-sales/')\ntotal_value = pd.read_csv('total_value.csv')\ntotal_value.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.chdir('/kaggle/input/wallmart/')\ncal = pd.read_csv('calendar.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cal","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Pre-processing cal dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# One-hot encoding months\nmonth = pd.get_dummies(cal['month'],prefix='month',drop_first=True)\n\n# Dropping unecessary cols\ncal.drop(['wm_yr_wk', 'weekday','d', 'event_type_1', 'event_name_2', 'event_type_2', 'snap_TX', 'snap_WI'],1,inplace=True)\n\n# Handling events\ncal['event_name_1'] = cal['event_name_1'].fillna(0)\ncal['event_name_1'] = np.where(cal['event_name_1'] != 0,1,0)\n\n# One-hot encoding day of months\ncal['date'] = pd.to_datetime(cal['date'])\ncal['dayofmonth'] = cal['date'].dt.day     \ndom = pd.DataFrame(np.where(cal['dayofmonth']>=15,1,0),columns=['day_ge_15'])\n\n# One-hot encoding years\nyear = pd.get_dummies(cal['year'],prefix='year_',drop_first=True)\n\n# One-hot encoding weekdays\nwday = pd.get_dummies(cal['wday'],prefix='wday_',drop_first=True)\n\n# Combing and removing features\ncal.drop(['month','year','dayofmonth','wday'],1,inplace=True)\ncal = pd.concat([cal,month,year,dom,wday],axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Pre-processing total_value dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function for filtering california store 3 items\ndef california_store_3(item):\n    state = item.split('_')[3] \n    store_no = int(item.split('_')[4])\n    if (state == 'CA' and store_no == 3): \n        return True\n    else: \n        return False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"item_list = list(total_value.columns[:-1])\ncalifornia_store_3_item = filter(california_store_3, item_list)\ncalifornia_store_3_item_list = [i for i in california_store_3_item]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"california_store_3_df = total_value.loc[:,california_store_3_item_list]\ncalifornia_store_3_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Concatinating categorical variables\ncalifornia_store_3_df = pd.concat([cal.iloc[:1941,:],california_store_3_df],1)\ncalifornia_store_3_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"california_store_3_df['date'] = pd.to_datetime(california_store_3_df['date'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 3049 items\ncalifornia_store_3_last_1_year_df = california_store_3_df[california_store_3_df['date'] >='2015-02-22']\ncalifornia_store_3_last_1_year_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 3021 items\ncalifornia_store_3_last_1_year_df_without_Nas = california_store_3_last_1_year_df.dropna(axis=1)\ncalifornia_store_3_last_1_year_df_without_Nas.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Seperating HOUSEHOLD items","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fuction for filtering household\ndef california_store_3_household(item):\n    category = item.split('_')[0]\n    if (category == 'HOUSEHOLD'): \n        return True\n    else: \n        return False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_variables = list(california_store_3_last_1_year_df_without_Nas.columns[:26])\ncalifornia_store_3_last_1_year_without_Nas_item_list = list(california_store_3_last_1_year_df_without_Nas.columns[26:])\ncalifornia_store_3_last_1_year_without_Nas_item_household = filter(california_store_3_household, california_store_3_last_1_year_without_Nas_item_list)\ncalifornia_store_3_last_1_year_without_Nas_item_household_list = categorical_variables + [i for i in california_store_3_last_1_year_without_Nas_item_household]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"california_store_3_last_1_year_without_Nas_item_household_df = california_store_3_last_1_year_df_without_Nas.loc[:,california_store_3_last_1_year_without_Nas_item_household_list]\ncalifornia_store_3_last_1_year_without_Nas_item_household_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"master_df = california_store_3_last_1_year_without_Nas_item_household_df.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = go.Figure()\n\nfig.add_trace(go.Scatter(x=master_df.date, \n                         y=master_df.iloc[26:].sum(axis=1),\n                         mode='lines',\n                         name='pred'))\n   \nfig.update_layout(\n    autosize=False,\n    width=1000,\n    height=700,\n    margin=dict(\n        l=50,\n        r=50,\n        b=100,\n        t=100,\n        pad=4\n    ),\n    paper_bgcolor=\"LightSteelBlue\",\n    title=\"Walmart California store 3 food sales\",\n    xaxis_title=\"Date\",\n    yaxis_title=\"Sales\",\n    font=dict(\n        family=\"Courier New, monospace\",\n        size=18,\n        color=\"#042a30\"\n    )\n)\n\n\nfig.update_xaxes(rangeslider_visible=True)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = go.Figure()\n\nfig.add_trace(go.Scatter(x=master_df.date, \n                         y=master_df.iloc[:,26:26+15].sum(axis=1),\n                         mode='lines',\n                         name='pred'))\n   \nfig.update_layout(\n    autosize=False,\n    width=1000,\n    height=700,\n    margin=dict(\n        l=50,\n        r=50,\n        b=100,\n        t=100,\n        pad=4\n    ),\n    paper_bgcolor=\"LightSteelBlue\",\n    title=\"Walmart California store 3 household sales for 15 items\",\n    xaxis_title=\"Date\",\n    yaxis_title=\"Sales\",\n    font=dict(\n        family=\"Courier New, monospace\",\n        size=18,\n        color=\"#042a30\"\n    )\n)\n\n\nfig.update_xaxes(rangeslider_visible=True)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"master_df_15_items = master_df.iloc[:,:26+15]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## LSTM","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# loop for lstm\n\ncategorical_varibales = master_df_15_items.iloc[:,:26] \ntarget_variables = master_df_15_items.iloc[:,26:].columns\n\npredictions = pd.DataFrame(np.arange(1,29),columns=['index'])\nactual = pd.DataFrame(np.arange(1,29),columns=['index'])\n\nfor target_variable in target_variables:\n    \n    # Making dataset\n    dataset = pd.concat([categorical_varibales,master_df[target_variable]],1)\n\n    # Splitting train and test data\n    split_date = '2016-04-24'\n    Train = dataset.loc[dataset['date'] <= split_date].copy()\n    Test = dataset.loc[dataset['date'] > split_date].copy()\n    \n    # Dropping date\n    Train.drop(['date'],axis=1,inplace=True)\n    Test.drop(['date'],axis=1,inplace=True)\n    \n    x_train = Train.drop([target_variable],1)\n    y_train = Train[target_variable]\n    x_test = Test.drop([target_variable],1)\n    y_test = Test[target_variable]\n\n    #Create model layers\n    model = tf.keras.Sequential([\n        tf.keras.layers.LSTM(64,input_shape=(len(x_test.keys()),1)),\n        tf.keras.layers.Dense(1)\n    ])\n\n    #Choose optimizer\n    optimizer = tf.keras.optimizers.Adam()\n\n    #Compile model with mean squared error as loss function\n    model.compile(loss='mse',\n                  optimizer=optimizer,\n                  metrics=['mae', 'mse'])\n\n    # Number of epochs\n    EPOCHS = 10\n    early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n    history=model.fit(np.reshape(x_train.values, (x_train.shape[0], x_train.shape[1], 1))\n    , y_train,epochs=EPOCHS, validation_split = 0.2,callbacks=[early_stop], verbose=1)\n    \n    # Predictions\n    test_predictions = model.predict(np.reshape(x_test.values, (x_test.shape[0], x_test.shape[1], 1))).flatten()\n    print(f'{target_variable}:{metrics.mean_squared_error(test_predictions,y_test)}')\n\n    test_predictions = pd.DataFrame(test_predictions, columns=[target_variable])\n    predictions = pd.concat([predictions, test_predictions], 1)\n\n    y_test = pd.DataFrame(y_test.values, columns=[target_variable])\n    actual = pd.concat([actual, y_test], 1, ignore_index = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = go.Figure()\n\n\nfig.add_trace(go.Scatter(x=predictions.index, y=predictions.sum(axis=1),mode='lines',name='pred'))\n\nfig.add_trace(go.Scatter(x=predictions.index, y=actual.sum(axis=1),mode='lines',name='actual'))\n    \n    \nfig.update_layout(\n    autosize=False,\n    width=1000,\n    height=700,\n    margin=dict(\n        l=50,\n        r=50,\n        b=100,\n        t=100,\n        pad=4\n    ),\n    paper_bgcolor=\"LightSteelBlue\",\n    title=\"Walmart California store 3 household sales for 15 items\",\n    xaxis_title=\"Date\",\n    yaxis_title=\"Sales\",\n    font=dict(\n        family=\"Courier New, monospace\",\n        size=18,\n        color=\"#042a30\"\n    )\n)\n\n\nfig.update_xaxes(rangeslider_visible=True)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Arima","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Packages for arima\n!python3.7 -m pip install --upgrade pip\n!pip install pmdarima\nfrom pmdarima.arima import auto_arima","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# loop for arima\n\ntarget_variables = master_df_15_items.iloc[:,26:].columns\n\npredictions_ar = pd.DataFrame(np.arange(1,29),columns=['index'])\nactual_ar = pd.DataFrame(np.arange(1,29),columns=['index'])\n\nfor target_variable in target_variables:\n     \n    # Making dataset\n    dataset = master_df[target_variable]\n\n    # Splitting train and test data\n    df_arima_train = dataset[:-28]\n    y_test = dataset[-28:]    \n    \n    # Defining model\n    stepwise_model = auto_arima(df_arima_train,start_p=1,start_q=1,max_p=3,max_q=3,m=7,start_P=0,seasonal=True,d=1,D=1,trace=True,error_action='ignore',suppress_warnings=True,stepwise=True)\n\n    # Predictions\n    test_predictions = stepwise_model.predict(n_periods=28)\n    ar_day_rmse = np.sqrt(metrics.mean_squared_error(test_predictions, y_test))\n    print(f'{target_variable}th rmse:{ar_day_rmse}')\n\n    test_predictions = pd.DataFrame(test_predictions, columns=[target_variable])\n    predictions_ar = pd.concat([predictions_ar, test_predictions], 1)\n\n    y_test = pd.DataFrame(y_test.values, columns=[target_variable])\n    actual_ar = pd.concat([actual_ar, y_test], 1, ignore_index = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = go.Figure()\n\n\nfig.add_trace(go.Scatter(x=predictions.index, y=predictions_ar.sum(axis=1),mode='lines',name='pred_ar'))\n\nfig.add_trace(go.Scatter(x=predictions.index, y=actual_ar.sum(axis=1),mode='lines',name='actual'))\n    \n    \nfig.update_layout(\n    autosize=False,\n    width=1000,\n    height=700,\n    margin=dict(\n        l=50,\n        r=50,\n        b=100,\n        t=100,\n        pad=4\n    ),\n    paper_bgcolor=\"LightSteelBlue\",\n    title=\"Walmart California store 3 household sales for 15 items\",\n    xaxis_title=\"Date\",\n    yaxis_title=\"Sales\",\n    font=dict(\n        family=\"Courier New, monospace\",\n        size=18,\n        color=\"#042a30\"\n    )\n)\n\n\nfig.update_xaxes(rangeslider_visible=True)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}