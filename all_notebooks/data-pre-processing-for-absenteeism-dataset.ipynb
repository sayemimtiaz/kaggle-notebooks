{"cells":[{"metadata":{},"cell_type":"markdown","source":"Dataset: https://archive.ics.uci.edu/ml/datasets/Absenteeism+at+work here you can download dataset and description to it\n\nAlways we starting with data preprocessing: group of operations that will convert raw data into a format that is easier to understand and useful for further processing and analysis. Also helps organize information in suitable and practical way. It takes the most of the time and it is crucial part of every analytical ask. While preprocessing we make raw dataset usable for machine learning algorithm.","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rawdata = pd.read_csv('/kaggle/input/absenteeism-at-works/absenteeism.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After loading a data always Iâ€™m exploring it manually. It helps to have some first predictions. Sometimes it helps find some errors - even like importing wrong file ðŸ˜… and let us dive in into problem. Jupyter Notebook or JupyterLab dont let us see whole table so I can use:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.options.display.max_columns = None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rawdata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = rawdata.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ID - individual identification - indicates precisely who has been away during working hours. It is a label variable to distinguish the individuals from one another, not to carry any numeric information.\n\nWe have to drop variable â€œIDâ€ because it harm the estimation.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop(['ID'], axis = 1) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next column, Reason from Absence - we have to keep in mind that they are represent categories that are equally meaningful so they are categorical nominal variables. We use numbers and provide to them descriptions because using less characters will think the volume of our dataset, it's easier to digest, btw it is called â€œdatabase theoryâ€.\n\nExtracting distinct values only:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df['Reason for absence'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sorted(df['Reason for absence'].unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is no number â€™20â€™ in the list. That means that nobody left the work because of â€œExternal causes of morbidity and mortalityâ€ (we know from the additional info UCI_ABS_TEXT) phew! We have to change this variables into dummy variables. Dummy variable is an explanatory binary variable that equals 1 - if a certain categorical effect is present 0 - if the same effect is absent\n\nWe our data we will do like this: 1 - if person was absent because of reason 1 0 - if person was absent because any other reason\n\nnext: 1 - if person was absent because of reason 2 0 - if person was absent because any other reason\n\nFortunately I donâ€™t have to do it manually it is possible thanks to panda by simply .get_dummies()","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"rcol = pd.get_dummies(df['Reason for absence'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"rcolumn is new dataframe with 28 columns which contains information about which I wrote above.\n\nTo this data frame we can add another column where it will be sum:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"rcol['check'] = rcol.sum(axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rcol['check'].unique() #checking if for sure every person have only one reason ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In next stage I have to drop column â€˜0â€™ from rcolumn dataframe. I'm doing this to avoid multicollinearity. For n categories we using n-1 dummies so I am dealing with 28 categories so I need only 27 dummies. (https://www.quora.com/How-and-why-having-the-same-number-of-dummy-variables-as-categories-is-problematic-in-linear-regression-Dummy-variable-trap-Im-looking-for-a-purely-mathematical-not-intuitive-explanation-Also-please-avoid-using-the)\n\nIn original â€˜datasetâ€™ I still have column called â€˜Reason for absenceâ€™, if we will leave it we will have duplication of information which lead to multicollinearity. So lets drop this column from â€˜datasetâ€™. If we will add our â€˜rcolumnâ€™ into â€˜datasetâ€™ that means that we will have additional 27 columns in dataframe. A bit too much. Lets group these variables, this action we call classification. We will group basing on features descriptions: Reson1 1-14 diseases Reason2 15-17 - pregnancy related Reason 3 18 - 21 - poisonings Reason 4 22-28 - light reasons\n\nWe will create new data frame for each group. Thats why we needed to drop column with ID - because we need every individual have only one reason being out of work. So now we want to create a tables with only type of reason\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"rcol = rcol.drop(['check'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rcol = pd.get_dummies(df['Reason for absence'], drop_first = True) #drop reason '0'\nrcol","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop(['Reason for absence'], axis=1) #drop 'Reason for absence', replace with dummies. \ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# merging dummies into 4 categories based on reason for abscence\nreasontype1 = rcol.loc[:, 1:14].max(axis=1)\nreasontype2 = rcol.loc[:, 15:17].max(axis=1)\nreasontype3 = rcol.loc[:, 18:21].max(axis=1)\nreasontype4 = rcol.loc[:, 22:28].max(axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(reasontype1.sum(), reasontype2.sum(), reasontype3.sum(), reasontype4.sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.concat([df, reasontype1, reasontype2, reasontype3, reasontype4], axis = 1)\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Adding to data frame and rename it and then reordering columns because we want to see the reason first:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"column_names = ['Month of absence', 'Day of the week', 'Seasons',\n       'Transportation expense', 'Distance from Residence to Work',\n       'Service time', 'Age', 'Work load Average/day ', 'Hit target',\n       'Disciplinary failure', 'Education', 'Son', 'Social drinker',\n       'Social smoker', 'Pet', 'Weight', 'Height', 'Body mass index',\n       'Absenteeism time in hours', 'Reason1', 'Reason2', 'Reason3', 'Reason4']\ndf.columns = column_names\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reordered = ['Reason1', 'Reason2', 'Reason3', 'Reason4','Month of absence', 'Day of the week', 'Seasons',\n       'Transportation expense', 'Distance from Residence to Work',\n       'Service time', 'Age', 'Work load Average/day ', 'Hit target',\n       'Disciplinary failure', 'Education', 'Son', 'Social drinker',\n       'Social smoker', 'Pet', 'Weight', 'Height', 'Body mass index',\n       'Absenteeism time in hours']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df[reordered]\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creating a checkpoints - an interim save of your work","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"I called it df_mod1 which stands for modified dataframe version 1. It is very good practice to creating checkpoints - it is help to organize, storing the current version of code so we reducing risk of losing our data at a later stages. We donâ€™t have to do anything with date - month and the day of the week.\n\nLetâ€™s move to next columns: Transportation Expense, Distance, Age, Daily Work Load, BMI - we are not going to manipulate them too.\n\nWhat we have next is:\u2028 â€˜Educationâ€™\u2028(high school (1), graduate (2), postgraduate (3), master and doctor (4)) 'Sonâ€™ - Number of children â€˜Petâ€™ - Number of pets Columns â€˜Sonâ€™ and â€˜Petâ€™ we will leave untouched.\n\nWe have to change education into dummy variable. To not scroll down everything lets check what we have in â€˜educationâ€™ variable","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_mod1 = df.copy()\ndf_mod1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#correlation matrix\ncormatrix = df_mod1.corr()\nplt.subplots(figsize=(8, 8))\nsns.heatmap(cormatrix, vmin=-1, vmax=1, center= 0, cmap= 'coolwarm')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = cormatrix.nlargest(10, 'Absenteeism time in hours')['Absenteeism time in hours'].index\ncorrcoef = np.corrcoef(df_mod1[cols].values.T)\nplt.subplots(figsize=(8, 8))\nsns.heatmap(corrcoef, annot=True,  yticklabels=cols.values, xticklabels=cols.values, vmin=-1, vmax=1, center= 0,  cmap= 'coolwarm')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_mod2 = df_mod1.copy() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_mod2 = df_mod2.drop(['Month of absence','Distance from Residence to Work','Body mass index'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_mod2['Education'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_mod2['Education'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we can see that 611 is undergraduate and only 129 people holds higher degree (graduate, postgraduate, a master or a doctor) so it is not so relevant anymore. We can combine them in single category. We can assign undergraduate as 0 and at least graduate to 1: 1 -> 0 2 -> 1 3 -> 1 4 -> 1","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_mod2['Education'] = df_mod2['Education'].map({1:0, 2:1, 3:1, 4:1})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_mod2['Education'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Saving file as csv: ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"d_pre = df_mod2.copy()\nd_pre","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d_pre.to_csv('Absenteeism_preprocessed.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}