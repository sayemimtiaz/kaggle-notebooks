{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#preparing kaggle for pyspark\n!pip install pyspark","metadata":{"_uuid":"a4eef3ad-d80d-4033-bcbd-268303be618b","_cell_guid":"7c836b27-cc36-48ce-98b9-467c6376c8e6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# importing","metadata":{"_uuid":"fa6353c2-4aff-4a5b-9abe-6100963088f4","_cell_guid":"1e82ddbe-b994-4054-8697-f3172ec9ed51","trusted":true}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nsns.set_style('darkgrid')\nimport matplotlib.pyplot as plt\n\n\nfrom pyspark import SparkConf, SparkContext\nfrom pyspark.sql import SparkSession, SQLContext\n\nfrom pyspark.sql.types import *\nimport pyspark.sql.functions as F\nfrom pyspark.sql.functions import col\n\nfrom pyspark.ml.feature import StringIndexer\nfrom pyspark.ml.feature import OneHotEncoder\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml import Pipeline\n\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.classification import DecisionTreeClassifier\nfrom pyspark.ml.classification import RandomForestClassifier\nfrom pyspark.ml.classification import GBTClassifier\n\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\n\nprint(\"Import completed\")","metadata":{"_uuid":"75c45370-4b7c-4430-8ecc-00cdf58aa84b","_cell_guid":"f9ea3743-37eb-46f8-808b-ab58a9d83845","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# create spark session","metadata":{"_uuid":"d82ee34f-7e9b-4cb5-854e-39002f92bb67","_cell_guid":"4420c6a6-37a8-4cf9-a094-a60df22f1665","trusted":true}},{"cell_type":"code","source":"spark = SparkSession.builder.master(\"local\").appName(\"soddisfazione-passeggeri\").getOrCreate()\nsc = spark.sparkContext\nsqlContext = SQLContext(spark.sparkContext)\n\nprint(spark, sc, sqlContext)","metadata":{"_uuid":"d9ac6cde-90cd-4ebc-8a98-716765342bbc","_cell_guid":"53e2ee60-8c42-4939-9a0c-b1a5b5757172","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# IMPORTING DATASET","metadata":{"_uuid":"9c27e2d3-b3d6-484c-9d71-768c339c5d3e","_cell_guid":"7449217f-93b4-449a-be9c-a35d77a12c43","trusted":true}},{"cell_type":"code","source":"airline_test_dataset = \"../input/airline-passenger-satisfaction/test.csv\"\nairline_train_dataset = \"../input/airline-passenger-satisfaction/train.csv\"\n\nprint(\"Datasets imported\")","metadata":{"_uuid":"074791e1-8eb7-4224-98e8-391ff592332d","_cell_guid":"3aad71da-70f1-49ed-bc1d-6a119c847ef4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Merge test and train csv into a single dataframe","metadata":{}},{"cell_type":"code","source":"original_test_df = spark.read.csv(path=airline_test_dataset, inferSchema =True, header=True).cache()\noriginal_train_df = spark.read.csv(path=airline_train_dataset, inferSchema =True, header=True).cache()\n\n#merge test and train dataframes\nfull_df = original_test_df.union(original_train_df) \n\n#show a summary of dataframe\nfull_df.summary().show()","metadata":{"_uuid":"c60fb4d9-a192-4632-8d27-7649e2cd72c4","_cell_guid":"a4ca66bd-590b-4bd2-af97-1295917cd292","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data cleaning","metadata":{"_uuid":"a73b8cae-c8a2-4520-9054-f00d41187db1","_cell_guid":"39ba4cbb-4649-464b-9633-5ed2deb51542","trusted":true}},{"cell_type":"code","source":"#Clean the dataframe from id e number _c0 features, which are useless.\nfull_df = full_df.drop(\"_c0\",\"id\") \n\nprint(\"Cleaned\")","metadata":{"_uuid":"0cba2cb7-bcc9-4101-bc5d-c7f6f9851e5a","_cell_guid":"e5cd4695-4092-4275-9b35-57604c723323","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As shown in summary, all features have 129880 values, just **\"Arrival Delay in Minutes\"** has 129487. Its mean value is 15.09112883918849","metadata":{}},{"cell_type":"markdown","source":"> ","metadata":{}},{"cell_type":"code","source":"#Counting null values in Arrival Delay in Minutes\nfull_df.filter(col(\"Arrival Delay in Minutes\").isNull()).count()","metadata":{"_uuid":"76a1e274-9c59-422c-95da-b3046c630e9d","_cell_guid":"d8e389d9-685c-4dd5-9581-197b6f2124e2","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Fill missing arrival delay values with column mean\nfull_df = full_df.fillna({\"Arrival Delay in Minutes\":'15.1'})\n\nprint(\"Filled, now null values count is: \",full_df.filter(col(\"Arrival Delay in Minutes\").isNull()).count())","metadata":{"_uuid":"9d0e3aef-d94a-4a7e-b882-7b59bdb24be2","_cell_guid":"9dbf8f65-6898-47e7-bb23-77660277b8a0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Replace blank characters with underscore\nreplacements = {c:c.replace(' ','_') for c in full_df.columns if ' ' in c}\n\n#Replace satisfied with '1', neutral or dissatisfied with '0'\nfull_df = full_df.withColumn(\"satisfaction\", F.when(F.col(\"satisfaction\")==\"satisfied\", 1).otherwise(F.col(\"satisfaction\")))\nfull_df = full_df.withColumn(\"satisfaction\", F.when(F.col(\"satisfaction\")==\"neutral or dissatisfied\", 0).otherwise(F.col(\"satisfaction\")))\n\n#Cast String type of satisfaction column into Integer type\nfull_df = full_df.withColumn(\"satisfaction\",col(\"satisfaction\").cast(IntegerType()))\n\nprint(\"renamed\")\n\nfull_df.dtypes","metadata":{"_uuid":"9c0c188d-d4ac-4037-a938-dc036da0caae","_cell_guid":"65abe52d-7292-45b9-a293-9d23db774ffc","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Heatmap analysis ","metadata":{}},{"cell_type":"code","source":"pandas_full_df = full_df.toPandas()\nplt.figure(figsize=(13,13))\nsns.heatmap(abs(pandas_full_df.corr()), cmap = 'Blues', annot=True, fmt=\".2f\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize = (10,7))\nplt.scatter(pandas_full_df['Departure Delay in Minutes'], pandas_full_df['Arrival Delay in Minutes'], alpha = 0.1)\n\nplt.xlabel(\"Departure Delay in Minutes\")\nplt.ylabel(\"Arrival Delay in Minutes\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Arrival Delay in Minutes and Departure Delay in Minutes are highly correlated. One of them can be dropped","metadata":{}},{"cell_type":"code","source":"#Drop Arrival delay in minutes, since it is highly correlated with other column\n\nfull_df = full_df.drop(\"Arrival Delay in Minutes\") \n\nprint(\"dropped Arrival Delay in Minutes\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DATA Visualization","metadata":{}},{"cell_type":"markdown","source":"What influences satisfaction?","metadata":{}},{"cell_type":"code","source":"abs(pandas_full_df.corr()['satisfaction']).sort_values().drop('satisfaction').plot(kind='barh')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.express as px\nfig = px.sunburst(pandas_full_df, path=[\"satisfaction\",'Type of Travel','Class', 'Customer Type'],color_continuous_scale='RdBu')\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Age & Satisfaction","metadata":{}},{"cell_type":"code","source":"g= sns.FacetGrid(pandas_full_df,col=\"satisfaction\")\ng.map(sns.distplot,\"Age\",bins=25)\nplt.show()\n# 0=neutral or dissatisfied, 1=satisfied ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Missing categorical columns\npandas_full_df.hist(bins=50, figsize=(20,15))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Customer Type & Satisfaction","metadata":{}},{"cell_type":"code","source":"g=sns.catplot(x=\"Customer Type\",y=\"satisfaction\",data=pandas_full_df,kind=\"bar\",height=6, palette=\"Blues\")\ng.set_ylabels(\"Satisfaction Probability\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Class & Satisfaction","metadata":{}},{"cell_type":"code","source":"g=sns.catplot(x=\"Class\",y=\"satisfaction\",data=pandas_full_df,kind=\"bar\",height=6, palette=\"Blues\")\ng.set_ylabels(\"Satisfation Probability\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data types manipulation","metadata":{"_uuid":"5e4437d5-c688-42d3-bb83-9f11d9609517","_cell_guid":"f7c4da4f-3a53-418a-9eab-1bb265dc8059","trusted":true}},{"cell_type":"code","source":"#Rename the satisfaction column as label for easier manipulation\nfull_df = full_df.withColumnRenamed(\"satisfaction\",\"label\")\n\n#Merge train and test dataframes into a single one for easier manipulation\ntrain_df, test_df = full_df.randomSplit([0.7, 0.3], seed=30)\n\nprint(f\"Train set length: {train_df.count()} entries\")\nprint(f\"Test set length: {test_df.count()} entries\")","metadata":{"_uuid":"ca7d238a-198a-4813-be22-4380413231ba","_cell_guid":"5d7f2a87-8206-4867-b980-970b336112a3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Select only categorical features excluding the label satisfaction\ncatCols = [x for (x, dataType) in full_df.dtypes if ((dataType ==\"string\") & (x !=\"label\"))]\nnumCols = [x for (x, dataType) in full_df.dtypes if ((dataType !=\"string\") & (x !=\"label\"))]\n\nprint(catCols)\nprint(numCols)","metadata":{"_uuid":"e385db95-1202-4634-9afe-763c4ff89af9","_cell_guid":"d3602343-33b8-44e1-a2be-122798ccd408","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TRAIN TEST SPLIT","metadata":{"_uuid":"04548f92-2683-49c8-8fff-d5397f4ea4f5","_cell_guid":"370e8c31-c9c0-44a2-b6c8-fc7e480cc847","trusted":true}},{"cell_type":"code","source":"#recap of datatypes\ntrain_df.dtypes","metadata":{"_uuid":"8e8d6cba-8b5e-436b-8f8a-425254562cb9","_cell_guid":"b0650716-d322-4416-aefa-61843f40b3e1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Transform categorical variables\n\nLabel encoding assigns each unique value to a different integer.","metadata":{"_uuid":"b0381004-969e-46de-a5a1-1a9f7352a433","_cell_guid":"2eb9df86-bf1d-4754-bfa7-73fb123daa60","trusted":true}},{"cell_type":"markdown","source":"Import onehot encoder and string indexer. OnehotEncoder is used because I don't want the model to see some sort of unrelated ordering.","metadata":{}},{"cell_type":"code","source":"#from pyspark.ml.feature import (StringIndexer, OneHotEncoder)\n\nstring_indexer = [\n    StringIndexer(inputCol=x, outputCol=x + \"_StringIndexer\", handleInvalid=\"skip\")\n    for x in catCols\n]\nstring_indexer","metadata":{"_uuid":"603fd82f-1ccd-48d3-8241-68532838ea03","_cell_guid":"08069a30-d51d-49a3-bd79-953dc999cd21","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"one_hot_encoder = [\n    OneHotEncoder(\n        inputCols=[f\"{x}_StringIndexer\" for x in catCols],\n        outputCols=[f\"{x}_OneHotEncoder\" for x in catCols]\n    )\n]\n\none_hot_encoder","metadata":{"_uuid":"65df5786-5ae6-45fd-8955-30ffe9b64d5c","_cell_guid":"40c385d9-b4fe-41e7-9280-f57d906a4a21","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"vector assembler to be used by the machine model. transform all the features in a single vector\n","metadata":{}},{"cell_type":"code","source":"#from pyspark.ml.feature import VectorAssembler\n\nassemblerInput = [x for x in numCols]\nassemblerInput += [f\"{x}_OneHotEncoder\" for x in catCols]\n\nassemblerInput","metadata":{"_uuid":"54f5a5c8-1f1e-49d6-928f-34fe54591d83","_cell_guid":"1f3003c5-c258-49b8-b484-f56c8f05af04","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vector_assembler = VectorAssembler(\n    inputCols = assemblerInput, outputCol=\"features\"\n)\n\nvector_assembler","metadata":{"_uuid":"d598dd15-89d2-473d-96e6-67072d1f026b","_cell_guid":"52011b44-2bd9-418f-a74f-8a5007fee3c0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Logistic regression","metadata":{"_uuid":"33cfb5b4-c02d-433b-b965-e14e4fc59dd5","_cell_guid":"dd0a92a1-8c91-4b46-a8a0-9dc303b1d46d","trusted":true}},{"cell_type":"code","source":"#from pyspark.ml.classification import LogisticRegression\n\nlr = LogisticRegression()","metadata":{"_uuid":"9e2474d5-8fb8-4afe-944c-f42c85c20a6b","_cell_guid":"23443b5f-03f9-4c3c-b9d8-45a2a5afdc77","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pipeline creation","metadata":{"_uuid":"f0a01706-15c1-40d8-9685-4544405747a5","_cell_guid":"c00b7553-ffc2-4144-a1f0-67b0b079b55c","trusted":true}},{"cell_type":"code","source":"stages = []\nstages += string_indexer\nstages += one_hot_encoder\nstages += [vector_assembler , lr] #Must be inserted as list\n\nstages","metadata":{"_uuid":"ae6bb863-a427-447c-b032-c72297c2ed15","_cell_guid":"faef24f3-c69c-47a0-a0da-f58515470615","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#from pyspark.ml import Pipeline\n\npipeline = Pipeline().setStages(stages)\nmodel_pp_lr = pipeline.fit(train_df)\npredictions_pp_lr = model_pp_lr.transform(test_df)\n\nprint(\"pipeline completed\")","metadata":{"_uuid":"3e17562f-d3cb-499a-aad5-03154ea950d9","_cell_guid":"4e300d0a-2f15-4fa7-831f-e23a29b19a2c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_pp_lr.select(\"features\", \"rawPrediction\", \"probability\", \"prediction\",\"label\").show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# AUC","metadata":{}},{"cell_type":"code","source":"#show\npredictions_pp_lr.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"ROC evaluation with PySpark.","metadata":{}},{"cell_type":"code","source":"#from pyspark.ml.evaluation import BinaryClassificationEvaluator\n\nevaluator = BinaryClassificationEvaluator()\nprint('PySpark Area Under ROC', evaluator.evaluate(predictions_pp_lr))\nprint(\"Area Under PR: \" + str(evaluator.evaluate(predictions_pp_lr, {evaluator.metricName: \"areaUnderPR\"})))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_pp_lr.stages[-1].summary.pr.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n\nprint('Accuracy: ', MulticlassClassificationEvaluator(labelCol='label',metricName='accuracy').evaluate(predictions_pp_lr))\nprint('Precision: ',MulticlassClassificationEvaluator(labelCol='label',metricName='weightedPrecision').evaluate(predictions_pp_lr))\nprint('Recall: ',MulticlassClassificationEvaluator(labelCol='label',metricName='weightedRecall').evaluate(predictions_pp_lr))\nprint('f1: ',MulticlassClassificationEvaluator(labelCol='label',metricName='f1').evaluate(predictions_pp_lr))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainingSummary = model_pp_lr.stages[-1].summary\nroc = trainingSummary.roc.toPandas()\nplt.plot(roc['FPR'],roc['TPR'])\nplt.ylabel('False Positive Rate')\nplt.xlabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.show()\nprint('AreaUnderROC: ' + str(trainingSummary.areaUnderROC))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pr = trainingSummary.pr.toPandas()\nplt.plot(pr['recall'],pr['precision'])\nplt.ylabel('Precision')\nplt.xlabel('Recall')\nplt.title('PR Curve')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rmse = evaluator.evaluate(predictions_pp_lr)\nprint(\"RMSE: %g\" % rmse)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TREES ðŸŒ³","metadata":{"_uuid":"f5d6f104-bb42-4e18-8814-0585f24e7544","_cell_guid":"66defe2e-bf3b-4519-a7a0-acba72547cce","trusted":true}},{"cell_type":"markdown","source":"# ðŸŒ³ Decision tree classifier","metadata":{}},{"cell_type":"code","source":"#from pyspark.ml.classification import DecisionTreeClassifier\n\ndt = DecisionTreeClassifier(maxDepth = 3)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stages = []\nstages += string_indexer\nstages += one_hot_encoder\nstages += [vector_assembler , dt] \n\nstages","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipeline = Pipeline().setStages(stages)\nmodel_pp_dt = pipeline.fit(train_df)\npredictions_pp_dt = model_pp_dt.transform(test_df)\n\nprint(\"pipeline completed\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluator = BinaryClassificationEvaluator()\n\nprint(\"Area Under ROC: \" + str(evaluator.evaluate(predictions_pp_dt, {evaluator.metricName: \"areaUnderROC\"})))\nprint(\"Area Under PR: \" + str(evaluator.evaluate(predictions_pp_dt, {evaluator.metricName: \"areaUnderPR\"})))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Accuracy: ', MulticlassClassificationEvaluator(labelCol='label',metricName='accuracy').evaluate(predictions_pp_dt))\nprint('Precision: ',MulticlassClassificationEvaluator(labelCol='label',metricName='weightedPrecision').evaluate(predictions_pp_dt))\nprint('Recall: ',MulticlassClassificationEvaluator(labelCol='label',metricName='weightedRecall').evaluate(predictions_pp_dt))\nprint('f1: ',MulticlassClassificationEvaluator(labelCol='label',metricName='f1').evaluate(predictions_pp_dt))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rmse = evaluator.evaluate(predictions_pp_dt)\nprint(\"RMSE: %g\" % rmse)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ðŸŒ²ðŸŒ´ðŸŒ³ Random forest ","metadata":{}},{"cell_type":"code","source":"#from pyspark.ml.classification import RandomForestClassifier\n\nrf = RandomForestClassifier(featuresCol = 'features', labelCol = 'label')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stages = []\nstages += string_indexer\nstages += one_hot_encoder\nstages += [vector_assembler , rf]\n\nstages","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipeline = Pipeline().setStages(stages)\nmodel_pp_rf = pipeline.fit(train_df)\npredictions_pp_rf = model_pp_rf.transform(test_df)\n\nprint(\"pipeline completed\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluator = BinaryClassificationEvaluator()\n\nprint(\"Area Under ROC: \" + str(evaluator.evaluate(predictions_pp_rf, {evaluator.metricName: \"areaUnderROC\"})))\nprint(\"Area Under PR: \" + str(evaluator.evaluate(predictions_pp_rf, {evaluator.metricName: \"areaUnderPR\"})))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Accuracy: ', MulticlassClassificationEvaluator(labelCol='label',metricName='accuracy').evaluate(predictions_pp_rf))\nprint('Precision: ',MulticlassClassificationEvaluator(labelCol='label',metricName='weightedPrecision').evaluate(predictions_pp_rf))\nprint('Recall: ',MulticlassClassificationEvaluator(labelCol='label',metricName='weightedRecall').evaluate(predictions_pp_rf))\nprint('f1: ',MulticlassClassificationEvaluator(labelCol='label',metricName='f1').evaluate(predictions_pp_rf))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainingSummary = model_pp_rf.stages[-1].summary\nroc = trainingSummary.roc.toPandas()\nplt.plot(roc['FPR'],roc['TPR'])\nplt.ylabel('False Positive Rate')\nplt.xlabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.show()\n\nprint('AreaUnderROC: ' + str(trainingSummary.areaUnderROC))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pr = trainingSummary.pr.toPandas()\nplt.plot(pr['recall'],pr['precision'])\nplt.ylabel('Precision')\nplt.xlabel('Recall')\nplt.title('PR Curve')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rmse = evaluator.evaluate(predictions_pp_rf)\nprint(\"RMSE: %g\" % rmse)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ðŸŽ„ Gradient-boosted tree classifier","metadata":{}},{"cell_type":"code","source":"#from pyspark.ml.classification import GBTClassifier\n\ngbt = GBTClassifier(maxIter=10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stages = []\nstages += string_indexer\nstages += one_hot_encoder\nstages += [vector_assembler , gbt] \n\nstages","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipeline = Pipeline().setStages(stages)\nmodel_pp_gbt = pipeline.fit(train_df)\npredictions_pp_gbt = model_pp_gbt.transform(test_df)\n\nprint(\"pipeline completed\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluator = BinaryClassificationEvaluator()\n\nprint(\"Area Under ROC: \" + str(evaluator.evaluate(predictions_pp_gbt, {evaluator.metricName: \"areaUnderROC\"})))\nprint(\"Area Under PR: \" + str(evaluator.evaluate(predictions_pp_gbt, {evaluator.metricName: \"areaUnderPR\"})))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Accuracy: ', MulticlassClassificationEvaluator(labelCol='label',metricName='accuracy').evaluate(predictions_pp_gbt))\nprint('Precision: ',MulticlassClassificationEvaluator(labelCol='label',metricName='weightedPrecision').evaluate(predictions_pp_gbt))\nprint('Recall: ',MulticlassClassificationEvaluator(labelCol='label',metricName='weightedRecall').evaluate(predictions_pp_gbt))\nprint('f1: ',MulticlassClassificationEvaluator(labelCol='label',metricName='f1').evaluate(predictions_pp_gbt))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rmse = evaluator.evaluate(predictions_pp_gbt)\nprint(\"RMSE: %g\" % rmse)","metadata":{},"execution_count":null,"outputs":[]}]}