{"cells":[{"execution_count":null,"outputs":[],"metadata":{},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"execution_count":null,"outputs":[],"metadata":{},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom scipy import stats\nimport os, sys\npd.options.mode.chained_assignment = None # subpress some warnning\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")"},{"execution_count":null,"outputs":[],"metadata":{},"cell_type":"code","source":"from IPython.display import HTML\n\nHTML('''<script>\ncode_show=true; \nfunction code_toggle() {\n if (code_show){\n $('div.input').hide();\n } else {\n $('div.input').show();\n }\n code_show = !code_show\n} \n$( document ).ready(code_toggle);\n</script>\n<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')"},{"metadata":{},"cell_type":"markdown","source":"###  1) Load Data"},{"execution_count":null,"outputs":[],"metadata":{},"cell_type":"code","source":"full_data = pd.read_csv('../input/UCI_Credit_Card.csv')\nfull_data.rename(columns={'default.payment.next.month': 'dpnm'}, inplace=True)\nprint('data_origin.shape: ', full_data.shape)\nprint('data_target_value_counts:')\nprint(full_data['dpnm'].value_counts())\nfull_data.head()"},{"metadata":{},"cell_type":"markdown","source":"####  a) running next code，if not sampling"},{"execution_count":null,"outputs":[],"metadata":{"collapsed":true},"cell_type":"code","source":"data_origin = full_data"},{"metadata":{},"cell_type":"markdown","source":"#### b) running next code, if sampling"},{"execution_count":null,"outputs":[],"metadata":{},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE"},{"execution_count":null,"outputs":[],"metadata":{},"cell_type":"code","source":"X_sampled, Y_sampled = SMOTE().fit_sample(full_data.drop('dpnm', axis=1), full_data.dpnm)\nXY_sampled = np.append(X_sampled, Y_sampled.reshape(Y_sampled.shape[0], 1), axis=1)\n\ncata_variables = ['ID', 'AGE', 'EDUCATION', 'SEX', 'MARRIAGE', 'PAY_0','PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'dpnm']\nXY_sampled_m = pd.DataFrame(XY_sampled, columns=full_data.columns)\nXY_sampled_m[cata_variables] = XY_sampled_m[cata_variables].astype(int)\ndata_origin = XY_sampled_m\n\nprint('data_dimension after sampling: ')\nprint(data_origin.shape)"},{"metadata":{},"cell_type":"markdown","source":"###  2) Data Preproessing"},{"execution_count":null,"outputs":[],"metadata":{},"cell_type":"code","source":"from termcolor import colored\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pylab as plt\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import MinMaxScaler\n"},{"execution_count":null,"outputs":[],"metadata":{},"cell_type":"code","source":"print(colored('DATA_FEATURES: ', 'yellow'))\npd.DataFrame(data_origin.columns).T"},{"metadata":{},"cell_type":"markdown","source":"#### 1) Describe and reform category and quantitative data respectively:"},{"execution_count":null,"outputs":[],"metadata":{},"cell_type":"code","source":"def describe_factor(x_):\n    \"\"\"\n    describe data features, trying to find nan\n    :param x: dataframe\n    return: level conclusion\n    \"\"\"\n    level_count = dict()\n    \n    for lvl in x_.unique():\n        if pd.isnull(lvl):\n            level_count[\"NaN\"] = x_.isnull().sum()\n        else:\n            level_count[lvl] = np.sum(x_==lvl)\n    return level_count\n\nprint('Describe and reform category data:')\nprint('\\n')\nprint(colored('Sex:', 'red'))\nprint(describe_factor(data_origin['SEX']))\nprint(colored('Education: ', 'red'))\nprint(describe_factor(data_origin[\"EDUCATION\"]))\ndata_origin[\"EDUCATION\"] = data_origin[\"EDUCATION\"].map({0: np.NaN, 1:1, 2:2, 3:3, 4:np.NaN, \n    5: np.NaN, 6: np.NaN})\nprint(colored('For Education, (0, 5, 6) should be setted to be NA for further analysis, then;', 'yellow'))\nprint(describe_factor(data_origin[\"EDUCATION\"]))\nprint(colored('Marriage:', 'red'))\nprint(describe_factor(data_origin['MARRIAGE']))\ndata_origin.MARRIAGE = data_origin.MARRIAGE.map({0:np.NaN, 1:1, 2:2, 3:3})\nprint(colored('For Marriage, (0) should be setted to be NA for further analysis, then;', 'yellow'))\nprint(describe_factor(data_origin.MARRIAGE))"},{"execution_count":null,"outputs":[],"metadata":{"scrolled":false},"cell_type":"code","source":"print(\"Others are quantitative\")\nprint('\\n')\nprint('#'*8, ' CHECK NULL:  ', '#'*8)\nprint(data_origin.isnull().sum())"},{"metadata":{},"cell_type":"markdown","source":"#### 2） Imputation\n##### As you can see, we have replaced several levels with 'NAN' before, and the number of such 'NAN' is not really big, therefore we simply impute it using Mode imputation."},{"execution_count":null,"outputs":[],"metadata":{},"cell_type":"code","source":"data_origin[\"EDUCATION\"][data_origin[\"EDUCATION\"].isnull()] = data_origin[\"EDUCATION\"].mode().values\ndata_origin[\"MARRIAGE\"][data_origin[\"MARRIAGE\"].isnull()] = data_origin[\"MARRIAGE\"].mode().values\n\nprint('After imputation, check null: ')\nprint('the number of \"NAN\": ', data_origin.isnull().sum().sum())"},{"metadata":{},"cell_type":"markdown","source":"\n#### 3) Plot correlation between features\n##### From the plot below, we can notice that only 'PAY_0' has significant influence on our traget。 Also, bill_amout seems not influential at all"},{"execution_count":null,"outputs":[],"metadata":{"scrolled":false},"cell_type":"code","source":"corr = data_origin.drop(['ID'], axis=1).corr()\n\n# Generate a mask for the upper triangle\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(11, 9))\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\nplt.show()"},{"metadata":{},"cell_type":"markdown","source":"#### 4) Using RFE( Recursive features elemination) to select  influential features\n##### After applying RFE, only one feature has popped up, PAY_0, which is consistent with the result we have obtained from correlation plot"},{"execution_count":null,"outputs":[],"metadata":{},"cell_type":"code","source":"lr_raw_model = LogisticRegression()\nmmscale = MinMaxScaler()\nX_scaled = mmscale.fit_transform(full_data.iloc[:,1:-1])\nrfe_lr = RFE(lr_raw_model, 1)\nfit = rfe_lr.fit(X_scaled, full_data.dpnm)\nprint(\"Num Features:\",fit.n_features_)\nprint(\"Selected Features:\",fit.support_)\nprint(\"Feature Ranking: \",fit.ranking_)\nprint('\\n')"},{"metadata":{},"cell_type":"markdown","source":"#### 5) Discretize quantitative features using two methods: \n##### a) Decision tree;\n##### b) K-means.\n##### Before applying these two methods, we can think about for a minute. Decision tree classify samples based on there taget value, cause using GINI or ENTROPY, whereas K-means only cares about distances between samples without any reference to their target value.\n\n#### On the other hand, discretization may help us avoid outliers and unit-difference."},{"metadata":{},"cell_type":"markdown","source":"#### a) firstly, trying Decision_tree"},{"execution_count":null,"outputs":[],"metadata":{},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.tree import DecisionTreeClassifier,export_graphviz\n"},{"execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_kg_hide-input":true},"cell_type":"code","source":"import numpy as np\nimport math\nfrom scipy import stats\nfrom sklearn.utils.multiclass import type_of_target\n\nclass WOE:\n    def __init__(self):\n        self._WOE_MIN = -20\n        self._WOE_MAX = 20\n\n    def woe(self, X, y, event=1):\n        '''\n        Calculate woe of each feature category and information value\n        :param X: 2-D numpy array explanatory features which should be discreted already\n        :param y: 1-D numpy array target variable which should be binary\n        :param event: value of binary stands for the event to predict\n        :return: numpy array of woe dictionaries, each dictionary contains woe values for categories of each feature\n                 numpy array of information value of each feature\n        '''\n        self.check_target_binary(y)\n\n        res_woe = []\n        res_iv = []\n        for i in range(0, X.shape[-1]):\n            x = X[:, i]\n            woe_dict, iv1 = self.woe_single_x(x, y, event)\n            res_woe.append(woe_dict)\n            res_iv.append(iv1)\n        return np.array(res_woe), np.array(res_iv)\n\n    def woe_single_x(self, x, y, event=1):\n        '''\n        calculate woe and information for a single feature\n        :param x: 1-D numpy starnds for single feature\n        :param y: 1-D numpy array target variable\n        :param event: value of binary stands for the event to predict\n        :return: dictionary contains woe values for categories of this feature\n                 information value of this feature\n        '''\n        self.check_target_binary(y)\n\n        event_total, non_event_total = self.count_binary(y, event=event)\n        x_labels = np.unique(x)\n        woe_dict = {}\n        iv = 0\n        for x1 in x_labels:\n            y1 = y[np.where(x == x1)[0]]\n            event_count, non_event_count = self.count_binary(y1, event=event)\n            rate_event = 1.0 * (event_count + 1.0) / (event_total + 2.0)\n            rate_non_event = 1.0 * (non_event_count + 1.0) / (non_event_total + 2.0)\n            woe1 = math.log(rate_event / rate_non_event)\n            woe_dict[x1] = woe1\n            iv += (rate_event - rate_non_event) * woe1\n        return woe_dict, iv\n\n    def woe_replace(self, X, woe_arr):\n        '''\n        replace the explanatory feature categories with its woe value\n        :param X: 2-D numpy array explanatory features which should be discreted already\n        :param woe_arr: numpy array of woe dictionaries, each dictionary contains woe values for categories of each feature\n        :return: the new numpy array in which woe values filled\n        '''\n        if X.shape[-1] != woe_arr.shape[-1]:\n            raise ValueError('WOE dict array length must be equal with features length')\n\n        res = np.copy(X).astype(float)\n        idx = 0\n        for woe_dict in woe_arr:\n            for k in woe_dict.keys():\n                woe = woe_dict[k]\n                res[:, idx][np.where(res[:, idx] == k)[0]] = woe * 1.0\n            idx += 1\n\n        return res\n\n    def combined_iv(self, X, y, masks, event=1):\n        '''\n        calcute the information vlaue of combination features\n        :param X: 2-D numpy array explanatory features which should be discreted already\n        :param y: 1-D numpy array target variable\n        :param masks: 1-D numpy array of masks stands for which features are included in combination,\n                      e.g. np.array([0,0,1,1,1,0,0,0,0,0,1]), the length should be same as features length\n        :param event: value of binary stands for the event to predict\n        :return: woe dictionary and information value of combined features\n        '''\n        if masks.shape[-1] != X.shape[-1]:\n            raise ValueError('Masks array length must be equal with features length')\n\n        x = X[:, np.where(masks == 1)[0]]\n        tmp = []\n        for i in range(x.shape[0]):\n            tmp.append(self.combine(x[i, :]))\n\n        dumy = np.array(tmp)\n        # dumy_labels = np.unique(dumy)\n        woe, iv = self.woe_single_x(dumy, y, event)\n        return woe, iv\n\n    def combine(self, list):\n        res = ''\n        for item in list:\n            res += str(item)\n        return res\n\n    def count_binary(self, a, event=1):\n        event_count = (a == event).sum()\n        non_event_count = a.shape[-1] - event_count\n        return event_count, non_event_count\n\n    def check_target_binary(self, y):\n        '''\n        check if the target variable is binary, raise error if not.\n        :param y:\n        :return:\n        '''\n        y_type = type_of_target(y)\n        if y_type not in ['binary']:\n            raise ValueError('Label type must be binary')\n\n    def feature_discretion(self, X):\n        '''\n        Discrete the continuous features of input data X, and keep other features unchanged.\n        :param X : numpy array\n        :return: the numpy array in which all continuous features are discreted\n        '''\n        temp = []\n        for i in range(0, X.shape[-1]):\n            x = X[:, i]\n            x_type = type_of_target(x)\n            if x_type == 'continuous':\n                x1 = self.discrete(x)\n                temp.append(x1)\n            else:\n                temp.append(x)\n        return np.array(temp).T\n\n    def discrete(self, x):\n        '''\n        Discrete the input 1-D numpy array using 5 equal percentiles\n        :param x: 1-D numpy array\n        :return: discreted 1-D numpy array\n        '''\n        res = np.array([0] * x.shape[-1], dtype=int)\n        for i in range(5):\n            point1 = stats.scoreatpercentile(x, i * 20)\n            point2 = stats.scoreatpercentile(x, (i + 1) * 20)\n            x1 = x[np.where((x >= point1) & (x <= point2))]\n            mask = np.in1d(x, x1)\n            res[mask] = (i + 1)\n        return res\n\n    @property\n    def WOE_MIN(self):\n        return self._WOE_MIN\n    @WOE_MIN.setter\n    def WOE_MIN(self, woe_min):\n        self._WOE_MIN = woe_min\n    @property\n    def WOE_MAX(self):\n        return self._WOE_MAX\n    @WOE_MAX.setter\n    def WOE_MAX(self, woe_max):\n        self._WOE_MAX = woe_max"},{"execution_count":null,"outputs":[],"metadata":{},"cell_type":"code","source":"# using tree to discretize continous variables 'LIMIT_BAL' as an example.\n\nreg_labels = ['LIMIT_BAL', 'AGE', 'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1',\n       'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']\ndata_cut_dt = data_origin.copy()\ny = data_cut_dt['dpnm']  \ndt_model_ori = DecisionTreeClassifier(random_state=9, criterion='gini')\nparams_to_try = {'max_leaf_nodes': [5, 10, 15]}\n\ngrid_dt = GridSearchCV(dt_model_ori, params_to_try, n_jobs=-1, verbose=0)\ngrid_dt.fit(pd.DataFrame(data_origin['LIMIT_BAL']),y)\ngrid_dt.best_estimator_"},{"metadata":{},"cell_type":"markdown","source":"##### After trying different values of \"max_lead_nodes\", the tree always chooses the largest one. However, it is understandable that the gini coefficient becomes smaller when tree grows.\n##### So we try different values of 'max_lead_nodes' for each quantative feature, store their resulted IV and select the value where the diff (or derivatives) of IV dose not change much."},{"execution_count":null,"outputs":[],"metadata":{},"cell_type":"code","source":"# using decision tree to discretize the continuous variables.\n\nwoe_c = WOE() # function from tools\n\n\nmax_iv = []   \ngroup_numbers_to_try = [4, 5, 8, 9, 10, 12, 15]\n\nprint(colored('the resulted rolling differences or deriavtes of each IV for each label are: ', 'yellow'))\n\nfor label in reg_labels:\n    print('\\n')\n    print(colored('label: {}'.format(label), 'red'))\n    \n    iv_i = []\n    X_to_use = pd.DataFrame(data_cut_dt[label])\n    \n    for g_n in group_numbers_to_try:\n        dt_model = DecisionTreeClassifier(random_state=9, max_leaf_nodes=g_n, criterion='gini')\n        dt_model.fit(X_to_use, y)\n        X_pred_group_number = dt_model.apply(X_to_use, check_input=True)\n        iv_i.append(woe_c.woe_single_x(x=np.array(X_pred_group_number), y=y)[1]) #calculate iv for each feature and each tried value\n        \n    max_iv_i = np.argmax(iv_i) # the position of max iv for each feature\n    max_iv.append(max_iv_i)\n    print(np.diff(iv_i) / np.diff(group_numbers_to_try))"},{"metadata":{},"cell_type":"markdown","source":"#### from above, we choose leaf_nodes for 14 quantitative variables as  [5, 4, 10, 12, 15, 10, 10, 12, 8, 8, 12, 10, 8, 12]"},{"execution_count":null,"outputs":[],"metadata":{},"cell_type":"code","source":"# after selecting the best cut_lines mannually.\n\ncut_bins = [5, 4, 10, 12, 15, 10, 10, 12, 8, 8, 12, 10, 8, 12]\n\nfor i, label in enumerate(reg_labels):\n    X_to_use = pd.DataFrame(data_cut_dt[label])\n    \n    dt_model = DecisionTreeClassifier(random_state=9, max_leaf_nodes=cut_bins[i], criterion='gini')\n    dt_model.fit(X_to_use, y)\n    X_pred_group_number = dt_model.apply(X_to_use, check_input=True)\n    X_pred_group_number_uniq = np.unique(X_pred_group_number)\n    \n    for j in range(len(X_pred_group_number_uniq)):\n        data_cut_dt[label][X_pred_group_number == X_pred_group_number_uniq[j]] = j # convert label into 0,1,2,3,..."},{"execution_count":null,"outputs":[],"metadata":{"scrolled":true},"cell_type":"code","source":"data_cut_dt.head()"},{"metadata":{},"cell_type":"markdown","source":"##### then, we can calculate the IV for each feature after discretization"},{"execution_count":null,"outputs":[],"metadata":{},"cell_type":"code","source":"woes, iv = woe_c.woe(X=np.array(data_cut_dt.iloc[:,1:-1]), y=y)\n\nprint('IV for each feature after discretization: ')\npd.DataFrame(iv, index=data_cut_dt.iloc[:,1:-1].columns)"},{"metadata":{"collapsed":true},"cell_type":"markdown","source":"#### b) Secondly, we try K-means for dividing"},{"execution_count":null,"outputs":[],"metadata":{},"cell_type":"code","source":"from sklearn.cluster import KMeans"},{"metadata":{},"cell_type":"markdown","source":"##### here, we simply choose the same cutting group for each quantitative feature, with cut_bins = [5, 4, 10, 12, 15, 10, 10, 12, 8, 8, 12, 10, 8, 12]\n##### the resulted cutting points:"},{"execution_count":null,"outputs":[],"metadata":{"collapsed":true},"cell_type":"code","source":"def kmeans_cut(data_origin, labels, k):\n    \"\"\"\n    Using k-means to discretize continuous features\n    :param data_origin: original data_set\n    :param labels: column names which need discretization\n    :param k: the number of groups to be divided\n    :return: centers, cutting_points and transformed data\n    \"\"\"\n    data = data_origin.copy()\n\n    for label in labels:\n        k_model = KMeans(n_clusters=k)\n        k_model.fit(pd.DataFrame(data[label]))\n        cut_centers = pd.DataFrame(k_model.cluster_centers_).sort_values(0)\n        cutting_points = cut_centers.rolling(2).mean().iloc[1:]  # 相邻两项求重点，作为边界点\n\n        # get minimum point of cutting points\n        if data[label].min() > 0:\n            cutting_points = [0] + list(cutting_points[0]) + [data[label].max() + 1]\n        else:\n            cutting_points = [data[label].min()] + list(cutting_points[0]) + [data[label].max() + 10]\n\n        data_cut_group_label = pd.cut(data[label], bins=cutting_points, labels=range(k), right=False)\n        data[label] = data_cut_group_label\n    return cut_centers, cutting_points, data"},{"execution_count":null,"outputs":[],"metadata":{},"cell_type":"code","source":"# trying k-means distreriztion , see any difference\n\ndata_cut_kms = data_origin.copy()\n\nprint(colored('the resulted rolling differences or deriavtes of each IV for each label are: ', 'yellow'))\n\nfor i, label in enumerate(reg_labels):\n    c =[]\n    c.append(label) # convert label to be a list\n    \n    centers, cutting_points, resulted_data = kmeans_cut(data_cut_kms, c, k=cut_bins[i])\n    data_cut_kms = resulted_data.copy()\n    \n    print('\\n')\n    print('#'*10, label,':')\n    print(cutting_points)"},{"execution_count":null,"outputs":[],"metadata":{},"cell_type":"code","source":"data_cut_kms.head()"},{"metadata":{},"cell_type":"markdown","source":"##### Again, we can calculate the IV for each feature after discretization"},{"execution_count":null,"outputs":[],"metadata":{},"cell_type":"code","source":"woes, iv = woe_c.woe(X=np.array(data_cut_kms.iloc[:,1:-1]), y=y)\n\nprint('IV for each feature after discretization: ')\npd.DataFrame(iv, index=data_cut_kms.iloc[:,1:-1].columns)"},{"metadata":{},"cell_type":"markdown","source":"### 3)  Now, continue to modeling"},{"metadata":{},"cell_type":"markdown","source":"#### before modeling, you need to determine which discretization method to use and therefore the data used in model"},{"metadata":{},"cell_type":"markdown","source":"##### if using decisition tree, use following data"},{"execution_count":null,"outputs":[],"metadata":{},"cell_type":"code","source":"data_cut_dt.drop(['ID','SEX', 'MARRIAGE', 'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6'],\n                 axis=1, inplace=True)\n\n# delete SEX, MARRIAGE, BILL_AMOUNT\ndata_cut_X = data_cut_dt.iloc[:,:-1]\ndata_cut_Y = data_cut_dt.iloc[:,-1]"},{"metadata":{},"cell_type":"markdown","source":"##### if using k-means, use following data"},{"execution_count":null,"outputs":[],"metadata":{},"cell_type":"code","source":"data_cut_kms.drop(['ID','AGE', 'SEX', 'MARRIAGE', 'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6'], \n                  axis=1, inplace=True)\n\n# delete SEX, MARRIAGE, BILL_AMOUNT\ndata_cut_X = data_cut_kms.iloc[:,:-1]\ndata_cut_Y = data_cut_kms.iloc[:,-1]"},{"metadata":{"collapsed":true},"cell_type":"markdown","source":"#### 1) after choosing data, we need to split choosed data into training and testing data."},{"execution_count":null,"outputs":[],"metadata":{"collapsed":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedShuffleSplit"},{"execution_count":null,"outputs":[],"metadata":{"collapsed":true},"cell_type":"code","source":"def split_data(size, data_x, data_y):\n    \"\"\"\n    split full data into training and testing data\n    :param size: percentile for testing data\n    :param data_x: dataframe of full data\n    :param data_y: target\n    \"\"\"\n    sss = StratifiedShuffleSplit(n_splits=2, test_size=size, random_state=9)\n    split1, split2 = sss.split(data_x, data_y)\n    x_train, x_test = data_x.iloc[split1[0]], data_x.iloc[split1[1]]\n    Y_train, Y_test = data_y[split1[0]], data_y[split1[1]]\n    return x_train, x_test, Y_train, Y_test"},{"execution_count":null,"outputs":[],"metadata":{},"cell_type":"code","source":"# eliminate negative integers\n\npay_status = ['PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']\n\nfor pay in pay_status:\n    pay_value = data_cut_X[pay]\n    data_cut_X[pay][pay_value == -1] = 9\n    data_cut_X[pay][pay_value == -2] = 10\n\n# now split\nX_train, X_test, y_train, y_test = split_data(0.2, data_cut_X, data_cut_Y) # use 20% percentile testing data here"},{"execution_count":null,"outputs":[],"metadata":{},"cell_type":"code","source":"print(colored('FULL_X_DATA: ', 'green'))\nprint(data_cut_X.shape)\nprint(colored('X_TRAIN.shape: ', 'green'))\nprint(X_train.shape)\nprint(colored('X_TEST.shape: ', 'green'))\nprint(X_test.shape)"},{"metadata":{},"cell_type":"markdown","source":"#### 2)  applying one-hot encoder to all data_X"},{"execution_count":null,"outputs":[],"metadata":{"collapsed":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder"},{"execution_count":null,"outputs":[],"metadata":{},"cell_type":"code","source":"# one_hot encoder\n\none_hot = OneHotEncoder(sparse=True)\none_hot.fit(data_cut_X)\nX_train_oh = one_hot.transform(X_train)\nX_test_oh = one_hot.transform(X_test)\n\n#using dummy to get column names\nX_dummy = pd.get_dummies(X_train, columns=X_train.columns)\nnames = X_dummy.columns\nX_train_oh = pd.DataFrame(X_train_oh.toarray(), columns=names, index=X_train.index)\nX_test_oh = pd.DataFrame(X_test_oh.toarray(), columns=names, index=X_test.index)"},{"execution_count":null,"outputs":[],"metadata":{"scrolled":false},"cell_type":"code","source":"print(colored('After encodering: ', 'yellow'))\nprint(colored('X_TRAIN.shape: ', 'green'))\nprint(X_train_oh.shape)\nprint(colored('X_TEST.shape: ', 'green'))\nprint(X_test_oh.shape)"},{"metadata":{},"cell_type":"markdown","source":"#### 3) Let's try four models. the parameters of some models have not been optimised, but they work well."},{"execution_count":null,"outputs":[],"metadata":{"collapsed":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.svm import LinearSVC\nimport matplotlib.pylab as plt\nfrom sklearn.metrics import roc_auc_score, roc_curve, precision_score, recall_score, accuracy_score, auc, confusion_matrix, f1_score"},{"execution_count":null,"outputs":[],"metadata":{},"cell_type":"code","source":"# classifier to be tried.\n\nclfs = {'LogisticRegression':LogisticRegressionCV(Cs=10, scoring='recall', penalty='l1', solver='liblinear'),\n       'RandomForest': RandomForestClassifier(n_estimators=100),\n       'GradientBoosting': GradientBoostingClassifier(learning_rate= 0.05, max_depth= 6,\n                                                        n_estimators=200, max_features = 0.3,\n                                                        min_samples_leaf = 5)}"},{"metadata":{},"cell_type":"markdown","source":"#### fit the four models, calculate the metrics in cols, plot a roc curve and create a feature_importance dataframe for tree_based models"},{"execution_count":null,"outputs":[],"metadata":{},"cell_type":"code","source":"# original_oh = pd.read_csv(DATA_PATH + 'original_data_oh.csv').iloc[:,1:]\n\ncols = ['model', 'auc', 'precision_score', 'recall_score', 'f1_score', 'accuracy', 'train_score']\nmodels_report = pd.DataFrame(columns=cols)\nfeature_importance = pd.DataFrame()\nconf_matrix = dict()\n\nfor clf, clf_name in zip(clfs.values(), clfs.keys()):\n    # fit model\n    clf.fit(X_train_oh, y_train)\n    y_pred = clf.predict(X_test_oh)\n#     y_original_pred = clf.predict(original_oh)\n    y_score = pd.DataFrame(clf.predict_proba(X_test_oh)).iloc[:,1]\n#     y_original_score = pd.DataFrame(clf.predict_proba(original_oh)).iloc[:,1]\n\n    print('Computing{}'.format(clf_name))\n    \n    # add features importance\n    if (clf_name == 'RandomForest') | (clf_name == 'GradientBoosting'):\n        tmp_fi = pd.Series(clf.feature_importances_)\n        feature_importance[clf_name] = tmp_fi\n    \n    # calculate required metrics\n    tmp = pd.Series({\n                    'model': clf_name,\n                    'auc': roc_auc_score(y_test, y_score),\n                    'precision_score':precision_score(y_test, y_pred),\n                    'recall_score':recall_score(y_test, y_pred),\n                    'f1_score': f1_score(y_test, y_pred),\n                    'accuracy': accuracy_score(y_test, y_pred),\n                    'train_score': clf.score(X_train_oh, y_train),\n#                     'original_recall': recall_score(full_data.dpnm, y_original_pred),\n#                     'original_auc': roc_auc_score(full_data.dpnm, y_original_score),\n                    })\n    models_report = models_report.append(tmp, ignore_index = True)\n    conf_matrix[clf_name] = pd.crosstab(y_test, y_pred, rownames=['True'], colnames= ['Predicted'], margins=False)\n    \n    # plot roc\n    fpr, tpr, _ = roc_curve(y_test, y_score, drop_intermediate = False, pos_label = 1)\n    auc_value = auc(fpr, tpr)\n    \n    plt.figure(1, figsize = (9,9))\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver operating characteristic example')\n    plt.plot(fpr, tpr, lw=2, label=clf_name + '(area = %0.2f)' % auc_value)\n    plt.legend(loc=\"lower right\")\n    \nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.show()"},{"execution_count":null,"outputs":[],"metadata":{},"cell_type":"code","source":"print('models_report: ')\nmodels_report"},{"metadata":{},"cell_type":"markdown","source":"#### Feature importance"},{"execution_count":null,"outputs":[],"metadata":{},"cell_type":"code","source":"fi = feature_importance\nfeatures = X_train_oh.columns\nfi.index = features\nfi = fi.head(15) # Only take the 15 most important metrics\nfi = fi.sort_values('RandomForest', ascending=False)\nfi = (fi / fi.sum(axis=0)) * 100\nfi.plot.barh(title = 'Feature importances for Tree algorithms', figsize = (6,9))\nplt.show()"},{"metadata":{},"cell_type":"markdown","source":"### 4) take logistic regression as example for further analysis "},{"execution_count":null,"outputs":[],"metadata":{},"cell_type":"code","source":"# fit logistic regression model\n\nlrcv = LogisticRegressionCV(Cs=10, class_weight='balanced', scoring='recall', penalty='l1', solver='liblinear')\nlrcv.fit(X_train_oh, y_train)\nlrcv.C_  # c selected\n\nprint('scores for training data: ')\nprint(lrcv.score(X_train_oh, y_train))\nprint('scores for testing data: ')\nprint(lrcv.score(X_test_oh, y_test))"},{"execution_count":null,"outputs":[],"metadata":{"collapsed":true},"cell_type":"code","source":"def roc_curve_plot(classifier, data, y, event=1):\n    \"\"\"\n    plot rov curve and also calculate auc\n    :param classifier: defined and fitted classifier\n    :param data: data for calculating, dataframe\n    :param y: true target value for data\n    :return: auc value and plot\n    \"\"\"\n\n    y_pred = classifier.decision_function(data)\n\n    fpr, tpr, thresholds = roc_curve(y, y_pred, pos_label=event)\n    auc_value = auc(fpr, tpr)\n\n    # plot roc curve and caluculate auc\n    plt.figure(figsize=(10, 10))\n    lw = 2\n    plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % auc_value)\n    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver operating characteristic example')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n    return auc_value\n"},{"execution_count":null,"outputs":[],"metadata":{},"cell_type":"code","source":"# metrics for model performance examnation\nauc_v = roc_curve_plot(lrcv, X_train_oh, y_train)"},{"execution_count":null,"outputs":[],"metadata":{"collapsed":true},"cell_type":"code","source":"def ks_plot(y_true, y_prob):\n    \"\"\"\n    plot ks-curve and calculate ks value\n    :param y_true: true values of target y of samples\n    :param y_prob: predicted probability of been positive of samples\n    :return: ks curve plot ad ks value\n    \"\"\"\n    df = pd.concat((pd.DataFrame(np.array(y_prob[:, 0]), columns=['y_prob']),\n                    pd.DataFrame(np.array(y_true), columns=['y_true'])),\n                    axis=1)\n    df_sorted = df.sort_values(by='y_prob')  # sort by predicted probability of samples\n    y_prob_sorted = df_sorted.iloc[:, 0]\n    y_true_sorted = df_sorted.iloc[:, 1]\n    total_good_count = y_true.value_counts()[0]\n    total_bad_count = y_true.value_counts()[1]\n\n    cut_points = np.linspace(y_prob.min(), y_prob.max(), 31)  # thresholds\n    good_event_cdf = []\n    bad_event_cdf = []\n\n    # calculate cdf for good and bad event respectively.\n    for i, tr in enumerate(cut_points):\n        selected_data = y_true_sorted[y_prob_sorted <= tr]\n        good_event_count = sum(selected_data == 0)  # count good_event\n        bad_event_count = sum(selected_data == 1)  # count bad_event\n        good_event_cdf.append(good_event_count / total_good_count)\n        bad_event_cdf.append(bad_event_count / total_bad_count)\n\n    # calculate ks value\n    good_bad_diff = np.array(bad_event_cdf) - np.array(good_event_cdf)\n    ks_value = max(good_bad_diff)\n    ks_position = np.argmax(good_bad_diff).astype(int)\n\n    # plot curve\n    plt.figure(figsize=(10, 10))\n    lw = 2\n    plt.plot(cut_points, good_event_cdf, color='darkorange', lw=lw, label='good_event_cdf')\n    plt.plot(cut_points, bad_event_cdf, color='green', lw=lw, label='bad_event_cdf')\n    plt.plot([cut_points[ks_position], cut_points[ks_position]],\n             [good_event_cdf[ks_position], bad_event_cdf[ks_position]],\n             color='navy', lw=lw, linestyle='--')\n    plt.xlim([0.0, 1.3])\n    plt.ylim([0.0, 1.2])\n    plt.xlabel('thresholds')\n    plt.ylabel('cumulative rate')\n    plt.title('K-S plot')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n\n    return ks_value\n"},{"execution_count":null,"outputs":[],"metadata":{},"cell_type":"code","source":"# plot ks\n\nks_plot(y_test, lrcv.predict_proba(X_test_oh))"},{"execution_count":null,"outputs":[],"metadata":{},"cell_type":"code","source":"print(colored('resultes of metrics for logistic regression: ', 'yellow'))\nprint('accuracy_score: ')\nprint(accuracy_score(y_test,lrcv.predict(X_test_oh)))\nprint('recall_score: ')\nprint(recall_score(y_test,lrcv.predict(X_test_oh), pos_label=1))  #  tp / (tp + fn)\nprint('precision_score: ')\nprint(precision_score(y_test,lrcv.predict(X_test_oh), pos_label=1))  #  tp / (tp + fp)\nprint('f1_score: ')\nprint(f1_score(y_test, lrcv.predict(X_test_oh)))\nprint('confusion_matrix: ')\nconfusion_matrix(y_test,lrcv.predict(X_test_oh))\n# tn, fp, fn, tp = confusion_matrix(y_test,lrcv.predict(X_test_oh)).ravel()\n# print(tn, fp, fn, tp)"},{"execution_count":null,"outputs":[],"metadata":{},"cell_type":"code","source":"# from sklearn.metrics import precision_recall_curve\n# from sklearn.model_selection import cross_val_predict\n\n# y_scores = pd.DataFrame(cross_val_predict(lrcv, X_train_oh, y_train, cv=3, method='decision_function'))\n# precisions, recalls, thresholds = precision_recall_curve(y_train, y_scores)"},{"execution_count":null,"outputs":[],"metadata":{},"cell_type":"code","source":"# from sklearn.metrics import precision_recall_curve\n# from model.tools import *\n# plot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n# plt.show()"},{"metadata":{"collapsed":true},"cell_type":"markdown","source":"###  5) trying woe and iv methods"},{"metadata":{},"cell_type":"markdown","source":"#### replace discretized data with woe and split data into training and testing"},{"execution_count":null,"outputs":[],"metadata":{},"cell_type":"code","source":"# replace discretized data with woe\n\nwoes, iv = woe_c.woe(X=np.array(data_cut_X), y=y)\ndata_woe = pd.DataFrame(woe_c.woe_replace(X=np.array(data_cut_X), woe_arr=woes), index=data_cut_X.index, columns=data_cut_X.columns)\n\n# split data\nX_train, X_test, y_train, y_test = split_data(0.3, data_woe, data_cut_Y)"},{"metadata":{},"cell_type":"markdown","source":"#### fit logistic regression model"},{"execution_count":null,"outputs":[],"metadata":{},"cell_type":"code","source":"lrcv_woe = LogisticRegressionCV(Cs=10, class_weight='balanced', scoring='recall', penalty='l1', solver='liblinear')\nlrcv_woe.fit(X_train, y_train)\nlrcv_woe.C_  # C selected\nprint('scores for training data: ')\nprint(lrcv_woe.score(X_train, y_train))\nprint('scores for testing data: ')\nprint(lrcv_woe.score(X_test, y_test))"},{"metadata":{},"cell_type":"markdown","source":"#### plot roc and calculate auc"},{"execution_count":null,"outputs":[],"metadata":{},"cell_type":"code","source":"# plot ks\n\nauc_v = roc_curve_plot(lrcv_woe, X_test, y_test)"},{"execution_count":null,"outputs":[],"metadata":{},"cell_type":"code","source":"ks_plot(y_test, lrcv_woe.predict_proba(X_test))"},{"execution_count":null,"outputs":[],"metadata":{},"cell_type":"code","source":"print(colored('resultes of metrics for WOE logistic regression: ', 'yellow'))\nprint('WOE model')\nprint('accuracy_score: ')\nprint(accuracy_score(y_test,lrcv_woe.predict(X_test)))\nprint('recall_score: ')\nprint(recall_score(y_test,lrcv_woe.predict(X_test), pos_label=1))  #  tp / (tp + fn)\nprint('precision_score: ')\nprint(precision_score(y_test,lrcv_woe.predict(X_test), pos_label=1))  #  tp / (tp + fp)\nprint('f1_score: ')\nprint(f1_score(y_test, lrcv_woe.predict(X_test)))\nprint('confusion_matrix: ')\nconfusion_matrix(y_test,lrcv_woe.predict(X_test))"},{"execution_count":null,"outputs":[],"metadata":{"collapsed":true},"cell_type":"code","source":""}],"metadata":{"language_info":{"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","version":"3.6.1","codemirror_mode":{"version":3,"name":"ipython"},"pygments_lexer":"ipython3"},"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"}},"nbformat_minor":1,"nbformat":4}