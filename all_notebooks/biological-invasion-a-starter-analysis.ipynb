{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Biological invasion: a starter analysis\nHello Kagglers! Welcome to this starter notebook. At this opportunity, I present to you one of the most troubling issues in recent years.\n\nFirst of all, the [original data](https://catalog.data.gov/dataset/trends-in-non-native-aquatic-species-richness-in-the-united-states-reveal-shifting-pattern) was obtained in U.S. Environmental Protection Agency. This institution has the mission to protect human health and the environment. Credits for that institution and its works. \n\nThe [preprocessed data](https://www.kaggle.com/lazaro97/biological-invasions) you can find [here](https://www.kaggle.com/lazaro97/biological-invasions).\n\nSo, as indicated in its description:\n\n> Nonindigenous aquatic species introductions are widely recognized as major stressors to freshwater ecosystems, threatening native endemic biodiversity and causing negative impacts to ecosystem services as well as damaging local and regional economies. So, it's thus necessary to monitor the spatial and temporal trends and spread in order to guide prevention and control efforts and to develop effective policy aimed at mitigating impacts. (Michael J. Mangiante, 2018)\n\nFrom our perspective, these new species bring about a number of changes in the ecosystems, such as altering the structure and composition of plant communities; reducing agricultural productivity, wildlife, biodiversity, and fodder availability; changing soil structure; affecting health of us and livestock.\n\nYou can say \"Well, invasion is not a novel phenomenon; it always happens\". However, the biological invasion increases tremendously during the past few years because of rapidly expanding trade and transport among countries. And will grow even more because of globalization.\n\n![](http://muwo1.unibo.it/steamgreenuniboit/wp-content/uploads/sites/6/2017/07/inva.jpg)\n\nI think that it exist two possible solutions:\n\n1. Large corporations should take preventive measures in any transfer of resources between regions\n2. Search some spaciotemporal pattern and anticipate a possible new introduction\n\nEach one has their pros and cons. However, for bird and aquatic species are distinct. They arrive on their own, that detail complains the first solution. So, given the available information in the dataset, the latter is more feasible. But this case is difficult too, as there may be several cycle events, atypical data or lost data in the recollection. So, the establishment of forecasts is a challenge.\n\nNext I'll show you some basic ideas for this type of analysis. Below there are a descriptive analysis for find any spatial or temporal pattern. If there is any improvement in this code do not hesitate to comment it.\n\nFor more information, at the end of the notebook I'll mention some additional references. "},{"metadata":{"_uuid":"051d70d956493feee0c6d64651c6a088724dca2a","_execution_state":"idle","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n#Spatial libaries\nimport geopandas as gpd\nimport folium\nfrom folium import Choropleth, Circle, Marker\nfrom folium.plugins import HeatMap, MarkerCluster","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory analysis\n\nFirst, explore our dataset. In this step we will check if the information is ok and find any visible pattern. To do this it must be 1) make visualizations 2) integrate all sources of data 3) clean the data 4) consider to add new features.\n\nPreviously, the dataset was preprocessed, so this part is more directly. "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Get the data\nspat=pd.read_csv('../input/biological-invasions/dat_spatial.csv')\nspec=pd.read_csv('../input/biological-invasions/dat_species.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#How many null values are there?\nf, ax = plt.subplots(nrows=1, ncols=2, figsize=(20, 6))\nsns.heatmap(spec.isna(),cmap='cubehelix',yticklabels=False,cbar=False,ax=ax[0])\nsns.heatmap(spat.isna(),cmap='cubehelix',yticklabels=False,cbar=False,ax=ax[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The graph shows the number of null values per variable. The x-axis shows the name of the variable and the y-axis shows absence (white), or presence (black) of values for each variable.\n* Georeferenced information in dat_spatial has no null values.\n* As soon as group, family, dateobserved. Note that there are two large disjointed sets. So it is sensed that there is some special characteristic (or could not get that information) for each set.\n* The most appreciable thing is the recordedby variable. If the data description is reviewed, the variable indicates the discoverer, which is closely associated with the source where the observation was collected. So there are no drawbacks with removing it. However, if a study wanted to do more research into the methodology of extraction, it may be convenient to keep it."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Remove and fix null values\ndel spec['recordedBy']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Analyze numeric features\nspec['occurrence']=spec['occurrence'].astype('string') #Is a id, not a float. Although some ids gives information\nspec.select_dtypes(include=['float64','int64']).hist(color='blue',figsize=(10,8),bins=12)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Latitude and longitude are ok. Their distribution is logical and it can conclude that there is a greater agglomerment in a specific region.\n* Year is biased to the right. There's less information in the early years or there were very few species. For more information, review the used methodology of the institution.\n* On the huc features, it is logical that almost all areas are close to zero, and there are some that are very extensive."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Analize 'text' features\nspec.nativeregion.value_counts() #When I see this variable, I consider to define two values: possibly native or possibly foreign\ndef native_or_forecast(x):\n    if str(x).find(\"possibly native\")==-1: return('possibly native')\n    else: return('no native')\nprint(spec.nativeregion.apply(native_or_forecast).value_counts())\nplt.pie(spec.nativeregion.apply(native_or_forecast).value_counts(), autopct=\"%.1f%%\",pctdistance=0.5,shadow=True,colors=['darkblue','blue'],labels=['possibly native','no native'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Only claims that 10.7% is foreign. What about the other percentage? In general, what foreign (or native) area it comes from? \n\nRelative to this, a way is analyze the term, find many groups and makes a plot. Ex: Define dichotomic variables: europe, south america, african, asian,australian,.. and if your native region is that, its value is 1, else 0."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Analyze categorical features\nanimal=spec[spec.kingdom=='Animal']\n#sns.countplot(animal.group)\n\nprint(\"What's the animal group more common ?\")\nprint(animal.group.value_counts()[:4]) #Obviously, the fishes\nanimal=animal[animal.group=='Fishes']\n#What's the fisshes family more common ?\nan=animal.family.value_counts()[:4].keys()\nsns.countplot(animal[animal['family'].isin(an)].family, palette=\"Blues_r\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note that each observation is defined in a spacio temporal plane. So maybe this graphs are skewed. Ideally, you should choose an intersection between space and time and then select a particular species (or family). In any case, the above graphs may give a global view of what happened."},{"metadata":{},"cell_type":"markdown","source":"# Temporal features"},{"metadata":{"trusted":true},"cell_type":"code","source":"#A paper suggest this separation too\ndef gyear(x): #Cut the date\n    if x<=1900: return('1600-1900')\n    elif x<=1930: return('1901-1930')\n    elif x<=1950: return('1931-1950')\n    elif x<=1970: return('1951-1970')\n    elif x<=1990: return('1971-1990')\n    else: return('1991-2016')\nspec['gyear']=spec['year'].apply(gyear)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Arrival of species from 1600 to 2016')\nprint(spec.gyear.value_counts()) #Maybe, from 1676 to 1900 should be considered as outliers\nprint('Which species came first?')\nprint(spec[spec.year<1800].sciname.value_counts().keys()) #\nspec=spec[spec.gyear!='1600-1900'] #Remove that values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Time series of occurrence from 1901 to 2016\nfrom collections import Counter\nsns.set_style(\"whitegrid\")\ndef temporal_trend(text,col):  #Return a plot where appears a respective specie. Color can be removed as input\n    specie=spec[(spec.sciname==text)]\n    temporal=Counter(specie.year) # Temporal variation, In the plants kingdom there are months too\n    #spatial=Counter(specie.state) #Spatial variation\n    sns.lineplot(temporal.keys(),temporal.values(),color=col)\ntemporal_trend('Phalaris arundinacea','red')\ntemporal_trend('Cyprinus carpio','blue')\ntemporal_trend('Salmo trutta','green')\ntemporal_trend('Phragmites australis','black')\n# All species\n#for i in spec.sciname.unique()[:10]:\n#    temporal_trend(i,'red') ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Exists an anomaly between 2005 and 2015. That's weird, i'm not sure if I would have to think of it as an cycle variation or if it's really a part of the trend variation."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Another opcion: In generally, considering all species\ntemporal=Counter(spec.year)\nsns.lineplot(temporal.keys(),temporal.values(),sort=True,color='magenta') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#I think that I should show them how to process the date features. Previously, in the original dataset, the format was distinct between the items\n\ndef preprocess_date(x): #Varies depending on the species chosen. Should return same datetime format\n    if len(str(x))<11:return pd.to_datetime(x, format='%m-%d-%Y')\n    else: return pd.to_datetime(str(x)[:10], format='%Y-%m-%d')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"specie=spec[spec.sciname=='Phalaris arundinacea'] #Select only one specie. Select all species is possible too\nspecie['date']=specie['dateobserved'].apply(preprocess_date) \nfrom statsmodels.tsa.seasonal import seasonal_decompose\ndecomp = seasonal_decompose(specie.date, period=300, model='additive', extrapolate_trend='freq')\nspecie['trend'] = decomp.trend\nspecie[\"seasonal\"] = decomp.seasonal\nfig,ax=plt.subplots(2,1)\nsns.lineplot(specie.year,specie.trend,sort=True,color='darkred',ax=ax[0])\nsns.lineplot(specie.year,specie.seasonal,sort=True,color='darkblue',ax=ax[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.graphics.tsaplots import plot_acf\nfrom statsmodels.graphics.tsaplots import plot_pacf\n\nf, ax = plt.subplots(nrows=2, ncols=1, figsize=(9, 4.5))\n\nplot_acf(specie['date'], lags=100, ax=ax[0]) #Heavy decay\nplot_pacf(specie['date'], lags=100, ax=ax[1])\n\nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Spatial features"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Geopandas DataFrame. Deal with space features\nfrom shapely import wkt\nspat['geometry'] = spat['geometry'].apply(wkt.loads)\nspat = gpd.GeoDataFrame(spat, geometry = 'geometry')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#At any given time\nspec_2015=spec[spec.year==2015] #Just this year\npoints=spec_2015[['decimalLat', 'decimalLon']]\npoints = gpd.GeoDataFrame(points, geometry=gpd.points_from_xy(points.decimalLon, points.decimalLat)) #Elements to add\n#ax = spat.plot(figsize=(20,20), color='none', edgecolor='black', zorder=1) #boundary\n#points.plot(color='blue', ax=ax) This graph is confused..","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#..How to fix it?\n#USA have many unincorporated territories in their control (https://en.wikipedia.org/wiki/Unincorporated_territories_of_the_United_States)\n#Remove states with many islands. Some states have many islands in their control (https://en.wikipedia.org/wiki/List_of_islands_of_the_United_States_by_area)\nspatg=spat #backup\nspat=spat[-spat.name.isin(['Hawaii','Alaska'])] #sum(spec.state=='alaska') Also, no elements\n#Now plot the map\nax = spat.plot(figsize=(20,20), color='none', edgecolor='black', zorder=1) #boundary\npoints.plot(color='blue', ax=ax) #Elements to add","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"You can see in which areas appeared most aquatic species in 2015"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now add a temporal variation too\nspec_t1=spec[spec.gyear=='1600-1900']\nspec_t2=spec[spec.gyear=='1901-1930']\nspec_t3=spec[spec.gyear=='1931-1950']\nspec_t4=spec[spec.gyear=='1951-1970']\nspec_t5=spec[spec.gyear=='1971-1990']\nspec_t6=spec[spec.gyear=='1991-2016']\n#for i in spec['gyear'].values: lst.append(spec[spec.year==i])\ndef plot_map(df):\n    points = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.decimalLon, df.decimalLat))\n    ax = spat.plot(figsize=(20,20), color='none',edgecolor='black', zorder=1) #Same boundary\n    points.plot(color='blue', ax=ax) #In same boundary\n#plot_map(spec_t1)\n#plot_map(spec_t6)\n#Maybe this is not interpetable but it can shows how today there are several species compared to before \n#I think that the ideal is per year(or per day), not for a large range. I suggest build a dynamic plot\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Define the observations and features that you want to analyze\n#Species #Clearly, is convenient define the plot based on a specific specie \npl_2001=spec[(spec.sciname=='Phalaris arundinacea')&(spec.year==2001)]\nsalmo_2001=spec[(spec.sciname=='Salmo trutta')&(spec.year==2001)]\n#Boundary\nspat_s = spat[[\"name\", \"geometry\"]].set_index(\"name\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Build a map interactive\n#Point spatial process\nm_point = folium.Map(location=[41,-82], tiles='cartodbpositron', zoom_start=4.2) #Define the map\n \nfor i in range(0,len(pl_2001)):  #Add points\n    folium.Circle(\n      location=[pl_2001.iloc[i]['decimalLat'], pl_2001.iloc[i]['decimalLon']],\n      radius=pl_2001.iloc[i]['huc12skm'],  #I consider the area of HUC12. See the bubble\n      color='green',\n      fill=True,\n      fill_color='green').add_to(m_point)\n    \nfor i in range(0,len(salmo_2001)): #Also, is possible add other species\n    folium.Circle(\n      location=[salmo_2001.iloc[i]['decimalLat'], salmo_2001.iloc[i]['decimalLon']],\n      radius=salmo_2001.iloc[i]['huc12skm'],\n      color='blue',\n      fill=True,\n      fill_color='blue').add_to(m_point)\n\nm_point","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m_heatmap = folium.Map(location=[41,-82], tiles='cartodbpositron', zoom_start=4) #Again, define the map\nHeatMap(data=salmo_2001[['decimalLat', 'decimalLon']], radius=10).add_to(m_heatmap) #Also, it's possible define a heatmap\n#HeatMap(data=pl_2001[['decimalLat', 'decimalLon']], radius=10).add_to(m_heatmap)\nm_heatmap","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#For the discrete case is neccesary to define the number of events per region\nplot_dict = salmo_2001.state.value_counts() \ns=pd.DataFrame(plot_dict).reset_index()\ns.columns=['name','count']\n#Join tables\ndat=pd.merge(s,spat,on='name',how='inner')\ndat=dat.fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m_choropleth = folium.Map(location=[41,-82], tiles='cartodbpositron', zoom_start=4) #map\nChoropleth(geo_data=spat_s.__geo_interface__, #In generally, add layers (or caractheristics)\n           data=plot_dict, \n           key_on=\"feature.id\", \n           fill_color='YlGn', \n           legend_name='Major presence of Phalaris arundinacea (Jan-Dec 2001)'\n          ).add_to(m_choropleth)\nm_choropleth","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Build a dynamic map\nspec_e=spec[(spec.year>1900)&(spec.year<1971)]  #Only until 1970. Sorry, I couldn't optimize this part of the code, it took a long time if it was considered more years. If you consider more dates, remember the high rise betwwn 2005 and 2015\n#spec_e=spec_e[spec_e.sciname=='Salmo trutta'] #You can choose an specific specie\nplot_dict = spec_e[['state','year']].value_counts() #Transform to a discrete case. See the spatiotemporal index\ns=pd.DataFrame(plot_dict).reset_index()\ns.columns=['name','year','events'] #Same name of columns\n\nspatg = spatg[[\"iso_code\",\"name\", \"geometry\"]]\nspatg.iso_code=spatg.iso_code.apply(lambda x: str(x)[3:]) #In this case, the spatial code should be different \n\n#Join tables\ndat=pd.merge(s,spatg,on='name',how='inner')\ndat=dat.sort_values(by='year', ascending=True).reset_index()\ndel dat['index']\ndat","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.merge(spatg[['name','iso_code']],dat.year,how='cross') #I added zero values for the map. Maybe there's an alternative way\ndatf=pd.merge(dat,df,on=['name','year'],how='outer')\ndatf['events']=datf['events'].fillna(0) #Region without species should be 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install plotly","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px\nfig = px.choropleth(datf,                          \n                     locations='iso_code_y', locationmode='USA-states',     # identify country code column\n                     color=\"events\",                     # identify representing column\n                     animation_frame=\"year\",        # identify date column\n                     scope='usa',                #shows only this country\n                     color_continuous_scale= 'Ylgn', \n                     range_color=[0,datf.events.max()])             \nfig.write_html(\"historic-invasion.html\") \nfig.show() #It can looks better. Maybe it's better to use a point process","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclussions\n\n* The areas where new species are received most were identified. Obviously, there should be more agglomeration on the maritime boundaries. However, the graph also shows which of these limtrofes regions received the most species. That regions were California, Florida, Maine, New Jersey and Wisconsin.\n* California always keep in mind several aquatic species.\n* The number of species in USA get higher while the time goes on, but this change was slight.\n* In the dynamic graph, i analyze it in general way, maybe it's convenient to take just one specie. See the up and down in some states of the map.\n* A idea now would be to establish some model that determines what the cloropleth map will look like after a few years.\n* And no less important.. the maps and graphs are adaptable to any phenomenon. For example, you could analyze the human invasion, the spread of covid19, the occurrence of criminal acts, etc."},{"metadata":{},"cell_type":"markdown","source":"# Additional resources\n\n**Notebooks:**\n* https://www.kaggle.com/andreshg/timeseries-analysis-a-complete-guide\n* https://www.kaggle.com/umerkk12/geo-animation-of-vaccination\n* https://www.kaggle.com/learn/geospatial-analysis\n* https://www.kaggle.com/dbennett/test-map\n\n**Papers:**\n* http://www.aquaticinvasions.net/2018/issue3.html\n* https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6209226/"},{"metadata":{},"cell_type":"markdown","source":"## Any task for this dataset?\n\n* **Define some insights:** Maybe, the rate of increase per year, the neigborhood effect, first apparition, foreign area where it comes, etc.\n* **Make an interactive dashboard:** Showing results visually is more eye-catching and interpetative, making it easier to make decisions in a certain way.\n* **Build a spatiotemporal model:** The main objective is to predict the appearance of new species based on historical and spatial data. You can use a neural network or the bayesian theory.\n* **Realize a spatial (or temporal) analysis:** No combining, so it's more practical.\n* **Suggest some ideas in data staging**: More technical. I've always seen drawbacks in big data management. I think maybe by adding other data sources, you can get a more correct analysis.\n* **Cycle variation from 2005 to 2015**: Honestly, I'm not sure how to interpret the high rise in 2005, if it could already control that cycle variation, then is necessary to remove it from the analysis?\n\nThat'all! Thanks for read this notebook. Now, is your turn. Choose a task and have fun!\n\n**PD:** Don't forget to review and suport my [kaggle dataset](https://www.kaggle.com/lazaro97/biological-invasions). That motivates me to keep doing similar projects"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}