{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n#matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# read the data\nflights = pd.read_csv('../input/feb-2020-us-flight-delay/feb-20-us-flight-delay.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"flights.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Format\n* **MONTH** - Month\n* **DAY_OF_MONTH** - Day of Month\n* **DAY_OF_WEEK** - Day of Week\n* **OP_UNIQUE_CARRIER** - Unique Carrier Code\n* **ORIGIN** - Origin airport location\n* **DEST** - Destination airport location\n* **DEP_TIME** - Actual Departure Time (local time: hhmm)\n* **DEP_DEL15** - Departure Delay Indicator, 15 Minutes or More (1=Yes, 0=No) [TARGET VARIABLE]\n* **DISTANCE** - Distance between airports (miles)"},{"metadata":{"trusted":true},"cell_type":"code","source":"flights.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"flights['Unnamed: 9'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* 'Unnamed: 9' is an extra-empty column, so we will get rid of it."},{"metadata":{"trusted":true},"cell_type":"code","source":"flights.drop('Unnamed: 9', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"flights.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data preprocessing and visualization:"},{"metadata":{"trusted":true},"cell_type":"code","source":"flights.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Rename the DEP_DEL15 to is_dealy\nflights.rename(columns={'DEP_DEL15':'is_delay'}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Look for null values\nflights.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'\\'is_delay\\' missing values are {100*4951/flights.shape[0]}%')\nprint(f'\\'DEP_TIME\\' missing values are {100*4938/flights.shape[0]}%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* The missing 'is_delay' values represent only 0.86%, so we can safely remove them.\n* The same thing applies for 'DEP_TIME', the missing is ~0.86%."},{"metadata":{},"cell_type":"markdown","source":"**Note:** As will start to do some preprocessing and cleaning, we will make a new copy of the data to work on without changing the original one."},{"metadata":{"trusted":true},"cell_type":"code","source":"data = flights.copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### - Remove the missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualization"},{"metadata":{},"cell_type":"markdown","source":"### - Delay vs No Delay"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x=data['is_delay'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.groupby('is_delay').size()/len(data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We see that the data is highly imbalanced; 85.6% is 'no delay' vs 14.4% 'delay' flights.**"},{"metadata":{},"cell_type":"markdown","source":"### Now there are some questions we need to ask:\n\n* What day of the week has the most delays?\n* Which origin and destination airports have the most delays?\n* Is flight distance a factor in the delays?\n* Which carrier has the most delays?"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='DAY_OF_WEEK', hue=\"is_delay\", data=data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Number of Origin airports is {data.ORIGIN.nunique()}')\nprint(f'Number of Dest airports is {data.DEST.nunique()}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- We are goning to create a dataframe for 'Origin' and 'Dest' as the plot will be not clear due to the large numbers."},{"metadata":{"trusted":true},"cell_type":"code","source":"origins = pd.DataFrame(data.groupby('ORIGIN').is_delay.count())\norigins.rename(columns={'is_delay':'flights'}, inplace=True)\norigins['delayed'] = data.groupby('ORIGIN').is_delay.sum()\norigins['delayed_perc'] = 100*origins.delayed/origins.flights\norigins.reset_index(level=0, inplace=True)\norigins.sort_values(by=['delayed_perc'], inplace=True, ascending=False, ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"origins.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dests = pd.DataFrame(data.groupby('DEST').is_delay.count())\ndests.rename(columns={'is_delay':'flights'}, inplace=True)\ndests['delayed'] = data.groupby('DEST').is_delay.sum()\ndests['delayed_perc'] = 100*dests.delayed/dests.flights\ndests.reset_index(level=0, inplace=True)\ndests.sort_values(by=['delayed_perc'], inplace=True, ascending=False, ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dests.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Most delays happens at HGR airport."},{"metadata":{},"cell_type":"markdown","source":"- Thre are 350 airports for both 'DEST, nad 'ORIGIN', this will result in 700 new features when doing one-hot-encoding, so we will use the top 10 airports only, and set the rest "},{"metadata":{"trusted":true},"cell_type":"code","source":"origins.sort_values(by=['flights'], inplace=True, ascending=False, ignore_index=True)\ndests.sort_values(by=['flights'], inplace=True, ascending=False, ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"origins.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dests.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Top airports for 'dest' and 'origin' are:  ['ATL', 'ORD', 'DFW', 'DEN', 'CLT', 'LAX', 'PHX', 'IAH', 'LAS', 'SFO']"},{"metadata":{"trusted":true},"cell_type":"code","source":"airports = ['ATL', 'ORD', 'DFW', 'DEN', 'CLT', 'LAX', 'PHX', 'IAH', 'LAS', 'SFO']\n\ndata['ORIGIN'].loc[~data['ORIGIN'].isin(airports)] = 'others'\ndata['DEST'].loc[~data['DEST'].isin(airports)] = 'others'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'values in \\'ORIGIN\\': {data.ORIGIN.unique()}')\nprint(f'values in \\'DEST\\': {data.DEST.unique()}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.lmplot( x=\"is_delay\", y=\"DISTANCE\", data=data, fit_reg=False, hue='is_delay', legend=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Delay happens in both short and long distances."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='OP_UNIQUE_CARRIER', hue='is_delay', data=data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Check the features\n- Drop uncessary ones if exist.\n- Encoding\n- Scale if needed."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check coulmns types\ndata.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Distance range is high ---> needs to be scaled.\n- Dep_TIME needs to be in 24-hour format."},{"metadata":{"trusted":true},"cell_type":"code","source":"data['DISTANCE'] = (data['DISTANCE']-data['DISTANCE'].mean())/data['DISTANCE'].std()#\ndata['DEP_TIME'] = (data['DEP_TIME']//100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\nto_scale = ['DISTANCE', 'DAY_OF_WEEK', 'DEP_TIME', 'DAY_OF_MONTH']\nscaler = MinMaxScaler()\ndata[to_scale] = scaler.fit_transform(data[to_scale])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The month is not important here as it is the same for all samples (Feb)\ndata.drop(columns=['MONTH'], axis=1, inplace=True)\n\ncategorical_columns  = ['DAY_OF_MONTH', 'DAY_OF_WEEK','OP_UNIQUE_CARRIER', \n                        'ORIGIN', 'DEST', 'is_delay']\n\ncategorical_columns.remove('is_delay') # Remove the target variable before converting to categorical\n\n# Convert them to categorical dtype\nfor c in categorical_columns:\n    data[c] = data[c].astype('category')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dummies = pd.get_dummies(data[categorical_columns], drop_first=True)\ndata = pd.concat([data, data_dummies], axis = 1)\ndata.drop(categorical_columns,axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Bulid the Baseline Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import precision_recall_fscore_support","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extract the target column\ntarget = data.is_delay\ndata.drop(columns=['is_delay'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Split twice to get train, and test sets"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split the dataset in the ratio train 80% and test 20%\nx_train, x_test, y_train, y_test = train_test_split(data, target, test_size=0.20, random_state=95) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1 - Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"logReg =LogisticRegression()\nlogReg.fit(x_train, y_train)\ny_pred_logReg = logReg.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2- Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"randForest = RandomForestClassifier()\nrandForest.fit(x_train, y_train)\ny_pred_randForest = randForest.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3- XGBoost"},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb = XGBClassifier(use_label_encoder=False)\nxgb.fit(x_train, y_train)\ny_pred_xgb = xgb.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate accuracy\ndef evaluate_model(labels, preds):\n    accuracy = (preds == labels).sum() / preds.shape[0]\n    print(f'Accuracy: {accuracy}')\n\n    auc = roc_auc_score(labels, preds)\n    print(f'AUC     : {auc}')\n\n    precision, recall, f1_score, _ = precision_recall_fscore_support(labels, preds, average = 'binary')\n    print(f'Precision: {precision}')\n    print(f'Recall: {recall}')\n    print(f'F1_score: {f1_score}')\n\n    confusion_matrix = pd.crosstab(index=labels, columns=np.round(preds), \n                                   rownames=['True'], colnames=['predictions']).astype(int)\n    plt.figure(figsize = (5,5))\n    sns.heatmap(confusion_matrix, annot=True, fmt='.2f', cmap=\"YlGnBu\").set_title('Confusion Matrix') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluate_model(y_pred_logReg, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluate_model(y_pred_randForest, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluate_model(y_pred_xgb, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### since the data is unbalanced, we will look at the F1-Score.\n* f1-score of the RandomForest model is the highest one, so will go with this model."},{"metadata":{},"cell_type":"markdown","source":"# Model Tuning\n\n### We will use the **Grid Search**Â¶ algorithm to tune the hyperparameters\n\n### Most important hyperparameters of Random Forest:\n\n* n_estimators = number of trees, larger --> more complex.\n* max_features =  number of maximum features provided to each tree, the default value is the best 'square root of the number of features'.\n* max_depth = max number of levels in each decision tree, if it's too large --> overfitting.\n* min_samples_split = min number of data points placed in a node before the node is split, larger values prevent overfitting.\n* max_leaf_nodes = number of leaf nodes, very small --> underfitting, and very large --> overfitting.\n* min_samples_leaf = min number of data points allowed in a leaf node, very large --> underfitting, and very small --> overfitting.\n* bootstrap = method for sampling data points (with or without replacement)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import f1_score\nfrom sklearn.metrics import make_scorer\n\nf1_scorer = make_scorer(f1_score, greater_is_better=True)\n\nparam_grid = [\n{'n_estimators': [10, 25],\n 'max_depth': [10, 50],\n 'min_samples_split': [5, 10, 15],\n 'bootstrap': [True, False]}\n]\n\ngrid_search_forest = GridSearchCV(randForest, param_grid, cv=10, scoring=f1_scorer)\ngrid_search_forest.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cvres = grid_search_forest.cv_results_\n\nfor mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n    print(mean_score, params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_search_forest.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_search_forest.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_best= grid_search_forest.best_estimator_.predict(x_test)\nevaluate_model(grid_best, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Final Notes:\n- The final f1-score increased slightly, but if we increased the number of trees i.e.(n_estimators), it may get better.\n- Adding more features like (weather) will result in a better performance, but it's not availble right now."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}