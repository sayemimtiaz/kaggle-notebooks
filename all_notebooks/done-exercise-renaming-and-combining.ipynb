{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**This notebook is an exercise in the [Pandas](https://www.kaggle.com/learn/pandas) course.  You can reference the tutorial at [this link](https://www.kaggle.com/residentmario/renaming-and-combining).**\n\n---\n","metadata":{}},{"cell_type":"markdown","source":"# Introduction\n\nRun the following cell to load your data and some utility functions.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\nreviews = pd.read_csv(\"../input/wine-reviews/winemag-data-130k-v2.csv\", index_col=0)\n\nfrom learntools.core import binder; binder.bind(globals())\nfrom learntools.pandas.renaming_and_combining import *\nprint(\"Setup complete.\")","metadata":{"execution":{"iopub.status.busy":"2021-06-04T13:11:08.028287Z","iopub.execute_input":"2021-06-04T13:11:08.02914Z","iopub.status.idle":"2021-06-04T13:11:12.496593Z","shell.execute_reply.started":"2021-06-04T13:11:08.029012Z","shell.execute_reply":"2021-06-04T13:11:12.495598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exercises\n\nView the first several lines of your data by running the cell below:","metadata":{}},{"cell_type":"code","source":"reviews.head(1)","metadata":{"execution":{"iopub.status.busy":"2021-06-04T13:11:53.480282Z","iopub.execute_input":"2021-06-04T13:11:53.480936Z","iopub.status.idle":"2021-06-04T13:11:53.499998Z","shell.execute_reply.started":"2021-06-04T13:11:53.480876Z","shell.execute_reply":"2021-06-04T13:11:53.498472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1.\n`region_1` and `region_2` are pretty uninformative names for locale columns in the dataset. Create a copy of `reviews` with these columns renamed to `region` and `locale`, respectively.","metadata":{}},{"cell_type":"code","source":"# Your code here\nrenamed = reviews.rename(columns=dict(region_1='region', region_2='locale'))\n\n# Check your answer\n# q1.check()\nrenamed","metadata":{"execution":{"iopub.status.busy":"2021-06-04T13:14:51.537604Z","iopub.execute_input":"2021-06-04T13:14:51.538186Z","iopub.status.idle":"2021-06-04T13:14:51.588834Z","shell.execute_reply.started":"2021-06-04T13:14:51.538134Z","shell.execute_reply":"2021-06-04T13:14:51.587999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"q1.hint()\nq1.solution()","metadata":{"execution":{"iopub.status.busy":"2021-06-04T13:14:29.505551Z","iopub.execute_input":"2021-06-04T13:14:29.50614Z","iopub.status.idle":"2021-06-04T13:14:29.516212Z","shell.execute_reply.started":"2021-06-04T13:14:29.506103Z","shell.execute_reply":"2021-06-04T13:14:29.514989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.\nSet the index name in the dataset to `wines`.","metadata":{}},{"cell_type":"code","source":"reindexed = reviews.rename_axis(\"wines\", axis='rows').rename_axis(\"fields\", axis='columns')\n\n# Check your answer\nq2.check()\nreindexed","metadata":{"execution":{"iopub.status.busy":"2021-06-04T13:20:56.844375Z","iopub.execute_input":"2021-06-04T13:20:56.844743Z","iopub.status.idle":"2021-06-04T13:20:56.929509Z","shell.execute_reply.started":"2021-06-04T13:20:56.844714Z","shell.execute_reply":"2021-06-04T13:20:56.928231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#q2.hint()\n#q2.solution()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.\nThe [Things on Reddit](https://www.kaggle.com/residentmario/things-on-reddit/data) dataset includes product links from a selection of top-ranked forums (\"subreddits\") on reddit.com. Run the cell below to load a dataframe of products mentioned on the */r/gaming* subreddit and another dataframe for products mentioned on the *r//movies* subreddit.","metadata":{}},{"cell_type":"code","source":"gaming_products = pd.read_csv(\"../input/things-on-reddit/top-things/top-things/reddits/g/gaming.csv\")\ngaming_products['subreddit'] = \"r/gaming\"\nmovie_products = pd.read_csv(\"../input/things-on-reddit/top-things/top-things/reddits/m/movies.csv\")\nmovie_products['subreddit'] = \"r/movies\"","metadata":{"execution":{"iopub.status.busy":"2021-06-04T13:21:13.491885Z","iopub.execute_input":"2021-06-04T13:21:13.492229Z","iopub.status.idle":"2021-06-04T13:21:13.519065Z","shell.execute_reply.started":"2021-06-04T13:21:13.492199Z","shell.execute_reply":"2021-06-04T13:21:13.517811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create a `DataFrame` of products mentioned on *either* subreddit.","metadata":{}},{"cell_type":"code","source":"combined_products = pd.concat([movie_products, gaming_products])\n\n# Check your answer\nq3.check()\ncombined_products","metadata":{"execution":{"iopub.status.busy":"2021-06-04T13:24:34.060507Z","iopub.execute_input":"2021-06-04T13:24:34.060932Z","iopub.status.idle":"2021-06-04T13:24:34.09681Z","shell.execute_reply.started":"2021-06-04T13:24:34.060895Z","shell.execute_reply":"2021-06-04T13:24:34.09557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"q3.hint()\nq3.solution()","metadata":{"execution":{"iopub.status.busy":"2021-06-04T13:23:52.512097Z","iopub.execute_input":"2021-06-04T13:23:52.512467Z","iopub.status.idle":"2021-06-04T13:23:52.525746Z","shell.execute_reply.started":"2021-06-04T13:23:52.512429Z","shell.execute_reply":"2021-06-04T13:23:52.524647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.\nThe [Powerlifting Database](https://www.kaggle.com/open-powerlifting/powerlifting-database) dataset on Kaggle includes one CSV table for powerlifting meets and a separate one for powerlifting competitors. Run the cell below to load these datasets into dataframes:","metadata":{}},{"cell_type":"code","source":"powerlifting_meets = pd.read_csv(\"../input/powerlifting-database/meets.csv\")\npowerlifting_competitors = pd.read_csv(\"../input/powerlifting-database/openpowerlifting.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-06-04T13:27:21.805861Z","iopub.execute_input":"2021-06-04T13:27:21.80622Z","iopub.status.idle":"2021-06-04T13:27:22.722855Z","shell.execute_reply.started":"2021-06-04T13:27:21.806191Z","shell.execute_reply":"2021-06-04T13:27:22.721408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Both tables include references to a `MeetID`, a unique key for each meet (competition) included in the database. Using this, generate a dataset combining the two tables into one.","metadata":{}},{"cell_type":"code","source":"# powerlifting_combined = ____\n\nleft = powerlifting_meets.set_index('MeetID')\nright = powerlifting_competitors.set_index('MeetID')\nleft.join(right)\n\n# Check your answer\n# q4.check()","metadata":{"execution":{"iopub.status.busy":"2021-06-04T13:31:20.41036Z","iopub.execute_input":"2021-06-04T13:31:20.410728Z","iopub.status.idle":"2021-06-04T13:31:21.1789Z","shell.execute_reply.started":"2021-06-04T13:31:20.410696Z","shell.execute_reply":"2021-06-04T13:31:21.177516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"q4.hint()\nq4.solution()","metadata":{"execution":{"iopub.status.busy":"2021-06-04T13:28:50.19993Z","iopub.execute_input":"2021-06-04T13:28:50.200311Z","iopub.status.idle":"2021-06-04T13:28:50.213364Z","shell.execute_reply.started":"2021-06-04T13:28:50.200279Z","shell.execute_reply":"2021-06-04T13:28:50.21244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Congratulations!\n\nYou've finished the Pandas micro-course.  Many data scientists feel efficiency with Pandas is the most useful and practical skill they have, because it allows you to progress quickly in any project you have.\n\nIf you'd like to apply your new skills to examining geospatial data, you're encouraged to check out our **[Geospatial Analysis](https://www.kaggle.com/learn/geospatial-analysis)** micro-course.\n\nYou can also take advantage of your Pandas skills by entering a **[Kaggle Competition](https://www.kaggle.com/competitions)** or by answering a question you find interesting using **[Kaggle Datasets](https://www.kaggle.com/datasets)**.","metadata":{}},{"cell_type":"markdown","source":"---\n\n\n\n\n*Have questions or comments? Visit the [Learn Discussion forum](https://www.kaggle.com/learn-forum/161299) to chat with other Learners.*","metadata":{}}]}