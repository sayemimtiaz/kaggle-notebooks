{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Importing the Libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport cv2\nimport os\nimport string\nimport pandas as pd\n\n\n# In[2]:\n\n\n# Deep Learning Imports\nimport tensorflow as tf\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Conv2D, add,MaxPooling2D, concatenate,Reshape, Bidirectional, LSTM,GRU, Dense, Lambda, Activation, BatchNormalization, Dropout,Concatenate\nfrom tensorflow.keras.optimizers import Adam,SGD,Adagrad\n","metadata":{"execution":{"iopub.status.busy":"2021-06-07T09:54:06.510263Z","iopub.execute_input":"2021-06-07T09:54:06.510752Z","iopub.status.idle":"2021-06-07T09:54:12.567255Z","shell.execute_reply.started":"2021-06-07T09:54:06.510666Z","shell.execute_reply":"2021-06-07T09:54:12.565733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from tensorflow.keras import mixed_precision\n\n\n# policy = mixed_precision.experimental.Policy('mixed_float16')\n# mixed_precision.set_global_policy(policy)\n\n# os.environ['TF_ENABLE_AUTO_MIXED_PRECISION'] = '1'\n# In[3]:\ntimestamps=64\nchar=string.ascii_uppercase+\"./-0123456789\"\n\n# char=string.ascii_lowercase\ntest_dir=\"../input/20k-synthetic-ocr-dataset/files/20k test\"\ntrain_dir=\"../input/20k-synthetic-ocr-dataset/files/20k train\"\n# Preparing the Data\n\n\n### check train and test set distribution\n\nfor d,c in zip([test_dir, train_dir],[\"../input/20k-synthetic-ocr-dataset/test.csv\",\"../input/20k-synthetic-ocr-dataset/train.csv\"]):\n\n    print(c.split(\".\")[0]+\"set distribution\")\n    filename=[os.path.join(d,i) for i in os.listdir(d)]\n\n    track=dict(zip(char,[0]*len(char)))\n    data=pd.read_csv(c)\n    for file in data[\"label\"]:\n        for l in file:\n            track[l]+=1\n    print(track)\n    print(\"====\"*20)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-07T09:54:58.486765Z","iopub.execute_input":"2021-06-07T09:54:58.487215Z","iopub.status.idle":"2021-06-07T09:54:59.2681Z","shell.execute_reply.started":"2021-06-07T09:54:58.487161Z","shell.execute_reply":"2021-06-07T09:54:59.266884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def num2label(num):\n ret = \"\"\n for ch in num:\n     if ch == -1:  # CTC Blank\n         break\n     else:\n         ret+=alphabets[ch]\n return ret\n\n\n\n# In[4]:\n\n\n# Custom Data Generator\nclass DataGenerator(tf.keras.utils.Sequence):\n    def __init__(self,batch_size=256,image_size=16,max_str_len=20,channels=3,path_to_img_dir=train_dir,shuffle=True,timestamps=timestamps,data=\"../input/20k-synthetic-ocr-dataset/train.csv\"):\n        self.info_csv=pd.read_csv(data)\n        self.batch_size = batch_size\n        self.image_size=image_size\n        self.channels=channels\n        self.shuffle = shuffle\n#         self.on_epoch_end()\n        self.alphabets=char\n        self.max_str_len=max_str_len\n        self.num_characters=len(self.alphabets)+1\n        self.num_timestamps=timestamps\n        self.path=path_to_img_dir\n        self.num_examples=len(os.listdir(self.path))\n        self.indices =list(range(self.num_examples))\n        self.images_path=[os.path.join(self.path,i) for i in self.info_csv[\"image name\"]]\n        self.label=self.info_csv[\"label\"]\n        self.n = 0\n        self.max = self.__len__()\n\n    def __len__(self):\n        return len(self.indices) // self.batch_size\n\n    def __getitem__(self, index):\n        inds = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n#         batch = [self.indices[k] for k in index]\n        \n        X,y,label_len,output_len,output = self.__get_data(inds)\n        \n        return [X,y,output_len,label_len],output\n\n    def label_to_num(self,label):\n        label_num = []\n        for ch in label:\n            label_num.append(self.alphabets.find(ch))\n\n        return np.array(label_num)\n\n\n    def on_epoch_end(self):\n        self.index = np.arange(len(self.indices))\n        if self.shuffle == True:\n            np.random.shuffle(self.index)\n            \n    def create_labels(self,raw_labels,batch):\n        num_examples=len(batch)\n        y = np.ones([num_examples,self.max_str_len]) * -1\n        label_len = np.zeros([num_examples, 1])\n        output_len = np.ones([num_examples,1]) * (self.num_timestamps-2)\n        output = np.zeros([num_examples])\n\n        for i in range(num_examples):\n            label_len[i] = len(raw_labels[i])\n            y[i, 0:len(raw_labels[i])]= self.label_to_num(raw_labels[i])\n\n        return y,label_len,output_len,output\n\n    def preprocess(self,imgPath):\n        img=cv2.imread(imgPath,cv2.IMREAD_GRAYSCALE)\n        img=cv2.resize(img,(256,64))\n    \n        (h, w) = img.shape\n        \n        final_img = np.ones([64, 256])*255 # blank white image\n        \n        # crop\n        if w > 256:\n            img = img[:, :256]\n            \n        if h > 64:\n            img = img[:64, :]\n        \n        \n        final_img[:h, :w] = img\n        train_x=cv2.rotate(final_img, cv2.ROTATE_90_CLOCKWISE)/255.\n\n        return train_x\n\n    def preprocess_data(self,batch):\n        images_array=[]\n        labels=[]\n        \n        batch_images=[self.images_path[i] for i in batch]\n        lbls=[self.label[i] for i in batch]\n        for single_image_path,label in zip(batch_images,lbls):\n\n            img=self.preprocess(single_image_path)\n            images_array.append(np.expand_dims(img,axis=0))\n            \n            labels.append(label)\n            \n        train_x=np.vstack(images_array)\n        \n        return np.array(train_x).reshape(-1, 256, 64, 1) ,np.array(labels)\n\n    def __get_data(self, batch):\n        input_images,input_labels=self.preprocess_data(batch)\n        \n        input_y,input_label_len,input_output_len,input_output=self.create_labels(input_labels,batch)\n            \n        return input_images, input_y,input_label_len,input_output_len,input_output\n    \n    def __next__(self):\n        if self.n >= self.max:\n           self.n = 0\n        result= self.__getitem__(self.n)\n        self.n += 1\n        return result\n\n\n# In[5]:","metadata":{"execution":{"iopub.status.busy":"2021-06-07T09:55:09.953686Z","iopub.execute_input":"2021-06-07T09:55:09.954042Z","iopub.status.idle":"2021-06-07T09:55:09.981987Z","shell.execute_reply.started":"2021-06-07T09:55:09.95401Z","shell.execute_reply":"2021-06-07T09:55:09.980746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dg=DataGenerator()\nval_dg=DataGenerator(path_to_img_dir=test_dir,data=\"../input/20k-synthetic-ocr-dataset/test.csv\")\n\nx,y=next(val_dg)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T09:55:14.152019Z","iopub.execute_input":"2021-06-07T09:55:14.152375Z","iopub.status.idle":"2021-06-07T09:55:15.496769Z","shell.execute_reply.started":"2021-06-07T09:55:14.152339Z","shell.execute_reply":"2021-06-07T09:55:15.495587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Preparing Labels for CTC Loss\nimages=os.listdir(train_dir)\n\nalphabets = char\n\nmax_str_len=20\n\nnum_of_characters=len(alphabets)+1\n\nnum_of_timestamps=timestamps\n\n\n## verify data\n\n# for i in range(10):\n#     plt.imshow(x[0][i])\n#     word=num2label(x[1][i].astype(\"int\"))\n#     print(word)\n#     plt.show()\n\n\ninput_data = Input(shape=(256, 64, 1), name='input')\n\ninner = Conv2D(32, (3, 3), padding='same', name='conv1', kernel_initializer='he_normal')(input_data)  \ninner = BatchNormalization()(inner)\ninner = Activation('relu')(inner)\ninner = MaxPooling2D(pool_size=(2, 2), name='max1')(inner)\n\ninner = Conv2D(64, (3, 3), padding='same', name='conv2', kernel_initializer='he_normal')(inner)\ninner = Conv2D(64, (3, 3), padding='same', name='conv2_1', kernel_initializer='he_normal')(inner)\ninner = BatchNormalization()(inner)\ninner = Activation('relu')(inner)\ninner = MaxPooling2D(pool_size=(2, 2), name='max2')(inner)\ninner = Dropout(0.5)(inner)\n\ninner = Conv2D(128, (3, 3), padding='same', name='conv3', kernel_initializer='he_normal')(inner)\ninner = Conv2D(128, (3, 3), padding='same', name='conv3_1', kernel_initializer='he_normal')(inner)\ninner = BatchNormalization()(inner)\ninner = Activation('relu')(inner)\ninner = MaxPooling2D(pool_size=(1, 2), name='max3')(inner)\ninner = Dropout(0.7)(inner)\n\n# CNN to RNN\ninner = Reshape(target_shape=((64, 1024)), name='reshape')(inner)\ninner = Dense(64, activation='relu', kernel_initializer='he_normal', name='dense1')(inner)\n\n## RNN\ninner = Bidirectional(GRU(256, return_sequences=True), name = 'lstm1')(inner)\ninner = Bidirectional(GRU(256, return_sequences=True), name = 'lstm2')(inner)\n\n## OUTPUT\ninner = Dense(num_of_characters, kernel_initializer='he_normal',name='dense2')(inner)\ny_pred = Activation('softmax', name='softmax')(inner)\n\nmodel = Model(inputs=input_data, outputs=y_pred)\n# model.summary()\n\n\n\n\n\ndef ctc_lambda_func(args):\n    y_pred, labels, input_length, label_length = args\n    # the 2 is critical here since the first couple outputs of the RNN\n    # tend to be garbage\n    y_pred = y_pred[:, 2:, :]\n    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-07T09:55:15.499021Z","iopub.execute_input":"2021-06-07T09:55:15.499497Z","iopub.status.idle":"2021-06-07T09:55:19.984012Z","shell.execute_reply.started":"2021-06-07T09:55:15.499447Z","shell.execute_reply":"2021-06-07T09:55:19.982595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nlabels = Input(name='gtruth_labels', shape=[max_str_len], dtype='float32')\ninput_length = Input(name='input_length', shape=[1], dtype='int64')\nlabel_length = Input(name='label_length', shape=[1], dtype='int64')\n\nctc_loss = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\nmodel_final = Model(inputs=[input_data, labels, input_length, label_length],outputs=ctc_loss)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-07T09:55:19.986723Z","iopub.execute_input":"2021-06-07T09:55:19.987499Z","iopub.status.idle":"2021-06-07T09:55:20.18993Z","shell.execute_reply.started":"2021-06-07T09:55:19.987436Z","shell.execute_reply":"2021-06-07T09:55:20.18572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_final.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T09:55:20.196713Z","iopub.execute_input":"2021-06-07T09:55:20.197158Z","iopub.status.idle":"2021-06-07T09:55:20.233639Z","shell.execute_reply.started":"2021-06-07T09:55:20.197101Z","shell.execute_reply":"2021-06-07T09:55:20.223944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Defining Model Callbacks\nsave_best=tf.keras.callbacks.ModelCheckpoint(filepath=\"GRU_uppercase.h5\",save_best_only=True,save_weights_only=True,verbose=True)\nreduce_lr=tf.keras.callbacks.ReduceLROnPlateau(min_lr_rate=0.00000000000001,factor=0.3,patience=10,verbose=True)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-07T09:55:20.235082Z","iopub.execute_input":"2021-06-07T09:55:20.235548Z","iopub.status.idle":"2021-06-07T09:55:20.257299Z","shell.execute_reply.started":"2021-06-07T09:55:20.235471Z","shell.execute_reply":"2021-06-07T09:55:20.256225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n## Defining Model Callbacks\nsave_best=tf.keras.callbacks.ModelCheckpoint(filepath=\"GRU_uppercase.h5\",save_best_only=True,save_weights_only=True,verbose=True)\nreduce_lr=tf.keras.callbacks.ReduceLROnPlateau(min_lr_rate=0.00000000000001,factor=0.3,patience=10,verbose=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T09:55:20.258708Z","iopub.execute_input":"2021-06-07T09:55:20.259161Z","iopub.status.idle":"2021-06-07T09:55:20.280848Z","shell.execute_reply.started":"2021-06-07T09:55:20.259118Z","shell.execute_reply":"2021-06-07T09:55:20.278282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.load_weights(\"Lstm_uppercase.h5\")\n## In[ ]:\n\n# opt=tf.keras.optimizers.Adadelta(learning_rate=0.001, rho=0.95, epsilon=1e-07, name=\"Adadelta\")\n## the loss calculation occurs elsewhere, so we use a dummy lambda function for the loss\n\nmodel_final.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=Adam(lr=0.0001))\n\nmodel_final.fit(train_dg, \n                validation_data=val_dg,\n                epochs=200,callbacks=[save_best,reduce_lr],workers=8)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-06-07T09:55:20.282489Z","iopub.execute_input":"2021-06-07T09:55:20.282951Z","iopub.status.idle":"2021-06-07T12:05:07.183898Z","shell.execute_reply.started":"2021-06-07T09:55:20.28288Z","shell.execute_reply":"2021-06-07T12:05:07.179748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('20k_synthetic_ocr_dataset.h5')","metadata":{"execution":{"iopub.status.busy":"2021-06-07T12:30:52.595014Z","iopub.execute_input":"2021-06-07T12:30:52.595424Z","iopub.status.idle":"2021-06-07T12:30:52.671855Z","shell.execute_reply.started":"2021-06-07T12:30:52.595391Z","shell.execute_reply":"2021-06-07T12:30:52.670486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nbatch_size=len(os.listdir(\"../input/20k-synthetic-ocr-dataset/files/20k test\"))\ntest_dg=DataGenerator(path_to_img_dir=test_dir,data=\"../input/20k-synthetic-ocr-dataset/test.csv\",batch_size=batch_size)\n\nX,y=next(test_dg)\nprint(X[0].shape)\n# Checking the Performance of the Model on Testing Set\npreds = model.predict(X[0])\n\nprint(preds)\ndecoded = K.get_value(K.ctc_decode(preds, input_length=np.ones(preds.shape[0])*preds.shape[1], \n                                   greedy=True)[0][0])\n\nprediction = []\nfor i in decoded:\n    prediction.append(num2label(i))\n\ngt = []\nfor i in X[1].astype(\"int\"):\n    gt.append(num2label(i))\n\n\n# In[47]:\n\ncorrect_char = 0\ntotal_char = 0\ncorrect = 0\n\nwrong_preds=[]\nfor i in range(X[0].shape[0]):\n    pr = prediction[i]\n    tr = gt[i]\n    total_char += len(tr)\n    \n    for j in range(min(len(tr), len(pr))):\n        if tr[j] == pr[j]:\n            correct_char += 1\n            \n    if pr == tr :\n        correct += 1\n\n    elif pr!=tr:\n        wrong_preds.append(i) \n    \nprint('Correct characters predicted : %.2f%%' %(correct_char*100/total_char))\nprint('Correct words predicted      : %.2f%%' %(correct*100/X[0].shape[0]))\n\n##\n### In[48]:\n##\n##\n\ndef preprocess(imgPath):\n        img=cv2.imread(imgPath,cv2.IMREAD_GRAYSCALE)\n        img=cv2.resize(img,(256,64))\n    \n        (h, w) = img.shape\n        \n        final_img = np.ones([64, 256])*255 # blank white image\n        \n        # crop\n        if w > 256:\n            img = img[:, :256]\n            \n        if h > 64:\n            img = img[:64, :]\n        \n        \n        final_img[:h, :w] = img\n        train_x=cv2.rotate(final_img, cv2.ROTATE_90_CLOCKWISE)/255.\n\n        return train_x\n\ntest_images=np.vstack([preprocess(os.path.join('../input/20k-synthetic-ocr-dataset/files/real_images',i)) for i in os.listdir(\"../input/20k-synthetic-ocr-dataset/files/real_images\")])\n\ntest_array=np.array(test_images).reshape(-1, 256, 64, 1)\n\n\n\n\nplt.figure(figsize=(15, 10))\n\nfor i in range(10):\n    ax = plt.subplot(2, 5, i+1)\n    rand_int=np.random.choice(wrong_preds)\n    image=X[0][rand_int]\n    gt=X[1][rand_int]\n    plt.imshow(np.rot90(image))\n    \n    pred = model.predict(np.expand_dims(image,axis=0))\n    decoded = K.get_value(K.ctc_decode(pred, input_length=np.ones(pred.shape[0])*pred.shape[1], \n                                       greedy=True)[0][0])\n    print(decoded)\n\n    print(num2label(gt.astype(\"int\")),\"predicted label is --->\",num2label(decoded[0]))\n    plt.title(num2label(decoded[0]), fontsize=14)\n    plt.axis('off')\n    \nplt.subplots_adjust(wspace=0.2, hspace=0.8)\n\nplt.show()\n\n\n\nfor i in range(20):\n    ax = plt.subplot(2, 10, i+1)\n    rand_int=np.random.randint(0,len(test_array))\n    image=test_array[rand_int]\n    plt.imshow(np.rot90(image))\n    \n    pred = model.predict(np.expand_dims(image,axis=0))\n    decoded = K.get_value(K.ctc_decode(pred, input_length=np.ones(pred.shape[0])*pred.shape[1], \n                                       greedy=True)[0][0])\n    print(decoded)\n\n    print(\"predicted label is --->\",num2label(decoded[0]))\n    plt.title(num2label(decoded[0]), fontsize=14)\n    plt.axis('off')\n    \nplt.subplots_adjust(wspace=0.2, hspace=0.8)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T12:05:39.803635Z","iopub.execute_input":"2021-06-07T12:05:39.804012Z","iopub.status.idle":"2021-06-07T12:05:57.520638Z","shell.execute_reply.started":"2021-06-07T12:05:39.803979Z","shell.execute_reply":"2021-06-07T12:05:57.519549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Models Predict the labels very well. Apart from the first Character in predictions.","metadata":{}},{"cell_type":"markdown","source":"# References","metadata":{}},{"cell_type":"markdown","source":"Thanks to Aurthor for sharing this data and its code.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}