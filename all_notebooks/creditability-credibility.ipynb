{"cells":[{"metadata":{},"cell_type":"markdown","source":"CREDITABILITY (noun):\n\nAppearance of truth or authenticity:\nbelievability, color, credibility, credibleness, creditableness, plausibility, plausibleness, verisimilitude.\n\nCREDIBILITY\n\nCredibility comprises the objective and subjective components of the believability of a source or message. Credibility dates back to Aristotle theory of Rhetoric. Aristotle defines rhetoric as the ability to see what is possibly persuasive in every situation. \n\nHe divided the means of persuasion into three categories, namely Ethos (the source's credibility), Pathos (the emotional or motivational appeals), and Logos (the logic used to support a claim), which he believed have the capacity to influence the receiver of a message. According to Aristotle, the term “Ethos” deals with the character of the speaker. The intent of the speaker is to appear credible.\n\nIn fact, the speaker's ethos is a rhetorical strategy employed by an orator whose purpose is to \"INSPIRE TRUST IN HIS AUDIENCE.” Credibility has two key components: trustworthiness and expertise, which both have objective and subjective components. \n\nTrustworthiness is based more on subjective factors, but can include objective measurements such as established reliability. Expertise can be similarly subjectively perceived, but also includes relatively objective characteristics of the source or message (e.g., credentials, certification or information quality).\n\nSecondary components of credibility include source dynamism (charisma) and physical attractiveness.\n\nhttps://en.wikipedia.org/wiki/Credibility"},{"metadata":{},"cell_type":"markdown","source":"#Even Birds know the Meaning of Creditability\n\n![](https://thesaurus.plus/img/synonyms/132/creditability.png)thesaurusplus"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns; sns.set()\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font color=\"#EC7063\">ETHOS. The source's credibility. </font>\n\n### <b><mark style=\"background-color: #9B59B6\"><font color=\"white\">* Has the applicant sources to pay the loan?   *</font></mark></b>\n\n<font color=\"#EC7063\">PATHOS. The emotional or motivational appeals. </font>\n\n### <b><mark style=\"background-color: #9B59B6\"><font color=\"white\">* Has the applicant good motivations to require the loan?   *</font></mark></b>\n\n<font color=\"#EC7063\">LOGOS. The logic used to support a claim. </font>\n\n### <b><mark style=\"background-color: #9B59B6\"><font color=\"white\">* Has the applicant convinced the bank that the loan will be paid?   *</font></mark></b>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"nRowsRead = 1000 # specify 'None' if want to read whole file\ndataset = pd.read_csv('../input/cusersmarildownloadsgermancsv/german.csv', delimiter=';', encoding = \"ISO-8859-2\", nrows = nRowsRead)\ndataset.dataframeName = 'german.csv'\nnRow, nCol = dataset.shape\nprint(f'There are {nRow} rows and {nCol} columns')\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The predictors that may potentially have any influence on Creditability:\n\nAccount Balance: No account (1), None (No balance) (2), Some Balance (3)\n\nPayment Status: Some Problems (1), Paid Up (2), No Problems (in this bank) (3)\n\nSavings/Stock Value: None, Below 100 DM, (100, 1000) DM, Above 1000 DM\n\nEmployment Length: Below 1 year (including unemployed), (1, 4), (4, 7), Above 7\n\nSex/Marital Status: Male Divorced/Single, Male Married/Widowed, Female\n\nNo of Credits at this bank: 1, More than 1\n\nGuarantor: None, Yes\n\nConcurrent Credits: Other Banks or Dept Stores, None\n\nForeignWorker variable may be dropped from the study\n\nPurpose of Credit: New car, Used car, Home Related, Other"},{"metadata":{},"cell_type":"markdown","source":"#All script by Baris Cal https://www.kaggle.com/bariscal/portugal-wine-dataset-quality-prediction-w-ml "},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"from sklearn import tree\nimport graphviz \nimport os\nimport preprocessing \n\nfrom pandas_profiling import ProfileReport\n\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2, f_classif\nfrom sklearn.model_selection import KFold\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.svm import LinearSVC\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import cross_val_predict\n\nfrom sklearn.preprocessing import normalize\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.pipeline import Pipeline, make_pipeline\nfrom sklearn.decomposition import PCA","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.naive_bayes import CategoricalNB\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.cluster import KMeans\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom xgboost import XGBClassifier\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.metrics import precision_score, recall_score, f1_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn.model_selection import GridSearchCV\n\n\nfrom sklearn.linear_model import SGDClassifier, LogisticRegression\n\n\nfrom sklearn.neural_network import MLPClassifier\nfrom xgboost import XGBClassifier, XGBRFClassifier\nfrom xgboost import plot_tree, plot_importance\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, roc_curve\nfrom sklearn import preprocessing\nfrom sklearn.feature_selection import RFE\n\n\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list(dataset.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = ['Account_Balance',\n 'Duration_of_Credit_monthly',\n 'Payment_Status_of_Previous_Credit',\n 'Purpose',\n 'Credit_Amount',\n 'Value_Savings_Stocks',\n 'Guarantors',\n 'Most_valuable_available_asset',\n 'Age_years',\n 'No_of_Credits_at_this_Bank',\n 'Occupation']\nsns.set_style('darkgrid')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#sns.pairplot(dataset, hue = 'Creditability')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask = np.zeros_like(dataset[features].corr(), dtype=np.bool) \nmask[np.triu_indices_from(mask)] = True \n\nf, ax = plt.subplots(figsize=(16, 12))\nplt.title('Pearson Correlation Matrix',fontsize=25)\n\nsns.set_style('darkgrid')\nsns.heatmap(dataset[features].corr(),linewidths=0.25,vmax=0.7,square=True,cmap=\"BuGn\", #\"BuGn_r\" to reverse \n            linecolor='w',annot=True,annot_kws={\"size\":8},mask=mask,cbar_kws={\"shrink\": .9});","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,8)) \nsns.heatmap(dataset.corr(), annot=True, cmap='Dark2_r', linewidths = 2)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(30,30))\n\nplt.subplot(4,4,1)\nsns.distplot(dataset['Creditability']).set_title('Creditability Interval')\n\nplt.subplot(4,4,2)\nsns.distplot(dataset['Account_Balance']).set_title('Account Balance Interval')\n\nplt.subplot(4,4,3)\nsns.distplot(dataset['Purpose']).set_title('Purpose Interval')\n\nplt.subplot(4,4,4)\nsns.distplot(dataset['Guarantors']).set_title('Guarantors Interval')\n\nplt.subplot(4,4,5)\nsns.distplot(dataset['Most_valuable_available_asset']).set_title('Most valuable available asset Interval')\n\nplt.subplot(4,4,6)\nsns.distplot(dataset['Age_years']).set_title('Age Interval')\n\nplt.subplot(4,4,7)\nsns.distplot(dataset['Occupation']).set_title('Occupation Interval')\n\nplt.subplot(4,4,8)\nsns.distplot(dataset['Value_Savings_Stocks']).set_title('Value Savings & Stocks Interval')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,15))\nplt.subplot(2,2,1)\nsns.violinplot(x = 'Creditability', y = 'Account_Balance', data = dataset)\nplt.subplot(2,2,2)\nsns.violinplot(x = 'Creditability', y = 'Credit_Amount', data = dataset)\nplt.subplot(2,2,3)\nsns.violinplot(x = 'Creditability', y = 'Occupation', data = dataset)\nplt.subplot(2,2,4)\nsns.violinplot(x = 'Creditability', y = 'Guarantors', data = dataset)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Apple co-founder says Apple Card algorithm gave wife LOWER CREDIT LIMIT\n\nApple Inc AAPL.O co-founder Steve Wozniak joined in the online debate over accusations of GENDER DISCRIMINATION by the ALGORITHM behind the iPhone maker's credit card, fueling scrutiny of the newly launched Apple Card.\n\nThe criticism started after entrepreneur David Heinemeier Hansson railed against the Apple Card in a series of Twitter posts, saying it gave him 20 times the credit limit his wife received.\n\nApple Card applicants were evaluated independently, according to income and creditworthiness, taking into account factors such as personal credit scores and personal debt.\n\nWozniak said he got 10 times more credit on the card, compared with his wife.\n\nhttps://www.reuters.com/article/us-goldman-sachs-apple/apple-co-founder-says-apple-card-algorithm-gave-wife-lower-credit-limit-idUKKBN1XL038"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset[\"Sex_Marital_Status\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plt.figure(1, figsize=(10,10))\ndataset['Sex_Marital_Status'].value_counts().plot.pie(autopct=\"%1.1f%%\")\nplt.title ('Sex & Marital Status')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Sex/Marital Status: Male Divorced/Single, Male Married/Widowed, Female.\n\n#They didn't mentioned which number corresponds to the status. What percent correspond to females if I don't know female number?\n\nhttps://online.stat.psu.edu/stat508/resources/analysis/gcd/gcd.1"},{"metadata":{"trusted":true},"cell_type":"code","source":"features = ['Account_Balance',\n 'Duration_of_Credit_monthly',\n 'Payment_Status_of_Previous_Credit',\n 'Purpose',\n 'Credit_Amount',\n 'Value_Savings_Stocks',\n 'Guarantors',\n 'Most_valuable_available_asset',\n 'Age_years',\n 'No_of_Credits_at_this_Bank',\n 'Occupation']\nlabel = ['Creditability']\n\nX = dataset[features]\ny = dataset[label]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Attention Below it's NOT 12 it's l2 (lower case L)"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = normalize(X, norm = 'l2')\nprint(X[:3])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=101) \nX_valid, X_test, y_valid, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n\nprint(f'Total # of sample in whole dataset: {len(X)}')\nprint(f'Total # of sample in train dataset: {len(X_train)}')\nprint(f'Total # of sample in validation dataset: {len(X_valid)}')\nprint(f'Total # of sample in test dataset: {len(X_test)}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Score of Models"},{"metadata":{"_kg_hide-output":true,"trusted":true,"collapsed":true},"cell_type":"code","source":"#Scores of Models\nmodels = {\n    'GaussianNB': GaussianNB(),\n    'MultinomialNB': MultinomialNB(),\n    'BernoulliNB': BernoulliNB(),\n    'LogisticRegression': LogisticRegression(),\n    'RandomForestClassifier': RandomForestClassifier(),\n    'SupportVectorMachine': SVC(),\n    'DecisionTreeClassifier': DecisionTreeClassifier(),\n    'KNeighborsClassifier': KNeighborsClassifier(),\n    'GradientBoostingClassifier': GradientBoostingClassifier(),\n    'Stochastic Gradient Descent':  SGDClassifier(max_iter=5000, random_state=0),\n    'Neural Nets': MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5000, 10), random_state=1),\n    'XGBClassifier': XGBClassifier()\n}\n\nmodelNames = [\"GaussianNB\",\"MultinomialNB\",'BernoulliNB','LogisticRegression','RandomForestClassifier','SupportVectorMachine',\n             'DecisionTreeClassifier', 'KNeighborsClassifier','GradientBoostingClassifier',\n             'Stochastic Gradient Descent', 'Neural Nets', 'XGBClassifier']\n\ntrainScores = []\nvalidationScores = []\ntestScores = []\n\nfor m in models:\n  model = models[m]\n  model.fit(X_train, y_train)\n  score = model.score(X_valid, y_valid)\n  #print(f'{m} validation score => {score*100}')\n    \n  print(f'{m}') \n  train_score = model.score(X_train, y_train)\n  print(f'Train score of trained model: {train_score*100}')\n  trainScores.append(train_score*100)\n\n  validation_score = model.score(X_valid, y_valid)\n  print(f'Validation score of trained model: {validation_score*100}')\n  validationScores.append(validation_score*100)\n\n  test_score = model.score(X_test, y_test)\n  print(f'Test score of trained model: {test_score*100}')\n  testScores.append(test_score*100)\n  print(\" \")\n    \n  y_predictions = model.predict(X_test)\n  conf_matrix = confusion_matrix(y_predictions, y_test)\n\n  print(f'Confussion Matrix: \\n{conf_matrix}\\n')\n\n  predictions = model.predict(X_test)\n  cm = confusion_matrix(predictions, y_test)\n\n  tn = conf_matrix[0,0]\n  fp = conf_matrix[0,1]\n  tp = conf_matrix[1,1]\n  fn = conf_matrix[1,0]\n  accuracy  = (tp + tn) / (tp + fp + tn + fn)\n  precision = tp / (tp + fp)\n  recall    = tp / (tp + fn)\n  f1score  = 2 * precision * recall / (precision + recall)\n  specificity = tn / (tn + fp)\n  print(f'Accuracy : {accuracy}')\n  print(f'Precision: {precision}')\n  print(f'Recall   : {recall}')\n  print(f'F1 score : {f1score}')\n  print(f'Specificity : {specificity}')\n  print(\"\") \n  print(f'Classification Report: \\n{classification_report(predictions, y_test)}\\n')\n  print(\"\")\n   \n  for m in range (1):\n    current = modelNames[m]\n    modelNames.remove(modelNames[m])\n\n  preds = model.predict(X_test)\n  confusion_matr = confusion_matrix(y_test, preds) #normalize = 'true'\n  print(\"############################################################################\")\n  print(\"\")\n  print(\"\")\n  print(\"\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,10))\nplt.title('Train - Validation - Test Scores of Models', fontweight='bold', size = 24)\n\nbarWidth = 0.25\n \nbars1 = trainScores\nbars2 = validationScores\nbars3 = testScores\n \nr1 = np.arange(len(bars1))\nr2 = [x + barWidth for x in r1]\nr3 = [x + barWidth for x in r2]\n \nplt.bar(r1, bars1, color='blue', width=barWidth, edgecolor='white', label='train', yerr=0.5,ecolor=\"black\",capsize=10)\nplt.bar(r2, bars2, color='#557f2d', width=barWidth, edgecolor='white', label='validation', yerr=0.5,ecolor=\"black\",capsize=10, alpha = .50)\nplt.bar(r3, bars3, color='red', width=barWidth, edgecolor='white', label='test', yerr=0.5,ecolor=\"black\",capsize=10, hatch = '-')\n \nmodelNames = [\"GaussianNB\",\"MultinomialNB\",'BernoulliNB','LogisticRegression','RandomForestClassifier','SupportVectorMachine',\n             'DecisionTreeClassifier', 'KNeighborsClassifier','GradientBoostingClassifier',\n             'Stochastic Gradient Descent', 'Neural Nets', 'XGBClassifier']\n    \nplt.xlabel('Algorithms', fontweight='bold', size = 24)\nplt.ylabel('Scores', fontweight='bold', size = 24)\nplt.xticks([r + barWidth for r in range(len(bars1))], modelNames, rotation = 75)\n \nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(12):\n    print(f'Accuracy of {modelNames[i]} -----> {testScores[i]}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The best result was from XGBClassifier with 75.15 accuracy score.\n\nThat phrase below I simply didn't get. Maybe I'll ask Baris Cal.\n\n\"We had 7 labels to predict. Now, i will decrease this 7 labels to 3 and try to increase accuracy scores.\""},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['Creditability'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Improving Results\n\nDataset includes 'Creditability' attribute. This atribute values are between 0 and 1. So I think I don't even have to decrease the value interval.\n\n\n\nOn the original Dataset (Portugal Wines) the attribute \"quality\" values are between 0 and 9\n\n\"For increase the accuracy of results, I have done decrease the value interval. So I created an attribute. According to these attribute, if 'quality' value of sample is lower than 5, it will be classified as 'low', if 6 or 7 it will be in 'medium' range and the others will be 'high' quality wines. For use this new data in machine learning algorithms, I made this values integers. 'low' quality is 0, 'medium' quality is 1 and 'high' quality is 2. I not gonna use 'quality_value' attribute in my application. I did it to see how did I obtain that values.\"\nhttps://www.kaggle.com/bariscal/portugal-wine-dataset-quality-prediction-w-ml"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#Code by Olga Belitskaya https://www.kaggle.com/olgabelitskaya/sequential-data/comments\nfrom IPython.display import display,HTML\nc1,c2,f1,f2,fs1,fs2=\\\n'#eb3434','#eb3446','Akronim','Smokum',30,15\ndef dhtml(string,fontcolor=c1,font=f1,fontsize=fs1):\n    display(HTML(\"\"\"<style>\n    @import 'https://fonts.googleapis.com/css?family=\"\"\"\\\n    +font+\"\"\"&effect=3d-float';</style>\n    <h1 class='font-effect-3d-float' style='font-family:\"\"\"+\\\n    font+\"\"\"; color:\"\"\"+fontcolor+\"\"\"; font-size:\"\"\"+\\\n    str(fontsize)+\"\"\"px;'>%s</h1>\"\"\"%string))\n    \n    \ndhtml('Be patient. Marília Prata, @mpwolke was Here')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}