{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Break linearity example\n\n> Why does neural network rules the fitting power since 2006\n\n> This is a notebook intended for company(Genomicare Bio) training, to help people feel more friendly about NN\n\nYou certainly hear ```neural network``` & ```deep learning``` a lot in recent years. Yes it is something really advanced in certain aspects, but it's just a tool, which is much easier to use than its predecessor: linear regression.\n\nThis notebook is yet another effort to democratize deep learning. \n\nThis kind of graph appear at many tutorials\n\n![Simple nn view from wikipedia](https://upload.wikimedia.org/wikipedia/commons/e/e4/Artificial_neural_network.svg)"},{"metadata":{},"cell_type":"markdown","source":"## Some playing around\n\n* Try use your [face to control pac man](https://storage.googleapis.com/tfjs-examples/webcam-transfer-learning/dist/index.html)\n\n* A neural [network playground](https://playground.tensorflow.org/)"},{"metadata":{},"cell_type":"markdown","source":"# What's and why is all the fuss?\n\n### What?\n\nIn a simple one liner answer:\n\nNeural network is one of the most powerful, easiest to use **predictor**, that given x, any shape of x to predict y, any shape of y.\n\nI can rephrase the sentence even longer, but it is in its essence, an awesome **predictor**\n\nThink of $y = f(x)$,  the $f$ is a function(model), a predictor\n\n### Why?\n\n* It often works, with less effort than you expected, often better than human judgement\n* Paper in this area often compare model learning theory to human recognition.\n* It's like a warp engine for other traditional model.\n* x and y can be really noisy, in some twisted & wierd shape, AKA, it predicts all sorts of problem set, with **much less preprocessing**, **much less feature engineering**\n* Real life data itself is noisy, in some twisted & wierd shape"},{"metadata":{},"cell_type":"markdown","source":"## Dataset\n### Simplified Human Activity Recognition w/Smartphone\n\nSee the [dataset detail](https://www.kaggle.com/mboaglio/simplifiedhuarus)\n\n> Abstract: Human Activity Recognition database built from the recordings of 30 subjects performing activities of daily living (ADL) while carrying a waist-mounted smartphone with embedded inertial sensors.\n\n> Data Set Characteristics: Multivariate, Time-Series\n\n> Data Set Information:\n\n> The experiments have been carried out with a group of 30 volunteers within an age bracket of 19-48 years. Each person performed six activities (WALKING, WALKINGUPSTAIRS, WALKINGDOWNSTAIRS, SITTING, STANDING, LAYING) wearing a smartphone (Samsung Galaxy S II) on the waist. Using its embedded accelerometer and gyroscope, we captured 3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz. The experiments have been video-recorded to label the data manually. The obtained dataset has been randomly partitioned into two sets, where 70% of the volunteers was selected for generating the training data and 30% the test data.\n\n> The sensor signals (accelerometer and gyroscope) were pre-processed by applying noise filters and then sampled in fixed-width sliding windows of 2.56 sec and 50% overlap (128 readings/window). The sensor acceleration signal, which has gravitational and body motion components, was separated using a Butterworth low-pass filter into body acceleration and gravity. The gravitational force is assumed to have only low frequency components, therefore a filter with 0.3 Hz cutoff frequency was used. From each window, a vector of features was obtained by calculating variables from the time and frequency domain.\n\n> Check the README.txt file for further details about this dataset.\n\n> An updated version of this dataset can be found at [here](https://archive.ics.uci.edu/ml/datasets/human+activity+recognition+using+smartphones). It includes labels of postural transitions between activities and also the full raw inertial signals instead of the ones pre-processed into windows."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nfrom sklearn.decomposition import PCA","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Install extra [packages](https://github.com/raynardj/forgebox)"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install -q forgebox","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from forgebox.imports import *\nfrom forgebox.ftorch.prepro import split_df\nfrom forgebox.html import DOM\nfrom forgebox.images.widgets import view_images","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train data and test(validation) data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# constant\nDATA = Path(\"/kaggle/input/simplifiedhuarus\")\nVALID_RATIO = .2\n\ndef read_data(filename: str) -> pd.DataFrame:return pd.read_csv(DATA/f'{filename}.csv')\n\ntotal_df = read_data(\"train\")\n# train/valid split\ntrain_df, valid_df = split_df(total_df, valid = VALID_RATIO)\n\ntest_df = read_data(\"test\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_df.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.vc(\"activity\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_df.vc(\"activity\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualize data signal pattern"},{"metadata":{},"cell_type":"markdown","source":"We have 561 input features at our disposal"},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_nums = train_df.query(\"activity=='LAYING'\").values[:200,2:].shape[1]\nfeature_nums","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(train_df.query(\"activity=='LAYING'\").values[:200,2:].astype(np.float32))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(train_df.query(\"activity=='STANDING'\").values[:200,2:].astype(np.float32))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(train_df.query(\"activity=='WALKING_UPSTAIRS'\").values[:200,2:].astype(np.float32))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Build up dataloader"},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.utils.data import DataLoader,Dataset","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have a pretty balanced dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_map = dict((v,k) for k,v in enumerate(train_df.vc(\"activity\").index))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Target categories mapped to indices"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_map","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ArrayDs(Dataset):\n    def __init__(self, df, y_map=y_map):\n        self.df = df\n        self.y_map = y_map\n        self.Xs = self.df.values[:,2:].astype(np.float32)\n        if 'activity' in self.df.columns:\n            self.has_y = True\n            self.Ys = self.df['activity'].apply(lambda x:y_map[x]).values\n        else:\n            self.has_y = False\n        \n    def __len__(self): return len(self.df)\n    \n    def __getitem__(self,idx):\n        if self.has_y:\n            return self.Xs[idx],self.Ys[idx]\n        else:\n            return self.Xs[idx]\n    \ndef get_data_dl(df: pd.DataFrame, batch_size: int=128, shuffle=False) -> DataLoader:\n    ds = ArrayDs(df)\n    return DataLoader(ds, shuffle=shuffle, batch_size=batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x, y = ArrayDs(train_df,)[6]\n\nx, y","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training boiler template\n\n> You can also use sklearn at this part"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install -q pytorch-lightning==1.0.4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pytorch_lightning import LightningDataModule, LightningModule\nimport pytorch_lightning as pl\n\nclass AllData(LightningDataModule):\n    def __init__(self):\n        super().__init__()\n        \n    def prepare_data(self):\n        self.total_df = read_data(\"train\")\n        # train/valid split\n        self.train_df, self.valid_df = split_df(\n            self.total_df, valid = VALID_RATIO)\n        \n        self.test_df = read_data(\"test\")\n    \n    def train_dataloader(self): return get_data_dl(\n        self.train_df, shuffle=True)\n    \n    def val_dataloader(self): return get_data_dl(self.valid_df)\n    \n    def test_dataloader(self): return get_data_dl(self.test_df)\n    \n\nclass ltModule(LightningModule):\n    def __init__(self, base_model):\n        super().__init__()\n        self.base_model = base_model\n        self.crit = nn.CrossEntropyLoss()\n        self.accuracy = pl.metrics.Accuracy()\n            \n    def configure_optimizers(self):\n        opt = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return opt\n    \n    def forward(self, x): return self.base_model(x)\n    \n    def forward_pass(self, batch):\n        x, y = batch\n        y_ = self(x)\n        loss = self.crit(y_,y)\n        acc = self.accuracy(y_.argmax(dim=-1),y)\n        return {'loss': loss, 'acc':acc}\n        \n    def training_step(self, batch, batch_idx): return self.forward_pass(batch)\n        \n    def validation_step(self, batch, batch_idx): return self.forward_pass(batch)\n    \n    def print_acc(self, outputs, phase):\n        avg_acc = torch.stack([x['acc'] for x in outputs]).mean()\n        print(f\"[{phase}]\\tAccuracy:\\t{int(avg_acc.item()*100)}%\", end=\"\\t\")\n    \n    def training_epoch_end(self, outputs):\n        self.print_acc(outputs, \"TRAIN\")\n\n    def validation_epoch_end(self, outputs):\n        self.print_acc(outputs, \"VALID\")\n\ndef learn(base_model, max_epochs=5):\n    \"\"\"\n    Train the model automatially, the entire pipeline\n    \"\"\"\n    all_data = AllData()\n    module = ltModule(base_model)\n    trainer = pl.Trainer(max_epochs=max_epochs)\n    trainer.fit(model = module, datamodule=all_data, )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Linear relation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# create linear model\nlinear_model = nn.Linear(feature_nums,len(y_map))\n\n# learning process\nlearn(linear_model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Break Linearity\n\n> Basic neural network"},{"metadata":{"trusted":true},"cell_type":"code","source":"HIDDEN_SIZE = 512\n\n# create model structure\nneural_network = nn.Sequential(\n    nn.Linear(feature_nums, HIDDEN_SIZE),\n    nn.BatchNorm1d(HIDDEN_SIZE),\n    nn.ReLU(),\n    nn.Linear(HIDDEN_SIZE, len(y_map))\n)\n\n# learning process\nlearn(neural_network)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualize"},{"metadata":{},"cell_type":"markdown","source":"### Weights structure"},{"metadata":{"trusted":true},"cell_type":"code","source":"def print_param_shape(model) -> pd.DataFrame:\n    \"\"\"print out the parameter shapes of a model\"\"\"\n    return pd.DataFrame(list({\"name\":k, \"shape\":tuple(p.T.shape)} \n        for k,p in model.named_parameters()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print_param_shape(linear_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print_param_shape(neural_network)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Find influence"},{"metadata":{},"cell_type":"markdown","source":"Input features, we print out the first 50 features of our input columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_map = np.array(total_df.columns[2:])\nprint('\\t'.join(x_map[:50]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Output categories"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_map","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"linear_weight = linear_model.weight.data.T\nlinear_weight, linear_weight.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"most_influential_rank = linear_weight.abs().sum(-1).argsort(descending=True).numpy()\n\nx_map[most_influential_rank][:30]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px\ndef plot_heat(w,xname,yname,x,y,x_axis_top=True, height=None):\n    pca = PCA(1,)\n    new_order = pca.fit_transform(w)[:,0].argsort()\n    new_w = w[new_order,:].T\n\n    fig = px.imshow(new_w,\n                    labels = dict(x=xname,y=yname),\n                    x=x[new_order],y=y)\n    if x_axis_top:\n        fig.update_xaxes(side=\"top\")\n    if height:\n        fig.update_layout(height=height)\n    fig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Linear visualize\n> We visualize the influences directly from ```input``` features to ```output``` categories\n\nThe size of the weights are 561 columns x 6 labels\n\nHere we pick the most influential 30 input features for visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_heat(\n    w=linear_weight[most_influential_rank][:30],\n    xname=\"features\",\n    yname=\"activities\",\n    x=x_map[most_influential_rank][:30],\n    y=np.array(list(y_map.keys()))\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_heat(\n    w=linear_model.bias.data.numpy()[None,:],\n    xname=\"bias\",\n    yname=\"activities\",\n    x=np.array([\"bias_layer\",]),\n    y=np.array(list(y_map.keys()))\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"neural_network[0],neural_network[3]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Break linearity\n> But linearity can not simulate a full spectrum of ```OR, AND, XOR``` logic gates, the weight $W_{ij}$ simply tells \"the bigger/smaller $X_{i}$ the better for lable $Y_{j}$\"\n\n> Before neural network, what people usually tried, is the complicated feature enginearing to break linearity: to treat things like $X_{1}^2X_{2}, X_{1}X_{2}^2, X_{1}^2X_{2}^2, X_{1}^3X_{2}$... as extra part of input dimension \n\n\n### Where does hidden layer comes in \nInstead of $X_{i} \\times W_{ij} => Y_{j}$, we do $X_{i} \\times L1_{ik} => H_{k}, H_{k}\\times L2_{kj} => Y_{j}$\n\n> Neural network just using a linear model to fit input into hidden neurons (summarize input features into a middle layer), then use another linear model to fit hidden neurons into output. Hence breaking the linearity.\n\n### Visualize input to hidden layer\n> We pick first 80 input features and first 30 hidden neurons to visualize"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_heat(\n    w=neural_network[0].weight.data.T[:80,:30],\n    xname=\"features\",\n    yname=\"hidden_feature\",\n    x=x_map[:80],\n    y=np.arange(30)\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualize hidden layer to output\n\n> We pick first 30 hidden neurons to all our output categories for visualize"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_heat(\n    w=neural_network[3].weight.data.T[:30,:],\n    xname=\"hidden_feature\",\n    yname=\"activity\",\n    x=np.array(list(map(lambda i:f\"H{i}\",range(30)))),\n    y=np.array(list(y_map.keys())),\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# What goes from here"},{"metadata":{},"cell_type":"markdown","source":"### Use the same model weights through time over and over again"},{"metadata":{},"cell_type":"markdown","source":"If a sentence, eg. ```I will not fear. Fear is the mind-killer. I will face my fear. I will let it pass through me. When the fear has gone, there shall be nothing. Only I will remain.```"},{"metadata":{},"cell_type":"markdown","source":"f(\"I will not fe\") => \"a\"\n\nf(\" will not fea\") => \"r\"\n\nf(\"will not fear\") => \".\"\n\n...\n\nf(\"Only I will re\") => \"m\"\n\nf(\"nly I will rem\") => \"a\"\n\nf(\"ly I will rema\") => \"i\"\n\nf(\"y I will remai\") => \"n\""},{"metadata":{},"cell_type":"markdown","source":"Here $f(x)$ should not be different models depend on where we at within the sentence. It should be one single model that being ran **recurrently**. Hence the term RNN(recurrent neural networks)"},{"metadata":{},"cell_type":"markdown","source":"### Use the same model weights through space over and over again"},{"metadata":{},"cell_type":"markdown","source":"### Stuck an Neural network in Bellman equation\n\n$\\large V^{\\pi*}(s)=  \\max_a \\{ {R(s,a) + \\gamma \\sum_{s'} P(s'|s,a) V^{\\pi*}(s')} \\}.\\ $\n\nBut [with deep nn you can play all sorts of atari game](https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf)"},{"metadata":{},"cell_type":"markdown","source":"# Let several models play with/ teach /fight each other\n\nWith [this paper](https://arxiv.org/pdf/1406.2661.pdf) end up from a bar fight, people start to play with serveral models interacting together.\n\nAnd this [imaginative paper](https://arxiv.org/pdf/1703.10593.pdf) is one of the good example"},{"metadata":{},"cell_type":"markdown","source":"# How to start?"},{"metadata":{},"cell_type":"markdown","source":"* For genomicarers. Just look for ðŸ’ªRayðŸ˜²\n* Mostly, python\n* [Kaggle](www.kaggle.com): competitions, notebooks to boost start the unfamiliar problem set\n* [fast.ai](fast.ai): a tutorial:\n    * almost writing a DL library from scratch\n    \n## Environments\n\n* [Google Colab](https://colab.research.google.com/), free environment, GPU/TPU\n* Kaggle kernels, also free environment, GPU/TPU"},{"metadata":{},"cell_type":"markdown","source":"## About Ray\n* [Kaggle profile](https://www.kaggle.com/raynardj)\n    * Competition notes for [Understanding Clouds from Satellite Images](https://github.com/iofthetiger/ucsi)\n    * and [Global Wheat Detection](https://github.com/iofthetiger/gwd)\n    * and [Recursion Cell Image Classification](https://github.com/raynardj/python4ml/tree/master/experiments/rcic)\n* My [experiments](https://genomicare.github.io/docs/docs/experiments/) at genomicare\n* My [python tutorial](https://github.com/raynardj/python4ml) designed for machine learning"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}