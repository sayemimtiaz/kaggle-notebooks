{"cells":[{"metadata":{},"cell_type":"markdown","source":"IN SEARCH OF LOST TIME\n\nIn Search of Lost Time (French: √Ä la recherche du temps perdu), also translated as Remembrance of Things Past, is a novel in seven volumes by Marcel Proust (1871‚Äì1922). It is his most prominent work, known both for its length and its theme of involuntary memory; the most famous example of this is the \"episode of the madeleine,\" which occurs early in the first volume. It gained fame in English in translations by C. K. Scott Moncrieff and Terence Kilmartin as Remembrance of Things Past, but the title In Search of Lost Time, a literal rendering of the French, became ascendant after D. J. Enright adopted it for his revised translation published in 1992.\nhttps://en.wikipedia.org/wiki/In_Search_of_Lost_Time"},{"metadata":{},"cell_type":"markdown","source":"![](https://i1.wp.com/cgfewston.me/wp-content/uploads/2018/02/quote-how-about-proust-s-in-search-of-lost-time-tamaru-asked-if-you-ve-never-read-it-this-haruki-murakami-50-11-94.jpg?resize=814%2C335&ssl=1)cgfwston.me"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.graph_objs as go\nimport plotly.offline as py\nimport plotly.express as px\nfrom plotly.offline import iplot\nimport seaborn\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"from tensorflow.keras import utils\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import models\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\n\nimport tensorflow as tf\n\nimport numpy as np\nimport pandas as pd\n\nimport nltk\nfrom nltk.tokenize.treebank import TreebankWordDetokenizer\nnltk.download('punkt')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Codes by Erin Ward  https://www.kaggle.com/eward96/derry-girls-new-script-generator"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def process(text):\n    with open (text, \"r\", encoding = \"ISO-8859-1\") as file:\n        data=file.readlines()\n        script = \"\"\n        for i in data:\n            i = i.lower().replace('\"', '').replace(\"\\n\", \" \\n \")\n            if i.strip() != \"\":\n                script += \"\".join(i).replace(\"\\n\",\" \\n \")\n        return script","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df = process(\"../input/marcel-proust-in-search-of-lost-time/proust_dataset_ENG.csv\") \nprint(df[0:2000])","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"Text_Data = df\n\ncharindex = list(set(Text_Data))\ncharindex.sort() \nprint(charindex)\n\nnp.save(\"charindex.npy\", charindex)\n\nprint(len(Text_Data))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#The snippet below take so long that I could read the Whole Proust till I wait for it.\n\nFake, that's just a figure of speech."},{"metadata":{"trusted":true},"cell_type":"code","source":"chars_size = len(charindex)\nseq_len = 80\n\nx_train = []\ny_train = []\n\nfor i in range(0, len(Text_Data)-seq_len, 1 ): \n    X = Text_Data[i:i + seq_len]\n    Y = Text_Data[i + seq_len]\n    x_train.append([charindex.index(x) for x in X])\n    y_train.append(charindex.index(Y))\n\nx_train = np.reshape(x_train, (len(x_train), seq_len))\n\ny_train = utils.to_categorical(y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"LSTMs (Long Short Term Memory networks) are excellent for learning and generating text, because they are capable of learning long-term dependencies. Dropout is also super important here to avoid overfitting!"},{"metadata":{"trusted":true},"cell_type":"code","source":"#LSTMs (Long Short Term Memory networks) are excellent for learning and generating text.üèª\n\ndef LSTM_model():\n    model = models.Sequential()\n    inp = layers.Input(shape=(seq_len, ))\n    x = layers.Embedding(chars_size, 80, trainable=False)(inp)\n    x = tf.compat.v1.keras.layers.CuDNNLSTM(1024, return_sequences=True,)(x)\n    x = tf.compat.v1.keras.layers.CuDNNLSTM(512, return_sequences=True,)(x)\n    x = tf.compat.v1.keras.layers.CuDNNLSTM(256,)(x)\n    x = layers.Dropout(0.2)(x)\n    x = layers.Dense(256, activation=\"elu\")(x)\n    x = layers.Dense(128, activation=\"elu\")(x)\n    x = layers.Dropout(0.2)(x)\n    outp = layers.Dense(chars_size, activation='softmax')(x)\n    \n    model = models.Model(inputs=inp, outputs=outp)\n    model.compile(loss='categorical_crossentropy',\n                  optimizer=optimizers.Adam(lr=0.0008),\n                  metrics=['accuracy']\n                 )\n\n    return model\n\nmodel = LSTM_model()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true,"collapsed":true},"cell_type":"code","source":"model.fit(x_train, y_train,\n          batch_size=128,\n          epochs=3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#It was epochs=70. Doesn't matter, 70 or 3 epochs, both resulted in ERROR."},{"metadata":{},"cell_type":"markdown","source":"#Codes by Rithesh Yadav https://www.kaggle.com/ritesh2000/spacy-guide-all-in-one/notebook"},{"metadata":{"_kg_hide-output":true,"trusted":true,"collapsed":true},"cell_type":"code","source":"!pip install -U spacy","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true,"collapsed":true},"cell_type":"code","source":"!python -m spacy download en_core_web_lg","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true,"collapsed":true},"cell_type":"code","source":"!python -m spacy download en_core_web_sm","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"import spacy\nfrom spacy import displacy\nnlp = spacy.load(\"en_core_web_sm\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"doc = nlp(\"I could hear the whistling of trains,which, now nearer and now farther off\")\nfor token in doc:\n    print(token.text, token.pos_, token.dep_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a nlp object\ndoc = nlp(\"punctuating the distance like the note of a bird in a forest\")","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"nlp.pipe_names","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"nlp.disable_pipes('tagger', 'parser')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"nlp.pipe_names","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Though I have import spacy AND nlp spacy load Before. It didn't work without Importing it AGAIN!"},{"metadata":{},"cell_type":"markdown","source":"#Tokenization"},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"import spacy\n\nnlp = spacy.load('en_core_web_sm')\n\ndoc = nlp(\"punctuating the distance like the note of a bird in a forest\")\nfor token in doc:\n    print(token.text)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Part-Of-Speech (POS) Tagging"},{"metadata":{"trusted":true},"cell_type":"code","source":"nlp = spacy.load('en_core_web_sm')\n\n# Create an nlp object\ndoc = nlp(\"punctuating the distance like the note of a bird in a forest\")\n \n# Iterate over the tokens\nfor token in doc:\n    # Print the token and its part-of-speech tag\n    print(token, token.tag_, token.pos_, spacy.explain(token.tag_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from spacy import displacy\n\ndoc = nlp(\"punctuating the distance like the note of a bird in a forest\")\ndisplacy.render(doc, style=\"dep\" , jupyter=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Dependency Parsing"},{"metadata":{"trusted":true},"cell_type":"code","source":"nlp = spacy.load('en_core_web_sm')\n\n# Create an nlp object\ndoc = nlp(\"punctuating the distance like the note of a bird in a forest\")\n \n# Iterate over the tokens\nfor token in doc:\n    # Print the token and its part-of-speech tag\n    print(token.text, \"-->\", token.dep_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"spacy.explain(\"nsubj\"), spacy.explain(\"ROOT\"), spacy.explain(\"aux\"),spacy.explain('nmod'), spacy.explain(\"advcl\"), spacy.explain(\"dobj\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Lemmatization"},{"metadata":{"trusted":true},"cell_type":"code","source":"nlp = spacy.load('en_core_web_sm')\n\n# Create an nlp object\ndoc = nlp(\"punctuating the distance like the note of a bird in a forest\")\n \n# Iterate over the tokens\nfor token in doc:\n    # Print the token and its part-of-speech tag\n    print(token.text, \"-->\", token.lemma_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Sentence Boundary Detection (SBD)\n\nThat returns the number of Sentences."},{"metadata":{"trusted":true},"cell_type":"code","source":"nlp = spacy.load('en_core_web_sm')\n\n# Create an nlp object\ndoc = nlp(\"To doing unusual things. To the last words of conversation. To farewells exchanged beneath an unfamiliar lamp which echoed still in his ears amid the silence of the night\")\n \nsentences = list(doc.sents)\nlen(sentences)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for sentence in sentences:\n     print (sentence)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nlp = spacy.load(\"en_core_web_sm\")\ndoc = nlp(\"To doing unusual things. To the last words of conversation. To farewells exchanged beneath an unfamiliar lamp which echoed still in his ears amid the silence of the night\")\n#See the entity present\nprint(doc.ents)\nfor ent in doc.ents:\n    print(ent.text, ent.start_char, ent.end_char, ent.label_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Entity Detection"},{"metadata":{"trusted":true},"cell_type":"code","source":"from spacy import displacy\nnlp = spacy.load(\"en_core_web_sm\")\n\ndoc= nlp(u\"\"\"for a long time I used to go to bed early. sometimes, when I had put out my candle,\nmy eyes would close so quickly that I had not even time to say that I am going to sleep. and half an hour later\nthe thought that it was time to go to sleep would awaken me; I would try to put away the book which, I imagined,\nwas still in my hands, and to blow out the light; I had been thinking all the time, while I was asleep, \nof what I had just been reading, but my thoughts had run into a channel of their own, \nuntil I myself seemed actually to have become the subject of my book: a church, a quartet, the rivalry between Fran√ßois I and Charles V. This impression would persist for some moments after I was awake; it did not disturb my mind, but it lay like scales upon my eyes and prevented them from registering the fact that the candle was no longer burning. then it would begin to seem unintelligible, as the thoughts of a former existence must be to a reincarnate spirit; the subject of my book would separate itself from me, leaving me free to choose whether I would form part of it or no; and at the same time my sight would return and I would be astonished to find myself in a state of darkness, pleasant and restful enough for the eyes, and even more, perhaps, for my mind, to which it appeared incomprehensible, without a cause, a matter dark indeed.@1@1  \n  1 I would ask myself what o'clock it could be; I could hear the whistling of trains, which, now nearer and now farther off, punctuating the distance like the note of a bird in a forest, shewed me in perspective the deserted countryside through which a traveller would be hurrying towards the nearest station: the path that he followed being fixed for ever in his memory by the general excitement due to being in a strange place, to doing unusual things, to the last words of conversation, to farewells exchanged beneath an unfamiliar lamp which echoed still in his ears amid the silence of the night\n \"\"\")\n\nentities=[(i, i.label_, i.label) for i in doc.ents]\nentities","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"displacy.render(doc, style = \"ent\",jupyter = True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nlp = spacy.load(\"en_core_web_lg\")\ntokens = nlp(\"punctuating the distance like the note of a bird in a forest. Even Proust has Birds in his Words!\")\n\nfor token in tokens:\n    print(token.text, token.has_vector, token.vector_norm, token.is_oov)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Proust without Madeleines it's not Proust.\n\n![](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRCZeV_UyxJ1hXp-7U_qGmjb68YPWJQhQKsUw&usqp=CAU)forademim.com.br"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#Code by Olga Belitskaya https://www.kaggle.com/olgabelitskaya/sequential-data/comments\nfrom IPython.display import display,HTML\nc1,c2,f1,f2,fs1,fs2=\\\n'#2B3A67','#42a7f5','Akronim','Smokum',30,15\ndef dhtml(string,fontcolor=c1,font=f1,fontsize=fs1):\n    display(HTML(\"\"\"<style>\n    @import 'https://fonts.googleapis.com/css?family=\"\"\"\\\n    +font+\"\"\"&effect=3d-float';</style>\n    <h1 class='font-effect-3d-float' style='font-family:\"\"\"+\\\n    font+\"\"\"; color:\"\"\"+fontcolor+\"\"\"; font-size:\"\"\"+\\\n    str(fontsize)+\"\"\"px;'>%s</h1>\"\"\"%string))\n    \n    \ndhtml('Be patient. Mar√≠lia Prata, @mpwolke was Here.' )","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}