{"cells":[{"metadata":{},"cell_type":"markdown","source":"# 3 million Sudoku puzzles with ratings\n\nDavid Radcliffe (dradcliffe@gmail.com), 2020-01-06.\n\n## Overview\n\nThis is a notebook to accompany the dataset [3 million Sudoku puzzles with ratings](https://www.kaggle.com/radcliffe/3-million-sudoku-puzzles-with-ratings). The dataset contains 3 million Sudoku puzzles, with solutions and estimated difficulty ratings.\n\nThere are five columns:\n * **id:** Unique id number.\n * **puzzle:** A string of 81 characters, representing an incomplete Sudoku grid. Peridos indicate unknown values.\n * **solution:** A string of 81 digits between 1 and 9, representing a completed Sudoku grid.\n * **clues:** The number of clues (givens) in the puzzle.\n * **difficulty:** The estimated difficulty rating."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"filename = '/kaggle/input/3-million-sudoku-puzzles-with-ratings/sudoku-3m.csv'\ndf = pd.read_csv(filename)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's take a look at the first puzzle."},{"metadata":{"trusted":true},"cell_type":"code","source":"def view_grid(puzzle_string):\n    return pd.DataFrame(np.array(list(puzzle_string.replace('.', ' '))).reshape((9, 9)))\n\nview_grid(df.puzzle[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"view_grid(df.solution[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The number of clues ranges from 19 to 31, but most puzzles have between 23 and 26 clues. The smallest possible number of clues for a well-formed Sudoku puzzle is 17, but these are difficult to generate. There are no 17-clue puzzles in our dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby('clues').size().reset_index(name='count')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The difficulty ratings vary from 0 to 8.5, but most of the ratings are less than 4.0. Nearly half of the puzzles have difficulty zero, which means that they can be solved by a simple scanning procedure."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.difficulty.hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(data = {'Value': [\n    np.min(df.difficulty),\n    np.max(df.difficulty),\n    np.mean(df.difficulty),\n    100 * np.mean(df.difficulty == 0),\n    100 * np.mean(df.difficulty < 4)\n]}, index = [\n    'Min',\n    'Max',\n    'Mean',\n    'Percent = 0',\n    'Percent < 4'\n])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Sudoku data generator\n\nThis section contains code for a data generator, which yields data in batches. The default batch size is 32.\nOn each iteration, the generator yields four numpy arrays.\n\n* **puzzles:** An array of shape (32, 9, 9) containing 32 incomplete Sudoku grids.\n* **solutions:** An array of shape (32, 9, 9) containing 32 completed Sudoku grids.\n* **clues:** An array of shape (32,) containing the number of clues in each incomplete grid.\n* **difficulty:** An array of shape (32,) containing the difficulty ratings of the puzzles.\n\nThe generator has the option of applying random transformations to the grid, from the following list.\n\n* Relabeling symbols\n* Band permutations\n* Row permutations within a band\n* Stack permutations\n* Column permutations within a stack\n* Transposition\n\n(See https://en.wikipedia.org/wiki/Mathematics_of_Sudoku#Enumerating_essentially_different_Sudoku_solutions)\n\nThese transformations effectively increase the number of records by a factor of \n$6^8 \\times 2 \\times 9! = \\text{1,218,998,108,160}$. (Actually, a bit less than this, due to\n[automorphic grids](https://en.wikipedia.org/wiki/Mathematics_of_Sudoku#Automorphic_Sudokus).)\n\nI used a [script](https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly) from \nShervine Amidi's blog as a starting point for my generator."},{"metadata":{"trusted":true},"cell_type":"code","source":"from random import shuffle\nimport keras\nimport sklearn\n\n\nclass DataGenerator(keras.utils.Sequence):\n\n    def __init__(self, list_IDs, batch_size=32, nrows=None, shuffle=True, transform=True):\n        self.batch_size = batch_size\n        self.list_IDs = list_IDs\n        self.shuffle = shuffle\n        self.transform = transform\n        self.load_data(nrows=nrows)\n        self.on_epoch_end()\n    \n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) / self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n\n        # Find list of IDs\n        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n\n        # Generate data\n        X, y, clues, difficulty = self.data_generation(list_IDs_temp)\n\n        return X, y, clues, difficulty\n    \n    def load_data(self, nrows=None):\n        df = pd.read_csv(filename, nrows=nrows)\n        string_to_array = lambda s: np.array(list(map(int, s.replace('.', '0')))).reshape((9, 9))\n        self.puzzles = np.stack(df['puzzle'].apply(string_to_array))\n        self.solutions = np.stack(df['solution'].apply(string_to_array))\n        self.clues = np.array(df['clues'])\n        self.difficulty = np.array(df['difficulty'])\n\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n    \n    def data_generation(self, list_IDs_temp):\n        'Generates data containing batch_size samples'\n        # Initialization\n        puzzles = self.puzzles[list_IDs_temp]\n        solutions = self.solutions[list_IDs_temp]\n        clues = self.clues[list_IDs_temp]\n        difficulty = self.difficulty[list_IDs_temp]\n        if self.transform:\n            self.transform_grids(puzzles, solutions)\n        \n        return puzzles, solutions, clues, difficulty\n    \n    def transform_grids(self, X, y):\n    \n        def axis_permutation():\n            x = [0, 1, 2]\n            y = [3, 4, 5]\n            z = [6, 7, 8]\n            p = [x, y, z]\n            shuffle(x)\n            shuffle(y)\n            shuffle(z)\n            shuffle(p)\n            return p[0] + p[1] + p[2]\n        \n        def relabel_cells(X, y):\n            p = list(range(1, 10))\n            shuffle(p)\n            X = sum(p[i - 1] * (X == i) for i in range(1, 10))\n            y = sum(p[i - 1] * (y == i) for i in range(1, 10))\n            return X, y\n        \n        p = axis_permutation()\n        q = axis_permutation()\n        X = X[:, p][:, :, q]\n        y = y[:, p][:, :, q]\n        if np.random.rand() > 0.5:\n            X = X.transpose((0, 2, 1))\n            y = y.transpose((0, 2, 1))\n        \n        X, y = relabel_cells(X, y)\n        return X, y","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here is an example of how the data generator could be used. We will load just the first 1000 rows of the data set, and split them into a training set and a test set. Then we will iterate through the training set once (i.e. a single epoch) in batches of 32.\n\nBe aware that loading all 3 million rows will take several minutes. I recommend experimenting with small subsets before loading the entire dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nids = list(range(1000))\ntrain_ids, test_ids = train_test_split(ids, test_size=0.33)\n\ntraining_generator = DataGenerator(train_ids, batch_size=32, nrows=1000)\nfor X, y, clues, difficulty in training_generator:\n    print(*clues)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}