{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Key insights summary\n\n### (1) For predicting the 2-years default (<code>SeriousDlqin2yrs</code>), the following 7 columns are useful:\n* <code>RevolvingUtilizationOfUnsecuredLines</code> correlation with the target 0.28\n* <code>DebtRatio</code>\n* <code>NumberOfOpenCreditLinesAndLoans</code>\n* <code>age</code>\n* <code>NumberOfTime30-59DaysPastDueNotWorse</code> correlation with the target 0.28\n* <code>NumberOfTime60-89DaysPastDueNotWorse</code> correlation with the target 0.27\n* <code>NumberOfTimes90DaysLate</code>: correlation with the target 0.32\n    \nIn other words, there is no need to use extra resources to obtain and/or increase the quality of the <code>MonthlyIncome</code> and <code>NumberOfDependents</code> data.\n\n### (2) RevolvingUtilizationOfUnsecuredLines is a great predictor for the 2-year default, effective for all age groups\nMore than half of all defaulted users have the <code>RevolvingUtilizationOfUnsecuredLines</code> above 0.8,<br>but only 18% of non-defaulted users are above that value.\n\n\n### (3) More users default at younger age\nHalf of all defaults are happening before 45, while the average are of the non-default user is around 52.<br>\nNoticeably, younger age groups (20 ~ 40) have the highest concentration of users with high <code>RevolvingUtilizationOfUnsecuredLines</code>.\n\n### (4) Average DebtRatio of the default users is above 0.4 for over 40 age group\nFor the non-default users, the average <code>DebtRatio</code> is at 0.33 for the 40~50 age group, and from there decreases<br>\nto below 0.2 for users over 80. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Step 0: Environment preparation, data load, brief quality check","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preparing essentials environment\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib import rc\nfrom sklearn import preprocessing\nfrom itertools import cycle\npd.options.mode.chained_assignment = None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reading CSV data\ndf = pd.read_csv('../input/give-me-some-credit-dataset/cs-training.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the data types and column names\ndf.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the data top 15 rows \ndf.head(15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Observations from the sample:**\n* <code>Unnamed: 0</code> is most likely the \"id\" column\n* <code>DebtRatio</code> has unexpected (> 1) values\n* <code>MonthlyIncome</code> has unexpected (NaN, 0) values\n* <code>NumberOfDependants</code> has unexpected (NaN) values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking basic stats\nrs = round(df.describe(), 2)\nrs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Renaming the first column to \"id\"\ndf.rename(\n    columns = {'Unnamed: 0':'id'},\n    inplace = True\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Counting empty cells in each column\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Quick notes about the data quality:\n* <code>RevolvingUtilizationOfUnsecuredLines</code>: contains wrong data (max = 50708.00), needs cleaning\n* <code>age</code>: contains wrong data (min = 0.00), needs cleaning\n* <code>NumberOfTime30-59DaysPastDueNotWorse</code>: seems fine\n* <code>DebtRatio</code>: seems off when MonthlyIncome is \"NaN\", contains wrong data (max = 329664.00), needs cleaning\n* <code>MonthlyIncome</code>: 19.8% are \"NaN\" values, some outliers (min = 0, max = 3,008,750) >> needs cleaning, possibly splitting the dataset in 2 to build the model if this is a good predictor\n* <code>NumberOfOpenCreditLinesAndLoans</code>: seems fine\n* <code>NumberOfTimes90DaysLate</code>: seems fine \n* <code>NumberRealEstateLoansOrLines</code>: seems fine \n* <code>NumberOfTime60-89DaysPastDueNotWorse</code>: seems fine\n* <code>NumberOfDependents</code>: 2.6% are \"NaN\" values, needs cleaning","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Step 1: Data cleaning: wrong values, nulls, outliers, etc.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 1) RevolvingUtilizationOfUnsecuredLines","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the issues with RevolvingUtilizationOfUnsecuredLines\ndf[df[\"RevolvingUtilizationOfUnsecuredLines\"] > 2].sample(n = 30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# There seems to be no clear source of the issue (i.e. no connection with other columns) for the wrong values\n# Checking how many RevolvingUtilizationOfUnsecuredLines values are over 2\ndf[\"id\"][df[\"RevolvingUtilizationOfUnsecuredLines\"] >= 2].count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking RevolvingUtilizationOfUnsecuredLines for outliers (Q1 - 1.5*IQR, Q3 + 1.5*IQR)\nplt.figure(figsize = (4,8))\na = sns.boxplot(\n    y = \"RevolvingUtilizationOfUnsecuredLines\", \n    x = \"SeriousDlqin2yrs\",\n    data = df\n)\na.set(\n    ylim = (0, 2)\n);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Data prep actions memo:\n* <code>RevolvingUtilizationOfUnsecuredLines</code> limit at 1.9","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 2) age","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.sort_values(by = [\"age\"]).head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.sort_values(by = [\"age\"], ascending = False).head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Data prep actions memo:\n* <code>RevolvingUtilizationOfUnsecuredLines</code> limit at 1.4\n* <code>age</code> remove one row with 0","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 3) NumberOfTime30-59DaysPastDueNotWorse, NumberOfTime60-89DaysPastDueNotWorse, NumberOfTimes90DaysLate","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['NumberOfTime30-59DaysPastDueNotWorse'].value_counts().sort_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['NumberOfTime60-89DaysPastDueNotWorse'].value_counts().sort_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['NumberOfTimes90DaysLate'].value_counts().sort_index()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Data prep actions memo:\n* <code>RevolvingUtilizationOfUnsecuredLines</code> limit at 1.9\n* <code>age</code> remove one row with 0\n* <code>NumberOfTime30-59DaysPastDueNotWorse</code>: clip at 5 to exclude values \"96\" and \"98\"\n* <code>NumberOfTime60-89DaysPastDueNotWorse</code>: clip at 5 to exclude values \"96\" and \"98\"\n* <code>NumberOfTimes90DaysLate</code>: clip at 6 to exclude values \"96\" and \"98\"","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 4) MonthlyIncome and DebtRatio","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the data when MonthlyIncome is null \nrs = round(df[df[\"MonthlyIncome\"].isnull()].describe(), 2)\nrs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Seems like when MonthlyIncome is null, DebtRatio is 100% wrong (i.e. way over 1, which should be it's max value by definition)...\nplt.figure(figsize = (16,5))\n\na = sns.boxplot(\n    y = \"DebtRatio\",\n    x = pd.qcut((df[df[\"MonthlyIncome\"].isnull()][\"age\"]), 15),\n    data = df[df[\"MonthlyIncome\"].isnull()]\n)\n\na.set(\n    ylim = (0, 9000)\n)\n\nplt.setp(\n    a.get_xticklabels(), \n    rotation = 55\n);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ... and when MonthlyIncome is not null, DebtRatio is behaving as expected and could be considered as \"correct\"\nplt.figure(figsize = (16,10))\n\na = sns.boxplot(\n    y = \"DebtRatio\",\n    x = pd.qcut((df[df[\"MonthlyIncome\"] > 0][\"age\"]), 15),\n    data = df[df[\"MonthlyIncome\"] > 0]\n)\n\na.set(\n    ylim = (0, 10)\n)\n\nplt.setp(\n    a.get_xticklabels(), \n    rotation = 55\n);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df[\"MonthlyIncome\"] > 0]['DebtRatio'].value_counts().sort_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df[\"MonthlyIncome\"] > 0]['DebtRatio'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df[\"MonthlyIncome\"] > 0]['MonthlyIncome'].quantile(.02)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df[\"MonthlyIncome\"] > 0]['MonthlyIncome'].quantile(.98)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Data prep actions memo:\n* <code>RevolvingUtilizationOfUnsecuredLines</code> limit at 1.9\n* <code>age</code> remove one row with 0\n* <code>NumberOfTime30-59DaysPastDueNotWorse</code>: clip at 5 to exclude values \"96\" and \"98\"\n* <code>NumberOfTime60-89DaysPastDueNotWorse</code>: clip at 5 to exclude values \"96\" and \"98\"\n* <code>NumberOfTimes90DaysLate</code>: clip at 6 to exclude values \"96\" and \"98\"\n* <code>MonthlyIncome</code>: remove nulls for analysis, clip between 800 and 20,000\n* <code>DebtRatio</code>: after removing MonthlyIncome null data the distribuion should be back to as expected, limit at 50 and clip at 1.2\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 5) NumberOfOpenCreditLinesAndLoans","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking NumberOfOpenCreditLinesAndLoans for outliers (Q1 - 1.5*IQR, Q3 + 1.5*IQR)\nplt.figure(figsize = (4,8))\n\na = sns.boxplot(\n    y = \"NumberOfOpenCreditLinesAndLoans\",\n    x =\"SeriousDlqin2yrs\",  \n    data = df\n);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 6) NumberRealEstateLoansOrLines","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking NumberRealEstateLoansOrLines for outliers (Q1 - 1.5*IQR, Q3 + 1.5*IQR)\nplt.figure(figsize = (4,8))\n\na = sns.boxplot(\n    y = \"NumberRealEstateLoansOrLines\",\n    x =\"SeriousDlqin2yrs\",  \n    data = df\n);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 7) NumberOfDependents","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking NumberOfDependents for outliers (Q1 - 1.5*IQR, Q3 + 1.5*IQR)\nplt.figure(figsize = (4,8))\n\na = sns.boxplot(\n    y = \"NumberOfDependents\",\n    x =\"SeriousDlqin2yrs\",  \n    data = df\n);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Data prep actions memo:\n* <code>RevolvingUtilizationOfUnsecuredLines</code> limit at 1.9\n* <code>age</code> remove one row with 0\n* <code>NumberOfTime30-59DaysPastDueNotWorse</code>: clip at 5 to exclude values \"96\" and \"98\"\n* <code>NumberOfTime60-89DaysPastDueNotWorse</code>: clip at 5 to exclude values \"96\" and \"98\"\n* <code>NumberOfTimes90DaysLate</code>: clip at 6 to exclude values \"96\" and \"98\"\n* <code>MonthlyIncome</code>: remove nulls for analysis, clip between 800 and 20,000\n* <code>DebtRatio</code>: after removing MonthlyIncome null data the distribuion should be back to as expected, limit at 50 and clip at 1.2\n* <code>NumberOfOpenCreditLinesAndLoans</code>: clip at 20\n* <code>NumberRealEstateLoansOrLines</code>: clip at 5\n* <code>NumberOfDependents</code>: clip at 5","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Step 2: Making a clean dataset, EDA","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating a clean dataset for EDA according to the Actions memo\ndf_clean = df[\n    df['RevolvingUtilizationOfUnsecuredLines'].notnull() & \n    (df['RevolvingUtilizationOfUnsecuredLines'] <= 1.9) &\n    (df['age'] > 0) &\n    (df['DebtRatio'] < 50) &\n    (df['MonthlyIncome'] > 0) &\n    (df['MonthlyIncome'].notnull())\n]\n\ndf_clean[\"RevolvingUtilizationOfUnsecuredLines\"] = df_clean[\"RevolvingUtilizationOfUnsecuredLines\"].clip(upper = 1.2)\ndf_clean[\"age\"] = df_clean[\"age\"].clip(upper = 95)\ndf_clean[\"NumberOfTime30-59DaysPastDueNotWorse\"] = df_clean[\"NumberOfTime30-59DaysPastDueNotWorse\"].clip(upper = 5)\ndf_clean[\"NumberOfTime60-89DaysPastDueNotWorse\"] = df_clean[\"NumberOfTime60-89DaysPastDueNotWorse\"].clip(upper = 5)\ndf_clean[\"NumberOfTimes90DaysLate\"] = df_clean[\"NumberOfTimes90DaysLate\"].clip(upper = 6)\ndf_clean[\"MonthlyIncome\"] = df_clean[\"MonthlyIncome\"].clip(upper = 20000, lower = 800)\ndf_clean[\"DebtRatio\"] = df_clean[\"DebtRatio\"].clip(upper = 1.2)\ndf_clean[\"NumberOfOpenCreditLinesAndLoans\"] = df_clean[\"NumberOfOpenCreditLinesAndLoans\"].clip(upper = 20)\ndf_clean[\"NumberRealEstateLoansOrLines\"] = df_clean[\"NumberRealEstateLoansOrLines\"].clip(upper = 5)\ndf_clean[\"NumberOfDependents\"] = df_clean[\"NumberOfDependents\"].clip(upper = 5)\ndf_clean[\"NumberOfDependents\"].fillna(0, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Adding a custom predictor\ndf_clean[\"Custom1\"] = df_clean[\"NumberOfTime30-59DaysPastDueNotWorse\"] + df_clean[\"NumberOfTime60-89DaysPastDueNotWorse\"] * 1.6 + df_clean[\"NumberOfTimes90DaysLate\"] * 2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the clean dataset \nrs = round(df_clean.describe(), 2)\nrs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the distribution of the target variable SeriousDlqin2yrs\nsns.countplot(\n    x = \"SeriousDlqin2yrs\",\n    data = df_clean\n);\n# Seems like Accuracy is not a good metric for ML models","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting the pair grid to better understand connections between columns \ngrid = sns.pairplot(\n    df_clean[[\"SeriousDlqin2yrs\",\n              \"RevolvingUtilizationOfUnsecuredLines\",\n              \"age\",\n              \"DebtRatio\",\n              \"MonthlyIncome\",\n              \"NumberOfOpenCreditLinesAndLoans\",\n              \"NumberRealEstateLoansOrLines\",\n              \"NumberOfDependents\"\n             ]].sample(n = 3000),\n    hue = \"SeriousDlqin2yrs\",\n    height = 3,\n    kind = \"reg\",\n    plot_kws = {'scatter_kws': {'alpha': 0}}\n)\ngrid = grid.map_upper(plt.scatter)\ngrid = grid.map_lower(\n    sns.kdeplot, \n    shade = True,\n    shade_lowest = False,\n    alpha = 0.6,\n    n_levels = 5\n);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"#### Explore further memo:\n* Defaulted (<code>SeriousDlqin2yrs</code> = 1) users are generally younger than non-defaulted users \n* Defaulted users have <code>RevolvingUtilizationOfUnsecuredLines</code> much closer to maximum (1), which is opposite for the non-defaulted users\n* Defaulted users' <code>DebpRatio</code> tend to be increasing with <code>age</code>, and for non-defaulted users the trend is the opposite ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking most highly correlated variables\ndef highestcorrelatedpairs (df, top_num):\n    correl_matrix = df.corr()\n    correl_matrix *=np.tri(*correl_matrix.values.shape, k = -1).T\n    correl_matrix = correl_matrix.stack()\n    correl_matrix = correl_matrix.reindex(correl_matrix.abs().sort_values(ascending = False).index).reset_index()\n    correl_matrix.columns = [\n        \"Variable 1\",\n        \"Variable 2\",\n        \"Correlation\"\n    ]\n    return correl_matrix.head(top_num)\n\nhighestcorrelatedpairs(df_clean, 16)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Explore further memo - part 2:\n* <code>MonthlyIncome</code> has an unexpected medium positive correlation with <code>NumberRealEstateLoansOrLines</code>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preparations for ECDF plot \ndef ecdf_plot(df, col, split):\n    x0 = np.sort(df[(df[split] == 0) | (df[split] == -1)][col])\n    x1 = np.sort(df[df[split] == 1][col])\n    y0 = np.arange(1, len(x0)+1) / len(x0)\n    y1 = np.arange(1, len(x1)+1) / len(x1)\n    _ = plt.plot(x0, y0, marker = '.', linestyle = 'none')\n    _ = plt.plot(x1, y1, marker = '.', linestyle = 'none')\n    plt.margins(0.04) \n    plt.legend([split + \": 0\", split + \": 1\"])\n    plt.xlabel(col, fontsize = 12)\n    plt.grid()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 1st variable for ECDF: Age\nplt.figure(figsize = (8.5,6))\necdf_plot(df_clean, \"age\", \"SeriousDlqin2yrs\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"![](http://)Average age of the defaulted user is around **45**, and non-default user is around **52**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# 2nd pair for ECDF: RevolvingUtilizationOfUnsecuredLines\nplt.figure(figsize = (8.5,6))\necdf_plot(df_clean, \"RevolvingUtilizationOfUnsecuredLines\", \"SeriousDlqin2yrs\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"More than half of defaulted users have the <code>RevolvingUtilizationOfUnsecuredLines</code> above **0.8**<br>\nOnly 18% of non-defaulted users have such high <code>RevolvingUtilizationOfUnsecuredLines</code>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Defining ageRange for easier visualization\nageRange = pd.interval_range(\n    start = 20, \n    freq = 10, \n    end = 90\n)\ndf_clean['ageRange'] = pd.cut(df_clean['age'], bins = ageRange)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exploring the connections between RevolvingUtilizationOfUnsecuredLines and age\nplt.figure(figsize = (16,8))\nsns.violinplot(\n    y = \"RevolvingUtilizationOfUnsecuredLines\",\n    x = \"ageRange\",\n    data = df_clean\n);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Out of all age groups, users between 20 and 30 have the highest ratio of very high (close to 1) <code>RevolvingUtilizationOfUnsecuredLines</code>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Explorning the RevolvingUtilizationOfUnsecuredLines by age groups for both categories of the target variable\nplt.figure(figsize = (16,8))\nsns.boxplot(\n    y = \"RevolvingUtilizationOfUnsecuredLines\",\n    x = \"ageRange\",\n    hue =\"SeriousDlqin2yrs\",  \n    data = df_clean\n);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For all age groups, <code>RevolvingUtilizationOfUnsecuredLines</code> is noticably different between defaulted and non-defaulted users","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Explorning the DebtRatio by age groups for both categories of the target variable\nplt.figure(figsize = (16,8))\nsns.boxplot(\n    y = \"DebtRatio\",\n    x = \"ageRange\",\n    hue =\"SeriousDlqin2yrs\",  \n    data = df_clean\n);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"While the average <code>DebtRatio</code> is decreasing with age for the groups from 40 to 80 for non-defaulted users, it almost doesn't change for defaulted users","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the RevolvingUtilizationOfUnsecuredLines distribution differences by age group and both categories of the target variable\nplt.figure(figsize = (16,8))\nsns.violinplot(\n    y = \"RevolvingUtilizationOfUnsecuredLines\",\n    x = \"ageRange\",\n    hue = \"SeriousDlqin2yrs\",  \n    data = df_clean,\n    split = True,\n    inner = \"quart\"\n);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For higher age groups, it's easier to tell if the user would default if the <code>RevolvingUtilizationOfUnsecuredLines</code> is high (around \"1\")","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the RevolvingUtilizationOfUnsecuredLines distribution differences by NumberOfTime30-59DaysPastDueNotWorse and both categories of the target variable\nplt.figure(figsize = (16,8))\nsns.violinplot(\n    y = \"RevolvingUtilizationOfUnsecuredLines\",\n    x = \"NumberOfTime30-59DaysPastDueNotWorse\",\n    hue = \"SeriousDlqin2yrs\",  \n    data = df_clean,\n    split = True,\n    inner = \"quart\"\n);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"When the <code>NumberOfTime30-59DaysPastDueNotWorse</code> is **4 or higher**, it becomes less effective to use <code>RevolvingUtilizationOfUnsecuredLines</code> as a predictor of default.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.FacetGrid(\n    df_clean,\n    col = \"SeriousDlqin2yrs\", \n    row = \"ageRange\", \n    height = 2.5,\n    aspect = 1.6\n)\ng.map(sns.kdeplot, \"RevolvingUtilizationOfUnsecuredLines\", \"DebtRatio\");\nplt.ylim(-0.5, 1.5);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Defining MonthlyIncomeRanges for easier visualization\nincomeRange = pd.interval_range(\n    start = 0, \n    freq = 2500, \n    end = 25000\n)\ndf_clean['MonthlyIncomeRanges'] = pd.cut(df_clean['MonthlyIncome'], bins = incomeRange)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Explorning the NumberOfOpenCreditLinesAndLoans by income groups for both categories of the target variable\nplt.figure(figsize = (16,8))\na = sns.boxplot(\n    y = \"DebtRatio\",\n    x = \"MonthlyIncomeRanges\",\n    hue =\"SeriousDlqin2yrs\",  \n    data = df_clean\n)\nplt.setp(\n    a.get_xticklabels(), \n    rotation = 55\n);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For all income groups, average <code>DebtRatio</code> of defaulted users is higher than non-defaulted users, with the difference becoming bigger as the income increases","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.jointplot(\n    \"MonthlyIncome\",\n    \"NumberRealEstateLoansOrLines\",\n    data = df_clean.sample(n = 3000),\n    kind = 'kde'\n);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking medium and strong correlations in preparation for ML \ncorr = df_clean.corr()\nplt.subplots(figsize = (11, 9))\nsns.heatmap(\n    corr[(corr >= 0.25) | (corr <= -0.25)], \n    cmap = 'viridis', \n    vmax = 1.0, \n    vmin = -1.0, \n    linewidths = 0.1,\n    annot = True, \n    annot_kws = {\"size\": 10}, \n    square = True\n);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Step 3: ML","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# ML environment for Random Forest with Random Search optimization \n\nfrom numpy import arange\nfrom numpy import argmax\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import precision_score, recall_score, roc_auc_score, roc_curve, classification_report, confusion_matrix, f1_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\nimport itertools\n\n# Set a random seed\nseed = 87\n\n# Define evaluation function (source: https://github.com/WillKoehrsen/Machine-Learning-Projects/blob/master/Random%20Forest%20Tutorial.ipynb)\ndef evaluate_model(predictions, probs, train_predictions, train_probs):\n    \n    baseline = {}\n    \n    baseline['recall'] = recall_score(test_labels, [1 for _ in range(len(test_labels))])\n    baseline['precision'] = precision_score(test_labels, [1 for _ in range(len(test_labels))])\n    baseline['roc'] = 0.5\n    \n    results = {}\n    \n    results['recall'] = recall_score(test_labels, predictions)\n    results['precision'] = precision_score(test_labels, predictions)\n    results['roc'] = roc_auc_score(test_labels, probs)\n    \n    train_results = {}\n    train_results['recall'] = recall_score(train_labels, train_predictions)\n    train_results['precision'] = precision_score(train_labels, train_predictions)\n    train_results['roc'] = roc_auc_score(train_labels, train_probs)\n    \n    for metric in ['recall', 'precision', 'roc']:\n        print(f'{metric.capitalize()} Baseline: {round(baseline[metric], 2)} Test: {round(results[metric], 2)} Train: {round(train_results[metric], 2)}')\n    \n    # Calculate false positive rates and true positive rates\n    base_fpr, base_tpr, _ = roc_curve(test_labels, [1 for _ in range(len(test_labels))])\n    model_fpr, model_tpr, _ = roc_curve(test_labels, probs)\n\n    plt.figure(figsize = (8, 6))\n    plt.rcParams['font.size'] = 12\n    \n    # Plot both curves\n    plt.plot(base_fpr, base_tpr, 'b', label = 'baseline')\n    plt.plot(model_fpr, model_tpr, 'r', label = 'model')\n    plt.legend();\n    plt.xlabel('False Positive Rt'); plt.ylabel('True Positive Rt'); plt.title('ROC Curves');\n    \n# Define confusion matrix function (source: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html)\ndef plot_confusion_matrix(cm,\n                          classes,\n                          normalize = False,\n                          title = 'Confusion matrix',\n                          cmap = plt.cm.Oranges):\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis = 1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.figure(figsize = (4, 4))\n    plt.imshow(cm, interpolation = 'nearest', cmap = cmap)\n    plt.title(title, size = 10)\n    plt.colorbar(aspect = 3)\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation = 45, size = 10)\n    plt.yticks(tick_marks, classes, size = 10)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    \n    # Labeling the plot\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt), fontsize = 12,\n                 horizontalalignment = \"center\",\n                 color = \"white\" if cm[i, j] > thresh else \"black\")\n        \n    plt.grid(None)\n    plt.tight_layout()\n    plt.ylabel('True label', size = 10)\n    plt.xlabel('Predicted label', size = 10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### ML-relevant observations summary:\n* <code>MonthlyIncome</code> has >20% of missing values AND is not a strong predictor (correlation is less than 0.2), so consider removing it from the model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Test data preparations\n# a) Dropping MonthlyIncome and id\ndf_ml = df_clean.drop(\n    columns = [\n        \"MonthlyIncome\",\n        \"id\",\n        \"MonthlyIncomeRanges\",\n        \"ageRange\",\n        \"NumberOfTime60-89DaysPastDueNotWorse\",\n        \"NumberOfTime30-59DaysPastDueNotWorse\",\n        \"NumberOfTimes90DaysLate\",\n        \"NumberRealEstateLoansOrLines\",\n        \"NumberOfDependents\"\n    ]\n);\n# b) Splitting the dataset (30%)\nlabels = np.array(df_ml.pop('SeriousDlqin2yrs'))\ntrain, test, train_labels, test_labels = train_test_split(\n    df_ml, \n    labels, \n    stratify = labels,\n    test_size = 0.3, \n    random_state = seed\n);\n# c) Saving features\nfeatures = list(train.columns);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Take 1 - RandomForest","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model = RandomForestClassifier(\n    n_estimators = 230, \n    random_state = seed, \n    max_features = 'sqrt',\n    n_jobs = -1,\n    verbose = 1\n)\n\n# Fitting on the Train dataset, predicting\nmodel.fit(train, train_labels)\n\ntrain_rf_pred = model.predict(train)\ntrain_rf_probs = model.predict_proba(train)[:, 1]\n\nrf_pred = model.predict(test)\nrf_probs = model.predict_proba(test)[:, 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluating\nevaluate_model(rf_pred, rf_probs, train_rf_pred, train_rf_probs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"roc_auc_score(test_labels, rf_probs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(test_labels, rf_pred)\nplot_confusion_matrix(\n    cm, \n    classes = ['0', '1'],\n    normalize = True,\n    title = 'Confusion Matrix'\n);\nplt.grid(None);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(test_labels, rf_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking variables importance\nrf_model = pd.DataFrame({'feature': features,\n                   'importance': model.feature_importances_}).\\\n                    sort_values('importance', ascending = False)\nrf_model.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Take 2 - RandomForest with Random Search optimization","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Hyperparameters\nparams = {\n    'n_estimators': np.linspace(100, 210).astype(int),\n    'max_depth': [None] + list(np.linspace(4, 24).astype(int)),\n    'max_features': ['auto', 'sqrt', None] + list(np.arange(0.2, 0.4)),\n    'max_leaf_nodes': [None] + list(np.linspace(16, 48, 80).astype(int)),\n    'min_samples_split': [1, 2, 3],\n    'bootstrap': [True, False]\n}\n\n# Estimator\nestimator = RandomForestClassifier(random_state = seed)\n\n# Random search model\nrs = RandomizedSearchCV(\n    estimator,\n    params,\n    n_jobs = -1, \n    scoring = 'recall',\n    cv = 3, \n    n_iter = 10, \n    verbose = 1,\n    random_state = seed\n)\n\n# Fitting\nrs.fit(train, train_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predicting\ntrain_rs_pred = rs.predict(train)\ntrain_rs_probs = rs.predict_proba(train)[:, 1]\n\nrs_pred = rs.predict(test)\nrs_probs = rs.predict_proba(test)[:, 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluating\nevaluate_model(rs_pred, rs_probs, train_rs_pred, train_rs_probs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"roc_auc_score(test_labels, rs_probs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rs.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(test_labels, rs_pred)\nplot_confusion_matrix(\n    cm, \n    classes = ['0', '1'],\n    normalize = True,\n    title = 'Confusion Matrix'\n);\nplt.grid(None);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(test_labels, rs_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking variables importance\nrs_model = pd.DataFrame({'feature': features,\n                   'importance': rs.best_estimator_.feature_importances_}).\\\n                    sort_values('importance', ascending = False)\nrs_model.head(10)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}