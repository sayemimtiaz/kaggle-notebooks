{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Comparing two datasets\nThe challenges of Machine Learning algorithm generalizing on new data is based on the assumption that, the trends that the model has learnt on the traning data will be seen on the new datasets as well. This is not usually the case for real world problems, which leads to the generalization error and performance deterioration overtime. Specfically, these two use cases can benefit from knowing what changed in the datasets\n\n* **Pre Implementation** - Finding out what is different between train and OOS/OOT and identifying variables with similar distributions\n* **Post Implementation** - finding out what changed between training and production time period to deep dive changes in variable distribution and affect on the performance\n\nIn this notebook, I will explore 5 ways of doing these comparisons\n\n* Using seaborn violin plots to compare the distributions visually between two datasets\n* ANOVA and Tukey's test to establish whether the difference between two datasets is significant or not\n* Andrew's Curves - these curves help distinguish various observations whether any differences exist on visual inspection\n* KS Statistic to check whether the each variable in train and test comes from the same distribution \n* And finally, my favorite, Building a ML classifier and predicting which dataset it belongs to. This will throw out a quantitative measure using AUC as to how different are these datasets and specify which variables should be considered as important to change in datasets\n\n### Dataset\n\nI am using [Default on credit card clients dataset](https://www.kaggle.com/uciml/default-of-credit-card-clients-dataset) and splitting it into train and test by sklearn library.\n","metadata":{}},{"cell_type":"markdown","source":"## 1. Violin Plots\nViolin plots are similar to box and whisker plots. These are being used instead because you can split the violin in two parts compare distributions in train and test side by side. You can visually see that the plots for train (light green) and fairly close to test (darker blue)","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef PrepareData():\n    df = pd.read_csv('/kaggle/input/default-of-credit-card-clients-dataset/UCI_Credit_Card.csv')\n#     print ('Shape :',df.shape)\n#     print ('NULLS : \\n', df.isnull().sum())\n\n    df = df.rename(columns={'default.payment.next.month': 'def_pay', \n                            'PAY_0': 'PAY_1'})\n\n    from sklearn.model_selection import train_test_split\n    features = ['LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_1', 'PAY_2',\n           'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'BILL_AMT1', 'BILL_AMT2',\n           'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1',\n           'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']\n    X = df[features].copy()\n    y = df['def_pay']\n    \n#     print ('Train Test Split')\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n#     print ('X_train Shape :', X_train.shape)\n#     print ('X_test Shape :', X_test.shape)\n#     print ('Event Rate Train : ', y_train.mean())\n#     print ('Event Rate Test : ', y_test.mean())\n    \n    return X_train, X_test, y_train, y_test\n\n# prepare data\nX_train, X_test, y_train, y_test = PrepareData()\n\nX_train['dataset'] = 'TRAIN'\nX_test['dataset'] = 'TEST'\ndata = X_train.append(X_test)\n\n# create subplots\nf, axes = plt.subplots(4,6,figsize = (30,15))\nax0 = axes.ravel()[0]\n\n# set ticks to non\nfor ax in axes.ravel():\n    ax.set_xticks([])\n    ax.set_yticks([])\n    \n# iterate over all variables and generate violin plot\nfor i, col in enumerate(X_train.drop('SEX', axis=1).columns[:-1]):\n    ax = axes.ravel()[i]\n    g = sns.violinplot(x='SEX', data=data, ax=ax, y=col, hue='dataset', split=True, palette = ['#78e08f', '#0a3d62'])\n    ax.set_title(col, fontsize=14, color='#0a3d62', fontfamily='monospace')\n    ax.set_ylabel('')\n    ax.set_xticks([])\n    ax.set_xlabel('')\n    ax.get_legend().remove()\n    sns.despine(top=True, right=True, left=True, bottom=True)\nplt.suptitle('DISTRIBUTIONS BY GENDER FOR EACH VARIABLE IN TRAIN AND TEST', fontsize=20, color='#0a3d62', fontweight='bold', fontfamily='monospace')\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-28T04:42:10.362625Z","iopub.execute_input":"2021-07-28T04:42:10.363036Z","iopub.status.idle":"2021-07-28T04:42:16.812089Z","shell.execute_reply.started":"2021-07-28T04:42:10.362997Z","shell.execute_reply":"2021-07-28T04:42:16.811135Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Anova\nThe analysis of variance statistical models were developed by the English statistician Sir R. A. Fisher and are commonly used to determine if there is a significant difference between the means of two or more data sets.\n\nHere we are comparing the train and test datasets. So,\n* **Null Hypothesis** - The two datasets are similar\n* **Alternate Hypothesis** - The two datsets are dissimilar\n\nOne way anova allows us to do this comparison, and rejecting the null hypothesis means, accepting the alternate, meaning the two datasets are significantly different. The decision for rejection is based on $p$ if $p \\leq \\alpha$ or significance level. $\\alpha$ is typically 5% i.e. 95% confidence\n","metadata":{}},{"cell_type":"code","source":"X_train['y'] = y_train\nX_train['dataset'] = 1\nX_test['y'] = y_test\nX_test['dataset'] = 2\ndata2 = X_train.append(X_test)\n# data2.drop('dataset', axis=1, inplace=True)\n\nimport statsmodels.api as sm\nfrom statsmodels.formula.api import ols\nfrom statsmodels.stats.multicomp import pairwise_tukeyhsd\nfrom statsmodels.stats.multicomp import MultiComparison\n\nanova_results = pd.DataFrame()\nfor col in X_train.columns[:-2]:\n    model = ols(f'{col} ~ dataset', data = data2).fit()\n    anova_result = sm.stats.anova_lm(model, typ=2)\n    anova_result['var'] = col\n    anova_results = anova_results.append(anova_result)\n\ntukeys_results = pd.DataFrame()\nfor col in X_train.columns[:-2]:\n    mc = MultiComparison(data2[col], data2['dataset'])\n    result = mc.tukeyhsd().summary()\n    result_as_df = pd.read_html(result.as_html())[0]\n    result_as_df['var'] = col\n    tukeys_results = tukeys_results.append(result_as_df, ignore_index=True)\n    \nf, ax = plt.subplots(1,1,figsize=(30,6))\nanova_results[['var','PR(>F)']].dropna().set_index('var')['PR(>F)'].plot(kind='bar', ax=ax, color = '#78e08f', width=0.6)\nax.set_xticklabels(ax.get_xticklabels(), rotation=0, color='#0a3d62', fontfamily='monospace', fontsize=12)\nax.set_xlabel('')\nax.set_yticks([])\nfor s in ['top','right','bottom','left']:\n    ax.spines[s].set_visible(False)\nplt.axhline(y = 0.05, color = '#0a3d62', linestyle = '--', lw=3)\nax.text(-0.5,1.17,'P VALUES FOR EACH VARIABLE', fontsize=20, fontweight='bold', color='#0a3d62', fontfamily='monospace')\nax.text(-0.5,1.12,'All P values are > 0.05 (horizontal line), i.e. for none of variables are significantly different between train and test', fontsize=15, color='#0a3d62', fontfamily='monospace')\nfor bar in ax.patches:\n    ax.annotate(\n        format(bar.get_height(), '.2f'), \n        (bar.get_x() + bar.get_width() / 2, bar.get_height()), \n        ha='center', va='bottom',\n        size=15, xytext=(0, 8), color = '#0a3d62',\n        textcoords='offset points'\n    )\n\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-28T04:43:30.162552Z","iopub.execute_input":"2021-07-28T04:43:30.162949Z","iopub.status.idle":"2021-07-28T04:43:31.960065Z","shell.execute_reply.started":"2021-07-28T04:43:30.162915Z","shell.execute_reply":"2021-07-28T04:43:31.959079Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Andrew's Curves\nAndrews curves are used for visualizing high-dimensional data by mapping each observation onto a function. It preserves means, distance, and variances. It is given by formula:\n\n$$T(n) = \\frac{x_1}{sqrt(2)} + x_2sin(n) + x_3 cos(n) + x_4 sin(2n) + x_5 cos(2n) + ...$$\n\nThe test is completely overlayed on train curves which means there is a huge overlap in distributions of variables between train and test.","metadata":{}},{"cell_type":"code","source":"from pandas.plotting import andrews_curves\nf,ax = plt.subplots(1,1, figsize=(30,10))\ndata2['dataset'] = data2.dataset.replace({1:'TRAIN',2:'TEST'})\ndata3 = data2.drop('y', axis=1)\nandrews_curves(data3, \"dataset\", ax=ax, color = ['#0a3d62','#78e08f'])\nfor s in ['top','right','bottom','left']:\n    ax.spines[s].set_visible(False)\nplt.title('ANDREWS CURVES BY DATASET', fontsize=20, color='#0a3d62', fontfamily='monospace', fontweight='bold')\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-28T03:16:02.301538Z","iopub.execute_input":"2021-07-28T03:16:02.301822Z","iopub.status.idle":"2021-07-28T03:17:13.418792Z","shell.execute_reply.started":"2021-07-28T03:16:02.301795Z","shell.execute_reply":"2021-07-28T03:17:13.417918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. KS Statistic\n\n* Performs the two-sample Kolmogorov-Smirnov test for goodness of fit.\n* Null hypothesis states null both cumulative distributions are similar. Rejecting the null hypothesis means cumulative distributions are different.\n* This test compares the underlying continuous distributions F(x) and G(x) of two independent samples.\n    * `two-sided`: The null hypothesis is that the two distributions are identical, F(x)=G(x) for all x; the alternative is that they are not identical.\n    * `less`: The null hypothesis is that F(x) >= G(x) for all x; the alternative is that F(x) < G(x) for at least one x.\n    * `greater`: The null hypothesis is that F(x) <= G(x) for all x; the alternative is that F(x) > G(x) for at least one x.","metadata":{}},{"cell_type":"code","source":"from scipy.stats import ks_2samp\nksdf = pd.DataFrame()\nalpha = 0.05\nfor col in X_train.columns[:-2]:\n    s, p = ks_2samp(X_train[col], X_test[col])\n    ksdf = ksdf.append(pd.DataFrame({\n        'kstat' : [s],\n        'pval': [p],\n        'variable': [col],\n        'reject_null_hypo': [p<alpha]\n    }), ignore_index=True)\n    \n\nf, ax = plt.subplots(1,1,figsize=(30,6))\nksdf[['variable','pval']].set_index('variable')['pval'].plot(kind='bar', ax=ax, color = '#78e08f', width=0.6)\nax.set_xticklabels(ax.get_xticklabels(), rotation=0, color='#0a3d62', fontfamily='monospace', fontsize=12)\nax.set_xlabel('')\nax.set_yticks([])\nfor s in ['top','right','bottom','left']:\n    ax.spines[s].set_visible(False)\nplt.axhline(y = alpha, color = '#0a3d62', linestyle = '--', lw=3)\nax.text(-0.5,1.17,'P VALUE FOR EACH VARIABLE', fontsize=20, fontweight='bold', color='#0a3d62', fontfamily='monospace')\nax.text(-0.5,1.12,f'All P values are < {alpha}(horizontal line), i.e. for none of variables are significantly different between train and test', fontsize=15, color='#0a3d62', fontfamily='monospace')\nfor bar in ax.patches:\n    ax.annotate(\n        format(bar.get_height(), '.2f'), \n        (bar.get_x() + bar.get_width() / 2, bar.get_height()), \n        ha='center', va='bottom',\n        size=15, xytext=(0, 8), color = '#0a3d62',\n        textcoords='offset points'\n    )\nplt.show()\n\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-28T03:17:13.420052Z","iopub.execute_input":"2021-07-28T03:17:13.420334Z","iopub.status.idle":"2021-07-28T03:17:14.030448Z","shell.execute_reply.started":"2021-07-28T03:17:13.420302Z","shell.execute_reply":"2021-07-28T03:17:14.029662Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. Building Model to predict train/test label\n* The objective is to build a model to predict whether an observation belongs to train or test by stacking train and test\n* The performance would be measured on AUC - higher AUC would mean higher difference between train and test and vice versa\n* The variable importance would also suggest the variables leading the differences\n","metadata":{}},{"cell_type":"code","source":"X_train['label'] = 0\nX_test['label'] = 1\ndata5 = X_train.append(X_test)\ndata5.drop('dataset', axis=1, inplace=True)\nprint(data5.shape)\n\nfrom sklearn.model_selection import train_test_split\n# print ('Train Test Split')\nX_train, X_test, y_train, y_test = train_test_split(data5.drop('label',axis=1), data5.label, test_size=0.20, random_state=42)\n# print ('X_train Shape :', X_train.shape)\n# print ('X_test Shape :', X_test.shape)\n# print ('Event Rate Train :', round(y_train.mean(),2))\n# print ('Event Rate Test :', round(y_test.mean(),2))\n\nimport xgboost as xgb\ntrain_dm = xgb.DMatrix(data = X_train, label = y_train.values)\ntest_dm = xgb.DMatrix(data = X_test, label = y_test.values)\nparams = {\n    'num_boost_round': 500,\n    'objective': 'binary:logistic',\n    'max_depth' : 5,\n    'gamma':10,\n    'eta': 0.01,\n    'min_child_weight': 10,\n    'verbosity': 0\n}\nmodel = xgb.train(params, train_dm, num_boost_round = params['num_boost_round'])\ntrain_preds = model.predict(train_dm)\ntest_preds = model.predict(test_dm)\nfrom sklearn.metrics import roc_auc_score\n\nprint('TRAIN AUC :',round((roc_auc_score(y_train.values, train_preds))*100,2), '%')\nprint('TEST AUC:',round((roc_auc_score(y_test.values, test_preds))*100,2), '%')","metadata":{"execution":{"iopub.status.busy":"2021-07-28T03:17:14.031487Z","iopub.execute_input":"2021-07-28T03:17:14.031887Z","iopub.status.idle":"2021-07-28T03:17:14.068776Z","shell.execute_reply.started":"2021-07-28T03:17:14.031856Z","shell.execute_reply":"2021-07-28T03:17:14.067926Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The AUCs are around 50%, which means the model is not able to differentiate between the two datasets, which is exactly what we need for the datasets to show in ideal scenarios, for the model to perform. We can also look at the variable importances and see which variables contribute to the differences","metadata":{"execution":{"iopub.status.busy":"2021-07-28T04:26:27.720942Z","iopub.execute_input":"2021-07-28T04:26:27.721317Z","iopub.status.idle":"2021-07-28T04:26:40.209042Z","shell.execute_reply.started":"2021-07-28T04:26:27.721286Z","shell.execute_reply":"2021-07-28T04:26:40.207097Z"}}},{"cell_type":"markdown","source":"#### Finding out which Variable contributes to most differences between datasets","metadata":{}},{"cell_type":"code","source":"fi = pd.DataFrame(model.get_score(importance_type='total_gain'), index = range(1)).T.reset_index()\nfi.columns = ['variable','total_gain']\nfi = fi.sort_values('total_gain', ascending = False)\nfi['importance'] = np.sqrt(fi.total_gain)/np.sqrt(fi.total_gain.max()) * 100\nfi.reset_index(drop = True)\n\nf, ax = plt.subplots(1,1,figsize=(30,6))\nfi[['variable','importance']].set_index('variable')['importance'].plot(kind='bar', ax=ax, color = '#78e08f', width=0.6)\nax.set_xticklabels(ax.get_xticklabels(), rotation=0, color='#0a3d62', fontfamily='monospace', fontsize=12)\nax.set_xlabel('')\nax.set_yticks([])\nfor s in ['top','right','bottom','left']:\n    ax.spines[s].set_visible(False)\nax.text(-0.35,120,'VARIABLE IMPORTANCES', fontsize=20, fontweight='bold', color='#0a3d62', fontfamily='monospace')\nax.text(-0.35,113,f'Top 5 variables {fi.head().variable.values.tolist()} contribute most to the differences between train and test', fontsize=15, color='#0a3d62', fontfamily='monospace')\nfor bar in ax.patches:\n    ax.annotate(\n        format(bar.get_height(), '.2f'), \n        (bar.get_x() + bar.get_width() / 2, bar.get_height()), \n        ha='center', va='bottom',\n        size=12, xytext=(0, 8), color = '#0a3d62',\n        textcoords='offset points'\n    )\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-28T04:24:43.758438Z","iopub.execute_input":"2021-07-28T04:24:43.758933Z","iopub.status.idle":"2021-07-28T04:24:44.007862Z","shell.execute_reply.started":"2021-07-28T04:24:43.758897Z","shell.execute_reply":"2021-07-28T04:24:44.00653Z"},"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Conclusion\n\nThese 5 methods can be used to establish whether the datasets for train and OOT (Out of Time)/OOS (Out of Sample) are similar to know whether the model will generalize or not. If not, using these methods you'll know exactly which variables are contributing to the deviations both visually and quantitatively\n\n## References\n\n* [KS Statistic from scipy](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ks_2samp.html)\n* [One way ANOVA and Tukey's Test](https://manchev.org/2015/07/01/using-one-way-anova-and-tukeys-test-to-compare-data-sets/)\n* [Use Many models to compare](https://cran.r-project.org/web/packages/datarobot/vignettes/ComparingSubsets.html)\n* [Seaborn Violin Plots](https://seaborn.pydata.org/generated/seaborn.violinplot.html)\n* [How to plot Andrews curves using Pandas in Python?](https://www.geeksforgeeks.org/how-to-plot-andrews-curves-using-pandas-in-python/)\n","metadata":{}}]}