{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction\nAnomaly detection has applications in many fields, such as system health monitoring, fraud detection, and intrusion detection.\n\n![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F3595464%2F4088133a20318f4e47e1e2d738509d12%2F__results___5_0.png?generation=1590869249365044&alt=media)\n\n## Using Luminol\nDetecting Outliers and Change Points from Time Series","metadata":{}},{"cell_type":"code","source":"!pip install luminol\nimport luminol\n\nfrom luminol import anomaly_detector,correlator\n\nfrom luminol.anomaly_detector import AnomalyDetector\nfrom luminol.correlator import Correlator","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt# Standardize/scale the dataset and apply PCA\nfrom sklearn.decomposition import PCA\ndef Score_data(pred, real):\n    # computing errors\n    errors = np.abs(pred - real).flatten()\n    # estimation\n    mean = sum(errors)/len(errors)\n    cov = 0\n    for e in errors:\n        cov += (e - mean)**2\n    cov /= len(errors)\n\n    print('mean : ', mean)\n    print('cov : ', cov)\n    return errors, cov, mean\n\n# calculate Mahalanobis distance\ndef Mahala_distantce(x,mean,cov):\n    return (x - mean)**2 / cov\n\n\ndef scale(A):\n    return (A-np.min(A))/(np.max(A) - np.min(A))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n## see this: https://github.com/waico/SKAB/\ndef evaluating_change_point(true, prediction, metric='nab', numenta_time=None):\n    \"\"\"\n    true - both:\n                list of pandas Series with binary int labels\n                pandas Series with binary int labels\n    prediction - both:\n                      list of pandas Series with binary int labels\n                      pandas Series with binary int labels\n    metric: 'nab', 'binary' (FAR, MAR), 'average_delay'\n                \n    \"\"\"\n    \n    def binary(true, prediction):      \n        \"\"\"\n        true - true binary series with 1 as anomalies\n        prediction - trupredicted binary series with 1 as anomalies\n        \"\"\"\n        def single_binary(true,prediction):\n            true_ = true == 1 \n            prediction_ = prediction == 1\n            TP = (true_ & prediction_).sum()\n            TN = (~true_ & ~prediction_).sum()\n            FP = (~true_ & prediction_).sum()\n            FN = (true_ & ~prediction_).sum()\n            return TP,TN,FP,FN\n            \n        if type(true) != type(list()):\n            TP,TN,FP,FN = single_binary(true,prediction)\n        else:\n            TP,TN,FP,FN = 0,0,0,0\n            for i in range(len(true)):\n                TP_,TN_,FP_,FN_ = single_binary(true[i],prediction[i])\n                TP,TN,FP,FN = TP+TP_,TN+TN_,FP+FP_,FN+FN_       \n    \n        f1 = round(TP/(TP+(FN+FP)/2), 2)\n        print(f'False Alarm Rate {round(FP/(FP+TN)*100,2)} %' )\n        print(f'Missing Alarm Rate {round(FN/(FN+TP)*100,2)} %')\n        print(f'F1 metric {f1}')\n        return f1\n    \n    def average_delay(detecting_boundaries, prediction):\n        \n        def single_average_delay(detecting_boundaries, prediction):\n            missing = 0\n            detectHistory = []\n            for couple in detecting_boundaries:\n                t1 = couple[0]\n                t2 = couple[1]\n                if prediction[t1:t2].sum()==0:\n                    missing+=1\n                else:\n                    detectHistory.append(prediction[prediction ==1][t1:t2].index[0]-t1)\n            return missing, detectHistory\n            \n        \n        if type(prediction) != type(list()):\n            missing, detectHistory = single_average_delay(detecting_boundaries, prediction)\n        else:\n            missing, detectHistory = 0, []\n            for i in range(len(prediction)):\n                missing_, detectHistory_ = single_average_delay(detecting_boundaries[i], prediction[i])\n                missing, detectHistory = missing+missing_, detectHistory+detectHistory_\n\n        add = pd.Series(detectHistory).mean()\n        print('Average delay', add)\n        print(f'A number of missed CPs = {missing}')\n        return add\n    \n    def evaluate_nab(detecting_boundaries, prediction, table_of_coef=None):\n        \"\"\"\n        Scoring labeled time series by means of\n        Numenta Anomaly Benchmark methodics\n        Parameters\n        ----------\n        detecting_boundaries: list of list of two float values\n            The list of lists of left and right boundary indices\n            for scoring results of labeling\n        prediction: pd.Series with timestamp indices, in which 1 \n            is change point, and 0 in other case. \n        table_of_coef: pandas array (3x4) of float values\n            Table of coefficients for NAB score function\n            indeces: 'Standart','LowFP','LowFN'\n            columns:'A_tp','A_fp','A_tn','A_fn'\n        Returns\n        -------\n        Scores: numpy array, shape of 3, float\n            Score for 'Standart','LowFP','LowFN' profile \n        Scores_null: numpy array, shape 3, float\n            Null score for 'Standart','LowFP','LowFN' profile             \n        Scores_perfect: numpy array, shape 3, float\n            Perfect Score for 'Standart','LowFP','LowFN' profile  \n        \"\"\"\n        def single_evaluate_nab(detecting_boundaries, prediction, table_of_coef=None, name_of_dataset=None):\n            if table_of_coef is None:\n                table_of_coef = pd.DataFrame([[1.0,-0.11,1.0,-1.0],\n                                     [1.0,-0.22,1.0,-1.0],\n                                      [1.0,-0.11,1.0,-2.0]])\n                table_of_coef.index = ['Standart','LowFP','LowFN']\n                table_of_coef.index.name = \"Metric\"\n                table_of_coef.columns = ['A_tp','A_fp','A_tn','A_fn']\n\n            alist = detecting_boundaries.copy()\n            prediction = prediction.copy()\n\n            Scores, Scores_perfect, Scores_null=[], [], []\n            for profile in ['Standart', 'LowFP', 'LowFN']:       \n                A_tp = table_of_coef['A_tp'][profile]\n                A_fp = table_of_coef['A_fp'][profile]\n                A_fn = table_of_coef['A_fn'][profile]\n                def sigm_scale(y, A_tp, A_fp, window=1):\n                    return (A_tp-A_fp)*(1/(1+np.exp(5*y/window))) + A_fp\n\n                #First part\n                score = 0\n                if len(alist)>0:\n                    score += prediction[:alist[0][0]].sum()*A_fp\n                else:\n                    score += prediction.sum()*A_fp\n                #second part\n                for i in range(len(alist)):\n                    if i<=len(alist)-2:\n                        win_space = prediction[alist[i][0]:alist[i+1][0]].copy()\n                    else:\n                        win_space = prediction[alist[i][0]:].copy()\n                    win_fault = prediction[alist[i][0]:alist[i][1]]\n                    slow_width = int(len(win_fault)/4)\n\n                    if len(win_fault) + slow_width >= len(win_space):\n                        print(f'Intersection of the windows of too wide widths for dataset {name_of_dataset}')\n                        win_fault_slow = win_fault.copy()\n                    else:\n                        win_fault_slow= win_space[:len(win_fault)  +  slow_width]\n\n                    win_fp = win_space[-len(win_fault_slow):]\n\n                    if win_fault_slow.sum() == 0:\n                        score+=A_fn\n                    else:\n                        #to get the first index\n                        tr = pd.Series(win_fault_slow.values,index = range(-len(win_fault), len(win_fault_slow)-len(win_fault)))\n                        tr_values= tr[tr==1].index[0]\n                        tr_score = sigm_scale(tr_values, A_tp,A_fp,slow_width)\n                        score += tr_score\n                        score += win_fp.sum()*A_fp\n                Scores.append(score)\n                Scores_perfect.append(len(alist)*A_tp)\n                Scores_null.append(len(alist)*A_fn)\n            return np.array([np.array(Scores),np.array(Scores_null), np.array(Scores_perfect)])\n       #======      \n        if type(prediction) != type(list()):\n            matrix = single_evaluate_nab(detecting_boundaries, prediction, table_of_coef=table_of_coef)\n        else:\n            matrix = np.zeros((3,3))\n            for i in range(len(prediction)):\n                matrix_ = single_evaluate_nab(detecting_boundaries[i], prediction[i], table_of_coef=table_of_coef,name_of_dataset=i)\n                matrix = matrix + matrix_      \n                \n        results = {}\n        desc = ['Standart', 'LowFP', 'LowFN'] \n        for t, profile_name in enumerate(desc):\n            results[profile_name] = round(100*(matrix[0,t]-matrix[1,t])/(matrix[2,t]-matrix[1,t]), 2)\n            print(profile_name,' - ', results[profile_name])\n        \n        return results\n            \n            \n    #=========================================================================\n    if type(true) != type(list()):\n        true_items = true[true==1].index\n    else:\n        true_items = [true[i][true[i]==1].index for i in range(len(true))]\n        \n\n    if not metric=='binary':\n        def single_detecting_boundaries(true, numenta_time, true_items):\n            detecting_boundaries=[]\n            td = pd.Timedelta(numenta_time) if numenta_time is not None else pd.Timedelta((true.index[-1]-true.index[0])/len(true_items))  \n            for val in true_items:\n                detecting_boundaries.append([val, val + td])\n            return detecting_boundaries\n        \n        if type(true) != type(list()):\n            detecting_boundaries = single_detecting_boundaries(true=true, numenta_time=numenta_time, true_items=true_items)\n        else:\n            detecting_boundaries=[]\n            for i in range(len(true)):\n                detecting_boundaries.append(single_detecting_boundaries(true=true[i], numenta_time=numenta_time, true_items=true_items[i]))\n\n    if metric== 'nab':\n        return evaluate_nab(detecting_boundaries, prediction)\n    elif metric=='average_delay':\n        return average_delay(detecting_boundaries, prediction)\n    elif metric== 'binary':\n        return binary(true, prediction)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# benchmark files checking\nall_files=[]\nimport os\nfor root, dirs, files in os.walk(\"../input/skoltech-anomaly-benchmark-skab/SKAB\"):\n    for file in files:\n        if file.endswith(\".csv\"):\n             all_files.append(os.path.join(root, file))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# datasets with anomalies loading\nlist_of_df = [pd.read_csv(file, \n                          sep=';', \n                          index_col='datetime', \n                          parse_dates=True) for file in all_files if 'anomaly-free' not in file]\n# anomaly-free df loading\nanomaly_free_df = pd.read_csv([file for file in all_files if 'anomaly-free' in file][0], \n                            sep=';', \n                            index_col='datetime', \n                            parse_dates=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data description and visualization","metadata":{}},{"cell_type":"code","source":"# dataset characteristics printing\nprint(f'A number of datasets in the SkAB v1.0: {len(list_of_df)}\\n')\nprint(f'Shape of the random dataset: {list_of_df[0].shape}\\n')\nn_cp = sum([len(df[df.changepoint==1.]) for df in list_of_df])\nn_outlier = sum([len(df[df.anomaly==1.]) for df in list_of_df])\nprint(f'A number of changepoints in the SkAB v1.0: {n_cp}\\n')\nprint(f'A number of outliers in the SkAB v1.0: {n_outlier}\\n')\nprint(f'Head of the random dataset:')\ndisplay(list_of_df[0].head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# random dataset visualizing\nlist_of_df[0].plot(figsize=(12,6))\nplt.xlabel('Time')\nplt.ylabel('Value')\nplt.title('Signals')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"###  Labels","metadata":{}},{"cell_type":"code","source":"# plotting the labels both for outlier and changepoint detection problems\nlist_of_df[0].anomaly.plot(figsize=(12,3))\nlist_of_df[0].changepoint.plot()\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Method applying","metadata":{}},{"cell_type":"code","source":"def scoreLuminolALLData(ts_dict):    \n    data = np.array(ts_dict)\n    ts_s = pd.Series(data)\n    ts_dict = ts_s.to_dict()\n\n\n    detector = anomaly_detector.AnomalyDetector(ts_dict)\n    score = detector.get_all_scores()\n    score_v = []\n    for timestamp, value in score.iteritems():\n        score_v.append(value)\n#         print(timestamp, value)\n    return score_v","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# inference\npredicted_outlier, predicted_cp = [], []\nfor df in list_of_df:\n    X_train = df.drop(['Accelerometer1RMS','Accelerometer2RMS', 'Current', 'Temperature', 'Thermocouple', 'Voltage', 'Pressure', 'anomaly','changepoint'], axis=1)\n#     pca = PCA(n_components=1)\n#     principalComponents = pca.fit_transform(X_train.values.reshape(-1,1))\n#     principalDf = pd.DataFrame(data = principalComponents, columns = ['pc1'])\n    ts_s = scoreLuminolALLData(X_train['Volume Flow RateRMS'].values)\n\n    errors, cov, mean = Score_data(ts_s , X_train['Volume Flow RateRMS'].values)\n    mahala_dist = []\n    for e in errors:\n        mahala_dist.append(Mahala_distantce(e, mean, cov))\n\n    X_train['pca1_value'] = X_train['Volume Flow RateRMS']\n    X_train['pca1_scores'] = mahala_dist\n    X_train['pca1_scores_norm'] = scale(mahala_dist)\n\n    \n    q1_pc1, q3_pc1 = X_train['pca1_scores'].quantile([0.10, 0.75])\n    iqr_pc1 = q3_pc1 - q1_pc1\n    # Calculate upper and lower bounds for outlier for pc1\n    lower_pc1 = q1_pc1 - (1.5*iqr_pc1)\n    upper_pc1 = q3_pc1 + (1.5*iqr_pc1)\n    # Filter out the outliers from the pc1\n    X_train['outlier_pca1'] = ((X_train['pca1_scores']>upper_pc1) | (X_train['pca1_scores']<lower_pc1)).astype('int')\n    \n    \n    # results predicting\n    prediction = pd.Series(X_train['outlier_pca1'], \n                                index=df.index).rolling(3).median().fillna(0).replace(-1,0)\n    \n    # predicted outliers saving\n    predicted_outlier.append(prediction)\n    \n    # predicted CPs saving\n    prediction_cp = abs(prediction.diff())\n    prediction_cp[0] = prediction[0]\n    predicted_cp.append(prediction_cp)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Results","metadata":{}},{"cell_type":"markdown","source":"true changepoint indices selection","metadata":{}},{"cell_type":"code","source":"# true changepoint indices selection\ntrue_cp = [df.changepoint for df in list_of_df]\n\npredicted_cp[0].plot(figsize=(12,3), label='predictions', marker='o', markersize=5)\ntrue_cp[0].plot(marker='o', markersize=2)\nplt.legend();","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"true outlier indices selection","metadata":{}},{"cell_type":"code","source":"# true outlier indices selection\ntrue_outlier = [df.anomaly for df in list_of_df]\n\npredicted_outlier[0].plot(figsize=(12,3), label='predictions', marker='o', markersize=5)\ntrue_outlier[0].plot(marker='o', markersize=2)\nplt.legend();","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Metrics calculation","metadata":{}},{"cell_type":"markdown","source":"binary classification metrics calculation","metadata":{}},{"cell_type":"code","source":"# binary classification metrics calculation\nbinary = evaluating_change_point(true_outlier, predicted_outlier, metric='binary', numenta_time='30 sec')","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"average detection delay metric calculation","metadata":{}},{"cell_type":"code","source":"# average detection delay metric calculation\nadd = evaluating_change_point(true_cp, predicted_cp, metric='average_delay', numenta_time='30 sec')","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"nab metric calculation","metadata":{}},{"cell_type":"code","source":"# nab metric calculation\nnab = evaluating_change_point(true_cp, predicted_cp, metric='nab', numenta_time='30 sec')","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Visualizations","metadata":{}},{"cell_type":"code","source":"X_train['anomaly'] = df['anomaly']\nX_train['changepoint'] = df['changepoint']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# visualization\na = X_train.loc[X_train['anomaly'] == 1] \n_ = plt.figure(figsize=(18,6))\n_ = plt.plot(X_train[['pca1_scores']], color='blue', label='Inline')\n_ = plt.plot(a[['pca1_scores']], linestyle='none', marker='X', color='red', markersize=12, label='Anomaly')\n_ = plt.xlabel('Series')\n_ = plt.ylabel('Readings')\n_ = plt.title('True Anomaly')\n_ = plt.legend(loc='best')\nplt.show();","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# visualization\na = X_train.loc[X_train['outlier_pca1'] == 1] \n_ = plt.figure(figsize=(18,6))\n_ = plt.plot(X_train[['pca1_scores']], color='blue', label='Inline')\n_ = plt.plot(a[['pca1_scores']], linestyle='none', marker='X', color='red', markersize=12, label='Anomaly')\n_ = plt.xlabel('Series')\n_ = plt.ylabel('Readings')\n_ = plt.title('Anomaly')\n_ = plt.legend(loc='best')\nplt.show();","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"N = X_train.shape[0]\nplt.scatter(range(N),X_train['pca1_scores_norm'][:N].cumsum(),marker='1',label='PCA ')\nplt.xlabel('Readings')\nplt.ylabel('anomalies frequency')\nplt.legend()\nplt.show()","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#2 -- Distributions of Predicted Probabilities of both classes\nlabels=['Positive','Negative']\nplt.hist(X_train[X_train['outlier_pca1']==1]['pca1_scores_norm'], density=False, bins=100,\n             alpha=.5, color='green',  label=labels[0])\nplt.hist(X_train[X_train['outlier_pca1']==0]['pca1_scores_norm'], density=False, bins=100,\n             alpha=.5, color='red', label=labels[1])\nplt.axvline(.5, color='blue', linestyle='--', label='decision boundary')\n# plt.xlim([0,1])\nplt.title('Distributions', size=13)\nplt.xlabel('Norm values', size=13)\nplt.ylabel('Readings (norm.)', size=13)\nplt.legend(loc=\"upper right\")","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\n\nprint(classification_report(X_train['anomaly'], X_train['outlier_pca1']))\nconfusion_matrix(X_train['anomaly'], X_train['outlier_pca1'])","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(X_train['changepoint'], X_train['outlier_pca1']))\nconfusion_matrix(X_train['changepoint'], X_train['outlier_pca1'])","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nroc_auc_score(X_train['outlier_pca1'], X_train['anomaly'])","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"roc_auc_score(X_train['outlier_pca1'], X_train['changepoint'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}