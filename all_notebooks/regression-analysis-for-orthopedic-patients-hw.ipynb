{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Introduction**\n\nAs a beginner, I purpose to analyse orthopedic patients bones with using some regression algorithms for this Kernel. Firstly, I will analyze my data; according to results, try to apply some regression models, and lastly I will conclude my report.\n\n1. Linear regression\n2. Logistic Regression\n3. KNN Algorithm"},{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns  # visualization tool\nfrom sklearn.linear_model import LinearRegression\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#read data\ndata = pd.read_csv(\"../input/biomechanical-features-of-orthopedic-patients/column_2C_weka.csv\")\ndata.info()\ndata.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After info() funciton, there are no null value therefore I dont need to apply any filling up function, I can use direclt my data.\n\n*First 6 rows* ==> float values(my features for analyzing my data)\n\n*Last row'class' * ==> string value and has **\"Normal\" and \"Abnormal\"**\n\nTherefore I can use my \"Class\" feature as a binary classification, and try to understand my features characteristics and effects on that feature."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Analyze data**\n\nTo understand relaitonhip between features, \n\n*Firstly,* I want to divide my data on binary classificaiton point; means Noemal and Abnormal.In order to analyze those classes I want to plot count of those class values.\n    \n*Secondly, *I want to learn correlation between my features.\nNote: Correlation matrix is a very useful plot for the first look up;  intersection of features seems approximately 1 it means those 2 features are very related with each other and they have big correlation."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x=\"class\", data=data)\ndata.loc[:,'class'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the figure, as it seems Normal class values are smaller than Abnormal values; therefore i need to narrow my perspective with selecting some correlated features. Lets look at correlation matrix of all features:"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Correlation map\ndata.corr() \nf, ax = plt.subplots(figsize = (8,8))\nsns.heatmap(data.corr(), annot = True, linewidths=.5, fmt = \".2f\", ax=ax)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As it seems from the figure,  **pelvic_incidence** and **sacral_slope** has the big correlation among the other features.\nHence, I want to focus on those features while analyzing my data with respect to \"Normal\" and \"Abnormal\" class feature."},{"metadata":{},"cell_type":"markdown","source":" ** 1. \n LINEAR REGRESSION ANALYSIS**\n\nIn that part of the analysis, I want to give some brief information about Linear Regression;\n\nIt is a mathematical representation on data. \n> Y = B0 + B1.X + ... BN.X\n\n**B0:** it is a bias for our data\n**B1:** coefficient for input data\n**Y: **result\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dividing my data as Normal and Abnormal class\ndata_a = data[data[\"class\"] == \"Abnormal\"]\ndata_n = data[data[\"class\"] == \"Normal\"]\n\n#For Abnormal data\nx_a = np.array(data_a.loc[:,'pelvic_incidence']).reshape(-1,1)\ny_a = np.array(data_a.loc[:,'sacral_slope']).reshape(-1,1)\n#For Normal data\nx_n = np.array(data_n.loc[:,'pelvic_incidence']).reshape(-1,1)\ny_n = np.array(data_n.loc[:,'sacral_slope']).reshape(-1,1)\n\n# Scatter plot\nplt.scatter(x = x_a, y = y_a, color = \"red\", label = \"Abnormal\", alpha = 0.5)\nplt.scatter(x = x_n, y = y_n, color = \"green\", label = \"Normal\", alpha = 0.5)\nplt.xlabel('pelvic_incidence')\nplt.ylabel('sacral_slope')\nplt.legend()\nplt.title(\"pelvic_incidence and sacral_slope for Normal and Abnormal class\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Linear Regression and drawing line and calculate accuracy\nlr = LinearRegression()\nlr.fit(x_a, y_a)\npredicted_a = np.linspace(min(x_a), max(x_a)).reshape(-1,1)\ny_a_head = lr.predict(predicted_a)\nprint('Accuracy for Abnormal: ',lr.score(x_a, y_a))\n\nlr2 = LinearRegression()\nlr2.fit(x_n, y_n)\npredicted_n = np.linspace(min(x_n), max(x_n)).reshape(-1,1)\ny_n_head = lr2.predict(predicted_n)\nprint('Accuracy for Normal: ',lr2.score(x_n, y_n))\n\n# Plot regression line and scatter\nplt.figure(figsize=[10,8])\nplt.plot(predicted_a, y_a_head, color='black', linewidth=3, label = \"Abnormal\", linestyle='dashed')\nplt.plot(predicted_n, y_n_head, color='black', linewidth=3, label = \"Normal\")\nplt.scatter(x = x_a, y = y_a, color = \"red\", label = \"Abnormal\", alpha = 0.5)\nplt.scatter(x = x_n, y = y_n, color = \"green\", label = \"Normal\", alpha = 0.5)\nplt.xlabel('pelvic_incidence')\nplt.ylabel('sacral_slope')\nplt.legend()\nplt.title(\"pelvic_incidence and sacral_slope for Normal and Abnormal class\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" **2. LOGISTIC REGRESSION**\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns = data.columns.str.replace('class','bone_type')#I chance class because it has some refer problem\n\n#Convert Abnormal to 1 Normal 0 for binary representation\ndata.bone_type = [1 if each == \"Abnormal\" else 0 for each in data.bone_type]\n\ny = data.bone_type.values #take all values into y \nx_data = data.drop(['bone_type'], axis = 1)\n\n#Normalization for all values into x between 0 and 1 for calculation\n#  (x- min(x)) / (max(x) - min(x))\nx = (x_data - np.min(x_data)) / (np.max(x_data) - np.min(x_data)).values\n\n#Split data for train and test and test size is assumed as 20%\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)\n\nprint(\"x_train: \", x_train.shape,\"y_train: \", y_train.shape,\" \\nx_test: \", x_test.shape, \" y_test: \", y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nlor = LogisticRegression()\nlor.fit(x_train,y_train)\n\ny_predict = lor.predict(x_test)\n\ndef find_accuracy(y_test, y_predict):\n    count = 0\n    if(len(y_test) == len(y_predict)):\n        for i in range(len(y_test)):\n            if(y_test[i] == y_predict[i]): \n                count += 1\n        acc = count / len(y_test) * 100\n        print(\"Accuracy -->\", acc, \"%\")\n    else:\n        print(\"Your test and predicted data set are not equal accuracy will not be calculated\")\n\nfind_accuracy(y_test, y_predict)\n#lor.score(x_test, y_test)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**COMPARISION**\n\nIt is a comparision between Linear and Logistic Regression with plot"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_1 = np.array(x_data.pelvic_incidence).reshape(-1,1)\ny_1 = np.array(data.bone_type.values).reshape(-1,1)\n\n#Linear Regression\nx_n = (x_1 - min(x_1)) / (max(x_1) - min(x_1))\nlr = LinearRegression()\nlr.fit(x_n,y_1)\nlp = np.linspace(min(x_n), max(x_n)).reshape(-1,1)\ny_head = lr.predict(lp)\nprint('Accuracy for Linear Regression: ',lr.score(x_n, y_1))\n\n#Logistic Regression\nlgr = LogisticRegression()\nlgr.fit(x_n, y_1)\nlp = np.linspace(min(x_n), max(x_n)).reshape(-1,1)\ny_head2 = lgr.predict(lp)\nprint('Accuracy Logistic Regression: ',lgr.score(x_n, y_1))\n\n# Plot regression line and scatter\nplt.plot(lp, y_head, color='black', linewidth=3, label = \"Linear\")\nplt.plot(lp, y_head2, color='red', linewidth=3, label = \"Logistic\")\nplt.scatter(x = x_n, y = y_1)\nplt.xlabel(\"Pelvic Incidence\")\nplt.ylabel(\"Type(Normal || Abnormal)\")\nplt.legend()\nplt.title(\"Linear and Logistic Regression\")\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**3. KNN ALGORITHM**\n\nK-Neighbor algorithm is classification algorithm to find k neighbors and then according to neighbors classificaiton find test point class.\n\nI will use divided classes as abnormal and normal in Linear Regression secion for this algorithm:\n\n+Abnormal class --> a_data (value 1)\n\n+Normal class --> n_data (value 0)\n\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#For plotting I need to change column[class] name because class is defined word.\n#Then I will represent my class attribitues as binary representation \na_data = data[data[\"bone_type\"] == 1]\nn_data = data[data[\"bone_type\"] == 0]\n\nplt.scatter(a_data.degree_spondylolisthesis, a_data.lumbar_lordosis_angle, color = \"red\", label = \"Abnormal\", alpha=0.5)\nplt.scatter(n_data.degree_spondylolisthesis, n_data.lumbar_lordosis_angle, color = \"green\", label = \"Normal\", alpha = 0.5)\nplt.xlabel(\"Pelvic Incidence\")\nplt.ylabel(\"Pelvic Radius\")\nplt.legend()\nplt.title(\"Pelvic Incidence and Radius for Normal and Abnormal Bone Type\")\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_all = data.drop([\"bone_type\"], axis = 1) # all values except bone type\ny = data.bone_type.values #label 0 or 1\n\n#Normalization\nx_norm = (x_all - np.min(x_all))/(np.max(x_all)-np.min(x_all))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Train-Test Splitting\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x_norm, y, test_size = 0.3, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#KNN Algorithm application\nfrom sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors = 5) # give number of neighbor as 5\nknn.fit(x_train, y_train)\nprediction = knn.predict(x_test)\nprint(\"KNN Accuracy: \", knn.score(x_test, y_test))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Find best neighbor number for this situation and then plot it\naccuracy_list = []\nfor each in range (1,30):\n    knn2 = KNeighborsClassifier(n_neighbors = each)\n    knn2.fit(x_train, y_train)\n    accuracy_list.append(knn2.score(x_test, y_test))\n\n#Plot with line diagram\nplt.plot(range(1,30),accuracy_list, label = \"Accuracy\", linewidth = 3)\nplt.grid()\nplt.xlabel(\"K Neighbors numbers\")\nplt.ylabel(\"Accuracy\")\nplt.title(\"Accuracy graph according to Neighbors numbers\")\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you can see from the above figure K = 15 has the best accuracy.\nAccording to that good neighbor number, I would like to plot decision boundaries because my accuracy is very accurate."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}