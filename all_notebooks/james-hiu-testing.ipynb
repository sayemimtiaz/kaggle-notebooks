{"cells":[{"metadata":{},"cell_type":"markdown","source":"# **My Housing Price Competition Notebook**","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom xgboost import XGBRegressor\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Reading the Data**","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"home = pd.read_csv('../input/home-data-for-ml-course/train.csv',index_col='Id')\ntest = pd.read_csv('../input/home-data-for-ml-course/test.csv',index_col='Id')\n\n#home.head()\n#test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Explore the data - Correlations\nIdentify property features that have \"very Low\" correlation with Sale Price and property features highly correlated with one another (multicollinearity)\n\n**1. Low Correlation Features (-0.1<x<0.1)** - We wish to drop features that appear to have low value in predicting a home's sale price\n<br>\n      <br>  a)<font color=blue> **MSSubClass**:</font> Identifies the type of dwelling involved in the sale (-0.08)\n      <br>  b)<font color=blue> **OverallCond**:</font> Rates the overall condition of the house (-0.08)\n      <br>  c)<font color=blue> **LowQualFinSF**:</font> Low quality finished square feet (all floors) (-0.03)\n      <br>  d)<font color=blue> **MiscVal**:</font> Dollar value of miscellaneous feature (-0.02)\n      <br>  e)<font color=blue> **PoolArea**:</font> Month Sold (0.09)\n      <br>  f)<font color=blue> **MoSold**:</font> Month Sold (0.05)\n      <br>  g)<font color=blue> **YrSold**:</font> Year Sold (-0.03)\n\n**2. Highly Correlated Features |x|>0.8** - We wish to drop features highly similar features to predict sale price when one feature will do\n<br>\n      <br>  a)<font color=blue> **GarageYrBlt**:</font> GarageYrBlt & YearBuilt (0.83), drop GarageYrBlt because property without garage more likely than garage without property\n      <br>  b)<font color=blue> **TotRmsAbvGrd**:</font> GrLivArea & TotRmsAbvGrd (0.83), drop TotRmsAbvGrd because this variable does not count bathrooms and squarefeet differences is more detailed\n      <br>  c)<font color=blue> **GarageCars**:</font> GarageArea and GarageCars (0.88), drop GarageCars because squarefeet differences is more detailed\n\n**3. Other Features**\n<br>\n      <br> As for BsmtFinSF2 (-0.01) and BsmtHalfBath (-0.02) having weak correlation with Sales Price.\n      <br> Also, the strong correlation between TotalBsmtSF vs 1stFlrSF (0.82).\n      <br>\n      <br> I am retaining these features for feature engineering.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Generate feature correlation visualization\n\nplt.figure(figsize=(18,18))\nsns.heatmap(home.corr(), annot=True, fmt=\".2f\", vmin=-1, vmax=1, center= 0, cmap= 'coolwarm', cbar_kws= {'orientation': 'horizontal'} )\n\nhome.drop(['MSSubClass','OverallCond','LowQualFinSF','MiscVal','PoolArea','MoSold','YrSold','GarageYrBlt','TotRmsAbvGrd','GarageCars'], axis=1, inplace=True)\ntest.drop(['MSSubClass','OverallCond','LowQualFinSF','MiscVal','PoolArea','MoSold','YrSold','GarageYrBlt','TotRmsAbvGrd','GarageCars'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Explore the data - Missing Values\nIdentify columns with missing values and decide how to best treat these variables\n\n**1. Dropped Columns** - We wish to drop variables with a very high number of null values.\n      <br>  a)<font color=blue> **PoolQC**:</font> Pool Quality 1453 null values out of 1460\n      <br>  b)<font color=blue> **MiscFeature**:</font> Miscellaneous features (e.g. Elevators/Shed) 1406 null values out of 1460\n      <br>  c)<font color=blue> **Alley**:</font> Type of alley access to property 1369 null values out of 1460\n      <br>  d)<font color=blue> **Fence**:</font> Fence Quality on the property 1179 null values out of 1460\n\n**2. Categorical Features:** - For categorical columns with missing values we will encode missing values with the most common type reported in that neighbourhood.\n\n**3. Numerical Features:** - For numerical columns with missing values we will encode with averages value reported in that neighbourhood.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Identify and report count - columns with missing values\nmissing_data = home.isnull().sum()\ncol_with_missing = missing_data[missing_data>0]\ncol_with_missing.sort_values(inplace=True)\nprint(col_with_missing)\n\nmissing_data2 = test.isnull().sum()\ncol_with_missing2 = missing_data2[missing_data2>0]\ncol_with_missing2.sort_values(inplace=True)\nprint(col_with_missing2)\n\nhome.drop(['PoolQC','MiscFeature','Alley','Fence'], axis=1, inplace=True)\ntest.drop(['PoolQC','MiscFeature','Alley','Fence'], axis=1, inplace=True)\n\nfor df in [home, test]:\n#Encode missing categorical features with most common type/quality, grouping by neighborhood\n    for col in (\"Electrical\",\"MasVnrType\", \"GarageType\",\"BsmtQual\",\"BsmtCond\",\"BsmtFinType1\",\"BsmtFinType2\",\"BsmtExposure\",\"GarageFinish\",\"GarageQual\",\"GarageCond\",\"FireplaceQu\",\"KitchenQual\",\"SaleType\"\n               ,\"Exterior1st\",\"Exterior2nd\",\"Utilities\",\"Functional\",\"MSZoning\"):\n         df[col] = df.groupby(\"Neighborhood\")[col].transform(lambda x: x.fillna(x.mode()[0]))\n#Encode missing numerical features with average values, grouping by neighborhood\n    for col2 in (\"MasVnrArea\",\"LotFrontage\",\"TotalBsmtSF\",\"GarageArea\",\"BsmtUnfSF\",\"BsmtFinSF2\",\"BsmtFinSF1\",\"BsmtFullBath\",\"BsmtHalfBath\"):\n        df[col2] = df.groupby('Neighborhood')[col2].transform(lambda x: x.fillna(x.mean()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"#Identify Numerical Data\nnumerical_data = home.select_dtypes(exclude=['object']).drop('SalePrice', axis=1)\n\n#Explore Numerical Data Distribution\nfig = plt.figure(figsize=(20,18))\nfor i in range(len(numerical_data.columns)):\n    fig.add_subplot (9,4,i+1)\n    sns.distplot(a=numerical_data.iloc[:,i].dropna(), kde=False)\n    plt.xlabel(numerical_data.columns[i])\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"#Identify Categorical Data\ncategorical_data = home.select_dtypes(['object'])\n\n#Explore Categorical Data Distribution\nfig = plt.figure(figsize=(20,18))\nfor i in range(len(categorical_data.columns)):\n    fig.add_subplot(12,4,i+1)\n    sns.countplot(x=categorical_data.iloc[:,i])\nplt.tight_layout()\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modelling the Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fit the Model on Training Data\ny = home.SalePrice\nX = home.drop(['SalePrice'],axis=1)\n# Get list of categorical variables\na = (home.dtypes == 'object')\nobject_cols = list(a[a].index)\n# Apply one-hot encoder to each column with categorical data\nOH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\nOH_cols_train = pd.DataFrame(OH_encoder.fit_transform(home[object_cols]))\n# One-hot encoding removed index; put it back\nOH_cols_train.index = home.index\n# Remove categorical columns (will replace with one-hot encoding)\nX = X.drop(object_cols, axis=1)\n\nmy_model = XGBRegressor()\nmy_model.fit(X, y)\n\npredictions = my_model.predict(X)\nprint(\"Mean Absolute Error: \" + str(mean_absolute_error(predictions, y)))\n\n\n#Apply the model to Test Data\nX_test = test\n# Get list of categorical variables\nb = (test.dtypes == 'object')\nobject_cols2 = list(b[b].index)\n# Apply one-hot encoder to each column with categorical data\nOH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\nOH_cols_test = pd.DataFrame(OH_encoder.fit_transform(test[object_cols2]))\n# One-hot encoding removed index; put it back\nOH_cols_test.index = test.index\n# Remove categorical columns (will replace with one-hot encoding)\nX_test = test.drop(object_cols, axis=1)\n\n\npredictions2 = my_model.predict(X_test)\n\nprint(predictions2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submit for Evaluation\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save test predictions to file\noutput = pd.DataFrame({'Id': X_test.index,\n                       'SalePrice': predictions2})\noutput.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}