{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Heart Disease Analysis & Classification"},{"metadata":{},"cell_type":"markdown","source":"![](https://creakyjoints.org/wp-content/uploads/2019/12/1219_Heart_Inflammation_Logo-1024x671.jpg)"},{"metadata":{},"cell_type":"markdown","source":"> In this notebook i will try to investigate and visualize heart-disease data and later on evaluate different machine learning models.\n> Feel free to comment on this notebook.ðŸ‘ðŸ‘"},{"metadata":{},"cell_type":"markdown","source":"# Importing Libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import tree\nimport os\nimport preprocessing \n\nfrom pandas_profiling import ProfileReport\n\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2, f_classif\nfrom sklearn.model_selection import KFold\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.svm import LinearSVC\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import cross_val_predict\n\nfrom sklearn.preprocessing import normalize\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.cluster import KMeans\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom xgboost import XGBClassifier\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.metrics import precision_score, recall_score, f1_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import SGDClassifier, LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neural_network import MLPClassifier\nfrom xgboost import XGBClassifier\nfrom xgboost import XGBClassifier, XGBRFClassifier\nfrom xgboost import plot_tree, plot_importance\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, roc_curve\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_selection import RFE\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Importing the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndf = pd.read_csv('../input/heart-disease-uci/heart.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Print the first 5 rows\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Column Descriptions**\n1. age\n2. sex\n3. chest pain type (4 values)\n4. resting blood pressure\n5. serum cholestoral in mg/dl\n6. fasting blood sugar > 120 mg/dl\n7. resting electrocardiographic results (values 0,1,2)\n8. maximum heart rate achieved\n9. exercise induced angina\n10. oldpeak = ST depression induced by exercise relative to rest\n11. the slope of the peak exercise ST segment\n12. number of major vessels (0-3) colored by flourosopy\n13. thal: 3 = normal; 6 = fixed defect; 7 = reversable defect\n14. target: 0 or 1 "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Print the numeric information about the data\ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# How many rows the data has\nprint(\"Rows:\", len(df))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# How many columns the data has\nprint(\"Columns:\", df.shape[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Pandas Profiling"},{"metadata":{},"cell_type":"markdown","source":"> Pandas profiling generates profile reports from a pandas DataFrame. The pandas df.describe() function is great but a little basic for serious exploratory data analysis. pandas_profiling extends the pandas DataFrame with df.profile_report() for quick data analysis."},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas_profiling as pandas_pf\npandas_pf.ProfileReport(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# missing values\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal','target']\nsns.set_style('darkgrid')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> We haven't got any missing values in this set"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(df['age'])\nplt.xlabel('Age')\nplt.ylabel('Count')\nplt.title('Age distribution.')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Age distribution by sex (0 = female, 1 = male)"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.histplot(data=df, x=\"age\", hue=\"sex\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets investigate age values\nminAge=min(df.age)\nmaxAge=max(df.age)\nmeanAge=df.age.mean()\nprint('Min Age :',minAge)\nprint('Max Age :',maxAge)\nprint('Mean Age :',meanAge)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Seaborn CountPlots"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(30,20))\n\nplt.subplot(3,3,1)\nsns.countplot(df['sex'])\n\nplt.subplot(3,3,2)\nsns.countplot(df['cp'])\n\nplt.subplot(3,3,3)\nsns.countplot(df['fbs'])\n\nplt.subplot(3,3,4)\nsns.countplot(df['restecg'])\n\nplt.subplot(3,3,5)\nsns.countplot(df['exang'])\n\nplt.subplot(3,3,6)\nsns.countplot(df['slope'])\n\nplt.subplot(3,3,7)\nsns.countplot(df['ca'])\n\nplt.subplot(3,3,8)\nsns.countplot(df['thal'])\n\nplt.subplot(3,3,9)\nsns.countplot(df['target'])\n\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,10))\nsns.countplot(df['age'])\nplt.xticks(rotation = 90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Scatter Plots"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nplt.scatter(x=df.age[df.target==1], y=df.thalach[(df.target==1)], c=\"red\")\nplt.scatter(x=df.age[df.target==0], y=df.thalach[(df.target==0)], c=\"green\")\nplt.legend([\"Disease\", \"Not Disease\"])\nplt.xlabel(\"Age\")\nplt.ylabel(\"Maximum Heart Rate\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(x=df.age[df.target==1], y=df.trestbps[(df.target==1)], c=\"red\")\nplt.scatter(x=df.age[df.target==0], y=df.trestbps[(df.target==0)], c=\"green\")\nplt.legend([\"Disease\", \"Not Disease\"])\nplt.xlabel(\"Age\")\nplt.ylabel(\"Resting Blood Pressure\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(x=df.age[df.target==1], y=df.chol[(df.target==1)], c=\"red\")\nplt.scatter(x=df.age[df.target==0], y=df.chol[(df.target==0)], c=\"green\")\nplt.legend([\"Disease\", \"Not Disease\"])\nplt.xlabel(\"Age\")\nplt.ylabel(\"Serum cholestoral in mg/dl\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# DistPlot"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,15))\n\nplt.subplot(2,3,1)\nsns.distplot(df['age']).set_title('Age Interval')\n\nplt.subplot(2,3,2)\nsns.distplot(df['chol']).set_title('Chol Interval')\n\nplt.subplot(2,3,3)\nsns.distplot(df['thalach']).set_title('Thalach Interval')\n\nplt.subplot(2,3,4)\nsns.distplot(df['oldpeak']).set_title('Oldpeak Interval')\n\nplt.subplot(2,3,5)\nsns.distplot(df['trestbps']).set_title('Resting Blood Pressure Interval')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# BarPlots"},{"metadata":{},"cell_type":"markdown","source":"> Bar plot representation of features about whether they have heart disease or not"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(30,20))\n\nplt.subplot(4,4,1)\nsns.barplot(x = 'target', y = 'sex', data = df)\n\nplt.subplot(4,4,2)\nsns.barplot(x = 'target', y = 'trestbps', data = df)\n\nplt.subplot(4,4,3)\nsns.barplot(x = 'target', y = 'chol', data = df)\n\nplt.subplot(4,4,4)\nsns.barplot(x = 'target', y = 'thalach', data = df)\n\nplt.subplot(4,4,5)\nsns.barplot(x = 'target', y = 'exang', data = df)\n\nplt.subplot(4,4,6)\nsns.barplot(x = 'target', y = 'oldpeak', data = df)\n\nplt.subplot(4,4,7)\nsns.barplot(x = 'target', y = 'slope', data = df)\n\nplt.subplot(4,4,8)\nsns.barplot(x = 'target', y = 'age', data = df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,10))\nsns.barplot(x=\"trestbps\", y=\"chol\", data=df)\nplt.xticks(rotation=90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,10))\nsns.barplot(x=\"age\", y=\"thalach\", data=df, hue=\"target\")\nplt.xticks(rotation=90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.lmplot(x='age', y='chol', hue='target', data=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Pairplot"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(data=df, hue=\"target\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Heatmap"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,8)) \nsns.heatmap(df.corr(), annot=True, cmap='gist_heat', linewidths = 2)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df[\"target\"]\nX = df.drop('target',axis=1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Machine Learning Models"},{"metadata":{},"cell_type":"markdown","source":"* Logistic Regression\n* Naive Bayes\n* Random Forest Classifier\n* Extreme Gradient Boost\n* K-Nearest Neighbour\n* Decision Tree\n* Support Vector Machine\n* Stochastic Gradient Descent\n* Neural Nets"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_lgr = 'Logistic Regression'\nlr = LogisticRegression()\nmodel = lr.fit(X_train, y_train)\nlr_predict = lr.predict(X_test)\nlr_conf_matrix = confusion_matrix(y_test, lr_predict)\nlr_acc_score = accuracy_score(y_test, lr_predict)\nprint(\"confussion matrix\")\nprint(lr_conf_matrix)\nprint(\"-------------------------------------------\")\nprint(\"Accuracy of Logistic Regression:\",lr_acc_score*100,'\\n')\nprint(\"-------------------------------------------\")\nprint(classification_report(y_test,lr_predict))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_nb = 'Naive Bayes'\nnb = GaussianNB()\nnb.fit(X_train,y_train)\nnbpred = nb.predict(X_test)\nnb_conf_matrix = confusion_matrix(y_test, nbpred)\nnb_acc_score = accuracy_score(y_test, nbpred)\nprint(\"confussion matrix\")\nprint(nb_conf_matrix)\nprint(\"-------------------------------------------\")\nprint(\"Accuracy of Naive Bayes model:\",nb_acc_score*100,'\\n')\nprint(\"-------------------------------------------\")\nprint(classification_report(y_test,nbpred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_rfc = 'Random Forest Classfier'\nrf = RandomForestClassifier(n_estimators=20, random_state=12,max_depth=5)\nrf.fit(X_train,y_train)\nrf_predicted = rf.predict(X_test)\nrf_conf_matrix = confusion_matrix(y_test, rf_predicted)\nrf_acc_score = accuracy_score(y_test, rf_predicted)\nprint(\"confussion matrix\")\nprint(rf_conf_matrix)\nprint(\"-------------------------------------------\")\nprint(\"Accuracy of Random Forest:\",rf_acc_score*100,'\\n')\nprint(\"-------------------------------------------\")\nprint(classification_report(y_test,rf_predicted))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_egb = 'Extreme Gradient Boost'\nxgb = XGBClassifier(learning_rate=0.01, n_estimators=25, max_depth=15,gamma=0.6, subsample=0.52,colsample_bytree=0.6,seed=27, \n                    reg_lambda=2, booster='dart', colsample_bylevel=0.6, colsample_bynode=0.5)\nxgb.fit(X_train, y_train)\nxgb_predicted = xgb.predict(X_test)\nxgb_conf_matrix = confusion_matrix(y_test, xgb_predicted)\nxgb_acc_score = accuracy_score(y_test, xgb_predicted)\nprint(\"confussion matrix\")\nprint(xgb_conf_matrix)\nprint(\"-------------------------------------------\")\nprint(\"Accuracy of Extreme Gradient Boost:\",xgb_acc_score*100,'\\n')\nprint(\"-------------------------------------------\")\nprint(classification_report(y_test,xgb_predicted))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_knn = 'K-NeighborsClassifier'\nknn = KNeighborsClassifier(n_neighbors=10)\nknn.fit(X_train, y_train)\nknn_predicted = knn.predict(X_test)\nknn_conf_matrix = confusion_matrix(y_test, knn_predicted)\nknn_acc_score = accuracy_score(y_test, knn_predicted)\nprint(\"confussion matrix\")\nprint(knn_conf_matrix)\nprint(\"-------------------------------------------\")\nprint(\"Accuracy of K-NeighborsClassifier:\",knn_acc_score*100,'\\n')\nprint(\"-------------------------------------------\")\nprint(classification_report(y_test,knn_predicted))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_dtc = 'DecisionTreeClassifier'\ndt = DecisionTreeClassifier(criterion = 'entropy',random_state=0,max_depth = 6)\ndt.fit(X_train, y_train)\ndt_predicted = dt.predict(X_test)\ndt_conf_matrix = confusion_matrix(y_test, dt_predicted)\ndt_acc_score = accuracy_score(y_test, dt_predicted)\nprint(\"confussion matrix\")\nprint(dt_conf_matrix)\nprint(\"-------------------------------------------\")\nprint(\"Accuracy of DecisionTreeClassifier:\",dt_acc_score*100,'\\n')\nprint(\"-------------------------------------------\")\nprint(classification_report(y_test,dt_predicted))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_svc = 'Support Vector Classifier'\nsvc =  SVC(kernel='rbf', C=2)\nsvc.fit(X_train, y_train)\nsvc_predicted = svc.predict(X_test)\nsvc_conf_matrix = confusion_matrix(y_test, svc_predicted)\nsvc_acc_score = accuracy_score(y_test, svc_predicted)\nprint(\"confussion matrix\")\nprint(svc_conf_matrix)\nprint(\"-------------------------------------------\")\nprint(\"Accuracy of Support Vector Classifier:\",svc_acc_score*100,'\\n')\nprint(\"-------------------------------------------\")\nprint(classification_report(y_test,svc_predicted))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_sgd = 'Stochastic Gradient Descent'\nsgdc = SGDClassifier(max_iter=5000, random_state=0)\nsgdc.fit(X_train, y_train)\nsgdc_predicted = sgdc.predict(X_test)\nsgdc_conf_matrix = confusion_matrix(y_test, sgdc_predicted)\nsgdc_acc_score = accuracy_score(y_test, sgdc_predicted)\nprint(\"confussion matrix\")\nprint(sgdc_conf_matrix)\nprint(\"-------------------------------------------\")\nprint(\"Accuracy of : Stochastic Gradient Descent\",sgdc_acc_score*100,'\\n')\nprint(\"-------------------------------------------\")\nprint(classification_report(y_test,sgdc_predicted))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_nn = 'Neural Nets'\nmlpc = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5000, 10), random_state=1)\nmlpc.fit(X_train, y_train)\nmlpc_predicted = mlpc.predict(X_test)\nmlpc_conf_matrix = confusion_matrix(y_test, mlpc_predicted)\nmlpc_acc_score = accuracy_score(y_test, mlpc_predicted)\nprint(\"confussion matrix\")\nprint(mlpc_conf_matrix)\nprint(\"-------------------------------------------\")\nprint(\"Accuracy of : MLP Classifier\",mlpc_acc_score*100,'\\n')\nprint(\"-------------------------------------------\")\nprint(classification_report(y_test,mlpc_predicted))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Confusion Matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(30,20))\n\nplt.subplot(3,3,1)\nplt.title('Heart Disease --- Model: Logistic Regression --- Accuracy:{x:.5f}'.format(x=lr_acc_score))\nsns.heatmap(lr_conf_matrix, annot=True, cmap=\"Blues\")\n\nplt.subplot(3,3,2)\nplt.title('Heart Disease --- Model: Naive Bayes --- Accuracy:{x:.5f}'.format(x=nb_acc_score))\nsns.heatmap(nb_conf_matrix, annot=True, cmap=\"Blues\")\n\nplt.subplot(3,3,3)\nplt.title('Heart Disease --- Model: Random Forest --- Accuracy:{x:.5f}'.format(x=rf_acc_score) )\nsns.heatmap(rf_conf_matrix, annot=True, cmap=\"Blues\")\n\nplt.subplot(3,3,4)\nplt.title('Heart Disease --- Model: Extreme Gradient Boost --- Accuracy:{x:.5f}'.format(x=xgb_acc_score))\nsns.heatmap(xgb_conf_matrix, annot=True, cmap=\"Blues\")\n\nplt.subplot(3,3,5)\nplt.title('Heart Disease --- Model: K-Nearest Neighbour --- Accuracy:{x:.5f}'.format(x=knn_acc_score))\nsns.heatmap(knn_conf_matrix, annot=True, cmap=\"Blues\")\n\nplt.subplot(3,3,6)\nplt.title('Heart Disease --- Model: Decision Tree --- Accuracy:{x:.5f}'.format(x=nb_acc_score))\nsns.heatmap(nb_conf_matrix, annot=True, cmap=\"Blues\")\n\nplt.subplot(3,3,7)\nplt.title('Heart Disease --- Model: Support Vector Machine --- Accuracy:{x:.5f}'.format(x=svc_acc_score))\nsns.heatmap(svc_conf_matrix, annot=True, cmap=\"Blues\")\n\nplt.subplot(3,3,8)\nplt.title('Heart Disease --- Model: Stochastic Gradient Descent --- Accuracy:{x:.5f}'.format(x=sgdc_acc_score))\nsns.heatmap(sgdc_conf_matrix, annot=True, cmap=\"Blues\")\n\nplt.subplot(3,3,9)\nplt.title('Heart Disease --- Model: Neural Nets --- Accuracy:{x:.5f}'.format(x=mlpc_acc_score))\nsns.heatmap(mlpc_conf_matrix, annot=True, cmap=\"Blues\")\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Importance"},{"metadata":{"trusted":true},"cell_type":"code","source":"imp_feature = pd.DataFrame({'Feature': ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach',\n       'exang', 'oldpeak', 'slope', 'ca', 'thal'], 'Importance': xgb.feature_importances_})\nplt.figure(figsize=(10,4))\nplt.title(\"barplot Represent feature importance \")\nplt.xlabel(\"importance \")\nplt.ylabel(\"features\")\nplt.barh(imp_feature['Feature'],imp_feature['Importance'],color = 'rgbkymc')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluation of Models"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_ev = pd.DataFrame({'Model': ['Logistic Regression','Naive Bayes','Random Forest','Extreme Gradient Boost',\n                    'K-Nearest Neighbour','Decision Tree','Support Vector Machine', 'Stochastic Gradient Descent', 'Neural Nets'], 'Accuracy': [lr_acc_score*100,\n                    nb_acc_score*100,rf_acc_score*100,xgb_acc_score*100,knn_acc_score*100,dt_acc_score*100,svc_acc_score*100, sgdc_acc_score*100, mlpc_acc_score*100]})\nmodel_ev","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"colors = ['red','green','blue','gold','silver','yellow','orange','magenta', 'cyan']\nplt.figure(figsize=(12,5))\nplt.title(\"barplot Represent Accuracy of different models\")\nplt.xlabel(\"Accuracy %\")\nplt.xticks(rotation=90)\nplt.ylabel(\"Algorithms\")\nplt.bar(model_ev['Model'],model_ev['Accuracy'],color = colors)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusion"},{"metadata":{},"cell_type":"markdown","source":"> Extreme Gradient Boost gave the best accuracy on test with the : 90.163934"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}