{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Car Price Prediction\n*The aim of this company is to  know:\n* Which variables are significant in predicting the price of a car\n* How well those variables describe the price of a car\n\nThe solution is divided into the following sections: \n- Data understanding and exploration\n- Data cleaning\n- Data preparation\n- Model building and evaluation\n"},{"metadata":{},"cell_type":"markdown","source":"first let's understand and explore our data "},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"carP=pd.read_csv(\"../input/car-price-prediction/CarPrice_Assignment.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"carP.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"carP.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"carP['symboling'].astype('category').value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"carP['aspiration'].astype('category').value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"carP['doornumber'].astype('category').value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"carP['drivewheel'].astype('category').value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"carP['compressionratio'].astype('category').value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# wheelbase: distance between centre of front and rarewheels\nsns.distplot(carP['wheelbase'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(carP['compressionratio'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# target variable: price of car\nsns.distplot(carP['price'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#select all numerical variables\nnumeric_car=carP.select_dtypes(include=['float64','int64'])\nnumeric_car","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numeric_car = numeric_car.drop(['symboling', 'car_ID'], axis=1)\nnumeric_car.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plotting pairwise\nplt.figure(figsize=(20,10))\nsns.pairplot(numeric_car)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is quite hard to read, and we can rather plot correlations between variables. Also, a heatmap is pretty useful to visualise multiple correlations in one plot."},{"metadata":{"trusted":true},"cell_type":"code","source":"cor=numeric_car.corr()\ncor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plotting correlations on a heatmap\n\n# figure size\nplt.figure(figsize=(16,8))\n\n# heatmap\nsns.heatmap(cor, cmap=\"YlGnBu\", annot=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Correlation of price with independent variables:\n\nPrice is highly (positively) correlated with wheelbase, carlength, carwidth, curbweight, enginesize, horsepower (notice how all of these variables represent the size/weight/engine power of the car)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# converting symboling to categorical\ncarP['symboling'] = carp['symboling'].astype('object')\ncarp.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"carP['CarName'].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we have just the first part of CarName is the name of company "},{"metadata":{"trusted":true},"cell_type":"code","source":"car_names=carP['CarName'].apply(lambda x: x.split(\" \")[0])\ncar_names.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"let's add new column of car_names"},{"metadata":{"trusted":true},"cell_type":"code","source":"# New column car_company\ncarP['car_company'] = car_names","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"carP.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"carP=carP.drop(['CarName'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"carP.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"carP['car_company'].astype('category').value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"wa have some names in company name which are not written correctly , we have to rewrite them like VW vokswagen toyouta porcche... which are toyota porche..\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# volkswagen\ncarP.loc[(carP['car_company'] == \"vw\") | \n         (carP['car_company'] == \"vokswagen\")\n         , 'car_company'] = 'volkswagen'\n\n# porsche\ncarP.loc[carP['car_company'] == \"porcshce\", 'car_company'] = 'porsche'\n\n# toyota\ncarP.loc[carP['car_company'] == \"toyouta\", 'car_company'] = 'toyota'\n\n# nissan\ncarP.loc[carP['car_company'] == \"Nissan\", 'car_company'] = 'nissan'\n\n# mazda\ncarP.loc[carP['car_company'] == \"maxda\", 'car_company'] = 'mazda'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"carP['car_company'].astype('category').value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"carP.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"carP.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Prepare the data for our Model "},{"metadata":{"trusted":true},"cell_type":"code","source":"x=carP.loc[:, carP.columns != 'price']\ny=carP['price']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"creating dummy variables for categorical variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"# subset all categorical variables\ncars_categorical = x.select_dtypes(include=['object'])\ncars_categorical.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert into dummies\ncars_dummies = pd.get_dummies(cars_categorical, drop_first=True)\ncars_dummies.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=x.drop(list(cars_categorical.columns), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=pd.concat([x,cars_dummies],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# scaling the features\nfrom sklearn.preprocessing import scale\n\n# storing column names in cols, since column names are (annoyingly) lost after \n# scaling (the df is converted to a numpy array)\ncols = x.columns\nx = pd.DataFrame(scale(x))\nx.columns = cols\nx.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# split into train and test\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(x, y, train_size=0.7,test_size = 0.3, random_state=100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**BUilding the model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\n# Building the first model with all the features\nRg = LinearRegression()\n# fit\nRg.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print coefficients and intercept\nprint(Rg.coef_)\nprint(Rg.intercept_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predict \ny_pred = Rg.predict(X_test)\n\n# metrics\nfrom sklearn.metrics import r2_score\n\nprint(r2_score(y_true=y_test, y_pred=y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Not bad, we are getting approx. 82.5% r-squared with all the variables"},{"metadata":{},"cell_type":"markdown","source":"\nLet's now build a model using recursive feature elimination to select features"},{"metadata":{"trusted":true},"cell_type":"code","source":"# RFE with 15 features\nfrom sklearn.feature_selection import RFE\n#Initializing RFE model\nRg=LinearRegression()\nrfe = RFE(Rg, 15)\n#Transforming data using RFE\nX_rfe = rfe.fit(X_train,y_train)  \n\nprint(rfe.support_)\nprint(rfe.ranking_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# making predictions using rfe model\ny_pred = rfe.predict(X_test)\n\n# r-squared\nprint(r2_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# RFE with 7 features\n\n#Initializing RFE model\nRg=LinearRegression()\nrfe_7 = RFE(Rg, 7)\n#Transforming data using RFE\nX_rfe7 = rfe_7.fit(X_train,y_train)\n# making predictions using rfe model\ny_pred = rfe_7.predict(X_test)\n\n# r-squared\nprint(r2_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note that RFE with 7 features is giving about 88% r-squared, compared to 90% with 15 features. \nShould we then choose more features for slightly better performance?"},{"metadata":{"trusted":true},"cell_type":"code","source":"# import statsmodels\nimport statsmodels.api as sm  \n\n# subset the features selected by rfe_15\ncol_15 = X_train.columns[rfe.support_]\n\n# subsetting training data for 15 selected columns\nX_train_rfe_15 = X_train[col_15]\n\n# add a constant to the model\nX_train_rfe_15 = sm.add_constant(X_train_rfe_15)\nX_train_rfe_15.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fitting the model with 15 variables\nRg_15 = sm.OLS(y_train, X_train_rfe_15).fit()   \nprint(Rg_15.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note that the model with 15 variables gives about 93.6% r-squared, though that is on training data. The adjusted r-squared is 92.9."},{"metadata":{"trusted":true},"cell_type":"code","source":"# making predictions using rfe_15 sm model\nX_test_rfe_15 = X_test[col_15]\n\n\n# # Adding a constant variable \nX_test_rfe_15 = sm.add_constant(X_test_rfe_15, has_constant='add')\nX_test_rfe_15.info()\n\n\n# # Making predictions\ny_pred = Rg_15.predict(X_test_rfe_15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# r-squared\nr2_score(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" the test r-squared of model with 15 features is about 90.7%, while training is about 93.6%"},{"metadata":{},"cell_type":"markdown","source":"Choosing the optimal number of features"},{"metadata":{"trusted":true},"cell_type":"code","source":"n_features_list = list(range(4, 20))\nadjusted_r2 = []\nr2 = []\ntest_r2 = []\n\nfor n_features in range(4, 20):\n\n    # RFE with n features\n    Rg = LinearRegression()\n\n    # specify number of features\n    rfe_n = RFE(Rg, n_features)\n\n    # fit with n features\n    rfe_n.fit(X_train, y_train)\n\n    # subset the features selected by rfe_6\n    col_n = X_train.columns[rfe_n.support_]\n\n    # subsetting training data for 6 selected columns\n    X_train_rfe_n = X_train[col_n]\n\n    # add a constant to the model\n    X_train_rfe_n = sm.add_constant(X_train_rfe_n)\n\n\n    # fitting the model with 6 variables\n    Rg_n = sm.OLS(y_train, X_train_rfe_n).fit()\n    adjusted_r2.append(Rg_n.rsquared_adj)\n    r2.append(Rg_n.rsquared)\n    \n    \n    # making predictions using rfe_15 sm model\n    X_test_rfe_n = X_test[col_n]\n\n\n    # # Adding a constant variable \n    X_test_rfe_n = sm.add_constant(X_test_rfe_n, has_constant='add')\n\n\n\n    # # Making predictions\n    y_pred = Rg_n.predict(X_test_rfe_n)\n    \n    test_r2.append(r2_score(y_test, y_pred))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plotting adjusted_r2 against n_features\nplt.figure(figsize=(10, 8))\nplt.plot(n_features_list, adjusted_r2, label=\"adjusted_r2\")\nplt.plot(n_features_list, r2, label=\"train_r2\")\nplt.plot(n_features_list, test_r2, label=\"test_r2\")\nplt.legend(loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Based on the plot, we can choose the number of features considering the r2_score we are looking for.\n\nwe can choose anything between 4 and 12 features, since beyond 12, the test r2 goes down; and at lesser than 4, the r2_score is too less.\n\nIn fact, the test_r2 score doesn't increase much anyway from n=6 to n=12. It is thus wiser to choose a simpler model, and so let's choose n=6."},{"metadata":{"trusted":true},"cell_type":"code","source":"# RFE with n features\nlm = LinearRegression()\n\nn_features = 6\n\n# specify number of features\nrfe_n = RFE(Rg, n_features)\n\n# fit with n features\nrfe_n.fit(X_train, y_train)\n\n# subset the features selected by rfe_6\ncol_n = X_train.columns[rfe_n.support_]\n\n# subsetting training data for 6 selected columns\nX_train_rfe_n = X_train[col_n]\n\n# add a constant to the model\nX_train_rfe_n = sm.add_constant(X_train_rfe_n)\n\n\n# fitting the model with 6 variables\nRg_n = sm.OLS(y_train, X_train_rfe_n).fit()\nadjusted_r2.append(Rg_n.rsquared_adj)\nr2.append(Rg_n.rsquared)\n\n\n# making predictions using rfe_15 sm model\nX_test_rfe_n = X_test[col_n]\n\n\n# # Adding a constant variable \nX_test_rfe_n = sm.add_constant(X_test_rfe_n, has_constant='add')\n\n\n\n# # Making predictions\ny_pred = Rg_n.predict(X_test_rfe_n)\n\ntest_r2.append(r2_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# summary\nRg_n.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# results \nr2_score(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Final Model Evaluation**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Error terms\nc = [i for i in range(len(y_pred))]\nfig = plt.figure()\nplt.plot(c,y_test-y_pred, color=\"blue\", linewidth=2.5, linestyle=\"-\")\nfig.suptitle('Error Terms', fontsize=20)              # Plot heading \nplt.xlabel('Index', fontsize=18)                      # X-label\nplt.ylabel('ytest-ypred', fontsize=16)                # Y-label\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# mean\nnp.mean(y_test-y_pred)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now it may look like that the mean is not 0, though compared to the scale of 'price', -380 is not such a big number (see distribution below)."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(carP['price'],bins=50)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# multicollinearity\npredictors = ['carwidth', 'curbweight', 'enginesize', \n             'enginelocation_rear', 'car_company_bmw', 'car_company_porsche']\n\ncors = x.loc[:, list(predictors)].corr()\nsns.heatmap(cors, annot=True)\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}