{"cells":[{"metadata":{},"cell_type":"markdown","source":"# 1. Introduction: Business Goal & Problem Definition\n\nThis project´s goal is creating a model to identify the potential risk of clients leaving the company, what I understand is a crucial information for the business. The concerning dataset is called \"Predicting Churn for Bank Customers\" and it´s available in Kaggle. We´ll use the following 10 features below to create the model:\n\nIF YOU LIKE IT OR IF IT HELPS YOU SOMEHOW, COULD YOU PLEASE UPVOTE? THANK YOU VERY MUCH!!!\n\n* Credit Score\n* Geography\n* Gender\n* Age\n* Tenure\n* Balance\n* Number of products\n* Credit card possession\n* Is active member\n* Salary"},{"metadata":{},"cell_type":"markdown","source":"# 2. Importing Basic Libraries"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import io\nimport openpyxl\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Data Collection"},{"metadata":{"trusted":true},"cell_type":"code","source":"#For this exercise I understand it´s a better exercise if we do the analysis by country in order to have a more accurate analyzis by market\n\n# geo = input(\"Select the country you´d like to analyze (France / Germany / Spain): \")\n\nchurn_ds = pd.read_csv(\"../input/predicting-churn-for-bank-customers/Churn_Modelling.csv\", sep=\",\")\nchurn_ds = churn_ds.loc[churn_ds[\"Geography\"] == \"Germany\"]\n\nchurn_ds","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Data Preliminary Exploration"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking a dataset sample\n\npd.set_option(\"display.max_rows\", 100)\npd.set_option(\"display.max_columns\", 100)\npd.options.display.float_format=\"{:,.2f}\".format\nchurn_ds.sample(n=10, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking dataset info by feature\n\nchurn_ds.info(verbose=True, null_counts=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking the existence of zeros in rows\n\n(churn_ds==0).sum(axis=0).to_excel(\"zeros_per_feature.xlsx\")\n(churn_ds==0).sum(axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking the existence of duplicated rows\n\nchurn_ds.duplicated().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking data balancing (for classification)\n\ndata_balancing = pd.DataFrame()\ndata_balancing[\"Count\"] = churn_ds[\"Exited\"].value_counts()\ndata_balancing[\"Count%\"] = churn_ds[\"Exited\"].value_counts()/churn_ds.shape[0]*100\n\ndata_balancing","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking basic statistical data by feature\n\nchurn_ds.describe(include=\"all\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Data Preparation\n\n    We´ll perform the following:\n\n    1. Create a column that will be the \"Balance\" divided by the \"Salary\", what could potentially bring relevant information to the model\n\n\n    2. Remove columns that don´t add any value to the model: \"RowNumber\", \"CustomerId\", \"Surname\" and \"Geography\"\n\n\n    3. Convert categorical variables to dummies: \"Gender\"\n\n\n    * No duplicated rows found\n    * No outliers found"},{"metadata":{"trusted":true},"cell_type":"code","source":"#1\n\nchurn_ds[\"BalanceSalaryProportion\"] = (churn_ds[\"Balance\"]/churn_ds[\"EstimatedSalary\"])\nchurn_ds.reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#2\n\nchurn_ds.drop([\"RowNumber\", \"CustomerId\", \"Surname\", \"Geography\"], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#3\n\nchurn_ds = pd.concat([churn_ds, pd.get_dummies(churn_ds[\"Gender\"], prefix=\"Gender\")], axis=1)\n\nchurn_ds.to_excel(\"churn_ds_clean.xlsx\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6. Data Exploration"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotting Categorical Variables\n\nfig, ax = plt.subplots(1, 2)\nchurn_ds[\"Exited\"].value_counts().plot.bar(color=\"purple\", ax=ax[0])\nchurn_ds[\"Exited\"].value_counts().plot.pie(autopct='%1.1f%%',shadow=True,textprops={\"fontsize\": 10},ax=ax[1])\nfig.suptitle(\"Exited Frequency\", fontsize=15)\nplt.xticks(rotation=90)\nplt.yticks(rotation=45)\n\nfig, ax = plt.subplots(1, 2)\nchurn_ds[\"Gender\"].value_counts().plot.bar(color=\"purple\", ax=ax[0])\nchurn_ds[\"Gender\"].value_counts().plot.pie(autopct='%1.1f%%',shadow=True,textprops={\"fontsize\": 10},ax=ax[1])\nfig.suptitle(\"Gender Frequency\", fontsize=15)\nplt.xticks(rotation=90)\nplt.yticks(rotation=45)\n\nfig, ax = plt.subplots(1, 2)\nchurn_ds[\"HasCrCard\"].value_counts().plot.bar(color=\"purple\", ax=ax[0])\nchurn_ds[\"HasCrCard\"].value_counts().plot.pie(autopct='%1.1f%%',shadow=True,textprops={\"fontsize\": 10},ax=ax[1])\nfig.suptitle(\"HasCrCard Frequency\", fontsize=15)\nplt.xticks(rotation=90)\nplt.yticks(rotation=45)\n\nfig, ax = plt.subplots(1, 2)\nchurn_ds[\"IsActiveMember\"].value_counts().plot.bar(color=\"purple\", ax=ax[0])\nchurn_ds[\"IsActiveMember\"].value_counts().plot.pie(autopct='%1.1f%%',shadow=True,textprops={\"fontsize\": 10},ax=ax[1])\nfig.suptitle(\"IsActiveMember Frequency\", fontsize=15)\nplt.xticks(rotation=90)\nplt.yticks(rotation=45)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotting Numerical Variables\n\nfig, ax = plt.subplots(1,3)\nfig.suptitle(\"CreditScore Distribution\", fontsize=15)\nsns.distplot(churn_ds[\"CreditScore\"], ax=ax[0])\nsns.boxplot(churn_ds[\"CreditScore\"], ax=ax[1])\nsns.violinplot(churn_ds[\"CreditScore\"], ax=ax[2])\n\nfig, ax = plt.subplots(1,3)\nfig.suptitle(\"Age Distribution\", fontsize=15)\nsns.distplot(churn_ds[\"Age\"], ax=ax[0])\nsns.boxplot(churn_ds[\"Age\"], ax=ax[1])\nsns.violinplot(churn_ds[\"Age\"], ax=ax[2])\n\nfig, ax = plt.subplots(1,3)\nfig.suptitle(\"Tenure Distribution\", fontsize=15)\nsns.distplot(churn_ds[\"Tenure\"], ax=ax[0])\nsns.boxplot(churn_ds[\"Tenure\"], ax=ax[1])\nsns.violinplot(churn_ds[\"Tenure\"], ax=ax[2])\n\nfig, ax = plt.subplots(1,3)\nfig.suptitle(\"Balance Distribution\", fontsize=15)\nsns.distplot(churn_ds[\"Balance\"], ax=ax[0])\nsns.boxplot(churn_ds[\"Balance\"], ax=ax[1])\nsns.violinplot(churn_ds[\"Balance\"], ax=ax[2])\n\nfig, ax = plt.subplots(1,3)\nfig.suptitle(\"NumOfProducts Distribution\", fontsize=15)\nsns.distplot(churn_ds[\"NumOfProducts\"], ax=ax[0])\nsns.boxplot(churn_ds[\"NumOfProducts\"], ax=ax[1])\nsns.violinplot(churn_ds[\"NumOfProducts\"], ax=ax[2])\n\nfig, ax = plt.subplots(1,3)\nfig.suptitle(\"EstimatedSalary Distribution\", fontsize=15)\nsns.distplot(churn_ds[\"EstimatedSalary\"], ax=ax[0])\nsns.boxplot(churn_ds[\"EstimatedSalary\"], ax=ax[1])\nsns.violinplot(churn_ds[\"EstimatedSalary\"], ax=ax[2])\n\nfig, ax = plt.subplots(1,3)\nfig.suptitle(\"BalanceSalaryProportion Distribution\", fontsize=15)\nsns.distplot(churn_ds[\"BalanceSalaryProportion\"], ax=ax[0])\nsns.boxplot(churn_ds[\"BalanceSalaryProportion\"], ax=ax[1])\nsns.violinplot(churn_ds[\"BalanceSalaryProportion\"], ax=ax[2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Alternatively using Profile Report to see variables statistics and correlations\n\n# from pandas_profiling import ProfileReport\n# profile = ProfileReport(churn_ds, title=\"Customer Index\")\n# profile.to_file(output_file=\"Customer_Churn.html\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 7. Correlations Analysis & Features Selection"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Deleting original categorical columns\n\nchurn_ds.drop([\"Gender\"], axis=1, inplace=True)\n\n#Plotting a Heatmap\n\nfig, ax = plt.subplots(1, figsize=(25,25))\nsns.heatmap(churn_ds.corr(), annot=True, fmt=\",.2f\")\nplt.title(\"Heatmap Correlation\", fontsize=20)\nplt.tick_params(labelsize=12)\nplt.xticks(rotation=90)\nplt.yticks(rotation=45)\n\n#Plotting a Pairplot\n\nsns.pairplot(churn_ds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotting a Feature Importance\n\nfrom xgboost import XGBClassifier\nfrom matplotlib import pyplot\n#Defining Xs and y\nX = churn_ds.drop([\"Exited\"], axis=1)\ny = churn_ds[\"Exited\"]\n#Defining the model\nmodel = XGBClassifier().fit(X, y)\n#Getting importance\nimportance = model.feature_importances_\n#Summarizing feature importance\nfor i,v in enumerate(importance):\n    print(\"Feature:{0:}, Score:{1:,.4f}\".format(X.columns[i], v))\n#Plotting feature importance\npd.Series(model.feature_importances_[::-1], index=X.columns[::-1]).plot(kind=\"barh\", figsize=(25,25))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 8. Data Modelling"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Defining Xs and y\n\nX = churn_ds[[\"NumOfProducts\", \"IsActiveMember\", \"Age\", \"Gender_Female\", \"Balance\", \"HasCrCard\", \"BalanceSalaryProportion\", \"EstimatedSalary\", \"CreditScore\", \"Tenure\"]]\ny = churn_ds[[\"Exited\"]]\n\n#Scaling all features\n\nfrom sklearn.preprocessing import MinMaxScaler\nsc_X = MinMaxScaler()\nX_scaled = sc_X.fit_transform(X)\nX_scaled = pd.DataFrame(X_scaled)\n\n#Setting train/test split\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 9. Machine Learning Algorithms Implementation & Assessment"},{"metadata":{},"cell_type":"markdown","source":"# 9.1 Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating a Logistic Regression model and checking its Metrics\n\nfrom sklearn import linear_model\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n\n#Trying different polynomial degrees\ndegrees = [1, 2, 3, 4, 5]\nprint(\"Testing degrees:\")\nfor a in degrees:\n    poly = PolynomialFeatures(degree=a)\n    X_train_degree = poly.fit_transform(X_train)\n    X_test_degree = poly.fit_transform(X_test)\n    model_lr = linear_model.LogisticRegression(max_iter=1000000000).fit(X_train_degree, y_train.values.ravel())\n    y_preds_train = model_lr.predict(X_train_degree)\n    y_preds_test = model_lr.predict(X_test_degree)\n    accuracy_train = accuracy_score(y_train, y_preds_train)\n    accuracy_test = accuracy_score(y_test, y_preds_test)\n    precision_train = precision_score(y_train, y_preds_train)\n    precision_test = precision_score(y_test, y_preds_test)\n    recall_train = recall_score(y_train, y_preds_train)\n    recall_test = recall_score(y_test, y_preds_test)\n    f1_train = f1_score(y_train, y_preds_train)\n    f1_test = f1_score(y_test, y_preds_test)\n    print(\"Train: Degree:{0:,.0f}, Accuracy:{1:,.3f}, Precision:{2:,.3f}, Recall:{3:,.3f}, F1:{4:,.3f}\".format(a, accuracy_train, precision_train, recall_train, f1_train))\n    print(\"Test : Degree:{0:,.0f}, Accuracy:{1:,.3f}, Precision:{2:,.3f}, Recall:{3:,.3f}, F1:{4:,.3f}\".format(a, accuracy_test, precision_test, recall_test, f1_test))\nprint(\"\")\n\n#Choosing the best polynomial degree\nchosen_degree = 4\npoly = PolynomialFeatures(degree=chosen_degree)\n\n#Working on X_train & X_test in the polynomial chosen degree\nX_train_degree = poly.fit_transform(X_train)\nX_test_degree = poly.fit_transform(X_test)\n\n#Fitting to the model\nmodel_lr = linear_model.LogisticRegression(max_iter=1000000000).fit(X_train_degree, y_train.values.ravel())\nprint(f\"Linear Regression Intercept: {model_lr.intercept_}\")\nprint(f\"Linear Regression Coefficients: {model_lr.coef_}, \\n\")\n\n#Getting the predictions & Metrics\ny_preds_train = model_lr.predict(X_train_degree)\ny_preds_test = model_lr.predict(X_test_degree)\naccuracy_train = accuracy_score(y_train, y_preds_train)\naccuracy_test = accuracy_score(y_test, y_preds_test)\nprecision_train = precision_score(y_train, y_preds_train)\nprecision_test = precision_score(y_test, y_preds_test)\nrecall_train = recall_score(y_train, y_preds_train)\nrecall_test = recall_score(y_test, y_preds_test)\nf1_train = f1_score(y_train, y_preds_train)\nf1_test = f1_score(y_test, y_preds_test)\nprint(\"Chosen degree:\")\nprint(\"Train: Degree:{0:,.0f}, Accuracy:{1:,.3f}, Precision:{2:,.3f}, Recall:{3:,.3f}, F1:{4:,.3f}\".format(chosen_degree, accuracy_train, precision_train, recall_train, f1_train))\nprint(\"Test : Degree:{0:,.0f}, Accuracy:{1:,.3f}, Precision:{2:,.3f}, Recall:{3:,.3f}, F1:{4:,.3f}\".format(chosen_degree, accuracy_test, precision_test, recall_test, f1_test))\n# print(\"\\nConfusion matrix:\")\n# confusion_matrix = pd.crosstab(y_test, y_preds_test, rownames=[\"Actual\"], colnames=[\"Predicted\"])\n# print(f\"{confusion_matrix}, \\n\")\n# sns.heatmap(confusion_matrix, annot=True, fmt='0f')\n\n#Visualizing y_pred in the dataset\nX_degree = poly.fit_transform(X_scaled)\ny_preds_all = model_lr.predict(X_degree)\nchurn_ds[\"Exited_predicted\"] = y_preds_all\nchurn_ds.to_excel(\"model_lr.xlsx\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 9.2 SVM"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating a SVM model and checking its Metrics\n\nfrom sklearn import svm\n\n#Fitting to the model\nmodel_svm = svm.SVC().fit(X_train, y_train.values.ravel())\n\n#Getting the predictions & Metrics\ny_preds_train = model_svm.predict(X_train)\ny_preds_test = model_svm.predict(X_test)\naccuracy_train = accuracy_score(y_train, y_preds_train)\naccuracy_test = accuracy_score(y_test, y_preds_test)\nprecision_train = precision_score(y_train, y_preds_train)\nprecision_test = precision_score(y_test, y_preds_test)\nrecall_train = recall_score(y_train, y_preds_train)\nrecall_test = recall_score(y_test, y_preds_test)\nf1_train = f1_score(y_train, y_preds_train)\nf1_test = f1_score(y_test, y_preds_test)\nprint(\"Train: Accuracy:{0:,.3f}, Precision:{1:,.3f}, Recall:{2:,.3f}, F1:{3:,.3f}\".format(accuracy_train, precision_train, recall_train, f1_train))\nprint(\"Test : Accuracy:{0:,.3f}, Precision:{1:,.3f}, Recall:{2:,.3f}, F1:{3:,.3f}\".format(accuracy_test, precision_test, recall_test, f1_test))\n# print(\"\\nConfusion matrix:\")\n# confusion_matrix = pd.crosstab(y_test, y_preds_test, rownames=[\"Actual\"], colnames=[\"Predicted\"])\n# print(f\"{confusion_matrix}, \\n\")\n# sns.heatmap(confusion_matrix, annot=True, fmt='0f')\n\n#Visualizing y_pred in the dataset\ny_preds_all = model_svm.predict(X_scaled)\nchurn_ds[\"Exited_predicted\"] = y_preds_all\nchurn_ds.to_excel(\"model_svm.xlsx\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 9.3 Naive Bayes"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating a Naive Bayes model and checking its Metrics\n\nfrom sklearn import naive_bayes\n\n#Fitting to the model\nmodel_nb = naive_bayes.MultinomialNB().fit(X_train, y_train.values.ravel())\n\n#Getting the predictions & Metrics\ny_preds_train = model_nb.predict(X_train)\ny_preds_test = model_nb.predict(X_test)\naccuracy_train = accuracy_score(y_train, y_preds_train)\naccuracy_test = accuracy_score(y_test, y_preds_test)\nprecision_train = precision_score(y_train, y_preds_train)\nprecision_test = precision_score(y_test, y_preds_test)\nrecall_train = recall_score(y_train, y_preds_train)\nrecall_test = recall_score(y_test, y_preds_test)\nf1_train = f1_score(y_train, y_preds_train)\nf1_test = f1_score(y_test, y_preds_test)\nprint(\"Train: Accuracy:{0:,.3f}, Precision:{1:,.3f}, Recall:{2:,.3f}, F1:{3:,.3f}\".format(accuracy_train, precision_train, recall_train, f1_train))\nprint(\"Test : Accuracy:{0:,.3f}, Precision:{1:,.3f}, Recall:{2:,.3f}, F1:{3:,.3f}\".format(accuracy_test, precision_test, recall_test, f1_test))\n# print(\"\\nConfusion matrix:\")\n# confusion_matrix = pd.crosstab(y_test, y_preds_test, rownames=[\"Actual\"], colnames=[\"Predicted\"])\n# print(f\"{confusion_matrix}, \\n\")\n# sns.heatmap(confusion_matrix, annot=True, fmt='0f')\n\n#Visualizing y_pred in the dataset\ny_preds_all = model_nb.predict(X_scaled)\nchurn_ds[\"Exited_predicted\"] = y_preds_all\nchurn_ds.to_excel(\"model_nb.xlsx\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 9.4 KNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating a KNN model and checking its Metrics\n\nfrom sklearn import neighbors\n\n#Trying different neighbors\nn_neighbors = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\nprint(\"Testing neighbors:\")\nfor a in n_neighbors:\n    model_knn = neighbors.KNeighborsClassifier(n_neighbors=a).fit(X_train, y_train.values.ravel())\n    y_preds_train = model_knn.predict(X_train)\n    y_preds_test = model_knn.predict(X_test)\n    accuracy_train = accuracy_score(y_train, y_preds_train)\n    accuracy_test = accuracy_score(y_test, y_preds_test)\n    precision_train = precision_score(y_train, y_preds_train)\n    precision_test = precision_score(y_test, y_preds_test)\n    recall_train = recall_score(y_train, y_preds_train)\n    recall_test = recall_score(y_test, y_preds_test)\n    f1_train = f1_score(y_train, y_preds_train)\n    f1_test = f1_score(y_test, y_preds_test)\n    print(\"Train: Neighbors:{0:,.0f}, Accuracy:{1:,.3f}, Precision:{2:,.3f}, Recall:{3:,.3f}, F1:{4:,.3f}\".format(a, accuracy_train, precision_train, recall_train, f1_train))\n    print(\"Test : Neighbors:{0:,.0f}, Accuracy:{1:,.3f}, Precision:{2:,.3f}, Recall:{3:,.3f}, F1:{4:,.3f}\".format(a, accuracy_test, precision_test, recall_test, f1_test))\nprint(\"\")\n\n#Choosing the best neighbor\nchosen_neighbor = 13\nmodel_knn = neighbors.KNeighborsClassifier(n_neighbors=chosen_neighbor).fit(X_train, y_train.values.ravel())\ny_preds_train = model_knn.predict(X_train)\ny_preds_test = model_knn.predict(X_test)\naccuracy_train = accuracy_score(y_train, y_preds_train)\naccuracy_test = accuracy_score(y_test, y_preds_test)\nprecision_train = precision_score(y_train, y_preds_train)\nprecision_test = precision_score(y_test, y_preds_test)\nrecall_train = recall_score(y_train, y_preds_train)\nrecall_test = recall_score(y_test, y_preds_test)\nf1_train = f1_score(y_train, y_preds_train)\nf1_test = f1_score(y_test, y_preds_test)\nprint(\"Chosen neighbors:\")\nprint(\"Train: Neighbors:{0:,.0f}, Accuracy:{1:,.3f}, Precision:{2:,.3f}, Recall:{3:,.3f}, F1:{4:,.3f}\".format(chosen_neighbor, accuracy_train, precision_train, recall_train, f1_train))\nprint(\"Test : Neighbors:{0:,.0f}, Accuracy:{1:,.3f}, Precision:{2:,.3f}, Recall:{3:,.3f}, F1:{4:,.3f}\".format(chosen_neighbor, accuracy_test, precision_test, recall_test, f1_test))\n# print(\"\\nConfusion matrix:\")\n# confusion_matrix = pd.crosstab(y_test, y_preds_test, rownames=[\"Actual\"], colnames=[\"Predicted\"])\n# print(f\"{confusion_matrix}, \\n\")\n# sns.heatmap(confusion_matrix, annot=True, fmt='0f')\n\n#Visualizing y_pred in the dataset\ny_preds_all = model_knn.predict(X_scaled)\nchurn_ds[\"Exited_predicted\"] = y_preds_all\nchurn_ds.to_excel(\"model_knn.xlsx\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 9.5 Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating a Random Forest model and checking its Metrics\n\nfrom sklearn import ensemble\n\n#Trying different depths\ndepths = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\nprint(\"Testing depths:\")\nfor a in depths:\n    model_rf = ensemble.RandomForestClassifier(max_depth=a, random_state=0).fit(X_train, y_train.values.ravel())\n    y_preds_train = model_rf.predict(X_train)\n    y_preds_test = model_rf.predict(X_test)\n    accuracy_train = accuracy_score(y_train, y_preds_train)\n    accuracy_test = accuracy_score(y_test, y_preds_test)\n    precision_train = precision_score(y_train, y_preds_train)\n    precision_test = precision_score(y_test, y_preds_test)\n    recall_train = recall_score(y_train, y_preds_train)\n    recall_test = recall_score(y_test, y_preds_test)\n    f1_train = f1_score(y_train, y_preds_train)\n    f1_test = f1_score(y_test, y_preds_test)\n    print(\"Train: Depth:{0:,.0f}, Accuracy:{1:,.3f}, Precision:{2:,.3f}, Recall:{3:,.3f}, F1:{4:,.3f}\".format(a, accuracy_train, precision_train, recall_train, f1_train))\n    print(\"Test : Depth:{0:,.0f}, Accuracy:{1:,.3f}, Precision:{2:,.3f}, Recall:{3:,.3f}, F1:{4:,.3f}\".format(a, accuracy_test, precision_test, recall_test, f1_test))\nprint(\"\")\n\n#Choosing the best depth\nchosen_depth = 8\nmodel_rf = ensemble.RandomForestClassifier(max_depth=chosen_depth, random_state=0).fit(X_train, y_train.values.ravel())\ny_preds_train = model_rf.predict(X_train)\ny_preds_test = model_rf.predict(X_test)\naccuracy_train = accuracy_score(y_train, y_preds_train)\naccuracy_test = accuracy_score(y_test, y_preds_test)\nprecision_train = precision_score(y_train, y_preds_train)\nprecision_test = precision_score(y_test, y_preds_test)\nrecall_train = recall_score(y_train, y_preds_train)\nrecall_test = recall_score(y_test, y_preds_test)\nf1_train = f1_score(y_train, y_preds_train)\nf1_test = f1_score(y_test, y_preds_test)\nprint(\"Chosen depth:\")\nprint(\"Train: Depth:{0:,.0f}, Accuracy:{1:,.3f}, Precision:{2:,.3f}, Recall:{3:,.3f}, F1:{4:,.3f}\".format(chosen_depth, accuracy_train, precision_train, recall_train, f1_train))\nprint(\"Test : Depth:{0:,.0f}, Accuracy:{1:,.3f}, Precision:{2:,.3f}, Recall:{3:,.3f}, F1:{4:,.3f}\".format(chosen_depth, accuracy_test, precision_test, recall_test, f1_test))\n# print(\"\\nConfusion matrix:\")\n# confusion_matrix = pd.crosstab(y_test, y_preds_test, rownames=[\"Actual\"], colnames=[\"Predicted\"])\n# print(f\"{confusion_matrix}, \\n\")\n# sns.heatmap(confusion_matrix, annot=True, fmt='0f')\n\n#Visualizing y_pred in the dataset\ny_preds_all = model_rf.predict(X_scaled)\nchurn_ds[\"Exited_predicted\"] = y_preds_all\nchurn_ds.to_excel(\"model_rf.xlsx\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 9.6 XGBoost"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating a XGBoost model and checking its Metrics\n\nfrom xgboost import XGBClassifier\n\n#Trying different depths\ndepths = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\nprint(\"Testing depths:\")\nfor a in depths:\n    model_xgbc = XGBClassifier(max_depth=a, objective=\"multi:softmax\", num_class=4, random_state=0).fit(X_train, y_train.values.ravel())\n    y_preds_train = model_xgbc.predict(X_train)\n    y_preds_test = model_xgbc.predict(X_test)\n    accuracy_train = accuracy_score(y_train, y_preds_train)\n    accuracy_test = accuracy_score(y_test, y_preds_test)\n    precision_train = precision_score(y_train, y_preds_train)\n    precision_test = precision_score(y_test, y_preds_test)\n    recall_train = recall_score(y_train, y_preds_train)\n    recall_test = recall_score(y_test, y_preds_test)\n    f1_train = f1_score(y_train, y_preds_train)\n    f1_test = f1_score(y_test, y_preds_test)\n    print(\"Train: Depth:{0:,.0f}, Accuracy:{1:,.3f}, Precision:{2:,.3f}, Recall:{3:,.3f}, F1:{4:,.3f}\".format(a, accuracy_train, precision_train, recall_train, f1_train))\n    print(\"Test : Depth:{0:,.0f}, Accuracy:{1:,.3f}, Precision:{2:,.3f}, Recall:{3:,.3f}, F1:{4:,.3f}\".format(a, accuracy_test, precision_test, recall_test, f1_test))\nprint(\"\")\n\n#Choosing the best depth\nchosen_depth = 1\nmodel_xgbc = XGBClassifier(max_depth=chosen_depth, objective=\"multi:softmax\", num_class=4, random_state=0).fit(X_train, y_train.values.ravel())\ny_preds_train = model_xgbc.predict(X_train)\ny_preds_test = model_xgbc.predict(X_test)\naccuracy_train = accuracy_score(y_train, y_preds_train)\naccuracy_test = accuracy_score(y_test, y_preds_test)\nprecision_train = precision_score(y_train, y_preds_train)\nprecision_test = precision_score(y_test, y_preds_test)\nrecall_train = recall_score(y_train, y_preds_train)\nrecall_test = recall_score(y_test, y_preds_test)\nf1_train = f1_score(y_train, y_preds_train)\nf1_test = f1_score(y_test, y_preds_test)\nprint(\"Chosen depth:\")\nprint(\"Train: Depth:{0:,.0f}, Accuracy:{1:,.3f}, Precision:{2:,.3f}, Recall:{3:,.3f}, F1:{4:,.3f}\".format(chosen_depth, accuracy_train, precision_train, recall_train, f1_train))\nprint(\"Test : Depth:{0:,.0f}, Accuracy:{1:,.3f}, Precision:{2:,.3f}, Recall:{3:,.3f}, F1:{4:,.3f}\".format(chosen_depth, accuracy_test, precision_test, recall_test, f1_test))\n# print(\"\\nConfusion matrix:\")\n# confusion_matrix = pd.crosstab(y_test, y_preds_test, rownames=[\"Actual\"], colnames=[\"Predicted\"])\n# print(f\"{confusion_matrix}, \\n\")\n# sns.heatmap(confusion_matrix, annot=True, fmt='0f')\n\n#Visualizing y_pred in the dataset\ny_preds_all = model_xgbc.predict(X_scaled)\nchurn_ds[\"Exited_predicted\"] = y_preds_all\nchurn_ds.to_excel(\"model_xgbc.xlsx\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 9.7 Deep Learning"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating a Deep Learning model and checking its Metrics\n\nfrom keras import Sequential\nfrom keras.layers import Dense\n\n#Creating a model\nmodel_dl = Sequential()\n\n#Input and First Hidden Layer\nmodel_dl.add(Dense(units=256, activation=\"relu\", input_dim=X_train.shape[-1]))\n\n#Output Layer\nmodel_dl.add(Dense(units=1, activation=\"sigmoid\",))\n\n#Compiling the neural network\nmodel_dl.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"binary_accuracy\"])\n\n#Fitting to the model\nmodel_dl.fit(X_train, y_train.values.ravel(), epochs=250)\n\n#Getting the predictions & Metrics\ny_preds_train = model_dl.predict(X_train)\ny_preds_test = model_dl.predict(X_test)\naccuracy_train = accuracy_score(y_train, y_preds_train.round())\naccuracy_test = accuracy_score(y_test, y_preds_test.round())\nprecision_train = precision_score(y_train, y_preds_train.round())\nprecision_test = precision_score(y_test, y_preds_test.round())\nrecall_train = recall_score(y_train, y_preds_train.round())\nrecall_test = recall_score(y_test, y_preds_test.round())\nf1_train = f1_score(y_train, y_preds_train.round())\nf1_test = f1_score(y_test, y_preds_test.round())\nprint(\"Train: Accuracy:{0:,.3f}, Precision:{1:,.3f}, Recall:{2:,.3f}, F1:{3:,.3f}\".format(accuracy_train, precision_train, recall_train, f1_train))\nprint(\"Test : Accuracy:{0:,.3f}, Precision:{1:,.3f}, Recall:{2:,.3f}, F1:{3:,.3f}\".format(accuracy_test, precision_test, recall_test, f1_test))\n# print(\"\\nConfusion matrix:\")\n# from sklearn.metrics import confusion_matrix\n# confusion_matrix = confusion_matrix(y_test, y_preds_test)\n# print(f\"{confusion_matrix}, \\n\")\n# sns.heatmap(confusion_matrix, annot=True, fmt='.0f')\n\n#Visualizing y_pred in the dataset\ny_preds_all = model_dl.predict(X_scaled)\nchurn_ds[\"Exited_predicted\"] = y_preds_all\nchurn_ds.to_excel(\"model_dl.xlsx\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 10. Model Deployment"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Entering Xs\n\n# num_prods = int(input(\"Enter the client´s number of Products: \"))\n# is_act = str(input(\"Is the client an active member (Yes/No)? \"))\n# if is_act == \"No\":\n#     is_act = 0\n# else:\n#     is_act = 1\n# age = float(input(\"Enter the client´s age: \"))\n# female = str(input(\"Enter the client gender (Male/Female): \"))\n# if female == \"Male\":\n#     female = 0\n# else:\n#     female = 1\n# balance = float(input(\"Enter the client´s balance: \"))\n# has_cr_cd = str(input(\"Does the client have a credit card (Yes/No)? \"))\n# if has_cr_cd == \"No\":\n#     has_cr_cd = 0\n# else:\n#     has_cr_cd = 1\n# estim_sal = float(input(\"Enter the client´s estimated salary: \"))\n# cred_score = int(input(\"Enter the client´s credit score: \"))\n# tenure = int(input(\"Enter the client´s tenure: \"))\n# bal_sal_prop= balance/estim_sal\n\n#Defining Xs\n\n# X_mod_dep = pd.DataFrame({\"NumOfProducts\":[num_prods], \"IsActiveMember\": [is_act], \"Age\": [age], \n#                           \"Gender_Female\": [female], \"Balance\": [balance], \"HasCrCard\": [has_cr_cd], \n#                           \"BalanceSalaryProportion\": [bal_sal_prop], \"EstimatedSalary\": [estim_sal], \n#                           \"CreditScore\": [cred_score], \"Tenure\": [tenure]})\n#Choosing an specific client for testing:\nX_mod_dep = pd.DataFrame({\"NumOfProducts\":[4], \"IsActiveMember\": [0], \"Age\": [29], \n                          \"Gender_Female\": [1], \"Balance\": [115046], \"HasCrCard\": [1], \n                          \"BalanceSalaryProportion\": [0.9639], \"EstimatedSalary\": [119346], \n                          \"CreditScore\": [376], \"Tenure\": [4]})\n\n#Appending X_mod_dep to original X dataframe, so we can scale it all together next\n\nX_with_X_mode_dep = X.append(X_mod_dep)\nX_with_X_mode_dep.reset_index(drop=True)\n\n#Scaling all features\n\nfrom sklearn.preprocessing import MinMaxScaler\nsc_X = MinMaxScaler()\nX_scaled = sc_X.fit_transform(X_with_X_mode_dep)\nX_scaled = pd.DataFrame(X_scaled)\n\n#Recovering X_mod_dep row in dataframe after scaling\n\nX_mod_dep = X_scaled.tail(1)\n\n#Predicting results\n\nprediction = model_xgbc.predict(X_mod_dep).round()\nif prediction == 0:\n    prediction_answer = \"No\"\nelse:\n    prediction_answer = \"Yes\"\n\nprint(\"\")\nprint(f\"Is this client predicted as in risk of leaving the bank? {prediction_answer}.\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 11. Conclusions\n\nIF YOU LIKE IT OR IF IT HELPS YOU SOMEHOW, COULD YOU PLEASE UPVOTE? THANK YOU VERY MUCH!!!\n\nIn this project we went through all the process from defining the business objective, collecting data, exploring features and distributions, treating data, understanding correlations, selecting relevant features, data modelling and presenting 7 different algorithms with metrics to select the best to predict the Customer´s risk of leaving our business, what´s crucial for the bank since with it we can start taking measures to avoid it, keeping the client portfolio. The chosen model was XGBoost, with around 83% accuracy."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}