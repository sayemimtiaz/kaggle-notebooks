{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Identifying Breast Cancer using Logistic Regression with Weight of Evidence","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"![Weight Of Evidence](https://miro.medium.com/max/768/1*6Aw782wiyiFtzvK7EOY8CA.png)\n![Information Value](https://miro.medium.com/max/1400/1*xWA7a2KsTQOhaQ9MZFJJeQ.png)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"* [Introduction](#Introduction)\n* [Import Packages](#Import-Packages)\n* [Load in Data](#Load-in-Data)\n* [EDA](#EDA)\n* [WOE and IV](#WOE-and-IV)\n    * [Weight of Evidence](#Weight-of-Evidence)\n    * [Information Value](#Information-Value)\n* [Encoding Data](#Encoding-Data)\n* [Training Model](#Training-Model)\n* [Testing and Checking Metrics](#Testing-and-Checking-Metrics)\n* [Conclusion](#Conclusion)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Introduction","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The purpose of this notebook is to show how to use Weight of Evidence (WOE) and Information Value (IV) to predict whether breast tissues are benign or malignant using the Breast Cancer Wisconsin (Diagnostic) Data Set.  \n\nSince this is a binary classification problem, Logisitic Regression will be used as the classifier. \n\nAll information included in this notebook on WOE and IV can be found here: [Weight of evidence and Information Value using Python](https://medium.com/@sundarstyles89/weight-of-evidence-and-information-value-using-python-6f05072e83eb)\n\n<a href=\"#top\">Back to Top</a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Import Packages","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import classification_report, confusion_matrix , accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\n\nimport pandas.core.algorithms as algos\nfrom pandas import Series\nimport scipy.stats.stats as stats\nimport re\nimport traceback\nimport string\n\nimport warnings\n\nimport gc; gc.enable()\n\n%matplotlib inline\nsns.set(style=\"darkgrid\", color_codes=True, font_scale=1.3)\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a href=\"#top\">Back to Top</a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Load in Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#read in data\ndf = pd.read_csv(\"../input/breast-cancer-wisconsin-data/data.csv\", index_col = 0)\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a href=\"#top\">Back to Top</a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## EDA","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.reset_index(inplace=True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#drop last column with no values\ndf.drop(\"Unnamed: 32\", axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Setting our target and converting values to numeric\ndf['target'] = df['diagnosis'].apply(lambda x : 1 if x == 'M' else 0)\ndf.drop('diagnosis', axis = 1, inplace = True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualize distribution of classes \nplt.figure(figsize=(10, 8))\nsns.countplot(df['target'], palette='RdBu')\n\n# count number of obvs in each class\nbenign, malignant = df['target'].value_counts()\nprint('Number of cells labeled Benign: ', benign)\nprint('Number of cells labeled Malignant : ', malignant)\nprint('')\nprint('% of cells labeled Benign', round(benign / len(df) * 100, 2), '%')\nprint('% of cells labeled Malignant', round(malignant / len(df) * 100, 2), '%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target = 'target'\n_id = \"id\"\nused_cols = [col for col in df.columns.tolist() if col not in [target, _id]]\nX = df[used_cols].copy()\ny = df[target].copy()\ndel df\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=40)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a href=\"#top\">Back to Top</a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## WOE and IV\nref : [Weight of evidence and Information Value using Python](https://medium.com/@sundarstyles89/weight-of-evidence-and-information-value-using-python-6f05072e83eb)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"max_bin = 20\nforce_bin = 3\n\n# define a binning function\ndef mono_bin(Y, X, n = max_bin):\n    \n    df1 = pd.DataFrame({\"X\": X, \"Y\": Y})\n    justmiss = df1[['X','Y']][df1.X.isnull()]\n    notmiss = df1[['X','Y']][df1.X.notnull()]\n    r = 0\n    while np.abs(r) < 1:\n        try:\n            d1 = pd.DataFrame({\"X\": notmiss.X, \"Y\": notmiss.Y, \"Bucket\": pd.qcut(notmiss.X, n)})\n            d2 = d1.groupby('Bucket', as_index=True)\n            r, p = stats.spearmanr(d2.mean().X, d2.mean().Y)\n            n = n - 1 \n        except Exception as e:\n            n = n - 1\n\n    if len(d2) == 1:\n        n = force_bin         \n        bins = algos.quantile(notmiss.X, np.linspace(0, 1, n))\n        if len(np.unique(bins)) == 2:\n            bins = np.insert(bins, 0, 1)\n            bins[1] = bins[1]-(bins[1]/2)\n        d1 = pd.DataFrame({\"X\": notmiss.X, \"Y\": notmiss.Y, \"Bucket\": pd.cut(notmiss.X, np.unique(bins),include_lowest=True)}) \n        d2 = d1.groupby('Bucket', as_index=True)\n    \n    d3 = pd.DataFrame({},index=[])\n    d3[\"MIN_VALUE\"] = d2.min().X\n    d3[\"MAX_VALUE\"] = d2.max().X\n    d3[\"COUNT\"] = d2.count().Y\n    d3[\"EVENT\"] = d2.sum().Y\n    d3[\"NONEVENT\"] = d2.count().Y - d2.sum().Y\n    d3=d3.reset_index(drop=True)\n    \n    if len(justmiss.index) > 0:\n        d4 = pd.DataFrame({'MIN_VALUE':np.nan},index=[0])\n        d4[\"MAX_VALUE\"] = np.nan\n        d4[\"COUNT\"] = justmiss.count().Y\n        d4[\"EVENT\"] = justmiss.sum().Y\n        d4[\"NONEVENT\"] = justmiss.count().Y - justmiss.sum().Y\n        d3 = d3.append(d4,ignore_index=True)\n    \n    d3[\"EVENT_RATE\"] = d3.EVENT/d3.COUNT\n    d3[\"NON_EVENT_RATE\"] = d3.NONEVENT/d3.COUNT\n    d3[\"DIST_EVENT\"] = d3.EVENT/d3.sum().EVENT\n    d3[\"DIST_NON_EVENT\"] = d3.NONEVENT/d3.sum().NONEVENT\n    d3[\"WOE\"] = np.log(d3.DIST_EVENT/d3.DIST_NON_EVENT)\n    d3[\"IV\"] = (d3.DIST_EVENT-d3.DIST_NON_EVENT)*np.log(d3.DIST_EVENT/d3.DIST_NON_EVENT)\n    d3[\"VAR_NAME\"] = \"VAR\"\n    d3 = d3[['VAR_NAME','MIN_VALUE', 'MAX_VALUE', 'COUNT', 'EVENT', 'EVENT_RATE', 'NONEVENT', 'NON_EVENT_RATE', 'DIST_EVENT','DIST_NON_EVENT','WOE', 'IV']]       \n    d3 = d3.replace([np.inf, -np.inf], 0)\n    d3.IV = d3.IV.sum()\n    \n    return(d3)\n\ndef char_bin(Y, X):\n        \n    df1 = pd.DataFrame({\"X\": X, \"Y\": Y})\n    justmiss = df1[['X','Y']][df1.X.isnull()]\n    notmiss = df1[['X','Y']][df1.X.notnull()]    \n    df2 = notmiss.groupby('X',as_index=True)\n    \n    d3 = pd.DataFrame({},index=[])\n    d3[\"COUNT\"] = df2.count().Y\n    d3[\"MIN_VALUE\"] = df2.sum().Y.index\n    d3[\"MAX_VALUE\"] = d3[\"MIN_VALUE\"]\n    d3[\"EVENT\"] = df2.sum().Y\n    d3[\"NONEVENT\"] = df2.count().Y - df2.sum().Y\n    \n    if len(justmiss.index) > 0:\n        d4 = pd.DataFrame({'MIN_VALUE':np.nan},index=[0])\n        d4[\"MAX_VALUE\"] = np.nan\n        d4[\"COUNT\"] = justmiss.count().Y\n        d4[\"EVENT\"] = justmiss.sum().Y\n        d4[\"NONEVENT\"] = justmiss.count().Y - justmiss.sum().Y\n        d3 = d3.append(d4,ignore_index=True)\n    \n    d3[\"EVENT_RATE\"] = d3.EVENT/d3.COUNT\n    d3[\"NON_EVENT_RATE\"] = d3.NONEVENT/d3.COUNT\n    d3[\"DIST_EVENT\"] = d3.EVENT/d3.sum().EVENT\n    d3[\"DIST_NON_EVENT\"] = d3.NONEVENT/d3.sum().NONEVENT\n    d3[\"WOE\"] = np.log(d3.DIST_EVENT/d3.DIST_NON_EVENT)\n    d3[\"IV\"] = (d3.DIST_EVENT-d3.DIST_NON_EVENT)*np.log(d3.DIST_EVENT/d3.DIST_NON_EVENT)\n    d3[\"VAR_NAME\"] = \"VAR\"\n    d3 = d3[['VAR_NAME','MIN_VALUE', 'MAX_VALUE', 'COUNT', 'EVENT', 'EVENT_RATE', 'NONEVENT', 'NON_EVENT_RATE', 'DIST_EVENT','DIST_NON_EVENT','WOE', 'IV']]      \n    d3 = d3.replace([np.inf, -np.inf], 0)\n    d3.IV = d3.IV.sum()\n    d3 = d3.reset_index(drop=True)\n    \n    return(d3)\n\ndef data_vars(df1, target):\n    \n    stack = traceback.extract_stack()\n    filename, lineno, function_name, code = stack[-2]\n    vars_name = re.compile(r'\\((.*?)\\).*$').search(code).groups()[0]\n    final = (re.findall(r\"[\\w']+\", vars_name))[-1]\n    \n    x = df1.dtypes.index\n    count = -1\n    \n    for i in x:\n        if i.upper() not in (final.upper()):\n            if np.issubdtype(df1[i], np.number) and len(Series.unique(df1[i])) > 2:\n                conv = mono_bin(target, df1[i])\n                conv[\"VAR_NAME\"] = i\n                count = count + 1\n            else:\n                conv = char_bin(target, df1[i])\n                conv[\"VAR_NAME\"] = i            \n                count = count + 1\n                \n            if count == 0:\n                iv_df = conv\n            else:\n                iv_df = iv_df.append(conv,ignore_index=True)\n    \n    iv = pd.DataFrame({'IV':iv_df.groupby('VAR_NAME').IV.max()})\n    iv = iv.reset_index()\n    return(iv_df,iv)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a href=\"#top\">Back to Top</a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Weight of Evidence","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"final_iv, df_IV = data_vars(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_iv.sort_values(\"IV\").head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a href=\"#top\">Back to Top</a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Information Value","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"From the reference material an IV less than 0.02 is characterized as a useless predictor","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_IV.loc[df_IV['IV'] < .02].sort_values(\"IV\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"useless_ = df_IV.loc[df_IV['IV'] < .02]['VAR_NAME'].tolist()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"An IV between 0.02 to 0.1 is characterized as a weak predictor","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_IV.loc[(df_IV['IV']>.02) & (df_IV['IV']<.1)].sort_values(\"IV\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"An IV between 0.1 to 0.3 is characterized as a medium predictor","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_IV.loc[(df_IV['IV']>.1) & (df_IV['IV']<.3)].sort_values(\"IV\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"An IV between 0.3 to 0.5 is characterized as a strong predictor","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_IV.loc[(df_IV['IV']>.3) & (df_IV['IV']<.5)].sort_values(\"IV\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"An IV is greater than 0.5 is characterized as suspicious or too good to be true.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_IV.loc[df_IV['IV']>.5].sort_values(\"IV\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a href=\"#top\">Back to Top</a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Encoding Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#function that uses our information determined form WOE and applies it to our data\ndef transform_(df, transform_vars_list, final_iv):\n    for var in transform_vars_list:\n        small_df = final_iv[final_iv['VAR_NAME'] == var]\n        transform_dict = dict(zip(small_df.MAX_VALUE,small_df.WOE))\n        replace_cmd = ''\n        replace_cmd1 = ''\n        for i in sorted(transform_dict.items()):\n            replace_cmd = replace_cmd + str(i[1]) + str(' if x <= ') + str(i[0]) + ' else '\n            replace_cmd1 = replace_cmd1 + str(i[1]) + str(' if x == \"') + str(i[0]) + '\" else '\n        replace_cmd = replace_cmd + '0'\n        replace_cmd1 = replace_cmd1 + '0'\n        if replace_cmd != '0':\n            try:\n                df[transform_prefix + var] = df[var].apply(lambda x: eval(replace_cmd))\n            except:\n                df[transform_prefix + var] = df[var].apply(lambda x: eval(replace_cmd1))\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dropping useless predictors\nkeep_cols = [col for col in used_cols if col not in useless_]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transform_prefix = ''\nX_train = transform_(X_train, keep_cols, final_iv)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a href=\"#top\">Back to Top</a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Training Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"logreg = LogisticRegression(fit_intercept = False, class_weight = 'balanced', C = 1e15)\nmodel_log = logreg.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a href=\"#top\">Back to Top</a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = transform_(X_test, keep_cols, final_iv)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model_log.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(confusion_matrix(y_test,y_pred))  \nprint(classification_report(y_test,y_pred)) \nprint(\"The accuracy score is\" + \" \"+ str(accuracy_score(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a href=\"#top\">Back to Top</a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Conclusion","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"We can see from these metrics that using WOE and IV with Logistic Regression can be a strong technique to use in solving binary classification problems.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"More information on Weight of Evidence and Information Value used for this can be found in the following Notebooks:\n* [Weight of Evidence(WOE) & Information Value(IV)](https://www.kaggle.com/pavansanagapati/weight-of-evidence-woe-information-value-iv)\n* [IV + WoE Starter for Python](https://www.kaggle.com/puremath86/iv-woe-starter-for-python)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Let me know if you have any feedback. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a href=\"#top\">Back to Top</a>","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}