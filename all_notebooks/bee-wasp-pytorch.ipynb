{"cells":[{"metadata":{},"cell_type":"markdown","source":"Imported necessary libraries"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.datasets as datasets\nimport torchvision.models as models\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nimport pandas as pd\nimport cv2\nfrom torch.utils.data import Dataset, DataLoader, random_split\nimport copy\nimport torch.optim as optim","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checked for GPU"},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Read labels.csv file to know about dataset division"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/bee-vs-wasp/kaggle_bee_vs_wasp/labels.csv\")\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Encoded labels"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nle.fit(data[\"label\"])\ndata[\"label\"] = le.transform(data[\"label\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Made the path column as valid path by replacing '\\' by '/"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in data.index:\n    data[\"path\"].iloc[i] = data[\"path\"].iloc[i].replace(\"\\\\\", \"/\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Split the dataframe into train , val and test by using the information in is_validation and is_final_validation column"},{"metadata":{"trusted":true},"cell_type":"code","source":"def split(dt):\n    idx = []\n    a = pd.DataFrame()\n    b = pd.DataFrame()\n    for i in data.index:\n        if data[\"is_validation\"].iloc[i] == 1:\n            a = a.append(dt.iloc[i])\n            idx.append(i)\n        if data[\"is_final_validation\"].iloc[i] == 1:\n            b = b.append(dt.iloc[i])\n            idx.append(i)\n    dt = dt.drop(dt.index[idx])\n    a = a.reset_index()\n    b = b.reset_index()\n    dt = dt.reset_index()\n    return dt,a,b\n        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finally splitted dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df, val_df, test_df = split(data)\nprint(\"Length of train dataset: \", len(train_df))\nprint(\"Length of validation dataset: \" ,len(val_df))\nprint(\"Length of test dataset: \", len(test_df))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Defined transformations required to convert data into dataloader"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_transform = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.RandomResizedCrop(224),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\ntest_transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_df.label = val_df.label.astype(np.int64)\ntest_df.label = test_df.label.astype(np.int64)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Defined a class to form a dataloader"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Bee_Wasp(Dataset):\n    def __init__(self, df:pd.DataFrame, imgdir:str,\n                 transforms=None):\n        self.df = df\n        self.imgdir = imgdir\n        self.transforms = transforms\n    \n    def __getitem__(self, index):\n        im_path = os.path.join(self.imgdir, self.df.iloc[index][\"path\"])\n        x = cv2.imread(im_path)\n        x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n        x = cv2.resize(x, (224, 224))\n\n        if self.transforms:\n            x = self.transforms(x)\n            \n        y = self.df.iloc[index][\"label\"]\n        return x, y\n    \n    def __len__(self):\n        return len(self.df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Got train_data, test_data and val_data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = Bee_Wasp(df=train_df,\n                        imgdir=\"../input/bee-vs-wasp/kaggle_bee_vs_wasp\",\n                        transforms=train_transform)\n\nval_data = Bee_Wasp(df=val_df,\n                      imgdir=\"../input/bee-vs-wasp/kaggle_bee_vs_wasp\",\n                      transforms=test_transform)\n\ntest_data = Bee_Wasp(df=test_df,\n                       imgdir=\"../input/bee-vs-wasp/kaggle_bee_vs_wasp\",\n                       transforms=test_transform)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Got final three dataloaders ready "},{"metadata":{"trusted":true},"cell_type":"code","source":"train_loader = DataLoader(dataset=train_data, shuffle=True, batch_size=32, num_workers=4)\nval_loader = DataLoader(dataset = val_data, shuffle = True, batch_size = 32, num_workers=4)\ntest_loader = DataLoader(dataset=test_data, shuffle=True, batch_size=32, num_workers=4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checked for the shape of images and labels in train_loader. Batch_size is 32."},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\ndataiter = iter(train_loader)\nimages, labels = dataiter.next()\nprint(images.shape)\nprint(labels.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Downloaded Resnet Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = torchvision.models.resnet50(pretrained=True, progress=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No need for weights of resnet to be trained again ao set False"},{"metadata":{"trusted":true},"cell_type":"code","source":"for p in model.parameters():\n    p.requires_grad = False","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Changed last layer to ensure that we have four classes"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fc = nn.Sequential(\n    nn.Linear(2048, 1024),\n    nn.ReLU(),\n    nn.Linear(1024,4),\n    nn.LogSoftmax(dim=1)\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The new weights need to be trained"},{"metadata":{"trusted":true},"cell_type":"code","source":"for param in model.parameters():\n    if param.requires_grad:\n        print(param.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Set the optimizer and loss function and transferred model on GPU"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = model.to(device)\nopt = optim.Adam(model.parameters(), lr=0.001)\nloss_fn = nn.NLLLoss()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Defined evaluation function to find accuracy percentage"},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluation(dataloader):\n    total, correct = 0,0\n    model.eval()\n    for data in dataloader:\n        inputs, labels = data\n        inputs =inputs.to(device)\n        labels = labels.to(device)\n        outputs = model(inputs)\n        _ , pred = torch.max(outputs.data, 1 )\n        total += labels.size(0)\n        correct += (pred == labels).sum().item()\n    return 100*correct/total","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"TRAINED!!"},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 32\nimport copy\nloss_epoch_arr = []\nmax_epochs = 6\nmin_loss = 1000\nn_iters = np.ceil(50000/batch_size)\nfor epoch in range(max_epochs):\n    for i,data in enumerate(train_loader):\n        inputs,labels = data\n        inputs = inputs.to(device)\n        labels =  labels.to(device)\n        opt.zero_grad()\n        model.train()\n        outputs = model(inputs)\n        loss = loss_fn(outputs, labels)\n        loss.backward()\n        opt.step()\n        if min_loss>loss.item():\n            min_loss = loss.item()\n            best_model = copy.deepcopy(model.state_dict())\n            print('Min loss %0.2f' % min_loss)\n            del inputs, labels, outputs\n            torch.cuda.empty_cache()\n    loss_epoch_arr.append(loss.item())\n    model.eval()\n    print(\"Epoch %d/%d, Train acc: %0.2f, Val acc: %0.2f\" %(epoch, max_epochs, evaluation(train_loader), evaluation(val_loader)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Loss v/s Epochs"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(loss_epoch_arr)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Loaded best model and found accuracy on TEST dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_state_dict(best_model)\nprint(evaluation(test_loader))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Defined classes and checked the prediction by loading an image"},{"metadata":{"trusted":true},"cell_type":"code","source":"classes = ['bee', 'wasp', 'other_insect', 'noninsect']\ndataiter = iter(test_loader)\nimages, labels = dataiter.next()\ndef imshow(img):\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1,2,0)))\n    plt.show()\nimshow(torchvision.utils.make_grid(images[:1]))\nprint(\"Ground_Truth - \")\nprint(classes[labels[0]])\nimages = images.to(device)\noutputs = model(images)\nmax_values, pred_class = torch.max(outputs.data, 1)\nprint(\"Predicted_class - \")\nprint(classes[pred_class[0]])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}