{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Trying different Image dropout implementations for Tensorflow.\n\n**Todo**\n* Create Benchmark performance for each\n* Remove for loop implementation on Hide and Seek Dropout\n\nCode implementation primarily comes from Chris Deotte great [post](https://www.kaggle.com/c/siim-isic-melanoma-classification/discussion/169721) on TPU/GPU augmentation.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib import pyplot as plt\nimport math, os, re, gc\nimport numpy as np, pandas as pd\nfrom sklearn.metrics import classification_report, accuracy_score\n\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\n\nimport pandas as pd\nimport random","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Detect hardware, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_mnist = pd.read_csv(\"../input/fashionmnist/fashion-mnist_train.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dropout Code"},{"metadata":{"trusted":true},"cell_type":"code","source":"def random_dropout(image, p = 0.5, s_l = 0.02, s_h=0.4, r_1=0.3, r_2=1/0.3, seed=None):\n    \n    probability = tf.cast(tf.random.uniform([], 0, 1) < p, tf.int32)\n    if (probability == 0): return image\n    \n    img_height, img_width, img_depth = image.shape\n    \n    s = tf.random.uniform(shape=[], minval=s_l, maxval=s_h, dtype = tf.float32) * img_height * img_width\n    r =  tf.random.uniform(shape=[], minval=r_1, maxval=r_2, dtype =  tf.float32)\n    width = tf.cast(tf.math.sqrt(s / r), tf.int32)\n    height = tf.cast(tf.math.sqrt(s * r), tf.int32)\n\n    left = tf.random.uniform(shape=[], minval=0, maxval=img_width, dtype =  tf.int32)\n    bottom = tf.random.uniform(shape=[], minval=0, maxval=img_height, dtype =  tf.int32)\n\n    ya = tf.math.maximum(0, bottom)\n    yb = tf.math.minimum(img_height, bottom+height)\n    xa = tf.math.maximum(0, left)\n    xb = tf.math.minimum(img_width, left+width)\n\n\n    middle_one = image[ya:yb,0:xa,:]\n    middle_two = tf.zeros([yb-ya,xb-xa,img_depth], dtype=tf.int64) \n    middle_three = image[ya:yb,xb:img_width,:]\n\n    middle = tf.concat([middle_one,middle_two,middle_three],axis=1)\n    image = tf.concat([image[0:ya,:,:],middle,image[yb:img_height,:,:]],axis=0)\n\n    return image\n\ndef has_dropout(image, p=0.5, hide_p=0.25, grid_sizes = [3, 6, 8]):\n    \n    probability = tf.cast(tf.random.uniform([], 0, 1) < p, tf.int32)\n    \n    if (probability == 0)|(len(grid_sizes) == 0)|(hide_p == 0): return image\n    \n    img_height, img_width, img_depth = image.shape\n    img_depth = tf.cast(img_depth, tf.int32)\n    grid_size = grid_sizes[random.randint(0,len(grid_sizes)-1)] # random grid size\n    \n    for x in range(0, img_height, grid_size):\n        for y in range(0, img_width, grid_size):\n            \n            hide_probability = tf.cast(tf.random.uniform([], 0, 1) < hide_p, tf.int32)\n            \n            if (hide_probability == 1):\n                xa = tf.cast(x, tf.int32)\n                ya = tf.cast(y, tf.int32)\n                xb = tf.math.minimum(img_height ,tf.cast(x+grid_size, tf.int32))\n                yb = tf.math.minimum(img_width, tf.cast(y+grid_size, tf.int32))\n\n                middle_one = image[ya:yb,0:xa,:]\n                middle_two = tf.zeros([yb-ya, xb-xa, img_depth], dtype=tf.int64)\n                middle_three = image[ya:yb,xb:img_width,:]\n                middle = tf.concat([middle_one, middle_two, middle_three], axis=1)\n                image = tf.concat([image[0:ya,:,:],middle,image[yb:img_height,:,:]],axis=0)\n                \n    return image\n\ndef coarse_dropout(image, p=0.5, count=8, size = 0.15):\n    \n    probability = tf.cast(tf.random.uniform([], 0, 1) < p, tf.int32)\n    img_height, img_width, img_depth = image.shape\n    \n    if (probability == 0)|(count == 0)|(size == 0): return image\n    \n    for k in range(count):\n        \n        x = tf.cast( tf.random.uniform([],0,img_width), tf.int32)\n        y = tf.cast( tf.random.uniform([],0,img_height), tf.int32)\n        \n        width = tf.cast(size * img_width, tf.int32) * probability\n        ya = tf.math.maximum(0, y-width//2)\n        yb = tf.math.minimum(img_height, y+width//2)\n        xa = tf.math.maximum(0, x-width//2)\n        xb = tf.math.minimum(img_width, x+width//2)\n        \n        \n        # Dropout Image\n        middle_one = image[ya:yb,0:xa,:]\n        middle_two = tf.zeros([yb-ya, xb-xa, img_depth], dtype=tf.int64)\n        middle_three = image[ya:yb,xb:img_width,:]\n        middle = tf.concat([middle_one, middle_two, middle_three], axis=1)\n        image = tf.concat([image[0:ya,:,:],middle,image[yb:img_height,:,:]],axis=0)\n        \n    return image\n\ndef gridmask_dropout(image, p = 0.5, d1=6, d2=12, ratio=0.5):\n\n    probability = tf.cast(tf.random.uniform([], 0, 1) < p, tf.int32)\n    if (probability == 0): return image\n    \n    img_height, img_width, img_depth = image.shape\n    h, w = img_height, img_width\n    \n    hh = int(np.ceil(np.sqrt((img_height**2)+(img_width**2))))\n    hh = hh+1 if hh%2==1 else hh\n    \n    d = tf.random.uniform(shape=[], minval=d1, maxval=d2, dtype=tf.int32)\n    l = tf.cast(tf.cast(d,tf.float32)*ratio+0.5, tf.int32)\n    \n    st_h = tf.random.uniform(shape=[], minval=0, maxval=d, dtype=tf.int32)\n    st_w = tf.random.uniform(shape=[], minval=0, maxval=d, dtype=tf.int32)\n\n    y_ranges = tf.range(-1 * d + st_h, -1 * d + st_h + l)\n    x_ranges = tf.range(-1 * d + st_w, -1 * d + st_w + l)\n    \n    for i in range(0, hh//d+1):\n        s1 = i * d + st_h\n        s2 = i * d + st_w\n        y_ranges = tf.concat([y_ranges, tf.range(s1,s1+l)], axis=0)\n        x_ranges = tf.concat([x_ranges, tf.range(s2,s2+l)], axis=0)\n    \n    x_clip_mask = tf.logical_or(x_ranges <0 , x_ranges > hh-1)\n    y_clip_mask = tf.logical_or(y_ranges <0 , y_ranges > hh-1)\n    clip_mask = tf.logical_or(x_clip_mask, y_clip_mask)\n\n    x_ranges = tf.boolean_mask(x_ranges, tf.logical_not(clip_mask))\n    y_ranges = tf.boolean_mask(y_ranges, tf.logical_not(clip_mask))\n    \n    hh_ranges = tf.tile(tf.range(0,hh), [tf.cast(tf.reduce_sum(tf.ones_like(x_ranges)), tf.int32)])\n    x_ranges = tf.repeat(x_ranges, hh)\n    y_ranges = tf.repeat(y_ranges, hh)\n    \n    y_hh_indices = tf.transpose(tf.stack([y_ranges, hh_ranges]))\n    x_hh_indices = tf.transpose(tf.stack([hh_ranges, x_ranges]))\n\n    y_mask_sparse = tf.SparseTensor(tf.cast(y_hh_indices, tf.int64),  tf.zeros_like(y_ranges), [hh, hh])\n    y_mask = tf.sparse.to_dense(y_mask_sparse, 1, False)\n\n    x_mask_sparse = tf.SparseTensor(tf.cast(x_hh_indices, tf.int64), tf.zeros_like(x_ranges), [hh, hh])\n    x_mask = tf.sparse.to_dense(x_mask_sparse, 1, False)\n    \n    mask = tf.expand_dims(tf.clip_by_value(x_mask + y_mask, 0, 1), axis=-1)\n    \n    mask = tf.image.crop_to_bounding_box(mask, (hh-h)//2, (hh-w)//2, img_height, img_width)\n    \n    if img_depth == 3:\n        mask = tf.concat([mask, mask, mask], axis=-1)\n\n    return image * tf.cast(mask, tf.int64)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Helper Code"},{"metadata":{"trusted":true},"cell_type":"code","source":"def image_reshape(target, image):\n    image = tf.reshape(image, (28,28, 1))\n    return target, image\n\ndef get_dataset(targets, features, augment=False, batch_size=32, gridmask= False, coarse= False, rand_dropout= False, HaS = False):\n    \n    targets = tf.constant(targets)\n    features = tf.constant(features)\n    dataset = tf.data.Dataset.from_tensor_slices((targets, features))\n    dataset = dataset.map(image_reshape)\n    \n    if gridmask:\n        dataset = dataset.map(lambda target, features: (target, gridmask_dropout(features, p=1)))\n\n    if coarse:\n        dataset = dataset.map(lambda target, features: (target, coarse_dropout(features, p=1)))\n\n    if rand_dropout:\n        dataset = dataset.map(lambda target, features: (target, random_dropout(features, p=1)))\n        \n    if HaS:\n        dataset = dataset.map(lambda target, features: (target, has_dropout(features, p=1)))\n    \n    \n    dataset = dataset.cache().shuffle(2000)\n    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n    dataset = dataset.batch(batch_size)\n    \n    return dataset\n\ndef show_batch_images(data):\n    \n    for labels, images in data.take(1):\n        labels = labels.numpy()\n        images = images.numpy()\n\n        plt.figure(figsize=(24,10))\n        col = 5\n        row = 2\n        for idx, image in enumerate(images[:10]):\n            plt.subplot(row, col, idx+1)\n            plt.imshow(image)\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# MNIST Raw"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nlabels_mnist = train_mnist[\"label\"].values\ntrain_data_mnist = train_mnist.drop(columns=[\"label\"]).values\ndataset_fashion_mnist = get_dataset(labels_mnist, train_data_mnist)\nshow_batch_images(dataset_fashion_mnist)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# MNIST Random Dropout"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ndataset_fashion_mnist = get_dataset(labels_mnist, train_data_mnist, rand_dropout=True)\nshow_batch_images(dataset_fashion_mnist)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# MNIST HaS (Hide and Seek) Dropout"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ndataset_fashion_mnist = get_dataset(labels_mnist, train_data_mnist, HaS=True)\nshow_batch_images(dataset_fashion_mnist)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# MNIST COARSE DROPOUT"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ndataset_fashion_mnist = get_dataset(labels_mnist, train_data_mnist, coarse=True)\nshow_batch_images(dataset_fashion_mnist)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# MNIST GRIDMASK DROPOUT"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ndataset_fashion_mnist = get_dataset(labels_mnist, train_data_mnist, gridmask=True)\nshow_batch_images(dataset_fashion_mnist)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}