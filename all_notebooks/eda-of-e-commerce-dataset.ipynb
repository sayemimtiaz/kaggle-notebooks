{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib as plt\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#    <span style='font-family:\"Times New Roman\"'> <span styel=''><span style='color:red'> __EXPLORATORY DATA ANALYSIS OF E-COMMERCE DATA__"},{"metadata":{},"cell_type":"markdown","source":"<img src=https://miro.medium.com/max/540/1*Ipr4zoMxipIzZEE4S0hleQ.jpeg width=\"350\">"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/ecommerce-data/data.csv\" , encoding = \"ISO-8859-1\")\nprint(df)\n\n\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##   <span style='font-family:\"Times New Roman\"'> <span styel=''><span style='color:black'> Now we have successfully loaded our data.Lets check for the missing values of data.\n   "},{"metadata":{"trusted":true},"cell_type":"code","source":"print (\"Rows     : \" ,df.shape[0])\nprint (\"Columns  : \" ,df.shape[1])\nprint (\"\\nFeatures : \\n\" ,df.columns.tolist())\nprint (\"\\nMissing values :  \", df.isnull().sum().values.sum())\nprint (\"\\nUnique values :  \\n\",df.nunique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"  ##  <span style='font-family:\"Times New Roman\"'> <span styel=''><span style='color:black'> Our data have some missing values. Lets drop missing values. Now the question arises what is the need of removing data.Missing data can reduce the statistical power of a study and can produce biased estimates, leading to invalid conclusions."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (\"Rows     : \" ,df.shape[0])\nprint (\"Columns  : \" ,df.shape[1])\nprint (\"\\nFeatures : \\n\" ,df.columns.tolist())\nprint (\"\\nMissing values :  \", df.isnull().sum().values.sum())\nprint (\"\\nUnique values :  \\n\",df.nunique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" ##   <span style='font-family:\"Times New Roman\"'> <span styel=''><span style='color:black'> Now we have dropped missing values. Lest start analysis "},{"metadata":{"trusted":true},"cell_type":"code","source":"df_Country=df.groupby('Country').count()\ndf_country = df_Country.sort_values('InvoiceNo', ascending=[False])\n\ndf_country1 = df_country.drop(df_country[df_country.InvoiceNo < 1000].index)\ndf_country2= df_country1[['InvoiceNo']]\nprint(df_country)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_country2.plot.bar(figsize=(10,8))\n#plt.title(label='Countrywise_sales(Top-10 Country)',\n       #  fontsize='20',\n        # color='green')\n#plt.ylabel('sales')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <span style='font-family:\"Times New Roman\"'> <span styel=''><span style='color:black'>__As the company is uk based so maximum sales happens in united kingdom only. for comparison in other countries , for our simplicity lets drop row for united kingdom and compare sales in   other countries__\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_2=df_Country\ndf_2\ndf_2=df_2.drop('United Kingdom')\ndf_2 = df_2.sort_values('InvoiceNo', ascending=[False])\ndf_2=df_2[['InvoiceNo']]\ndf_2.plot.bar(figsize=(20,10))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <span style='font-family:\"Times New Roman\"'><span style='color:black'> __from this graph we can observe that after united kingdom top five countries with maximum sales are Germany. France , EIRE ,Spain , Netherland respectively__"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.InvoiceDate = pd.to_datetime(df.InvoiceDate) \ndf.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <span style='font-family:\"Times New Roman\"'><span style='color:black'> Lets add some more columns in our data for further analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['new_date'] = [d.date() for d in df['InvoiceDate']] # to separate date and time from invoice date and create columns for it\ndf['new_time'] = [d.time() for d in df['InvoiceDate']]\ndf.new_date = pd.to_datetime(df.new_date)\ndf['year'] = df['new_date'].dt.year\ndf['month'] = df['new_date'].dt.month\ndf['date'] = df['new_date'].dt.day\ndf['hour'] = df['InvoiceDate'].dt.hour\ndf[\"period\"] = df[\"year\"].astype(str) + df[\"month\"].astype(str)\nprint(df)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <span style='font-family:\"Times New Roman\"'><span style='color:black'> Now we have added some columns like date ,month ,year in our data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_monthwise=df.groupby('period').count()\ndf_period = df_monthwise.sort_values('period', ascending=[True])\ndf_period=df_period[['InvoiceNo']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_period=df_period.plot.bar(figsize=(20,10))\ndf_period.set_xticklabels(['Dec-2010','jan-2011','oct-2011','nov-2011','dec-2011','feb-2011','march-2011','april-2011','may-2011','june-2011','july-2011','aug-2011','sept-2011'])\n#plt.title(label='monthwise sales from 1-dec-2010 to 09-dec-2011',\n #        fontsize='25',\n  #       color='green')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <span style='font-family:\"Times New Roman\"'><span style='color:black'>__Overall, we consider that the company receives the highest number of orders in November 2011 since we do not have the full month of data for December 2011.__\n "},{"metadata":{"trusted":true},"cell_type":"code","source":"df_date=df.groupby('date').count()\ndf2=df_date['InvoiceNo']\ndf_daywise=df2.plot.bar(figsize=(20,10))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <span style='font-family:\"Times New Roman\"'><span style='color:black'> __Maximum sales happen on 5th to 8th of each month.And sales decreases on last week of month__\n## <span style='font-family:\"Times New Roman\"'><span style='color:black'>  __One of the reason for this is salary of most of the peoples happens at first week of month__    "},{"metadata":{"trusted":true},"cell_type":"code","source":"df_hour=df.groupby('hour').count()\ndf9=df_hour[\"InvoiceNo\"]\ndf_timewise=df9.plot.bar(figsize=(10,5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <span style='font-family:\"Times New Roman\"'><span style='color:green'> In terms of hours, there are no transactions after 8:00pm until the next day at 6:00am.\n## <span style='font-family:\"Times New Roman\"'><span style='color:green'> Besides, we notice that the company receives the highest number of orders at 12:00pm. One of the reasons could be due to the fact that most customers make purchases during lunch hour between 12:00pm — 2:00pm.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[df[['Quantity']].idxmax()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_stock=df.groupby('StockCode').count()\nrslt_df = df_stock.sort_values(by = 'Quantity', ascending = False) \nrslt_df.reset_index()\nrslt_df1 = rslt_df.drop(rslt_df[rslt_df.InvoiceNo < 20].index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df9=rslt_df1[\"InvoiceNo\"]\ndf10=df9.head(20)\ndf_stock=df10.plot.bar(figsize=(15,10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1=df.loc[(df.StockCode == '85132A'), ['StockCode','Description']]\ndf2=df.loc[(df.StockCode == '22423'), ['StockCode','Description']]\ndf3=df.loc[(df.StockCode == '85099B'), ['StockCode','Description']]\ndf4=df.loc[(df.StockCode == '84879'), ['StockCode','Description']]\ndf5=df.loc[(df.StockCode == '47566'), ['StockCode','Description']]\nprint(df1.head(1))\nprint(df2.head(1))\nprint(df3.head(1))\nprint(df4.head(1))\nprint(df5.head(1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <span style='font-family:\"Times New Roman\"'> <span styel=''><span style='color:red'> __CONCLUSION:__"},{"metadata":{},"cell_type":"markdown","source":"### * As the company is UK Based , around __89%__ of sales occurs in __United Kingdom__ only\n### * Maximum sales happened at november-2011 as we dont have complete data for december-2011\n### * Maximum sales happens in first week of each month\n### *  In terms of hours, there are no transactions after 8:00pm until the next day at 6:00am.\n### *  Besides, we notice that the company receives the highest number of orders at 12:00pm. One of the reasons could be due to the fact that most customers make purchases during lunch hour between 12:00pm — 2:00pm.\n### * CHARLIE + LOLA BISCUITS TINS is the most saled product \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}