{"cells":[{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport re\nimport matplotlib.pyplot as plt\n\n!pip install pycountry_convert\nimport pycountry_convert\n\nfrom sklearn.impute import KNNImputer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/datarelated-developers-survey-by-stack-overflow/survey_final.csv',low_memory=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe(include='all')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next cell, I will clean the data and make it more consistent"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Make all data field consistent betweem years\ndata['EdLevel'].replace({\"Master's degree (M.A., M.S., M.Eng., MBA, etc.)\":\"Master's degree\",\n                          \"Bachelor's degree (B.A., B.S., B.Eng., etc.)\":\"Bachelor's degree\",\n                          \"Secondary school\": \"Secondary school\",\n                          \"Professional degree (JD, MD, etc.)\":\"Professional degree\",\n                          \"Some college/university study without earning a degree\":\"Some college/university study without earning a bachelor's degree\",\n                          \"Associate degree (A.A., A.S., etc.)\":\"Associate degree\", \n                          \"Other doctoral degree (Ph.D., Ed.D., etc.)\":\"Doctoral degree\",\n                          \"Bachelor's degree (BA, BS, B.Eng., etc.)\":\"Bachelor's degree\",\n                          \"Master's degree (MA, MS, M.Eng., MBA, etc.)\":\"Master's degree\",\n                          \"Other doctoral degree (Ph.D, Ed.D., etc.)\":\"Doctoral degree\",\n                          \"Bachelor‚'s degree (BA, BS, B.Eng., etc.)\":\"Bachelor's degree\",\n                          \"Master‚'s degree (MA, MS, M.Eng., MBA, etc.)\":\"Master's degree\",\n                          \"Secondary school (e.g. American high school, German Realschule or Gymnasium, etc.)\":\"Secondary school\", \n                          \" \":\"I prefer not to answer\",\n                          \"Full-stack developer\":\"I prefer not to answer\" }, inplace=True)\n\ndata['OrgSize'].replace({'2-9 employees' : '2 to 9 employees',\n                        'Fewer than 10 employees': '2 to 9 employees'}, inplace = True)\n\ndata['UndergradMajor'].replace({\"Computer science, computer engineering, or software engineering\":\"Computer science\",\n                                \"Another engineering discipline (such as civil, electrical, mechanical, etc.)\":\"Another engineering discipline\",\n                                \"A humanities discipline (such as literature, history, philosophy, etc.)\":\"Humanities\",\n                                \"A health science (such as nursing, pharmacy, radiology, etc.)\":\"Health science\",\n                                \"Information systems, information technology, or system administration\":\"Information systems\",\n                                \"A natural science (such as biology, chemistry, physics, etc.)\":\"Natural science\",\n                                \"Fine arts or performing arts (such as graphic design, music, studio art, etc.)\":\"Fine arts or performing arts\",\n                                \"A social science (such as anthropology, psychology, political science, etc.)\":\"Social science\",\n                                \"A business discipline (such as accounting, finance, marketing, etc.)\":\"Business\",\n                                \"Another engineering discipline (ex. civil, electrical, mechanical)\":\"Another engineering discipline\",\n                                \"A business discipline (ex. accounting, finance, marketing)\":\"Business\",\n                                \"A natural science (ex. biology, chemistry, physics)\":\"Natural science\",\n                                \"A social science (ex. anthropology, psychology, political science)\":\"Social science\",\n                                \"A humanities discipline (ex. literature, history, philosophy)\":\"Humanities\",\n                                \"Fine arts or performing arts (ex. graphic design, music, studio art)\":\"Fine arts or performing arts\",\n                                \"A health science (ex. nursing, pharmacy, radiology)\":\"Health science\",\n                                \"Computer science or software engineering\":\"Computer science\",\n                                \"A non-computer-focused engineering discipline\":\"Another engineering discipline\",\n                                \"A social science\":\"Social science\",\"A natural science\":\"Natural science\",\n                                \"A business discipline\":\"Business\",\"Information technology, networking, or system administration\":\"Information systems\",\"Fine arts or performing arts\":\"Fine arts or performing arts\",\"Management information systems\":\"Information systems\",\"A humanities discipline\":\"Humanities\",\"Psychology\":\"Social science\",\"A health science\":\"Health science\"}, inplace=True)\n\ndef jobsat(x):\n    if (x == 'Extremely satisfied') | (x == 10):\n        return 9\n    elif x == 'Very satisfied':\n        return 8\n    elif x == 'Moderately satisfied':\n        return 7\n    elif x == 'Slightly satisfied':\n        return 6\n    elif x == 'Neither satisfied nor dissatisfied':\n        return 5\n    elif x == 'Slightly dissatisfied':\n        return 4\n    elif x == 'Moderately dissatisfied':\n        return 3\n    elif x == 'Very dissatisfied':\n        return 2\n    elif (x == 'Extremely dissatisfied') | (x == 0):\n        return 1\n    else:\n        return x\n\ndata['JobSat'] = data['JobSat'].apply(jobsat).astype(float) \n\n\ndef yearcodeconvert(x):\n    if type(x) == str:\n        a = re.findall('[0-9]+', x)\n        if len(a) == 2:\n            return int(a[1])\n        if int(a[0]) >=30:\n            return 30\n        else:\n            return int(x)\n    else:\n        return x\ndata['YearsCodePro'].replace({'Less than 1 year':1,\n                              'Less than a year':1,\n                              '20 or more years':20,\n                              '30 or more years':30,\n                              'More than 50 years':30}, inplace = True)\n                             \ndata['YearsCodePro'] = data['YearsCodePro'].apply(yearcodeconvert)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# save data of each year for processing\ndata_2017 = data[data['Year']==2017]\ndata_2018 = data[data['Year']==2018]\ndata_2019 = data[data['Year']==2019]\ndata_2020 = data[data['Year']==2020]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## DevType separation"},{"metadata":{},"cell_type":"markdown","source":"This step will convert the Devtype column's values into dummies variables of eachdev type, then I will keep only the data-related devtype\n- Data scientist or machine learning specialist\n- Database administrator\n- Data or business analyst\n- Engineer, data"},{"metadata":{},"cell_type":"markdown","source":"### 2017"},{"metadata":{"trusted":true},"cell_type":"code","source":"mask = data_2017['DevType'].str.contains(r'data|machine|business', case = False,na=False)\ndf = data_2017[mask].copy()\n# remove all space at beginning of the text\ndf['DevType'].replace('^\\s+', '', regex=True, inplace=True) #front\n# Split the text by semi colon\nsplit_2017 = df['DevType'].str.get_dummies(sep='; ')\n# as 2017 have different choice from 18,19 and 20, we will merge the choices to align it with the rest\nsplit_2017['Data scientist or machine learning specialist'] = split_2017['Data scientist'] | split_2017['Machine learning specialist']\n# Get the desired columns\nselect_type_2017 = ['Data scientist or machine learning specialist',\n                   'Database administrator']\ncandidate_2017 = (np.sum(split_2017.loc[:,select_type_2017],axis = 1) != 0).index","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"split_2017.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2018"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"mask = data_2018['DevType'].str.contains(r'data|machine|business', case = False,na=False)\ndf = data_2018[mask].copy()\n# Replace all space at beginning of the text\ndf['DevType'].replace('^\\s+', '', regex=True, inplace=True) #front\n# Split the text by semi colon\nsplit_2018 = df['DevType'].str.get_dummies(sep=';')\n# Get the desired columns\nselect_type_2018 = ['Data or business analyst',\n                    'Data scientist or machine learning specialist',\n                    'Database administrator']\ncandidate_2018 = (np.sum(split_2018.loc[:,select_type_2018],axis = 1) != 0).index","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2019"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"mask = data_2019['DevType'].str.contains(r'data|machine|business', case = False,na=False)\ndf = data_2019[mask].copy()\n# Replace all space at beginning of the text\ndf['DevType'].replace('^\\s+', '', regex=True, inplace=True) #front\n# Split the text by semi colon\nsplit_2019 = df['DevType'].str.get_dummies(sep=';')\n# Get the desired columns\nselect_type_2019 = ['Data or business analyst',\n               'Data scientist or machine learning specialist',\n               'Database administrator',\n               'Engineer, data']\ncandidate_2019 = (np.sum(split_2019.loc[:,select_type_2019],axis = 1) != 0).index","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2020"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"mask = data_2020['DevType'].str.contains(r'data|machine|business', case = False,na=False)\ndf = data_2020[mask].copy()\n# Replace all space at beginning of the text\ndf['DevType'].replace('^\\s+', '', regex=True, inplace=True) #begin of the txt\n# Split the text by semi colon\nsplit_2020 = df['DevType'].str.get_dummies(sep=';')\n# Get the desired columns\nselect_type_2020 = ['Data or business analyst',\n                   'Data scientist or machine learning specialist',\n                   'Database administrator',\n                   'Engineer, data']\ncandidate_2020 = (np.sum(split_2020.loc[:,select_type_2020],axis = 1) != 0).index","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Now, we merge all the splitted columns of `DevType` together. And from now, we will just use the data of the developers having the data related job \n- Then we will also convert features that contain list of values in to dummies variable: `DatabaseDesireNextYear`, `DatabaseWorkedWith`, `LanguageDesireNextYear` and `LanguageWorkedWith`."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Concat all dummies of 4 year\ndm_dev_type = pd.concat([split_2017[select_type_2017],\n                                 split_2018[select_type_2018],\n                                 split_2019[select_type_2019],\n                                 split_2020[select_type_2020]],axis = 0)\n\ndm_dev_type.rename(columns = {'Data scientist or machine learning specialist' : 'DS_MLspecialist',\n                             'Database administrator' : 'DB_Admin',\n                             'Data or business analyst' : 'DA_BAnalyst',\n                             'Engineer, data':'DataEngineer'},inplace=True)\n# we only consider these job type in the data\ndata = data.loc[dm_dev_type.index,:]\n# Function to convert \ndef dummies_converter(df, col):\n    # remove space at the begining of the text\n    df[col].replace('^\\s+', '', regex=True, inplace=True) #begin of the txt\n    # Split the text by semi colon\n    dm1 = df[df['Year'] == 2017][col].str.get_dummies(sep='; ')\n    dm2 = df[df['Year'] >= 2018][col].str.get_dummies(sep=';')\n    return pd.concat([dm1,dm2],axis = 0)\n# Feature to get dummies:\nfeat_for_dm = ['DatabaseDesireNextYear', 'DatabaseWorkedWith', 'LanguageDesireNextYear', 'LanguageWorkedWith', 'DevType']\n# Convert to dummies\ndm_db_nextyear = dummies_converter(data,'DatabaseDesireNextYear')\ndm_db_work = dummies_converter(data,'DatabaseWorkedWith')\ndm_language_nextyear = dummies_converter(data,'LanguageDesireNextYear')\ndm_language_work = dummies_converter(data,'LanguageWorkedWith')\n# Drop converted features\ndata = data.drop(feat_for_dm,axis = 1,errors='ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Now we have 5 data frames of dummies features**\n- dm_dev_type\n- dm_db_nextyear\n- dm_db_work\n- dm_language_nextyear\n- dm_language_work"},{"metadata":{"trusted":true},"cell_type":"code","source":"#data = pd.merge(data, dev_type, left_index=True, right_index=True)\ndm_dev_type.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = data.copy()\ndf.describe(include='all')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**The target varialbe of this analyis this annual salary - `ConvertedComp`, lets take a look into that feature first**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(18, 5))\nsns.boxplot(x=\"Year\", y=\"ConvertedComp\",\n            hue = 'Employment',\n            data=df,\n            ax = ax)\nsns.despine(offset=10, trim=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To make this analysis as practical as possible, we will only consider people who was having a job related to data, so we will exclude people who does not have a salary information and job of not employed, no information on job or retired."},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# Drop irrelevant job title\ndf = df.loc[~df['Employment'].isin(['Not employed, and not looking for work',\n                                    'Not employed, but looking for work',\n                                    'I prefer not to say', 'Retired']), :]\n# Drop people do not have information about salary\ndf = df.loc[~df[\"ConvertedComp\"].isna(),:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(18, 5))\nsns.boxplot(x=\"Year\", y=\"ConvertedComp\",\n            hue = 'Employment',\n            data=df,\n            ax = ax)\nsns.despine(offset=10, trim=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the box-plot, we can observe that there is a lot of outliers in the annual salary, for relevancy of this analysis, we will exclude people ving annual salary more than 300,000$"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Remove outlier\ndf = df.loc[(df['ConvertedComp'] < 300000) & (df['ConvertedComp'] > 0),:]\n# plot\nfig, ax = plt.subplots(figsize=(18, 5))\nsns.boxplot(x=\"Year\", y=\"ConvertedComp\",\n            hue = 'Employment',\n            data=df,\n            ax = ax)\nsns.despine(offset=10, trim=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"#percentage of data kept after removing outliers and considering only instances that have our target variable\nlen(df)/len(data)*100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Missing values treatment"},{"metadata":{"trusted":true},"cell_type":"code","source":"#This is the number of missing values still existing (without dummies)\ndf.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#will give the index of the rows with any missing value\nnans_index = df.isna().any(axis=1)\n#if we would remove all the rowa with still missing values that would mean loosing 14,5% of data\nlen(df[nans_index])/len(df)*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df.dtypes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"#the nan values in the dummies will be substituted by zero, we just must have in consideration that for example the databases in 2017 don't include all the options that exist in the other years\n#in the same way in devtype the options of data/ business analyst and data engineer in 2017 qre not existing\ndm_db_nextyear.fillna(value=0, inplace=True)\ndm_dev_type.fillna(value=0, inplace=True)\ndm_db_work.fillna(value=0, inplace=True)\ndm_language_nextyear.fillna(value=0, inplace=True)\ndm_language_work.fillna(value=0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all = pd.concat([df, dm_dev_type, dm_db_nextyear, dm_db_work, dm_language_nextyear, dm_language_work],\n                   axis=1, join='inner')\n# export the data\nfilename = 'stack.csv'\ndf_all.to_csv(filename, index=False)\n# df\ndf_all.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"# First, we will divided the salary by 1000 for easy interpretation\ndf['ConvertedComp'] = df['ConvertedComp']/1000","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1. What is the impact of education major on salary"},{"metadata":{},"cell_type":"markdown","source":"## 2. What is the impact of Job type on salary"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let concat the data and the dummies variables of devtype\ndf_job = pd.concat([df, dm_dev_type],\n                   axis=1, join='inner')\ndf_job.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Percentage of respondents by title"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"df_dev_type = pd.concat([data['Year'], dm_dev_type],\n                   axis=1, join='inner')\ndf_measured = df_dev_type.groupby('Year').sum()\ndf_measured.loc[2017,:] = df_measured.loc[2017,:]/data_2017.shape[0]\ndf_measured.loc[2018,:] = df_measured.loc[2018,:]/data_2018.shape[0]\ndf_measured.loc[2019,:] = df_measured.loc[2019,:]/data_2019.shape[0]\ndf_measured.loc[2020,:] = df_measured.loc[2020,:]/data_2020.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df_measured","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Average salary by title"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows = 1, ncols = 4, sharex=\"all\", figsize=(16,4))\nsns.set_style(\"white\")\nnames = [\"Data scientist \\n Machine learning specialist\", 'Database administrator' , 'Data or business analyst', 'Engineer, data']\njob_types = ['DS_MLspecialist', 'DB_Admin', 'DA_BAnalyst', 'DataEngineer']\nfor job_type, name, ax in zip(job_types ,names , axes.flatten()):\n    ax = sns.pointplot(x=\"Year\", y=\"ConvertedComp\", hue=job_type, \n                capsize=.2, palette=\"rocket\", legend_out=True,\n                data=df_job, ax= ax)\n    ax.set_title(name, fontsize=14)\n    ax.set_ylim(bottom=50, top=75)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Median salary by average job satisfaction"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_toconcat = pd.concat([df_job[df_job['DS_MLspecialist'] ==1].groupby('Year')['JobSat'].mean(),\n                        df_job[df_job['DB_Admin'] ==1].groupby('Year')['JobSat'].mean(),\n                        df_job[df_job['DA_BAnalyst'] ==1].groupby('Year')['JobSat'].mean(),\n                        df_job[df_job['DataEngineer'] ==1].groupby('Year')['JobSat'].mean()],axis = 1)\ndf_toconcat.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"df_measured = pd.concat([df_job[df_job['DS_MLspecialist'] ==1].groupby('Year')['ConvertedComp'].median(),\n                        df_job[df_job['DB_Admin'] ==1].groupby('Year')['ConvertedComp'].median(),\n                        df_job[df_job['DA_BAnalyst'] ==1].groupby('Year')['ConvertedComp'].median(),\n                        df_job[df_job['DataEngineer'] ==1].groupby('Year')['ConvertedComp'].median()],axis = 1)\n\ndf_measured = pd.DataFrame(df_measured.values, index = df_measured.index, columns=job_types)\n\ndf_test = pd.DataFrame([] , columns=['year','medianSalary','type'])\nfor col in df_measured.columns:\n    df_test = pd.concat([df_test,\n                         pd.DataFrame({'year' : df_measured[col].index ,  \n                                       'medianSalary': df_measured[col].values,\n                                       'type': [col,col,col,col]})],axis = 0)\n    \ndf_measured = pd.concat([df_job[df_job['DS_MLspecialist'] ==1].groupby('Year')['JobSat'].mean(),\n                        df_job[df_job['DB_Admin'] ==1].groupby('Year')['JobSat'].mean(),\n                        df_job[df_job['DA_BAnalyst'] ==1].groupby('Year')['JobSat'].mean(),\n                        df_job[df_job['DataEngineer'] ==1].groupby('Year')['JobSat'].mean()],axis = 1)\ndf_measured = pd.DataFrame(df_toconcat.values, index = df_toconcat.index, columns=job_types)\ndf_test1 = pd.DataFrame([] , columns=['year','averageSatisfation','type'])\nfor col in df_measured.columns:\n    df_test1 = pd.concat([df_test1,\n                         pd.DataFrame({'year' : df_measured[col].index ,  \n                                       'averageSatisfation': df_measured[col].values,\n                                       'type': [col,col,col,col]})],axis = 0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(figsize=(6,6))\nsns.set_style(\"whitegrid\")\nsns.scatterplot(x = 'averageSatisfation' , y = 'medianSalary',\n               hue = 'type', size=\"year\" , palette=\"tab10\",\n               s=200,\n               data = pd.concat([df_test, df_test1['averageSatisfation']],axis =1), ax = axes)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data job in the world"},{"metadata":{"trusted":true},"cell_type":"code","source":"coordinate = pd.read_csv('https://raw.githubusercontent.com/albertyw/avenews/master/old/data/average-latitude-longitude-countries.csv')\ncoordinate.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_map = pd.merge(df_job.groupby('Country')['ConvertedComp'].median(), coordinate.set_index('Country'),left_index=True,right_index=True)\ndf_map['Country'] = df_map.index\ndf_map","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Refference:\n#1. https://python-visualization.github.io/folium/quickstart.html\n#2. https://towardsdatascience.com/creating-a-simple-folium-map-covid-19-worldwide-total-case-a0a1429c6e7c\n\nurl = 'https://raw.githubusercontent.com/python-visualization/folium/master/examples/data'\ncountry_shapes = f'{url}/world-countries.json'\n# Create a world map to show distributions of users \nimport folium\nfrom folium.plugins import MarkerCluster\n#empty map\n\nworld_map= folium.Map(tiles=\"cartodbpositron\")\n\n#show the map\nfolium.Choropleth(\n    #The GeoJSON data to represent the world country\n    geo_data=country_shapes,\n    name='Median salary',\n    data=df_map,\n    bins=9,\n    #The column aceppting list with 2 value; The country name and  the numerical value\n    columns=['Country', 'ConvertedComp'],\n    key_on='feature.properties.name',\n    fill_color='YlOrRd',  \n    fill_opacity = 0.9,\n    nan_fill_color='white',\n    nan_fill_opacity = 0.1,\n    line_weight = 0.5\n).add_to(world_map)\n\nworld_map","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"See by continent"},{"metadata":{"trusted":true},"cell_type":"code","source":"#function to convert to alpah2 country codes and continents\n#from pycountry_convert import country_alpha2_to_continent_code, country_name_to_country_alpha2\n\ndef get_continent(col):\n    try:\n        cn_continent = pycountry_convert.country_alpha2_to_continent_code(col)\n    except:\n        cn_continent = 'Unknown' \n    return cn_continent","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_map_1 = pd.merge(df_job.groupby(['Year','Country'])['ConvertedComp'].median(), coordinate.set_index('Country'),left_index=True,right_index=True)\ndf_map_1.reset_index(inplace=True) \ndf_map_1['Continent'] = df_map_1['ISO 3166 Country Code'].map(get_continent)\ndf_map_1 = df_map_1[df_map_1['Continent'] != 'Unknown']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows = 1, ncols = 6, sharex=\"all\", figsize=(24,8))\nsns.set_style(\"whitegrid\")\ncontinents = ['OC','NA', 'EU', 'AS','AF', 'SA']\ncontinent_names = [ 'Oceania','North America', 'Europe', 'Asia', 'Africa', 'South America']\ni = 0\nfor continent, name, ax in zip(continents ,continent_names , axes.flatten()): \n    ax = sns.barplot(x=\"Year\", y=\"ConvertedComp\", \n                    color = sns.color_palette(\"autumn\")[i], capsize= 0.2, \n                    data=df_map_1[df_map_1['Continent'] == continent], ax = ax)\n    ax.set_title(name, fontsize=24)        \n    if i >= 1:\n        ax.set_yticks(t)\n        #ax.get_yaxis().set_visible(False)\n        ax.set_yticklabels([])\n    else: \n        t = ax.get_yticks()\n        #ax.set_yticklabels(labels = ax.get_yticklabels(),fontsize = 14) \n    ax.tick_params(axis='both', which='major', labelsize=18)\n    ax.set_xlabel('')\n    ax.set_ylabel('')\n    sns.despine(right=True, left=True)\n    i += 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. What is the impact of Year of experience on Salary"},{"metadata":{},"cell_type":"markdown","source":"## 4. What is the impact of Programming language on Salary"},{"metadata":{"trusted":true},"cell_type":"code","source":"# concat programming language features together\ndf_p_language = pd.concat([df, dm_db_nextyear, dm_db_work,  dm_language_nextyear, dm_language_work],\n                   axis=1, join='inner')\ndf_p_language.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}