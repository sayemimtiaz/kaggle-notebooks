{"cells":[{"metadata":{"_uuid":"c0283e1a136a9b1d17561e5d3a64aa31280d21c7"},"cell_type":"markdown","source":"# Facebook comments Sentiment analysis"},{"metadata":{"_uuid":"0c9cdaffef486eff9b35b284bf5d16804bff73de"},"cell_type":"markdown","source":"The aim of this notebook is to train and test a Neural Network to detect, if a Facebook comment is either positive or negative in nature, based on a sample of Facebook comments with attatched sentiment ratings."},{"metadata":{"id":"8epK4XQqaJjb","colab_type":"text","_uuid":"87e514e64567e016bf3fdb09c23fc3be4c231650"},"cell_type":"markdown","source":"## Loading packages"},{"metadata":{"id":"-aOPCSzOaNSm","colab_type":"code","colab":{},"trusted":true,"_uuid":"0cd79b50e5b522468aca9dd7b718432cdec2c000"},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils.np_utils import to_categorical\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"id":"xTKiKluQQdix","colab_type":"code","colab":{},"trusted":true,"_uuid":"9e7f2c751e35e7c9cb87ef04d0a703a7d7b87f6f"},"cell_type":"code","source":"fb = pd.read_csv('../input/fb_sentiment.csv')","execution_count":null,"outputs":[]},{"metadata":{"id":"1ZJ6NgfGTCYL","colab_type":"text","_uuid":"05f7802fcf53b85a4c37a8975904a31e23b9958d"},"cell_type":"markdown","source":"## Exploring Data"},{"metadata":{"id":"GJPDpHKD4Mlh","colab_type":"text","_uuid":"3f36e758ff2bf6df4e04b45f0a4b23e9a0701607"},"cell_type":"markdown","source":"The data that we have chosen are Facebook-comments (`FBPost`) , with sentiments (`Label`) rated *positive*, *negative* or *other*. There are rows in the dataset, with an uneven distribution of sentiments.\n\nIn this section, some minor cleaning will take place."},{"metadata":{"id":"Zm-ktQz8RSuE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":195},"outputId":"cd71f113-d250-483f-e14c-91def38a29ad","trusted":true,"_uuid":"7a1990a7c284e9e1223f521a0278d194657a8f16"},"cell_type":"code","source":"fb.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"cTbNxoxkES78","colab_type":"code","colab":{},"trusted":true,"_uuid":"20cfe4699d11cab5a311ef63e9236d1d48650b95"},"cell_type":"code","source":"# lower-casing the coloumn names\nfb.columns = map(str.lower, fb.columns)","execution_count":null,"outputs":[]},{"metadata":{"id":"w2yIWgFDRtGU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"33a6dccb-fb7c-44e6-ef53-d426bd116cbe","trusted":true,"_uuid":"47550f799903343e581a4ba76889c2291c526ce8"},"cell_type":"code","source":"# checkin the shape of the DF\nfb.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"bGSFhP2bWsgT","colab_type":"text","_uuid":"68ff2ec79195ccc3cc7b976191e8e4399ec7a45a"},"cell_type":"markdown","source":"## Data preperation"},{"metadata":{"id":"U6OodXl2ZBUu","colab_type":"text","_uuid":"45a114fc2a9417377ba2a4f66f90ef84ff0a432a"},"cell_type":"markdown","source":"### Preparing the Facebook comments"},{"metadata":{"id":"OaigJdraW1ac","colab_type":"code","colab":{},"trusted":true,"_uuid":"841b1a613c17188abf38e1d8999488dbbe10f37a"},"cell_type":"code","source":"#lowercasing the text and removing symbols though RegEx\nimport re\nfb['fbpost'] = fb['fbpost'].apply(lambda x: x.lower())\nfb['fbpost'] = fb['fbpost'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))","execution_count":null,"outputs":[]},{"metadata":{"id":"S_1SxJn_5uJx","colab_type":"text","_uuid":"eb0138f78d1bfa64336f7072d763092854e74e1b"},"cell_type":"markdown","source":"With this Neural network, we want to predict, wether a comment is Positive (`P`) or Negative (`N`), so the comments with the sentiment labeled Other (`O`) is of no use to us, so it's removed from the dataset."},{"metadata":{"id":"QC_F5dRCbf3X","colab_type":"code","colab":{},"trusted":true,"_uuid":"ea642b2673523f9204206f3aa80a82ec488ac5de"},"cell_type":"code","source":"fb = fb[fb.label != \"O\"]","execution_count":null,"outputs":[]},{"metadata":{"id":"AsbmJh2h6Zuu","colab_type":"text","_uuid":"03117148c91b3eee6c4da8c4ead9663f0bdcdca7"},"cell_type":"markdown","source":"Now to tokenize the actual Facebook comments:"},{"metadata":{"id":"tl6cWObKav4e","colab_type":"code","colab":{},"trusted":true,"_uuid":"4befaacd1e8951027fb77c3faa29db16c665bafd"},"cell_type":"code","source":"max_fatures = 2000\ntokenizer = Tokenizer(num_words=max_fatures, split=' ')\ntokenizer.fit_on_texts(fb['fbpost'].values)\nX = tokenizer.texts_to_sequences(fb['fbpost'].values)\nX = pad_sequences(X)","execution_count":null,"outputs":[]},{"metadata":{"id":"2-IReEGSZhqb","colab_type":"text","_uuid":"baceea32adf980395ee8f3b6b914d454ee62aa95"},"cell_type":"markdown","source":"### Preparing the labels"},{"metadata":{"id":"Sgysju6B6rBv","colab_type":"text","_uuid":"df406b01adcd37b7afe723263d17c95db77e21d0"},"cell_type":"markdown","source":"Here the lables are checked after the removel of the \"other\" sentimented comments. Also some preperation to the algorithm, as preparing the test-, and training sets are done."},{"metadata":{"id":"fhQBEgGtW1hv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":67},"outputId":"0a55f5ab-321f-4d9e-8827-bdf4ee25aaf3","trusted":true,"_uuid":"15d3cffd824cd937d471b5b4fb3982d4f1ca5b75"},"cell_type":"code","source":"fb.label.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"id":"ZfvXn-Q4eChl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"outputId":"c15590a6-032b-4325-edca-40f85a788de4","trusted":true,"_uuid":"5e823e4189bc1ff7be4f2a399479fa1a50698e4d"},"cell_type":"code","source":"Y = pd.get_dummies(fb['label']).values\nX_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.33, random_state = 42)\nprint(X_train.shape,Y_train.shape)\nprint(X_test.shape,Y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"id":"Yo_LYWBwchiV","colab_type":"text","_uuid":"2843d947e6ee1eb376abafa5fe5462c76f2d8af0"},"cell_type":"markdown","source":"## The Neural Network"},{"metadata":{"id":"GuAVZ2A07VUl","colab_type":"text","_uuid":"7020e84ea7f690dd6d04e76e740317a33b5b494c"},"cell_type":"markdown","source":"In this section, the algorithm is prepared with following features:\n\n- The model is Sequential\n- The model type is an LSTM model"},{"metadata":{"id":"YDUPRuwjckqL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":289},"outputId":"49261247-e79e-43a8-9e1b-5cf5fced2874","trusted":true,"_uuid":"425b231e04c6836fcc983b719687d242c0bb5ecb"},"cell_type":"code","source":"embed_dim = 200\nlstm_out = 200\n\nmodel = Sequential()\nmodel.add(Embedding(max_fatures, embed_dim,input_length = X.shape[1]))\nmodel.add(SpatialDropout1D(0.4))\nmodel.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\nmodel.add(Dense(2,activation='softmax'))\nmodel.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\nprint(model.summary())","execution_count":null,"outputs":[]},{"metadata":{"id":"lINuVR3Kc6Md","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":255},"outputId":"fd8a00ba-ae69-4043-d834-ccff9e9004d1","trusted":true,"_uuid":"76ab53e65c2e5fc1a9ca66350b274f488cd004b2"},"cell_type":"code","source":"# Here we train the model\nbatch_size = 32\nhist = model.fit(X_train, Y_train, epochs = 7, batch_size=batch_size, verbose = 2)","execution_count":null,"outputs":[]},{"metadata":{"id":"mkECIjnllcg_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":443},"outputId":"aecde4db-3f0b-42e4-bd95-56c44f3f5643","trusted":true,"_uuid":"cd8fa92809abba5b1fc129052b78f290de460c66"},"cell_type":"code","source":"#Plotting a histogram over the 7 epocs and plotting the accuracy and loss\nhistory = pd.DataFrame(hist.history)\nplt.figure(figsize=(7,7));\nplt.plot(history[\"loss\"]);\nplt.plot(history[\"acc\"]);\nplt.title(\"Loss and accuracy of model\");\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"id":"-r9YugI0dTnO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"outputId":"16a18d07-aaeb-44b7-83ce-9a0782c18d27","trusted":true,"_uuid":"b407f40938398308c143b5c45c3acb12aa08e4ac"},"cell_type":"code","source":"#Testing the model, and retrieveing score and accuracy:\nscore,acc = model.evaluate(X_test,Y_test)\nprint(\"score: %.2f\" % (score))\nprint(\"accuracy: %.2f\" % (acc))\n","execution_count":null,"outputs":[]},{"metadata":{"id":"23LR124pybug","colab_type":"code","colab":{},"trusted":true,"_uuid":"1b5703285789fd033a9e012e526c6b70cf41f27b"},"cell_type":"code","source":"#now we validate for the models accuracy in predicting either a positive, or a negative score:\nvalidation_size = 1500\n\nX_validate = X_test[-validation_size:]\nY_validate = Y_test[-validation_size:]\nx_test = X_test[:-validation_size]\ny_test = Y_test[:-validation_size]","execution_count":null,"outputs":[]},{"metadata":{"id":"O5juxN48yGfa","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"37f5f99b-852c-4c0a-8ff7-c3db742b2b86","trusted":true,"_uuid":"8f6ce219f3a95f4ffe22c9a6e2b5ca717f58b05f"},"cell_type":"code","source":"pos_cnt, neg_cnt, pos_correct, neg_correct = 0, 0, 0, 0\nfor x in range(len(X_validate)):\n    result = model.predict(X_validate[x].reshape(1,x_test.shape[1]),verbose = 2)[0]\n    if np.argmax(result) == np.argmax(Y_validate[x]):\n        if np.argmax(Y_validate[x]) == 0:\n            neg_correct += 1\n        else:\n            pos_correct += 1\n    if np.argmax(Y_validate[x]) == 0:\n        neg_cnt += 1\n    else:\n        pos_cnt += 1\nprint(\"positive_acc\", pos_correct/pos_cnt*100, \"%\")\nprint(\"negative_acc\", neg_correct/neg_cnt*100, \"%\")","execution_count":null,"outputs":[]},{"metadata":{"id":"eg3T0v7tyGid","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":238},"outputId":"b0771d58-bd2e-4c8a-ec8c-ae45463284fd","trusted":true,"_uuid":"e2d8edb0e7f99e207ad01551f5181d17f0b53e8b"},"cell_type":"code","source":"#now testing  on a random sample from the Facebook comments on Kindle's page:\ncmnt = ['your customer service is the absolute worst i now have a mess of books on my kindle']\n#vectorizing the comment\ncmnt = tokenizer.texts_to_sequences(cmnt)\ncmnt = pad_sequences(cmnt, maxlen=203, dtype='int32', value=0)\nprint(cmnt)\nsentiment = model.predict(cmnt,batch_size=2,verbose = 2)[0]\nif(np.argmax(sentiment) == 0):\n    print(\"negative\")\nelif (np.argmax(sentiment) == 1):\n    print(\"positive\")","execution_count":null,"outputs":[]},{"metadata":{"id":"TkruxKLCAdDX","colab_type":"text","_uuid":"2da1ccc8342fd172de67a2cc152b23f9078ab563"},"cell_type":"markdown","source":"What went wrong? \n\nOur sample size for the training-, and test set was in fact quite small (under 1000 comments), and the proportion of negative to positive comments was skewed about 1 to 9. So the algorithm was not really optimized on the basis of our data. This is the reason for the algorithm choosing the wrong sentiment in the sample-test above."},{"metadata":{"trusted":true,"_uuid":"497ce01d17f2d30955be47f1f77f06a53b49e541"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"39647bc1f806fc1be604ffdc9e8473906aea34e8"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"colab":{"name":"M3_pr√¶sentation.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":["8epK4XQqaJjb","LxqAGstIS645","1ZJ6NgfGTCYL","bGSFhP2bWsgT","U6OodXl2ZBUu","2-IReEGSZhqb","Yo_LYWBwchiV"]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}