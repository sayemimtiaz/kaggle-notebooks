{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Introduction","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Hypothesis testing** is a critical tool in determing what the value of a parameter could be.\n\nBasis of our testing has two attributes:\n\nNull Hypothesis:  H0 \n\nAlternative Hypothesis:  Ha \n\nThe tests we have discussed in Notebook are:\n* One Population Proportion\n* Difference in Population Proportions\n* Comparing means\n\nTo calculate a test statistic , the equation is -\n\n# (Best Estimateâˆ’Hypothesized Estimate)/ Standard Error of Estimate","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"In this notebook we demonstrate formal hypothesis testing using the NHANES data.\n\nIt is important to note that the NHANES data are a \"complex survey\". The data are not an independent and representative sample from the target population. Proper analysis of complex survey data should make use of additional information about how the data were collected. Since complex survey analysis is a somewhat specialized topic, we ignore this aspect of the data here, and analyze the NHANES data as if it were an independent and identically distributed sample from a population.","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib\nmatplotlib.use('Agg') # workaround, there may be a better way\nimport seaborn as sns\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport statsmodels.api as sm\nimport scipy.stats.distributions as dist","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#we'll import data now   \ndata = pd.read_csv('/kaggle/input/nhanes-2015-2016/NHANES.csv') #Data is available in my dataset\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Some Data Cleaning**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"SMQ020x\"] = data.SMQ020.replace({1: \"Yes\", 2: \"No\", 7: np.nan, 9: np.nan})\ndata[\"RIAGENDRx\"] = data.RIAGENDR.replace({1: \"Male\", 2: \"Female\"})\ndata[\"RIAGENDRx\"].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Hypothesis Testing for One proportion","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The most basic hypothesis test may be the one-sample test for a proportion.  This test is used if we have specified a particular value as the null value for the proportion, and we wish to assess if the data are compatible with the true parameter value being equal to this specified value.  One-sample tests are not used very often in practice, because it is not very common that we have a specific fixed value to use for comparison. For illustration, imagine that the rate of lifetime smoking in another country was known to be 40%, and we wished to assess whether the rate of lifetime smoking in the US were different from 40%. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x = data.SMQ020x.dropna() == \"Yes\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p = x.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Standard_error=np.sqrt(.4 * (1 - .4)/ len(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Standard_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_statistic = (p - 0.4) / Standard_error\ntest_statistic","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pvalue = 2 * dist.norm.cdf(-np.abs(test_statistic))\nprint(test_statistic, pvalue)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The following cell carries out the same test as performed above using the Statsmodels library. The results in the first (default) case below are slightly different from the results obtained above because Statsmodels by default uses the sample proportion instead of the null proportion when computing the standard error. This distinction is rarely consequential, but we can specify that the null proportion should be used to calculate the standard error, and the results agree exactly with what we calculated above. The first two lines below carry out tests using the normal approximation to the sampling distribution of the test statistic, and the third line below carries uses the exact binomial sampling distribution. We can see here that the p-values are nearly identical in all three cases. This is expected when the sample size is large, and the proportion is not close to either 0 or 1.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sm.stats.proportions_ztest(x.sum(), len(x), 0.4)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sm.stats.binom_test(x.sum(), len(x), 0.4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We carry out the (two-sided) one-sample test that the population proportion of smokers is 0.4, and obtain a p-value of 0.43.  This indicates that the NHANES data are compatible with the proportion of (ever) smokers in the US being 40%. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Hypothesis Tests for Two Proportions","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Comparative tests tend to be used much more frequently than tests comparing one population to a fixed value.  A two-sample test of proportions is used to assess whether the proportion of individuals with some trait differs between two sub-populations.  For example, we can compare the smoking rates between females and males. Since smoking rates vary strongly with age, we do this in the subpopulation of people between 20 and 25 years of age.  In the cell below, we carry out this test without using any libraries, implementing all the test procedures covered elsewhere in the course using Python code.  We find that the smoking rate for men is around 10 percentage points greater than the smoking rate for females, and this difference is statistically significant (the p-value is around 0.01).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dx = data[[\"SMQ020x\", \"RIDAGEYR\", \"RIAGENDRx\"]].dropna()  # Drop missing values\ndx = dx.loc[(dx.RIDAGEYR >= 20) & (dx.RIDAGEYR <= 25), :] # Restrict to people between 20 and 25 years old","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Summarize the data by caclculating the proportion of yes responses and the sample size\np = dx.groupby(\"RIAGENDRx\")[\"SMQ020x\"].agg([lambda z: np.mean(z==\"Yes\"), \"size\"])\np.columns = [\"Smoke\", \"N\"]\nprint(p)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# The pooled rate of yes responses, and the standard error of the estimated difference of proportions\np_comb = (dx.SMQ020x == \"Yes\").mean()\nva = p_comb * (1 - p_comb)\nse = np.sqrt(va * (1 / p.N.Female + 1 / p.N.Male))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"se","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate the test statistic and its p-value\ntest_stat = (p.Smoke.Female - p.Smoke.Male) / se\npvalue = 2*dist.norm.cdf(-np.abs(test_stat))\nprint(test_stat, pvalue)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"As P-value < 0.01 , we reject the null hypothesis and conclude that smoking rate for men is around 10 percentage points greater than the smoking rate for females, and this difference is statistically significant.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Essentially the same test as above can be conducted by converting the \"Yes\"/\"No\" responses to numbers (Yes=1, No=0) and conducting a two-sample t-test, as below:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dx_females = dx.loc[dx.RIAGENDRx==\"Female\", \"SMQ020x\"].replace({\"Yes\": 1, \"No\": 0})\ndx_males = dx.loc[dx.RIAGENDRx==\"Male\", \"SMQ020x\"].replace({\"Yes\": 1, \"No\": 0})\nsm.stats.ttest_ind(dx_females, dx_males) # prints test statistic, p-value, degrees of freedom","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Hypothesis tests comparing means","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Tests of means are similar in many ways to tests of proportions. Just as with proportions, for comparing means there are one and two-sample tests, z-tests and t-tests, and one-sided and two-sided tests. As with tests of proportions, one-sample tests of means are not very common, but we illustrate a one sample test in the cell below. We compare systolic blood pressure to the fixed value 120 (which is the lower threshold for \"pre-hypertension\"), and find that the mean is significantly different from 120 (the point estimate of the mean is 126).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dx = data[[\"BPXSY1\", \"RIDAGEYR\", \"RIAGENDRx\"]].dropna()\ndx = dx.loc[(dx.RIDAGEYR >= 40) & (dx.RIDAGEYR <= 50) & (dx.RIAGENDRx == \"Male\"), :]\nprint(len(dx))\nprint(dx.BPXSY1.mean()) # prints mean blood pressure\nsm.stats.ztest(dx.BPXSY1, value=120)  # prints test statistic, p-value","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the cell below, we carry out a formal test of the null hypothesis that the mean blood pressure for women between the ages of 50 and 60 is equal to the mean blood pressure of men between the ages of 50 and 60. The results indicate that while the mean systolic blood pressure for men is slightly greater than that for women (129 mm/Hg versus 128 mm/Hg), this difference is not statistically significant.\n\nThere are a number of different variants on the two-sample t-test. Two often-encountered variants are the t-test carried out using the t-distribution, and the t-test carried out using the normal approximation to the reference distribution of the test statistic, often called a z-test. Below we display results from both these testing approaches. When the sample size is large, the difference between the t-test and z-test is very small.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dx = data[[\"BPXSY1\", \"RIDAGEYR\", \"RIAGENDRx\"]].dropna()\ndx = dx.loc[(dx.RIDAGEYR >= 50) & (dx.RIDAGEYR <= 60), :]\nbpx_female = dx.loc[dx.RIAGENDRx==\"Female\", \"BPXSY1\"]\nbpx_male = dx.loc[dx.RIAGENDRx==\"Male\", \"BPXSY1\"]\nprint(bpx_female.mean(), bpx_male.mean()) # prints female mean, male mean\nprint(sm.stats.ztest(bpx_female, bpx_male)) # prints test statistic, p-value\nprint(sm.stats.ttest_ind(bpx_female, bpx_male)) # prints test statistic, p-value, degrees of freedom","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Another important aspect of two-sample mean testing is \"heteroscedasticity\", meaning that the variances within the two groups being compared may be different. While the goal of the test is to compare the means, the variances play an important role in calibrating the statistics (deciding how big the mean difference needs to be to be declared statistically significant). In the NHANES data, we see that there are moderate differences between the amount of variation in BMI for females and for males, looking within 10-year age bands. In every age band, females having greater variation than males.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dx = data[[\"BMXBMI\", \"RIDAGEYR\", \"RIAGENDRx\"]].dropna()\ndata[\"agegrp\"] = pd.cut(data.RIDAGEYR, [18, 30, 40, 50, 60, 70, 80])\ndata.groupby([\"agegrp\", \"RIAGENDRx\"])[\"BMXBMI\"].agg(np.std).unstack()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The standard error of the mean difference (e.g. mean female blood pressure minus mean male blood pressure) can be estimated in at least two different ways. In the statsmodels library, these approaches are referred to as the \"pooled\" and the \"unequal\" approach to estimating the variance. If the variances are equal (i.e. there is no heteroscedasticity), then there should be little difference between the two approaches. Even in the presence of moderate heteroscedasticity, as we have here, we can see that the results for the two methods are quite similar. Below we have a loop that considers each 10-year age band and assesses the evidence for a difference in mean BMI for women and for men. The results printed in each row of output are the test-statistic and p-value.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for k, v in data.groupby(\"agegrp\"):\n    bmi_female = v.loc[v.RIAGENDRx==\"Female\", \"BMXBMI\"].dropna()\n    bmi_female = sm.stats.DescrStatsW(bmi_female)\n    bmi_male = v.loc[v.RIAGENDRx==\"Male\", \"BMXBMI\"].dropna()\n    bmi_male = sm.stats.DescrStatsW(bmi_male)\n    print(k)\n    print(\"pooled: \", sm.stats.CompareMeans(bmi_female, bmi_male).ztest_ind(usevar='pooled'))\n    print(\"unequal:\", sm.stats.CompareMeans(bmi_female, bmi_male).ztest_ind(usevar='unequal'))\n    print()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}