{"cells":[{"metadata":{"_uuid":"ba8dfc99efe0c92f2586ec6af68538e19c095130"},"cell_type":"markdown","source":"# Women in Analytics 2019 Workshop\n## March 22, 2019\n## Author: Jaya Zenchenko, @datanerd_jaya\n## https://www.linkedin.com/in/jayazenchenko/\n## Machine Learning with Python\n\nAgenda:\n* Intro\n* What is machine learning?\n* Python package highlights\n* Quickest intro to numpy, scipy\n* Exploratory Data Analysis (EDA) with Pandas\n* Unsupervised Learning, Supervised Learning\n* Model evaluation, cross-validation\n* Wrap Up\n"},{"metadata":{"_uuid":"0c10f5a7864e954b26b50d164ae984f0b695d715"},"cell_type":"markdown","source":"Fork this notebook!"},{"metadata":{"_uuid":"c0d4b69b495daa5ebc1f2862986061c241cf40fb"},"cell_type":"markdown","source":"Exciting times! Data sources, tools, compute resources readily available to get started!\n\nFree Data Sources:\n* Too many to list!\n* Caution: Data sources vs. Machine learning data - structured/unstrctured data vs labeled data\n* Caution: Check out everyone's licensing before using it for your enterprise needs.\n\n\nQuick intro to open source data science and analytics - \n\nCompute resources to use:\nFree (or free trial):\n* https://data.world/community/open-community/\n* https://colab.research.google.com/notebooks/welcome.ipynb\n* https://aws.amazon.com/sagemaker/pricing/\n* https://cloud.google.com/products/ai/\n* https://datastudio.google.com/navigation/reporting\n* https://azure.microsoft.com/en-us/pricing/details/virtual-machines/windows/\n* https://www.dominodatalab.com/domino-for-good/\n* https://www.dominodatalab.com/domino-for-good/for-students/\n* https://www.kaggle.com/sigma23/women-in-analytics-2019-workshop/edit\n* https://medium.com/@jamsawamsa/running-a-google-cloud-gpu-for-fast-ai-for-free-5f89c707bae6\n\nCaution: Make sure you know how to shut them down to not rack up a huge bill!\n\nGenerally free tools \n* RStudio\n* Anaconda (Jupyter, Spyder, Orange)\n* Weka\n* KNIME\n* https://www.h2o.ai/products/h2o/#how-it-works\n* https://public.tableau.com/en-us/s/\n* https://plot.ly/create/#/\n\n\nGreat Resources:\nFree Code!\n* https://github.com/amueller/scipy-2018-sklearn\n* https://jakevdp.github.io/PythonDataScienceHandbook\n* https://github.com/rasbt/python-machine-learning-book-2nd-edition\n* https://github.com/josephmisiti/awesome-machine-learning\n* https://github.com/lazyprogrammer/machine_learning_examples\n* https://github.com/scikit-learn/scikit-learn\n\nFree Courses:\nCoursera, edx, classcentral.com\n\nSoapbox: Free means people have dedicated time and resources to creating and maintaining these things.  Be a part of the open source community by contributing!\n\n\n\n"},{"metadata":{"trusted":true,"_uuid":"ece3e3c3cbbfc15fc4110c37b0cb82cafc241648"},"cell_type":"code","source":"from IPython.display import Image\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0499f89bbd360681d402113ce4e70ccddb90dcb1"},"cell_type":"markdown","source":"# What is Machine Learning?\n\nMachine Learning\n\nGreat definition: https://emerj.com/ai-glossary-terms/what-is-machine-learning/\n\n"},{"metadata":{"_uuid":"0499f89bbd360681d402113ce4e70ccddb90dcb1","trusted":true},"cell_type":"code","source":"Image(\"../input/images2/images/images/what_is_ml.png\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d22ee8f7845c96aea185058677a30641a271affb"},"cell_type":"code","source":"Image(\"../input/images2/images/images/types_oh_ml.png\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"15e661b12dcff6792a457bc90244fc98162b6504"},"cell_type":"code","source":"Image(\"../input/images2/images/images/types_of_ml.png\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"81abd9441348cea4a9edf6d7b249a05dc5ab88ce"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0499f89bbd360681d402113ce4e70ccddb90dcb1"},"cell_type":"markdown","source":"Source:\n\n- https://medium.com/deep-math-machine-learning-ai/introduction-of-machine-learning-why-how-what-84c881c70763\n- https://medium.com/deep-math-machine-learning-ai/different-types-of-machine-learning-and-their-types-34760b9128a2 (pic) "},{"metadata":{"_uuid":"33986f4f73238115db2678079f7029a1cbf5348d"},"cell_type":"markdown","source":"## Let's get started! Import packages!"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport sklearn\nimport scipy \n\nimport xgboost\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5b248c12afa64ac2dae741b00bc8093318e065ec"},"cell_type":"markdown","source":"Need latest package for categorical_encoders:"},{"metadata":{"trusted":true,"_uuid":"ae2e820a896205b4eecf7e1f180b4c83c799b890"},"cell_type":"code","source":"!pip install --upgrade git+https://github.com/scikit-learn-contrib/categorical-encoding","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fb473d470bed58835e0fed25113cae496293a51b"},"cell_type":"code","source":"import category_encoders","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e9fd293776bb1c7eb51c28be5934860f0312261f"},"cell_type":"markdown","source":"Caution: Keep track of python packages using docker (kaggle does this), conda environments, virtualenv, or with watermark:  https://github.com/rasbt/watermark#installation-and-updating\n\nCaution: Important to remember reproducible code and research!\n\nCaution: Check internet connection for pip install"},{"metadata":{"trusted":true,"_uuid":"14054181259be1e8993e2106efed6c349fc81036"},"cell_type":"code","source":"!pip install watermark","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"687fdce06242acb78d856194f2e06ac096e59798"},"cell_type":"code","source":"%load_ext watermark","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2edcd645223c41335446b258cb9a7a5014b79edf","trusted":true},"cell_type":"code","source":"%watermark --iversions","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d8bbd552dcfd0164a391773701bb98643925b242"},"cell_type":"markdown","source":"Caution: VERY important to keep track of the versions used - open source packages change frequently and the code may not work with new package versions.  Use Docker or virtual environments to keep track and test all your code anytime you want to update a package in your environment.\n\nI like to print it out in the notebook if I'm just sharing my notebook.\n"},{"metadata":{"_uuid":"96cffb38afd9a6bfb91ad25e3db6f08a6b22a273"},"cell_type":"markdown","source":"## Quickest intro to numpy/scipy:\n* NumPy (1995 as numeric, 2006 as NumPy)\n    * Array data types and basic operations (with some overlap with scipy)\n* SciPy (Scientific Python) - created 2001\n    * Fully featured versions of the linear algebra and numerical algorithms\n    \n    \n* Fortran/C/C++ under the hood - fast! Don't rewrite these methods!\n* Incredible SciPy conference held yearly in Austin, TX! Meet many of the scikit-learn and other python open source contributers! https://conference.scipy.org/ Watch all talks for free: https://www.youtube.com/user/EnthoughtMedia\n"},{"metadata":{"trusted":true,"_uuid":"839a2b04e4af866eff218c9b28bafebe34033c84"},"cell_type":"code","source":"## Basic numpy:\n# 1d:\na = np.array([0, 1, 2, 3])\nprint(\"a = \", a)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8ba783d1681c36decb5036554341db78a1a49552"},"cell_type":"code","source":"# 2x3 array:\nb = np.array([[0, 1, 2], [3, 4, 5]])    # 2 x 3 array\nprint(\"b = \", b)\n# https://scipy-lectures.org/intro/numpy/array_object.html#what-are-numpy-and-numpy-arrays\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"15c9cb0cab2f2c8a27ae49591ed50b9df71c2704"},"cell_type":"code","source":"a.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4f72df50a8e647a83f4429e997db7418c915f7ea"},"cell_type":"code","source":"b.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8eb0467912c15dbaa8209de582f1eb6b5e9c9c77"},"cell_type":"markdown","source":"#### Most common: \n* np.reshape()\n* np.arange()\n* np.linspace()\n* np.zeros()\n* np.sum()\n* np.mean()\n* np.argmax()\n* np.argmin()\n* np.array()\n* np.sort()\n\n#### Cheat Sheets!\n* https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Numpy_Python_Cheat_Sheet.pdf\n* https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Scikit_Learn_Cheat_Sheet_Python.pdf\n* https://s3.amazonaws.com/assets.datacamp.com/blog_assets/PandasPythonForDataScience.pdf\n* https://s3.amazonaws.com/assets.datacamp.com/blog_assets/PythonForDataScience.pdf\n\n#### Additional Resources:\n* https://towardsdatascience.com/lets-talk-about-numpy-for-datascience-beginners-b8088722309f\n"},{"metadata":{"trusted":true,"_uuid":"b6b62852e5c7af8acf98fee04a3cc8607541fc8f"},"cell_type":"code","source":"a.reshape(4,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7319998550c0b61438f4457b9be59a47c0f98a2b"},"cell_type":"code","source":"a","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ad007ee3ba44fc1dd17d8ab8c7147b89df13daaa"},"cell_type":"code","source":"a.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"91357517293b189ed5cc4ebef2ce8db5685d16b1"},"cell_type":"code","source":"a = a.reshape(4,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3b94d153865490943dcb4836372d08e4a24b654d"},"cell_type":"code","source":"a","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"52456c0a2ef38fa2bbd28db6e062ecb7081cfb87"},"cell_type":"code","source":"a = np.arange(10) # evenly spaced\nprint(a)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5c5be74f3593c501bd5bbaa6e9a5c2a03e17869c"},"cell_type":"code","source":"np.linspace(0, 1, 10) # Start, end, Number of points","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c75232546a57d7eb4f5069ee33ffbb7d97cb7b65"},"cell_type":"code","source":"?np.linspace # Get help on how to call the function!","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"11831f5f9b98ad7a5ad9127fd3f48a53364f0a5c"},"cell_type":"code","source":"Image(\"../input/images2/images/images/numpy_slicing.png\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"609a03b298b3f82b43f8636afb756d4c284bea54"},"cell_type":"code","source":"# Indexing\na = np.arange(10) # evenly spaced\na[2:9:3] # [start:end:step]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"19fc23c290d86dd9c0789b36e30493c909e10b40"},"cell_type":"code","source":"a[:4] # last index is not included.  Default start is 0, end is last, step is 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"39ced374068fcbd5edae6fde9659161ed7ca13b1"},"cell_type":"code","source":"a[::-1] # Can easily reverse!","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"27a7701e19baa4457afea9789e10f22c539b18c7","_kg_hide-input":true},"cell_type":"code","source":"Image(\"../input/images2/images/images/numpy_fancy_indexing.png\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3657b0369928e68158a6c865c33963ab1a9b5a9f"},"cell_type":"markdown","source":"## Pandas\n- Part of NumFOCUS\n- Used for python data analysis\n\nhttps://github.com/pandas-dev/pandas/blob/master/doc/cheatsheet/Pandas_Cheat_Sheet.pdf\n\nhttps://numfocus.org/sponsored-projects"},{"metadata":{"trusted":true,"_uuid":"1f0c3ad6c8d8750db5f02b5129687980a9981abc"},"cell_type":"code","source":"Image(\"../input/images2/images/images/pandas_cheetsheet.png\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f81c99cca0ad7d1662f084c4279e460aabbc2177"},"cell_type":"markdown","source":"Let's dig into our data!"},{"metadata":{"_uuid":"9f40a99043b9d80eaf3e9fe884e2400de1c32e74"},"cell_type":"markdown","source":"**Import Student Dataset:**\n\nhttps://www.kaggle.com/aljarah/xAPI-Edu-Data\n\n- Data already attached to this kernel so no need to import :)\n\nCitation:\n* Amrieh, E. A., Hamtini, T., & Aljarah, I. (2016). Mining Educational Data to Predict Studentâ€™s academic Performance using Ensemble Methods. International Journal of Database Theory and Application, 9(8), 119-136.\n\n* Amrieh, E. A., Hamtini, T., & Aljarah, I. (2015, November). Preprocessing and analyzing educational data set using X-API for improving student's performance. In Applied Electrical Engineering and Computing Technologies (AEECT), 2015 IEEE Jordan Conference on (pp. 1-5). IEEE."},{"metadata":{"trusted":true,"_uuid":"02f378f32856a2e0f6b663f7e6901c8a7ab925c5"},"cell_type":"code","source":"school_data = pd.read_csv('../input/xAPI-Edu-Data/xAPI-Edu-Data.csv') # pandas has lots of ways to read in data!","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e49eb994e280603e2835d90a46ec72b3bb3fcca8"},"cell_type":"code","source":"school_data.head() #shows top 5 lines","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"64945e6ba2adfad7b3af431974d6efb6e3ec9127"},"cell_type":"code","source":"Image(\"../input/images2/images/images/xapi_data_attributes.png\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3c428cdd47127304d931f838da0735d01aca3b06"},"cell_type":"code","source":"Image(\"../input/images2/images/images/xapi_class_outputs.png\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c858644f83073cb43f6e5cff440bea3daeac6308"},"cell_type":"code","source":"type(school_data) # get the type of data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b2b1517960109c028109f093c5ef67a549220e7c"},"cell_type":"code","source":"type(school_data.gender)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d46df2d7ab583ae80851bd7673e3854e27421697"},"cell_type":"code","source":"school_data.iloc[0,3:5] #just like numpy indexing","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1e5932f93231c21d7b88c12a7dd63be888bf8713"},"cell_type":"markdown","source":"Caution: Pandas has 2 basic methods of indexing, \"loc\" and \"iloc\" - \n* loc - gets rows/columns with particular labels from the index\n* iloc - gets rows/columns with positional index"},{"metadata":{"trusted":true,"_uuid":"266624213b2c06e776940071e87dfc849af1e2b7"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7de86c51ce23febe0860b4ddd7154bb954cb6a40"},"cell_type":"code","source":"school_data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5671dd46b15e6d165ae457cf018867e280f6875d"},"cell_type":"code","source":"print(school_data.StageID[0])\nprint(school_data['StageID'][0])\nprint(school_data.loc[0, 'StageID'])\nprint(school_data.iloc[0, 3])\n\nprint(\"Caution: Indexing slightly differently will return a Series: school_data.iloc[0, 3:4]\")\nprint(school_data.iloc[0, 3:4])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8ffae22484a660d9af218c7b2402956f6430c24f"},"cell_type":"code","source":"type(school_data.iloc[0, 3])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7fe4a7481a4fecc36b5a9a8469f568fd26de1607"},"cell_type":"code","source":"type(school_data.iloc[0, 3:4])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"786a728e19409b4bf82ebe994915a636f9aff386"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d6cd85c4cdd7ca5c8c34df687ec315ffad6b43ef"},"cell_type":"code","source":"# Filter the data:\nschool_data[(school_data.gender=='F')].head() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"254ac880096e6a08a8dc949da87ff21702104cbb"},"cell_type":"code","source":"# Multiple filters\nschool_data[(school_data.gender=='F') & (school_data.Topic=='IT')].head() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"58a1fecf8ffdecb3205460570b55f0976077544f"},"cell_type":"code","source":"school_data[(school_data.gender=='F')].loc[5:9,:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ed14c968f77b44fe847280b91460290b95715395"},"cell_type":"code","source":"school_data[(school_data.gender=='F')].iloc[0:3,:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"17135689a331d9670a5526633f4551615dd4ff0a"},"cell_type":"code","source":"# Count the values in a column:\nschool_data.gender.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5f719f3fe453e88bfcf57c23ce5a1dd5e81b3a2c"},"cell_type":"code","source":"# Group by and count:\nschool_data.groupby(['StageID', 'Topic']).count()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"091fb822dc42ba815e41db24bed4a25b701d0fca"},"cell_type":"code","source":"# Since we are just counting the number of rows, select one of them and sort \nschool_data.groupby(['StageID', 'Topic']).gender.count().sort_values(ascending=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"70f35c6492946342a3cbf2ab4abbe8789a75f540"},"cell_type":"code","source":"school_data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8c8e7b2456caa5e1b47e9fd133f7a8d98034b3c7","_kg_hide-output":false,"collapsed":true},"cell_type":"code","source":"# Get statistics on numeric column and sort by the mean of raisedhands\nschool_data.groupby(['StageID', 'Topic']).raisedhands.describe().sort_values(by='mean', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5ab0a8c93cb8f5c22745bf22b558faa79845a1b8"},"cell_type":"markdown","source":"- Exercise: For all the kids in middle school (school_data.StageID=='MiddleSchool'), which subject (Topic) is taken the most?\n- Exercise: Do boys or girls in Middle school have the highest average Discussion ?"},{"metadata":{"trusted":true,"_uuid":"b6ef4d8205972582afbe7258357458903964488f"},"cell_type":"code","source":"# Exercise:\nschool_data[(school_data.StageID=='MiddleSchool')].groupby('Topic').count()\nschool_data[(school_data.StageID=='MiddleSchool')].Topic.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"167b1f19ca15590ec156c15538ed4e674e722a10"},"cell_type":"markdown","source":"### Explore the data more with pandas and seaborn:"},{"metadata":{"trusted":true,"_uuid":"a86e348cf048976bef14e349225777724990a2ba"},"cell_type":"code","source":"school_data.info(verbose=True, null_counts=True) # get information about the dataframe, how many nulls, and datatype","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a1ab6e24985719dddf0dd90d074d487bd94ef4f7"},"cell_type":"code","source":"school_data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bccc3cf238f4e25fb0f6b7aa09d6cd3dac3608d5"},"cell_type":"code","source":"## My method of taking an initial glance at the columns:\nfor each_column in school_data.columns:\n    print(\"Column = \", each_column)\n    print(school_data[each_column].describe()) #describe gives summary stats for numeric columns and count/unique/top value for strings\n    if school_data[each_column].nunique() < 50: # nunique get the number of unique values for the column\n        print(\"Counts of {} :\".format(each_column)) # can use format to format the string\n        print(school_data[each_column].value_counts())\n    print()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"137b27251a22f56ea90892e5b8cc9a75a3f6ef11"},"cell_type":"code","source":"## New packages, pandas-profiling and pandas_summary","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6f0d0164b42e98ac722cceed54ca1f465531d55f"},"cell_type":"code","source":"school_data.shape # 480 rows and 17 columns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"426228ead7f03a8619e02463f9253a412d676050"},"cell_type":"markdown","source":"Exercise: Identify the maximum value for all the numerical columns. Which categorical column has the most unique values? "},{"metadata":{"trusted":true,"_uuid":"44ad6ddf85d2b80814b34e414529d397486bae4d"},"cell_type":"code","source":"# Exercise:\nschool_data.max()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c462870bef77602d8d418fa3904d5b97a8e2de28"},"cell_type":"markdown","source":"Caution: When looking at your dataset, check to see how big it is and select methods that are appropriate for the size.  Beware of overfitting when working with small datasets.\n\nResources: \n- https://medium.com/rants-on-machine-learning/what-to-do-with-small-data-d253254d1a89\n- https://datascience.stackexchange.com/questions/19925/what-are-the-most-suitable-machine-learning-algorithms-according-to-type-of-data"},{"metadata":{"_uuid":"b195aae18b99b24571ec6c29b104292f8f0a81b1"},"cell_type":"markdown","source":"Alternative ways to explore data !  Additional profiling, and visualization with pandas_summary and pandas_profiling.\n"},{"metadata":{"trusted":true,"_uuid":"f99cb21d365f4ef6279472f241cf13937db4ec82"},"cell_type":"code","source":"from pandas_summary import DataFrameSummary # https://github.com/mouradmourafiq/pandas-summary","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c11060a3b7956321da93fa11a3bcf82cc5365a42"},"cell_type":"code","source":"school_data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e38e1a48df0b54216822957b949f0dfb8223d7a9"},"cell_type":"code","source":"## Explore with pandas","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0d72865d279dd3f0aa6bf2b11f06f64df5d01027"},"cell_type":"code","source":"dfs = DataFrameSummary(school_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0ab4f5cc3b384ff34ab5c764669763c2f07b8c86"},"cell_type":"code","source":"dfs.columns_types #one step further than pandas.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3b1a2fbb7f4afd098a88fdd07a35743b66015bc2"},"cell_type":"code","source":"dfs.columns_stats","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d941c308d85371abe1b103a361db3046fbd61ecd"},"cell_type":"code","source":"import pandas_profiling","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6e430f785e65a5e2b75dbe78897b41974ca4e935"},"cell_type":"code","source":"pandas_profiling.ProfileReport(school_data)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6cd3e1e72ed29bb0a04dfaf9a7ffd0f4e60d6bd1"},"cell_type":"markdown","source":"Caution: Generally we would want to deal with duplicate rows, here we assume that 2 students have the same data.  Data set would be better if it had some kind of studentID.\n\nResource: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop_duplicates.html"},{"metadata":{"_uuid":"47ba2e4be0ad2d561be55d13cdfeb00af17bb814"},"cell_type":"markdown","source":"### Visualize the data:"},{"metadata":{"_uuid":"1cefa32e6e5daaee159dbe0cc733331ac6e22055"},"cell_type":"markdown","source":"Caution: Always important to visualize and not just rely on sample statistics! \n\nResources: \n- https://seaborn.pydata.org/examples/anscombes_quartet.html\n- HOT OFF THE PRESS: https://medium.com/@plotlygraphs/introducing-plotly-express-808df010143d - Plotly express!\n"},{"metadata":{"trusted":true,"_uuid":"59ed2281ae71b17ddca063dfd8b9631086e40d9f"},"cell_type":"code","source":"%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"60de852087c7d59837819abeec5635ad1605b6a4"},"cell_type":"code","source":"sns.set(style=\"ticks\")\n\n# Load the example dataset for Anscombe's quartet\ndf = sns.load_dataset(\"anscombe\") #same sample statistics, and regression line for 4 different datasets\n\n# Show the results of a linear regression within each dataset\nsns.lmplot(x=\"x\", y=\"y\", col=\"dataset\", hue=\"dataset\", data=df,\n           col_wrap=2, ci=None, palette=\"muted\", height=4,\n           scatter_kws={\"s\": 50, \"alpha\": 1})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8d0488dcc5f57852157dcc7926a8a1b09d0b11ca"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fb247d31c6aa2badf6a2f6f1299e33fa28951abc"},"cell_type":"code","source":"# Seaborn : http://seaborn.pydata.org/index.html\nsns.set(style=\"ticks\")\nsns.pairplot(school_data, hue=\"Class\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"acb88b3fa8251f4a3585051850350ab5ee0b1349"},"cell_type":"code","source":"school_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ab6ecdb3e32a61cece7c124a510a682eb5872ca0"},"cell_type":"code","source":"for each in school_data.columns:\n    if school_data[each].dtype=='object':\n        sns.catplot(x=each, y=\"raisedhands\", hue=\"Class\", kind=\"swarm\", data=school_data)\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"610fc89bf839a3eb57e990fa6b5d2e993397d5e1"},"cell_type":"markdown","source":"Exercise: Look at the data with respect to another numeric variable (i.e y='VisITedResources').  Any interesting insights?"},{"metadata":{"trusted":true,"_uuid":"05c068fbafe500a1a8cbac3d9bb5153cc4bfcddb"},"cell_type":"code","source":"# Exercise:","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cf69ee7575bf04c45c59f2e200cb96565323c201"},"cell_type":"code","source":"school_data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bee0d76ead6c1a5280794d9f6c294118e1c21bc6"},"cell_type":"code","source":"school_data.gender.value_counts().plot(kind='bar') # Quick view of the data:","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"248387daffb6bf4749c83bd05262e4784b8c90a4"},"cell_type":"code","source":"school_data.AnnouncementsView.plot(kind='hist')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"321f494a223642a11ab7733fd93347816f2ae013"},"cell_type":"code","source":"school_data.AnnouncementsView.hist() # Another way to quickly plot","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d1f03609651e0d3633b4ed55bd0e2fdccc266471"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"d93004b2882ff72fa7848c2d50bc05f51774f016"},"cell_type":"markdown","source":"## Machine Learning:"},{"metadata":{"trusted":true,"_uuid":"1c339ff7ae9952a7177ec5ab18df8d8619d843c2"},"cell_type":"code","source":"Image(\"../input/images2/images/images/types_of_ml.png\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"926142177845e388be69ff84c4e01c6c0ffbf918"},"cell_type":"markdown","source":"\n\nResource: https://www.researchgate.net/figure/Examples-of-real-life-problems-in-the-context-of-supervised-and-unsupervised-learning_fig8_319093376\n\n\nNo free lunch! \n* \"All models are wrong but some are useful\"\n* Bias-Variance tradeoff\n* Curse of dimensionality\n\n        "},{"metadata":{"trusted":true,"_uuid":"2a57d5efee0b9d328752e20f6c226085d37427c2"},"cell_type":"code","source":"Image(\"../input/images2/images/images/bias_variance_tradeoff_reg.png\")\n# Source: http://scott.fortmann-roe.com/docs/BiasVariance.html","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2a57d5efee0b9d328752e20f6c226085d37427c2"},"cell_type":"code","source":"Image(\"../input/images2/images/images/overfitting_under_classification.png\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a535469e3994580e96fc0a05f6631f428d0253b7"},"cell_type":"markdown","source":"\n"},{"metadata":{"_uuid":"8a20d3de5e2eb59d66be2fe32001f0c3481a2b76"},"cell_type":"markdown","source":"## Data Preprocessing:\n* Models require numeric data (most of the time)\n* Potential Steps:\n    * Clean up outliers\n    * Decide how to deal with missing values (i.e. impute missing values, remove rows or columns) \n    * Identify multicollinearity (and remove if neccessary)\n    * Scale or normalize (if neccessary)\n    * Encode categoricals into numeric (if neccessary, many ways to do this)\n\nCaution: Important to note the assumptions of your algorithm so you preprocess correctly!\n\nResources:\n- https://hackernoon.com/what-steps-should-one-take-while-doing-data-preprocessing-502c993e1caa\n- https://towardsdatascience.com/preprocessing-with-sklearn-a-complete-and-comprehensive-guide-670cb98fcfb9"},{"metadata":{"_uuid":"bcb5952a8265bb0d30893e6c91428dff48e5aa5f"},"cell_type":"markdown","source":"#### Missing Values"},{"metadata":{"trusted":true,"_uuid":"2ff0833f29460d448ef6d15d86c2ab5a2011e118"},"cell_type":"code","source":"school_data.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"14ac5f662be5551b2b65d719c869971d38f1c451"},"cell_type":"markdown","source":"Caution: We do not have any missing data, need to clean up if we did with imputing or dealing with rows/columns.\n\nResource: Preprocessing - https://scikit-learn.org/stable/modules/preprocessing.html"},{"metadata":{"_uuid":"dedf803b9ddb64b276c790a298acc4a97f5bb2a6"},"cell_type":"markdown","source":"#### Convert categoricals into numeric\nQuick way to convert categoricals into numeric - \"get dummies\""},{"metadata":{"trusted":true,"_uuid":"496cac6c5e5c8d860d2ec951451e8f092f3b62ea"},"cell_type":"code","source":"school_data.GradeID.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a5ce92ac4048645e3bc2f7021da67a7faca1a750"},"cell_type":"code","source":"pd.get_dummies(school_data['GradeID']).head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"23c4e1e569c26655c8f5b290cff7905f76f365d7"},"cell_type":"code","source":"school_data.GradeID.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dd89bae12897068c6027273a210a9b434044cf69"},"cell_type":"code","source":"school_data_dummies_df = pd.get_dummies(school_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"79aeb0f16a68361999afb795c0484df6e75f9e0b"},"cell_type":"code","source":"school_data_dummies_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c084d416cd50a5a9ae86bc5448dad2cfab1566c7"},"cell_type":"code","source":"school_data_dummies_df.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f0c9a94d5fefe306707338ef21e4430f1a6dcb98"},"cell_type":"code","source":"corr = school_data_dummies_df.corr()\ncorr.style.background_gradient(cmap='coolwarm')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"53da622a1f942a29231f22fbfac18f0f703b207e"},"cell_type":"code","source":"import seaborn as sns\ncorr = school_data_dummies_df.corr()\nsns.set(rc={'figure.figsize':(18,13)})\n#sns.heatmap(corr, \n #           xticklabels=corr.columns.values,\n #           yticklabels=corr.columns.values) # original didnt show colors that made it easy to see the correlations\n\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, cmap='coolwarm', vmax=1, center=0,\n            square=True, linewidths=.5,  xticklabels=corr.columns.values,\n            yticklabels=corr.columns.values)\n\n# https://seaborn.pydata.org/examples/many_pairwise_correlations.html","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f7c6cd59d31d7a7ac0bdd626d68a78994f791c6f"},"cell_type":"markdown","source":"Exercise: What columns look redundant?"},{"metadata":{"_uuid":"ad93872afa821d18cf9c30a70c0f9dc0981ec5fa"},"cell_type":"markdown","source":"## Sci-kit Learn (sklearn)\n* Considered the \"gold standard\" interface to transforming, and fitting models\n* Spark's ML Lib interface is modeled after it\n* fit_transform, fit_predict\n* Can create pipelines to transform, preprocess, clean, and fit models\n\n"},{"metadata":{"_uuid":"a61bd86e6427fc032f318a03eb3521d19685ae0f"},"cell_type":"markdown","source":"#### Example of preprocessing data with sklearn\nPrimarily done with \"fit_transform\"\n"},{"metadata":{"trusted":true,"_uuid":"fdaa294d817f9ba1e7f409aea770ebf0d6d1f201"},"cell_type":"code","source":"from sklearn import preprocessing","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"44cf0cb03ffefa5e5d9b0221cf986bef22a40598"},"cell_type":"code","source":"ohe = sklearn.preprocessing.OneHotEncoder() # create a one hot encoding object","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ac93bcb4ec37656275fd7d26ca10c0157b400ff2"},"cell_type":"code","source":"ohe.get_feature_names()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3d60801a1b93bc93db1344460d5abc2082451b03"},"cell_type":"code","source":"ohe_data = ohe.fit_transform(school_data) # fit_transform, fit will modify the ohe object","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ffdd3ea63bd52c7d74e76cc060af8a241231f319"},"cell_type":"code","source":"ohe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6989feef2d338a7b38c2a13a7820d4ef11c27ce9"},"cell_type":"code","source":"# Get the feature names:\nohe.get_feature_names()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"20d2f8ed16df6aeab64ff2e547fa9dad3914773c"},"cell_type":"code","source":"ohe_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d20ed508d039cea0f118dc632098bcb1d9dc9850"},"cell_type":"code","source":"ohe.get_feature_names()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bca43669ec02d8c60e6cda620852ccaabf00aae9"},"cell_type":"markdown","source":"Notice that converted all the numeric columns into categoricals as well due to their discrete nature.\n"},{"metadata":{"trusted":true,"_uuid":"8c0d958ab20370a6cd4b030b46b8ef789551a4e5"},"cell_type":"code","source":"school_data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"43f95a5e10c22bdb85ad305cbb006055cb8b16d4"},"cell_type":"code","source":"school_data.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b14cb624fec622497a5df8d00de84fcb868483ca"},"cell_type":"markdown","source":"Caution: Calling \"fit\" or \"fit_transform\" on object \"ohe\" will modify the metadata!"},{"metadata":{"_uuid":"f14f8cf4c4353e51ce91a96777845e3b9705f3c1"},"cell_type":"markdown","source":"# Unsupervised Learning\n\nClustering and dimensionality reduction are 2 common approaches to unsupervised learning.\nUnsupervised learning can be a part of exploratory data analysis.\n\n* Find meaningful relationships\n* Low dimensional representations for visualization or compression\n\nResource: https://web.stanford.edu/class/stats202/content/lec2.pdf\n\n## Clustering\n* Clustering is to group the data\n* Some algorithms are: KMeans, heirarchical clustering, DBSCAN, etc\n* Downside is that it is difficult to evaluate the model\n\nCaution: Make sure to look at the details of your algorithm to identify the assumpions of the expected input data.  \n\nResource: https://www.r-bloggers.com/k-means-clustering-is-not-a-free-lunch/\n\nhttps://web.stanford.edu/class/stats202/content/lec2.pdf\n\n"},{"metadata":{"trusted":true,"_uuid":"3598efd76f00da8d3c1b69e7d8f3917b7ba6ba4c"},"cell_type":"code","source":"Image(\"../input/images2/images/images/wht_is_a_cluster.png\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d9d35310e2a09523c9c23e7e617a43f4c4f0cc68"},"cell_type":"markdown","source":"## KMeans Clustering\n* Simple clustering algorithm\n* Can handle very large datasets\n\nCaution: Make sure to look at the details of your algorithm to identify the assumpions of the expected input data\n\n* Hands on visualization of how it works: http://web.stanford.edu/class/ee103/visualizations/kmeans/kmeans.html"},{"metadata":{"_uuid":"aa1b83c87b1d40a41d359f518de4dac4ce0a2020"},"cell_type":"markdown","source":"Lets look at a subset of our data to dig into clustering.  To do similar one hot encoding as pandas get_dummies, need to use ColumnTransformer."},{"metadata":{"trusted":true,"_uuid":"21900f3dbd10dcea9a2559f76afe55a169a2f048"},"cell_type":"code","source":"from sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"740375f5e0546759e92d8ff0e386ff9aa3372cfe"},"cell_type":"code","source":"subset_features = ['GradeID','StudentAbsenceDays', 'raisedhands',\n       'VisITedResources', 'AnnouncementsView', 'Discussion']\n\nnumeric_features = ['raisedhands',  'VisITedResources', 'AnnouncementsView', 'Discussion']\n\ncategorical_features = ['GradeID', 'StudentAbsenceDays']\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('onehot', OneHotEncoder(handle_unknown='ignore'), categorical_features), ('nothing', 'passthrough', numeric_features)])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8254d69378df75cc4328dfc5448b9543f165bc88"},"cell_type":"code","source":"ohe_data = preprocessor.fit_transform(school_data[subset_features])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"09e89e31bf99f65a7b199969f0cc7fa36672168f"},"cell_type":"code","source":"ohe_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"72919cec8fa9058762e0175f072c53fd8dfe6dad"},"cell_type":"code","source":"preprocessor.named_transformers_['onehot'].get_feature_names() #Get the feature names of the transformer called ohe_transformer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8a533475088d2fa3dd98d1b045021245397c7ee5"},"cell_type":"code","source":"ohe_features = list(preprocessor.named_transformers_['onehot'].get_feature_names()) + list(numeric_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3aad71316b82fdc0c7d5259ca55b0af33c3d0a07"},"cell_type":"code","source":"ohe_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"99de1690ed54ed5f14be54302d1e5f5f9f8fc744"},"cell_type":"code","source":"ohe_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"49055a4d2ca569ddfc43b7cad933b59654967bb7"},"cell_type":"code","source":"ohe_data","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8cbbf1045993e720c8d451327dc5a0c3314e0183"},"cell_type":"markdown","source":"KMeans groups points together in the 16 dimensional space using Eucliean distance - anything concerning about this data set?"},{"metadata":{"_uuid":"62af46c920f33b39c3a737eff8a8e24dc04ae1f2"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"91eb596db16b209b5d3ad889a59b5ccceb7a88b6"},"cell_type":"markdown","source":"Let's look back at our data set and pull out a different subset:"},{"metadata":{"trusted":true,"_uuid":"53fb8a921ee4dfdcb1c4d8608f693a8d5f69deab"},"cell_type":"code","source":"numeric_school_data = school_data[numeric_features]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"25888a0fa76609d064f4a2a4d3bc7597ef54b87b"},"cell_type":"code","source":"numeric_school_data.mean(axis=0)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"54d5d7bcbad5063fcf9a2cc23570fb62b96f8426"},"cell_type":"markdown","source":"## KMeans Clustering\n\nCaution: Need to scale the data for kmeans to work!\nCaution: Make sure to look at the details of your algorithm to identify the assumpions of the expected input data\n\nKMeans: \n- shperical clusters\n- evenly sized clusters\n- need to provide K\n\nResources:\n- https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_assumptions.html\n- https://hdbscan.readthedocs.io/en/latest/comparing_clustering_algorithms.html\n- https://stats.stackexchange.com/questions/89809/is-it-important-to-scale-data-before-clustering\n\n\npic from http://bioinformaticsinstitute.ru/sites/default/files/preprocessing_unsupervised.pdf\npics from https://www.r-bloggers.com/k-means-clustering-is-not-a-free-lunch/\n\n\n"},{"metadata":{"trusted":true,"_uuid":"32e4e8a141ee660cd7ed4a9d7c97079cbc0b50d6"},"cell_type":"code","source":"Image(\"../input/images2/images/images/unevenly_sized_kmeans.png\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ea51f18cb8c8ec1d664654208d3bc35d76dbe766","trusted":true},"cell_type":"code","source":"Image(\"../input/images2/images/images/kmeans_nonspherical.png\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"69014ccfded0b4b1e1945eb71eac693863d8c71c"},"cell_type":"code","source":"from sklearn import cluster","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bc0d089bf86a9a9eddf0297192de82af7c8efda5"},"cell_type":"code","source":"from sklearn import decomposition","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b6642dbc85afc8fae258fa710391e9ba9d2d24c0"},"cell_type":"code","source":"ss = sklearn.preprocessing.StandardScaler()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"effab63d44396fa2d295162be48bf5ddedc4e037"},"cell_type":"code","source":"ss_data = ss.fit_transform(numeric_school_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6e6bdfedcae5794951aae148f40e41dbc4665713"},"cell_type":"code","source":"numeric_school_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"29c342032c7f21e4036ef61ec5026c27a054bbc3"},"cell_type":"code","source":"ss.mean_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0b3f90e8b4054da4863493f6ea6d98f36a0190d4"},"cell_type":"code","source":"ss_data.mean(axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d28543e69a54a95019f9e7ec8a8f6b086d646b5e"},"cell_type":"code","source":"kmeans_scaled = sklearn.cluster.KMeans(n_clusters=3, random_state=42, n_jobs=-1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"994fb56724cd81216d31cd37f92d6b35eba85f92"},"cell_type":"markdown","source":"Caution: To ensure reproducibility, check to see if your function accepts a random_state, and make sure to set it manually otherwise your results will change each time you re-run the function!"},{"metadata":{"trusted":true,"_uuid":"6deabcba4858a8a546274690bb2658a61f303ed5"},"cell_type":"code","source":"kclusters_scaled_only = kmeans_scaled.fit_predict(ss_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e448311742ae2160b05aa6d2aaeb8b854c20f7a9"},"cell_type":"code","source":"kmeans_scaled.cluster_centers_.shape #cluster_centers_ attribute has values for the cluster centers, 3 clusters x 4 features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"984af022846392ba9fa3d03050c0d0601b6015b7"},"cell_type":"code","source":"pd.Series(kclusters_scaled_only).value_counts() # How many in each cluster","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"69d85ee12e54a3c72187a5ee85e6f50594b618fb"},"cell_type":"code","source":"pd.Series(kmeans_scaled.labels_).value_counts() # Alternative way to find cluster labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"052eafbdcb84624b0480e3860f8ff57d4062b350"},"cell_type":"code","source":"school_data[kclusters_scaled_only==0][numeric_features].head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eb3a432f142ccc96d1e640fe15b68d8fbbf686fa"},"cell_type":"code","source":"dict(zip(numeric_features, kmeans_scaled.cluster_centers_[0]))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1827e9290880aa4b75d338a1c94ac696278c19ea"},"cell_type":"markdown","source":"What does this mean?"},{"metadata":{"trusted":true,"_uuid":"ec5a9f8123d8b641c52148e0111531d1ab92d95d"},"cell_type":"code","source":"# Need to look at what the data looked like before it was scaled\ndict(zip(numeric_features, ss.inverse_transform(kmeans_scaled.cluster_centers_[0]))) \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2e3f66bdafbe73df6992f59b46d1061ad1652b96"},"cell_type":"code","source":"dict(zip(numeric_features, ss.inverse_transform(kmeans_scaled.cluster_centers_[1]))) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"235907a4f0432aa51c111fe6a833f260795525b4"},"cell_type":"code","source":"dict(zip(numeric_features, ss.inverse_transform(kmeans_scaled.cluster_centers_[2]))) ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b84bbb3aad91a394049b4cab1d2c889c74a55f1c"},"cell_type":"markdown","source":"Difficult to evaluate, but there are clustering evaluation metrics out there."},{"metadata":{"trusted":true,"_uuid":"9123d451293cd3a4188b81d4058abe8a8a35b8e3"},"cell_type":"code","source":"Image(\"../input/images2/images/images/clustering_metrics.png\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c69f00984f4bfdbb88b425cae035c080a0d47e0c"},"cell_type":"code","source":"Image(\"../input/images2/images/images/clustering_algos.png\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6128cd1a80d778aae4abc9c1d236778f8a2d7bb7"},"cell_type":"markdown","source":"Our dataset is mostly categorical - to leverage all of the data, we could use kmodes.\n\nResource: https://github.com/nicodv/kmodes"},{"metadata":{"_uuid":"8f4e064947bb1b1d2a10b0d2939fc3d0d5f3fb2a"},"cell_type":"markdown","source":"Using all the data means we would have 17 dimensions.  Not huge, but it's bigger than the 4 we used.\n\n### NO FREE LUNCH - Curse of Dimensionality\nRemember, KMeans is finding 'distance' as euclidean distance in an n-dimensional space.  Points are few in these high dimensional space."},{"metadata":{"trusted":true,"_uuid":"304214b330ed4462d9d3bb1b066900d35d9740b6"},"cell_type":"code","source":"Image(\"../input/images2/images/images/curse_of_dimensionality.png\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f4e064947bb1b1d2a10b0d2939fc3d0d5f3fb2a"},"cell_type":"markdown","source":"Resource: https://www.kdnuggets.com/2017/04/must-know-curse-dimensionality.html"},{"metadata":{"_uuid":"2071042c752d36cf112901ba851ab9adffc3a74b"},"cell_type":"markdown","source":"## Dimensionality Reduction\n* Reduce the dimensions of your input data\n* Remove multi-collinearity\n* Some approaches are: PCA, LDA, SVD, t-SNE, etc\n\nCaution: Some ML algorithms need the data to be non-collinear (i.e. generalized linear models) make sure to check and remove multi-collinearity!  \nCaution: Some dimensionality reduction techniques find linear relationships and others find non-linear relationships\n\nResources:\n- http://setosa.io/ev/principal-component-analysis/\n- https://scikit-learn.org/stable/auto_examples/preprocessing/plot_scaling_importance.html#sphx-glr-auto-examples-preprocessing-plot-scaling-importance-py\n- https://www.analyticsvidhya.com/blog/2018/08/dimensionality-reduction-techniques-python/"},{"metadata":{"_uuid":"951e2fd1c79ac4af74fe149f6113d3d0b68b037d"},"cell_type":"markdown","source":"## PCA/SVD\n\nRelationship - PCA(X) = SVD(X-mean(X))\n- Sklearn calculates PCA using SVD\n- Sklearn's PCA doesn't support sparse matrix\n- Use TruncatedSVD for sparse matrices\n- PCA and SVD creates new features which are linear transformations of original features\n- Basis of Latent Semantic Indexing Topic Modeling \n\n\nResources:\n- CLICK ME: http://setosa.io/ev/principal-component-analysis/\n- https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\n- Theoretical: https://arxiv.org/pdf/1404.1100.pdf\n- https://jakevdp.github.io/PythonDataScienceHandbook/05.09-principal-component-analysis.html\n- https://medium.com/data-design/how-to-not-be-dumb-at-applying-principal-component-analysis-pca-6c14de5b3c9d\n\n"},{"metadata":{"trusted":true,"_uuid":"22677ea10f1501c1618aded7f048a81fed3ef3b5"},"cell_type":"code","source":"Image(\"../input/images2/images/images/setosa_pca_pic.png\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"00f32c62f7f5b33834efdb5690a53794575aab9c"},"cell_type":"code","source":"svd = sklearn.decomposition.TruncatedSVD(n_components=2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"173ac08ecf91be25482942d246e94b8145c4ce93"},"cell_type":"code","source":"ss_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3f23ea07f3c89ca9fefadf7c1bac1fb856a1c761"},"cell_type":"code","source":"svdschool = svd.fit_transform(ss_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e2ac3a5ac53f6dc4f6da1b72fd65269680f5c52f"},"cell_type":"code","source":"svd.explained_variance_ratio_.sum() # With our 2 components, we have accounted for 83% of the variability","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"099079108f5da6d6b4c140abb1a885d59ed6f264"},"cell_type":"code","source":"svdschool.shape # number of data points x number of dimensions in our lower dim space","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2b79965388dcc00278efd6c123137173a05007d9"},"cell_type":"code","source":"svd.components_.shape # each new component as a linear combination of the original space ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b60b07d30d0373fa547b0562b6b402877e0b218c"},"cell_type":"markdown","source":"Let's cluster using our new data:"},{"metadata":{"trusted":true,"_uuid":"6886b7f4ab0b73eac5cae027f6261e49b920d9d5"},"cell_type":"code","source":"kmeans = sklearn.cluster.KMeans(n_clusters=3, random_state=42, n_jobs=-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a1667394bad708e4b2afbacb92d62d24863945e6"},"cell_type":"code","source":"kclusters_dimreduced = kmeans.fit_predict(svdschool)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"edd7e5bc4f7988f21048dfe55b1dce50225d973a"},"cell_type":"code","source":"pd.Series(kclusters_dimreduced).value_counts()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"542ea4f8912531f5fff1a502750825c58bd0fddd"},"cell_type":"code","source":"school_data[kclusters_dimreduced==0][numeric_features].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b9bb02e8f120dedd19b8e752c75114636912f0ff"},"cell_type":"code","source":"kmeans.cluster_centers_ # cluster centers, 3 clusters x 2 dimensions in SVD space","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1a7f86a4fd1e442c24101e8df41ba46606876a97"},"cell_type":"code","source":"svd_centroid = svd.inverse_transform(kmeans.cluster_centers_) # Just like before, we want to know what the center is in our original feature space","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"87f66a4fb409d334da32aaaddbd3a3179c935afa"},"cell_type":"code","source":"svd_centroid.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0a86c091a2188cb15da2937f92d7885518fdaf5e"},"cell_type":"code","source":"dict(zip(numeric_features, ss.inverse_transform(svd_centroid[0])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b66a4b51a3e307b17cffcc27ccb6e2b19e7e7514"},"cell_type":"code","source":"dict(zip(numeric_features, ss.inverse_transform(svd_centroid[1])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"42f1b3a6b09a549bff7f2a2c3ebceb4ce3572d42"},"cell_type":"code","source":"dict(zip(numeric_features, ss.inverse_transform(svd_centroid[2])))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"52509ca7d364f45ffbd3228ac6ede209947d5706"},"cell_type":"markdown","source":"#### Reduce dimensions for visualization:\nhttps://jakevdp.github.io/PythonDataScienceHandbook/05.09-principal-component-analysis.html"},{"metadata":{"trusted":true,"_uuid":"02e8b551991a53e186fefda9a37223e55b3a5c00"},"cell_type":"code","source":"ss_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5a84f1304ade8ddc9d2c91b902b6051bfcd7138b"},"cell_type":"code","source":"svdschool.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9828522b803996b920106f0f638e26b162005bf4"},"cell_type":"code","source":"pd.Series(kclusters_scaled_only).nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b66ac0cafc43af19b8ad3386b7578c03e5d5c7a2"},"cell_type":"code","source":"plt.figure(figsize=(8, 6))\nplt.scatter(svdschool[:,0], svdschool[:,1], c=kclusters_scaled_only.astype(float), edgecolor='none', alpha=0.5,\n            cmap=plt.cm.get_cmap('rainbow', pd.Series(kclusters_scaled_only).nunique()))\nplt.xlabel('component 1')\nplt.ylabel('component 2')\nplt.title(\"2d Visualization of Numeric School Data - KMEANS on Scaled Data (4 Dimensions )\")\nplt.colorbar()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c5cb84b19063d19cc16f538496e89ae49a074d84"},"cell_type":"code","source":"plt.figure(figsize=(8, 6))\nplt.scatter(svdschool[:,0], svdschool[:,1], c=kclusters_dimreduced.astype(float), edgecolor='none', alpha=0.5,\n            cmap=plt.cm.get_cmap('rainbow', pd.Series(kclusters_dimreduced).nunique()))\nplt.xlabel('component 1')\nplt.ylabel('component 2')\nplt.title(\"2d Visualization of Numeric School Data - KMEANS on Reduced Dimensional Data (2 Dimensions)\")\nplt.colorbar()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"22c1120c258e0d85fa4d0605af0e88edc226a484"},"cell_type":"markdown","source":"How different do these clusters look?"},{"metadata":{"_uuid":"f429513ba13bfa7c52b5b47eddb6b34f6f6f1d60"},"cell_type":"markdown","source":"Let's visualize how well the clusters look when colored by the Class (L, M, H)."},{"metadata":{"trusted":true,"_uuid":"0d80161e89f5deb6c3f0b1da8da66ea35f944255"},"cell_type":"code","source":"school_data.Class.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7b32a6df734feca0b4fc7a82af53fb38098d9b0e"},"cell_type":"code","source":"class_vals = school_data.Class.map({'L': 0, 'M': 1, 'H': 2})\n#le = sklearn.preprocessing.OrdinalEncoder(categories=np.array(['L', 'M', 'H']) )\n#le.fit(np.array(['L', 'M', 'H']).reshape(-1,1))\n#class_vals = le.fit_transform(school_data.Class.values.reshape(-1,1))\n\n# LabelEncoder and OrdinalEncoder didn't let me set the order, so used basic pandas instead :)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c73dbd951f58fadcc32e964cb6d0628ea6678961"},"cell_type":"code","source":"plt.figure(figsize=(8, 6))\nplt.scatter(svdschool[:,0], svdschool[:,1], c=class_vals.astype(float), edgecolor='none', alpha=0.5,\n            cmap=plt.cm.get_cmap('rainbow', school_data.Class.nunique()))\nplt.xlabel('component 1')\nplt.ylabel('component 2')\nplt.title(\"2d Visualization of Numeric Data Colored by True Class Labels\")\nplt.colorbar()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5308ff0413d088770bf5edd9c229bfad350316a7"},"cell_type":"markdown","source":"Resources: https://georgemdallas.wordpress.com/2013/10/30/principal-component-analysis-4-dummies-eigenvectors-eigenvalues-and-dimension-reduction/\n"},{"metadata":{"_uuid":"6aac35677017950aa7a7dcccbfed3ced47eec414"},"cell_type":"markdown","source":"Maybe our clustering would have been better if we used all our data and not just 4 numeric features.\n\nJust like KMeans has KModes for categorical, PCA on categoricals can be done with MCA (Multiple Correspondance Analysis)\n\nResource: \nhttps://github.com/MaxHalford/Prince (sklearn compatible package for categorical analysis)"},{"metadata":{"trusted":true,"_uuid":"61831cffa4d3033de672d21d5ff4fe0bed7115b5"},"cell_type":"code","source":"Image(\"../input/images2/images/images/clustering_metrics.png\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4b89cba61f995c1d1d224b2a98340adb8ea108c9"},"cell_type":"markdown","source":"Clustering metric exercise in extra credit section.\n\nResources:\n- https://scikit-learn.org/stable/modules/clustering.html#clustering-evaluation\n- https://scikit-learn.org/stable/modules/classes.html#clustering-metrics\n\n\n"},{"metadata":{"_uuid":"1a5880ec499ab5a740d20f4d3f5f14113eae8652"},"cell_type":"markdown","source":"### Let's get fancy!\n### Convert our categorical data to numeric using target encoding:\n* Also called \"mean encoding\"\n* This is advanced feature engineering\n* Easy to overfit"},{"metadata":{"trusted":true,"_uuid":"f3f10ec5935b7816b2b35da12685d15ce5ebcb08"},"cell_type":"code","source":"Image(\"../input/images2/images/images/categorical_encoders.png\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"154ef87b6337dbd42a03616eec1df124ff9f6994"},"cell_type":"code","source":"Image(\"../input/images2/images/images/mean_encoding.png\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1a5880ec499ab5a740d20f4d3f5f14113eae8652"},"cell_type":"markdown","source":"\nResource: \n- https://github.com/scikit-learn-contrib/categorical-encoding\n- Video: https://www.coursera.org/lecture/competitive-data-science/concept-of-mean-encoding-b5Gxv"},{"metadata":{"trusted":true,"_uuid":"6a528f0b416334f480c06883db302567b859cabf"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"05b2fc54d68640c109d6c60d886974dbfccdc8ea"},"cell_type":"code","source":"ce = category_encoders.TargetEncoder()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2ad483e020f3a78c3b05e941cc6f273985f21089"},"cell_type":"code","source":"# Go through the kmeans clustering again with the target encoding","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3b8831339a03535d4f97965ca9663a8b3ab22db0"},"cell_type":"code","source":"school_data_target_encoded_df = ce.fit_transform(school_data.drop('Class', axis=1), class_vals)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"28bf159df80b1fafd0283dca27723197eaf87f94"},"cell_type":"code","source":"school_data_target_encoded_df.gender.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bd0d08e1e43778df783a677d0b90b6f0b8734370"},"cell_type":"code","source":"school_data.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"51675133ab8ff2112e092b0b05755a29a6dfc605"},"cell_type":"code","source":"school_data_target_encoded_df.head(20)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ad26b5559c1ce2b5f16476d48c6668cbdd2806c4"},"cell_type":"markdown","source":"Exercise: Go through and redo the exercise of reducing the dimensions of this new data and doing clustering - how do the clusters look? "},{"metadata":{"_uuid":"4fb1f53a6e21be5a611202cc755a5e0a2df18faf"},"cell_type":"markdown","source":"## Supervised Learning:\n* Learning with labels provided.\n* Many classification methods\n"},{"metadata":{"trusted":true,"_uuid":"dd277e52ce8698d391db1e8c698d10d65e8abb50"},"cell_type":"code","source":"Image(\"../input/images2/images/images/classifier_comparison.png\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cc8a3fd68ab8295ec9c48dd167253d977c43d9f4"},"cell_type":"markdown","source":"## Getting started building a classifier:\n- Assuming data cleaning has been done ( outliers, missing, duplicates, etc)\n* Split data into training, validation, and test\n* Encode/scale/preprocess data as neccessary\n* Build baseline dummy classifier\n* Evaluate dummy classifier\n* Try other classifiers (make sure to preprocess the data as expected by the classifier)\n* Validate and evaluate other classifiers\n* Choose a classifier\n* Evaluate on the test set\n* Stop\n\nCaution: Split the data right away into training and test. Make sure to truly separate training and test data - dont have dirty data or data leakage ðŸ™‚\n\nCaution: If there is student specific data in the training and test, this will make our test set evaluation look more optimisitic.  Careful how the data is split. Think about data availability at the time of a prediction.\n\n"},{"metadata":{"_uuid":"a236f39434108cd3da563077d9c109f39e269cb0"},"cell_type":"markdown","source":"#### Split the data"},{"metadata":{"trusted":true,"_uuid":"2c1e5dd892d5de565eb8f6aacdf82feb96902205"},"cell_type":"code","source":"from sklearn import model_selection","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9925619bf5c136658c421f5bdc8db579769e7cd1"},"cell_type":"code","source":"X_train, X_test, y_train, y_test = model_selection.train_test_split(school_data.drop('Class', axis=1), \n                                                            class_vals, test_size=0.25, random_state = 42, stratify=class_vals)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2c681b2e8abe3c2a7715e325a53645c75582d4b3"},"cell_type":"markdown","source":"Caution: Stratify splits based on class imbalance instead of randomly.  Make sure to look at the class imbalance and deal with it appropriately based on the algorithm!\n\nResource: https://github.com/scikit-learn-contrib/imbalanced-learn \n\n"},{"metadata":{"trusted":true,"_uuid":"bae09013d0843a7b93d30b68b11eb5b22a02d627"},"cell_type":"code","source":"pd.Series(y_train).value_counts() #Check class imbalance","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cef23b487c783fbb2871384ddb4affa6da65ed6e"},"cell_type":"code","source":"ce = category_encoders.TargetEncoder() # Create TargetEncoder object","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"af08b0f1c3474900bf1a96758362b122437a8400"},"cell_type":"code","source":"X_train_numeric = ce.fit_transform(X_train, y_train) # Transform our categorical data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7676a9f74cf00e3498eeb229f05f2a83ae203532"},"cell_type":"code","source":"X_train_numeric.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1cee3117603cf2a2d215d2bcfeaa7da1ebea2774"},"cell_type":"code","source":"ss = preprocessing.StandardScaler()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3c24870ddf552e2284cc441f523e552363311b22"},"cell_type":"code","source":"X_train_scaled = ss.fit_transform(X_train_numeric) # Scale our data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a14be0a1169abb7574bb293dad948836a4795393"},"cell_type":"code","source":"X_train_scaled.shape ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"59296b9e0fbc8e13c2ec33f14118635a7c12cea9"},"cell_type":"markdown","source":"Get a baseline and then let's create more models to compare it to. \n\nTopics:\n- Model evaluation - how do we evaluate our model\n- Pipelines - makes it easy to preprocessing training and test data\n- Cross-validation - how do we choose hyperparameters and final model"},{"metadata":{"trusted":true,"_uuid":"d7e4bee029f415040b42effc9f7bd738f02fcefa"},"cell_type":"markdown","source":""},{"metadata":{"trusted":true,"_uuid":"fbc850402fa034cb33fbce9a73dd2753fb748145"},"cell_type":"code","source":"from sklearn import dummy # Make dummy clissifier as baseline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9ca8c40bd82722c5a9022c975b3c3517de0920e7"},"cell_type":"code","source":"dummy = sklearn.dummy.DummyClassifier(random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"faab1b800b00b3ce126265489078a1e532e4c5da"},"cell_type":"code","source":"dummy.fit(X_train_scaled, y_train) # Fit the model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cc2cecef47477fc8a56a4f5ee84e60c277280568"},"cell_type":"code","source":"dummy_predictions = dummy.predict(X_train_scaled) # Make predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e163e59c6d21fa6b3af6cfcae3b55339e323fa66"},"cell_type":"code","source":"dummy.score(X_train_scaled, y_train) # Score our training data set for now","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b63c613c72f259c9498b6518684de17b6dc8857d"},"cell_type":"markdown","source":"What does this score mean?\n\nCaution: Scoring on the training data set will be better than scoring on validation or test set.\n\nCaution: Model evaluation - how to evaluate? Accuracy? Never only use it and â€œif it seems too good to be true, it probably isâ€ .\n\n* e-book on Evaluating Machine Learning Models: https://www.oreilly.com/ideas/evaluating-machine-learning-models\n\nResource:\nhttps://machinelearningmastery.com/classification-accuracy-is-not-enough-more-performance-measures-you-can-use/\n\n\nSource: https://en.wikipedia.org/wiki/Precision_and_recall"},{"metadata":{"trusted":true,"_uuid":"4f4cf96348de113c22adbe47baa985f99572ae97"},"cell_type":"code","source":"Image(\"../input/images2/images/images/truepos_trueneg_wiki.png\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b37bbd127eea516ffe79708ba584d7320633cb46"},"cell_type":"code","source":"Image(\"../input/images2/images/images/precision_recall.png\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a99f7608ab2512d4327afff21196638269dfe92d"},"cell_type":"code","source":"Image(\"../input/images2/images/images/roc_curve_pic.png\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b63c613c72f259c9498b6518684de17b6dc8857d"},"cell_type":"markdown","source":"\nroc pic: https://machinelearningmastery.com/assessing-comparing-classifier-performance-roc-curves-2/\n\nSource: https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc_crossval.html\n\nSource: https://scikit-learn.org/stable/modules/model_evaluation.html\n\n- Multiclass metrics:\n\"weighted\" accounts for class imbalance by computing the average of binary metrics in which each classâ€™s score is weighted by its presence in the true data sample.\n\nCaution:\n- Many classifiers predict probabilities along with class labels, use ROC or precision-recall curves to find the best threshold for your classifier based on your problem!\n- Your model is always wrong, spend time thinking about what type of wrong you are comfortable with."},{"metadata":{"trusted":true,"_uuid":"2f58710f74ddaaa718a5ddb82367da56f9aacfaf"},"cell_type":"code","source":"from sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5668cebf624a0dd75347c770c6e85e5f58313104"},"cell_type":"code","source":"print(metrics.classification_report(dummy_predictions, y_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"09e64204bd1de33421329380972d06acb24258c2"},"cell_type":"code","source":"metrics.confusion_matrix(dummy_predictions, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ee629b90a8bcf888fe776b1f523fc8ac0bb3d8f7"},"cell_type":"code","source":"metrics.accuracy_score(dummy_predictions, y_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"03392641b06bb2c6fde23777bd3d5d3e70bf8bce"},"cell_type":"markdown","source":"Great - now we have a baseline model - let's go beat it!\n"},{"metadata":{"_uuid":"f818458c92536982f3b383288b9ac47850d203b9"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"b85a04edd29db7e4cf20d3305921da1a45982055"},"cell_type":"markdown","source":"### Model Selection\n* Can run through many ML algorithms\n* Loop through hyperparamters\n* Where's my validation set? \n\nResource: https://machinelearningmastery.com/difference-test-validation-datasets/\n\n* Even better - cross-validation!\n\nCaution:  The purpose of cross-validation is model selection, not model building!\n\n### Pipelines\n\nhttps://scikit-learn.org/stable/modules/cross_validation.html\n- Pipelines make it easy to store \"steps\" - preprocessing steps, encoding, model itself - easy to call the pipeline to transform our validation set in the same way\n* Caution: Preprocessing all the training data once prior to doing cross validation is a form of 'leakage' - where part of the solution has leaked into the training data,\n\n\n"},{"metadata":{"trusted":true,"_uuid":"6f0b57738e6ac5b2b3a70dca29cec24fc89fc154"},"cell_type":"code","source":"Image(\"../input/images2/images/images/pipelines.png\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"591e6f20d2343fb4aea9bd366563ce8da678f5bb"},"cell_type":"code","source":"Image(\"../input/images2/images/images/cross_validation.png\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"716132b3ae44efa786bbf712bb6fe90f5c64f712"},"cell_type":"code","source":"from sklearn.pipeline import Pipeline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"144020c8ea6d7e064137653db5ad77ce31c40860"},"cell_type":"code","source":"preprocessing_pipeline = Pipeline([('cat_encoder', category_encoders.TargetEncoder(return_df=False)), \n                                   ('scaler', preprocessing.StandardScaler())])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f22b4e533ad41d9f3baf631e2f1e3a43775cecb8"},"cell_type":"code","source":"from sklearn.model_selection import cross_validate, cross_val_score\nfrom sklearn.metrics import accuracy_score, f1_score ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7635fa1cb28f0b874976839534c3b2681d1480c8"},"cell_type":"code","source":"sklearn.metrics.SCORERS","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"24bfdff438bfc7ac352c44d2f18cdc0d8976d5b0"},"cell_type":"code","source":"from sklearn.pipeline import make_pipeline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"80ab1bdfe537002a33d1122e7e8d26976ebbf76a"},"cell_type":"markdown","source":"\n\n\n\n\n"},{"metadata":{"trusted":true,"_uuid":"4c52dedc338a70722a589469a8dace572eb732c8"},"cell_type":"code","source":"Image(\"../input/images2/images/images/stratified_k_fold.png\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ee19e0d7575b55660608552ed9df4789af6d5e33"},"cell_type":"markdown","source":"Resource: \nhttps://www.analyticsvidhya.com/blog/2018/05/improve-model-performance-cross-validation-in-python-r/\nhttps://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate"},{"metadata":{"_uuid":"6d559af6f6f2d39f3c2972dd5747261bdc030a90"},"cell_type":"markdown","source":"#### Logistic Regression:\n* Good one to start with\n* Fast to train and score"},{"metadata":{"trusted":true,"_uuid":"aded5c6580acf4e08ec49a2dfa4881c9da013b8c"},"cell_type":"code","source":"preprocessing_pipeline = Pipeline([('cat_encoder', category_encoders.TargetEncoder(return_df=False)), \n                                   ('scaler', preprocessing.StandardScaler())])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f0c8aa7273abe1c56a8e2efee71c6c5b6213cbd5"},"cell_type":"code","source":"lr_pipeline = make_pipeline(preprocessing_pipeline,\n                         sklearn.linear_model.LogisticRegression(class_weight='balanced', random_state=42, solver='sag', multi_class='multinomial', n_jobs=1))\nscoring = ['balanced_accuracy', 'f1_weighted']\nlr_cv_scores = cross_validate(lr_pipeline, X_train, y_train, scoring=scoring, cv=10, return_train_score=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fd3f670def9904da6a3acd0fe6ee4b4bc4a5a9ef"},"cell_type":"code","source":"lr_cv_scores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"56e9b6d8215717e6c522d033c311421c774db7ee"},"cell_type":"code","source":"for key in lr_cv_scores.keys():\n    print(\"%s: %0.2f (+/- %0.2f)\" % (key, lr_cv_scores[key].mean(), lr_cv_scores[key].std() * 2))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dc9efd939e041c71769e6a7a819924659a45b7c3"},"cell_type":"markdown","source":"Since we want to try out a bunch of models, lets make a function:"},{"metadata":{"trusted":true,"_uuid":"e199f3a43978f3335d8ba847036d49f097a100fc"},"cell_type":"code","source":"def cross_validate_and_print(preprocessing_pipeline, model_type):\n    cv=10\n    pipeline = make_pipeline(preprocessing_pipeline, model_type)\n    print(\"Preprocessing Steps : \", preprocessing_pipeline)\n    print(\"Model Type : \", model_type)\n    scoring = ['balanced_accuracy', 'f1_weighted']\n    cv_scores = cross_validate(pipeline, X_train, y_train, scoring=scoring, cv=cv, return_train_score=False)\n    print(\"Running {} Fold Cross Validation :\".format(cv))\n    for key in cv_scores.keys():\n        print(\"%s: %0.2f (+/- %0.2f)\" % (key, cv_scores[key].mean(), cv_scores[key].std() * 2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d0c4da8b2bcb7ae858a1d885eb32a446e82f19d2"},"cell_type":"code","source":"cross_validate_and_print(preprocessing_pipeline=preprocessing_pipeline, \n        model_type=sklearn.linear_model.LogisticRegression(class_weight='balanced', random_state=42, \n                                                           solver='sag', multi_class='multinomial', n_jobs=1))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"39eabfbec23ef1353accfaf785165132d6d7f921"},"cell_type":"markdown","source":"Exercise: Try also reducing the dimensions to 10 and see how LR changes.  (Hint: add TruncatedSVD to preprocessing_pipeline)"},{"metadata":{"trusted":true,"_uuid":"f9ee35f7e49c77f94e54262c2d1f680a1a94ed07"},"cell_type":"code","source":"#Exercise:","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4f1422ac1ee187939c319b845c8a2efee3051984"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"afef2b355b88120cdc3c9487944e3806641919e5"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"91f8ec8e8a9553077e16132885b556d6a1612cdf"},"cell_type":"markdown","source":"## Deep dive - Trees\n- Decision Tree\n- Random Forest\n- Gradient Boosted Trees (GBT)\n- One implementation of GBT - XGBoost - created 2016 - won a lot of kaggle competitions when it first came out. \n- Trees can handle multi-collinearity\n- Trees can handle categoricals\n- Caution: Tree based methods with feature importance will give more importance to variables with greater cardinality\n\nResources:\n- http://arogozhnikov.github.io/2016/06/24/gradient_boosting_explained.html\n- https://www.displayr.com/gradient-boosting-the-coolest-kid-on-the-machine-learning-block/\n- http://blog.kaggle.com/2017/01/23/a-kaggle-master-explains-gradient-boosting/\n- https://stackoverflow.com/questions/51601122/xgboost-minimize-influence-of-continuous-linear-features-as-opposed-to-categori\n- Brief history - http://www.ccs.neu.edu/home/vip/teach/MLcourse/4_boosting/slides/gradient_boosting.pdf\n- Categorical Boosting - https://towardsdatascience.com/catboost-vs-light-gbm-vs-xgboost-5f93620723db\n\nCLICK ME! http://www.r2d3.us/visual-intro-to-machine-learning-part-1/\n\n"},{"metadata":{"_uuid":"4f0dce1d41202252cbfd09e891aebf4eb43f4699"},"cell_type":"markdown","source":"### Tree Terminology:"},{"metadata":{"trusted":true,"_uuid":"5dd492545439e4b37c7f4da4e6ab05b359515053"},"cell_type":"code","source":"Image(\"../input/images2/images/images/tree_terminology.png\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4f0dce1d41202252cbfd09e891aebf4eb43f4699"},"cell_type":"markdown","source":"Source:\nhttps://www.analyticsvidhya.com/blog/2016/04/complete-tutorial-tree-based-modeling-scratch-in-python/"},{"metadata":{"_uuid":"cfd4589551e867b695bda9ff6d03b474232e10cb"},"cell_type":"markdown","source":"### Tree Creation\n- Maximum class separation\n- Pruning\n\nResources:\n- https://www.analyticsvidhya.com/blog/2016/04/complete-tutorial-tree-based-modeling-scratch-in-python/\nhttps://medium.com/deep-math-machine-learning-ai/chapter-4-decision-trees-algorithms-b93975f7a1f1\n"},{"metadata":{"trusted":true,"_uuid":"84d5d3f0d3cfc649357b8948eb0d3d0e215ec4bc"},"cell_type":"code","source":"Image(\"../input/images2/images/images/tree_pruning.png\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"38480761f98c45da6d12515ac7d12cf71f964334"},"cell_type":"markdown","source":"### Decision Trees\n- One tree\nhttps://en.wikipedia.org/wiki/Decision_tree_learning\n\nResources:\n- https://www.analyticsvidhya.com/blog/2016/04/complete-tutorial-tree-based-modeling-scratch-in-python/\n- https://bricaud.github.io/personal-blog/entropy-in-decision-trees/\n- https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\npic\n"},{"metadata":{"trusted":true,"_uuid":"9d1259f9e023bababc0c8b8ef5a8be50a514b4ab"},"cell_type":"code","source":"Image(\"../input/images2/images/images/decision_tree_wiki.png\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bdd99109accfa91881b9e5f17e2dab201f64fde4"},"cell_type":"code","source":"Image(\"../input/images2/images/images/dtc_variables.png\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"47b16b077e358295f593a2ecb2ee3eba6a1c90e1"},"cell_type":"markdown","source":"What do you think could be the pros and cons of using a decision tree?"},{"metadata":{"_uuid":"a587ec1d3ef4e2282462ab77a63056de0e00a27b"},"cell_type":"markdown","source":"### Random Forest\n- Forest of trees!\n- Also called 'ensemble' method - ensembling multiple decision trees\n- Randomly selects points to build each tree (can spcify with or without replacement)\n- Can use a subset of the features to reduce overfitting\n\n"},{"metadata":{"trusted":true,"_uuid":"7dee713a616aacf352f8960a3e25cfff6ca3d6a9"},"cell_type":"code","source":"Image(\"../input/images2/images/images/random_forest_simplified.png\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a587ec1d3ef4e2282462ab77a63056de0e00a27b"},"cell_type":"markdown","source":"Resource: https://github.com/andosa/treeinterpreter\nhttps://medium.com/@williamkoehrsen/random-forest-simple-explanation-377895a60d2d"},{"metadata":{"trusted":true,"_uuid":"8a518945aaaa61e9bd3208f3e0bc384c25170d14"},"cell_type":"code","source":"Image(\"../input/images2/images/images/linreg_vs_xgboost.png\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c6e3a716b28b6623e575f4914110f7f8598f1c73"},"cell_type":"markdown","source":"Resource:\nhttp://blog.kaggle.com/2017/01/23/a-kaggle-master-explains-gradient-boosting/"},{"metadata":{"_uuid":"837327c67288e3b376be6beda023cd8e55db257f"},"cell_type":"markdown","source":"### Gradient Boosted Trees\n* Also builds many trees, but learns from the mistake of the previous tree\n* Can use a subset of the features and subset of the data to reduce overfitting\n\nCLICK ME: http://arogozhnikov.github.io/2016/07/05/gradient_boosting_playground.html\n\nhttps://medium.com/mlreview/gradient-boosting-from-scratch-1e317ae4587d\n\nResource: Excellent  explanation of each paramter for XGBoost: https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/"},{"metadata":{"trusted":true,"_uuid":"472bd4dccfd2d060afecc45b0cafb4979a22dabb"},"cell_type":"code","source":"Image(\"../input/images2/images/images/ensembling_pic.png\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"844acb20bf72dabe5f3ee5ebf24d7ef35724ac04"},"cell_type":"code","source":"Image(\"../input/images2/images/images/bagging_vs_boosting.png\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"837327c67288e3b376be6beda023cd8e55db257f"},"cell_type":"markdown","source":"Resource:\nhttps://quantdare.com/what-is-the-difference-between-bagging-and-boosting/\nhttps://medium.com/mlreview/gradient-boosting-from-scratch-1e317ae4587d"},{"metadata":{"trusted":true,"_uuid":"2c6b99b4d5c922c71c633890f3c0f013a423490d"},"cell_type":"code","source":"from sklearn import tree","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"234429b4e2bb1564d62b174ad7a369c2415a0165"},"cell_type":"code","source":"preprocessing_pipeline = Pipeline([('cat_encoder', category_encoders.TargetEncoder(return_df=False)), \n                                   ('scaler', preprocessing.StandardScaler())])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"303c4d9f538e5f349bf8bc59193c4c16c5ed10da"},"cell_type":"code","source":"cross_validate_and_print(preprocessing_pipeline, tree.DecisionTreeClassifier(random_state=42, class_weight='balanced'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"abf49f7e8e68ac12e58e18143fe968819e4188d7"},"cell_type":"code","source":"from sklearn import ensemble","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"358d1a6b19bb7d92ef50f663a1f75cb843f33ab0"},"cell_type":"code","source":"forest = sklearn.ensemble.RandomForestClassifier(n_estimators=100, max_depth=10, \n                                                 n_jobs=-1, random_state=42, class_weight='balanced_subsample')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"46a9075d70567d4a3bf012eb1675a541d360671f"},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e4fc4909524152657fa7288168a7751d803d2ab2"},"cell_type":"code","source":"X_train_ss = preprocessing_pipeline.fit_transform(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bbc02fa504e49fbcef0601b6534742f622f38bec"},"cell_type":"code","source":"forest.fit(X_train_ss, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c25049c4539c01fd0bef53f57679284b67d37ce5"},"cell_type":"code","source":"forest.feature_importances_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"889369323d20788ad244895ed9c4897d00fc58a3"},"cell_type":"code","source":"forest.estimators_[0] # Can access each of the decision tree estimators - we have 100 - can use this for visualization","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9addaf10448e1190f82a42c61868d86a6cf68e27"},"cell_type":"code","source":"importances = forest.feature_importances_\n\nindices = np.argsort(importances)[::-1]\n\n# Print the feature ranking\nprint(\"Feature ranking:\")\n\nfor f in range(X_train_ss.shape[1]):\n    print(\"%d. feature %d = %s (%f)\" % (f + 1, indices[f], X_train.columns[indices[f]], importances[indices[f]]))\n\n# Plot the feature importances of the forest\nplt.figure()\nplt.title(\"Feature importances\")\nplt.bar(range(X_train_ss.shape[1]), importances[indices],\n       color=\"r\", align=\"center\")\nplt.xticks(range(X_train_ss.shape[1]), indices )\nplt.xlim([-1, X_train_ss.shape[1]])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9dd13de6ec4122235ff0885dc706c7feeccf8410"},"cell_type":"code","source":"print(metrics.classification_report(forest.predict(X_train_ss), y_train))  # What an awesome classifier! ?","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0558122ca41aa11979309d9bb1e7e81817fbc1e4"},"cell_type":"code","source":"rfc = ensemble.RandomForestClassifier(n_estimators=100, max_depth=10, n_jobs=-1, random_state=42, class_weight='balanced_subsample')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a3f245fc26eec56fb7e9ca0cdc1fd772c066a185"},"cell_type":"code","source":"cross_validate_and_print(preprocessing_pipeline, rfc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"23da8d08e7226d799a8be35a41f6a9199449451a"},"cell_type":"markdown","source":"And this is why we cross validate! So easy to overfit! "},{"metadata":{"_uuid":"856324fc4144a8cd2c53a6439a08e737012e4acf"},"cell_type":"markdown","source":"   Use min_samples_lead, min_samples_split, max_features to not overfit."},{"metadata":{"trusted":true,"_uuid":"67f79d807063066fff5f1ece8c6e48c38b182adb"},"cell_type":"code","source":"rfc = ensemble.RandomForestClassifier(n_estimators=100, max_depth=3, n_jobs=-1, random_state=42, min_samples_split=5, class_weight='balanced_subsample')\ncross_validate_and_print(preprocessing_pipeline, rfc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c5958bba2fdfe1a5f62d5f7ff8f3e4fa9f41b3c6"},"cell_type":"code","source":"import xgboost as xgb","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"048a2b4efdf41c124ffcb146ea9af8b2b530b5d1"},"cell_type":"markdown","source":"XGBoost has a scikitlearn api wrapper so we can call it the same way we call other classification algorithms."},{"metadata":{"trusted":true,"_uuid":"1265b553e08e4f563ae2c435f7829345cee0ff5b"},"cell_type":"code","source":"xgb.XGBClassifier()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9169b2cce4d2cf3f08902d4badf1a218caf32db6"},"cell_type":"markdown","source":"Need to change our objective because we have a multiclass problem.  \nResource:\nhttps://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\n"},{"metadata":{"trusted":true,"_uuid":"ec4ac48004ef4e3078bd299ad6d993f4486c8d15"},"cell_type":"code","source":"Image(\"../input/images2/images/images/xgboost_learning_task_parameter.png\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"13535ccc96c600fd0f5d82e6f2e32178824e19dd"},"cell_type":"code","source":"# Fit the model\nxgb_model = xgb.XGBClassifier(max_depth=5, random_state=42, \n                              subsample=0.8, colsample_bytree=0.8, n_jobs=-1, objective='multi:softmax').fit(X_train_ss, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"49fff1fb6dd21444da951de7847853aa0a67c2e0"},"cell_type":"code","source":"# feature importance\nprint(xgb_model.feature_importances_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2d848977680fe72e733d6a80d3d192a8fec2d168"},"cell_type":"code","source":"from xgboost import plot_importance","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"842fdf1aeda40a55f0b4be50d0aab3bc2fa575d1"},"cell_type":"code","source":"plot_importance(xgb_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"43b15b61996cde45154898068b12e6d1c6e4d57a"},"cell_type":"code","source":"sorted_idx = np.argsort(xgb_model.feature_importances_)[::-1]\nfor index in sorted_idx:\n    print([X_train.columns[index], xgb_model.feature_importances_[index]]) \n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3ad0cc54dc5f2a15a343eb210e9bee9f07443afc"},"cell_type":"markdown","source":"Note that 'Relation' moved up here in feature importance compared to RandomForest model."},{"metadata":{"trusted":true,"_uuid":"01d54c9a892acb36183e172a35966a23fefb53aa"},"cell_type":"code","source":"xgbc = xgb.XGBClassifier(n_estimators=20, max_depth=3, random_state=42, subsample=0.8, colsample_bytree=0.8, \n                                           n_jobs=-1, objective='multi:softmax')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1209d76f20b8afe6c22668a04ba163ff4c78f926"},"cell_type":"code","source":"cross_validate_and_print(preprocessing_pipeline, xgbc)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c6c5eda749fb6d5ffe6736c884d9378a8693aa54"},"cell_type":"markdown","source":"Note how close the evaluation metrics are to Random Forest - how many estimators did we use? Go back and compare the score_times."},{"metadata":{"_uuid":"29e23c4019346b96e50c6aef8f30ccacd0324af3"},"cell_type":"markdown","source":"Exercise: Try without scaling, does this change the cross-validation accuracy of GBT? \n\n"},{"metadata":{"_uuid":"3f1d75315529636d021951cb5bca59e19f24dfb8"},"cell_type":"markdown","source":"STOP - After trying all the different paramters, identify a model to select, and train with all the data and show the test set accuracy.  DO NOT GO BACK AND CHOOSE A DIFFERENT MODEL IF TEST SET ACCURACY DOESN\"T MAKE YOU HAPPY."},{"metadata":{"_uuid":"254f18eba20d09a024395a9f605271aaae36789b"},"cell_type":"markdown","source":"Note: We would use a combination of cross validation and grid search against all the parameters - called \"hyperparameter tuning\" to pick our final model.  Look at resources section at the end which has python packages that will do these in a 'smarter' way rather than brute force.\n"},{"metadata":{"trusted":true,"_uuid":"9d2269d3fc70070f9ff86d146cddd4e8739a6075"},"cell_type":"code","source":"final_model = xgb.XGBClassifier(n_estimators=20, max_depth=3, random_state=42, subsample=0.8, colsample_bytree=0.8, \n                                           n_jobs=-1, objective='multi:softmax')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"00f46f3a8496fbfb56fbd48ac0617cb155497776"},"cell_type":"code","source":"final_model_pipeline = make_pipeline(preprocessing_pipeline, final_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"40735534ab54d36124355cc5c262fa9eef18fab6"},"cell_type":"code","source":"final_model_pipeline.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e182e6d6190e3a202d538c2569ca149654f8039e"},"cell_type":"code","source":"final_model_pipeline.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f0c23892d781ee6861d08bc013af3c3f60a62b0c"},"cell_type":"code","source":"y_test_predictions = final_model_pipeline.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"26d5840ae186c7ef30db581a62204a58cb67805f"},"cell_type":"code","source":"print(metrics.classification_report(y_test_predictions, y_test))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b9194f0185e42d72c39c193ed993cee7df0fcc0b"},"cell_type":"markdown","source":"Congratulations - you have now gone through a data set and built many models and selected one.  To continue your journey in improving this model, you can try additional things like hyperparamter tuning, feature engineering, ensembling linear and tree based models, etc!  For example, start digging into the misclassifications to gain more insight about your model and data.\n\nCaution: Digging into misclassification is an excellent way to find gaps in your modeling approach - especially when putting models in production! "},{"metadata":{"_uuid":"434e9aeb7421133567fa3145e787a3f763c3a4e9"},"cell_type":"markdown","source":"## Wrap Up:\n- scipy, numpy, pandas\n- sklearn, pipelines\n- model evaluation\n- supervised, unsupervised approaches\n- model selection using cross validation"},{"metadata":{"_uuid":"530d4b3336cace843411a22907e7fe37022cd62e"},"cell_type":"markdown","source":"## Extra Credit Assignments\n\nExtra Credit Cluster:\n* Since we have Class labels for our data - go through different clustering algorithms and evaluation metrics to find an approach that clusters our data well\n* Rerun Kmeans and evaluate, better with 5 clusters? better with 10 clusters? Evaluation of your choice\n* Use https://scikit-learn.org/stable/modules/generated/sklearn.metrics.adjusted_mutual_info_score.html#sklearn.metrics.adjusted_mutual_info_score metric to evaluate which approach gives us a better score, kmeans with pca or kmeans without scaling?\nResources:\nhttps://scikit-learn.org/stable/modules/clustering.html\nhttps://scikit-learn.org/stable/modules/clustering.html#clustering-performance-evaluation\n\nExtra Credit LDA:\n* Use LDA algorithm to reduce the dimension of the data using the Class labels and see how the performance of the tree based models changes with this transformed data\nResources:\nhttps://stackabuse.com/implementing-lda-in-python-with-scikit-learn/\n\nExtra Credit Trees:\n* Try building a decision tree, random forest, and GBT and reduce the dimensions to 5 using TruncatedSVD, how does this change the cross-validation accuracy?\n* How does removing scaling change the cross validation accuracy of Random Forest? or Decision Tree?\n"},{"metadata":{"_uuid":"8800a4c0a4b4d59629ebd3abbab623fa79e3558e"},"cell_type":"markdown","source":"## Additional Packages (My favorites)"},{"metadata":{"trusted":true,"_uuid":"8f183baa865df8702745112060378c301178093c"},"cell_type":"markdown","source":"Python packages used:\nnumpy, scipy, pandas, sklearn, xgboost\n\nHighlights of others:\nh2o - huge set of algos including AutoML (newly opensourced)\nLightGBM\ncatboost\n\ntext:\ngensim\nnltk\nspacy\n\nGraphs:\nnetworkx\n\nFeature engineering:\nhttps://www.featuretools.com/\nhttps://towardsdatascience.com/smarter-ways-to-encode-categorical-data-for-machine-learning-part-1-of-3-6dca2f71b159\nEncoding - https://github.com/scikit-learn-contrib/categorical-encoding\n\nImbalanced Learning:\nhttps://imbalanced-learn.org/en/stable/index.html\n\nPython Visualization:\nmatplotlib\nseaborn\naltair\nholoviews\nbokeh\nplot.ly / Dash\n\nClustering:\nHDBSCAN\n\nHyperparameter Optimization:\nHyperopt\ntpot\nspearmint\n\nGeneral:\nhttps://github.com/scikit-learn-contrib\n\n"},{"metadata":{"_uuid":"a3de051224f343a52f90cbf7c0dc83b833e25625"},"cell_type":"markdown","source":"## Additional resources "},{"metadata":{"_uuid":"b253df4508aad2dd815a443a4cc29b0f921baf66"},"cell_type":"markdown","source":"Explore the data with Pandas:\nhttps://github.com/pandas-profiling/pandas-profiling\n\nPCA: \nhttps://www.utdallas.edu/~herve/abdi-awPCA2010.pdf\nhttps://www.kaggle.com/merckel/preliminary-investigation-pca-boosting\nhttps://medium.com/data-design/how-to-not-be-dumb-at-applying-principal-component-analysis-pca-6c14de5b3c9d\n\nClustering:\nhttps://courses.cs.washington.edu/courses/cse546/08sp/slides/cdr.pdf\nhttp://www.cbs.dtu.dk/chipcourse/Lectures/ClusteringPCA_2010.pdf\nhttps://www.youtube.com/watch?v=EUQY3hL38cw\nhttps://github.com/nicodv/kmodes\nhttps://pypi.org/project/pyclustering/\n\nVisualizing Multidimensional Data :\nhttp://www.apnorton.com/blog/2016/12/19/Visualizing-Multidimensional-Data-in-Python/\nhttps://medium.com/@luckylwk/visualising-high-dimensional-datasets-using-pca-and-t-sne-in-python-8ef87e7915b\n\n\nLDA can be used for dimensionality reduction as well as classification.\nhttps://scikit-learn.org/stable/auto_examples/decomposition/plot_pca_vs_lda.html\nhttps://scikit-learn.org/stable/modules/lda_qda.html\nhttps://scikit-learn.org/stable/auto_examples/classification/plot_lda.html#sphx-glr-auto-examples-classification-plot-lda-py\n\n\nPitfalls:  \nhttp://www.cs.colorado.edu/~mozer/Research/Selected%20Publications/white-paper3.html\nhttp://danielnee.com/2015/01/common-pitfalls-in-machine-learning/\n\nData Set Size:\nhttps://medium.com/rants-on-machine-learning/what-to-do-with-small-data-d253254d1a89\nhttps://datascience.stackexchange.com/questions/19925/what-are-the-most-suitable-machine-learning-algorithms-according-to-type-of-data\nhttps://blog.myyellowroad.com/using-categorical-data-in-machine-learning-with-python-from-dummy-variables-to-deep-category-66041f734512\nhttps://www.datacamp.com/community/tutorials/categorical-data\n\nOther good things:\nhttps://heartbeat.fritz.ai/how-to-make-your-machine-learning-models-robust-to-outliers-44d404067d07\nhttps://github.com/scikit-learn-contrib/sklearn-pandas\nhttps://medium.com/dunder-data/from-pandas-to-scikit-learn-a-new-exciting-workflow-e88e2271ef62\nhttps://machinelearningmastery.com/the-model-performance-mismatch-problem/\nhttps://medium.com/@outside2SDs/an-overview-of-correlation-measures-between-categorical-and-continuous-variables-4c7f85610365\n\n\n\n\n\n"},{"metadata":{"trusted":true,"_uuid":"be3dadc823174d88c80dd6bd88d33a5ffe156757"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}