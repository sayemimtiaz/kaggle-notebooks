{"cells":[{"metadata":{},"cell_type":"markdown","source":"1. [ 1. NIH Chest X-ray Dataset](#1-1)\n    - [1.1 Brief Overview](#1-1)\n    - [1.2 Data Limitations](#1-2)\n    - [1.3 Class Description](#1-3)\n    - [1.4 Special Remarks](#1-4)\n2. [Loading Data](#2-1)\n    - [2.1 Loading Libraries](#2-1)\n    - [2.2 Loading DataFrames](#2-2)\n    \n"},{"metadata":{},"cell_type":"markdown","source":"<a name='1-1'></a>\n# 1. NIH Chest X-ray Dataset\n## National Institutes of Health Chest X-Ray Dataset\nChest X-ray exams are one of the most frequent and cost-effective medical imaging examinations available. However, clinical diagnosis of a chest X-ray can be challenging and sometimes more difficult than diagnosis via chest CT imaging. The lack of large publicly available datasets with annotations means it is still very difficult, if not impossible, to achieve clinically relevant computer-aided detection and diagnosis (CAD) in real world medical sites with chest X-rays. One major hurdle in creating large X-ray image datasets is the lack resources for labeling so many images. Prior to the release of this dataset, (Openi)[https://openi.nlm.nih.gov/] was the largest publicly available source of chest X-ray images with 4,143 images available.\n\nThis NIH Chest X-ray Dataset is comprised of 112,120 X-ray images with disease labels from 30,805 unique patients. **To create these labels, the authors used Natural Language Processing to text-mine disease classifications from the associated radiological reports.** **The labels are expected to be >90% accurate and suitable for weakly-supervised learning.** The original radiology reports are not publicly available but you can find more details on the labeling process in this Open Access paper: \"ChestX-ray8: Hospital-scale Chest X-ray Database and Benchmarks on Weakly-Supervised Classification and Localization of Common Thorax Diseases.\" [(Wang et al)](https://www.nih.gov/news-events/news-releases/nih-clinical-center-provides-one-largest-publicly-available-chest-x-ray-datasets-scientific-community)\n\n<a name='1-2'></a>\n## 1.2 Data limitations:\nThe image labels are NLP extracted so there could be some erroneous labels but the NLP labeling accuracy is estimated to be >90%. Very limited numbers of disease region bounding boxes (See BBoxlist2017.csv) Chest x-ray radiology reports are not anticipated to be publicly shared. Parties who use this public dataset are encouraged to share their “updated” image labels and/or new bounding boxes in their own studied later, maybe through manual annotation\n\n\n### File contents\nImage format: 112,120 total images with size 1024 x 1024\n* images_001.zip: Contains 4999 images\n* images_002.zip: Contains 10,000 images\n* images_003.zip: Contains 10,000 images\n* images_004.zip: Contains 10,000 images\n* images_005.zip: Contains 10,000 images\n* images_006.zip: Contains 10,000 images\n* images_007.zip: Contains 10,000 images\n* images_008.zip: Contains 10,000 images\n* images_009.zip: Contains 10,000 images\n* images_010.zip: Contains 10,000 images\n* images_011.zip: Contains 10,000 images\n* images_012.zip: Contains 7,121 images\nREADME_ChestXray.pdf: Original README file\n\n### BBoxlist2017.csv: Bounding box coordinates. Note: Start at x,y, extend horizontally w pixels, and vertically h pixels\nImage Index: File name\nFinding Label: Disease type (Class label)\nBbox x\nBbox y\nBbox w\nBbox h\n\n### Dataentry2017.csv: Class labels and patient data for the entire dataset\nImage Index: File name\nFinding Labels: Disease type (Class label)\nFollow-up #\nPatient ID\nPatient Age\nPatient Gender\nView Position: X-ray orientation\nOriginalImageWidth\nOriginalImageHeight\nOriginalImagePixelSpacing_x\nOriginalImagePixelSpacing_y\n\n<a name='1-3'></a>\n### 1.3 Class descriptions\nThere are 15 classes (14 diseases, and one for \"No findings\"). Images can be classified as \"No findings\" or one or more disease classes:\n\n* Atelectasis\n* Consolidation\n* Infiltration\n* Pneumothorax\n* Edema\n* Emphysema\n* Fibrosis\n* Effusion\n* Pneumonia\n* Pleural_thickening\n* Cardiomegaly\n* Nodule Mass\n* Hernia\n\n<a name='1-4'></a>\n## 1.4 Special Remarks\n### In order to use the images for a classification task, I converted the metadata file Data_Entry_2017.csv and converted it into a one hot vector encoding for using in classification problem [here](https://www.kaggle.com/redwankarimsony/chestxray8-dataframe)\n\nI also removed some of the images from the dataframe as those images were inverted, rotated or not-frontal view of the chest because they carry little or no information necesary for the classification problem. ****\n\n\n<a name='2-0'></a>\n# 2. Loading Data\n\n<a name='2-1'></a>\n## 2.1 Loading Libraries\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Import necessary packages\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nfrom os import listdir\nfrom os.path import join, isfile, isdir\nfrom glob import glob\n\n\nfrom PIL import Image\nsns.set()\nfrom tqdm import tqdm\n%matplotlib inline\n\n\n\n\nfrom keras.preprocessing.image import ImageDataGenerator\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a name='2-2'></a>\n## 2.2 Loading DataFrames\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dir1 = '../input/data/'\ndata_dir2 = '../input/chestxray8-dataframe/'\ntrain_df = pd.read_csv(data_dir1 + 'Data_Entry_2017.csv')\nimage_label_map = pd.read_csv(data_dir2 + 'train_df.csv')\nbad_labels = pd.read_csv(data_dir2 + 'cxr14_bad_labels.csv')\n\n# Listing all the .jpg filepaths\nimage_paths = glob(data_dir1+'images_*/images/*.png')\nprint(f'Total image files found : {len(image_paths)}')\nprint(f'Total number of image labels: {image_label_map.shape[0]}')\nprint(f'Unique patients: {len(train_df[\"Patient ID\"].unique())}')\n\nimage_label_map.drop(['No Finding'], axis = 1, inplace = True)\nlabels = image_label_map.columns[2:-1]\nlabels\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a name='2-3'></a>\n## 2.3 Removing Samples with Bad Labels\n\nYou oboserve that in main dataset`Data_Entry_2017.csv` contains **112120** rows but in modified dataset `train_df.csv` contains only **111863** images. It turns out some of the images are problematic as discussed in this datasets discussion [thread](https://www.kaggle.com/nih-chest-xrays/data/discussion/55461). They are inverted, not-frontal or somehow badly rotated. Therefore they are removed. So we need to do a little bit of peprocessing here to deal with that matter and we are good to go. "},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.rename(columns={\"Image Index\": \"Index\"}, inplace = True)\nimage_label_map.rename(columns={\"Image Index\": \"Index\"}, inplace = True)\ntrain_df = train_df[~train_df.Index.isin(bad_labels.Index)]\ntrain_df.shape\n\nIndex =[]\nfor path in image_paths:\n    Index.append(path.split('/')[5])\nindex_path_map = pd.DataFrame({'Index':Index, 'FilePath': image_paths})\nindex_path_map.head()\n\n# Merge the absolute path of the images to the main dataframe\npd.merge(train_df, index_path_map, on='Index', how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.merge(train_df, index_path_map, on='Index', how='left')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a name='2-4'></a>\n### 2.4 Preparing Images\nWith our dataset splits ready, we can now proceed with setting up our model to consume them. \n- For this the off-the-shelf [ImageDataGenerator](https://keras.io/preprocessing/image/) class from the Keras framework, which allows us to build a \"generator\" for images specified in a dataframe. \n- This class also provides support for basic data augmentation such as random horizontal flipping of images.\n- We also use the generator to transform the values in each batch so that their mean is $0$ and their standard deviation is 1. \n    - This will facilitate model training by standardizing the input distribution. \n- The generator also converts our single channel X-ray images (gray-scale) to a three-channel format by repeating the values in the image across all channels.\n    - We will want this because the pre-trained model that we'll use requires three-channel inputs.\n\nSince it is mainly a matter of reading and understanding Keras documentation, we have implemented the generator for you. There are a few things to note: \n1. The mean and standard deviation of the data is normalized\n3. The input is shuffled after each epoch.\n4. The default image size is selected as 320px by 320px but it can be changed. \n\n\n\n<a name='2-5'></a>\n### 2.5 Creating Data Generator\n\nBefore we create the training data generator from the keras built-in library, we can set several parameters. You can play with the folowing parameters to see what changes. \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"IMAGE_SIZE=[256, 256]\nEPOCHS = 20\n# BATCH_SIZE = 8 * strategy.num_replicas_in_sync\nBATCH_SIZE = 64","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_train_generator(df, image_dir, x_col, y_cols, shuffle=True, batch_size=8, seed=1, target_w = 320, target_h = 320):\n    \"\"\"\n    Return generator for training set, normalizing using batch\n    statistics.\n\n    Args:\n      train_df (dataframe): dataframe specifying training data.\n      image_dir (str): directory where image files are held.\n      x_col (str): name of column in df that holds filenames.\n      y_cols (list): list of strings that hold y labels for images.\n      batch_size (int): images per batch to be fed into model during training.\n      seed (int): random seed.\n      target_w (int): final width of input images.\n      target_h (int): final height of input images.\n    \n    Returns:\n        train_generator (DataFrameIterator): iterator over training set\n    \"\"\"        \n    print(\"getting train generator...\")\n    # normalize images\n    image_generator = ImageDataGenerator(\n        samplewise_center=True,\n        samplewise_std_normalization= True, \n        shear_range=0.1,\n        zoom_range=0.15,\n        rotation_range=5,\n        width_shift_range=0.1,\n        height_shift_range=0.05,\n        horizontal_flip=True, \n        vertical_flip = False, \n        fill_mode = 'reflect')\n    \n    \n    # flow from directory with specified batch size\n    # and target image size\n    generator = image_generator.flow_from_dataframe(\n            dataframe=df,\n            directory=image_dir,\n            x_col=x_col,\n            y_col=y_cols,\n            class_mode=\"raw\",\n            batch_size=batch_size,\n            shuffle=shuffle,\n            seed=seed,\n            target_size=(target_w,target_h))\n    \n    return generator\n\ntrain_generator = get_train_generator(df = image_label_map,\n                                      image_dir = None, \n                                      x_col = 'FilePath',\n                                      y_cols = labels, \n                                      batch_size=BATCH_SIZE,\n                                      target_w = IMAGE_SIZE[0], \n                                      target_h = IMAGE_SIZE[1] \n                                      )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a name='2-6'></a>\n### 2.6 Look at the X-rays\nNow lets have a look at the original dataset. Here `get_label()` function returns the concatenated version of the names of the diagnosis categories. You can run the following cell multiple times to get more images. "},{"metadata":{"trusted":true},"cell_type":"code","source":"X, Y = train_generator.next()\n\ndef get_label(y):\n\n    ret_labels = []\n    for idx in range(len(y)):\n        if y[idx]: ret_labels.append(labels[idx])\n    if len(ret_labels):  return '|'.join(ret_labels)\n    else: return 'No Label'\n\nrows = int(np.floor(np.sqrt(X.shape[0])))\ncols = int(X.shape[0]//rows)\nfig = plt.figure(figsize=(20,15))\nfor i in range(1, rows*cols+1):\n    fig.add_subplot(rows, cols, i)\n    plt.imshow(X[i-1], cmap='gray')\n    plt.title(get_label(Y[i-1]))\n    plt.axis(False)\n    fig.add_subplot","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"<a name='2-7'></a>\n### 2.7 Diagnosis Distribution (Normal vs Sick)\nNow lets have a look at the distribution of the dataset. It is quire evident that almost half of the images didn't have any problem. They are simply the x-rays of healthy people marked as **No Finding** in the data frame. However we can have a look at the number of healthy and non-healthy x-rays.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"import bokeh\nimport IPython.display as ipd\nfrom bokeh.layouts import column, row\nfrom bokeh.models import ColumnDataSource, LinearAxis, Range1d\nfrom bokeh.models.tools import HoverTool\nfrom bokeh.palettes import BuGn4, cividis\nfrom bokeh.plotting import figure, output_notebook, show, output_file\nfrom bokeh.transform import cumsum\nfrom bokeh.palettes import Category20b\n\noutput_notebook()\ndiagnosis = ['Normal', 'Sick' ]\ncounts = [(train_df['Finding Labels'] == 'No Finding').sum(), train_df.shape[0]- (train_df['Finding Labels'] == 'No Finding').sum()]\nsource = ColumnDataSource(pd.DataFrame({'Type':diagnosis,'Counts':counts, 'color':['#054000', '#e22d00']}))\n\ntooltips = [\n    (\"Category\", \"@Type\"),\n    (\"No of Samples\", \"@Counts\")\n]\n\nnormal_vs_sick = figure(x_range=diagnosis, y_range=(0,70000), plot_height=400, plot_width = 400, title=\"Normal vs Sick Distribution\", tooltips = tooltips)\nnormal_vs_sick.vbar(x='Type', top='Counts', width=0.75, legend_field=\"Type\", color = 'color', source=source)\nnormal_vs_sick.xgrid.grid_line_color = None\nnormal_vs_sick.legend.orientation = \"vertical\"\nnormal_vs_sick.legend.location = \"top_right\"\nshow(normal_vs_sick)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a name='2-8'></a>\n### 2.8 Diagnosis Distribution\nNow lets have a look at the distribution of the dataset. It is quire evident that almost half of the images didn't have any problem. They are simply the x-rays of healthy people marked as **No Finding** in the data frame. However we can have a look at the number of healthy and non-healthy x-rays.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"data = image_label_map[labels].sum(axis=0).sort_values(ascending = True)\n\n# bokeh packages\n\ndiagnosis = data.index.tolist()\nsource = ColumnDataSource(data=dict(diagnosis=data.index.tolist(), counts=data.tolist(), color = Category20b[len(data)]))\n\ntooltips = [(\"Diagnosis\", \"@diagnosis\"), (\"Count\", \"@counts\") ]\ndiag_dist = figure(x_range=diagnosis, y_range=(0,15000), plot_height=400, plot_width = 700, title=\"Diagnosis Distributions\", tooltips = tooltips)\ndiag_dist.vbar(x='diagnosis', top='counts', width=0.65, color='color', legend_field=\"diagnosis\", source=source)\n\ndiag_dist.xgrid.grid_line_color = None\ndiag_dist.legend.orientation = \"vertical\"\ndiag_dist.legend.location = \"top_left\"\n\n# show(diag_dist)\n\n\n\n\ndef plot_pie_bokeh(data = None):\n    from math import pi\n    from bokeh.palettes import Category20c\n    x = data.to_dict()\n\n    data = pd.Series(x).reset_index(name='value').rename(columns={'index':'category'})\n    data['angle'] = data['value']/data['value'].sum() * 2*pi\n    data['color'] = Category20b[len(x)]\n    p = figure(plot_height=400, plot_width = 700, title=\"Pie Chart\", tooltips=\"@category: @value%\", x_range=(-0.5, 1.0))\n    p.wedge(x=0.38, y=1, radius=0.4, start_angle=cumsum('angle', include_zero=True), end_angle=cumsum('angle'),\n            line_color=\"black\", fill_color='color', legend_field='category', source=data)\n\n    p.axis.axis_label=None\n    p.axis.visible=False\n    p.grid.grid_line_color = None\n\n    p.legend.orientation = \"vertical\"\n    p.legend.location = \"top_left\"\n    \n    return p\n\n\ndist_diag_percent = plot_pie_bokeh(data/data.sum()*100)\n\nshow(column(diag_dist, dist_diag_percent))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We observe that among the different identified conditions, **Infiltration, Effusion and Atelectasis** have the highest dominance and **Hernia** has the lowest prevalance. Hernia is very small **(0.28% only)** among the sick patients. However the hightest prevalance **Infiltration** has only **25%** and rest of the 13 classses combines to the rest. So the dataset has highly imbalanced positive class which will in turn create problem of negative bias while training CNN models. "},{"metadata":{"trusted":true},"cell_type":"code","source":"show(plot_pie_bokeh(data/data.sum()*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a name='2-9'></a>\n### 2.9 Age Histogram Distribution\nLooking at the dataframe from the metadata, I found something interesting.  At first try, when I wanted to draw the histogram using `np.histogram`, I was getting unusually high range. Then I had a look at the metadata checking the Patient Age has some unusually high numbers. Just checked the patients with age greater than 100 and found out several patients samples where age is listed 140+ year to even 450 years :P :P :P Then I replaced those values with mean of the rest of the dataset which are less than 100 years old because they are simply data entry error. "},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.rename(columns={\"Patient Age\": \"PatientAge\"}, inplace = True)\ntrain_df[train_df['PatientAge'] > 100]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"average_age = int(train_df[train_df['PatientAge'] < 100]['PatientAge'].mean())\nfor idx in range(train_df.shape[0]):\n    if train_df.iloc[idx, 4] > 100:\n        print(f'{train_df.iloc[idx, 0]} : age {train_df.iloc[idx, 4]} is changed to ->> {average_age}')\n        train_df.iloc[idx, 4] = average_age\n\ntrain_df[train_df['PatientAge'] > 100]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def hist_hover(data, column=None,  title = 'Histogram',  colors=[\"SteelBlue\", \"Tan\"], bins=30, log_scale=False, show_plot=True):\n\n    # build histogram data with Numpy\n    hist, edges = np.histogram(data, bins = bins)\n\n    hist_df = pd.DataFrame({column: hist, \"left\": edges[:-1], \"right\": edges[1:]})\n    hist_df[\"interval\"] = [\"%d to %d\" % (left, right) for left, \n                           right in zip(hist_df[\"left\"], hist_df[\"right\"])]\n\n    # bokeh histogram with hover tool\n    if log_scale == True:\n        hist_df[\"log\"] = np.log(hist_df[column])\n        src = ColumnDataSource(hist_df)\n        plot = figure(plot_height = 300, plot_width = 600,\n              title = title,\n              x_axis_label = column.capitalize(),\n              y_axis_label = \"Log Count\")    \n        plot.quad(bottom = 0, top = \"log\",left = \"left\", \n            right = \"right\", source = src, fill_color = colors[0], \n            line_color = \"black\", fill_alpha = 0.7,\n            hover_fill_alpha = 1.0, hover_fill_color = colors[1])\n    else:\n        src = ColumnDataSource(hist_df)\n        plot = figure(plot_height = 300, plot_width = 600,\n            title = title,\n              x_axis_label = column.capitalize(),\n              y_axis_label = \"Count\")    \n        plot.quad(bottom = 0, top = column,left = \"left\", \n            right = \"right\", source = src, fill_color = colors[0], \n            line_color = \"black\", fill_alpha = 0.7,\n            hover_fill_alpha = 1.0, hover_fill_color = colors[1])\n    # hover tool\n    hover = HoverTool(tooltips = [(' Age Interval', '@interval'),\n                              ('Sample Count', str(\"@\" +str(column)))])\n    plot.add_tools(hover)\n    # output\n    if show_plot == True:\n        show(plot)\n    else:\n        return plot","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hist_hover(train_df['PatientAge'], column = 'PatientAge', bins = 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[train_df['Patient Age'] > 100 ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ages_male = train_df.loc[(train_df[\"Patient Gender\"] == 'M'), \"PatientAge\"].tolist()\nages_female = train_df.loc[(train_df[\"Patient Gender\"] == 'F'), \"PatientAge\"].tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show(column(hist_hover(ages_male, column = 'MaleAges', title = 'Male Patients Age Histogram', bins = 95, show_plot=False),\n            hist_hover(ages_female, column = 'FemaleAges', title = 'Female Patients Age Histogram',  bins = 95, show_plot=False)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.PatientAge.max() - train_df.PatientAge.min()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}