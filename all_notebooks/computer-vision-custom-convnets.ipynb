{"cells":[{"metadata":{},"cell_type":"markdown","source":"**This notebook is an exercise in the [Computer Vision](https://www.kaggle.com/learn/computer-vision) course.  You can reference the tutorial at [this link](https://www.kaggle.com/ryanholbrook/custom-convnets).**\n\n---\n"},{"metadata":{},"cell_type":"markdown","source":"# Introduction #\n\nIn these exercises, you'll build a custom convnet with performance competitive to the VGG16 model from Lesson 1.\n\nGet started by running the code cell below."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Setup feedback system\nfrom learntools.core import binder\nbinder.bind(globals())\nfrom learntools.computer_vision.ex5 import *\n\n# Imports\nimport os, warnings\nimport matplotlib.pyplot as plt\nfrom matplotlib import gridspec\n\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\n\n# Reproducability\ndef set_seed(seed=31415):\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    os.environ['TF_DETERMINISTIC_OPS'] = '1'\nset_seed()\n\n# Set Matplotlib defaults\nplt.rc('figure', autolayout=True)\nplt.rc('axes', labelweight='bold', labelsize='large',\n       titleweight='bold', titlesize=18, titlepad=10)\nplt.rc('image', cmap='magma')\nwarnings.filterwarnings(\"ignore\") # to clean up output cells\n\n\n# Load training and validation sets\nds_train_ = image_dataset_from_directory(\n    '../input/car-or-truck/train',\n    labels='inferred',\n    label_mode='binary',\n    image_size=[128, 128],\n    interpolation='nearest',\n    batch_size=64,\n    shuffle=True,\n)\nds_valid_ = image_dataset_from_directory(\n    '../input/car-or-truck/valid',\n    labels='inferred',\n    label_mode='binary',\n    image_size=[128, 128],\n    interpolation='nearest',\n    batch_size=64,\n    shuffle=False,\n)\n\n# Data Pipeline\ndef convert_to_float(image, label):\n    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n    return image, label\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE\nds_train = (\n    ds_train_\n    .map(convert_to_float)\n    .cache()\n    .prefetch(buffer_size=AUTOTUNE)\n)\nds_valid = (\n    ds_valid_\n    .map(convert_to_float)\n    .cache()\n    .prefetch(buffer_size=AUTOTUNE)\n)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Design a Convnet #\n\nLet's design a convolutional network with a block architecture like we saw in the tutorial. The model from the example had three blocks, each with a single convolutional layer. Its performance on the \"Car or Truck\" problem was okay, but far from what the pretrained VGG16 could achieve. It might be that our simple network lacks the ability to extract sufficiently complex features. We could try improving the model either by adding more blocks or by adding convolutions to the blocks we have.\n\nLet's go with the second approach. We'll keep the three block structure, but increase the number of `Conv2D` layer in the second block to two, and in the third block to three. ???\n\n<figure>\n<!-- <img src=\"./images/2-convmodel-2.png\" width=\"250\" alt=\"Diagram of a convolutional model.\"> -->\n<img src=\"https://i.imgur.com/Vko6nCK.png\" width=\"250\" alt=\"Diagram of a convolutional model.\">\n</figure>\n\n# 1) Define Model #\n\nGiven the diagram above, complete the model by defining the layers of the third block."},{"metadata":{"lines_to_next_cell":0,"trusted":true},"cell_type":"code","source":"import tensorflow.keras as keras\nimport tensorflow.keras.layers as layers\n\nmodel = keras.Sequential([\n    # Block One\n    layers.Conv2D(filters=32, kernel_size=3, activation='relu', padding='same',\n                  input_shape=[128, 128, 3]),\n    layers.MaxPool2D(),\n\n    # Block Two\n    layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='same'),\n    layers.MaxPool2D(),\n\n    # Block Three\n    layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'),\n    layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'),\n    layers.MaxPool2D(),\n\n    # Head\n    layers.Flatten(),\n    layers.Dense(6, activation='relu'),\n    layers.Dropout(0.2),\n    layers.Dense(1, activation='sigmoid'),\n])\n\n# Check your answer\nq_1.check()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.keras.utils.plot_model(model, show_shapes=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lines below will give you a hint or solution code\n#q_1.hint()\n#q_1.solution()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2) Compile #\n\nTo prepare for training, compile the model with an appropriate loss and accuracy metric for the \"Car or Truck\" dataset."},{"metadata":{"lines_to_next_cell":0,"trusted":true},"cell_type":"code","source":"model.compile(\n    optimizer=tf.keras.optimizers.Adam(epsilon=0.01),\n    loss='binary_crossentropy',\n    metrics=['binary_accuracy']\n)\n\n# Check your answer\nq_2.check()","execution_count":null,"outputs":[]},{"metadata":{"lines_to_next_cell":0,"trusted":true},"cell_type":"code","source":"model.compile(\n    optimizer=tf.keras.optimizers.Adam(epsilon=0.01),\n    loss='binary_crossentropy',\n    metrics=['binary_accuracy'],\n)\n\nq_2.assert_check_passed()","execution_count":null,"outputs":[]},{"metadata":{"lines_to_next_cell":0,"trusted":true},"cell_type":"code","source":"# Lines below will give you a hint or solution code\n#q_2.hint()\n#q_2.solution()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finally, let's test the performance of this new model. First run this cell to fit the model to the training set."},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(\n    ds_train,\n    validation_data=ds_valid,\n    epochs=50,\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And now run the cell below to plot the loss and metric curves for this training run."},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nhistory_frame = pd.DataFrame(history.history)\nhistory_frame.loc[:, ['loss', 'val_loss']].plot()\nhistory_frame.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3) Train the Model #\n\nHow would you interpret these training curves? Did this model improve upon the model from the tutorial?"},{"metadata":{"lines_to_next_cell":0,"trusted":true},"cell_type":"code","source":"# View the solution (Run this code cell to receive credit!)\nq_3.check()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusion #\n\nThese exercises showed you how to design a custom convolutional network to solve a specific classification problem. Though most models these days will be built on top of a pretrained base, in certain circumstances a smaller custom convnet might still be preferable -- such as with a smaller or unusual dataset or when computing resources are very limited. As you saw here, for certain problems they can perform just as well as a pretrained model.\n\n# Keep Going #\n\nContinue on to [**Lesson 6**](https://www.kaggle.com/ryanholbrook/data-augmentation), where you'll learn a widely-used technique that can give a boost to your training data: **data augmentation**."},{"metadata":{},"cell_type":"markdown","source":"---\n\n\n\n\n*Have questions or comments? Visit the [Learn Discussion forum](https://www.kaggle.com/learn-forum/196537) to chat with other Learners.*"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}