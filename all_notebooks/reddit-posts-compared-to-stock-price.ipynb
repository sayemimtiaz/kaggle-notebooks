{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Reddit posts compared to Stock Price","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\ndf= pd.read_csv(\"../input/reddit-finance-data/wallstreetbets/submissions_reddit.csv\")\n\ndf.head(5)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Count frecuent words","metadata":{}},{"cell_type":"code","source":"#Download stopwords\nimport nltk\n#nltk.download('stopwords')\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# remove stopwords \n\n\ndef removeStopWords(texto):\n    texto= str(texto)\n    import nltk\n    from nltk.corpus import stopwords\n    stopwords= list(stopwords.words('english'))\n    stopwords.append(\"im\")\n    lista2= texto.lower().split()\n    for elemento in stopwords:\n        if elemento in lista2:\n            for i in range (lista2.count(elemento)):\n                lista2.remove(elemento)  \n\n    return lista2\n\n#Remove signs and simbols\n\ndef RemoveNotAlphabetCharacters(lista):\n    lista2=[]\n    for palabra in lista:\n        palabraN=\"\"\n        for letra in palabra:\n            if letra.isalpha()==True:\n                palabraN += letra\n        if palabraN != \"\":\n            lista2.append(palabraN)\n    return lista2\n\n#Create Dictionari with key: word , value: frec\n\ndef CountWords(lista):\n    dic={}\n    for palabra in lista:\n        if palabra not in dic:\n            dic[palabra] = 1\n        elif palabra in dic:\n            dic[palabra] += 1\n    return dic\n\ndf[\"words\"] = df[\"title\"].apply(removeStopWords)\n\ndf[\"words\"] = df[\"words\"].apply(RemoveNotAlphabetCharacters)\n\ndf[\"words\"] = df[\"words\"].apply(CountWords)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# I will create and auxiliary class called \"Dic\" , with an __add__ function\n# The add function will allow us to sum dictionaries\n# This way having a = { \"apple\" : 1 , \"pineaple\" : 3 } and b = { \"apple\" : 2 } (a and b are Dic objects);  \n# a+b= { \"apple\" : 3 , \"pineapple\" : 3}\n\nclass Dic:\n    def __init__ (self, dic):\n        self.dic=(dic)\n        self.cdic= dic.copy()\n    \n    \n    def di(self):\n        return (self.dic)\n        \n    def __add__ (self, other):\n        \n        if isinstance(other, Dic):\n            other=(other).di()\n\n            dic= self.dic\n            \n            cdic= dic.copy()\n\n            for palabra in dict(other):\n                if palabra not in cdic:\n                    cdic[palabra] = other[palabra]\n                elif palabra in dic:\n                    cdic[palabra] += other[palabra]\n        \n        self.cdic=cdic\n        return Dic((cdic))\n    \n    def __str__ (self):\n        return str(self.dic)\n    \ndef toAux(x):\n    return Dic(x)\ndf[\"words\"] = df[\"words\"].apply(toAux)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#I will group by day and have the dictionaries of df[\"words\"] summed\n\n#this function is to short \"created\" to only have days and not hours\ndef shortDate(t):\n    t=str(t)\n    return t[:10]\n\ndf[\"timestamp\"]= df[\"created\"].apply(shortDate)\n\n\ndf1 = df.groupby(\"timestamp\").agg({\"words\" :\"sum\"})\n\ndef todict(Aux):\n    return Aux.dic\n\ndf1[\"words\"] = df1[\"words\"].apply(todict)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" ","metadata":{}},{"cell_type":"markdown","source":"\n ","metadata":{}},{"cell_type":"code","source":"#EXECUTE PROGRAM TO SEE MOST COMMON WORDS IN A DAY\n\nimport operator\n\n\nrow_names = df1.index.values\n\ndate = input(\"Introduce the date where you want to search the most used words(YYYY-MM-DD): \")\nx= dict(zip(list(row_names), range(len(list(row_names)))))[date]\ndf1_sorted = sorted(df1[\"words\"][x].items(), key=operator.itemgetter(1), reverse=True)\n\nfor  y in range(0,10):\n    print(df1_sorted[y])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\n## PLOT gme word appereance\n","metadata":{}},{"cell_type":"code","source":"def countGME(dic):\n    try: \n         return dic[\"gme\"]\n    except:\n        return 0\n    \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1[\"gme\"] = df1[\"words\"].apply(countGME)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(50,25))\nplt.xticks(range(200), size=5)\n\n\n\ndf1[\"gme\"].plot(color=\"red\")\n\nplt.grid(True)\n\n\n\n\n\n#plt.savefig(\"GME word appereance\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# yfinance , (superimpose two graphs)","metadata":{}},{"cell_type":"code","source":"\nimport pandas as pd\n\n\n\n\n\ngme_data=pd.read_csv(\"../input/gmedata/gmedata.csv\")\n\n\n#df1=df1.reset_index()\ngme_data= gme_data.reset_index()\n\ngme_data[\"timestamp\"]= (gme_data[\"Date\"]).apply(shortDate)\n\ngg= pd.merge(df1, gme_data, on='timestamp')\n\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(50,25))\nplt.xticks(range(200), size=5)\n\ngg['Close2']=gg['Close']*50\n\ngg[\"gme\"].plot(color=\"red\")\ngg[\"Close2\"].plot(color=\"blue\")\n\nplt.grid(True)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## P-VALUE\n\n#### The p-value roughly indicates the probability of an uncorrelated system producing datasets that have a Pearson correlation at least as extreme as the one computed from these datasets.\n","metadata":{}},{"cell_type":"code","source":"import scipy.stats\nprint(f'The correlation coefficient is : {scipy.stats.pearsonr(gg[\"gme\"], gg[\"Close2\"])[0]}\\n')\nprint('The p-value is:' , scipy.stats.pearsonr(gg[\"gme\"], gg[\"Close2\"])[1])\nprint(f'\\nThe probability that the 2 graphs are not correlated is: {scipy.stats.pearsonr(gg[\"gme\"], gg[\"Close2\"])[1] *100} %')\nprint(f'The probability that the 2 graphs are correlated is: {100- scipy.stats.pearsonr(gg[\"gme\"], gg[\"Close2\"])[1] *100} %')\n\n\nmy_plot = gg.plot(\"gme\", \"Close2\", kind=\"scatter\")\nplt.show() ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Extra: \n\nget just messages containing gme chronologically","metadata":{}},{"cell_type":"code","source":"def gmeinwords(dic):\n    if \"gme\" in dic or \"gamestop\" in dic:\n        return 1\n    else:\n        return 0\n\ndf[\"words\"] = df[\"title\"].apply(removeStopWords)\n\ndf[\"words\"] = df[\"words\"].apply(RemoveNotAlphabetCharacters)\n\ndf[\"gmeindic\"] = df[\"words\"].apply(gmeinwords)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df3= df[df[\"gmeindic\"] ==1]\ndf=df3.reset_index(drop=True)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"first=  pd.DataFrame()\nfirst[\"timestamp\"]= df[\"timestamp\"] \nfirst[\"title\"] = df[\"title\"]\nfirst[\"shortlink\"] = df[\"shortlink\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for x in range(0,20):\n    print(first[\"timestamp\"][x] , first[\"title\"][x], first[\"shortlink\"][x])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"...","metadata":{}},{"cell_type":"markdown","source":"...","metadata":{}},{"cell_type":"markdown","source":"##### By Pablo Llobregat (pallobre@gmail.com)","metadata":{}}]}