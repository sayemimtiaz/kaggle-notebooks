{"cells":[{"metadata":{},"cell_type":"markdown","source":"****Beginners Need A Small End-to-End Project"},{"metadata":{},"cell_type":"markdown","source":"Books and courses are frustrating. They give you lots of recipes and snippets, but you never get to see how they all fit together.\n\nWhen you are applying machine learning to your own datasets, you are working on a project.\n\nA machine learning project may not be linear, but it has a number of well known steps:\n\n    Define Problem.\n    Prepare Data.\n    Evaluate Algorithms.\n    Improve Results.\n    Present Results.\n\nThe best way to really come to terms with a new platform or tool is to work through a machine learning project end-to-end and cover the key steps. Namely, from loading data, summarizing data, evaluating algorithms and making some predictions.\n\nIf you can do that, you have a template that you can use on dataset after dataset. You can fill in the gaps such as further data preparation and improving result tasks later, once you have more confidence."},{"metadata":{},"cell_type":"markdown","source":"****Hello World of Machine Learning\nThe best small project to start with on a new tool is the classification of iris flowers (e.g. the iris dataset).\n\nThis is a good project because it is so well understood.\n\n    Attributes are numeric so you have to figure out how to load and handle data.\n    It is a classification problem, allowing you to practice with perhaps an easier type of supervised learning algorithm.\n    It is a multi-class classification problem (multi-nominal) that may require some specialized handling.\n    It only has 4 attributes and 150 rows, meaning it is small and easily fits into memory (and a screen or A4 page).\n    All of the numeric attributes are in the same units and the same scale, not requiring any special scaling or transforms to get started.\n\nLet’s get started with your hello world machine learning project in Python."},{"metadata":{},"cell_type":"markdown","source":"****Start Python and Check Versions"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Check the versions of libraries\n# Python version\nimport sys\nprint('Python: {}'.format(sys.version))\n# scipy\nimport scipy\nprint('scipy: {}'.format(scipy.__version__))\n# numpy\nimport numpy\nprint('numpy: {}'.format(numpy.__version__))\n# matplotlib\nimport matplotlib\nprint('matplotlib: {}'.format(matplotlib.__version__))\n# pandas\nimport pandas\nprint('pandas: {}'.format(pandas.__version__))\n# scikit-learn\nimport sklearn\nprint('sklearn: {}'.format(sklearn.__version__))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Loading required libraries..."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas \nfrom pandas.plotting import scatter_matrix\nimport matplotlib.pyplot as plt\nfrom sklearn import model_selection\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Loading the Iris dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"#url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv\"\n#names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'class']\n#dataset = pandas.read_csv(url, names=names)\ndata='../input/iris-flower-dataset/IRIS.csv'\n#reading dataset\ndataset=pandas.read_csv(data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"About the dataset"},{"metadata":{},"cell_type":"markdown","source":"We can get a quick idea of how many instances (rows) and how many attributes (columns) the data contains with the shape property."},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"print('shape:')\nprint(dataset.shape)    #outputs shape of the dataset\nprint('data:')\nprint(dataset.head())    #prints top 5 data points\nprint('description:')\nprint(dataset.describe())    #computs mean ,std ,min,max etc\nprint('number of examples:')\nprint(dataset.groupby('species').size())   #class distribution","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"****Data Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"#plotting box plot\ndataset.plot(kind='box',subplots=True, layout=(2,2),sharex=False, sharey=False)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#histogram\ndataset.hist()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# scatter plot matrix\nscatter_matrix(dataset)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create a Validation Dataset\nLater, we will use statistical methods to estimate the accuracy of the models that we create on unseen data. We also want a more concrete estimate of the accuracy of the best model on unseen data by evaluating it on actual unseen data.\n\nThat is, we are going to hold back some data that the algorithms will not get to see and we will use this data to get a second and independent idea of how accurate the best model might actually be.\n\nWe will split the loaded dataset into two, 80% of which we will use to train our models and 20% that we will hold back as a validation dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"array=dataset.values\nX=array[:,0:4]\nY=array[:,4]\nvalidation_size=0.2\nseed=1\nX_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(X, Y, test_size=validation_size, random_state=seed)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will use 10-fold cross validation to estimate accuracy.\n\nThis will split our dataset into 10 parts, train on 9 and test on 1 and repeat for all combinations of train-test splits."},{"metadata":{"trusted":true},"cell_type":"code","source":"seed=1\nscoring='accuracy'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We are using the metric of ‘accuracy‘ to evaluate models. This is a ratio of the number of correctly predicted instances in divided by the total number of instances in the dataset multiplied by 100 to give a percentage (e.g. 95% accurate). We will be using the scoring variable when we run build and evaluate each model next."},{"metadata":{},"cell_type":"markdown","source":"****Build Models"},{"metadata":{},"cell_type":"markdown","source":"We don’t know which algorithms would be good on this problem or what configurations to use. We get an idea from the plots that some of the classes are partially linearly separable in some dimensions, so we are expecting generally good results.\n\nLet’s evaluate 6 different algorithms:\n\n    Logistic Regression (LR)\n    Linear Discriminant Analysis (LDA)\n    K-Nearest Neighbors (KNN).\n    Classification and Regression Trees (CART).\n    Gaussian Naive Bayes (NB).\n    Support Vector Machines (SVM).\n"},{"metadata":{},"cell_type":"markdown","source":"****Let’s build and evaluate our models:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Spot Check Algorithms\nmodels = []\nmodels.append(('LR', LogisticRegression(solver='liblinear', multi_class='ovr')))\nmodels.append(('LDA', LinearDiscriminantAnalysis()))\nmodels.append(('KNN', KNeighborsClassifier()))\nmodels.append(('CART', DecisionTreeClassifier()))\nmodels.append(('NB', GaussianNB()))\nmodels.append(('SVM', SVC(gamma='auto')))\n# evaluate each model in turn\nresults = []\nnames = []\nfor name, model in models:\n    kfold = model_selection.KFold(n_splits=10, random_state=seed)\n    cv_results = model_selection.cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n    results.append(cv_results)\n    names.append(name)\n    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n    print(msg)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"****Make Predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make predictions on validation dataset\nknn = KNeighborsClassifier()\nknn.fit(X_train, Y_train)\npredictions = knn.predict(X_validation)\nprint(accuracy_score(Y_validation, predictions))\nprint(confusion_matrix(Y_validation, predictions))\nprint(classification_report(Y_validation, predictions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"****Summary"},{"metadata":{},"cell_type":"markdown","source":"We did not cover all of the steps in a machine learning project because this is your first project and we need to focus on the key steps. Namely, loading data, looking at the data, evaluating some algorithms and making some predictions"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}