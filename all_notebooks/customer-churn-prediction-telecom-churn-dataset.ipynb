{"cells":[{"metadata":{"_uuid":"3e3c536c27c26c023cbec0cadc083edaf09e1d20"},"cell_type":"markdown","source":"# Customer churn prediction: Telecom Churn Dataset\n\nCustomer churn, also known as customer retention, customer turnover, or customer defection, is the loss of clients or customers.\n\nTelephone service companies, Internet service providers, pay TV companies, insurance firms, and alarm monitoring services, often use customer attrition analysis and customer attrition rates as one of their key business metrics  because the cost of retaining an existing customer is far less than acquiring a new one. Companies from these sectors often have customer service branches which attempt to win back defecting clients, because recovered long-term customers can be worth much more to a company than newly recruited clients.\n\nCompanies usually make a distinction between voluntary churn and involuntary churn. Voluntary churn occurs due to a decision by the customer to switch to another company or service provider, involuntary churn occurs due to circumstances such as a customer's relocation to a long-term care facility, death, or the relocation to a distant location. In most applications, involuntary reasons for churn are excluded from the analytical models. Analysts tend to concentrate on voluntary churn, because it typically occurs due to factors of the company-customer relationship which companies control, such as how billing interactions are handled or how after-sales help is provided.\n\npredictive analytics  use churn prediction models that predict customer churn by assessing their propensity of risk to churn. Since these models generate a small prioritized list of potential defectors, they are effective at focusing customer retention marketing programs on the subset of the customer base who are most vulnerable to churn.\n\n**Please upvote for this kernel as well as the Telecom Churn Dataset if you find them useful.**"},{"metadata":{"_uuid":"75867907e48104003cfa148d4d4ca47c82309114"},"cell_type":"markdown","source":"- <a href='#1'>1. Data overview</a>\n- <a href='#2'>2. Exploratory Data Analysis</a>\n    - <a href='#2.1'>2.1. Customer churn in data</a>\n    - <a href='#2.2'>2.2. Variable distributions</a>\n- <a href='#3'>3. Data preprocessing</a>\n    - <a href='#3.1'>3.1. Variable summary</a>\n    - <a href='#3.2'>3.2. Correlation matrix</a>\n    - <a href='#3.3'>3.3. Visualizing data with principal components</a>\n    - <a href='#3.4'>3.4. Binary variable distributions in customer churn (Radar Chart)</a>\n- <a href='#4'>4. Model Building</a>\n    - <a href='#4.1'>4.1. Baseline model</a>\n    - <a href='#4.2'>4.2. Synthetic Minority Oversampling TEchnique (SMOTE)</a>\n    - <a href='#4.3'>4.3. Recursive Feature Elimination</a>\n    - <a href='#4.4'>4.4. Univariate Selection</a>\n    - <a href='#4.5'>4.5. Decision Tree Classifier</a> \n    - <a href='#4.6'>4.6. KNN Classifier</a>\n    - <a href='#4.7'>4.7. Random Forest Classifier</a>\n    - <a href='#4.8'>4.8. Gaussian Naive Bayes</a>\n    - <a href='#4.9'>4.9. Support Vector Machine</a>\n        - <a href='#4.9.1'>4.9.1. Support Vector Machine (linear)</a>\n        - <a href='#4.9.2'>4.9.2. Support Vector Machine (rbf)</a>\n    - <a href='#4.10'>4.10. LightGBM Classifier</a>\n    - <a href='#4.11'>4.11. XGBoost Classifier</a>\n    - <a href='#4.12'>4.12. Gaussian Process Classifier</a> \n    - <a href='#4.13'>4.13. AdaBoost Classifier</a> \n    - <a href='#4.14'>4.14. GradientBoosting Classifier</a>\n    - <a href='#4.15'>4.15. Linear Discriminant Analysis</a> \n    - <a href='#4.16'>4.16. Quadratic Discriminant Analysis</a> \n    - <a href='#4.17'>4.17. Multi-layer Perceptron Classifier</a> \n    - <a href='#4.18'>4.18. Bagging Classifier</a>\n- <a href='#5'>5. Model performances over the training dataset</a>\n    - <a href='#5.1'>5.1. Model performance metrics</a>\n    - <a href='#5.2'>5.2. Compare model metrics</a>\n    - <a href='#5.3'>5.3. Confusion matrices for models</a>\n    - <a href='#5.4'>5.4. ROC - Curves for models</a>\n    - <a href='#5.5'>5.5. Precision recall curves</a>\n- <a href='#6'>6. Model performances over the principal test dataset</a>\n    - <a href='#6.1'>6.1. Model performance metrics</a>\n    - <a href='#6.2'>6.2. Compare model metrics</a>\n    - <a href='#6.3'>6.3. Confusion matrices for models</a>\n    - <a href='#6.4'>6.4. ROC - Curves for models</a>\n    - <a href='#6.5'>6.5. Precision recall curves</a>\n    "},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":false,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"#Importing libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom math import * # module math\nimport matplotlib.pyplot as plt # visualization\nfrom PIL import Image\nimport seaborn as sns # visualization\nimport itertools\nimport io\nimport plotly.offline as py # visualization\npy.init_notebook_mode(connected=True) # visualization\nimport plotly.graph_objs as go # visualization\nfrom plotly.subplots import make_subplots\nimport plotly.figure_factory as ff # visualization\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fa7e507381a982dfb9bcba253537c50ecd956230"},"cell_type":"markdown","source":"# <a id='1'>1. Data overview</a>"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"telcom = pd.read_csv(r\"../input/telecom-churn-datasets/churn-bigml-80.csv\")\ntelcom_test = pd.read_csv(r\"../input/telecom-churn-datasets/churn-bigml-20.csv\")\ntelcom.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dataoveriew(df, message):\n    print(f'{message}:\\n')\n    print(\"Rows:\", df.shape[0])\n    print(\"\\nNumber of features:\", df.shape[1])\n    print(\"\\nFeatures:\")\n    print(telcom.columns.tolist())\n    print(\"\\nMissing values:\", df.isnull().sum().values.sum())\n    print(\"\\nUnique values:\")\n    print(df.nunique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataoveriew(telcom, 'Overiew of the training dataset')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataoveriew(telcom_test, 'Overiew of the test dataset')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fbe477239c9240b5402053e0bc572bc5841c91a4"},"cell_type":"markdown","source":"# <a id='2'>2. Exploratory Data Analysis</a>"},{"metadata":{"_uuid":"09ba96d314bd92da87f956c3b265b78317a17d17"},"cell_type":"markdown","source":"## <a id='2.1'>2.1. Customer churn in data</a>"},{"metadata":{"_kg_hide-input":false,"_uuid":"35bf6ff6c7e9ed36b0fb6fa2c67450a58135b62a","trusted":true},"cell_type":"code","source":"trace = go.Pie(labels = telcom[\"Churn\"].value_counts().keys().tolist(),\n               values = telcom[\"Churn\"].value_counts().values.tolist(),\n               marker = dict(colors = ['royalblue','lime'],\n                             line = dict(color = \"white\", width =  1.3)\n                            ),\n               rotation = 90,\n               hoverinfo = \"label+value+text\",\n               hole = .5\n              )\nlayout = go.Layout(dict(title = \"Customer churn in training data\",\n                        plot_bgcolor = \"rgb(243,243,243)\",\n                        paper_bgcolor = \"rgb(243,243,243)\",\n                       )\n                  )\ndata = [trace]\nfig = go.Figure(data = data, layout = layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"34b437d12b3391c3a4d6ae357cb23d408cbc1b18"},"cell_type":"markdown","source":"## <a id='2.2'>2.2. Variable distributions</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Separating columns to be visualized\nout_cols = list(set(telcom.nunique()[telcom.nunique()<6].keys().tolist()\n                    + telcom.select_dtypes(include='object').columns.tolist()))\nviz_cols = [x for x in telcom.columns if x not in out_cols] + ['Churn']\n\nsns.pairplot(telcom[viz_cols], diag_kind=\"kde\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Several of the numerical data are very correlated. (Total day minutes and Total day charge), (Total eve minutes and Total eve charge), (Total night minutes and Total night charge) and lastly (Total intl minutes and Total intl charge) are alo correlated. We only have to select one of them."},{"metadata":{"_uuid":"6dfa77b43fe1a1a301bab65186c2a9f90245ab7d"},"cell_type":"markdown","source":"# <a id='3'>3. Data preprocessing</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\n\n#Removing correlated and unneccessary columns\ncol_to_drop = ['State', 'Area code', 'Total day charge', 'Total eve charge', \n               'Total night charge', 'Total intl charge']\n   \ntelcom = telcom.drop(columns = col_to_drop, axis = 1)\ntelcom_test = telcom_test.drop(columns = col_to_drop, axis = 1)\n\n#target column\ntarget_col = [\"Churn\"]\n\n#number of levels in feature to be a categorical feature\nnlevels = 6\n\n#Separating categorical and numerical columns\n#categorical columns\ncat_cols = list(set(telcom.nunique()[telcom.nunique()<nlevels].keys().tolist() \n                    + telcom.select_dtypes(include='object').columns.tolist()))\ncat_cols = [x for x in cat_cols if x not in target_col]\n#numerical columns\nnum_cols = [x for x in telcom.columns if x not in cat_cols + target_col]\n#Binary columns with 2 values\nbin_cols = telcom.nunique()[telcom.nunique() == 2].keys().tolist()\n#Columns more than 2 values\nmulti_cols = [i for i in cat_cols if i not in bin_cols]\n\n#Label encoding Binary columns\nle = LabelEncoder()\nfor i in bin_cols:\n    telcom[i] = le.fit_transform(telcom[i])\n    telcom_test[i] = le.transform(telcom_test[i])\n\n#combining the train and test datasets\ntrainsize = telcom.shape[0]\ncomb = pd.concat((telcom, telcom_test), sort=False)\n\n#Duplicating columns for multi value columns\ncomb = pd.get_dummies(data = comb, columns = multi_cols)\n\n#Separating the train and test datasets\ntelcom = comb[:trainsize]\ntelcom_test = comb[trainsize:]\n\n#Scaling Numerical columns\nstd = StandardScaler()\nscaled = std.fit_transform(telcom[num_cols])\nscaled = pd.DataFrame(scaled, columns=num_cols)\n\nscaled_test = std.transform(telcom_test[num_cols])\nscaled_test = pd.DataFrame(scaled_test, columns=num_cols)\n\n#dropping original values merging scaled values for numerical columns\ndf_telcom_og = telcom.copy()\ntelcom = telcom.drop(columns = num_cols, axis = 1)\ntelcom = telcom.merge(scaled, left_index=True, right_index=True, how = \"left\")\n\ndf_telcom_test_og = telcom_test.copy()\ntelcom_test = telcom_test.drop(columns = num_cols, axis = 1)\ntelcom_test = telcom_test.merge(scaled_test, left_index=True, right_index=True, how = \"left\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9ec25cff71c0eb0f0c839a726cb06cb43462a53f"},"cell_type":"markdown","source":"## <a id='3.1'>3.1. Variable summary</a>"},{"metadata":{"_uuid":"9f1fbaf6d979c28b6f763eb398e4cdd2091fc37b","trusted":true},"cell_type":"code","source":"summary = (df_telcom_og[[i for i in df_telcom_og.columns]].\n           describe().transpose().reset_index())\n\nsummary = summary.rename(columns = {\"index\" : \"feature\"})\nsummary = np.around(summary,3)\n\nval_lst = [summary['feature'], summary['count'],\n           summary['mean'],summary['std'],\n           summary['min'], summary['25%'],\n           summary['50%'], summary['75%'], summary['max']]\n\ntrace  = go.Table(header = dict(values = summary.columns.tolist(),\n                                line = dict(color = ['#506784']),\n                                fill = dict(color = ['#119DFF']),\n                               ),\n                  cells  = dict(values = val_lst,\n                                line = dict(color = ['#506784']),\n                                fill = dict(color = [\"lightgrey\",'#F5F8FF'])\n                               ),\n                  columnwidth = [200,60,100,100,60,60,80,80,80])\nlayout = go.Layout(dict(title = \"Training variable Summary\"))\nfigure = go.Figure(data=[trace],layout=layout)\npy.iplot(figure)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"82a7617e37906622dbe00a1783a13cbf382d2513"},"cell_type":"markdown","source":"## <a id='3.2'>3.2. Correlation matrix</a>"},{"metadata":{"_uuid":"b52cf9c7f402ed706e82221e3f8601fdeea9ab27","trusted":true},"cell_type":"code","source":"#correlation\ncorrelation = telcom.corr()\n#tick labels\nmatrix_cols = correlation.columns.tolist()\n#convert to array\ncorr_array = np.array(correlation)\n\n#Plotting\ntrace = go.Heatmap(z = corr_array,\n                   x = matrix_cols,\n                   y = matrix_cols,\n                   colorscale = \"Viridis\",\n                   colorbar = dict(title = \"Pearson Correlation coefficients\", titleside = \"right\"),\n                  )\nlayout = go.Layout(dict(title = \"Correlation matrix\",\n                        autosize = False,\n                        height = 720,\n                        width = 800,\n                        margin = dict(r = 0, l = 210, t = 25, b = 210),\n                        yaxis = dict(tickfont = dict(size = 9)),\n                        xaxis = dict(tickfont = dict(size = 9))\n                       )\n                  )\ndata = [trace]\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"abaf205d4be08b2b9951b1c1a878c6e387998abc"},"cell_type":"markdown","source":"## <a id='3.3'>3.3. Visualizing data with principal components</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"def pca_scatter(pcadf, targetfeature, targetlabel, color):\n    tracer = go.Scatter(x = pcadf[pcadf[targetfeature]==targetlabel][\"PC1\"],\n                        y = pcadf[pcadf[targetfeature]==targetlabel][\"PC2\"],\n                        name = targetlabel, mode = \"markers\",\n                        marker = dict(color = color, line = dict(width = .5), symbol = \"diamond-open\"),\n                       )\n    return tracer","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"60c93b7dc48f91fa850d163486f771072f506401","trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\n\npca = PCA(n_components = 2)\n\nX = telcom[[i for i in telcom.columns if i not in target_col]]\nY = telcom[target_col]\n\nprincipal_components = pca.fit_transform(X)\npca_data = pd.DataFrame(principal_components, columns = [\"PC1\", \"PC2\"])\npca_data = pca_data.merge(Y, left_index=True, right_index=True, how=\"left\")\npca_data[\"Churn\"] = pca_data[\"Churn\"].replace({1: \"Churn\", 0: \"Not churn\"})\n\nlayout = go.Layout(dict(title = \"Visualizing data with PCA\",\n                        plot_bgcolor = \"rgb(243,243,243)\",\n                        paper_bgcolor = \"rgb(243,243,243)\",\n                        xaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n                                     title = \"first principal component (PC1)\",\n                                     zerolinewidth=1, ticklen=5, gridwidth=2),\n                        yaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n                                     title = \"second principal component (PC2)\",\n                                     zerolinewidth=1, ticklen=5, gridwidth=2),\n                        height = 400\n                       )\n                  )\ntrace1 = pca_scatter(pca_data, 'Churn', 'Churn', 'red')\ntrace2 = pca_scatter(pca_data, 'Churn', 'Not churn', 'royalblue')\ndata = [trace2, trace1]\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a261b0d62fe4af69dc412143d6b4e019cd65963e"},"cell_type":"markdown","source":"## <a id='3.4'>3.4. Binary variable distribution in customer churn (Radar Chart)</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_radar(df, aggregate, title):\n    data_frame = df[df[\"Churn\"] == aggregate] \n    data_frame_x = data_frame[bi_cs].sum().reset_index()\n    data_frame_x.columns = [\"feature\", \"yes\"]\n    data_frame_x[\"no\"] = data_frame.shape[0] - data_frame_x[\"yes\"]\n    data_frame_x = data_frame_x[data_frame_x[\"feature\"] != \"Churn\"]\n    \n    #count of 1's (yes)\n    trace1 = go.Scatterpolar(r = data_frame_x[\"yes\"].values.tolist(),\n                             theta = data_frame_x[\"feature\"].tolist(),\n                             fill = \"toself\", \n                             name = \"count of 1's\",\n                             mode = \"markers+lines\",\n                             marker = dict(size = 5)\n                            )\n    #count of 0's (no)\n    trace2 = go.Scatterpolar(r = data_frame_x[\"no\"].values.tolist(),\n                             theta = data_frame_x[\"feature\"].tolist(),\n                             fill = \"toself\", \n                             name = \"count of 0's\",\n                             mode = \"markers+lines\",\n                             marker = dict(size = 5)\n                            ) \n    layout = go.Layout(dict(polar = dict(radialaxis = dict(visible = True,\n                                                           side = \"counterclockwise\",\n                                                           showline = True,\n                                                           linewidth = 2,\n                                                           tickwidth = 2,\n                                                           gridcolor = \"white\",\n                                                           gridwidth = 2),\n                                         angularaxis = dict(tickfont = dict(size = 10),\n                                                            layer = \"below traces\"\n                                                           ),\n                                         bgcolor = \"rgb(243,243,243)\",\n                                        ),\n                            paper_bgcolor = \"rgb(243,243,243)\",\n                            title = title, height = 600, width = 600))\n    \n    data = [trace2, trace1]\n    fig = go.Figure(data=data, layout=layout)\n    py.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3a5c9e2edb9121a8db7e2b2d3f1ed23fc9983e9a","trusted":true},"cell_type":"code","source":"#separating binary columns\nbi_cs = telcom.nunique()[telcom.nunique() == 2].keys()\ndat_rad = telcom[bi_cs]\n\n#plotting radar chart for churn and not churn customers (binary variables)\nplot_radar(dat_rad, 1, \"Churn customers\")\nplot_radar(dat_rad, 0, \"Not churn customers\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f944336cbe67efb3422b79864d9478e2cfbdc860"},"cell_type":"markdown","source":"# <a id='4'>4. Model Building</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"def telecom_churn_prediction(algorithm, training_x, testing_x, training_y, testing_y, cf, threshold_plot):\n    #model\n    algorithm.fit(training_x, training_y)\n    predictions = algorithm.predict(testing_x)\n    probabilities = algorithm.predict_proba(testing_x)\n        \n    print('Algorithm:', type(algorithm).__name__)\n    print(\"\\nClassification report:\\n\", classification_report(testing_y, predictions))\n    print(\"Accuracy Score:\", accuracy_score(testing_y, predictions))\n    \n    #confusion matrix\n    conf_matrix = confusion_matrix(testing_y, predictions)\n    #roc_auc_score\n    model_roc_auc = roc_auc_score(testing_y, predictions) \n    print(\"Area under curve:\", model_roc_auc,\"\\n\")\n    \n    fpr, tpr, thresholds = roc_curve(testing_y, probabilities[:,1])\n     \n    #plot confusion matrix\n    trace1 = go.Heatmap(z = conf_matrix,\n                        x = [\"Not churn\", \"Churn\"],\n                        y = [\"Not churn\", \"Churn\"],\n                        showscale = False, colorscale = \"Picnic\",\n                        name = \"Confusion matrix\")\n    \n    #plot roc curve\n    trace2 = go.Scatter(x = fpr, y = tpr,\n                        name = \"Roc: \" + str(model_roc_auc),\n                        line = dict(color = ('rgb(22, 96, 167)'), width = 2))\n    trace3 = go.Scatter(x = [0,1], y = [0,1],\n                        line = dict(color = ('rgb(205, 12, 24)'), width = 2,\n                        dash = 'dot'))\n    \n    if cf in ['coefficients', 'features']:\n        if cf == 'coefficients':\n            coefficients = pd.DataFrame(algorithm.coef_.ravel())\n        elif cf == 'features':\n            coefficients = pd.DataFrame(algorithm.feature_importances_)\n        \n        column_df = pd.DataFrame(training_x.columns.tolist())\n        coef_sumry = (pd.merge(coefficients, column_df, left_index=True, \n                               right_index=True, how=\"left\"))\n        coef_sumry.columns = [\"coefficients\", \"features\"]\n        coef_sumry = coef_sumry.sort_values(by = \"coefficients\", ascending=False)\n        \n        #plot coeffs\n        trace4 = go.Bar(x = coef_sumry[\"features\"], y = coef_sumry[\"coefficients\"], \n                        name = \"coefficients\",\n                        marker = dict(color = coef_sumry[\"coefficients\"],\n                                      colorscale = \"Picnic\",\n                                      line = dict(width = .6, color = \"black\")\n                                     )\n                       )\n        #subplots\n        fig = make_subplots(rows=2, cols=2, specs=[[{}, {}], [{'colspan': 2}, None]],\n                                subplot_titles=('Confusion matrix',\n                                                'Receiver operating characteristic',\n                                                'Feature importances')\n                           )  \n        fig.append_trace(trace1,1,1)\n        fig.append_trace(trace2,1,2)\n        fig.append_trace(trace3,1,2)\n        fig.append_trace(trace4,2,1)\n        fig['layout'].update(showlegend=False, title=\"Model performance\",\n                             autosize=False, height = 900, width = 800,\n                             plot_bgcolor = 'rgba(240,240,240, 0.95)',\n                             paper_bgcolor = 'rgba(240,240,240, 0.95)',\n                             margin = dict(b = 195))\n        fig[\"layout\"][\"xaxis2\"].update(dict(title = \"false positive rate\"))\n        fig[\"layout\"][\"yaxis2\"].update(dict(title = \"true positive rate\"))\n        fig[\"layout\"][\"xaxis3\"].update(dict(showgrid = True, tickfont = dict(size = 10), tickangle = 90))\n        \n    elif cf == 'None':\n        #subplots\n        fig = make_subplots(rows=1, cols=2,\n                            subplot_titles=('Confusion matrix',\n                                            'Receiver operating characteristic')\n                           )\n        fig.append_trace(trace1,1,1)\n        fig.append_trace(trace2,1,2)\n        fig.append_trace(trace3,1,2)\n        fig['layout'].update(showlegend=False, title=\"Model performance\",\n                         autosize=False, height = 500, width = 800,\n                         plot_bgcolor = 'rgba(240,240,240,0.95)',\n                         paper_bgcolor = 'rgba(240,240,240,0.95)',\n                         margin = dict(b = 195))\n        fig[\"layout\"][\"xaxis2\"].update(dict(title = \"false positive rate\"))\n        fig[\"layout\"][\"yaxis2\"].update(dict(title = \"true positive rate\"))  \n        \n    py.iplot(fig)\n    \n    if threshold_plot == True: \n        visualizer = DiscriminationThreshold(algorithm)\n        visualizer.fit(training_x,training_y)\n        visualizer.poof()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report, cohen_kappa_score\nfrom sklearn.metrics import roc_auc_score, roc_curve,scorer, f1_score, precision_score, recall_score\nfrom sklearn.metrics import precision_recall_curve, average_precision_score\n\nimport statsmodels.api as sm\nfrom yellowbrick.classifier import DiscriminationThreshold\n\n#defining the studied or used independent features (columns) as well the target  \ncols = [i for i in telcom.columns if i not in target_col]\ntarget_col = ['Churn']\n\n#splitting the principal training dataset to subtrain and subtest datasets\nx_train, x_test, y_train, y_test = train_test_split(telcom[cols], telcom[target_col], \n                                                    test_size = .25, random_state = 111)\n\n#splitting the no scaled principal training dataset to subtrain and subtest datasets\nx_train_og, x_test_og, y_train_og, y_test_og = train_test_split(df_telcom_og[cols], telcom[target_col],\n                                                                test_size = .25, random_state = 111)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id='4.1'>4.1. Baseline model</a>"},{"metadata":{"_kg_hide-input":false,"_uuid":"84038088d314f275c654021432f614ecf0b7914d","trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\n#Baseline model        \nlogit = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n                           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n                           penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n                           verbose=0, warm_start=False)\n\ntelecom_churn_prediction(logit, x_train, x_test, y_train, y_test, \"coefficients\", threshold_plot=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5d772699a8637e6e9e1a90f424db967b6ae3c12a"},"cell_type":"markdown","source":"## <a id='4.2'>4.2. Synthetic Minority Oversampling TEchnique (SMOTE)</a>\n* Randomly pick a point from the minority class.\n* Compute the k-nearest neighbors (for some pre-specified k) for this point.\n* Add k new points somewhere between the chosen point and each of its neighbors"},{"metadata":{"_uuid":"977d0eb5f44d745d2e54b9643df9c3bcf5d461f7","trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\n\n#oversampling minority class using smote\nsmote = SMOTE(random_state = 0)\nx_smote, y_smote = smote.fit_sample(x_train, y_train)\nx_smote = pd.DataFrame(data = x_smote, columns=cols)\ny_smote = pd.DataFrame(data = y_smote, columns=target_col)\n\nlogit_smote = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n                                 intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n                                 penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n                                 verbose=0, warm_start=False)\n\ntelecom_churn_prediction(logit_smote, x_smote, x_test, y_smote, y_test, \"coefficients\", threshold_plot=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"35f4bbedca5efb1ea70dfa71649cf36e5bdd6e86"},"cell_type":"markdown","source":"## <a id='4.3'>4.3. Recursive Feature Elimination</a>\nRecursive Feature Elimination (RFE) is based on the idea to repeatedly construct a model and choose either the best or worst performing feature, setting the feature aside and then repeating the process with the rest of the features. This process is applied until all features in the dataset are exhausted. The goal of RFE is to select features by recursively considering smaller and smaller sets of features."},{"metadata":{"_uuid":"a12d867c80eb421a8f97edc35417c53fef9243ed","trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import RFE\n\nlogit_rfe = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n                               intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n                               penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n                               verbose=0, warm_start=False)\n\n\nrfe = RFE(logit_rfe, 10)\nrfe = rfe.fit(x_train, y_train.values.ravel())\n\n#identified columns Recursive Feature Elimination\nidc_rfe = pd.DataFrame({\"rfe_support\": rfe.support_,\n                        \"columns\": cols,\n                        \"ranking\": rfe.ranking_,\n                       })\ncols_rfe = idc_rfe[idc_rfe[\"rfe_support\"] == True][\"columns\"].tolist()\n\n#applying model\ntelecom_churn_prediction(logit_rfe, x_train[cols_rfe], x_test[cols_rfe], y_train, y_test, \"coefficients\", threshold_plot=True)\n\ntable_rk = ff.create_table(idc_rfe)\npy.iplot(table_rk)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1f7057d8314e17bf67c544794a6b3c2025ac9b99"},"cell_type":"markdown","source":"## <a id='4.4'>4.4. Univariate Selection</a>\n* Feature Extraction with Univariate Statistical Tests (Chi-squared for classification)\n* uses the chi squared ($\\chi^2$) statistical test for non-negative features to select the best features"},{"metadata":{"_uuid":"27089924eba9425a075576c5254523281dc5b1f5","trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import chi2\nfrom sklearn.feature_selection import SelectKBest\n\n#dataframe with non negative values\nx_df = df_telcom_og[cols]\ny_df = df_telcom_og[target_col]\n\n#fit model with k= 3\nselect = SelectKBest(score_func = chi2, k = 3)\nselect = select.fit(x_df, y_df)\n\n#create dataframe\nscore = pd.DataFrame({\"features\": cols, \"scores\": select.scores_, \"p_values\": select.pvalues_ })\nscore = score.sort_values(by = \"scores\", ascending=False)\n\n#createing new label for categorical and numerical columns\nscore[\"feature_type\"] = np.where(score[\"features\"].isin(num_cols), \"Numerical\", \"Categorical\")\n\ntable_score = ff.create_table(score)\npy.iplot(table_score)\n\n#plot\ntrace1 = go.Scatter(x = score[score[\"feature_type\"]==\"Categorical\"][\"features\"],\n                   y = score[score[\"feature_type\"]==\"Categorical\"][\"scores\"],\n                   name = \"Categorial\", mode = \"lines+markers\",\n                   marker = dict(color = \"red\", line = dict(width =1))\n                   )\n\ntrace2 = go.Bar(x = score[score[\"feature_type\"]==\"Numerical\"][\"features\"],\n                y = score[score[\"feature_type\"]==\"Numerical\"][\"scores\"], name = \"Numerical\",\n                marker = dict(color = \"royalblue\", line = dict(width =1)),\n                xaxis = \"x2\", yaxis = \"y2\"\n               )\nlayout = go.Layout(dict(title = \"Scores for Categorical & Numerical features\",\n                        plot_bgcolor = \"rgb(243,243,243)\",\n                        paper_bgcolor = \"rgb(243,243,243)\",\n                        xaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n                                     tickfont = dict(size =10),\n                                     domain=[0, 0.7],\n                                     tickangle = 90, zerolinewidth=1,\n                                     ticklen=5, gridwidth=2),\n                        yaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n                                     title = \"scores\",\n                                     zerolinewidth=1, ticklen=5, gridwidth=2),\n                        margin = dict(b=200),\n                        xaxis2=dict(domain=[0.8, 1], tickangle = 90, gridcolor = 'rgb(255, 255, 255)'),\n                        yaxis2=dict(anchor='x2', gridcolor = 'rgb(255, 255, 255)')\n                        )\n                  )\n\ndata = [trace1, trace2]\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a07fecf352ce39ca7cc43664b6995807a89a3821"},"cell_type":"markdown","source":"## <a id='4.5'>4.5. Decision Tree Classifier</a>\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def treeplot(classifier, cols, classnames):\n    #plot decision tree\n    graph = Source(tree.export_graphviz(classifier, out_file=None, \n                                        rounded=True, proportion=False,\n                                        feature_names = cols, \n                                        precision = 2,\n                                        class_names = classnames,\n                                        filled = True)\n                  )\n    display(graph)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.tree import export_graphviz\nfrom sklearn import tree\nfrom graphviz import Source\nfrom IPython.display import SVG, display\n\ndecision_tree = DecisionTreeClassifier(max_depth = 9, random_state = 123,\n                                       splitter = \"best\", criterion = \"gini\")\n\ntelecom_churn_prediction(decision_tree, x_train, x_test, y_train, y_test, \"features\", threshold_plot=True)\n\n#plot decision tree\ntreeplot(decision_tree, cols, [\"Not churn\", \"Churn\"])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d1f760b002defd916b4566ae59312bcada1a9229"},"cell_type":"markdown","source":"## <a id='4.6'>4.6. KNN Classifier</a>\n"},{"metadata":{"_uuid":"8697d16c7e56db13e012458c797b60c3fa6b2f67","trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n                           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n                           weights='uniform')\ntelecom_churn_prediction(knn, x_train, x_test, y_train, y_test, 'None', threshold_plot=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5dac202bbbe6e6869eab168e6a10a1efa6abe291"},"cell_type":"markdown","source":"## <a id='4.7'>4.7. Random Forest Classifier</a>\nRandom forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and use averaging to improve the predictive accuracy and control over-fitting. The sub-sample size is always the same as the original input sample size but the samples are drawn with replacement."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nrfc = RandomForestClassifier(n_estimators = 100, random_state = 123,\n                             max_depth = 9, criterion = \"gini\")\n\ntelecom_churn_prediction(rfc, x_train, x_test, y_train, y_test, 'features', threshold_plot=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d89e418310cb3f60d4db4fdb4be330a74b918ba7"},"cell_type":"markdown","source":"## <a id='4.8'>4.8. Gaussian Naive Bayes</a>"},{"metadata":{"_uuid":"106512611d7108e63d5b4dc38cdf5fd72eef8ea4","trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\n\ngnb = GaussianNB(priors=None)\n\ntelecom_churn_prediction(gnb, x_train, x_test, y_train, y_test, 'None', threshold_plot=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6574aaec38141dce75510e2b473058238711e74d"},"cell_type":"markdown","source":"## <a id='4.9'>4.9. Support Vector Machine</a>\n“Support Vector Machine” (SVM) is a supervised machine learning algorithm which can be used for both classification or regression challenges.   it is mostly used in classification problems. In this algorithm, we plot each data item as a point in n-dimensional space .where n is number of features you have) with the value of each feature being the value of a particular coordinate. Then, we perform classification by finding the hyper-plane that differentiate the two classes.\n\n### <a id='4.9.1'>4.9.1. Support Vector Machine (linear)</a>"},{"metadata":{"_uuid":"5c44767e6467369ffd0bbe77bf74cc2af6d66455","trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\n\n#Support vector classifier using linear hyper plane\nsvc_lin  = SVC(C=1.0, kernel='linear', probability=True, random_state=124)\n\ntelecom_churn_prediction(svc_lin, x_train, x_test, y_train, y_test, \"coefficients\", threshold_plot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <a id='4.9.2'>4.9.2. Support Vector Machine (rbf)</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#support vector classifier using non-linear hyper plane (\"rbf\")\nsvc_rbf  = SVC(C=10.0, kernel='rbf', gamma=0.1, probability=True, random_state=124)   \n\ntelecom_churn_prediction(svc_rbf, x_train, x_test, y_train, y_test, \"None\", threshold_plot=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"940f332d9d6c261cda8e149c634e2526b591c88b"},"cell_type":"markdown","source":"## <a id='4.10'>4.10. LightGBM Classifier</a>"},{"metadata":{"_uuid":"c76c25d63a9554b5d20ae9be3cff0069dabdede8","trusted":true},"cell_type":"code","source":"from lightgbm import LGBMClassifier\n\nlgbmc = LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n                        learning_rate=0.5, max_depth=7, min_child_samples=20,\n                        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n                        n_jobs=-1, num_leaves=500, objective='binary', random_state=None,\n                        reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,\n                        subsample_for_bin=200000, subsample_freq=0)\n\ntelecom_churn_prediction(lgbmc, x_train, x_test, y_train, y_test, \"features\", threshold_plot=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ce2c26ca71afd0cb5be5428fc467ab6ccadfc78c"},"cell_type":"markdown","source":"## <a id='4.11'>4.11. XGBoost  Classifier</a>"},{"metadata":{"_uuid":"23bd0fd13e72af0845582cca9376fb1ef658c0d7","trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\n\nxgc = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n                    colsample_bytree=1, gamma=0, learning_rate=0.9, max_delta_step=0,\n                    max_depth=7, min_child_weight=1, missing=None, n_estimators=100,\n                    n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n                    reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n                    silent=True, subsample=1)\n\ntelecom_churn_prediction(xgc, x_train, x_test, y_train, y_test, \"features\", threshold_plot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id='4.12'>4.12. Gaussian Process Classifier</a> "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.gaussian_process import GaussianProcessClassifier\n\ngpc = GaussianProcessClassifier(random_state=124)\n\ntelecom_churn_prediction(gpc, x_train, x_test, y_train, y_test, \"None\", threshold_plot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id='4.13'>4.13. AdaBoost Classifier</a> "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\n\nadac = AdaBoostClassifier(random_state=124)\n\ntelecom_churn_prediction(adac, x_train, x_test, y_train, y_test, \"features\", threshold_plot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id='4.14'>4.14. GradientBoosting Classifier</a> "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\n\ngbc = GradientBoostingClassifier(random_state=124)\n\ntelecom_churn_prediction(gbc, x_train, x_test, y_train, y_test, \"features\", threshold_plot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id='4.15'>4.15. Linear Discriminant Analysis</a> "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n\nlda = LinearDiscriminantAnalysis()\n\ntelecom_churn_prediction(lda, x_train, x_test, y_train, y_test, \"None\", threshold_plot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id='4.15'>4.16. Quadratic Discriminant Analysis</a> "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n\nqda = QuadraticDiscriminantAnalysis()\n\ntelecom_churn_prediction(qda, x_train, x_test, y_train, y_test, \"None\", threshold_plot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id='4.17'>4.17. Multi-layer Perceptron Classifier</a> "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neural_network import MLPClassifier\n\nmlp = MLPClassifier(alpha=1, max_iter=1000, random_state=124)\n\ntelecom_churn_prediction(mlp, x_train, x_test, y_train, y_test, \"None\", threshold_plot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id='4.18'>4.18. Bagging Classifier</a> "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble.bagging import BaggingClassifier\n\nbgc = BaggingClassifier(random_state=124)\n\ntelecom_churn_prediction(bgc, x_train, x_test, y_train, y_test, \"None\", threshold_plot=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f985c3fb0797143d22aa5635cb58cbbab954bb2c"},"cell_type":"markdown","source":"# <a id='5'>5. Model performances over the training dataset</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#putting all the model names, model classes and the used columns in a dictionary\nmodels = {'Logistic (Baseline)': [logit, cols],\n          'Logistic (SMOTE)': [logit_smote, cols], \n          'Logistic (RFE)': [logit_rfe, cols_rfe], \n          'Decision Tree': [decision_tree, cols], \n          'KNN Classifier': [knn, cols], \n          'Random Forest': [rfc, cols], \n          'Naive Bayes': [gnb, cols], \n          'SVM (linear)': [svc_lin, cols], \n          'SVM (rbf)': [svc_rbf, cols], \n          'LGBM Classifier': [lgbmc, cols], \n          'XGBoost Classifier': [xgc, cols], \n          'Gaussian Process': [gpc, cols], \n          'AdaBoost': [adac, cols], \n          'GradientBoost': [gbc, cols], \n          'LDA': [lda, cols], \n          'QDA': [qda, cols], \n          'MLP Classifier': [mlp, cols], \n          'Bagging Classifier': [bgc, cols],\n         }","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id='5.1'>5.1. Model performance metrics</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#gives model report in dataframe\ndef model_report(model, training_x, testing_x, training_y, testing_y, name):\n    model = model.fit(training_x, training_y)\n    predictions = model.predict(testing_x)\n    accuracy = accuracy_score(testing_y, predictions)\n    recallscore = recall_score(testing_y, predictions)\n    precision = precision_score(testing_y, predictions)\n    roc_auc = roc_auc_score(testing_y, predictions)\n    f1score = f1_score(testing_y, predictions) \n    kappa_metric = cohen_kappa_score(testing_y, predictions)\n    \n    df = pd.DataFrame({\"Model\"           : [name],\n                       \"Accuracy\"        : [accuracy],\n                       \"Recall\"          : [recallscore],\n                       \"Precision\"       : [precision],\n                       \"f1-score\"        : [f1score],\n                       \"Roc_auc\"         : [roc_auc],\n                       \"Kappa_metric\"    : [kappa_metric],\n                      })\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#outputs for all models over the training dataset\nmodel_performances_train = pd.DataFrame() \nfor name in models:\n    if name == 'Logistic (SMOTE)':\n        model_performances_train = model_performances_train.append(model_report(models[name][0], \n                                                                                x_smote[models[name][1]], x_test[models[name][1]], \n                                                                                y_smote, y_test, name), ignore_index=True)\n    else:\n        model_performances_train = model_performances_train.append(model_report(models[name][0], x_train[models[name][1]], \n                                                                                x_test[models[name][1]], \n                                                                                y_train, y_test, name), ignore_index=True)\n        \ntable_train = ff.create_table(np.round(model_performances_train, 4))\npy.iplot(table_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"132cc1f1657a71dd267b44c232741b44b5f174fb"},"cell_type":"markdown","source":"## <a id='5.2'>5.2. Compare model metrics</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"def output_tracer(df, metric, color):\n    tracer = go.Bar(y = df[\"Model\"],\n                    x = df[metric],\n                    orientation = \"h\", name = metric ,\n                    marker = dict(line = dict(width =.7), color = color)\n                   )\n    return tracer\n\ndef modelmetricsplot(df, title):\n    layout = go.Layout(dict(title = title,\n                        plot_bgcolor = \"rgb(243,243,243)\",\n                        paper_bgcolor = \"rgb(243,243,243)\",\n                        xaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n                                     title = \"metric\",\n                                     zerolinewidth=1,\n                                     ticklen=5, gridwidth=2),\n                        yaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n                                     zerolinewidth=1, ticklen=5, gridwidth=2),\n                        margin = dict(l = 250),\n                        height = 780\n                       )\n                  )\n    trace1 = output_tracer(df, \"Accuracy\", \"#6699FF\")\n    trace2 = output_tracer(df, 'Recall', \"red\")\n    trace3 = output_tracer(df, 'Precision', \"#33CC99\")\n    trace4 = output_tracer(df, 'f1-score', \"lightgrey\")\n    trace5 = output_tracer(df, 'Roc_auc', \"magenta\")\n    trace6 = output_tracer(df, 'Kappa_metric', \"#FFCC99\")\n\n    data = [trace1, trace2, trace3, trace4, trace5, trace6]\n    fig = go.Figure(data=data, layout=layout)\n    py.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelmetricsplot(df=model_performances_train, title=\"Model performances over the training dataset\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"920f02fd2a3da5aed679aade56b1227481cc42a3"},"cell_type":"markdown","source":"## <a id='5.3'>5.3. Confusion matrices for models</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"def confmatplot(modeldict, df_train, df_test, target_train, target_test, figcolnumber):\n    fig = plt.figure(figsize=(4*figcolnumber, 4*ceil(len(modeldict)/figcolnumber)))\n    fig.set_facecolor(\"#F3F3F3\")\n    for name, figpos in itertools.zip_longest(modeldict, range(len(modeldict))):\n        plt.subplot(ceil(len(modeldict)/figcolnumber), figcolnumber, figpos+1)\n        if name=='Logistic (SMOTE)':\n            model = modeldict[name][0].fit(df_train[1][modeldict[name][1]], target_train[1])\n            predictions = model.predict(df_test[modeldict[name][1]])\n            conf_matrix = confusion_matrix(target_test, predictions)\n            sns.heatmap(conf_matrix, annot=True, fmt = \"d\", square = True,\n                        xticklabels=[\"Not churn\", \"Churn\"],\n                        yticklabels=[\"Not churn\", \"Churn\"],\n                        linewidths = 2, linecolor = \"w\", cmap = \"Set1\")\n            plt.title(name, color = \"b\")\n            plt.subplots_adjust(wspace = .3, hspace = .3)\n        else:\n            model = modeldict[name][0].fit(df_train[0][modeldict[name][1]], target_train[0])\n            predictions = model.predict(df_test[modeldict[name][1]])\n            conf_matrix = confusion_matrix(target_test, predictions)\n            sns.heatmap(conf_matrix, annot=True, fmt = \"d\", square = True,\n                        xticklabels=[\"Not churn\", \"Churn\"],\n                        yticklabels=[\"Not churn\", \"Churn\"],\n                        linewidths = 2, linecolor = \"w\", cmap = \"Set1\")\n            plt.title(name, color = \"b\")\n            plt.subplots_adjust(wspace = .3, hspace = .3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confmatplot(modeldict=models, df_train=[x_train, x_smote], df_test=x_test, \n             target_train=[y_train, y_smote], target_test=y_test, figcolnumber=3)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7d3d15f7aa0c14639397d99ac351be0324605ff9"},"cell_type":"markdown","source":"## <a id='5.4'>5.4. ROC - Curves  for models</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"def rocplot(modeldict, df_train, df_test, target_train, target_test, figcolnumber):\n    fig = plt.figure(figsize=(4*figcolnumber, 4*ceil(len(modeldict)/figcolnumber)))\n    fig.set_facecolor(\"#F3F3F3\")\n    for name, figpos in itertools.zip_longest(modeldict, range(len(modeldict))):\n        qx = plt.subplot(ceil(len(modeldict)/figcolnumber), figcolnumber, figpos+1)\n        if name=='Logistic (SMOTE)':\n            model = modeldict[name][0].fit(df_train[1][modeldict[name][1]], target_train[1])\n            probabilities = model.predict_proba(df_test[modeldict[name][1]])\n            predictions = model.predict(df_test[modeldict[name][1]])\n                        \n            fpr, tpr, thresholds = roc_curve(target_test, probabilities[:,1])\n            plt.plot(fpr, tpr, linestyle = \"dotted\",\n                     color = \"royalblue\", linewidth = 2,\n                     label = \"AUC = \" + str(np.around(roc_auc_score(target_test, predictions), 3)))\n            plt.plot([0,1],[0,1], linestyle = \"dashed\",\n                     color = \"orangered\", linewidth = 1.5)\n            plt.fill_between(fpr, tpr, alpha = .1)\n            plt.fill_between([0, 1], [0, 1], color = \"b\")\n            plt.legend(loc = \"lower right\",\n                       prop = {\"size\" : 12})\n            qx.set_facecolor(\"w\")\n            plt.grid(True, alpha = .15)\n            plt.title(name, color = \"b\")\n            plt.xticks(np.arange(0, 1, .3))\n            plt.yticks(np.arange(0, 1, .3))\n       \n        else:\n            model = modeldict[name][0].fit(df_train[0][modeldict[name][1]], target_train[0])\n            probabilities = model.predict_proba(df_test[modeldict[name][1]])\n            predictions = model.predict(df_test[modeldict[name][1]])\n                        \n            fpr, tpr, thresholds = roc_curve(target_test, probabilities[:,1])\n            plt.plot(fpr, tpr, linestyle = \"dotted\",\n                     color = \"royalblue\", linewidth = 2,\n                     label = \"AUC = \" + str(np.around(roc_auc_score(target_test, predictions), 3)))\n            plt.plot([0,1],[0,1], linestyle = \"dashed\",\n                     color = \"orangered\", linewidth = 1.5)\n            plt.fill_between(fpr, tpr, alpha = .1)\n            plt.fill_between([0, 1], [0, 1], color = \"b\")\n            plt.legend(loc = \"lower right\",\n                       prop = {\"size\" : 12})\n            qx.set_facecolor(\"w\")\n            plt.grid(True, alpha = .15)\n            plt.title(name, color = \"b\")\n            plt.xticks(np.arange(0, 1, .3))\n            plt.yticks(np.arange(0, 1, .3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rocplot(modeldict=models, df_train=[x_train, x_smote], df_test=x_test, \n             target_train=[y_train, y_smote], target_test=y_test, figcolnumber=3)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4e3e5dd305ef65d9c16be5a93634689ce944de5a"},"cell_type":"markdown","source":"## <a id='5.5'>5.5. Precision recall curves</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"def prcplot(modeldict, df_train, df_test, target_train, target_test, figcolnumber):\n    fig = plt.figure(figsize=(4*figcolnumber, 4*ceil(len(modeldict)/figcolnumber)))\n    fig.set_facecolor(\"#F3F3F3\")\n    for name, figpos in itertools.zip_longest(modeldict, range(len(modeldict))):\n        qx = plt.subplot(ceil(len(modeldict)/figcolnumber), figcolnumber, figpos+1)\n        if name=='Logistic (SMOTE)':\n            model = modeldict[name][0].fit(df_train[1][modeldict[name][1]], target_train[1])\n            probabilities = model.predict_proba(df_test[modeldict[name][1]])\n            predictions = model.predict(df_test[modeldict[name][1]])\n            \n            recall, precision, thresholds = precision_recall_curve(target_test, probabilities[:,1])\n            plt.plot(recall, precision, linewidth = 1.5,\n                     label = (\"avg_pcn: \"+str(np.around(average_precision_score(target_test, predictions), 3))))\n            plt.plot([0, 1], [0, 0], linestyle = \"dashed\")\n            plt.fill_between(recall, precision, alpha = .1)\n            plt.legend(loc = \"lower left\", prop = {\"size\": 10})\n            qx.set_facecolor(\"w\")\n            plt.grid(True, alpha = .15)\n            plt.title(name, color = \"b\")\n            plt.xlabel(\"recall\", fontsize=7)\n            plt.ylabel(\"precision\", fontsize=7)\n            plt.xlim([0.25,1])\n            plt.yticks(np.arange(0, 1, .3))\n        else:\n            model = modeldict[name][0].fit(df_train[0][modeldict[name][1]], target_train[0])\n            probabilities = model.predict_proba(df_test[modeldict[name][1]])\n            predictions = model.predict(df_test[modeldict[name][1]])\n            \n            recall, precision, thresholds = precision_recall_curve(target_test, probabilities[:,1])\n            plt.plot(recall, precision, linewidth = 1.5,\n                     label = (\"avg_pcn: \"+str(np.around(average_precision_score(target_test, predictions), 3))))\n            plt.plot([0, 1], [0, 0], linestyle = \"dashed\")\n            plt.fill_between(recall, precision, alpha = .1)\n            plt.legend(loc = \"lower left\", prop = {\"size\": 10})\n            qx.set_facecolor(\"w\")\n            plt.grid(True, alpha = .15)\n            plt.title(name, color = \"b\")\n            plt.xlabel(\"recall\", fontsize=7)\n            plt.ylabel(\"precision\", fontsize=7)\n            plt.xlim([0.25,1])\n            plt.yticks(np.arange(0, 1, .3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prcplot(modeldict=models, df_train=[x_train, x_smote], df_test=x_test, \n             target_train=[y_train, y_smote], target_test=y_test, figcolnumber=3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <a id='6'>6. Model performances over the principal test dataset</a>\n## <a id='6.1'>6.1. Model performance metrics</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#outputs for all models over the principal test dataset\nmodel_performances_test = pd.DataFrame() \nfor name in models:\n    if name == 'Logistic (SMOTE)':\n        model_performances_test = model_performances_test.append(model_report(models[name][0], \n                                                                              x_smote[models[name][1]], telcom_test[models[name][1]], \n                                                                              y_smote, telcom_test[target_col], name), ignore_index=True)\n    else:\n        model_performances_test = model_performances_test.append(model_report(models[name][0], \n                                                                              x_train[models[name][1]], telcom_test[models[name][1]], \n                                                                              y_train, telcom_test[target_col], name), ignore_index=True)\n        \ntable_test = ff.create_table(np.round(model_performances_test, 4))\npy.iplot(table_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id='6.2'>6.2. Compare model metrics</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"modelmetricsplot(df=model_performances_test, title=\"Model performances over the principal test dataset\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id='6.3'>6.3. Confusion matrices for models</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"confmatplot(modeldict=models, df_train=[x_train, x_smote], df_test=telcom_test[cols], \n             target_train=[y_train, y_smote], target_test=telcom_test[target_col], figcolnumber=3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id='6.4'>6.4. ROC - Curves for models</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"rocplot(modeldict=models, df_train=[x_train, x_smote], df_test=telcom_test[cols], \n             target_train=[y_train, y_smote], target_test=telcom_test[target_col], figcolnumber=3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id='6.5'>6.5. Precision recall curves</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"prcplot(modeldict=models, df_train=[x_train, x_smote], df_test=telcom_test[cols], \n             target_train=[y_train, y_smote], target_test=telcom_test[target_col], figcolnumber=3)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":1}