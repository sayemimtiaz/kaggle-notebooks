{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import glob\nimport random\nimport os\nimport random\nimport time\nimport datetime\nimport sys\nimport numpy as np\nimport argparse\nimport math\nimport itertools\n\nimport torch\nimport torch.functional as F\nimport torch.nn as nn\nimport torchvision.transforms as transforms\n\nfrom torch.autograd import Variable\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import datasets\nfrom torchvision.utils import save_image, make_grid\nfrom PIL import Image\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def weights_init_normal(m):\n    classname = m.__class__.__name__\n    if classname.find(\"Conv\") != -1:\n        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n        if hasattr(m, \"bias\") and m.bias is not None:\n            torch.nn.init.constant_(m.bias.data, 0.0)\n    elif classname.find(\"BatchNorm2d\") != -1:\n        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n        torch.nn.init.constant_(m.bias.data, 0.0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# epoch to start training from\nepoch = 0\n# number of epoch of training\nn_epochs = 1\n# name of the dataset\ndataset_name = \"monet2photo\"\n#batch size\nbatch_size = 1\n# learning rate for ADAM optimizer\nlr = 0.0002\n#decay of first gardient momentum for ADAM optimizer\nb1 = 0.5\nb2 = 0.999\n#epoch to start decay from\ndecay_epoch = 0\n#number of cpu to use\nn_cpu = 8\n# size of image height\nimg_height = 256\n# size of image width\nimg_width = 256\n#number of channels\nchannels = 3\n#interval between saving images\nsample_interval = 100\n#interval between saving model checkpoint\ncheckpoint_interval = 1\n# number of residual block in generator\nn_residual_blocks = 9\n#cycle loss weight\nlambda_cyc = 10.0\n#identity loss weight\nlambda_id = 5.0\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def to_rgb(image):\n    rgb_image = Image.new(\"RGB\", image.size)\n    rgb_image.paste(image)\n    return rgb_image\n\n\nclass ImageDataset(Dataset):\n    def __init__(self, root, transforms_=None, unaligned=False, mode=\"train\"):\n        self.transform = transforms.Compose(transforms_)\n        self.unaligned = unaligned\n\n        self.files_A = sorted(glob.glob(os.path.join(root,dataset_name,mode+\"A\")+ \"//*.*\"))\n        self.files_B = sorted(glob.glob(os.path.join(root,dataset_name,mode+\"B\") + \"//*.*\"))\n\n\n    def __getitem__(self, index):\n        image_A = Image.open(self.files_A[index % len(self.files_A)])\n\n        if self.unaligned:\n            image_B = Image.open(self.files_B[random.randint(0, len(self.files_B) - 1)])\n        else:\n            image_B = Image.open(self.files_B[index % len(self.files_B)])\n\n        # Convert grayscale images to rgb\n        if image_A.mode != \"RGB\":\n            image_A = to_rgb(image_A)\n        if image_B.mode != \"RGB\":\n            image_B = to_rgb(image_B)\n\n        item_A = self.transform(image_A)\n        item_B = self.transform(image_B)\n        return {\"A\": item_A, \"B\": item_B}\n\n    def __len__(self):\n        return max(len(self.files_A), len(self.files_B))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ResidualBlock(nn.Module):\n    def __init__(self, in_features):\n        super(ResidualBlock, self).__init__()\n        \n        self.block = nn.Sequential(\n        nn.ReflectionPad2d(1),\n        nn.Conv2d(in_features, in_features,3),\n        nn.InstanceNorm2d(in_features),\n        nn.ReLU(inplace=True),\n        nn.ReflectionPad2d(1),\n        nn.Conv2d(in_features, in_features,3),\n        nn.InstanceNorm2d(in_features),)\n        \n    def forward(self, x):\n        return x + self.block(x)\n   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class GeneratorResNet(nn.Module):\n    def __init__(self, input_shape, num_residual_blocks):\n        super(GeneratorResNet, self).__init__()\n        channels = input_shape[0]\n        \n        #initial convolution block\n        out_features = 64\n        model = [nn.ReflectionPad2d(channels),\n                 nn.Conv2d(channels, out_features, 7),\n                 nn.InstanceNorm2d(out_features),\n                 nn.ReLU(inplace=True),]\n        in_features = out_features\n        \n        #downsampling\n        for _ in range(2):\n            out_features *= 2\n            model += [nn.Conv2d(in_features,out_features,3,stride=2,padding=1),\n                      nn.InstanceNorm2d(out_features),\n                      nn.ReLU(inplace=True),]\n            in_features = out_features\n            \n        #residual blocks\n        for _ in range(2):\n            out_features //= 2\n            model += [nn.Upsample(scale_factor=2),\n                      nn.Conv2d(in_features,out_features,3,stride=1,padding=1),\n                      nn.InstanceNorm2d(out_features),\n                      nn.ReLU(inplace=True),]\n            in_features = out_features\n            \n        #outer layer\n        model += [nn.ReflectionPad2d(channels), \n                  nn.Conv2d(out_features,channels,7),\n                  nn.Tanh()]\n        self.model = nn.Sequential(*model)\n        \n    def forward(self, x):\n        return self.model(x)\n            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Discriminator(nn.Module):\n    def __init__(self, input_shape):\n        super(Discriminator, self).__init__()\n        channels, height, width = input_shape\n        \n        #output image shape\n        self.output_shape = (1,height // 2 ** 4, width // 2 ** 4)\n        \n        def discriminator_block(in_filters, out_filters, normalize=True):\n            layers = [nn.Conv2d(in_filters, out_filters, 4, stride=2, padding=1)]\n            if normalize:\n                layers.append(nn.InstanceNorm2d(out_filters))\n            layers.append(nn.LeakyReLU(0.2, inplace=True))\n            return layers\n        self.model = nn.Sequential(\n                    *discriminator_block(channels, 64, normalize=False),\n                    *discriminator_block(64,128),\n                    *discriminator_block(128,256),\n                    *discriminator_block(256,512),\n                    nn.ZeroPad2d((1,0,1,0)),\n                    nn.Conv2d(512,1,4,padding=1))\n        \n    def forward(self, img):\n        return self.model(img)\n       ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ReplayBuffer:\n    def __init__(self, max_size=50):\n        assert max_size > 0 \n        self.max_size = max_size\n        self.data = []\n\n    def push_and_pop(self, data):\n        to_return = []\n        for element in data.data:\n            element = torch.unsqueeze(element, 0)\n            if len(self.data) < self.max_size:\n                self.data.append(element)\n                to_return.append(element)\n            else:\n                if random.uniform(0, 1) > 0.5:\n                    i = random.randint(0, self.max_size - 1)\n                    to_return.append(self.data[i].clone())\n                    self.data[i] = element\n                else:\n                    to_return.append(element)\n        return Variable(torch.cat(to_return))\n\n\nclass LambdaLR:\n    def __init__(self, n_epochs, offset, decay_start_epoch):\n        assert (n_epochs - decay_start_epoch) > 0\n        self.n_epochs = n_epochs\n        self.offset = offset\n        self.decay_start_epoch = decay_start_epoch\n\n    def step(self, epoch):\n        return 1.0 - max(0, epoch + self.offset - self.decay_start_epoch)/(self.n_epochs - self.decay_start_epoch)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create sample and checkpoint directories\nos.makedirs(\"images/%s\" % dataset_name, exist_ok=True)\nos.makedirs(\"saved_models/%s\" % dataset_name, exist_ok=True)\n\n# Losses\ncriterion_GAN = torch.nn.MSELoss()\ncriterion_cycle = torch.nn.L1Loss()\ncriterion_identity = torch.nn.L1Loss()\n\ncuda = torch.cuda.is_available()\n\ninput_shape = (channels, img_height, img_width)\n\n# Initialize generator and discriminator\nG_AB = GeneratorResNet(input_shape, n_residual_blocks)\nG_BA = GeneratorResNet(input_shape, n_residual_blocks)\nD_A = Discriminator(input_shape)\nD_B = Discriminator(input_shape)\n\nif cuda:\n    G_AB = G_AB.cuda()\n    G_BA = G_BA.cuda()\n    D_A = D_A.cuda()\n    D_B = D_B.cuda()\n    criterion_GAN.cuda()\n    criterion_cycle.cuda()\n    criterion_identity.cuda()\n\nif epoch != 0:\n    # Load pretrained models\n    G_AB.load_state_dict(torch.load(\"saved_models/%s/G_AB_%d.pth\" % (dataset_name, epoch)))\n    G_BA.load_state_dict(torch.load(\"saved_models/%s/G_BA_%d.pth\" % (dataset_name, epoch)))\n    D_A.load_state_dict(torch.load(\"saved_models/%s/D_A_%d.pth\" % (dataset_name, epoch)))\n    D_B.load_state_dict(torch.load(\"saved_models/%s/D_B_%d.pth\" % (dataset_name, epoch)))\nelse:\n    # Initialize weights\n    G_AB.apply(weights_init_normal)\n    G_BA.apply(weights_init_normal)\n    D_A.apply(weights_init_normal)\n    D_B.apply(weights_init_normal)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Optimizers\noptimizer_G = torch.optim.Adam(\n    itertools.chain(G_AB.parameters(), G_BA.parameters()), lr=lr, betas=(b1, b2)\n)\noptimizer_D_A = torch.optim.Adam(D_A.parameters(), lr=lr, betas=(b1, b2))\noptimizer_D_B = torch.optim.Adam(D_B.parameters(), lr=lr, betas=(b1, b2))\n\n# Learning rate update schedulers\nlr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(\n    optimizer_G, lr_lambda=LambdaLR(n_epochs, epoch, decay_epoch).step\n)\nlr_scheduler_D_A = torch.optim.lr_scheduler.LambdaLR(\n    optimizer_D_A, lr_lambda=LambdaLR(n_epochs, epoch, decay_epoch).step\n)\nlr_scheduler_D_B = torch.optim.lr_scheduler.LambdaLR(\n    optimizer_D_B, lr_lambda=LambdaLR(n_epochs, epoch,decay_epoch).step\n)\n\nTensor = torch.cuda.FloatTensor if cuda else torch.Tensor\n\n# Buffers of previously generated samples\nfake_A_buffer = ReplayBuffer()\nfake_B_buffer = ReplayBuffer()\n\n# Image transformations\ntransforms_ = [\n    transforms.Resize(int(img_height * 1.12), Image.BICUBIC),\n    transforms.RandomCrop((img_height, img_width)),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training data loader\ndataloader = DataLoader(\n    ImageDataset(\"../input\", transforms_=transforms_, unaligned=True),\n    batch_size=batch_size,\n    shuffle=True,\n    num_workers=n_cpu,\n)\n# Test data loader\nval_dataloader = DataLoader(\n    ImageDataset(\"../input\", transforms_=transforms_, unaligned=True, mode=\"test\"),\n    batch_size=5,\n    shuffle=True,\n    num_workers=1,\n)\n\n\ndef sample_images(batches_done):\n    \"\"\"Saves a generated sample from the test set\"\"\"\n    imgs = next(iter(val_dataloader))\n    G_AB.eval()\n    G_BA.eval()\n    real_A = Variable(imgs[\"A\"].type(Tensor))\n    fake_B = G_AB(real_A)\n    real_B = Variable(imgs[\"B\"].type(Tensor))\n    fake_A = G_BA(real_B)\n    # Arange images along x-axis\n    real_A = make_grid(real_A, nrow=5, normalize=True)\n    real_B = make_grid(real_B, nrow=5, normalize=True)\n    fake_A = make_grid(fake_A, nrow=5, normalize=True)\n    fake_B = make_grid(fake_B, nrow=5, normalize=True)\n    # Arange images along y-axis\n    image_grid = torch.cat((real_A, fake_B, real_B, fake_A), 1)\n    save_image(image_grid, \"images/%s/%s.png\" % (dataset_name, batches_done), normalize=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ----------\n#  Training\n# ----------\n\nprev_time = time.time()\nfor epoch in range(epoch, n_epochs):\n    for i, batch in enumerate(dataloader):\n\n        # Set model input\n        real_A = Variable(batch[\"A\"].type(Tensor))\n        real_B = Variable(batch[\"B\"].type(Tensor))\n\n        # Adversarial ground truths\n        valid = Variable(Tensor(np.ones((real_A.size(0), *D_A.output_shape))), requires_grad=False)\n        fake = Variable(Tensor(np.zeros((real_A.size(0), *D_A.output_shape))), requires_grad=False)\n\n        # ------------------\n        #  Train Generators\n        # ------------------\n\n        G_AB.train()\n        G_BA.train()\n\n        optimizer_G.zero_grad()\n\n        # Identity loss\n        loss_id_A = criterion_identity(G_BA(real_A), real_A)\n        loss_id_B = criterion_identity(G_AB(real_B), real_B)\n\n        loss_identity = (loss_id_A + loss_id_B) / 2\n\n        # GAN loss\n        fake_B = G_AB(real_A)\n        loss_GAN_AB = criterion_GAN(D_B(fake_B), valid)\n        fake_A = G_BA(real_B)\n        loss_GAN_BA = criterion_GAN(D_A(fake_A), valid)\n\n        loss_GAN = (loss_GAN_AB + loss_GAN_BA) / 2\n\n        # Cycle loss\n        recov_A = G_BA(fake_B)\n        loss_cycle_A = criterion_cycle(recov_A, real_A)\n        recov_B = G_AB(fake_A)\n        loss_cycle_B = criterion_cycle(recov_B, real_B)\n\n        loss_cycle = (loss_cycle_A + loss_cycle_B) / 2\n\n        # Total loss\n        loss_G = loss_GAN + lambda_cyc * loss_cycle + lambda_id * loss_identity\n\n        loss_G.backward()\n        optimizer_G.step()\n\n        # -----------------------\n        #  Train Discriminator A\n        # -----------------------\n\n        optimizer_D_A.zero_grad()\n\n        # Real loss\n        loss_real = criterion_GAN(D_A(real_A), valid)\n        # Fake loss (on batch of previously generated samples)\n        fake_A_ = fake_A_buffer.push_and_pop(fake_A)\n        loss_fake = criterion_GAN(D_A(fake_A_.detach()), fake)\n        # Total loss\n        loss_D_A = (loss_real + loss_fake) / 2\n\n        loss_D_A.backward()\n        optimizer_D_A.step()\n\n        # -----------------------\n        #  Train Discriminator B\n        # -----------------------\n\n        optimizer_D_B.zero_grad()\n\n        # Real loss\n        loss_real = criterion_GAN(D_B(real_B), valid)\n        # Fake loss (on batch of previously generated samples)\n        fake_B_ = fake_B_buffer.push_and_pop(fake_B)\n        loss_fake = criterion_GAN(D_B(fake_B_.detach()), fake)\n        # Total loss\n        loss_D_B = (loss_real + loss_fake) / 2\n\n        loss_D_B.backward()\n        optimizer_D_B.step()\n\n        loss_D = (loss_D_A + loss_D_B) / 2\n\n        # --------------\n        #  Log Progress\n        # --------------\n\n        # Determine approximate time left\n        batches_done = epoch * len(dataloader) + i\n        batches_left = n_epochs * len(dataloader) - batches_done\n        time_left = datetime.timedelta(seconds=batches_left * (time.time() - prev_time))\n        prev_time = time.time()\n\n        # Print log\n        sys.stdout.write(\n            \"\\r[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f, adv: %f, cycle: %f, identity: %f] ETA: %s\"\n            % (\n                epoch,\n                n_epochs,\n                i,\n                len(dataloader),\n                loss_D.item(),\n                loss_G.item(),\n                loss_GAN.item(),\n                loss_cycle.item(),\n                loss_identity.item(),\n                time_left,\n            )\n        )\n\n        # If at sample interval save image\n        if batches_done % sample_interval == 0:\n            sample_images(batches_done)\n\n    # Update learning rates\n    lr_scheduler_G.step()\n    lr_scheduler_D_A.step()\n    lr_scheduler_D_B.step()\n\n    if checkpoint_interval != -1 and epoch % checkpoint_interval == 0:\n        # Save model checkpoints\n        torch.save(G_AB.state_dict(), \"saved_models/%s/G_AB_%d.pth\" % (dataset_name, epoch))\n        torch.save(G_BA.state_dict(), \"saved_models/%s/G_BA_%d.pth\" % (dataset_name, epoch))\n        torch.save(D_A.state_dict(), \"saved_models/%s/D_A_%d.pth\" % (dataset_name, epoch))\n        torch.save(D_B.state_dict(), \"saved_models/%s/D_B_%d.pth\" % (dataset_name, epoch))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}