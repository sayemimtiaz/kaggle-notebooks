{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Hello\n**We will seek answers to some questions asked to the data set.I hope this study can be useful. thank you to everyone already reading**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/factors-affecting-campus-placement/Placement_Data_Full_Class.csv')\ndata.head()\n# Read to data set","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **I think to check missing observations and others**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().any()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Missing observation in a variable**\n\n- I will delete this because I couldn't fully control the story of the dataset.\n- But the average can also be filled with solutions like estimation.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"CopyData = data.copy() # I copy the data set\nCopyData.fillna(CopyData['salary'].mean(),inplace=True) # I fill in the missing values with the average.\n#I will continue with all transactions with the copy data set.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"CopyData.isnull().any()\n# Its Done","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Let's check our variable information and descriptive statistics immediately**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"CopyData.describe().T\n# Students in the classroom are on the same average.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Of course, we may have to check against the observer.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px\nimport plotly.graph_objects as go\nfig = go.Figure()\nfig.add_trace(go.Box(y=CopyData['ssc_p'],name='Secondary Education percentage',boxpoints='all',jitter=0.3,marker_color='rgb(0,255,0)',line_color='rgb(50,205,50)'))\nfig.add_trace(go.Box(y=CopyData['hsc_p'],name='Higher Secondary Education percentage',boxpoints='suspectedoutliers',jitter=0.3,marker_color='rgb(32,178,170)',line_color='rgb(102,205,170)'))\nfig.add_trace(go.Box(y=CopyData['degree_p'],name='Degree Percentage',boxpoints='suspectedoutliers',jitter=0.3,marker_color='rgb(47,79,79)',line_color='rgb(0,128,128)'))\nfig.add_trace(go.Box(y=CopyData['etest_p'],name='Employability test percentage',boxpoints='all',jitter=0.3,marker_color='rgb(127,255,212)',line_color='rgb(64,224,208)'))\nfig.add_trace(go.Box(y=CopyData['mba_p'],name='MBA percentage',boxpoints='all',jitter=0.3,marker_color='rgb(0,191,255)',line_color='rgb(25,25,112)'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# There's a little bit of contradiction,i don't want to touch this.\n- Let's examine the connection between variables.\n- I will do this with the help of heatmap.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nf, ax = plt.subplots(figsize=(10, 10))\nsns.heatmap(data.corr(),ax=ax,annot=True,linewidths=.5,cmap=\"YlGnBu\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **I guess there is no other variable that directly affects the Salary variable**\n- Let's look at it from a different perspective.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(CopyData, kind  =\"reg\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **It sounds complicated but it expresses the connection of the variables better.**\n\n**As a result, there is a little connection between the variables.I think we can set up a linear regression for the salary variable.**\n\n\n\n->  Now let's look at selected specialties in secondary education.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px\ncolors = ['Gold','GoldenRod','Gray']\nfig = go.Figure()\nfig.add_trace(go.Bar(x=['Commerce','Science','Arts'],y=[113,91,11],marker_color=colors))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ***Areas of expertise selected in this way***\n\n- Let's take a look at the training board.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"colors = ['Crimson','LightPink']\nfig = go.Figure()\nfig.add_trace(go.Bar(x=['Others','Central'],y=[131,84],marker_color=colors))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Maybe we can make an inference that we need to look at the gender of those who choose specialization in secondary school**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(figsize=(8, 5))\nsns.barplot(x='salary', y='gender',hue='hsc_s', data=CopyData,ax=ax,color='Crimson');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **When we look here, we see that men receive a good salary from science and women from trade.**\n\n## **Let's look at the salary effects of graduation specialties.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(figsize=(10, 8))\nsns.barplot(x='salary', y='gender',hue=CopyData['degree_t'], data=CopyData,ax=ax,color='BlueViolet');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **If I comment on this,men continued to advance in science and technique.If we look at women, they turned to other branches.But as a general comment, their salaries increased on both sides**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## **Let's build a model like this,Let's check whether it is settled according to school scores.**\n\n- Let's do this classification by random forest algorithm.\n\n\n![](https://img.gazetevatan.com/vatanmediafile/Haber598x362/2020/02/07/ogm-sonuclari-belli-oldu-mu-ogm-sonuc-sorgulama-n-4395954.Jpeg)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## **First I want to make the following categorical variables 0 and 1**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"CopyDataX = CopyData.copy() # Let's copy whatever happens ;)\ndms = pd.get_dummies(CopyData[['ssc_b','hsc_b','hsc_s','degree_t','workex','specialisation','status','gender']])\ndms.head() # Let's clean this one too","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = CopyData['status']\nX_ = CopyData.drop(['ssc_b','hsc_b','hsc_s','degree_t','workex','specialisation','status','gender'],axis=1).astype('float64')\nX_.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = pd.concat([X_,dms[['ssc_b_Central','hsc_b_Central','hsc_s_Arts','hsc_s_Commerce','hsc_s_Science','degree_t_Comm&Mgmt','degree_t_Others','degree_t_Sci&Tech','workex_Yes','specialisation_Mkt&Fin','status_Placed','gender_M']]],axis=1)\nX.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **I hope the effects of this separation will not affect us badly.**\n- Let's do the separation of train and test sets.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"CopyDataT = X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ny = CopyDataT['status_Placed']\nx = CopyDataT.drop(['status_Placed'],axis=1)\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.30,random_state=42)\n# We made our train and test distinctions.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Building a model**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nRandomFC = RandomForestClassifier()\nRandomFCmodel = RandomFC.fit(x_train,y_train)\nprint(RandomFCmodel)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\ny_prediction = RandomFCmodel.predict(x_test)\naccuracy_score(y_test,y_prediction)\n# Yes, we could have built a beautiful model.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Let's take a look at our real y and estimate y values.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_p = pd.DataFrame({\n    'y_pred':y_prediction,\n    'y_real':y_test\n})\nY_p.head(10)\n# Quite successful.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Let's try to improve our model a little more.**\n\n\n# MODEL TUNİNG","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nRF_params = {\n    'max_depth':[2,3,5,8,10],\n    'max_features':[2,5,8],\n    'n_estimators':[10,500,1000,2000],\n    'min_samples_split':[2,5,10]\n}\nRF = RandomForestClassifier()\nRF_model_cv = GridSearchCV(RF,RF_params,cv=10,n_jobs=-1,verbose=2)\nRF_model_cv.fit(x_train,y_train)\n# We are searching for hyperparameters.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Best Parameter:' + str(RF_model_cv.best_params_))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Now let's create a new model using these parameters**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"RF_tuned = RandomForestClassifier(max_depth=RF_model_cv.best_params_['max_depth'],\n                                  max_features=RF_model_cv.best_params_['max_features'],\n                                 min_samples_split=RF_model_cv.best_params_['min_samples_split'],\n                                 n_estimators=RF_model_cv.best_params_['n_estimators']).fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_predic_new = RF_tuned.predict(x_test)\naccuracy_score(y_test,y_predic_new)\n# Not much has changed, but we used the optimum parameters.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Let's take a look at which variables are more important in case of  being settled.**\n\n- Importance of variables in classification.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Importance = pd.DataFrame({'Importance':RF_tuned.feature_importances_*100},\n                         index=x_train.columns)\nImportance_sorted = Importance.sort_values(by='Importance',\n                                          axis=0,\n                                          ascending=True).plot(kind='barh',color='Coral');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Yes, when I look at the significance levels, I see that the scores affect but the salary variable affects too much**\n\n- Experience, gender etc. It doesn't matter.\n\n\n--> Let's try to set up a very linear regression model for the salary variable.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"MPData = pd.DataFrame({\n    'ssc_p':CopyDataT['ssc_p'],\n    'hsc_p':CopyDataT['hsc_p'],\n    'degree_p':CopyDataT['degree_p'],\n    'etest_p':CopyDataT['etest_p'],\n    'mba_p':CopyDataT['mba_p'],\n    'salary':CopyDataT['salary']\n})\nMPData.head()\n# I don't think the rest will affect the rest except mba but I want to include them too.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We do train and test separation.\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.model_selection import train_test_split,cross_val_score,cross_val_predict\nx_x = data.drop(['salary'],axis=1)\ny_y = data['salary']\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.30,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nLinear = LinearRegression()\nLinearModel = Linear.fit(x_train,y_train)\nprint('Linear Model İntercept' + str(LinearModel.intercept_))\nprint('Linear Model Coef' + str(LinearModel.coef_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rmse = np.sqrt(mean_squared_error(y_train,LinearModel.predict(x_train)))\nprint('Train Error:',rmse)\nt_rmse = np.sqrt(mean_squared_error(y_test,LinearModel.predict(x_test)))\nprint('Test Error:',t_rmse)\nprint('Verified Error:',cross_val_score(LinearModel,x_train,y_train,cv=10,scoring='r2').mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Thank you for reading so much I can**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}