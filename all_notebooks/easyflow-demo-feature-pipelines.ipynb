{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Easy Tensorflow:\n\nAn interface containing easy tensorflow model building blocks and feature encoding pipelines. This module contains functionality similar to what sklearn does with its Pipeline, FeatureUnion and ColumnTransformer. \n\nPipeline types:\n- Encoder: Preprocess feature based on specified preprocessing layer \n- SequentialEncoder: Preprocessing pipeline to apply multiple encoders in serie\n- Pipeline:  Main interface for transforming features. Apply feature encoder list which can contain both Encoder and SequentialEncoder object types\n- FeatureUnion: Similar tp Pipeline, but concats the Layers from Pipeline","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%pip install -q easy-tensorflow","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers.experimental.preprocessing import Normalization, CategoryEncoding, StringLookup\n\n# import from easyflow\nfrom easyflow.data.mapper import TensorflowDataMapper\nfrom easyflow.preprocessing.preprocessor import Encoder, FeatureUnion","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataframe = pd.read_csv('/kaggle/input/heart-disease-uci/heart.csv')\nlabels = dataframe.pop(\"target\")\n\nbatch_size = 32\ndataset_mapper = TensorflowDataMapper() \ndataset = dataset_mapper.map(dataframe, labels)\ntrain_data_set, val_data_set = dataset_mapper.split_data_set(dataset)\ntrain_data_set = train_data_set.batch(batch_size)\nval_data_set = val_data_set.batch(batch_size)\n\nNUMERICAL_FEATURES = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak', 'slope']\nCATEGORICAL_FEATURES = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'ca', 'thal']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Setup Preprocessing layer using FeatureUnion","metadata":{}},{"cell_type":"code","source":"feature_encoder_list = [\n                        Encoder([('numeric_encoder', Normalization(), NUMERICAL_FEATURES)]),\n                        Encoder([('categorical_encoder', CategoryEncoding(), CATEGORICAL_FEATURES)]),\n                        ]\n\nencoder = FeatureUnion(feature_encoder_list)\nall_feature_inputs, preprocessing_layer = encoder.encode(train_data_set)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# setup simple network\nx = tf.keras.layers.Dense(128, activation=\"relu\")(preprocessing_layer)\nx = tf.keras.layers.Dropout(0.5)(x)\noutputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\nmodel = tf.keras.Model(inputs=all_feature_inputs, outputs=outputs)\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(),\n    loss=tf.keras.losses.BinaryCrossentropy(),\n    metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy'), tf.keras.metrics.AUC(name='auc')])\n\nhistory=model.fit(train_data_set, validation_data=val_data_set, epochs=10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}