{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nall_filenames = []\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        all_filenames.append(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_city_lookup():\n    \"\"\"\n    First 12 rows contain information about cities and no temperture data.\n    Extract the rows and transform into useful lookup table\n    \"\"\"\n    city_lookup = pd.read_csv(all_filenames[0], nrows=12).T\n    city_lookup.columns = city_lookup.iloc[0]\n    city_lookup = city_lookup.iloc[1:,:]\n    city_lookup[\"lat\"] = city_lookup.lat.astype(np.float)\n    city_lookup[\"lng\"] = city_lookup.lng.astype(np.float)\n    return city_lookup\n\nbuild_city_lookup()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def build_reduced_city_lookup():\n    \"\"\"\n    Convert city_lookup types and assert data is valid\n    \"\"\"\n    city_lookup = build_city_lookup()\n\n    # First 12 rows are information about the cities\n    city_lookup = build_city_lookup()\n    city_lookup = city_lookup[[\"city\", \"country\", \"lat\", \"lng\", \"population\"]]\n    city_lookup.loc[:,\"population\"] = city_lookup.population.fillna(0).astype(float).astype(np.uint)\n\n    assert len(city_lookup) == len(city_lookup.drop_duplicates())\n    non_null = city_lookup[[\"city\", \"country\", \"lat\", \"lng\"]]\n    assert len(non_null[non_null.isnull().T.any()]) == 0, non_null[non_null.isnull().T.any()]\n\n    assert city_lookup.loc[(city_lookup.lat < -90) | (city_lookup.lat > 90), \"lat\"].count() == 0\n    assert city_lookup.loc[(city_lookup.lng < -180) | (city_lookup.lng > 180), \"lng\"].count() == 0\n\n    return city_lookup\n\ncity_lookup = build_reduced_city_lookup()\nprint(city_lookup.info())\ncity_lookup","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def city_by_name(city_lookup, city_name:str):\n    \"\"\"Lookup col of city and call city_by_index\"\"\"\n    city_col  = city_lookup[city_lookup[\"city\"]==city_name]\n    city_index = int(city_col.index[0])\n\n    return city_by_index(city_index), city_col\n\ndef city_by_index(city_col:int):\n    \"\"\"Read only one col from the csv that contains the city we are interested in\"\"\"\n    city_data = pd.read_csv(all_filenames[0], skiprows=12, usecols=[0, city_col + 1], index_col=0, parse_dates=True, cache_dates=False).iloc[:, 0]\n\n    return city_data\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_city = city_by_index(0)\nsummary = f\"\"\"This data contains daily temperatures for {len(city_lookup)} cities coving a population of at least {city_lookup[\"population\"].sum():,} and {len(city_lookup[\"country\"].unique())} countries. The first recorded day is {sample_city.index.min().strftime('%d %B, %Y')} and the last {sample_city.index.max().strftime('%d %B, %Y')}.\"\"\"\nsummary","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Example city data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# for i in range(1000):\n#     city_data = city_by_index(0)\n#     assert city_data[city_data < -100].count() == 0\n#     assert city_data[city_data > 200].count() == 0\n#     assert not np.isnan(city_data).any()\n\ncity_by_index(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"city_by_name(city_lookup, \"London\")[0].plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Animate years"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ncity_data, city_col = city_by_name(city_lookup, \"London\")\nall_year = city_data.index.year.unique()\nprint(city_col)\n\nprint(all_year)\nfilenames = []\nfor year in all_year:\n    plt.ylim(city_data.min(), city_data.max())\n    city_data[city_data.index.year == year].plot()\n    file_name = str(year) + '.png'\n    filenames.append(file_name)\n    plt.savefig(file_name)\n    plt.close()\n    \n\nprint(filenames)\nimport imageio\nimages = []\nfor filename in filenames:\n    images.append(imageio.imread(filename))\nimageio.mimsave('movie.gif', images)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[](http://)![movie.gif](movie.gif)\n"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}