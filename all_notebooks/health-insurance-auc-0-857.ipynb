{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df_data = pd.read_csv('/kaggle/input/health-insurance-cross-sell-prediction/train.csv')\nprint(df_data.shape)\ndf_data=df_data.rename(columns={\"Response\": \"Target\"})\ndf_data.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = pd.read_csv('/kaggle/input/health-insurance-cross-sell-prediction/test.csv')\ndf_test['Target']=2 \n#this data set will be prepared like the train data set.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ids_for_submission=df_test['id']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_data['Driving_License']=df_data['Driving_License'].astype(object)\ndf_data['Region_Code']=df_data['Region_Code'].astype(object)\ndf_data['Previously_Insured']=df_data['Previously_Insured'].astype(object)\ndf_data['Policy_Sales_Channel']=df_data['Policy_Sales_Channel'].astype(object)\ndf_data['Target']=df_data['Target'].astype(object)\ndf_test['Driving_License']=df_test['Driving_License'].astype(object)\ndf_test['Region_Code']=df_test['Region_Code'].astype(object)\ndf_test['Previously_Insured']=df_test['Previously_Insured'].astype(object)\ndf_test['Policy_Sales_Channel']=df_test['Policy_Sales_Channel'].astype(object)\ndf_test['Target']=df_test['Target'].astype(object)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=df_data['Target']\nplt.pie(x.value_counts(),labels = x.unique(),explode = [0,0.2],\nautopct = lambda x: str(round(x, 2)) + '%')\nplt.title(x.name)\nplt.legend(loc='upper right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=df_data['Previously_Insured']\nplt.pie(x.value_counts(),labels = x.unique(),explode = [0,0.2],\nautopct = lambda x: str(round(x, 2)) + '%')\nplt.title(x.name)\nplt.legend(loc='upper right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=df_data['Gender']\nplt.pie(x.value_counts(),labels = x.unique(),explode = [0,0.2],\nautopct = lambda x: str(round(x, 2)) + '%')\nplt.title(x.name)\nplt.legend(loc='upper right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=df_data['Vehicle_Age']\nplt.pie(x.value_counts(),labels = x.unique(),explode = [0, 0.2,0.2],\nautopct = lambda x: str(round(x, 2)) + '%')\nplt.title(x.name)\nplt.legend(loc='upper right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=df_data['Vehicle_Damage']\nplt.pie(x.value_counts(),labels = x.unique(),explode = [0,0.2],\nautopct = lambda x: str(round(x, 2)) + '%')\nplt.title(x.name)\nplt.legend(loc='upper right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a=df_data.describe(include=np.object)\ndescriptionQual=pd.DataFrame(a)\ndescriptionQual","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"b=df_data.drop(columns='id').describe(include=np.number).round(2)\ndescriptionQuant=pd.DataFrame(b)\ndescriptionQuant","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df_data[df_data['Target']==0]['Age'], hist=False, label = 'Age/Non interested').set_title('Variable Age en fonction de la r√©ponse', fontsize = 15)\nsns.distplot(df_data[df_data['Target']==1]['Age'], hist=False,label = 'Age/Interested')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(df_data['Target'], df_data['Age'])\nplt.title('Boxplot of Age with respect to Target', fontsize = 15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_groups = df_data['Vehicle_Age'].nunique()\na=df_data[df_data['Target']==1].groupby(['Vehicle_Age']).count()\nb=df_data[df_data['Target']==0].groupby(['Vehicle_Age']).count()\ninterest1=a['Target']['< 1 Year']/df_data[df_data['Vehicle_Age']=='< 1 Year']['id'].nunique()\ninterest12=a['Target']['1-2 Year']/df_data[df_data['Vehicle_Age']=='1-2 Year']['id'].nunique()\ninterest2=a['Target']['> 2 Years']/df_data[df_data['Vehicle_Age']=='> 2 Years']['id'].nunique()\nninterest1=b['Target']['< 1 Year']/df_data[df_data['Vehicle_Age']=='< 1 Year']['id'].nunique()\nninterest12=b['Target']['1-2 Year']/df_data[df_data['Vehicle_Age']=='1-2 Year']['id'].nunique()\nninterest2=b['Target']['> 2 Years']/df_data[df_data['Vehicle_Age']=='> 2 Years']['id'].nunique()\ninterested = (interest1,interest12,interest2)\nninterested = (ninterest1,ninterest12,ninterest2)\n\nfig, ax = plt.subplots()\nindex = np.arange(n_groups)\nbar_width = 0.2\nopacity = 0.8\n\nrects1 = plt.bar(index, interested, bar_width,alpha=opacity,color='b',label='Interested')\nrects2 = plt.bar(index + bar_width, ninterested, bar_width,alpha=opacity,color='g',label='N/Interested')\nplt.xlabel('Vehicle_Age')\nplt.ylabel('Proportion')\nplt.title('Proportion of Target with respect to Vehicle_Age')\nplt.xticks(index + bar_width, ('< 1 Year', '1-2 Year', '> 2 Years'))\nplt.legend()\nplt.figure(figsize=(50,10))\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_groups = df_data['Previously_Insured'].nunique()\na=df_data[df_data['Target']==1].groupby(['Previously_Insured']).count()\nb=df_data[df_data['Target']==0].groupby(['Previously_Insured']).count()\ninterest0=a['Target'][0]/df_data[df_data['Previously_Insured']==1]['id'].nunique()\ninterest1=a['Target'][1]/df_data[df_data['Previously_Insured']==1]['id'].nunique()\nninterest0=b['Target'][0]/df_data[df_data['Previously_Insured']==0]['id'].nunique()\nninterest1=b['Target'][1]/df_data[df_data['Previously_Insured']==0]['id'].nunique()\ninterested = (interest0,interest1)\nninterested = (ninterest0,ninterest1)\n\nfig, ax = plt.subplots()\nindex = np.arange(n_groups)\nbar_width = 0.2\nopacity = 0.8\n\nrects1 = plt.bar(index, interested, bar_width,alpha=opacity,color='b',label='Interested')\nrects2 = plt.bar(index + bar_width, ninterested, bar_width,alpha=opacity,color='g',label='N/Interested')\n\nplt.xlabel('Previously_Insured')\nplt.ylabel('Proportion')\nplt.title('Proportion of Target with respect to Previously_Insured')\nplt.xticks(index + bar_width, ('0', '1'))\nplt.legend()\nplt.figure(figsize=(50,10))\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nbs=[]\nz=df_data['Region_Code'].unique()\nfor x in z:\n    nb=df_data[(df_data['Region_Code']==x)]['id'].nunique()\n    nbs.append(nb)\nindices=[]\nmaxis=sorted(nbs,reverse=True)[0:10]\nfor x in maxis:\n    indice=0\n    for y in nbs:\n        if x==y:\n            indices.append(indice)\n        indice=indice+1\nnames=df_data['Region_Code'].unique()\nxlabels=[]\nfor i in names:\n    xlabels.append(str(int(i)))\nfig = plt.figure(1, figsize=(12, 6))\nplt.bar(xlabels, nbs, color = \"#A0AAE4\", edgecolor=\"red\",\n        linewidth=3, ecolor = \"green\",capsize = 14)\nplt.title('Nombre people for each region')\nplt.xticks(rotation=90,fontsize=12)\nplt.ylabel('Nombre')\nbars = plt.bar(xlabels,nbs)\nfor i in indices:\n    bars[i].set_facecolor('yellow')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"proportions=[]\nz=df_data['Region_Code'].unique()\nfor x in z:\n    proportion=df_data[(df_data['Region_Code']==x)&(df_data['Target']==1)]['id'].nunique()/df_data[(df_data['Region_Code']==x)]['id'].nunique()\n    proportions.append(round(proportion,5))\nindices=[]\nmaxis=sorted(proportions,reverse=True)[0:10]\nfor x in maxis:\n    indice=0\n    for y in proportions:\n        if x==y:\n            indices.append(indice)\n        indice=indice+1\nmain_regions=[]\nmain_proportions=[]\nfor x in indices:\n    main_regions.append(df_data['Region_Code'].unique()[x])\n    main_proportions.append(proportions[x])\nf=df_data[(df_data['Region_Code']!=38) & (df_data['Region_Code']!=28) & (df_data['Region_Code']!=19) & (df_data['Region_Code']!=4) & (df_data['Target']==1)  & (df_data['Region_Code']!=23)]['id'].nunique()/df_data[(df_data['Region_Code']!=38) & (df_data['Region_Code']!=38) & (df_data['Region_Code']!=19) & (df_data['Region_Code']!=4)& (df_data['Region_Code']!=23)]['id'].nunique()\n\nnames = main_regions\nvalues=main_proportions\nnames=df_data['Region_Code'].unique()\nxlabels=[]\nfor i in names:\n    xlabels.append(str(int(i)))\nfig = plt.figure(1, figsize=(12, 6))\nplt.bar(xlabels, proportions, color = \"#A0AAE4\", edgecolor=\"red\",linewidth=3, ecolor = \"green\",capsize = 14)\nplt.title('Proportion of interested people for each region')\nplt.xticks(rotation=90,fontsize=12)\nplt.ylabel('Proportion')\nbars = plt.bar(xlabels,proportions)\nfor i in indices:\n    bars[i].set_facecolor('yellow')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f=df_data[(df_data['Policy_Sales_Channel']!=152) & (df_data['Policy_Sales_Channel']!=26) & (df_data['Policy_Sales_Channel']!=124) ]['id'].nunique()\nnbs=[]\nz=df_data['Policy_Sales_Channel'].unique()\nfor x in z:\n    nb=df_data[(df_data['Policy_Sales_Channel']==x)]['id'].nunique()\n    nbs.append(nb)\n\nindices=[]\nmaxis=sorted(nbs,reverse=True)[0:3]\nfor x in maxis:\n    indice=0\n    for y in nbs:\n        if x==y:\n            indices.append(indice)\n        indice=indice+1\nvalues=[]\nfor i in indices:\n    values.append(nbs[i])\nvalues.append(f)\nxlabels=[]\nfor i in indices:\n    xlabels.append(str(df_data['Policy_Sales_Channel'].unique()[i]))\nxlabels.append('Others')\n\nfig = plt.figure(1, figsize=(8, 6))\nplt.bar(xlabels, values, color = \"#A0AAE4\", edgecolor=\"red\",\n        linewidth=3, ecolor = \"green\",capsize = 14)\nplt.title('Nb people for each Policy_Sales_Channel')\nplt.xticks(rotation=90,fontsize=12)\nplt.ylabel('Number')\nbars = plt.bar(xlabels,values,label='Nb customers not interested')\nothers=df_data[(df_data['Policy_Sales_Channel']!=152) & (df_data['Target']==1) &(df_data['Policy_Sales_Channel']!=26) & (df_data['Policy_Sales_Channel']!=124)  ]['id'].nunique()\nliste=[]\nxlabels.remove('Others')\nfor x in xlabels:\n    liste.append(df_data[(df_data['Policy_Sales_Channel']==float(x)) & (df_data['Target']==1)]['id'].nunique())\n\nxlabels.append('Others')\nliste.append(others)\nbars= plt.bar(xlabels,liste,label='Nb customers interested')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(1, figsize=(8, 6))\na=df_data[df_data['Target']==1].groupby(['Vehicle_Damage']).count()\nb=df_data[df_data['Target']==0].groupby(['Vehicle_Damage']).count()\ninterest0=a['Target'][0]\ninterest1=a['Target'][1]\nninterest0=b['Target'][0]\nninterest1=b['Target'][1]\ninterested = [interest0,interest1]\nninterested = [ninterest0,ninterest1]\nxlabel=['0','1']\nplt.bar(xlabel, interested, color = \"#A0AAE4\", edgecolor=\"red\",\n        linewidth=3, ecolor = \"green\",capsize = 14)\nplt.title('Nb people for each Vehicle_Damage')\nplt.xticks(rotation=90,fontsize=12)\nplt.ylabel('Number')\nbars = plt.bar(xlabel,ninterested,label='Nb customers not interested')\nbars= plt.bar(xlabel,interested,label='Nb customers interested')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df_data[df_data['Target']==0]['Annual_Premium'], hist=False, label = 'Annual_Premium/Not interested').set_title('Variable Annual_Premium with respect to target', fontsize = 15)\nsns.distplot(df_data[df_data['Target']==1]['Annual_Premium'], hist=False,label = 'Annual_Premium/Interested')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(1, figsize=(8, 6))\na=df_data[df_data['Target']==1].groupby(['Gender']).count()\nb=df_data[df_data['Target']==0].groupby(['Gender']).count()\ninterest0=a['Target'][0]\ninterest1=a['Target'][1]\nninterest0=b['Target'][0]\nninterest1=b['Target'][1]\ninterested = [interest0,interest1]\nninterested = [ninterest0,ninterest1]\nxlabel=['0','1']\nplt.bar(xlabel, interested, color = \"#A0AAE4\", edgecolor=\"red\",\n        linewidth=3, ecolor = \"green\",capsize = 14)\nplt.title('Nb people with respect to gender')\nplt.xticks(rotation=90,fontsize=12)\nplt.ylabel('Number')\nbars = plt.bar(xlabel,ninterested,label='Nb customers not interested')\nbars= plt.bar(xlabel,interested,label='Nb customers interested')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(1, figsize=(8, 6))\na=df_data[df_data['Target']==1].groupby(['Driving_License']).count()\nb=df_data[df_data['Target']==0].groupby(['Driving_License']).count()\ninterest0=a['Target'][0]\ninterest1=a['Target'][1]\nninterest0=b['Target'][0]\nninterest1=b['Target'][1]\ninterested = [interest0,interest1]\nninterested = [ninterest0,ninterest1]\nxlabel=['0','1']\nplt.bar(xlabel, interested, color = \"#A0AAE4\", edgecolor=\"red\",\n        linewidth=3, ecolor = \"green\",capsize = 14)\nplt.title('Number of people for Driving_License')\nplt.xticks(rotation=90,fontsize=12)\nplt.ylabel(' Number')\nbars = plt.bar(xlabel,ninterested,label='Nb customers not interested')\nbars= plt.bar(xlabel,interested,label='Nb customers interested')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def compute_impurity(feature, impurity_criterion):\n    probs = feature.value_counts(normalize=True)\n    \n    if impurity_criterion == 'entropy':\n        impurity = -1 * np.sum(np.log2(probs) * probs)\n    elif impurity_criterion == 'gini':\n        impurity = 1 - np.sum(np.square(probs))\n    else:\n        raise ValueError('Unknown impurity criterion')      \n    return(round(impurity, 8))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def comp_feature_information_gain(df, target, descriptive_feature, split_criterion):\n    print('target feature:', target)\n    print('descriptive_feature:', descriptive_feature)\n    print('split criterion:', split_criterion)\n            \n    target_entropy = compute_impurity(df[target], split_criterion)\n    entropy_list = list()\n    weight_list = list()\n    \n\n    for level in df[descriptive_feature].unique():\n        df_feature_level = df[df[descriptive_feature] == level]\n        entropy_level = compute_impurity(df_feature_level[target], split_criterion)\n        entropy_list.append(round(entropy_level, 3))\n        weight_level = len(df_feature_level) / len(df)\n        weight_list.append(round(weight_level, 3))\n\n    #print('impurity of partitions:', entropy_list)\n    #print('weights of partitions:', weight_list)\n\n    feature_remaining_impurity = np.sum(np.array(entropy_list) * np.array(weight_list))\n    #print('remaining impurity:', feature_remaining_impurity)\n    information_gain = target_entropy - feature_remaining_impurity\n    print('information gain:', information_gain)\n    print('====================')\n\n    return(information_gain)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=[]\nfor feature in df_data.drop(columns=['Target','id','Vintage','Age','Annual_Premium']).columns:\n    feature_info_gain = comp_feature_information_gain(df_data, 'Target', feature, 'gini')\n    x.append(feature_info_gain)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predictive models"},{"metadata":{},"cell_type":"markdown","source":"> ## Useful functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def split_types(df):\n    categorical=[]\n    numerical=[]\n    j=0\n    for i in df.dtypes:\n        if i=='object':\n            categorical.append(df.columns[j])\n        else:\n            numerical.append(df.columns[j])\n        j+=1\n    return categorical,numerical","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def normalize(df):\n    from sklearn import preprocessing\n    categorical,numerical=split_types(df)\n    print('Qualitatives features : ',categorical)\n    print('Quantitatives features : ',numerical)\n    Data_scaler = preprocessing.MinMaxScaler() \n    Data_encoded_norm = Data_scaler.fit_transform(df.drop(columns=categorical))\n    df_normalized = pd.DataFrame(Data_encoded_norm, columns=df.drop(columns=categorical).columns,index=df.index)\n    return df_normalized","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def binariser(df,df_normalized):\n    categorical,numerical=split_types(df)\n    if len(numerical)!=0:\n        df_categorical=df.drop(columns=numerical)\n    else:\n        df_categorical=df\n    # categorical features (with 2 levels)\n    for col in df_categorical.columns:\n        q = len(df_categorical[col].unique())\n        if (q == 2) and (col!='Target'):\n            df_categorical[col] = pd.get_dummies(df_categorical[col], drop_first=True)\n    # categorical features (with more than 2 levels), \n    df_categorical= pd.get_dummies(df_categorical,drop_first=True)\n    df_ready=df_categorical\n    if len(numerical)!=0:\n        for x in numerical:\n            df_ready[x]=df_normalized[x]\n    return df_ready","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def reduce_dataset(df,fraction0,fraction1):\n    df1 = df[df['Target']==1].sample(frac=fraction1)\n    df0 = df[df['Target']==0].sample(frac=fraction0)\n    df_reduced=pd.concat([df0,df1])\n    return df_reduced","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ndef set_train_test_sets(df) :\n    D_train, D_test, t_train, t_test = train_test_split(df.drop(columns=['Target']).values,df['Target'].values, test_size=0.4, random_state=999)\n    return(D_train,t_train,D_test,t_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve\ndef plot_roc_curve(classifier,D_test,t_test):  \n    probs = classifier.predict_proba(D_test)  \n    probs = probs[:, 1]  \n    fper, tper, thresholds = roc_curve(t_test, probs) \n    auc=metrics.auc(fper,tper)\n    plt.plot(fper, tper, color='orange', label='AUC=%.5f' % auc)\n    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic (ROC) Curve')\n    plt.legend()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import SelectKBest\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.feature_selection import chi2, f_classif\nfrom sklearn import metrics\ndef select_best_features(df,n):\n    selector = SelectKBest( f_classif,k=n) \n    selector.fit(df.drop(columns='Target'),df['Target'])\n    cols = selector.get_support(indices=True)\n    df_best_features = df.iloc[:,cols]\n    return df_best_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_df_with(columns):\n    df_new=pd.DataFrame()\n    for x in columns:\n        df_new[x]=df_data[x]\n    return df_new","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import plot_confusion_matrix\ndef display_performances(classifier,D_test,t_test):\n    plot_confusion_matrix(classifier,D_test,t_test,values_format='d',display_labels=['Not interested','Interested'])\n    plt.show()\n    print(classification_report(t_test, classifier.predict(D_test),digits=4))\n    plot_roc_curve(classifier,D_test,t_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Transform channel feature into a proportion feature\ndef feature_engineering_regions(df_data_new_columns):\n    proportions=[]\n    regions=[]\n    nbtotal=len(df_data)\n    for x in df_data_new_columns['Region_Code'].unique():\n        d=df_data_new_columns.loc[df_data_new_columns['Region_Code']==x,['Target']]\n        nb1=len(d)\n        proportions.append(nb1/nbtotal)\n        regions.append(x)\n    proportionsRegions=pd.DataFrame(proportions,columns=['Proportion'])\n    proportionsRegions['Region']=pd.DataFrame(regions)\n    proportionsRegions['Region']=proportionsRegions['Region'].astype(object)\n    for i in range (0,df_data['Region_Code'].nunique()):\n        df_data_new_columns['Region_Code'].replace(int(proportionsRegions.iloc[i,1]),proportionsRegions.iloc[i,0],inplace=True)\n    return df_data_new_columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Transform channel feature into a proportion feature\ndef feature_engineering_channels(df_data,df_test):\n    df=pd.concat([df_data,df_test])\n    df_data_new_columns=df.copy()\n    proportions=[]\n    channels=[]\n    nbtotal=len(df_data_new_columns)\n    for x in df_data_new_columns['Policy_Sales_Channel'].unique():\n        d=df_data_new_columns.loc[df_data_new_columns['Policy_Sales_Channel']==x,['Target']]\n        nb1=len(d)\n        proportions.append(nb1/nbtotal)\n        channels.append(x)\n    proportionsChannels=pd.DataFrame(proportions,columns=['Proportion'])\n    proportionsChannels['Channel']=pd.DataFrame(channels)\n    proportionsChannels['Channel']=proportionsChannels['Channel'].astype(object)\n    for i in range (0,154):\n        df_data_new_columns['Policy_Sales_Channel'].replace(int(proportionsChannels.iloc[i,1]),proportionsChannels.iloc[i,0],inplace=True)\n    return df_data_new_columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\nimport sklearn\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import GridSearchCV\ndef xgboost(D_train,t_train,D_test,t_test):\n        xgb= XGBClassifier(learning_rate=0.05,min_child_weight = 0, n_estimators=40,gamma=0.01,\n                           max_depth=12,max_features='sqrt',objective='binary:logistic',subsample=0.7,\n                           colsample_bytree = 0.7,scale_pos_weight=2.95,reg_lambda = 2, reg_alpha = 8)\n        print(\"Fitting...\")\n        xgb.fit(D_train, t_train,verbose=3)\n        display_performances(xgb,D_test,t_test)\n        return xgb","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Building dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_data.drop(columns='id',inplace=True)\ndf_test.drop(columns='id',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_data_new_columns=feature_engineering_channels(df_data,df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_data_new_columns=feature_engineering_regions(df_data_new_columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_data_new_columns.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_normalized=normalize(df_data_new_columns.drop(columns='Target'))\ndf_ready=binariser(df_data_new_columns.drop(columns='Target'),df_normalized)\ndf_ready['Target']=df_data_new_columns['Target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test_ready=df_ready.loc[df_ready['Target']==2] #separation of test and train data\ndf_ready=pd.concat([df_ready,df_test_ready])\ndf_ready=df_ready.drop_duplicates(keep=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_ready['Gender']=df_ready['Gender'].astype(int)\ndf_ready['Driving_License']=df_ready['Driving_License'].astype(int)\ndf_ready['Previously_Insured']=df_ready['Previously_Insured'].astype(int)\ndf_ready['Vehicle_Damage']=df_ready['Vehicle_Damage'].astype(int)\ndf_ready['Vehicle_Age_< 1 Year']=df_ready['Vehicle_Age_< 1 Year'].astype(int)\ndf_ready['Vehicle_Age_> 2 Years']=df_ready['Vehicle_Age_> 2 Years'].astype(int)\ndf_ready['Target']=df_ready['Target'].astype(int)\ndf_ready.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_trainNF,y_trainNF,X_testNF,y_testNF=set_train_test_sets(df_ready)\nprint('Shape training set : ',X_trainNF.shape)\nprint('Shape test set : ',X_testNF.shape)\ndf_trainNF=pd.DataFrame(X_trainNF)\ndf_trainNF['Target']=pd.DataFrame(y_trainNF)\nprint(df_trainNF['Target'].value_counts())\ndf_testNF=pd.DataFrame(X_testNF)\ndf_testNF['Target']=pd.DataFrame(y_testNF)\nprint(df_testNF['Target'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predictive Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_xgb=xgboost(X_trainNF,y_trainNF,X_testNF,y_testNF)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission=model_xgb.predict_proba(df_test_ready.drop(columns='Target').to_numpy())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_submission=pd.DataFrame(columns=['id','Response'])\nfinal_submission['id']=ids_for_submission\nfinal_submission['Response']=submission[:,1]\nfinal_submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hello everyone. Here is my first notebook about Health Insurance Cross Sell Prediction. I chose to use boosting models, so first of all I used Xgboost Classifier with a bit of feature engineering. I got an accuracy of 0.8026 and an AUC-score of 0.8572. This notebook might need some improvements : the code might not be optimal and others algorithms might be betters ! Don't hesitate to let me know what you think about my work ! Thanks in advance."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}