{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Michelin Star Restaurant Exploration and Star Classification"},{"metadata":{},"cell_type":"markdown","source":"Coded by Luna McBride\n\nNote from the dataset: explicitly not including these regions: Belgium, France, Germany, Italy, Japan, Luxembourg, Netherlands, Portugal, China, Spain, and Switzerland"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom sklearn.model_selection import train_test_split #Split the data into train and test\nfrom sklearn.ensemble import RandomForestClassifier #Forest for classification\nfrom sklearn.metrics import mean_squared_error #Error testing\nfrom sklearn.metrics import classification_report #Report of Classification\n\nfrom mpl_toolkits.basemap import Basemap #Plot onto map\nimport geopy #Zip Code Tracker (in this case)\nimport matplotlib.pyplot as plt #Plotting\n%matplotlib inline\n\nplt.rcParams['figure.figsize'] = (15,10) #Set the default figure size\nplt.style.use('ggplot') #Set the plotting method\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"oneStar = pd.read_csv(\"../input/michelin-restaurants/one-star-michelin-restaurants.csv\") #Load 1 star restaurants\ntwoStar = pd.read_csv(\"../input/michelin-restaurants/two-stars-michelin-restaurants.csv\") #Load 2 star restaurants\nthreeStar = pd.read_csv(\"../input/michelin-restaurants/three-stars-michelin-restaurants.csv\") #Load 3 star restaurants\nthreeStar.head() #Take a peek at some of the datasets","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"# Combine the Datasets"},{"metadata":{"trusted":true},"cell_type":"code","source":"oneStar[\"star\"] = 1 #Fill the one star sets with 1\ntwoStar[\"star\"] = 2 #Fill the two star sets with 2\nthreeStar[\"star\"] = 3 #Fill the three star sets with 3\nthreeStar.head() #Take a peek at one of the sets","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datasets = [oneStar, twoStar, threeStar] #Take the three datasets\nstars = pd.concat(datasets) #Combine the datasets\nstars = stars.reset_index() #Reset the index\nstars.head() #Take a peek at the combined dataset","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"# Check for Null Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(stars.isnull().any()) #Check for null values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Price is in the form of $'s. I will just add a ? to hold that place.\n\nThe only null cities have a region of Hong Kong, which I will just fill with Hong Kong because it is a city.\n\nThe zip codes can be gotten from the lat/long data via GeoPy, which have no null items."},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"# Fix Null Values"},{"metadata":{},"cell_type":"markdown","source":"## Price"},{"metadata":{"trusted":true},"cell_type":"code","source":"stars[\"price\"] = stars[\"price\"].fillna(\"?\") #Fill null prices with unknown ?\nprint(stars.isnull().any()) #Make sure all null values are filled","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## City"},{"metadata":{"trusted":true},"cell_type":"code","source":"stars[\"city\"] = stars[\"city\"].fillna(\"Hong Kong\") #Fill the null cities will Hong Kong, since all of the null ones are in HK\nprint(stars.isnull().any()) #Make sure that filled the nulls","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Zip Code"},{"metadata":{},"cell_type":"markdown","source":"Zip Encoding: https://gis.stackexchange.com/questions/352961/convert-lat-lon-to-zip-postal-code-using-python"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(stars.loc[stars[\"zipCode\"].isnull()][:4])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"geolocator = geopy.Nominatim(user_agent = \"user_agent\") #Get the geolocator\n\n# For each row, fill null postcodes\nfor i in range(0, len(stars.index)):\n    zipCode = stars[\"zipCode\"][i] #Get the zipcode\n    \n    #If the zipcode is null\n    if zipCode is np.nan:\n        location = geolocator.reverse((stars[\"latitude\"][i], stars[\"longitude\"][i])) #Get the zip code from the geolocator\n        \n        #Try to get the postcode/zipcode field from the locator\n        try:\n            stars[\"zipCode\"][i] = location.raw[\"address\"][\"postcode\"] #Get the zip code\n        \n        #Fill the code with 00000 if the code cannot be accessed\n        except:\n            stars[\"zipCode\"][i] = \"00000\" #Fill the zip code with 00000\n        \nprint(stars.isnull().any()) #Make sure the null values have been filled","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(stars.loc[[59]]) #Print a row with the zip code filled\nprint(stars.loc[[137]]) #Print a Hong Kong row that was null, which has no zip code field, so fill with 00000","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"# Plot on a Map"},{"metadata":{"trusted":true},"cell_type":"code","source":"lat = list(stars[\"latitude\"]) #Get the list of latitudes\nlon = list(stars[\"longitude\"]) #Get the list of longitudes\n\nplt.title(\"Star Restaurants\") #Add a title for the restaurants\n\n#Set a basemap for the world\nmRes = Basemap(width = 10000000, height = 10000000, projection = \"cyl\",\n            resolution = \"l\", lat_1 = 50.0, lat_2 = 0.0, lat_0 = 25.0, lon_0 = 0.0)\n\nmRes.drawcoastlines() #Draw the coastlines\nmRes.fillcontinents(color = \"lightgreen\") #Make the land light green\nxlon, ylat = mRes(lon, lat) #Fit the coordinates to fit with the map\nmRes.plot(xlon, ylat, \"b.\") #Plot the restaurants","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It seems this dataset specifically ignores various countries. The UK is littered with them, along with some in central Europe and Scandinavia. Other than that, restaurants are pretty sparce."},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"# Plot Different Colors for Different Star Numbers"},{"metadata":{"trusted":true},"cell_type":"code","source":"colors = [\"r.\", \"b.\", \"y.\"] #Define our colors\ni = 0 #Add an iterator for our colors\n\nfor star in stars[\"star\"].unique():\n    newStat = stars.loc[stars[\"star\"] == star] #Get the restaurants by star amount\n    lat = list(newStat[\"latitude\"]) #Get the list of latitudes\n    lon = list(newStat[\"longitude\"]) #Get the list of longitudes\n\n    plt.title(\"Star Restaurants by Star Count\") #Add a title for the restaurants\n\n    #Set a basemap for the world\n    mRes = Basemap(width = 10000000, height = 10000000, projection = \"cyl\",\n                resolution = \"l\", lat_1 = 50.0, lat_2 = 0.0, lat_0 = 25.0, lon_0 = 0.0)\n\n    mRes.drawcoastlines() #Draw the coastlines\n    mRes.fillcontinents(color = \"lightgreen\") #Make the land light green\n    xlon, ylat = mRes(lon, lat) #Fit the coordinates to fit with the map\n    mRes.plot(xlon, ylat, colors[i]) #Plot the restaurants\n    \n    i += 1 #Change the color","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The gold (3 star) appear to be located in the bigger areas of bigger countries in this dataset (ie around the major cities of San Francisco, Chicago, and New York in the US). I will need to zoom into Europe for a better understanding."},{"metadata":{"trusted":true},"cell_type":"code","source":"colors = [\"r.\", \"b.\", \"y.\"] #Define our colors\ni = 0 #Add an iterator for our colors\n\nfor star in stars[\"star\"].unique():\n    newStat = stars.loc[stars[\"star\"] == star] #Get the restaurants by star amount\n    lat = list(newStat[\"latitude\"]) #Get the list of latitudes\n    lon = list(newStat[\"longitude\"]) #Get the list of longitudes\n\n    plt.title(\"Star Restaurants by Star Count\") #Add a title for the restaurants\n\n    #Set a basemap for the Europe\n    mRes = Basemap(width = 10000000, height = 10000000, projection = \"lcc\",\n                resolution = \"l\", lat_1 = 50.0, lat_2 = 0.0, lat_0 = 25.0, lon_0 = 0.0)\n\n    mRes.drawcoastlines() #Draw the coastlines\n    mRes.fillcontinents(color = \"lightgreen\") #Make the land light green\n    xlon, ylat = mRes(lon, lat) #Fit the coordinates to fit with the map\n    mRes.plot(xlon, ylat, colors[i]) #Plot the restaurants\n    \n    i += 1 #Change the Color","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"My previous statement is affirmed by the 3 star restaurant in Vienna. I will need to zoom in closer to look at the UK and Scandinavia. I assume, since countries like France and Italy were explicitly excluded from the dataset, that they would look like the UK if they were included."},{"metadata":{"trusted":true},"cell_type":"code","source":"colors = [\"r.\", \"b.\", \"y.\"] #Define our colors\ni = 0 #Add an iterator for our colors\n\nfor star in stars[\"star\"].unique():\n    newStat = stars.loc[stars[\"star\"] == star] #Get the restaurants by star amount\n    lat = list(newStat[\"latitude\"]) #Get the list of latitudes\n    lon = list(newStat[\"longitude\"]) #Get the list of longitudes\n\n    plt.title(\"Star Restaurants by Star Count\") #Add a title for the restaurants\n\n    #Set a basemap for the UK\n    mRes = Basemap(width = 2500000, height = 2500000, projection = \"lcc\",\n                resolution = \"l\", lat_1 = 70.0, lat_2 = 50.0, lat_0 = 60.0, lon_0 = 0.0)\n\n    mRes.drawcoastlines() #Draw the coastlines\n    mRes.fillcontinents(color = \"lightgreen\") #Make the land light green\n    xlon, ylat = mRes(lon, lat) #Fit the coordinates to fit with the map\n    mRes.plot(xlon, ylat, colors[i]) #Plot the restaurants\n    \n    i += 1 #Change the Color","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Of course the 3 star areas are the large ones, namely London, Stolkholm, Copenhagen, and Oslo. I am honestly surprised how many restaurants have at least one star, especially in England and Wales specifically (ignoring Scotland and Northern Ireland). I was also nervous about the two locations located in seemingly the middle of the water near Sweden and above Scotland, but a look at Google Maps tells me those are on Bornholm and the Faroe Islands respectively."},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"# Star Classification"},{"metadata":{"trusted":true},"cell_type":"code","source":"#GetChara: Get the most important characteristics to the classification\n#Input: the characteristics, the model\n#Output: None\ndef getChara(characteristics, forest):\n    attributes = characteristics.columns #Get the tested attributes\n    attributes = list(zip(attributes, forest.feature_importances_)) #Zip the attributes together with their coefficient\n    sortAtt = sorted(attributes, key = lambda x: x[1], reverse = True) #Sort the zipped attributes by their coefficients\n\n    print(\"According to the Random Forest, the most important factors for restaurant stars are: \") #Start printing the most important labels\n    i = 0 #Counter variable so only the top five are printed\n\n    #For each attribute in the sorted attributes\n    for label, coef in sortAtt:\n        if i < 5: #If there has not been five printed yet\n            print(label) #Print the label as an important factor\n        i += 1 #Increase i by 1\n\n#ClassifyStars: Classify which restaurants are 1/2/3 stars\n#Input: The dataframe for the restaurants, the labels used\n#Output: None\ndef classifyStars(stars, labels):\n    star = stars[\"star\"].copy() #Get the star as our classification metric\n    star = pd.get_dummies(star) #Get dummies for the star metric\n\n    characteristics = stars.drop(columns = {\"star\"}).copy() #Get the characteristics used for classification\n    characteristics = pd.get_dummies(characteristics)\n    \n    charaTrain, charaTest, starTrain, starTest = train_test_split(characteristics, star, test_size = 0.3) #Split the dataset\n    \n    forest = RandomForestClassifier(n_estimators = 100) #Build a forest\n    forest.fit(charaTrain, starTrain) #Fit the forest model\n    \n    predict = forest.predict(charaTest) #Get a list of predictions\n    \n    print(\"Forest Accuracy: \", forest.score(charaTest, starTest)) #Print the accuracy\n    print(\"Root Mean Square Error: \", np.sqrt(mean_squared_error(starTest, predict))) #Print the root mean square error\n    print(\"Classification Report:\\n \", classification_report(starTest, predict, target_names = labels, zero_division = 0)) #Print a classification report\n    \n    getChara(characteristics, forest) #Get the important Characteristics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Try dropping the index column\ntry:\n    stars = stars.drop(columns = \"index\") #Drop the index column\n\n#Fill the except clause so it does not throw the error\nexcept:\n    a = 1 #Filler\n    \n#What to do after the index is dropped\nfinally:\n    labels = [\"1\", \"2\", \"3\"] #Set the labels\n    classifyStars(stars, labels) #Classify by star amount","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The size difference between the number of 1 star restaurants versus the others made it hard for it to classify the other ones at all. This made for a 83% classification rate, but it kept missing all the other labels."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}