{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction\n\nIn this notebook, we will try to predict the average score of a student based on their socio economic status, family background, as well as their gender. Below are the steps that we will be performing:\n\n1. Exploratory Data Analytics\n    * Checking for missing values\n    * Visualization of variables & correlations\n2. Data Engineering\n    * Hypothesis testing on the proportion of the scores, to further validate the use of students' average score\n    * Converting qualitative variables to dummy variables\n3. Data Modelling with:\n    * Linear Regression\n    * K Nearest Neighbour Regression\n    * Support Vector Regression (SVR)\n    * Neural Networks\n4. Comparison and Conclusion"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport scipy\nfrom scipy import stats\nimport statsmodels.formula.api as smf \nfrom sklearn.model_selection import train_test_split\nfrom sklearn import neighbors\nfrom sklearn.metrics import mean_squared_error \nfrom math import sqrt\nfrom sklearn.svm import SVR\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import make_scorer\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"students = pd.read_csv(\"/kaggle/input/students-performance-in-exams/StudentsPerformance.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analytics\nWe first take a look at the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"students.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The dataframe columns are renamed for easier accessibility"},{"metadata":{"trusted":true},"cell_type":"code","source":"students.columns = \"gender\",\"race\",\"parental_edu\",\"lunch\",\"test_prep\",\"math\",\"reading\",\"writing\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We also check if there are any missing data in the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"students.isna().sum()\n# No missing data in this dataset","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We then plot bar plots and histograms to visualize the distribution of the data for each variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"f, axs = plt.subplots(3,3,figsize=(15,15))\nstudents['gender'].value_counts().plot(kind='bar', ax=axs[0,0])\naxs[0,0].title.set_text('Gender')\nstudents['race'].value_counts().plot(kind='bar', ax=axs[0,1])\naxs[0,1].title.set_text('Race')\nstudents['parental_edu'].value_counts().plot(kind='bar', ax=axs[0,2])\naxs[0,2].title.set_text('Parental Education')\nstudents['lunch'].value_counts().plot(kind='bar', ax=axs[1,0])\naxs[1,0].title.set_text('Lunch')\nstudents['test_prep'].value_counts().plot(kind='bar', ax=axs[1,1])\naxs[1,1].title.set_text('Test Prep')\naxs[1,2].hist(students['math'])\naxs[1,2].title.set_text('Math')\naxs[2,0].hist(students['reading'])\naxs[2,0].title.set_text('Readiing')\naxs[2,1].hist(students['writing'])\naxs[2,1].title.set_text('Writing')\n\nf.delaxes(axs[2][2])\nf.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From this, we observe the following regarding the data:\n\n* Qualitative variables are distributed rather evenly between the classes, with no sparse classes.\n* Quantitative variables 'Math', 'Reading', and 'Writing' have a relatively normal distribution. Besides that, they have also taken on acceptable values within the range of 0 to 100 (i.e no outliers due to typos/data entry)"},{"metadata":{},"cell_type":"markdown","source":"Besides that, we also study the relationship between the quantitative variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(students.iloc[:,:])\nstudents.corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From this, it can be observed that the 3 score variables are quite highly correlated, with highest correlation between reading & writing. As this may affect the model output, we may remove certain variables during modelling or combine them during the data modelling stage"},{"metadata":{},"cell_type":"markdown","source":"# Data & Feature Engineering\n**Target Variable**\n\nBased on the high correlation between the 3 scores above, we hypothesize that the proportion of the scores are equal across the samples (students). We will perform the hypothesis test to verify this:\n\n* H0: Proportion of math scores = Proportion of writing scores = Proportion of reading scores across all students\n* H1: Proportions are not equal\n\nWe will perform the Pearson Chi-Squared test for proportion similarity"},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = students.loc[:,['math','reading','writing']].transpose()\n\nChisquares_results=scipy.stats.chi2_contingency(scores)\nprint(\"Chi-Squared test returns P-value of\", Chisquares_results[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Based on the P-value, we can deduce that the proportion of scores are similar across all students. Thus, we will calculate the average score, to be used as the prediction target"},{"metadata":{"trusted":true},"cell_type":"code","source":"students[\"average_score\"] = students.loc[:,['math','reading','writing']].mean(axis=1).round(1)\nstudents","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We are also interested in the shape of the data for average score, thus we will plot a histogram"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(students['average_score'])\nplt.title('Distribution of Student Average Scores')\nplt.xlabel('Score')\nplt.ylabel('Frequency')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Independent Variables**\n\nAs the columns \"gender\", \"race\", \"parental_edu\", \"lunch\" and \"test_prep\" are qualitative variables, we will create dummy variables for them, removing 1 dummy variable for each variable to prevent dummy trap (multi-collinearity problems)\n\nWe then concatenate the dummy variables with the original dataset, and remove the original variable, we will store this as a new dataframe students_d\n\nThe column names containing spaces are then renamed to omit the spaces"},{"metadata":{"trusted":true},"cell_type":"code","source":"students = pd.get_dummies(students, columns=['gender', 'race', 'parental_edu', 'lunch', 'test_prep'],\n               drop_first=True, prefix=['gender', 'race', 'parental_edu', 'lunch', 'test_prep'], prefix_sep='_')\n\nstudents.rename(columns={'race_group B': 'race_B', 'race_group C': 'race_C', 'race_group D': 'race_D', \n                             'race_group E': 'race_E', 'parental_edu_bachelor\\'s degree': 'parental_bachelor', \n                             'parental_edu_high school': 'parental_hs', 'parental_edu_master\\'s degree': 'parental_masters',\n                             'parental_edu_some college': 'parental_somecol', 'parental_edu_some high school': 'parental_somehs'}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n# Scores Prediction\n\nFor score prediction, we will try and compare several models, namely:\n* Linear Regression\n* K Nearest Neighbour Regression\n* SVR\n* Neural Networks"},{"metadata":{},"cell_type":"markdown","source":"# Linear Regression Model\nFor model validation, we will use validation set approach. For this, we first perform a train-test split on the data in the ratio of 70:30"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data,test_data = train_test_split(students, test_size = 0.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ml1 = smf.ols('average_score ~ gender_male+race_B+race_C+race_D+race_E+parental_bachelor+parental_hs+parental_masters+parental_somecol+parental_somehs+lunch_standard+test_prep_none', data=train_data).fit()\n\nml1.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the model summary, the R-squared value is extremely low. This is likely due to the low number of predictors that are all categorical variables.\n\nI have tried dropping variables, with no improvement on the R-squared value. Thus, we will leave the model as is. Besides that, transformations on the predictors will not work either as they are all coded as binary values only.\n\nWe are also interested to have a visualization of the predicted values. We will plot a histogram for this"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pred = ml1.predict(test_data)\n\nplt.hist(test_pred)\nplt.title('Distribution of Predicted Scores using Logistic Regression')\nplt.xlabel('Scores')\nplt.ylabel('Frequency')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From this, it can be observed that the model is predicting all score values between 50 and 90 only, and not able to handle extreme cases. \n\nHowever, the distribution of the data is rather similar to the average score, showing that the model is not blindly predicting certain scores all the time\n\nWe will calculate and store the RMSE values for final tabulation and comparison"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_resid  = test_pred - test_data.average_score\n\n# RMSE value for test data \nlr_test_rmse = np.sqrt(np.mean(test_resid*test_resid))\n\nprint(\"Test RMSE using logistic regression is:\",lr_test_rmse)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# K Nearest Neighbours Regression\nWe will fit the same test & train data onto the KNN regression algorithm"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_X = train_data.drop(['average_score','math','writing','reading'], axis=1)\ntrain_Y = train_data.loc[:,'average_score']\ntest_X = test_data.drop(['average_score','math','writing','reading'], axis=1)\ntest_Y = test_data.loc[:,'average_score']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fitting the model for values of k from 1 to 150 and calculating the resulting RMSE\n\nNote that this is only done for learning purpose as it is a small dataset, not recommended to run so many k values sequentially on large datasets"},{"metadata":{"trusted":true},"cell_type":"code","source":"rmse_val = [] #to store rmse values for different k\nfor K in range(150):\n    K = K+1\n    model = neighbors.KNeighborsRegressor(n_neighbors = K)\n\n    model.fit(train_X, train_Y)  #fit the model\n    pred=model.predict(test_X) #make prediction on test set\n    error = sqrt(mean_squared_error(test_Y,pred)) #calculate rmse\n    rmse_val.append(error) #store rmse values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Saving the data as a dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = {\"k\": range(1,151),\"RMSE\": rmse_val}\nfinal_rmse=pd.DataFrame(data)\nmin_index = final_rmse.iloc[:,1].idxmin()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plotting the rmse values against the number of neighbours, k, as well as the value which k returns min RMSE"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(final_rmse.k, final_rmse.RMSE)\nplt.plot(final_rmse.k[min_index],final_rmse.RMSE[min_index],'ro')\nplt.title('Plot of Test RMSE vs K number of neighbours')\nplt.xlabel('K')\nplt.ylabel('Test RMSE')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the elbow plot, we will select the smallest value of K that provides largest reduction in RMSE. From the plot, we will select the value K = 35 \n\nFor this value of K, we will plot a histogram to look at the distribution of predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = neighbors.KNeighborsRegressor(n_neighbors = 35)\nmodel.fit(train_X, train_Y) \npred=model.predict(test_X)\n\nplt.hist(pred)\nplt.title('Distribution of Predicted Scores for KNN Regression')\nplt.xlabel('Scores')\nplt.ylabel('Frequency')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the histogram, it can be seen that all the predicted scores fall on a very short range, from 55 to 80 only. \n\nThis is because the KNN algorithm averages the scores of the nearest neighbours, thus the predictions tend to fall closer to the average value of the data. \n\nIn other words, KNN regression is not able to give very accurate predictions of student scores (especially those on the lower ranges)"},{"metadata":{},"cell_type":"markdown","source":"We will store the rmse values for final tabulation and comparison"},{"metadata":{"trusted":true},"cell_type":"code","source":"knn_test_rmse = sqrt(mean_squared_error(test_Y,pred))\nprint(\"Test RMSE using KNN regression is:\",knn_test_rmse)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Support Vector Regression (SVR)\nWe will utilize the same train & test split data to model for SVR\n\nWe will model the data for the following kernels to select the best one:\n* Linear\n* Polynomial\n* Sigmoid\n* Gaussian (rbf)"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_linear = SVR(kernel=\"linear\")\nmodel_linear.fit(train_X, train_Y)\npred_linear = model_linear.predict(test_X)\nlinear_rmse = sqrt(mean_squared_error(test_Y,pred_linear))\n\n# kernel = poly\nmodel_poly = SVR(kernel=\"poly\")\nmodel_poly.fit(train_X, train_Y)\npred_poly = model_poly.predict(test_X)\npoly_rmse = sqrt(mean_squared_error(test_Y,pred_poly))\n\n# kernel = sigmoid\nmodel_sigmoid = SVR(kernel=\"sigmoid\")\nmodel_sigmoid.fit(train_X, train_Y)\npred_sigmoid = model_sigmoid.predict(test_X)\nsigmoid_rmse = sqrt(mean_squared_error(test_Y,pred_sigmoid))\n\n# kernel = rbf\nmodel_rbf = SVR(kernel=\"rbf\")\nmodel_rbf.fit(train_X, train_Y)\npred_rbf = model_rbf.predict(test_X)\nrbf_rmse = sqrt(mean_squared_error(test_Y,pred_rbf))\n\ndata = {\"kernel\":pd.Series([\"linear\",\"polynomial\",\"sigmoid\",\"rbf\"]),\n            \"Test RMSE\":pd.Series([linear_rmse,poly_rmse,sigmoid_rmse,rbf_rmse]),\n            \"Pred\":pd.Series([pred_linear,pred_poly,pred_sigmoid,pred_rbf])}\ntable_rmse=pd.DataFrame(data)\ntable_rmse\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So far, it seems like SVR is giving the best (lowest) RMSE out of the models. We will try to further improve the model by doing a grid search to find the best parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"K = 15\nparameters = [{'kernel': ['linear','sigmoid','rbf'], 'gamma': [2e-3,2e-2, 2e-1, 1, 2, 4, 8, 16],'C': [2e-5,2e-4,2e-3,2e-2, 2e-1, 1, 2, 4, 8, 16]}]\nscorer = make_scorer(mean_squared_error, greater_is_better=False)\nsvr_gs = GridSearchCV(SVR(epsilon = 0.01), parameters, cv = K, scoring=scorer)\n\nsvr_gs.fit(train_X, train_Y)\nprint(svr_gs.best_params_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We perform prediction for test data using the best parameters from grid search, and append this test RMSE to the table of results for SVR"},{"metadata":{"trusted":true},"cell_type":"code","source":"regressor = SVR(**svr_gs.best_params_)\nregressor.fit(train_X,train_Y)\npred=regressor.predict(test_X)\n\nerror = sqrt(mean_squared_error(test_Y,pred))\ndata = {\"kernel\":pd.Series([\"GS Output\"]),\"Test RMSE\":pd.Series([error]),\"Pred\":pd.Series([pred])}\ntable_rmse = table_rmse.append(pd.DataFrame(data))\nprint(table_rmse)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For the model that returns the lowest RMSE value, we plot a histogram to look at the distribution of the prediction values"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(table_rmse.Pred.iloc[table_rmse[\"Test RMSE\"].idxmin()])\nplt.title('Distribution of Predicted Scores for SVR')\nplt.xlabel('Scores')\nplt.ylabel('Frequency')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the histogram, it can be seen that all the predicted scores fall on a short range, from 55 to 85. Similar to the previous models, it is also unable to predict scores on the upper and lower ranges\n\nWe then store the lowest RMSE value for final tabulation and comparison"},{"metadata":{"trusted":true},"cell_type":"code","source":"svr_test_rmse = table_rmse[\"Test RMSE\"].min()\nprint(\"Test RMSE using SVR is:\",svr_test_rmse)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Neural Networks\n\nWe will fit the same train & test split data onto an artificial neural network\n\nNote that multiple activation functions and neural network structures are tested, but only the final network is shown here"},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"import tensorflow as tf\n\n# Importing necessary models for implementation of ANN\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n\ncont_model = Sequential()\ncont_model.add(Dense(100, input_dim=train_X.columns.value_counts().sum(), activation=\"softmax\"))\ncont_model.add(Dense(60, activation=\"relu\"))\ncont_model.add(Dense(1, kernel_initializer=\"normal\"))\ncont_model.compile(loss=\"mean_squared_error\", optimizer = \"adam\", metrics = [\"mse\"])\n\nmodel = cont_model\nmodel.fit(np.array(train_X), np.array(train_Y), epochs=300)\n\n# On Test dataset\npred = model.predict(np.array(test_X))\npred = pd.Series([i[0] for i in pred])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We plot a histogram to look at the distribution of the prediction values"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(pred)\nplt.title('Distribution of Predicted Scores for Neural Network')\nplt.xlabel('Scores')\nplt.ylabel('Frequency')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the histogram, it can be seen that all the predicted scores fall on a short range, from 55 to 85. Note that this is a similar theme across all models built\n\nWe store the lowest RMSE value for final tabulation and comparison"},{"metadata":{"trusted":true},"cell_type":"code","source":"nn_test_rmse = sqrt(mean_squared_error(test_Y,pred))\nprint(\"Test RMSE using ANN is:\",nn_test_rmse)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Comparison & Conclusion\nWe will tabulate the test & train accuracies for the 4 algorithms"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = {\"Model\":pd.Series([\"Linear Regression\",\"KNN Regression\",\"SVR\",\"Neural Network\"]),\n            \"Test RMSE\":pd.Series([lr_test_rmse,knn_test_rmse,svr_test_rmse,nn_test_rmse])}\ntable_final=pd.DataFrame(data)\ntable_final","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the final results, it is observed that linear regression and SVR provide the best models to predict student score. \n\nHowever, in all 4 models, the ranges of scores predicted are quite small, and the models are unable to predict scores on the higher and lower ranges of the spectrum. This is because the dataset is relatively small, and the input variables are all qualitative variables. A more accurate model can be produced to predict student scores, given more data & quantitative variables, for example:\n* hours spent studying a week\n* average score on previous exams\n* attendance in school\n* enrollment in extra classes"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}