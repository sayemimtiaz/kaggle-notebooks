{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport cufflinks as cf\nimport matplotlib.pyplot as plt\nimport plotly.graph_objects as go\nimport plotly as ply\nimport datetime as dt\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/novel-corona-virus-2019-dataset/COVID19_line_list_data.csv')\ndf.describe(include='all')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime as dt\n\ndf['ReportDateStamp'] = pd.to_datetime(df['reporting date'])\ndf['ReportDate_F'] = df['ReportDateStamp'].apply(lambda x: x.date())\nSta = df['ReportDateStamp'].max().strftime(\"%d/%m/%Y\")\nasa = dt.datetime.today().strftime(\"%d/%m/%Y\")\nEnd = df['ReportDateStamp'].min().strftime(\"%d/%m/%Y\")\n\nprint('Most Recent: ' + Sta)\nprint('Earliest: ' + End )\nprint('As At: ' + asa )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Look at the line-by-line dataset, doesn't seem to be updated or very big but still worth a look"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,5)) \nsns.set(palette='colorblind')\nsns.distplot(df['age'],rug=True,hist=False)\nplt.xlim(left=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Seems have at an overall level, double peaks. Lets see how it varies by country."},{"metadata":{"trusted":true},"cell_type":"code","source":"country_list = list(df['country'].value_counts().head(7).reset_index()['index'])\npopular_countries = df[df['country'].isin(country_list)]\n\n\nfig = go.Figure()\nfig.add_trace(go.Violin(x=popular_countries['country'][ popular_countries['gender'] == 'male' ],\n                        y=popular_countries['age'][ popular_countries['gender'] == 'male' ],\n                        legendgroup='M', scalegroup='M', name='Male',\n                        line_color='blue')\n             )\nfig.add_trace(go.Violin(x=popular_countries['country'][ popular_countries['gender'] == 'female' ],\n                        y=popular_countries['age'][ popular_countries['gender'] == 'female' ],\n                        legendgroup='F', scalegroup='F', name='Female',\n                        line_color='green')\n             )\n\nfig.update_traces(box_visible=True, meanline_visible=True)\nfig.update_layout(violinmode='group')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Conclusion from this plot shows that Thailand should focus on younger children since, the have the lowest concentration of ages. \nJapan could be worse effected since they have a higher median age of all countries for both genders. \nLooking at this plot, people across the world need to stop seeing their Grandmothers. Compared to males, females are skewed much higher on the infection for most countires."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(nrows=1,ncols=2,figsize=(12,6))\n\n\nelse_countries = df[~df['country'].isin(country_list)]\nsns.boxplot(y=else_countries['age'],x=else_countries['gender'],ax=ax[0])\nsns.boxplot(y=popular_countries['age'],x=popular_countries['gender'],ax=ax[1])\n\n# ax[2].table(cellText=else_countries['gender'].value_counts().reset_index()\n#             , cellColours=None, cellLoc='right', colWidths=None, rowLabels=None, \n#       rowColours=None, rowLoc='left', colLabels=None, colColours=None, colLoc='center',\n#       loc='right', bbox=None, edges='closed')\n\nax[0].title.set_text('All ex 7 countries')\nax[1].title.set_text('Top 7 countries')\n\n\nplt.ylim((0,100))\nprint(df['gender'].value_counts().reset_index())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Females seem to be much older when they contract virus when split down the different countires M/F, however when comparing the top 7 vs else, not so clear but *there is still a difference*. This shows that when countries get infected, they seem to be being driven by old(er) females. Could be noise but male distributions are consistent. Cannot draw any stable conclusions on 382 females overall"},{"metadata":{},"cell_type":"markdown","source":"## Next Step to try and categorise somehow the groups infected\n\n"},{"metadata":{},"cell_type":"markdown","source":"Use the rolling feature to show recovery figures"},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px\ntime_series = pd.read_csv('/kaggle/input/novel-corona-virus-2019-dataset/COVID19_line_list_data.csv',\n                          index_col='id', parse_dates=True)\ntime_series['recovered_value'] = np.where(time_series['recovered'] != '0',1,0)\ntime_series['case'] = 1\n\nplot1 = time_series.groupby(['reporting date'])['recovered_value','case'].sum()\nplot1['recovery_rate'] = plot1['recovered_value']/plot1['case'] \n# Compute the centered 7-day rolling mean\nplt.figure(figsize=(15,5))\nrolling=14\nplot1_7d = plot1.rolling(rolling, center=True).mean().reset_index()\nfig = px.line(plot1_7d, x=\"reporting date\", y=\"recovered_value\", title='Recovery figures  (rolling)')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looks like dataset hasn't been updated. Maybe continue once this has been refreshed?"},{"metadata":{},"cell_type":"markdown","source":"Could so classify the symptoms for dies vs not dies, might need more data though (?)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#sns.countplot(x='symptom',data=df)\ndf[['symptom_1','symptom_2','symptom_3']] = df['symptom'].str.split(pat=',', n=2, expand=True)\n\nplot,ax = plt.subplots(nrows=2,ncols=1,figsize=(22,10))\nsns.countplot(x='symptom_1',data=df,ax=ax[0])\nsns.countplot(x='symptom_2',data=df,ax=ax[1])\n\nax[0].set_title('Symptom (1)')\nax[1].set_title('Symptom (2)')\n\nfor ax in plot.axes:\n    plt.sca(ax)\n    plt.xticks(rotation=45)\n    plt.xlabel(' ')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So there is no need to go out and buy toilet paper after all, we can sleep soundly. \nPossibly need to stock up on Lemsip and cold packs."},{"metadata":{},"cell_type":"markdown","source":"## Switch datasets to the larger aggregate data, predict the cases X country"},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df = pd.read_csv('/kaggle/input/novel-corona-virus-2019-dataset/covid_19_data.csv',parse_dates=True,index_col='SNo')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df.describe(include='all')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df['ReportDateStamp'] = pd.to_datetime(new_df['Last Update'])\nnew_df['ReportDate_F'] = new_df['ReportDateStamp'].apply(lambda x: x.date())\nSta = new_df['ReportDateStamp'].max().strftime(\"%d/%m/%Y\")\nasa = dt.datetime.today().strftime(\"%d/%m/%Y\")\nEnd = new_df['ReportDateStamp'].min().strftime(\"%d/%m/%Y\")\n\nprint('Most Recent: ' + Sta)\nprint('Earliest: ' + End )\nprint('As At: ' + asa )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Analyse UK vs EU countries infection rates"},{"metadata":{},"cell_type":"markdown","source":"This df has been updated much more recently. \nHere I am interested in EU countires cases to the UK. So try and group EU countries (exclude Italy, analyse seperately)\nI want to see if the UK governments' sliggish response has effected the cases."},{"metadata":{"trusted":true},"cell_type":"code","source":"total_df = new_df.groupby(['Country/Region','ObservationDate'])['Confirmed'].sum().reset_index()\ncountries_summary  = new_df.groupby(['Country/Region'])['Confirmed'].sum().reset_index()\ncountries_summary  = countries_summary.loc[countries_summary['Country/Region'] != 'Mainland China',:]\ncountries_summary  = countries_summary.sort_values(by=['Confirmed'],ascending=0).head(15)\n\nplt.figure(figsize=(20,5))\nsns.barplot(x='Country/Region',y='Confirmed',data=countries_summary)\nplt.xticks(rotation=45)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Simple countplot of all countries in df, excluding mainland China. Which clearly has the most cases. Next would be to group the EU countires excluding Italy to stop it skewing result."},{"metadata":{"trusted":true},"cell_type":"code","source":"EU_MAP = dict({\"Austria\" : 'EU',\n\"Belgium\" : 'EU' ,\n\"Bulgaria\" : 'EU' ,\n\"Croatia\" : 'EU' ,\n\"Cyprus\" : 'EU' ,\n\"Czechia\" : 'EU' ,\n\"Denmark\" : 'EU' ,\n\"Estonia\" : 'EU' ,\n\"Finland\" : 'EU' ,\n\"France\" : 'EU' ,\n\"Germany\" : 'EU' ,\n\"Greece\" : 'EU' ,\n\"Hungary\" : 'EU' ,\n\"Ireland\" : 'EU' ,\n#\"Italy\" : 'EU' ,\n\"Latvia\" : 'EU' ,\n\"Lithuania\" : 'EU' ,\n\"Luxembourg\" : 'EU' ,\n\"Malta\" : 'EU' ,\n\"Netherlands\" : 'EU' ,\n\"Poland\" : 'EU' ,\n\"Portugal\" : 'EU' ,\n\"Romania\" : 'EU' ,\n\"Slovakia\" : 'EU' ,\n\"Slovenia\" : 'EU' ,\n\"Spain\" : 'EU' ,\n\"Sweden\" : 'EU' ,\n\"UK\" : 'UK'})\n\nnew_df['EU_member'] = new_df['Country/Region'].map(EU_MAP)\nnew_df.groupby(['EU_member'])['Confirmed'].sum().reset_index()\n\n\ngroupd_df = new_df.groupby(['EU_member']).agg({'Confirmed': 'sum'})\n# Change: groupby state_office and divide by sum\npcts = groupd_df.apply(lambda x: 100 * x / float(x.sum()))\npcts","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It's not going to be a straight comparison since UK only represents 5% of cases. "},{"metadata":{"trusted":true},"cell_type":"code","source":"d1 = dt.datetime(2020,2,15) \nnew_df['ObservationDate_F'] = pd.to_datetime(new_df['ObservationDate'])\nnew_df = new_df.loc[new_df['ObservationDate'] >= d1,:]\n\ntime_series = new_df.groupby(['EU_member','ObservationDate_F'])['Confirmed'].sum().reset_index()\n\n\n\nplt.figure(figsize=(20,5))\nsns.lineplot(x='ObservationDate_F', y='Confirmed', data=time_series, hue='EU_member')\nplt.xticks(rotation=45)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.pipeline import Pipeline\n\nmodel = Pipeline([('poly', PolynomialFeatures(degree=2)),('linear', LinearRegression(fit_intercept=False))])\n\nmodel = model.fit(x[:, np.newaxis], y)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}