{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split,GridSearchCV\nfrom sklearn.metrics import roc_auc_score,accuracy_score,confusion_matrix\n\nfrom sklearn.preprocessing import StandardScaler,MinMaxScaler\n\nimport warnings","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv\")\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"    The data contains 7043 rows of data with 21 different features.","metadata":{}},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"    Most of the columns are non-numeric which we need to encode to numeric. The 'Churn' column is the target","metadata":{}},{"cell_type":"markdown","source":"    TotalCharges is non-numeric. So convert into numeric datatype and check for any missing values in raw data.","metadata":{}},{"cell_type":"code","source":"df['TotalCharges'] = pd.to_numeric(df['TotalCharges'],errors='coerce')\ndf.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['TotalCharges'].fillna(0,inplace=True)\ndf = df[df['TotalCharges'] !=0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"    11 rows of TotalCharges are null. Replace it with 0 and remove them as its a small data","metadata":{}},{"cell_type":"markdown","source":"    A look at the non-numeric columns and their unique values","metadata":{}},{"cell_type":"code","source":"obj_cols = df.select_dtypes(include='O').columns\nobj_cols = obj_cols.drop(['customerID'])\nfor col in obj_cols:\n    print(col,':',df[col].unique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Visualization","metadata":{}},{"cell_type":"code","source":"cols = ['gender', 'SeniorCitizen', 'Partner', 'Dependents','PhoneService', 'InternetService', 'Contract',\n       'PaperlessBilling', 'PaymentMethod']\nfor col in cols:\n    plt.figure(figsize=(10, 4))\n    plt.title(col)\n    ax = sns.countplot(data=df, x=col, hue='Churn')\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"    Observations from above visuals - \n    \n    Customers opting for Electronic payment are more probable churn.\n    Customers with Paperless Billing are more probable to churn.\n    Short term contract customers are more likely to churn.\n    Customers with Fiber Optics internet service have high churn rate","metadata":{}},{"cell_type":"code","source":"df1 = df.drop(['customerID', 'Churn', 'TotalCharges','tenure', 'MonthlyCharges'],axis=1)\n\nplt.figure(figsize=(24, 12))\ncorr = df1.apply(lambda x: pd.factorize(x)[0]).corr()\nax = sns.heatmap(corr, xticklabels=corr.columns, annot=True,yticklabels=corr.columns, \n                 linewidths=.2, cmap=\"YlGnBu\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"    PhoneService and MultipleLines have some correlation. InternetService is related to OnlineSecurity, Online \n    Backup,DeviceProtection,TechSupport,StreamingTV,StreamingMovies ","metadata":{}},{"cell_type":"markdown","source":"    Encode the non-numeric values into numeric labels","metadata":{}},{"cell_type":"code","source":"df['gender'] = df['gender'].map({'Female':0,'Male':1})\ndf['gender'].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols = ['Partner','Dependents','PhoneService','PaperlessBilling','Churn']\nfor c in cols:\n    df[c] = df[c].map({'Yes':1,'No':0})\n    print(c,':',df[c].unique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"    Looking into the column PhoneService and MultipleLines","metadata":{}},{"cell_type":"code","source":"df[(df.PhoneService==0) & (df.MultipleLines == 'No phone service')]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Seems redundant to have 'No phone service' in MultipleLines as PhoneService(0 or 1) already conveys the same. We can use dummy or one hot encoding to get a seperate column and then delete the unwanted one","metadata":{}},{"cell_type":"code","source":"df = pd.concat([df,pd.get_dummies(df['MultipleLines'],prefix='MultipleLines')],axis=1).drop('MultipleLines',axis=1)\ndf.drop('MultipleLines_No phone service',axis = 1, inplace=True)\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['InternetService'] = df['InternetService'].map({'No':0,'DSL':1,'Fiber optic':1})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"    Some columns are related to Internet Service. One hot encoding and dropping the no internet column which would be \n    redundant.","metadata":{}},{"cell_type":"code","source":"cols = ['OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies']\n\nfor col in cols:\n    df = pd.concat([df,pd.get_dummies(df[col],prefix=col)],axis=1).drop(col,axis=1)\n\ndf.drop(['OnlineSecurity_No internet service','OnlineBackup_No internet service','DeviceProtection_No internet service',\n             'TechSupport_No internet service','StreamingTV_No internet service','StreamingMovies_No internet service'],\n            axis=1,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"    Encoding the Contract and PaymentMethod","metadata":{}},{"cell_type":"code","source":"df['Contract'] = df['Contract'].map({'Month-to-month':0, 'One year':1, 'Two year':2})\ndf['PaymentMethod'] = df['PaymentMethod'].map({'Electronic check':0, 'Mailed check':1, 'Bank transfer (automatic)':2,\n                                           'Credit card (automatic)':3})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"df['Tenure'] = pd.cut(df['tenure'],bins=4,labels=['<20','20-40','40-60','>60'])\ndf.drop(['tenure'],axis=1,inplace=True)\nprint(df['Tenure'].value_counts())\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.concat( [df,pd.get_dummies(df['Tenure'],prefix='Tenure')],axis=1).drop('Tenure',axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sc = StandardScaler()\ndf['MonthlyCharges'] = sc.fit_transform(df[['MonthlyCharges']].values)\ndf['TotalCharges'] = sc.fit_transform(df[['TotalCharges']].values)\n\n#mm = MinMaxScaler()\n#df['MonthlyCharges'] = mm.fit_transform(df[['MonthlyCharges']].values)\n#df['TotalCharges'] = mm.fit_transform(df[['TotalCharges']].values)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df.drop(['customerID','Churn'],axis=1)\ny = df['Churn']\ny.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"    Looks like a imbalanced data as there are less Churn customers","metadata":{}},{"cell_type":"code","source":"X_train,X_test,y_train,y_test = train_test_split(X,y,stratify=y,test_size=0.3)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"    Checking with Decision Tree, RandomForest and LogisticRegression (without tuning the model parameters)","metadata":{}},{"cell_type":"code","source":"dt_model = DecisionTreeClassifier()\ndt_model.fit(X_train,y_train)\ndt_pred  =dt_model.predict(X_test)\n\ndt_roc_auc_score_default = roc_auc_score(y_test, dt_pred)\ndt_accuracy_default = accuracy_score(y_test, dt_pred)\n\nprint(dt_accuracy_default)\nprint(confusion_matrix(y_test, dt_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rfc_model = RandomForestClassifier()\nrfc_model.fit(X_train,y_train)\nrfc_pred =  rfc_model.predict(X_test)\n\nrfc_roc_auc_score_default = roc_auc_score(y_test, rfc_pred)\nrfc_accuracy_default = accuracy_score(y_test, rfc_pred)\n\nprint(rfc_accuracy_default)\nprint(confusion_matrix(y_test, rfc_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"log_model = LogisticRegression()\nlog_model.fit(X_train,y_train)\nlog_pred =  log_model.predict(X_test)\n\nlog_roc_auc_score_default = roc_auc_score(y_test, log_pred)\nlog_accuracy_default = accuracy_score(y_test, log_pred)\n\nprint(log_accuracy_default)\nprint(confusion_matrix(y_test, log_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"    Exploring the important features","metadata":{}},{"cell_type":"markdown","source":"    Parameter Tuning","metadata":{}},{"cell_type":"code","source":"param_grid = {\"criterion\":['gini','entropy'], \n              \"max_depth\":[5,10,15,20]\n             }    \ngrid = GridSearchCV(DecisionTreeClassifier(), param_grid,verbose=True)\ngrid.fit(X_train,y_train)\nbest_param = grid.best_params_\nbest_param","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dt_model = DecisionTreeClassifier(criterion=best_param['criterion'],max_depth=best_param['max_depth'])\ndt_model.fit(X_train,y_train)\ndt_pred  =dt_model.predict(X_test)\ndt_roc_auc_score = roc_auc_score(y_test, dt_pred)\ndt_accuracy = accuracy_score(y_test, dt_pred)\n\nprint(dt_accuracy)\n\nprint(confusion_matrix(y_test, dt_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"param_grid = {\"n_estimators\":[5,20,50], 'max_depth':range(5,16,5), 'min_samples_split':range(200,1001,500),\n              'min_samples_leaf':range(30,71,20), \n             }    \ngrid = GridSearchCV(RandomForestClassifier(), param_grid,verbose=True)\ngrid.fit(X_train,y_train)\nbest_param = grid.best_params_\nbest_param","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rfc_model = RandomForestClassifier(max_depth = best_param['max_depth'],\n                                   min_samples_leaf = best_param['min_samples_leaf'],\n                                   min_samples_split = best_param['min_samples_split'],\n                                   n_estimators = best_param['n_estimators'])\nrfc_model.fit(X_train,y_train)\nrfc_pred =  rfc_model.predict(X_test)\nrfc_roc_auc_score = roc_auc_score(y_test, rfc_pred)\nrfc_accuracy = accuracy_score(y_test, rfc_pred)\nprint(rfc_accuracy)\n\nprint(confusion_matrix(y_test, rfc_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000] }\nparam_grid={'C': np.logspace(-3, 0, 20)}\ngrid = GridSearchCV(LogisticRegression(), param_grid)\ngrid.fit(X_train,y_train)\nbest_param = grid.best_params_\nbest_param","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"log_model = LogisticRegression(C = best_param['C'])\nlog_model.fit(X_train,y_train)\nlog_pred =  log_model.predict(X_test)\nlog_roc_auc_score = roc_auc_score(y_test, log_pred)\nlog_accuracy = accuracy_score(y_test, log_pred)\nprint(log_roc_auc_score)\nprint(log_accuracy)\nprint(confusion_matrix(y_test, log_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models_scores = pd.DataFrame({'roc_auc_score_default':[log_roc_auc_score_default,dt_roc_auc_score_default,rfc_roc_auc_score_default],\n                             'roc_auc_score_tuned':[log_roc_auc_score,dt_roc_auc_score,rfc_roc_auc_score],\n                              'accuracy_default':[log_accuracy_default,dt_accuracy_default,rfc_accuracy_default], \n                             'accuracy_tuned':[log_accuracy,dt_accuracy,rfc_accuracy],\n                              \n                             },index = ['logit','tree','forest'])\n\nmodels_scores","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"    Logistic Regression seems to have better metrics for this dataset","metadata":{}}]}