{"cells":[{"metadata":{},"cell_type":"markdown","source":"# 1. Introduction\n\nThis EDA was developed for a data science project I did on the craigslist vehicle listings in my local area. I thought it would be intersting to apply the same methods to this larger dataset. The github repo for the original project is [here](https://github.com/asylve/Craiglist-Cars-Study)."},{"metadata":{},"cell_type":"markdown","source":"# 2. Loading Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ncars = pd.read_csv('/kaggle/input/craigslist-carstrucks-data/vehicles.csv')\ncars = cars[cars.price<1e5]#drop cars with prices above $100,000 and below $100\ncars = cars[cars.price>100]\ncars = cars[['id', 'price', 'year', 'manufacturer', 'model', 'odometer', 'type', 'lat', 'long']]#we will only look at these columns in the analysis\ncars['age'] = 2020 - cars['year'] #add an age column\ncars.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Missing Data"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def get_missing_info(df):\n    num_entries = df.shape[0]*df.shape[1]\n    null_entries = df.isnull().sum().sum()\n    percent_empty = null_entries/num_entries*100\n    num_missing = df.isna().sum()\n    percent_missing = num_missing/len(df)*100\n    col_modes = df.mode().loc[0]\n    percent_mode = [df[x].isin([df[x].mode()[0]]).sum()/len(df)*100 for x in df]\n    missing_value_df = pd.DataFrame({'num_missing': num_missing,\n                                     'percent_missing': percent_missing, \n                                     'mode': col_modes,\n                                     'percent_mode':percent_mode})\n    print('total empty percent:', percent_empty, '%')\n    print('columns that are more than 97% mode:', missing_value_df.loc[missing_value_df['percent_mode']>97].index.values)\n    return(missing_value_df)\nget_missing_info(cars)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fill the missing 'type' column with the most frequent type for the model of vehicle"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#fill missing type column with mode from model column\nimport math\ndef modef(x):#get mode of groupby row\n    m = pd.Series.mode(x)\n    if len(m)==1: \n        return m\n    if len(m)==0:\n        return 'unknown'\n    else: return m[0]\n\ndef isnan(x):#check if entry is nan\n    try:\n        out = math.isnan(float(x))\n    except:\n        out = False\n    return(out)\n\ndef fill_type(x):#fill type column with mode of model columns\n    if isnan(x['type']):\n        try:\n            out = model_types[x['model']] \n        except:\n            out = 'unknown'\n    else:\n        out = x['type']\n    return(out)\n\nmodel_types = cars.groupby(['model'])['type'].agg(modef)\ncars['type'] = cars.apply(fill_type, axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Price Histogram and Density Functions"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#plot price histogram\nsns.displot(cars, x='price', binwidth=1000, height=5, aspect=2)#, bw_adjust=0.4)\nplt.xticks(range(0,int(1e5), int(1e4)))\nplt.xlabel('Price ($)')\nplt.title('Price Distribution of Vehicles (Under $100,000)')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#plot pricing probability density for different types of vehicle\ncars_plt = cars[cars.type.isin(['sedan', 'SUV', 'truck'])]\nsns.displot(cars_plt, x='price', hue='type', kind='kde', bw_adjust=0.6, cut=0, common_norm=False, height=5, aspect=2)\nplt.xticks(range(0,int(1e5), int(1e4)))\nplt.xlabel('Price ($)')\nplt.xlim(0,int(1e5))\nplt.ylabel('Normalized Probability Density')\nplt.title('Price Density Distribution by Type (Under $100,000)')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Above is the smoothed distribution of price for sedans, SUVs, and Trucks. The curves hve been noramlized so the area under each curve is 1. Sedans are the most skewed to the low price end. The SUV curve looks closer to the sedan curve than the truck curve, which is indicative of a general trend for SUVs becoming people's 'daily driver'.\n\nTrucks have lower end options (under \\\\$10,000) but are also commonly found in the \\\\$30,000-\\$40,000 range. For all types of vehicles it looks like there is a psychological strategy of pricing just under multiples of \\\\$10,000 to make the price seem lower than it actually is."},{"metadata":{},"cell_type":"markdown","source":"# 5. Price Distribution by Odometer and Year\n\nA contourplot of price vs odometer and year can give a birds-eye view of how vehicles depreciate over their lifetime. However generating such as plot is complicated by the noise and sparsity of the pricing data. That is, for a given year and odometer reading, there can be many different prices in the dataset, and the data is not filled in in a nice grid-like fashion. To get around this, the pricing data was first interpolated, then smoothed with a moving average filter.\n\nThe plots below and to the left show the raw scattered datapoints and three different methods for interpolating into a uniform grid. The 'nearest' was chosen and smoothed using a moving average with a window of 15,000mi and 3 years."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#get contour plot of price vs odometer and year\ncarsd = cars.dropna(axis=0, subset=['odometer', 'year'])#drop rows if odometer or year are missing\n\n#interpolate pricing data using several different methods\nfrom scipy.interpolate import griddata\n#available sample data for the contour plot\nxs = carsd['odometer']\nys = carsd['year']\nzs = carsd['price']\npoints = np.array([xs, ys]).T \n#we wish to interpolate the data above onto the grid below\ngrid_x, grid_y = np.meshgrid(\n    np.linspace(0,3e5,10000), #odometer goes from 0 to 300,000km with steps of 300,000/10000 = 30mi\n    np.arange(1970,2021,1)) #year goes from 1970 to 2021 in steps of 1 year\n\n#try out three different methods of interpolation\ngrid_z0 = griddata(points, zs, (grid_x, grid_y), method='nearest')\ngrid_z1 = griddata(points, zs, (grid_x, grid_y), method='linear')\ngrid_z2 = griddata(points, zs, (grid_x, grid_y), method='cubic')\n\n#plot the raw data\nfig, axs = plt.subplots(2, 2, figsize=(12,10))\naxs[0,0].scatter(xs, ys, c=zs)\naxs[0,0].set_xlim(0,6e5)\naxs[0,0].set_title('raw data')\n\n#plot the three different interpolation methods\nim = axs[0,1].contour(grid_x, grid_y, grid_z0)\nfig.colorbar(im, ax=axs[0,1])\naxs[0,1].set_title('nearest')\n\nim = axs[1,0].contour(grid_x, grid_y, grid_z1)\nfig.colorbar(im, ax=axs[1,0])\naxs[1,0].set_title('linear')\n\nim = axs[1,1].contour(grid_x, grid_y, grid_z2)\nfig.colorbar(im, ax=axs[1,1])\naxs[1,1].set_title('cubic')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#Filter out noise in the interpolated dataset and plot the final contour.\nfrom scipy.signal import convolve2d\nsz_o = 500 #size of averaging window for odometer (500steps * 60mi/step = 30,000mi)\nsz_y = 3 #size of averaging window for year (3 years or +-1 year)\nkernel = np.ones((sz_y,sz_o))/(sz_y*sz_o)#averaging kernel, corresponds to averaging over +-15000 mi and +-1 year\ngrid_z0f = convolve2d(grid_z0, kernel, boundary='symm', mode='same')#run a moving average over the 'nearest' interpolated dataset\n\nfig, ax = plt.subplots(1, figsize=(9,7))\nim = ax.contourf(grid_x, grid_y, grid_z0f, levels=15, cmap='RdYlBu_r', zorder=0)\ncbar = fig.colorbar(im, ax=ax)\ncbar.set_label('Price ($)')\nax.set_xlim(0, 3e5)\nax.set_xlabel('Odometer (mi)')\nax.set_ylabel('Year')\nax.set_title('Contours of Averaged Pricing Data')\nax.grid(True, color='k')\nax.annotate(\"\", xy=(1.35e5, 2010), xytext=(0, 2020), arrowprops=dict(arrowstyle=\"->\", color='k'))\nplt.show()\n\nxloc_e = np.where((1.349e5<grid_x[0]) & (grid_x[0]<1.36e5)) #find x grid location where km's driven is what we want\nyloc_e = 40 #row 30 of the y grid is 2010\nprice_end = grid_z0f[yloc_e,xloc_e[0]]\nyloc_s = 50 #row 40 of the y grid is 2020\nxloc_s = np.where(grid_x[0]==0)\nprice_start = grid_z0f[yloc_s,xloc_s[0]]\ndepr_rate = ((price_start-price_end)/1.35e5)[0]\nprint('Benchmark Depreciation rate: ${:.2f}/mi'.format(depr_rate))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"According to this data, a new vehicle would lose ~35\\% (\\\\$12,000) of its value after 20 years with no driving. On the other hand, the same vehicle driven 50,000mi in one year would lose 30\\% (\\\\$10,000) of its value. To put this in practical terms, the arrow on the plot indicates the depreciation for a vehicle driven 13,500 miles per year (average for US) for 10 years. This works out to a depreciation of 72\\% (\\\\$34,000 to \\\\$11,000) which is a depreciation rate of $0.17/mi."},{"metadata":{},"cell_type":"markdown","source":"# 6. Pricing of the Most Popular Vehicles"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#Take a look at the most popular vehicles for sale\ncars['make_model'] = cars['manufacturer'] + ': ' + cars['model'] #add a column with the make and model in one string (for plotting)\ncom_cars = cars.make_model.value_counts()[:25]#the 25 most popular cars\n\n#plot the results\nfig = com_cars.plot.bar(figsize=(12,5))\nplt.xlabel('Make and Model')\nplt.ylabel('Number of Postings')\nplt.title('25 Most Popular Vehichles')\nplt.xticks(rotation=80)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#plot the average prices of the 25 most popular cars\ncom_price = cars.loc[cars.make_model.isin(com_cars.index)]\nordered_labels = com_price.groupby('make_model').price.median().sort_values(ascending=False).index.values\n\nfig, ax = plt.subplots(figsize=(12,6))\nsns.boxplot(data=com_price, x=\"make_model\", y=\"price\", order=ordered_labels, ax=ax)\nplt.xticks(rotation = 80)\nplt.xlabel('Make and Model')\nplt.ylabel('Price ($)')\nplt.title('Pricing of the 25 Most Popular Vehichles')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#plot the average prices of the 25 most popular trucks, trucks, and SUVS\nfor thing in ['sedan', 'truck', 'SUV']:\n    com = cars[cars['type']==thing].make_model.value_counts()[0:25].index\n    com_price = cars.loc[cars.make_model.isin(com)]\n    ordered_labels = com_price.groupby('make_model').price.median().sort_values(ascending=False).index.values\n    \n    fig, ax = plt.subplots(figsize=(12,6))\n    sns.boxplot(data=com_price, x=\"make_model\", y=\"price\", order=ordered_labels, ax=ax)\n    plt.xticks(rotation = 80)\n\n    plt.xlabel('Make and Model')\n    plt.ylabel('Price ($)')\n    plt.title('Pricing of the 25 Most Popular {}s'.format(thing.capitalize()))\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 7. Depreciation of the Most Popular Vehicles\n\nWhen buying a car, you are not only interested in the current price, but the future price you might be able to sell it for. Here we will fit a decaying exponential function to individual model of vehicle to quantify the depreciation of that model over time. This will tell us if that model 'holds its value'."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#fit an exponential to the toyota corolla data to determine how well it holds its value\nfrom scipy.optimize import curve_fit\ndef func(x, a, b):\n    return a * np.exp(-b*x)#exponential function we will use to fit\n\ndef plot_depr(data, func, model):\n    #get model data and filter out cars older than 50 years\n    df = data[(data['make_model']==model) & (data['age']<=50)].sort_values(by='age')\n    xdata = df['age']\n    ydata = df['price']\n    \n    #fit to the data\n    popt, _ = curve_fit(func, xdata, ydata, p0=[4e4, 0.1])#fit the exponential to the data\n    init = popt[0]#intiial value (age=0) according to the curve fit\n    depr20 = -np.log(0.80)/popt[1]#time to depreciate 20% according to the curve fit\n    depr90 = -np.log(0.10)/popt[1]#time to depreciate 90% according to the curve fit\n    \n    fig, ax = plt.subplots(figsize=(10,5))\n    carplt = ax.scatter(xdata, ydata, c=df['odometer'], cmap='viridis')#scatter plot of age vs price, colored by odometer    \n    plt.plot(xdata, func(xdata, *popt), 'r--')#plot the fitted curve\n    \n    plt.text(0.5, 0.85, \n             'Initial Value: {:,.0f}$\\n'\n             'Time to lose 20% value: {:.2f} years\\n'\n             'Time to lose 90% value: {:.2f} years'.format(init, depr20, depr90),\n             transform = ax.transAxes, \n            bbox=dict(facecolor='white', edgecolor='black'))\n    \n    cbar=plt.colorbar(carplt)\n    cbar.set_label('Odomater (mi)')\n    plt.xlabel('Age (years)')\n    plt.ylabel('Price ($)')\n    plt.title(model)\n    plt.show()\n    \nplot_depr(cars, func, 'toyota: corolla')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#run curve fits for the 25 most popular sedans, SUVs, and trucks and plot\nfor kind in ['sedan', 'SUV', 'truck']:#loop over the type of vehicle\n    com = cars[cars['type']==kind].make_model.value_counts()[0:25].index #25 most popular models of this type\n    depr_df = pd.DataFrame(columns={'Model', 'val0', 'depr20', 'depr90'}) #initialize an empty dataframe to hold the data\n    for name in com:#loop over the models\n        df = cars[(cars['make_model']==name) & (cars['age']<=50)].sort_values(by='age')\n        xdata = df['age']\n        ydata = df['price']  \n        popt, pcov = curve_fit(func, xdata, ydata, p0=[4e4, 0.1])\n\n        init = popt[0]\n        depr20 = -np.log(0.80)/popt[1]\n        depr90 = -np.log(0.10)/popt[1]\n        depr_df = depr_df.append({'Model':name, 'val0':init, 'depr20':depr20, 'depr90':depr90}, ignore_index=True)\n\n    depr_df = depr_df.sort_values(by='depr20', ascending=False)\n\n    fig, ax = plt.subplots(figsize=(12,5))\n    sns.barplot(data=depr_df, x='Model', y='depr20', ax=ax)\n    plt.title('Depreciation of the 25 Most Popular {}s'.format(kind.capitalize()))\n    plt.ylabel('Time to Depreciate 20% (Years)')\n    plt.xticks(rotation = 80)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Many people say that Toyotas hold their value. Let us see if that is true in our dataset by calculating the median deprecition value for different vehicle manufacturers."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#Boxplot of deprecition for different manufactureers\nmakes = cars['manufacturer'].value_counts()[:15].index#15 most popular manufacturers\ndepr_df = pd.DataFrame(columns={'Make', 'Model', 'val0', 'depr20', 'depr90'})#this will hold the depreciation data\nfor make in makes:#loop over manufactureres\n    com = cars[cars['manufacturer']==make].model.value_counts()[0:10].index #get the 10 most poopular models by the manufacturer\n    for name in com:#look over the models\n        df = cars[(cars['model']==name) & (cars['age']<50)].sort_values(by='age')#get data for the model for ages under 50\n        xdata = df['age']\n        ydata = df['price']  \n        popt, pcov = curve_fit(func, xdata, ydata, p0=[4e4, 0.1])#fit to the data\n\n        init = popt[0]#initial value\n        depr20 = -np.log(0.80)/popt[1]#time to depreciate 20%\n        depr90 = -np.log(0.10)/popt[1]#time to depreciate 90%\n        #append this data to the dataframe\n        depr_df = depr_df.append({'Make':make, 'Model':name, 'val0':init, 'depr20':depr20, 'depr90':depr90}, ignore_index=True)\n\n#order the data in terms of decreasing median depreciation time\norder = depr_df.groupby('Make')['depr20'].median().sort_values(ascending=False).index\n\nfig, ax=plt.subplots(figsize=(12,5))\nsns.boxplot(data=depr_df, x='Make', y='depr20', order=order)\nplt.title('Depreciation of the 15 Most Popular Makes of Vehicle')\nplt.ylabel('Time to Depreciate 20% (Years)')\nplt.ylim(0.5,4)\nplt.xticks(rotation=90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So in the US, Jeeps and Rams hold their value the best. It seems folks like big 4wd vehicles. In the case of jeeps, some older models are highly sought after and can actually appreciate in value, which we might be seeing here. Toyotas also hold their value the well, with a median time of about 2.2 years for a vehicle to depreciate 20\\%. \n\nUse caution when interpreting this data due to the large variability within manufacturers. It is likely best to determine the depreciation value for the individual model in question when considering a purchase."},{"metadata":{},"cell_type":"markdown","source":"# 8. Geographic Distribution of Vehicles"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#map distribution of vehichles\nimport geopandas as gpd\nimport contextily as ctx\ngdf = gpd.GeoDataFrame(#convert the data to a geodataframe so it can be plotted on a map\n    cars, geometry=gpd.points_from_xy(cars.long, cars.lat))\n#remove data outside the geographic area of interest\ngdf = gdf[(22<gdf.lat) & (gdf.lat<65) & (-144<gdf.long) & (gdf.long<-56)]\n#tell geopandas what the coordinate system of our data is\ngdf = gdf.set_crs(epsg=4326)#this is the latitude/longitude system the scraped data was in\ngdf = gdf.to_crs(epsg=3857)#this is the coordinate system that the imported map is in\n\n#plot the geographic area where data was collected and the points of the vehicles\nax = gdf.plot(figsize=(10, 10), alpha=0.5, edgecolor='k')\nctx.add_basemap(ax, zoom=4)\nplt.xlim(-1.5e7,-0.7e7)\nplt.ylim(2.15e6,6.65e6)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's take a closer at how different types of vehicle are distributed from coast to coast."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#plot the distribution of sedans, trucks, and suvs in the area around Vancouver\nimport geoplot\nextent = (-1.5e7,-0.7e7, 2.6e6,6.5e6) #x and y limits of where we will plot\n\n#look at sales of trucks, sedans, and SUVS\ngtrucks = gdf[(gdf['type']=='truck')]\ngsedans = gdf[(gdf['type']=='sedan')]\ngsuvs = gdf[(gdf['type']=='SUV')]\n#get the longitude data for each type of vehicle\ntrucks= pd.Series(gtrucks.geometry.x)\nsedans= pd.Series(gsedans.geometry.x)\nsuvs= pd.Series(gsuvs.geometry.x)\n\nfig, ax = plt.subplots(2, figsize=(13, 8), gridspec_kw={'height_ratios': [1, 6], 'hspace':0})\n#plot the density distribution of each type by longitde\nsns.kdeplot(data=trucks, ax=ax[0], clip=(extent[0], extent[1]), bw_adjust=0.35, label='Trucks', color='red')\nsns.kdeplot(data=sedans, ax=ax[0], clip=(extent[0], extent[1]), bw_adjust=0.35, label='Sedans', color='blue')\nsns.kdeplot(data=suvs, ax=ax[0], clip=(extent[0], extent[1]), bw_adjust=0.35, label='SUVs', color='green')\nax[0].set_xlim(extent[0], extent[1])#set the x limits of the plot to be the same as our map\nax[0].set_ylabel('Probability Density')\nax[0].set_title('Sales of Trucks and Sedans in the Lower 48 States')\nax[0].set_xticks([])\nax[0].legend()\n\n#Plot the location of each posting on a map\ngeoplot.pointplot(gtrucks, ax=ax[1], s=1, color='red')\ngeoplot.pointplot(gsedans, ax=ax[1], s=1, color='blue')\ngeoplot.pointplot(gsuvs, ax=ax[1], s=1, color='green')\nax[1].axis(extent)\nctx.add_basemap(ax[1], zoom=4)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The plot above shows the distribution of sedan, suv, and truck sales by owner in lower 48 states. The top probability density curves show the normalized distribution of each vehicle type over longitude. As expected, distinct peaks in all curves occur around population cennters.\n\nNote that sedan and SUVs sales are almost exactly the same, again confirming that the SUV has become the 'daily driver' for many. Trucks deviate from the sedan/suv curves in the mid-west (perhaps in line with chicago) where there are slighly fewer, and the coasts where there are slightly more."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}