{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"9459ae9a-bfcb-0d65-7911-1716a2ffd0c2"},"source":"**It seems that Kaggle has some problems with its IPython Notebook, you can refer [here](https://www.kaggle.com/alanch/d/uciml/default-of-credit-card-clients-dataset/feature-engineering/run/668752) for the latest successful run.**"},{"cell_type":"markdown","metadata":{"_cell_guid":"93df9b91-a88f-a2d4-f61a-5c035cb1e4f7"},"source":"This script takes Vipul's python script as a handy boilerplate to kickstart.\n\nSince I didn't get the dataset on Kaggle but from my professor, there are some naming incompatibility issues. The following cell resolves the problem.\n\nSpecifically, the differences are:\n\n 1. I didn't have the LIMIT_BAL on my dataset.\n 2. The default column was placed on the first column."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ab63b1aa-c5d4-f835-d90f-d3c61401289f"},"outputs":[],"source":"# coding: utf-8\n\n# Init the script\n# ERG2050 Group Work\n# CUHK(SZ) 2016 Term 2\n\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom scipy import interp\nfrom itertools import cycle\nfrom sklearn.svm import LinearSVC\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_curve,auc\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import RidgeClassifier\nfrom sklearn.linear_model import Lasso\nimport itertools\nfrom sklearn.model_selection import StratifiedKFold\n\n\ndef rename_for_kaggle(default):\n    default=default.rename(columns = {'default.payment.next.month':'default'})\n    default=default.rename(columns = {'PAY_0':'PAY_1'})\n    cols = list(default.columns[2:]) # Dismiss BAL_LIMIT, since it wasn't in my version of dataset originally.\n    cols = [cols[-1]] + cols[:-1]\n    return default[cols]\n\ndefault = pd.read_csv(\"../input/UCI_Credit_Card.csv\")\ndefault = rename_for_kaggle(default)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"042f7293-04bf-0476-dd07-38a8f982bb11"},"outputs":[],"source":"warnings.filterwarnings('ignore')\n\ncolors = cycle(['brown','lightcoral','red','magenta','cyan', 'indigo', 'seagreen', 'yellow', 'blue', 'darkorange'])\n\ndef get_model(algoname,feature,target):\n    X_train = feature\n    y_train = target\n    return algoname.fit(X_train,y_train.values.ravel())\n\ndef algorithm(algoname,colors,train,test,pos):\n    mean_tpr,lw,i =0.0, 2,1\n    mean_fpr = np.linspace(0, 1, 100)\n    fold_accuracy= []\n    cnf_mat = 0\n    skfold = StratifiedKFold(n_splits=10,shuffle = True)\n    for (trainindex,testindex), color in zip(skfold.split(train, test.values.ravel()), colors):\n        X_train, X_test = train.loc[trainindex], train.loc[testindex]\n        y_train, y_test = test.loc[trainindex], test.loc[testindex]\n        model = algoname.fit(X_train,y_train.values.ravel())\n        fold_accuracy.append(model.score(X_test,y_test.values.ravel()))\n        result = model.predict(X_test)\n        fpr, tpr, thresholds= roc_curve(y_test.values,result,pos_label=pos)\n        mean_tpr += interp(mean_fpr, fpr, tpr)\n        mean_tpr[0] = 0.0\n        roc_auc = auc(fpr, tpr)\n        cm = confusion_matrix(y_test.values,result)\n        cnf_mat +=  cm\n        plt.step(fpr, tpr, lw=lw, color=color,label='ROC fold %d (area = %0.2f)' % (i, roc_auc))\n        i+=1\n    mean_tpr /= skfold.get_n_splits(train,test.values.ravel())\n    mean_tpr[-1] = 1.0\n    mean_auc = auc(mean_fpr, mean_tpr)\n    plt.step(mean_fpr, mean_tpr, color='g', linestyle='--',\n             label='Mean ROC (area = %0.2f)' % mean_auc, lw=lw)\n    plt.title(\"Average accuracy: {0:.3f}\".format(np.asarray(fold_accuracy).mean()))\n    plt.xlim([-0.05, 1.05])\n    plt.ylim([-0.05, 1.05])\n    plt.xlabel('FPR')\n    plt.ylabel('TPR')\n    plt.legend(loc=\"lower right\") \n    plt.show()\n    plt.figure()\n    plot_confusion_matrix(cnf_mat, classes=[\"0\",\"1\"],\n                      title='Confusion matrix, without normalization')\n    plt.show()\n    return(\"Average accuracy: {0:.3f} (+/-{1:.3f})\".format(np.asarray(fold_accuracy).mean(),\n                                                           np.asarray(fold_accuracy).std()),\n           \"\\n Confustion Matrix:\",cnf_mat)\n\ndef benchmark(default):\n    default_train,default_test = default.iloc[:,1:].astype(int), default.iloc[:,0].astype(int)\n\n    # In[5]:\n\n    print(\"\\n Default of Credit Card Clients Data Set\")\n    print(\"\\n Random Forest\")\n    forest = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n                max_depth=100, max_features='auto', max_leaf_nodes=None,\n                min_impurity_split=1e-07, min_samples_leaf=50,\n                min_samples_split=2, min_weight_fraction_leaf=0.0,\n                n_estimators=600, n_jobs=-1, oob_score=False,\n                random_state=None, verbose=0, warm_start=False)\n    print(algorithm(forest,colors,default_train,default_test,pos = None))\n    \n    #print(\"\\n Random Forest (EXP)\")\n    forest_exp = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n                max_depth=200, max_features=None, max_leaf_nodes=None,\n                min_impurity_split=1e-07, min_samples_leaf=50,\n                min_samples_split=2, min_weight_fraction_leaf=0.0,\n                n_estimators=600, n_jobs=-1, oob_score=False,\n                random_state=None, verbose=0, warm_start=False)\n    #print(algorithm(forest_exp,colors,default_train,default_test,pos = None))\n\n\n    # In[6]:\n    print(\"\\n Logistic\")\n    logistic = LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n              intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n              penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n              verbose=0, warm_start=False)\n    print(algorithm(logistic,colors,default_train,default_test,pos = None))\n\n\n    # In[7]:\n    print(\"\\n Naive\")\n    naive = GaussianNB()\n    print(algorithm(naive,colors,default_train,default_test,pos = None))\n\n\n    # In[8]:\n    print(\"\\n KNN\")\n    knneigh = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n               metric_params=None, n_jobs=-1, n_neighbors=50, p=2,\n               weights='uniform')\n    print(algorithm(knneigh,colors,default_train,default_test,pos = None))\n\n\n    # In[9]:\n    print(\"\\n SVM\")\n    svm = LinearSVC(C=1, class_weight=None, dual=False, fit_intercept=True,\n         intercept_scaling=1, loss='squared_hinge', max_iter=10,\n         multi_class='ovr', penalty='l1', random_state=1000, tol=0.0001,\n         verbose=0)\n    print(algorithm(svm,colors,default_train,default_test,pos = None))\n    \ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    \ndef benchmark_hard(default):\n    default_train,default_test = default.iloc[:,1:].astype(int), default.iloc[:,0].astype(int)\n    print(\"\\n Default of Credit Card Clients Data Set\")\n    forest = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n                max_depth=1000, max_features='auto', max_leaf_nodes=None,\n                min_impurity_split=1e-07, min_samples_leaf=10,\n                min_samples_split=2, min_weight_fraction_leaf=0.0,\n                n_estimators=6000, n_jobs=-1, oob_score=False,\n                random_state=None, verbose=0, warm_start=False)\n    print(algorithm(forest,colors,default_train,default_test,pos = None))\n    \ndef export_false_prediction(result, filename, data):\n    false_index = []\n    for i in range(len(result)):\n        if result[i] != data.iloc[i,0]:\n            false_index.append(i)\n    false_pred = data.iloc[false_index,:]\n    false_pred.to_csv(filename, index=False)\n    print(\"Trainning Errors: \" + str(len(false_pred)))\n    \ndef export_negative(result, filename, data):\n    negative_index = []\n    for i in range(len(result)):\n        if result[i] == 0:\n            negative_index.append(i)\n    data.iloc[negative_index,:].to_csv(filename)\n    \n    \ndef stage1(filename):\n    default = pd.read_csv(filename)\n    default = rename_for_kaggle(default)\n    breakpoint = int(1 * len(default))\n    train_features, train_target = default.iloc[:breakpoint,1:].astype(int), default.iloc[:breakpoint,0].astype(int)\n    test_features, test_target = default.iloc[breakpoint:,1:].astype(int), default.iloc[breakpoint:,0].astype(int)\n    forest = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n                    max_depth=100, max_features='auto', max_leaf_nodes=None,\n                    min_impurity_split=1e-07, min_samples_leaf=50,\n                    min_samples_split=2, min_weight_fraction_leaf=0.0,\n                    n_estimators=600, n_jobs=-1, oob_score=False,\n                    random_state=None, verbose=0, warm_start=False)\n    model = get_model(forest, train_features, train_target)\n    # result = model.predict(test_features)\n    result = model.predict(train_features)\n    export_false_prediction(result, \"false_negative.csv\", default)\n    return model\n\ndef stage2(filename_false_negative):\n    default = pd.read_csv(filename_false_negative)\n    default = rename_for_kaggle(default)\n    train_features, train_target = default.iloc[:,1:].astype(int), default.iloc[:,0].astype(int)\n    forest = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n                    max_depth=100, max_features='auto', max_leaf_nodes=None,\n                    min_impurity_split=1e-07, min_samples_leaf=50,\n                    min_samples_split=2, min_weight_fraction_leaf=0.0,\n                    n_estimators=600, n_jobs=-1, oob_score=False,\n                    random_state=None, verbose=0, warm_start=False)\n    logistic = LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n              intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n              penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n              verbose=0, warm_start=False)\n    naive = GaussianNB()\n    model = get_model(naive, train_features, train_target)\n    return model\n\ndef naive(filename):\n    default = pd.read_csv(filename)\n    default = rename_for_kaggle(default)\n    breakpoint = int(1 * len(default))\n    train_features, train_target = default.iloc[:breakpoint,1:].astype(int), default.iloc[:breakpoint,0].astype(int)\n    test_features, test_target = default.iloc[breakpoint:,1:].astype(int), default.iloc[breakpoint:,0].astype(int)\n    forest = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n                    max_depth=100, max_features='auto', max_leaf_nodes=None,\n                    min_impurity_split=1e-07, min_samples_leaf=50,\n                    min_samples_split=2, min_weight_fraction_leaf=0.0,\n                    n_estimators=600, n_jobs=-1, oob_score=False,\n                    random_state=None, verbose=0, warm_start=False)\n    naive_model = GaussianNB()\n    model = get_model(naive_model, train_features, train_target)\n    # result = model.predict(test_features)\n    result = model.predict(train_features)\n    export_false_prediction(result, \"false_negative.csv\", default)\n    return model\n\ndef magic(train_file, test_file):\n    model1 = stage1(train_file)\n    model2 = stage2(\"false_negative.csv\")\n    # Models trainetest_ext4.csv   \n    # Load Test file\n    test = pd.read_csv(test_file)\n    print(\"Test size: \" + str(len(test)))\n    test_features = test.iloc[:,1:].astype(int)\n    test_target = test.iloc[:,0].astype(int)\n\n    # Test\n    # First Stage Fit\n\n    print(\"Model 1 Score:\" + str(model1.score(test_features,test_target.values.ravel())))\n    print(\"Model 2 Score:\" + str(model2.score(test_features,test_target.values.ravel())))\n    # Using Model 1 to predict test set\n    result1 = model1.predict(test_features)\n    error_count = 0\n    for i in range(len(test)):\n        if result1[i] == 0 and test_target.iloc[i] == 1:\n            error_count += 1\n    print(\"Model 1 Testing False Negative: \" + str(error_count))\n\n    # Find negative predictions\n    export_negative(result1, \"negative.csv\", test)\n    negative = pd.read_csv(\"negative.csv\")\n    print(\"Model 2 Input Size: \" + str(len(negative)))\n    negative_features = negative.iloc[:,2:].astype(int)\n\n    # Second Stage\n    result2 = model2.predict(negative_features)\n    print(\"Result2 Size: \" + str(len(result2)))\n    diff = 0\n    diff_fn = 0\n    for i in range(len(result2)):\n        result_1 = result1[negative.iloc[i,1].astype(int)]\n        if result_1 != result2[i]:\n            result1[negative.iloc[i,1].astype(int)] = result2[i]\n            diff += 1\n            if result_1 != test_target.iloc[negative.iloc[i,1].astype(int)]:\n                diff_fn += 1\n    print(\"DIFF: \" + str(diff) + \" Correction: \" + str(diff_fn))\n\n\n    # Get Score\n    error_count = 0\n    for i in range(len(test)):\n        if result1[i] != test_target.iloc[i]:\n            error_count += 1\n    print(\"Errors: \" + str(error_count))\n    print(\"Accuracy: \" + str(1-(error_count/len(test))))\n    error_count = 0\n    for i in range(len(test)):\n        if result1[i] == 0 and test_target.iloc[i] == 1:\n            error_count += 1\n    print(\"Model 1+2 Testing False Negative: \" + str(error_count))\n\ndef get_model(algoname,feature,target):\n    X_train = feature\n    y_train = target\n    return algoname.fit(X_train,y_train.values.ravel())\n\ndef test(train_file, test_file):\n    model1 = stage1(train_file)\n    \n    # Load Test file\n    test = pd.read_csv(test_file)\n    print(\"Test size: \" + str(len(test)))\n    test_features = test.iloc[:,1:].astype(int)\n    test_target = test.iloc[:,0].astype(int)\n    \n    # Test\n    # First Stage Fit\n\n    print(\"Model Score:\" + str(model1.score(test_features,test_target.values.ravel())))\n    # Using Model 1 to predict test set\n    result1 = model1.predict(test_features)\n    \n    # Draw Confusion Matrix\n    cm = confusion_matrix(test_target.values,result1)\n    plot_confusion_matrix(cm, classes=[\"0\",\"1\"],\n                      title='Confusion matrix, without normalization')\n    plt.show()\n    \n    # Count\n    error_count = 0\n    for i in range(len(test)):\n        if result1[i] == 0 and test_target.iloc[i] == 1:\n            error_count += 1\n    print(\"Model Testing False Negative: \" + str(error_count))\n    \ndef naive_test(train_file, test_file):\n    model1 = naive(train_file)\n    \n    # Load Test file\n    test = pd.read_csv(test_file)\n    print(\"Test size: \" + str(len(test)))\n    test_features = test.iloc[:,1:].astype(int)\n    test_target = test.iloc[:,0].astype(int)\n\n    # Test\n    # First Stage Fit\n\n    print(\"Model Score:\" + str(model1.score(test_features,test_target.values.ravel())))\n    # Using Model 1 to predict test set\n    result1 = model1.predict(test_features)\n    \n    # Draw Confusion Matrix\n    cm = confusion_matrix(test_target.values,result1)\n    plot_confusion_matrix(cm, classes=[\"0\",\"1\"],\n                      title='Confusion matrix, without normalization')\n    plt.show()\n    \n    error_count = 0\n    for i in range(len(test)):\n        if result1[i] == 0 and test_target.iloc[i] == 1:\n            error_count += 1\n    print(\"Model Testing False Negative: \" + str(error_count))\n    \n\nprint(\"Ready.\")"},{"cell_type":"markdown","metadata":{"_cell_guid":"8a53826f-6a89-7816-688d-9931803ef328"},"source":"# Benchmarking Several Models Using Original Data\n\nThe code section below will run a benchmark of several common methods with the original dataset."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"989f6c2a-2ed7-980a-e79b-6abf6ffd12b4"},"outputs":[],"source":"%%timeit -n 1 -r 1\nbenchmark(default)"},{"cell_type":"markdown","metadata":{"_cell_guid":"534e3a8e-6266-9ac8-128d-e3731be3cb3e"},"source":"# Feature Engineering\n\nIt is intuitive to manipulate the data for a bit to let algorithms capture some underlying connection among these dimensions. For example, algorithms cannot understand time series relationships of BILL_AMTX and PAY_X, where X is a time indicator.\n\nHere is how we did it."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9c33a44b-3f0e-0191-241e-9ac177720b2c"},"outputs":[],"source":"def BILL_regression(default):\n    data = default.copy()\n    pandas = pd\n    from scipy import stats\n    for i in range(len(data)):\n        temp = pandas.DataFrame.transpose(pandas.DataFrame(data=data.iloc[i]))\n        for j in range(1,7):\n            temp.loc[j] = temp.iloc[0]\n        temp[\"BILL_AMT\"] = 0\n        temp[\"BILL_DATE\"] = 0\n        for j in range(1,7):\n            temp.at[j, \"BILL_AMT\"] = data.iloc[i][\"BILL_AMT\" + str(j)]\n            temp.at[j, \"BILL_DATE\"] = j\n        slope, intercept, r_value, p_value, std_err = stats.linregress(temp[\"BILL_DATE\"],temp[\"BILL_AMT\"])\n        data.at[i, \"BILL_SLOPE\"] = slope\n        data.at[i, \"BILL_INCEPT\"] = intercept\n        data.at[i, \"BILL_STDERR\"] = std_err\n    return data\nv1 = BILL_regression(default)\nv1.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bc55c5f2-fc57-db12-4d60-c08f1ec373d7"},"outputs":[],"source":"def BILL_poly_regression(default):\n    data = default.copy()\n    for i in range(len(data)):\n        temp = pd.DataFrame.transpose(pd.DataFrame(data=data.iloc[i]))\n        for j in range(1,7):\n            temp.loc[j] = temp.iloc[0]\n        temp[\"BILL_AMT\"] = 0\n        temp[\"BILL_DATE\"] = 0\n        for j in range(1,7):\n            temp.at[j, \"BILL_AMT\"] = data.iloc[i][\"BILL_AMT\" + str(j)]\n            temp.at[j, \"BILL_DATE\"] = j\n        result = np.polynomial.polynomial.polyfit(temp[\"BILL_DATE\"],temp[\"BILL_AMT\"],4)\n        for j in range(len(result)):\n            data.at[i, \"BILL_POLY\" + str(j)] = result[j]\n    return data\nv2 = BILL_poly_regression(v1)\nv2.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ebfa76b8-5600-3280-8626-17c49c715ceb"},"outputs":[],"source":"def threshold_count(label, default, thresholds):\n    data = default.copy()\n    for threshold in thresholds:\n        for i in range(len(data)):\n            count = 0\n            for j in range(1,7):\n                if data.iloc[i][label + str(j)] <= threshold:\n                    count += 1\n            data.at[i, label + \"_COUNT_\" + str(threshold)] = count\n    return data\nv3 = threshold_count(\"BILL_AMT\", v2, [0,20000,70000])\nv3 = threshold_count(\"PAY_AMT\", v3, [0,1000,5000])\nv3.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7059afc5-44b4-16c2-9ae0-36ecca3c1fcf"},"outputs":[],"source":"def pay_count(default):\n    data = default.copy()\n    pandas = pd\n    from scipy import stats\n    for i in range(len(data)):\n        temp = pandas.DataFrame.transpose(pandas.DataFrame(data=data.iloc[i]))\n        for val in [-2,-1,1,2,3,4,5,6,7,8,9]:\n            count = 0\n            for j in range(1,7):\n                if data.iloc[i][\"PAY_\" + str(j)] == val:\n                    count += 1\n                data.at[i, \"PAY_COUNT_\" + str(val)] = count\n    return data\nv4 = pay_count(v3)\nv4.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"feb4abfb-0818-4475-8fb6-d30181ea60c2"},"outputs":[],"source":"#VAR\ndef var(label, default):\n    data=default.copy()\n    for i in range(len(data)):\n        temp = pd.DataFrame.transpose(pd.DataFrame(data=data.iloc[i]))\n        for j in range(1,7):\n            temp.loc[j] = temp.iloc[0]\n        temp[\"VAL\"] = 0\n        for j in range(1,7):\n            temp.at[j, \"VAL\"] = data.iloc[i][label + str(j)]\n        data.at[i, label + \"_VAR\"] = temp.VAL.var()\n    return data\nv5 = var(\"PAY_AMT\", v4)\nv5 = var(\"BILL_AMT\", v5)\nv5.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e90736d9-633e-afc3-8fc9-6723835aa27c"},"outputs":[],"source":"def f(x):\n    return float(1)/float(1+np.exp(x))\n\ndef pbr(bill, pay):\n    if bill > 0:\n        if pay < bill:\n            result = pay/bill\n        else:\n            result = 1 + f(pay)\n    elif bill == 0:\n        if pay != 0:\n            result = 2 + f(pay)\n        if pay == 0:\n            result = 1\n    else:\n        if pay == 0:\n            result = 3 + f(pay)\n        if pay > 0:\n            result = 4 + f(pay) \n    return result\n\n#Payback Ratio\ndef calc_pbr(default):\n    data = default\n    for i in range(len(data)):\n        temp = pd.DataFrame.transpose(pd.DataFrame(data=data.iloc[i]))\n        for j in range(1,7):\n            temp.loc[j] = temp.iloc[0]\n        temp[\"VAL\"] = 0\n        for j in range(1,7):\n            bill = data.iloc[i][\"BILL_AMT\" + str(j)]\n            pay = data.iloc[i][\"PAY_AMT\" + str(j)]\n            data.at[i, \"PBR_\" + str(j)] = pbr(bill, pay)\n    return data\n\nv6 = calc_pbr(v5)\nv6.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cd8ef1b9-ddfe-0ff7-8930-600060d21182"},"outputs":[],"source":"def PBR_regression(default):\n    data = default.copy()\n    pandas = pd\n    from scipy import stats\n    for i in range(len(data)):\n        temp = pandas.DataFrame.transpose(pandas.DataFrame(data=data.iloc[i]))\n        for j in range(1,7):\n            temp.loc[j] = temp.iloc[0]\n        temp[\"AMT\"] = 0\n        temp[\"DATE\"] = 0\n        for j in range(1,7):\n            temp.at[j, \"AMT\"] = data.iloc[i][\"PBR_\" + str(j)]\n            temp.at[j, \"DATE\"] = j\n        slope, intercept, r_value, p_value, std_err = stats.linregress(temp[\"DATE\"],temp[\"AMT\"])\n        data.at[i, \"PBR_SLOPE\"] = slope\n        data.at[i, \"PBR_INCEPT\"] = intercept\n        data.at[i, \"PBR_STDERR\"] = std_err\n    return data\nv7 = PBR_regression(v6)\nv7.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c1a29323-c70c-134c-7824-592c4d5e9eec"},"outputs":[],"source":"def PAY_regression(default):\n    data = default.copy()\n    pandas = pd\n    from scipy import stats\n    for i in range(len(data)):\n        temp = pandas.DataFrame.transpose(pandas.DataFrame(data=data.iloc[i]))\n        for j in range(1,7):\n            temp.loc[j] = temp.iloc[0]\n        temp[\"AMT\"] = 0\n        temp[\"DATE\"] = 0\n        for j in range(1,7):\n            temp.at[j, \"AMT\"] = data.iloc[i][\"PAY_AMT\" + str(j)]\n            temp.at[j, \"DATE\"] = j\n        slope, intercept, r_value, p_value, std_err = stats.linregress(temp[\"DATE\"],temp[\"AMT\"])\n        data.at[i, \"PAY_SLOPE\"] = slope\n        data.at[i, \"PAY_INCEPT\"] = intercept\n        data.at[i, \"PAY_STDERR\"] = std_err\n    return data\nv8 = PAY_regression(v7)\nv8.head()"},{"cell_type":"markdown","metadata":{"_cell_guid":"336f6c25-c900-f177-6637-376c1057283e"},"source":"# Feature Selection\nNow let's see what we have got:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"095bf634-03e7-2237-5f71-bc9869bf7b5f"},"outputs":[],"source":"list(v8.columns)"},{"cell_type":"markdown","metadata":{"_cell_guid":"7b624d17-e777-4971-5f00-63f46abe0594"},"source":"So now we have a total of 61 features. To select the most useful ones, we tried lasso:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"59b234fb-f533-e22e-7af5-151a898a30ca"},"outputs":[],"source":"def sub_features(data, alpha):\n    features = [\"default\"]\n    lasso = Lasso(alpha=alpha)\n    default_train, default_test = data.iloc[:,1:].astype(int), data.iloc[:,0].astype(int)\n    lasso.fit(default_train, default_test)\n    for i in range(len(lasso.coef_)):\n        if lasso.coef_[i] > 0:\n            features.append(default_train.columns[i])\n    return data.copy()[features]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5bc402f2-0100-32f5-af6d-0c7b5b48c4ed"},"outputs":[],"source":"data_1 = sub_features(v8, 0.1)\nlist(data_1.columns)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"875fbef9-92f3-396a-c780-c63b229eef54"},"outputs":[],"source":"benchmark(data_1)"},{"cell_type":"markdown","metadata":{"_cell_guid":"3ccdb965-1abe-1e9a-ffb0-1b47a6ccb9fa"},"source":"Feel free to play around the parameters and other subset selction methods. Somehow we got the following subset: (guess how we got it?)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dc97fd14-7319-6c97-8955-8d06871d0d0c"},"outputs":[],"source":"data_2 = v8.copy()[['default', 'PAY_1',\n 'PAY_AMT1',\n 'PAY_AMT_COUNT_1000',\n 'PAY_AMT_COUNT_5000',\n 'PAY_COUNT_-2',\n 'PAY_COUNT_2',\n 'PAY_COUNT_3',\n 'PAY_COUNT_7',\n 'PBR_STDERR',\n 'BILL_AMT_COUNT_20000']]\nbenchmark(data_2)"},{"cell_type":"markdown","metadata":{"_cell_guid":"00ea7f4b-7d9b-c75c-3030-ce6286e482b4"},"source":"You can see how our feature engineering helps Naive Bayes improve significantly.\n\nP.S. There are some experimental methods in the second cell. Feel free to explore."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6adc875e-ffb0-8234-07cf-47f69e91ec16","collapsed":true},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}