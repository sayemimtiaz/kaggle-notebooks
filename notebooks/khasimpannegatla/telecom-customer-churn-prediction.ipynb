{"cells":[{"metadata":{"_uuid":"3e3c536c27c26c023cbec0cadc083edaf09e1d20"},"cell_type":"markdown","source":"# Customer Attrition\n\nCustomer attrition, also known as customer churn, customer turnover, or customer defection, is the loss of clients or customers.\n\nTelephone service companies, Internet service providers, pay TV companies, insurance firms, and alarm monitoring services, often use customer attrition analysis and customer attrition rates as one of their key business metrics  because the cost of retaining an existing customer is far less than acquiring a new one. Companies from these sectors often have customer service branches which attempt to win back defecting clients, because recovered long-term customers can be worth much more to a company than newly recruited clients.\n\nCompanies usually make a distinction between voluntary churn and involuntary churn. Voluntary churn occurs due to a decision by the customer to switch to another company or service provider, involuntary churn occurs due to circumstances such as a customer's relocation to a long-term care facility, death, or the relocation to a distant location. In most applications, involuntary reasons for churn are excluded from the analytical models. Analysts tend to concentrate on voluntary churn, because it typically occurs due to factors of the company-customer relationship which companies control, such as how billing interactions are handled or how after-sales help is provided.\n\npredictive analytics  use churn prediction models that predict customer churn by assessing their propensity of risk to churn. Since these models generate a small prioritized list of potential defectors, they are effective at focusing customer retention marketing programs on the subset of the customer base who are most vulnerable to churn."},{"metadata":{"_uuid":"75867907e48104003cfa148d4d4ca47c82309114"},"cell_type":"markdown","source":"- <a href='#1'>1. Data</a>\n    - <a href='#1.1'>1.1. Data overview</a>\n- <a href='#2'>2. Data Manipulation</a>\n- <a href='#3'>3. Exploratory Data Analysis</a>\n    - <a href='#3.1'>3.1. Customer attrition in data</a>\n    - <a href='#3.2'>3.2. Varibles distribution in customer attrition</a>\n    - <a href='#3.3'>3.3. Customer attrition in tenure groups</a>\n    - <a href='#3.4'>3.4. Monthly Charges and Total Charges by Tenure and Churn  group</a>\n    - <a href='#3.5'>3.5. Average Charges by tenure groups</a>\n    - <a href='#3.6'>3.6. Monthly charges,total charges and tenure in customer attrition</a>\n    - <a href='#3.7'>3.7. Variable Summary</a>\n    - <a href='#3.8'>3.8. Correlation Matrix</a>\n    - <a href='#3.9'>3.9. Visualising data with principal components</a>\n    - <a href='#3.10'>3.10. Binary variables distribution in customer attrition(Radar Chart)</a>\n- <a href='#4'>4. Data preprocessing</a>\n- <a href='#5'>5. Model Building</a>\n    - <a href='#5.1'>5.1. Baseline Model</a>\n    - <a href='#5.2'>5.2. Synthetic Minority Oversampling TEchnique (SMOTE)</a>\n    - <a href='#5.3'>5.3. Recursive Feature Elimination</a>\n    - <a href='#5.4'>5.4. Univariate Selection</a>\n    - <a href='#5.5'>5.5. Decision Tree Visualization</a>\n    - <a href='#5.6'>5.6. KNN Classifier</a>\n    - <a href='#5.7'>5.7. Vizualising a decision tree from random forest classifier</a>\n    - <a href='#5.8'>5.8. A random forest classifier.</a>\n    - <a href='#5.9'>5.9. Gaussian Naive Bayes</a>\n    - <a href='#5.10'>5.10. Support Vector Machine</a>\n    - <a href='#5.11'>5.11. Tuning parameters for support vector machine</a>\n    - <a href='#5.12'>5.12. LightGBMClassifier</a>\n    - <a href='#5.13'>5.13. XGBoost  Classifier</a>\n- <a href='#6'>6. Model Performances</a>\n    - <a href='#6.1'>6.1. model performance metrics</a>\n    - <a href='#6.2'>6.2. Compare model metrics</a>\n    - <a href='#6.3'>6.3. Confusion matrices for models</a>\n    - <a href='#6.4'>6.4. ROC - Curves  for models</a>\n    - <a href='#6.5'>6.5. Precision recall curves</a>\n   \n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"#Importing libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n# Input data files are available in the \"../input/\" directory.\nimport os\nimport matplotlib.pyplot as plt#visualization\nfrom PIL import  Image\n%matplotlib inline\nimport pandas as pd\nimport seaborn as sns#visualization\nimport itertools\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport io\nimport plotly.offline as py#visualization\npy.init_notebook_mode(connected=True)#visualization\nimport plotly.graph_objs as go#visualization\nimport plotly.tools as tls#visualization\nimport plotly.figure_factory as ff#visualization","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fa7e507381a982dfb9bcba253537c50ecd956230"},"cell_type":"markdown","source":"# <a id='1'>1.Data</a>"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"telcom = pd.read_csv(r\"../input/WA_Fn-UseC_-Telco-Customer-Churn.csv\")\n#first few rows\ntelcom.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"82e4c33ee04800fd84784c289f11906fda8ec201"},"cell_type":"markdown","source":"## <a id='1.1'>1.1. Data overview</a>"},{"metadata":{"trusted":true,"_uuid":"aa25365d81b3952c65b09ed30543b6172fd333f7"},"cell_type":"code","source":"print (\"Rows     : \" ,telcom.shape[0])\nprint (\"Columns  : \" ,telcom.shape[1])\nprint (\"\\nFeatures : \\n\" ,telcom.columns.tolist())\nprint (\"\\nMissing values :  \", telcom.isnull().sum().values.sum())\nprint (\"\\nUnique values :  \\n\",telcom.nunique())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c8c010f36e29c116c6662301b08b0b0019d6e22e"},"cell_type":"markdown","source":"# <a id='2'>2. Data Manipulation</a>"},{"metadata":{"trusted":true,"_uuid":"8b10c13086dff7182e399b849e31bc03df54a14e"},"cell_type":"code","source":"#Data Manipulation\n\n#Replacing spaces with null values in total charges column\ntelcom['TotalCharges'] = telcom[\"TotalCharges\"].replace(\" \",np.nan)\n\n#Dropping null values from total charges column which contain .15% missing data \ntelcom = telcom[telcom[\"TotalCharges\"].notnull()]\ntelcom = telcom.reset_index()[telcom.columns]\n\n#convert to float type\ntelcom[\"TotalCharges\"] = telcom[\"TotalCharges\"].astype(float)\n\n#replace 'No internet service' to No for the following columns\nreplace_cols = [ 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n                'TechSupport','StreamingTV', 'StreamingMovies']\nfor i in replace_cols : \n    telcom[i]  = telcom[i].replace({'No internet service' : 'No'})\n    \n#replace values\ntelcom[\"SeniorCitizen\"] = telcom[\"SeniorCitizen\"].replace({1:\"Yes\",0:\"No\"})\n\n#Tenure to categorical column\ndef tenure_lab(telcom) :\n    \n    if telcom[\"tenure\"] <= 12 :\n        return \"Tenure_0-12\"\n    elif (telcom[\"tenure\"] > 12) & (telcom[\"tenure\"] <= 24 ):\n        return \"Tenure_12-24\"\n    elif (telcom[\"tenure\"] > 24) & (telcom[\"tenure\"] <= 48) :\n        return \"Tenure_24-48\"\n    elif (telcom[\"tenure\"] > 48) & (telcom[\"tenure\"] <= 60) :\n        return \"Tenure_48-60\"\n    elif telcom[\"tenure\"] > 60 :\n        return \"Tenure_gt_60\"\ntelcom[\"tenure_group\"] = telcom.apply(lambda telcom:tenure_lab(telcom),\n                                      axis = 1)\n\n#Separating churn and non churn customers\nchurn     = telcom[telcom[\"Churn\"] == \"Yes\"]\nnot_churn = telcom[telcom[\"Churn\"] == \"No\"]\n\n#Separating catagorical and numerical columns\nId_col     = ['customerID']\ntarget_col = [\"Churn\"]\ncat_cols   = telcom.nunique()[telcom.nunique() < 6].keys().tolist()\ncat_cols   = [x for x in cat_cols if x not in target_col]\nnum_cols   = [x for x in telcom.columns if x not in cat_cols + target_col + Id_col]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fbe477239c9240b5402053e0bc572bc5841c91a4"},"cell_type":"markdown","source":"# <a id='3'>3. Exploratory Data Analysis</a>"},{"metadata":{"_uuid":"09ba96d314bd92da87f956c3b265b78317a17d17"},"cell_type":"markdown","source":"## <a id='3.1'>3.1. Customer attrition in data</a>"},{"metadata":{"trusted":true,"_uuid":"35bf6ff6c7e9ed36b0fb6fa2c67450a58135b62a","_kg_hide-input":false},"cell_type":"code","source":"#labels\nlab = telcom[\"Churn\"].value_counts().keys().tolist()\n#values\nval = telcom[\"Churn\"].value_counts().values.tolist()\n\ntrace = go.Pie(labels = lab ,\n               values = val ,\n               marker = dict(colors =  [ 'royalblue' ,'lime'],\n                             line = dict(color = \"white\",\n                                         width =  1.3)\n                            ),\n               rotation = 90,\n               hoverinfo = \"label+value+text\",\n               hole = .5\n              )\nlayout = go.Layout(dict(title = \"Customer attrition in data\",\n                        plot_bgcolor  = \"rgb(243,243,243)\",\n                        paper_bgcolor = \"rgb(243,243,243)\",\n                       )\n                  )\n\ndata = [trace]\nfig = go.Figure(data = data,layout = layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"34b437d12b3391c3a4d6ae357cb23d408cbc1b18"},"cell_type":"markdown","source":"## <a id='3.2'>3.2. Varibles distribution in customer attrition</a>"},{"metadata":{"trusted":true,"_uuid":"cd1173ccd1666f350390b7d401e3a5075a7e790d","_kg_hide-input":false},"cell_type":"code","source":"#function  for pie plot for customer attrition types\ndef plot_pie(column) :\n    \n    trace1 = go.Pie(values  = churn[column].value_counts().values.tolist(),\n                    labels  = churn[column].value_counts().keys().tolist(),\n                    hoverinfo = \"label+percent+name\",\n                    domain  = dict(x = [0,.48]),\n                    name    = \"Churn Customers\",\n                    marker  = dict(line = dict(width = 2,\n                                               color = \"rgb(243,243,243)\")\n                                  ),\n                    hole    = .6\n                   )\n    trace2 = go.Pie(values  = not_churn[column].value_counts().values.tolist(),\n                    labels  = not_churn[column].value_counts().keys().tolist(),\n                    hoverinfo = \"label+percent+name\",\n                    marker  = dict(line = dict(width = 2,\n                                               color = \"rgb(243,243,243)\")\n                                  ),\n                    domain  = dict(x = [.52,1]),\n                    hole    = .6,\n                    name    = \"Non churn customers\" \n                   )\n\n\n    layout = go.Layout(dict(title = column + \" distribution in customer attrition \",\n                            plot_bgcolor  = \"rgb(243,243,243)\",\n                            paper_bgcolor = \"rgb(243,243,243)\",\n                            annotations = [dict(text = \"churn customers\",\n                                                font = dict(size = 13),\n                                                showarrow = False,\n                                                x = .15, y = .5),\n                                           dict(text = \"Non churn customers\",\n                                                font = dict(size = 13),\n                                                showarrow = False,\n                                                x = .88,y = .5\n                                               )\n                                          ]\n                           )\n                      )\n    data = [trace1,trace2]\n    fig  = go.Figure(data = data,layout = layout)\n    py.iplot(fig)\n\n\n#function  for histogram for customer attrition types\ndef histogram(column) :\n    trace1 = go.Histogram(x  = churn[column],\n                          histnorm= \"percent\",\n                          name = \"Churn Customers\",\n                          marker = dict(line = dict(width = .5,\n                                                    color = \"black\"\n                                                    )\n                                        ),\n                         opacity = .9 \n                         ) \n    \n    trace2 = go.Histogram(x  = not_churn[column],\n                          histnorm = \"percent\",\n                          name = \"Non churn customers\",\n                          marker = dict(line = dict(width = .5,\n                                              color = \"black\"\n                                             )\n                                 ),\n                          opacity = .9\n                         )\n    \n    data = [trace1,trace2]\n    layout = go.Layout(dict(title =column + \" distribution in customer attrition \",\n                            plot_bgcolor  = \"rgb(243,243,243)\",\n                            paper_bgcolor = \"rgb(243,243,243)\",\n                            xaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n                                             title = column,\n                                             zerolinewidth=1,\n                                             ticklen=5,\n                                             gridwidth=2\n                                            ),\n                            yaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n                                             title = \"percent\",\n                                             zerolinewidth=1,\n                                             ticklen=5,\n                                             gridwidth=2\n                                            ),\n                           )\n                      )\n    fig  = go.Figure(data=data,layout=layout)\n    \n    py.iplot(fig)\n    \n#function  for scatter plot matrix  for numerical columns in data\ndef scatter_matrix(df)  :\n    \n    df  = df.sort_values(by = \"Churn\" ,ascending = True)\n    classes = df[\"Churn\"].unique().tolist()\n    classes\n    \n    class_code  = {classes[k] : k for k in range(2)}\n    class_code\n\n    color_vals = [class_code[cl] for cl in df[\"Churn\"]]\n    color_vals\n\n    pl_colorscale = \"Portland\"\n\n    pl_colorscale\n\n    text = [df.loc[k,\"Churn\"] for k in range(len(df))]\n    text\n\n    trace = go.Splom(dimensions = [dict(label  = \"tenure\",\n                                       values = df[\"tenure\"]),\n                                  dict(label  = 'MonthlyCharges',\n                                       values = df['MonthlyCharges']),\n                                  dict(label  = 'TotalCharges',\n                                       values = df['TotalCharges'])],\n                     text = text,\n                     marker = dict(color = color_vals,\n                                   colorscale = pl_colorscale,\n                                   size = 3,\n                                   showscale = False,\n                                   line = dict(width = .1,\n                                               color='rgb(230,230,230)'\n                                              )\n                                  )\n                    )\n    axis = dict(showline  = True,\n                zeroline  = False,\n                gridcolor = \"#fff\",\n                ticklen   = 4\n               )\n    \n    layout = go.Layout(dict(title  = \n                            \"Scatter plot matrix for Numerical columns for customer attrition\",\n                            autosize = False,\n                            height = 800,\n                            width  = 800,\n                            dragmode = \"select\",\n                            hovermode = \"closest\",\n                            plot_bgcolor  = 'rgba(240,240,240, 0.95)',\n                            xaxis1 = dict(axis),\n                            yaxis1 = dict(axis),\n                            xaxis2 = dict(axis),\n                            yaxis2 = dict(axis),\n                            xaxis3 = dict(axis),\n                            yaxis3 = dict(axis),\n                           )\n                      )\n    data   = [trace]\n    fig = go.Figure(data = data,layout = layout )\n    py.iplot(fig)\n\n#for all categorical columns plot pie\nfor i in cat_cols :\n    plot_pie(i)\n\n#for all categorical columns plot histogram    \nfor i in num_cols :\n    histogram(i)\n\n#scatter plot matrix\nscatter_matrix(telcom)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e672e14b3e9c120667e4016f7302bbf5197db9a4"},"cell_type":"markdown","source":"## <a id='3.3'>3.3. Customer attrition in tenure groups</a>"},{"metadata":{"trusted":true,"_uuid":"cd4cac7beecf94213485984b0d6aa9cc5a9b91c5"},"cell_type":"code","source":"#cusomer attrition in tenure groups\ntg_ch  =  churn[\"tenure_group\"].value_counts().reset_index()\ntg_ch.columns  = [\"tenure_group\",\"count\"]\ntg_nch =  not_churn[\"tenure_group\"].value_counts().reset_index()\ntg_nch.columns = [\"tenure_group\",\"count\"]\n\n#bar - churn\ntrace1 = go.Bar(x = tg_ch[\"tenure_group\"]  , y = tg_ch[\"count\"],\n                name = \"Churn Customers\",\n                marker = dict(line = dict(width = .5,color = \"black\")),\n                opacity = .9)\n\n#bar - not churn\ntrace2 = go.Bar(x = tg_nch[\"tenure_group\"] , y = tg_nch[\"count\"],\n                name = \"Non Churn Customers\",\n                marker = dict(line = dict(width = .5,color = \"black\")),\n                opacity = .9)\n\nlayout = go.Layout(dict(title = \"Customer attrition in tenure groups\",\n                        plot_bgcolor  = \"rgb(243,243,243)\",\n                        paper_bgcolor = \"rgb(243,243,243)\",\n                        xaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n                                     title = \"tenure group\",\n                                     zerolinewidth=1,ticklen=5,gridwidth=2),\n                        yaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n                                     title = \"count\",\n                                     zerolinewidth=1,ticklen=5,gridwidth=2),\n                       )\n                  )\ndata = [trace1,trace2]\nfig  = go.Figure(data=data,layout=layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7bfdef2b80b0504b9b61d857d2634caf2a563173"},"cell_type":"markdown","source":"## <a id='3.4'>3.4. Monthly Charges and Total Charges by Tenure and Churn groups</a>"},{"metadata":{"trusted":true,"_uuid":"ac6bc6c2fbfbcb8c46f98aececc8443151011075"},"cell_type":"code","source":"telcom[['MonthlyCharges', 'TotalCharges','tenure',\"tenure_group\"]]\n\n#scatter plot monthly charges & total charges by tenure group\n\ndef plot_tenure_scatter(tenure_group,color) :\n    tracer = go.Scatter(x = telcom[telcom[\"tenure_group\"] == tenure_group][\"MonthlyCharges\"],\n                        y = telcom[telcom[\"tenure_group\"] == tenure_group][\"TotalCharges\"],\n                        mode = \"markers\",marker = dict(line = dict(color = \"black\",\n                                                                   width = .2),\n                                                       size = 4 , color = color,\n                                                       symbol = \"diamond-dot\",\n                                                      ),\n                        name = tenure_group,\n                        opacity = .9\n                       )\n    return tracer\n\n#scatter plot monthly charges & total charges by churn group\ndef plot_churncharges_scatter(churn,color) :\n    tracer = go.Scatter(x = telcom[telcom[\"Churn\"] == churn][\"MonthlyCharges\"],\n                        y = telcom[telcom[\"Churn\"] == churn][\"TotalCharges\"],\n                        mode = \"markers\",marker = dict(line = dict(color = \"black\",\n                                                                   width = .2),\n                                                       size = 4 , color = color,\n                                                       symbol = \"diamond-dot\",\n                                                      ),\n                        name = \"Churn - \" + churn,\n                        opacity = .9\n                       )\n    return tracer\n\ntrace1 = plot_tenure_scatter(\"Tenure_0-12\",\"#FF3300\")\ntrace2 = plot_tenure_scatter(\"Tenure_12-24\",\"#6666FF\")\ntrace3 = plot_tenure_scatter(\"Tenure_24-48\",\"#99FF00\")\ntrace4 = plot_tenure_scatter(\"Tenure_48-60\",\"#996600\")\ntrace5 = plot_tenure_scatter(\"Tenure_gt_60\",\"grey\")\ntrace6 = plot_churncharges_scatter(\"Yes\",\"red\")\ntrace7 = plot_churncharges_scatter(\"No\",\"blue\")\n\ndata1   = [trace1,trace2,trace3,trace4,trace5] \ndata2   = [trace7,trace6]\n\n#layout\ndef layout_title(title) :\n    layout = go.Layout(dict(title = title,\n                            plot_bgcolor  = \"rgb(243,243,243)\",\n                            paper_bgcolor = \"rgb(243,243,243)\",\n                            xaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n                                         title = \"Monthly charges\",\n                                         zerolinewidth=1,ticklen=5,gridwidth=2),\n                            yaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n                                         title = \"Total Charges\",\n                                         zerolinewidth=1,ticklen=5,gridwidth=2),\n                            height = 600\n                           )\n                      )\n    return layout\n\nlayout1  = layout_title(\"Monthly Charges & Total Charges by Tenure group\")\nlayout2  = layout_title(\"Monthly Charges & Total Charges by Churn group\")\nfig1 = go.Figure(data = data1,layout = layout1)\nfig2 = go.Figure(data = data2,layout = layout2)\npy.iplot(fig1)\npy.iplot(fig2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"633be2cff456e1c2426e4659a4edccb786d4b563"},"cell_type":"markdown","source":"## <a id='3.5'>3.5. Average Charges by tenure groups</a>"},{"metadata":{"trusted":true,"_uuid":"9f5bfdefa74bc8cd062c353467635279c9d3236a"},"cell_type":"code","source":"avg_tgc = telcom.groupby([\"tenure_group\",\"Churn\"])[[\"MonthlyCharges\",\n                                                    \"TotalCharges\"]].mean().reset_index()\n\n#function for tracing \ndef mean_charges(column,aggregate) :\n    tracer = go.Bar(x = avg_tgc[avg_tgc[\"Churn\"] == aggregate][\"tenure_group\"],\n                    y = avg_tgc[avg_tgc[\"Churn\"] == aggregate][column],\n                    name = aggregate,marker = dict(line = dict(width = 1)),\n                    text = \"Churn\"\n                   )\n    return tracer\n\n#function for layout\ndef layout_plot(title,xaxis_lab,yaxis_lab) :\n    layout = go.Layout(dict(title = title,\n                            plot_bgcolor  = \"rgb(243,243,243)\",\n                            paper_bgcolor = \"rgb(243,243,243)\",\n                            xaxis = dict(gridcolor = 'rgb(255, 255, 255)',title = xaxis_lab,\n                                         zerolinewidth=1,ticklen=5,gridwidth=2),\n                            yaxis = dict(gridcolor = 'rgb(255, 255, 255)',title = yaxis_lab,\n                                         zerolinewidth=1,ticklen=5,gridwidth=2),\n                           )\n                      )\n    return layout\n    \n\n#plot1 - mean monthly charges by tenure groups\ntrace1  = mean_charges(\"MonthlyCharges\",\"Yes\")\ntrace2  = mean_charges(\"MonthlyCharges\",\"No\")\nlayout1 = layout_plot(\"Average Monthly Charges by Tenure groups\",\n                      \"Tenure group\",\"Monthly Charges\")\ndata1   = [trace1,trace2]\nfig1    = go.Figure(data=data1,layout=layout1)\n\n#plot2 - mean total charges by tenure groups\ntrace3  = mean_charges(\"TotalCharges\",\"Yes\")\ntrace4  = mean_charges(\"TotalCharges\",\"No\")\nlayout2 = layout_plot(\"Average Total Charges by Tenure groups\",\n                      \"Tenure group\",\"Total Charges\")\ndata2   = [trace3,trace4]\nfig2    = go.Figure(data=data2,layout=layout2)\n\npy.iplot(fig1)\npy.iplot(fig2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e3cd2356bfb98d43703d4f3809e7d117f47d90c8"},"cell_type":"markdown","source":"## <a id='3.6'>3.6. Monthly charges,total charges and tenure in customer attrition</a>"},{"metadata":{"trusted":true,"_uuid":"1271c61fb1d3ce099ee91372f5a4e0286196bb3f"},"cell_type":"code","source":"##copy data\ntel_df = telcom.copy()\n#Drop tenure column\ntelcom = telcom.drop(columns = \"tenure_group\",axis = 1)\n\ntrace1 = go.Scatter3d(x = churn[\"MonthlyCharges\"],\n                      y = churn[\"TotalCharges\"],\n                      z = churn[\"tenure\"],\n                      mode = \"markers\",\n                      name = \"Churn customers\",\n                      text = \"Id : \" + churn[\"customerID\"],\n                      marker = dict(size = 1,color = \"red\")\n                     )\ntrace2 = go.Scatter3d(x = not_churn[\"MonthlyCharges\"],\n                      y = not_churn[\"TotalCharges\"],\n                      z = not_churn[\"tenure\"],\n                      name = \"Non churn customers\",\n                      text = \"Id : \" + not_churn[\"customerID\"],\n                      mode = \"markers\",\n                      marker = dict(size = 1,color= \"green\")\n                     )\n\n\n\nlayout = go.Layout(dict(title = \"Monthly charges,total charges & tenure in customer attrition\",\n                        scene = dict(camera = dict(up=dict(x= 0 , y=0, z=0),\n                                                   center=dict(x=0, y=0, z=0),\n                                                   eye=dict(x=1.25, y=1.25, z=1.25)),\n                                     xaxis  = dict(title = \"monthly charges\",\n                                                   gridcolor='rgb(255, 255, 255)',\n                                                   zerolinecolor='rgb(255, 255, 255)',\n                                                   showbackground=True,\n                                                   backgroundcolor='rgb(230, 230,230)'),\n                                     yaxis  = dict(title = \"total charges\",\n                                                   gridcolor='rgb(255, 255, 255)',\n                                                   zerolinecolor='rgb(255, 255, 255)',\n                                                   showbackground=True,\n                                                   backgroundcolor='rgb(230, 230,230)'\n                                                  ),\n                                     zaxis  = dict(title = \"tenure\",\n                                                   gridcolor='rgb(255, 255, 255)',\n                                                   zerolinecolor='rgb(255, 255, 255)',\n                                                   showbackground=True,\n                                                   backgroundcolor='rgb(230, 230,230)'\n                                                  )\n                                    ),\n                        height = 700,\n                       )\n                  )\n                  \n\ndata = [trace1,trace2]\nfig  = go.Figure(data = data,layout = layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6dfa77b43fe1a1a301bab65186c2a9f90245ab7d"},"cell_type":"markdown","source":"# <a id='4'>4. Data preprocessing</a>"},{"metadata":{"trusted":true,"_uuid":"8921591320c5e336ec5a2e1efc5ed3cb0f9ec1b2"},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\n\n#customer id col\nId_col     = ['customerID']\n#Target columns\ntarget_col = [\"Churn\"]\n#categorical columns\ncat_cols   = telcom.nunique()[telcom.nunique() < 6].keys().tolist()\ncat_cols   = [x for x in cat_cols if x not in target_col]\n#numerical columns\nnum_cols   = [x for x in telcom.columns if x not in cat_cols + target_col + Id_col]\n#Binary columns with 2 values\nbin_cols   = telcom.nunique()[telcom.nunique() == 2].keys().tolist()\n#Columns more than 2 values\nmulti_cols = [i for i in cat_cols if i not in bin_cols]\n\n#Label encoding Binary columns\nle = LabelEncoder()\nfor i in bin_cols :\n    telcom[i] = le.fit_transform(telcom[i])\n    \n#Duplicating columns for multi value columns\ntelcom = pd.get_dummies(data = telcom,columns = multi_cols )\n\n#Scaling Numerical columns\nstd = StandardScaler()\nscaled = std.fit_transform(telcom[num_cols])\nscaled = pd.DataFrame(scaled,columns=num_cols)\n\n#dropping original values merging scaled values for numerical columns\ndf_telcom_og = telcom.copy()\ntelcom = telcom.drop(columns = num_cols,axis = 1)\ntelcom = telcom.merge(scaled,left_index=True,right_index=True,how = \"left\")\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9ec25cff71c0eb0f0c839a726cb06cb43462a53f"},"cell_type":"markdown","source":"## <a id='3.7'>3.7. Variable Summary</a>"},{"metadata":{"trusted":true,"_uuid":"9f1fbaf6d979c28b6f763eb398e4cdd2091fc37b"},"cell_type":"code","source":"summary = (df_telcom_og[[i for i in df_telcom_og.columns if i not in Id_col]].\n           describe().transpose().reset_index())\n\nsummary = summary.rename(columns = {\"index\" : \"feature\"})\nsummary = np.around(summary,3)\n\nval_lst = [summary['feature'], summary['count'],\n           summary['mean'],summary['std'],\n           summary['min'], summary['25%'],\n           summary['50%'], summary['75%'], summary['max']]\n\ntrace  = go.Table(header = dict(values = summary.columns.tolist(),\n                                line = dict(color = ['#506784']),\n                                fill = dict(color = ['#119DFF']),\n                               ),\n                  cells  = dict(values = val_lst,\n                                line = dict(color = ['#506784']),\n                                fill = dict(color = [\"lightgrey\",'#F5F8FF'])\n                               ),\n                  columnwidth = [200,60,100,100,60,60,80,80,80])\nlayout = go.Layout(dict(title = \"Variable Summary\"))\nfigure = go.Figure(data=[trace],layout=layout)\npy.iplot(figure)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"82a7617e37906622dbe00a1783a13cbf382d2513"},"cell_type":"markdown","source":"## <a id='3.8'>3.8. Correlation Matrix</a>"},{"metadata":{"trusted":true,"_uuid":"b52cf9c7f402ed706e82221e3f8601fdeea9ab27"},"cell_type":"code","source":"#correlation\ncorrelation = telcom.corr()\n#tick labels\nmatrix_cols = correlation.columns.tolist()\n#convert to array\ncorr_array  = np.array(correlation)\n\n#Plotting\ntrace = go.Heatmap(z = corr_array,\n                   x = matrix_cols,\n                   y = matrix_cols,\n                   colorscale = \"Viridis\",\n                   colorbar   = dict(title = \"Pearson Correlation coefficient\",\n                                     titleside = \"right\"\n                                    ) ,\n                  )\n\nlayout = go.Layout(dict(title = \"Correlation Matrix for variables\",\n                        autosize = False,\n                        height  = 720,\n                        width   = 800,\n                        margin  = dict(r = 0 ,l = 210,\n                                       t = 25,b = 210,\n                                      ),\n                        yaxis   = dict(tickfont = dict(size = 9)),\n                        xaxis   = dict(tickfont = dict(size = 9))\n                       )\n                  )\n\ndata = [trace]\nfig = go.Figure(data=data,layout=layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"abaf205d4be08b2b9951b1c1a878c6e387998abc"},"cell_type":"markdown","source":"## <a id='3.9'>3.9. Visualising data with principal components</a>"},{"metadata":{"trusted":true,"_uuid":"60c93b7dc48f91fa850d163486f771072f506401"},"cell_type":"code","source":"from sklearn.decomposition import PCA\n\npca = PCA(n_components = 2)\n\nX = telcom[[i for i in telcom.columns if i not in Id_col + target_col]]\nY = telcom[target_col + Id_col]\n\nprincipal_components = pca.fit_transform(X)\npca_data = pd.DataFrame(principal_components,columns = [\"PC1\",\"PC2\"])\npca_data = pca_data.merge(Y,left_index=True,right_index=True,how=\"left\")\npca_data[\"Churn\"] = pca_data[\"Churn\"].replace({1:\"Churn\",0:\"Not Churn\"})\n\ndef pca_scatter(target,color) :\n    tracer = go.Scatter(x = pca_data[pca_data[\"Churn\"] == target][\"PC1\"] ,\n                        y = pca_data[pca_data[\"Churn\"] == target][\"PC2\"],\n                        name = target,mode = \"markers\",\n                        marker = dict(color = color,\n                                      line = dict(width = .5),\n                                      symbol =  \"diamond-open\"),\n                        text = (\"Customer Id : \" + \n                                pca_data[pca_data[\"Churn\"] == target]['customerID'])\n                       )\n    return tracer\n\nlayout = go.Layout(dict(title = \"Visualising data with principal components\",\n                        plot_bgcolor  = \"rgb(243,243,243)\",\n                        paper_bgcolor = \"rgb(243,243,243)\",\n                        xaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n                                     title = \"principal component 1\",\n                                     zerolinewidth=1,ticklen=5,gridwidth=2),\n                        yaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n                                     title = \"principal component 2\",\n                                     zerolinewidth=1,ticklen=5,gridwidth=2),\n                        height = 600\n                       )\n                  )\ntrace1 = pca_scatter(\"Churn\",'red')\ntrace2 = pca_scatter(\"Not Churn\",'royalblue')\ndata = [trace2,trace1]\nfig = go.Figure(data=data,layout=layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a261b0d62fe4af69dc412143d6b4e019cd65963e"},"cell_type":"markdown","source":"## <a id='3.10'>3.10. Binary variables distribution in customer attrition(Radar Chart)</a>"},{"metadata":{"trusted":true,"_uuid":"3a5c9e2edb9121a8db7e2b2d3f1ed23fc9983e9a"},"cell_type":"code","source":"#separating binary columns\nbi_cs = telcom.nunique()[telcom.nunique() == 2].keys()\ndat_rad = telcom[bi_cs]\n\n#plotting radar chart for churn and non churn customers(binary variables)\ndef plot_radar(df,aggregate,title) :\n    data_frame = df[df[\"Churn\"] == aggregate] \n    data_frame_x = data_frame[bi_cs].sum().reset_index()\n    data_frame_x.columns  = [\"feature\",\"yes\"]\n    data_frame_x[\"no\"]    = data_frame.shape[0]  - data_frame_x[\"yes\"]\n    data_frame_x  = data_frame_x[data_frame_x[\"feature\"] != \"Churn\"]\n    \n    #count of 1's(yes)\n    trace1 = go.Scatterpolar(r = data_frame_x[\"yes\"].values.tolist(),\n                             theta = data_frame_x[\"feature\"].tolist(),\n                             fill  = \"toself\",name = \"count of 1's\",\n                             mode = \"markers+lines\",\n                             marker = dict(size = 5)\n                            )\n    #count of 0's(No)\n    trace2 = go.Scatterpolar(r = data_frame_x[\"no\"].values.tolist(),\n                             theta = data_frame_x[\"feature\"].tolist(),\n                             fill  = \"toself\",name = \"count of 0's\",\n                             mode = \"markers+lines\",\n                             marker = dict(size = 5)\n                            ) \n    layout = go.Layout(dict(polar = dict(radialaxis = dict(visible = True,\n                                                           side = \"counterclockwise\",\n                                                           showline = True,\n                                                           linewidth = 2,\n                                                           tickwidth = 2,\n                                                           gridcolor = \"white\",\n                                                           gridwidth = 2),\n                                         angularaxis = dict(tickfont = dict(size = 10),\n                                                            layer = \"below traces\"\n                                                           ),\n                                         bgcolor  = \"rgb(243,243,243)\",\n                                        ),\n                            paper_bgcolor = \"rgb(243,243,243)\",\n                            title = title,height = 700))\n    \n    data = [trace2,trace1]\n    fig = go.Figure(data=data,layout=layout)\n    py.iplot(fig)\n\n#plot\nplot_radar(dat_rad,1,\"Churn -  Customers\")\nplot_radar(dat_rad,0,\"Non Churn - Customers\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f944336cbe67efb3422b79864d9478e2cfbdc860"},"cell_type":"markdown","source":"# <a id='5'>5. Model Building</a>\n## <a id='5.1'>5.1. Baseline Model</a>"},{"metadata":{"trusted":true,"_uuid":"84038088d314f275c654021432f614ecf0b7914d","_kg_hide-input":false},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix,accuracy_score,classification_report\nfrom sklearn.metrics import roc_auc_score,roc_curve,scorer\nfrom sklearn.metrics import f1_score\nimport statsmodels.api as sm\nfrom sklearn.metrics import precision_score,recall_score\nfrom yellowbrick.classifier import DiscriminationThreshold\n#splitting train and test data \ntrain,test = train_test_split(telcom,test_size = .25 ,random_state = 111)\n    \n##seperating dependent and independent variables\ncols    = [i for i in telcom.columns if i not in Id_col + target_col]\ntrain_X = train[cols]\ntrain_Y = train[target_col]\ntest_X  = test[cols]\ntest_Y  = test[target_col]\n\n#Function attributes\n#dataframe     - processed dataframe\n#Algorithm     - Algorithm used \n#training_x    - predictor variables dataframe(training)\n#testing_x     - predictor variables dataframe(testing)\n#training_y    - target variable(training)\n#training_y    - target variable(testing)\n#cf - [\"coefficients\",\"features\"](cooefficients for logistic \n                                 #regression,features for tree based models)\n\n#threshold_plot - if True returns threshold plot for model\n    \ndef telecom_churn_prediction(algorithm,training_x,testing_x,\n                             training_y,testing_y,cols,cf,threshold_plot) :\n    \n    #model\n    algorithm.fit(training_x,training_y)\n    predictions   = algorithm.predict(testing_x)\n    probabilities = algorithm.predict_proba(testing_x)\n    #coeffs\n    if   cf == \"coefficients\" :\n        coefficients  = pd.DataFrame(algorithm.coef_.ravel())\n    elif cf == \"features\" :\n        coefficients  = pd.DataFrame(algorithm.feature_importances_)\n        \n    column_df     = pd.DataFrame(cols)\n    coef_sumry    = (pd.merge(coefficients,column_df,left_index= True,\n                              right_index= True, how = \"left\"))\n    coef_sumry.columns = [\"coefficients\",\"features\"]\n    coef_sumry    = coef_sumry.sort_values(by = \"coefficients\",ascending = False)\n    \n    print (algorithm)\n    print (\"\\n Classification report : \\n\",classification_report(testing_y,predictions))\n    print (\"Accuracy   Score : \",accuracy_score(testing_y,predictions))\n    #confusion matrix\n    conf_matrix = confusion_matrix(testing_y,predictions)\n    #roc_auc_score\n    model_roc_auc = roc_auc_score(testing_y,predictions) \n    print (\"Area under curve : \",model_roc_auc,\"\\n\")\n    fpr,tpr,thresholds = roc_curve(testing_y,probabilities[:,1])\n    \n    #plot confusion matrix\n    trace1 = go.Heatmap(z = conf_matrix ,\n                        x = [\"Not churn\",\"Churn\"],\n                        y = [\"Not churn\",\"Churn\"],\n                        showscale  = False,colorscale = \"Picnic\",\n                        name = \"matrix\")\n    \n    #plot roc curve\n    trace2 = go.Scatter(x = fpr,y = tpr,\n                        name = \"Roc : \" + str(model_roc_auc),\n                        line = dict(color = ('rgb(22, 96, 167)'),width = 2))\n    trace3 = go.Scatter(x = [0,1],y=[0,1],\n                        line = dict(color = ('rgb(205, 12, 24)'),width = 2,\n                        dash = 'dot'))\n    \n    #plot coeffs\n    trace4 = go.Bar(x = coef_sumry[\"features\"],y = coef_sumry[\"coefficients\"],\n                    name = \"coefficients\",\n                    marker = dict(color = coef_sumry[\"coefficients\"],\n                                  colorscale = \"Picnic\",\n                                  line = dict(width = .6,color = \"black\")))\n    \n    #subplots\n    fig = tls.make_subplots(rows=2, cols=2, specs=[[{}, {}], [{'colspan': 2}, None]],\n                            subplot_titles=('Confusion Matrix',\n                                            'Receiver operating characteristic',\n                                            'Feature Importances'))\n    \n    fig.append_trace(trace1,1,1)\n    fig.append_trace(trace2,1,2)\n    fig.append_trace(trace3,1,2)\n    fig.append_trace(trace4,2,1)\n    \n    fig['layout'].update(showlegend=False, title=\"Model performance\" ,\n                         autosize = False,height = 900,width = 800,\n                         plot_bgcolor = 'rgba(240,240,240, 0.95)',\n                         paper_bgcolor = 'rgba(240,240,240, 0.95)',\n                         margin = dict(b = 195))\n    fig[\"layout\"][\"xaxis2\"].update(dict(title = \"false positive rate\"))\n    fig[\"layout\"][\"yaxis2\"].update(dict(title = \"true positive rate\"))\n    fig[\"layout\"][\"xaxis3\"].update(dict(showgrid = True,tickfont = dict(size = 10),\n                                        tickangle = 90))\n    py.iplot(fig)\n    \n    if threshold_plot == True : \n        visualizer = DiscriminationThreshold(algorithm)\n        visualizer.fit(training_x,training_y)\n        visualizer.poof()\n        \nlogit  = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n          verbose=0, warm_start=False)\n\ntelecom_churn_prediction(logit,train_X,test_X,train_Y,test_Y,\n                         cols,\"coefficients\",threshold_plot = True)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5d772699a8637e6e9e1a90f424db967b6ae3c12a"},"cell_type":"markdown","source":"## <a id='5.2'>5.2. Synthetic Minority Oversampling TEchnique (SMOTE)</a>\n* Randomly pick a point from the minority class.\n* Compute the k-nearest neighbors (for some pre-specified k) for this point.\n* Add k new points somewhere between the chosen point and each of its neighbors"},{"metadata":{"trusted":true,"_uuid":"977d0eb5f44d745d2e54b9643df9c3bcf5d461f7"},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\n\ncols    = [i for i in telcom.columns if i not in Id_col+target_col]\n\nsmote_X = telcom[cols]\nsmote_Y = telcom[target_col]\n\n#Split train and test data\nsmote_train_X,smote_test_X,smote_train_Y,smote_test_Y = train_test_split(smote_X,smote_Y,\n                                                                         test_size = .25 ,\n                                                                         random_state = 111)\n\n#oversampling minority class using smote\nos = SMOTE(random_state = 0)\nos_smote_X,os_smote_Y = os.fit_sample(smote_train_X,smote_train_Y)\nos_smote_X = pd.DataFrame(data = os_smote_X,columns=cols)\nos_smote_Y = pd.DataFrame(data = os_smote_Y,columns=target_col)\n###\n\n\n\nlogit_smote = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n          verbose=0, warm_start=False)\n\ntelecom_churn_prediction(logit_smote,os_smote_X,test_X,os_smote_Y,test_Y,\n                         cols,\"coefficients\",threshold_plot = True)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"35f4bbedca5efb1ea70dfa71649cf36e5bdd6e86"},"cell_type":"markdown","source":"## <a id='5.3'>5.3. Recursive Feature Elimination</a>\nRecursive Feature Elimination (RFE) is based on the idea to repeatedly construct a model and choose either the best or worst performing feature, setting the feature aside and then repeating the process with the rest of the features. This process is applied until all features in the dataset are exhausted. The goal of RFE is to select features by recursively considering smaller and smaller sets of features."},{"metadata":{"trusted":true,"_uuid":"a12d867c80eb421a8f97edc35417c53fef9243ed"},"cell_type":"code","source":"from sklearn.feature_selection import RFE\n\nlogit = LogisticRegression()\n\nrfe = RFE(logit,10)\nrfe = rfe.fit(os_smote_X,os_smote_Y.values.ravel())\n\nrfe.support_\nrfe.ranking_\n\n#identified columns Recursive Feature Elimination\nidc_rfe = pd.DataFrame({\"rfe_support\" :rfe.support_,\n                       \"columns\" : [i for i in telcom.columns if i not in Id_col + target_col],\n                       \"ranking\" : rfe.ranking_,\n                      })\ncols = idc_rfe[idc_rfe[\"rfe_support\"] == True][\"columns\"].tolist()\n\n\n#separating train and test data\ntrain_rf_X = os_smote_X[cols]\ntrain_rf_Y = os_smote_Y\ntest_rf_X  = test[cols]\ntest_rf_Y  = test[target_col]\n\nlogit_rfe = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n          verbose=0, warm_start=False)\n#applying model\ntelecom_churn_prediction(logit_rfe,train_rf_X,test_rf_X,train_rf_Y,test_rf_Y,\n                         cols,\"coefficients\",threshold_plot = True)\n\ntab_rk = ff.create_table(idc_rfe)\npy.iplot(tab_rk)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1f7057d8314e17bf67c544794a6b3c2025ac9b99"},"cell_type":"markdown","source":"## <a id='5.4'>5.4. Univariate Selection</a>\n* Feature Extraction with Univariate Statistical Tests (Chi-squared for classification)\n* uses the chi squared (chi^2) statistical test for non-negative features to select the best features"},{"metadata":{"trusted":true,"_uuid":"27089924eba9425a075576c5254523281dc5b1f5"},"cell_type":"code","source":"from sklearn.feature_selection import chi2\nfrom sklearn.feature_selection import SelectKBest\n\n#select columns\ncols = [i for i in telcom.columns if i not in Id_col + target_col ]\n\n#dataframe with non negative values\ndf_x = df_telcom_og[cols]\ndf_y = df_telcom_og[target_col]\n\n#fit model with k= 3\nselect = SelectKBest(score_func = chi2,k = 3)\nfit    = select.fit(df_x,df_y)\n\n#Summerize scores\nprint (\"scores\")\nprint (fit.scores_)\nprint (\"P - Values\")\nprint (fit.pvalues_)\n\n#create dataframe\nscore = pd.DataFrame({\"features\":cols,\"scores\":fit.scores_,\"p_values\":fit.pvalues_ })\nscore = score.sort_values(by = \"scores\" ,ascending =False)\n\n\n#createing new label for categorical and numerical columns\nscore[\"feature_type\"] = np.where(score[\"features\"].isin(num_cols),\"Numerical\",\"Categorical\")\n\n#plot\ntrace  = go.Scatter(x = score[score[\"feature_type\"] == \"Categorical\"][\"features\"],\n                    y = score[score[\"feature_type\"] == \"Categorical\"][\"scores\"],\n                    name = \"Categorial\",mode = \"lines+markers\",\n                    marker = dict(color = \"red\",\n                                  line = dict(width =1))\n                   )\n\ntrace1 = go.Bar(x = score[score[\"feature_type\"] == \"Numerical\"][\"features\"],\n                y = score[score[\"feature_type\"] == \"Numerical\"][\"scores\"],name = \"Numerical\",\n                marker = dict(color = \"royalblue\",\n                              line = dict(width =1)),\n                xaxis = \"x2\",yaxis = \"y2\"\n               )\nlayout = go.Layout(dict(title = \"Scores for Categorical & Numerical features\",\n                        plot_bgcolor  = \"rgb(243,243,243)\",\n                        paper_bgcolor = \"rgb(243,243,243)\",\n                        xaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n                                     tickfont = dict(size =10),\n                                     domain=[0, 0.7],\n                                     tickangle = 90,zerolinewidth=1,\n                                     ticklen=5,gridwidth=2),\n                        yaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n                                     title = \"scores\",\n                                     zerolinewidth=1,ticklen=5,gridwidth=2),\n                        margin = dict(b=200),\n                        xaxis2=dict(domain=[0.8, 1],tickangle = 90,\n                                    gridcolor = 'rgb(255, 255, 255)'),\n                        yaxis2=dict(anchor='x2',gridcolor = 'rgb(255, 255, 255)')\n                        )\n                  )\n\ndata=[trace,trace1]\nfig = go.Figure(data=data,layout=layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a07fecf352ce39ca7cc43664b6995807a89a3821"},"cell_type":"markdown","source":"## <a id='5.5'>5.5. Decision Tree Visualization</a>\n* Using top three numerical features"},{"metadata":{"trusted":true,"_uuid":"ea1d40b1f9909f5460441817ee36ba2da51b02ed","scrolled":false},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.tree import export_graphviz\nfrom sklearn import tree\nfrom graphviz import Source\nfrom IPython.display import SVG,display\n\n#top 3 categorical features\nfeatures_cat  = score[score[\"feature_type\"] == \"Categorical\"][\"features\"][:3].tolist()\n\n#top 3 numerical features\nfeatures_num  = score[score[\"feature_type\"] == \"Numerical\"][\"features\"][:3].tolist()\n\n\n#Function attributes\n#columns        - selected columns\n#maximum_depth  - depth of tree\n#criterion_type - [\"gini\" or \"entropy\"]\n#split_type     - [\"best\" or \"random\"]\n#Model Performance - True (gives model output)\n\ndef plot_decision_tree(columns,maximum_depth,criterion_type,\n                       split_type,model_performance = None) :\n    \n    #separating dependent and in dependent variables\n    dtc_x = df_x[columns]\n    dtc_y = df_y[target_col]\n    \n    #model\n    dt_classifier = DecisionTreeClassifier(max_depth = maximum_depth,\n                                           splitter  = split_type,\n                                           criterion = criterion_type,\n                                          )\n    dt_classifier.fit(dtc_x,dtc_y)\n    \n    #plot decision tree\n    graph = Source(tree.export_graphviz(dt_classifier,out_file=None,\n                                        rounded=True,proportion = False,\n                                        feature_names = columns, \n                                        precision  = 2,\n                                        class_names=[\"Not churn\",\"Churn\"],\n                                        filled = True                         \n                                       )\n                  )\n    \n    #model performance\n    if model_performance == True :\n        telecom_churn_prediction(dt_classifier,\n                                 dtc_x,test_X[columns],\n                                 dtc_y,test_Y,\n                                 columns,\"features\",threshold_plot = True)\n    display(graph)\n    \nplot_decision_tree(features_num,3,\"gini\",\"best\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2ccee38cc7cda6e59cc97de47da9096f03123dd3"},"cell_type":"markdown","source":"### * Using top three categorical features"},{"metadata":{"trusted":true,"_uuid":"dfe50b84806d633c49780cc518017b26f66c0c31"},"cell_type":"code","source":"plot_decision_tree(features_cat,3,\"entropy\",\"best\",\n                   model_performance = True ,)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d0a7f7cb549f592142166505a3f03e612f690bb2"},"cell_type":"code","source":"#using contract,tenure and paperless billing variables\ncolumns = ['tenure','Contract_Month-to-month', 'PaperlessBilling',\n           'Contract_One year', 'Contract_Two year']\n\nplot_decision_tree(columns,3,\"gini\",\"best\",model_performance= True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d1f760b002defd916b4566ae59312bcada1a9229"},"cell_type":"markdown","source":"## <a id='5.6'>5.6. KNN Classifier</a>\n* Applying knn algorithm to smote  oversampled data.\n"},{"metadata":{"trusted":true,"_uuid":"8697d16c7e56db13e012458c797b60c3fa6b2f67"},"cell_type":"code","source":"def telecom_churn_prediction_alg(algorithm,training_x,testing_x,\n                                 training_y,testing_y,threshold_plot = True) :\n    \n    #model\n    algorithm.fit(training_x,training_y)\n    predictions   = algorithm.predict(testing_x)\n    probabilities = algorithm.predict_proba(testing_x)\n    \n    print (algorithm)\n    print (\"\\n Classification report : \\n\",classification_report(testing_y,predictions))\n    print (\"Accuracy Score   : \",accuracy_score(testing_y,predictions))\n    #confusion matrix\n    conf_matrix = confusion_matrix(testing_y,predictions)\n    #roc_auc_score\n    model_roc_auc = roc_auc_score(testing_y,predictions) \n    print (\"Area under curve : \",model_roc_auc)\n    fpr,tpr,thresholds = roc_curve(testing_y,probabilities[:,1])\n     \n    #plot roc curve\n    trace1 = go.Scatter(x = fpr,y = tpr,\n                        name = \"Roc : \" + str(model_roc_auc),\n                        line = dict(color = ('rgb(22, 96, 167)'),width = 2),\n                       )\n    trace2 = go.Scatter(x = [0,1],y=[0,1],\n                        line = dict(color = ('rgb(205, 12, 24)'),width = 2,\n                        dash = 'dot'))\n    \n    #plot confusion matrix\n    trace3 = go.Heatmap(z = conf_matrix ,x = [\"Not churn\",\"Churn\"],\n                        y = [\"Not churn\",\"Churn\"],\n                        showscale  = False,colorscale = \"Blues\",name = \"matrix\",\n                        xaxis = \"x2\",yaxis = \"y2\"\n                       )\n    \n    layout = go.Layout(dict(title=\"Model performance\" ,\n                            autosize = False,height = 500,width = 800,\n                            showlegend = False,\n                            plot_bgcolor  = \"rgb(243,243,243)\",\n                            paper_bgcolor = \"rgb(243,243,243)\",\n                            xaxis = dict(title = \"false positive rate\",\n                                         gridcolor = 'rgb(255, 255, 255)',\n                                         domain=[0, 0.6],\n                                         ticklen=5,gridwidth=2),\n                            yaxis = dict(title = \"true positive rate\",\n                                         gridcolor = 'rgb(255, 255, 255)',\n                                         zerolinewidth=1,\n                                         ticklen=5,gridwidth=2),\n                            margin = dict(b=200),\n                            xaxis2=dict(domain=[0.7, 1],tickangle = 90,\n                                        gridcolor = 'rgb(255, 255, 255)'),\n                            yaxis2=dict(anchor='x2',gridcolor = 'rgb(255, 255, 255)')\n                           )\n                  )\n    data = [trace1,trace2,trace3]\n    fig = go.Figure(data=data,layout=layout)\n    \n    py.iplot(fig)\n    \n    if threshold_plot == True : \n        visualizer = DiscriminationThreshold(algorithm)\n        visualizer.fit(training_x,training_y)\n        visualizer.poof()\n\n    \nfrom sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n           weights='uniform')\ntelecom_churn_prediction_alg(knn,os_smote_X,test_X,\n                             os_smote_Y,test_Y,threshold_plot = True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4da23289dc077e781656d2996c990a08a527c8f9"},"cell_type":"markdown","source":"## <a id='5.7'>5.7. Vizualising a decision tree from random forest classifier</a>"},{"metadata":{"trusted":true,"_uuid":"75a1414fe8147d4f4bca042c019e273c70d33c07"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\n#function attributes\n#columns  - column used\n#nf_estimators   - The number of trees in the forest.\n#estimated_tree  - tree number to be displayed\n#maximum_depth   - depth of the tree\n#criterion_type  - split criterion type [\"gini\" or \"entropy\"]\n#Model performance - prints performance of model\n\ndef plot_tree_randomforest(columns,nf_estimators,\n                           estimated_tree,maximum_depth,\n                           criterion_type,model_performance = None) :\n    \n    dataframe = df_telcom_og[columns + target_col].copy()\n    \n    #train and test datasets\n    rf_x     = dataframe[[i for i in columns if i not in target_col]]\n    rf_y     = dataframe[target_col]\n    \n    #random forest classifier\n    rfc   = RandomForestClassifier(n_estimators = nf_estimators,\n                                   max_depth = maximum_depth,\n                                   criterion = criterion_type,\n                                  )\n    rfc.fit(rf_x,rf_y)\n    \n    estimated_tree = rfc.estimators_[estimated_tree]\n    \n    graph = Source(tree.export_graphviz(estimated_tree,out_file=None,\n                                        rounded=True,proportion = False,\n                            feature_names = columns, \n                            precision  = 2,\n                            class_names=[\"Not churn\",\"Churn\"],\n                            filled = True))\n    display(graph)\n    \n    #model performance\n    if model_performance == True :\n        telecom_churn_prediction(rfc,\n                                 rf_x,test_X[columns],\n                                 rf_y,test_Y,\n                                 columns,\"features\",threshold_plot = True)\n        \n\ncols1 = [ i for i in train_X.columns if i not in target_col + Id_col] \nplot_tree_randomforest(cols1,100,99,3,\"entropy\",True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5dac202bbbe6e6869eab168e6a10a1efa6abe291"},"cell_type":"markdown","source":"## <a id='5.8'>5.8. A random forest classifier.</a>\n* A random forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and use averaging to improve the predictive accuracy and control over-fitting. The sub-sample size is always the same as the original input sample size but the samples are drawn with replacement .\n* Below are the trees produced by random forest model with 10 estimated trees with maximum depth of three  for each tree. Each tree produced is slightly different from other."},{"metadata":{"trusted":true,"_uuid":"bec2258c30240d958901d705c7b4ab1d8ab6c43f"},"cell_type":"code","source":"#making 10 trees with random forest.\nn = np.arange(0,10).tolist()\ncols1 = [ i for i in train_X.columns if i not in target_col + Id_col] \nfor i in n :\n    plot_tree_randomforest(cols1,10,i,3,\"entropy\",model_performance=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"593bb355aec5d5baa385000f55319f064539f2f8"},"cell_type":"code","source":"#making 10 trees with random forest for columns \n#selected from recursive feature elimination\n\nn = np.arange(0,10).tolist()\ncols = idc_rfe[idc_rfe[\"rfe_support\"] == True][\"columns\"].tolist() \nfor i in n :\n    plot_tree_randomforest(cols,10,i,3,\"gini\",model_performance=False)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d89e418310cb3f60d4db4fdb4be330a74b918ba7"},"cell_type":"markdown","source":"## <a id='5.9'>5.9. Gaussian Naive Bayes.</a>"},{"metadata":{"trusted":true,"_uuid":"106512611d7108e63d5b4dc38cdf5fd72eef8ea4"},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\ngnb = GaussianNB(priors=None)\n\ntelecom_churn_prediction_alg(gnb,os_smote_X,test_X,os_smote_Y,test_Y)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6574aaec38141dce75510e2b473058238711e74d"},"cell_type":"markdown","source":"## <a id='5.10'>5.10. Support Vector Machine</a>\n* Support Vector Machine (SVM) is a supervised machine learning algorithm which can be used for both classification or regression challenges.   it is mostly used in classification problems. In this algorithm, we plot each data item as a point in n-dimensional space .where n is number of features you have) with the value of each feature being the value of a particular coordinate. Then, we perform classification by finding the hyper-plane that differentiate the two classes "},{"metadata":{"trusted":true,"_uuid":"5c44767e6467369ffd0bbe77bf74cc2af6d66455"},"cell_type":"code","source":"from sklearn.svm import SVC\n\n#Support vector classifier\n#using linear hyper plane\nsvc_lin  = SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n               decision_function_shape='ovr', degree=3, gamma=1.0, kernel='linear',\n               max_iter=-1, probability=True, random_state=None, shrinking=True,\n               tol=0.001, verbose=False)\n\ncols = [i for i in telcom.columns if i not in Id_col + target_col]\ntelecom_churn_prediction(svc_lin,os_smote_X,test_X,os_smote_Y,test_Y,\n                         cols,\"coefficients\",threshold_plot = False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fd577130cae87f970137f2c8eed0dea5287eb9c9"},"cell_type":"markdown","source":"## <a id='5.11'>5.11. Tuning parameters for support vector machine</a>"},{"metadata":{"trusted":true,"_uuid":"4fb858e9b766f7672a61a21f5e5e518ff9ffd31f"},"cell_type":"code","source":"#tuning parameters\n#Support vector classifier\n#using non-linear hyper plane(\"rbf\")\n\nsvc_rbf  = SVC(C=1.0, kernel='rbf', \n               degree= 3, gamma=1.0, \n               coef0=0.0, shrinking=True,\n               probability=True,tol=0.001,\n               cache_size=200, class_weight=None,\n               verbose=False,max_iter= -1,\n               random_state=None)\n\ntelecom_churn_prediction_alg(svc_rbf,os_smote_X,test_X,os_smote_Y,test_Y,threshold_plot = False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"940f332d9d6c261cda8e149c634e2526b591c88b"},"cell_type":"markdown","source":"## <a id='5.12'>5.12. LightGBMClassifier</a>"},{"metadata":{"trusted":true,"_uuid":"c76c25d63a9554b5d20ae9be3cff0069dabdede8"},"cell_type":"code","source":"from lightgbm import LGBMClassifier\n\nlgbm_c = LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n                        learning_rate=0.5, max_depth=7, min_child_samples=20,\n                        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n                        n_jobs=-1, num_leaves=500, objective='binary', random_state=None,\n                        reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,\n                        subsample_for_bin=200000, subsample_freq=0)\n\ncols = [i for i in telcom.columns if i not in Id_col + target_col]\ntelecom_churn_prediction(lgbm_c,os_smote_X,test_X,os_smote_Y,test_Y,\n                         cols,\"features\",threshold_plot = True)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ce2c26ca71afd0cb5be5428fc467ab6ccadfc78c"},"cell_type":"markdown","source":"## <a id='5.13'>5.13. XGBoost  Classifier</a>"},{"metadata":{"trusted":true,"_uuid":"23bd0fd13e72af0845582cca9376fb1ef658c0d7"},"cell_type":"code","source":"from xgboost import XGBClassifier\n\nxgc = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n                    colsample_bytree=1, gamma=0, learning_rate=0.9, max_delta_step=0,\n                    max_depth = 7, min_child_weight=1, missing=None, n_estimators=100,\n                    n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n                    reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n                    silent=True, subsample=1)\n\n\ntelecom_churn_prediction(xgc,os_smote_X,test_X,os_smote_Y,test_Y,\n                         cols,\"features\",threshold_plot = True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f985c3fb0797143d22aa5635cb58cbbab954bb2c"},"cell_type":"markdown","source":"# <a id='6'>6. Model Performances</a>\n## <a id='6.1'>6.1. model performance metrics</a>"},{"metadata":{"trusted":true,"_uuid":"0fa855b07426701aa3ec9724669c022854087ef6"},"cell_type":"code","source":"from sklearn.metrics import f1_score\nfrom sklearn.metrics import cohen_kappa_score\n\n#gives model report in dataframe\ndef model_report(model,training_x,testing_x,training_y,testing_y,name) :\n    model.fit(training_x,training_y)\n    predictions  = model.predict(testing_x)\n    accuracy     = accuracy_score(testing_y,predictions)\n    recallscore  = recall_score(testing_y,predictions)\n    precision    = precision_score(testing_y,predictions)\n    roc_auc      = roc_auc_score(testing_y,predictions)\n    f1score      = f1_score(testing_y,predictions) \n    kappa_metric = cohen_kappa_score(testing_y,predictions)\n    \n    df = pd.DataFrame({\"Model\"           : [name],\n                       \"Accuracy_score\"  : [accuracy],\n                       \"Recall_score\"    : [recallscore],\n                       \"Precision\"       : [precision],\n                       \"f1_score\"        : [f1score],\n                       \"Area_under_curve\": [roc_auc],\n                       \"Kappa_metric\"    : [kappa_metric],\n                      })\n    return df\n\n#outputs for every model\nmodel1 = model_report(logit,train_X,test_X,train_Y,test_Y,\n                      \"Logistic Regression(Baseline_model)\")\nmodel2 = model_report(logit_smote,os_smote_X,test_X,os_smote_Y,test_Y,\n                      \"Logistic Regression(SMOTE)\")\nmodel3 = model_report(logit_rfe,train_rf_X,test_rf_X,train_rf_Y,test_rf_Y,\n                      \"Logistic Regression(RFE)\")\ndecision_tree = DecisionTreeClassifier(max_depth = 9,\n                                       random_state = 123,\n                                       splitter  = \"best\",\n                                       criterion = \"gini\",\n                                      )\nmodel4 = model_report(decision_tree,train_X,test_X,train_Y,test_Y,\n                      \"Decision Tree\")\nmodel5 = model_report(knn,os_smote_X,test_X,os_smote_Y,test_Y,\n                      \"KNN Classifier\")\nrfc = RandomForestClassifier(n_estimators = 1000,\n                             random_state = 123,\n                             max_depth = 9,\n                             criterion = \"gini\")\nmodel6 = model_report(rfc,train_X,test_X,train_Y,test_Y,\n                      \"Random Forest Classifier\")\nmodel7 = model_report(gnb,os_smote_X,test_X,os_smote_Y,test_Y,\n                      \"Naive Bayes\")\nmodel8 = model_report(svc_lin,os_smote_X,test_X,os_smote_Y,test_Y,\n                      \"SVM Classifier Linear\")\nmodel9 = model_report(svc_rbf,os_smote_X,test_X,os_smote_Y,test_Y,\n                      \"SVM Classifier RBF\")\nmodel10 = model_report(lgbm_c,os_smote_X,test_X,os_smote_Y,test_Y,\n                      \"LGBM Classifier\")\nmodel11 = model_report(xgc,os_smote_X,test_X,os_smote_Y,test_Y,\n                      \"XGBoost Classifier\")\n\n#concat all models\nmodel_performances = pd.concat([model1,model2,model3,\n                                model4,model5,model6,\n                                model7,model8,model9,\n                                model10,model11],axis = 0).reset_index()\n\nmodel_performances = model_performances.drop(columns = \"index\",axis =1)\n\ntable  = ff.create_table(np.round(model_performances,4))\n\npy.iplot(table)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"132cc1f1657a71dd267b44c232741b44b5f174fb"},"cell_type":"markdown","source":"## <a id='6.2'>6.2. Compare model metrics</a>"},{"metadata":{"trusted":true,"_uuid":"bac094f82b5581e62772d201c5dcc964e2f8698a"},"cell_type":"code","source":"model_performances\ndef output_tracer(metric,color) :\n    tracer = go.Bar(y = model_performances[\"Model\"] ,\n                    x = model_performances[metric],\n                    orientation = \"h\",name = metric ,\n                    marker = dict(line = dict(width =.7),\n                                  color = color)\n                   )\n    return tracer\n\nlayout = go.Layout(dict(title = \"Model performances\",\n                        plot_bgcolor  = \"rgb(243,243,243)\",\n                        paper_bgcolor = \"rgb(243,243,243)\",\n                        xaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n                                     title = \"metric\",\n                                     zerolinewidth=1,\n                                     ticklen=5,gridwidth=2),\n                        yaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n                                     zerolinewidth=1,ticklen=5,gridwidth=2),\n                        margin = dict(l = 250),\n                        height = 780\n                       )\n                  )\n\n\ntrace1  = output_tracer(\"Accuracy_score\",\"#6699FF\")\ntrace2  = output_tracer('Recall_score',\"red\")\ntrace3  = output_tracer('Precision',\"#33CC99\")\ntrace4  = output_tracer('f1_score',\"lightgrey\")\ntrace5  = output_tracer('Kappa_metric',\"#FFCC99\")\n\ndata = [trace1,trace2,trace3,trace4,trace5]\nfig = go.Figure(data=data,layout=layout)\npy.iplot(fig)\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"920f02fd2a3da5aed679aade56b1227481cc42a3"},"cell_type":"markdown","source":"## <a id='6.3'>6.3. Confusion matrices for models</a>"},{"metadata":{"trusted":true,"_uuid":"47ecb82832b1af00324b808c7e6ff30e15aa06df"},"cell_type":"code","source":"lst    = [logit,logit_smote,decision_tree,knn,rfc,\n          gnb,svc_lin,svc_rbf,lgbm_c,xgc]\n\nlength = len(lst)\n\nmods   = ['Logistic Regression(Baseline_model)','Logistic Regression(SMOTE)',\n          'Decision Tree','KNN Classifier','Random Forest Classifier',\"Naive Bayes\",\n          'SVM Classifier Linear','SVM Classifier RBF', 'LGBM Classifier',\n          'XGBoost Classifier']\n\nfig = plt.figure(figsize=(13,15))\nfig.set_facecolor(\"#F3F3F3\")\nfor i,j,k in itertools.zip_longest(lst,range(length),mods) :\n    plt.subplot(4,3,j+1)\n    predictions = i.predict(test_X)\n    conf_matrix = confusion_matrix(predictions,test_Y)\n    sns.heatmap(conf_matrix,annot=True,fmt = \"d\",square = True,\n                xticklabels=[\"not churn\",\"churn\"],\n                yticklabels=[\"not churn\",\"churn\"],\n                linewidths = 2,linecolor = \"w\",cmap = \"Set1\")\n    plt.title(k,color = \"b\")\n    plt.subplots_adjust(wspace = .3,hspace = .3)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7d3d15f7aa0c14639397d99ac351be0324605ff9"},"cell_type":"markdown","source":"## <a id='6.4'>6.4. ROC - Curves  for models</a>"},{"metadata":{"trusted":true,"_uuid":"defa68e25a63291f858057efec664391b2639e59"},"cell_type":"code","source":"lst    = [logit,logit_smote,decision_tree,knn,rfc,\n          gnb,svc_lin,svc_rbf,lgbm_c,xgc]\n\nlength = len(lst)\n\nmods   = ['Logistic Regression(Baseline_model)','Logistic Regression(SMOTE)',\n          'Decision Tree','KNN Classifier','Random Forest Classifier',\"Naive Bayes\",\n          'SVM Classifier Linear','SVM Classifier RBF', 'LGBM Classifier',\n          'XGBoost Classifier']\n\nplt.style.use(\"dark_background\")\nfig = plt.figure(figsize=(12,16))\nfig.set_facecolor(\"#F3F3F3\")\nfor i,j,k in itertools.zip_longest(lst,range(length),mods) :\n    qx = plt.subplot(4,3,j+1)\n    probabilities = i.predict_proba(test_X)\n    predictions   = i.predict(test_X)\n    fpr,tpr,thresholds = roc_curve(test_Y,probabilities[:,1])\n    plt.plot(fpr,tpr,linestyle = \"dotted\",\n             color = \"royalblue\",linewidth = 2,\n             label = \"AUC = \" + str(np.around(roc_auc_score(test_Y,predictions),3)))\n    plt.plot([0,1],[0,1],linestyle = \"dashed\",\n             color = \"orangered\",linewidth = 1.5)\n    plt.fill_between(fpr,tpr,alpha = .4)\n    plt.fill_between([0,1],[0,1],color = \"k\")\n    plt.legend(loc = \"lower right\",\n               prop = {\"size\" : 12})\n    qx.set_facecolor(\"k\")\n    plt.grid(True,alpha = .15)\n    plt.title(k,color = \"b\")\n    plt.xticks(np.arange(0,1,.3))\n    plt.yticks(np.arange(0,1,.3))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4e3e5dd305ef65d9c16be5a93634689ce944de5a"},"cell_type":"markdown","source":"## <a id='6.5'>6.5. Precision recall curves</a>"},{"metadata":{"trusted":true,"_uuid":"d0124d0b53da3a46be6d1fcf160d59ef1cc3a81c"},"cell_type":"code","source":"from sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import average_precision_score\n\n\nlst    = [logit,logit_smote,decision_tree,knn,rfc,\n          gnb,svc_lin,svc_rbf,lgbm_c,xgc]\n\nlength = len(lst)\n\nmods   = ['Logistic Regression(Baseline_model)','Logistic Regression(SMOTE)',\n          'Decision Tree','KNN Classifier','Random Forest Classifier',\"Naive Bayes\",\n          'SVM Classifier Linear','SVM Classifier RBF', 'LGBM Classifier',\n          'XGBoost Classifier']\n\nfig = plt.figure(figsize=(13,17))\nfig.set_facecolor(\"#F3F3F3\")\nfor i,j,k in itertools.zip_longest(lst,range(length),mods) :\n    \n    qx = plt.subplot(4,3,j+1)\n    probabilities = i.predict_proba(test_X)\n    predictions   = i.predict(test_X)\n    recall,precision,thresholds = precision_recall_curve(test_Y,probabilities[:,1])\n    plt.plot(recall,precision,linewidth = 1.5,\n             label = (\"avg_pcn : \" + \n                      str(np.around(average_precision_score(test_Y,predictions),3))))\n    plt.plot([0,1],[0,0],linestyle = \"dashed\")\n    plt.fill_between(recall,precision,alpha = .2)\n    plt.legend(loc = \"lower left\",\n               prop = {\"size\" : 10})\n    qx.set_facecolor(\"k\")\n    plt.grid(True,alpha = .15)\n    plt.title(k,color = \"b\")\n    plt.xlabel(\"recall\",fontsize =7)\n    plt.ylabel(\"precision\",fontsize =7)\n    plt.xlim([0.25,1])\n    plt.yticks(np.arange(0,1,.3))\n    ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}