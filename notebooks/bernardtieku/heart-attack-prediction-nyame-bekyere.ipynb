{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-31T04:06:34.458252Z","iopub.execute_input":"2021-05-31T04:06:34.458675Z","iopub.status.idle":"2021-05-31T04:06:34.479489Z","shell.execute_reply.started":"2021-05-31T04:06:34.458582Z","shell.execute_reply":"2021-05-31T04:06:34.477785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n# Classifiers\n#import decisiontreeclassifier\nfrom sklearn import tree\nfrom sklearn.tree import export_text\nfrom sklearn.tree import DecisionTreeClassifier\n#import logisticregression classifier\nfrom sklearn.linear_model import LogisticRegression\n\n#import knn classifier\nfrom sklearn.neighbors import KNeighborsClassifier\n\n#for validating your classification model\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn import metrics\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.metrics import roc_auc_score\n\n# feature selection\nfrom sklearn.feature_selection import RFE\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\n\nfrom sklearn.ensemble import RandomForestClassifier\n\n# grid search\nfrom sklearn.model_selection import GridSearchCV\n\n# advanced algorthms\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.svm import SVC\n\n#ignore warning\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:06:34.481442Z","iopub.execute_input":"2021-05-31T04:06:34.482013Z","iopub.status.idle":"2021-05-31T04:06:35.965461Z","shell.execute_reply.started":"2021-05-31T04:06:34.481955Z","shell.execute_reply":"2021-05-31T04:06:35.964215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load data\ncl = pd.read_csv('/kaggle/input/heart-attack-analysis-prediction-dataset/heart.csv')\ncl.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:06:35.967441Z","iopub.execute_input":"2021-05-31T04:06:35.967765Z","iopub.status.idle":"2021-05-31T04:06:36.016449Z","shell.execute_reply.started":"2021-05-31T04:06:35.967731Z","shell.execute_reply":"2021-05-31T04:06:36.015571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Looking for data type\ncl.info()","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:06:36.017823Z","iopub.execute_input":"2021-05-31T04:06:36.018306Z","iopub.status.idle":"2021-05-31T04:06:36.042375Z","shell.execute_reply.started":"2021-05-31T04:06:36.018269Z","shell.execute_reply":"2021-05-31T04:06:36.041156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# looking for null values in the dataset\ncl.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:06:36.043868Z","iopub.execute_input":"2021-05-31T04:06:36.044203Z","iopub.status.idle":"2021-05-31T04:06:36.055727Z","shell.execute_reply.started":"2021-05-31T04:06:36.044169Z","shell.execute_reply":"2021-05-31T04:06:36.054196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Decriptive Analysis and Data Visualization","metadata":{}},{"cell_type":"code","source":"# to check outliers\ncl.describe()","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:06:36.057406Z","iopub.execute_input":"2021-05-31T04:06:36.057844Z","iopub.status.idle":"2021-05-31T04:06:36.130602Z","shell.execute_reply.started":"2021-05-31T04:06:36.057804Z","shell.execute_reply":"2021-05-31T04:06:36.129367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Pivot talbe for output thus those less chance of heart attack and more chance of heart attack.\ncl.groupby(['output']).size()","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:06:36.132278Z","iopub.execute_input":"2021-05-31T04:06:36.132634Z","iopub.status.idle":"2021-05-31T04:06:36.143161Z","shell.execute_reply.started":"2021-05-31T04:06:36.132601Z","shell.execute_reply":"2021-05-31T04:06:36.14231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot for output\ncl.groupby(['output']).size().plot(kind='bar')","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:06:36.146014Z","iopub.execute_input":"2021-05-31T04:06:36.14637Z","iopub.status.idle":"2021-05-31T04:06:36.370262Z","shell.execute_reply.started":"2021-05-31T04:06:36.146337Z","shell.execute_reply":"2021-05-31T04:06:36.369139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cl.groupby(['output', 'sex']).size()","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:06:36.372284Z","iopub.execute_input":"2021-05-31T04:06:36.372618Z","iopub.status.idle":"2021-05-31T04:06:36.388119Z","shell.execute_reply.started":"2021-05-31T04:06:36.372585Z","shell.execute_reply":"2021-05-31T04:06:36.386604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cl.groupby(['output', 'fbs']).size()","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:06:36.390076Z","iopub.execute_input":"2021-05-31T04:06:36.39042Z","iopub.status.idle":"2021-05-31T04:06:36.405823Z","shell.execute_reply.started":"2021-05-31T04:06:36.390386Z","shell.execute_reply":"2021-05-31T04:06:36.404403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cl.groupby(['output', 'slp']).size()","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:06:36.407743Z","iopub.execute_input":"2021-05-31T04:06:36.408138Z","iopub.status.idle":"2021-05-31T04:06:36.422437Z","shell.execute_reply.started":"2021-05-31T04:06:36.4081Z","shell.execute_reply":"2021-05-31T04:06:36.421136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data visualisation for output and age\nsns.violinplot(x=\"sex\", y=\"output\", data=cl)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:06:36.424129Z","iopub.execute_input":"2021-05-31T04:06:36.424438Z","iopub.status.idle":"2021-05-31T04:06:36.657247Z","shell.execute_reply.started":"2021-05-31T04:06:36.424408Z","shell.execute_reply":"2021-05-31T04:06:36.656298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data visualisation for output and chol\nsns.catplot(\"output\", \"chol\", data=cl, kind='bar')","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:06:36.65867Z","iopub.execute_input":"2021-05-31T04:06:36.659395Z","iopub.status.idle":"2021-05-31T04:06:37.142328Z","shell.execute_reply.started":"2021-05-31T04:06:36.659339Z","shell.execute_reply":"2021-05-31T04:06:37.141002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploratory Analysis","metadata":{}},{"cell_type":"code","source":"# Correlation Analysis without Dummies\ncl.corr()","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:06:37.145215Z","iopub.execute_input":"2021-05-31T04:06:37.146004Z","iopub.status.idle":"2021-05-31T04:06:37.176965Z","shell.execute_reply.started":"2021-05-31T04:06:37.145945Z","shell.execute_reply":"2021-05-31T04:06:37.175379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Correlation Analysis with dummies","metadata":{}},{"cell_type":"code","source":"cl.nunique()","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:06:37.178923Z","iopub.execute_input":"2021-05-31T04:06:37.179541Z","iopub.status.idle":"2021-05-31T04:06:37.204269Z","shell.execute_reply.started":"2021-05-31T04:06:37.179484Z","shell.execute_reply":"2021-05-31T04:06:37.202736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cl_1 = pd.get_dummies(cl, columns=['output', 'cp', 'restecg', 'sex'])\ncl_1.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:06:37.206737Z","iopub.execute_input":"2021-05-31T04:06:37.207447Z","iopub.status.idle":"2021-05-31T04:06:37.24998Z","shell.execute_reply.started":"2021-05-31T04:06:37.207388Z","shell.execute_reply":"2021-05-31T04:06:37.248311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cl_1=cl_1.corr()\ncl_1","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:06:37.252133Z","iopub.execute_input":"2021-05-31T04:06:37.252722Z","iopub.status.idle":"2021-05-31T04:06:37.32351Z","shell.execute_reply.started":"2021-05-31T04:06:37.252664Z","shell.execute_reply":"2021-05-31T04:06:37.322053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Heat Map\nfig = plt.figure(figsize = (30,15))\nsns.heatmap(cl_1, annot = True)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:06:37.328174Z","iopub.execute_input":"2021-05-31T04:06:37.328739Z","iopub.status.idle":"2021-05-31T04:06:39.645512Z","shell.execute_reply.started":"2021-05-31T04:06:37.328689Z","shell.execute_reply":"2021-05-31T04:06:39.643809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## First of all we need to explain the positives and negatives associated with the numbers obtained.\n- Positive Correlation; A positive correlation is a relationship between 2 variables which the increase of one variable causes an increase for another variable.\n- Negative Correlation; The Negative correlation is the opposite, itâ€™s a relationship between 2 variables which the increase of one variable causes a decrease for another variable. This applies otherwise.\n- From our correlation analysis, we can see age has AGE has a positive weak correlation with output_0 (less chance of heart attack). This means that as age increase the more likely there is a chance of heart attack and vice versa.\n- We can also see that AGE has a negative weak correlation with output_1 (more chance of heart attack). This means that the lower the age the patient will not have more chance of a heat attack and vice versa.","metadata":{}},{"cell_type":"markdown","source":"# Statistical inference\n","metadata":{}},{"cell_type":"code","source":"import scipy.stats as stats\n# T-test for clients who is less likely or more likely in relation to age if their mean values are the same\nno = cl[cl['output'] == 0]['age']\nyes = cl[cl['output'] == 1]['age']\n\nstats.ttest_ind(no, yes)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:06:39.647697Z","iopub.execute_input":"2021-05-31T04:06:39.64826Z","iopub.status.idle":"2021-05-31T04:06:39.665438Z","shell.execute_reply.started":"2021-05-31T04:06:39.648196Z","shell.execute_reply":"2021-05-31T04:06:39.663848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Null hypothesis says two means are almost same.\n- p-value is a probability if the null hypothesis is true. A high p-value (> 0.05) means we can't reject the null hypothesis\n- Since we have a low p-value, we reject the null hypothesis that output and age are the same in terms of painthreshold (No difference)","metadata":{}},{"cell_type":"code","source":"# T-test for clients who is less likely or more likely in relation to cp if their mean values are the same\nno = cl[cl['output'] == 0]['cp']\nyes = cl[cl['output'] == 1]['cp']\n\nstats.ttest_ind(no, yes)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:06:39.667423Z","iopub.execute_input":"2021-05-31T04:06:39.667932Z","iopub.status.idle":"2021-05-31T04:06:39.682911Z","shell.execute_reply.started":"2021-05-31T04:06:39.667859Z","shell.execute_reply":"2021-05-31T04:06:39.681682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Null hypothesis says two means are almost same.\n- p-value is a probability if the null hypothesis is true. A high p-value (> 0.05) means we can't reject the null hypothesis\n- Since we have a low p-value, we reject the null hypothesis that output and cp are the same in terms of painthreshold (No difference)","metadata":{}},{"cell_type":"code","source":"# T-test for clients who is less likely or more likely in relation to thalachh if their mean values are the same\nno = cl[cl['output'] == 0]['thalachh']\nyes = cl[cl['output'] == 1]['thalachh']\n\nstats.ttest_ind(no, yes)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:06:39.684812Z","iopub.execute_input":"2021-05-31T04:06:39.685438Z","iopub.status.idle":"2021-05-31T04:06:39.702625Z","shell.execute_reply.started":"2021-05-31T04:06:39.685386Z","shell.execute_reply":"2021-05-31T04:06:39.701802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Null hypothesis says two means are almost same.\n- p-value is a probability if the null hypothesis is true. A high p-value (> 0.05) means we can't reject the null hypothesis\n- Since we have a low p-value, we reject the null hypothesis that output and thalachh are the same in terms of painthreshold (No difference)","metadata":{}},{"cell_type":"code","source":"# T-test for clients who is less likely or more likely in relation to exng if their mean values are the same\nno = cl[cl['output'] == 0]['exng']\nyes = cl[cl['output'] == 1]['exng']\n\nstats.ttest_ind(no, yes)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:06:39.703847Z","iopub.execute_input":"2021-05-31T04:06:39.704279Z","iopub.status.idle":"2021-05-31T04:06:39.719142Z","shell.execute_reply.started":"2021-05-31T04:06:39.704247Z","shell.execute_reply":"2021-05-31T04:06:39.718313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Null hypothesis says two means are almost same.\n- p-value is a probability if the null hypothesis is true. A high p-value (> 0.05) means we can't reject the null hypothesis\n- Since we have a low p-value, we reject the null hypothesis that output and exng are the same in terms of painthreshold (No difference)","metadata":{}},{"cell_type":"markdown","source":"# Model Building","metadata":{}},{"cell_type":"code","source":"# looking for unique variables\ncl.nunique()","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:06:39.723479Z","iopub.execute_input":"2021-05-31T04:06:39.72398Z","iopub.status.idle":"2021-05-31T04:06:39.741845Z","shell.execute_reply.started":"2021-05-31T04:06:39.723935Z","shell.execute_reply":"2021-05-31T04:06:39.741006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Categorical to Dummy Variables\ncl =  pd.get_dummies(cl, columns=[\"sex\", \"cp\", \"fbs\", \"restecg\", \"exng\", \"slp\", \"caa\", \"thall\"],\n                         prefix=[\"sex\", \"cp\", \"fbs\", \"restecg\", \"exng\", \"slp\", \"caa\", \"thall\"],\n                         drop_first=True)\ncl.head(2)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:06:39.74397Z","iopub.execute_input":"2021-05-31T04:06:39.744465Z","iopub.status.idle":"2021-05-31T04:06:39.785306Z","shell.execute_reply.started":"2021-05-31T04:06:39.744432Z","shell.execute_reply":"2021-05-31T04:06:39.783981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### c. checking for p-value (TESTING FOR STATISTICAL SIGNIFICANCE OF INDEPENDENT VARIABLES)\nimport scipy.stats as stats\ncl_corr = pd.DataFrame() # Correlation matrix\ncl_p = pd.DataFrame() # Matrix of p-values\nfor x in cl.columns:   # assuming cl as your dataframe name\n   for y in cl.columns:\n      corr = stats.pearsonr(cl[x], cl[y])\n      cl_corr.loc[x,y] = corr[0]\n      cl_p.loc[x,y] = corr[1]\n\ncl_p['output']","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:06:39.786705Z","iopub.execute_input":"2021-05-31T04:06:39.787158Z","iopub.status.idle":"2021-05-31T04:06:40.090583Z","shell.execute_reply.started":"2021-05-31T04:06:39.787113Z","shell.execute_reply":"2021-05-31T04:06:40.08915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### At 0.05 level of significance to test the statistical significance of the X variables, chol, caa_4, thall_1, cp_3 and others are not statistically significant whiles the rest of X variables are statistically significant using the p-value. This is to test our three hypothesis.\n### Our null hypthesis is X variables (independent) are not statistically significant in predicting output (dependent variable). We will fail to reject the null hypothesis if the p-value for our x variables are greater than significant level 0.05.\n### The p-values of some X variables such as age, thalachh, thall_3 and others are all less than the 0.05 significant level therefore we reject the null hypothesis and that they are all statistically significant in predicting the dependent variable output.","metadata":{}},{"cell_type":"markdown","source":"# Using variables that are statistically significant for model selection","metadata":{}},{"cell_type":"code","source":"# Assigning dataset into dependent (y_1) and independent (X_1)\ny_1 = cl['output']\nX_1 = cl.drop(['output', 'chol', 'cp_3', 'fbs_1', 'restecg_2', 'caa_4', 'thall_1'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:06:40.093941Z","iopub.execute_input":"2021-05-31T04:06:40.094256Z","iopub.status.idle":"2021-05-31T04:06:40.101465Z","shell.execute_reply.started":"2021-05-31T04:06:40.094227Z","shell.execute_reply":"2021-05-31T04:06:40.100143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Normalizing all features\nfrom sklearn import preprocessing\nX_1 = preprocessing.StandardScaler().fit(X_1).transform(X_1)\nX_1[0:5]","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:06:40.10284Z","iopub.execute_input":"2021-05-31T04:06:40.103153Z","iopub.status.idle":"2021-05-31T04:06:40.136478Z","shell.execute_reply.started":"2021-05-31T04:06:40.103125Z","shell.execute_reply":"2021-05-31T04:06:40.135422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Splitting data into 70/30. 70% trained dataset and 30% test dataset\nX_1_train, X_1_test, y_1_train, y_1_test = train_test_split(X_1, y_1, train_size = 0.7, random_state =100)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:06:40.137766Z","iopub.execute_input":"2021-05-31T04:06:40.138096Z","iopub.status.idle":"2021-05-31T04:06:40.148967Z","shell.execute_reply.started":"2021-05-31T04:06:40.138065Z","shell.execute_reply":"2021-05-31T04:06:40.147916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Best model selection\nplt.figure()\n\n# Add the models to the list that you want to view on the ROC plot\nmodels = [\n{\n    'label': 'Decision Tree',\n    'model': DecisionTreeClassifier(),\n},\n{\n    'label': 'K-nearest neighbors',\n    'model': KNeighborsClassifier(),\n},\n{\n    'label': 'Logistic Regression',\n    'model': LogisticRegression(solver='lbfgs', max_iter=20000),\n},\n{\n    'label': 'Random Forest',\n    'model': RandomForestClassifier(n_estimators=100),\n}\n]\n\n# Below for loop iterates through your models list\nfor m in models:\n    model = m['model'] # select the model\n    model.fit(X_1_train, y_1_train) # train the model\n    #y_pred=model.predict(X_1_test) # predict the test data\n    \n    # Compute False postive rate, and True positive rate\n    fpr, tpr, thresholds = metrics.roc_curve(y_1_test, model.predict_proba(X_1_test)[:,1])\n\n    # Calculate Area under the curve to display on the plot\n    auc = metrics.roc_auc_score(y_1_test,model.predict(X_1_test))\n\n    # Now, plot the computed values\n    plt.plot(fpr, tpr, label='%s ROC (area = %0.2f)' % (m['label'], auc))\n\n# Custom settings for the plot \nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('1-Specificity(False Positive Rate)')\nplt.ylabel('Sensitivity(True Positive Rate)')\nplt.title('Receiver Operating Characteristic')\nplt.legend(loc=\"lower right\")\nplt.show()   # Display","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:06:40.150036Z","iopub.execute_input":"2021-05-31T04:06:40.150379Z","iopub.status.idle":"2021-05-31T04:06:40.640993Z","shell.execute_reply.started":"2021-05-31T04:06:40.150292Z","shell.execute_reply":"2021-05-31T04:06:40.640195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# From our analysis, logistic regression came out on top with 86% using ROC.","metadata":{}},{"cell_type":"code","source":"# Assigning dataset into dependent (y) and independent (x)\ny = cl['output']\nX = cl.drop(['output'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:06:40.642569Z","iopub.execute_input":"2021-05-31T04:06:40.643338Z","iopub.status.idle":"2021-05-31T04:06:40.650159Z","shell.execute_reply.started":"2021-05-31T04:06:40.643295Z","shell.execute_reply":"2021-05-31T04:06:40.649055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Normalizing all features\nfrom sklearn import preprocessing\nX_2 = preprocessing.StandardScaler().fit(X).transform(X)\nX_2[0:5]","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:06:40.651797Z","iopub.execute_input":"2021-05-31T04:06:40.652508Z","iopub.status.idle":"2021-05-31T04:06:40.675204Z","shell.execute_reply.started":"2021-05-31T04:06:40.652463Z","shell.execute_reply":"2021-05-31T04:06:40.674172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Splitting data into 70/30. 70% trained dataset and 30% test dataset\nX_train, X_test, y_train, y_test = train_test_split(X_2, y, train_size = 0.7, random_state =100)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:06:40.676768Z","iopub.execute_input":"2021-05-31T04:06:40.677187Z","iopub.status.idle":"2021-05-31T04:06:40.692756Z","shell.execute_reply.started":"2021-05-31T04:06:40.677147Z","shell.execute_reply":"2021-05-31T04:06:40.691333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model Selection\nplt.figure()\n\n# Add the models to the list that you want to view on the ROC plot\nmodels = [\n{\n    'label': 'Decision Tree',\n    'model': DecisionTreeClassifier(),\n},\n{\n    'label': 'K-nearest neighbors',\n    'model': KNeighborsClassifier(),\n},\n{\n    'label': 'Logistic Regression',\n    'model': LogisticRegression(solver='lbfgs', max_iter=20000),\n},\n{\n    'label': 'Random Forest',\n    'model': RandomForestClassifier(n_estimators=100),\n}\n]\n\n# Below for loop iterates through your models list\nfor m in models:\n    model = m['model'] # select the model\n    model.fit(X_train, y_train) # train the model\n    #y_pred=model.predict(X_test) # predict the test data\n    \n    # Compute False postive rate, and True positive rate\n    fpr, tpr, thresholds = metrics.roc_curve(y_test, model.predict_proba(X_test)[:,1])\n\n    # Calculate Area under the curve to display on the plot\n    auc = metrics.roc_auc_score(y_test,model.predict(X_test))\n\n    # Now, plot the computed values\n    plt.plot(fpr, tpr, label='%s ROC (area = %0.2f)' % (m['label'], auc))\n\n# Custom settings for the plot \nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('1-Specificity(False Positive Rate)')\nplt.ylabel('Sensitivity(True Positive Rate)')\nplt.title('Receiver Operating Characteristic')\nplt.legend(loc=\"lower right\")\nplt.show()   # Display","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:06:40.694655Z","iopub.execute_input":"2021-05-31T04:06:40.695059Z","iopub.status.idle":"2021-05-31T04:06:41.208931Z","shell.execute_reply.started":"2021-05-31T04:06:40.695019Z","shell.execute_reply":"2021-05-31T04:06:41.207699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# From our analysis, logistic regression came out on top with 87% using ROC.","metadata":{}},{"cell_type":"code","source":"# Model Selection for advance classification algorithms\nplt.figure()\n\n# Add the models to the list that you want to view on the ROC plot\nmodels = [\n{\n    'label': 'Support Vector Machine',\n    'model': SVC(gamma='auto', probability=True),\n},\n{\n    'label': 'Gradient Boosting',\n    'model': GradientBoostingClassifier(),\n},\n{\n    'label': 'Neural Network',\n    'model': MLPClassifier(solver='lbfgs', max_iter=15000),\n}\n]\n\n# Below for loop iterates through your models list\nfor m in models:\n    model = m['model'] # select the model\n    model.fit(X_train, y_train) # train the model\n    #y_pred=model.predict(X_test) # predict the test data\n    \n    # Compute False postive rate, and True positive rate\n    fpr, tpr, thresholds = metrics.roc_curve(y_test, model.predict_proba(X_test)[:,1])\n\n    # Calculate Area under the curve to display on the plot\n    auc = metrics.roc_auc_score(y_test,model.predict(X_test))\n\n    # Now, plot the computed values\n    plt.plot(fpr, tpr, label='%s ROC (area = %0.2f)' % (m['label'], auc))\n\n# Custom settings for the plot \nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('1-Specificity(False Positive Rate)')\nplt.ylabel('Sensitivity(True Positive Rate)')\nplt.title('Receiver Operating Characteristic')\nplt.legend(loc=\"lower right\")\nplt.show()   # Display","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:06:41.21043Z","iopub.execute_input":"2021-05-31T04:06:41.210773Z","iopub.status.idle":"2021-05-31T04:06:41.605788Z","shell.execute_reply.started":"2021-05-31T04:06:41.210738Z","shell.execute_reply":"2021-05-31T04:06:41.604429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# From our analysis, Support Vector Machine came out on top with 85% using ROC.","metadata":{}},{"cell_type":"code","source":"# using Logistic Regression\nlr = LogisticRegression(solver='lbfgs', max_iter=20000)\nlr.fit(X_train, y_train)\ny_pred = lr.predict(X_test)\n# print coefficients\ncoef = pd.DataFrame(list(zip(X.columns, np.transpose(lr.coef_))), \n             columns=['X variables', 'coef']).sort_values('coef', ascending=False)\n\ncoef['coef'] = coef['coef'].str[0]\ncoef","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:06:41.607198Z","iopub.execute_input":"2021-05-31T04:06:41.607532Z","iopub.status.idle":"2021-05-31T04:06:41.636965Z","shell.execute_reply.started":"2021-05-31T04:06:41.607503Z","shell.execute_reply":"2021-05-31T04:06:41.635858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### As we can see, the highest positive coefficient or weight is cp_2 and the highest negative coefficient is caa_1.","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:06:41.6406Z","iopub.execute_input":"2021-05-31T04:06:41.640917Z","iopub.status.idle":"2021-05-31T04:06:41.645998Z","shell.execute_reply.started":"2021-05-31T04:06:41.640871Z","shell.execute_reply":"2021-05-31T04:06:41.644694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(metrics.accuracy_score(y_test, lr.predict(X_test)))\nprint(metrics.confusion_matrix(y_test, lr.predict(X_test)))\nprint(metrics.classification_report(y_test, lr.predict(X_test)))\nprint(metrics.roc_auc_score(y_test, lr.predict(X_test)))","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:06:41.647229Z","iopub.execute_input":"2021-05-31T04:06:41.647504Z","iopub.status.idle":"2021-05-31T04:06:41.677732Z","shell.execute_reply.started":"2021-05-31T04:06:41.647478Z","shell.execute_reply":"2021-05-31T04:06:41.676725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 10 fold cross validation evaluation\nscores = cross_val_score(LogisticRegression(solver='lbfgs', max_iter=20000), X_test, y_test, scoring='accuracy', cv=10)\nprint(scores)\nprint(scores.mean())","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:06:41.679016Z","iopub.execute_input":"2021-05-31T04:06:41.679314Z","iopub.status.idle":"2021-05-31T04:06:41.769378Z","shell.execute_reply.started":"2021-05-31T04:06:41.679284Z","shell.execute_reply":"2021-05-31T04:06:41.768318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# probability of heart attack\nprobs = lr.predict_proba(X_test)\nprobs[0:20]\n#1st column: probability of less chance of heart attack\n#2nd column: probabiility of more chance of heart attack","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:06:41.770818Z","iopub.execute_input":"2021-05-31T04:06:41.771223Z","iopub.status.idle":"2021-05-31T04:06:41.780078Z","shell.execute_reply.started":"2021-05-31T04:06:41.771183Z","shell.execute_reply":"2021-05-31T04:06:41.778627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# RandomForestClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\nclf = RandomForestClassifier(n_estimators=100)    #building 100 decision trees\nclf=clf.fit(X_train, y_train)\nclf.score(X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:06:41.781716Z","iopub.execute_input":"2021-05-31T04:06:41.782149Z","iopub.status.idle":"2021-05-31T04:06:42.007864Z","shell.execute_reply.started":"2021-05-31T04:06:41.782109Z","shell.execute_reply":"2021-05-31T04:06:42.006585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluation metrics\nprint(metrics.accuracy_score(y_test, clf.predict(X_test))) #overall accuracy\nprint(metrics.confusion_matrix(y_test, clf.predict(X_test)))\nprint(metrics.classification_report(y_test, clf.predict(X_test)))","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:06:42.009431Z","iopub.execute_input":"2021-05-31T04:06:42.009775Z","iopub.status.idle":"2021-05-31T04:06:42.06239Z","shell.execute_reply.started":"2021-05-31T04:06:42.009742Z","shell.execute_reply":"2021-05-31T04:06:42.061189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 10 fold cross validation evaluation\nscores = cross_val_score(RandomForestClassifier(), X_test, y_test, scoring='accuracy', cv=10)\nprint(scores)\nprint(scores.mean())","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:06:42.064854Z","iopub.execute_input":"2021-05-31T04:06:42.065256Z","iopub.status.idle":"2021-05-31T04:06:43.953495Z","shell.execute_reply.started":"2021-05-31T04:06:42.065222Z","shell.execute_reply":"2021-05-31T04:06:43.952217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# another method\npd.DataFrame(clf.feature_importances_, index = X.columns,\n                                    columns=['importance']).sort_values('importance', ascending=False)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:06:43.955023Z","iopub.execute_input":"2021-05-31T04:06:43.955358Z","iopub.status.idle":"2021-05-31T04:06:43.985344Z","shell.execute_reply.started":"2021-05-31T04:06:43.955324Z","shell.execute_reply":"2021-05-31T04:06:43.983762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- The 5 most important features are oldpeak, thalachh, thall_3, chol and trtbps.","metadata":{}},{"cell_type":"code","source":"# Visualization for the most important features.\npd.DataFrame(clf.feature_importances_, index = X.columns,\n                                    columns=['importance']).sort_values('importance', ascending=True).plot(kind='barh', \n                                                                                                            legend=None);","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:06:43.98709Z","iopub.execute_input":"2021-05-31T04:06:43.987465Z","iopub.status.idle":"2021-05-31T04:06:44.284551Z","shell.execute_reply.started":"2021-05-31T04:06:43.987431Z","shell.execute_reply":"2021-05-31T04:06:44.283369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Support Vector Machine (SVM)\nsvm = SVC(gamma='auto', probability=True)\nsvm.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:06:44.286123Z","iopub.execute_input":"2021-05-31T04:06:44.286472Z","iopub.status.idle":"2021-05-31T04:06:44.312051Z","shell.execute_reply.started":"2021-05-31T04:06:44.286431Z","shell.execute_reply":"2021-05-31T04:06:44.31072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Model evaluation\n# http://scikit-learn.org/stable/modules/model_evaluation.html\nprint(metrics.accuracy_score(y_test, svm.predict(X_test)))\nprint(\"--------------------------------------------------------\")\nprint(metrics.confusion_matrix(y_test, svm.predict(X_test))) \nprint(\"--------------------------------------------------------\")\nprint(metrics.classification_report(y_test, svm.predict(X_test)))\nprint(\"--------------------------------------------------------\")\nprint(metrics.roc_auc_score(y_test, svm.predict(X_test)))","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:06:44.313319Z","iopub.execute_input":"2021-05-31T04:06:44.313643Z","iopub.status.idle":"2021-05-31T04:06:44.338445Z","shell.execute_reply.started":"2021-05-31T04:06:44.313609Z","shell.execute_reply":"2021-05-31T04:06:44.337183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 10-fold cross-validation\nsvm = SVC(gamma='auto')\n\nscores = cross_val_score(svm, X_test, y_test, scoring='accuracy', cv=10)\nprint(scores)\nprint(scores.mean())","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:06:44.340044Z","iopub.execute_input":"2021-05-31T04:06:44.340374Z","iopub.status.idle":"2021-05-31T04:06:44.375658Z","shell.execute_reply.started":"2021-05-31T04:06:44.340341Z","shell.execute_reply":"2021-05-31T04:06:44.374252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Deployment\n- We going to employ the logistic regression model since it gave as the highest prediction.\n- Also, the whole dataset is going to used for out model deployment.","metadata":{"execution":{"iopub.status.busy":"2021-05-31T03:24:39.021456Z","iopub.execute_input":"2021-05-31T03:24:39.021788Z","iopub.status.idle":"2021-05-31T03:24:39.02924Z","shell.execute_reply.started":"2021-05-31T03:24:39.021759Z","shell.execute_reply":"2021-05-31T03:24:39.027413Z"}}},{"cell_type":"code","source":"# Logistic Regression\ny_predict = lr.predict(X_2)\ny_predict[0:20]","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:06:44.377156Z","iopub.execute_input":"2021-05-31T04:06:44.377455Z","iopub.status.idle":"2021-05-31T04:06:44.387348Z","shell.execute_reply.started":"2021-05-31T04:06:44.377425Z","shell.execute_reply":"2021-05-31T04:06:44.385529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# probability of heart attack\nprobs_new = lr.predict_proba(X_2)\nprobs_new[0:20]\n#1st column: probability of less chance of heart attack\n#2nd column: probabiility of more chance of heart attack","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:06:44.388491Z","iopub.execute_input":"2021-05-31T04:06:44.389183Z","iopub.status.idle":"2021-05-31T04:06:44.398728Z","shell.execute_reply.started":"2021-05-31T04:06:44.389151Z","shell.execute_reply":"2021-05-31T04:06:44.39801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluation Metrics\nprint(metrics.accuracy_score(y, lr.predict(X_2)))\nprint(metrics.confusion_matrix(y, lr.predict(X_2)))\nprint(metrics.classification_report(y, lr.predict(X_2)))\nprint(metrics.roc_auc_score(y, lr.predict(X_2)))","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:06:44.399962Z","iopub.execute_input":"2021-05-31T04:06:44.400238Z","iopub.status.idle":"2021-05-31T04:06:44.426548Z","shell.execute_reply.started":"2021-05-31T04:06:44.400203Z","shell.execute_reply":"2021-05-31T04:06:44.425043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 10 fold cross validation evaluation\nscores = cross_val_score(LogisticRegression(solver='lbfgs', max_iter=20000), X_2, y, scoring='accuracy', cv=10)\nprint(scores)\nprint(scores.mean())","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:06:44.428635Z","iopub.execute_input":"2021-05-31T04:06:44.429152Z","iopub.status.idle":"2021-05-31T04:06:44.526162Z","shell.execute_reply.started":"2021-05-31T04:06:44.429097Z","shell.execute_reply":"2021-05-31T04:06:44.524657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation of prediction to original output","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import f1_score\nf1_score(y, y_predict, average='weighted') \n\n# The F1 score is the harmonic average of the precision and recall, where an F1 score reaches its best value at 1 (perfect precision and recall) and worst at 0. \n# It is a good way to show that a classifer has a good value for both recall and precision.\n# And finally, we can tell the average accuracy for this classifier is the average of the F1-score for both labels, which is 0.89 in our case.","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:06:44.527536Z","iopub.execute_input":"2021-05-31T04:06:44.527841Z","iopub.status.idle":"2021-05-31T04:06:44.538214Z","shell.execute_reply.started":"2021-05-31T04:06:44.527811Z","shell.execute_reply":"2021-05-31T04:06:44.537024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import jaccard_score\njaccard_score(y, y_predict,pos_label=1) \n# Lets try jaccard index for accuracy evaluation. \n# we can define jaccard as the size of the intersection divided by the size of the union of two label sets. \n# If the entire set of predicted labels for a sample strictly match with the true set of labels, then the subset accuracy is 1.0; otherwise it is 0.0.","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:06:44.539743Z","iopub.execute_input":"2021-05-31T04:06:44.540193Z","iopub.status.idle":"2021-05-31T04:06:44.551755Z","shell.execute_reply.started":"2021-05-31T04:06:44.54016Z","shell.execute_reply":"2021-05-31T04:06:44.551015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import log_loss\nlog_loss(y, probs_new) # This probability is a value between 0 and 1. \n                      # Log loss( Logarithmic loss) measures the performance of a classifier where the predicted output is a probability value between 0 and 1.","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:06:44.552711Z","iopub.execute_input":"2021-05-31T04:06:44.553025Z","iopub.status.idle":"2021-05-31T04:06:44.572458Z","shell.execute_reply.started":"2021-05-31T04:06:44.552995Z","shell.execute_reply":"2021-05-31T04:06:44.571656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ROC\npreds = lr.predict_proba(X_2)[:,1]\nfpr, tpr, threshold = metrics.roc_curve(y, y_predict)\nroc_auc = metrics.auc(fpr, tpr)\n\n# method I: plt\nimport matplotlib.pyplot as plt\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1.05])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:06:44.573417Z","iopub.execute_input":"2021-05-31T04:06:44.573678Z","iopub.status.idle":"2021-05-31T04:06:44.74523Z","shell.execute_reply.started":"2021-05-31T04:06:44.573641Z","shell.execute_reply":"2021-05-31T04:06:44.743995Z"},"trusted":true},"execution_count":null,"outputs":[]}]}