{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Multi-Class Image Classification using PyTorch for Beginners\n\nI have fine tuned pre-trained VGG16 model, you can create your own model or use any pre-built pytorch model. More details [here](https://pytorch.org/docs/stable/torchvision/models.html).","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nimport cv2\nimport time\nimport numpy as np\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.utils.data import RandomSampler\n\nimport torchvision.transforms as T\nimport torchvision.models as models\nfrom torchvision.utils import make_grid\nfrom torchvision.datasets import ImageFolder\n\nfrom matplotlib import pyplot as plt\n\nDIR_TRAIN = \"../input/100-bird-species/train/\"\nDIR_VALID = \"../input/100-bird-species/valid/\"\nDIR_TEST = \"../input/100-bird-species/test/\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Exploring Dataset\n\nclasses = os.listdir(DIR_TRAIN)\nprint(\"Total Classes: \",len(classes))\n\n#Counting total train, valid & test images\n\ntrain_count = 0\nvalid_count = 0\ntest_count = 0\nfor _class in classes:\n    train_count += len(os.listdir(DIR_TRAIN + _class))\n    valid_count += len(os.listdir(DIR_VALID + _class))\n    test_count += len(os.listdir(DIR_TEST + _class))\n\nprint(\"Total train images: \",train_count)\nprint(\"Total valid images: \",valid_count)\nprint(\"Total test images: \",test_count)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Creating a list of all images : DIR_TRAIN/class_folder/img.jpg - FOR METHOD 2 of data loading\n#   A dict for mapping class labels to index\n\ntrain_imgs = []\nvalid_imgs = []\ntest_imgs = []\n\nfor _class in classes:\n    \n    for img in os.listdir(DIR_TRAIN + _class):\n        train_imgs.append(DIR_TRAIN + _class + \"/\" + img)\n    \n    for img in os.listdir(DIR_VALID + _class):\n        valid_imgs.append(DIR_VALID + _class + \"/\" + img)\n        \n    for img in os.listdir(DIR_TEST + _class):\n        test_imgs.append(DIR_TEST + _class + \"/\" + img)\n\nclass_to_int = {classes[i] : i for i in range(len(classes))}\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are multiple ways to load images from the dataset, I have used 2 such methods:\n1. Using ImageFolder Class\n2. Using Dataset Class","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"### Loading Classification Dataset - FOR METHOD 2: For multi-class data, by inheriting Dataset class\n\ndef get_transform():\n    return T.Compose([T.ToTensor()])\n\nclass BirdDataset(Dataset):\n    \n    def __init__(self, imgs_list, class_to_int, transforms = None):\n        \n        super().__init__()\n        self.imgs_list = imgs_list\n        self.class_to_int = class_to_int\n        self.transforms = transforms\n        \n        \n    def __getitem__(self, index):\n    \n        image_path = self.imgs_list[index]\n        \n        #Reading image\n        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n        image /= 255.0\n        \n        #Retriving class label\n        label = image_path.split(\"/\")[-2]\n        label = self.class_to_int[label]\n        \n        #Applying transforms on image\n        if self.transforms:\n            image = self.transforms(image)\n        \n        return image, label\n        \n        \n        \n    def __len__(self):\n        return len(self.imgs_list)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Loading Classification Dataset\n\n\"\"\"\n# Method 1: For multi-class data directly from folders using ImageFolder\ntrain_dataset = ImageFolder(root = DIR_TRAIN, transform = T.ToTensor())\nvalid_dataset = ImageFolder(root = DIR_VALID, transform = T.ToTensor())\ntest_dataset = ImageFolder(root = DIR_TEST, transform = T.ToTensor())\n\"\"\"\n\n# Method 2: Using Dataset Class\ntrain_dataset = BirdDataset(train_imgs, class_to_int, get_transform())\nvalid_dataset = BirdDataset(valid_imgs, class_to_int, get_transform())\ntest_dataset = BirdDataset(test_imgs, class_to_int, get_transform())\n\n#Data Loader  -  using Sampler (YT Video)\ntrain_random_sampler = RandomSampler(train_dataset)\nvalid_random_sampler = RandomSampler(valid_dataset)\ntest_random_sampler = RandomSampler(test_dataset)\n\n#Shuffle Argument is mutually exclusive with Sampler!\ntrain_data_loader = DataLoader(\n    dataset = train_dataset,\n    batch_size = 16,\n    sampler = train_random_sampler,\n    num_workers = 4,\n)\n\nvalid_data_loader = DataLoader(\n    dataset = valid_dataset,\n    batch_size = 16,\n    sampler = valid_random_sampler,\n    num_workers = 4,\n)\n\ntest_data_loader = DataLoader(\n    dataset = test_dataset,\n    batch_size = 16,\n    sampler = test_random_sampler,\n    num_workers = 4,\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualize one training batch\nfor images, labels in train_data_loader:\n    fig, ax = plt.subplots(figsize = (10, 10))\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.imshow(make_grid(images, 4).permute(1,2,0))\n    break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Define model\nmodel = models.vgg16(pretrained = True)\n\n### Modifying last few layers and no of classes\n# NOTE: cross_entropy loss takes unnormalized op (logits), then function itself applies softmax and calculates loss, so no need to include softmax here\nmodel.classifier = nn.Sequential(\n    nn.Linear(25088, 4096, bias = True),\n    nn.ReLU(inplace = True),\n    nn.Dropout(0.4),\n    nn.Linear(4096, 2048, bias = True),\n    nn.ReLU(inplace = True),\n    nn.Dropout(0.4),\n    nn.Linear(2048, 200)\n)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Get device\n\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\ntorch.cuda.empty_cache()\n\nmodel.to(device)\n\n### Training Details\n\noptimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\nlr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 5, gamma = 0.75)\ncriterion = nn.CrossEntropyLoss()\n\ntrain_loss = []\ntrain_accuracy = []\n\nval_loss = []\nval_accuracy = []\n\nepochs = 20\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def calc_accuracy(true,pred):\n    pred = F.softmax(pred, dim = 1)\n    true = torch.zeros(pred.shape[0], pred.shape[1]).scatter_(1, true.unsqueeze(1), 1.)\n    acc = (true.argmax(-1) == pred.argmax(-1)).float().detach().numpy()\n    acc = float((100 * acc.sum()) / len(acc))\n    return round(acc, 4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I did not execute training code given below as it takes time, you can fork this notebook and try yourself.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"### Training Code\n\nfor epoch in range(epochs):\n    \n    start = time.time()\n    \n    #Epoch Loss & Accuracy\n    train_epoch_loss = []\n    train_epoch_accuracy = []\n    _iter = 1\n    \n    #Val Loss & Accuracy\n    val_epoch_loss = []\n    val_epoch_accuracy = []\n    \n    # Training\n    for images, labels in train_data_loader:\n        \n        images = images.to(device)\n        labels = labels.to(device)\n        \n        #Reset Grads\n        optimizer.zero_grad()\n        \n        #Forward ->\n        preds = model(images)\n        \n        #Calculate Accuracy\n        acc = calc_accuracy(labels.cpu(), preds.cpu())\n        \n        #Calculate Loss & Backward, Update Weights (Step)\n        loss = criterion(preds, labels)\n        loss.backward()\n        optimizer.step()\n        \n        #Append loss & acc\n        loss_value = loss.item()\n        train_epoch_loss.append(loss_value)\n        train_epoch_accuracy.append(acc)\n        \n        if _iter % 500 == 0:\n            print(\"> Iteration {} < \".format(_iter))\n            print(\"Iter Loss = {}\".format(round(loss_value, 4)))\n            print(\"Iter Accuracy = {} % \\n\".format(acc))\n        \n        _iter += 1\n    \n    #Validation\n    for images, labels in valid_data_loader:\n        \n        images = images.to(device)\n        labels = labels.to(device)\n        \n        #Forward ->\n        preds = model(images)\n        \n        #Calculate Accuracy\n        acc = calc_accuracy(labels.cpu(), preds.cpu())\n        \n        #Calculate Loss\n        loss = criterion(preds, labels)\n        \n        #Append loss & acc\n        loss_value = loss.item()\n        val_epoch_loss.append(loss_value)\n        val_epoch_accuracy.append(acc)\n    \n    \n    train_epoch_loss = np.mean(train_epoch_loss)\n    train_epoch_accuracy = np.mean(train_epoch_accuracy)\n    \n    val_epoch_loss = np.mean(val_epoch_loss)\n    val_epoch_accuracy = np.mean(val_epoch_accuracy)\n    \n    end = time.time()\n    \n    train_loss.append(train_epoch_loss)\n    train_accuracy.append(train_epoch_accuracy)\n    \n    val_loss.append(val_epoch_loss)\n    val_accuracy.append(val_epoch_accuracy)\n    \n    #Print Epoch Statistics\n    print(\"** Epoch {} ** - Epoch Time {}\".format(epoch, int(end-start)))\n    print(\"Train Loss = {}\".format(round(train_epoch_loss, 4)))\n    print(\"Train Accuracy = {} % \\n\".format(train_epoch_accuracy))\n    print(\"Val Loss = {}\".format(round(val_epoch_loss, 4)))\n    print(\"Val Accuracy = {} % \\n\".format(val_epoch_accuracy))\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}