{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"# Funding of Indian Startups in depth analysis\n## *Inspiration*\n-  How does the funding ecosystem change with time?\n-  Do cities play a major role in funding?\n-  Which industries are favored by investors for funding?\n-  Who are the important investors in the Indian Ecosystem?\n-  How much funds does startups generally get in India?\n\n## Objectives\n1. Clean the data\n2. Time-Wise Analysis:\n -  *Show the year wise funding of startups.*\n -  *Show the monthly funding of startups for various years.*\n3. Find the startups which recieved the largest funding.\n4. Find the startups with maximum investors.\n5. Find the investors who invested the maximum number of times.\n6. Find the type of funding startups recieved."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Import the libraries\n\n#1: Pandas will be used for data maniplation of csv file.\nimport pandas as pd\n#2: Numpy adds support for matrix calculation.\nimport numpy as np\n#3: Matplotlib used for creating plots.\nimport matplotlib.pyplot as plt\n#4: Seaborn is used for data visualization. \nimport seaborn as sns\n#5: Squarify is used to create square plots.\nimport squarify\n#6: RE is used for regular expressions.\nimport re \n#Read the data\ndf = pd.read_csv('/kaggle/input/indian-startup-funding/startup_funding.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Sample the data and find information about the data. "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Find the type of data in various columns.\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Change the investment type into categorical data\ndf['InvestmentnType'] = df['InvestmentnType'].astype('category')\n#Now display the sample of the data.\ndf.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking if null values are present in data\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Cleaning the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Remarks is an unnecessary column. So, we remove it.\ndf = df.drop(columns = 'Remarks')\n\n#Similarly we do away with Sr No.\ndf = df.drop(columns = 'Sr No')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Cleaning the Amounts in USD by removing Null Values, and non-numeric values."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Save a copy of original dataframe.\ndata = df.copy()\n\n#Rename the column for convenieance.\ndata.columns = ['Date', 'Startup Name', 'Industry Vertical', 'SubVertical',\n       'City  Location', 'Investors Name', 'Investment Type',\n       'Amount in USD']\n\n#Drop the rows where amount is zero.\ndata = data.drop(data[data['Amount in USD'].isnull()].index )\n\n#Drop the rows where amount is Undisclosed\ndata = data.drop(data[(data['Amount in USD'] == 'Undisclosed') | (data['Amount in USD'] == 'undisclosed')].index )\n\n#Data in amount is using delimiter ',' so we need to remove it and convert the data into float. \ndata['Amount in USD'] = data['Amount in USD'].apply(lambda x: x.replace(',',''))\n\n#Some data has amount like 25000+ replace the plus to obtain clean data.\ndata['Amount in USD'] = data['Amount in USD'].apply(lambda x: x.replace('+',''))\n\n#Drop the rows where amount is not a valid float number.\ndata = data[data['Amount in USD'].str.replace('.','',1).str.isdigit()]\n\n#Convert the data into float\ndata['Amount in USD'] = data['Amount in USD'].astype('float')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Cleaning the columns industry vertical and sub vertical."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fill the missing values with Others.\ndata['Industry Vertical'] = data['Industry Vertical'].fillna('Others')\ndata['SubVertical'] = data['SubVertical'].fillna('Others')\ndata['Industry Vertical'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### As you can see there are various duplicate entries like E-Commerce, ECommerce etc. \n#### We need to consolidate such Entries into single group."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Step 1\n\n# Convert all the values to upper case to avoid confusion\ndata['Industry Vertical'] = data['Industry Vertical'].apply(lambda x: x.upper())\n\n# Replace & with 'AND'\ndata['Industry Vertical'] = data['Industry Vertical'].apply(lambda x: x.replace('&','AND'))\n\n# A lot of values have \\\\XA2 replace them with ''\ndata['Industry Vertical'] = data['Industry Vertical'].apply(lambda x: re.sub('\\\\\\\\[A-Z][A-Z][0-9]','',x))\n\n# Now replace \\ with ''\ndata['Industry Vertical'] = data['Industry Vertical'].apply(lambda x: re.sub('\\\\\\\\',' ',x))\n\n# Remove any unnecessary spaces.\ndata['Industry Vertical'] = data['Industry Vertical'].apply(lambda x: x.replace('  ',''))\n\n# Remove - \ndata['Industry Vertical'] = data['Industry Vertical'].apply(lambda x: x.replace('-',''))\n\n# I will be using sets for this purpose. I create a set which avoids repeated values.\n\ndef create_unique_Set(series):\n    # We get all the values in series\n    t_List = series.value_counts().index\n    \n    # We create an empty set to store unique values.\n    t_Set = set()\n    \n    for i in t_List:\n        r = re.compile('^{exp}'.format(exp = i.strip()))\n        # We match the expression in i with values in temporary set to see if a similar value is already present.\n        temp = list(filter(r.match, t_Set))\n        if len(temp)>0:\n        #If set has similar values we simply replace it with the longest value.    \n            temp = [x for x in temp if len(x) == len(max(temp , key = len))]\n            if len(temp[0]) < len(i):\n                t_Set.remove(temp[0])\n                t_Set.add(i)\n        # If a match is not found we add the value in set.        \n        elif len(temp) == 0 :\n            t_Set.add(i)\n    return t_Set    \n\n        \n# I am using the longest match function to replace similar values.\n\ndef find_longest_match(value, set_values):\n    r = re.compile('^{val}'.format(val = value))\n    # I match the value with values in our unique list.\n    temp_list = list(filter(r.match , set_values))\n    # We replace the current value with the longest value.\n    temp = [x for x in temp_list if len(x) == len(max(temp_list, key = len))]\n    # We return the longest value.\n    if len(temp) > 0:\n        temp = temp[0]\n        return temp\n    else:\n        return value\n# Create the set of unique values for data['Industry Vertical'] and eliminate duplicate values. \nset_iv = create_unique_Set(data['Industry Vertical'])      \ndata['Industry Vertical'] = data['Industry Vertical'].apply(find_longest_match , set_values = set_iv)  \n\ndata['Industry Vertical'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### I do the same thing for column, sub vertical."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Step 1\n\n# Convert all the values to upper case to avoid confusion\ndata['SubVertical'] = data['SubVertical'].apply(lambda x: x.upper())\n\n# Replace & with 'AND'\ndata['SubVertical'] = data['SubVertical'].apply(lambda x: x.replace('&','AND'))\n\n# A lot of values have \\\\XA2 replace them with ''\ndata['SubVertical'] = data['SubVertical'].apply(lambda x: re.sub('\\\\\\\\[A-Z][A-Z][0-9]','',x))\n\n# Now replace \\ with ''\ndata['SubVertical'] = data['SubVertical'].apply(lambda x: re.sub('\\\\\\\\',' ',x))\n\n# Remove any unnecessary spaces.\ndata['SubVertical'] = data['SubVertical'].apply(lambda x: x.replace('  ',''))\n\n# Remove - \ndata['SubVertical'] = data['SubVertical'].apply(lambda x: x.replace('-',''))\n\n# Remove NLOANS COMPARISON PLATFORMNNNN (ADSBYGOOGLE = WINDOW.ADSBYGOOGLE || []).PUSH({});NN with NLOANS COMPARISON PLATFORM\ndata['SubVertical'] = data['SubVertical'].apply(lambda x: re.sub(r'\\([^()]*\\)','',x))\n\n# Create the set of unique values for data['Industry Vertical'] and eliminate duplicate values.\nset_sv = create_unique_Set(data['SubVertical'])\ndata['SubVertical'] = data['SubVertical'].apply(find_longest_match , set_values = set_sv)  \n\ndata['SubVertical'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Cleaning the column City Location."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check for null values\nprint(\"Null values are: \" , len(data[data['City  Location'].isnull()]))\n\n# Replace the Null values with others.\ndata['City  Location'] = data['City  Location'].fillna('OTHERS')\n\n# We convert all values to uppercase for convineance.\ndata['City  Location'] = data['City  Location'].apply(lambda x: x.upper())\n\n# The data has multiple cities seperated by /. So we remove the slash and pick one city. \ndata['City  Location'].value_counts()\n\n# We remove the slash and remove any excess space.\ndata['City  Location'] = data['City  Location'].apply(lambda x: x.split('/')[0].strip())\n\n# We have to clean the data to avoid duplicity. \ndata.loc[(data['City  Location'] == 'AHEMADABAD') | (data['City  Location'] == 'AHMEDABAD') , 'City  Location'] = 'AHMEDABAD'\ndata.loc[(data['City  Location'] == 'BANGALORE') | (data['City  Location'] == 'BENGALURU') , 'City  Location'] = 'BENGALURU'\ndata.loc[(data['City  Location'] == 'GURGAON') | (data['City  Location'] == 'GURUGRAM') , 'City  Location'] = 'GURUGRAM'\n\n# Display the cleaned data.\ndata['City  Location']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Clean the column investment type."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data['Investment Type'].value_counts(dropna = False))\n\n# Function to remove the slash\ndef remove_Slash(investment):\n    temp = investment\n    if re.search('/', investment):\n        temp = investment.split('/')[1].strip()        \n    return temp.upper().strip()    \n\n\n#Remove the null values with Private Equity as it is the most common values.\ndata['Investment Type'] = data['Investment Type'].fillna('Private Equity')\n\n# Remove the \\\\n.\ndata['Investment Type'] = data['Investment Type'].apply(lambda x: re.sub(r'\\\\\\\\n' , ' ' , x))\n\n# Convert all values to uppercase for convineance and remove the /.\ndata['Investment Type'] = data['Investment Type'].apply(remove_Slash)\n\n# Change the values of seed and seed round to seed funding to avoid duplication.. \ndata['Investment Type'][(data['Investment Type'] == 'SEED') | (data['Investment Type'] == 'SEED ROUND') | (data['Investment Type'] == 'SEED FUNDING ROUND')] = 'SEED FUNDING'\n\n# Change angel round, angel and angle funding to angel funding to avoid duplication.\ndata['Investment Type'][(data['Investment Type'] == 'ANGEL') | (data['Investment Type'] == 'ANGEL ROUND') | (data['Investment Type'] == 'ANGLE FUNDING')] = 'ANGEL FUNDING'\n\n# Change DEBT and DEBT-FUNDING to DEBT FUNDING to avoid duplication.\ndata['Investment Type'][(data['Investment Type'] == 'DEBT') | (data['Investment Type'] == 'DEBT-FUNDING') ] = 'DEBT FUNDING'\n\n# Change EQUITY and EQUITY BASED FUNDING to EQUITY BASED FUNDING to avoid duplication.\ndata['Investment Type'][(data['Investment Type'] == 'EQUITY') | (data['Investment Type'] == 'EQUITY BASED FUNDING') ] = 'EQUITY BASED FUNDING'\n\n# Change PRIVATE FUNDING, PRIVATEEQUITY , PRIVATE FUNDING ROUND and PRIVATE to PRIVATE EQUITY to avoid duplication.\ndata['Investment Type'][(data['Investment Type'] == 'PRIVATE FUNDING') | (data['Investment Type'] == 'PRIVATE EQUITY ROUND') | (data['Investment Type'] == 'PRIVATE') | (data['Investment Type'] == 'PRIVATEEQUITY') | (data['Investment Type'] == 'PRIVATE FUNDING ROUND')] = 'PRIVATE EQUITY'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Cleaned data.')\nprint(data['Investment Type'].value_counts(dropna = False))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Cleaning the Date column"},{"metadata":{"trusted":true},"cell_type":"code","source":"# First replace // with / and . with /.\ndata['Date'] = data['Date'].apply(lambda x: x.replace('//' , '/' ))\ndata['Date'] = data['Date'].apply(lambda x: x.replace('.' , '/' ))\n\n# Showing the discrepancies in data.\nprint('Showing formats of date other than dd/mm/yyyy:')\nfor i in data['Date']:\n    if not re.match(r'\\b[0-9][0-9]/[0-9][0-9]/[0-9][0-9][0-9][0-9]' , i.strip()):\n        print(i)\n        \n# As you can see incorrect formats for dates are d/mm/yyyy , dd/m/yyyy , d/m/yyyy or dd/mmyyyy.        \n# We have to convert them into dd/mm/yyyy \n\n# Function to put all date values in correct format.\ndef correct_date(date):\n\n    # Extract all the digits in form dd/mm/yyyy and store them in a list.\n    if re.match(r'\\b[0-9][0-9]/[0-1][0-9]/[0-9][0-9][0-9][0-9]' , date.strip()):\n        digits = re.findall(r'\\d' , date)\n        digits.insert(2,'/')\n        digits.insert(5,'/')\n        \n    # Extract all the digits in form d/mm/yyyy and store them in a list.    \n    elif re.match(r'\\b[0-9]/[0-1][0-9]/[0-9][0-9][0-9][0-9]' , date.strip()):\n        digits = re.findall(r'\\d' , date)\n        digits.insert(0,'0')\n        digits.insert(2,'/')\n        digits.insert(5,'/')\n        \n    # Extract all the digits in form d/m/yyyy and store them in a list.    \n    elif re.match(r'\\b[0-9]/[0-9]/[0-9][0-9][0-9][0-9]' , date.strip()):\n        digits = re.findall(r'\\d' , date)\n        digits.insert(0,'0')\n        digits.insert(2,'0')\n        digits.insert(2,'/')\n        digits.insert(5,'/')\n    \n    # Extract all the digits in form dd/m/yyyy and store them in a list.    \n    elif re.match(r'\\b[0-9][0-9]/[0-9]/[0-9][0-9][0-9][0-9]' , date.strip()):\n        digits = re.findall(r'\\d' , date)\n        digits.insert(2,'0')\n        digits.insert(2,'/')\n        digits.insert(5,'/')\n        \n     # Extract all the digits in form dd/mmyyyy and store them in a list.    \n    elif re.match(r'\\b[0-9][0-9]/[0-1][0-9][0-9][0-9][0-9][0-9]' , date.strip()):\n        digits = re.findall(r'\\d' , date)\n        digits.insert(2,'/')\n        digits.insert(5,'/')\n    \n    # Extract all the digits in form dd/mm/yyyy and store them in a list.\n    elif re.match(r'\\b[0-9][0-9]/[0-1][0-9]/[0-9][0-9][0-9]' , date.strip()):\n        digits = re.findall(r'\\d' , date)\n        digits.insert(2,'/')\n        digits.insert(5,'/')\n        digits.insert(6,'2')\n        \n    date_temp = ''\n#     print('date: ' , date)\n    # Finally we form the date in correct format.\n    for i in range(10):\n        date_temp = date_temp + digits[i]\n#     print('new date: ' , date_temp)    \n    return date_temp    \n\n# Since there are no null values in date we can go ahead and clean the data.\ndata['Date'] = data['Date'].apply(correct_date) \n\n# Convert the data type as datetime 64 \ndata['Date']=pd.to_datetime(data['Date'],format='%d/%m/%Y')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Cleaning the column startup name and investors name."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check for null values.\nprint('Null values in Startup names are: ' , data['Startup Name'].isnull().sum())\nprint('Null values in Investor names are: ' , data['Investors Name'].isnull().sum())\n\n# Replace the null values with anonymous.\ndata['Investors Name'][data['Investors Name'].isnull()] = 'Undisclosed Investor'\n\n# Convert all the values to upper case to avoid confusion.\ndata['Investors Name'] = data['Investors Name'].apply(lambda x: x.upper())\n\n# Replace & with 'AND'\ndata['Investors Name'] = data['Investors Name'].apply(lambda x: x.replace('&','AND'))\n\n# A lot of values have \\\\XA2 replace them with ''\ndata['Investors Name'] = data['Investors Name'].apply(lambda x: re.sub('\\\\\\\\[A-Z][A-Z][0-9]','',x))\n\n# Now replace \\ with ''\ndata['Investors Name'] = data['Investors Name'].apply(lambda x: re.sub('\\\\\\\\',' ',x))\n\n# Remove any unnecessary spaces.\ndata['Investors Name'] = data['Investors Name'].apply(lambda x: x.replace('  ',''))\n\n# Remove - \ndata['Investors Name'] = data['Investors Name'].apply(lambda x: x.replace('-',''))\n\n#Display the unique values in Investors Name.\ndata['Investors Name'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a unique set.\nset_in = create_unique_Set(data['Investors Name'])\n#Find the longest match.\ndata['Investors Name'] = data['Investors Name'].apply(find_longest_match, set_values = set_in)\n\n# Since we have a number of investors we need to make a new column to define the number of investors.\ndef no_of_investors(value):\n    if re.search(',',value):\n        return len(value.split(','))\n    else:\n        return 1\ndata['No of Investors'] = data['Investors Name'].apply(no_of_investors)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Cleaning the column startup name"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove .com to avoid confusion.\ndata['Startup Name'] = data['Startup Name'].apply(lambda x: re.sub('.com',' ',x))\n\n# Convert all the values to upper case to avoid confusion.\ndata['Startup Name'] = data['Startup Name'].apply(lambda x: x.upper())\n\n# Replace & with 'AND'\ndata['Startup Name'] = data['Startup Name'].apply(lambda x: x.replace('&','AND'))\n\n# A lot of values have \\\\XA2 replace them with ''\ndata['Startup Name'] = data['Startup Name'].apply(lambda x: re.sub('\\\\\\\\[A-Z][A-Z][0-9]','',x))\n\n# Now replace \\ with ''\ndata['Startup Name'] = data['Startup Name'].apply(lambda x: re.sub('\\\\\\\\',' ',x))\n\n# Remove any unnecessary spaces.\ndata['Startup Name'] = data['Startup Name'].apply(lambda x: x.replace('  ',''))\n\n# Remove - \ndata['Startup Name'] = data['Startup Name'].apply(lambda x: x.replace('-',''))\n\n#Display the unique values in Investors Name.\ndata['Startup Name'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a unique set.\nset_sn = create_unique_Set(data['Startup Name'])\n#Find the longest match.\ndata['Startup Name'] = data['Startup Name'].apply(find_longest_match, set_values = set_sn)\n\n#Display the cleaned data.\ndata['Startup Name'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Stastical Analysis of data. \n### Time based analysis."},{"metadata":{"trusted":true},"cell_type":"code","source":"# First we find out the monthly increase in data.\n\n# Create a df to store the fund values.\ncol = ['Jan' , 'Feb' , 'Mar' , 'Apr' , 'May' , 'June' , 'July' , 'Aug' , 'Sep' , 'Oct' , 'Nov' , 'Dec']\nfund_year = [2015,2016,2017,2018,2019]\nfund_df = pd.DataFrame(columns=col , index=fund_year)\n\n# Set the default values as zero\nfund_df[fund_df[::].isnull()] = 0\n\nfund_df_temp = pd.DataFrame(columns= ['Year' , 'Month' , 'Amount in USD'] )\n\n# Store the month wise funding recieved in the df.    \nfor i,v in data.iterrows():\n    mn = v['Date'].month\n    yr = v['Date'].year\n    fund_df.loc[yr][col[mn-1]] += v['Amount in USD']    \n    fund_df_temp = fund_df_temp.append({'Year' : yr , 'Month' : mn , 'Amount in USD': v['Amount in USD'] } , ignore_index = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Month-wise analysis of funding recieved by startups in various years."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot a line-plot to show the month-wise funding recieved.\nsns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\nax = sns.relplot( height = 10,x = 'Month' , style = 'Year' ,kind = 'line', lw = 2, y = 'Amount in USD' , sort = col,  palette = ['black' , 'maroon' , 'navy' , 'limegreen' , 'mediumvioletred'], hue= 'Year', data = fund_df_temp)\nplt.xticks(np.arange(1,13) , col , rotation = 45)\nplt.title('Monthly analysis of Funding Recieved.')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Yearwise funding recieved by startups."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot a bar plot to show the year wise funding recieved by startups.\nplt.figure(figsize= (12,12))\nplt.ylabel('Amount in USD')         \nplt.xlabel('Year')\nsns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\nsns.barplot(x = fund_df[::].index ,  y = [fund_df.loc[2015].values.sum() , fund_df.loc[2016].values.sum() , \n           fund_df.loc[2017].values.sum() , fund_df.loc[2018].values.sum() , fund_df.loc[2019].values.sum()] , palette=\"RdBu\" \n          ) \nplt.title('Year-Wise Funding of startups.')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### The highest funding recieved was in year 2017."},{"metadata":{},"cell_type":"markdown","source":"## Top twenty startups which received the highest funding."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,12))\nsns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\nsns.barplot(y = data.groupby('Startup Name').sum().sort_values(by = 'Amount in USD' ,ascending = False)[:20]['Amount in USD'].index , x = 'Amount in USD' , data = data.groupby('Startup Name').sum().sort_values(by = 'Amount in USD' ,ascending = False)[:20]) \nplt.title('Top 20 Startups which recieved the maximum funding.')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,12))\nplt.xticks(rotation = 90)\nsns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\nsns.barplot(x = data.groupby('Startup Name').count().sort_values(by = 'No of Investors' ,ascending = False)[:20]['Amount in USD'].index , palette='GnBu' , y = 'No of Investors' , data = data.groupby('Startup Name').sum().sort_values(by = 'No of Investors' ,ascending = False)[:20]) \nplt.title('Top 20 Startups with largest no of investors.' )\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Find the investors who made the maximum investment."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.groupby('Investors Name').sum().sort_values(by = 'No of Investors' ,ascending = False)[:20]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# As we can see there are investors who made combined investment. \n# So, we try to find out the investors who made the maximum number of investment.\n\n# Create a function to seperate the investors and store them \ninvestors_set = set()\ndef seperate_investors(series):\n\n    for i in series.values:\n        if re.search(',' , i):\n            t_lst = i.split(',')\n            for j in t_lst:\n                investors_set.add(j)\n        else:\n            investors_set.add(i)\n            \nseperate_investors(data['Investors Name'])\n\n# Now create a new dataframe.\ninvestment_df = pd.DataFrame(columns=['Investor Name' , 'No of Investment'])\ninvestment_df['No of Investment'] = investment_df['No of Investment'].astype('float') \n# Initialize the dataframe.\nfor i in investors_set:\n    if i != '':\n        investment_df = investment_df.append({'Investor Name':i , 'No of Investment':0} , ignore_index = True)\n        \n# Populate the dataframe.\nfor name in data['Investors Name']:\n    if re.search(',', name):\n        temp_lst = name.split(',')\n        for nm in temp_lst:\n            investment_df.loc[investment_df['Investor Name'] == nm , 'No of Investment'] += 1.0 \n    else:\n        investment_df.loc[investment_df['Investor Name'] == name , 'No of Investment']  += 1.0 \n         \n# investment_df[investment_df['Investor Name']== 'EQUITY CREST']['No of Investment'] = 3\ninvestment_df.loc[investment_df['Investor Name']== 'EQUITY CREST' , 'No of Investment'] += 1            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"investment_df.sort_values(by= 'No of Investment', ascending=False)[:20]['Investor Name']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot the graph\nplt.figure(figsize=(12,12))\nsns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\nsns.barplot(y =investment_df.sort_values(by= 'No of Investment', ascending=False)[:20]['Investor Name'] , x = 'No of Investment' , data = investment_df.sort_values(by= 'No of Investment', ascending=False)[:20] , palette= 'dark') \nplt.title('Top 20 Investors who invested the maximum number of times.' )\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Type of funding recieved by startups."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Here we find the type of funding(top 5) recieved by startups.\nfont = {'family' : 'normal',\n        'weight' : 'bold',\n        'size'   : 15}\nplt.rc('font', **font)\nlabels = data.groupby('Investment Type').sum().sort_values(by = 'Amount in USD' , ascending = False)[:5].index\nvalues = data.groupby('Investment Type').sum().sort_values(by = 'Amount in USD' , ascending = False)[:5]['Amount in USD'].values\nfig , ax = plt.subplots()\nfig.set_size_inches(12,12)\nax.pie(colors = ['b' , 'g' , 'c' , 'm' , 'y'] ,  labels = labels , x = values , autopct='%.1f%%' , explode = [0.1 for x in range(5)])\nplt.title(' Top five types of funding recieved by startups.' , fontsize = 20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Industry Verticals which recieved the maximum funding."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Here we find the industry vertical which recieved the maximum funding.\nfont = {'family' : 'normal',\n        'weight' : 'bold',\n        'size'   : 22}\nplt.rc('font', **font)\nlabels = data.groupby('Industry Vertical').sum().sort_values(by = 'Amount in USD' , ascending = False)[:10].index\nvalues = data.groupby('Industry Vertical').sum().sort_values(by = 'Amount in USD' , ascending = False)[:10]['Amount in USD'].values\nfig , ax = plt.subplots()\nfig.set_size_inches(12,12)\nax.pie(  labels = labels , x = values , autopct='%.1f%%' , explode = [0.1 for x in range(10)])\nplt.title(' Percentage of funding recieved by top ten industry verticals.' , fontsize = 30)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Top Cities which recieved the maximum funding."},{"metadata":{"trusted":true},"cell_type":"code","source":"colors = ['#6987C2' ,'#947EB0' , '#A9D2D5' , '#ADFCF9' , '#4B644A' , '#2589BD' , '#E8AEB7' , '#58A4B0' , '#A9A587' ]\ndata.groupby('City  Location' ).sum().sort_values(by = 'Amount in USD' , ascending = False ).index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We have to clean the data to avoid duplicity. \ndata.loc[(data['City  Location'] == 'AHEMADABAD') | (data['City  Location'] == 'AHMEDABAD') , 'City  Location'] = 'AHMEDABAD'\ndata.loc[(data['City  Location'] == 'BANGALORE') | (data['City  Location'] == 'BENGALURU') , 'City  Location'] = 'BENGALURU'\ndata.loc[(data['City  Location'] == 'GURGAON') | (data['City  Location'] == 'GURUGRAM') , 'City  Location'] = 'GURUGRAM'\n\n# Plot the data.\ncity_data = data.groupby('City  Location' ).sum().sort_values(by = 'Amount in USD' , ascending = False)[:10]\nplt.figure(figsize=(12,12))\nsns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\nsns.barplot(y = city_data.index , x = 'Amount in USD' , data = city_data , palette= 'pastel') \nplt.title('Top 10 Cities which recieved the maximum funding.' )\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Top ten cities with maximum number of investors."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot the data.\ncity_data = data.groupby('City  Location' ).sum().sort_values(by = 'No of Investors' , ascending = False)[:10]\nplt.figure(figsize=(12,12))\nsns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\nsns.barplot(y = city_data.index , x = 'No of Investors' , data = city_data , palette= 'BuGn') \nplt.title('Top 10 Cities which had the maximum number of investors.' )\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Top ten cities with maximum number of startups."},{"metadata":{"trusted":true},"cell_type":"code","source":"top_cities = data.groupby('City  Location' ).count().sort_values(by = 'Startup Name' , ascending = False)[:10]\n# Here we find the industry vertical which recieved the maximum funding.\nfont = {'family' : 'normal',\n        'weight' : 'bold',\n        'size'   : 15}\nplt.rc('font', **font)\nlabels = top_cities.index\nvalues = top_cities['Startup Name'].values\nfig , ax = plt.subplots()\nfig.set_size_inches(12,12)\nax.pie(  colors = colors,labels = labels , x = values , autopct='%.1f%%' , explode = [0.1 for x in range(10)])\nplt.title(' Percentage of number of startups recieved by top ten cities.' , fontsize = 30)\nplt.show()\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}