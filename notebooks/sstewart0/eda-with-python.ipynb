{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction\n\n### Welcome to this notebook!\n\nMy aim is to provide **rigorous** explanations for each step of the process in order to perform exploratory data analysis. \n\nThis notebook can be broken down into the following:\n\n### Stages:\n\n1. Data Manipulation & Aggregation\n2. Creating functions for visualisation\n\n> Once we have done this we can perform our **analysis**, which is divided into analysing:\n\n3. The performance of plants,\n4. The age of the plants,\n5. The conditions each plant is working under, and\n6. How the feature variables are related.\n\nFinally, we draw some **conclusions**.\n\n---"},{"metadata":{},"cell_type":"markdown","source":"# Abstract\n\nThis data has been gathered at two solar power plants in India over a 34 day period. It has two pairs of files - each pair has one power generation dataset and one sensor readings dataset. The power generation datasets are gathered at the inverter level - each inverter has multiple lines of solar panels attached to it. The sensor data is gathered at a plant level - single array of sensors optimally placed at the plant.\n\n---"},{"metadata":{},"cell_type":"markdown","source":"# Import the necessary libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Reading files from directory\nimport os\n\n# Data manipulation & analysis\nimport pandas as pd\nimport datetime as dt\n\n# Linear Algebra\nimport numpy as np\n\n# Statistical Tests\nfrom scipy.stats import pearsonr\n\n# Visualisation\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"# Acquire Data\n\n## Find the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Now that we have the filepaths for the data, we can read it using pandas.\n\n---"},{"metadata":{},"cell_type":"markdown","source":"## Reading the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Power generation data\nplant_1_gd = pd.read_csv(\"/kaggle/input/solar-power-generation-data/Plant_1_Generation_Data.csv\")\nplant_2_gd = pd.read_csv(\"/kaggle/input/solar-power-generation-data/Plant_2_Generation_Data.csv\")\n\n# Weather sensor data\nplant_1_wsd = pd.read_csv(\"/kaggle/input/solar-power-generation-data/Plant_1_Weather_Sensor_Data.csv\")\nplant_2_wsd = pd.read_csv(\"/kaggle/input/solar-power-generation-data/Plant_2_Weather_Sensor_Data.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"## What does our data look like?\n\n### Power Generation Data:\n\n|No.|Variable|Data Type|\n|---|---|---|\n|1|DATE_TIME|String|\n|2|PLANT_ID|integer|\n|3|SOURCE_KEY|integer|\n|4|DC_POWER|float|\n|5|AC_POWER|float|\n|6|DAILY_YIELD|float|\n|7|TOTAL_YIELD|float|\n\n### Plant Weather Sensor Data:\n\n|No.|Variable|Data Type|\n|---|---|---|\n|1|DATE_TIME|String|\n|2|PLANT_ID|integer|\n|3|SOURCE_KEY|integer|\n|4|AMBIENT_TEMPERATURE|float|\n|5|MODULE_TEMPERATURE|float|\n|6|IRRADATION|float|\n\n---"},{"metadata":{},"cell_type":"markdown","source":"# Data manipulation"},{"metadata":{},"cell_type":"markdown","source":"### Change DATE_TIME ---> valid datetime data type."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Change Datetime column to valid datetime format\nplant_1_gd.DATE_TIME = pd.to_datetime(plant_1_gd.DATE_TIME)\nplant_2_gd.DATE_TIME = pd.to_datetime(plant_2_gd.DATE_TIME)\n\nplant_1_wsd.DATE_TIME = pd.to_datetime(plant_1_wsd.DATE_TIME)\nplant_2_wsd.DATE_TIME = pd.to_datetime(plant_2_wsd.DATE_TIME)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"### Splitting   DATETIME  --->  DATE & TIME "},{"metadata":{"trusted":true},"cell_type":"code","source":"def split_date_time(data):\n    data['DATE'] = np.array([dt.datetime.date(x) for x in data['DATE_TIME']])\n    data['TIME'] = np.array([dt.datetime.time(x) for x in data['DATE_TIME']])\n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Applying the above function to split: DATETIME ---> DATE & TIME\nplant_1_gd = split_date_time(plant_1_gd)\nplant_2_gd = split_date_time(plant_2_gd)\n\nplant_1_wsd = split_date_time(plant_1_wsd)\nplant_2_wsd = split_date_time(plant_2_wsd)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"## What does our updated data look like?\n\n### *Updated* Power Generation Data:\n\n|No.|Variable|Data Type|\n|---|---|---|\n|1|DATE_TIME|String|\n|2|PLANT_ID|integer|\n|3|SOURCE_KEY|integer|\n|4|DC_POWER|float|\n|5|AC_POWER|float|\n|6|DAILY_YIELD|float|\n|7|TOTAL_YIELD|float|\n|8|DATE|date|\n|9|TIME|time|\n\n### *Updated* Plant Weather Sensor Data:\n\n|No.|Variable|Data Type|\n|---|---|---|\n|1|DATE_TIME|String|\n|2|PLANT_ID|integer|\n|3|SOURCE_KEY|integer|\n|4|AMBIENT_TEMPERATURE|float|\n|5|MODULE_TEMPERATURE|float|\n|6|IRRADATION|float|\n|7|DATE|date|\n|8|TIME|time|\n\n---"},{"metadata":{},"cell_type":"markdown","source":"## Converting DATE ---> INT\n\nWhen we fit a linear best fit line we will require the DATE field to be a numeric value."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a dictionary to map DATE ---> INT\ndef map_dates(dates):\n    return {date:i for i,date in enumerate(dates)}\n\n# Function to convert all dates to integer values\ndef date_to_int(dates):\n    date_map = map_dates(dates.unique())\n    ds = np.array([date_map[d] for d in dates])\n    return ds","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"# Data aggregation\n\nIn order to perform analysis on the datasets, we need to group the data by relevant columns and apply necessary aggregations over the resulting columns, e.g. sum, mean & variance.\n\n## Group by: DATE\n\nWe want to **sum** or calculate the **mean** of the numerical variables from all the inverters (depending on the task), for each DATE level. If we take the sum, we acquire\n\n\n| DATE | $x_1$ | ... | $x_p$ |\n| --- | --- | --- | --- |\n| $d_1$ | $\\sum_{i=1}^{Q}({x_{1i})^{d_{1}}}$ | ... | $\\sum_{i=1}^{Q}({x_{pi})^{d_{1}}}$ |\n| ... |  |  |  |\n| $d_{\\alpha}$ | $\\sum_{i=1}^{Q}({x_{1i})^{d_{\\alpha}}}$ | ... | $\\sum_{i=1}^{Q}({x_{pi})^{d_{\\alpha}}}$ |\n\nwhere:\n* $ p = $ number of numeric variables,\n* $ \\alpha = $ number of dates,\n* $ Q = $ number of inverters,\n* $\\sum_{i=1}^{Q}({x_{ji})^{d_{k}}}$ is the sum of variable $x_j$ over all $Q$ inverters on date $d_{k}$.\n\nAnd if we use the mean, we simply divide $\\sum_{i=1}^{Q}({x_{ji})^{d_{k}}}$ by $Q$."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to group data by DATE and apply either sum or mean aggregation\ndef group_by_date(data,method='sum'):\n    grouped_df = data.groupby(['DATE'])\n    if method == 'avg':\n        return grouped_df.agg('mean').reset_index()\n    else:\n        return grouped_df.agg('sum').reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# PLANT 1 GENERATION DATA GROUPED BY DATE\ngd_dd1 = group_by_date(plant_1_gd)\n# PLANT 2 GENERATION DATA GROUPED BY DATE\ngd_dd2 = group_by_date(plant_2_gd)\n\n# PLANT 1 WEATHER SENSOR DATA GROUPED BY DATE\nwsd_dd1 = group_by_date(plant_1_wsd,method='avg')\n# PLANT 2 WEATHER SENSOR DATA GROUPED BY DATE\nwsd_dd2 = group_by_date(plant_2_wsd,method='avg')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"## Group by: DATE & TIME\n\nWe want to **sum** the numerical variables from all the inverters, for each DATE & TIME level. That is, \n\n\n| DATE | TIME | $x_1$ | ... | $x_p$ |\n| --- | --- | --- | --- | --- |\n| $d_1$ | $t_1$ | $\\sum_{i=1}^{Q}({x_{1i})^{d_{1}t_{1}}}$ | ... | $\\sum_{i=1}^{Q}({x_{pi})^{d_{1}t_{1}}}$ |\n| $d_1$ | $t_2$ | $\\sum_{i=1}^{Q}({x_{1i})^{d_{1}t_{2}}}$ | ... | $\\sum_{i=1}^{Q}({x_{pi})^{d_{1}t_{2}}}$ |\n| ... |  |  |  |  |\n| $d_{\\alpha}$ | $t_{\\beta}$ | $\\sum_{i=1}^{Q}({x_{1i})^{d_{\\alpha}t_{\\beta}}}$ | ... | $\\sum_{i=1}^{Q}({x_{pi})^{d_{\\alpha}t_{\\beta}}}$ |\n\nwhere:\n* $ \\beta = $ number of times,\n* $\\sum_{i=1}^{Q}({x_{ji})^{d_{k}t_{l}}}$ is the sum of variable $x_j$ over all $Q$ inverters on date $d_{k}$ at time $t_{l}$."},{"metadata":{"trusted":true},"cell_type":"code","source":"def group_by_date_time(data):\n    grouped_df = data.groupby(['DATE','TIME'])\n    df = grouped_df.agg('sum').reset_index()\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# PLANT 1 GENERATION DATA GROUPED BY DATE & TIME\ngd_dt1 = group_by_date_time(plant_1_gd)\n# PLANT 2 GENERATION DATA GROUPED BY DATE & TIME\ngd_dt2 = group_by_date_time(plant_2_gd)\n\n# PLANT 1 WEATHER SENSOR DATA GROUPED BY DATE & TIME\nwsd_dt1 = group_by_date_time(plant_1_wsd)\n# PLANT 2 WEATHER SENSOR DATA GROUPED BY DATE & TIME\nwsd_dt2 = group_by_date_time(plant_2_wsd)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"## Group by: TIME\n\nWe want to analyse the **mean**, that is,\n\n$$\\mu_X = E[X] =\\frac{1}{N}\\sum_{i=1}^{N}{x_i}$$\n\n\nand the **standard deviation**, that is,\n\n$$ \\sigma_X = \\sqrt{Var[X]} = \\sqrt{\\frac{1}{N}\\sum_{i=1}^{N}{(x_i-\\mu_X)^2}}$$\n\nfor each numerical variable $X$, at each time.\n\n(where: $N$ is the total number of observations of $X$.)\n\nThe table will look like this,\n\n\n| TIME | $E[x_1]$ | $sd[x_1]$ |... | $E[x_p]$ | $sd[x_p]$ |\n| --- | --- | --- | --- | --- | --- |\n| $t_1$ | $(\\mu_{x_1})^{t_{1}}$ | $(sd[x_1])^{t_{1}}$  |... | $(\\mu_{x_p})^{t_{1}}$ | $(sd[x_p])^{t_{1}}$ |\n| ... |  |  |  |  |  |\n| $t_{\\beta}$ | $(\\mu_{x_1})^{t_{\\beta}}$ | $(sd[x_1])^{t_{\\beta}}$ |... | $(\\mu_{x_p})^{t_{\\beta}}$ |$(sd[x_p])^{t_{\\beta}}$ |\n\nwhere:\n* $(\\mu_{x_j})^{t_{l}}$ is the mean for $x_j$ at time $t_l$, and\n* $(sd[x_j])^{t_{l}}$ is the standard deviation for $x_j$ at time $t_l$."},{"metadata":{"trusted":true},"cell_type":"code","source":"# We can specify what dataset we are giving the below function by specifying data_type as either:\n# 'gd' (i.e. generation data) or 'wsd' (i.e weather sensor data)\n\ndef group_by_time(data, data_type='gd'):\n    grouped_df = data.groupby(['TIME'])\n    if data_type == 'gd':\n        col_names = ['TIME','AVG_DC_POWER','SE_DC_POWER','AVG_AC_POWER','SE_AC_POWER',\n                     'AVG_DAILY_YIELD','SE_DAILY_YIELD','MEDIAN_TOTAL_YIELD','SE_TOTAL_YIELD']\n        df = grouped_df.agg({'DC_POWER':['mean','std'],\n                             'AC_POWER':['mean','std'],\n                             'DAILY_YIELD':['mean','std'],\n                             'TOTAL_YIELD':['median','std']}).reset_index()\n        df.columns = col_names\n    else:\n        col_names = ['TIME', 'AVG_AMBIENT_TEMPERATURE', 'SE_AMBIENT_TEMPERATURE', 'AVG_MODULE_TEMPERATURE',\n                     'SE_MODULE_TEMPERATURE', 'AVG_IRRADIATION', 'SE_IRRADIATION']\n        df = grouped_df.agg({'AMBIENT_TEMPERATURE': ['mean', 'std'],\n                             'MODULE_TEMPERATURE': ['mean', 'std'],\n                             'IRRADIATION': ['mean', 'std']}).reset_index()\n        df.columns = col_names\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# PLANT 1 GENERATION DATA GROUPED BY TIME\ngd_t1 = group_by_time(gd_dt1,data_type='gd')\n# PLANT 2 GENERATION DATA GROUPED BY TIME\ngd_t2 = group_by_time(gd_dt2,data_type='gd')\n\n# PLANT 1 WEATHER SENSOR DATA GROUPED BY TIME\nwsd_t1 = group_by_time(wsd_dt1,data_type='wsd')\n# PLANT 2 WEATHER SENSOR DATA GROUPED BY TIME\nwsd_t2 = group_by_time(wsd_dt2,data_type='wsd')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Group by: (DATE or TIME) & INVERTERS"},{"metadata":{},"cell_type":"markdown","source":"We only need to group the Power Generator Data by inverters because we only have data from one inverter in the Weather Sensor data. We want to calculate the sum, mean and standard deviation for each inverter. For example if we group by DATE & inverters;\n\n\n| DATE | INVERTER | $x_1$ | $E[x_1]$ | $sd[x_1]$ |... | $x_p$ | $E[x_p]$ | $sd[x_p]$ |\n| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n| $d_1$ | $I_1$ | $\\sum_{i=1}^{\\beta}({x_{1i})^{d_{1}I_{1}}}$ | $(\\mu_{x_1})^{d_{1}I_{1}}$ | $(sd[x_1])^{d_{1}I_{1}}$  |... | $\\sum_{i=1}^{\\beta}({x_{pi})^{d_{1}I_{1}}}$ |$(\\mu_{x_p})^{d_{1}I_{1}}$ | $(sd[x_p])^{d_{1}I_{1}}$  |\n| $d_1$ | $I_2$ | $\\sum_{i=1}^{\\beta}({x_{1i})^{d_{1}I_{2}}}$ |$(\\mu_{x_1})^{d_{1}I_{2}}$ | $(sd[x_1])^{d_{1}I_{2}}$  | ... | $\\sum_{i=1}^{\\beta}({x_{pi})^{d_{1}I_{2}}}$ |$(\\mu_{x_p})^{d_{1}I_{2}}$ | $(sd[x_p])^{d_{1}I_{2}}$  |\n| ... |  |  |  |  | | | | |\n| $d_{\\alpha}$ | $I_Q$ | $\\sum_{i=1}^{\\beta}({x_{1i})^{d_{\\alpha}I_{Q}}}$ | $(\\mu_{x_1})^{d_{\\alpha}I_{Q}}$ | $(sd[x_1])^{d_{\\alpha}I_{Q}}$  |... | $\\sum_{i=1}^{\\beta}({x_{pi})^{d_{\\alpha}I_{Q}}}$ |$(\\mu_{x_p})^{d_{\\alpha}I_{Q}}$ | $(sd[x_p])^{d_{\\alpha}I_{Q}}$  |\n\nwhere:\n* $\\sum_{i=1}^{\\beta}({x_{ji})^{d_{k}I_{l}}}$ is the sum of the variable $x_j$ on date $d_{k}$ for inverter $I_{l}$ (over all times $t_1$ to $t_{\\beta}$),\n* $(\\mu_{x_j})^{d_{k}I_{l}}$ is the mean of the variable $x_j$ on date $d_{k}$ for inverter $I_{l}$ (over all times $t_1$ to $t_{\\beta}$), and\n* $(sd[x_j])^{d_{k}I_{l}}$ is the standard deviation of the variable $x_j$ on date $d_{k}$ for inverter $I_{l}$ (over all times $t_1$ to $t_{\\beta}$)."},{"metadata":{"trusted":true},"cell_type":"code","source":"def group_by_x_inverters(x, data):\n    grouped_df = data.groupby([x,'SOURCE_KEY'])\n    col_names = [x, 'SOURCE_KEY','SUM_DC_POWER','AVG_DC_POWER', 'SE_DC_POWER',\n                 'SUM_AC_POWER','AVG_AC_POWER','SE_AC_POWER',\n                 'SUM_DAILY_YIELD','AVG_DAILY_YIELD', 'SE_DAILY_YIELD',\n                 'SUM_TOTAL_YIELD','AVG_TOTAL_YIELD', 'SE_TOTAL_YIELD',]\n    df = grouped_df.agg({'DC_POWER': ['sum','mean', 'std'],\n                         'AC_POWER': ['sum','mean', 'std'],\n                         'DAILY_YIELD': ['sum','mean', 'std'],\n                         'TOTAL_YIELD': ['sum','mean', 'std']}).reset_index()\n    df.columns = col_names\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# PLANT 1 GENERATION DATA GROUPED BY DATE & INVERTERS\ninv1_date = group_by_x_inverters('DATE', plant_1_gd)\n# PLANT 2 GENERATION DATA GROUPED BY DATE & INVERTERS\ninv2_date = group_by_x_inverters('DATE', plant_2_gd)\n\n# PLANT 1 WEATHER SENSOR DATA GROUPED BY TIME & INVERTERS\ninv1_time = group_by_x_inverters('TIME', plant_1_gd)\n# PLANT 2 WEATHER SENSOR DATA GROUPED BY TIME & INVERTERS\ninv2_time = group_by_x_inverters('TIME', plant_2_gd)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### The good thing about the above grouping functions is that they can be applied to both the Generation Data and Weather Sensor data, so in this way our functions generalise well."},{"metadata":{},"cell_type":"markdown","source":"## Combine: Generation & Weather Sensor Data\n\nWhen we analyse correlations between all feature variables we will need the Generation Data & Weather Sensor Data in one pandas DataFrame."},{"metadata":{"trusted":true},"cell_type":"code","source":"# We will pass the data that has been grouped by DATE & TIME\ndef combine_gd_wsd(gds, wsds):\n    \n    #[Generation Data from plant 1, Generation Data from plant 2]\n    [gd1, gd2] = gds\n    \n    #[Weather Sensor Data from plant 1, Weather Sensor Data from plant 2]\n    [wsd1,wsd2] = wsds\n    \n    # When we grouped by DATE,TIME the plant ID's were treated as a number and are summed, so we must ammend this\n    gd1['PLANT_ID'] = 4135001\n    gd2['PLANT_ID'] = 4136001\n\n    wsd1['PLANT_ID'] = 4135001\n    wsd2['PLANT_ID'] = 4136001\n\n    both_plants_gd = pd.concat(gds)\n    both_plants_wsd = pd.concat(wsds)\n\n    return pd.merge(both_plants_gd,both_plants_wsd,on=['PLANT_ID','DATE','TIME'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"# Functions for plotting\n\nThe plan is to create functions for plotting that can be applied to **any specified columns from both datasets** so that we do not end up repeating code unneccesarily.\n\n## Plotting: Variable ~ $X$\n\nWhere,\n* Variable is any numeric variable, and\n* $X$ can be either DATE or TIME"},{"metadata":{"trusted":true},"cell_type":"code","source":"# plants will be passed as a list : [plant1-data,plant2-data]\ndef plot_variable_vs_x(plants, x, variable, style='.', bestfit = False):\n    # DATE or TIME\n    x1 = plants[0][x].astype(str)\n    x2 = plants[1][x].astype(str)\n    \n    # Numeric variable\n    y1 = plants[0][variable]\n    y2 = plants[1][variable]\n    \n    fig, (ax1, ax2) = plt.subplots(ncols=2, sharey=True)\n    \n    fig.set_figheight(8)\n    fig.set_figwidth(8)\n\n    fig.suptitle('PLANT 1 & 2 ' + variable.replace('_',' '))\n    \n    # Generator function to return colours\n    my_colors = plt.rcParams['axes.prop_cycle']()\n\n    ax1.plot(x1, y1, style, **next(my_colors), alpha=.7, ms=4)\n    ax2.plot(x2, y2, style, **next(my_colors), alpha=.7, ms=4)\n    \n    # Calculate linear best fit line\n    if bestfit:\n        x1_int = date_to_int(x1)\n        x2_int = date_to_int(x2)\n\n        coef1 = np.polyfit(x1_int, y1, 1)\n        poly1d_fn1 = np.poly1d(coef1)\n\n        coef2 = np.polyfit(x2_int, y2, 1)\n        poly1d_fn2 = np.poly1d(coef2)\n        \n        # We can repeatedly call my_colors and it will return a color.\n        ax1.plot(x1_int,poly1d_fn1(x1_int), **next(my_colors))\n        ax2.plot(x2_int,poly1d_fn2(x2_int), 'k-', **next(my_colors))\n        \n    # Set the x-ticks, i.e. the x-axis values\n    x1_ticks = x1.unique()\n    x1_tick_loc = np.arange(len(x1_ticks)+1)\n    \n    x2_ticks = x2.unique()\n    x2_tick_loc = np.arange(len(x2_ticks)+1)\n\n    ax1.set_xticks(x1_tick_loc[::8])\n    ax1.set_xticklabels(x1_ticks[::8], rotation=90)\n\n    ax2.set_xticks(x2_tick_loc[::8])\n    ax2.set_xticklabels(x2_ticks[::8],rotation=90)\n    \n    # Set labels & title\n    ax1.set_xlabel(x)\n    ax2.set_xlabel(x)\n\n    ax1.set_title('PLANT1')\n    ax2.set_title('PLANT2')\n\n    ax1.set_ylabel(variable.replace('_',' '))\n\n    for a in fig.get_axes():\n        a.label_outer()\n\n    plt.show()\n    return None","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"## Plotting: $E[X]$ & $sd[X]$ over time.\n\nPlotting the mean, $E[X]$, and standard deviation, $sd[X]$, of a variable, $X$, is slightly different, so we define a new function."},{"metadata":{"trusted":true},"cell_type":"code","source":"# As above we pass plants as a list: [plant1-data,plant2-data]\ndef plot_mean_sd(plants, variable, style='k-'):\n    x = 'TIME'\n    x1 = plants[0][x].astype(str)\n    x2 = plants[1][x].astype(str)\n\n    median_variables = ['TOTAL_YIELD']\n\n    if variable in median_variables:\n        avg_variable = 'MEDIAN_' + variable\n    else:\n        avg_variable = 'AVG_' + variable\n        \n    # Variable we are plotting on the y-axis\n    y1 = plants[0][avg_variable]\n    y2 = plants[1][avg_variable]\n\n    se_variable = 'SE_' + variable\n    \n    # Standard deviations\n    error1 = plants[0][se_variable]\n    error2 = plants[1][se_variable]\n    \n    fig, (ax1, ax2) = plt.subplots(ncols=2, sharey=True)\n\n    fig.suptitle('PLANT 1 & 2 AVERAGE ' + variable.replace('_', ' '))\n    \n    fig.set_figheight(8)\n    fig.set_figwidth(8)\n\n    ax1.plot(x1, y1, style)\n    ax2.plot(x2, y2, style)\n\n    ax1.set_title('PLANT1')\n    ax2.set_title('PLANT2')\n    \n    ax1.fill_between(x1, y1 - error1, y1 + error1)\n    ax2.fill_between(x2, y2 - error2, y2 + error2)\n\n    x1_ticks = x1.unique()\n    x1_tick_loc = np.arange(len(x1_ticks)+1)\n    \n    x2_ticks = x2.unique()\n    x2_tick_loc = np.arange(len(x2_ticks)+1)\n\n    ax1.set_xticks(x1_tick_loc[::8])\n    ax1.set_xticklabels(x1_ticks[::8], rotation=90)\n\n    ax2.set_xticks(x2_tick_loc[::8])\n    ax2.set_xticklabels(x2_ticks[::8],rotation=90)\n\n    ax1.set_xlabel(x)\n    ax2.set_xlabel(x)\n\n    ax1.set_ylabel('AVG ' + variable.replace('_', ' '))\n\n    for a in fig.get_axes():\n        a.label_outer()\n\n    plt.show()\n    return None","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"## Plotting: Variable ~ $X$ for each inverter\n\nWhen we plot a variable for each inverter we must create a grid to plot the 22 inverters on, so the method is slighty different due to this.\n\nWhere again,\n* Variable is any numeric variable, and\n* $X$ can be either DATE or TIME"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_inverter_vs_variable(plant, x, y, title, style = 'k-'):\n    var_name = 'SUM_' + y\n    \n    # Create the grid with 6 rows and 4 columns\n    fig, axs = plt.subplots(6,4,sharex=True,sharey=True)\n    \n    fig.set_figheight(8)\n    fig.set_figwidth(8)\n\n    fig.suptitle(title + ' INVERTER ' + y.replace('_', ' '))\n\n    inverters = plant.SOURCE_KEY.unique().astype(str)\n\n    x_ticks = plant[x].unique().astype(str)\n    x_tick_loc = np.arange(len(x_ticks) + 1)\n\n    my_colors = plt.rcParams['axes.prop_cycle']()\n    \n    # Plot each inverter on the grid\n    i, j = 0, 0\n    for invert in inverters:\n        inverter_data = plant.loc[plant['SOURCE_KEY'] == invert]\n\n        x1 = inverter_data[x].astype(str)\n        y1 = inverter_data[var_name]\n\n        axs[i][j].set_title(invert,fontdict=dict(fontsize=7))\n\n        axs[i][j].plot(x1, y1, style, **next(my_colors))\n\n        axs[i][j].set_xticks(x_tick_loc[::8])\n        axs[i][j].set_xticklabels(x_ticks[::8],rotation=90)\n\n        if i == 5:\n            i = 0\n            j += 1\n        else:\n            i += 1\n\n    axs[5][3].set_xticklabels(x_ticks[::8], rotation=90)\n\n    for a in fig.get_axes():\n        a.label_outer()\n\n    plt.show()\n    return None","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"## Heatmap plot\n\nA heatmap plot is a visual representation of the correlations between two numeric variables $X$, $Y$. We will use the pearson correlation coefficient which is a statistic that measures **linear correlation** between two variables. It is defined as:\n\n$$cor(X,Y) = \\frac{cov(X,Y)}{sd(X).sd(Y)}$$\n\nwhere:\n* $cov(X,Y) = E[(X-\\mu_X)(X-\\mu_Y)]$ is the covariance between $X$ & $Y$."},{"metadata":{"trusted":true},"cell_type":"code","source":"def my_heat_map(data):\n    # Compute the correlation matrix\n    corr = data.corr()\n\n    # Generate a mask for the upper triangle\n    mask = np.triu(np.ones_like(corr, dtype=bool))\n\n    fig, ax = plt.subplots()\n    fig.set_figheight(8)\n    fig.set_figwidth(8)\n\n    # Generate a custom diverging colormap\n    cmap = sns.diverging_palette(230, 20, as_cmap=True)\n\n    # Draw the heatmap with the mask and correct aspect ratio\n    sns.heatmap(corr, mask=mask, cmap=cmap, center=0, annot=True,\n                square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n\n    plt.show()\n    return None\n    \n# CREDIT: https://seaborn.pydata.org/examples/many_pairwise_correlations.html","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"# Plant Efficiency\n\n#### Plot the mean & standard deviation (over time) of the variables that indicate performance of the plants.\n\n## AC POWER:"},{"metadata":{"trusted":true},"cell_type":"code","source":"gd_time_data = [gd_t1, gd_t2]\n\nplot_mean_sd(gd_time_data, 'AC_POWER')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n\n> * Plant 1 produces more AC power than plant 2. \n> * The distribution of average AC power production for plant 1 is a bell curve with maximum value located at 12:00pm. \n> * The average AC power production for plant 2 increases until around 8:00am, then levels off and begins to decrease around 4:00pm.\n\n---\n\n## DC POWER:"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_mean_sd(gd_time_data, 'DC_POWER')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n> * Plant 1 produces over 10 times more DC power than plant 2 at its peak production time of 12:00pm.\n> * The distribution of average DC power over time for plant 1 is again a bell curve with centre located at 12:00pm.\n\n---\n\n## DAILY YIELD:\n\n#### Daily yield is **cumulative**."},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_mean_sd(gd_time_data, 'DAILY_YIELD')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> * The (cumulative) daily yield for plants 1 and 2 are very similar.\n> * On average, plant 1 produces around 30,000 more yield than plant 2 daily.\n> * Power production begins around 8:00am in the morning and finishes around 6:00pm in the evening.\n> * There is a dip in daily yield at 6:00pm for plant 1 which doesn't make sense as the yield is cumulative. This must be how the inverters are configured.\n> * The daily yield decreases to zero at 6:00am for plant 2 which doesn't make sense, but again this must be how the inverters are configured for this plant.\n\n---"},{"metadata":{},"cell_type":"markdown","source":"# AGE INFERENCE\n\n## Age of Plant 1 & 2\n\n#### Inspect the total (cumulative) yield for plant 1 & 2."},{"metadata":{"trusted":true},"cell_type":"code","source":"date_data = [gd_dd1,gd_dd2]\n\nplot_variable_vs_x(date_data, x='DATE', variable='TOTAL_YIELD', style='k-')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> * The total yield for plant 2 is ~ 70 times greater than the total yield for plant 2.\n> * Therefore, **assume** that plant 2 is older than plant 1.\n\n---"},{"metadata":{},"cell_type":"markdown","source":"## Age of Inverters\n\n#### Inspect the total (cumulative) yield for each inverter seperately for both plant 1 & 2."},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_inverter_vs_variable(inv1_date, 'DATE', 'TOTAL_YIELD', 'PLANT 1')\nplot_inverter_vs_variable(inv2_date, 'DATE', 'TOTAL_YIELD', 'PLANT 2')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> * The total yield for inverters from plant 1 are all similar,\n> * The total yield for inverters from plant 2 vary greatly,\n> * **Assume**: The higher the total yield <=> the older the inverter,\n> * **Assume**: The lower the total yield <=> the more recently the inverter has been replaced.\n\n---"},{"metadata":{},"cell_type":"markdown","source":"# Equipment Optimality\n\n#### **Question:** Are all inverters performing optimally?\n\n* **Assume**: Since plant 1 is **younger** and more **efficient** the performance of its inverters are optimal.\n\n## Inverter Performance:\n\n#### Let's compare the **AC POWER** production for the inverters from plant 1 & 2.\n\n### PLANT 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_inverter_vs_variable(inv1_time, 'TIME', 'AC_POWER', 'PLANT 1')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> * Symmetric bell curve shape for all inverters centred at 12:00pm.\n\n---\n\n### PLANT 2"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_inverter_vs_variable(inv2_time, 'TIME', 'AC_POWER', 'PLANT 2')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> * A few symmetric bell curves (which is what we would like to see) like the inverter located at (row 1, column 1),\n> * Most production flatlines around 10:00am then begins to decrease at around 4:00pm, like the inverter located at (row 3, column 1).\n> * We see a slump in the AC power production for a few of the inverters where we would expect to see the highest production like inverter in (row 6, column 1).\n\n#### **Question**: Is the flatlining and slumping behaviour related to the age of the inverters?\n\n> * Just by quick visual inspection there does not seem to be any relationship, so no need to perform a statistical test.\n\n#### **Question**: What is causing the flatlining and slumping behaviour?\n\n> * **Assuming** that all inverters are collecting data correctly my best guess is that the solar panels themselves are not performing optimally, i.e. once they reach a certain AC power level they malfunction.\n\n### The same trend can be seen for **DC POWER** so I omit this.\n\n---"},{"metadata":{},"cell_type":"markdown","source":"## Inverter Malfunction\n\n#### Inspecting the **DAILY YIELD** for plant 2 over time,"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_inverter_vs_variable(inv2_date, 'DATE', 'DAILY_YIELD', 'PLANT 2')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> As you can see the inverters in:\n\n\n| row | column |\n|---|---|\n|5|1|\n|3|2|\n|3|3|\n|3|4|\n\n\n> have all stopped on 08/06/2020, 8 days before they should have. This can be noticed for the other variables as well, that is, AC_POWER & DC_POWER but I have omitted this.\n\n* **Assuming** that they have not been turned off purposefully we must assume that there has been a malfunction.\n---"},{"metadata":{},"cell_type":"markdown","source":"# Conditions\n\nNext, we analyse the weather sensor data to assess the conditions that the solar plants are operating under.\n\n## Ambient Temperature:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# This data uses average of values for each date\nwsd_date_data = [wsd_dd1, wsd_dd2]\nplot_variable_vs_x(wsd_date_data,'DATE', 'AMBIENT_TEMPERATURE', style='k-', bestfit=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> * The average ambient temperature at both plants is consistently decreasing from the 15th of May to the 16th of June.\n> * Plant 1 is located in a cooler region however the temperature at plant 2 is decreasing at a much more rapid pace.\n\n---"},{"metadata":{},"cell_type":"markdown","source":"## Module Temperature"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_variable_vs_x(wsd_date_data,'DATE', 'MODULE_TEMPERATURE', style='k-', bestfit=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> * Same trend in temperature over time for module temperature and ambient temperature.\n> * The (inverter) module temperature, on average, is about 6 degrees hotter than the surrounding ambient temperature.\n\n---"},{"metadata":{},"cell_type":"markdown","source":"## Irradiation"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_variable_vs_x(wsd_date_data,'DATE', 'IRRADIATION', style='k-', bestfit=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> * Irradiation levels for plant 1 are slowly decreasing over time but they are rapidly decreasing over time at plant 2.\n\n#### We conclude that plant 2 is located in an area with much harsher conditions, that is, more intense temperatures & irradiation values & also greater variance in temperature & irradiation than plant 1.\n---"},{"metadata":{},"cell_type":"markdown","source":"# Correlations\n\nAssessing the pearson correlation coefficient for each pair of numeric variables in the data."},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"# Combine all generator & weather sensor data\nall_data = combine_gd_wsd([gd_dt1,gd_dt2],[wsd_dt1,wsd_dt2])\n\n# Get correlations forall numeric variables\nmy_heat_map(all_data.loc[:, all_data.columns != 'PLANT_ID'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above heat map of correlations we obtain the following noteable results:\n\n|Relationship|Correlation co-eff|Variable 1|Variable 2|\n|---|---|---|---|\n|**Very strong positive**|0.95|Module Temperature|Irradiation|\n|**Very strong positive**|0.93|AC Power|Irradiation|\n|**Very strong positive**|0.9|AC Power|Module Temperature|\n|**Strong positive**|0.82|Ambient Temperature|Module Temperature|\n|**Moderate positive**|0.75|AC Power|DC Power|\n|**Mild positive**|0.65|Ambient Temperature|Irradiation|\n\n---\n\n# Concluding Thoughts:\n\n* We have discovered that plant 1 is younger and is more efficient than plant 2,\n* However, plant 2 seems to be located in a region with much harsher weather conditions, this along with the fact that it appears to be older than plant 1 will factor into the some-what unusual behaviour of it's inverters,\n* As the irradiation levels increase, we see an increase in the production of AC Power,\n* However with the increase in both irradiation or AC Power we also see an increase in module temperature which, over time, could degrade our equipment.\n\n\n#### The next stage will be to perform time-series analysis to try to predict future power production, however I will leave this to a seperate notebook.\n\n\n#### Thanks for reading, any constructive critism is gladly accepted. Hopefully this notebook is a bit different to the others you have read using this dataset!"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}