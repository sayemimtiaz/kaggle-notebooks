{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport ast\nfrom collections import Counter\nfrom collections import defaultdict\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport matplotlib.pyplot as plt\nimport matplotlib.axes as ax\nimport seaborn as sns\nimport math\n\nplt.style.use('ggplot')\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Import Datasets"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"ranking_df = pd.read_csv('../input/boardgamegeek-reviews/2019-05-02.csv')\nranking_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"review_df = pd.read_csv('../input/boardgamegeek-reviews/bgg-13m-reviews.csv', index_col=0)\nreview_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"detail_df = pd.read_csv('/kaggle/input/boardgamegeek-reviews/games_detailed_info.csv', index_col=0)\ndetail_df.iloc[:, :20].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"detail_df.iloc[:, 20:40].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"detail_df.iloc[:, 40:].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Repeated Columns Analysis\n\n- IDs are present for every table (join condition)\n- Ranking and game detail tables have published year, rank, average, bayes average, users rated and thumbnail columns\n- Looking at Kaggle, the dataset was last updated on 2nd June, and looking at the number of users rated, the game detailed info table looks more updated"},{"metadata":{"trusted":true},"cell_type":"code","source":"ranking_sub_df = ranking_df[['ID', 'Year', 'Rank', 'Average', 'Bayes average', 'Users rated', 'Thumbnail']]\nranking_sub_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"detail_sub_df = detail_df[['id', 'yearpublished', 'Board Game Rank', 'average', 'bayesaverage', 'usersrated', 'thumbnail']]\ndetail_sub_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"joined_df = ranking_sub_df.merge(detail_sub_df, left_on='ID', right_on='id', how='left')\njoined_df.head(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# View Columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"ranking_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"detail_df.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Extract Features"},{"metadata":{"trusted":true},"cell_type":"code","source":"output_df = detail_df.loc[: , ['averageweight', 'bayesaverage', 'description', 'id', 'image', \n                               'minage', 'minplayers', 'minplaytime', 'primary', 'thumbnail', \n                               'yearpublished']]\noutput_df.columns = ['complexity_score', 'bayes_average', 'description', 'id', 'image', \n                     'official_min_age', 'official_min_players', 'official_min_playtime', 'name', 'thumbnail', \n                     'year_published']\noutput_df.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create Features for Board Game Success\n- Success is determined by us as above the 75th percentile"},{"metadata":{"trusted":true},"cell_type":"code","source":"third_quartile = np.percentile(detail_df['bayesaverage'], [75])\n\nprint('3rd Quartile:', third_quartile)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output_df['is_success'] = detail_df['bayesaverage'].apply(lambda x, threshold: 1 if x > third_quartile else 0, args=[third_quartile])\noutput_df['is_success'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output_df.columns[-1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Engineering for Average Weight (Complexity of Game)"},{"metadata":{},"cell_type":"markdown","source":"# Success Rates Feature Creation for Artist, Designer and Publisher\n\nBoard Game Artist, Designer and Publisher success rates for each board game\n\nComputed as $\\frac{\\text{Number of successful board games}}{\\text{Number of board games}}$"},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_names(name_lst):\n    # Catch NaN\n    if type(name_lst) is float:\n        return []\n    # Convert to list\n    if type(name_lst) is str:\n        name_lst = ast.literal_eval(name_lst)\n    # Trim white space\n    for idx, name in enumerate(name_lst):\n        name_lst[idx] = name.strip()\n    # Remove duplicates\n    return list(set(name_lst))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def calculate_rate(name_lst, success_count_dict, overall_count_dict):\n    success_count = 0\n    total_count = 0\n    for name in name_lst:\n        success_count += success_count_dict[name]\n        total_count += overall_count_dict[name]\n    if total_count == 0:\n        return 0\n    return success_count / total_count","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Text cleaning\ndetail_df['boardgameartist'] = detail_df['boardgameartist'].apply(clean_names)\n\n# Filter success rows\nsub_df = detail_df.loc[output_df['is_success'] == 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"success_count_dict = Counter(sub_df['boardgameartist'].sum())\noverall_count_dict = Counter(detail_df['boardgameartist'].sum())\n\nprint(success_count_dict.most_common(10))\nprint()\nprint(overall_count_dict.most_common(10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output_df['artist_success_rate'] = detail_df['boardgameartist'].apply(calculate_rate, \n                                                                      args=[success_count_dict, overall_count_dict])\noutput_df['artist_success_rate'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.violinplot(output_df['artist_success_rate'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Text cleaning\ndetail_df['boardgamedesigner'] = detail_df['boardgamedesigner'].apply(clean_names)\n\n# Filter success rows\nsub_df = detail_df.loc[output_df['is_success'] == 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"success_count_dict = Counter(sub_df['boardgamedesigner'].sum())\noverall_count_dict = Counter(detail_df['boardgamedesigner'].sum())\n\nprint(success_count_dict.most_common(10))\nprint()\nprint(overall_count_dict.most_common(10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output_df['designer_success_rate'] = detail_df['boardgamedesigner'].apply(calculate_rate, \n                                                                          args=[success_count_dict, overall_count_dict])\noutput_df['designer_success_rate'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.violinplot(output_df['designer_success_rate'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Text cleaning\ndetail_df['boardgamepublisher'] = detail_df['boardgamepublisher'].apply(clean_names)\n\n# Filter success rows\nsub_df = detail_df.loc[output_df['is_success'] == 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"success_count_dict = Counter(sub_df['boardgamepublisher'].sum())\noverall_count_dict = Counter(detail_df['boardgamepublisher'].sum())\n\nprint(success_count_dict.most_common(10))\nprint()\nprint(overall_count_dict.most_common(10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output_df['publisher_success_rate'] = detail_df['boardgamepublisher'].apply(calculate_rate, \n                                                                               args=[success_count_dict, overall_count_dict])\noutput_df['publisher_success_rate'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.violinplot(output_df['publisher_success_rate'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output_df.columns[-3:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# One-Hot Encode Board Game Category"},{"metadata":{"trusted":true},"cell_type":"code","source":"detail_df['boardgamecategory'] = detail_df['boardgamecategory'].replace(np.nan, '[]')\nvectorizer = CountVectorizer(tokenizer=ast.literal_eval, lowercase=True, binary = True)\ndummies_df = pd.DataFrame(vectorizer.fit_transform(detail_df['boardgamecategory']).toarray(), \n                          columns=vectorizer.get_feature_names())\ndummies_df.columns = ['category_' + col_name.replace(' ', '_') for col_name in dummies_df.columns]\n\ndummies_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output_df.shape, dummies_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output_df = pd.concat([output_df, dummies_df], axis=1)\noutput_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output_df.columns[-83:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# One-Hot Encode Board Game Mechanic"},{"metadata":{"trusted":true},"cell_type":"code","source":"detail_df['boardgamemechanic'] = detail_df['boardgamemechanic'].replace(np.nan, '[]')\nvectorizer = CountVectorizer(tokenizer=ast.literal_eval, lowercase=True, binary = True)\ndummies_df = pd.DataFrame(vectorizer.fit_transform(detail_df['boardgamemechanic']).toarray(), \n                          columns=vectorizer.get_feature_names())\ndummies_df.columns = ['mechanic_' + col_name.replace(' ', '_') for col_name in dummies_df.columns]\n\ndummies_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output_df.shape, dummies_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output_df = pd.concat([output_df, dummies_df], axis=1)\noutput_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output_df.columns[-53:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Categorise Max Players\n\n- Very right skewed distribution\n- 90th percentile for max players is 8 - likely \"safe\" to categorise 8+ max players as 8"},{"metadata":{"trusted":true},"cell_type":"code","source":"detail_df['maxplayers'].plot(kind='hist')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.percentile(detail_df['maxplayers'], [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Trying out pd.cut()\npd.cut([1, 2, 3, 4, 5, 6, 7, 8, 9], bins=[0, 1, 2, 3, 4, 5, 6, 7, 100], labels=['1', '2', '3', '4', '5', '6', '7', '8'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Max Players\n# maxplayers_arr = detail_df['maxplayers'].values.tolist()\n# # maxplayers_arr\n# for i in range(len(maxplayers_arr)):\n#     numplayers = maxplayers_arr[i]\n#     if (numplayers >= 8):\n#         maxplayers_arr[i] = \"8+\"\n#     else:\n#         maxplayers_arr[i] = str(numplayers)\n# newfeature_df['new_maxplayers'] = maxplayers_arr\n# dummydf_mpy = newfeature_df['new_maxplayers'].str.join(sep='').str.get_dummies()\n# newfeature_df = pd.concat([newfeature_df, dummydf_mpy], axis=1, join='inner')\n# print(newfeature_df)\n\n# label = 8 is for 8+\noutput_df['official_max_players_categorised'] = pd.cut(detail_df['maxplayers'], \n                                                       bins=[detail_df['maxplayers'].min()-1, 1, 2, 3, 4, 5, 6, 7, detail_df['maxplayers'].max()+1], \n                                                       labels=['1', '2', '3', '4', '5', '6', '7', '8'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output_df.columns[-1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Categorise Max Playtime"},{"metadata":{"trusted":true},"cell_type":"code","source":"# maxplaytime_arr = detail_df['maxplaytime'].values.tolist()\n# df = pd.DataFrame()\n# df['new_maxplaytime'] = maxplaytime_arr\n# df\n\n# df['num'] = 1\n# df1 = df.groupby('new_maxplaytime').count()\n# filter1 = df1['num'] > (0.01*17000)\n# temp = df1.where(filter1).dropna()\n# # temp2 = df1.where(filter2)\n# print(temp)\n\n# for i in range(len(maxplaytime_arr)):\n#     playtime = int(maxplaytime_arr[i])\n    \n#     if (playtime <= 30):\n#         maxplaytime_arr[i] = 1\n#     elif (playtime > 30 and playtime <= 60):\n#         maxplaytime_arr[i] = 2\n#     elif (playtime > 60 and playtime <= 120):\n#         maxplaytime_arr[i] = 3\n#     elif (playtime > 120 and playtime <= 180):\n#         maxplaytime_arr[i] = 4\n#     elif (playtime > 180):\n#         maxplaytime_arr[i] = 5\n\n# newfeature_df['new_maxplaytime'] = maxplaytime_arr\n# newfeature_df\n\noutput_df['official_max_playtime_categorised'] = pd.cut(detail_df['maxplaytime'], \n                                                        bins=[detail_df['maxplaytime'].min()-1, \n                                                              30, 60, 120, 180, \n                                                              detail_df['maxplaytime'].max()+1], \n                                                        labels=['1', '2', '3', '4', '5'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output_df.columns[-1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Average Suggested Language Dependence\n\n- Scores are given to the language dependence\n    - 1 : No necessary in-game text\n    - 2 : Some necessary text - easily memorized or small crib sheet\n    - 3 : Moderate in-game text - needs crib sheet or paste ups\n    - 4 : Extensive use of text - massive conversion needed to be playable\n    - 5 : Unplayable in another language"},{"metadata":{"trusted":true},"cell_type":"code","source":"# View one of the values\ndetail_df['suggested_language_dependence'][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def eval_ordered_dict(str_list):\n    if isinstance(str_list, str):\n        str_list = str_list.replace(\"OrderedDict\",\"\")\n        return ast.literal_eval(str_list)\n    return list()\n\ndef get_suggested_language_dependence(lst):\n    if len(lst) == 0:\n        return np.nan\n    dictionary = defaultdict(None)\n    for idx, l in enumerate(lst):\n        dictionary[idx+1] = int(l[2][1])\n    dependences, votes = list(zip(*dictionary.items()))\n    return np.sum(np.array(dependences) * np.array(votes)) / np.sum(votes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output_df['suggested_language_dependence_mean'] = detail_df['suggested_language_dependence'] \\\n                                                            .apply(eval_ordered_dict) \\\n                                                            .apply(get_suggested_language_dependence)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output_df['suggested_language_dependence_mean'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 4k NaN values: Continuous variable - fill NA with mean\nsuggested_language_dependence_mean = output_df['suggested_language_dependence_mean'].mean()\nprint('Suggested Language Dependence Mean:', suggested_language_dependence_mean)\n\noutput_df['suggested_language_dependence_mean'] = output_df['suggested_language_dependence_mean'].fillna(suggested_language_dependence_mean)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"detail_df['suggested_language_dependence'].isna().sum(), output_df['suggested_language_dependence_mean'].isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output_df.columns[-1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Weighted Average Suggested Num Players\n\nSum product of the number of players and the number of votes\n\nAverage sum product with the total number of votes for each number of players\n\nGet the mean of the weighted averages"},{"metadata":{"trusted":true},"cell_type":"code","source":"# View one of the values\ndetail_df['suggested_num_players'][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_suggested_num_players(str_list_SNP):\n    iter_count = 0\n    snp_df = pd.DataFrame()\n    snp_dict = {\"suggested_num_players_feat\":[]}\n    \n    for items in str_list_SNP:\n        list_SNP = eval_ordered_dict(items)\n        final_dict = {}\n        if isinstance(list_SNP[0],list):\n            for tup in list_SNP:\n                try:\n                    num_players = float(tup[0][1])\n                except:\n                    num_players = float(tup[0][1][0]) + 1\n                result_list = tup[1][1]\n                best_votes = result_list[0][1][1]\n                rec_votes = result_list[1][1][1]\n                not_rec_votes = result_list[2][1][1]\n                if final_dict and final_dict[\"id\"] == detail_df.iloc[iter_count][\"id\"]:\n                    n_votes = int(best_votes) + int(rec_votes) + int(not_rec_votes)\n                    if n_votes == 0:\n                        weighted_average = None\n                    else:\n                        weighted_average = float((int(best_votes)*2 + int(rec_votes) + int(not_rec_votes)*(-1))/n_votes)\n                    if weighted_average and final_dict[\"votes_weighted_average\"][0]:\n                        if weighted_average == final_dict[\"votes_weighted_average\"][0]:\n                            final_dict[\"votes_weighted_average\"].append(weighted_average)\n                            final_dict[\"num_players\"].append(num_players)\n                        elif final_dict[\"votes_weighted_average\"][0] < weighted_average:\n                            final_dict[\"votes_weighted_average\"] = [weighted_average]\n                            final_dict[\"num_players\"] = [num_players]\n                    elif weighted_average:\n                        final_dict[\"votes_weighted_average\"] = [weighted_average]\n                        final_dict[\"num_players\"] = [num_players]\n                else:\n                    final_dict[\"id\"] = detail_df.iloc[iter_count][\"id\"]\n                    final_dict[\"num_players\"] = [num_players]\n                    n_votes = int(best_votes) + int(rec_votes) + int(not_rec_votes)\n                    if n_votes != 0:\n                        final_dict[\"votes_weighted_average\"] = [(int(best_votes)*2 + int(rec_votes) + int(not_rec_votes)*(-1))/n_votes]\n                    else:\n                        final_dict[\"votes_weighted_average\"] = [None]\n        else:\n            if len(list_SNP)==2:\n                try:\n                    num_players = float(list_SNP[0][1])\n                except:\n                    num_players = float(list_SNP[0][1][0]) + 1\n                best_votes = int(list_SNP[1][1][0][1][1])\n                rec_votes = int(list_SNP[1][1][1][1][1])\n                not_rec_votes = int(list_SNP[1][1][2][1][1])\n                if final_dict and final_dict[\"id\"] == detail_df.iloc[iter_count][\"id\"]:\n                    n_votes = best_votes + rec_votes + not_rec_votes\n                    if n_votes == 0:\n                        weighted_average = None\n                    else:\n                        weighted_average = float((int(best_votes)*2 + int(rec_votes) + int(not_rec_votes)*(-1))/n_votes)\n                    if weighted_average == final_dict[\"votes_weighted_average\"][0]:\n                        if weighted_average in final_dict[\"votes_weighted_average\"]:\n                            final_dict[\"num_players\"].append(num_players)\n                            final_dict[\"votes_weighted_average\"].append(weighted_average)\n                        elif final_dict[\"votes_weighted_average\"][0] < weighted_average:\n                            final_dict[\"votes_weighted_average\"] = [weighted_average]\n                            final_dict[\"num_players\"] = [num_players]\n                    elif weighted_average:\n                        final_dict[\"votes_weighted_average\"] = [weighted_average]\n                        final_dict[\"num_players\"] = [num_players]\n                    else:\n                        final_dict[\"votes_weighted_average\"].append(weighted_average)\n                        final_dict[\"num_players\"].append(num_players)\n                else:\n                    final_dict[\"id\"] = detail_df.iloc[iter_count][\"id\"]\n                    final_dict[\"num_players\"] = [num_players]\n                    n_votes = int(best_votes) + int(rec_votes) + int(not_rec_votes)\n                    if n_votes != 0:\n                        final_dict[\"votes_weighted_average\"] = [(int(best_votes)*2 + int(rec_votes) + int(not_rec_votes)*(-1))/n_votes]\n                    else:\n                        final_dict[\"num_players\"] = [None]\n                        final_dict[\"votes_weighted_average\"] = [None]\n            else:\n                final_dict[\"id\"] = detail_df.iloc[iter_count][\"id\"]\n                try:\n                    num_players = float(list_SNP[0][1])\n                except:\n                    num_players = float(list_SNP[0][1][0]) + 1\n                final_dict[\"num_players\"] = [None]\n                final_dict[\"votes_weighted_average\"] = [None]\n        iter_count += 1\n        num_players = final_dict[\"num_players\"]\n        votes_weighted_average = final_dict[\"votes_weighted_average\"]\n        if len(num_players) > 1 and len(votes_weighted_average) > 1:\n            counter = 0\n            for val in votes_weighted_average:\n                if val == None or val == 0.0:\n                    del num_players[counter]\n                    votes_weighted_average.remove(val)\n                else:\n                    counter+=1\n            final_dict[\"num_players\"] = num_players\n            final_dict[\"votes_weighted_average\"] = votes_weighted_average\n        elif not votes_weighted_average[0]:\n            final_dict[\"num_players\"] = [None]\n        if final_dict[\"num_players\"][0]:\n            final_dict[\"mean_num_players\"] = np.mean(final_dict[\"num_players\"])\n            final_dict[\"mean_votes_weighted_average\"] = np.mean(final_dict[\"votes_weighted_average\"])\n        else:\n            final_dict[\"mean_num_players\"] = None\n            final_dict[\"mean_votes_weighted_average\"] = None\n        snp_dict[\"suggested_num_players_feat\"].append(final_dict)\n    return snp_dict\n\nsnp_dict = get_suggested_num_players(detail_df['suggested_num_players'])\nsugg_num_players_df = pd.DataFrame(snp_dict[\"suggested_num_players_feat\"])\nsugg_num_players_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output_df['suggested_num_players_weighted_average'] = sugg_num_players_df['mean_num_players']\n\n# Free memory\ndel sugg_num_players_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"detail_df['suggested_num_players'].isna().sum(), output_df['suggested_num_players_weighted_average'].isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Normalise suggested players wrt min/max players: >0.5 suggested closer to max. <0.5 suggested closer to min\nnumerator = (output_df['suggested_num_players_weighted_average'] - output_df['official_min_players']).mean()\ndenominator = (output_df['official_max_players_categorised'].astype(float) - output_df['official_min_players']).mean()\npercentile_from_suggested_min_players = numerator/denominator\nprint('Percentile from suggested min players', percentile_from_suggested_min_players)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# if min max player info available, take midpoint round up\nminmax_avg = output_df['official_min_players'] + \\\n                (output_df['official_max_players_categorised'].astype(float) - output_df['official_min_players']) * \\\n                percentile_from_suggested_min_players\nminmax_avg = minmax_avg.apply(round)\n\n# if NaN then fill with above values\noutput_df['suggested_num_players_weighted_average'] = output_df['suggested_num_players_weighted_average'].fillna(minmax_avg)\noutput_df['suggested_num_players_weighted_average'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"detail_df['suggested_num_players'].isna().sum(), output_df['suggested_num_players_weighted_average'].isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output_df.columns[-1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Average Suggested Player Age"},{"metadata":{"trusted":true},"cell_type":"code","source":"# View one of the values\ndetail_df['suggested_playerage'][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_suggested_playerage(str_list_SPA):\n    spa_df = pd.DataFrame()\n    counter = 0\n    for items in str_list_SPA:\n        new_df = {}\n        new_df[\"id\"] = detail_df[\"id\"].iloc[counter]\n        if isinstance(items,str):\n            list_SPA = eval_ordered_dict(items)\n            new_df[\"2\"] = int(list_SPA[0][1][1])\n            new_df[\"3\"] = int(list_SPA[1][1][1])\n            new_df[\"4\"] = int(list_SPA[2][1][1])\n            new_df[\"5\"] = int(list_SPA[3][1][1])\n            new_df[\"6\"] = int(list_SPA[4][1][1])\n            new_df[\"8\"] = int(list_SPA[5][1][1])\n            new_df[\"10\"] = int(list_SPA[6][1][1])\n            new_df[\"12\"] = int(list_SPA[7][1][1])\n            new_df[\"14\"] = int(list_SPA[8][1][1])\n            new_df[\"16\"] = int(list_SPA[9][1][1])\n            new_df[\"18\"] = int(list_SPA[10][1][1])\n            new_df[\"21+\"] = int(list_SPA[11][1][1])\n        else:\n            new_df[\"2\"] = None\n            new_df[\"3\"] = None\n            new_df[\"4\"] = None\n            new_df[\"5\"] = None\n            new_df[\"6\"] = None\n            new_df[\"8\"] = None\n            new_df[\"10\"] = None\n            new_df[\"12\"] = None\n            new_df[\"14\"] = None\n            new_df[\"16\"] = None\n            new_df[\"18\"] = None\n            new_df[\"21+\"] = None\n        counter += 1       \n\n        spa_df = spa_df.append(new_df,ignore_index=True)\n    return spa_df\n\nspa_df = get_suggested_playerage(detail_df['suggested_playerage'])\nspa_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"spa_df[\"n\"] = spa_df[['2', '3', '4', '5', '6', '8', '10', '12', '14', '16', '18', '21+']].sum(axis=1)\nspa_df[\"total_n\"] = (spa_df[\"2\"]*2 + \n                     spa_df[\"3\"]*3 + \n                     spa_df[\"4\"]*4 + \n                     spa_df[\"5\"]*5 + \n                     spa_df[\"6\"]*6 + \n                     spa_df[\"8\"]*8 + \n                     spa_df[\"10\"]*10 + \n                     spa_df[\"12\"]*12 + \n                     spa_df[\"14\"]*14 + \n                     spa_df[\"16\"]*16 + \n                     spa_df[\"18\"]*18 + \n                     spa_df[\"21+\"]*21)\nspa_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output_df[\"suggested_player_age_mean\"] = spa_df.apply(lambda r : r[\"total_n\"]/r[\"n\"] if r[\"n\"] > 0 else None, axis=1)\n\n# Free memory\ndel spa_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# if NaN then just use the official value\noutput_df['suggested_player_age_mean'] = output_df['suggested_player_age_mean'].fillna(detail_df['minage'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"detail_df['suggested_playerage'].isna().sum(), output_df[\"suggested_player_age_mean\"].isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output_df.columns[-1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Check and Reorder Columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check rows for NA\noutput_df.isna().sum().loc[output_df.isna().sum() > 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = list(filter(lambda col_name: not col_name.startswith('category_') and \n                      not col_name.startswith('mechanic_'), output_df.columns)) + \\\n            list(filter(lambda col_name: col_name.startswith('category_'), output_df.columns)) + \\\n            list(filter(lambda col_name: col_name.startswith('mechanic_'), output_df.columns))\ncolumns[:5], columns[-5:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output_df.columns = columns\noutput_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Write CSV"},{"metadata":{"trusted":true},"cell_type":"code","source":"output_df.to_csv('cleaned_games_detailed_info.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":1}