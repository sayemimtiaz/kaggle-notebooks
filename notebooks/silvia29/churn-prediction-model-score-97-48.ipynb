{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Predict whether a customer will churn or not :\nCustomer churning or attrition in banking is when the customer no longer using the bank's credit cards. In this notebook the tasks covered are:\n\n1. Data Visualisation of features\n2. Data Cleaning and Preprocessing\n3. Applying models(KNN,Random Forest,SVC,RandomForest etc) and choosing the model with best model score\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First,let's look at the top 5 rows of the data."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data=pd.read_csv('/kaggle/input/credit-card-customers/BankChurners.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We notice we do not require the column that has client id (CLIENTNUM)in our analysis and prediction so let's drop it.The last two columns are also unnecessary so dropping it."},{"metadata":{"trusted":true},"cell_type":"code","source":"data=data.drop(['CLIENTNUM'],axis=1)\ndata = data.drop(['Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1'], axis=1)\ndata = data.drop(['Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2'], axis=1)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Visualisation\n \nSince our target column is 'Attrition_Flag',we will firstly see the percentage of Existing and attrited Customer."},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\ncount=pd.value_counts(data['Attrition_Flag']).tolist()\nplt.figure(figsize=(11,11))\nplt.title(\"Percentage of Attrited Customer and Existing Customer\")\nplt.pie(x=count,labels=[\"Attrited Customer\",\"Existing Customers\"],autopct='%.2f%%')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It turns out that the **ratio is highly imbalanced**.Attrited customers account to much higher percentage of the total data. \n\nLet's check with respect to the **genders- male and female** ."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2)=plt.subplots(1,2,figsize=(15,15))\n\nattrited_gender = data.loc[data[\"Attrition_Flag\"] == \"Attrited Customer\", [\"Gender\"]].value_counts().tolist()\nax1.pie(x=attrited_gender,labels=[\"Male\",\"Female\"],autopct='%.2f%%')\nax1.set_title('Gender vs Attrited Customer')\n\nexisting_gender=data.loc[data[\"Attrition_Flag\"] == \"Existing Customer\", [\"Gender\"]].value_counts().tolist()\nax2.pie(x=existing_gender,labels=[\"Male\",\"Female\"],autopct='%.2f%%')\nax2.set_title('Gender vs Existing Customer')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In both the cases,the male to female ratio is **almost same and comparable.** "},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nplt.figure(figsize=(28,11))\nplt.title(\"Distribution of Age with respect to Churned or not\")\nsns.countplot(data=data,x=data[\"Customer_Age\"],hue=\"Attrition_Flag\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The distribution of age is clearly a **Gaussian distribution** meaning that most of the data are clustered around the mean value. \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(2, 2, figsize=(15, 15), sharey=True)\nfig.suptitle('Group by Attrition Flag')\nsns.countplot(x=\"Gender\", hue = \"Attrition_Flag\",  data=data, ax=axes[0,0], palette=\"Set2\")\naxes[0,0].set_title(\"GENDER & ATTRITION FLAG\")\n\nsns.countplot(x=\"Income_Category\", hue = \"Attrition_Flag\",  data=data, ax=axes[0,1], palette=\"Set2\",order=data[\"Income_Category\"].value_counts().index)\naxes[0,1].set_title(\"INCOME CATEGORY & ATTRITION FLAG\")\n\nsns.countplot(x=\"Education_Level\", hue = \"Attrition_Flag\",  data=data, ax=axes[1,0], palette=\"Set1\",order=data[\"Education_Level\"].value_counts().index)\naxes[1,0].set_title(\"EDUCATION LEVEL & ATTRITION FLAG\")\n\nsns.countplot(x=\"Card_Category\", hue = \"Attrition_Flag\",  data=data, ax=axes[1,1], palette=\"Set1\",order=data[\"Card_Category\"].value_counts().index)\naxes[1,1].set_title(\"CARD CATEGORY & ATTRITION FLAG\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Correlation using heatmap \n\nIn a visually appealing way,correlation heatmaps show which variables are correlated, to what degree and in which direction. "},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax=plt.subplots(figsize=(10,10))\nsns.heatmap(data.corr(),annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the heatmap,it can be seen that the columns **'Avg_Open_To_Buy' and 'Credit_Limit','Total_Revolving_Bal' and 'Avg_Utilization_Ratio', 'Months_on_book' and 'Customer_Age**'are highly correlated**(value of 1)**."},{"metadata":{},"cell_type":"markdown","source":"We check if there are any null values in the dataframe."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().any()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Checking for Outliers and removing them\n\nUsing a **boxplot** it is easy to visualize whether there are any outliers in the data or not.The outliers for the column\"Total_Ct_Chng_Q4_Q1\" can seen for example. \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nsns.boxplot(x=data['Total_Ct_Chng_Q4_Q1'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It can be seen from the plot that the values above 3 are much farther than the mean and we consider them as outliers. "},{"metadata":{},"cell_type":"markdown","source":"# Removing Outlier\n\nUsing the **concept of z-score** it is possible to check for outliers in the columns. We set a particular threshold(3 in this case) and then remove those values which have a z-score less than 3."},{"metadata":{"trusted":true},"cell_type":"code","source":"#outlier cleanup\nfrom scipy import stats\nimport numpy as np\ncolumns = [\"Customer_Age\", 'Dependent_count', 'Months_on_book',\n       'Total_Relationship_Count', 'Months_Inactive_12_mon',\n       'Contacts_Count_12_mon', 'Credit_Limit', 'Total_Revolving_Bal',\n       'Avg_Open_To_Buy', 'Total_Amt_Chng_Q4_Q1', 'Total_Trans_Amt',\n       'Total_Trans_Ct', 'Total_Ct_Chng_Q4_Q1', 'Avg_Utilization_Ratio']\nprint(data.shape)\nfor column in columns : \n    z = np.abs(stats.zscore(data[column]))\n    data=data[(z < 3)]\nprint(data.shape)\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After removing outliers the size of the data frame is **(9317,20)** ie reduced from (10127,20) of the original data."},{"metadata":{"trusted":true},"cell_type":"code","source":"#boxplot after removing outlier\nimport seaborn as sns\nsns.boxplot(x=data['Total_Ct_Chng_Q4_Q1'],palette=[sns.xkcd_rgb[\"pale red\"]])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since the target column for prediction is \"Attrition_Flag\" we can drop that from the dataframe and seperate it. "},{"metadata":{"trusted":true},"cell_type":"code","source":"X=data.drop(\"Attrition_Flag\",axis=1)\nY=data[\"Attrition_Flag\"]\nY.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Preprocessing \n\nSince we require **numerical values** for the predictive model ,the categorical columns need to be transformed. Hence **label encoding** is done."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\ncategorical_col =['Gender','Education_Level', 'Marital_Status', 'Income_Category', 'Card_Category']\nfor cols in categorical_col :\n    le=LabelEncoder()\n    X[cols]=le.fit_transform(X[cols])\nY=le.fit_transform(Y)\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prediction Part \n\nWe split the data into train and test data.The predictive models are then applied and checked which one has the best model score. Consequently,we choose the model with the best score. The **model score**,the **cross validation score** and the **ROC-AUC** scores are calculated."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\nX_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold, GridSearchCV\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix, make_scorer, recall_score\nfrom sklearn.metrics import roc_auc_score\nfrom xgboost.sklearn import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import LinearSVC, SVC\n\nclassifiers = [[XGBClassifier(),'XGB Classifier'], [RandomForestClassifier(),'Random Forest'], \n    [KNeighborsClassifier(), 'K-Nearest Neighbours'], [SGDClassifier(),'SGD Classifier'], [SVC(),'SVC']]\nscore_list=[]\nroc_auc_list=[]\ncross_val_list=[]\n\nfor classifier in classifiers :\n    model=classifier[0]\n    model.fit(X_train,Y_train)\n    model_name=classifier[1]\n    prediction=model.predict(X_test)\n    \n    scores=model.score(X_test,Y_test)\n    cross_val=cross_val_score(model,X_test,Y_test).mean()\n    roc_auc = roc_auc_score(Y_test, prediction)\n    \n    score_list.append(scores)\n    cross_val_list.append(cross_val)\n    roc_auc_list.append(roc_auc)\n    \n    print(model_name,\"Score :\"+str(round(scores*100,2))+'%')\n    print(model_name,\"Cross Validation Score :\"+str(round(cross_val*100,2))+'%')\n    print(model_name,\"ROC AUC score:\"+str(round(roc_auc*100,2))+'%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Best Score :\n\nFrom the above output,it can be seen that **XGBoost** performs the best with a model score of **97.48%**. The **Random Forest classifier** also performs comparably well with a score of **96.41**. \n\nSo we use XGBoost and plot the confusion matrix for this model's prediction."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import plot_confusion_matrix\n\nmodel = XGBClassifier()\nmodel.fit(X_train, Y_train)\npred = model.predict(X_test)\nplot_confusion_matrix(model, X_test, Y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I hope this notebook was useful for Kaggle learners. I appreciate every feedback and if you think my code can be improved better please suggest me so in the comment. "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}