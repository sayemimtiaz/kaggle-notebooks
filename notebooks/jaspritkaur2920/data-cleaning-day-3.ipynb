{"cells":[{"metadata":{},"cell_type":"markdown","source":"# 5 Days of Data cleaning challenge.\n\n## Day 3 : Parsing dates\n\nHere's what we're going to do today:\n\n* [Get our environment set up](#1)\n* [Check the data type of our date column](#2)\n* [Convert our date columns to datetime](#3)\n* [Select just the day of the month from our column](#4)\n* [Plot the day of the month to check the date parsing](#5)\n\nLet's get started!\n\n* [Data for Landslides after rainfall](https://www.kaggle.com/nasa/landslide-events)\n* [Data for significant earthquakes](https://www.kaggle.com/usgs/earthquake-database)"},{"metadata":{},"cell_type":"markdown","source":"## Get our environment setup<a id=\"1\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport datetime\nimport numpy as np # linear algebra\nimport pandas as pd # data processing\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nnp.random.seed(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# importing data\nlandslides = pd.read_csv(\"/kaggle/input/landslide-events/catalog.csv\")\nearthquakes = pd.read_csv(\"/kaggle/input/earthquake-database/database.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# first look at landslides dataset\nprint(landslides.columns)\nlandslides.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# first look at earthquakes dataset\nprint(earthquakes.columns)\nearthquakes.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Check the date type of our date column<a id=\"2\"></a>\nLet's work with the `date` column from the `landslides` dataframe. The very first thing I'm going to do is take a peek at the first few rows to make sure it actually looks like it contains dates."},{"metadata":{"trusted":true},"cell_type":"code","source":"# for landslides\n\n# print the first few rows of the date column\nprint(landslides['date'].head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Yep, those are the dates! But just because I, a human, can tell that these are dates doesn't mean that python knows that they're dates. Notice that the bottom of the output of `head()`, you can see it says that the data type of this column is \"object\"\n\nPandas uses the \"object\" dtype for storing various types of data types, but most often when you see a column with the dtype \"object\" it will have strings in it.\n\nIf you check the pandas dtype documentation [here](https://pandas.pydata.org/pandas-docs/stable/getting_started/basics.html), you'll notice that there's also a specific datetime64 dtypes. Because the dtype of our column is object rather than datetime64, we can tell that Python doesn't know that this column contains dates.\n\nWe can also look at just the dtype of your column without printing the first few rows if we like:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# check the data type for date column\nlandslides['date'].dtype","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now , Let's see the date column from the `earthquakes` dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"# for earthquakes\n\n# print the first few rows of the date column\nprint(earthquakes['Date'].head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Check the date column to datetime<a id=\"3\"></a>\nNow that we know that our date column isn't being recognize as a date, it's time to convert it so that it is recognized as a date. This is called \"parsing dates\" because we're taking in a string and identifying it's component parts.\n\nWe can use oandas for the format of our dates with a guide called as [strftime directive](https://strftime.org/). The basic idea is that you need to point which parts of the date are where and what punctuation is between them. There are lots of possible paths of date, but the most comman are `%d` for date, `%m` for month, `%y` for a two-digit year and `%Y` for four-digit year.\n\nSome examples:\n\n* 1/17/07 has the format \"%m/%d/%y\"\n* 17-1-2007 has the format \"%d-%m-%Y\"\n\nLooking back up at the head of the date column in the `landslides` dataset, we can see that it's in the format \"month/day/two-digit year\", so we can use the same syntax as the first example to parse in our dates:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# for landslides \n\n# create a new column, date_parsed, with the parsed dates\nlandslides['date_parsed'] = pd.to_datetime(landslides['date'], format = \"%m/%d/%y\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now when I check the first few rows of the new column, I can see that the dtype is `datetime64`. I can also see that my dates have been slightly rearranged so that they fit the default order datetime objects (year-month-day)."},{"metadata":{"trusted":true},"cell_type":"code","source":"# print the first few rows\nlandslides['date_parsed'].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now that our dates are parsed correctly, we can interact with them in useful ways.\n\n* **What if I run into an error with multiple date formats?** While we're specifying the date format here, sometimes you'll run into an error when there are multiple date formats in a single column. If that happens, you have have pandas try to infer what the right date format should be. You can do that like so:\n\nlandslides['date_parsed'] = pd.to_datetime(landslides['Date'], infer_datetime_format=True)\n\n* **Why don't you always use infer_datetime_format = True?** There are two big reasons not to always have pandas guess the time format. The first is that pandas won't always been able to figure out the correct date format, especially if someone has gotten creative with data entry. The second is that it's much slower than specifying the exact format of the dates.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# for earthquake\n\n# create a new column, date_parsed, with the parsed dates\n\nearthquakes[\"date_parsed\"] = pd.to_datetime(earthquakes[\"Date\"], format=\"%m/%d/%Y\", errors=\"coerce\")\n\ninvalid_date_index = earthquakes[\"date_parsed\"][earthquakes[\"date_parsed\"].isnull() == True].index.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print the first few rows\nearthquakes['date_parsed'].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Select just the day of the month from our column<a id=\"4\"></a>\nLet's try to get information on the day of the month that a landslide occured on from the original \"date\" column, which has an \"object\" dtype:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# for landslides\n\n# try to get the day of the month from the date column\nday_of_month_landslides = landslides['date'].dt.day","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We got an error! The important part to look at here is the part at the very end that says `AttributeError: Can only use .dt accessor with datetimelike values`. We're getting this error because the dt.day() function doesn't know how to deal with a column with the dtype \"object\". Even though our dataframe has dates in it, because they haven't been parsed we can't interact with them in a useful way.\n\nLuckily, we have a column that we parsed earlier , and that lets us get the day of the month out no problem:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# for landslides\n\n# get the day of the month from the date_parsed column \nday_of_month_landslides = landslides['date_parsed'].dt.day\nday_of_month_landslides.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for earthquakes\n\n# get the day of the month from the date_parsed column \nday_of_month_earthquakes = earthquakes['date_parsed'].dt.day\nday_of_month_earthquakes.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plot the day of the month to check the date parsing<a id=\"5\"></a>\nOne of the biggest dangers in parsing dates is mixing up the months and days. The to_datetime() function does have very helpful error messages, but it doesn't hurt to double-check that the days of the month we've extracted make sense.\n\nTo do this, let's plot a histogram of the days of the month. We expect it to have values between 1 and 31 and, since there's no reason to suppose the landslides are more common on some days of the month than others, a relatively even distribution. (With a dip on 31 because not all months have 31 days.) Let's see if that's the case:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# for landslides\n\n# remove na's\nday_of_month_landslides = day_of_month_landslides.dropna()\n\n# plot the day of the month\nsns.distplot(day_of_month_landslides, kde = False, bins = 31)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Yep, it looks like we did parse our dates correctly & this graph makes good sense to me. Why don't you take a turn checking the dates you parsed earlier?"},{"metadata":{"trusted":true},"cell_type":"code","source":"# for earthquakes\n\n#remove na's\nday_of_month_earthquakes = day_of_month_earthquakes.dropna()\n\n# plot the day of the month\nsns.distplot(day_of_month_earthquakes, kde = False, bins = 31)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}