{"cells":[{"metadata":{},"cell_type":"markdown","source":"### IMPORTANT: Run the below cell once, then go to \"Run -> Restart & clear cell outputs\" before proceeding further"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pandas==1.1.5\n!pip install numpy==1.18.5\n\nfrom IPython.core.display import HTML\nHTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Extracting Shopper Insights using Python & Pandas\n\n### We shall explore & mine an eCommerce store's sales data to understand how to perform data manipulation, extract findings & patterns from the data using Python, Numpy & Pandas. We shall also showcase results using charting modules - Seaborn & Matplotlib, for conveying our results. \n\n### The data spans 5 lac entries across an year, for a UK based retailer. \n\n### The learners would get a walk-through & understanding of basic & advanced concepts of Python & few data-science modules through this dataset for further use in their own day-to-day projects.\u000b\n"},{"metadata":{},"cell_type":"markdown","source":"# Part 1: Basics of Python\n\n### Overview-\n\n* Python syntax\n\n* Data types\n\n* Data structures\n\n* Environment variables & working with files\n\n* Control flow & logic\n\n* Error handling\n\n* Scope of variables\n\n* Working directory & searching for files with Glob module\n\n* Installing libraries online & offline"},{"metadata":{},"cell_type":"markdown","source":"### Python Syntax\n\n* Python code can be run both interactively(this notebook or via the console prompt) & also using scripts(.py)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print text using built-in ```print``` function\n\nprint(\"Hello BIU!\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Direct evaluation of expression,  \n# This ia a comment, a single line statement preceeded by # or\n\"\"\" multiple lines enclosed within triple quotes is treated as a comment & not exectuted, unless assigned to a variable otherwise it is treated as multi-line string\n\"\"\"\n\nprint(673762*62)\n\n\n# Variable value assignment\na = 10\n\nprint(a+a)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Pandas \n\nPandas is a data wrangling module for Python. It treats data in either tabular format(also called a DataFrame) or as a series, while also offering a whole range of functions to help with data manipulation."},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\n\n# Loading a dataset from a csv file and creating a dataframe\n# specify encoding to deal with different formats\ndf = pd.read_csv('../input/ecommerce-data/data.csv', encoding = 'ISO-8859-1')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Set Information:\n\nThis is a transnational data set which contains all the transactions occurring between 01/12/2010 and 09/12/2011 for a UK-based and registered non-store online retail. The company mainly sells unique all-occasion gifts. Many customers of the company are wholesalers.\n\n## Attribute Information:\n\n* InvoiceNo: Invoice number. Nominal, a 6-digit integral number uniquely assigned to each transaction. If this code starts with letter 'c', it indicates a cancellation.\n* StockCode: Product (item) code. Nominal, a 5-digit integral number uniquely assigned to each distinct product.\n* Description: Product (item) name. Nominal.\u000bQuantity: The quantities of each product (item) per transaction. Numeric.\u000b\n* InvoiceDate: Invice Date and time. Numeric, the day and time when each transaction was generated.\u000b\n* UnitPrice: Unit price. Numeric, Product price per unit in sterling.\u000b\n* CustomerID: Customer number. Nominal, a 5-digit integral number uniquely assigned to each customer.\n* Country: Country name. Nominal, the name of the country where each customer resides.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# head() is used to read top 5 rows and tail() is used to read bottom 5 rows of a dataframe\n# The value can be changed --> head(10)\n\ndf.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Accessing specific columns and rows of a dataframe\n\n#There are 3 ways to access --> using loc, iloc and list\n\n# Using loc\nprint('Using loc: \\n', df.loc[:, ['InvoiceNo', 'Description']].head())    # rows,  columns\n\n# Using iloc --> Using index\nprint('\\n Using iloc: \\n', df.iloc[:, [0,1,2]].head())    # rows,  columns\n\n# Using list of columns\nprint('\\n Using list of columns: \\n', df[['InvoiceNo', 'Description']].head())    # rows,  columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Accessing individual columns, it can be used if column names do not contain spaces\n\ndf.InvoiceNo.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Functions\n\n# Built-in functions that are part of Python\n\nprint(\"hello\")\nprint(len(\"63726372\"))\n\n# User defined functions, are created using the def(define) keyword, you can pass multiple arguments to them as well\n# To invoke them write the function name & choose to either pass an argument if it accepts one or simply call with parentheses/()\n\ndef double_quantity(x):\n    '''\n    These are called document comments the other ones are using #\n    x: int\n    It takes x as input and returns 2 times x\n    '''\n    return x * 2\n\n\ndf['Double_quantity'] = df.Quantity.apply(double_quantity)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Types"},{"metadata":{"trusted":true},"cell_type":"code","source":"# We can check the datatype of a varible using type function, we want to check the datatype assigned to a value in a column\n# Python automatically assigns a datatype to a variable\n\n# Integer datatype\nprint(type(df.Quantity[0])) #64 specifies the size\n\n# Float --> Used to store decimal values\nprint(type(df.UnitPrice[0]))\n\n# String\nprint(type(df.Description[0]))\n\n# Boolean --> True(1) or False(0)\nprint(type(df.InvoiceNo[0] == 536365))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Structures\n\n#### Commonly used data structures are Lists, Tuples, Sets & Dictionaries"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lists are denoted by [] & can contain the same or different data types within them-\n# Lists are mutable --> the values can be modified\n# We want to list out all the countries available in our dataset\n\n# List of all countries\ncountries_list = list(df.Country.unique())\nprint(countries_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# List operations\n\n# Remove an element from a list, we want to exclude a country from our analysis\n\ncountries_list.remove('United Kingdom') # It updates the existing list countries_list\nprint(\"After removing UK: \\n\", countries_list, \"\\n\") # \\n is used for next line \\t for tab these are called \nprint(countries_list.remove('France')) # If you try to print the object returned after operation it will return None\nprint(\"After removing France: \\n\", countries_list, \"\\n\")\n\n\n# Append an element to the list\n# Creating a list\nremoved_countries = ['United Kingdom', 'France']\ncountries_list.append(removed_countries) # Append them as list \ncountries_list = countries_list + removed_countries # Add elements to the list\nprint(\"After adding removed countries: \\n\", countries_list,  \"\\n\")\ncountries_list.remove(removed_countries)\n\n# Sorting a list\ncountries_list.sort(reverse=False) # reverse True-->Descending\nprint(\"After sorting: \\n\", countries_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Tuples\n# Tuples a consists of a number of values separated by commas & can be defined with or without parentheses\n# They are immutable --> the values cannot be modified\n\ncountries_tuple = tuple(df.Country.unique())\nprint(countries_tuple) # Notice round bracket\n\ncountries_tuple[0:5] #Indexing in python always starts from 0, when we specify 5 it one value less 5 -->0,1,2,3,4 [0:(5-1)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sets\n# Sets are an unordered collection with no duplicate elements\n\ncountry_list = list(df.Country)\nprint(len(country_list), \"\\n\")\n\n# Convert to set --> It will only keep unique entries\ncountry_set = set(country_list)\nprint(len(country_set), \"\\n\")\nprint(country_set, \"\\n\") # Notice {} braces\n\n# Basic uses include membership testing and eliminating duplicate entries. \n# Set objects also support mathematical operations like union, intersection, difference, and symmetric difference.\n\n# Check if India is present in set\nprint(\"India\" in country_set, \"\\n\")\n\ncountries_set_2 = {'Hong Kong', 'Iceland', 'European Community'}\nindia = {'India'}\n\nprint(country_set - countries_set_2, \"\\n\") # Countries in country_set but not in countries_set_2\nprint(country_set & countries_set_2, \"\\n\") # Countries in country_set and countries_set_2 (intersection)\nprint(country_set.union(india), \"\\n\") # Countries in country_set and countries_set_2 (intersection)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dictionary\n# Dictionary is a set of \"key: value\" pairs, with the requirement that the keys are unique (within one dictionary). \n# A pair of braces creates an empty dictionary: {}\n\n# We want to select top 5 countries on the basis of their occurance in the dataset\ncountry_dict = dict(df.Country.value_counts()[:6])\nprint(country_dict)\nprint(\"Key: \", country_dict.keys())\nprint(\"Values: \", country_dict.values(), \"\\n\")\n\n\nprint(country_dict['Germany']) # Extract values using the key\n\n# Operations like deleting a key-value pair is also possible using ```del```\ndel country_dict[\"France\"]\nprint(country_dict)\n\nindia_dict = {'India' : 757574734}\ncountry_dict.update(india_dict)\nprint(country_dict)\n# For more operations on dictionaries refer to https://docs.python.org/3/tutorial/datastructures.html#dictionaries","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Environment variables & working with files"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Quite often you will end up working with libraries or databases where you might need-\n# values from the environment directly for functionality or security of passphrase/keys/port numbers\n\nimport os\n!set USERNAME=akash\nprint(\"$username\",os.getenv(\"USERNAME\",\"dev\"))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Writing to a file\nwith open(\"test.txt\",'w') as f:\n   f.write(\"my first file\\n\")   # \\n denotes newline character\n   f.write(\"This file\\n\")\n   f.write(\"contains three lines\\n\")\n\n\n!ls  # In the notebook commands prefixed with '!' are run by the host os, ```ls``` command lists all files & folders in current directory\n# Output from ls shows that the file was created","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reading a file\nwith open(\"test.txt\",'rb') as f:\n   # perform file operations\n    print(f.read())\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### File modes-\n#### There are multiple modes with which a file can be interacted with-\n\n* 'r'\tThis is the default mode. It Opens file for reading.\n* 'w'\tThis Mode Opens file for writing. If file does not exist, it creates a new file. If file exists it truncates the file.\n* 'a'\tOpen file in append mode. If file does not exist, it creates a new file.\n* 'b'\tThis opens in binary mode."},{"metadata":{},"cell_type":"markdown","source":"### Control flow & logic\n\n#### It is essential to be able to control the behaviour of your code, you may want something to run 100 times given a condition or iterate through a list etc. Control flow with loops & conditional logic help you do the same."},{"metadata":{"trusted":true},"cell_type":"code","source":"# 'For loop' is a tool to loop over a piece of code, given that a certain condition holds true\n# The condition could be a range of values or a variable who's evaluation comes to True(Boolean) value\n\n# Loop for 5 times-\nfor i in range(5):   # range starts from 0 until the number specified, hence in this case- 0,1,2,3,4\n    print(i)\nprint('\\n')    \n    \n# Iterating a list\nfor index,country in enumerate(removed_countries):\n    print(index,country)\nprint('\\n')    \n\n# Enumerating a dictionary\nfor key,value in country_dict.items():\n    print(key, \"--\", value)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# If Else conditions are standard ways of controlling whether to do something if an expression/variable is true otherwise do something else\n\n# We want to find list of countries having more than 1000 entries\nfor key, value in dict(df.Country.value_counts()).items():\n    \n    if value > 1000:\n        print(key, \"--\",value)\n        \n        \nprint('\\nClassifying counties based on count:')\n        \n# We want to find list of countries having more than 1000 entries\nfor key, value in dict(df.Country.value_counts()[:11]).items():\n    \n    if value > 10000:\n        print(\"More than 10k count\")\n    elif value <=10000 and value >= 2000:\n        print(\"Between 10k and 2k \")\n    else:\n        print(\"Less than 2k\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 'While loop' is used for repeatedly running code as long as an expression/variable is true\ni = 0\nwhile i<3:\n    print(df.iloc[i, [1,2,3]])\n    i += 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Break/Continue statement"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Break statement terminates the nearest enclosing loop, skipping the optional else clause if the loop has one.\n# Continue statement continues with the next cycle of the nearest enclosing loop.\n\ni = 0\nwhile True:\n    temp = df.iloc[i, [1,2,3]]\n    print(temp)\n    \n    if temp.Quantity <= 6:\n        print(\"Quantity less than 6\")\n        i += 1\n        continue\n        \n    if temp.Quantity > 6:\n        print(\"Quantity greater than 6\")\n        i += 1\n        break\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"### Error handling\n\nWhen an error occurs or exception is raised, Python will normally stop and generate an error message. In order to continue executing our code we need to handle such situations with a try/except block.\n\nCommon scenarios are around trying to read a file which does not exist or when making an API call over the network etc"},{"metadata":{"trusted":true},"cell_type":"code","source":"# We are trying to access few columns from a dataframe but it throws an error was the column quantity is incorrect, the correct name is \"Quantity\"\ndf.loc[:3, ['InvoiceNo', 'StockCode', 'quantity']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We can use error handling to avoid this and print appropriate message to the user\n\ntry:\n    print(df.loc[:3, ['InvoiceNo', 'StockCode', 'quantity']])\nexcept Exception as e:   # You can also handle multiple exceptions differently by specifying it like-> except NameError:\n    print(\"The specified column is not availabe in dataframe.\")\n    print(\"Please use capital letter for 1st character in column name or check if the column exists in the dataframe.\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(demo_var)\nprint(\"This should not print\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We havent initialized demo_var with any value, so the below will throw an error\ntry:\n  print(demo_var)\nexcept Exception as e:   # You can also handle multiple exceptions differently by specifying it like-> except NameError:\n  print(\"An exception occurred\",e)\n\nprint(\"This should print\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Scope of variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"# All Variables have a scope within which they can be modified, in order to modify them in a function you need to use global keyword\n\n# This would work since no modification takes place\n\nx = 10\ndef bar():\n    print(x)\nbar()\n\n# but this code will error out\nx = 10\ndef bar():\n    print(x)\n    x = x + 1\n    print(x)\nbar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# To solve the above issue we use `global` keyword which allows us to modify global variables\n\nx = 10\ndef bar():\n    global x\n    print(x)\n    x = x + 1\n    print(x)\nbar()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Working directory & searching for files with Glob module"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sometimes you might want to change your working directory to another folder in order to access files\n# You can do this with `os` module chdir() & find out your current working directory using getcwd()\n\n# Check current working directory.\nimport os\nretval = os.getcwd()\n\n# This is way of printing text & variables using f-strings with the use of `f` prefix & brackets/{} around variable/expression\nprint(f\"Current working directory- {retval}\")  \n\npath = \"/kaggle/input\"\n\n# Now change the directory\nos.chdir( path )\n\n# Check current working directory.\nretval = os.getcwd()\nprint(f\"Directory changed successfully- {retval}\")\n\n# Revert back using old path\npath = \"/kaggle/working\"\nos.chdir( path )\nretval = os.getcwd()\nprint(f\"Directory changed back successfully- {retval}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Finding files - You may want to search for all files that are of a certain extension, you can do that with `glob` module\n# We create mock-files using linux's `touch` command\n!touch 1.csv 2.csv 3.csv\n\nimport glob\n\nlist_of_csv = glob.glob('./*.csv')\n\nprint(f\"{list_of_csv}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Installing libraries online & offline"},{"metadata":{"trusted":true},"cell_type":"code","source":"# You can install python modules using pip(recursive acronym of \"Pip Installs Packages\")\n# !pip install pandas\n\n# In certain environments without internet connectivity you can download packages from pypi & install them offline\n# Ex. Flask web-server from https://pypi.org/project/Flask/#files\n\n!wget https://files.pythonhosted.org/packages/f2/28/2a03252dfb9ebf377f40fba6a7841b47083260bf8bd8e737b0c6952df83f/Flask-1.1.2-py2.py3-none-any.whl\n    \n!pip install Flask-1.1.2-py2.py3-none-any.whl","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Kaggle Platform Additional Info"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Part 2: Basic Data Science with Python using Numpy & Pandas\n\n### Overview-\n* Loading the dataset\n\n* Numpy & Pandas basics\n\n* Exploratory Data Analysis on dataset\n\n* Results"},{"metadata":{},"cell_type":"markdown","source":"# Context of Dataset\nCompany - UK-based and registered non-store online retail\n\nProducts for selling - Mainly all-occasion gifts\n\nCustomers - Most are wholesalers (local or international)\n\nTransactions Period - **1st Dec 2010 - 9th Dec 2011 (One year)**"},{"metadata":{},"cell_type":"markdown","source":"* #  *Loading the dataset*"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns \n\nimport warnings\n# current version of seaborn generates a bunch of warnings that we'll ignore\nwarnings.filterwarnings('ignore')\nsns.set_style('whitegrid')\n\nimport missingno as msno # missing data visualization module for Python\nimport pandas_profiling\n\nimport gc\nimport datetime\n\n%matplotlib inline\ncolor = sns.color_palette()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_rows', 10000)\npd.set_option('display.max_columns', 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# specify encoding to deal with different formats\ndf = pd.read_csv('../input/ecommerce-data/data.csv', encoding = 'ISO-8859-1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# change the column names\ndf.rename(index=str, columns={'InvoiceNo': 'invoice_num',\n                              'StockCode' : 'stock_code',\n                              'Description' : 'description',\n                              'Quantity' : 'quantity',\n                              'InvoiceDate' : 'invoice_date',\n                              'UnitPrice' : 'unit_price',\n                              'CustomerID' : 'cust_id',\n                              'Country' : 'country'}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* # *Numpy basics*"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert pandas to numpy array\n\narr = np.array(df.iloc[:10, [3,5]])\narr","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Basic array operations"},{"metadata":{"trusted":true},"cell_type":"code","source":"arr.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np_reshape_arr = arr.reshape(2, 10)\nprint(\"Shape of array after reshaping: \", np_reshape_arr.shape)\nnp_reshape_arr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Concatenate along the axis \n# 0 --> running vertically along rows\n\nnp_concat_0 = np.concatenate((arr, arr), axis=0)\nprint(\"Shape after concatinating along axis 0: \", np_concat_0.shape)\n\n# 1 --> running horizontally along columns\nnp_concat_1 = np.concatenate((arr, arr), axis=1)\nprint(\"Shape after concatinating along axis 0: \", np_concat_1.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create an array 0s, this is generally used when we have to initialize a parameter.\n\nnp_arr_zeros = np.zeros((10, 2))\nprint(\"Numpy array of zeros: \\n\", np_arr_zeros)\n\n# Create an array 1s, this is generally used when we have to initialize a parameter.\n\nnp_arr_ones = np.ones((10, 2))\nprint(\"Numpy array of ones \\n\", np_arr_ones)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Transforming an array & Matrix multiplication\n\nprint(\"arr shape: \", arr.shape)\nprint(\"np_arr_ones shape: \", np_arr_ones.shape)\nprint(\"np_arr_ones shape after transformation: \", np_arr_ones.T.shape)\n\nnp.matmul(arr, np_arr_ones.T)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Stats operations using numpy\n\n# Mean\nprint(\"Mean of an the entire array:\", np.mean(arr))\n\n# These operations can be applied along the axis\nprint(\"Mean of an the array along axis 0(vertically):\", np.mean(arr, axis=0))\nprint(\"Mean of an the array along axis 1(horizontally):\", np.mean(arr, axis=1))\n      \nprint(\"Standard deviation of an the entire array:\", np.std(arr))\nprint(\"Min of an the entire array:\", np.min(arr))\nprint(\"Max of an the entire array:\", np.max(arr))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sorting an array\n\n# Default axis is 1(Horizontally), the same array is sorted if we try to assign it to a variable it stores as None\nprint(hex(id(arr)))\narr.sort(axis=1)\nprint(\"Sorted array:\\n\", arr)\nprint(hex(id(arr)))\n\narr_sorted_0 = arr.sort(axis=0)\nprint(\"Trying to assign sorted array to a variable:\", arr_sorted_0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Conditions on array  -> This can be used in pandas to create new varibles using condition on existing variables\n\n# Identifying values greater than 6 in array and assigning them 1\nnp.where(arr > 6, 1, 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Assigning seed and generating random numbers\n\n# Setting seed will generate same output from the same random function, change seed and try again.\n# This is also used to initializing parameters\nnp.random.seed(1234)\nprint(\"Array of random numbers:\\n\", np.random.rand(2,3))\nprint(\"Integer array of random numbers from 50 - 100:\\n\", np.random.randint(low=50, high=100, size=10))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* # Pandas basics\n\nPandas is a data wrangling module for Python. It treats data in either tabular format(also called a DataFrame) or as a series, while also offering a whole range of functions to help with data manipulation.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing pandas & numpy\nimport pandas as pd\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating a series from a dataframe\n# Series represents a single column of a dataframe\ndf_invoice_series = df.invoice_num\ntype(df_invoice_series)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# How to infer data type of a dataframe\n# df_1.dtypes\ndf.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data manipulation- There are two ways in which you can perform manipulation to a Pandas object.\n## 1. User defined functions, inline/anonymous functions called lambdas can also be used. More info at https://pandas.pydata.org/pandas-docs/version/0.18.1/generated/pandas.Series.apply.html\n## 2. Pandas built-in functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 2. Pandas built-in functions\n# Pandas has a lot of statistical & linear-algebra functions ex. mean, median, sum, value_counts, rank, quantile\n# More at https://pandas.pydata.org/pandas-docs/stable/reference/frame.html\n\nprint(\"Mean unit price\")\nprint(df.unit_price.mean())\n\nprint(\"\\nTotal unit price\")\nprint(df.unit_price.sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the missing values in all the columns\n\nprint(\"Missing values in all the columns:\")\nprint(df.isna().sum())\n\n# Replace missing values with a default value\ndf.description.fillna('No description', inplace=True) #inplace will replace the column in same dataframe and wont return a new dataframe\nprint(\"\\nMissing values in all the columns after replacement:\")\nprint(df.isna().sum())\n\n# Replace missing values with a mean value\ndf.cust_id.fillna(np.mean(df.cust_id), inplace=True) \nprint(\"\\nMissing values in all the columns after replacement:\")\nprint(df.isna().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Working with multiple dataframes using `merge`\n# The data is generally available in multiple tables or excel sheet and we need to join multiple tables to create new variables\n# The merge function helps in this task\n\nprint('Base data\\n', df.head())\n\n# Creating a new dataframe using a dictionary\n# Creating a list of unique countries \ncountry_list = df.loc[:, 'country'].unique()\npopulation = {}\nfor country in country_list:\n    # Assigning a random value between 1000 - 10000000\n    population[country] = np.random.randint(1000, 10000000)\n    \npopulation_df = pd.DataFrame.from_dict(population, orient='index', columns=[\"Population\"]).reset_index() #orient specifies how the keys should be aligned either as columns or index\npopulation_df.columns = ['country', 'Population']\nprint('\\nPopulation data\\n', population_df.head())\n\n\n# Merging 2 dataframes based on common column\ndf = pd.merge(df, population_df, on='country', how='left') # Check out more samples on how to merge, ex. left/right etc\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Grouping values in a dataframe\n\n# A groupby operation involves some combination of splitting the object, applying a function, and combining the results. \n# This can be used to group large amounts of data and compute operations on these groups.\n# df = pd.DataFrame({'Animal': ['Falcon', 'Falcon','Parrot', 'Parrot'],'Max Speed': [380., 370., 24., 26.]})\nprint(df.groupby(['invoice_num','cust_id']).sum().head(10))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Accessing specific rows/columns of data using `loc` & 'iloc'\n\n# Let's say you want to access all the rows which have orders from United Kindgom, you can use 'loc' & provide a statement to filter such rows\nprint(df.loc[df['country'] == 'United Kingdom'])\n\n# In case you need to access a subset of rows only using their index instead of columnar values you can do so with 'iloc'\nprint(df.iloc[7:10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Saving a dataframe\n# Pandas allows you to save a dataframe in multiple formats like csv, excel, pickle, sql, JSON etc\n\ndf.to_csv('output.csv') # You can customize aspects like headers or indexes to keep as well\n\n# Check out more samples at https://pandas.pydata.org/pandas-docs/version/0.18.1/api.html#serialization-io-conversion","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Cleaning "},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Check missing values for each column "},{"metadata":{"trusted":true},"cell_type":"code","source":"# check missing values for each column \ndf.isnull().sum().sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check out the rows with missing values\ndf[df.isnull().any(axis=1)].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# change the invoice_date format - String to Timestamp format\ndf['invoice_date'] = pd.to_datetime(df.invoice_date, format='%m/%d/%Y %H:%M')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# change description - UPPER case to LOWER case\ndf['description'] = df.description.str.lower()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Remove rows with missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_new without missing values\ndf_new = df.dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check missing values for each column \ndf_new.isnull().sum().sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_new.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# change columns tyoe - String to Int type \ndf_new['cust_id'] = df_new['cust_id'].astype('int64')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_new.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_new.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_new.describe().round(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* ## Remove Quantity with negative values"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_new = df_new[df_new.quantity > 0]\ndf_new = df_new[df_new.unit_price >= 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_new.describe().round(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Add the column - amount_spent"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_new['amount_spent'] = df_new['quantity'] * df_new['unit_price']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# rearrange all the columns for easy reference\ndf_new = df_new[['invoice_num','invoice_date','stock_code','description','quantity','unit_price','amount_spent','cust_id','country']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Add the columns - Month, Day and Hour for the invoice"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_new.insert(loc=2, column='year_month', value=df_new['invoice_date'].map(lambda x: 100*x.year + x.month))\ndf_new.insert(loc=3, column='month', value=df_new.invoice_date.dt.month)\n# +1 to make Monday=1.....until Sunday=7\ndf_new.insert(loc=4, column='day', value=(df_new.invoice_date.dt.dayofweek)+1)\ndf_new.insert(loc=5, column='hour', value=df_new.invoice_date.dt.hour)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_new.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Hands on exercises-\n\n## The dataframe ```df_new``` contains all the columns that are needed for the below exercises\n"},{"metadata":{},"cell_type":"markdown","source":"1. Which customer places the most orders & which country are they from?\n  Also plot the number of orders for the top 5 customers"},{"metadata":{},"cell_type":"markdown","source":"2. Which customers spent the most? Also plot the money spent for top 5 customers"},{"metadata":{},"cell_type":"markdown","source":"3. Plot how many orders per month/day/hour of the day"},{"metadata":{},"cell_type":"markdown","source":"4. Certain items are priced at $0, as a free gift. Try out different chart types(scatterplot, boxplot etc) to see distribution of unit prices & also plot the frequency of free items being given for every month"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"5. Find out which country places the most orders & plot the same"},{"metadata":{},"cell_type":"markdown","source":"6. Find out how did each country spend & plot the same, also try removing the top country & then plotting again to see the updated data"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}