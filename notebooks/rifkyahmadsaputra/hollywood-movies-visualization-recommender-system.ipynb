{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install currencyconverter","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import some libraries\n\nimport numpy as np\nimport pandas as pd\npd.options.mode.chained_assignment = None\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style='whitegrid')\nfrom currency_converter import CurrencyConverter\nimport datetime\nfrom wordcloud import WordCloud, STOPWORDS \nimport textwrap\nimport string\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer \nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.feature_extraction.text import CountVectorizer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load data from a CSV file into pandas DataFrame\n\ndata_imdb_movies = pd.read_csv('../input/imdb-extensive-dataset/IMDb movies.csv')\ndata_imdb_names = pd.read_csv('../input/imdb-extensive-dataset/IMDb names.csv')\ndata_imdb_title_principals = pd.read_csv('../input/imdb-extensive-dataset/IMDb title_principals.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imdb_movies = data_imdb_movies.copy()\nimdb_movies.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imdb_names = data_imdb_names.copy()\nimdb_names.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imdb_title_principals = data_imdb_title_principals.copy()\nimdb_title_principals.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Informations on each data\n\nprint(imdb_movies.info())\nprint('\\n')\nprint(imdb_names.info())\nprint('\\n')\nprint(imdb_title_principals.info())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Preprocessing & Exploratory Data Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Merge name to title principals\nimdb_title_principals = pd.merge(imdb_title_principals, imdb_names[['imdb_name_id', 'name']], \n                                 left_on = ['imdb_name_id'], right_on = ['imdb_name_id']) \n# Ordering columns\nimdb_title_principals = imdb_title_principals[['imdb_title_id', 'ordering', 'imdb_name_id', 'name', 'category', 'job', 'characters']]\nimdb_title_principals.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create new column \"cinematographer\" into imdb_movies data\ncinematographer_name = imdb_title_principals[imdb_title_principals['category']=='cinematographer'].reset_index()\ncinematographer_name.rename(columns={'name' : 'cinematographer'}, inplace = True)\nimdb_movies = pd.merge(imdb_movies, cinematographer_name[['imdb_title_id', 'cinematographer']],\n                       left_on = 'imdb_title_id', right_on = 'imdb_title_id', how = 'left')\n\n# Group/join cinematographer names with same imdb_title_id to avoid duplicated data (from merging imdb_movies and cinematographer_name)\nduplicated_data = imdb_movies[imdb_movies['imdb_title_id'].duplicated(keep = False)]\nmultiple_names_cinematographer = duplicated_data.groupby('imdb_title_id')['cinematographer'].apply(', '.join).reset_index()\nduplicated_data.drop(['cinematographer'], axis = 1, inplace = True)\nduplicated_data.drop_duplicates(subset=['imdb_title_id'], inplace = True)\ndata_multiple_names = pd.merge(duplicated_data, multiple_names_cinematographer[['imdb_title_id', 'cinematographer']], \n                               left_on = 'imdb_title_id', right_on = 'imdb_title_id')\ndata_multiple_names[['imdb_title_id', 'cinematographer']].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop and replace duplicate data (because names of cinematographer) with data which have multiple names of cinematographer\nimdb_movies.drop_duplicates(subset=['imdb_title_id'], keep = False, inplace = True)\nimdb_movies = pd.concat((imdb_movies, data_multiple_names), sort = False).sort_values('imdb_title_id')\n\n# Reorder column cinematographer\ncols = imdb_movies.columns.tolist()\ncols = cols[0:13] + cols[-1:] + cols [13:-1]\nimdb_movies = imdb_movies[cols]\nimdb_movies.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Filtering data (only USA or Hollywood Movies)\nimdb_movies['country'].fillna('', inplace = True)\nimdb_movies = imdb_movies[imdb_movies['country'].str.contains('USA')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create budget_currency column and formatting budget column into numeric values for converting to usd\nimdb_movies['budget_currency'] = imdb_movies['budget'].str.split(' ', expand = True)[0]\nimdb_movies['budget_currency'] = imdb_movies['budget_currency'].str.replace('$', 'USD')\nimdb_movies['budget'] = imdb_movies['budget'].str.split(' ', expand = True)[1]\nimdb_movies['budget'] = pd.to_numeric(imdb_movies['budget'], errors='coerce')\n\n# Create worlwide_gross_income_currency column and formatting worlwide_gross_income column into numeric values for converting to usd\nimdb_movies['worlwide_gross_income_currency'] = imdb_movies['worlwide_gross_income'].str.split(' ', expand = True)[0]\nimdb_movies['worlwide_gross_income_currency'] = imdb_movies['worlwide_gross_income_currency'].str.replace('$', 'USD')\nimdb_movies['worlwide_gross_income'] = imdb_movies['worlwide_gross_income'].str.split(' ', expand = True)[1]\nimdb_movies['worlwide_gross_income'] = pd.to_numeric(imdb_movies['worlwide_gross_income'], errors='coerce')\n\n# Create usa_gross_income_currency column and formatting usa_gross_income column into numeric values for converting to usd\nimdb_movies['usa_gross_income_currency'] = imdb_movies['usa_gross_income'].str.split(' ', expand = True)[0]\nimdb_movies['usa_gross_income_currency'] = imdb_movies['usa_gross_income_currency'].str.replace('$', 'USD')\nimdb_movies['usa_gross_income'] = imdb_movies['usa_gross_income'].str.split(' ', expand = True)[1]\nimdb_movies['usa_gross_income'] = pd.to_numeric(imdb_movies['usa_gross_income'], errors='coerce')\n","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# Convert currencies into USD\n\nc = CurrencyConverter()\nfor i in range(imdb_movies.shape[0]):\n    # budget column\n    if (imdb_movies['budget_currency'].iloc[i] in c.currencies):\n        imdb_movies['budget'].iloc[i] = c.convert(imdb_movies['budget'].iloc[i], imdb_movies['budget_currency'].iloc[i], 'USD')\n    else :\n        imdb_movies['budget'].iloc[i] = np.nan\n   \n    # worlwide_gross_income column   \n    if (imdb_movies['worlwide_gross_income_currency'].iloc[i] in c.currencies):\n        imdb_movies['worlwide_gross_income'].iloc[i] = c.convert(imdb_movies['worlwide_gross_income'].iloc[i], \n                                                            imdb_movies['worlwide_gross_income_currency'].iloc[i], 'USD', )\n    else :\n        imdb_movies['worlwide_gross_income'].iloc[i] = np.nan\n    \n    # usa_gross_income column   \n    if (imdb_movies['usa_gross_income_currency'].iloc[i] in c.currencies):\n        imdb_movies['usa_gross_income'].iloc[i] = c.convert(imdb_movies['usa_gross_income'].iloc[i], \n                                                       imdb_movies['usa_gross_income_currency'].iloc[i], 'USD', \n                                                       )\n    else :\n        imdb_movies['usa_gross_income'].iloc[i] = np.nan\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Analysis Numeric and Categorical Data"},{"metadata":{},"cell_type":"markdown","source":"### Analysis Numeric Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"num_data = ['duration', 'avg_vote', 'votes', 'budget', 'usa_gross_income', 'worlwide_gross_income', \n            'metascore', 'reviews_from_users', 'reviews_from_critics']\nimdb_movies[num_data].describe()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Visualize distplot and boxplot on each numerical data/columns\n\nfig, ax = plt.subplots(9, 2, figsize = (14, 24))\nfig.tight_layout(pad = 5)\n\nfor i, n in enumerate(num_data):\n    sns.distplot(ax = ax[i,0], a = imdb_movies[n].dropna(), label = 'skewness : %.2f'%(imdb_movies[n].skew()))\n    ax[i,0].set_title(n, fontsize = 18)\n    ax[i,0].legend(loc = 'best')\n    \n    sns.boxplot(ax = ax[i, 1], x = imdb_movies[n].dropna())\n    ax[i, 1].set_title(n, fontsize = 18)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Analysis Categorical Data"},{"metadata":{},"cell_type":"markdown","source":"#### Which Decade Has Release Most Movies and Highest Average Vote (Rating)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Clean the data on 'year' column\nimdb_movies['year'].replace('TV Movie 2019', 2019, inplace = True)\nimdb_movies['year'] = imdb_movies['year'].astype(int)\n\n# Group the data based on Decades\nmovies_by_decades = imdb_movies[['imdb_title_id', 'original_title', 'year','avg_vote', 'votes']]\ndecades = movies_by_decades['year']//10*10\ndecades = decades.astype(str)+' - '+ (decades+9).astype(str)\ndecades_column = pd.DataFrame(decades)\nmovies_by_decades.insert(3, 'decades', decades_column)\nmovies_by_decades.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualize movie counts release based on decade with barchart\n\nmax_width = 15\nfig, ax = plt.subplots(figsize = (16,4))\ndecades = movies_by_decades.groupby('decades')['imdb_title_id'].count().index\ncount = movies_by_decades.groupby('decades')['imdb_title_id'].count()\nsns.barplot(ax = ax, x = decades, y = count)\nax.set_title('Movie Counts Based on Decade', fontsize = 18)\nax.set_xlabel('Decade')\nfor index,count in enumerate(count.astype(int)):\n       ax.text(x=index-0.15 , y =count+1 , s=f\"{count}\" , fontdict=dict(fontsize=10))\nax.set_ylabel('No. of Movies')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualize average vote (rating) based on decade with barchart\n\nmax_width = 15\nfig, ax = plt.subplots(figsize = (16,4))\ndecades = movies_by_decades.groupby('decades')['avg_vote'].mean().index\navg_vote = movies_by_decades.groupby('decades')['avg_vote'].mean()\nsns.barplot(ax = ax, x = decades, y = avg_vote)\nax.set_title('Average Vote (Rating) Based on Decade', fontsize = 18)\nax.set_xlabel('Decade')\nfor index,avg_vote in enumerate(np.round(avg_vote, 2)):\n       ax.text(x=index-0.15 , y =avg_vote+0 , s=f\"{avg_vote}\" , fontdict=dict(fontsize=10))\nax.set_ylabel('Average Vote')\nax.set_ylim((5, 7))\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Which Month Has Release Most Movies"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preprocess the data \n\nimdb_movies['date_published'].replace('TV Movie 2019', 2019, inplace = True)\nmovies_published = imdb_movies[['imdb_title_id', 'original_title', 'genre', 'date_published']]\nmovies_published['month_published'] = [month[5:7] for month in movies_published['date_published'].astype(str)]\n\n#print(movies_published['month_published'].unique()) # There are blank values on month_published column\nmovies_published['month_published'][movies_published['month_published']==''] = np.nan # replace blank values with nan\nmovies_published.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualize movie counts release based on month with barchart\n\nmax_width = 15\nfig, ax = plt.subplots(figsize = (16,4))\nmonths_published = movies_published.groupby('month_published')['imdb_title_id'].count().index\ncount_movies = movies_published.groupby('month_published')['imdb_title_id'].count()\nsns.barplot(ax = ax, x = months_published, y = count_movies)\nax.set_title('Movie Counts Based on Month', fontsize = 18)\nax.set_xlabel('Month')\nax.set_ylabel('No. of Movies')\nfor index,count_movies in enumerate(count_movies):\n       ax.text(x=index-0.15 , y =count_movies+0 , s=f\"{count_movies}\" , fontdict=dict(fontsize=10))\nax.set_xticklabels(['January', 'February', 'March', 'April', 'May', 'June'\n                    , 'July', 'August', 'September', 'October', 'November', 'December'])\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Wordcloud Genre Column\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create wordcloud on genre column data\n\ncomment_words = ''\nstop_words = set(STOPWORDS)\n\nfor val in imdb_movies['genre']:\n    val = str(val)\n    tokens = val.split()\n    \n    for i in range(len(tokens)):\n        tokens[i] = tokens[i].lower()\n    \n    comment_words += \" \".join(tokens)+\" \"\n\nwordcloud = WordCloud(width = 800, height = 600, background_color = 'black'\n                      , stopwords = stop_words, min_font_size = 10).generate(comment_words)\n\nfig, ax = plt.subplots(figsize = (8, 6))\nax.grid(False)\nax.imshow((wordcloud))\nfig.tight_layout(pad=0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Which Genre Has Release Most Movies and Highest Average Vote (Rating)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preprocess and split genre column data (because there are more than one genre in each row data)\n\nmovies_genre = imdb_movies[['imdb_title_id', 'original_title', 'genre', 'avg_vote']]\nmovies_genre['genre'] = movies_genre['genre'].astype('str')\n\ngenre_split = pd.DataFrame(movies_genre['genre'].str.split(',').tolist(), index=movies_genre['imdb_title_id']).stack()\ngenre_split = genre_split.reset_index(['imdb_title_id'])\ngenre_split.columns = ['imdb_title_id', 'genre_split']\nmovies_genre_split = pd.merge(genre_split, movies_genre[['imdb_title_id', 'original_title', 'avg_vote']],\n                              left_on = 'imdb_title_id', right_on = 'imdb_title_id')\nmovies_genre_split['genre_split'] = movies_genre_split['genre_split'].str.lstrip(' ').str.rstrip(' ')\nmovies_genre_split.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualize top 5 genres based on movie counts and based on average vote (rating)\n\nfig, ax = plt.subplots(1, 2, figsize = (16,6))\n\ngenres = movies_genre_split.groupby('genre_split')['imdb_title_id'].count().sort_values(ascending = False).index[0:5]\ncount_movies = movies_genre_split.groupby('genre_split')['imdb_title_id'].count().sort_values(ascending = False)[0:5]\nax[0].pie(x=count_movies, autopct=\"%.2f%%\", labels=genres, pctdistance=0.5)\nax[0].set_title('Top 5 Genres Based on Movie Counts', fontsize = 18)\n\ngenres = movies_genre_split.groupby('genre_split')['avg_vote'].mean().sort_values(ascending = False).index[0:5]\navg_votes = movies_genre_split.groupby('genre_split')['avg_vote'].mean().sort_values(ascending = False)[0:5]\nsns.barplot(ax = ax[1], x = genres, y = avg_votes)\nax[1].set_title('Top 5 Genres Based on Average Vote (Rating)', fontsize = 18)\nax[1].set_xlabel('Genre')\nfor index,avg_votes in enumerate(round(avg_votes, 2)):\n    ax[1].text(x=index-0.1 , y =avg_votes+0 , s=f\"{avg_votes}\" , fontdict=dict(fontsize=10))\nax[1].set_ylabel('Average Vote')\nax[1].set_ylim(6, 8)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Which Director Has Release Most Movies and Highest Average Vote (Rating)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preprocess and split director column data (because there are more than one director in each row data)\n\nmovies_director = imdb_movies[['imdb_title_id', 'original_title', 'director', 'avg_vote']]\nmovies_director['director'] = movies_director['director'].astype('str')\n\ndirector_split = pd.DataFrame(movies_director['director'].str.split(',').tolist(), index=movies_director['imdb_title_id']).stack()\ndirector_split = director_split.reset_index(['imdb_title_id'])\ndirector_split.columns = ['imdb_title_id', 'director_split']\nmovies_director_split = pd.merge(director_split, movies_director[['imdb_title_id', 'original_title', 'avg_vote']],\n                              left_on = 'imdb_title_id', right_on = 'imdb_title_id')\nmovies_director_split['director_split'] = movies_director_split['director_split'].str.lstrip(' ').str.rstrip(' ')\ngb_director = movies_director_split.groupby('director_split').agg({ 'imdb_title_id' : ['count'], 'avg_vote': ['mean']})\ngb_director.drop(gb_director[gb_director.index == 'nan'].index, inplace = True)\ngb_director.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualize top 10 directors based on movie counts with barchart\n\nmax_width = 15\nfig, ax = plt.subplots(figsize = (16,4))\ndirectors = gb_director[('imdb_title_id', 'count')].sort_values(ascending = False)[0:10].index\ncount_movies = gb_director[('imdb_title_id', 'count')].sort_values(ascending = False)[0:10]\nsns.barplot(ax = ax, x = directors, y = count_movies)\nax.set_title('Top 10 Directors Based on Movie Counts', fontsize = 18)\nax.set_xlabel('Director')\nax.set_xticklabels((textwrap.fill(x.get_text(), max_width) for x in ax.get_xticklabels()), fontsize = 10)\nfor index,count_movies in enumerate(count_movies):\n    ax.text(x=index-0.05 , y =count_movies+0 , s=f\"{count_movies}\" , fontdict=dict(fontsize=10))\nax.set_ylabel('No. of Movies')\nax.set_ylim(50, 100)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualize top 10 directors based on average vote (rating) with barchart\n\nmax_width = 15\nfig, ax = plt.subplots(figsize = (16,4))\n\n# Specification : at least have direct 5 movies\nmask = movies_director_split.groupby('director_split')['imdb_title_id'].count() >= 5\ndirectors = gb_director.loc[mask][('avg_vote',  'mean')].sort_values(ascending = False)[0:10].index\navg_vote = gb_director.loc[mask][('avg_vote',  'mean')].sort_values(ascending = False)[0:10]\n\nsns.barplot(ax = ax, x = directors, y = avg_vote)\nax.set_title('Top 10 Directors Based on Average Vote (Rating)', fontsize = 18)\nax.set_xlabel('Director')\nax.set_xticklabels((textwrap.fill(x.get_text(), max_width) for x in ax.get_xticklabels()), fontsize = 10)\nfor index,avg_vote in enumerate(round(avg_vote, 2)):\n    ax.text(x=index-0.1 , y =avg_vote+0 , s=f\"{avg_vote}\" , fontdict=dict(fontsize=10))\nax.set_ylabel('Average Vote')\nax.set_ylim(7.4, 8.4)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Which Writer Has Release Most Movies and Highest Average Vote (Rating)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preprocess and split writer column data (because there are more than one writer in each row data)\n\nmovies_writer = imdb_movies[['imdb_title_id', 'original_title', 'writer', 'avg_vote']]\nmovies_writer['writer'] = movies_writer['writer'].astype('str')\n\nwriter_split = pd.DataFrame(movies_writer['writer'].str.split(',').tolist(), index=movies_writer['imdb_title_id']).stack()\nwriter_split = writer_split.reset_index(['imdb_title_id'])\nwriter_split.columns = ['imdb_title_id', 'writer_split']\nmovies_writer_split = pd.merge(writer_split, movies_writer[['imdb_title_id', 'original_title', 'avg_vote']],\n                              left_on = 'imdb_title_id', right_on = 'imdb_title_id')\nmovies_writer_split['writer_split'] = movies_writer_split['writer_split'].str.lstrip(' ').str.rstrip(' ')\ngb_writer = movies_writer_split.groupby('writer_split').agg({ 'imdb_title_id' : ['count'], 'avg_vote': ['mean']})\ngb_writer.drop(gb_writer[gb_writer.index == 'nan'].index, inplace = True)\ngb_writer.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualize top 10 writers based on movie counts with barchart\n\nmax_width = 15\nfig, ax = plt.subplots(figsize = (16,4))\n\nwriters = gb_writer[('imdb_title_id', 'count')].sort_values(ascending = False)[0:10].index\ncount_movies = gb_writer[('imdb_title_id', 'count')].sort_values(ascending = False)[0:10]\n\nsns.barplot(ax = ax, x = writers, y = count_movies)\nax.set_title('Top 10 Writers Based on Movie Counts', fontsize = 18)\nax.set_xlabel('Writer')\nfor index,count_movies in enumerate(count_movies):\n    ax.text(x=index-0.05 , y =count_movies+0 , s=f\"{count_movies}\" , fontdict=dict(fontsize=10))\nax.set_ylabel('No. of Movies')\nax.set_ylim(30, 60)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualize top 10 writers based on average vote (rating) with barchart\n\nmax_width = 15\nfig, ax = plt.subplots(figsize = (16,4))\n\n# Specification : at least have write 5 movies\nmask = movies_writer_split.groupby('writer_split')['imdb_title_id'].count() >= 5\nwriters = gb_writer.loc[mask][('avg_vote',  'mean')].sort_values(ascending = False)[0:10].index\navg_vote = gb_writer.loc[mask][('avg_vote',  'mean')].sort_values(ascending = False)[0:10]\n\nsns.barplot(ax = ax, x = writers, y = avg_vote)\nax.set_title('Top 10 Writers Based on Average Vote (Rating)', fontsize = 18)\nax.set_xlabel('Writer')\nax.set_xticklabels((textwrap.fill(x.get_text(), max_width) for x in ax.get_xticklabels()), fontsize = 10)\nfor index,avg_vote in enumerate(round(avg_vote, 2)):\n    ax.text(x=index-0.1 , y =avg_vote+0 , s=f\"{avg_vote}\" , fontdict=dict(fontsize=10))\nax.set_ylabel('Average Vote')\nax.set_ylim(7.4, 8.8)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Which Production Company Has Release Most Movies and Highest Average Vote (Rating)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preprocess production company column data\n\nmovies_productioncomp = imdb_movies[['imdb_title_id', 'original_title', 'production_company', 'avg_vote']]\nmovies_productioncomp['production_company'] = movies_productioncomp['production_company'].astype('str')\n\ngb_productioncomp = movies_productioncomp.groupby('production_company').agg({ 'imdb_title_id' : ['count'], 'avg_vote': ['mean']})\ngb_productioncomp.drop((gb_productioncomp[gb_productioncomp.index == ''].index) | (gb_productioncomp[gb_productioncomp.index == 'nan'].index), inplace = True)\ngb_productioncomp.head()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# Visualize top 10 production companies based on movie counts with barchart\n\nmax_width = 15\nfig, ax = plt.subplots(figsize = (16,4))\n\nproductioncomp = gb_productioncomp[('imdb_title_id', 'count')].sort_values(ascending = False)[0:10].index\ncount_movies = gb_productioncomp[('imdb_title_id', 'count')].sort_values(ascending = False)[0:10]\n\nsns.barplot(ax = ax, x = productioncomp, y = count_movies)\nax.set_title('Top 10 Production Companies Based on Movie Counts', fontsize = 18)\nax.set_xlabel('Production Company')\nax.set_xticklabels((textwrap.fill(x.get_text(), max_width) for x in ax.get_xticklabels()), fontsize = 10)\nfor index,count_movies in enumerate(count_movies):\n    ax.text(x=index-0.1 , y =count_movies+0.6 , s=f\"{count_movies}\" , fontdict=dict(fontsize=10))\nax.set_ylabel('No. of Movies')\nax.set_ylim(100, 1400)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# Visualize top 10 production companies based on average vote (rating) with barchart\n\nmax_width = 15\nfig, ax = plt.subplots(figsize = (16,4))\n\n# Specification : at least have produce 20 movies\nmask = movies_productioncomp.groupby('production_company')['imdb_title_id'].count() >= 20\nproductioncomp = gb_productioncomp.loc[mask][('avg_vote',  'mean')].sort_values(ascending = False)[0:10].index\navg_vote = gb_productioncomp.loc[mask][('avg_vote',  'mean')].sort_values(ascending = False)[0:10]\n\nsns.barplot(ax = ax, x = productioncomp, y = avg_vote)\nax.set_title('Top 10 Production Companies Based on Average Vote (Rating)', fontsize = 18)\nax.set_xlabel('Production Company')\nax.set_xticklabels((textwrap.fill(x.get_text(), max_width) for x in ax.get_xticklabels()), fontsize = 10)\nfor index,avg_vote in enumerate(round(avg_vote, 2)):\n    ax.text(x=index-0.1 , y =avg_vote+0.005 , s=f\"{avg_vote}\" , fontdict=dict(fontsize=10))\nax.set_ylabel('Average Vote')\nax.set_ylim(6.4, 7.2)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Which Actor Has Release Most Movies and Highest Average Vote (Rating)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preprocess and split actor column data (because there are more than one actor in each row data)\n\nmovies_actor = imdb_movies[['imdb_title_id', 'original_title', 'actors', 'avg_vote']]\nmovies_actor['actors'] = movies_actor['actors'].astype('str')\n\nactor_split = pd.DataFrame(movies_actor['actors'].str.split(',').tolist(), index=movies_actor['imdb_title_id']).stack()\nactor_split = actor_split.reset_index(['imdb_title_id'])\nactor_split.columns = ['imdb_title_id', 'actor_split']\nmovies_actor_split = pd.merge(actor_split, movies_actor[['imdb_title_id', 'original_title', 'avg_vote']],\n                              left_on = 'imdb_title_id', right_on = 'imdb_title_id')\nmovies_actor_split['actor_split'] = movies_actor_split['actor_split'].str.lstrip(' ').str.rstrip(' ')\ngb_actor = movies_actor_split.groupby('actor_split').agg({ 'imdb_title_id' : ['count'], 'avg_vote': ['mean']})\ngb_actor.drop((gb_actor[gb_actor.index == 'nan'].index), inplace = True)\ngb_actor.head()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# Visualize top 10 actors based on movie counts with barchart\n\nmax_width = 15\nfig, ax = plt.subplots(figsize = (16,4))\n\nactor = gb_actor[('imdb_title_id', 'count')].sort_values(ascending = False)[0:10].index\ncount_movies = gb_actor[('imdb_title_id', 'count')].sort_values(ascending = False)[0:10]\n\nsns.barplot(ax = ax, x = actor, y = count_movies)\nax.set_title('Top 10 Actors/Actess Based on Movie Counts', fontsize = 18)\nax.set_xlabel('Actor/Actess')\nax.set_xticklabels((textwrap.fill(x.get_text(), max_width) for x in ax.get_xticklabels()), fontsize = 10)\nfor index,count_movies in enumerate(count_movies):\n    ax.text(x=index-0.1 , y =count_movies+0 , s=f\"{count_movies}\" , fontdict=dict(fontsize=10))\nax.set_ylabel('No. of Movies')\nax.set_ylim(90, 200)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# Visualize top 10 actors based on average vote (rating) with barchart\n\nmax_width = 15\nfig, ax = plt.subplots(figsize = (16,4))\n\n# Specification : at least have become an actor/actress on 10 movies\nmask = movies_actor_split.groupby('actor_split')['imdb_title_id'].count() >= 10\nactor = gb_actor.loc[mask][('avg_vote',  'mean')].sort_values(ascending = False)[0:10].index\navg_vote = gb_actor.loc[mask][('avg_vote',  'mean')].sort_values(ascending = False)[0:10]\n\nsns.barplot(ax = ax, x = actor, y = avg_vote)\nax.set_title('Top 10 Actors/Actress Based on Average Vote (Rating)', fontsize = 18)\nax.set_xlabel('Actor/Actess')\nax.set_xticklabels((textwrap.fill(x.get_text(), max_width) for x in ax.get_xticklabels()), fontsize = 10)\nfor index,avg_vote in enumerate(round(avg_vote, 2)):\n    ax.text(x=index-0.1 , y =avg_vote+0.005 , s=f\"{avg_vote}\" , fontdict=dict(fontsize=10))\nax.set_ylabel('Average Vote')\nax.set_ylim(7, 7.6)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Which Cinematographer Has Release Most Movies and Highest Average Vote (Rating)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preprocess and split cinematographer column data (because there are more than one cinematographer in each row data)\n\nmovies_cinematographer = imdb_movies[['imdb_title_id', 'original_title', 'cinematographer', 'avg_vote']]\nmovies_cinematographer['cinematographer'] = movies_cinematographer['cinematographer'].astype('str')\n\ncinematographer_split = pd.DataFrame(movies_cinematographer['cinematographer'].str.split(',').tolist(), index=movies_cinematographer['imdb_title_id']).stack()\ncinematographer_split = cinematographer_split.reset_index(['imdb_title_id'])\ncinematographer_split.columns = ['imdb_title_id', 'cinematographer_split']\n\nmovies_cinematographer_split = pd.merge(cinematographer_split, movies_cinematographer[['imdb_title_id', 'original_title', 'avg_vote']],\n                              left_on = 'imdb_title_id', right_on = 'imdb_title_id')\nmovies_cinematographer_split['cinematographer_split'] = movies_cinematographer_split['cinematographer_split'].str.lstrip(' ').str.rstrip(' ')\ngb_cinematographer = movies_cinematographer_split.groupby('cinematographer_split').agg({ 'imdb_title_id' : ['count'], 'avg_vote': ['mean']})\ngb_cinematographer.drop((gb_cinematographer[gb_cinematographer.index == 'nan'].index), inplace = True)\ngb_cinematographer.head()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# Visualize top 10 cinematographers based on movie counts with barchart\n\nmax_width = 15\nfig, ax = plt.subplots(figsize = (16,4))\n\ncinematographer = gb_cinematographer[('imdb_title_id', 'count')].sort_values(ascending = False)[0:10].index\ncount_movies = gb_cinematographer[('imdb_title_id', 'count')].sort_values(ascending = False)[0:10]\n\nsns.barplot(ax = ax, x = cinematographer, y = count_movies)\nax.set_title('Top 10 Cinematographers Based on Movie Counts', fontsize = 18)\nax.set_xlabel('Cinematographer')\nax.set_xticklabels((textwrap.fill(x.get_text(), max_width) for x in ax.get_xticklabels()), fontsize = 10)\nfor index,count_movies in enumerate(count_movies):\n    ax.text(x=index-0.05 , y =count_movies+0 , s=f\"{count_movies}\" , fontdict=dict(fontsize=10))\nax.set_ylabel('No. of Movies')\nax.set_ylim(55, 80)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# Visualize top 10 cinematographers based on average vote (rating) with barchart\n\nmax_width = 15\nfig, ax = plt.subplots(figsize = (16,4))\n\n# Specification : at least have direct 5 movies\nmask = movies_cinematographer_split.groupby('cinematographer_split')['imdb_title_id'].count() >= 5\ncinematographer = gb_cinematographer.loc[mask][('avg_vote',  'mean')].sort_values(ascending = False)[0:10].index\navg_vote = gb_cinematographer.loc[mask][('avg_vote',  'mean')].sort_values(ascending = False)[0:10]\n\nsns.barplot(ax = ax, x = cinematographer, y = avg_vote)\nax.set_title('Top 10 Cinematographers Based on Average Vote (Rating)', fontsize = 18)\nax.set_xlabel('Cinematographer')\nax.set_xticklabels((textwrap.fill(x.get_text(), max_width) for x in ax.get_xticklabels()), fontsize = 10)\nfor index,avg_vote in enumerate(round(avg_vote, 2)):\n    ax.text(x=index-0.1 , y =avg_vote+0.005 , s=f\"{avg_vote}\" , fontdict=dict(fontsize=10))\nax.set_ylabel('Average Vote')\nax.set_ylim(6.8, 8)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Recommender System Based on Content"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Features that used in this recommender system is 'original_title' (as index),  'genre', 'director', 'actors', 'description'\ndata_recsys=imdb_movies[['original_title', 'genre', 'director', 'actors', 'description']].reset_index(drop = True)\ndata_recsys.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preprocess the data\n\ndata_recsys.set_index('original_title', inplace = True)\n\ndata_recsys['genre'] = data_recsys['genre'].fillna('').astype('str').str.lower()\ndata_recsys['genre'] = data_recsys['genre'].str.split(',')\n\ndata_recsys['director'] = data_recsys['director'].fillna('').astype('str').str.lower()\ndata_recsys['director'] = data_recsys['director'].str.split(',')\n\ndata_recsys['actors'] = data_recsys['actors'].fillna('').astype('str').str.lower()\ndata_recsys['actors'] = data_recsys['actors'].str.split(',')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preprocess description column data\n\ndata_recsys['description'] = data_recsys['description'].fillna('').astype('str').str.lower()\ndata_recsys['description'] = data_recsys['description'].str.translate(str.maketrans('', '', string.punctuation))\n\n#from nltk.corpus import stopwords\nlistStopwords = set(stopwords.words('english'))\nfiltered = []\nps = PorterStemmer() \nfor i, text in enumerate(data_recsys['description'].str.split()):\n    for word in text:\n        # Filtering/Removing stopwords in the text\n        if word not in listStopwords:\n            # Stemming words\n            word_stemmed = ps.stem(word)\n            filtered.append(word_stemmed)\n    data_recsys['description'][i] = filtered\n    filtered = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create new column 'bunch_of_words' that contains words taken from all features columns\n\ndata_recsys['bunch_of_words'] = ''\nfor i, text in data_recsys.iterrows():\n    words = ''\n    for col in data_recsys.columns:\n        words = words + ' '.join(text[col]) + ' '\n    data_recsys['bunch_of_words'][i] = words","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_recsys.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert a collection of text documents to a vector of term/token counts (CountVectorizer)\n\ncount = CountVectorizer()\ncount_matrix = count.fit_transform(data_recsys['bunch_of_words']).astype(np.uint8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# To reduce memory usage\ndel data_imdb_names\ndel data_imdb_title_principals","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate Cosine Similarity\n# Cosine similarity is a metric used to measure how similar the documents are irrespective of their size\n\nchunk_size = 500 \nmatrix_len = count_matrix.shape[0] # Not sparse numpy.ndarray\n\n# Calculate cosine similarity chunk by chunk\ndef similarity_cosine_by_chunk(start, end):\n    if end > matrix_len:\n        end = matrix_len\n    return cosine_similarity(X=count_matrix[start:end], Y=count_matrix)\ncosine_similarity_all = []\ni=0\nfor chunk_start in range(0, matrix_len, chunk_size):\n    \n    # Initialize first cosine sim chunk (for first concatenating chunks purpose)\n    if i == 0: \n        cosine_sim = similarity_cosine_by_chunk(chunk_start, chunk_start+chunk_size)\n    \n    # Initialize other cosine sim chunk, then concatenating chunk by chunk untill all chunks concatenated\n    else :\n        cosine_similarity_chunk= similarity_cosine_by_chunk(chunk_start, chunk_start+chunk_size)\n        # Use type data float32 for reduce memory usage\n        cosine_sim = np.concatenate((cosine_sim.astype(np.float32), cosine_similarity_chunk.astype(np.float32)))\n    \n    # Change value i != 0 for execute else statement, because we dont need execute if statement anymore (if statement only to initialize first chunk for first concatenating purpose)\n    i= 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create function that return 10 recommended/similar movies based on input\n\n# Create variable index\nindex_movies = pd.Series(data_recsys.index)\n\n# Movies Recommendation function\ndef recommendation_movies(title, cosine_sim = cosine_sim):\n    recommended_movies = []\n    index_movie_input = index_movies[index_movies == title].index[0]\n    score_movies = pd.Series(cosine_sim[index_movie_input]).sort_values(ascending = False)\n    top_10_index_movies = list(score_movies.iloc[1:11].index)\n    # Get movies title and year by index (top 10 movies)\n    for i in top_10_index_movies:\n        recommended_movies.append(imdb_movies['original_title'].iloc[i] + ' (' + str(imdb_movies['year'].iloc[i]) + ')')\n    return recommended_movies","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Results\nrecommendation_movies('The Dark Knight')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}