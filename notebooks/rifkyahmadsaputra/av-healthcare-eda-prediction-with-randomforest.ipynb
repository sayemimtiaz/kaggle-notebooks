{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style = 'whitegrid')\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train = pd.read_csv('../input/av-healthcare-analytics-ii/healthcare/train_data.csv')\ndata_test = pd.read_csv('../input/av-healthcare-analytics-ii/healthcare/test_data.csv')\ndata_train_dict = pd.read_csv('../input/av-healthcare-analytics-ii/healthcare/train_data_dictionary.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = data_train.copy()\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = data_test.copy()\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data_train.info())\nprint('\\n')\nprint(data_test.info())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import Counter\nCounter(train['Stay'].tolist())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get lower and upper bound value on column \"Age\"\ntrain['Lower_Bound_Age'] = train['Age'].str.split('-', expand = True)[0].astype(int)\ntrain['Upper_Bound_Age'] = train['Age'].str.split('-', expand = True)[1].astype(int)\n\ntest['Lower_Bound_Age'] = test['Age'].str.split('-', expand = True)[0].astype(int)\ntest['Upper_Bound_Age'] = test['Age'].str.split('-', expand = True)[1].astype(int)\n","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# split data (data train) into numerical dan categorical data\nnum_data = train[['Available Extra Rooms in Hospital', 'Bed Grade', 'Visitors with Patient'\n             , 'Admission_Deposit', 'Lower_Bound_Age', 'Upper_Bound_Age']]\n\ncat_data = train[['Hospital_code', 'Hospital_type_code', 'City_Code_Hospital', 'Hospital_region_code'\n             , 'Department', 'Ward_Type', 'Ward_Facility_Code', 'City_Code_Patient', 'Type of Admission'\n             , 'Severity of Illness', 'Stay']]\n\nprint(num_data.info())\nprint('\\n')\nprint(cat_data.info())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Analysis Numeric Data","execution_count":null},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"fig, ax =plt.subplots(3,2, figsize=(14,10))\nfig.tight_layout(pad=5.0)\n\nfor ax, n in zip(ax.flatten(), num_data.columns.tolist()):\n    sns.distplot(ax=ax, a=num_data[n].dropna(), label=\"Skewness : %.2f\"%(num_data[n].skew()))\n    ax.set_title(n, fontsize = 14)\n    ax.legend(loc = 'best')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Based on histogram and skewness value, we can know who columns is nearly normally distributed or not. You can see on extra rooms, visitors with patient and admission deposite columns they have right skewed distributions (based on histograms above ), and based on the skewness value they are in moderately skewed/highly skewed (see the detail on below). So,  we should cleaning thats columns into more nearly normally distributed.\n\n\n-------------------------------------------------------------------------------------------------------------------------------\nThe skewness value can be positive or negative, or even undefined. If skewness is 0, the data are perfectly symmetrical, although it is quite unlikely for real-world data. As a general rule of thumb:\n\nIf skewness is less than -1 or greater than 1, the distribution is highly skewed.\n\nIf skewness is between -1 and -0.5 or between 0.5 and 1, the distribution is moderately skewed.\n\nIf skewness is between -0.5 and 0.5, the distribution is approximately symmetric.\n\n\nsource :\nhttps://help.gooddata.com/doc/en/reporting-and-dashboards/maql-analytical-query-language/maql-expression-reference/aggregation-functions/statistical-functions/predictive-statistical-use-cases/normality-testing-skewness-and-kurtosis\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Heatmap data numeric\nheatmapdata = train[['Stay', 'Available Extra Rooms in Hospital', 'Bed Grade', 'Visitors with Patient'\n             , 'Admission_Deposit', 'Lower_Bound_Age', 'Upper_Bound_Age', 'City_Code_Patient']]\n\ncormat = heatmapdata.corr()\nfig, ax = plt.subplots(figsize = (8,4))\nsns.heatmap(data = cormat)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Analysis Categorical Data","execution_count":null},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(cat_data.shape[1],1, figsize = (14, 32))\nfig.tight_layout(pad = 5.0)\n\nfor ax, n in zip(ax.flatten(), cat_data.columns.tolist()):\n    x_axis = cat_data[n].fillna('NaN').value_counts().index\n    y_axis = cat_data[n].fillna('NaN').value_counts()\n    sns.barplot(ax = ax, x = x_axis, y = y_axis, order =  x_axis)\n    ax.set_title(n, fontsize = 14)\n    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing Data (handle missing data, cleaning data, feature engineering, etc.) on Each Columns","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Manipulate columns position to easly do preprocessing data\n\n# Move columns 'Stay' to first position\ntrain = train[['Stay'] + [col for col in train.columns.tolist() if col != 'Stay']]\n# Create columns 'Stay' so that same shape with data train\ntest.insert(0, 'Stay', 'NaN')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Handle Missing Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Total null value on data train (%) :\\n', np.round(train.isnull().sum() * 100 / len(train), 4))\nprint('\\n')\nprint('Total null value on data test (%) :\\n', np.round(test.isnull().sum() * 100 / len(test), 4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop missing value on columns 'Bed Grade' and 'City_Code_Patient'\ntrain.dropna(subset = ['Bed Grade', 'City_Code_Patient'], inplace = True)\n\ntest['Bed Grade'].fillna(train['Bed Grade'].mode()[0], inplace = True)\ntest['City_Code_Patient'].fillna(train['City_Code_Patient'].mode()[0], inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Total null value on data train (%) :\\n', np.round(train.isnull().sum() * 100 / len(train), 4))\nprint('\\n')\nprint('Total null value on data test (%) :\\n', np.round(test.isnull().sum() * 100 / len(test), 4))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Cleaning Data on Columns 'Available Extra Rooms', 'Visitors with Patient' & 'Admission Deposit'","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(2,2, figsize = (16,8))\nsns.boxplot(ax = ax[0, 0], x = train['Available Extra Rooms in Hospital'])\nsns.boxplot(ax = ax[0, 1], x = train['Visitors with Patient'])\nsns.boxplot(ax = ax[1, 0], x = train['Admission_Deposit'])\nfig.delaxes(ax[1,1])\n\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove outliers from data train\n# https://towardsdatascience.com/ways-to-detect-and-remove-the-outliers-404d16608dba\n\nq1 = train['Available Extra Rooms in Hospital'].quantile(0.25)\nq3 = train['Available Extra Rooms in Hospital'].quantile(0.75)\niqr = q3-q1\ntrain = train[~((train['Available Extra Rooms in Hospital'] < (q1 - 1.5 * iqr)) | (train['Available Extra Rooms in Hospital'] > (q3+1.5*iqr)))]\n\nq1=train['Visitors with Patient'].quantile(0.25)\nq3 = train['Visitors with Patient'].quantile(0.75)\niqr = q3-q1\ntrain = train[~ ((train['Visitors with Patient'] < q1 - 1.5 * iqr) | (train['Visitors with Patient'] > (q3 + 1.5 * iqr)))]\n\nq1=train['Admission_Deposit'].quantile(0.25)\nq3 = train['Admission_Deposit'].quantile(0.75)\niqr = q3-q1\ntrain = train[~ ((train['Admission_Deposit'] < q1 - 1.5 * iqr) | (train['Admission_Deposit'] > (q3 + 1.5 * iqr)))]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Do log transform on data train\ntrain['Available Extra Rooms in Hospital'] = np.log(train['Available Extra Rooms in Hospital'] + 1)\ntrain['Visitors with Patient'] = np.log(train['Visitors with Patient'] + 1)\n# Remove outliers after log transform on data train\ntrain = train[train['Available Extra Rooms in Hospital'] > 0]\ntrain = train[train['Visitors with Patient'] > 0]\n\n# Do the same log transform on data test ( for make the same scale value with data train) \ntest['Available Extra Rooms in Hospital'] = np.log(test['Available Extra Rooms in Hospital'] + 1)\ntest['Visitors with Patient'] = np.log(test['Visitors with Patient'] + 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(2,2, figsize = (16,8))\nsns.boxplot(ax = ax[0, 0], x = train['Available Extra Rooms in Hospital'])\nsns.boxplot(ax = ax[0, 1], x = train['Visitors with Patient'])\nsns.boxplot(ax = ax[1, 0], x = train['Admission_Deposit'])\nfig.delaxes(ax[1,1])\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax =plt.subplots(2,2, figsize=(16,8))\nfig.tight_layout(pad=5.0)\n\nsns.distplot(ax=ax[0, 0], a=train['Available Extra Rooms in Hospital']\n             , label=\"Skewness : %.2f\"%(train['Available Extra Rooms in Hospital'].skew()))\nax[0, 0].set_title('Available Extra Rooms in Hospital', fontsize = 14)\nax[0, 0].legend(loc = 'best')\n\nsns.distplot(ax=ax[0, 1], a=train['Visitors with Patient']\n             , label=\"Skewness : %.2f\"%(train['Visitors with Patient'].skew()))\nax[0, 1].set_title('Visitors with Patient', fontsize = 14)\nax[0, 1].legend(loc = 'best')\n\nsns.distplot(ax=ax[1, 0], a=train['Admission_Deposit']\n             , label=\"Skewness : %.2f\"%(train['Admission_Deposit'].skew()))\nax[1, 0].set_title('Admission_Deposit', fontsize = 14)\nax[1, 0].legend(loc = 'best')\n\nfig.delaxes(ax[1,1])\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Encode Categorical Data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Do Encoding on Ordinal Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"admission_encode = {'Trauma' : 1, 'Urgent' : 2, 'Emergency' : 3}\ntrain['Type of Admission'] = train['Type of Admission'].map(admission_encode)\ntest['Type of Admission'] = test['Type of Admission'].map(admission_encode)\n\n\nseverity_encode = {'Minor' : 1, 'Moderate' : 2, 'Extreme' : 3}\ntrain['Severity of Illness'] = train['Severity of Illness'].map(severity_encode)\ntest['Severity of Illness'] = test['Severity of Illness'].map(severity_encode)\n\nstay_encode = {'0-10' : 1, '11-20' : 2, '21-30' : 3, '31-40' : 4, '41-50' : 5, '51-60' : 6, '61-70' : 7\n            ,'71-80' : 8, '81-90' : 9, '91-100' : 10, 'More than 100 Days' : 11}\ntrain['Stay'] = train['Stay'].map(stay_encode)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Do One Hot Encoder on Nominal Data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Because there are lots of nominal data columns, so I choose who columns that usefull or important for prediction model based on my analysis.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\n# By dropping one of the one-hot encoded columns from each categorical feature, we ensure there are no \"reference\" columnsâ€”the remaining columns become linearly independent.\n# https://kiwidamien.github.io/are-you-getting-burned-by-one-hot-encoding.html\n# https://www.youtube.com/watch?v=g9aLvY8BfRM\nnominal_data = ['Hospital_type_code', 'Hospital_region_code', 'Department', 'Ward_Type', 'Ward_Facility_Code']\ntestja = pd.DataFrame()\nfor n in nominal_data:\n    ohe = OneHotEncoder(sparse = False, drop = 'first', categories = 'auto')\n    ohe.fit(train[nominal_data])\n    ohecategory_train = ohe.transform(train[nominal_data])\n    ohecategory_test = ohe.transform(test[nominal_data])\n\n    for i in range(ohecategory_train.shape[1]):\n        train['dummy_variable_' + n + '_' + str(i)] = ohecategory_train[:,i]\n        \n    for i in range(ohecategory_test.shape[1]):\n        test['dummy_variable_' + n + '_' + str(i)] = ohecategory_test[:,i]\n\n\nprint('Train shape :', train.shape)\nprint('Test shape :', test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Standardization Numerical Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nnum_col = ['Available Extra Rooms in Hospital', 'Bed Grade', 'Visitors with Patient'\n             , 'Admission_Deposit', 'Lower_Bound_Age', 'Upper_Bound_Age']\nsc.fit(train[num_col])\ntrain[num_col] = sc.transform(train[num_col])\ntest[num_col] = sc.transform(test[num_col])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[num_col].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test[num_col].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Selection","execution_count":null},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# See if train and test data have same shape and column position\nprint('Train columns :\\n',train.columns)\nprint('Train shape : ', train.shape)\nprint('\\n')\nprint('Test columns :\\n',test.columns)\nprint('Test shape : ', test.shape)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop(['case_id', 'Hospital_code', 'patientid', 'Age', 'City_Code_Hospital', 'City_Code_Patient'\n            , 'Hospital_type_code', 'Hospital_region_code', 'Department', 'Ward_Type', 'Ward_Facility_Code']\n           , axis = 1, inplace = True)\n\ntest.drop(['case_id', 'Hospital_code', 'patientid', 'Age', 'City_Code_Hospital', 'City_Code_Patient'\n            , 'Hospital_type_code', 'Hospital_region_code', 'Department', 'Ward_Type', 'Ward_Facility_Code']\n           , axis = 1, inplace = True)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Explanation :\nDrop unused features, because :\n\n'case_id', 'Hospital_code', 'patientid' -> I dont need this, its just id columns\n\n'Age' -> because I haved create lower and upper bound age, so this column is not used anymore\n\n'City_Code_Hospital' -> I use hospital_region_code instead of this column, because they have same explanation\n\n'City_Code_Patient' -> I think there are no relations between where patient live and how long they have stayed on hospital and there are to much categories on this column, so i drop it to reduce the dimension of the data\n\n'Hospital_type_code', 'Hospital_region_code', 'Department', 'Ward_Type', 'Ward_Facility_Code' -> because i haved one hot encode them, so I used dummy variable of them","execution_count":null},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# See if train and test data have same shape and column position\nprint('Train columns :\\n',train.columns)\nprint('Train shape : ', train.shape)\nprint('\\n')\nprint('Test columns :\\n',test.columns)\nprint('Test shape : ', test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = train.iloc[:, 1:].values\ny_train = train.iloc[:, 0].values\nX_test = test.iloc[:, 1:].values\ny_test = test.iloc[:, 0].values\n\n#print('X_train :\\n', X_train[0:5])\n#print('y_train :\\n', y_train[0:5])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Prediction","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Random Forest Classifier","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Train and Evaluate a Model Prediction","execution_count":null},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\n\nx_train_split, x_val_split, y_train_split, y_val_split = train_test_split(X_train, y_train, test_size = 0.3, random_state = 0)\nclf = RandomForestClassifier(n_estimators=300, max_depth = 20, min_samples_leaf= 10, max_features=0.5)\nclf.fit(x_train_split, y_train_split)\ny_pred = clf.predict(x_val_split)\naccuracy = accuracy_score(y_pred, y_val_split)\nprint('Accuracy :',accuracy)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature Importances","execution_count":null},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"feature_importances = pd.DataFrame( data = {'Features' : train.iloc[:, 1:].columns\n                                    ,'Features Importances' : clf.feature_importances_.tolist()})\nfeature_importances","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = []\nfi = []\n# 'nominal_data' from one hot encoder cell (cell no.27)\nfor n in nominal_data:\n    features.append(n)\n    fi.append(feature_importances.loc[feature_importances['Features'].str.contains(n), 'Features Importances'].sum())\n    \n    feature_importances =  feature_importances[~feature_importances['Features'].str.contains(n)]\n\nfi_nominal_data = pd.DataFrame(list(zip(features, fi)), columns = ['Features', 'Features Importances'])\nfeature_importances = feature_importances.append(fi_nominal_data).sort_values('Features Importances'\n                                                                              , ascending = False).reset_index(drop = True)\n\nfeature_importances","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(16,8))\nax = sns.barplot(ax = ax, data = feature_importances.nlargest(20,'Features Importances')\n                 ,x='Features Importances',y='Features')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Predict Data Test","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fit the model into the whole data train\nclf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = clf.predict(X_test)\n\n\nsubmission = pd.DataFrame()\nsubmission['case_id'] = data_test['case_id']\nsubmission['Stay'] = y_pred\n\nstay_decode = { 1 : '0-10', 2 : '11-20', 3 : '21-30', 4 : '31-40', 5 : '41-50', 6 : '51-60', 7 : '61-70'\n            ,8 : '71-80', 9 : '81-90', 10 : '91-100', 11 : 'More than 100 Days'}\n\nsubmission['Stay'] = submission['Stay'].map(stay_decode)\nsubmission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv(r'Submission.csv', index = False, header = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### The Result of This Model in \"Janatahack: Healthcare Analytics II\" Leaderboard :\n### Public Score : 40.8613\n### Private Score : 40.5301","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}