{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Wine Quality Analysis\n\n<img style=\"margin-left:0\" src=\"https://thumbor.forbes.com/thumbor/fit-in/1200x0/filters%3Aformat%28jpg%29/https%3A%2F%2Fspecials-images.forbesimg.com%2Fdam%2Fimageserve%2F1133888244%2F0x0.jpg%3Ffit%3Dscale\" width=\"600px\" />\n\nThis notebook analyse a database of **red** and **white** variants of the Portuguese \"Vinho Verde\" wine based on wine **physicochemical test results** and quality scores that experts assign to each wine sample.\n\n- EDA Part of the Analysis: https://www.kaggle.com/glushko/wine-quality-domain-driven-eda-part-i\n- Feel free to upvote this notebook if you find it helpful ðŸ’«"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.experimental import enable_hist_gradient_boosting  # noqa\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer, PolynomialFeatures, PowerTransformer\nfrom sklearn.decomposition import PCA\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold, cross_validate, GridSearchCV, cross_val_predict\nfrom sklearn.metrics import f1_score, balanced_accuracy_score, classification_report, confusion_matrix, plot_confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn import set_config\nfrom sklearn.utils.multiclass import unique_labels\n\nfrom yellowbrick.model_selection import ValidationCurve\nimport shap","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (12, 8)\nset_config(display='diagram')\n\n\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)\nshap.initjs()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_df = pd.read_csv('../input/wine-quality/winequalityN.csv')\n\nfull_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Classification Objective ðŸŽ¯"},{"metadata":{},"cell_type":"markdown","source":"The most obvious classification objective for this training set is **multiclass wine quality classification**. \n\nThe dataset is **higly imbalanced**. We have only 5 samples of exellent wines and 30 samples of the lowest quality wines. If we take into account test set split and cross-validation folds, we may have only a couple of examples during training. This means that there may be a problem of applying SMOTE and similar synthetical methods to balance datasets as they would require more samples to create clusters for samplings from.\n\nOther possible objectives are:\n- multiclass quality classification with only 3 classes: low, medium, high quality wines\n- binary quality classification: good or bad quality wine\n- binary wine type classification: red or white wine (which would also suffer from imbalance, but could be fixed by synthetic resampling)"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"full_df['quality'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will stick with **multiclass quality classification** and 3 classes: low, medium, high quality wines:"},{"metadata":{"trusted":true},"cell_type":"code","source":"def impute_quality_group(quality):\n    if quality <= 5:\n        return 0 # low\n    if quality > 5 and quality < 7:\n        return 1 # average\n    if quality >= 7:\n        return 2 # high\n\nfull_df['quality_group'] = full_df['quality'].apply(impute_quality_group)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_df['quality_group'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'pH', 'sulphates']:\n    full_df[feature] = full_df.groupby(['type'])[feature].transform(lambda x: x.fillna(x.median()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def impute_sweetness(residual_sugar):\n    if residual_sugar < 1:\n        return 0\n    if residual_sugar >= 1 and residual_sugar < 9:\n        return 1\n    if residual_sugar >= 9 and residual_sugar < 18:\n        return 2\n    if residual_sugar >= 18 and residual_sugar < 50:\n        return 3\n    if residual_sugar >= 50 and residual_sugar < 120:\n        return 4\n    if residual_sugar >= 120:\n        return 5\n\nfull_df['sweetness'] = full_df['residual sugar'].apply(impute_sweetness)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_df['fixed_acidity_red_wine'] = (full_df['type'] == 'red') * full_df['fixed acidity']\nfull_df['fixed_acidity_white_wine'] = (full_df['type'] == 'white') * full_df['fixed acidity']\n\nfull_df['molecular_sulfur_dioxid'] = full_df['free sulfur dioxide'] / (1 + 10 ** (full_df['pH'] - 1.8))\nfull_df['free_total_so2_rate'] = full_df['free sulfur dioxide'] / full_df['total sulfur dioxide']\nfull_df['bound_sulfur_dioxid'] = full_df['total sulfur dioxide'] - full_df['free sulfur dioxide']\nfull_df['sugar_acidity_ratio'] = full_df['residual sugar'] / full_df['fixed acidity']\n\nalcohol_labels = ['low', 'medium', 'high']\nalcohol_bins = [0, 9.5, 11.5, 20]\nfull_df['alcohol_groups'] = pd.cut(full_df['alcohol'], bins=alcohol_bins, labels=alcohol_labels) \n\npH_labels = ['high', 'mod high', 'medium', 'low']\npH_bins = [2.5, 3.2, 3.3, 3.4, 4.1]\nfull_df['pH_groups'] = pd.cut(full_df['pH'], bins=pH_bins, labels=pH_labels) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Feature Engineering:\n- `total sulfur dioxide` - doesn't improve models in a raw view\n- `free_total_so2_rate` - brings 0 improvements\n- `sweetness` - degrades performance of all models\n- `alcohol_groups` - degrades performance of all models\n- `pH_groups` - degrades performance of all models\n- `sugar_acidity_ratio` improves score's std but degrades CV scores"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_features = [\n    'type',\n    'alcohol',\n    'fixed acidity',\n    'volatile acidity',\n    'citric acid',\n    'pH',\n    'residual sugar',\n    'free sulfur dioxide',\n    'chlorides',\n    'density',\n    'sulphates',\n    'bound_sulfur_dioxid',\n    'molecular_sulfur_dioxid',\n    'sugar_acidity_ratio'\n]\n\nX = full_df[model_features]\ny = full_df['quality_group']\n\nstratified_splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=RANDOM_SEED)\n\nfor train_idx, test_idx in stratified_splitter.split(X, y):\n    X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n    X_test, y_test = X.iloc[test_idx], y.iloc[test_idx]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Processing"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_feature_transformer():\n    oneplus_transformer = FunctionTransformer(func=lambda x: 1 + x, inverse_func=lambda x: 1 - x)\n    boxcox_transformer = PowerTransformer(method='box-cox', standardize=False)\n\n    numerical_transformer = Pipeline([\n        ('positive_transforming', oneplus_transformer),\n        ('boxcox_transforming', boxcox_transformer),\n    ])\n\n    return ColumnTransformer([\n            ('feature_transforming', numerical_transformer, [\n                'fixed acidity', 'chlorides', 'citric acid', 'volatile acidity', \n                'sulphates', 'alcohol', 'residual sugar', 'free sulfur dioxide', \n                'sulphates', 'pH', 'sugar_acidity_ratio'\n            ]),\n            ('wine_type_onehot', OneHotEncoder(), ['type']),\n        ],\n        remainder='passthrough'\n    )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modelling ðŸ§ª"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_confusion_matrix_by_predictions(y_true, y_predicted, *, labels=None,\n                          sample_weight=None, normalize=None,\n                          display_labels=None, include_values=True,\n                          xticks_rotation='horizontal',\n                          values_format=None,\n                          cmap='viridis', ax=None):\n    \n    cm = confusion_matrix(y_true, y_predicted, sample_weight=sample_weight,\n                          labels=labels, normalize=normalize)\n\n    if display_labels is None:\n        if labels is None:\n            display_labels = unique_labels(y_true, y_predicted)\n        else:\n            display_labels = labels\n\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n                                  display_labels=display_labels)\n\n    return disp.plot(include_values=include_values,\n                     cmap=cmap, ax=ax, xticks_rotation=xticks_rotation,\n                     values_format=values_format)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def score_classification_model(model, X_train, y_train):\n    \n    cv_scores = cross_validate(\n        model, X_train, y_train, \n        scoring=['f1_weighted', 'balanced_accuracy'],\n        cv=5,\n        n_jobs=-1, verbose=0\n    )\n\n    cv_y_predicted = cross_val_predict(\n        model, X_train, y_train,\n        cv=5,\n        n_jobs=-1\n    )\n\n    cv_f1_weighted, f1_weighted_std = cv_scores['test_f1_weighted'].mean(), cv_scores['test_f1_weighted'].std()\n    cv_balanced_accuracy, balanced_accuracy_std = cv_scores['test_balanced_accuracy'].mean(), cv_scores['test_balanced_accuracy'].std()\n\n    model.fit(X_train, y_train)\n\n    y_train_predicted = model.predict(X_train)\n\n    train_f1_weighted = f1_score(y_train, y_train_predicted, average='weighted')\n    train_balanced_accuracy = balanced_accuracy_score(y_train, y_train_predicted)\n\n    print('[Train] F1 Weighted: %.4f' % (train_f1_weighted))\n    print('[Train] Balanced Accuracy: %.4f' % (train_balanced_accuracy))\n    print('Train Set Report:')\n    print(classification_report(y_train, y_train_predicted, digits=3))\n\n    print('[CV] F1 Weighted: %.4f (%.4f)' % (cv_f1_weighted, f1_weighted_std))\n    print('[CV] Balanced Accuracy: %.4f (%.4f)' % (cv_balanced_accuracy, balanced_accuracy_std))\n    print('CV Report:')\n    print(classification_report(y_train, cv_y_predicted, digits=3))\n    \n    # display confusion matrixes\n\n    _, (ax0, ax1) = plt.subplots(1, 2)\n\n    ax0.set_title('Train Confusion Matrix')\n    plot_confusion_matrix(\n        model, X_train, y_train,\n        cmap=plt.cm.Blues,\n        normalize='true',\n        ax=ax0,\n    )\n\n    ax1.set_title('CV Confusion Matrix')\n    plot_confusion_matrix_by_predictions(\n        y_train, cv_y_predicted,\n        cmap=plt.cm.Blues,\n        normalize='true',\n        ax=ax1,\n    )\n\n    return y_train_predicted, cv_y_predicted","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sklearn's pipeline API is limited at this point and doesn't provide a way to get columns of transformed X array\n# This snippet will cover our back \n\ndef get_columns_from_transformer(column_transformer, input_colums):    \n    col_name = []\n\n    for transformer_in_columns in column_transformer.transformers_[:-1]: #the last transformer is ColumnTransformer's 'remainder'\n        raw_col_name = transformer_in_columns[2]\n        if isinstance(transformer_in_columns[1],Pipeline): \n            transformer = transformer_in_columns[1].steps[-1][1]\n        else:\n            transformer = transformer_in_columns[1]\n        try:\n            names = transformer.get_feature_names(raw_col_name)\n        except AttributeError: # if no 'get_feature_names' function, use raw column name\n            names = raw_col_name\n        if isinstance(names,np.ndarray): # eg.\n            col_name += names.tolist()\n        elif isinstance(names,list):\n            col_name += names    \n        elif isinstance(names,str):\n            col_name.append(names)\n\n    [_, _, reminder_columns] = column_transformer.transformers_[-1]\n\n    for col_idx in reminder_columns:\n        col_name.append(input_colums[col_idx])\n\n    return col_name","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## LogisticRegression"},{"metadata":{"trusted":true},"cell_type":"code","source":"logistic_regression = LogisticRegression(\n    solver='liblinear',\n    penalty='l1',\n    C=0.9,\n    max_iter=500,\n    class_weight='balanced',\n    random_state=RANDOM_SEED,\n    n_jobs=-1,\n)\n\nlogistic_regression_pipeline = Pipeline([\n    ('feature_processing', get_feature_transformer()),\n    ('scaling', StandardScaler()),\n    ('quality_classification', logistic_regression),\n])\n\nlogistic_regression_pipeline\n\n## [Tr] F1 Weighted: 0.5732, Balanced Accuracy: 0.5920\n## [CV] F1 Weighted: 0.5688 (0.0135), Balanced Accuracy: 0.5866 (0.0099)\n# solver='liblinear',\n# penalty='l1',\n# C=0.9,\n# max_iter=500,\n# class_weight='balanced'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score_classification_model(logistic_regression_pipeline, X_train, y_train);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Hyperparam Tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"parameters = {\n    'quality_classification__penalty': ['l2', 'l1', 'elasticnet', 'none'], # 'l1', 'elasticnet', 'none'\n    'quality_classification__C': [1.0, 0.95, 0.9, 0.8], # 1.0\n    'quality_classification__tol': [1e-4],\n    'quality_classification__class_weight': ['balanced'],\n    'quality_classification__solver': ['lbfgs', 'liblinear', 'sag', 'saga'], # lbfgs\n    'quality_classification__max_iter': [500],\n    'quality_classification__l1_ratio': [1.0, 0.0, 0.3, 0.4, 0.5],\n}\n\nparam_searcher = GridSearchCV(\n   estimator=logistic_regression_pipeline,\n   scoring='balanced_accuracy',\n   param_grid=parameters,\n   cv=5,\n   n_jobs=-1, \n   verbose=3\n)\n\n#param_searcher.fit(X_train, y_train)\n#param_searcher.best_params_, param_searcher.best_score_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Polynomial Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"logistic_classifier = LogisticRegression(\n    penalty='l2',\n    solver='newton-cg',\n    class_weight='balanced',\n    random_state=RANDOM_SEED,\n    n_jobs=-1,\n)\n\npolynomial_pipeline = Pipeline([\n    ('feature_processing', get_feature_transformer()),\n    ('polynomial_features', PolynomialFeatures()),\n    ('scaling', StandardScaler()),\n    ('quality_classification', logistic_classifier),\n])\n\npolynomial_pipeline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score_classification_model(polynomial_pipeline, X_train, y_train);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Hyperparam Tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"parameters = [\n    {\n        'quality_classification__solver': ['newton-cg'], # lbfgs, liblinear, 'lbfgs', 'sag', 'saga',\n        'quality_classification__penalty': ['l2', 'l1', 'elasticnet', 'none'], # 'l1', 'elasticnet', 'none'\n        'quality_classification__C': [1.0], # 1.0\n        'quality_classification__l1_ratio': [1.0, 0.9],\n        'quality_classification__max_iter': [100, 200],\n        'quality_classification__class_weight': ['balanced'],\n        'polynomial_features__degree': [2],\n    },\n]\n\nparam_searcher = GridSearchCV(\n   estimator=polynomial_pipeline,\n   scoring='balanced_accuracy',\n   param_grid=parameters,\n   cv=5,\n   n_jobs=-1, \n   verbose=3\n)\n\n#param_searcher.fit(X_train, y_train)\n#param_searcher.best_params_, param_searcher.best_score_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## SVC"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import LinearSVC, SVC\n\nlsvm_classifier = LinearSVC(\n    C=0.01,\n    max_iter=1000,\n    loss='squared_hinge',\n    class_weight='balanced',\n    random_state=RANDOM_SEED,\n)\n\nlsvm_pipeline = Pipeline([\n    ('feature_processing', get_feature_transformer()),\n    ('scaling', StandardScaler()),\n    ('quality_classification', lsvm_classifier),\n])\n\npsvm_classifier = SVC(\n    kernel='poly',\n    degree=4,\n    coef0=1,\n    class_weight='balanced',\n    random_state=RANDOM_SEED,\n)\n\npsvm_pipeline = Pipeline([\n    ('feature_processing', get_feature_transformer()),\n    ('scaling', StandardScaler()),\n    ('quality_classification', psvm_classifier),\n])\n\nksvm_classifier = SVC(\n    kernel='rbf',\n    C=5,\n    gamma=0.01,\n    class_weight='balanced',\n    random_state=RANDOM_SEED,\n)\n\nksvm_pipeline = Pipeline([\n    ('feature_processing', get_feature_transformer()),\n    ('scaling', StandardScaler()),\n    ('quality_classification', ksvm_classifier),\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score_classification_model(lsvm_pipeline, X_train, y_train);\n\n# [CV] F1 Weighted: 0.5552 (0.0132)\n# [CV] Balanced Accuracy: 0.5846 (0.0094)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score_classification_model(psvm_pipeline, X_train, y_train);\n\n## [Train] F1 Weighted: 0.5476, Balanced Accuracy: 0.5654\n## [CV] F1 Weighted: 0.5225 (0.0097), Balanced Accuracy: 0.5395 (0.0134)\n# kernel='poly',\n# degree=2,\n# class_weight='balanced'\n\n## [Train] F1 Weighted: 0.5979, Balanced Accuracy: 0.6337\n## [CV] F1 Weighted: 0.5807 (0.0036), Balanced Accuracy: 0.6147 (0.0090)\n# kernel='poly',\n# degree=2,\n# coef0=1,\n# class_weight='balanced'\n\n## [Train] F1 Weighted: 0.6323, Balanced Accuracy: 0.6724\n## [CV] F1 Weighted: 0.5865 (0.0068), Balanced Accuracy: 0.6264 (0.0127)\n# kernel='poly',\n# degree=3,\n# coef0=1,\n# class_weight='balanced'\n\n## [Train] F1 Weighted: 0.6874, Balanced Accuracy: 0.7242\n## [CV] F1 Weighted: 0.6072 (0.0154), Balanced Accuracy: 0.6388 (0.0167)\n# kernel='poly',\n# degree=4,\n# coef0=1,\n# class_weight='balanced'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score_classification_model(ksvm_pipeline, X_train, y_train);\n\n## [Train] F1 Weighted: 0.7151, [CV] Balanced Accuracy: 0.7483\n## [CV] F1 Weighted: 0.6048 (0.0102), [CV] Balanced Accuracy: 0.6400 (0.0124)\n# kernel='rbf',\n# C=10,\n# class_weight='balanced'\n\n## [Train] F1 Weighted: 0.6772, [CV] Balanced Accuracy: 0.7152\n## [CV] F1 Weighted: 0.5971 (0.0140), [CV] Balanced Accuracy: 0.6353 (0.0190)\n# kernel='rbf',\n# C=5,\n# class_weight='balanced'\n\n## [Train] F1 Weighted: 0.5954, [CV] Balanced Accuracy: 0.6341\n## [CV] F1 Weighted: 0.5784 (0.0041), [CV] Balanced Accuracy: 0.6191 (0.0039)\n# kernel='rbf',\n# C=5,\n# gamma=0.01,\n# class_weight='balanced'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Hypertuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"parameters = {\n    'quality_classification__C': [0.01, 0.1, 1],\n}\n\nparam_searcher = GridSearchCV(\n   estimator=lsvm_pipeline,\n   scoring='balanced_accuracy',\n   param_grid=parameters,\n   cv=5,\n   n_jobs=-1, \n   verbose=3\n)\n\n# param_searcher.fit(X_train, y_train)\n# param_searcher.best_params_, param_searcher.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"parameters = {\n    'quality_classification__C': [20, 60, 70, 80, 90],\n    'quality_classification__gamma': ['scale', 'auto', 0.01, 0.1, 1, 5, 10],\n}\n\nparam_searcher = GridSearchCV(\n   estimator=ksvm_pipeline,\n   scoring='balanced_accuracy',\n   param_grid=parameters,\n   cv=5,\n   n_jobs=-1, \n   verbose=3\n)\n\n#param_searcher.fit(X_train, y_train)\n#param_searcher.best_params_, param_searcher.best_score_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## DecisionTree"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\ntree_classifier = DecisionTreeClassifier(\n    max_depth=12,\n    max_leaf_nodes=65,\n    class_weight='balanced',\n    random_state=RANDOM_SEED,\n)\n\ntree_pipeline = Pipeline([\n    ('feature_processing', get_feature_transformer()),\n    ('quality_classification', tree_classifier),\n])\n\n## [CV] F1 Weighted: 0.5421 (0.0147), Balanced Accuracy: 0.5787 (0.0163)\n# max_leaf_nodes=25","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score_classification_model(tree_pipeline, X_train, y_train);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Hypertuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"parameters = {\n    'quality_classification__max_depth': np.arange(1, 15),\n    'quality_classification__max_leaf_nodes': np.arange(1, 80, 5),\n}\n\nparam_searcher = GridSearchCV(\n   estimator=tree_pipeline,\n   scoring='balanced_accuracy',\n   param_grid=parameters,\n   cv=5,\n   n_jobs=-1, \n   verbose=3\n)\n\nparam_searcher.fit(X_train, y_train)\nparam_searcher.best_params_, param_searcher.best_score_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## RandomForest"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_classifier = RandomForestClassifier(\n    criterion='entropy',\n    n_estimators=200,\n    max_depth=6,\n    max_leaf_nodes=10,\n    max_features='sqrt',\n    class_weight='balanced',\n    random_state=RANDOM_SEED,\n    n_jobs=-1,\n)\n\nrf_pipeline = Pipeline([\n    ('feature_processing', get_feature_transformer()),\n    ('quality_classification', rf_classifier),\n])\n\nrf_pipeline\n\n## F1 Weighted: 0.6949 (0.0167), Balanced Accuracy: 0.6948 (0.0211)\n# criterion='entropy',\n# n_estimators=179,\n# min_samples_split=5,\n# min_samples_leaf=4,\n# max_features='sqrt',\n# class_weight='balanced'\n\n## F1 Weighted: 0.4946 (0.0078), Balanced Accuracy: 0.5912 (0.0106)\n# criterion='entropy',\n# n_estimators=200,\n# max_depth=6,\n# max_leaf_nodes=10,\n# max_features='sqrt',\n# class_weight='balanced'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred, y_cv_pred = score_classification_model(rf_pipeline, X_train, y_train);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Inspection ðŸ”Ž"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_features = get_columns_from_transformer(rf_pipeline.named_steps['feature_processing'], list(X_train.columns))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features_importance = sorted(zip(rf_pipeline.named_steps['quality_classification'].feature_importances_, X_train_features), reverse=True)\npd.DataFrame(features_importance, columns=['importance', 'feature'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_transformed = rf_pipeline.named_steps['feature_processing'].fit_transform(X_train)\n\nrf_explainer = shap.TreeExplainer(rf_classifier)\nrf_explanation = rf_explainer.shap_values(X_train_transformed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shap.summary_plot(rf_explanation, X_train_transformed, X_train_features)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Generalization"},{"metadata":{"trusted":true},"cell_type":"code","source":"def score_model_generalization(model, X_test, y_test):\n    y_test_predicted = model.predict(X_test)\n\n    test_f1_weighted = f1_score(y_test, y_test_predicted, average='weighted')\n    test_balanced_accuracy = balanced_accuracy_score(y_test, y_test_predicted)\n\n    print('[Test] F1 Weighted: %.4f' % (test_f1_weighted))\n    print('[Test] Balanced Accuracy: %.4f' % (test_balanced_accuracy))\n    print('Test Set Report:')\n    print(classification_report(y_test, y_test_predicted, digits=3))\n\n    plot_confusion_matrix_by_predictions(\n        y_test, y_test_predicted,\n        cmap=plt.cm.Greens,\n        normalize='true',\n    )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"score_model_generalization(logistic_regression_pipeline, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Polynomial Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"score_model_generalization(polynomial_pipeline, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## SVM"},{"metadata":{"trusted":true},"cell_type":"code","source":"score_model_generalization(lsvm_pipeline, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score_model_generalization(psvm_pipeline, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score_model_generalization(ksvm_pipeline, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"score_model_generalization(rf_pipeline, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Summary ðŸ’«\n\nWine Quality database is a good example of datasets you may face in the real life. It's **imbalanced** and **quality classes** are hard to separate. It pushed us to rethinking the our classification objectives and assuming what we could potentialy sqeeze from it.\n\nWe have trained several models from a simple Logistic Regression and SVM to RandomForest and measured their performance with **balanced accuracy** metric.\n\nTurned out, the polinomial **SVC model** performs best for us:\n- CV: 63.88% (-+1.67%)\n- Test: 61.73% \n\nOur goal was to get the higher balanced accuracy while keeping a score difference between train and CV scores small.\n\nRandomForest and XGBoost are easily overfit and show around 70% of balanced accuracy on the CV and test datasets (while almost 100% on training sets). However, we don't believe these model would generalize when even if they showed good results on the current test set (which include only 1300 observations (20% of the overall dataset)).\n\n**Another approach to improve the accuracy** is to train two separate models for red and white wines. Meanwhile, the fact that quality classes are hardly separable makes us think it would be little improvement."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}