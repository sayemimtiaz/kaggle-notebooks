{"nbformat":4,"cells":[{"cell_type":"code","outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"metadata":{"_uuid":"40b18ce81a03b274b64761fdd8a74fb2dad34ed7","_cell_guid":"f1888510-e51d-4908-8656-16cb484d0f4b","_execution_state":"idle"}},{"cell_type":"code","outputs":[],"source":"#from pandas_confusion import ConfusionMatrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport sklearn as sk\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.model_selection import cross_val_score\n%matplotlib inline","execution_count":null,"metadata":{"_uuid":"62fcbefe809cc1d57d966c7c36e0cd1ad1269aa7","collapsed":true,"_cell_guid":"cc7b5087-bb83-410b-8de7-b327290dd951","_execution_state":"idle"}},{"cell_type":"code","outputs":[],"source":"df = pd.read_csv('../input/zoo.csv')\nprint(df.shape)\ncols = df.columns.tolist\n\ndf = sk.utils.shuffle(df)\n#df = df.reindex(index=range(df.index.size))\ndf.head()\n","execution_count":null,"metadata":{"_uuid":"1e434865cdb0832326f757abcb100db105ddfda0","_cell_guid":"3e1d3a0e-a2ba-4e20-ae92-6458b9f7df68","_execution_state":"idle"}},{"cell_type":"code","outputs":[],"source":"testCarogna = pd.DataFrame(columns=df.columns,dtype=int)\nrowRemove = []\nfor i in range(1,8):\n    for index,row in df.iterrows():\n        if (row[17]==i and row[13]!=5 and row[0]!='frog'):\n            testCarogna.loc[i]= row\n            rowRemove.append(index)\n            i=i+1\n            break\n\ndf.drop(rowRemove, inplace=True)\ntestCarogna","execution_count":null,"metadata":{"_uuid":"2648ecce3c5698f5379ca6ae75083e08e2e7d53e","_cell_guid":"35c9de4a-1217-40b7-9fc3-1a390c59f5f1","_execution_state":"idle"}},{"cell_type":"code","outputs":[],"source":"cols = df.columns.tolist\ncols","execution_count":null,"metadata":{"_uuid":"f1e38ae267871c4bdf86d21487493bccf85d52fe","_cell_guid":"69f00017-e2e4-4166-8540-76f9d946cd5f","_execution_state":"idle"}},{"cell_type":"code","outputs":[],"source":"df.info()","execution_count":null,"metadata":{"_uuid":"955d812faed2d5047b0ef9d6e17cff66cae5433d","_cell_guid":"57ff1f23-5b8a-4805-ac58-6f3152582416","_execution_state":"idle"}},{"cell_type":"code","outputs":[],"source":"df.describe()","execution_count":null,"metadata":{"_uuid":"961b218254403d07880018bc4cb7b1adf0124f03","_cell_guid":"6b0392f9-71c0-465c-afe2-8180bb3efabb","_execution_state":"idle"}},{"cell_type":"code","outputs":[],"source":"sns.countplot(df['class_type'])\npd.Series.value_counts(df['class_type'])\n# 1 \t40\tMammal\n# 2 \t19\tBird\n# 3 \t4\tReptile\n# 4 \t12\tFish\n# 5 \t3\tAmphibian\n# 6 \t7\tBug\n# 7 \t9\tInvertebrate","execution_count":null,"metadata":{"_uuid":"dc84377511d1455e714d84d002995aeeca347cfc","_cell_guid":"1b3f4e81-6178-4628-b1db-fce21ffffa99","_execution_state":"idle"}},{"cell_type":"code","outputs":[],"source":"#knn \nfrom sklearn import neighbors\n\ncols_X =['hair', 'feathers', 'eggs', 'milk', 'airborne',\n       'aquatic', 'predator', 'toothed', 'backbone', 'breathes', 'venomous',\n       'fins', 'legs', 'tail', 'domestic', 'catsize']\ncols_Y = ['class_type']\n\nsco = []\nscobru = []\nsco_ = 0\nbestk=0\nfor j in range(1,10):\n    neigh = sk.neighbors.KNeighborsClassifier(n_neighbors=j)\n    for i in range(10):\n        \n        df_nn = sk.utils.shuffle(df)\n        df_nn = df_nn.reset_index()\n        df_nn = df_nn.drop('index',axis=1)\n        \n        #split \n        X_train, X_test, y_train, y_test = sk.cross_validation.train_test_split(\n        df_nn[cols_X], df_nn[cols_Y], test_size=0.3, random_state=10)\n        #knn\n        neigh.fit(X_train, y_train.values.ravel())\n        predict = neigh.predict(X_test)\n        sco.append(neigh.score(X_test,y_test))\n        #val_sco = cross_val_score(neigh, X = df_nn[cols_X], y = df_nn[cols_Y])\n        #sco.append(np.mean(val_sco))\n    if(np.mean(sco)>sco_):\n        bestk = j\n        sco_ = np.mean(sco)\n    #print(\"ksco: \"+str(np.mean(sco)))\n    sco.clear\nprint(\"best k: \"+str(bestk))\nneigh = sk.neighbors.KNeighborsClassifier(n_neighbors=bestk)\n\nsco = []\nfor i in range(100):\n    \n    df_nn = sk.utils.shuffle(df)\n    #df_nn = df_nn.reset_index()\n    #df_nn = df_nn.drop('index',axis=1)\n    \n    #split \n    X_train, X_test, y_train, y_test = sk.cross_validation.train_test_split(\n    df_nn[cols_X], df_nn[cols_Y], test_size=0.3, random_state=2*i)\n    #knn\n    neigh.fit(X_train, y_train.values.ravel()) \n\n    predict = neigh.predict(X_test)\n    sco.append(neigh.score(X_test,y_test))\n    if(neigh.score(X_test,y_test)<0.9):\n        y_test_err = y_test\n    ##predict = neigh.predict(testCarogna[cols_X])\n    ##scobru.append(neigh.score(testCarogna[cols_X],testCarogna[cols_Y]))\nprint(\"score x_test: \"+str(np.mean(sco)))","execution_count":null,"metadata":{"_kg_hide-input":false,"_uuid":"920d92c75071a35595045f7219cf4c29bc72ec69","_cell_guid":"36c8a826-719d-4f30-8d15-7ca1bdc14028","_execution_state":"idle"}},{"cell_type":"code","outputs":[],"source":"def plot_correlation_map( df ):\n    corr = df.corr()\n    _ , ax = plt.subplots( figsize =( 14 , 12 ) )\n    cmap = sns.diverging_palette( 220 , 10 , as_cmap = True )\n    _ = sns.heatmap(\n        corr, \n        cmap = cmap,\n        square=True, \n        cbar_kws={ 'shrink' : .9 }, \n        ax=ax, \n        annot = True, \n        annot_kws = { 'fontsize' : 8 }\n    )","execution_count":null,"metadata":{"_uuid":"a24fc5ddb092fc1a576e6458fc6fdaaed85eb773","collapsed":true,"_cell_guid":"404d5e6e-4821-4c00-871e-90851648adcf","_execution_state":"idle"}},{"cell_type":"code","outputs":[],"source":"# CORRELATION MATRIX  \nplot_correlation_map(df)\n","execution_count":null,"metadata":{"_uuid":"76025720ad1e6c9c11ab435bd74eff2d2a1c0491","_cell_guid":"2d6905b6-113b-40a1-b3f7-dee4ecc7e09e","_execution_state":"idle"}},{"cell_type":"code","outputs":[],"source":"import itertools\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    \n    \n# CONFUSION MATRIX  - use test_err\n    #from pandas_ml import ConfusionMatrix\n    #from pandas_confusion import ConfusionMatrix\nfrom sklearn.metrics import confusion_matrix\np= pd.DataFrame(predict,dtype=int, index=y_test_err.index)\np.columns = ['pred']\nconfusion_matrix = confusion_matrix(y_test_err['class_type'], p['pred'])\n#print(\"Confusion matrix:\\n%s\" % confusion_matrix)\nplot_confusion_matrix(confusion_matrix, classes=cols_Y)","execution_count":null,"metadata":{"_uuid":"55228c55ca4246e6281902fc4406f35dcaf8c77f","_cell_guid":"77f7faa7-7f74-40e4-bdd9-5f5acaeb473e","_execution_state":"idle"}},{"cell_type":"code","outputs":[],"source":"#'legs' -> dummy\n\ndf_legs = pd.DataFrame()\ndf_legs = pd.get_dummies(df['legs'],sparse=True)\ncolsLegs = ['legs0','legs2','legs4','legs5','legs6','legs8']\ndf_legs.columns = colsLegs\ndf_legs.head()\n","execution_count":null,"metadata":{"_uuid":"7a54a429ee4a4414c8a8f6a6242b2201737e69d8","_cell_guid":"c3bc8c37-d2e9-4cf0-b270-2589931e053b","_execution_state":"idle"}},{"cell_type":"code","outputs":[],"source":"# output dummy \n\ndf_class = pd.DataFrame()\ndf_class = pd.get_dummies(df['class_type'],sparse=True)\ncolsName = ['Mammal','Bird','Reptile','Fish','Amphibian','Bug','Invertebrate']\ndf_class.columns = colsName\ndf_class.head()","execution_count":null,"metadata":{"_uuid":"9c6e36cd3d9b91c0cab8be041bf2e8557820465a","_cell_guid":"232c91d7-e329-4359-a7b1-bcedf9462261","_execution_state":"idle"}},{"cell_type":"code","outputs":[],"source":"df_corr = df.join(df_legs)\ndf_corr = df_corr.join(df_class)\ndf_corr = df_corr.drop(['legs'],axis=1)\ndf_corr = df_corr.drop(['class_type'],axis=1)\n\nplot_correlation_map(df_corr) ","execution_count":null,"metadata":{"_uuid":"60daa37d9fdcb4d702f30b810d5b5da48ac55164","_cell_guid":"2c480fd3-703b-4d38-b5c3-7e59c29d3bd4","_execution_state":"idle"}},{"cell_type":"code","outputs":[],"source":"# df_n\n\ndf_n = df.join(df_legs)\ndf_n = df_n.drop(['legs'],axis=1)\ndf_n = df_n.drop(['legs4'],axis=1)\n\ndf_n.head()\n\ndf_n  = df_n.drop(['animal_name'],axis=1)\ndf_n = df_n.astype(int)\n\n#new coolumns\nl = df_n.columns.tolist\ncolsX_ = ['hair', 'feathers', 'eggs', 'milk', 'airborne',\n       'aquatic', 'predator', 'toothed', 'backbone', 'breathes', 'venomous',\n       'fins', 'legs0','legs2','legs5','legs6','legs8', 'tail', 'domestic', 'catsize']\ncolsY = ['class_type']\nprint(l)","execution_count":null,"metadata":{"_uuid":"68c9613dd0cfaa2375fd44adc92f0cc074fffbf4","_cell_guid":"706ce007-222f-4fca-8081-3918221a1399","_execution_state":"idle"}},{"cell_type":"code","outputs":[],"source":"# FEATURES SELECTION\nfrom sklearn.svm import SVC\n#from sklearn.naive_bayes import MultinomialNB\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.feature_selection import RFECV\nfrom sklearn.datasets import make_classification\n\n# Create the RFE object and compute a cross-validated score.\nsvc = SVC(kernel=\"linear\",C=0.01) #Penalty parameter C of the error term.\n#nvb = MultinomialNB(alpha=0.5)\n# The \"accuracy\" scoring is proportional to the number of correct\n# classifications\nrfecv = RFECV(estimator=svc, step=1, cv=StratifiedKFold(3),\n              scoring='accuracy')","execution_count":null,"metadata":{"_uuid":"2e43c207e0453bbb13ff4194e80b901d14dc6482","collapsed":true,"_cell_guid":"21b6a847-1ad6-4b65-9533-8fb590d0b486","_execution_state":"idle"}},{"cell_type":"code","outputs":[],"source":"rfecv.fit(df_n[colsX_], df_n[colsY].values.ravel())\nrfopt = rfecv\nn_fest_opt = rfecv.n_features_\ndf_nn = df_n\nrfopt_sup = rfecv.support_\nrfopt_grid = rfecv.grid_scores_ \nprint ('n_fest_opt:')\nprint (n_fest_opt)\ncBest = 0.1\ncScore = 0\n\nprint('best c value:' )\n#set c\nfor c in [0.001,0.01,0.1,1,10,100,1000]:\n    svc.C=c\n    rfecv.fit(df_n[colsX_], df_n[colsY].values.ravel())\n    if(rfecv.score(df_n[colsX_], df_n[colsY])>cScore):\n        print(c)\n        cBest = c\n        cScore = rfecv.score(df_n[colsX_], df_n[colsY])\n\nsvc.C = cBest\n\n# rfecv 10 times\nfor k in range(10):\n    df_n = sk.utils.shuffle(df_n)\n    #df_n = df_n.reset_index()\n    #df_n = df_n.drop('index',axis=1)\n    \n    rfecv.fit(df_n[colsX_], df_n[colsY].values.ravel())\n    if(rfecv.n_features_<n_fest_opt and rfecv.score(df_n[colsX_], df_n[colsY])>0.8):\n        print(\"nfeat:\")\n        print(rfecv.n_features_)\n        df_nn = df_n\n        rfopt_sup = rfecv.support_\n        rfopt_grid = rfecv.grid_scores_      \n        n_fest_opt = rfecv.n_features_\n\n#best features \ncolsXopt = []\nmask = rfopt_sup\nprint(mask)\nprint(mask.shape)\nfor i in range(len(mask)):\n    if (mask[i] == True):\n        colsXopt.append(colsX_[i])\n\nprint(\"Optimal number of features : %d\" % n_fest_opt)\n\n# Plot number of features VS. cross-validation scores\nplt.figure()\nplt.xlabel(\"Number of features selected\")\nplt.ylabel(\"Cross validation score (nb of correct classifications)\")\nplt.plot(range(1, len(rfopt_grid) + 1), rfopt_grid)\nplt.show()\nprint(\"list of best features: \"+str(colsXopt))","execution_count":null,"metadata":{"_uuid":"68fc541ee685b57716ad81734bcabf368f20bbbd","_cell_guid":"3c747854-48bc-4bfa-a29b-668d63d5ea92","_execution_state":"idle"}},{"cell_type":"code","outputs":[],"source":"# PAIRPLOT (best features)\n\nc = colsXopt.copy()\nc.append('class_type')\nsns.pairplot(df_n[c],hue='class_type')\n","execution_count":null,"metadata":{"_uuid":"15534d65783da6e722a50f2e7406d3dc8db76544","_cell_guid":"1431797e-9b32-4a25-ba81-01bbc7a24074","_execution_state":"idle"}},{"cell_type":"code","outputs":[],"source":"# repeat knn ('legs' is dummy, best features )\n\nsco = []\nstop = 0\nprint('some wrong predictions:')\nfor i in range(100):\n    df_nn = sk.utils.shuffle(df_n)\n        #df_nn = df_nn.reset_index()\n        #df_nn = df_nn.drop('index',axis=1)\n    #split \n    X_train, X_test, y_train, y_test = sk.cross_validation.train_test_split(\n    df_nn[colsXopt], df_nn[colsY], test_size=0.3, random_state=10)\n    #knn\n    neigh.fit(X_train, y_train.values.ravel()) \n\n    predict = neigh.predict(X_test)\n    sco.append(neigh.score(X_test,y_test))\n    \n    if(neigh.score(X_test,y_test)<1):\n        tmp = df.drop(['class_type'],axis=1)\n        #print(y_test.index)\n        #print(pd.DataFrame(predict))\n        p = pd.DataFrame(predict,dtype=int, index=y_test.index)\n        y_test['predict'] = p\n        tmp = tmp.join(y_test,how='inner')\n        #print(tmp.shape)\n        for i in range(tmp.shape[0]):\n            if (tmp.iloc[i][17] != tmp.iloc[i][18] and stop<10):\n                stop = stop +1 \n                print(\"  \"+str(tmp.iloc[i][0]))\n                print(\"     class_type: \"+str(tmp.iloc[i][17]) )\n                print(\"     predict: \"+str(tmp.iloc[i][18]) )\nprint(\"\\nscore medio: \")\nprint(np.mean(sco))","execution_count":null,"metadata":{"_uuid":"63c35501ef479e748ec02f0ea206753c8e9004ce","_cell_guid":"b9de98b7-bec7-429c-a38e-6d89969ff1c3","_execution_state":"idle"}},{"cell_type":"code","outputs":[],"source":"# knn graphics idea\nimport hypertools as hyp \nhyp.plot(df_n[colsX_],'m.')","execution_count":null,"metadata":{"_uuid":"d70df424770297906bc97a61fbec8518ad952d2f","_cell_guid":"b39b786e-2730-47e2-b513-d0c17925b75e","_execution_state":"idle"}},{"cell_type":"code","outputs":[],"source":"hyp.plot(df_n,'o', group=colsX_, legend=list(set(colsX_)))","execution_count":null,"metadata":{"_uuid":"dead193ea79699944ee5e435b7139f3a74930e4e","_cell_guid":"b33b6a26-2c31-4d56-9ebd-a989e79d2b38","_execution_state":"idle"}},{"cell_type":"code","outputs":[],"source":"hyp.plot(df_n, 'o', n_clusters=7)\n\n# you can also recover the cluster labels using the cluster tool\ncluster_labels = hyp.tools.cluster(df_n, n_clusters=7, ndims=2) \n","execution_count":null,"metadata":{"_uuid":"bb192dc86e3f1492d9751510a111c29ffe94021b","_cell_guid":"f0234701-211e-4541-ac14-1fcbdd2cdc43","_execution_state":"idle"}},{"cell_type":"code","outputs":[],"source":"# balancing -> repeat samples: features are generic(deer and buffalo have the same values)\n\nfrog = df.loc[df['animal_name'] == 'frog']\nsns.countplot(df['class_type'])\n\nfrog","execution_count":null,"metadata":{"_uuid":"68707f470cee78dfa5547c8a7407a1df16558d5d","_cell_guid":"da034b34-76fb-43c1-bd6b-9a9d0ebd555e","_execution_state":"idle"}},{"cell_type":"code","outputs":[],"source":"df_c3 = df_n.loc[df_n['class_type'] == 3]\ndf_c5 = df_n.loc[df_n['class_type'] == 5]\ndf_c6 = df_n.loc[df_n['class_type'] == 6]\n\ndf_adj = pd.concat([df_n,df_c3])\ndf_adj = pd.concat([df_adj,df_c3])\ndf_adj = pd.concat([df_adj,df_c5])\ndf_adj = pd.concat([df_adj,df_c5])\ndf_adj = pd.concat([df_adj,df_c6])\n\ndf_adj = sk.utils.shuffle(df_adj)\n\n\nsns.countplot(df_adj['class_type'])","execution_count":null,"metadata":{"_uuid":"c95f34e369b1bbebba9de5c802d5e77b33cd0357","_cell_guid":"afd4a8c8-0f25-49cc-9b82-805fa06e247b","_execution_state":"idle"}},{"cell_type":"code","outputs":[],"source":"# repeat knn\n\nsco = []\nfor i in range(1,20):\n    #split \n    df_adj = sk.utils.shuffle(df_adj)\n    #df_adj = df_adj.reset_index()\n    #df_adj = df_adj.drop('index',axis=1)\n\n    X_train, X_test, y_train, y_test = sk.cross_validation.train_test_split(\n    df_adj[colsXopt], df_adj[colsY], test_size=0.3, random_state=42)\n    #knn\n    neigh.fit(X_train, y_train.values.ravel()) \n\n    predict = neigh.predict(X_test)\n    sco.append(neigh.score(X_test,y_test))\n    print(\"score: \"+str(neigh.score(X_test,y_test)))\n    if(neigh.score(X_test,y_test)<1):\n        tmp = df.drop(['class_type'],axis=1)\n        #print(y_test.index)\n        #print(pd.DataFrame(predict))\n        p = pd.DataFrame(predict,dtype=int, index=y_test.index)\n        y_test['predict'] = p\n        tmp = tmp.join(y_test,how='inner')\n        #print(tmp.shape)\n        for i in range(tmp.shape[0]):\n            if (tmp.iloc[i][17] != tmp.iloc[i][18]):\n                print(\"  \"+str(tmp.iloc[i][0]))\n                print(\"     class_type: \"+str(tmp.iloc[i][17]) )\n                print(\"     predict: \"+str(tmp.iloc[i][18]) )\n                \n    \n    \nprint(\"---\")\nprint(\"score medio: \"+str(np.mean(sco)))\nprint(\"---\")\nprint(\"last prediction: \")\ntmp","execution_count":null,"metadata":{"_uuid":"7644522fb4c1a3dd0ed9066eb2b5875750d4abef","_cell_guid":"2bfa1f67-abb1-46c6-8186-8f3f738e4e35","_execution_state":"idle"}},{"cell_type":"code","outputs":[],"source":"df_adj = df_adj.reset_index()\ndf_adj = df_adj.drop('index',axis=1)","execution_count":null,"metadata":{"_uuid":"aa22186e94c1fcbbff8fd915b6a0c7bc96c87ca0","collapsed":true,"_cell_guid":"32aa46e7-bc9b-493f-95b2-6ca995b40134","_execution_state":"idle"}},{"cell_type":"code","outputs":[],"source":"df_legs = pd.get_dummies(testCarogna['legs'],sparse=True)\n\ndf_legs = df_legs.rename_axis({0.0: \"legs0\", 2.0: \"legs2\",4.0: \"legs4\",5.0: \"legs5\",6.0: \"legs6\",8.0: \"legs8\"}, axis=\"columns\")\n\ntestCarogna = testCarogna.join(df_legs)\ntestCarogna = testCarogna.drop(['legs'],axis=1)\ntestCarogna = testCarogna.drop(['legs4'],axis=1)\ntestCarogna","execution_count":null,"metadata":{"_uuid":"5728804165484eeffaab2cb99172be5575459039","_cell_guid":"9862dc1f-c0c7-48a7-b815-978307cdf815","_execution_state":"idle"}},{"cell_type":"code","outputs":[],"source":"copt= colsXopt.copy()\nif 'legs0' in copt:\n    copt.remove('legs0')\n    copt.append(0.0)\nif 'legs2' in copt:\n    copt.remove('legs2')\n    copt.append(2.0)\nif 'legs5' in copt:\n    copt.remove('legs5')\n    copt.append(5.0)\nif 'legs6' in copt:\n    copt.remove('legs6')\n    copt.append(6.0)\nif 'legs8' in copt:\n    copt.remove('legs8')\n    copt.append(8.0)\n\n    \nprint('col opt:')    \nprint(copt)\n\n###--------------------------\n\n","execution_count":null,"metadata":{"_uuid":"7025c296896ae8974058701c17d4528c38c22536","_cell_guid":"5394f1e0-df51-4f13-9af4-61e50f4ed295","_execution_state":"idle"}},{"cell_type":"code","outputs":[],"source":"predict = neigh.predict(testCarogna[colsXopt])\n#print(\"score: \"+str(neigh.score(testCarogna[colsXopt],testCarogna[colsY])))\n\np= pd.DataFrame(predict,dtype=int, index=testCarogna.index)\np.columns = ['pred']\nprint('testCarogna prediction:')\nprint( p)\n#cm(y_test, y_pred)\n#---confusion_matr = confusion_matrix(testCarogna['class_type'],p['pred'])\n#print(\"Confusion matrix:\\n%s\" % confusion_matrix)\n#---plot_confusion_matrix(confusion_matr, classes=colsY)\n#plt.show()\n\ntestCarogna[colsXopt].astype(int)\ntestCarogna","execution_count":null,"metadata":{"_uuid":"eb06c08b2b4dcfd782d9b37b81744000a172b1d7","_cell_guid":"79277e61-a878-48da-bdfa-b02a61708a91"}},{"cell_type":"code","outputs":[],"source":"print(df_adj.columns.tolist)\nprint(testCarogna.columns.tolist)","execution_count":null,"metadata":{"_uuid":"15e4fa4bcd42df323156e3d41215f09580d2bc5c","_cell_guid":"fa02b513-e495-4ff4-b658-e42be1588b24","_execution_state":"idle"}},{"cell_type":"code","outputs":[],"source":"df_union = pd.concat([df_adj[colsXopt],testCarogna[colsXopt]],ignore_index=True)\ndf_union_target = pd.concat([df_adj[colsY],testCarogna[colsY]],ignore_index=True)\n\ndf_union.head()","execution_count":null,"metadata":{"_uuid":"011032bf3694ae425fd3269326a1ae3dc8a0c103","_cell_guid":"6016deb0-3f03-4c89-a71b-5c435521d8cd","_execution_state":"idle"}},{"cell_type":"code","outputs":[],"source":"#-----------------------------------------------------------------------------\n#------------------------PCA SU df_n con colsXopt-----------------------------\n#-----------------------------------------------------------------------------\nfrom sklearn.decomposition import PCA","execution_count":null,"metadata":{"_uuid":"7d62f07d9620e9aef53fde36247ffa99c12e8f30","collapsed":true,"_cell_guid":"a35aaf40-1c0f-46f5-a580-f8b373fbb27b","_execution_state":"idle"}},{"cell_type":"code","outputs":[],"source":"scaler = StandardScaler().fit(df_union)\nzoo_scaled = scaler.transform(df_union)\n\nprint(zoo_scaled[:,0].mean())  # zero (or very close)\nprint(zoo_scaled[:,0].std())  # 1 (or very close)\n","execution_count":null,"metadata":{"_uuid":"8fce7444b91b2a837d4b2c2c20134625bb4c30e9","_cell_guid":"d06dc72b-1d62-421e-831f-d3e41e144eb9","_execution_state":"idle"}},{"cell_type":"code","outputs":[],"source":"pca = PCA(n_components=0.9)  # consider enough components to explain 90% of the variance\npca.fit(zoo_scaled)\npcscores = pd.DataFrame(pca.transform(zoo_scaled))\npcscores.columns = ['PC'+str(i+1) for i in range(len(pcscores.columns))]\nloadings = pd.DataFrame(pca.components_, columns=colsXopt)\nloadings.index = ['PC'+str(i+1) for i in range(len(pcscores.columns))]","execution_count":null,"metadata":{"_uuid":"35d61cb1d8a61106c890b2e48a907d9de14e6579","collapsed":true,"_cell_guid":"5058cdd3-17bf-4ded-9b9a-dde832512f32","_execution_state":"idle"}},{"cell_type":"code","outputs":[],"source":"ax = sns.heatmap(loadings.transpose(), center=0, linewidths=0.5, \n                 cmap=\"RdBu\", vmin=-1, vmax=1, annot=True)\nax.set_xticklabels(ax.xaxis.get_majorticklabels(), rotation=0, fontsize=8)\nax.set_yticklabels(ax.yaxis.get_majorticklabels(), rotation=0, fontsize=8)\n","execution_count":null,"metadata":{"_uuid":"f23290269244f2526a754db9e45501a814dd3509","_cell_guid":"5fa66814-ca33-4975-ac4b-98a43adb7a63","_execution_state":"idle"}},{"cell_type":"code","outputs":[],"source":"pcscores.head()","execution_count":null,"metadata":{"_uuid":"aad6a8b3d310cec1685b682e19ca99768cc3cf1d","_cell_guid":"e78a0e4a-9ff3-4d83-91b6-fcab11528d70","_execution_state":"idle"}},{"cell_type":"code","outputs":[],"source":"# knn following pca\nsco = []\nprint(X_train.columns)\nprint(y_test.columns)\nfor i in range(1,100):\n\n   \n    #split \n    X_train, X_test, y_train, y_test = sk.cross_validation.train_test_split(\n        pcscores, df_union_target, test_size=0.2, random_state=42*i)\n    #knn\n    \n    #neigh.fit(X_train, y_train) \n    #np.asarray(train['P1'], dtype=\"|S6\")\n    neigh.fit(X_train, np.asarray(y_train['class_type'], dtype=\"|S6\"))\n\n    predict = neigh.predict(X_test)\n    sco.append((neigh.score(X_test,np.asarray(y_test['class_type'], dtype=\"|S6\"))))\nprint(\"score: \"+str(np.mean(sco)))\n","execution_count":null,"metadata":{"_uuid":"43abcc98a5cc5388510fb00b0bf2eecc7a65cfa5","_cell_guid":"940bf70e-3045-4607-af4f-c034efe824ee","_execution_state":"idle"}},{"cell_type":"code","outputs":[],"source":"# cambio valori a n_components, ora ho provato con 90% della varianza magari usando un numero diverso di \n# features(output) diverso le cose migliorano.\n# ottengo comunque score piÃ¹ bassi di prima\n\nn_feat = []\n\nprint(\"cambio valori a n_components\")\nfor j in range(1,len(colsXopt)):\n    pca = PCA(n_components=j)  # consider enough components to explain 80% of the variance\n    pca.fit(zoo_scaled)\n    pcscores = pd.DataFrame(pca.transform(zoo_scaled))\n    pcscores.columns = ['PC'+str(i+1) for i in range(len(pcscores.columns))]\n    loadings = pd.DataFrame(pca.components_, columns=colsXopt)\n    loadings.index = ['PC'+str(i+1) for i in range(len(pcscores.columns))]\n\n    sco = [];\n    for r in range(1,100):\n\n        #split \n        X_train, X_test, y_train, y_test = sk.cross_validation.train_test_split(\n        pcscores, df_union_target, test_size=0.2, random_state=42*r)\n        #knn\n        neigh.fit(X_train,np.asarray(y_train['class_type'], dtype=\"|S6\")) \n\n        predict = neigh.predict(X_test)\n        sco.append((neigh.score(X_test,np.asarray(y_test['class_type'], dtype=\"|S6\"))))\n    print(\"score con  \"+str(j)+\" features\")\n    print(np.mean(sco))\n    n_feat.append(np.mean(sco))\nprint(\"array di score: \")\nprint(n_feat)","execution_count":null,"metadata":{"_uuid":"58c43d12b2198601b762547572ebb5f55b49f640","_cell_guid":"cace3215-5398-4450-a1da-922e77bc7502"}},{"cell_type":"code","outputs":[],"source":"opt_feat = 0\nmaxind = 0\nfor i in range(len(n_feat)):\n        if(n_feat[i]>opt_feat):\n            opt_feat=n_feat[i]\n            maxind = i+1\n        \nopt_feat","execution_count":null,"metadata":{"_uuid":"97b21e50122be8e65ff71c3e6958911eeee24a6f","_cell_guid":"b36513f2-f4f4-4d8d-b27f-5b2eef5bb330","_execution_state":"idle"}},{"cell_type":"code","outputs":[],"source":"df_pca = pcscores.iloc[:115, :maxind]\ntestCarogna_pca = pcscores.iloc[115:, :maxind]\n\ndf_pca_target = df_union_target.iloc[:115, :]\ntestCarogna_pca_target = df_union_target.iloc[115:, :]\n\ntestCarogna_pca","execution_count":null,"metadata":{"_uuid":"c2b69883bde6c7d366dc15c9fc198389488cae2b","_cell_guid":"22f9fa05-a1f3-4508-af1e-01da8a18143b","_execution_state":"idle"}},{"cell_type":"code","outputs":[],"source":"pca = PCA(n_components=maxind)  # consider enough components to explain 80% of the variance\npca.fit(zoo_scaled)\npcscores = pd.DataFrame(pca.transform(zoo_scaled))\npcscores.columns = ['PC'+str(i+1) for i in range(len(pcscores.columns))]\nloadings = pd.DataFrame(pca.components_, columns=colsXopt)\nloadings.index = ['PC'+str(i+1) for i in range(len(pcscores.columns))]\n\n#split \nX_train, X_test, y_train, y_test = sk.cross_validation.train_test_split(\npcscores, df_union_target, test_size=0.2, random_state=42*r)\n#knn\nneigh.fit(X_train, np.asarray(y_train['class_type'], dtype=\"|S6\")) \n\npredict = neigh.predict(X_test)\nprint(\"score di test con  \"+str(maxind)+\" features:\")\nprint((neigh.score(X_test,np.asarray(y_test['class_type'], dtype=\"|S6\"))))\n#print (testCarogna_pca.shape)\n#print (X_test.shape)\n\npredict = neigh.predict(testCarogna_pca)\nprint(\"score di testCarogna: \"+str(neigh.score(testCarogna_pca,np.asarray(testCarogna_pca_target['class_type'], dtype=\"|S6\"))))\n                                               #testCarogna_pca_target)))\ntestCarogna_pca","execution_count":null,"metadata":{"_uuid":"09baabf11eac77e1e32f43e389b967acf8615974","_cell_guid":"e7d7b83a-e6f8-45cd-9a2c-bd01fd1ce26d","_execution_state":"idle"}},{"cell_type":"code","outputs":[],"source":"#-----------------------------------------------------------------------------\n#------------------------BATTLE OF ALGORITHMS--------------------------------- su pca\n#-----------------------------------------------------------------------------\n\nfrom sklearn import svm\nfrom sklearn.neural_network import MLPClassifier","execution_count":null,"metadata":{"_uuid":"51f343b41a467251a685714bf7f151ac86fea53d","collapsed":true,"_cell_guid":"b16fa407-e2b7-487c-a223-76df8a60e623","_execution_state":"idle"}},{"cell_type":"code","outputs":[],"source":"# dataset for battle\nX_train, X_test, y_train, y_test = sk.cross_validation.train_test_split(\n    df_pca, df_pca_target, test_size=0.3, random_state=40)\n","execution_count":null,"metadata":{"_uuid":"e4f0680201953f6c260326455c6c1918d8af9a31","collapsed":true,"_cell_guid":"c39461f2-4880-4061-83cd-7c1b7e501c65","_execution_state":"idle"}},{"cell_type":"code","outputs":[],"source":"# sklearn.svm.SVC\n\nclf = svm.SVC(decision_function_shape='ovo')\nclf.fit(X_train, np.asarray(y_train['class_type'], dtype=\"|S6\")) \n\nclf.predict(X_test)\nprint(\"score svm: \"+str(clf.score(X_test,np.asarray(y_test['class_type'], dtype=\"|S6\"))))\n\nclf.predict(testCarogna_pca)\nprint(\"score svm di testCarogna: \"+str(clf.score(testCarogna_pca,np.asarray(testCarogna_pca_target['class_type'], dtype=\"|S6\"))))\n","execution_count":null,"metadata":{"_uuid":"13e51e934e6d599f632b2508dc17b1398f1da9bc","_cell_guid":"fdd6f94e-a003-416f-b0ee-cc7599d64b65","_execution_state":"idle"}},{"cell_type":"code","outputs":[],"source":"# sklearn.svm.SVC --- weight\n\nclf = svm.SVC(decision_function_shape='ovo', class_weight= 'balanced' )\n# stampo pesi ottenuti con 'balanced', da documentazione\nweigth_ = (df_adj.shape[1] / (7 * np.bincount(df_adj.class_type.values)))\nweigth_ = weigth_[1:]\nprint(weigth_)\n\nsampl_to_wei = []\nfor index,row in df.iterrows():\n        if (row[17]==3 or row[17]==5 or row[17]==7):\n            sampl_to_wei.append(row.index)\n            \nclf.fit(X_train,np.asarray(y_train['class_type'], dtype=\"|S6\")) \n\nclf.predict(X_test)\nprint(clf.score(X_test,np.asarray(y_test['class_type'], dtype=\"|S6\")))\n    \n\nclf.predict(testCarogna_pca)\nprint(\"score svm pesato di testCarogna: \"+str(clf.score(testCarogna_pca,np.asarray(testCarogna_pca_target['class_type'], dtype=\"|S6\"))))\n","execution_count":null,"metadata":{"_uuid":"75a517530ee347aa12686cf65b5807fb46fcacb5","_cell_guid":"b2dfddc4-c450-445e-9826-5218fcb29139","_execution_state":"idle"}},{"cell_type":"code","outputs":[],"source":" # sklearn.neural_network.MLPClassifier \nbesti = 0\nbestj = 0\nbestsco = 0\nfor i in range(1,10):\n        for j in range(1,10):\n                clf = MLPClassifier(solver='lbfgs',activation = 'logistic', alpha=1e-5,\n                                    hidden_layer_sizes=(j,i), random_state=1)\n                sco = []\n                for k in range(5):\n                        XX_train, XX_test, yy_train, yy_test = sk.cross_validation.train_test_split(\n                        df_pca, df_pca_target, test_size=0.3, random_state=40)\n                        clf.fit(XX_train,np.asarray(yy_train['class_type'], dtype=\"|S6\"))\n                        clf.predict(XX_test)\n                        sco.append(clf.score(XX_test,np.asarray(yy_test['class_type'], dtype=\"|S6\")))\n                if(np.mean(sco)>bestsco):\n                    bestsco = np.mean(sco)\n                    besti = i\n                    bestj = j\n\nprint(\"best i: \"+str(besti))\nprint(\"best j: \"+str(bestj))\nclf = MLPClassifier(solver='lbfgs', activation = 'logistic',alpha=1e-5,\n                     hidden_layer_sizes=(bestj,besti), random_state=1)\n\nclf.fit(X_train, np.asarray(y_train['class_type'], dtype=\"|S6\")) \n\nclf.predict(X_test)\nprint(clf.score(X_test,np.asarray(y_test['class_type'], dtype=\"|S6\")))\n\nclf.predict(testCarogna_pca)\nprint(\"score reteneurale di testCarogna: \"+str(clf.score(testCarogna_pca,np.asarray(testCarogna_pca_target['class_type'], dtype=\"|S6\"))))\n\n ","execution_count":null,"metadata":{"_uuid":"1802445d44a1db2f2145019b36c23627824ea1d1","_cell_guid":"ab739057-0f24-4644-87c8-29728f8e3ad3","_execution_state":"idle"}},{"cell_type":"code","outputs":[],"source":"# neural network autoset\nclf = MLPClassifier(solver='lbfgs',activation = 'logistic', alpha=1e-5, shuffle=True,early_stopping=True,\n                    validation_fraction = 0.2, random_state=1)\n\n#print(\"autoset i: \"+str(clf.hidden_layer_sizes))\n#print(\"autoset j: \"+str(clf.hidden_layer_sizes))\n\nclf.fit(X_train, np.asarray(y_train['class_type'], dtype=\"|S6\")) \n\nclf.predict(X_test)\nprint(\"score reteneurale: \"+str(clf.score(X_test,np.asarray(y_test['class_type'], dtype=\"|S6\"))))\n\nclf.predict(testCarogna_pca)\nprint(\"score reteneurale di testCarogna: \"+str(clf.score(testCarogna_pca,np.asarray(testCarogna_pca_target['class_type'], dtype=\"|S6\"))))\n","execution_count":null,"metadata":{"_uuid":"a4a3bd9221039dc9ab1a65745935b870b863fcb1","_cell_guid":"f4953a11-c9b7-4d81-afb6-abb32ce9d39d","_execution_state":"idle"}},{"cell_type":"code","outputs":[],"source":"from sklearn.naive_bayes import GaussianNB\nclf = GaussianNB()\n\nclf.fit(X_train, np.asarray(y_train['class_type'], dtype=\"|S6\"))\n\nclf.predict(X_test)\nprint(\"score GaussianNB: \"+str(clf.score(X_test,np.asarray(y_test['class_type'], dtype=\"|S6\"))))\n\nclf.predict(testCarogna_pca)\nprint(\"score GaussianNB di testCarogna: \"+str(clf.score(testCarogna_pca,np.asarray(testCarogna_pca_target['class_type'], dtype=\"|S6\"))))\n","execution_count":null,"metadata":{"_uuid":"250b610ddfe70187249f2d01e9b971f266e25489","_cell_guid":"e55cb7b7-72fe-4d68-a1eb-5c349e293ea0","_execution_state":"idle"}},{"cell_type":"code","outputs":[],"source":"","execution_count":null,"metadata":{"_uuid":"7d48a2510e3aa3907ffede108710419f049d153f","collapsed":true,"_cell_guid":"a59dc110-db6a-433e-a01c-510701d2049d","_execution_state":"idle"}}],"metadata":{"kernelspec":{"language":"python","name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"version":3,"name":"ipython"},"pygments_lexer":"ipython3","version":"3.6.1","name":"python","nbconvert_exporter":"python","mimetype":"text/x-python","file_extension":".py"}},"nbformat_minor":1}