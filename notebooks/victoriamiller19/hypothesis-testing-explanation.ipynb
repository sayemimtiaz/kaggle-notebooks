{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport missingno as msno \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.impute import KNNImputer\nfrom sklearn.linear_model import LinearRegression\nimport plotly.graph_objs as go\nimport plotly.express as px\nfrom scipy.stats import shapiro\nfrom scipy.stats import normaltest\nfrom scipy.stats import chi2_contingency\nfrom scipy.stats import chi2\nimport scipy.stats as stats\nfrom numpy import median\nfrom numpy import std\n\nfrom scipy import stats\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-26T15:03:37.29196Z","iopub.execute_input":"2021-08-26T15:03:37.292606Z","iopub.status.idle":"2021-08-26T15:03:40.238996Z","shell.execute_reply.started":"2021-08-26T15:03:37.292504Z","shell.execute_reply":"2021-08-26T15:03:40.238017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **What is Hypothesis Testing**\n\n### Hypothesis testing is an act in statistics with which an analyst tests an assumption regarding a population parameter. It is used extensively to assess the plausibility of a hypothesis by using sample data. The assumptions made might be correct or it may not be. Data alone isn't interesting enough. It is the interpretation that we are really interested in.\n\n\n\n","metadata":{}},{"cell_type":"markdown","source":"### Table of Contents\n\n\nGetting familiar with our data \n\n* Data types and data completeness\n* Feature engineering\n* Statistical summary\n* Handling outliers\n* Handling missing values\n\nVisual Exploratory Data Analysis\n\n* Diploma distribution by income level\n* Average income by diploma\n* Spending by Income\n* Diploma distribution by marital situation\n* Income level by parental status\n\nStatistical Hypothesis Testing\n\n* Test for normality\n    * Graphical Method : Histogram plot\n    * Statistical Method : Shapiro test\n* Rank Significance Tests\n    * Numerical variables : Mann-Whitney's test\n* Rank Correlation Tests\n    * Numerical variables : Spearman test\n    * Categorical variables : Chi-square test\n\n\n   ","metadata":{}},{"cell_type":"markdown","source":"# **1. Getting familiar with data**","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv('../input/marketing-data/marketing_data.csv')\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-26T15:03:40.240539Z","iopub.execute_input":"2021-08-26T15:03:40.240837Z","iopub.status.idle":"2021-08-26T15:03:40.316257Z","shell.execute_reply.started":"2021-08-26T15:03:40.240806Z","shell.execute_reply":"2021-08-26T15:03:40.315143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-26T15:03:40.317953Z","iopub.execute_input":"2021-08-26T15:03:40.318453Z","iopub.status.idle":"2021-08-26T15:03:40.326246Z","shell.execute_reply.started":"2021-08-26T15:03:40.318418Z","shell.execute_reply":"2021-08-26T15:03:40.325103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize the general missing values of data\nmsno.matrix(data)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-26T15:03:40.328424Z","iopub.execute_input":"2021-08-26T15:03:40.329085Z","iopub.status.idle":"2021-08-26T15:03:40.946374Z","shell.execute_reply.started":"2021-08-26T15:03:40.329036Z","shell.execute_reply":"2021-08-26T15:03:40.945133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"missingvalues = data.isnull().sum()\nprint(missingvalues.loc[missingvalues!=0], '\\n')","metadata":{"execution":{"iopub.status.busy":"2021-08-26T15:03:40.947674Z","iopub.execute_input":"2021-08-26T15:03:40.947986Z","iopub.status.idle":"2021-08-26T15:03:40.973305Z","shell.execute_reply.started":"2021-08-26T15:03:40.947956Z","shell.execute_reply":"2021-08-26T15:03:40.9719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Data types and data completeness**","metadata":{}},{"cell_type":"markdown","source":"**Column Details:**\n\nID: Customer's Unique Identifier\n\nYear_Birth: Customer's Birth Year\n\nEducation: Customer's education level\n\nMarital_Status: Customer's marital status\n\nIncome: Customer's yearly household income\n\nKidhome: Number of children in customer's household\n\nTeenhome: Number of teenagers in customer's household\n\nDt_Customer: Date of customer's enrollment with the company\n\nRecency: Number of days since customer's last purchase\n\nMntWines: Amount spent on wine in the last 2 years\n\nMntFruits: Amount spent on fruits in the last 2 years\n\nMntMeatProducts: Amount spent on meat in the last 2 years\n\nMntFishProducts: Amount spent on fish in the last 2 years\n\nMntSweetProducts: Amount spent on sweets in the last 2 years\n\nMntGoldProds: Amount spent on gold in the last 2 years\n\nNumDealsPurchases: Number of purchases made with a discount\n\nNumWebPurchases: Number of purchases made through the company's web site\n\nNumCatalogPurchases: Number of purchases made using a catalogue\n\nNumStorePurchases: Number of purchases made directly in stores\n\nNumWebVisitsMonth: Number of visits to company's web site in the last month\n\nAcceptedCmp1: 1 if customer accepted the offer in the 1st campaign, 0 otherwise (Target variable)\n\nAcceptedCmp2: 1 if customer accepted the offer in the 2nd campaign, 0 otherwise (Target variable)\n\nAcceptedCmp3: 1 if customer accepted the offer in the 3rd campaign, 0 otherwise (Target variable)\n\nAcceptedCmp4: 1 if customer accepted the offer in the 4th campaign, 0 otherwise (Target variable)\n\nAcceptedCmp5: 1 if customer accepted the offer in the 5th campaign, 0 otherwise (Target variable)\n\nResponse: 1 if customer accepted the offer in the last campaign, 0 otherwise (Target variable)\n\nComplain: 1 if customer complained in the last 2 years, 0 otherwise\n\nCountry: Customer's location","metadata":{}},{"cell_type":"markdown","source":"### **Feature Engineering**","metadata":{}},{"cell_type":"code","source":"print(data.info())","metadata":{"execution":{"iopub.status.busy":"2021-08-26T15:03:40.974668Z","iopub.execute_input":"2021-08-26T15:03:40.975057Z","iopub.status.idle":"2021-08-26T15:03:40.998601Z","shell.execute_reply.started":"2021-08-26T15:03:40.975024Z","shell.execute_reply":"2021-08-26T15:03:40.997582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Using the info function, we can pull the following information from our dataset :**\n\nWe have **5** categorical variables and **23** numerical variables\n\nWe have missing values for the Income variable","metadata":{}},{"cell_type":"markdown","source":"We see that column_name **\"Income\"** has a space before it's name that will create problems in further analysis, so we'll rename it.\n\n\nThere looks a problem with 2 column's datatypes. We need to change the datatype of **\"Income\"** column into int64 so that it can be used for further calculations.","metadata":{}},{"cell_type":"code","source":"data.rename(columns={' Income ':'Income'},inplace=True)\ndata[\"Income\"] = data[\"Income\"].str.replace(\"$\",\"\").str.replace(',', '')\ndata[\"Income\"] = data[\"Income\"].astype(float)","metadata":{"execution":{"iopub.status.busy":"2021-08-26T15:03:40.999968Z","iopub.execute_input":"2021-08-26T15:03:41.000572Z","iopub.status.idle":"2021-08-26T15:03:41.015537Z","shell.execute_reply.started":"2021-08-26T15:03:41.000525Z","shell.execute_reply":"2021-08-26T15:03:41.014186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Having a first look at the row data enables us to start thinking at some useful variables we could create in order to better understand our dataset and reveal precious information.\n\n**We wrill create several variables :**\n\nVariable Age in replacement of the variable Year_birth\n\nVariable Spending as the sum of the amount spent on the 6 product categories\n\nVariable Marital_Situation to group the different marital status in only 2 comprehensive categories : In couple vs Alone\n\nVariable Has_child as a binary variable equal to Yes if the customer has 1 child or more\n\nVariable Educationnal_years as the total number of years of education the individual achieved according to its diploma\n\nWe will remove the unused variables for this analysis","metadata":{}},{"cell_type":"code","source":"data['Age']=2021-data['Year_Birth']\ndata['Spending']=data['MntWines']+data['MntFruits']+data['MntMeatProducts']+data['MntFishProducts']+data['MntSweetProducts']+data['MntGoldProds']\ndata['Marital_Situation']=data['Marital_Status'].replace({'Divorced':'Alone','Single':'Alone','Married':'In couple','Together':'In couple','Absurd':'Alone','Widow':'Alone','YOLO':'Alone'})\ndata['Has_child'] = np.where(data.Kidhome+data.Teenhome > 0, 'Yes', 'No')\ndata['Educational_years']=data['Education'].replace({'Basic':5,'2n Cycle':8,'Graduation':12,'Master':18,'PhD':21})\ndata=data[['Age','Income','Spending','Marital_Situation','Has_child','Educational_years', 'Education']]","metadata":{"execution":{"iopub.status.busy":"2021-08-26T15:03:41.019303Z","iopub.execute_input":"2021-08-26T15:03:41.019633Z","iopub.status.idle":"2021-08-26T15:03:41.044249Z","shell.execute_reply.started":"2021-08-26T15:03:41.019598Z","shell.execute_reply":"2021-08-26T15:03:41.0429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Statistical summary**","metadata":{}},{"cell_type":"code","source":"pd.options.display.float_format = \"{:.2f}\".format\ndata.describe()","metadata":{"execution":{"iopub.status.busy":"2021-08-26T15:03:41.046696Z","iopub.execute_input":"2021-08-26T15:03:41.047118Z","iopub.status.idle":"2021-08-26T15:03:41.076206Z","shell.execute_reply.started":"2021-08-26T15:03:41.047084Z","shell.execute_reply":"2021-08-26T15:03:41.075093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The describe function generates for us the 3-Number summary, particularly useful as a first step in our preliminary investigation. Analyzing the statistical summary gives us insightful information in one look :\n\nAverage **income** is 52247 dollars while median income is 51300 dollars. The distribution is right skewed with the possible presence of outliers. A little bit later we will handle outliers.\n\nThe maximum value being equal to 666666 dollars and the 3rd quartile being only equal to 68522 dollars reinforce this hypothesis\n\nAverage **spending** in the last 2 years is 600 dollars while median spending is 396 dollars\n\nAverage **age** is 45 years old and the oldest customer is 121 years old which is a pretty (and beautiful) rare event\n\nAverage number of years of **education** is 14.4 years which corresponds to a Bachelor degree\n","metadata":{}},{"cell_type":"code","source":"df = pd.DataFrame(data=data, columns=['Age','Income','Spending','Educational_years'])\n\nnd = pd.melt(df, value_vars =df )\nn1 = sns.FacetGrid (nd, col='variable', col_wrap=4, sharex=False, sharey = False)\nn1 = n1.map(sns.histplot, 'value')\nn1","metadata":{"execution":{"iopub.status.busy":"2021-08-26T15:03:41.07746Z","iopub.execute_input":"2021-08-26T15:03:41.077776Z","iopub.status.idle":"2021-08-26T15:03:42.388155Z","shell.execute_reply.started":"2021-08-26T15:03:41.077747Z","shell.execute_reply":"2021-08-26T15:03:42.387315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.boxplot(data = data['Income'])","metadata":{"execution":{"iopub.status.busy":"2021-08-26T15:03:42.389437Z","iopub.execute_input":"2021-08-26T15:03:42.390024Z","iopub.status.idle":"2021-08-26T15:03:42.524105Z","shell.execute_reply.started":"2021-08-26T15:03:42.389964Z","shell.execute_reply":"2021-08-26T15:03:42.523058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Insight:** We have a varied range of Customers in this store. People with income as high as 700k yearly income and some customers with less than $100k yearly income as well.\n\nHowever, majority of customers are with low yearly income and there are only a few which have income more than $100k. This means that the store caters to majorly low-income group customers and doesn't entertain rich/luxury customers.\n\nSo, we will remove this outliers otherwise it will pose a problem in further analysis. We use the log transformation technqiue for this.","metadata":{}},{"cell_type":"markdown","source":"### **Handling outliers**","metadata":{}},{"cell_type":"markdown","source":"An outlier is an observation that differs significantly from other values.  \n\nOutliers can be detected using several methods such as statistical methods or graphical methods.\nWe will use the Box-Plot graphical method which enables us to vizualize the range of our data and plot the outliers. By using this technique, we first calculate the Interquartile Range (IQR) defined as follow :\n\n**IQR = Q_3-Q_1**\n\nwhere :\n- Q_1 is the first quartile\n- Q_3 is the third quartile  \n\n> - Any value greater (lower) 1.5 times the IQR above (below) the third quartile (the first quartile) is defined as a __mild outlier__  \n>- Any value greater (lower) 3 times the IQR above (below) the third quartile (the first quartile) is defined as an __extreme outlier__","metadata":{}},{"cell_type":"code","source":"df = data[['Age','Income','Spending','Educational_years']]\n\nfig = px.box(df.melt(), y=\"value\", facet_col=\"variable\",facet_col_wrap=2, boxmode=\"overlay\", color=\"variable\",height=1000, width=900)\nfig.update_yaxes(matches=None)\n\nfor i in range(len(fig[\"data\"])):\n    yaxis_name = 'yaxis' if i == 0 else f'yaxis{i + 1}'\n    fig.layout[yaxis_name].showticklabels = True\n\nfig.update_layout(showlegend=False)\nfig.update_xaxes(showline=True, linewidth=2, linecolor='grey')\nfig.update_yaxes(showline=True, linewidth=2, linecolor='grey')\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-26T15:03:42.525572Z","iopub.execute_input":"2021-08-26T15:03:42.525977Z","iopub.status.idle":"2021-08-26T15:03:44.026236Z","shell.execute_reply.started":"2021-08-26T15:03:42.525934Z","shell.execute_reply":"2021-08-26T15:03:44.024977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Outliers analysis must be done with care. From above we can see that several variables seem to have outliers :\n\n>Age: 3 customers older than the Upper Fence set at 74 years old. We will not remove them\n\n>Income : Several value are greater than the Upper Fence of 113K. While having an income of 150k is not impossible, we will remove the customer who has an income of 666k (Moreover, this observation is defined as an extreme outlier based on our definition stated previously)\n\n>Spending : There is only one outlier which is at the limit of the Upper Fence. We will not remove it","metadata":{}},{"cell_type":"code","source":"#We remove the only outlier in our dataset before handling missing values\ndataset = data.drop(data[data['Income']> 600000].index).reset_index(drop=True)\ndataset","metadata":{"execution":{"iopub.status.busy":"2021-08-26T15:03:44.027853Z","iopub.execute_input":"2021-08-26T15:03:44.028325Z","iopub.status.idle":"2021-08-26T15:03:44.052723Z","shell.execute_reply.started":"2021-08-26T15:03:44.028278Z","shell.execute_reply":"2021-08-26T15:03:44.051541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Handling missing values**","metadata":{}},{"cell_type":"markdown","source":"As seen earlier, the Income variable has 24 missing values\n\n**There are several ways to handle null-values**:\n\nWe can delete the entire column containing null-values\n\nWe can delete the rows containing null-values\n\nWe can impute the mean value\n\nWe can input the mean value of a specific population : in this case we would split by Education diploma\n\nWe can use a model to predict missing values\n\nWith our dataset, we will go for the last option and use the **K-Nearest Neighbor Imputation**.\nKNN Imputation works by imputing the average income of the k nearest neighbors found in the training set for each of the missing value.\n\nWe will use Education, Age and Income to run the algorithm. KNNimputer will automatically normalize our data.","metadata":{}},{"cell_type":"code","source":"imputer = KNNImputer()\nimputer = KNNImputer(n_neighbors=5,metric='nan_euclidean')\n# fit on the dataset\nimputer.fit(dataset[['Income','Age','Educational_years']])\n# transform the dataset\nX = imputer.transform(dataset[['Income','Age','Educational_years']])\nIncome_impute=pd.DataFrame(X,columns=['Income','Age','Educational_years'])\ndataset['Income']=Income_impute['Income'].reset_index(drop=True)\ncount_nan = len(dataset) - dataset.count()\nprint(count_nan)","metadata":{"execution":{"iopub.status.busy":"2021-08-26T15:03:44.054406Z","iopub.execute_input":"2021-08-26T15:03:44.054818Z","iopub.status.idle":"2021-08-26T15:03:44.082313Z","shell.execute_reply.started":"2021-08-26T15:03:44.054776Z","shell.execute_reply":"2021-08-26T15:03:44.081047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We don't have any missing value anymore","metadata":{}},{"cell_type":"markdown","source":"# **Visual Exploratory Data Analysis**","metadata":{}},{"cell_type":"markdown","source":"**Let's plot a correlation matrix to show correlation coefficients between out variables.**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,5))\nsns.heatmap(dataset.corr(),annot=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-26T15:03:44.083485Z","iopub.execute_input":"2021-08-26T15:03:44.083939Z","iopub.status.idle":"2021-08-26T15:03:44.357348Z","shell.execute_reply.started":"2021-08-26T15:03:44.083898Z","shell.execute_reply":"2021-08-26T15:03:44.356601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Diploma distribution by income level**","metadata":{}},{"cell_type":"code","source":"df = dataset[['Income','Education']]\ncategory_orders={\"Education\":[\"Basic\",\"2n Cycle\",\"Graduation\",\"Master\",\"PhD\"]}\nfig = px.histogram(df, x=\"Education\",y=\"Income\",  histfunc='avg',category_orders=category_orders)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-26T15:03:44.358648Z","iopub.execute_input":"2021-08-26T15:03:44.35936Z","iopub.status.idle":"2021-08-26T15:03:44.486993Z","shell.execute_reply.started":"2021-08-26T15:03:44.359314Z","shell.execute_reply":"2021-08-26T15:03:44.486049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Average income is the highest for PhD owners with 56161 dollars\n\nAverage income is the lowest for Basic diploma owners with 20306 dollars\n\nThe better the diploma is, the higher the average salary\n\nWe will verify later with a statistical test if the average salary of PhD owners is statistically different from Master owners ","metadata":{}},{"cell_type":"markdown","source":"### **Spending by Income**","metadata":{}},{"cell_type":"code","source":"reg = LinearRegression()\nfig = go.Figure(data=go.Scatter(name='observations',x=dataset['Spending'], y=dataset['Income'],mode='markers'))\n\nfig.update_traces(hovertemplate='Spending: %{x} <br>Income: %{y}')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-26T15:03:44.488458Z","iopub.execute_input":"2021-08-26T15:03:44.489031Z","iopub.status.idle":"2021-08-26T15:03:44.510599Z","shell.execute_reply.started":"2021-08-26T15:03:44.488975Z","shell.execute_reply":"2021-08-26T15:03:44.509813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Spending seems to be positively correlated with the income level.\n\nWe will verify later with a statistical test if the correlation between the annual income and the amount of spending is statistically significant.","metadata":{}},{"cell_type":"markdown","source":"### **Diploma distribution by marital situation**","metadata":{}},{"cell_type":"code","source":"dataset['Marital_Situation']=dataset['Marital_Situation'].replace({'Divorced':'Alone','Single':'Alone','Married':'In couple','Together':'In couple','Absurd':'Alone','Widow':'Alone','YOLO':'Alone'})","metadata":{"execution":{"iopub.status.busy":"2021-08-26T15:03:44.511687Z","iopub.execute_input":"2021-08-26T15:03:44.512139Z","iopub.status.idle":"2021-08-26T15:03:44.51928Z","shell.execute_reply.started":"2021-08-26T15:03:44.512093Z","shell.execute_reply":"2021-08-26T15:03:44.51841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = dataset[['Education','Marital_Situation']]\n\nfig = px.sunburst(df, path=['Marital_Situation','Education'],color_discrete_sequence=px.colors.sequential.Rainbow)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-26T15:03:44.520524Z","iopub.execute_input":"2021-08-26T15:03:44.520971Z","iopub.status.idle":"2021-08-26T15:03:44.702031Z","shell.execute_reply.started":"2021-08-26T15:03:44.520929Z","shell.execute_reply":"2021-08-26T15:03:44.701275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The distribution of diploma category owned seems to be identical for the two population In couple and Alone\n\nWe could be tempted to believe that there is no correlation between the diploma owned and the marital status\n\nWe will verify later if this hypothesis is true.","metadata":{}},{"cell_type":"markdown","source":"### **Income level by parental status**","metadata":{}},{"cell_type":"code","source":"fig = px.histogram(dataset, \n                   x='Income', \n                   marginal='box', \n                   color='Has_child', \n                   color_discrete_sequence=['blue', 'green'], \n                   title='Income level by parental status')\nfig.update_layout(bargap=0.1)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-26T15:03:44.703189Z","iopub.execute_input":"2021-08-26T15:03:44.703635Z","iopub.status.idle":"2021-08-26T15:03:44.819648Z","shell.execute_reply.started":"2021-08-26T15:03:44.703587Z","shell.execute_reply":"2021-08-26T15:03:44.818921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"People with high income are largely representing the population who has no child\n\nPeople having at least 1 child are mainly represented by people with low income\n\n\n\nWe will verify later if there is a correlation between the income and the fact to have at least one child","metadata":{}},{"cell_type":"markdown","source":"# **Statistical Hypothesis Testing**","metadata":{}},{"cell_type":"markdown","source":"### **We have 3 business problems to answer usuing Hypothesis Testing:**\n\n1. Is the average salary of PhD owners statistically different from Master owners?\n\n2. Is the correlation between the annual income and the amount of spending statistically significant?\n\n3. Is there correlation between the diploma owned and the marital status?\n\n\n","metadata":{}},{"cell_type":"markdown","source":"### **Test for normality**\n\n\n\n\n\n","metadata":{}},{"cell_type":"markdown","source":"Before running any hypothesis test, it's important to know which statistical method we should use. Statstical methods are divided in two parts :\n\n* Parametric statistical methods\n\n* Nonparametric statistical methods\n\nTo know which one to use, normality tests must be done on our data. If our data have a known and specific distribution, such as the Gaussian distribution; parametric statistical methods must be used. On the contrary, if data are not Gaussian, nonparametric statistical methods should be used.\n\nThere are two main ways to know if our data are Gaussian :\n\n* Graphical methods\n    * Histogram plot\n    * QQ plot\n\n* Statistical methods\n    * Shapiro test\n    * D'Agostino and Pearson test\n    * Anderson-Darling test\n    * Kolmogorov-Smirnov test\n    \n\n\n**Graphical methods** are mainly used for qualifying deviations from normality\n\n**Statistical** methods are mainly used for quantifying deviations from normality","metadata":{}},{"cell_type":"markdown","source":"#### **Graphical Method**\n\n**Histogram plot**","metadata":{}},{"cell_type":"code","source":"df = pd.DataFrame(data=dataset, columns=['Age','Income','Spending','Educational_years'])\nnd = pd.melt(df, value_vars =df )\nn1 = sns.FacetGrid (nd, col='variable', col_wrap=4, sharex=False, sharey = False)\nn1 = n1.map(sns.histplot, 'value')\nn1","metadata":{"execution":{"iopub.status.busy":"2021-08-26T15:03:44.820914Z","iopub.execute_input":"2021-08-26T15:03:44.821483Z","iopub.status.idle":"2021-08-26T15:03:45.801433Z","shell.execute_reply.started":"2021-08-26T15:03:44.821384Z","shell.execute_reply":"2021-08-26T15:03:45.80046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the graph, we can immediately see which variables seem to be Gaussian or Gaussian-like :\n\nAge and Income have Gaussian-like distributions\n\nSpending has a Log-normal distribution\n\nEducationnal_years has a Multinomial distribution\n\nWe can verify with a statistical method that none of our variables is Gaussian","metadata":{}},{"cell_type":"markdown","source":"**Statistical Method**","metadata":{}},{"cell_type":"markdown","source":"Before you can apply the statistical tests, you must know how to interpret the results.\n\nEach test will return at least two things:\n\n**Statistic:** A quantity calculated by the test that can be interpreted in the context of the test via comparing it to critical values from the distribution of the test statistic.\n\n**p-value:** Used to interpret the test, in this case whether the sample was drawn from a Gaussian distribution.\n\n\nThe tests assume that that the sample was drawn from a Gaussian distribution. Technically this is called the null hypothesis, or H0. A threshold level is chosen called alpha, typically 5% (or 0.05), that is used to interpret the p-value.\n\nIn the SciPy implementation of these tests, you can interpret the p value as follows.\n\np <= alpha: reject H0, not normal.\n\np > alpha: fail to reject H0, normal.\n\n\nA result above 5% does not mean that the null hypothesis is true. It means that it is very likely true given available evidence. The p-value is not the probability of the data fitting a Gaussian distribution; it can be thought of as a value that helps us interpret the statistical test.","metadata":{}},{"cell_type":"markdown","source":"#### **Shapiro test**","metadata":{}},{"cell_type":"code","source":"X=['Age','Income','Spending','Educational_years']\n\ncolumn_dict= {elem : pd.DataFrame() for elem in X}\n\ndef shapiro_test(data):\n    stat, p = shapiro(data)\n    print('%s : Statistics=%.3f, p=%.3f' % (column,stat, p))\n    alpha = 0.05\n    if p > alpha:\n        print('Sample looks Gaussian (We fail to reject H0)')\n    else:\n        print('Sample does not look Gaussian (We reject H0)')\n\nfor column in X:\n    column_dict[column] = dataset[column]\n    shapiro_test(column_dict[column])","metadata":{"execution":{"iopub.status.busy":"2021-08-26T15:03:45.802643Z","iopub.execute_input":"2021-08-26T15:03:45.802934Z","iopub.status.idle":"2021-08-26T15:03:45.815667Z","shell.execute_reply.started":"2021-08-26T15:03:45.802905Z","shell.execute_reply":"2021-08-26T15:03:45.814535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"All the p-values are inferior to 0.05 :\n\nWe reject the null-hypothesis. Our variables are not Gaussian at a 5% significance level\n\nFrom this point we have two options :\n\n>Normalizing our data to use parametric statistical methods\n\n>Using directly nonparametric statistical methods\n\nWe will go for the second option and use nonparametric statistical methods to test our hypotheses","metadata":{}},{"cell_type":"markdown","source":"### **Rank Significance Tests**","metadata":{}},{"cell_type":"markdown","source":"#### **Numerical variables : Mann-Whitney's test**","metadata":{}},{"cell_type":"markdown","source":"Our first question was to find if the average income of PhD owners is statistically different from the average income of Master owners.\n\n1. Hypothesis statement\n\n**H_0** : The mean ranks of the two groups are equal\n\n**H_a** : The mean ranks of the two groups are not equal\n\n2. Analysis plan formulation\n\nSignificance level : We will test our hypothesis at a 5% significance level\n\nTest method : We use the Mann-Whitney's test to determine whether one group has higher or lower income than the other group. \nMann-Whitney U test is a nonparametric statistical significance test for determining whether two independent samples were drawn from a population with the same distribution. The default assumption or null hypothesis is that there is no difference between the distributions of the data samples. Rejection of this hypothesis suggests that there is likely some difference between the samples. More specifically, the test determines whether it is equally likely that any randomly selected observation from one sample will be greater or less than a sample in the other distribution. If violated, it suggests differing distributions. \nTherefore, if our assumption is correct, the result of the test should enable us to reject the null hypothesis.","metadata":{}},{"cell_type":"code","source":"#Creation of the samples\nDiploma=dataset[['Education','Income']]\n\nPhd_graduate=Diploma[Diploma['Education']=='PhD']\nMaster_graduate=Diploma[Diploma['Education']=='Master']\nBasic_graduate=Diploma[Diploma['Education']=='Basic']\nSecond_cycle_graduate=Diploma[Diploma['Education']=='2n Cycle']\nGraduation_graduate=Diploma[Diploma['Education']=='Graduation']","metadata":{"execution":{"iopub.status.busy":"2021-08-26T15:03:45.81914Z","iopub.execute_input":"2021-08-26T15:03:45.819533Z","iopub.status.idle":"2021-08-26T15:03:45.836496Z","shell.execute_reply.started":"2021-08-26T15:03:45.819499Z","shell.execute_reply":"2021-08-26T15:03:45.835422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Mann-Whitney U statistic :\n\n![](https://www.statisticssolutions.com/wp-content/uploads/2010/01/man1.jpg)\n\nWhere:\n\nU=Mann-Whitney U test\n\nN1 = sample size one\n\nN2= Sample size two\n\nRi = Rank of the sample size","metadata":{}},{"cell_type":"code","source":"# normality tests of our two samples\nstat, p = shapiro(Phd_graduate.Income)\nprint('Statistics=%.3f, p=%.3f' % (stat, p))\n# interpret\nalpha = 0.05\nif p > alpha:\n\tprint('Sample looks Gaussian (fail to reject H0)')\nelse:\n\tprint('Sample does not look Gaussian (reject H0)')","metadata":{"execution":{"iopub.status.busy":"2021-08-26T15:03:45.837882Z","iopub.execute_input":"2021-08-26T15:03:45.838247Z","iopub.status.idle":"2021-08-26T15:03:45.854687Z","shell.execute_reply.started":"2021-08-26T15:03:45.838213Z","shell.execute_reply":"2021-08-26T15:03:45.853644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stat, p = shapiro(Master_graduate.Income)\nprint('Statistics=%.3f, p=%.3f' % (stat, p))\n# interpret\nalpha = 0.05\nif p > alpha:\n\tprint('Sample looks Gaussian (fail to reject H0)')\nelse:\n\tprint('Sample does not look Gaussian (reject H0)')","metadata":{"execution":{"iopub.status.busy":"2021-08-26T15:03:45.856292Z","iopub.execute_input":"2021-08-26T15:03:45.856613Z","iopub.status.idle":"2021-08-26T15:03:45.870792Z","shell.execute_reply.started":"2021-08-26T15:03:45.856584Z","shell.execute_reply":"2021-08-26T15:03:45.869801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# summarize\nprint('PhD: median = %.0f stdv = %.1f' % (median(Phd_graduate.Income), std(Phd_graduate.Income)))\nprint('Master: median = %.0f stdv = %.1f' % (median(Master_graduate.Income), std(Master_graduate.Income)))\n\nprint(stats.mannwhitneyu(Phd_graduate.Income, Master_graduate.Income))\n\nif p > alpha:\n\tprint('Means are not statistically different (We fail to reject H0)')\nelse:\n\tprint('Means are statistically different (We reject H0)')    ","metadata":{"execution":{"iopub.status.busy":"2021-08-26T15:03:45.872222Z","iopub.execute_input":"2021-08-26T15:03:45.87254Z","iopub.status.idle":"2021-08-26T15:03:45.888452Z","shell.execute_reply.started":"2021-08-26T15:03:45.87251Z","shell.execute_reply":"2021-08-26T15:03:45.887337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The p-value is inferior than the significance level of 5%, we can reject the null hypothesis.\n\nWe can conclude that the average income of PhD owners is different from the average income of Master owners at a 95% confidence level","metadata":{}},{"cell_type":"markdown","source":"### **Rank Correlation Tests**","metadata":{}},{"cell_type":"markdown","source":"#### Numerical variables : Spearman Rank Correlation test","metadata":{}},{"cell_type":"markdown","source":"The following formula is used to calculate the Spearman rank correlation:\n\n![](https://cdn.questionpro.com/userimages/help_file_images/682/help-682-1.png)\n\n\nRs = Spearman rank correlation\n\nD = the difference between the ranks of corresponding variables\n\nn = number of observations","metadata":{}},{"cell_type":"markdown","source":"Spearman rank correlation is a non-parametric test that is used to measure the degree of association between two variables.\n\nOur second question was to find if there is a statistically significant correlation between the income and the spending amount.\n\n#### 1. Hypothesis statement  \n* __H_0__ : There is no monotonic association between income and spending amount  \n* __H_a__ : There is a monotonic association between income and spending amount\n\n#### 2. Analysis plan formulation  \n* __Significance level__ : We will test our hypothesis at 5% significance level  \n* __Test method__ : We use the Spearman rank correlation test to determine if our two variables are correlated. This statistical method quantifies the degree to which ranked variables are associated by a monotonic function, meaning an increasing or decreasing relationship. As a statistical hypothesis test, the method assumes that the samples are uncorrelated (fail to reject H0).  \nTherefore, if our assumption is correct, the result of the test should enable us to reject the null hypothesis.","metadata":{}},{"cell_type":"code","source":"Spending=dataset[['Spending','Income']]\n\ncor, pval = stats.spearmanr(Spending[['Spending']], Spending[['Income']])\nprint(\"Non-Parametric Spearman correlation test : correlation coefficient : %.4f, pval: %.4f\" % (cor, pval))","metadata":{"execution":{"iopub.status.busy":"2021-08-26T15:03:45.889771Z","iopub.execute_input":"2021-08-26T15:03:45.89018Z","iopub.status.idle":"2021-08-26T15:03:45.907752Z","shell.execute_reply.started":"2021-08-26T15:03:45.890143Z","shell.execute_reply":"2021-08-26T15:03:45.906341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The closer Rs is to +1 or -1, the stronger the likely correlation. A perfect positive correlation is +1 and a perfect negative correlation is -1. The Rs value of 0.8466 suggests a fairly strong positive relationship.\n\nThe high correlation coefficient induces a strong positive relationship between the two variables, confirming our alternative hypothesis.\n","metadata":{}},{"cell_type":"markdown","source":"#### **Categorical variables : Chi-square test for independance**","metadata":{}},{"cell_type":"markdown","source":"Our third question was to find if there is a statistically significant correlation between the diploma and the marital situation.\n\n\n#### 1. Hypothesis statement\n*H_0*  : Education and Marital_Situation are independent  \n*H_a*  : Education and Marital_Situation are not independent\n\n#### 2. Analysis plan formulation  \n* __Significance level__ : We will test our hypothesis at a 5% significance level  \n* __Test method__ : We use the Chi-square test for independence to determine whether there is a significant relationship between our two categorical variables.","metadata":{}},{"cell_type":"code","source":"Marital_Situation=dataset[['Education','Marital_Situation']]\ncrosstab = pd.crosstab(Marital_Situation[\"Education\"], Marital_Situation[\"Marital_Situation\"])\ncrosstab","metadata":{"execution":{"iopub.status.busy":"2021-08-26T15:03:45.909585Z","iopub.execute_input":"2021-08-26T15:03:45.910242Z","iopub.status.idle":"2021-08-26T15:03:45.943903Z","shell.execute_reply.started":"2021-08-26T15:03:45.910084Z","shell.execute_reply":"2021-08-26T15:03:45.943101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Degrees of freedom**\n\nCalculating Degrees of Freedom is key when trying to understand the importance of a Chi-Square statistic and the validity of the null hypothesis.\n\n<img src=\"https://www.thoughtco.com/thmb/ZOngumdBr_1XRgm3bVpHRKF6Kj8=/768x0/filters:no_upscale():max_bytes(150000):strip_icc()/df-58588dcb3df78ce2c3203706.jpg\" width=\"200\" height=\"200\" />\n\n\nwhere r is the number of levels for one catagorical variable, and $c$ is the number of levels for the other categorical variable.","metadata":{}},{"cell_type":"code","source":"stat, p, dof, expected = chi2_contingency(crosstab)\nprint('Degress of freedom = %d' % dof)","metadata":{"execution":{"iopub.status.busy":"2021-08-26T15:03:45.944882Z","iopub.execute_input":"2021-08-26T15:03:45.945289Z","iopub.status.idle":"2021-08-26T15:03:45.950179Z","shell.execute_reply.started":"2021-08-26T15:03:45.94526Z","shell.execute_reply":"2021-08-26T15:03:45.949476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**The test statistic is a chi-square random variable ( ùúí2 ) defined by the following equation:\n**","metadata":{}},{"cell_type":"markdown","source":"\n\n<img src=\"https://www.thoughtco.com/thmb/ns7d4DC1AqVGme2p1-WYqC26r_s=/768x0/filters:no_upscale():max_bytes(150000):strip_icc()/latex_ac74fec08532861eb5f8b87226ebf396-5c59a6fcc9e77c00016b4195.jpg\" width=\"200\" height=\"200\" />","metadata":{}},{"cell_type":"markdown","source":"Expected frequencies :\n\nThe expected frequency counts are computed separately for each level of one categorical variable at each level of the other categorical variable.\n\n","metadata":{}},{"cell_type":"markdown","source":"Where : \n    \nùëÇùëü is the observed frequency count at level r of Variable  ùê¥ and level  ùëê of Variable  ùêµ\n \nùê∏ùëü is the expected frequency count at level  ùëü of Variable  ùê¥ and level  ùëê of Variable  ùêµ","metadata":{}},{"cell_type":"code","source":"print(expected)","metadata":{"execution":{"iopub.status.busy":"2021-08-26T15:03:45.951203Z","iopub.execute_input":"2021-08-26T15:03:45.951594Z","iopub.status.idle":"2021-08-26T15:03:45.965524Z","shell.execute_reply.started":"2021-08-26T15:03:45.951565Z","shell.execute_reply":"2021-08-26T15:03:45.964327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prob = 0.95\ncritical = chi2.ppf(prob, dof)\nprint('probability=%.3f, critical=%.3f, stat=%.3f' % (prob, critical, stat))","metadata":{"execution":{"iopub.status.busy":"2021-08-26T15:03:45.966968Z","iopub.execute_input":"2021-08-26T15:03:45.967345Z","iopub.status.idle":"2021-08-26T15:03:45.978845Z","shell.execute_reply.started":"2021-08-26T15:03:45.967312Z","shell.execute_reply":"2021-08-26T15:03:45.977766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"P-value :\n\nThe P-value is the probability of observing a sample statistic as extreme as the test statistic. Since the test statistic is a Chi-square, we should use use the Chi-Square table to assess the probability associated with the test statistic by using the degrees of freedom we found above.","metadata":{}},{"cell_type":"code","source":"if abs(stat) >= critical:\n\tprint('Dependent (We reject H0)')\nelse:\n\tprint('Independent (We fail to reject H0)')\nalpha = 1.0 - prob\nprint('significance=%.3f, p=%.3f' % (alpha, p))\nif p <= alpha:\n\tprint('Dependent (We reject H0)')\nelse:\n\tprint('Independent (We fail to reject H0)')","metadata":{"execution":{"iopub.status.busy":"2021-08-26T15:03:45.980373Z","iopub.execute_input":"2021-08-26T15:03:45.981085Z","iopub.status.idle":"2021-08-26T15:03:45.992028Z","shell.execute_reply.started":"2021-08-26T15:03:45.981038Z","shell.execute_reply":"2021-08-26T15:03:45.991091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Interpretation of the results**\n\nWe can interpret the results by two ways :\n\n* The P-value is superior than the significance level of 5%, we fail to reject the null hypothesis.\n\n* The Test-statistic is inferior than the critical value, we fail to reject the null hypothesis.\n\nWe can conclude that the marital status is independent from the diploma owned at a 95% confidence level","metadata":{}},{"cell_type":"markdown","source":"## **Conclusion**","metadata":{}},{"cell_type":"markdown","source":"We have done a great job! Firstly, we did some data preprocessing: haddled missing values, detected and removed outliers.\n\nSecond step was Exploratory Data Analysis to undestand relationships between our data.\n\nDuring the final step, we covered an essenatial part of our research - we applied hypothesis testing to answer the following **3 business problems**:\n\n**1. Is the average salary of PhD owners statistically different from Master owners?**\n\nWe assumed **Null hypothesis(H_0)**: The mean ranks of the two groups are equal\n\n**Alternative hypothesis(H_a)**: The mean ranks of the two groups are not equal\n\nWe used Mann-Whitney's test, and got p-value < significance level, so we can conclude that the average income of PhD owners is different from the average income of Master owners at a 95% confidence level\n\n\n**2. Is the correlation between the annual income and the amount of spending statistically significant?**\n\nUsing Spearman correlation test we received the following result: correlation coefficient : 0.8466, pval: 0.0000 \n\nThere is a strong positive collection, thats why we reject out null hypothesis in favor of the alternative hypothesis - **there is statistically significant correlation between the income and the spending amount**.\n\n\n\n**3. Is there correlation between the diploma owned and the marital status?**\n\n**Null hypothesis(H_o)**: Education and Marital_Situation are independant\n\n**Alternative_hypothesis(H_a)**: Education and Marital_Situation are not independent\n\nUsing the chi-square test, we can see that the P-value is superior than the significance level of 5%, we fail to reject the null hypothesis.\n\nThe Test-statistic is inferior than the critical value, we fail to reject the null hypothesis.\n\nThats why we conclude that the marital status is independent from the diploma owned at a 95% confidence level","metadata":{}},{"cell_type":"markdown","source":"# Thanks for reading this tutorial! I'd be glad to see your upvotes and comments!","metadata":{}}]}