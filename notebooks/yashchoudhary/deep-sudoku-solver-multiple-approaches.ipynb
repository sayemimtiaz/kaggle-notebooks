{"cells":[{"metadata":{},"cell_type":"markdown","source":"# **<span style=\"color:red;text-decoration:underline\">Let's solve some sudokus!</span>**\nIn this notebook we will try to solve some sudokus using neural networks. As you will see that a neural net is not very suited for this use case so we would look at some of the most optimised approaches in the end.\n\n<t>This tutorial is inspired by [this](https://towardsdatascience.com/solving-sudoku-with-convolution-neural-network-keras-655ba4be3b11) awesome medium article. This tutorial is beginner friendly so anyone with a basic understanding of python and neural nets(convnets) can proceed.\n\n## <span style=\"color:green;text-decoration:underline\">What is a sudoku?</span>\nSudoku is a logic-based, combinatorial number-placement puzzle. The objective is to fill a 9×9 grid with digits so that each column, each row, and each of the nine 3×3 subgrids that compose the grid contain all of the digits from 1 to 9.\n<t>The modern Sudoku was most likely designed anonymously by Howard Garns, a 74-year-old retired architect and freelance puzzle constructor from Connersville, Indiana, and first published in 1979 by Dell Magazines as Number Place (the earliest known examples of modern Sudoku).\n<t>\n![img](https://upload.wikimedia.org/wikipedia/commons/thumb/e/e0/Sudoku_Puzzle_by_L2G-20050714_standardized_layout.svg/300px-Sudoku_Puzzle_by_L2G-20050714_standardized_layout.svg.png)\n    \n### Rules\n1. Each row, column, and subgrid should contain each number (1 to 9) exactly once.\n2. The sum of all numbers in any subgrid, row, or column must be equal to 45.\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## <span style=\"color:green;text-decoration:underline\">Exploratory Data Analysis?</span>\nLet's understand the data we are working with.\nWe are using the [9 Million Sudoku Puzzles and Solutions](https://www.kaggle.com/rohanrao/sudoku) dataset. \n<br>You can also combine the [1 million Sudoku games](https://www.kaggle.com/bryanpark/sudoku) dataset to have more data although 9M is already a lot.","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport keras\nimport keras.backend as K\nfrom keras.optimizers import Adam\nfrom keras.models import Sequential\nfrom keras.utils import Sequence\nfrom keras.layers import *\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"path = \"../input/sudoku/\"\ndata = pd.read_csv(path+\"sudoku.csv\")\ntry:\n    data = pd.DataFrame({\"quizzes\":data[\"puzzle\"],\"solutions\":data[\"solution\"]})\nexcept:\n    pass\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Quizes and Solutions are in the form of strings of length 81. '0' in the quizzes are for blank spaces.\n<br>Let's see the quizes and solutions more semantically.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Quiz:\\n\",np.array(list(map(int,list(data['quizzes'][0])))).reshape(9,9))\nprint(\"Solution:\\n\",np.array(list(map(int,list(data['solutions'][0])))).reshape(9,9))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <span style=\"color:green;text-decoration:underline\">Deep Learning Approach</span>\n### Let's create a basic model\nWe know that semantics are important for solving a sudoku and convnets are ideal in preserving semantics and extracting semantic features so we will be creating a [convnet](https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53).\n\n* Our input are batches of arrays of shape (9,9).\n* Output is of shape (81,1) because we are using [sparse_categorical_crossentropy](https://stackoverflow.com/questions/58565394/what-is-the-difference-between-sparse-categorical-crossentropy-and-categorical-c) loss function which does not require passing one-hot vectors as output. \n* We are using a batch size of 640 as the data is very large in number and can easily fit in a decent GPU.\n* Training and validation split is of 95% to 5% as 5% of 9M is also very large(4,50,000).\n* We will be using reducing lr approach to finetune our model and model checkpointing to save the best model and avoid overfitting.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Utility Functions\nclass DataGenerator(Sequence):\n    def __init__(self, df,batch_size = 16,subset = \"train\",shuffle = False, info={}):\n        super().__init__()\n        self.df = df\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        self.subset = subset\n        self.info = info\n        \n        self.data_path = path\n        self.on_epoch_end()\n        \n    def __len__(self):\n        return int(np.floor(len(self.df)/self.batch_size))\n    def on_epoch_end(self):\n        self.indexes = np.arange(len(self.df))\n        if self.shuffle==True:\n            np.random.shuffle(self.indexes)\n            \n    def __getitem__(self,index):\n        X = np.empty((self.batch_size, 9,9,1))\n        y = np.empty((self.batch_size,81,1))\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        for i,f in enumerate(self.df['quizzes'].iloc[indexes]):\n            self.info[index*self.batch_size+i]=f\n            X[i,] = (np.array(list(map(int,list(f)))).reshape((9,9,1))/9)-0.5\n        if self.subset == 'train': \n            for i,f in enumerate(self.df['solutions'].iloc[indexes]):\n                self.info[index*self.batch_size+i]=f\n                y[i,] = np.array(list(map(int,list(f)))).reshape((81,1)) - 1\n        if self.subset == 'train': return X, y\n        else: return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(64, kernel_size=(3,3), activation='relu', padding='same', input_shape=(9,9,1)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64, kernel_size=(3,3), activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(128, kernel_size=(1,1), activation='relu', padding='same'))\n\nmodel.add(Flatten())\nmodel.add(Dense(81*9))\nmodel.add(Reshape((-1, 9)))\nmodel.add(Activation('softmax'))\n\nadam = keras.optimizers.adam(lr=.001)\nmodel.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Generators\nWe will be creating training and test data generator. Lets use 95% data for training and 5% data for validation as 5% of 9Million is still very large for validation purposes. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_idx = int(len(data)*0.95)\ndata = data.sample(frac=1).reset_index(drop=True)\ntraining_generator = DataGenerator(data.iloc[:train_idx], subset = \"train\", batch_size=640)\nvalidation_generator = DataGenerator(data.iloc[train_idx:], subset = \"train\",  batch_size=640)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_generator.__getitem__(4)[0].shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Callbacks\nCallbacks help in monitoring model training on-the-go. They can be used to stop training, saving best weights, reducing learning rate if validation accuracy is not improving.\n<br>\nIn our case we are using two callbacks.\n1. First one is **ModelCheckpoint** which saves the weights as soon as the validation accuracy imporves from the previous best.\n2. Second one is **ReduceLROnPlateau** which reduces the learning rate if the validation loss doesnot improve after a set no of epochs called patience. In our case the patience is of 3 and the lowest it can go is 1e-6 after which it does not reduce LR.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau\nfilepath1=\"weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\nfilepath2 = \"best_weights.hdf5\"\ncheckpoint1 = ModelCheckpoint(filepath1, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\ncheckpoint2 = ModelCheckpoint(filepath2, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n\nreduce_lr = ReduceLROnPlateau(\n    monitor='val_loss',\n    patience=3,\n    verbose=1,\n    min_lr=1e-6\n)\ncallbacks_list = [checkpoint1,checkpoint2,reduce_lr]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit_generator(training_generator, validation_data = validation_generator, epochs = 1, verbose=1,callbacks=callbacks_list )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"NOTE: For best results train for 5 to 6 epochs. I've tried training upto 30 epochs and the accuracy doesn't improve above 5 epochs.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_weights('best_weights.hdf5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <span style=\"color:green;text-decoration:underline\">Solving Real Sudokus!!?</span>\nHere we use a more human approach to solving the sudoku that is to fill one number at a time. This means that we pass the sudoku through the neural net once and fill the number that it is most sure of, than again pass it and fill another number till all the numbers are filled. This helps the neural net to gain context from the previously filled digits like a human player.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def norm(a):\n    return (a/9)-.5\n\ndef denorm(a):\n    return (a+.5)*9\n\ndef inference_sudoku(sample):\n    \n    '''\n        This function solve the sudoku by filling blank positions one by one.\n    '''\n    \n    feat = sample\n    \n    while(1):\n    \n        out = model.predict(feat.reshape((1,9,9,1)))  \n        out = out.squeeze()\n\n        pred = np.argmax(out, axis=1).reshape((9,9))+1 \n        prob = np.around(np.max(out, axis=1).reshape((9,9)), 2) \n        \n        feat = denorm(feat).reshape((9,9))\n        mask = (feat==0)\n     \n        if(mask.sum()==0):\n            break\n            \n        prob_new = prob*mask\n    \n        ind = np.argmax(prob_new)\n        x, y = (ind//9), (ind%9)\n\n        val = pred[x][y]\n        feat[x][y] = val\n        feat = norm(feat)\n    \n    return pred\n\ndef test_accuracy(feats, labels):\n    \n    correct = 0\n    \n    for i,feat in enumerate(feats):\n        \n        pred = inference_sudoku(feat)\n        \n        true = labels[i].reshape((9,9))+1\n        \n        if(abs(true - pred).sum()==0):\n            correct += 1\n        \n    print(correct/feats.shape[0])\n\ndef solve_sudoku(game):\n    \n    game = game.replace('\\n', '')\n    game = game.replace(' ', '')\n    game = np.array([int(j) for j in game]).reshape((9,9,1))\n    game = norm(game)\n    game = inference_sudoku(game)\n    return game","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"You can put in any game in the \"game\" string to solve it. Just copy new_game string in the game string and modify the desired zeros.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"new_game = '''\n          0 0 0 0 0 0 0 0 0\n          0 0 0 0 0 0 0 0 0\n          0 0 0 0 0 0 0 0 0\n          0 0 0 0 0 0 0 0 0\n          0 0 0 0 0 0 0 0 0\n          0 0 0 0 0 0 0 0 0\n          0 0 0 0 0 0 0 0 0\n          0 0 0 0 0 0 0 0 0\n          0 0 0 0 0 0 0 0 0\n      '''\n\ngame = '''\n          0 0 0 7 0 0 0 9 6\n          0 0 3 0 6 9 1 7 8\n          0 0 7 2 0 0 5 0 0\n          0 7 5 0 0 0 0 0 0\n          9 0 1 0 0 0 3 0 0\n          0 0 0 0 0 0 0 0 0\n          0 0 9 0 0 0 0 0 1\n          3 1 8 0 2 0 4 0 7\n          2 4 0 0 0 5 0 0 0\n      '''\n\ngame = solve_sudoku(game)\n\nprint('solved puzzle:\\n')\nprint(game)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.sum(game, axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <span style=\"color:green;text-decoration:underline\">Normal Approach #1</span>\nAs we can see that this model only achieved an accuracy of 84% on the training set and is not ideal for solving a sudoku. Neural nets are built to generalise and are not ideal for this problem. There are better approaches to achieve this using normal programming like the one given below which uses [backtracking](https://www.geeksforgeeks.org/sudoku-backtracking-7/) to solve the problem.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def solve(bo):\n    find = find_empty(bo)\n    if not find:\n        return True\n    else:\n        row, col = find\n\n    for i in range(1,10):\n        if valid(bo, i, (row, col)):\n            bo[row][col] = i\n\n            if solve(bo):\n                return True\n\n            bo[row][col] = 0\n\n    return False\n\n\ndef valid(bo, num, pos):\n    # Check row\n    for i in range(len(bo[0])):\n        if bo[pos[0]][i] == num and pos[1] != i:\n            return False\n\n    # Check column\n    for i in range(len(bo)):\n        if bo[i][pos[1]] == num and pos[0] != i:\n            return False\n\n    # Check box\n    box_x = pos[1] // 3\n    box_y = pos[0] // 3\n\n    for i in range(box_y*3, box_y*3 + 3):\n        for j in range(box_x * 3, box_x*3 + 3):\n            if bo[i][j] == num and (i,j) != pos:\n                return False\n\n    return True\n\n\ndef print_board(bo):\n    for i in range(len(bo)):\n        if i % 3 == 0 and i != 0:\n            print(\"- - - - - - - - - - - - - \")\n\n        for j in range(len(bo[0])):\n            if j % 3 == 0 and j != 0:\n                print(\" | \", end=\"\")\n\n            if j == 8:\n                print(bo[i][j])\n            else:\n                print(str(bo[i][j]) + \" \", end=\"\")\n\n\ndef find_empty(bo):\n    for i in range(len(bo)):\n        for j in range(len(bo[0])):\n            if bo[i][j] == 0:\n                return (i, j)  # row, col\n\n    return None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ngame = '''\n          0 0 0 7 0 0 0 9 6\n          0 0 3 0 6 9 1 7 8\n          0 0 7 2 0 0 5 0 0\n          0 7 5 0 0 0 0 0 0\n          9 0 1 0 0 0 3 0 0\n          0 0 0 0 0 0 0 0 0\n          0 0 9 0 0 0 0 0 1\n          3 1 8 0 2 0 4 0 7\n          2 4 0 0 0 5 0 0 0\n      '''\ngame = game.strip().split(\"\\n\")\nboard = []\nfor i in game:\n    t = i.replace(' ','').strip()\n    t = list(t)\n    t = list(map(int,t))\n    board.append(t)\n    \nif solve(board):\n    print_board(board)\nelse:\n    print(\"Can't be solved.\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.sum(board, axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This works like a charm and it is also very fast.\n<br>Let's check how fast is this algo. We will solve first 1000 problems and see the accuracy and speed!!","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"val_set = data.iloc[:1000]\n\n\nfrom tqdm import tqdm\nquiz_list = list(val_set['quizzes'])\nsol_list = list(val_set['solutions'])\nval_quiz = []\nval_sol = []\nfor i,j in tqdm(zip(quiz_list,sol_list)):\n    q = np.array(list(map(int,list(i)))).reshape(9,9)\n    s = np.array(list(map(int,list(j)))).reshape(9,9)\n    val_quiz.append(q)\n    val_sol.append(s)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ncount = 0\nfor i,j in tqdm(zip(val_quiz,val_sol)):\n    if solve(i):\n        if (i==j).all():\n            count+=1\n    else:\n        pass\n    \nprint(\"{}/1000 solved!! That's {}% accuracy.\\n\".format(count,(count/1000.0)*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that although it achieved 100% accuracy it is slow as it took a lot of time| to solve 1000 problems. Let's look at some better approaches.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## <span style=\"color:green;text-decoration:underline\">Normal Approach #2</span>\nA faster approach is to use the [**Naked Twin**](https://medium.com/@anandpathak69/solving-sudoku-using-naked-twin-strategies-f7ed23ea867f) approach which is a lot faster than backtracking.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport collections\n\nrows = 'ABCDEFGHI'\ncols = '123456789'\n\ndef cross(A, B):\n    \"Cross product of elements in A and elements in B.\"\n    return [s + t for s in A for t in B]\n\n\nboxes = cross(rows, cols)\n\nrow_units = [cross(r, cols) for r in rows]\ncolumn_units = [cross(rows, c) for c in cols]\nsquare_units = [cross(rs, cs) for rs in ('ABC', 'DEF', 'GHI') for cs in ('123', '456', '789')]\nunitlist = row_units + column_units + square_units \nunits = dict((s, [u for u in unitlist if s in u]) for s in boxes)\npeers = dict((s, set(sum(units[s], [])) - set([s])) for s in boxes)\n\n\ndef assign_value(values, box, value):\n    \"\"\"\n    Please use this function to update your values dictionary!\n    Assigns a value to a given box. If it updates the board record it.\n    \"\"\"\n    values[box] = value\n    return values\n\n\ndef naked_twins(values):\n    \"\"\"Eliminate values using the naked twins strategy.\n    Args:\n        values(dict): a dictionary of the form {'box_name': '123456789', ...}\n    Returns:\n        the values dictionary with the naked twins eliminated from peers.\n    \"\"\"\n\n    # Find all instances of naked twins\n    for unit in unitlist:\n        # Occurrences dict\n        unit_values_counter = collections.Counter([values[box] for box in unit])\n        for twins, count in unit_values_counter.items():\n            # twins will occur twice in a unit, triples will occur three times, and quads four times\n            if 1 < count == len(twins):\n                for box in unit:\n                    # for all boxes except twins boxes in a unit,\n                    # remove all potential values that exist in twins, triples, quads..\n                    if values[box] != twins and set(values[box]).intersection(set(twins)):\n                        for digit in twins:\n                            values = assign_value(values, box, values[box].replace(digit, ''))\n    return values\n\n\ndef grid_values(grid):\n    \"\"\"\n    Convert grid into a dict of {square: char} with '123456789' for empties.\n    Args:\n        grid(string) - A grid in string form.\n    Returns:\n        A grid in dictionary form\n            Keys: The boxes, e.g., 'A1'\n            Values: The value in each box, e.g., '8'. If the box has no value, then the value will be '123456789'.\n    \"\"\"\n    chars = []\n    digits = '123456789'\n    for c in grid:\n        if c in digits:\n            chars.append(c)\n        if c == '0':\n            chars.append(digits)\n    assert len(chars) == 81\n    return dict(zip(boxes, chars))\n\n\ndef display(values):\n    \"\"\"\n    Display the values as a 2-D grid.\n    Args:\n        values(dict): The sudoku in dictionary form\n    \"\"\"\n    width = 1 + max(len(values[s]) for s in boxes)\n    line = '+'.join(['-' * (width * 3)] * 3)\n    for r in rows:\n        print(''.join(values[r + c].center(width) + ('|' if c in '36' else '')\n                      for c in cols))\n        if r in 'CF': print(line)\n    print\n\n\ndef eliminate(values):\n    \"\"\"\n        Go through all the boxes, and whenever there is a box with a value, eliminate this value from the values of all its peers.\n        Input: A sudoku in dictionary form.\n        Output: The resulting sudoku in dictionary form.\n        \"\"\"\n    solved_values = [box for box in values.keys() if len(values[box]) == 1]\n    for box in solved_values:\n        digit = values[box]\n        for peer in peers[box]:\n            values[peer] = values[peer].replace(digit, '')\n    return values\n\n\ndef only_choice(values):\n    \"\"\"\n        Go through all the units, and whenever there is a unit with a value that only fits in one box, assign the value to this box.\n        Input: A sudoku in dictionary form.\n        Output: The resulting sudoku in dictionary form.\n        \"\"\"\n    for unit in unitlist:\n        for digit in '123456789':\n            dplaces = [box for box in unit if digit in values[box]]\n            if len(dplaces) == 1:\n                values[dplaces[0]] = digit\n    return values\n\n\ndef reduce_puzzle(values):\n    \"\"\"\n    Iterate eliminate() and only_choice(). If at some point, there is a box with no available values, return False.\n    If the sudoku is solved, return the sudoku.\n    If after an iteration of both functions, the sudoku remains the same, return the sudoku.\n    Input: A sudoku in dictionary form.\n    Output: The resulting sudoku in dictionary form.\n    \"\"\"\n    stalled = False\n    while not stalled:\n        solved_values_before = len([box for box in values.keys() if len(values[box]) == 1])\n        values = eliminate(values)\n        values = only_choice(values)\n        values = naked_twins(values)\n        solved_values_after = len([box for box in values.keys() if len(values[box]) == 1])\n        stalled = solved_values_before == solved_values_after\n        if len([box for box in values.keys() if len(values[box]) == 0]):\n            #display(values)\n            return False\n    return values\n\n\ndef search(values):\n    \"Using depth-first search and propagation, create a search tree and solve the sudoku.\"\n    # First, reduce the puzzle using the previous function\n    values = reduce_puzzle(values)\n    if values is False:\n        return False  ## Failed earlier\n    if all(len(values[s]) == 1 for s in boxes):\n        return values  ## Solved!\n    # Choose one of the unfilled squares with the fewest possibilities\n    min_possibility_box = min([box for box in boxes if len(values[box]) > 1])\n    # Now use recursion to solve each one of the resulting sudokus, and if one returns a value (not False), return that answer!\n    for digit in values[min_possibility_box]:\n        new_sudoku = values.copy()\n        new_sudoku[min_possibility_box] = digit\n        attempt = search(new_sudoku)\n        if attempt:\n            return attempt\n\n\ndef solve2(grid):\n\n    values = grid_values(grid)\n    values = search(values)\n    return values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ncount = 0\nfor row in tqdm(data.head(1000).iterrows()):\n    if (solve2(row[1][\"quizzes\"]) == grid_values(row[1][\"solutions\"])):\n        count+=1\n        \nprint(\"{}/1,000 solved!! That's {}% accuracy.\\n\".format(count,(count/1000.0)*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thats really fast compared to backtracking. Let's improve it a little bit more using multithreding(using all cpu cores in parallel).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nfrom multiprocessing import Pool\nnum_partitions = 100 #number of partitions to split dataframe\nnum_cores = 6 #number of cores on your machine\n\ndef parallelize_dataframe(df, func):\n    df_split = np.array_split(df, num_partitions)\n    pool = Pool(num_cores)\n    pool.map(func, df_split)\n    pool.close()\n    pool.join()\n\ndef solve_and_verify(data):\n    for row in data.iterrows():\n        assert solve2(row[1][\"quizzes\"]) == grid_values(row[1][\"solutions\"])\n    \nparallelize_dataframe(data.head(1000), solve_and_verify)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you can see this is a lot faster(almost real-time)!!","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Conclusion\n* From the above experiments to solve a sudoku, we found out that neural nets are not very accurate in this task and are not ideal candidates for this. They perform better in more generic tasks rather than very specific and arithmetic tasks.\n* Using backtracking we can solve a sudoku but it will be very slow as it uses multiple combinations as it proceeds.\n* The best approach by-far according to this experiment is Naked Twins approach. There are better versions of this approach out there that are even faster than this called Naked Triplets and even Naked Quadruples.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### TODO: \n1. Creating a image sudoku extractor and solver.\n2. Write a detailed medium article.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**NOTE:**<span style=\"color:red\"> If you like my work, or you want to use it please give an </span>***UPVOTE***. <span style=\"color:red\">It really motivates me to create more and better tutorials.</span> ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Credits\n1. https://www.kaggle.com/azureq/sudoku-ai-first-100k-in-7-mins\n2. https://towardsdatascience.com/solving-sudoku-with-convolution-neural-network-keras-655ba4be3b11\n3. https://techwithtim.net/tutorials/python-programming/sudoku-solver-backtracking/","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}