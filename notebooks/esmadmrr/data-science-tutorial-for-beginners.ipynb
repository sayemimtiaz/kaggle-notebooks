{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction\n\n![](https://comps.canstockphoto.com/credit-risk-drawings_csp11709232.jpg)\n\n## Context\n\nThe original dataset contains 1000 entries with 20 categorial/symbolic attributes prepared by Prof. Hofmann. In this dataset, each entry represents a person who takes a credit by a bank. Each person is classified as good or bad credit risks according to the set of attributes.\n\n## Content\n\n1. [Load and Check Data](#0)\n1. [Dataset Description](#1)\n1. [Standardization of Data](#2)\n1. [Missing Value Analysis](#3)\n1. [Outlier Value Analysis](#4)\n1. [Variable Transformation](#5)\n1. [Exploratory Data Analysis](#6)","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns #visualition\nimport matplotlib.pyplot as plt\nimport missingno as msno\nimport scipy.stats as stats\nimport statsmodels.api as sm\nimport pylab \nimport scipy\nfrom scipy.stats import mannwhitneyu\nfrom scipy.stats import chi2_contingency\nfrom scipy.stats import kstest\nfrom yellowbrick.cluster import KElbowVisualizer\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\nimport sklearn.metrics as metrics\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"0\"></a>\n# Load and Check Data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"* Load file","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"germanCreditData=pd.read_csv(\"/kaggle/input/german-credit-data-with-risk/german_credit_data.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* First 10 records in the Dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df=germanCreditData.copy()\n\ndf.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()\nprint(\"\\n\")\nprint(\"shape: \",df.shape)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Our data set consists of 11 columns and 1000 observations.\n* There are two types of data among variables. Data types are int and object.\n* Unnamed variable has no effect on the data set. Therefore, it will be removed from the data set in the next steps.\n* When we look at the information about the data set, it is determined that there is missing data in the SAving account and Checking amount section.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id=\"1\"></a>\n# Dataset Description","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"* Unnecessary variable deletion.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(df.columns[[0]],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Check, delete successful. Our new number of variables is 10.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2>Content</h2>\nIt is almost impossible to understand the original dataset due to its complicated system of categories and symbols. Thus, I wrote a small Python script to convert it into a readable CSV file. Several columns are simply ignored, because in my opinion either they are not important or their descriptions are obscure. The selected attributes are:\n\n<b>Age </b>(numeric)<br>\n<b>Sex </b>(text: male, female)<br>\n<b>Job </b>(numeric: 0 - unskilled and non-resident, 1 - unskilled and resident, 2 - skilled, 3 - highly skilled)<br>\n<b>Housing</b> (text: own, rent, or free)<br>\n<b>Saving accounts</b> (text - little, moderate, quite rich, rich)<br>\n<b>Checking account </b>(numeric, in DM - Deutsch Mark)<br>\n<b>Credit amount</b> (numeric, in DM)<br>\n<b>Duration</b> (numeric, in month)<br>\n<b>Purpose</b>(text: car, furniture/equipment, radio/TV, domestic appliances, repairs, education, business, vacation/others<br>\n<b>Risk </b> (Value target - Good or Bad Risk)<br>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id=\"2\"></a>\n# Standardization of Data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"* Cleaning is done to standardize the column names in the data set. New column names and old column names are kept in the list for the operation.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"oldColumn = df.columns\n\nnewColumn = [\"age\",\"sex\",\"job\",\"housing\",\"savingAccounts\",\"checkingAccount\",\"creditAmount\",\"duration\",\"purpose\",\"risk\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Old column names are replaced with new column names.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#df.rename(columns={\"Age\":\"age\"})\n\nfor i in range(len(newColumn)):\n    \n    df.rename(columns={oldColumn[i]:newColumn[i]},inplace=True)\n                \ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"3\"></a>\n# Missing Value ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"* Is there any missing data?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().values.any()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* How many are missing data in what variables?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Missing data is observed in SavingAccount and checkingAccount variables.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Missing data is Visualized","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"* The number of data is observed for each variable with barplot.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"msno.bar(df,color=sns.color_palette(\"deep\"));","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* The relationship between the heatmap chart and missing observations is examined.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"msno.heatmap(df);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* There is a 0.1 relationship between the Saving Account value and the Checking Account value.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"* The randomness between Saving Account and Checking Account observations is examined by looking at the matrix table.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"msno.matrix(df,color=(0.5,0.3,0.2));","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* When the missing observation values are examined, it is confirmed that the relationship between the observations is low.\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"* Customers may not have or may not have an account in the bank, so missing data are filled with \"no account\" information.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.savingAccounts=df.savingAccounts.fillna(value=\"no account\")\ndf.checkingAccount=df.checkingAccount.fillna(value=\"no account\")\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ekle = pd.DataFrame(\n        {'housing': pd.Categorical(\n              values =  df[\"housing\"],\n              categories=[\"free\",\"rent\",\"own\"]),\n\n         'savingAccounts': pd.Categorical(\n             values = df[\"savingAccounts\"],\n             categories=[\"no account\",\"little\",\"moderate\",\"rich\",\"quite rich\"]),\n\n         'checkingAccount': pd.Categorical(\n             values = df[\"checkingAccount\"],\n             categories=[\"no account\",\"little\",\"moderate\",\"rich\"])\n        }\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = df.copy()\nekle = ekle.apply(lambda x: x.cat.codes)\nekle.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del df1[\"savingAccounts\"]\ndel df1[\"checkingAccount\"]\ndel df1[\"housing\"]\ndf1 = pd.concat([df1,ekle],axis=1)\ndf1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1=pd.get_dummies(df1, columns = [\"sex\"], prefix = [\"sex\"])\ndf1=pd.get_dummies(df1, columns = [\"risk\"], prefix = [\"risk\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del df1[\"sex_male\"]\ndel df1[\"risk_bad\"]\ndf1.rename(columns={\"risk_good\":\"risk\",\n                  \"sex_female\":\"sex\"},inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.duration.plot(kind='hist',color='green',bins=20,figsize=(10,5))\nplt.title(\"duration Variable Histogram Chart\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"4\"></a>\n# Data Outlier","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"* The normality of the credit amount variable is examined with histogram and propplot graphs.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplot(2,1,1)\ndf.creditAmount.plot(kind='hist',color='pink',bins=50,figsize=(10,10))\nplt.title(\"creditAmount Variable Histogram Chart\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* The CreditAmount variable is skewed to the left so it is not distributed normally.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"stats.probplot(df.creditAmount, dist=\"norm\", plot=pylab)\npylab.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stat, p = stats.kstest(df[\"creditAmount\"], 'norm')\nprint('Statistics=%.3f, p=%.3f' % (stat, p))\nalpha = 0.05\nif p > alpha:\n    print('Credit Amount is distributed normally(H0:fail to reject)')\nelse:\n    print('Credit Amount is not distributed normally.(H0:reject)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* The graph is not distributed normally because the data in the CreditAmount variable is not around the line.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"*  Also Kruskal-wallis test shows that it is not distributed normally.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"group1 = df1[\"creditAmount\"][df1[\"risk\"] == 1]\ngroup2 = df1[\"creditAmount\"][df1[\"risk\"] == 0]\nstat, p = scipy.stats.mannwhitneyu(group1,group2)\nprint('Statistics=%.3f, p=%.3f' % (stat, p))\nalpha = 0.05\nif p > alpha:\n    print('it is not significant between Risk and Credit Amount(H0:fail to reject)')\nelse:\n    print('it is significant between Risk and Credit Amount(H0:reject)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* The relationship between CreditAmount and risk is analyzed with the boxplot chart.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(style=\"ticks\", palette=\"pastel\")\nsns.boxplot(x=\"risk\",y=\"creditAmount\",\n             palette=[\"m\", \"g\"],\n            data=df)\nsns.despine(offset=10, trim=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"* The relationship between the credit amount and housing is visualized by the boxplot method according to risk.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\nsns.set(style=\"ticks\", palette=\"pastel\")\n# Draw a nested boxplot to show bills by day and time\nsns.boxplot(x=\"housing\",y=\"creditAmount\",\n            hue=\"risk\", palette=[\"m\", \"g\"],\n            data=df)\nsns.despine(offset=10, trim=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* According to the graph, the most contradictory observations are observed in its own class in the housing variable.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"* The relationship between creditAmount variable and job variable is visualized with violinplot.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(style=\"whitegrid\", palette=\"pastel\", color_codes=True)\nsns.violinplot(x=\"job\", y=\"creditAmount\", hue=\"risk\",\n               split=True, inner=\"quarts\",\n               palette={\"good\": \"G\", \"bad\": \"B\"},\n               data=df);\nsns.despine(left=True);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Violinplot visualizes the data according to its quartiles. The place where the violin is the widest is the place where the creditAmount value repeats the most according to the job variable.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.purpose.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Boxenplot chart shows outliers between creditAmount and purpose variable.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(style=\"whitegrid\")\nsns.boxenplot(x=\"purpose\", y=\"creditAmount\",\n              color=\"b\",\n              scale=\"linear\", data=df);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* The Pairplot chart shows the relationship between creditAmount and the duration variable.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(df, height=3,\n                 vars=[\"creditAmount\",\"duration\"],hue=\"risk\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* The density of the values is between x = 0-50 and y = 0-10000.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"* The relationship between creditAmount and the sex variable is visualized according to the barplot chart.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x='sex',y='creditAmount',hue='risk',data=df);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(df.creditAmount);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* IQR value calculation is made to observe excessive values.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**IQR (Interquartile Range)**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Q1 = df1.creditAmount.quantile(0.25)\nQ3 = df1.creditAmount.quantile(0.75)\nIQR = Q3 - Q1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Q1:\",Q1)\nprint(\"Q3:\",Q3)\nprint(\"IQR:\",IQR)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"upper_value = Q3 + 1.5*IQR\nlower_value = Q1 - 1.5*IQR","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"upper_value:\",upper_value)\nprint(\"lower_value:\",lower_value)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Using the threshold values, outliers in the data set are detected.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"outlier_values = (df1.creditAmount < lower_value) | (df1.creditAmount > upper_value)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Total outliers.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.creditAmount[outlier_values].value_counts().sum() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Outliers Value Correction**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"upper_outlier = df1.creditAmount> upper_value\nupper_outlier.sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* All outliers are upper outliers.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.creditAmount[upper_outlier] = upper_value","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* After Correction","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(df1.creditAmount);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"5\"></a>\n# Data Visualition","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* We have 10 variables in total, 2 of these variables are numeric and 8 of them are categorical. Each variable will be analyzed according to targe and standardization work will be done for it.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"* Unique values of observations are examined.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Purpose : \",df.purpose.unique())\nprint(\"Sex : \",df.sex.unique())\nprint(\"Housing : \",df.housing.unique())\nprint(\"Saving accounts : \",df['savingAccounts'].unique())\nprint(\"Risk : \",df['risk'].unique())\nprint(\"Checking account : \",df['checkingAccount'].unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Categorical variables are examined and new variables are created from categorical variables using the dummy method and categorical methods.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"* Age variable","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.age.unique","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stat, p = stats.kstest(df[\"age\"], 'norm')\nprint('Statistics=%.3f, p=%.3f' % (stat, p))\nalpha = 0.05\nif p > alpha:\n    print('Age is distributed normally(H0:fail to reject)')\nelse:\n    print('Age is not distributed normally.(H0:reject)')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"group1 = df[\"age\"][df1[\"risk\"] == 1]\ngroup2 = df[\"age\"][df1[\"risk\"] == 0]\nstat, p = scipy.stats.mannwhitneyu(group1,group2)\nprint('Statistics=%.3f, p=%.3f' % (stat, p))\nalpha = 0.05\nif p > alpha:\n    print('it is not significant between Risk and Age(H0:fail to reject)')\nelse:\n    print('it is significant between Risk and Age(H0:reject)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is a significant betweet Risk and Age features. We decided to classificate of variable Age.\nK-Means applied.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.swarmplot(x='risk',y='age',hue='sex',data=df1);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.cluster import KMeans\ncolumns = ['job', 'creditAmount', 'duration', 'purpose', 'housing',\n       'savingAccounts', 'checkingAccount', 'sex', 'risk']\nkumeleme = df1.drop(columns,axis=1)\nkumeleme","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans = KMeans()\nclust = KElbowVisualizer(kmeans, k = (2,20))\nclust.fit(kumeleme)\nclust.poof()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"k_means = KMeans(n_clusters = 3).fit(kumeleme)\ncluster = k_means.labels_\nplt.scatter(df1.iloc[:,0], df.iloc[:,9], c = cluster, s = 60, cmap = \"winter\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1[\"age\"] = cluster","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.age.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nl = \"\\n\"\ncrosstab = pd.crosstab(df1['age'], df1['risk'])\nchi2, p, dof, expected = stats.chi2_contingency(crosstab)\nprint(f\"Chi-square= {chi2}{nl}p-value= {p}{nl}Degrees of freedom= {dof}\")\nalpha = 0.05\nif p > alpha:\n    print('it is not significant between Age and Risk(H0:fail to reject)')\nelse:\n    print('it is significant between Age and Risk(H0:reject)')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x=\"age\",hue=\"risk\",data=df1);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Sex variable","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.sex.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x=\"sex\",hue=\"risk\",data=df);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nl = \"\\n\"\ncrosstab = pd.crosstab(df1['sex'], df1['risk'])\nchi2, p, dof, expected = stats.chi2_contingency(crosstab)\nprint(f\"Chi-square= {chi2}{nl}p-value= {p}{nl}Degrees of freedom= {dof}\")\nalpha = 0.05\nif p > alpha:\n    print('it is not significant between Sex and Risk(H0:fail to reject)')\nelse:\n    print('it is significant between Sex and Risk(H0:reject)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Risk variable\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.risk.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Housing variable","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.housing.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x=\"housing\",hue=\"risk\",data=df);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nl = \"\\n\"\ncrosstab = pd.crosstab(df1['housing'], df1['risk'])\nchi2, p, dof, expected = stats.chi2_contingency(crosstab)\nprint(f\"Chi-square= {chi2}{nl}p-value= {p}{nl}Degrees of freedom= {dof}\")\nalpha = 0.05\nif p > alpha:\n    print('it is not significant between Housing and Risk(H0:fail to reject)')\nelse:\n    print('it is significant between Housing and Risk(H0:reject)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* CheckingAccount variable","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.checkingAccount.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x=\"checkingAccount\",hue=\"risk\",data=df);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nl = \"\\n\"\ncrosstab = pd.crosstab(df1['checkingAccount'], df1['risk'])\nchi2, p, dof, expected = stats.chi2_contingency(crosstab)\nprint(f\"Chi-square= {chi2}{nl}p-value= {p}{nl}Degrees of freedom= {dof}\")\nalpha = 0.05\nif p > alpha:\n    print('it is not significant between Checking Account and Risk(H0:fail to reject)')\nelse:\n    print('it is significant between Checking Account and Risk(H0:reject)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* SavingAccount variable","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.savingAccounts.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x=\"savingAccounts\",hue=\"risk\",data=df);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nl = \"\\n\"\ncrosstab = pd.crosstab(df1['savingAccounts'], df1['risk'])\nchi2, p, dof, expected = stats.chi2_contingency(crosstab)\nprint(f\"Chi-square= {chi2}{nl}p-value= {p}{nl}Degrees of freedom= {dof}\")\nalpha = 0.05\nif p > alpha:\n    print('it is not significant between Saving Accounts and Risk(H0:fail to reject)')\nelse:\n    print('it is significant between Saving Accounts and Risk(H0:reject)')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"risk2=df.risk.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot( x=risk2.index,y=risk2.values,data=df);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Purpose Variable","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x=\"purpose\",hue=\"risk\",data=df);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nl = \"\\n\"\ncrosstab = pd.crosstab(df1['purpose'], df1['risk'])\nchi2, p, dof, expected = stats.chi2_contingency(crosstab)\nprint(f\"Chi-square= {chi2}{nl}p-value= {p}{nl}Degrees of freedom= {dof}\")\nalpha = 0.05\nif p > alpha:\n    print('it is not significant between Purpose and Risk(H0:fail to reject)')\nelse:\n    print('it is significant between Purpose and Risk(H0:reject)')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"purpose_vs_Risk = pd.crosstab(index=df1[\"purpose\"], \n                             columns=df1[\"risk\"],\n                             margins=True)\n\npurpose_vs_Risk","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nThere is no significant difference between the Purpose and Risk variable.\n\nSignificance can be gained by making various changes.\n\nWe decided to combine domestic appliances and furniture/equipment.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.purpose[df1.purpose == \"domestic appliances\"] = \"furniture/equipment\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nl = \"\\n\"\ncrosstab = pd.crosstab(df1['purpose'], df1['risk'])\nchi2, p, dof, expected = stats.chi2_contingency(crosstab)\nprint(f\"Chi-square= {chi2}{nl}p-value= {p}{nl}Degrees of freedom= {dof}\")\nalpha = 0.05\nif p > alpha:\n    print('it is not significant between Purpose and Risk(H0:fail to reject)')\nelse:\n    print('it is significant between Purpose and Risk(H0:reject)')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ekle1 = pd.DataFrame({'purpose': pd.Categorical(\n             values = df1[\"purpose\"],\n             categories=[\"repairs\",\"vacation/others\",\"furniture/equipment\"\n                         ,\"radio/TV\",\"education\",\"business\",\"car\"])\n    }\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2 = df1.copy()\nekle1 = ekle1.apply(lambda x: x.cat.codes)\nekle1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del df2[\"purpose\"]\ndf2 = pd.concat([df2,ekle1],axis=1)\ndf2.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* SECOND TRIAL","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df1=pd.get_dummies(df1, columns = [\"purpose\"], prefix = [\"p\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del df1[\"p_repairs\"]\ndf1.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Job Variable","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"nl = \"\\n\"\ncrosstab = pd.crosstab(df1['job'], df1['risk'])\nchi2, p, dof, expected = stats.chi2_contingency(crosstab)\nprint(f\"Chi-square= {chi2}{nl}p-value= {p}{nl}Degrees of freedom= {dof}\")\nalpha = 0.05\nif p > alpha:\n    print('it is not significant between Job and Risk(H0:fail to reject)')\nelse:\n    print('it is significant between Job and Risk(H0:reject)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is no significant difference between the Job and Risk variable.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"job_vs_Risk = pd.crosstab(index=df1[\"job\"], \n                             columns=df1[\"risk\"],\n                             margins=True)\n\njob_vs_Risk","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"6\"></a>\n# ML Modeling","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df2[\"risk\"]\nX = df2.drop([\"risk\"], axis = 1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.30, \n                                                    random_state=982)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_tuned1 = XGBClassifier(learning_rate= 0.01, \n                                max_depth= 7, \n                                n_estimators= 1000, \n                                subsample= 0.7).fit(X_train, y_train)\ny_pred = xgb_tuned1.predict(X_test)\naccuracy_score(y_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metrics.confusion_matrix(y_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fpr, tpr, threshold = metrics.roc_curve(y_test, y_pred)\nroc_auc = metrics.auc(fpr, tpr)\nplt.title('Feature Characteristics')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_imp = pd.Series(xgb_tuned1.feature_importances_,\n                        index=X_train.columns).sort_values(ascending=False)\nsns.barplot(x=feature_imp, y=feature_imp.index)\nplt.xlabel(\"Feature Significance Scores\")\nplt.ylabel('Features')\nplt.title(\"Significance Levels\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* SECOND TRÄ°AL ML MODEL","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df1[\"risk\"]\nX = df1.drop([\"risk\"], axis = 1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.30, \n                                                    random_state=982)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_tuned2 = XGBClassifier(learning_rate= 0.01, \n                                max_depth= 7, \n                                n_estimators= 1000, \n                                subsample= 0.7).fit(X_train, y_train)\ny_pred = xgb_tuned2.predict(X_test)\naccuracy_score(y_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metrics.confusion_matrix(y_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fpr, tpr, threshold = metrics.roc_curve(y_test, y_pred)\nroc_auc = metrics.auc(fpr, tpr)\nplt.title('Feature Characteristics')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_imp = pd.Series(xgb_tuned2.feature_importances_,\n                        index=X_train.columns).sort_values(ascending=False)\n\nsns.barplot(x=feature_imp, y=feature_imp.index)\nplt.xlabel(\"Feature Significance Scores\")\nplt.ylabel('Features')\nplt.title(\"Significance Levels\")\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}