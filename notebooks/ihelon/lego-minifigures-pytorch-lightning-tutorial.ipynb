{"cells":[{"metadata":{},"cell_type":"markdown","source":"# PyTorch Lightning Modeling for [LEGO Minifigures Classification](https://www.kaggle.com/ihelon/lego-minifigures-classification) dataset\n\nThis is the guide about using pretrained models with PyTorch Lightning framework.   \nWe will use MobileNetV2 model to predict which Minifigure is in the image.   "},{"metadata":{},"cell_type":"markdown","source":"If you are interested in other frameworks you can check these tutorials:\n* [LEGO Minifigures - PyTorch Tutorial](https://www.kaggle.com/ihelon/lego-minifigures-pytorch-tutorial)\n* [LEGO Minifigures - TensorFlow Tutorial](https://www.kaggle.com/ihelon/lego-minifigures-tensorflow-tutorial)"},{"metadata":{},"cell_type":"markdown","source":"![](https://i.imgur.com/4cPQlEN.jpg)"},{"metadata":{},"cell_type":"markdown","source":"### Please Upvote [this](https://www.kaggle.com/ihelon/lego-minifigures-classification) dataset ðŸ˜€"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install -q --upgrade pip\n!pip install -q pytorch-lightning","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"top\"></a>\n\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:blue; border:0' role=\"tab\" aria-controls=\"home\"><center>Quick Navigation</center></h3>\n\n* [1. Configurations](#1)\n* [2. Dataset class](#2)\n* [3. Augmentations](#3)\n* [4. Data module](#4)\n* [5. Lightning module](#5)\n* [6. Model training](#6)\n* [7. Inference model loading](#7)\n* [8. Final validation check](#8)\n* [9. Error analysis - Confusion matrix](#9)\n* [10. Error analysis - Misclassified samples](#10)"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"1\"></a>\n<h2 style='background:blue; border:0; color:white'><center>Configurations<center><h2>"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport math\nimport time\nimport random\nimport warnings\n\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sn\nimport albumentations as A\nimport torch\nfrom torch.utils import data as torch_data\nfrom torch import nn as torch_nn\nfrom torch.nn import functional as torch_F\nimport torchvision\nimport pytorch_lightning as pl\nfrom pytorch_lightning import metrics as pl_metrics\nfrom pytorch_lightning import callbacks as pl_callbacks\nfrom pytorch_lightning.core.decorators import auto_move_data\nfrom sklearn import metrics as sk_metrics\n\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def set_seed(seed):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n        torch.backends.cudnn.deterministic = True\n\n\nSEED = 42\nset_seed(SEED)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The base dataset directory\nBASE_DIR = '../input/lego-minifigures-classification/'\n\ndf_metadata = pd.read_csv(os.path.join(BASE_DIR, 'metadata.csv'), index_col=0)\nN_CLASSES = df_metadata.shape[0]\nprint('Number of classes: ', N_CLASSES)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"2\"></a>\n<h2 style='background:blue; border:0; color:white'><center>Dataset class<center><h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"class DataRetriever(torch_data.Dataset):\n    def __init__(\n        self, \n        paths, \n        targets, \n        image_size=(224, 224),\n        transforms=None\n    ):\n        self.paths = paths\n        self.targets = targets\n        self.image_size = image_size\n        self.transforms = transforms\n        self.preprocess = torchvision.transforms.Compose([\n            torchvision.transforms.ToTensor(),\n            torchvision.transforms.Normalize(\n                mean=[0.485, 0.456, 0.406], \n                std=[0.229, 0.224, 0.225]\n            ),\n        ])\n          \n    def __len__(self):\n        return len(self.targets)\n    \n    def __getitem__(self, index):\n        img = cv2.imread(self.paths[index])\n        img = cv2.resize(img, self.image_size)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        if self.transforms:\n            img = self.transforms(image=img)['image']\n            \n        img = self.preprocess(img)\n        \n        y = torch.tensor(self.targets[index], dtype=torch.long)\n            \n        return {'X': img, 'y': y}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"3\"></a>\n<h2 style='background:blue; border:0; color:white'><center>Augmentations<center><h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_train_transforms():\n    return A.Compose(\n        [\n            A.Rotate(limit=30, border_mode=cv2.BORDER_REPLICATE, p=0.5),\n            A.Cutout(num_holes=8, max_h_size=25, max_w_size=25, fill_value=0, p=0.25),\n            A.Cutout(num_holes=8, max_h_size=25, max_w_size=25, fill_value=255, p=0.25),\n            A.HorizontalFlip(p=0.5),\n            A.RandomContrast(limit=(-0.3, 0.3), p=0.5),\n            A.RandomBrightness(limit=(-0.4, 0.4), p=0.5),\n            A.Blur(p=0.25),\n        ], \n        p=1.0\n    )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"4\"></a>\n<h2 style='background:blue; border:0; color:white'><center>Data module<center><h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"class LEGOMinifiguresDataModule(pl.LightningDataModule):\n    def __init__(\n        self, \n        train_batch_size, \n        valid_batch_size, \n        image_size, \n        base_dir,\n        train_augmentations=None\n    ):\n        super().__init__()\n        self.train_batch_size = train_batch_size\n        self.valid_batch_size = valid_batch_size\n        self.image_size = image_size\n        self.base_dir = base_dir\n        self.train_augmentations=train_augmentations\n        \n    def prepare_data(self):\n        self.df = pd.read_csv(os.path.join(self.base_dir, 'index.csv'), index_col=0)\n\n    def setup(self, stage):\n        tmp_train = self.df[self.df['train-valid'] == 'train']\n        train_paths = tmp_train['path'].values\n        self.train_targets = tmp_train['class_id'].values - 1\n        self.train_paths = list(map(lambda x: os.path.join(self.base_dir, x), train_paths))\n        \n        tmp_valid = self.df[self.df['train-valid'] == 'valid']\n        valid_paths = tmp_valid['path'].values\n        self.valid_targets = tmp_valid['class_id'].values - 1\n        self.valid_paths = list(map(lambda x: os.path.join(self.base_dir, x), valid_paths))\n        \n    def train_dataloader(self):\n        train_data_retriever = DataRetriever(\n            self.train_paths, \n            self.train_targets, \n            image_size=self.image_size,\n            transforms=self.train_augmentations\n        )\n        \n        train_loader = torch_data.DataLoader(\n            train_data_retriever,\n            batch_size=self.train_batch_size,\n            shuffle=True,\n        )\n        return train_loader\n    \n    def val_dataloader(self):\n        valid_data_retriever = DataRetriever(\n            self.valid_paths, \n            self.valid_targets, \n            image_size=self.image_size,\n        )\n        \n        valid_loader = torch_data.DataLoader(\n            valid_data_retriever, \n            batch_size=self.valid_batch_size,\n            shuffle=False,\n        )\n        return valid_loader","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"5\"></a>\n<h2 style='background:blue; border:0; color:white'><center>Lightning module<center><h2>\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"class LitModel(pl.LightningModule):\n    \n    def __init__(self, n_classes):\n        super().__init__()\n        self.net = torch.hub.load(\n            'pytorch/vision:v0.6.0', \n            'mobilenet_v2', \n            pretrained=True\n        )\n        self.net.classifier = torch_nn.Linear(\n            in_features=1280, \n            out_features=n_classes, \n            bias=True\n        )\n        self.save_hyperparameters()\n\n    @auto_move_data\n    def forward(self, x):\n        x = self.net(x)\n        return x\n    \n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n        return optimizer\n    \n    def training_step(self, batch, batch_idx):\n        X, y = batch['X'], batch['y']\n        y_hat = self(X)\n        train_loss = torch_F.cross_entropy(y_hat, y)\n        train_acc = pl_metrics.functional.accuracy(\n            y_hat, \n            y, \n            num_classes=self.hparams.n_classes\n        )\n        \n        result = pl.TrainResult(train_loss)\n        result.log('train_loss', train_loss, prog_bar=True, on_epoch=True, on_step=False)\n        result.log('train_acc', train_acc, prog_bar=True, on_epoch=True, on_step=False)\n        return result\n    \n    def validation_step(self, batch, batch_idx):\n        X, y = batch['X'], batch['y']\n        y_hat = self(X)\n        \n        valid_loss = torch_F.cross_entropy(y_hat, y)\n        valid_acc = pl_metrics.functional.accuracy(\n            y_hat, \n            y, \n            num_classes=self.hparams.n_classes\n        )\n        \n        result = pl.EvalResult(checkpoint_on=valid_loss, early_stop_on=valid_loss)\n        result.log('valid_loss', valid_loss, prog_bar=True, on_epoch=True, on_step=False)\n        result.log('valid_acc', valid_acc, prog_bar=True, on_epoch=True, on_step=False)\n        return result\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"6\"></a>\n<h2 style='background:blue; border:0; color:white'><center>Model training<center><h2>"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"model = LitModel(n_classes=N_CLASSES)\n\ndata_module = LEGOMinifiguresDataModule(\n    train_batch_size=4, \n    valid_batch_size=1, \n    image_size=(512, 512), \n    base_dir=BASE_DIR,\n    train_augmentations=get_train_transforms()\n)\n\ncallback_early_stopping = pl_callbacks.EarlyStopping(\n    'valid_loss', \n    patience=3, \n    mode='min'\n)\ncallback_model_checkpoint = pl_callbacks.ModelCheckpoint(\n    '{epoch}-{valid_loss:.3f}', \n    monitor='valid_loss', \n    mode='min'\n)\n\ntrainer = pl.Trainer(\n    gpus=1,\n    early_stop_callback=callback_early_stopping,\n    checkpoint_callback=callback_model_checkpoint, \n    max_epochs=50\n)\n\ntrainer.fit(\n    model, \n    data_module,\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"7\"></a>\n<h2 style='background:blue; border:0; color:white'><center>Inference model loading<center><h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nbest_model_path = callback_model_checkpoint.best_model_path\n\nmodel = LitModel.load_from_checkpoint(\n    checkpoint_path=best_model_path\n)\nmodel = model.to(device)\nmodel.freeze()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"8\"></a>\n<h2 style='background:blue; border:0; color:white'><center>Final validation check<center><h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save the model predictions and true labels\ny_pred = []\ny_valid = []\nfor ind, batch in enumerate(data_module.val_dataloader()):\n    pred_probs = model(batch['X'])\n    y_pred.extend(pred_probs.argmax(axis=-1).cpu().numpy())\n    y_valid.extend(batch['y'])\n    \n\n# Calculate needed metrics\nprint(f'Accuracy score on validation data:\\t{sk_metrics.accuracy_score(y_valid, y_pred)}')\nprint(f'Macro F1 score on validation data:\\t{sk_metrics.f1_score(y_valid, y_pred, average=\"macro\")}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"9\"></a>\n<h2 style='background:blue; border:0; color:white'><center>Error analysis - Confusion matrix<center><h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load metadata to get classes people-friendly names\nlabels = df_metadata['minifigure_name'].tolist()\n\n# Calculate confusion matrix\nconfusion_matrix = sk_metrics.confusion_matrix(y_valid, y_pred)\ndf_confusion_matrix = pd.DataFrame(confusion_matrix, index=labels, columns=labels)\n\n# Show confusion matrix\nplt.figure(figsize=(12, 12))\nsn.heatmap(df_confusion_matrix, annot=True, cbar=False, cmap='Oranges', linewidths=1, linecolor='black')\nplt.xlabel('Predicted labels', fontsize=15)\nplt.xticks(fontsize=12)\nplt.ylabel('True labels', fontsize=15)\nplt.yticks(fontsize=12);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"10\"></a>\n<h2 style='background:blue; border:0; color:white'><center>Error analysis - Misclassified samples<center><h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"error_images = []\nerror_label = []\nerror_pred = []\nerror_prob = []\nfor batch in data_module.val_dataloader():\n    _X_valid, _y_valid = batch['X'], batch['y']\n    pred = torch.softmax(model(_X_valid), axis=-1).cpu().numpy()\n    pred_class = pred.argmax(axis=-1)\n    if pred_class != _y_valid.cpu().numpy():\n        error_images.extend(_X_valid)\n        error_label.extend(_y_valid)\n        error_pred.extend(pred_class)\n        error_prob.extend(pred.max(axis=-1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def denormalize_image(image):\n    return image * [0.229, 0.224, 0.225] + [0.485, 0.456, 0.406]\n\nplt.figure(figsize=(16, 16))\nw_size = int(len(error_images) ** 0.5)\nh_size = math.ceil(len(error_images) / w_size)\nfor ind, image in enumerate(error_images):\n    plt.subplot(h_size, w_size, ind + 1)\n    plt.imshow(denormalize_image(image.permute(1, 2, 0).numpy()))\n    pred_label = labels[error_pred[ind]]\n    pred_prob = error_prob[ind]\n    true_label = labels[error_label[ind]]\n    plt.title(f'predict: {pred_label} ({pred_prob:.2f}) true: {true_label}')\n    plt.axis('off')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}