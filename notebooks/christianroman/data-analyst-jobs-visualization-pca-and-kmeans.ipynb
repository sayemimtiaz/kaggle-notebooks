{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Import DataSet 'Data Analyst Jobs'"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# IMPORT DATA AND PACKED\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.graph_objs as go\nimport plotly.express as px\nfrom plotly.subplots import make_subplots \nfrom plotly.offline import init_notebook_mode, iplot","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Conditions all for the plotting\nsns.set()\npd.options.plotting.backend = 'plotly'\nplt.style.use('seaborn')\ninit_notebook_mode(connected = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Charge data csv 'data-analyst-jobs' as format Dataframe from pandas\ndf = pd.read_csv('../input/data-analyst-jobs/DataAnalyst.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# General info from data:\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Cleaning to be Worked On"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Delete column \"Unnamed: 0\"\ndf.drop(['Unnamed: 0'], axis = 1, inplace = True)\n# Copy data a new DataFrame\ndf1 = df.copy()\ndf1.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# DATA CLEANING\n\n#Separate values for create new two fields from them:\ndf1['Job Title'],df1['Department']= df['Job Title'].str.split(',',1).str\ndf1['Company Name'],_ = df['Company Name'].str.split('\\n',1).str\ndf1['Salary Estimate'],_= df['Salary Estimate'].str.split('(',1).str\ndf1['Min Salary'],df1['Max Salary']= df1['Salary Estimate'].str.split('-').str\n\n# Created values Max Salary and Min Salary as well as data cleaning with strip methods from string class\n# Replace withe spaces for nan values through the numpy.\nclean_salary = lambda x: x.replace('', np.nan).str.strip().str.lstrip('$').str.rstrip('K').fillna(0).astype(int)\ndf1['Min Salary'] = clean_salary(df1['Min Salary'])\ndf1['Max Salary'] = clean_salary(df1['Max Salary'])\n\n# Empty Field 'Salary Estimate' but created Max and Min salary.\ndf1 = df1.drop(['Salary Estimate'],axis = 1)\n\n# Show 'df1' with the changes realized previously. \ndf1.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Companies Easy Apply for Data Analyst Jobs"},{"metadata":{"trusted":true},"cell_type":"code","source":"# DATA ANALYTICS\n# Count values from easy apply for each job offers\ndf1['Easy Apply'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Easy applicated only 80 companies, the rest could to be applicated dificult it.\n# With a function, it recodes key and values to take new values between 0 and 1\ndef recode(column, new_code):\n    col_cod = pd.Series(column, copy = True)\n    for key, values in new_code.items():\n        col_cod.replace(key, values, inplace = True)\n    return col_cod","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Use the new function\ndf1['Easy Apply'] = recode(df1['Easy Apply'],{'-1':0,'True':1})\ndf1['Competitors'] = recode(df1['Competitors'],{'-1':np.nan})\n\n# Extracted data the Easy Apply with values equal '1', in the other words,  \n# this part will to make only in offers jobs where is easy applicated\ndf_easy_apply = df1[df1['Easy Apply'] == 1]\ndf_easy_apply.reset_index()\ndf_easy_apply.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# New Dataframe through method 'Groupby' from 'pandas' packet. It's grouped in fallen order and count the values \"Easy Apply\" for each offer jobs\ndf_easy_apply_1 = df_easy_apply.groupby(['Company Name','Sector'])['Easy Apply'].count().reset_index()\n# In the same way, apply method 'Groupby' with the values \"Max Salary\". It's grouped throght it's average\ndf_easy_apply_2 = df_easy_apply.groupby(['Company Name'])['Max Salary'].mean().reset_index()\n# Apply concate fields and order descendent for dataframe before and perform cut in ten primary\ndf_easy = pd.DataFrame()\ndf_easy = pd.concat([df_easy_apply_1['Company Name'], df_easy_apply_1['Easy Apply'], \n                     df_easy_apply_2['Max Salary']], axis = 1)\ndf_easy = df_easy.sort_values('Easy Apply', ascending = False).head(10).reset_index().drop('index', axis = 1)\ndf_easy.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot graph bar with Plotly included color graduation in function the Max Salary Mean.\nchart = px.bar(df_easy, y = 'Easy Apply', x = 'Company Name', color = 'Max Salary',\n              color_continuous_scale = px.colors.sequential.Viridis,\n              title = \"Companies That Have Jobs as Data Analyst With Easily Apply\")\nchart.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Size Company - Employed Quantity that Offer Jobs as a Data Analyst**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now, visualization of size company in funtion quantily employees that offers job in data analyst.\n\n# Create DateFrame and empty rows with useless data\n# Change of field names for easy descriptive in graphic and visualization\ndf_employed = df1['Size'].value_counts().to_frame().reset_index()\ndf_employed = df_employed.drop(df_employed[(df_employed['index'] == '-1') | \\\n                                           (df_employed['index'] == 'Unknown')].index, \n                               axis = 0).rename(columns = {'index': 'Size Company',\n                                                           'Size': 'Nº Company'})\ndf_employed.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Finally, plot graphic barplot in horizontal for Size Company in function of employees Quantity:\n# Use Plotly Express\nchart1 = px.bar(df_employed, x = 'Nº Company', y = 'Size Company',\n               title = 'Size Company in function of employees Quantity')\nchart1.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Classification of Companies vs Ratings"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Use grouby method for get a new dataframe thad measure number companies your rating\n# In addition, we order descending in the ratings function, discard lower rating values that 3.00 \n# And rename fields\ndf_rating = df1.groupby('Rating')['Company Name'].count().to_frame().reset_index()\\\n                        .sort_values('Rating', ascending = False).reset_index()\\\n                        .drop('index', axis = 1)\\\n                        .rename(columns = {'Company Name': 'Nº Companies'})\n\ndf_rating = df_rating.drop(df_rating[(df_rating['Rating'] <= 3.00)].index, axis = 0)\n\ndf_rating.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot visualization in graphic bars. \nplt.figure(figsize = (12,6))\n\nplot = sns.barplot(x = 'Rating', y = 'Nº Companies', data = df_rating, palette = 'rocket')\nplot = plot.set_xticklabels(plot.get_xticklabels(),\n                           horizontalalignment = 'right',\n                           fontweight = 'light')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Ownership Companies Type that Offers Jobs Data Analyst"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualization of Ownerships companies type that offers job Data Analysta\n# Empty row with '-1 index, rename fields and discard lowers values that 10\ndf_ownership = df1['Type of ownership'].value_counts().to_frame()\\\n               .drop('-1').reset_index()\\\n               .rename(columns = {'index': 'Type of Ownership',\n                                  'Type of ownership': 'Nº Offers Jobs'})\n\ndf_ownership = df_ownership.drop(df_ownership[(df_ownership['Nº Offers Jobs'] <= 10)].index, axis = 0)\ndf_ownership.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Finaly, barplot with seaborn\nplt.figure(figsize = (12,6))\nplot = sns.barplot(x = 'Nº Offers Jobs', y = 'Type of Ownership', data = df_ownership)\nplot = plot.set_xticklabels(plot.get_xticklabels(),\n                           rotation = 65,\n                           horizontalalignment = 'right')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Range Salary for Each Sector"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now, analyze Max salary in fuction the each sector\n# Empty rows and fields innesesary\ndf_mean_salary = df1.groupby(['Sector']).mean().reset_index()\\\n                    .drop(['Founded','Easy Apply'], axis = 1)\n# The sectors as government and non-profit it would't take for analitycs\ndf_mean_salary = df_mean_salary.drop(df_mean_salary[(df_mean_salary['Sector'] == '-1') | \\\n                                                    (df_mean_salary['Sector'] == 'Government') | \\\n                                                    (df_mean_salary['Sector'] == 'Non-Profit')].index,\n                                     axis = 0) \\\n                                     .sort_values('Max Salary', ascending = False)\n\ndf_mean_salary.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualization in bar graph with plotly\n\n# Create Trace 1\ntrace1 = go.Bar(x = df_mean_salary['Sector'],\n                y = df_mean_salary['Max Salary'],\n                name = 'Max Salary',\n                marker = dict(color ='rgb(55, 83, 109)',\n                             line = dict(color = 'rgb(0,0,0)', width = 1.5)))\n\n# Create Trace 2\ntrace2 = go.Bar(x = df_mean_salary['Sector'],\n                y = df_mean_salary['Min Salary'],\n                name = 'Min Salary',\n                marker = dict(color = 'indianred',\n                             line = dict(color = 'rgb(0,0,0)', width = 1.5)))\n\ndata = [trace1, trace2]\n\nlayout = go.Layout(title = 'Salary Range For Each Sector', \n                   barmode = 'group')\n\nchart = go.Figure(data = data, layout = layout)\niplot(chart)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Distribution of Job Offers as a Data Analyst in the Territory of the United States"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a DataFrame with features (Mean Salary, Location and Mean Salary) \ndf_states = pd.DataFrame()\ndftemp = df1.copy()\ndftemp['Mean Salary'] = (df1['Max Salary'] + df1['Min Salary']) / 2\ndf_states = pd.concat([df1['Sector'],df1['Location'], dftemp['Mean Salary']], axis = 1)\ndf_states.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Seperate Acronym and City from Location Field\ndf_states['City'], df_states['Acronym State'] = df_states['Location'].str.split(',', 1).str\n# Remove field \"Location\" and values '-1' in field sector:\ndf_states = df_states.drop('Location', axis = 1) \\\n                     .drop(df_states[df_states['Sector'] == '-1'].index, axis = 0)\ndf_states.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Apply Groupy with DataFrame both in the count and the mean values, after concated fields in the new DataFrame:\ndf_states_group = df_states.groupby(['Acronym State']).count().reset_index()\ndf_salary_group = df_states.groupby(['Acronym State']).mean().reset_index()\n\n# New Dataframe \ndf_map = pd.DataFrame()\ndf_map = pd.concat([df_states_group['Acronym State'], \n                    df_states_group['Sector'], \n                    df_salary_group['Mean Salary']], \n                   axis = 1)\ndf_map.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Round Mean Salary Value with Lambda function and remove row in 'Araphone, CO' Value of \"Sector\" field\ndf_map = df_map.drop([1], axis = 0).rename(columns = {'Sector': 'Nº Offers Jobs'})\ndf_map['Mean Salary'] = df_map['Mean Salary'].apply(lambda x: round(x, 2))\ndf_map.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot Map of United States with Plotly in module graph_objects:\nlocations = list(df_map['Acronym State'])\n\n# Remove withe space in \"Acronym State\" field\nfor i in range(0, len(locations)):\n    locations[i] = locations[i].replace(\" \", \"\")\n\nqjobs = list(df_map['Nº Offers Jobs'])\n\n# Create text that displays the basic data when the cursor is over the chart status \ndf_map_str = df_map.copy()\nfor col in df_map_str.columns:\n    df_map_str[col] = df_map_str[col].astype(str)\n    \n# Apply '$' symbol in Mean Salary values\ndf_map_str['Mean Salary'] = df_map_str['Mean Salary'].apply(lambda x: \"$\" + x + \"/Year\")\n# Text visualization:\ndf_map_str['Text'] = df_map_str['Acronym State']  + '<br>' + \\\n    \"Nª Offers Jobs: \" + df_map_str['Nº Offers Jobs'] + '<br>' \\\n        \"Mean Salary from the Jobs as Data Analyst: \" + '<br>' + df_map_str['Mean Salary'] + \" (Thousands)\"\ndf_map_str.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot Map in plotly\nimport plotly.graph_objects as go\n\n\nfig = go.Figure(data = go.Choropleth(locations = locations,\n                                    z = qjobs,\n                                    locationmode = 'USA-states',\n                                    text = df_map_str['Text'],\n                                    marker_line_color = 'black',\n                                    colorbar_title = 'Nº Offers Jobs'),) \n\nfig.update_layout(title_text = 'Nº Offers Jobs as Data Analyst<br>United States of America',\n                 geo = dict(scope = 'usa',\n                           projection = go.layout.geo.Projection(type = 'albers usa'),\n                           showlakes = True,\n                           lakecolor = 'rgb(255,255,255)'),)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Created new dataframe for view jobs percentage as well as its mean salary year for each state\ndf_map2 = df_map.copy()\ndf_map2['Jobs Percentage'] = (df_map2['Nº Offers Jobs'] / df_map2['Nº Offers Jobs'].sum()) * 100\ndf_map2['Jobs Percentage'] = df_map2['Jobs Percentage'].apply(lambda x: round(x, 1))\ndf_map2 = df_map2.sort_values('Jobs Percentage', ascending = True) \\\n                 .drop(df_map2[df_map2['Jobs Percentage'] <= 2.0].index, axis = 0) \\\n                 .reset_index() \\\n                 .drop('index', axis = 1)\ndf_map2.head(11)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create two Subplots:\nfig_states = make_subplots(rows = 1, cols = 2, specs = [[{},{}]], shared_xaxes = True,\n                          shared_yaxes = False, vertical_spacing = 0.001)\n\nfig_states.append_trace(go.Bar(x = df_map2['Jobs Percentage'],\n                       y = df_map2['Acronym State'],\n                       marker = dict(color = 'rgba(50, 171, 40, 0.7)',\n                                    line = dict(color='rgba(60, 171, 120, 1.0)',\n                                               width = 1,)\n                                    ),\n                       name = 'Percentage Jobs',\n                       orientation = 'h',\n                       ),\n                1, 1)\n\nfig_states.append_trace(go.Scatter(x = df_map2['Mean Salary'],\n                                  y = df_map2['Acronym State'],\n                                  mode = 'lines+markers',\n                                  line_color = 'rgb(128, 0, 128)',\n                                  name = 'Mean Salary'),\n                       1, 2)\n\nfig_states.update_layout(title = 'Distribution of the Offers Jobs From in United States',\n                        yaxis = dict(showgrid = True,\n                                    showline = True,\n                                    showticklabels = True,\n                                    linecolor = 'rgba(102,102,102,0.8)',\n                                    linewidth = 2,\n                                    domain = [0, 0.94],\n                                    ),\n                        yaxis2 = dict(showgrid = True,\n                                     showline = True,\n                                     showticklabels = False,\n                                     linecolor = 'rgba(102,102,102,0.8)',\n                                     linewidth = 1,\n                                     domain = [0, 0.94],\n                                     ),\n                        xaxis = dict(zeroline = False,\n                                    showline = False,\n                                    showticklabels = True,\n                                    showgrid = True,\n                                    domain = [0, 0.40],\n                                    dtick = 5,\n                                    ),\n                        xaxis2 = dict(zeroline = False,\n                                     showline = False,\n                                     showticklabels = True,\n                                     showgrid = True,\n                                     domain = [0.47, 1],\n                                     side = 'top',\n                                     dtick =8,\n                                     ),\n                        legend = dict(x = 0.02, y = 1.07, font_size = 12),\n                        margin = dict(l = 100, r = 20, t = 70, b = 70),\n                        paper_bgcolor='rgb(250, 248, 255)',\n                        plot_bgcolor='rgb(250, 248, 255)',)\n\nfig_states.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Hard Skills That it is Most Requested per The Companies"},{"metadata":{"trusted":true},"cell_type":"code","source":"# A dictionary is created with a list of hard skills to search in the job description fields\nimport re #Library for regular expresions \n\nhard_skills_dict = {\n    'Python': r\"python\",\n    'R': r\"[\\b\\s/]r[\\s,\\.]\",\n    'Excel': r\"excel\",\n    'SQL': r\"sql\",\n    'NoSQL': r\"\\bNo[\\s,-]sql[\\s]\",\n    'PowerBI': r\"power[\\s]BI\",\n    'Tableau': r\"tableau\",\n    'SPSS': r'\\bSPSS\\b',\n    'Big Data': r\"\\sbig\\sdata\\s\",\n    'SAP BI': r\"SAP[\\s]BI\",\n    'MongoDB': r\"MongoDB\",\n    'Hadoop': r\"Hadoop\",\n    'SAS': r\"\\bSAS\\b\",\n    'VBA': r\"\\bvba\\b\",\n    'AWS': r\"\\baws\\b\",\n    'Git': r\"\\bGit\",\n    'QlikView': r\"\\bQlikView\",\n    'Oracle BI': r\"oracle[\\n]BI\",\n    'Scala': r\"Scala\",\n    'Dashboard': r\"\\bDashboard[s]\",\n    'Spark': r\"Spark\",\n    'Matlab': r\"Matplotlib\",\n    'Linux': r\"linux\",\n    'Unix': r\"unix\",\n    'Looker': r\"looker\",\n    'C# or C++': r\"\\bC[#\\+\\+]\",\n    'Java': r\"java\",\n    'PowerPivot': r\"Power[\\s]Pivot\",\n    'PowerQuery': r\"Power[\\s]Query\",\n    'BigQuery': r\"Big[\\s]Query\",\n    'Apache Cassandra': r\"[\\b\\s]Cassandra[\\b\\s]\",\n    'Neo4j': r\"Neo4j\",\n    'TensorFlow': r\"TensorFlow\"\n}\n\nhard_skills_count = {}\n\n# Loop through skills for count the frecuency in Jobs Description Field.\nfor key, search in hard_skills_dict.items():\n    hard_skills_count[key] = df1['Job Description'].str.contains(search, flags = re.IGNORECASE).sum()\n\ndf_skills = pd.DataFrame.from_dict(hard_skills_count, orient = 'index') \\\n                        .sort_values(0, ascending = False) \\\n                        .reset_index() \\\n                        .rename(columns = {'index': 'Skills', 0: 'Count'})\n\ndf_skills['Relative Frecuency'] = (df_skills['Count'] / sum(df_skills['Count'])) *100\ndf_skills['Relative Frecuency'] = df_skills['Relative Frecuency'].apply(lambda x: round(x, 2))\n\n# Remove values less than '1' per cent in its Relative Frequency\ndf_skills = df_skills.drop(df_skills[df_skills['Relative Frecuency'] < 1.00].index, axis = 0)\n\ndf_skills.head(df_skills.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot visualization the tops hards skills.\nchart_skills = px.bar(df_skills, x = 'Skills', y = 'Count',\n                     color = 'Relative Frecuency',\n                     labels = {'Skills': 'Hard Skills','Count': 'Nº of Requests'})\nchart_skills.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Cluster Analysis (K-Means) and PCA"},{"metadata":{"trusted":true},"cell_type":"code","source":"# A cluster study is performed in a data frame for the data in order to find similarities\n# In addition, this is supported with PCA study\n# Import Library\nfrom sklearn.decomposition import PCA # For PCA dimensionality reduction\nfrom sklearn.cluster import KMeans    # Method for Cluster Kmeans\nfrom sklearn.preprocessing import QuantileTransformer #Realize Scaler Data\n# For visualization from 3D plot\nimport plotly.express as px","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create Data Frame with \"Mean Salary, Founded Years and Rating\" for cluster method and PCA\ndf2 = df1.copy()\ndf2 = df2.drop(df2[df2['Founded'] == -1].index, axis = 0)\ndf2 = df2.drop(df2[df2['Rating'] == -1.0].index, axis = 0)\ndf2['Years Founded'] = (2020 - df2['Founded'])\ndf2['Mean Salary'] = (df2['Max Salary'] + df2['Min Salary']) / 2\n\n# Create DataFrame\ndf3 = pd.DataFrame()\ndf3 = pd.concat([df2['Rating'], df2['Mean Salary'], df2['Years Founded']], axis = 1)\ndf3.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Rescale values with QuantileTransformer class\ndf3_scaler = QuantileTransformer().fit_transform(df3)\nprint(df3_scaler)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# PCA calculation is performed with a reduction of dimensionality equal to 2\npca = PCA(n_components = 2)\ndf_component = pca.fit_transform(df3_scaler)\nprint(df_component.shape, df3_scaler.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The clusters numbers is determined to minimize inertian infracluster through elbow method\nwcss = []\nfor i in range(1, 11):\n    kmeans = KMeans(n_clusters = i, init = 'k-means++', n_init = 10, \n                   max_iter = 300, random_state = 0)\n    kmeans.fit(df3_scaler)\n    wcss.append(kmeans.inertia_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plot curve inertian infracluster\nfig = plt.figure(figsize = (8,7))\nplt.plot(range(1,11), wcss)\nplt.scatter(4, wcss[3], c = 'red',s = 200)\nplt.text(4 + 0.4, wcss[3], s = '4 - Clusters', fontsize = 14)\nplt.xlabel('Nº Clusters', fontsize = 14)\nplt.ylabel('Inertian Infraclusters', fontsize = 14)\nplt.title('Elbow Method', fontsize = 14)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 4 clusters are selected, at that elbow point an optimized cluster can be achieved.\nkmeans = KMeans(n_clusters = 4, init = 'k-means++', n_init = 10, \n                max_iter = 300, random_state = 0)\nkmeans.fit(df3_scaler)\ny_predict = kmeans.predict(df3_scaler)\nprint(y_predict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# First one, 3D visualization are better for show clusters calculated\ncolors = ['crimson','yellow', 'indigo', 'lightseagreen']\n\nfig3d = px.scatter_3d(df3, x = 'Rating', y = 'Mean Salary', z = 'Years Founded', \n                      color = recode(pd.Series(pd.Categorical(y_predict, [0,1,2,3,4])),\n                                    {0: 'Cluster-1',\n                                     1: 'Cluster-2',\n                                     2: 'Cluster-3',\n                                     3: 'Cluster-4'}),\n                      color_discrete_sequence= colors,\n                      opacity = 0.9, \n                      size_max = 5)\n\nfig3d.update_layout(margin=dict(l=0, r=0, b=0, t=0))\n\nfig3d.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Graph PCA component with cluster predict\ndfsns = pd.DataFrame(df_component)\n# Rename Columns:\ndfsns = dfsns.rename(columns = {0: 'Component 1', 1: 'Component 2'})\n\n#Plot with Seaborn\nsns.set_style('darkgrid')\nsns.relplot(x = 'Component 1', \n            y = 'Component 2', \n            hue = recode(pd.Series(pd.Categorical(y_predict, [0,1,2,3,4])),\n                        {0: 'Cluster-1',\n                         1: 'Cluster-2',\n                         2: 'Cluster-3',\n                         3: 'Cluster-4'}), \n            data = dfsns, \n            palette= colors)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_predict = pd.DataFrame(y_predict)\ndf_predict = df_predict.rename(columns = {0 : 'Cluster'})\ndf_predict.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dataframe with cluster classification\ndf3_scaler = pd.DataFrame(df3_scaler)\ndf3_scaler = df3_scaler.rename(columns = {0: 'Rating', 1: 'Mean Salary', 2: 'Years Founded'})\ndf3_scaler['Cluster'] = df_predict['Cluster']\ndf3_scaler['Cluster'] = recode(df3_scaler['Cluster'], \n                               {0: 'Cluster-1', \n                                1: 'Cluster-2', \n                                2: 'Cluster-3',\n                                3: 'Cluster-4'}\n                              )\ndf3_scaler.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Groupby apply\ndf_cluster_group = df3_scaler.groupby('Cluster').mean()\ndf_cluster_group.head(df_cluster_group.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# RADAR PLOT:\ncolors = ['crimson','gold', 'darkcyan', 'magenta']\ny = np.array(df_cluster_group)\ncategories = list(df_cluster_group.columns)\nradar_chart = go.Figure()\n\n#Cluster 1\nradar_chart.add_trace(go.Scatterpolar(r = y[:1,:].tolist()[0],\n                                     theta = categories,\n                                     fill = 'toself',\n                                     name = 'Cluster-1',\n                                     marker = dict(color = colors[0])\n                                     ))\n\n#Cluster 2\nradar_chart.add_trace(go.Scatterpolar(r = y[1:2,:].tolist()[0],\n                                     theta = categories,\n                                     fill = 'toself',\n                                     name = 'Cluster-2',\n                                     marker = dict(color = colors[1])\n                                     ))\n\n#Cluster 3\nradar_chart.add_trace(go.Scatterpolar(r = y[2:3,:].tolist()[0],\n                                     theta = categories,\n                                     fill = 'toself',\n                                     name = 'Cluster-3',\n                                     marker = dict(color = colors[2])\n                                     ))\n\n#Cluster 4\nradar_chart.add_trace(go.Scatterpolar(r = y[3:4,:].tolist()[0],\n                                     theta = categories,\n                                     fill = 'toself',\n                                     name = 'Cluster-4',\n                                     marker = dict(color = colors[3])\n                                     ))\n\n# Update Layout\nradar_chart.update_layout(polar = dict(radialaxis = dict(visible = True,\n                                                        range = [0.0, 0.8])),\n                         showlegend = True,\n                         title = \"Graph Radar About Principal Fields\")\n\n\nradar_chart.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot clusters in graph bars to identify to better\nfig_bars = make_subplots(rows = 1, cols = 4, shared_yaxes = True)\n\n\n# Cluster 1\nfig_bars.add_trace(go.Bar(x = categories, \n                          y = y[:1,:].tolist()[0],\n                          marker = dict(color = colors,),\n                          name = 'Cluster - 1'),\n                   row = 1, \n                   col = 1)\n# Cluster 2\nfig_bars.add_trace(go.Bar(x = categories, \n                          y = y[1:2,:].tolist()[0],\n                          marker = dict(color = colors),\n                          name = 'Cluster - 2'),\n                   row = 1,\n                   col = 2)\n\n# Cluster 3\nfig_bars.add_trace(go.Bar(x = categories, \n                          y = y[2:3,:].tolist()[0],\n                          marker = dict(color = colors), \n                          name = 'Cluster - 3'),\n                   row = 1,\n                   col = 3)\n\n# Cluster 4\nfig_bars.add_trace(go.Bar(x = categories, \n                          y = y[3:4,:].tolist()[0],\n                          marker = dict(color = colors), \n                          name = 'Cluster - 4'),\n                   row = 1,\n                   col = 4)\n\nfig_bars.update_layout(showlegend = False, title = 'Cluster Behavior')\n\nfig_bars.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}