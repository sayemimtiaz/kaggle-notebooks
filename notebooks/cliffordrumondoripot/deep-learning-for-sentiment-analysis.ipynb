{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Set-up of the project\nWe'll start by importing some packages.","metadata":{"_uuid":"0f61e8a86efa85dbf7e7f77719b6547351b950c1"}},{"cell_type":"code","source":"# Basic packages\nimport pandas as pd \nimport numpy as np\nimport re\nimport collections\nimport matplotlib.pyplot as plt\n\n# Packages for data preparation\nfrom sklearn.model_selection import train_test_split\nfrom nltk.corpus import stopwords\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.preprocessing import LabelEncoder\n\n# Packages for modeling\nfrom keras import models\nfrom keras import layers\nfrom keras import regularizers","metadata":{"_cell_guid":"21cee267-f257-4ba3-88e1-d22e2fc57c7e","_uuid":"2fec7805d8d0e999fc405d136beff46ac331b963","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Then we set some parameters that will be used throughout the notebook.","metadata":{"_uuid":"5c8c473a857b9fd044c11bb332c351df0a2dd9fe"}},{"cell_type":"code","source":"NB_WORDS = 10000  # Parameter indicating the number of words we'll put in the dictionary\nVAL_SIZE = 1000  # Size of the validation set\nNB_START_EPOCHS = 20  # Number of epochs we usually start to train with\nBATCH_SIZE = 512  # Size of the batches used in the mini-batch gradient descent","metadata":{"_uuid":"992184fc16ab7ce9917146d08581772c2349337d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We read in the csv with the tweets data and perform a random shuffle. It's a good practice to shuffle the data before splitting between a train and test set. That way the sentiment classes are equally distributed over the train and test sets.\n\nWe'll only keep the *text* column as input and the *airline_sentiment* column as the target. ","metadata":{"_uuid":"66b54d1ea619e1067f1d39824b103bd060369885"}},{"cell_type":"code","source":"df = pd.read_csv('../input/Tweets.csv')\ndf = df.reindex(np.random.permutation(df.index))  \ndf = df[['text', 'airline_sentiment']]\ndf.head()","metadata":{"_uuid":"ca3edd68b979a54e032b5eaa62d0ea1dc5caff66","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data preparation","metadata":{"_uuid":"d04f62e6a9c95c9d8e05b33b1033798d41bd0ab3"}},{"cell_type":"markdown","source":"### Data cleaning\nThe first thing we'll do is removing stopwords. These words do not have any value for predicting the sentiment. Furthermore, as we want to build a model that can be used for other airline companies as well, we remove the mentions.","metadata":{"_uuid":"2b753fcb54745450486fa917de3983ae27a62908"}},{"cell_type":"code","source":"def remove_stopwords(input_text):\n        stopwords_list = stopwords.words('english')\n        # Some words which might indicate a certain sentiment are kept via a whitelist\n        whitelist = [\"n't\", \"not\", \"no\"]\n        words = input_text.split() \n        clean_words = [word for word in words if (word not in stopwords_list or word in whitelist) and len(word) > 1] \n        return \" \".join(clean_words) \n    \ndef remove_mentions(input_text):\n        return re.sub(r'@\\w+', '', input_text)\n       \ndf.text = df.text.apply(remove_stopwords).apply(remove_mentions)\ndf.head()","metadata":{"_uuid":"c1210dcf7d75e9cfd96d0ca489c7b9136aad21db","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train-Test split\nThe evaluation of the model performance needs to be done on a separate test set. As such, we can estimate how well the model generalizes. This is done with the *train_test_split* method of scikit-learn.","metadata":{"_uuid":"d2ea26c0cc56f3d456f6e06df7d66e91d6476e16"}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(df.text, df.airline_sentiment, test_size=0.1, random_state=37)\nprint('# Train data samples:', X_train.shape[0])\nprint('# Test data samples:', X_test.shape[0])\nassert X_train.shape[0] == y_train.shape[0]\nassert X_test.shape[0] == y_test.shape[0]","metadata":{"_cell_guid":"df742ade-52d3-4b47-80b0-1f7cc26545eb","_uuid":"6ab9296159749e4525244fae6d6f4e6a37121c93","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Converting words to numbers\nTo use the text as input for a model, we first need to convert the tweet's words into tokens, which simply means converting the words to integers that refer to an index in a dictionary. Here we will only keep the most frequent words in the train set.\n\nWe clean up the text by applying *filters* and putting the words to *lowercase*. Words are separated by spaces.","metadata":{"_uuid":"07e3df8462df02ae8336a1b9123f928b8cce814d"}},{"cell_type":"code","source":"tk = Tokenizer(num_words=NB_WORDS,\n               filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n               lower=True,\n               split=\" \")\ntk.fit_on_texts(X_train)\n\nprint('Fitted tokenizer on {} documents'.format(tk.document_count))\nprint('{} words in dictionary'.format(tk.num_words))\nprint('Top 5 most common words are:', collections.Counter(tk.word_counts).most_common(5))","metadata":{"_uuid":"6cbf76b09ac27e67f7e92eb0986a963db00ddcd6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"After having created the dictionary we can convert the text to a list of integer indexes. This is done with the *text_to_sequences* method of the Tokenizer.","metadata":{"_uuid":"a1bf813b1277821e18b257f207dfc8642ce5ad95"}},{"cell_type":"code","source":"X_train_seq = tk.texts_to_sequences(X_train)\nX_test_seq = tk.texts_to_sequences(X_test)\n\nprint('\"{}\" is converted into {}'.format(X_train[0], X_train_seq[0]))","metadata":{"_uuid":"28435e6639f4dac6d9bdc9df65b1dd4651b15617","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"These integers should now be converted into a one-hot encoded features.","metadata":{"_uuid":"0a6dbe6901ac0d7ce46797bd8d0d5c9722436c0b"}},{"cell_type":"code","source":"def one_hot_seq(seqs, nb_features = NB_WORDS):\n    ohs = np.zeros((len(seqs), nb_features))\n    for i, s in enumerate(seqs):\n        ohs[i, s] = 1.\n    return ohs\n\nX_train_oh = one_hot_seq(X_train_seq)\nX_test_oh = one_hot_seq(X_test_seq)\n\nprint('\"{}\" is converted into {}'.format(X_train_seq[0], X_train_oh[0]))\nprint('For this example we have {} features with a value of 1.'.format(X_train_oh[0].sum()))","metadata":{"_uuid":"cd91541a0f3c027dca3429af497379fd86a7079b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Converting the target classes to numbers\nWe need to convert the target classes to numbers as well, which in turn are one-hot-encoded with the *to_categorical* method in keras","metadata":{"_uuid":"0c35698c39d06b89151918b77c70791aac3fa63f"}},{"cell_type":"code","source":"le = LabelEncoder()\ny_train_le = le.fit_transform(y_train)\ny_test_le = le.transform(y_test)\ny_train_oh = to_categorical(y_train_le)\ny_test_oh = to_categorical(y_test_le)\n\nprint('\"{}\" is converted into {}'.format(y_train[0], y_train_le[0]))\nprint('\"{}\" is converted into {}'.format(y_train_le[0], y_train_oh[0]))","metadata":{"_uuid":"f64570f56244464eaf88805a8c41b46f76db4668","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Splitting of a validation set\nNow that our data is ready, we split of a validation set. This validation set will be used to evaluate the model performance when we tune the parameters of the model. ","metadata":{"_uuid":"73b4fe31f03a45fff85e75b72141029416050d08"}},{"cell_type":"code","source":"X_train_rest, X_valid, y_train_rest, y_valid = train_test_split(X_train_oh, y_train_oh, test_size=0.1, random_state=37)\n\nassert X_valid.shape[0] == y_valid.shape[0]\nassert X_train_rest.shape[0] == y_train_rest.shape[0]\n\nprint('Shape of validation set:',X_valid.shape)","metadata":{"_uuid":"e4b7683309d5501c80d9e4e7335a76e58e8999f0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Deep learning","metadata":{"_uuid":"8a52314ce6c1d0de5c3765ff5781b64c32c8871c"}},{"cell_type":"markdown","source":"### Baseline model\nWe start with a model with 2 densely connected layers of 64 hidden elements. The *input_shape* for the first layer is equal to the number of words we allowed in the dictionary and for which we created one-hot-encoded features.\n\nAs we need to predict 3 different sentiment classes, the last layer has 3 hidden elements. The *softmax* activation function makes sure the three probabilities sum up to 1.\n\nIn the first layer we need to estimate 640064 weights. This is determined by (nb inputs * nb hidden elements) + nb bias terms, or (10000 x 64) + 64 = 640064<br>\nIn the second layer we estimate (64 x 64) + 64 = 4160 weights<br>\nIn the last layer we estimate (64 x 3) + 3 = 195 weights<br>","metadata":{"_uuid":"3e7e167507953da952e50257aae77f36ec28e6cc"}},{"cell_type":"code","source":"base_model = models.Sequential()\nbase_model.add(layers.Dense(64, activation='relu', input_shape=(NB_WORDS,)))\nbase_model.add(layers.Dense(64, activation='relu'))\nbase_model.add(layers.Dense(3, activation='softmax'))\nbase_model.summary()","metadata":{"_uuid":"343bddd22935a60332161c6ae70ba20d2e8087ed","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Because this project is a multi-class, single-label prediction, we use *categorical_crossentropy* as the loss function and *softmax* as the final activation function. We fit the model on the remaining train data and validate on the validation set. We run for a predetermined number of epochs and will see when the model starts to overfit.","metadata":{"_uuid":"2ec3b5ac6911389154d370037d853c257cc7c5fc"}},{"cell_type":"code","source":"def deep_model(model):\n    model.compile(optimizer='rmsprop'\n                  , loss='categorical_crossentropy'\n                  , metrics=['accuracy'])\n    \n    history = model.fit(X_train_rest\n                       , y_train_rest\n                       , epochs=NB_START_EPOCHS\n                       , batch_size=BATCH_SIZE\n                       , validation_data=(X_valid, y_valid)\n                       , verbose=0)\n    \n    return history","metadata":{"_uuid":"1be72007bccc687064f789f9564354329d32e102","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_history = deep_model(base_model)","metadata":{"_uuid":"c3ab89d1291d07550f403f8144af5b739821b6b6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To evaluate the model performance, we will look at the training and validation loss and accuracy.","metadata":{"_uuid":"df985523b02871ef30b4fa17a629b54fd090cb4d"}},{"cell_type":"code","source":"def eval_metric(history, metric_name):\n    metric = history.history[metric_name]\n    val_metric = history.history['val_' + metric_name]\n\n    e = range(1, NB_START_EPOCHS + 1)\n\n    plt.plot(e, metric, 'bo', label='Train ' + metric_name)\n    plt.plot(e, val_metric, 'b', label='Validation ' + metric_name)\n    plt.legend()\n    plt.show()","metadata":{"_uuid":"fe4399bd073104da7e8e1bf8b99f5ef8e57e93fa","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see here that the validation loss starts to increase as from epoch 4. The training loss continues to lower, which is normal as the model is trained to fit the train data as good as possible.","metadata":{"_uuid":"3de1b2cf553848d8472ebca9d8156ec98eb231b2"}},{"cell_type":"code","source":"eval_metric(base_history, 'loss')","metadata":{"_uuid":"a8d0194eb405add560e62a66078e6145f12c2f36","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Just as with the validation loss, the validation accuracy peaks at an early epoch. After that, it goes down slightly. So to conclude, we can say that the model starts overfitting as from epoch 4. ","metadata":{"_uuid":"b60582a3e6056ed34e980af793720fa9b5fb4906"}},{"cell_type":"code","source":"eval_metric(base_history, 'acc')","metadata":{"_uuid":"150d375ca2a2642eec9199d5512fec19da13376d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Reducing the network's size\nWe reduce the network's size by removing one layer and lowering the number of hidden elements in the remaining layer to 32.","metadata":{"_uuid":"6768d95a28ff456f33546660512f3ffb398a94d9"}},{"cell_type":"code","source":"reduced_model = models.Sequential()\nreduced_model.add(layers.Dense(32, activation='relu', input_shape=(NB_WORDS,)))\nreduced_model.add(layers.Dense(3, activation='softmax'))\nreduced_model.summary()","metadata":{"_uuid":"268a0b46d93dae85e0b536a69a3efdf6eaea402b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reduced_history = deep_model(reduced_model)","metadata":{"_uuid":"88dd2db6557cb7868db3a0f2caef8b45329c5fbb","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compare_loss_with_baseline(h, model_name):\n    loss_base_model = base_history.history['val_loss']\n    loss_model = h.history['val_loss']\n\n    e = range(1, NB_START_EPOCHS + 1)\n\n    plt.plot(e, loss_base_model, 'bo', label='Validation Loss Baseline Model')\n    plt.plot(e, loss_model, 'b', label='Validation Loss ' + model_name)\n    plt.legend()\n    plt.show()","metadata":{"_uuid":"f7f430579f147e22312a6708d910ecdf67fbaf15","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that it takes more epochs before the reduced model starts overfitting (around epoch 10). Moreover, the loss increases much slower after that epoch compared to the baseline model.","metadata":{"_uuid":"e4995437cae53991f1f54f9e9e0513147e28775f"}},{"cell_type":"code","source":"compare_loss_with_baseline(reduced_history, 'Reduced Model')","metadata":{"_uuid":"b68ea6fa1c73f2183528024631b0818393ddd8b8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reg_model = models.Sequential()\nreg_model.add(layers.Dense(64, kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(NB_WORDS,)))\nreg_model.add(layers.Dense(64, kernel_regularizer=regularizers.l2(0.001), activation='relu'))\nreg_model.add(layers.Dense(3, activation='softmax'))\nreg_model.summary()","metadata":{"_uuid":"17e384daee482847293925c5c98697eb93b10c81","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reg_history = deep_model(reg_model)","metadata":{"_uuid":"b6eb4019580ea228350d1f143fbc9e3d34725c1b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"compare_loss_with_baseline(reg_history, 'Regularized Model')","metadata":{"_uuid":"dba7e497c502649455e55209824b88ad6704a168","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Adding dropout layers\nThe last option we'll try is to add dropout layers.","metadata":{"_uuid":"34c7ba86080b858475e08ae9652d9e7e1cb85dd4"}},{"cell_type":"code","source":"drop_model = models.Sequential()\ndrop_model.add(layers.Dense(64, activation='relu', input_shape=(NB_WORDS,)))\ndrop_model.add(layers.Dropout(0.5))\ndrop_model.add(layers.Dense(64, activation='relu'))\ndrop_model.add(layers.Dropout(0.5))\ndrop_model.add(layers.Dense(3, activation='softmax'))\ndrop_model.summary()","metadata":{"_uuid":"148084e8fdbae9eb8aacb16f63fb5ad1afa715c7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"drop_history = deep_model(drop_model)","metadata":{"_uuid":"68129f5c4e1408012bd5271c2e185a0f9b680fef","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"compare_loss_with_baseline(drop_history, 'Dropout Model')","metadata":{"_uuid":"2f84d9a3b71665e31817b87c3f7e0a7dcda8f168","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training on the full train data and evaluation on test data\nAt first sight the reduced model seems to be the best model for generalization. But let's check that on the test set.","metadata":{"_uuid":"54e689e46bcb6f6c1697ce551c318cf1bc2f1826"}},{"cell_type":"code","source":"def test_model(model, epoch_stop):\n    model.fit(X_train_oh\n              , y_train_oh\n              , epochs=epoch_stop\n              , batch_size=BATCH_SIZE\n              , verbose=0)\n    results = model.evaluate(X_test_oh, y_test_oh)\n    \n    return results","metadata":{"_uuid":"8e820d0d52358f5a9a514c754bccd56cc0496cfe","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_results = test_model(base_model, 4)\nprint('/n')\nprint('Test accuracy of baseline model: {0:.2f}%'.format(base_results[1]*100))","metadata":{"_uuid":"55fee33d47ca1f488a5c4ca262d95e3edb873fda","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reduced_results = test_model(reduced_model, 10)\nprint('/n')\nprint('Test accuracy of reduced model: {0:.2f}%'.format(reduced_results[1]*100))","metadata":{"_uuid":"fe5556d324cbef0b2f661772895ffca215313dcc","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reg_results = test_model(reg_model, 5)\nprint('/n')\nprint('Test accuracy of regularized model: {0:.2f}%'.format(reg_results[1]*100))","metadata":{"_uuid":"ed5cddbc024532a609193637fdc7335c9ecd3ea2","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"drop_results = test_model(drop_model, 6)\nprint('/n')\nprint('Test accuracy of dropout model: {0:.2f}%'.format(drop_results[1]*100))","metadata":{"_uuid":"b6beaf7c1988d3bfcb24a03b70d2b5127a6ae38f","trusted":true},"execution_count":null,"outputs":[]}]}