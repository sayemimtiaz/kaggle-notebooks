{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np\nfrom keras import Sequential\nfrom keras import layers\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nimport sqlite3\nimport re\nimport string\nfrom scipy import signal\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.cluster import KMeans","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"821e8e172a7279304f8df6261b69108b9dd142c9"},"cell_type":"code","source":"cn = sqlite3.connect('../input/database.sqlite')\nquery = \"SELECT * FROM Tweets\"\ndf = pd.read_sql_query(query, cn)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"54cd11d38649ce1ae0cd65cd6013f680a26b140d"},"cell_type":"markdown","source":"# **EDA**"},{"metadata":{"trusted":true,"_uuid":"15e30c2889025609e3fa6114b0f6234104d4a1f4"},"cell_type":"code","source":"output_for_ml_task = df[['airline_sentiment','text']]\n# Remane header\nheader = ['tweet_id', 'sentiment', 'sentiment_confidence','negative_reason', 'negative_reason_confidence', 'airline_name','sentiment_gold', 'user_name', 'negative_reason_gold','retweet_count', 'text', 'tweet_coordinate', 'date','tweet_location', 'user_timezone']\ndf.columns = header\n# Map every string to a weighted number\nmapping = {'negative': -1,\n           'neutral': 0,\n           'positive': 1,\n           '' : np.nan}\n\n# Apply mapping\ndf.replace({'sentiment': mapping}, inplace=True)\n\ndf.replace({'sentiment_gold': mapping}, inplace=True)\n\n# Drop data ids and confidence\ndf.drop(['tweet_id','sentiment_confidence', 'negative_reason_confidence'], axis=1, inplace=True)\n\n# Convert to datetime\ndf['date'] = pd.to_datetime(df['date'])\n# Set the index\ndf.set_index('date', inplace=True)\n\ndf['negative_reason'].replace('', 'None',  inplace=True)\ndf['negative_reason_gold'].replace('', 'None',  inplace=True)\ndf['tweet_location'].replace('', 'None',  inplace=True)\ndf['tweet_coordinate'].replace('', np.nan,  inplace=True)\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"08d9f44dd0ff6637d88a3cc0e42d08e01553e624"},"cell_type":"code","source":"df.sentiment.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f9e255df74f9b8caeb5fcdd7d820c84f80831537"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"02b0c3f47a9d68c39f27fb99397ffd091ecc57c7"},"cell_type":"code","source":"df.negative_reason.value_counts()[1::]\npd.Series(df[\"negative_reason\"]).value_counts()[1::].plot(kind = \"bar\",\n                                                           figsize=(24,12),\n                                                           title = \"Negative Reasons\", \n                                                           fontsize=20)\nplt.xlabel('Negative Reasons', fontsize=20)\nplt.ylabel('# of negative reasons', fontsize=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fa44798ca72886d8524d09b17ccfe740aed357c0"},"cell_type":"code","source":"def plot_sub_negative_reason_for_airline(Airline):\n    airline = df[df['airline_name']==Airline]\n    count = airline['negative_reason'].value_counts()\n    Index = [i+1 for i in range(len(count)-1)]\n    label = list(count.keys())\n    x = label.index('None')\n    label.pop(x)\n    count = list(count)\n    count.pop(x)\n    plt.bar(Index,count,width=0.5)\n    plt.xticks(Index, label, rotation='vertical')\n    plt.title('Negative reasons for %s'%Airline)\nairline_name = df['airline_name'].unique()\nplt.figure(1,figsize=(16,20))\n\nplt.subplots_adjust(hspace=0.4)\n\nfor i in range(len(airline_name)):\n    plt.subplot(len(airline_name)/3,3,i+1)\n    plot_sub_negative_reason_for_airline(airline_name[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f1f4e4854915aaff543c6bdb22e6603681659f28"},"cell_type":"code","source":"print(\"Day   # of retweet \\n%s\"%df.retweet_count.value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d490a7f49a81d6f5b921b5b4893aa0b3d5bfd092"},"cell_type":"code","source":"def plot_sub_retweet_per_day_for_airline(Airline):\n    airline = df[df['airline_name']==Airline]\n    count = airline['retweet_count'].index.day.value_counts()\n    Index = airline.index.day.drop_duplicates()\n    plt.plot(Index,count)\n    plt.xticks(Index, list(Index))\n    plt.title('Retweet per day for %s'%Airline)\nairline_name = df['airline_name'].unique()\nplt.figure(1,figsize=(18,18))\nfor i in range(len(airline_name)):\n    plt.subplot(len(airline_name)/3,3,i+1)\n    plot_sub_retweet_per_day_for_airline(airline_name[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"14653c5a65f51abcc2daee962625ebf526e905bf"},"cell_type":"code","source":"def plot_sub_sentiment_for_airline(Airline):\n    airline = df[df['airline_name']==Airline]\n    count = airline['sentiment'].value_counts()\n    Index = [i for i in range(len(count))]\n    plt.bar(Index,count,width=0.5)\n    plt.xticks(Index, list(mapping.keys()))\n    plt.title('Sentiment for %s'%Airline)\nairline_name = df['airline_name'].unique()\nplt.figure(1,figsize=(18,18))\nfor i in range(len(airline_name)):\n    plt.subplot(len(airline_name)/3,3,i+1)\n    plot_sub_sentiment_for_airline(airline_name[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"67f9f7d4cdde32aeaed6cd559463d2e3b23ec23e"},"cell_type":"code","source":"x = [x for x in df['tweet_coordinate'].tolist() if x]\nx = [incom for incom in x if str(incom) != 'nan']\ncoor = []\nfor i in x:\n    la, lo = i.replace('[','').replace(']','').split(',')\n    la, lo = float(la), float(lo)\n    if la == 0 and lo == 0:\n        continue\n    coor.append([float(la), float(lo)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"97ad312ef3405c68789f941b2042cd611cd984b5"},"cell_type":"code","source":"latitude, longitude = list(map(list, zip(*coor)))\n\n\nfrom mpl_toolkits.basemap import Basemap\nimport matplotlib.pyplot as plt\n\n# How much to zoom from coordinates (in degrees)\nzoom_scale = 1\n\nbbox = [np.min(latitude)-zoom_scale,np.max(latitude)+zoom_scale, \n        np.min(longitude)-zoom_scale,np.max(longitude)+zoom_scale]\n\nplt.figure(figsize=(24,12))\n# Define the projection, scale, the corners of the map, and the resolution.\nm = Basemap(projection='merc',llcrnrlat=bbox[0],urcrnrlat=bbox[1],\\\n            llcrnrlon=bbox[2],urcrnrlon=bbox[3],lat_ts=10,resolution='i')\n\n# Draw coastlines and fill continents\nm.drawcoastlines()\nm.fillcontinents(color='white')\n\n# build and plot coordinates onto map\nx,y = m(longitude,latitude)\nm.plot(x,y,'r*',markersize=10)\nplt.title(\"Tweet Location\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"789515b0deba738f43fee8a40523a333b3de0936"},"cell_type":"markdown","source":"# Data Preparation"},{"metadata":{"trusted":true,"_uuid":"cdca11e859cd3cc559a5fe5cd5f4b9cfdec08636"},"cell_type":"code","source":"distance = []\ncentral_mass_latitude, central_mass_longitude = sum(latitude)/len(latitude), sum(longitude)/len(longitude)\nnumber_of_positions = len(latitude)\n_=[distance.append(np.sqrt((central_mass_latitude - latitude[i])**2 + (central_mass_longitude - longitude[0])**2)) for i in range(number_of_positions)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cc9e173ad7045ea637d7d9ba7831050f00365ab8"},"cell_type":"code","source":"def central_limit_theorem(rv):\n    return (rv - np.average(rv))/(np.std(rv)/len(rv)**.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d4dcefd1f497832c7b70ed17ed7b8e9dfaa560bc"},"cell_type":"code","source":"def handle_gaussian(l):\n    # Make list to be as gaussian dist.\n    l = l.tolist()\n    l.sort()\n    n = len(l)\n    i = int(n/2)\n    halve1 = l[0:i]\n    halve2 = l[i+1:n-1]\n    halve2.reverse()\n    return halve1 + halve2","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"32beb4b2fe511779a7cfbcbf39afeb22093ac860"},"cell_type":"markdown","source":"# Testing\nTests whether distances has a Gaussian distribution.\nAssumptions\n\ndistances are independent and identically distributed (iid).\n\nInterpretation\n\nH0: the sample has a Gaussian distribution.\n\nH1: the sample does not have a Gaussian distribution"},{"metadata":{"trusted":true,"_uuid":"7dd75eaf4ba6d39c4d0760af97f0d81bce5bb58d"},"cell_type":"code","source":"data = np.array(distance,dtype='float64')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2c5c53c1c86ba1c2cc61f0d6ac42d83475420476"},"cell_type":"code","source":"from scipy.stats import shapiro\nstat, p = shapiro(data)\nprint(p)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b306086aec25bcbf2bbfe670b771804560852a96"},"cell_type":"code","source":"gaussian = signal.gaussian(len(data), std=np.std(central_limit_theorem(data)))\n\nfig = plt.figure()\nax = fig.add_subplot(1, 1, 1)\n\nax.plot(central_limit_theorem(handle_gaussian(data)), label='Data Curve', linestyle='--')\nax.plot(gaussian,label=\"Gaussian's Curve\", linewidth=4)\nax.legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b6cf68e94cc3ec8e5c971f536255c7f74e9d2257"},"cell_type":"markdown","source":"# Tests whether a negative reasons choice has a Gaussian distribution"},{"metadata":{"_uuid":"29a2e027e9f2ff100879918d8edcbb1c05409e1b"},"cell_type":"markdown","source":"### Assumptions\n\nnegative reasons choice are independent and identically distributed (iid).\n\n### Interpretation\n\nH0: the sample has a Gaussian distribution.\n    \nH1: the sample does not have a Gaussian distribution."},{"metadata":{"trusted":true,"_uuid":"1c46585dc7de9feba352ea498cb2bed37d281bfc"},"cell_type":"code","source":"data = np.array(df.negative_reason.value_counts().tolist(),dtype='float64')\nfrom scipy.stats import shapiro\nstat, p = shapiro(data)\nprint(p)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bea45b04a0309c4966bfd66d01940d8d4aee60e1"},"cell_type":"markdown","source":"### We can accept H0 at alpha equals 0.0005 and negative reasons choice has normal dist."},{"metadata":{"trusted":true,"_uuid":"a0308ed7ea887f4bb00a1cf8ddde0b32137ebe32"},"cell_type":"code","source":"gaussian = signal.gaussian(len(data), std=np.std(central_limit_theorem(data)))\n\nfig = plt.figure()\nax = fig.add_subplot(1, 1, 1)\n\nax.plot(central_limit_theorem(handle_gaussian(data)), label='Data Curve', linestyle='--')\nax.plot(gaussian,label=\"Gaussian's Curve\", linewidth=4)\nax.legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b44180a887279c839c12d6995d472612a4aad3cf"},"cell_type":"markdown","source":"Tests whether a retweets has a Gaussian distribution.\n\nAssumptions\n\nretweets are independent and identically distributed (iid).\n\nInterpretation\n\nH0: the sample has a Gaussian distribution.\nH1: the sample does not have a Gaussian distribution"},{"metadata":{"trusted":true,"_uuid":"a252560853bc18edba7ff206d68264cf8dfe0e87"},"cell_type":"code","source":"data = np.array(df['retweet_count'].value_counts().tolist(),dtype='float64')\nfrom scipy.stats import shapiro\nstat, p = shapiro(data)\nprint(p)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"635859dbcb0c2f3ca75c0b0972c7e42f09874e3e"},"cell_type":"markdown","source":"### We reject H0 and has no Gaussian's dist"},{"metadata":{"trusted":true,"_uuid":"a87c5c403f2df797a3a878d7528546db6e3e0a24"},"cell_type":"code","source":"gaussian = signal.gaussian(len(data), std=np.std(central_limit_theorem(data)))\n\nfig = plt.figure()\nax = fig.add_subplot(1, 1, 1)\n\nax.plot(central_limit_theorem(handle_gaussian(data)), label='Data Curve', linestyle='--')\nax.plot(gaussian,label=\"Gaussian's Curve\", linewidth=4)\nax.legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c16bc524f0c02f5cb866dc681e7a5cf2d7763b01"},"cell_type":"markdown","source":"Tests whether number of retweet and sentiment have a monotonic relationship.\n\n### Spearmanâ€™s Rank Correlation\n\nAssumptions\n\nObservations in each sample are independent and identically distributed (iid).\nObservations in each sample can be ranked.\n\nInterpretation\n\nH0: the two samples are independent.\n\nH1: there is a dependency between the samples."},{"metadata":{"trusted":true,"_uuid":"63e692cb79377167c0c7d1326ccf45d584c644b9"},"cell_type":"code","source":"from scipy.stats import spearmanr\ndata1, data2 = np.array(df.retweet_count.tolist()), np.array(df.sentiment.tolist())\ncorr, p = spearmanr(data1, data2)\nprint(p)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"01b90ec36af9b9b854b2583a9a715c40cc18274f"},"cell_type":"code","source":"gaussian = signal.gaussian(len(data), std=np.std(central_limit_theorem(data)))\n\nfig = plt.figure()\nax = fig.add_subplot(1, 1, 1)\n\nax.plot(handle_gaussian(data1), label='Retweet Count Curve', linestyle='--')\nax.plot(handle_gaussian(data2),label=\"Sentiment Curve\", linestyle=':')\nax.legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f4519e0aa7b10aa24c219ef7187b3fd42ac017ac"},"cell_type":"markdown","source":"# Sentiment prediction Modeling"},{"metadata":{"trusted":true,"_uuid":"8d8643e93857770131d1627d501984d0448df496"},"cell_type":"code","source":"percentage = 80/100\nlength_of_data = len(df.text.tolist())\nThreshold = int(length_of_data*percentage)\ninput_data = df.text.tolist()\nX_train, X_test  = np.array(input_data[0:Threshold]), np.array(input_data[Threshold + 1:length_of_data])\nY_train, Y_test = np.array(output_for_ml_task[0:Threshold]['airline_sentiment'].tolist()), np.array(output_for_ml_task[Threshold + 1:length_of_data]['airline_sentiment'].tolist())\nprint(\"\\t\\t\\tFeature Shapes:\")\nprint(\"Train set: \\t\\t{}\".format(X_train.shape), \n      \"\\nTest set: \\t\\t{}\".format(X_test.shape))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"01f10a2f79157549c580bea36900ff158f44f403"},"cell_type":"markdown","source":"### K-means Clustering using tf-idf"},{"metadata":{"trusted":true,"_uuid":"26e848b19d507ec8c52f5a70447edcaed3871f11"},"cell_type":"code","source":"# Preprocessing and tokenizing\ndef preprocessing(line):\n    line = line.lower()\n    line = re.sub(r\"[{}]\".format(string.punctuation), \" \", line)\n    return line\ntfidf_vectorizer = TfidfVectorizer(preprocessor=preprocessing)\ntfidf = tfidf_vectorizer.fit_transform(X_train)\nkmeans = KMeans(n_clusters=3).fit(tfidf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6be86af53981541b572db6d577e66a3270a9e08d"},"cell_type":"code","source":"transformation = ['negative','positive','neutral']\nnum_transformation = [-1,1,0]\n# Test the model\ntransformation[kmeans.predict(tfidf_vectorizer.transform(['bad travel'])).tolist()[0]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1f889a0a37de008f51bd44afbc0b7383bc925bfa"},"cell_type":"code","source":"prediction = kmeans.predict(tfidf_vectorizer.transform(X_train))\nY_model = [transformation[i] for i in prediction]\naccuracy = sum(np.array(Y_train) == np.array(Y_model)) / len(np.array(Y_train))\nprint(\"Training Accuracy: {:.4f}\".format(accuracy))\n\nprediction = kmeans.predict(tfidf_vectorizer.transform(X_test))\nY_model = [transformation[i] for i in prediction]\naccuracy = sum(np.array(Y_test) == np.array(Y_model)) / len(np.array(Y_test))\nprint(\"Testing Accuracy: {:.4f}\".format(accuracy))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ddf990ace0e7859e34ad1c04edceffb2c5a2169a"},"cell_type":"markdown","source":"### Deep Learning Model with Embedding Layer"},{"metadata":{"trusted":true,"_uuid":"fc3cdd02670abaade4d96e6754b233db9b8d1688"},"cell_type":"code","source":"plt.style.use('ggplot')\n\ndef plot_history(history):\n    acc = history.history['acc']\n    val_acc = history.history['val_acc']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    x = range(1, len(acc) + 1)\n\n    plt.figure(figsize=(12, 5))\n    plt.subplot(1, 2, 1)\n    plt.plot(x, acc, 'b', label='Training acc')\n    plt.plot(x, val_acc, 'r', label='Validation acc')\n    plt.title('Training and validation accuracy')\n    plt.legend()\n    plt.subplot(1, 2, 2)\n    plt.plot(x, loss, 'b', label='Training loss')\n    plt.plot(x, val_loss, 'r', label='Validation loss')\n    plt.title('Training and validation loss')\n    plt.legend()\n# Encode Y to be numerical value\ny_train_ = [mapping[i] for i in Y_train]\ny_test_ = [mapping[i] for i in Y_test]\nprint('Loaded dataset with {} training samples, {} test samples'.format(len(X_train), len(X_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f46df59fab82e131f55e494f0875dd3154f7a936"},"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\n\ntokenizer = Tokenizer(num_words=5000)\ntokenizer.fit_on_texts(X_train)\n\nX_train_ = tokenizer.texts_to_sequences(X_train)\nX_test_ = tokenizer.texts_to_sequences(X_test)\n\nvocab_size = len(tokenizer.word_index) + 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e6fd384d98773547e13e2ca120d02b75df18ee2c"},"cell_type":"code","source":"from keras.preprocessing.sequence import pad_sequences\n\nembedding_dim = 75\nmaxlen = 100\nX_train_ = pad_sequences(X_train_, padding='post', maxlen=maxlen)\nX_test_ = pad_sequences(X_test_, padding='post', maxlen=maxlen)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d7c7b33b35ad46760781698fdd55fca2e862eaac"},"cell_type":"code","source":"from keras.layers import Activation\nfrom keras.utils.generic_utils import get_custom_objects\n\n# My activation function\ndef custom_activation(x):\n    return x/(1 + abs(x))\n\nget_custom_objects().update({'custom_activation': Activation(custom_activation)})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5b5eba7fffa17d02f586441a9d96afdaa5ff14af"},"cell_type":"code","source":"model = Sequential()\nmodel.add(layers.Embedding(vocab_size, embedding_dim, input_length=maxlen, trainable=False))\nmodel.add(layers.GlobalMaxPool1D())\nmodel.add(layers.Dense(10, activation=Activation(custom_activation)))\nmodel.add(layers.Dense(1, activation='tanh'))\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"30d882b32cd73c90cb3d1b483efc88ae41dd5af0"},"cell_type":"code","source":"history = model.fit(X_train_, y_train_,\n                    epochs=50,\n                    validation_data=(X_test_, y_test_),\n                    batch_size=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3aff10450c8aaf0cec6cc43b70a5f4fd547e7ebe"},"cell_type":"code","source":"loss, accuracy = model.evaluate(X_train_, y_train_, verbose=False)\nprint(\"Training Accuracy: {:.4f}\".format(accuracy))\n\nloss, accuracy = model.evaluate(X_test_, y_test_, verbose=False)\nprint(\"Testing Accuracy:  {:.4f}\".format(accuracy))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6a68ca38be4fbbd41ff34ac8ed49304d08f5c57c"},"cell_type":"code","source":"plot_history(history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8c46bc8999a7cc418bada88c9dcbd7a06aeba1c2"},"cell_type":"code","source":"model.predict(pad_sequences(tokenizer.texts_to_sequences(['bad travel']), padding='post', maxlen=maxlen))[0][0]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"59e37fa63d905f1776e873d28dcbc5b9893b6e7f"},"cell_type":"markdown","source":"# Error Analysis"},{"metadata":{"trusted":true,"_uuid":"d1ca7a9e83dc69ceb19a376cdcc07a54726aea1b"},"cell_type":"code","source":"error_analysis = []\ny_kMean = []\ny_deep = []\nfor i,w in enumerate(X_test):\n    \n    desired = y_test_[i]\n    kMean = num_transformation[kmeans.predict(tfidf_vectorizer.transform([w])).tolist()[0]]\n    deep = model.predict(pad_sequences(tokenizer.texts_to_sequences([w]), padding='post', maxlen=maxlen))[0][0]\n    \n    y_kMean.append(kMean)\n    y_deep.append(deep)\n    error_analysis.append([w,desired,kMean,deep])\nerror_analysis_frame = pd.DataFrame(error_analysis, columns=['Text','Desired', 'K_Mean', 'Deep_model'])\nerror_analysis_frame.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"951bf5ee4f0a6162370cbd56f3c46096fa929280"},"cell_type":"code","source":"def make_roc(y, score):\n    roc_x = []\n    roc_y = []\n    min_score = min(score)\n    max_score = max(score)\n    thr = np.linspace(min_score, max_score, 30)\n    FP=0\n    TP=0\n    N = sum(y)\n    P = len(y) - N\n\n    for (i, T) in enumerate(thr):\n        for i in range(0, len(score)):\n            if (score[i] > T):\n                if (y[i]==1):\n                    TP = TP + 1\n                if (y[i]==0):\n                    FP = FP + 1\n        roc_x.append(FP/float(N))\n        roc_y.append(TP/float(P))\n        FP=0\n        TP=0\n\n    return roc_x, roc_y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0f370a56b58764c8e8473762cfa2bf3e00fe71c9"},"cell_type":"code","source":"roc_x, roc_y = make_roc(error_analysis_frame.Desired, error_analysis_frame.K_Mean)\nplt.plot(roc_x,roc_y, label='ROC for K-Mean')\nplt.title('Receiver Operating Characteristic')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a9e3d09aaaf087c9c502fd8942a44304af90ab32"},"cell_type":"code","source":"roc_x, roc_y = make_roc(error_analysis_frame.Desired, error_analysis_frame.Deep_model)\nplt.plot(roc_x,roc_y, label='ROC for deep model')\nplt.title('Receiver Operating Characteristic')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b2614c822fd3340d53e596efe023e1b85ea96514"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"74cddd3827fe45268d4043faf689ba3447b997bb"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}