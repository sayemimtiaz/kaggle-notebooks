{"cells":[{"metadata":{"_uuid":"d8850c68efc40e873f95beaea7de3b478a308a62"},"cell_type":"markdown","source":"**Used Car Price Prediction \nStep1 : Exploratory Data Analysis**\nIn this project, we have a look into the data related to used cars and understand the relationships among various variables and figure out the features which have a maximum impact on price. We use Correlation analysis, visualization techniques, log of features, as well as polynomial features, outlier analysis, normal distribution analysis etc. The goal is to create a predictive model which can give an estimation of the price to a customer who wants to buy/sell a used car. The data is taken from https://www.kaggle.com/CooperUnion/cardataset,"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport math\nfrom pandas.tools.plotting import scatter_matrix\nfrom sklearn.model_selection import train_test_split\nfrom collections import OrderedDict\n\nimport os\nprint(os.listdir(\"../input\"))\ncarSales = pd.read_csv('../input/data.csv',sep=\",\")\ncarSales.head()\n#Lets import the dataset and have a look at the first few records.\ncarSales.info()\ncarSales['Vehicle Style'].value_counts()\ncarSales['Vehicle Size'].value_counts()\n#As we can see above, there are a total of 16 features. The popularity of car is a number obtained from twitter assigned to a particular \n#Make and Model. Since, the users will not be aware of the popularity of a particular make, we should choose to ignore this feature.\n#dropping Popularity\ncarSales=carSales.drop('Popularity',axis=1)\n\n#We create derived feature,the Age of the car, derived from the Year of Mfr., which is certainly \n#a very important characteristic that a buyer looks into while looking for a used car.\n#This dataset is from 2017. So, using that as a reference to calculate the age of the car .\nprint(carSales['Year'].max())\ncarSales['Age']=2017-carSales['Year']\n\ncarSales.describe()\n\nax=plt.hist(carSales['MSRP'],bins=50)\nplt.xlim(0,150000)\nplt.show()\n%pylab inline\nMake=carSales.groupby(['Make'])['MSRP'].median()\nMake.plot(kind='bar',stacked=True)\npylab.ylabel('Median MSRP')\npylab.title('Chart: Median MSRP by Make')\nshow()\n\n\n\n#From the above plot, we see that the Make of a car has a significant impact on price. This is obvious as different manufacturers produce cars in different price ranges. It might be difficult for a single model to fit well to all the data. So, it might be wise to divide the data w.r.t price and then we can have individual models for a single price range.\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5d4e7a6de98cf2bcb0ffb2fea5e8802ea0caf58f"},"cell_type":"markdown","source":"Clearly, this is a skewed distribution. There are cars of several makes and models in this dataset. Lets have a look at the price with respect to the Make of the car. We are choosing the Median as the Central Tendency measure instead of the Mean since the Median is more robust in nature compared to the Mean. For some models such as Mercedes Benz, there are models such as SLR McLaren which have an approximate price range of $480000. This may drive the mean towards the right of the distribution and result in us placing the Mercedes Benz in a wrong category. Hence, median is a better choice here."},{"metadata":{"_uuid":"f2a7637ad51aa3133657bc2570e667334cfff6c9"},"cell_type":"markdown","source":"From the above plot, we see that the Make of a car has a significant impact on price. This is obvious as different manufacturers produce cars in different price ranges. It might be difficult for a single model to fit well to all the data. So, it might be wise to divide the data w.r.t price and then we can have individual models for a single price range."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"2d4158afa742b7046beb2f0058fa965de252c137"},"cell_type":"code","source":"carSales=carSales.join(carSales.groupby('Make')['MSRP'].median(), on='Make', rsuffix='_Median')\nmake = carSales.groupby('Make')['MSRP'].median().reset_index()\npd.options.display.float_format = '{:.4f}'.format\nmake.sort_values('MSRP', ascending=False)\n\ndef map_MSRP_to_group(x):\n    if x<30000:\n        return 'ordinary'\n    elif x<60000 :\n        return 'deluxe'\n    elif x<90000:\n        return 'super-deluxe'\n    elif x<350000:\n        return 'luxury'\n    else:\n        return 'super-luxury'\n#function to convert a series    \ndef convert_MSRP_series_to_MSRP_group(MSRP):\n    return MSRP.apply(map_MSRP_to_group)\n\nMSRP_group=convert_MSRP_series_to_MSRP_group(carSales['MSRP_Median'])\ncarSales['MSRP_group'] = MSRP_group\ncarSales.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"30face12607a03ae1615ee156a8415828cb30aa0"},"cell_type":"markdown","source":"Lets have a look at the Makes present in various price groups\n\n"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"carSales[carSales['MSRP_group']=='ordinary']['Make'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"274289cc3b62e2120c9b6981ac18af5b049301ed","collapsed":true},"cell_type":"code","source":"carSales[carSales['MSRP_group']=='deluxe']['Make'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"24221a959cb34de80828bee81e3e24b7c22a17ae","collapsed":true},"cell_type":"code","source":"carSales[carSales['MSRP_group']=='super-deluxe']['Make'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fca6489f2c6a2ffbb66ce77d3e8f491c74092bae","collapsed":true},"cell_type":"code","source":"carSales[carSales['MSRP_group']=='luxury']['Make'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d0cf7911f9113b99e0ef297ee67f5515e1c35f75","collapsed":true},"cell_type":"code","source":"carSales[carSales['MSRP_group']=='super-luxury']['Make'].unique()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5fcf4548c720c2a3f3f38ecf8b8a93bb9690c904"},"cell_type":"markdown","source":"Lets save the data as pickle files and they can be used easily for further processing"},{"metadata":{"trusted":true,"_uuid":"f9ed9ad4ba73e763f3b733abff8d1523e6b93ed6","collapsed":true},"cell_type":"code","source":"import pickle\nordinary='./ord.pkl'\ndeluxe='./del.pkl'\nsupdel='./supdel.pkl'\nluxury='./luxury.pkl'\nsuplux='./suplux.pkl'\n\nwith open(ordinary, \"wb\") as f:\n    w = pickle.dump(carSales[carSales['MSRP_group']=='ordinary'],f)\nwith open(deluxe, \"wb\") as f:\n    w = pickle.dump(carSales[carSales['MSRP_group']=='deluxe'],f)\nwith open(supdel, \"wb\") as f:\n    w = pickle.dump(carSales[carSales['MSRP_group']=='super-deluxe'],f)\nwith open(luxury, \"wb\") as f:\n    w = pickle.dump(carSales[carSales['MSRP_group']=='luxury'],f)\nwith open(suplux, \"wb\") as f:\n    w = pickle.dump(carSales[carSales['MSRP_group']=='super-luxury'],f)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b192617821252d6d862dc1358bf718e547885cd1"},"cell_type":"markdown","source":"Here, we shall provide the analysis for just one of the files. The remaining files will be processed in the same manner. Lets have a look at the ordinary category"},{"metadata":{"trusted":true,"_uuid":"0dfb04edefc60713ee7356eeed862d56c0d478d4","collapsed":true},"cell_type":"code","source":"ordinary=pd.read_pickle('./ord.pkl')\nordinary.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c0d152a98c91f11cc2dea9ceb31f62ecba6a25c7"},"cell_type":"markdown","source":"The index is still set to that of the original dataframe. Lets reset that."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"4c7af0c9c450b48d65f15cbc762b45149c38bcdf"},"cell_type":"code","source":"ordinary = ordinary.reset_index(drop=True)\nordinary=ordinary.drop(['MSRP_group','MSRP_Median'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3424def77436fafbc3bfc16e9c5c0215c3d2ae98"},"cell_type":"markdown","source":"We know that there are a few assumtions for Linear Regression:\nNo or little multicollinearity\nLinear relationship\nMultivariate normality\nNo auto-correlation\nHomoscedasticity \nLet us check if the above assumptions hold true for our data. First we will try to check for multicollinearity i.e whether there is any correlation between the independent variables. We will create a heatmap for correlation among the various variables."},{"metadata":{"trusted":true,"_uuid":"658d5c28641f48dc01b83a0eb9ad65dd3c66cb81","collapsed":true},"cell_type":"code","source":"corr=ordinary.corr()\n# Generate a mask for the upper triangle\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(11, 9))\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=1, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ebbb8e0637abcbc6f0837a3fc2266c961d368264","collapsed":true},"cell_type":"code","source":"#Also showcasing the table below to lookup exact values for reference.\ncorr","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0a089cde612c21b8b4e50ca65ad8ed1f95bb2077"},"cell_type":"markdown","source":"As we can see above, there is a very strong negative correlation between Year and Age, which makes sense as the Age of the car is a derived feature from Year."},{"metadata":{"trusted":true,"_uuid":"32be27cd6d44a3cd6188931038fb2236cd8dc7ec","collapsed":true},"cell_type":"code","source":"from numpy import cov\ncov(carSales['highway MPG'],carSales['city mpg'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"071bba504f6e190f5eb23e79998371c6b6054baf","collapsed":true},"cell_type":"code","source":"from scipy.stats import pearsonr\ncorr, _ = pearsonr(carSales['highway MPG'],carSales['city mpg'])\nprint('Pearsons correlation betweeen highway MPG and city MPG: %.3f' % corr)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b4628246101a8704e3d14338524a1ddf208de116"},"cell_type":"markdown","source":"from scipy.stats import pearsonr\ncorr, _ = pearsonr(carSales['highway MPG'],carSales['city mpg'])\nprint('Pearsons correlation betweeen highway MPG and city MPG: %.3f' % corr)"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"1d543805ff91bbd66a492e4b74fb0fe2384ab213"},"cell_type":"code","source":"#dropping the features as discussed above\nordinary=ordinary.drop(['Year','highway MPG'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f881b67521364d812faf209f6f0b1aac9aa16ef4"},"cell_type":"markdown","source":"We draw Scatter plot between Price and Engine HP. and find an interesting result."},{"metadata":{"trusted":true,"_uuid":"4229df5dc6a71b8aacd255c49568c597b993c241","collapsed":true},"cell_type":"code","source":"plt.scatter(ordinary['MSRP'], ordinary['Engine HP'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e2033372bfdc2eab1668fb8f394b083ced1aa66a","collapsed":true},"cell_type":"code","source":"#do some data cleansing to make sure the correlation analysis runs without any error\nm=ordinary[\"MSRP\"].isnull().any()\nprint(m[m])\nm=ordinary[\"Engine HP\"].isnull().any()\nprint(m[m])\nordinary[\"Engine HP\"].fillna(ordinary[\"Engine HP\"].mean())\nordinary['Engine HP'] = ordinary['Engine HP'].apply(lambda x: x if not pd.isnull(x) else ordinary[\"Engine HP\"].mean())\nm=ordinary[\"Engine HP\"].isnull().any()\nprint(m[m])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"79ece034a605207b7bd1ab858c9fce80d0a8baed"},"cell_type":"markdown","source":"The relationship does not look linear. We decide to try Pearson correlation. The Pearson correlation coefficient (named for Karl Pearson) can be used to summarize the strength of the linear relationship between two data samples. We try powers of Engine HP, ex: square, cube as well as log of Engine HP"},{"metadata":{"trusted":true,"_uuid":"928d500e3125ae2a1f97780f3ef2d1ccaa4c7df2","collapsed":true},"cell_type":"code","source":"from scipy.stats import spearmanr\n\ncorr_p, _ = pearsonr((ordinary['MSRP']), ordinary['Engine HP'])\nprint('Pearson correlation between Price and Engine HP : %.3f' % corr_p)\n\ncorr_p, _ = pearsonr((ordinary['MSRP']), np.square(ordinary['Engine HP']))\nprint('Pearson correlation between Price and square of Engine HP : %.3f' % corr_p)\n\ncorr_p, _ = pearsonr((ordinary['MSRP']), np.power(ordinary['Engine HP'],3))\nprint('Pearson correlation between Price and cube of Engine HP : %.3f' % corr_p)\n\ncorr_p, _ = pearsonr((ordinary['MSRP']), np.log(1+ordinary['Engine HP']))\nprint('Pearson correlation between Price and log of Engine HP : %.3f' % corr_p)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6cff9fd5b3b6f7fba4788ca02aa5fe4d3684b125"},"cell_type":"markdown","source":"We observe that the Engine HP, as is, has the highest correlation with Price\nIn case of nonlinear relationship or if the two variables being considered have a non-Gaussian distribution. In this case, the Spearmanâ€™s correlation coefficient (named for Charles Spearman) can be used to summarize the strength between the two data samples"},{"metadata":{"trusted":true,"_uuid":"3b2f5c709861c68ee58751222df1488feb26f103","collapsed":true},"cell_type":"code","source":"corr, _ = spearmanr(ordinary['MSRP'], ordinary['Engine HP'])\nprint('Spearman correlation between Price and Engine HP: %.3f' % corr)\ncorr, _ = spearmanr(ordinary['MSRP'], np.log(1+ordinary['Engine HP']))\nprint('Spearman correlation between Price and log of Engine HP : %.3f' % corr)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f4b1d4a232d48799420c1e821b102ed603e4f470"},"cell_type":"markdown","source":"We can also create a pairplot to better understand the relationship among features. We are selecting Make as the legend\nto see if the relationships vary with Make."},{"metadata":{"trusted":true,"_uuid":"d18e1e0f0e20361031805afe3659235b8ad7acfd","collapsed":true},"cell_type":"code","source":"import seaborn as sns\nsns.set(style=\"ticks\")\nsns.pairplot(ordinary,hue='Make')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"39b5ad8c857af440a8c15d03a31ecc144ce27f96"},"cell_type":"markdown","source":"We can draw some interesting insights from the charts above. For example, Number of doors and Engine Cylinders are better suited as categorical features rather than numerical. Also, the relationship of variables such as City MPG and Age with MSRP are not exactly linear. We can try some feature transformations to fix that.\nWe will explore these in detail going forward"},{"metadata":{"_uuid":"052ed6dd0b6dd7d93f4753d455c3eb9003874ec2"},"cell_type":"markdown","source":"**Data Cleansing**\nNext, we try to fix the blank values. As, we can see above there are blank values for Engine Fuel Type,Market Category and Engine Cyliders. Now lets check the Engine Fuel Type first"},{"metadata":{"trusted":true,"_uuid":"a8a3c77c69a4b280332182d07c4d24440b50fc23","collapsed":true},"cell_type":"code","source":"ordinary[ordinary['Engine Fuel Type'].isnull()]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2e622558dce4c6de4a90363954cddddcaa281c3a"},"cell_type":"markdown","source":"We lookup the values from the other records in the dataset or we check the internet. For eg, we check for Suzuki Verona as below."},{"metadata":{"trusted":true,"_uuid":"bcb645605ec1380e5aed9102c4a8532c95af3a80","collapsed":true},"cell_type":"code","source":"ordinary[(ordinary['Model']=='Verona')&(ordinary['Make']=='Suzuki')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"dcf214249bdbe272a0873f66171dd6e67108650b"},"cell_type":"code","source":"#For Suzuki Verona,  Fuel Type is regular unleaded\nordinary.loc[(ordinary['Engine Fuel Type'].isnull())&(ordinary['Model']=='Verona')&(ordinary['Make']=='Suzuki'),'Engine Fuel Type']='regular unleaded'","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b38816f475a5ccd5f717ebabbe35dcee9db3dc84"},"cell_type":"markdown","source":"Now, for engine cylinders, the makes and models having NaN's genuinely have no cylinders, only rotors. We replace the NaN's with zeros."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"7159a97bc4932af0d706eaffa822d742b4274096"},"cell_type":"code","source":"ordinary.loc[(ordinary['Make']=='Mazda')&(ordinary['Model']=='RX-8'),'Engine Cylinders']=0\nordinary.loc[(ordinary['Make']=='Mazda')&(ordinary['Model']=='RX-7'),'Engine Cylinders']=0\nordinary.loc[(ordinary['Make']=='Mitsubishi')&(ordinary['Model']=='i-MiEV'),'Engine Cylinders']=0\nordinary.loc[(ordinary['Make']=='Chevrolet')&(ordinary['Model']=='Bolt EV'),'Engine Cylinders']=0\nordinary.loc[(ordinary['Make']=='Volkswagen')&(ordinary['Model']=='e-Golf'),'Engine Cylinders']=0","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b7cc6615718bc902f147a7426fc16756da4e2827"},"cell_type":"markdown","source":"Market Category contains some generic categorical value for the car. The buyer/seller will not be aware of such values in our dataset. Hence, it should not be considered while creating the regression model"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"8369bafc79aedda2a9efbe2b2e6791c5a6339b08"},"cell_type":"code","source":"ordinary=ordinary.drop('Market Category',axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f7621be3ff23a232a208d4ded9511c1e503ee60e"},"cell_type":"markdown","source":"**Normality and Outliers**\nNow, lets check for normality. We can check this by creating histogram of the features."},{"metadata":{"trusted":true,"_uuid":"dd33404e005130804e9b3282ec3c8b521ff74407","collapsed":true},"cell_type":"code","source":"plt.hist(ordinary['Age'])\nplt.title('Age Histogram')\nplt.show()\nplt.hist(ordinary['MSRP'])\nplt.title('Price Histogram')\nplt.show()\nplt.hist(ordinary['city mpg'])\nplt.title('City mpg Histogram')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cb90214ff2e0a4cd2727b3d7093af074cab5bfed"},"cell_type":"markdown","source":"It seems like Age,MSRP and city_mpg have a skewed distribution.Lets have a look at our target variable MSRP"},{"metadata":{"trusted":true,"_uuid":"8ffcdc9a1822de19b6f60308986906ac8ed3dc21","collapsed":true},"cell_type":"code","source":"sns.boxplot(x=ordinary['MSRP'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"55b0afaaa3c2ad3275e97285cdef69252e345dfa"},"cell_type":"markdown","source":"As we can see above, the price is a positively skewed distribution. We know that one of the assumptions for using LinearRegression is that the variables be normally distributed.\nAlso,there seem to be some outliers. Lets have a look at them. Usually, we consider an values to be outliers if \na) Q1 - 1.5IQR \nb) Q3 + 1.5IQR \nwhere IQR=Q3-Q1 provided the distribution is symmetrical."},{"metadata":{"trusted":true,"_uuid":"348d3c2c2c6f9f4e6b164fae701c68908c455ef9","collapsed":true},"cell_type":"code","source":"q75, q25 = np.percentile(ordinary['MSRP'], [75 ,25])\niqr = q75 - q25\nq75+1.5*q75","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f58a54a8d7c172dee0bc41d1cb1a2dce810a77c4"},"cell_type":"markdown","source":"Considering that the data is positively skewed and looking at the box plot, we take any values above 140000 to be outliers, for the ordinary segment of cars"},{"metadata":{"trusted":true,"_uuid":"77dbe3fc8257181ff6270aa3546f63cf5e7e22cf","collapsed":true},"cell_type":"code","source":"ordinary[ordinary['MSRP']>140000]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a7aacf55e6aa97e18dd6958cf720b2f486ed36d3"},"cell_type":"markdown","source":"When we assigned a grouping based on price, we did so on the basis of Median price per Make.This will work in most of the cases but there may be individual models that can be in a different category. We will remove these outliers before building our models"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c275eaf6566d895453d632bc186ba1159c3efdff"},"cell_type":"code","source":"ordinary=ordinary[ordinary['MSRP']<140000]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8ea1a37c3470b3d54ae799a4271d2de6176c041e"},"cell_type":"markdown","source":"Lets log transform the data to handle the skewness"},{"metadata":{"trusted":true,"_uuid":"f40e8ef63466c9729398faf879d5fd4f2bc04cc9","collapsed":true},"cell_type":"code","source":"ordinary['log_MSRP']=ordinary['MSRP'].apply(lambda x:np.log(1+x))\nplt.hist(ordinary['log_MSRP'])\nplt.show()\nsns.boxplot(x=ordinary['log_MSRP'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5980aa04c5df0f551b3d13dbd4c8d1f5b002a6ba"},"cell_type":"markdown","source":"Now, lets have a look at Age. We will check out the relationship of Age with log_MSRP and try different transformations such as log,polynomial etc."},{"metadata":{"trusted":true,"_uuid":"dadec8ceecfe802463fcc5a64303fcb81228dfbf","collapsed":true},"cell_type":"code","source":"ordinary['log_Age']=ordinary['Age'].apply(lambda x: np.log(x+1))\nfig, (ax1,ax2) = plt.subplots(1,2,figsize=(15,3))\nax1.set_title('Log Age Histogram')\nax1.hist(ordinary['log_Age'])\nax2.boxplot(ordinary['log_Age'])\nax2.set_title('Log Age Box Plot')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6bdc1c36bdbe8a20e658dbb0d9c9b6959f98b462"},"cell_type":"markdown","source":"The log_Age distribution appears to be somewhat uniform. Lets have a look at the correlation with age."},{"metadata":{"trusted":true,"_uuid":"38740523562fe3ac7848c8a94edf911d7478cd80","collapsed":true},"cell_type":"code","source":"fig, (ax1,ax2) = plt.subplots(1,2,figsize=(12,3))\nax1.scatter(ordinary['Age'],ordinary['log_MSRP'],alpha=.3)\nax1.set_title('Age vs Log MSRP')\nax2.scatter(ordinary['log_Age'],ordinary['log_MSRP'],alpha=.3)\nax2.set_title('Log Age vs Log MSRP')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"95559f2678f08531182d04906901f53aad9758d5"},"cell_type":"markdown","source":"Lets check with sqrt as well"},{"metadata":{"trusted":true,"_uuid":"ae6382551c991376ac769916afcfa062a4573b18","collapsed":true},"cell_type":"code","source":"ordinary['sqrt_Age']=np.sqrt(ordinary['Age'])\nplt.scatter(ordinary['sqrt_Age'],ordinary['log_MSRP'],alpha=.3)\nplt.title('sqrt Age vs Log MSRP')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e13bb849df490324e6defa25f89c3af25fe5d358"},"cell_type":"markdown","source":"It seems Age and Log MSRP have a linear relationship. Now, lets have a look at city mpg"},{"metadata":{"trusted":true,"_uuid":"a2a7565ee1416ec50fe4b1a134e2a4cafd07e592","collapsed":true},"cell_type":"code","source":"sns.lmplot( x=\"Age\", y=\"log_MSRP\", data=ordinary, fit_reg=False, hue='Driven_Wheels', legend=False)\nplt.legend(loc='upper right')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b07e162c340b1464f314902ae6ead0d9dff8170d","collapsed":true},"cell_type":"code","source":"ordinary['log_city mpg']=ordinary['city mpg'].apply(lambda x: np.log(x+1))\nfig, (ax1,ax2) = plt.subplots(1,2,figsize=(15,3))\nax1.hist(ordinary['log_city mpg'])\nax1.set_title('log city mpg histogram')\nax2.boxplot(ordinary['log_city mpg'])\nax2.set_title('log city mpg boxplot')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"819d4380423d885b993b21533dcbece50d0c0dd4","collapsed":true},"cell_type":"code","source":"fig, (ax1,ax2) = plt.subplots(1,2,figsize=(15,3))\nax1.scatter(ordinary['city mpg'],ordinary['log_MSRP'],alpha=.1)\nax1.set_title('city mpg vs Log MSRP')\nax2.scatter(ordinary['log_city mpg'],ordinary['log_MSRP'],alpha=.1)\nax2.set_title('Log city mpg vs Log MSRP')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b9eaada46422460246681e94452cede5a0376580"},"cell_type":"markdown","source":"There seems to be some outliers w.r.t city mpg. Lets add legend to the chart and see if we can get some insights."},{"metadata":{"trusted":true,"_uuid":"98aecbe37242d71cfff685e638c663d0a5ca74ce","collapsed":true},"cell_type":"code","source":"sns.lmplot( x=\"city mpg\", y=\"log_MSRP\", data=ordinary, fit_reg=False, hue='Transmission Type', legend=False)\nplt.legend(loc='upper right')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cd39c35c751666b2f9861492b62e27045c0db90d"},"cell_type":"markdown","source":"The above chart seems interesting as almost all the vehicles which have a DIRECT_DRIVE transmission type seem to have a higher city mpg. \nLets have a look at the correlations to get a better idea"},{"metadata":{"trusted":true,"_uuid":"760debc417e817887785f2482a280e56a81e9ca2","collapsed":true},"cell_type":"code","source":"corr=ordinary.corr()\ncorr['log_MSRP'].sort_values(ascending=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2a9ebeec0eb8d49752f3496546115bae8580f7f8"},"cell_type":"markdown","source":"Age has a stronger correlation with log_MSRP compared to log_Age. For city mpg, we log transform the data as the distribution is close to normal and the correlation is slightly higher. So, the numeric features we are going to use are\nAge of Car\nEngine HP\nlog_city mpg \n\nLets drop the other numeric_features"},{"metadata":{"trusted":true,"_uuid":"a4973bc3afd3afcef23e05699996aaa05a1dd610","collapsed":true},"cell_type":"code","source":"ordinary=ordinary.drop(['log_Age','city mpg'],axis=1)\nordinary.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"431e0bdee3199fa3a77f276de90146b2241affe0","collapsed":true},"cell_type":"code","source":"#Since we have decided to take log MSRP as a target variable, we decide to check relationship between Engine HP, \n#with powers and Log MSRP\nfig, (ax1,ax2,ax3) = plt.subplots(1,3,figsize=(15,3))\nax1.scatter(np.power(ordinary['Engine HP'],1/2), ordinary['log_MSRP'],alpha=.3)\nax1.set_title('HP^2 vs Log MSRP')\nax2.scatter(np.power(ordinary['Engine HP'],1/3), ordinary['log_MSRP'],alpha=.3)\nax2.set_title('HP^3 vs Log MSRP')\nax3.scatter(log(1+ordinary['Engine HP']), ordinary['log_MSRP'],alpha=.3)\nax3.set_title('log Engine HP vs Log MSRP')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"566e415d6ae5af879361ce074ee49e690fd6b02c","collapsed":true},"cell_type":"code","source":"corr_p, _ = pearsonr((ordinary['log_MSRP']), ordinary['Engine HP'])\nprint('Pearson correlation between log Price and Engine HP : %.3f' % corr_p)\n\ncorr_p, _ = pearsonr((ordinary['log_MSRP']), np.square(ordinary['Engine HP']))\nprint('Pearson correlation between log Price and square of Engine HP : %.3f' % corr_p)\n\ncorr_p, _ = pearsonr((ordinary['log_MSRP']), np.power(ordinary['Engine HP'],3))\nprint('Pearson correlation between log Price and cube of Engine HP : %.3f' % corr_p)\n\ncorr_p, _ = pearsonr((ordinary['log_MSRP']), np.log(1+ordinary['Engine HP']))\nprint('Pearson correlation between log Price and log of Engine HP : %.3f' % corr_p)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5028daca9b06e7e923dcd0a2aea0eee7c7af4db6"},"cell_type":"markdown","source":"We find Pearson correlation between log Price and log Engine HP to be the highest and decide to log Engine HP as a numerical feature.\n"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"02eb1f620835b68efbfad556794b91718d4164bf"},"cell_type":"code","source":"ordinary['log_Engine HP']=ordinary['Engine HP'].apply(lambda x: np.log(x+1))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"66b6943000d199978c389786ad43d20babcea3d1"},"cell_type":"markdown","source":"Now lets have a look at the categorical features. Since, there are a huge number of models and there maybe very few number of records per model,one-hot encoding the same will result into a huge number of features. We use a few Makes and Models to reduce the number of features."},{"metadata":{"trusted":true,"_uuid":"108d4809b80f6ff9f3feae776890dba58192713f","collapsed":true},"cell_type":"code","source":"fig, (ax1) = plt.subplots(1,1,figsize=(15,5))\nMake=ordinary.groupby(['Make'])['MSRP'].mean()\nModel=ordinary.groupby(['Model'])['MSRP'].mean()\nFuelType=ordinary.groupby(['Engine Fuel Type'])['MSRP'].mean()\nTransmission=ordinary.groupby(['Transmission Type'])['MSRP'].mean()\nDrivenWheels=ordinary.groupby(['Driven_Wheels'])['MSRP'].mean()\nVehicleSize=ordinary.groupby(['Vehicle Size'])['MSRP'].mean()\nVehicleStyle=ordinary.groupby(['Vehicle Style'])['MSRP'].mean()\nax1.bar(Make.index,Make.values)\nax1.set_title('Mean MSRP by Make')\nplt.sca(ax1)\nplt.xticks(rotation=90)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"26af0deaf90cdf91bda3abec93b518cd55200ea9","collapsed":true},"cell_type":"code","source":"plt.bar(FuelType.index,FuelType.values)\nplt.title('Mean MSRP by Engine Fuel Type')\nplt.xticks(rotation=90)\nplt.show()\nplt.bar(Transmission.index,Transmission.values)\nplt.title('Mean MSRP by Transmission Type')\nplt.xticks(rotation=90)\nplt.show()\nplt.bar(DrivenWheels.index,DrivenWheels.values)\nplt.title('Mean MSRP by Driven_Wheels')\nplt.xticks(rotation=90)\nplt.show()\nplt.bar(VehicleSize.index,VehicleSize.values)\nplt.title('Mean MSRP by Vehicle Size')\nplt.xticks(rotation=90)\nplt.show()\nplt.bar(VehicleStyle.index,VehicleStyle.values)\nplt.title('Mean MSRP by Vehicle Style')\nplt.xticks(rotation=90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"07493a307fa42f1e7539b45923b1bad33b204a44"},"cell_type":"markdown","source":"As we see above the MSRP varies for different values of the features. Hence, we shall keep the above features and one hot encode the same.\nSaving the transformed dataframe as a pickle file"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"9bc07ad18f4bf8496285032ac71f6697df858fac"},"cell_type":"code","source":"#We take few specific models. This is to restric the number of features.\nMakes=['Ford','Chevrolet','Chrysler','Pontiac','Subaru','Hyundai','Honda','Mazda', 'Nissan','Suzuki']\nordinary=ordinary[ordinary.Make.isin(Makes)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"636d94bec44b63f618cb5f600be23e42a1c21479","collapsed":true},"cell_type":"code","source":"ordinary.Make.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"9729747c31d43423214db1a3ad1b2ab9c7f30b9f"},"cell_type":"code","source":"ordinary_trans='./ordinarydfUSJap.pkl'\nwith open(ordinary_trans, \"wb\") as f:\n    w = pickle.dump(ordinary,f)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"81ad51859c41719d446ad1523d14704693271ad5"},"cell_type":"markdown","source":"**Data Pre-processing** The numerical variables are scaled with StandardScaler, imputation strategy is used to replace 0 values with mean StratifiedRandomShuffleSplit is done based on Age of car (Curr Year - Year of Car), by creating Age category (Age / 5), and same distribution of Age-category is maintained in Train and Test data. The categorical variables (Engine Cylinders, Engine Fuel type, Transmission type, Vehicle Size, Vehichle Style, Drive wheels, Make) are one-hot encoded and added to the feature vector. The numerical variables considered are : Age of Car (derived from Year of Mfr), Log City mpg, Log Engine HP, based on initial Data Analysis. Two sets of X features are produced, with Make and without Make so the results can be compared. The target variable is Price. Again both Price and log of Price is used and results compared in final predictive Model."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"9c7feb7b46b71857346cd880aabb2593fc8b12a3"},"cell_type":"code","source":"#Import all necessary libraries\nimport pickle\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.preprocessing import Imputer\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import PolynomialFeatures","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4a53daac3af7f355a64f0f4e524ae7912fb9a436"},"cell_type":"markdown","source":"Read the pickle files prepared by stratifying the Car Sales Data based on Make and Price. This is necessary since cars belong to different price segments, and including all make and models is not a viable solution, as the range of price is different for the same features for different makes. The stratification details can be found above, which precedes this and outputs the data into .pkl files, based on car segment/price category"},{"metadata":{"trusted":true,"_uuid":"20b92509cf78aa7bdf69b3507ec2722b1d1e1a19","collapsed":true},"cell_type":"code","source":"df_ordinary=pd.read_pickle('./ordinarydfUSJap.pkl')\ndf_ordinary.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d41a6a93ab31279c149404cc8da9586fa56ef017","collapsed":true},"cell_type":"code","source":"df_ordinary[\"Make\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e62309d00454778269d907fa319521bfea23a3da","collapsed":true},"cell_type":"code","source":"print(len(df_ordinary))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"82a72d601cb393e1dd948450a555325dc5ccb962"},"cell_type":"markdown","source":"We will take the ordinary segment as it has the most data, and fit our model. Once done the same model will be applied to other segments.(For MVP, in actuality the modeling exercise needs to be repeated for each segment, as the relationships may be different)"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"03026b5e7e9de9fcfdf5ceb3ccb4c9c7247d657b"},"cell_type":"code","source":"#We do some data cleansing, as needed\ndf_ordinary[\"Number of Doors\"] = df_ordinary[\"Number of Doors\"].replace(\"?\",0)\ndf_ordinary[\"Number of Doors\"] = df_ordinary[\"Number of Doors\"].astype('float32')\ndf_ordinary[\"MSRP\"] = df_ordinary[\"MSRP\"].replace(\"?\",0)\ndf_ordinary[\"MSRP\"] = df_ordinary[\"MSRP\"].astype(\"float32\")\ndf_ordinary[\"log_Engine HP\"] = df_ordinary[\"log_Engine HP\"].astype(\"float32\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"694fe6c50cd1fba7a68f1ccbe2e180e853cb9d6f"},"cell_type":"markdown","source":"We check the distribution of Car Sales on the basis of Age of Car, and create Age-cat and check the distribution of the Car data based on Age-cat (Age / 5). We plan to use StratifiedSampling to make sure both Test and Train data represents same distribution of cars based on Age of Car"},{"metadata":{"trusted":true,"_uuid":"a3661438a71e7f9a9fe42575c589030d0510da76","collapsed":true},"cell_type":"code","source":"df_ordinary[\"Age\"].value_counts()\n#create a field Age-cat to divide the data into 5 Age categories, based on the Age of the car\ndf_ordinary[\"Age-cat\"] = np.ceil(df_ordinary[\"Age\"] / 5)\ndf_ordinary[\"Age-cat\"].where(df_ordinary[\"Age-cat\"] < 5, 5.0, inplace=True)\n#check distribution of Age Cat in the original data\ndf_ordinary[\"Age-cat\"].value_counts() / len(df_ordinary)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e8a7d8e788f9ed88896d3b1f0ade5b1991fe4aea"},"cell_type":"markdown","source":"We treat Engine Cylinders, Engine Fuel Type, Transmission Type, Driven_wheels, Vehicle Size, Make and style as Categorical variables based on our Data exploration. We use the LabelBinarizer to fit the variables on the entire set. The actual encoding will be done using the encoded values on the Train and test samples"},{"metadata":{"trusted":true,"_uuid":"ed463846cd22037a598a28e2304cd55d6f302425","collapsed":true},"cell_type":"code","source":"car_eng_cyl = df_ordinary[\"Engine Cylinders\"]\nencoder_cyl = LabelBinarizer()\nencoder_cyl.fit(car_eng_cyl)\nprint(encoder_cyl.classes_)\n\ncar_eng_fuel_type = df_ordinary[\"Engine Fuel Type\"]\nencoder_fuel = LabelBinarizer()\nencoder_fuel.fit(car_eng_fuel_type)\nprint(encoder_fuel.classes_)\n\ncar_trans_type = df_ordinary[\"Transmission Type\"]\nencoder_trans = LabelBinarizer()\nencoder_trans.fit(car_trans_type)\nprint(encoder_trans.classes_)\n\ncar_driven_wheels = df_ordinary[\"Driven_Wheels\"]\nencoder_wheels = LabelBinarizer()\nencoder_wheels.fit(car_driven_wheels)\nprint(encoder_wheels.classes_)\n\ncar_vehicle_size = df_ordinary[\"Vehicle Size\"]\nencoder_size = LabelBinarizer()\nencoder_size.fit(car_vehicle_size)\nprint(encoder_size.classes_)\n\ncar_make =df_ordinary[\"Make\"]\nencoder_make = LabelBinarizer()\nencoder_make.fit(car_make)\nprint(encoder_make.classes_)\n\n\ncar_style =df_ordinary[\"Vehicle Style\"]\nencoder_style = LabelBinarizer()\nencoder_style.fit(car_style)\nprint(encoder_style.classes_)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"4260c2f12dd6a200907d57805fdf2ef4c36f39ea"},"cell_type":"code","source":"#We use StratifiedShuffleSplit based on Age-cat, to make sure both train and test data have same distribution of New and Old cars\nsplit = StratifiedShuffleSplit(n_splits=1,test_size=0.2,random_state=42)\n\nfor train_index, test_index in split.split(df_ordinary,df_ordinary[\"Age-cat\"]):\n    strat_train_set = df_ordinary.iloc[train_index]\n    strat_test_set = df_ordinary.iloc[test_index]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8dd27c789da796b00166f39794ddefa775454567","collapsed":true},"cell_type":"code","source":"#check distribution of Age Cat in the train data\nstrat_train_set[\"Age-cat\"].value_counts() / len(strat_train_set)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4fea2c9b01e006d82996a7b9c5ac8c5e55f28cd8","collapsed":true},"cell_type":"code","source":"#check distribution of Age Cat in the test data\nstrat_test_set[\"Age-cat\"].value_counts() / len(strat_test_set)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"42f31840496efa4c63d61455128adb54a10147af"},"cell_type":"markdown","source":"Create the X and Y variables from the Feature analysis done in Exploration notebook. Repeat the same operations for Train and Test data."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"306a6ece75a90c6a560d9d8345053c9a409a4e8a"},"cell_type":"code","source":"carSales_X = strat_train_set.copy()\ncarSales_X = strat_train_set.drop(\"MSRP\", axis=1) # drop labels for training set\ncarSales_X = strat_train_set.drop(\"log_MSRP\", axis=1) # drop labels for training set\ncarSales_Y = strat_train_set[\"log_MSRP\"].copy() # use log MSRP as labels for training set, based on data Exploration\ncarSales_Y_orig = strat_train_set[\"MSRP\"].copy() # use MSRP as labels also for training set, to compare fit based on Log and original Price\n\ncarSales_test_X = strat_test_set.copy()\ncarSales_test_X = strat_test_set.drop(\"MSRP\", axis=1) # drop labels for test set\ncarSales_test_X = strat_test_set.drop(\"log_MSRP\", axis=1) # drop labels for test set\ncarSales_test_Y = strat_test_set[\"log_MSRP\"].copy()# use log MSRP as labels for test set, based on data Exploration\ncarSales_test_Y_orig = strat_test_set[\"MSRP\"].copy()# use MSRP as labels also for test set, to compare fit based on Log and original Price","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cedf75eb6eeb62ec233a47f5f900fd1e751f440b","collapsed":true},"cell_type":"code","source":"carSales_Y = carSales_Y.values.reshape(carSales_Y.shape[0],1)\ncarSales_test_Y = carSales_test_Y.values.reshape(carSales_test_Y.shape[0],1)\ncarSales_Y_orig = carSales_Y_orig.values.reshape(carSales_Y_orig.shape[0],1)\ncarSales_test_Y_orig = carSales_test_Y_orig.values.reshape(carSales_test_Y.shape[0],1)\nprint(carSales_X.shape)\nprint(carSales_Y.shape)\nprint(carSales_Y_orig.shape)\nprint(carSales_test_X.shape)\nprint(carSales_test_Y.shape)\nprint(carSales_test_Y_orig.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"291d26d64dd9d63e7a0841b44a1fd13b171a7dac"},"cell_type":"markdown","source":"Now we need to remove unnecessary columns based on Correlation analysis done in ExplorationNotebook, and do Encoding of Categorical variables. Also we need to do StandardNormalization before applying Regression models."},{"metadata":{"trusted":true,"_uuid":"638b3bd2caa257dc45d586d5ffe21ba297f0b2a3","collapsed":true},"cell_type":"code","source":"carSales_X.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"93903d74305d1fa6edef58c2f52861d460681184"},"cell_type":"markdown","source":"We drop all categorical columns after making a copy, and retain only the numerical features of significance"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"4c88799b910601ad8d52b58abc20b8730a0c6bac"},"cell_type":"code","source":"carSales_X_num = carSales_X\ncarSales_X_num  = carSales_X_num.drop(\"Make\",axis=1) # to be treated as categorical var\ncarSales_X_num  = carSales_X_num.drop(\"Model\",axis=1)\ncarSales_X_num  = carSales_X_num.drop(\"Engine Cylinders\",axis=1) # to be treated as categorical var\ncarSales_X_num  = carSales_X_num.drop(\"Engine Fuel Type\",axis=1) # to be treated as categorical var\ncarSales_X_num  = carSales_X_num.drop(\"Transmission Type\",axis=1) # to be treated as categorical var \ncarSales_X_num  = carSales_X_num.drop(\"Driven_Wheels\",axis=1) # to be treated as categorical var\ncarSales_X_num = carSales_X_num.drop(\"Number of Doors\",axis=1) # to be treated as categorical var\ncarSales_X_num  = carSales_X_num.drop(\"Vehicle Style\",axis=1) # to be treated as categorical var\ncarSales_X_num  = carSales_X_num.drop(\"Engine HP\",axis=1)  # since we are taking log of Engine HP,based on Analysis\ncarSales_X_num = carSales_X_num.drop(\"Vehicle Size\",axis=1) # to be treated as categorical var\ncarSales_X_num = carSales_X_num.drop(\"Age-cat\",axis=1) # derived column\ncarSales_X_num = carSales_X_num.drop(\"sqrt_Age\",axis=1) # derived column\ncarSales_X_num = carSales_X_num.drop(\"MSRP\",axis=1) #Target / label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3cc808f1fdfe21f3e2838ca084f340ad598338f2","collapsed":true},"cell_type":"code","source":"carSales_X_num.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"1fc0759f2371ae9e1079ef44ebaef3875fe4e0eb"},"cell_type":"code","source":"#Apply the same transformation on Test data\ncarSales_test_X_num = carSales_test_X\ncarSales_test_X_num  = carSales_test_X_num.drop(\"Make\",axis=1)\ncarSales_test_X_num  = carSales_test_X_num.drop(\"Model\",axis=1)\ncarSales_test_X_num  = carSales_test_X_num.drop(\"Engine Cylinders\",axis=1)\ncarSales_test_X_num  = carSales_test_X_num.drop(\"Engine Fuel Type\",axis=1)\ncarSales_test_X_num  = carSales_test_X_num.drop(\"Transmission Type\",axis=1)\ncarSales_test_X_num  = carSales_test_X_num.drop(\"Driven_Wheels\",axis=1)\ncarSales_test_X_num = carSales_test_X_num.drop(\"Number of Doors\",axis=1)\ncarSales_test_X_num  = carSales_test_X_num.drop(\"Vehicle Style\",axis=1)\ncarSales_test_X_num = carSales_test_X_num.drop(\"Vehicle Size\",axis=1)\ncarSales_test_X_num  = carSales_test_X_num.drop(\"Engine HP\",axis=1)\ncarSales_test_X_num = carSales_test_X_num.drop(\"Age-cat\",axis=1)\ncarSales_test_X_num = carSales_test_X_num.drop(\"sqrt_Age\",axis=1)\ncarSales_test_X_num = carSales_test_X_num.drop(\"MSRP\",axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"171ac9802f8ec7ec11d8dec4d402e13bd0d0a355","collapsed":true},"cell_type":"code","source":"carSales_test_X_num.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"05195e633c057b4a72b62b5cbf6636535219f49f"},"cell_type":"code","source":"#We do some data cleansing as needed\ncarSales_X_num[\"log_Engine HP\"] = carSales_X_num[\"log_Engine HP\"].astype(\"float32\")\ncarSales_X_num[\"Age\"] = carSales_X_num[\"Age\"].astype(\"float32\")\ncarSales_X_num.replace('null',np.NaN,inplace=True)\ncarSales_X_num = pd.DataFrame(carSales_X_num)\ncarSales_X_num = carSales_X_num.replace('?',0)\ncarSales_X_num = carSales_X_num.replace('NaN',0)\ncarSales_X_num = carSales_X_num.replace(np.NaN,0)\n\ncarSales_test_X_num[\"log_Engine HP\"] = carSales_test_X_num[\"log_Engine HP\"].astype(\"float32\")\ncarSales_test_X_num[\"Age\"] = carSales_test_X_num[\"Age\"].astype(\"float32\")\ncarSales_test_X_num.replace('null',np.NaN,inplace=True)\ncarSales_test_X_num = pd.DataFrame(carSales_test_X_num)\ncarSales_test_X_num = carSales_test_X_num.replace('?',0)\ncarSales_test_X_num = carSales_test_X_num.replace('NaN',0)\ncarSales_test_X_num = carSales_test_X_num.replace(np.NaN,0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dd6f92f937143dc6d84cbe4da7a7c850c0239543","collapsed":true},"cell_type":"code","source":"m=carSales_X_num.isnull().any()\nprint(m[m])\nm=np.isfinite(carSales_X_num.select_dtypes(include=['float64'])).any()\nprint(m[m])\nm=carSales_test_X_num.isnull().any()\nprint(m[m])\nm=np.isfinite(carSales_test_X_num.select_dtypes(include=['float64'])).any()\nprint(m[m])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d801f9778121b78fb2348513b345dd64c42c2a6b"},"cell_type":"markdown","source":"Wherever there are 0 values, we replace by the mean"},{"metadata":{"trusted":true,"_uuid":"e69bc7a399b5923e0ef8e043a94eb5a11815dacc","collapsed":true},"cell_type":"code","source":"imputer = Imputer(missing_values=0,strategy=\"mean\")\nimputer.fit(carSales_X_num)\nimputer.fit(carSales_test_X_num)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b717ca1c7b27ced4e7458449a035acd5a0387b05","collapsed":true},"cell_type":"code","source":"#Standardize the data using sklearn StandardScaler\nscaler = StandardScaler()\ntrain_X = scaler.fit_transform(carSales_X_num)\ntest_X = scaler.transform(carSales_test_X_num)\nprint(train_X.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c4271cf448e5e9013dffc1dbd749c5df30f77a6f"},"cell_type":"markdown","source":"Now add the Categorical variables using one-hot represenation, using the encoder already fit on the entire sample"},{"metadata":{"trusted":true,"_uuid":"4bd33f38eb5cc6d7ee050f160e5e26b4213d59ff","collapsed":true},"cell_type":"code","source":"car_eng_cyl = carSales_X[\"Engine Cylinders\"]\ncar_eng_1hot = encoder_cyl.transform(car_eng_cyl)\nprint(car_eng_1hot.shape)\n\ntrain_X = np.concatenate((train_X,car_eng_1hot),axis=1)\n\ncar_eng_fuel_type = carSales_X[\"Engine Fuel Type\"]\ncar_fuel_1hot = encoder_fuel.transform(car_eng_fuel_type)\nprint(car_fuel_1hot.shape)\n\ntrain_X = np.concatenate((train_X,car_fuel_1hot),axis=1)\n\ncar_trans_type = carSales_X[\"Transmission Type\"]\ncar_trans_1hot = encoder_trans.transform(car_trans_type)\nprint(car_trans_1hot.shape)\n\ntrain_X = np.concatenate((train_X,car_trans_1hot),axis=1)\n\ncar_driven_wheels = carSales_X[\"Driven_Wheels\"]\ncar_drive_1hot = encoder_wheels.transform(car_driven_wheels)\nprint(car_drive_1hot.shape)\n\ntrain_X = np.concatenate((train_X,car_drive_1hot),axis=1)\n\ncar_vehicle_size = carSales_X[\"Vehicle Size\"]\ncar_size_1hot = encoder_size.transform(car_vehicle_size)\nprint(car_size_1hot.shape)\n\ntrain_X = np.concatenate((train_X,car_size_1hot),axis=1)\n\ncar_vehicle_style = carSales_X[\"Vehicle Style\"]\ncar_style_1hot = encoder_style.transform(car_vehicle_style)\nprint(car_style_1hot.shape)\n\ntrain_X = np.concatenate((train_X,car_style_1hot),axis=1)\n\ncar_make = carSales_X[\"Make\"]\ncar_make_1hot = encoder_make.transform(car_make)\nprint(car_make_1hot.shape)\n\ntrain_X_make = np.concatenate((train_X,car_make_1hot),axis=1)\n\n#We prepare two sets of train X features, with Make and without Make and compare the performance of both\nprint(train_X.shape)\nprint(train_X_make.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"222bb66954fc9a3a843d8ad0ea9962020448b7cb","collapsed":true},"cell_type":"code","source":"car_eng_cyl = carSales_test_X[\"Engine Cylinders\"]\ncar_eng_1hot = encoder_cyl.transform(car_eng_cyl)\nprint(car_eng_1hot.shape)\n\ntest_X = np.concatenate((test_X,car_eng_1hot),axis=1)\n\ncar_eng_fuel_type = carSales_test_X[\"Engine Fuel Type\"]\ncar_fuel_1hot = encoder_fuel.transform(car_eng_fuel_type)\nprint(car_fuel_1hot.shape)\n\ntest_X = np.concatenate((test_X,car_fuel_1hot),axis=1)\n\ncar_trans_type_test = carSales_test_X[\"Transmission Type\"]\ncar_trans_1hot_test = encoder_trans.transform(car_trans_type_test)\nprint(car_trans_1hot_test.shape)\n\ntest_X = np.concatenate((test_X,car_trans_1hot_test),axis=1)\n\ncar_driven_wheels_test = carSales_test_X[\"Driven_Wheels\"]\ncar_drive_1hot_test = encoder_wheels.transform(car_driven_wheels_test)\nprint(car_drive_1hot_test.shape)\n\ntest_X = np.concatenate((test_X,car_drive_1hot_test),axis=1)\n\ncar_vehicle_size_test = carSales_test_X[\"Vehicle Size\"]\ncar_size_1hot_test = encoder_size.transform(car_vehicle_size_test)\nprint(car_size_1hot_test.shape)\n\ntest_X = np.concatenate((test_X,car_size_1hot_test),axis=1)\n\ncar_vehicle_style_test = carSales_test_X[\"Vehicle Style\"]\ncar_style_1hot_test = encoder_style.transform(car_vehicle_style_test)\nprint(car_style_1hot_test.shape)\n\ntest_X = np.concatenate((test_X,car_style_1hot_test),axis=1)\n\ncar_make_test = carSales_test_X[\"Make\"]\ncar_make_1hot_test = encoder_make.transform(car_make_test)\nprint(car_make_1hot_test.shape)\n\ntest_X_make = np.concatenate((test_X,car_make_1hot_test),axis=1)\n\nprint(test_X.shape)\nprint(test_X_make.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3e21ac2e85abe768a3a84abb3ead8127d2e3a8eb","collapsed":true},"cell_type":"code","source":"train_Y = pd.DataFrame(carSales_Y)\nm=train_Y.isnull().any()\nprint(m[m])\nm=np.isfinite(train_Y.select_dtypes(include=['float64'])).any()\nprint(m[m])\n\ntrain_Y_orig = pd.DataFrame(carSales_Y_orig)\nm=train_Y_orig.isnull().any()\nprint(m[m])\nm=np.isfinite(train_Y_orig.select_dtypes(include=['float64'])).any()\nprint(m[m])\n\ntest_Y = pd.DataFrame(carSales_test_Y)\nm=test_Y.isnull().any()\nprint(m[m])\nm=np.isfinite(test_Y.select_dtypes(include=['float64'])).any()\nprint(m[m])\n\ntest_Y_orig = pd.DataFrame(carSales_test_Y_orig)\nm=test_Y_orig.isnull().any()\nprint(m[m])\nm=np.isfinite(test_Y_orig.select_dtypes(include=['float64'])).any()\nprint(m[m])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d2df061228a1a3591034af78f783dcc44ee7c20d"},"cell_type":"markdown","source":"We now take backup of the pre-processed data, so the modeling can be done instantaneously on the pre-processed data at any later point of time"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"2708d8a2db5f5de5b125fb0969723e576a712a6b"},"cell_type":"code","source":"train_X_ordinary='./train_X_ordUSJap.pkl'\ntest_X_ordinary='./test_X_ordUSJap.pkl'\ntrain_Y_ordinary='./train_Y_ordUSJap.pkl'\ntest_Y_ordinary='./test_Y_ordUSJap.pkl'\ntrain_Y_ordinary_orig='./train_Y_ord_origUSJap.pkl'\ntest_Y_ordinary_orig='./test_Y_ord_origUSJap.pkl'\n\nwith open(train_X_ordinary, \"wb\") as f:\n    w = pickle.dump(train_X,f)\nwith open(test_X_ordinary, \"wb\") as f:\n    w = pickle.dump(test_X,f)\nwith open(train_Y_ordinary, \"wb\") as f:\n    w = pickle.dump(train_Y,f)\nwith open(test_Y_ordinary, \"wb\") as f:\n    w = pickle.dump(test_Y,f)\nwith open(train_Y_ordinary_orig, \"wb\") as f:\n    w = pickle.dump(train_Y_orig,f)\nwith open(test_Y_ordinary_orig, \"wb\") as f:\n    w = pickle.dump(test_Y_orig,f)\n    \ntrain_X_ord_make='./train_X_ord_makeUSJap.pkl'\ntest_X_ord_make='./test_X_ord_makeUSJap.pkl'\n\nwith open(train_X_ord_make, \"wb\") as f:\n    w = pickle.dump(train_X_make,f)\nwith open(test_X_ord_make, \"wb\") as f:\n    w = pickle.dump(test_X_make,f)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2247cd6eeefb14a97c0487fdb1b5c6b426b2e8bf"},"cell_type":"markdown","source":"**Predictive Modeling** Various Regression techniques are explored, like LinearRegression, RandomForestRegression, with K-fold cross validation, grid search of parameters, finally Deep Learning techniques, XGBoost is used and the best accuracy is shown. However the LinearRegression model is exposed as WebService, due to certain technical limitations faced in exposing the other models."},{"metadata":{"trusted":true,"_uuid":"dd9a6e82e7127a1d0ea2d2ff5d0bcf6a8ccd6c2a","collapsed":true},"cell_type":"code","source":"#Import all necessary libraries\nimport pickle\nimport pandas as pd\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.preprocessing import Imputer\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom pandas.plotting import scatter_matrix\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import SGDRegressor\nfrom keras.models import Sequential\nfrom keras.layers import Dense   \nfrom keras import optimizers\n\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import StratifiedKFold","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f38a9eefb2c29fe0341e9a8950440fc64c831b30"},"cell_type":"markdown","source":"Read the pre-processed pkl files"},{"metadata":{"trusted":true,"_uuid":"f21af255919cfbfb154ebc7b54cf671e9e1f9b34","collapsed":true},"cell_type":"code","source":"train_X=pd.read_pickle('./train_X_ordUSJap.pkl')\ntest_X=pd.read_pickle('./test_X_ordUSJap.pkl')\ntrain_Y=pd.read_pickle('./train_Y_ordUSJap.pkl') # train Y with log(MSRP)\ntest_Y=pd.read_pickle('./test_Y_ordUSJap.pkl')\ntrain_Y_orig=pd.read_pickle('./train_Y_ord_origUSJap.pkl') # train Y with MSRP unmodified\ntest_Y_orig=pd.read_pickle('./test_Y_ord_origUSJap.pkl')\n\ntrain_X_make=pd.read_pickle('./train_X_ord_makeUSJap.pkl')\ntest_X_make=pd.read_pickle('./test_X_ord_makeUSJap.pkl')\n\nprint(train_X.shape)\nprint(train_X_make.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a6a3a9e88a39bcef6b474ebfebf8c9c8086ca8e2"},"cell_type":"markdown","source":"**Linear Regression**\nWe fit Sklearn LinearRegression and use this to make predictions on the test data and check the RMSE Use train X data with make and without make, and Test Y as MSRP as well as Log MSRP and compare the RMSE values on test data"},{"metadata":{"trusted":true,"_uuid":"4400d71321fbbd11295a8697536acea0d0602073","collapsed":true},"cell_type":"code","source":"#fit train data without make info, and log MSRP\nlin_reg = LinearRegression()\nlin_reg.fit(train_X, train_Y)\n\n#fit train data without make and MSRP, as it\nlin_reg_1 = LinearRegression()\nlin_reg_1.fit(train_X, train_Y_orig)\n\n#fit train data with make and log MSRP\nlin_reg_make = LinearRegression()\nlin_reg_make.fit(train_X_make, train_Y)\n\n#fit train data with make and MSRP, as it\nlin_reg_make1 = LinearRegression()\nlin_reg_make1.fit(train_X_make, train_Y_orig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a2d4a6e441548ca4fdc56f45b51597912a03c694","collapsed":true},"cell_type":"code","source":"carSales_predictions = lin_reg.predict(test_X)\nlin_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions))\nlin_rmse = np.sqrt(lin_mse)\nprint(\"rmse without make, log MSRP:\"+str(lin_rmse))\n\ncarSales_predictions = lin_reg_1.predict(test_X)\nlin_mse = mean_squared_error(test_Y, carSales_predictions)\nlin_rmse = np.sqrt(lin_mse)\nprint(\"rmse without make, MSRP, as is:\"+str(lin_rmse))\n\ncarSales_predictions = lin_reg_make.predict(test_X_make)\nlin_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions))\nlin_rmse = np.sqrt(lin_mse)\nprint(\"rmse with make, log MSRP:\"+str(lin_rmse))\n\ncarSales_predictions = lin_reg_make1.predict(test_X_make)\nlin_mse = mean_squared_error(test_Y, carSales_predictions)\nlin_rmse = np.sqrt(lin_mse)\nprint(\"rmse with make, MSRP, as is:\"+str(lin_rmse))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"adeeeca3981d33f5d122328a6a361918aaa02c35"},"cell_type":"markdown","source":"We observe the data with make and log MSRP gives best results, as we found in our analysis. Next we use SGDRegressor from scikit learn and compare the RMSE"},{"metadata":{"trusted":true,"_uuid":"a5a7012b8999d33836a8082c19636baf287bbaf6","collapsed":true},"cell_type":"code","source":"sgd_reg_make = SGDRegressor(max_iter=500,penalty=None,eta0=0.01)\nsgd_reg_make.fit(train_X_make, train_Y.values.ravel())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3a981e424e5ea0d44ebae1bcfa361bf135c334a6","collapsed":true},"cell_type":"code","source":"carSales_predictions_make = sgd_reg_make.predict(test_X_make)\nsgd_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions_make))\nsgd_rmse = np.sqrt(sgd_mse)\nprint(\"SGD RMSE:\"+str(sgd_rmse))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f6ecbc873adc7103c669646d31515575694d1b60"},"cell_type":"markdown","source":"**Decision Tree Regressor**"},{"metadata":{"trusted":true,"_uuid":"8de221c0126adc6a313b91b03a19e6b90dfee976","collapsed":true},"cell_type":"code","source":"tree_reg = DecisionTreeRegressor()\ntree_reg.fit(train_X,train_Y)\n\ntree_reg_make = DecisionTreeRegressor()\ntree_reg_make.fit(train_X_make,train_Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4175495aecc8672d6d25b23de2286792be0e8015","collapsed":true},"cell_type":"code","source":"carSales_predictions = tree_reg.predict(test_X)\ntree_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions))\ntree_rmse = np.sqrt(tree_mse)\nprint(\"Decision Tree RMSE, without make:\"+str(tree_rmse))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c804e1eacb0670f5d8b9e4c7ac5fe2721e2e12c1","collapsed":true},"cell_type":"code","source":"carSales_predictions_make = tree_reg_make.predict(test_X_make)\ntree_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions_make))\ntree_rmse = np.sqrt(tree_mse)\nprint(\"Decision Tree RMSE, with make:\"+str(tree_rmse))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"89e43c8397e5930cc2b3fc3590fdbb6b301cf353","collapsed":true},"cell_type":"code","source":"#Lets print few predicted prices and actual prices\nprint(\"predicted prices\")\nprint(np.around(np.exp(carSales_predictions_make[0:5])))\nprint(\"actual prices\")\nprint(np.exp(test_Y[0:5]))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7a6185352e5802d55d1e2c93d348cfde69b959ce"},"cell_type":"markdown","source":"We find Decision tree with make data included reduces the RMSE and is the best so far. We validate this using K-fold Cross validation with k set to 10"},{"metadata":{"trusted":true,"_uuid":"550476cf7905e644bf14bc9788b29141bd009cfd","collapsed":true},"cell_type":"code","source":"scores = cross_val_score(tree_reg_make,train_X_make,train_Y,scoring=\"neg_mean_squared_error\",cv=10)\ntree_rmse_scores = np.sqrt(-scores)\n\nprint(\"scores:\",tree_rmse_scores)\nprint(\"mean:\",tree_rmse_scores.mean())\nprint(\"std dev:\",tree_rmse_scores.std())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"09d4edba35315bd76aed1eb8f8a72835eaeadb24"},"cell_type":"markdown","source":"This shows there is a good fit, and there is very less variation between the folds and the data is dependable. We now try RandomForestRegressor, with default parameters"},{"metadata":{"_uuid":"62e1f8243a858e047fa89ea37056768f43d1ac88"},"cell_type":"markdown","source":"**RandomForestRegressor**"},{"metadata":{"trusted":true,"_uuid":"912989bd8c439f9b2d4620e47d3866ec50af8014","collapsed":true},"cell_type":"code","source":"forest_reg_make = RandomForestRegressor()\nforest_reg_make.fit(train_X_make,train_Y.values.ravel())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a71b780e7823668121bd932f7369d458b1e9bedd","collapsed":true},"cell_type":"code","source":"carSales_predictions = forest_reg_make.predict(test_X_make)\nforest_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions))\nforest_rmse = np.sqrt(forest_mse)\nprint(\"Random Forest Regressor RMSE, with make:\"+str(forest_rmse))\nprint(\"predicted prices\")\nprint(np.around(np.exp(carSales_predictions[0:5])))\nprint(\"actual prices\")\nprint(np.exp(test_Y[0:5]))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"700c4d42c6cd038433ff38c9672337a0f82e67e1"},"cell_type":"markdown","source":"This is clearly a better fit compared to DecisionTree, and we validate this with k-fold CV"},{"metadata":{"trusted":true,"_uuid":"3c0f04107f530696a7642f9d3a220aafe5c17d73","collapsed":true},"cell_type":"code","source":"forest_scores = cross_val_score(forest_reg_make,train_X_make,train_Y.values.ravel(),scoring=\"neg_mean_squared_error\",cv=10)\nforest_rmse_scores = np.sqrt(-forest_scores)\n\nprint(\"scores:\",forest_rmse_scores)\nprint(\"mean:\",forest_rmse_scores.mean())\nprint(\"std dev:\",forest_rmse_scores.std())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"951f6b3c270ac78b4428500ad15180a7308e3b78"},"cell_type":"markdown","source":"We now use **GridSearch **to find the optimum parameters for RandomForestRegression"},{"metadata":{"trusted":true,"_uuid":"d9fe6a3685d4c370b45293a36e9ce0de7fde4bb7","collapsed":true},"cell_type":"code","source":"param_grid = [\n    # try 12 (3Ã—4) combinations of hyperparameters\n    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n    # then try 6 (2Ã—3) combinations with bootstrap set as False\n    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n  ]\n\nforest_reg = RandomForestRegressor(random_state=42)\n# train across 5 folds, that's a total of (12+6)*5=90 rounds of training \ngrid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n                           scoring='neg_mean_squared_error', return_train_score=True)\ngrid_search.fit(train_X_make, train_Y.values.ravel())\nprint(\"BEST PARAMETERS FOR RANDOM FOREST REGRESSOR IS:\")\ngrid_search.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0b35d2dd7dab6422b3f13b6934ea4b0c0cb9650b","collapsed":true},"cell_type":"code","source":"#Fit using best parameters and check\nforest_reg_make = RandomForestRegressor(max_features=8,n_estimators=30)\nforest_reg_make.fit(train_X_make,train_Y.values.ravel())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"30c64221fb5e536dfaa6101dcda6303d343bbc2d","collapsed":true},"cell_type":"code","source":"carSales_predictions = forest_reg_make.predict(test_X_make)\nforest_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions))\nforest_rmse = np.sqrt(forest_mse)\nprint(\"Random Forest Regressor RMSE, with make:\"+str(forest_rmse))\nprint(\"predicted prices\")\nprint(np.around(np.exp(carSales_predictions_make[0:5])))\nprint(\"actual prices\")\nprint(np.exp(test_Y[0:5]))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b0c80503ecd4933ccc5165dd3daaa529971e8f10"},"cell_type":"markdown","source":"The observation is : Default parameters gives better results."},{"metadata":{"_uuid":"cda8ead892138d965aeee32568e97e4ce6b42910"},"cell_type":"markdown","source":"**Feature importance** derivation"},{"metadata":{"trusted":true,"_uuid":"ddcd43f76718246d37dfa19b466d0d5faa127933","collapsed":true},"cell_type":"code","source":"feature_importances = grid_search.best_estimator_.feature_importances_\nnum_attribs = [\"Age\",\"City MPG\",\"Engine HP\"]\ncategorical_attribs = [  '0.' , ' 3.',   '4.' ,  '5.' ,  '6.',   '8.' , '10.', '12.'] + ['diesel', 'electric' ,'flex-fuel (unleaded/E85)',\n 'flex-fuel (unleaded/natural gas)' ,'natural gas', 'premium unleaded (recommended)', 'premium unleaded (required)',\n 'regular unleaded'] + ['AUTOMATED_MANUAL' ,'AUTOMATIC' ,'DIRECT_DRIVE' ,'MANUAL', 'UNKNOWN'] + ['all wheel drive','four wheel drive', 'front wheel drive', 'rear wheel drive'] + ['Compact' ,'Large', 'Midsize']+['2dr Hatchback', '2dr SUV' ,'4dr Hatchback', '4dr SUV', 'Cargo Minivan',\n 'Cargo Van', 'Convertible', 'Convertible SUV' ,'Coupe', 'Crew Cab Pickup','Extended Cab Pickup' ,'Passenger Minivan' ,'Passenger Van','Regular Cab Pickup', 'Sedan' ,'Wagon']+['Ford','Chevrolet','Chrysler','Pontiac','Subaru','Hyundai','Honda','Mazda', 'Nissan','Suzuki']\nattributes = num_attribs+categorical_attribs\nprint(sorted(zip(feature_importances, attributes), reverse=True))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"16f07dd55a805a4cf8f4eca8bebc7fb5e0de3828"},"cell_type":"markdown","source":"This shows the best predictors are Age, Engine HP, Transmission, Fuel Type, City MPG, Drive, Size, MAke, Style. We do retain all parameters in the prediction."},{"metadata":{"trusted":true,"_uuid":"0cf735fea9b83db858b9054b6836b0aadd4a5fcf","collapsed":true},"cell_type":"code","source":"final_model = grid_search.best_estimator_\nfinal_predictions = final_model.predict(test_X_make)\nfinal_mse = mean_squared_error(np.exp(test_Y), np.exp(final_predictions))\nfinal_rmse = np.sqrt(final_mse)\nprint(\"Random Forest Regressor Final RMSE:\"+str(final_rmse))\nprint(\"predicted prices\")\nprint(np.around(np.exp(final_predictions[0:5])))\nprint(\"actual prices\")\nprint(np.exp(test_Y[0:5]))\n\n\nfinal_model_scores = cross_val_score(final_model,test_X_make,test_Y.values.ravel(),scoring=\"neg_mean_squared_error\",cv=10)\nfinal_model_scores = np.sqrt(-final_model_scores)\n\nprint(\"scores:\",final_model_scores)\nprint(\"mean:\",final_model_scores.mean())\nprint(\"std dev:\",final_model_scores.std())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d0db49013709bb77124e1c352d97e07a3107d88c"},"cell_type":"markdown","source":"We find the model is fitting quite well. We plot the learning curves for the best model and see the learning curve, by plotting the rmse vs size of training set"},{"metadata":{"trusted":true,"_uuid":"caccf221b70961f37c1a1f0d80970321b24640d4","collapsed":true},"cell_type":"code","source":"def plot_learning_curves(model, X, y):\n    \n    train_errors, val_errors = [], []\n    for m in range(1, len(X)):\n        model.fit(X[:m], y[:m].values.ravel())\n        y_train_predict = model.predict(X[:m])\n        y_val_predict = model.predict(test_X_make)\n        train_errors.append(mean_squared_error(y[:m], y_train_predict))\n        val_errors.append(mean_squared_error(test_Y, y_val_predict))\n\n    plt.plot(np.sqrt(train_errors), \"r-+\", linewidth=2, label=\"train\")\n    plt.plot(np.sqrt(val_errors), \"b-\", linewidth=3, label=\"val\")\n    plt.legend(loc=\"upper right\", fontsize=14)   \n    plt.xlabel(\"Training set size\", fontsize=14) \n    plt.ylabel(\"RMSE\", fontsize=14)   \n\nplot_learning_curves(final_model, train_X_make, train_Y)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e3a47e5cbdb9d05189027c6d6a59260daf774d0e","collapsed":true},"cell_type":"code","source":"#We try ElasticNet\nfrom sklearn.linear_model import ElasticNet\nelastic_net = ElasticNet(alpha=0.1, l1_ratio=0.5, random_state=42)\nelastic_net.fit(train_X_make, train_Y)\ncarSales_predictions = elastic_net.predict(test_X_make)\nelastic_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions))\nelastic_rmse = np.sqrt(elastic_mse)\nprint(\"Elastic Net RMSE:\"+str(elastic_rmse))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"33050c4711e543b8ddc9e93a12c8cd4f8a86f09d","collapsed":true},"cell_type":"code","source":"#We try Ridge Regression\nfrom sklearn.linear_model import Ridge\nridge_reg = Ridge(alpha=1, solver=\"cholesky\", random_state=42)\nridge_reg.fit(train_X_make, train_Y)\ncarSales_predictions = ridge_reg.predict(test_X_make)\nridge_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions))\nridge_rmse = np.sqrt(ridge_mse)\nprint(\"Ridge RMSE:\"+str(ridge_rmse))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6f863a8c7e128a310bed8e4d57e54c79d487bf3f","collapsed":true},"cell_type":"code","source":"#We try Lasso Regression\nfrom sklearn.linear_model import Lasso\nlasso_reg = Lasso(alpha=0.1)\nlasso_reg.fit(train_X_make, train_Y)\ncarSales_predictions = lasso_reg.predict(test_X_make)\nlasso_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions))\nlasso_rmse = np.sqrt(lasso_mse)\nprint(\"Lasso RMSE:\"+str(lasso_rmse))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c9d8a2937fd3de3cb3dae0657ab686b77c1db58e"},"cell_type":"markdown","source":"We find these give worse results. We use GradientBoostingRegressor from sklearn finally"},{"metadata":{"_uuid":"3b36a71fb188a31b046f4e7e0ee8839cb42b2e65"},"cell_type":"markdown","source":"**Gradient Boosting Regressor**"},{"metadata":{"trusted":true,"_uuid":"1eb5022c4456187393bd16d03d7bda9038937545","collapsed":true},"cell_type":"code","source":"gbrt = GradientBoostingRegressor(max_depth=8, n_estimators=3, learning_rate=1.0, random_state=42)\ngbrt.fit(train_X_make, train_Y.values.ravel())\ncarSales_predictions = gbrt.predict(test_X_make)\ngbrt_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions))\ngbrt_rmse = np.sqrt(gbrt_mse)\nprint(\"Gradient Boosting Regressor RMSE:\"+str(gbrt_rmse))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1111760a38e613f84dfb3258122cfff247b1bf2b","collapsed":true},"cell_type":"code","source":"gbrt_slow = GradientBoostingRegressor(max_depth=30, n_estimators=200, learning_rate=0.1, random_state=42)\ngbrt_slow.fit(train_X_make, train_Y.values.ravel())\ncarSales_predictions = gbrt_slow.predict(test_X_make)\ngbrt_slow_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions))\ngbrt_slow_rmse = np.sqrt(gbrt_slow_mse)\nprint(\"Gradient Boosting Regressor SLOW RMSE:\"+str(gbrt_slow_rmse))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"51cc0443a27dfce716db6af914a30328850df2e4"},"cell_type":"markdown","source":"**GridSearch**"},{"metadata":{"trusted":true,"_uuid":"c5c07e30e9642aaf5760c0261c3c8bd7f703bf40","collapsed":true},"cell_type":"code","source":"param_grid = [\n    # try 2 (2Ã—2) combinations of hyperparameters\n    {'n_estimators': [100,200], 'max_depth': [20, 30]},\n    # then try 6 (2Ã—3) combinations with bootstrap set as False\n    #{'bootstrap': [False], 'n_estimators': [100,200], 'max_depth': [20, 30, 40]},\n  ]\n\ngbrt_reg = GradientBoostingRegressor(random_state=42, learning_rate=0.1)\n# train across 5 folds, that's a total of (4)*5=20 rounds of training \ngrid_search_gbrt = GridSearchCV(gbrt_reg, param_grid, cv=5,\n                           scoring='neg_mean_squared_error', return_train_score=True)\ngrid_search_gbrt.fit(train_X_make, train_Y.values.ravel())\nprint(\"BEST PARAMETERS FOR GRADIENT BOOSTING REGRESSOR IS:\")\ngrid_search_gbrt.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0f3595b00a222f027df5dc634b29be893ffcc8eb","collapsed":true},"cell_type":"code","source":"gbrt_slow = GradientBoostingRegressor(max_depth=20, n_estimators=100, learning_rate=0.1, random_state=42)\ngbrt_slow.fit(train_X_make, train_Y.values.ravel())\ncarSales_predictions = gbrt_slow.predict(test_X_make)\ngbrt_slow_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions))\ngbrt_slow_rmse = np.sqrt(gbrt_slow_mse)\nprint(\"Gradient Boosting Regressor BEST RMSE:\"+str(gbrt_slow_rmse))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2559aee03b05c60080930a35beb17fbcf37b321e"},"cell_type":"markdown","source":"**Deep Learning **technique. We use keras with tensorflow backend "},{"metadata":{"trusted":true,"_uuid":"920508da3d8ccf1c9ffb70a1dccfbb415e73d71c","collapsed":true},"cell_type":"code","source":"model = Sequential()\n\n#We use two hidden layers with 50 and 30 units with Relu activation, and no activation in the output layer, since \n#we want to predict the car price.\nmodel.add(Dense(50,input_dim=(train_X_make.shape[1]),activation='relu'))\nmodel.add(Dense(30,activation='relu'))\nmodel.add(Dense(1))\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"1e7d86c7ed67332b2c7ae9c9d4bb2ba7ccbdccef"},"cell_type":"code","source":"myOptimizer = optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=0.01, decay=0.0)\nmodel.compile(loss='mean_squared_error', optimizer=myOptimizer, metrics=['mse'])\nhistory = model.fit(train_X_make, train_Y, epochs=200,  validation_data=(test_X_make,test_Y), batch_size=5, verbose=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f96663922ee28c4961dba64d7008a00c934aba54","collapsed":true},"cell_type":"code","source":"plt.plot(history.history['loss'], color = 'blue')\nplt.plot(history.history['val_loss'], color=  'red')\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7b832a8f527f1c99e6c24246d50d374768d0fbb5","collapsed":true},"cell_type":"code","source":"carSales_predictions = model.predict(test_X_make)\ndl_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions))\ndl_rmse = np.sqrt(dl_mse)\nprint(\"Deep Learning RMSE with two hidden layers:\"+str(dl_rmse))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"576adc3d8e9212a0bee1c4409fa284ef553a4ca3","collapsed":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Dense(50,input_dim=(train_X_make.shape[1]),activation='relu'))\nmodel.add(Dense(20,activation='relu'))\nmodel.add(Dense(10,activation='relu'))\nmodel.add(Dense(1))\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"5362cd1d64a6613a98b007a14affaa2f0a7e41db"},"cell_type":"code","source":"myOptimizer = optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=0.01, decay=0.0)\nmodel.compile(loss='mean_squared_error', optimizer=myOptimizer, metrics=['mse'])\nhistory = model.fit(train_X_make, train_Y, epochs=300,  validation_data=(test_X_make,test_Y), batch_size=10, verbose=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"597f144538346d0d90a49272041af54c6db45b4f","collapsed":true},"cell_type":"code","source":"carSales_predictions = model.predict(test_X_make)\ndl_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions))\ndl_rmse = np.sqrt(dl_mse)\nprint(\"Deep Learning RMSE with three hidden layers:\"+str(dl_rmse))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e577a69f0859f3387a814db5e08c76e7a3e250e9"},"cell_type":"markdown","source":"We now try XGBRegressor, a latest technique. We start by default setting and then use best parameter for n_estimator by trying number of values"},{"metadata":{"trusted":true,"_uuid":"95687f7d8a900d0bbd40b3c2a729104807028195","collapsed":true},"cell_type":"code","source":"xgb_model = XGBRegressor() \nxgb_model.fit(train_X_make, train_Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ec4e81c0389cb692047ec43223ff5a1c4d1184c5","collapsed":true},"cell_type":"code","source":"carSales_predictions = xgb_model.predict(test_X_make)\nxgb_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions))\nxgb_rmse = np.sqrt(xgb_mse)\nprint(\"XGB RMSE:\"+str(xgb_rmse))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e171c4d9b100491ba0d313999a08ad540ecb589e","collapsed":true},"cell_type":"code","source":"xgb_model = XGBRegressor(n_estimators=350, max_depth=5) \nxgb_model.fit(train_X_make, train_Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0a57a67628554bb55707cdb4d226351c25ea1bd2","collapsed":true},"cell_type":"code","source":"carSales_predictions = xgb_model.predict(test_X_make)\nxgb_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions))\nxgb_rmse = np.sqrt(xgb_mse)\nprint(\"XGB RMSE, with n_estmators=350,max_depth=5:\"+str(xgb_rmse))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"476946c342d839a5c2c26e587d66e933542fd5ac","collapsed":true},"cell_type":"code","source":"xgb_model = XGBRegressor(n_estimators=350, max_depth=10) \nxgb_model.fit(train_X_make, train_Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"be1257ec2cccfb63abf1c1cb283541422a3f8f42","collapsed":true},"cell_type":"code","source":"carSales_predictions = xgb_model.predict(test_X_make)\nxgb_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions))\nxgb_rmse = np.sqrt(xgb_mse)\nprint(\"XGB RMSE, with n_estmators=350,max_depth=10:\"+str(xgb_rmse))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5261090ffaf39052423633b768a5465fcad4437d"},"cell_type":"markdown","source":"We conclude the setting of n_estimators=350 and max_depth=5 works best in this case, and this model is the best amongst all the models compared."},{"metadata":{"_uuid":"e1471d3037c53d13c6aab9f7cbded29da0eb9371"},"cell_type":"markdown","source":"We now calculate and display** feature importances** from the XGBoost model"},{"metadata":{"trusted":true,"_uuid":"b8d42afcdfec389bc89f7379635634ad3cbe8df3","collapsed":true},"cell_type":"code","source":"xgb_model = XGBRegressor(n_estimators=350, max_depth=5) \nxgb_model.fit(train_X_make, train_Y)\nprint(xgb_model.feature_importances_)\n# plot\nplt.bar(range(len(xgb_model.feature_importances_)), xgb_model.feature_importances_)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"866b74a76a2527bce0b1b340f95e30faae4db4cb"},"cell_type":"markdown","source":"We see that the numerical features, Engine HP, Age, City MPG has the highest importances, followed by categorical features. Among the categorical features we find the Engine Cylinder, and Engine Fuel Type has least importance. Transmission type, and Size, and Make have high importances. We drop the Engine Cylinder from Train and Test data and fit our model again.\nWe recall the order of Categorical variables is : [ 0. 3. 4. 5. 6. 8. 10. 12.] ['diesel' 'electric' 'flex-fuel (unleaded/E85)' 'flex-fuel (unleaded/natural gas)' 'natural gas' 'premium unleaded (recommended)' 'premium unleaded (required)' 'regular unleaded'] ['AUTOMATED_MANUAL' 'AUTOMATIC' 'DIRECT_DRIVE' 'MANUAL' 'UNKNOWN'] ['all wheel drive' 'four wheel drive' 'front wheel drive' 'rear wheel drive'] ['Compact' 'Large' 'Midsize'] ['2dr Hatchback' '2dr SUV' '4dr Hatchback' '4dr SUV' 'Cargo Minivan' 'Cargo Van' 'Convertible' 'Convertible SUV' 'Coupe' 'Crew Cab Pickup' 'Extended Cab Pickup' 'Passenger Minivan' 'Passenger Van' 'Regular Cab Pickup' 'Sedan' 'Wagon'] ['Ford','Chevrolet','Chrysler','Pontiac','Subaru','Hyundai','Honda','Mazda', 'Nissan','Suzuki']"},{"metadata":{"_uuid":"3c582d7c5fb8291c20845ce955dbb745455a57f3"},"cell_type":"markdown","source":"We drop Engine cylinder from set of features and recalculate RMSE"},{"metadata":{"trusted":true,"_uuid":"5603b0326c648e1ab648fcdf0760c18a1f61e895","collapsed":true},"cell_type":"code","source":"print(train_X_make.shape[1])\ntrain_X_make_upd = np.delete(train_X_make,[4,5,6,7,8,9,10,11],1) # we drop the 8 columns after the first 6 numeric ones\nprint(train_X_make_upd.shape[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"35da6779ca23e7a4c59b12029f71be1d082b9f09"},"cell_type":"code","source":"test_X_make_upd = np.delete(test_X_make,[4,5,6,7,8,9,10,11],1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ac4ff44d80a6b696033ec83daf59142efe9c7457","collapsed":true},"cell_type":"code","source":"xgb_model = XGBRegressor(n_estimators=350, max_depth=5) \nxgb_model.fit(train_X_make_upd, train_Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"99339052fcb18ca5fadac76786b121c50cfae974","collapsed":true},"cell_type":"code","source":"carSales_predictions = xgb_model.predict(test_X_make_upd)\nxgb_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions))\nxgb_rmse = np.sqrt(xgb_mse)\nprint(\"XGB RMSE, with n_estmators=350,max_depth=5:\"+str(xgb_rmse))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"35ab47f18dd7a947009c6d4c1da2a88904f23157"},"cell_type":"markdown","source":"We find removing the Engine cylinder categorical variable, does not have any effect on the model. We now try removing the Engine fuel type categorical variable"},{"metadata":{"trusted":true,"_uuid":"8a0bba30335282901653fdb68e41bf98c7cda6cf","collapsed":true},"cell_type":"code","source":"print(train_X_make.shape[1])\ntrain_X_make_upd1 = np.delete(train_X_make,[4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],1) # we drop the 8 columns after the first 3 numeric ones\nprint(train_X_make_upd1.shape[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"62f62397b9211a329bbc2160f75ba9102a3ab1af"},"cell_type":"code","source":"test_X_make_upd1 = np.delete(test_X_make,[4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d75bd86ecfbcc3798b4b55b53ff12f32b759ce80","collapsed":true},"cell_type":"code","source":"xgb_model = XGBRegressor(n_estimators=350, max_depth=5) \nxgb_model.fit(train_X_make_upd1, train_Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a7a69105851048810ce96596bdd00df07974b0e1","collapsed":true},"cell_type":"code","source":"carSales_predictions = xgb_model.predict(test_X_make_upd1)\nxgb_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions))\nxgb_rmse = np.sqrt(xgb_mse)\nprint(\"XGB RMSE, with n_estmators=350,max_depth=5:\"+str(xgb_rmse))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7090a046af063dea2758af61129ad4dff74f1117"},"cell_type":"markdown","source":"We find removing the Engine Fuel Type categorical variable, has no effect on accuracy. \nWe decide to drop the Engine Cylinder, and retain Engine Fuel Type based on this analysis from our original set of parameters."},{"metadata":{"_uuid":"1f2cbd3f438dfb47cdf492a4d38c3d91325d3350"},"cell_type":"markdown","source":"So our final model has the numerical parameters :log Engine HP, Age of Car, log City MPG\nand the categorical parameters : Engine Fuel Type,Transmission Type, Driven Wheels, Vehicle Size, Vehicle Style and Make"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a063fbd43bc470f31448ff0485511ccaf06b118d"},"cell_type":"code","source":"# save model to file\npickle.dump(xgb_model, open(\"./carsales_xgb.pickle.dat\", \"wb\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"5401aa6cf21bcf273d8e27f1cba6e3eac8a2d2f3"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}