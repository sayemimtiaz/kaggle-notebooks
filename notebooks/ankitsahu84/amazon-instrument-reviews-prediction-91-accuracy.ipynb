{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#All the imports for this program\nimport numpy as np # linear algebra\nimport pandas as pd \nimport os\nimport random\nfrom sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\nfrom sklearn.feature_selection import chi2\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import  accuracy_score,recall_score,precision_score,f1_score,roc_auc_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns \n\n#Check for files present\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"random.seed(30)\n#read review data \nreviews = pd.read_csv(\"../input/amazon-music-reviews/Musical_instruments_reviews.csv\")\n\nreviews.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#remove unncessary features\ndel reviews['reviewerID']\ndel reviews['asin']\ndel reviews['unixReviewTime']\ndel reviews['reviewTime']\ndel reviews['reviewerName']\ndel reviews['helpful']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#check for missing value\nreviews.isna().sum()\n\n#fill in missing values with \"\"\nreviews.reviewText.fillna(\"\",inplace = True)\n\n#combine the summary with review text and delete the summary and reviewText fiels\nreviews['review'] = reviews['reviewText'] + ' ' + reviews['summary']\ndel reviews['reviewText']\ndel reviews['summary']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#for ratings 4 & 5 consider then good 1 otherwise bad 0\nreviews['overall'] = (reviews['overall'] >3).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#At this point we have the overall field which is binary and review which is a text field\nreviews.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets check the distribution of good and bad reviews\nreviews.overall.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets prep the data for modeling\n\ntfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english')\n\nfeatureCounts = tfidf.fit_transform(reviews.review)\n\ntfidf_transformer = TfidfTransformer()\n\nfeatures = tfidf_transformer.fit_transform(featureCounts)\n\nlabels = reviews.overall\nfeatures.shape\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#use chi square test to list out the words used for good and bad reviews\nN = 2\n\nfor i in range(2):\n    features_chi2 = chi2(features, labels == i)\n    indices = np.argsort(features_chi2[i])\n    feature_names = np.array(tfidf.get_feature_names())[indices]\n    unigrams = [v for v in feature_names if len(v.split(' ')) == 1]\n    bigrams = [v for v in feature_names if len(v.split(' ')) == 2]\n    \n    print(\"# '{}':\".format(i))\n    print(\"  . Most correlated unigrams:\\n. {}\".format('\\n. '.join(unigrams[-N:])))\n    print(\"  . Most correlated bigrams:\\n. {}\".format('\\n. '.join(bigrams[-N:])))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#split the data for training and testing\nX_train, X_test, y_train, y_test = train_test_split(features, labels, random_state = 0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#I am planning to run multiple model and then choose the best, in order to do so let me write a function \n# which can train model, test the prediction, cross validate etc\n#please note that I am using stratified KFold because the distribution of classes is not normal\ndef performClassification(name, estimator, X, y, X_train, y_train, X_test, y_test):\n    \n    model = estimator.fit(X_train, y_train)\n    \n    y_pred = model.predict(X_test)\n    \n    kFold = StratifiedKFold(n_splits=8)\n    \n    cv_score = round((cross_val_score(estimator, X ,y.values.ravel(), cv=kFold, scoring='roc_auc').mean())*100,3)\n    \n    accuracy = round((accuracy_score(y_test, y_pred))*100,3)\n    \n    recall = round((recall_score(y_test, y_pred))*100,3)\n    \n    precision = round((precision_score(y_test, y_pred))*100,3)\n    f1 = round((f1_score(y_test, y_pred))*100,3)\n    \n    roc_auc = round((roc_auc_score(y_test, y_pred))*100,3)\n\n    returnArray = pd.array([name,cv_score,accuracy,recall,precision,f1,roc_auc])\n    \n    return returnArray\n\n#reate a data frame to store the scores\nmodelScores = pd.DataFrame(columns =['Name','CV','Accuracy','Recall','Precision','F1','Roc_Auc'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets try different models\n#execute models one by one\nlm = LogisticRegression()\nmodelScores = modelScores.\\\n    append(pd.Series(performClassification('Logistic Regression',lm,features,labels, X_train, y_train, X_test, y_test),\\\n                     index=modelScores.columns), ignore_index=True)\n\nMNB = MultinomialNB()\nmodelScores = modelScores.\\\n    append(pd.Series(performClassification('Multinomial Naive Bayes',MNB,features,labels, X_train, y_train, X_test, y_test),\\\n                     index=modelScores.columns), ignore_index=True)\n        \nSVC = LinearSVC()\nmodelScores = modelScores.\\\n    append(pd.Series(performClassification('Linear SVM',SVC,features,labels, X_train, y_train, X_test, y_test),\\\n                     index=modelScores.columns), ignore_index=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets check the outcome\nprint(modelScores)\n#we can choose model based on multiple scores here, I would go ahead and choose Linear SVM base don ROc_AUC score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see, the best model is Linear SVM with 91% accuracy","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets first check the classifucation report\ny_pred = SVC.predict(X_test)\n\nprint(metrics.classification_report(y_test, y_pred, target_names=reviews['overall'].unique().astype(str)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#now lets buld the confusion matrix and plot the heatmap\nconf_mat = confusion_matrix(y_test, y_pred)\ntn, fp, fn, tp = conf_mat.ravel()\n(tn, fp, fn, tp)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I have tried to achieve few things in this notebook\n* run models and validate them using stratified Kfold cross validation\n* compare multiple models using f1 score, AUC and accuracy\n\nFew this I will try later,\n* use more models, use hyper parameter tuning for some of these models\n* clean up of data and use other ways to generate vectors from the text","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}