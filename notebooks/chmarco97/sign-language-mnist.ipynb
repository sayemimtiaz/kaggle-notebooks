{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Sign Language MNIST\nThe purpose of this notebook is about images classification through a Convolutionary Neural Network.<br>\nIn particular, in this case has been obtained the 100% accuracy on test data.\n\nImages are about sign language, every 28x28 image represets a particular alphabet letter. "},{"metadata":{},"cell_type":"markdown","source":"## Importing Data and Preprocessing"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\ntrain_data = pd.read_csv(\"/kaggle/input/sign-language-mnist/sign_mnist_train/sign_mnist_train.csv\", sep=\",\")\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = pd.read_csv(\"/kaggle/input/sign-language-mnist/sign_mnist_test/sign_mnist_test.csv\", sep=\",\")\n\ntrain_data.append(test_data)\ndataset = train_data\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Image examples\n**Let's visualize one image for each class**\n\n*N.B.*: there is no image for label *9* and *25*, or *J* and *Z*, because their representation require motions."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\n\nmapping_values = {\n    0:\"A\", 1:\"B\", 2:\"C\", 3:\"D\", 4:\"E\", 5:\"F\",\n    6:\"G\", 7:\"H\", 8:\"I\", 10:\"K\", 11:\"L\", 12:\"M\", 13:\"N\",\n    14:\"O\", 15:\"P\", 16:\"Q\", 17:\"R\", 18:\"S\", 19:\"T\", 20:\"U\",\n    21:\"V\", 22:\"W\", 23:\"X\", 24:\"Y\"}\n\nplt.figure(figsize=(10, 18))\nfor i in range(26):\n    if i in (9, 25): \n        continue\n    plt.subplot(7, 4, i+1)\n    plt.imshow(np.array(dataset[dataset.label == i].iloc[0,1:].values.tolist()).reshape(28,28), cmap='Greys')\n    plt.xticks([])\n    plt.yticks([])\n    plt.title(mapping_values[i])\n\nplt.show()    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Defining Training, Validation and Test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"y = dataset.label\ndataset.drop(\"label\", axis=1, inplace=True)\nX = dataset","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's define train and test dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nprint(X_train.shape, X_test.shape, y_train.shape, y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Then, from train data let's extract a validation set for learning process."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = X_train.to_numpy().reshape(-1, 28,28, 1) # 28*28\nX_test = X_test.to_numpy().reshape(-1, 28,28, 1) # 28*28\nprint(X_train.shape, X_test.shape, y_train.shape, y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's normalize values, making them inside \\\\([0,1] \\in \\mathbb{R}\\\\).<br>\n*N.B.:* each pixel value is expressed as grey depth in 8bit, so values in \\\\([0, 255] \\in \\mathbb{N}\\\\)."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = X_train.astype('float32')\nX_test = X_test.astype('float32')\nX_train = X_train / 255.\nX_test = X_test / 255.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_valid,y_train,y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=13)\nprint(X_train.shape, X_test.shape, y_train.shape, y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Defining Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nimport tensorflow as tf\nfrom keras.models import Sequential,Input,Model\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.advanced_activations import LeakyReLU\n\nfrom tensorflow.python.client import device_lib \ndevice_lib.list_local_devices() # let's list all available computing devices","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's define basic learning parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 128\nepochs = 15\nnum_classes = 26","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here follows the model: a deep convolutionary neural network, with the following kind of layers:\n- **Conv2D**: convulutional layer. In the first layer the input is shaped (28, 28, 1): a 3D-object of 28x28x1, or simply a matrix 28x28;\n- **LeakyReLU**: this layer helps to manage non-linearity of data using a non linear activation function;\n- **MaxPooling2D**: used for reducing data dimensionality;\n- **Flatten**: number of units is proportional to input;\n- **Dense**: regular dense connected layer."},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(32, kernel_size=(3, 3),activation='linear',input_shape=(28,28,1),padding='same'))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(MaxPooling2D((2, 2),padding='same'))\nmodel.add(Conv2D(64, (3, 3), activation='linear',padding='same'))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\nmodel.add(Conv2D(128, (3, 3), activation='linear',padding='same'))\nmodel.add(LeakyReLU(alpha=0.1))                  \nmodel.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='linear'))\nmodel.add(LeakyReLU(alpha=0.1))                  \nmodel.add(Dense(num_classes, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss=keras.losses.sparse_categorical_crossentropy, \n              optimizer=keras.optimizers.Adam(),\n              metrics=['accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Training"},{"metadata":{},"cell_type":"markdown","source":"Let's train the model. I've used GPU for training: each epoch takes about ~2s to complete, against ~35s while using CPU."},{"metadata":{"trusted":true},"cell_type":"code","source":"with tf.device('/GPU:0'):\n    model_train = model.fit(X_train, y_train, \n                            batch_size=batch_size,\n                            epochs=epochs,\n                            verbose=1,\n                            validation_data=(X_valid, y_valid))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualizing Learning Process "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(7, 7), dpi=80)\nplt.subplot(2,1,1)\nplt.title(\"Training History - Accuracy\")\nplt.plot(range(epochs), model_train.history[\"accuracy\"], label=\"accuracy\", color=\"red\")\nplt.scatter(range(epochs), model_train.history[\"val_accuracy\"], label=\"val_accuracy\")\nplt.xticks(range(0,epochs,1))\nmin_y = min(np.min(model_train.history[\"val_accuracy\"]), np.min(model_train.history[\"accuracy\"]))\nplt.yticks(np.linspace(min_y-0.1,1,11))\nplt.legend()\n\n\nplt.subplot(2,1,2)\nplt.title(\"Training History - Loss\")\nplt.plot(range(epochs), model_train.history[\"val_loss\"], label=\"val_loss\", color=\"red\")\nplt.scatter(range(epochs), model_train.history[\"loss\"], label=\"loss\")\nplt.xticks(range(0,epochs,1))\nmax_y = max(np.max(model_train.history[\"val_loss\"]), np.max(model_train.history[\"loss\"]))\nplt.yticks(np.linspace(0,max_y+0.1,11))\nplt.legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model Evaluation"},{"metadata":{},"cell_type":"markdown","source":"Now let's evaluate the model on test data."},{"metadata":{"trusted":true},"cell_type":"code","source":"test_eval = model.evaluate(X_test, y_test, verbose=0)\nprint('Test loss:', test_eval[0])\nprint('Test accuracy:', test_eval[1]*100, \"%\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\n\ny_pred = np.argmax(np.round(model.predict(X_test)), axis=1)\n\ntarget_names = [\"Class {}\".format(i) for i in range(num_classes)]\nprint(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Confusion Matrix**<br>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport seaborn as sn\n\nplt.figure(figsize=(9, 7))\ncf = confusion_matrix(y_test, y_pred)\nsn.heatmap(cf, annot=True)\nplt.title(\"Confusion Matrix\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see, there are **no errors** and **100%** accuracy is reached."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}