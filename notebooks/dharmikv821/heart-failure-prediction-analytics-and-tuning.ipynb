{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Import Data and Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nsns.set_style('darkgrid')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/heart-failure-clinical-data/heart_failure_clinical_records_dataset.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,6))\nsns.heatmap(data.isna(),yticklabels=False, cmap='plasma')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,10))\nsns.heatmap(data.corr(),annot=True,cmap='coolwarm')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(data.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['DEATH_EVENT'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['DEATH_EVENT'].value_counts()/len(data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The data has in total 299 instances and 13 features.\nOut of 13, 6 are categorical features and 7 are numeric features.\nThere are no NULL values in the dataset.\nThis cn be considered a balanced dataset as the ration is 1:3 and there are pretty much instances to train the model for both the categorical values. \n0 : False (203)\n1 : True  (096)\nThe independent variable is 'DEATH_EVENT' indicating whether the patient expired or not."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"cat_features = ['anaemia','diabetes','high_blood_pressure','sex','smoking']\nfor cat in cat_features:\n    sns.countplot(data[cat], hue=data.DEATH_EVENT)\n    plt.title(cat.upper()+' (w.r.t. DEATH_EVENT)')\n    plt.show()\n    print(data.groupby(cat)['DEATH_EVENT'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Anaemia : The risk of heart failure is more than if the person has anaemia. There are approx. 33% chances of death if the person has anaemia.\n\nDiabetes : Like anaemia, diabetes also responsible for the heart failure. About 33% of total people having diabetes can die of heart failure.\n\nHigh BP : More than 33% people with High BP problem can die of heart failure. \n\nSex : There is no relation between sex of a person and heart failure as both the gender has almost same risk of havig heart failure.\n\nSmoking : There are approx 33% chances of a smoker to die of heart failure.\n\nSo, the statistics of all of the categorical features leading to death is almost same."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(data.age,bins=15)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"for cat in cat_features:\n    plt.figure(figsize=(15,6))\n    plt.subplot(1,2,1)\n    sns.distplot(data[data[cat]==0]['age'],label=0,color='blue',bins=15)\n    plt.legend()\n    plt.title(cat.upper())\n    plt.subplot(1,2,2)\n    sns.distplot(data[data[cat]==1]['age'],label=1,color='red',bins=15)\n    plt.legend()\n    plt.title(cat.upper())\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Mostly people having anaemia are of age range 47 to 66 years.\n\nMostly diabetic patients are of age range 43 to 72 years.\n\nMostly people having High Blood Pressure are of age range 43 to 78 years.\n\nMostly males are of age range 54 to 64 years.\n\nMostly smokers are of age range 50 to 72 years."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"cont_features = ['age','creatinine_phosphokinase','ejection_fraction','platelets','serum_creatinine','serum_sodium','time']\nfor col in cont_features:\n    plt.figure(figsize=(15,6))\n    plt.subplot(1,2,1)\n    sns.distplot(data[data['DEATH_EVENT']==0][col],label=0,color='blue',bins=10)\n    plt.legend()\n    plt.title(col.upper())\n    plt.subplot(1,2,2)\n    sns.distplot(data[data['DEATH_EVENT']==1][col],label=1,color='red',bins=10)\n    plt.legend()\n    plt.title(col.upper())\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Age wise, most of the deaths is between the range of 40 and 80.\n\nPeople with low level of Creatinine Phosphokinase (about 0-800 mcg/L) have mostly died due to heart failure.\n\nThe ejection fraction of blood from heart of about 14-60% has led to heart failure.\n\nThere is a normal distribution for platelet counts from 0 to 600000 and most people with counts of 150000-350000 have resulted in heart failure.\n\nThe level of serum creatinine of about 0.8 to 2.3 mg/dL had heart failure.\n"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"for col in cont_features:\n    plt.boxplot(data[col])\n    plt.title(col.upper())\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All the continuous value features have outliers.\n\nAll the features except age and time have the most outliers."},{"metadata":{},"cell_type":"markdown","source":"### Model Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data.iloc[:,:-1].values\ny = data.iloc[:,-1].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier(n_estimators=100, random_state=0)\nrfc.fit(X_train, y_train)\npred = rfc.predict(X_test)\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\nprint(confusion_matrix(y_test, pred))\nprint(accuracy_score(y_test, pred))\nprint(classification_report(y_test, pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nval_score = cross_val_score(estimator=rfc,X=X_train,y=y_train,cv=10,n_jobs=-1)\nval_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Hyper Parameter Tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc = RandomForestClassifier()\nrf_params = {'n_estimators':[i for i in range(100,1000,10)],\n          'criterion':['gini','entropy'],\n          'max_features':['auto','sqrt','log2'],\n          'max_depth':[i for i in range(10,1000,10)],\n          'min_samples_split':[2,4,6,8,10],\n          'min_samples_leaf':[1,2,3,4,5,6,7,8,9,10]\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\nrs = RandomizedSearchCV(estimator=rfc,n_jobs=-1,cv=10,n_iter=100,param_distributions=rf_params,verbose=5,random_state=0)\nrs.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rs.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rs.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Tuned Model Prdiction"},{"metadata":{"trusted":true},"cell_type":"code","source":"best = rs.best_estimator_\ny_pred = best.predict(X_test)\nprint(confusion_matrix(y_test, y_pred))\nprint(accuracy_score(y_test, y_pred))\nprint(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### So the default model (85.33%) gave more accuracy than the hyper parameter tuned model (84%)."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}