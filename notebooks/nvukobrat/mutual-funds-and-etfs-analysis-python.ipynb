{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Dependencies"},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\nimport random\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nfrom IPython.display import Markdown, display\nfrom sklearn import metrics\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder, MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import linear_model, svm\n\n%matplotlib inline\nrnd_seed_state = 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Configuration\n**The first step is the initial general pre-execution configuration of the notebook.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def pre_config():\n    \"\"\"\n    Does initial general pre-execution configuration.\n    \"\"\"\n    plt.rcParams.update({'font.size': 20})\n    random.seed(rnd_seed_state)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pre_config()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Loading dataset\n**Then datasets are loaded (ETFs and Mutual Fund's).**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_dataset():\n    \"\"\"\n    Loads ETFs and Mutual Fund's datasets.\n    \n    Returns:\n        ETF and MF DataFrames.\n    \"\"\"\n    df_etf = pd.read_csv('/kaggle/input/mutual-funds-and-etfs/ETFs.csv', index_col=False)\n    df_mf = pd.read_csv('/kaggle/input/mutual-funds-and-etfs/Mutual Funds.csv', index_col=False)\n\n    return df_etf, df_mf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_etf, df_mf = load_dataset()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ETFs Visualization\n**Each dataset attribute could be numerical or \ncategorical. Below is a list of all attributes \nand their types for ETFs.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def types(df):\n    \"\"\"\n    Prints DataFrame attribute types (numerical or \n    categorical) to the stdout.\n    \n    Arguments:\n        df: Dataset pandas DataFrame.        \n    \"\"\"\n    for c, t in zip(df, df.dtypes):\n        if np.issubdtype(t, np.number):\n            print(\"Num\", c, t)\n        else:\n            print(\"Cat\", c, t)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# types(df_etf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Extended descriptions\n**Bellow is an extended description that differs \nbased on column type (numerical or categorical). \nThis is used to gain more insights into the data.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def describe(df):\n    \"\"\"\n    Describes in more detail each attribute of \n    the referent DataFrame. These descriptions \n    differ based on the attribute type.\n    \n    Arguments:\n        df: Dataset pandas DataFrame.\n    \"\"\"\n    print(\"DataFrame summary:\")\n    print(df.info())\n    print()\n\n    print(\"Columns summary:\")\n    for col in list(df):\n        print(col)\n        print(df[col].dropna().describe())\n        print(df[col].dropna().value_counts())\n        print()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# describe(df_etf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Histograms and Bars\n**Here are visualized only attributes that have a \nsmaller number of unique properties within the \ndataset. Those visualizations does not contain \nall NaN values that are missing in each column. \nIn order to be able to train a model, those NaN \nvalues need to be handled. These steps will be \nshown in one of the next sections in this analysis.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def hist_bar_plot(df, rc_num=(2, 6), size=(16 * 3, 9 * 3), unique=True):\n    \"\"\"\n    Creates histogram and bar visualizations for \n    a given DataFrame. Depending on the DataFrame \n    attribute type, numerical or categorical, it \n    creates a histogram or bar plot respectively.\n    \n    Arguments:\n        df: Dataset pandas DataFrame.\n        rc_num: Number of rows and columns.\n        size: Size of the plot.\n        unique: If True, it reduces the number of \n        attributes that will be visualized using \n        the number of unique values as a heuristic.\n    \"\"\"\n    # Chose adequate columns for visualization\n    if unique:\n        num_unique_col = df.nunique()\n        df = df[[col for col in df if 1 < num_unique_col[col] < 50]]\n\n    # Create Hist and Bar plots\n    plt.figure(figsize=size)\n    for i, col in enumerate(df):\n        plt.subplot(rc_num[0], rc_num[1], i + 1)\n        df_column = df[col]\n        if np.issubdtype(type(df_column.iloc[0]), np.number):\n            df_column.hist()\n        else:\n            df_column.value_counts().plot.bar()\n        plt.title(col, fontsize=25)\n        plt.xticks(rotation=30, fontsize=30)\n        plt.yticks(fontsize=30)\n        plt.ylabel('counts')\n\n        if i == 10:\n            break\n    plt.tight_layout(pad=1.0, w_pad=1.0, h_pad=1.0)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hist_bar_plot(df_etf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Cleaning data utilizing correlations\n**Correlation cleaning reduces the number of \ncolumns (attributes) that will be used in future\nanalysis or model training. Reduction works by \nfocusing only on columns that have a greater \ncorrelation (positive or negative) with other \ncolumns. Having this, only high important attributes \nare left to be utilized.**\n\n**One of the reasons is that in large dimension datasets, \nit takes too much time to train a model, and doesn't \nguarantee that the model will have high accuracy. Also, \nvisualization in slow and through to understand in high \ndimension datasets.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def correlation_clean(df, threshold=(-0.9, -0.3, 0.3, 0.9)):\n    \"\"\"\n    This dataset cleaning type reduces the number of \n    columns (attributes) that will be used in future\n    analysis or model training. Reduction works by \n    focusing only on columns that have a greater \n    correlation (positive or negative) with other \n    columns. Having this, only high important attributes \n    are left to be utilized. \n\n    One of the reasons is that in large dimension datasets, \n    it takes too much time to train a model, and doesn't \n    guarantee that the model will have high accuracy. Also, \n    visualization in slow and through to understand in high \n    dimension datasets.\n    \n    Arguments:\n        df: Dataset pandas DataFrame.\n        threshold:  Threshold for choosing columns based \n        on correlation score.\n    \n    Returns:\n        Cleaned dataset with high-correlated columns.\n    \"\"\"\n    # Fix for non-numerical (or too many nan) columns\n    col_corr = {\n        # ETFs\n        'fund_name', 'fund_extended_name', 'category', 'fund_family', 'net_assets', 'legal_type', 'investment', 'size',\n        'currency', 'rating_us_government', 'fund_treynor_ratio_3years', 'category_treynor_ratio_5years',\n    }\n    try:\n        for col in col_corr:\n            del df[col]\n    except KeyError:\n        pass  # legal_type\n\n    # Chose numerical columns\n    corr_matrix = df.corr()\n    for i in range(len(corr_matrix.columns)):\n        for j in range(i):\n            if (not threshold[0] <= corr_matrix.iloc[i, j] <= threshold[1] and\n                not threshold[2] <= corr_matrix.iloc[i, j] <= threshold[3]\n            ) and (corr_matrix.columns[j] not in col_corr):\n                colname = corr_matrix.columns[i]\n                col_corr.add(colname)\n                if colname in df.columns:\n                    del df[colname]\n\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_etf = correlation_clean(df_etf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Correlation matrix\n**Correlation measures both the strength and direction of \nthe linear relationship between two variables. Depending \non the data, correlations could be calculated in a \ncouple of different ways. The most used way is to use \nthe Pearson product-moment correlation coefficient.**\n\n**Correlations bellow represent how each attribute is \ncorrelated to another (in pairs). Values vary in a \nrange [-1, 1], where -1 represents perfect negative \ncorrelation, 1 represents perfect positive correlation, \n0 represents no correlation, and all values between \n-1, 0 and 1 represent different correlations states \nand strengths between two variables.**\n\n**It is often assumed that positive values have a stronger \ncorrelation. But that isn't a case. High negative or \nhigh positive are both high correlations, but just in \ndifferent directions.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def corr_mtx(df, fig_size=50, unique=True):\n    \"\"\"\n    Correlation measures both the strength and direction of \n    the linear relationship between two variables. Depending \n    on the data, correlations could be calculated in a \n    couple of different ways. The most used way is to use \n    the Pearson product-moment correlation coefficient.\n    \n    Arguments:\n        df: Dataset pandas DataFrame.\n        fig_size: Size of the plot.\n        unique: If True, it reduces the number of \n        attributes that will be visualized using \n        the number of unique values as a heuristic.\n    \"\"\"\n    sns.set(font_scale=4.0)\n    # Chose adequate columns for visualization\n    if unique:\n        num_unique_col = df.nunique()\n        df = df[[col for col in df if num_unique_col[col] > 1]]\n\n    f, ax = plt.subplots(figsize=(fig_size, fig_size))\n    corr = df.corr()\n    sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),\n                square=True, ax=ax)\n    plt.show()\n    sns.set(font_scale=2.0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_mtx(df_etf, unique=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Scatter matrix\n**Creates a grid of Axes such that each numeric \nvariable in data will be shared in the y-axis \nacross a single row and in the x-axis across \na single column. The diagonal Axes are treated \ndifferently, drawing a plot to show the univariate \ndistribution of the data for the variable in \nthat column.**\n\n**This has the same structure as the correlation \nmatrix, but instead, the diagonal axis shows the \nvariable distribution for the given attribute, \nwhile other fields represent the scatter matrix \nthat visualizes correlation among two variables.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def scatter_mtx(df, fig_size=50, cap=10):\n    \"\"\"\n    Creates a grid of Axes such that each numeric \n    variable in data will be shared in the y-axis \n    across a single row and in the x-axis across \n    a single column. The diagonal Axes are treated \n    differently, drawing a plot to show the univariate \n    distribution of the data for the variable in \n    that column.\n    \n    Arguments:\n        df: Dataset pandas DataFrame.\n        fig_size: Size of the plot.\n        cap: Max plots to be plot.\n    \"\"\"\n    df = df.select_dtypes(np.number)\n    if len(list(df)) > cap:\n        df = df[list(df)[:cap]]\n    scatter_matrix = pd.plotting.scatter_matrix(df, alpha=0.2, figsize=(fig_size, fig_size), diagonal='kde')\n    for ax in scatter_matrix.ravel():\n        ax.set_xlabel(ax.get_xlabel(), fontsize=30, rotation=90)\n        ax.set_ylabel(ax.get_ylabel(), fontsize=30, rotation=0)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scatter_mtx(df_etf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## MF Visualization\n**Furthermore, MF section contains the same \nelements as an ETFs, but with different data \ngathered of Mutual Funds.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# types(df_mf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# describe(df_mf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hist_bar_plot(df_mf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_mf = correlation_clean(df_mf, threshold=(-0.9, -0.6, 0.6, 0.9))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_mtx(df_mf, unique=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scatter_mtx(df_mf, cap=20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dataset Cleaning\n**Dataset cleaning process serves to prepare a dataset \nfor the training and inference phase. The cleaning \nphase consists of:**\n- **Replacing all different NaN values with single\nconsistent NaN indicator** \n- **Removing columns with low-value information (ones\nthat have many unique values i.e. fund name)** \n- **Separation of categorical and numerical  attributes**\n- **Preparing categorical columns:**\n  - **Populate NaN values**\n  - **Label encode columns**\n  - **One-hot encode columns**\n- **Preparing numerical columns:**\n  - **Determine quantile and standard deviation of\n  each column** \n  - **Populate NaN values using the Normal (Gaussian)\n  distribution** "},{"metadata":{"trusted":true},"cell_type":"code","source":"df_etf, df_mf = load_dataset() # Load again because of 'correlation_clean' function","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def gaussian_clean(df, dataset_type):\n    \"\"\"\n    Prepares a dataset for the training and inference \n    phase. The cleaning phase consists of:\n    - Replacing all different NaN values with single \n    consistent NaN indicator\n    - Removing columns with low-value information (ones \n    that have many unique values i.e. fund name)\n    - Separation of categorical and numerical  attributes\n    - Preparing categorical columns:\n      - Populate NaN values\n      - Label encode columns\n      - One-hot encode columns\n    - Preparing numerical columns:\n      - Determine quantile and standard deviation of \n      each column\n      - Populate NaN values using the Normal (Gaussian) \n      distribution\n    \n    Arguments:\n        df: Dataset pandas DataFrame.\n        dataset_type: etf or mf.\n        \n    Returns:\n        Cleaned dataset.\n    \"\"\"\n    # Fix NaN\n    df.replace('', 'NaN', inplace=True)\n    df.replace('nan', 'NaN', inplace=True)\n    df.replace('NaN', np.nan, inplace=True)\n\n    # As consequence of too many NaN values\n    migrate_columns = [\n        'fund_treynor_ratio_3years',\n    ]\n    if dataset_type == 'etf':\n        migrate_columns += [\n            'category_treynor_ratio_5years',\n        ]\n    elif dataset_type == 'mf':\n        migrate_columns += [\n            'price_cashflow',\n            'price_sales',\n            'price_earnings',\n            'median_market_cap',\n            'fund_treynor_ratio_5years',\n            'fund_treynor_ratio_10years',\n        ]\n\n    # Join together numerical columns\n    num_mean = df.select_dtypes(np.number)\n    for col in migrate_columns:\n        num_mean = num_mean.join(pd.to_numeric(df[col], errors=\"coerce\"))\n\n    # Columns with low-value information (ignored during initial analysis)\n    low_info_categorical_columns = [\n        'category',\n        'currency',\n        'fund_extended_name',\n        'fund_family',\n        'fund_name',\n    ]\n    if dataset_type == 'etf':\n        low_info_categorical_columns += [\n            'legal_type',\n        ]\n    elif dataset_type == 'mf':\n        low_info_categorical_columns += [\n            'inception_date',\n        ]\n\n    # Join together categorical (without low-value) columns\n    str_mean = df[df.columns.difference(num_mean.columns)]\n    for col in low_info_categorical_columns:\n        str_mean = str_mean.drop(col, axis=1)\n\n    # Populate empty values in categorical columns\n    for col in list(str_mean):\n        unique = str_mean[col].unique()\n        unique = [x for x in unique if str(x) != 'nan']\n        for i, value in enumerate(str_mean[col]):\n            if value is np.nan:\n                choice = random.choice(unique)\n                str_mean[col].iloc[i] = choice\n\n    # Encode categorical columns\n    le = LabelEncoder()\n    for col in str_mean:\n        df[col] = le.fit_transform(str_mean[col])\n\n    # One-hot encode categorical columns\n    ohe = OneHotEncoder()\n    for col in str_mean:\n        unique = str_mean[col].unique()\n        unique = [col + \"_\" + x for x in unique if str(x) != 'nan']\n        enc_df = pd.DataFrame(ohe.fit_transform(df[[col]]).toarray(), columns=unique)\n        df = df.drop(col, axis=1)\n        df = df.join(enc_df)\n\n    # Populate numerical columns\n    mu = num_mean.quantile(0)\n    sigma = num_mean.std(axis=0)\n    for col in num_mean:\n        stack = num_mean[col]\n        null_stack = stack[pd.isnull(stack)]\n        ran = np.random.normal(mu[col], sigma[col], len(null_stack))\n        stack.loc[null_stack.index] = ran\n        df[col] = stack.values\n\n    # Clean\n    for col in low_info_categorical_columns:\n        df = df.drop(col, axis=1)\n\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_etf = gaussian_clean(df_etf, 'etf')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_mf = gaussian_clean(df_mf, 'mf')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualize after cleaning\n**Here is how some of the columns in the dataset \nlook after a cleaning process. In both ETF and MF \ndatasets, numerical columns tend towards normalized \ndistribution. In some columns in which this isn't \na case, there exists a small amount of NaN values, \nso populating them doesn't influence so much.**\n\n**Furthermore, categorical columns are split as a \nconsequence of one-hot encoding. Each column \nconsists of 0 and 1 representing the existence \n(mark with 1), or non-existence (mark with 0) of \ncertain investment types, fund size, etc.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"hist_bar_plot(df_etf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hist_bar_plot(df_mf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ML with focus on Year to Date returns\n**After the dataset cleaning process, it is possible \nto apply different ML algorithms in order to be \nable to predict some features based on previously \nobserved data. In this case, the referent attribute \nfor prediction is Year to Date (YTD).**\n\n**Before all, Year to Date (YTD) is simply the \namount of profit (or loss) generated by an \ninvestment since the beginning of the current \ncalendar year, usually January 1st or else the \nfirst trading date of the year or first day of \nthe fiscal year.**"},{"metadata":{},"cell_type":"markdown","source":"### Training\n**Regarding ML models, it is not possible to use \njust any model out there. Because the referent \nprediction attribute (YTD) is in numerical form \nand represented as a continual numerical stream, \nthe most efficient will be to chose one of the \nregression models for training and final inference. \nSome of the regression models chosen for this dataset are:**\n- **SVM**\n- **SGDRegressor**\n- **BayesianRidge**\n- **LassoLars**\n- **ARDRegression**\n- **PassiveAggressiveRegressor**\n- **TheilSenRegressor**\n- **LinearRegression**"},{"metadata":{"trusted":true},"cell_type":"code","source":"regressors = [\n#     svm.SVR(),\n    linear_model.SGDRegressor(),\n    linear_model.BayesianRidge(),\n    linear_model.LassoLars(),\n#     linear_model.ARDRegression(),\n    linear_model.PassiveAggressiveRegressor(),\n#     linear_model.TheilSenRegressor(),\n    linear_model.LinearRegression(),\n]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Before all, the dataset is split into two parts, \nthe train and test sets. A training set is used to \ntrain a regression model, while the testing set is \nused to validate how precise are our regressors.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def dataset_split(df, index_col):\n    \"\"\"\n    Splits dataset into train and test sets.\n    \n    Arguments:\n        df: Dataset pandas DataFrame.\n        index_col: Referent prediction column.\n    \n    Returns:\n        Train and test sets.\n    \"\"\"\n    train, test = train_test_split(df, test_size=0.2, random_state=rnd_seed_state)\n    y_train = train[index_col].copy()\n    del train[index_col]\n\n    y_test = test[index_col].copy()\n    del test[index_col]\n\n    return train, test, y_train, y_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = dataset_split(df_etf, index_col=\"ytd_return\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Then, models are trained and results are collected \nafter training on each regression model. There are \nalso specific metrics that are used to determine \nthe precision of our model. Some of them are:**\n- **Explained variance score**\n- **Max error**\n- **Mean absolute error**\n- **Mean squared error**\n- **Median absolute error**\n- **R² score, the coefficient of determination**\n- **Mean Poisson, Gamma, and Tweedie deviances**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def run_models(regressors, x_train, x_test, y_train, y_test, res):\n    \"\"\"\n    Trains and run inference on different models.\n    \n    Arguments:\n        regressors: List of all requested regression models.\n        x_train: X training data.\n        x_test: X testing data.\n        y_train: Y (index) training data.\n        y_test: Y (index) testing data.\n        res: Dictionary for storing results.\n    \"\"\"\n    print(\"Running models...\")\n    for model in regressors:\n        start_time = time.time()\n        model_name = type(model).__name__\n        print(\"\\tModel: {}\".format(model_name))\n        clf = model\n        clf.fit(x_train, y_train)\n        y_pred = clf.predict(x_test)\n        res[model_name] = {}\n        result_metrics(y_test, y_pred, res[model_name])\n        print(\"\\tExecution time: %s seconds\\n\" % (round((time.time() - start_time), 3)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def result_metrics(actual, predicted, res, print_adjust=50):\n    \"\"\"\n    Calculates metrics from different models. Used metrics\n    are explained in following sections:\n    \n    ### Explained variance score\n    If \\hat{y} is the estimated target output,\n    y the corresponding (correct) target output, and Var is Variance, the\n    square of the standard deviation, then the explained variance is estimated\n    as follow:\n\n    explained\\_{}variance(y, \\hat{y}) = 1 - \\frac{Var\\{ y - \\hat{y}\\}}{Var\\{y\\}}\n\n    The best possible score is 1.0, lower values are worse.\n\n    ### Max error\n    The max_error function computes the maximum residual error, a metric that captures\n    the worst case error between the predicted value and the true value. In a perfectly\n    fitted single output regression model, max_error would be 0 on the training set\n    and though this would be highly unlikely in the real world, this metric shows\n    the extent of error that the model had when it was fitted.\n\n    If \\hat{y}_i is the predicted value of the i-th sample, and y_i is the\n    corresponding true value, then the max error is defined as:\n\n    \\text{Max Error}(y, \\hat{y}) = max(| y_i - \\hat{y}_i |)\n\n    ### Mean absolute error\n    The mean_absolute_error function computes mean absolute error,\n    a risk metric corresponding to the expected value of the absolute error\n    loss or l1-norm loss.\n\n    If \\hat{y}_i is the predicted value of the -th sample, and y_i is the\n    corresponding true value, then the mean absolute error (MAE) estimated\n    over n_{samples} is defined as:\n\n    \\text{MAE}(y, \\hat{y}) = \\frac{1}{n_{\\text{samples}}} \\sum_{i=0}^{n_{\\text{samples}}-1} \\left| y_i - \\hat{y}_i \\right|.\n\n    ###  Mean squared error\n    The mean_squared_error function computes mean square error,\n    a risk metric corresponding to the expected value of the squared\n    (quadratic) error or loss.\n\n    If \\hat{y}_i is the predicted value of the i-th sample,\n    and y_i is the corresponding true value, then the mean squared\n    error (MSE) estimated over n_{\\text{samples}} is defined as:\n\n    \\text{MSE}(y, \\hat{y}) = \\frac{1}{n_\\text{samples}} \\sum_{i=0}^{n_\\text{samples} - 1} (y_i - \\hat{y}_i)^2.\n\n    ### Median absolute error\n    The median_absolute_error is particularly interesting because\n    it is robust to outliers. The loss is calculated by taking the\n    median of all absolute differences between the target and the\n    prediction.\n\n    If \\hat{y}_i is the predicted value of the i-th sample and y_i\n    is the corresponding true value, then the median absolute\n    error (MedAE) estimated over n_{\\text{samples}} is defined as:\n\n    \\text{MedAE}(y, \\hat{y}) = \\text{median}(\\mid y_1 - \\hat{y}_1 \\mid, \\ldots, \\mid y_n - \\hat{y}_n \\mid).\n\n    ### R² score, the coefficient of determination\n    The r2_score function computes the coefficient of determination, usually denoted as R².\n\n    It represents the proportion of variance (of y) that has been\n    explained by the independent variables in the model. It provides\n    an indication of goodness of fit and therefore a measure of how\n    well unseen samples are likely to be predicted by the model,\n    through the proportion of explained variance.\n\n    As such variance is dataset dependent, R² may not be meaningfully\n    comparable across different datasets. Best possible score is 1.0\n    and it can be negative (because the model can be arbitrarily worse).\n    A constant model that always predicts the expected value of y,\n    disregarding the input features, would get a R² score of 0.0.\n\n    If \\hat{y}_i is the predicted value of the i-th sample and y_i\n    is the corresponding true value for total  samples, the estimated\n    R² is defined as:\n\n    R^2(y, \\hat{y}) = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}\n\n    where \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 = \\sum_{i=1}^{n} \\epsilon_i^2\n\n    Note that r2_score calculates unadjusted R² without correcting\n    for bias in sample variance of y.\n\n    ### Mean Poisson, Gamma, and Tweedie deviances\n    The mean_tweedie_deviance function computes the mean Tweedie\n    deviance error with a power parameter (p). This is a metric\n    that elicits predicted expectation values of regression targets.\n\n    If \\hat{y}_i is the predicted value of the i-th sample, and y_i\n    is the corresponding true value, then the mean Tweedie deviance\n    error (D) for power p, estimated over n_{\\text{samples}} is defined as:\n\n    \\begin{split}\\text{D}(y, \\hat{y}) = \\frac{1}{n_\\text{samples}}\n    \\sum_{i=0}^{n_\\text{samples} - 1}\n    \\begin{cases}\n    (y_i-\\hat{y}_i)^2, & \\text{for }p=0\\text{ (Normal)}\\\\\n    2(y_i \\log(y/\\hat{y}_i) + \\hat{y}_i - y_i),  & \\text{for}p=1\\text{ (Poisson)}\\\\\n    2(\\log(\\hat{y}_i/y_i) + y_i/\\hat{y}_i - 1),  & \\text{for}p=2\\text{ (Gamma)}\\\\\n    2\\left(\\frac{\\max(y_i,0)^{2-p}}{(1-p)(2-p)}-\n    \\frac{y\\,\\hat{y}^{1-p}_i}{1-p}+\\frac{\\hat{y}^{2-p}_i}{2-p}\\right),\n    & \\text{otherwise}\n    \\end{cases}\\end{split}\n\n    ### Reference\n    https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics\n\n    Arguments:\n        actual: True (actual) value.\n        predicted: Predicted value.\n        print_adjust: Padding size to adjust output to STDOUT.\n    \"\"\"\n    evs = metrics.explained_variance_score(actual, predicted)\n    print(\"\\t\\tExplained variance score \".ljust(print_adjust, '.') + \" {}\".format(evs))\n    res[\"EVS\"] = evs\n\n    me = metrics.max_error(actual, predicted)\n    print(\"\\t\\tMax error \".ljust(print_adjust, '-') + \" {}\".format(me))\n    res[\"ME\"] = me\n\n    mean_ae = metrics.mean_absolute_error(actual, predicted)\n    print(\"\\t\\tMean absolute error \".ljust(print_adjust, '.') + \" {}\".format(mean_ae))\n    res[\"MeanAE\"] = mean_ae\n\n    mse = metrics.mean_squared_error(actual, predicted)\n    print(\"\\t\\tMean squared error \".ljust(print_adjust, '-') + \" {}\".format(mse))\n    res[\"MSE\"] = mse\n\n    median_ae = metrics.median_absolute_error(actual, predicted)\n    print(\"\\t\\tMedian absolute error \".ljust(print_adjust, '.') + \" {}\".format(median_ae))\n    res[\"MedianAE\"] = median_ae\n\n    r2 = metrics.r2_score(actual, predicted)\n    print(\"\\t\\tR² score, the coefficient of determination \".ljust(print_adjust, '-') + \" {}\".format(r2))\n    res[\"R2\"] = r2\n\n    mtd = metrics.mean_tweedie_deviance(actual, predicted)\n    print(\"\\t\\tMean Poisson, Gamma, and Tweedie deviances: \".ljust(50, '.') + \" {}\".format(mtd))\n    res[\"MTD\"] = mtd    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res = {\n    'ETF': {},\n    'MF': {},\n}\nrun_models(regressors, x_train, x_test, y_train, y_test, res['ETF'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = dataset_split(df_mf, index_col=\"ytd_return\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"run_models(regressors, x_train, x_test, y_train, y_test, res['MF'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Results\n**Model result analysis represents the final step. Different \ntypes of plots are used to get a better understanding of \nhow a model performs on test, previously unseen, data.**\n\n**But before visualizing, results are reconstructed and \nintegrated within pandas DataFrame for easier manipulation. \nAlso, scores on each metric are normalized. Why? Because \neach metric is different, and their results can differ a lot, \nwhich makes visualizing final results hard. In order to \nsimplify this, all metrics are normalized to the range [0, 1], \nwhich makes visualizations easier to understand.**\n\n**Have in mind that a smaller number represents better results!**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def visualize_results(res):\n    \"\"\"\n    Visualize model results in different graph\n    types.\n    \n    Arguments:\n        res: Dictionary that contains model results.\n    \"\"\"\n    # Restructure results\n    data = []\n    for k_fund, v_fund in res.items():\n        for k_alg, v_alg in res[k_fund].items():\n            for k_met, v_met in res[k_fund][k_alg].items():\n                data.append([k_fund, k_alg, k_met, v_met])\n    df = pd.DataFrame(data, columns=[\"Fund Type\", \"Model Name\", \"Metric\", \"Score\"])\n\n    # Normalize Score ranges\n    min_max_scaler = MinMaxScaler()\n    groups = df.groupby(\"Metric\", as_index=False)\n    for group in groups.groups.keys():\n        val = groups.get_group(group)[\"Score\"].values.reshape(-1, 1)\n        scaled = min_max_scaler.fit_transform(val)\n        df.loc[df[\"Metric\"] == group, \"Score\"] = scaled\n\n    visualize_with_focus(df, \"Metric\")\n    visualize_with_focus(df, \"Model Name\")\n\n\ndef visualize_with_focus(df, focus_index):\n    \"\"\"\n    Visualize data fith focus on specific column\n    [Model Name or Metric].\n    \n    Arguments:\n        df: Dataset pandas DataFrame.\n        focus_index: Focus column.\n    \"\"\"\n    print_md(\"### \" + focus_index)\n    fund_catplot(df, focus_index)\n    fund_lineplot(df, focus_index)\n    fund_barplot(df, focus_index)\n\n\ndef fund_catplot(df, focus_index):\n    \"\"\"\n    Creates categorical bar plot for comparison of\n    different fund types.\n    \n    Arguments:\n        df: Dataset pandas DataFrame.\n        focus_index: Focus column.\n    \"\"\"\n    sns.catplot(\n        x=\"Metric\" if focus_index == \"Model Name\" else \"Model Name\",\n        y=\"Score\", hue=\"Fund Type\", col=focus_index, kind=\"bar\", data=df, col_wrap=3, height=10)\n    plt.show()\n\n\ndef fund_lineplot(df, focus_index):\n    \"\"\"\n    Creates line plot for comparison of\n    different fund types.\n    \n    Arguments:\n        df: Dataset pandas DataFrame.\n        focus_index: Focus column.\n    \"\"\"\n    plt.figure(figsize=(40, 30))\n    for i, m in enumerate(df[focus_index].unique()):\n        plt.subplot(3, 3, i + 1)\n        df_group = df[df[focus_index] == m]\n        lp = sns.lineplot(x=\"Metric\" if focus_index == \"Model Name\" else \"Model Name\",\n                          y=\"Score\", hue=\"Fund Type\", data=df_group)\n        lp.set_title(m)\n        plt.xticks(rotation=30)\n    plt.show()\n\n\ndef fund_barplot(df, focus_index):\n    \"\"\"\n    Creates bar plot for each fund type.\n    \n    Arguments:\n        df: Dataset pandas DataFrame.\n        focus_index: Focus column.\n    \"\"\"\n    for fund_type in [\"ETF\", \"MF\"]:\n        plt.figure(figsize=(40, 30))\n        for i, mn in enumerate(df[focus_index].unique()):\n            plt.subplot(3, 3, i + 1)\n\n            # Plot config\n            df_group = df[(df[focus_index] == mn) & (df[\"Fund Type\"] == fund_type)]\n            lp = sns.barplot(x=\"Metric\" if focus_index == \"Model Name\" else \"Model Name\",\n                             y=\"Score\", hue=\"Fund Type\", data=df_group)\n            lp.set_title(mn)\n            plt.xticks(rotation=30)\n        plt.show()\n\n\ndef print_md(string):\n    \"\"\"\n    Print for Jupyter MarkDown.\n    \n    Arguments:\n        string: MarkDown content. \n    \"\"\"\n    display(Markdown(string))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"visualize_results(res)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Applying Correlation clean\n**Correlation cleaning keeps only high-correlated \ncolumns within the dataset. As mentioned above, \ncorrelation cleaning works by focusing only on \ncolumns that have a greater correlation \n(positive or negative) with other columns. \nThis way, the dataset keeps only essential \nattributes that are left to be employed.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_etf = correlation_clean(df_etf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_mf = correlation_clean(df_mf, threshold=(-0.9, -0.6, 0.6, 0.9))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res = {\n    'ETF': {},\n    'MF': {},\n}\nrun_models(regressors, x_train, x_test, y_train, y_test, res['ETF'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = dataset_split(df_mf, index_col=\"ytd_return\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"run_models(regressors, x_train, x_test, y_train, y_test, res['MF'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"visualize_results(res)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ML with focus on fund Net Assets\n**Same as in the above analysis, everything is the same, \njust instead on focusing inference on Year to Date attribute, \nthis section focuses on fund Net Assets.**\n\n**The Net Assets or Net Asset Value (NAV) represents the \nnet value of an entity and is calculated as the total \nvalue of the entity’s assets minus the total value of its \nliabilities.** "},{"metadata":{},"cell_type":"markdown","source":"### Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = dataset_split(df_etf, index_col=\"net_assets\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res = {\n    'ETF': {},\n    'MF': {},\n}\nrun_models(regressors, x_train, x_test, y_train, y_test, res['ETF'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = dataset_split(df_mf, index_col=\"net_assets\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"run_models(regressors, x_train, x_test, y_train, y_test, res['MF'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Results"},{"metadata":{"trusted":true},"cell_type":"code","source":"visualize_results(res)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Applying Correlation clean"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_etf = correlation_clean(df_etf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_mf = correlation_clean(df_mf, threshold=(-0.9, -0.6, 0.6, 0.9))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res = {\n    'ETF': {},\n    'MF': {},\n}\nrun_models(regressors, x_train, x_test, y_train, y_test, res['ETF'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = dataset_split(df_mf, index_col=\"net_assets\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"run_models(regressors, x_train, x_test, y_train, y_test, res['MF'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"visualize_results(res)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}