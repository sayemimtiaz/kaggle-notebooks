{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<img src=\"https://i.imgur.com/zK75gSX.gif\">\n\n<center><h1>üí∞ Bitcoin (&Dogecoin) Prices, Elon Musk and RAPIDS üí∞</h1></center>\n\n# Introduction\n\nWhat does a virtual coin that people like or hate, an excentric person that wants to get old on Mars and the suite of software libraries on GPUs all have in common?\n\nWell, you know what they say ... if you want, you can find a correlation anywhere you look ... if you're really, deeply paying attention.\n\n> **üü¢ Goal**: This notebook has the purpose of analysing and predicting bitcoin prices using RAPIDS, as well as identifying if there is any impact from Elon Musk's tweets on the fluctuation of the bitcoin prices.\n\n### üìö Libraries & Functions\n> You can learn more about W&B in [this great kernel right here](https://www.kaggle.com/ayuraj/experiment-tracking-with-weights-and-biases).","metadata":{}},{"cell_type":"code","source":"# Libraries\nimport wandb\nimport pandas as pd\nimport numpy as np\nimport re\nimport os\nimport string\nfrom datetime import datetime\nimport seaborn as sns\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nfrom matplotlib.offsetbox import AnnotationBbox, OffsetImage\nfrom wordcloud import WordCloud, ImageColorGenerator\nfrom wordcloud import STOPWORDS as stopwords_wc\nfrom statsmodels.tsa.stattools import adfuller       ### Augmented Dickey Fuller\n\nimport cupy\nimport cudf\nimport cuml\nfrom cuml.tsa.arima import ARIMA\n\n# Color palette\nmy_colors = [\"#ce8f5a\", \"#efd199\", \"#80c8bc\", \"#5ec0ca\", \"#6287a2\"]\nsns.palplot(sns.color_palette(my_colors))\n\n# Set Style\nsns.set_style(\"white\")\nmpl.rcParams['xtick.labelsize'] = 16\nmpl.rcParams['ytick.labelsize'] = 16\nmpl.rcParams['axes.spines.left'] = False\nmpl.rcParams['axes.spines.right'] = False\nmpl.rcParams['axes.spines.top'] = False\n\nclass color:\n    BOLD = '\\033[1m' + '\\033[93m'\n    END = '\\033[0m'\n    \n# W&B\nos.environ[\"WANDB_SILENT\"] = \"true\"\n# Secrets ü§´\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"wandb\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Link to **your own key** in W&B: https://wandb.ai/authorize","metadata":{}},{"cell_type":"code","source":"! wandb login $secret_value_0","metadata":{"_kg_hide-input":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def offset_png(x, y, path, ax, zoom, offset):\n    '''For adding other .png images to the graph.\n    source: https://stackoverflow.com/questions/61971090/how-can-i-add-images-to-bars-in-axes-matplotlib'''\n    \n    img = plt.imread(path)\n    im = OffsetImage(img, zoom=zoom)\n    im.image.axes = ax\n    x_offset = offset\n    ab = AnnotationBbox(im, (x, y), xybox=(x_offset, 0), frameon=False,\n                        xycoords='data', boxcoords=\"offset points\", pad=0)\n    ax.add_artist(ab)\n    \n\n    \ndef show_values_on_bars(axs, h_v=\"v\", space=0.4):\n    '''Plots the value at the end of the a seaborn barplot.\n    axs: the ax of the plot\n    h_v: weather or not the barplot is vertical/ horizontal'''\n    \n    def _show_on_single_plot(ax):\n        if h_v == \"v\":\n            for p in ax.patches:\n                _x = p.get_x() + p.get_width() / 2\n                _y = p.get_y() + p.get_height()\n                value = int(p.get_height())\n                ax.text(_x, _y, format(value, ','), ha=\"center\") \n        elif h_v == \"h\":\n            for p in ax.patches:\n                _x = p.get_x() + p.get_width() + float(space)\n                _y = p.get_y() + p.get_height()\n                value = int(p.get_width())\n                ax.text(_x, _y, format(value, ','), ha=\"left\")\n\n    if isinstance(axs, np.ndarray):\n        for idx, ax in np.ndenumerate(axs):\n            _show_on_single_plot(ax)\n    else:\n        _show_on_single_plot(axs)\n        \n\n\ndef emoji_extractor(string, remove=False):\n    '''Removes Emoji from a text.'''\n    emoji_pattern = re.compile(\"[\"\n                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n                               u\"\\U00002702-\\U000027B0\"\n                               u\"\\U00002702-\\U000027B0\"\n                               u\"\\U000024C2-\\U0001F251\"\n                               u\"\\U0001f926-\\U0001f937\"\n                               u\"\\U00010000-\\U0010ffff\"\n                               u\"\\u2640-\\u2642\"\n                               u\"\\u2600-\\u2B55\"\n                               u\"\\u200d\"\n                               u\"\\u23cf\"\n                               u\"\\u23e9\"\n                               u\"\\u231a\"\n                               u\"\\ufe0f\"  # dingbats\n                               u\"\\u3030\"\n                               \"]+\", flags=re.UNICODE)\n    if remove == False:\n        # Extract emoji\n        return emoji_pattern.findall(string)\n    else:\n        # Remove emoji from text\n        return emoji_pattern.sub(r'', string)\n\ndef clean_emoji(x):\n    if len(x) == 0:\n        return ''\n    else:\n        return x[0]\n    \n    \n    \ndef clean_tweets(df):\n    '''Returns the dataframe with the tweet column cleaned.'''\n    \n    # ----- Remove \\n, \\t, \\xa0 -----\n    df['tweet'] = df['tweet'].apply(lambda x: x.replace('\\n', ''))\n    df['tweet'] = df['tweet'].apply(lambda x: x.replace('\\xa0', ''))\n    df['tweet'] = df['tweet'].apply(lambda x: x.replace('\\t', ''))\n    \n    # ----- Remove pic.twitter and http:// + https:// links -----\n    df['tweet'] = df['tweet'].apply(lambda x: re.sub(r'http\\S+', '', x))\n    df['tweet'] = df['tweet'].apply(lambda x: re.sub(r'https\\S+', '', x))\n    df['tweet'] = df['tweet'].apply(lambda x: re.sub(r'pic.twitter\\S+', '', x))\n    \n    # ----- Remove mentions and hashtags -----\n    df['tweet'] = df['tweet'].apply(lambda x: re.sub(r'#\\S+', '', x))\n    df['tweet'] = df['tweet'].apply(lambda x: re.sub(r'@\\S+', '', x))\n    \n    # ----- Extract Emojis and Remove from Tweet -----\n    df['tweet_emojis'] = df['tweet'].apply(lambda x: emoji_extractor(x, remove=False))\n    df['tweet_emojis'].replace('', np.nan, inplace=True)\n#     df[\"tweet_emojis\"] = df[\"tweet_emojis\"].apply(lambda x: clean_emoji(x))\n    \n    df['tweet'] = df['tweet'].apply(lambda x: emoji_extractor(x, remove=True))\n    \n    # ----- Strip of whitespaces -----\n    df['tweet'] = df['tweet'].apply(lambda x: x.strip())\n    df['tweet'] = df['tweet'].apply(lambda x: ' '.join(x.split()))\n    \n    # ----- Remove punctuation & Make lowercase -----\n    df['tweet'] = df['tweet'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n    df['tweet'] = df['tweet'].apply(lambda x: x.lower())\n    \n    return df","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### üì• Read in Data","metadata":{}},{"cell_type":"code","source":"# === Tweets ===\ntweets = pd.read_csv(\"../input/all-elon-musks-tweets/TweetsElonMusk.csv\")\ntweets = tweets[[\"id\", \"date\", \"time\", \"username\", \n                 \"tweet\", \"mentions\", \"urls\", \"photos\", \"replies_count\", \n                 \"retweets_count\", \"likes_count\", \"hashtags\", \"link\"]]\n\n# Create new features\ntweets[\"year\"] = tweets[\"date\"].apply(lambda x: x.split(\"-\")[0])\n# Clean Tweets\ntweets = clean_tweets(df=tweets)\n\n# === Bitcoin ===\nbitcoin = cudf.read_csv(\"../input/bitcoin-historical-data/bitstampUSD_1-min_data_2012-01-01_to_2021-03-31.csv\")\n\n# === Dogecoin ===\ndogecoin = pd.read_csv(\"../input/dogecoin-historical-data/DOGE-USD.csv\")\n\n\n# Prints\nprint(color.BOLD + \"Tweets shape:\" + color.END, \"{}\".format(tweets.shape), \"\\n\" +\n      color.BOLD + \"Bitcoin shape:\" + color.END, \"{}\".format(bitcoin.shape), \"\\n\" +\n      color.BOLD + \"Dogecoin shape:\" + color.END, \"{}\".format(dogecoin.shape))\n\n# There are many missing values in Bitcoin data\nplt.figure(figsize = (25, 11))\nsns.heatmap(bitcoin.isna().as_matrix()[::10], cmap = [my_colors[1], \n                                                      my_colors[2]], xticklabels=bitcoin.columns)\nplt.title(\"Missing values in Bitcoin Data\", size=20);\n\n# Hence, we'll drop them\nbitcoin.dropna(axis=0, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save Tweets data to W&B Artifacts\n### versioned by me like the datasets\nrun = wandb.init(project='bitcoin-musk', name='all_elonmusk_tweets')\nartifact = wandb.Artifact(name='tweets', \n                          type='dataset')\nartifact.add_file(\"../input/all-elon-musks-tweets/TweetsElonMusk.csv\")\n\nwandb.log_artifact(artifact)\nwandb.finish()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. üöÄ Elon Musk's personality\n\nOk, let's have a bit of fun first. Let's see how the tweets look, his progression over time and get an overall feel of how, what, when he tweets. This will help us understand a bit of his behavior, as well as address and analyse the tweets that mention **Bitcoin**.","metadata":{}},{"cell_type":"code","source":"run = wandb.init(project='bitcoin-musk', name='elonmusk_analysis')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## I. Tweet Count Evolution\n> **üìù Note**: At the beginning of his tweeting journey, he was barely using the platform a few times in a year. 2015 was his breaking point, when he started tweeting more and more every year. It's also the year when Elon became ... well, he became **the rockstar** we know now. He was already known before, but 2015 got him on a whole new level, by announcing *Tesla's Powerwall battery* and putting out his personal life through *his biography*.","metadata":{}},{"cell_type":"code","source":"# Yearly evolution\ndate_count_df = tweets[tweets[\"year\"]!=\"2021\"].groupby(\"year\")[\"tweet\"].count().reset_index()\n\n# Plot\nplt.figure(figsize=(25, 11))\nax = sns.lineplot(data=date_count_df, x=\"year\", y=\"tweet\", lw=8, color=my_colors[3])\nplt.title(\"Tweet Count Evolution\", size=25)\nplt.xlabel(\"Year\", size=20)\nplt.ylabel(\"Frequency\", size=20)\nsns.despine(left=True);\n\n# Picture\npath='../input/all-elon-musks-tweets/images/images/elon_rocket.png'\noffset_png(x=6.9, y=2000, path=path, ax=ax, zoom=0.27, offset=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_wandb_lineplot(x_data, y_data, x_name, y_name, title, log):\n    '''Create and save barplot in W&B Environment.\n    x_data & y_data: Pandas Series containing x & y data\n    x_name & y_name: strings containing axis names\n    title: title of the graph\n    log: string containing name of log'''\n    \n    # Save Graph in W&B Dashboard as well\n    data = [[label, val] for (label, val) in zip(x_data, y_data)]\n\n    table = wandb.Table(data=data, columns = [x_name, y_name])\n    wandb.log({log : wandb.plot.line(table, x_name, y_name,\n                                                  title=title)})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"create_wandb_lineplot(x_data=date_count_df[\"year\"], y_data=date_count_df[\"tweet\"], \n                      x_name=\"year\", y_name=\"tweet count\", \n                      title=\"Tweet Count Evolution\", log=\"tweet_evolution\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## II. Popularity\n\n> **üìù Note**: It seems that his popularity grew with the number of tweets. He increased gradually in likes with the peak in 2020 (and I bet he'll continue in 2021 as well), but the replies reached a peak as well (he's communicating more with a broader audience, who's speaking back).\n<center><img src=\"https://media2.giphy.com/media/2Y8Iq3xe121Ba3hUAM/giphy.gif\" width=400></center>","metadata":{}},{"cell_type":"code","source":"# Get Popularity Information\npopularity = [\"likes_count\", \"retweets_count\", \"replies_count\"]\npopularity_df = tweets[tweets[\"year\"]!=\"2021\"].groupby(\"year\").agg({popularity[0] : 'sum',\n                                                                    popularity[1] : 'sum',\n                                                                    popularity[2] : 'sum',\n                                                                    'tweet' : 'count'}).reset_index()\npopularity_df[\"likes_count\"] = popularity_df[\"likes_count\"]/popularity_df[\"tweet\"]\npopularity_df[\"retweets_count\"] = popularity_df[\"retweets_count\"]/popularity_df[\"tweet\"]\npopularity_df[\"replies_count\"] = popularity_df[\"replies_count\"]/popularity_df[\"tweet\"]\n\n# Plot\nfig, (ax1, ax2, ax3) = plt.subplots(3, figsize=(25, 15))\naxs = [ax1, ax2, ax3]\nplt.suptitle(\"Popularity\", size=25)\nsns.barplot(data=popularity_df, x=\"year\", y=\"likes_count\", lw=5, color=my_colors[0], ax=ax1)\nsns.barplot(data=popularity_df, x=\"year\", y=\"retweets_count\", lw=5, color=my_colors[1], ax=ax2)\nsns.barplot(data=popularity_df, x=\"year\", y=\"replies_count\", lw=5, color=my_colors[2], ax=ax3)\nnames = [\"Average Likes\", \"Average Retweets\", \"Average Replies\"]\nfor ax, n in zip(axs, names):\n    ax.set_xlabel(\"\", size=20)\n    ax.set_ylabel(n, size=20)\n    ax.get_yaxis().set_ticks([])\n#     ax.title.set_text(n)\n    show_values_on_bars(axs=ax, h_v=\"v\", space=0.4)\nsns.despine(left=True);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_wandb_barplot(x_data, y_data, x_name, y_name, title, log):\n    '''Create and save barplot in W&B Environment.\n    x_data & y_data: Pandas Series containing x & y data\n    x_name & y_name: strings containing axis names\n    title: title of the graph\n    log: string containing name of log'''\n    \n    # Save Graph in W&B Dashboard as well\n    data = [[label, val] for (label, val) in zip(x_data, y_data)]\n\n    table = wandb.Table(data=data, columns = [x_name, y_name])\n    wandb.log({log : wandb.plot.bar(table, x_name, y_name,\n                                                  title=title)})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create W&B Barplots\ncreate_wandb_barplot(x_data=popularity_df[\"year\"], y_data=popularity_df[\"likes_count\"], \n                     x_name=\"year\", y_name=\"likes\", \n                     title=\"Likes Evolution\", log=\"likes_evolution\")\ncreate_wandb_barplot(x_data=popularity_df[\"year\"], y_data=popularity_df[\"retweets_count\"], \n                     x_name=\"year\", y_name=\"retweets\", \n                     title=\"Retweets Evolution\", log=\"retweets_evolution\")\ncreate_wandb_barplot(x_data=popularity_df[\"year\"], y_data=popularity_df[\"replies_count\"], \n                     x_name=\"year\", y_name=\"replies\", \n                     title=\"Replies Evolution\", log=\"replies_evolution\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## III. Most Frequent Words\n\n> **üìù Note**:  alot of talk about **Tesla, rocket, Mars, starship, launch**. To be observed that the wording sounds super positive: yes, yeah, good, thank, people, sure. I like that a lot, he's always super positive and enthusiastin in his messages.\n\n<center><img src=\"https://i.pinimg.com/originals/62/57/d3/6257d3ab7e42e96407944416ca9d3f18.gif\" width = 450></center>","metadata":{}},{"cell_type":"code","source":"# Make worldcloud\nall_tweets = \" \".join(token for token in tweets[\"tweet\"])\nstopwords_wc = set(stopwords_wc)\nfont_path = \"../input/all-elon-musks-tweets/acetone_font.otf\"\n\nwordcloud = WordCloud(stopwords=stopwords_wc, font_path=font_path,\n                      max_words=1500,\n                      max_font_size=350, random_state=42,\n                      width=2000, height=1000,\n                      colormap = \"twilight\")\nwordcloud.generate(all_tweets)\n\n# Plot\nplt.figure(figsize = (16, 8))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show();","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"WordCloud.to_file(wordcloud, \"wordcloud.png\")\n\n# Save image to W&B\nwandb.log({\"wordcloud\": wandb.Image(\"./wordcloud.png\")})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## IV. Let's talk about Bitcoin and ... Dogecoin?\n\nI wanted to throw Dogecoin in there for fun. I mean ... you never know.","metadata":{}},{"cell_type":"code","source":"# Retrieve only Bitcoin Information\nbitcoin_tweets = tweets[tweets[\"tweet\"].str.contains(\"bitcoin\")].reset_index(drop = True)\ndogecoin_tweets = tweets[tweets[\"tweet\"].str.contains(\"dogecoin\")].reset_index(drop = True)\n\n# Information\nprint(color.BOLD + \"% of tweets about Bitcoin:\" + color.END, \"{:.3}%\".format(bitcoin_tweets.shape[0]/tweets.shape[0]*100), \"\\n\" +\n      color.BOLD + \"% of tweets about Dogecoin:\" + color.END, \"{:.3}%\".format(dogecoin_tweets.shape[0]/tweets.shape[0]*100))\n\ntop = bitcoin_tweets.sort_values(\"likes_count\", ascending=False)[:7][\"tweet\"]\nprint(\"\\n\", color.BOLD + \"Most liked BITCOIN tweets:\" + color.END)\nfor k, text in enumerate(top):\n    print(f\"{k+1}. {text}\")\n    \ntop = dogecoin_tweets.sort_values(\"likes_count\", ascending=False)[:7][\"tweet\"]\nprint(\"\\n\", color.BOLD + \"Most liked DOGECOIN tweets:\" + color.END)\nfor k, text in enumerate(top):\n    print(f\"{k+1}. {text}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.finish()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> The [W&B Dashboard](https://wandb.ai/andrada/bitcoin-musk?workspace=user-andrada):\n\n<center><img src=\"https://i.imgur.com/Vl8Hixr.png\" width=800></center>\n\n# 2. üìà Predict Future Bitcoin Price using RAPIDS\n\n> We'll use the RAPIDS distribution for this experiment, as our **data is extremely large** (more than 3 million observations). You can find out more about [RAPIDS and cuml here](https://github.com/rapidsai/cuml/tree/branch-0.20/notebooks).","metadata":{}},{"cell_type":"code","source":"run = wandb.init(project='bitcoin-musk', name='bitcoin_analysis')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## I. Analyse Bitcoin Evolution","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (25, 11))\nplt.plot(bitcoin[\"Timestamp\"].to_array(), bitcoin[\"Weighted_Price\"].to_array(), color=my_colors[0], lw=3)\nplt.title(\"Bitcoin Price over time\", size=25)\nplt.xlabel(\"Time\", size=20)\nplt.ylabel(\"$ Price\", size=20);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Log to W&B\ncreate_wandb_lineplot(x_data=bitcoin[\"Timestamp\"][::50].to_array(), y_data=bitcoin[\"Weighted_Price\"][::50].to_array(), \n                     x_name=\"timestamp\", y_name=\"$price\", \n                     title=\"Price Evolution\", log=\"price_evolution\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (25, 11))\nplt.plot(bitcoin[\"Timestamp\"].to_array(), bitcoin[\"Volume_(Currency)\"].to_array(), color=my_colors[2], lw=3)\nplt.title(\"Bitcoin Volume over time\", size=25)\nplt.xlabel(\"Time\", size=20)\nplt.ylabel(\"Volume\", size=20);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Log to W&B\ncreate_wandb_lineplot(x_data=bitcoin[\"Timestamp\"][::50].to_array(), y_data=bitcoin[\"Volume_(Currency)\"][::50].to_array(), \n                     x_name=\"timestamp\", y_name=\"volume\", \n                     title=\"Volume Evolution\", log=\"volume_evolution\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.finish()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> The [W&B Dashboard](https://wandb.ai/andrada/bitcoin-musk?workspace=user-andrada):\n\n<center><img src=\"https://i.imgur.com/N6m3nyh.png\" width=800></center>\n\n## II. Testing Stationarity\n\nOur time series data **can have a trend or not**. It is of the utmost importance to determine how the series is behaving before applying any model to it.\n\n> **Augmented Dicky Fuller test**: it determines how strongly a time series is defined by a trend.\n\n**Hypothesis**:\n1. Null Hypothesis (H0): Null hypothesis of the test is that the time series can be represented by a unit root that **is not stationary**.\n2. Alternative Hypothesis (H1): Alternative Hypothesis of the test is that the time series **is stationary**.\n\n### Why is Stationarity Important?\nFor data to be stationary, the statistical properties of a system **do not change over time**. This does not mean that the values for each data point have to be the same, but the overall behavior of the data should remain constant.\n\nIf the data is non-stationary (meaning it has a trend), we need to **remove** it in order to proceed with the analysis.\n\n*My Reference: [Bitcoin Price Prediction](https://towardsdatascience.com/bitcoin-price-prediction-using-time-series-forecasting-9f468f7174d3)*","metadata":{}},{"cell_type":"code","source":"run = wandb.init(project='bitcoin-musk', name='stationarity')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_stationarity(x, log=\"non-stationary\"):\n    '''Test stationarity of a Time Series variable.'''\n    \n    # Perform Dickey Fuller test    \n    result = adfuller(x)\n    print('ADF Stastistic: %f'%result[0])\n    print('p-value: %f'%result[1])\n    pvalue=result[1]\n    \n    for key,value in result[4].items():\n        if result[0]>value:\n            print(color.BOLD + \"The graph is non stationary! (it has a trend)\" + color.END)\n            wandb.log({log : round(result[1], 5)})\n            break\n        else:\n            print(color.BOLD + \"The graph is stationary! (it doesn't have a trend)\" + color.END)\n            wandb.log({log : round(result[1], 5)})\n            break;\n    \n    print('Critical values:')\n    for key,value in result[4].items():\n        print('\\t%s: %.3f ' % (key, value))\n    \n    # Determing rolling statistics\n    rolmean = x.rolling(window=22,center=False).mean()\n    rolstd = x.rolling(window=12,center=False).std()\n    \n    # Plot rolling statistics:\n    plt.figure(figsize=(25, 11))\n    orig = plt.plot(x, color=my_colors[0], lw=8, label='Original')\n    mean = plt.plot(rolmean, color=my_colors[2], lw=2.5, ls=\"--\",  label='Rolling Mean')\n    std = plt.plot(rolstd, color=my_colors[3], lw=3, label = 'Rolling Std')\n    plt.legend(loc='best', fontsize=20)\n    plt.title('Rolling Mean & Standard Deviation', size=25)\n    plt.show(block=False)\n    \n    # Log to W&B\n    create_wandb_lineplot(x_data=pd.Series(range(len(rolmean))), y_data=pd.Series(rolmean), \n                          x_name=\"timestamp\", y_name=\"rolmean\", \n                          title=\"Stationarity Analysis\", log=log)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"price = pd.Series(bitcoin[\"Weighted_Price\"][::70].to_array())\ntest_stationarity(price, log=\"non-stationary\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And surprise surprise! The series has a trend (is non stationary). We could have noticed that by only using our naked eye, but we always need to double check.\n\n## III. From non-stationarity to stationarity\nNow that we now our series has a trend, we need to remove it in order to proceed with the models.\n\nWe can do that by applying a **natural log** to our series. Let's see how that's done!","metadata":{}},{"cell_type":"code","source":"# Adjust by applying natural log over the series\nadjusted_price = cupy.log(bitcoin[\"Weighted_Price\"])\n\nprice_adjusted = pd.Series(cupy.asnumpy(adjusted_price)[::70])\ntest_stationarity(price_adjusted, log=\"stationary\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the price with no trend into a new variable\nbitcoin[\"log_price\"] = adjusted_price","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.finish()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## IV. What tipe of ARIMA should I choose?\n\n### ARIMA:\n* AR: Auto Regressive model\n* I: Integrated\n* MA: Moving Average\n\nLet's take them step by step :)\n\n### Auto Regressive Model\n\n> An autoregressive (AR) model **predicts future behavior based on past behavior**. It's used for forecasting when there is **some correlation between values in a time series** and the values that precede and succeed them.\n\n**Criterias**\n\nLog Likelihood, Akaike and Bayesian Information Criterion are indicators that tell us how well our model is performing, meaning **how much information it's lost**. The less information lost, the better the model. Hence, we'll try to tweak these parameters and get ourselves the best model.","metadata":{}},{"cell_type":"code","source":"# Fit an ARI model - AR(1) + I(1)\nar_model = ARIMA(bitcoin[\"Weighted_Price\"][::100], order=(1,1,0), fit_intercept=True)\nar_model.fit()\n\n# Print Information on the model\nprint(color.BOLD + \"log-likelihood (smaller the better):\" + color.END, \"{:,.8}\".format(ar_model.llf[0]))\nprint(color.BOLD + \"\\nCorrected Akaike Information Criterion (AICc) (smaller the better):\" + color.END, \"{:,.8}\".format(ar_model.aicc[0]))\nprint(color.BOLD + \"\\nBayesian Information Criterion (BIC) (smaller the better):\" + color.END, \"{:,.8}\".format(ar_model.bic[0]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Moving Average Model\n> The moving-average model specifies that the output variable **depends linearly on the current and various past values** of a stochastic (imperfectly predictable) term.","metadata":{}},{"cell_type":"code","source":"# Fit an MA model - I(1) + MA(1)\nma_model = ARIMA(bitcoin[\"Weighted_Price\"][::100], order=(0,1,1), fit_intercept=True)\nma_model.fit()\n\n# Print Information on the model\nprint(color.BOLD + \"log-likelihood (smaller the better):\" + color.END, \"{:,.8}\".format(ma_model.llf[0]))\nprint(color.BOLD + \"\\nCorrected Akaike Information Criterion (AICc) (smaller the better):\" + color.END, \"{:,.8}\".format(ma_model.aicc[0]))\nprint(color.BOLD + \"\\nBayesian Information Criterion (BIC) (smaller the better):\" + color.END, \"{:,.8}\".format(ma_model.bic[0]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Auto Regressive Integrated Moving Average\n\n> Explains a given time series based on its own past values, that is, its own **lags** and the **lagged** forecast errors, so that equation can be used to forecast future values.","metadata":{}},{"cell_type":"code","source":"# Fit an MARIMA model AR(1) + I(1) + MA(2)\narima_model = ARIMA(bitcoin[\"Weighted_Price\"][::100], order=(1, 1, 2), fit_intercept=True)\narima_model.fit()\n\n# Print Information on the model\nprint(color.BOLD + \"log-likelihood (smaller the better):\" + color.END, \"{:,.8}\".format(arima_model.llf[0]))\nprint(color.BOLD + \"\\nCorrected Akaike Information Criterion (AICc) (smaller the better):\" + color.END, \"{:,.8}\".format(arima_model.aicc[0]))\nprint(color.BOLD + \"\\nBayesian Information Criterion (BIC) (smaller the better):\" + color.END, \"{:,.8}\".format(arima_model.bic[0]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## V. Predicting Bitcoin Price\n\nNow, let's predict Bitcoin Prices by using an ARIMA (1, 1, 2) model.\n\nThe steps will be:\n* Selecting only a small portion of data `test`: we don't have to train on all 3 mil rows of data. Choosing data that is closer ","metadata":{}},{"cell_type":"code","source":"run = wandb.init(project='bitcoin-musk', name='arima_predict')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def append(my_list, value):\n    '''.append() function does not exist for arrays (only for lists).\n    So we will make a function that tweaks this a bit.'''\n    \n    # Convert from array to list\n    my_list = my_list.tolist()\n    # Append new value\n    my_list.append(value)\n    # Convert back to array\n    my_list = cupy.asarray(my_list)\n    \n    return my_list","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ========== VARIABLES ==========\npercent = 0.99           ### percent of data to be used\nno_future_preds = 10    ### number of values to predict in the future\n# ===============================\n\nwandb.log({'percent_of_data':percent, 'future_values':no_future_preds})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Select only a small portion of the data\nsample_data = adjusted_price[percent*len(adjusted_price) : len(adjusted_price)]\nprint(color.BOLD + \"All data shape:\" + color.END, sample_data.shape)\n\n# Split into Train and Test data\nsplit = len(sample_data) - no_future_preds\n\ntrain_price = sample_data[:split]\ntest_price = sample_data[split:]\n\npred_list, actual_list, error_list = [], [], []","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# For each value in the 100 prices in test set\nfor k in range(len(test_price)):\n    \n    # Fit the arima model onto train data\n    arima_model = ARIMA(train_price, order=(1, 1, 2), fit_intercept=True)\n    arima_model.fit()\n    \n    # Predict next value\n    predicted_out = arima_model.forecast(1)[0]\n    predicted_out = np.exp(predicted_out)\n    \n    # Append the original value to training data\n    actual_out = test_price[k]\n    train_price = append(my_list=train_price, value=cupy.asnumpy(actual_out).min())\n    actual_out = np.exp(actual_out)\n    \n    # Compute the error of model\n    error = (abs(predicted_out - actual_out) / actual_out) * 100\n    print(color.BOLD + f\"Step {k}. | \" + color.END, \"Predicted: {} | Actual: {} | ERROR: {}\".format(predicted_out, actual_out, error))\n    \n    # Append information\n    pred_list.append(predicted_out)\n    actual_list.append(actual_out)\n    error_list.append(error)\n    \n    # Log to W&B\n    wandb.log({\"predicted\": float(predicted_out[0])}, step=k)\n    wandb.log({\"actual\": float(actual_out)}, step=k)\n    wandb.log({\"error\": float(error[0])}, step=k)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> This is how the logs look now in our Dashboard:\n\n<center><img src=\"https://i.imgur.com/CIrYGU7.png\" width=800></center>","metadata":{}},{"cell_type":"code","source":"# Prepare info to be plotted\nerror_list = [l[0].tolist() for l in error_list]\npred_list = [l[0].tolist() for l in pred_list]\nactual_list = [l.tolist() for l in actual_list]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(color.BOLD + 'Average Error:' + color.END, (sum(error_list) / float(len(error_list))))\n\n# Plot\nplt.figure(figsize=(25, 11))\ntime = [t for t in range(len(test_price))]\n\nplt.plot(time, pred_list, color=my_colors[0], label=\"Predicted\", lw=5)\nplt.plot(time, actual_list, color=my_colors[2], label=\"Actual\", lw=5)\nplt.title('Actual Vs Predicted Views Forecasting', size=25)\nplt.xlabel('Time', size=20)\nplt.ylabel('Price', size=20)\nplt.legend(fontsize=18);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Log to W&B\ncreate_wandb_lineplot(x_data=time, y_data=pred_list, \n                      x_name=\"time\", y_name=\"predictions\", \n                      title=\"Prediction Forecast\", log=\"prediction\")\ncreate_wandb_lineplot(x_data=time, y_data=actual_list, \n                      x_name=\"time\", y_name=\"actuals\", \n                      title=\"Actuals Values\", log=\"actuals\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> **Pro Tip**: If you would like to change something in the W&B Graph and you want it to show in the Dashboard, simply click \"Detach\" at the top after you've made your changes:\n\n<center><img src=\"https://i.imgur.com/NjIxgxj.png\" width=800></center>","metadata":{}},{"cell_type":"markdown","source":"### Use ARIMA to forecast the Future","metadata":{}},{"cell_type":"code","source":"def plot_prediction(actual, prediction, zoom=5000):\n    '''Plot actual and forecasted values in time.\n    actual: a GPU array of actual data in time\n    prediction: the predicted values from ARIMA model\n    zoom: number of observations (out of 3 million) to plot'''\n\n    actual_range = actual.count()\n    predict_range = prediction.count()\n    all_range = actual_range + predict_range\n    \n    plt.figure(figsize = (25, 10))\n    plt.plot(range(actual_range-zoom, actual_range), actual[actual_range-zoom:actual_range].to_array(), color=my_colors[0], lw=4, label=\"Actual\")\n    plt.plot(range(actual_range, all_range), prediction.to_array(), color=my_colors[3], lw=4, ls=\"--\", label=\"Predicted\")\n    plt.legend(fontsize=20)\n    plt.title(\"Prediction of Bitcoin Price\", size=25)\n    plt.xlabel(\"Time\", size=20)\n    plt.ylabel(\"log Price\", size=20);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"arima_model2 = ARIMA(sample_data, order=(1, 1, 2), fit_intercept=True)\narima_model2.fit()\npredictions = arima_model2.forecast(30)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_prediction(actual=cudf.Series(sample_data), prediction=cudf.Series(predictions), zoom=70)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.finish()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> The [W&B Dashboard](https://wandb.ai/andrada/bitcoin-musk?workspace=user-andrada):\n\n<center><img src=\"https://i.imgur.com/AKCHbUi.png\" width=800></center>\n\n# 3. üñá Is there correlation between Bitcoin and Elon Musk's Tweets?\n\nLet's find out!\n\nIn order to do this, I've decided to look at the points in time when Elon tweeted about Bitcoin.\n\n<center><img src=\"https://sm.pcmag.com/t/pcmag_uk/news/e/elon-musk-/elon-musk-tells-followers-to-use-signal-messaging-app-amid-w_p8u9.1920.jpg\" width = 450></center>\n\n## Overall View","metadata":{}},{"cell_type":"code","source":"# Get bitcoin info\nbtc_tweets = tweets[tweets[\"tweet\"].str.contains(\"bitcoin\")].reset_index(drop = True)\n# Convert date to number\nbtc_tweets[\"date\"] = btc_tweets[\"date\"].apply(lambda x: datetime.fromisoformat(x).timestamp())\n# Get only latest bitcoin data (as Elon never tweeted before 2018)\nbtc_prices = bitcoin.sort_values(\"Timestamp\", ascending=False).head(2000000)\ntimestamps = btc_tweets[\"date\"]\n\nfor k, tweet in enumerate(btc_tweets[\"tweet\"]): print(color.BOLD + f\"{k+1}.\" + color.END, tweet)\n\n# Get intersection\nx_values = cupy.asnumpy(btc_prices[btc_prices[\"Timestamp\"].isin(timestamps)][\"Timestamp\"])\ny_values = cupy.asnumpy(btc_prices[btc_prices[\"Timestamp\"].isin(timestamps)][\"Weighted_Price\"])\n\n# Plot\nplt.figure(figsize = (25, 11))\nfor x, y in zip(x_values, y_values):\n    plt.scatter(x, y, color=\"#FF451D\", lw=13, zorder=2)\nplt.plot(btc_prices[\"Timestamp\"].to_array(), btc_prices[\"Weighted_Price\"].to_array(), color=my_colors[3], lw=3, zorder=1)\nplt.title(\"Bitcoin Price & Elon's Tweets\", size=25)\nplt.xlabel(\"Time\", size=20)\nplt.ylabel(\"$ Price\", size=20);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> It doesn't really look like there is any strong correlation or that the tweets drive peaks.\n\n## Closer Look\n\nLet's use a magnifying glass and look closer to our points in time.","metadata":{}},{"cell_type":"code","source":"# Get bitcoin info\nbtc_tweets = tweets[tweets[\"tweet\"].str.contains(\"bitcoin\")].reset_index(drop = True)\n# Convert date to number\nbtc_tweets[\"date\"] = btc_tweets[\"date\"].apply(lambda x: datetime.fromisoformat(x).timestamp())\n# Get only latest bitcoin data (as Elon never tweeted before 2018)\nbtc_prices = bitcoin.sort_values(\"Timestamp\", ascending=False).head(80000)\ntimestamps = btc_tweets[\"date\"]\n\nfor k, tweet in enumerate(btc_tweets[\"tweet\"][:3]): print(color.BOLD + f\"{k+1}.\" + color.END, tweet)\n\n# Get intersection\nx_values = cupy.asnumpy(btc_prices[btc_prices[\"Timestamp\"].isin(timestamps)][\"Timestamp\"])\ny_values = cupy.asnumpy(btc_prices[btc_prices[\"Timestamp\"].isin(timestamps)][\"Weighted_Price\"])\n\n# Plot\nplt.figure(figsize = (25, 11))\nfor x, y in zip(x_values, y_values):\n    plt.scatter(x, y, color=\"#FF451D\", lw=13, zorder=2)\nplt.plot(btc_prices[\"Timestamp\"].to_array(), btc_prices[\"Weighted_Price\"].to_array(), color=my_colors[3], lw=3, zorder=1)\nplt.title(\"Last 3 tweets in time\", size=25)\nplt.xlabel(\"Time\", size=20)\nplt.ylabel(\"$ Price\", size=20);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> You can observe some sudden peaks within a few days (1 do 4 days) of the making of the tweet.\n\n# 4. üñá Is there correlation between Dogecoin and Elon Musk's Tweets?\n\nIs there?\n\n<center><img src=\"https://media.alephnews.ro/2021/04/musk-meme-doge.jpg\" width=500></center>","metadata":{}},{"cell_type":"code","source":"# Get bitcoin info\ndgc_tweets = tweets[tweets[\"tweet\"].str.contains(\"dogecoin\")].reset_index(drop = True)\n# Convert date to number\ndgc_tweets[\"date\"] = dgc_tweets[\"date\"].apply(lambda x: datetime.fromisoformat(x).timestamp())\ntimestamps = dgc_tweets[\"date\"]\n\ndgc_prices = dogecoin.sort_values(\"Date\", ascending=False).head(800)\ndgc_prices[\"Date\"] = dgc_prices[\"Date\"].apply(lambda x: datetime.fromisoformat(x).timestamp())\n\nfor k, tweet in enumerate(dgc_tweets[\"tweet\"]): print(color.BOLD + f\"{k+1}.\" + color.END, tweet)\n\n# Get intersection\nx_values = dgc_prices[dgc_prices[\"Date\"].isin(timestamps)][\"Date\"]\ny_values = dgc_prices[dgc_prices[\"Date\"].isin(timestamps)][\"Adj Close\"]\n\n# Plot\nplt.figure(figsize = (25, 11))\nfor x, y in zip(x_values, y_values):\n    plt.scatter(x, y, color=\"#FF451D\", lw=13, zorder=2)\nplt.plot(dgc_prices[\"Date\"], dgc_prices[\"Adj Close\"], color=my_colors[3], lw=3, zorder=1)\nplt.title(\"Dogecoin Price & Elon's Tweets\", size=25)\nplt.xlabel(\"Time\", size=20)\nplt.ylabel(\"$ Price\", size=20);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Closer Look","metadata":{}},{"cell_type":"code","source":"# Get bitcoin info\ndgc_tweets = tweets[tweets[\"tweet\"].str.contains(\"dogecoin\")].reset_index(drop = True)\n# Convert date to number\ndgc_tweets[\"date\"] = dgc_tweets[\"date\"].apply(lambda x: datetime.fromisoformat(x).timestamp())\ntimestamps = dgc_tweets[\"date\"]\n\ndgc_prices = dogecoin.sort_values(\"Date\", ascending=False).head(90)\ndgc_prices[\"Date\"] = dgc_prices[\"Date\"].apply(lambda x: datetime.fromisoformat(x).timestamp())\n\nfor k, tweet in enumerate(dgc_tweets[\"tweet\"][:6]): print(color.BOLD + f\"{k+1}.\" + color.END, tweet)\n\n# Get intersection\nx_values = dgc_prices[dgc_prices[\"Date\"].isin(timestamps)][\"Date\"]\ny_values = dgc_prices[dgc_prices[\"Date\"].isin(timestamps)][\"Adj Close\"]\n\n# Plot\nplt.figure(figsize = (25, 11))\nfor x, y in zip(x_values, y_values):\n    plt.scatter(x, y, color=\"#FF451D\", lw=13, zorder=2)\nplt.plot(dgc_prices[\"Date\"], dgc_prices[\"Adj Close\"], color=my_colors[3], lw=3, zorder=1)\nplt.title(\"Dogecoin Price & Elon's Tweets\", size=25)\nplt.xlabel(\"Time\", size=20)\nplt.ylabel(\"$ Price\", size=20);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### TODO:\n* Import W&B overlapped graphs","metadata":{}},{"cell_type":"markdown","source":"# ‚è≥ Work in Progress\n\n<img src=\"https://i.imgur.com/cUQXtS7.png\">\n\n# ‚å®Ô∏èüé® Specs on how I trained using RAPIDS\n### (on my local machine)\n* Z8 G4 Workstation üñ•\n* 2 CPUs & 96GB Memory üíæ\n* NVIDIA Quadro RTX 8000 üéÆ\n* RAPIDS version 0.18 üèÉüèæ‚Äç‚ôÄÔ∏è","metadata":{}}]}