{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Logistic regression on stroke prediction dataset"},{"metadata":{},"cell_type":"markdown","source":"Context:\n* Given a dataset that contain multiple variable and a target variable of stroke or no stroke (symbolize by 1 and 0), I would like to build a model where it can predict whether the user will more likely to get stroke or not.\n"},{"metadata":{},"cell_type":"markdown","source":"There are few steps that I will take in building prediction, they are:\n1. Data preprocessing -> to fill blank values, change the categorical values to numerical \n2. Splitting train and test data\n3. Build logistic regression model -> train the data\n4. Predict the test data\n5. Review the accuracy\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import library for numerical computation\nimport pandas as pd\nimport numpy as np\nimport pylab as pl\n\n#import library for visualisation\n%matplotlib inline \nimport matplotlib.pyplot as plt\n\n#import library for model\nfrom sklearn.model_selection import train_test_split\nimport scipy.optimize as opt\nfrom sklearn import preprocessing\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#read the data\ndf = pd.read_csv('/kaggle/input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv')\ndf.smoking_status.unique","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print the summary\ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As can be seen from the data above, there is a null data on the BMI desrcribed as NaN, we need to replace this with the average of the BMI"},{"metadata":{"trusted":true},"cell_type":"code","source":"#data preprocessing\n\n#replacing nan value with the average of the columns\ndf[\"bmi\"] = df[\"bmi\"].fillna(df[\"bmi\"].mean())\n\n#replacing gender male and female with 1 and 0\ndf.gender[df.gender == 'Male'] = 1\ndf.gender[df.gender == 'Female'] = 0\ndf.gender[df.gender == 'Other'] = 3\n\n#replacing smoking status with numerical values\ndf.smoking_status[df.smoking_status == 'never smoked'] = 0\ndf.smoking_status[df.smoking_status == 'formerly smoked'] = 1\ndf.smoking_status[df.smoking_status == 'smokes'] = 2\ndf.smoking_status[df.smoking_status == 'Unknown'] = 3\n#df['smoking_status'] = df['smoking_status'].apply({0:'never smoked', 1:'formerly smoked', 2:'smokes'}.get)\n\ndf.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Now since we have pre process the data, we will the select columns that will be used as the independent variable to explain whether user have higher probability to get stroke or not**"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df[[\"gender\",\"age\",\"hypertension\",\"heart_disease\",\"avg_glucose_level\",\"bmi\",\"smoking_status\"]]\ny = df[\"stroke\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#now new need to normalize the X\nX = preprocessing.StandardScaler().fit(X).transform(X)\nX[0:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#after do the data pre processing, now its time for us to split the data into train and test data\nX_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size = 0.3, random_state = 4)\nprint(\"X_train shape: {}\", format(X_train.shape))\nprint(\"Y_train shape: {}\", format(Y_train.shape))\nprint(\"X_test shape: {}\", format(X_test.shape))\nprint(\"Y_test shape: {}\", format(Y_test.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#now lets build logistic regression model\nstroke_lr = LogisticRegression(C=0.01, solver='liblinear').fit(X_train,Y_train)\nstroke_lr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#predicting the test dataset\ny_hat = stroke_lr.predict(X_test)\ny_hat[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yhat_prob = stroke_lr.predict_proba(X_test)\nyhat_prob","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nimport itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\nprint(confusion_matrix(Y_test, y_hat, labels=[1,0]))\n\n# Compute confusion matrix\ncnf_matrix = confusion_matrix(Y_test, y_hat, labels=[1,0])\nnp.set_printoptions(precision=2)\n\n\n# Plot non-normalized confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=['stroke=1','no stroke=0'],normalize= False,  title='Confusion matrix')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import jaccard_score\njaccard_score(Y_test, y_hat,pos_label=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In summary:\n* Using logistic regression to predict whether a user will have higher probability of getting cancer or not can yield 95% accuracy when the model is being tested out to the test set.\n* Another important thing in here that I do not include some categorical data such as ever_married, work_type, and residence_type"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}