{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# LIBRARIES\n# Data Wrangling\nimport pandas as pd\nimport numpy as np\nfrom collections import Counter\nimport re\nimport math\nimport joblib\nimport io\nimport base64\nimport pickle\nfrom time import sleep\nimport random\nimport string\n# Visualization\nimport seaborn as sns\nsns.set_style(\"whitegrid\")\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nimport matplotlib.colors as colors\nimport plotly.graph_objs as go\nimport plotly.offline as pyo\npyo.init_notebook_mode()\nimport plotly.express as px\nfrom IPython.display import display\n# Spatial\nimport folium\nfrom folium import Map,Choropleth, Circle, Marker,LayerControl,GeoJson,Icon,Popup\nfrom folium.plugins import HeatMap, MarkerCluster\nfrom IPython.display import IFrame\nimport branca.colormap as branca_folium_cm\nimport geopandas as gpd\nfrom shapely import wkt\nfrom shapely.geometry import Point, Polygon\n# Temporal\nfrom datetime import datetime,timedelta\nfrom statsmodels.tsa.seasonal import seasonal_decompose\n# Text\nfrom wordcloud import WordCloud\nimport nltk\nfrom nltk.corpus import stopwords\nstopwords_nltk =nltk.corpus.stopwords.words('spanish')\nfrom nltk.stem import SnowballStemmer\nfrom nltk import word_tokenize\nfrom nltk.util import ngrams\nimport spacy\nfrom spacy.lang.es.stop_words import STOP_WORDS\nfrom textblob import Word,TextBlob\n!pip install langdetect\nfrom langdetect import detect\n# Modeling\nfrom sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer,TfidfTransformer\nfrom sklearn.metrics.pairwise import cosine_similarity\n!python -m spacy download es_core_news_sm\nfrom spacy.lang.es import Spanish\nimport es_core_news_sm\nnlp = es_core_news_sm.load()\n# Modeling\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.manifold import TSNE\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split,StratifiedKFold\nfrom sklearn.metrics import roc_curve,roc_auc_score,log_loss,accuracy_score,silhouette_samples,silhouette_score,plot_confusion_matrix,classification_report,confusion_matrix","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-08-06T01:26:58.987773Z","iopub.execute_input":"2021-08-06T01:26:58.988081Z","iopub.status.idle":"2021-08-06T01:27:16.565364Z","shell.execute_reply.started":"2021-08-06T01:26:58.988055Z","shell.execute_reply":"2021-08-06T01:27:16.564463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Sentiment and GeoSpatial Analysis in Peruvian Food Reviews\n\nNatural language processing (NLP) refers to the branch of artificial intelligence concerned with giving computers the ability to understand text and spoken words in much the same way human beings can. On the other hand, Geospatial analysis is the gathering, display, and manipulation of imagery, GPS, satellite photography and historical data, described explicitly in terms of geographic coordinates or implicitly, in terms of a street address, postal code, or forest stand identifier as they are applied to geographic models.\n\nAbout the topic, Peru is one of best and peculiar culinary destination in the world. This country has diverse climates and ecological floors, where various crops have been developed. In this way, it has a lot of natural and unique inputs. So, peruvian food is a cuisine of opposites: hot and cold on the same plate. Acidic tastes melding with the starchy. Robust and delicate at the same time. All with an excellent result.\n\nAbout the Kaggle dataset, [**Peruvian Food Reviews**](https://www.kaggle.com/lazaro97/peruvian-food-reviews) have a diversity of information. This have text, spatial and temporal features! It's a good opportunity to show some mixed ideas about sentiment analysis, geospatial analysis and time series analysis. Possible uses here are: market research, create an guide app for clients.\n\n<center><img src=\"https://th.bing.com/th/id/OIP.cs5iCAa15Cz-27OnLnY6LgHaDl?pid=ImgDet&rs=1\" alt=\"centered image\" height=\"898\" width=\"678\"> </center>\n\nIn general, the project that i did are the following steps:\n- Extraction of Web-Data: Using Web Scraping in the platforms TripAdvisor and GoogleMaps.\n- Preprocessing: The computer should read all features. It exists a set of steps there.\n- Exploratory Analysis: Some first plots and get a first idea of the data.\n- Clustering: A review can be classified by emotion or sentiment. That is possible using Spanish NrcLexicon.\n- Classification: Identify what reviews are good, bad or so-so, and what is the probability to occur that.\n- Reports: The restaurants (or districts) have unique features and is interesting to see the diversity of patterns in each one.\n- Dashboard: Summary of all project where it exists interactivity with an user.\n<div class=\"alert alert-block alert-success\">  \nHello everybody! üòä<br>\nI have some lines of code (Python, R) in my local computer. If you like this series of notebooks (and dataset) don't forget to upvote. That's a good motivation to continue in create similar projects in near future.<br>\nThe way that i got the dataset you can find <a href=https://github.com/Lazaro-97/satisfaction-in-restaurants>here</a>. If you are interested in a specify country, you can change and adapt the code.<br>\nPd: Please see the dictionary of data, that contains a lot of information. At the moment this is the <B>base notebook</B>, i hope to see more complex works üòä.\n</div>  ","metadata":{}},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"# GET DATA\n# General data\nreviews_df=pd.read_csv('../input/peruvian-food-reviews/data/data/reviews.csv')\nreviews_df.dropna(subset=['review'],inplace=True)\nreviews_df.drop_duplicates(subset=['review'],inplace=True,keep=False)\nrestaurants_df=pd.read_csv('../input/peruvian-food-reviews/data/data/restaurants.csv')\n# Auxiliar data\nborders=gpd.read_file('../input/peruvian-food-reviews/data/data/geospatial/districts.shp')\nnrc=pd.read_csv('../input/peruvian-food-reviews/data/data/spanish-nrc/lexico_nrc.csv')\n# PREPROCESSING\ntrans=str.maketrans('√°√©√≠√≥√∫√º√±√Å√â√ç√ì√ö√ú','aeiouunAEIOUU')\nlemma_n={'limar':'lima','increiblemente':'increible','normalito':'normal','encantado':'encantar','lamentablemente':'lamentable','buenazo':'bueno','buenisimo':'bueno','buenisima':'bueno','zoolog':'zoo','abuelit':'abuel','malisimo':'malo','decepcion':'decepcio','decepcionado':'decepcio','decepcioado':'decepcio','decepcioante':'decepcio','riquisimo':'rico','recomendado':'recome','recomendacion':'recome','recomeir':'recome','recomer':'recome','recomendar':'recome','recomendarr':'recome','recomer':'recome','recomendarrr':'recome','recomendable':'recome','deliciosa':'delicia','delicioso':'delicia','delicios':'delicia','pesima':'pesimo','fria':'frio','atencion':'atender','comida':'comer','ambientar':'ambiente','venezuela':'venezolano','preciar':'precio','malisima':'malo'}\nlist_stopwords=list(set(stopwords_nltk+list(STOP_WORDS)+['\\n','\\t','nan','','aa',' ','q','pq','and','xd','xq']))\ndef remove_translate(x):\n    x=str(x)\n    if x.__contains__('(Traducci√≥n de Google)'): return x[len('(Traducci√≥n de Google)')+1:x.find('(Original)')]\n    else: return x\ndef create_lemma(x,dc):\n    if any(ext in x for ext in dc.keys()): \n        for k in dc.keys():\n            x=str(x).replace(k, str(dc[k]))\n        return x.replace('recome','recomendar').replace('ceviche','cebiche')\n    else: return x.replace('recome','recomendar').replace('ceviche','cebiche')\ndef preprocess_text(x):\n    try:\n        x=remove_translate(x)\n        x=x.lower()\n        x = re.sub('\\[.*?¬ø\\]\\%', '', x)\n        x = re.sub('[%s]' % re.escape(string.punctuation), '', x)\n        x = re.sub('\\w*\\d\\w*', '', x)\n        x = re.sub('[‚Äò‚Äô‚Äú‚Äù‚Ä¶¬´¬ª]', '', x)\n        x = re.sub('\\n', ' ', x)\n        x=x.replace('<br>','').replace('</br>','')\n        x= [t.lemma_.lower().translate(trans) for t in nlp(x) if (not t.is_stop) &(t.text not in list_stopwords)]\n        x=' '.join(x)\n        return create_lemma(x,lemma_n)\n    except Exception as e:  return ''\ndef get_entities(x):\n\ttry: return ' '.join([token.text for token in nlp(x) if (token.ent_type!=0) & (token.is_stop==False)])\n\texcept: return ''\ndef get_labels(x):\n    if x>3: return 'Excellent'\n    elif x<3: return 'Bad'\n    else: return 'Ok'\ndef translate_lg(x):\n\ttry: return detect(x)\n\texcept: return ' '\nreviews_df['language']=reviews_df['review'].apply(translate_lg) #Is not precise\nreviews_df=reviews_df[reviews_df['language']=='es']\nreviews_df['label']=reviews_df['score'].apply(lambda x: 'Excellent' if x>3 else 'Bad' if x<3 else 'Ok')\nreviews_df['pre_review']=reviews_df['review'].apply(preprocess_text)\n#reviews_df['entity']=reviews_df['review'].apply(get_entities) In 1rst and 2nd version\nreviews_df['date']=pd.Categorical(reviews_df['date'],categories=['1 months ago','2 months ago','3 months ago','4 months ago','5 months ago','6 months ago','7 months ago','8 months ago','9 months ago','10 months ago','11 months ago','12 months ago','1 years ago','2 years ago','3 years ago','4 years ago','5 years ago','6 years ago','7 years ago','8 years ago','9 years ago','10 years ago','11 years ago','12 years ago','13 years ago'],ordered=True)\ndef get_tags(df):\n\tvectorizer=CountVectorizer(tokenizer = lambda x:[x.split('||', 1)[0].strip()])\n\tmat=vectorizer.fit_transform(df.tag).toarray()\n\tmat=pd.DataFrame(mat,columns=vectorizer.get_feature_names())\n\tmat.drop(['','$', '$$ - $$$', '$$$$'],axis=1,inplace = True)\n\tmat=pd.concat([df.id,mat],axis = 1)\n\tmat.to_csv('./tag.csv',index=False)\n#get_tags(restaurants_df) In 1rst and 2nd version\nall_df=reviews_df.merge(restaurants_df,how='left',left_on='service',right_on='id')[['id_review', 'review', 'title', 'score', 'likes', 'id_nick', 'service','date', 'label', 'pre_review', 'id', 'name', 'tag','x', 'y', 'district', 'IDDIST']]\nall_df.to_csv('./all.csv')","metadata":{"execution":{"iopub.status.busy":"2021-08-06T01:27:16.566919Z","iopub.execute_input":"2021-08-06T01:27:16.567201Z","iopub.status.idle":"2021-08-06T01:27:54.034029Z","shell.execute_reply.started":"2021-08-06T01:27:16.567171Z","shell.execute_reply":"2021-08-06T01:27:54.03302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Saving the infomation to use in another moment:\n- All: Reviews with new **features**: preprocessed text, detection of entities, new label in scores, and **conexion** with Restaurants getting district, x, y and name of restaurant.\n- Tag: Type of restaurant. What products do they sell?","metadata":{}},{"cell_type":"markdown","source":"# Geospatial Analysis","metadata":{}},{"cell_type":"code","source":"def geo_map(df,dg,districts):\n\tdistricts = districts[[\"IDDIST\", \"geometry\"]].set_index(\"IDDIST\")\n\tmap = Map(location=[-12.3101093,-76.8850579], tiles='Stamen Toner', zoom_start=9.2) \n\tChoropleth(geo_data=districts.__geo_interface__,\n          data=df['stars'],\n          key_on=\"feature.id\",\n           fill_color='Blues',\n         #  legend_name=\"Satisfaction of restaurant's services in Lima by district\"\n          ).add_to(map)\n\tHeatMap(data=zip(dg['x'], dg['y'],dg['n_reviews']), radius=30).add_to(map)\n\tmc = MarkerCluster()\n\tfor idx, row in dg.iterrows():\n\t\thtml=f\"\"\"\n\t\t    <h1 style=\"color:DodgerBlue;\"> <b> {row['name']} </b></h1>\n\t\t    <p> {row['stars']/10} estrellas </p>\n\t\t    <p> {row['n_reviews']} rese√±as </p>\n\t\t     <p> {row['direction']} </p>\n\t\t    \"\"\"\n\t\tpopup = Popup(folium.IFrame(html=html, width=500, height=300), max_width=2650)\n\t\tmc.add_child(Marker([row['x'], row['y']],color='red',popup = popup,icon=Icon(color='blue')))#\n\tmap.add_child(mc)\n\treturn embed_map(map,'./map.html')\ndef embed_map(m, file_name):\n    m.save(file_name)\n    return IFrame(file_name, width='100%', height='500px')\ndgs=restaurants_df[restaurants_df['IDDIST']!='Out']\ndg=dgs.groupby(by=\"IDDIST\").mean()\nds=borders[borders['PROVINCIA']=='LIMA']\ngeo_map(dg,dgs,ds)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T01:27:54.035991Z","iopub.execute_input":"2021-08-06T01:27:54.036256Z","iopub.status.idle":"2021-08-06T01:28:22.973343Z","shell.execute_reply.started":"2021-08-06T01:27:54.03623Z","shell.execute_reply":"2021-08-06T01:28:22.972187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- The heatmap and red scale represents the number of reviews.\n- The choropleth map and blue scale represents the mean score by district.\n- The ubication of the restaurants in markers.\n\nPd: The map can be adapted for other cases. For example: analyzing the progress of COVID-19 vaccination, or maybe, analyzing the taccidents in any state.","metadata":{}},{"cell_type":"markdown","source":"# Create reports","metadata":{}},{"cell_type":"code","source":"class report:\n\tdef __init__(self,x,c,ids):\n\t\tself.df=x\n\t\tself.element=c\n\t\tself.ids=ids\n\tdef generate_all(self):\n\t\tfor idx in self.ids: \n\t\t\tprint(f'Analyzing the {self.element} {idx}')\n\t\t\tdf=self.df[self.df[self.element]==idx]\n\t\t\tself.get_score(df)\n\t\t\tself.generate_wordcloud(df,idx)\n\t\t\tself.get_reviews(df)\n\t\t\tself.get_timeseries(df)\n\tdef get_reviews(self,df):\n\t\tfill_color = []; n = len(df)\n\t\tfor i in range(n):\n\t\t\tif df.iloc[i]['label']=='Excellent':fill_color.append('rgb(102, 178, 255)')\n\t\t\telif df.iloc[i]['label']=='Bad':fill_color.append(\"rgb(255, 102, 102)\")\n\t\t\telse:fill_color.append('rgb(153, 255, 204)')\n\t\tfig = go.Figure(data=[\n\t        go.Table(columnorder = [1,2], columnwidth = [440,40],\n\t      header=dict(values=['<b>Reviews</b>', '<b>Score</b>'],\n\t        line_color='black', fill_color='black',\n\t        align='center',font=dict(color='white', size=12)),\n\t      cells=dict(values=[df.review, df.score],\n\t        line_color=['black']*2,fill_color=[fill_color,fill_color],\n\t        align='center', font=dict(color='black', size=11)))\n\t    ])        \n\t\tfig.show()\n\tdef generate_wordcloud(self,df,save):\n\t\twordcloud = WordCloud(width=1640, height=1200,stopwords=set(stopwords.words('spanish')).union(set(['pre_review','Length','dtype','object','comida','comer','rico','atender','restaurante','servicio','plato','excelente','recomendar','delicia','ambiente','sabor','pedir','precio','agradable','local','calidad'])),\n\t        max_font_size=500,scale=3,random_state=60).generate(\" \".join(df['pre_review'])) #Removing very common words in restaurants\n\t\twordcloud.recolor(random_state=1)\n\t\tplt.figure(figsize=(25, 21))\n\t\tplt.imshow(wordcloud)\n\t\tplt.axis('off')\n\t\tplt.savefig(f'./wordcloud_{save}.png')\n\t\tplt.show()\n\tdef get_score(self,df):\n\t\tdg=pd.DataFrame(df['score'].value_counts())\n\t\tdg.sort_index(inplace=True)\n\t\tdg.columns=['Number of reviews']\n\t\tclrs=['red' if (x > dg['Number of reviews'].sum()/3) else 'lightcoral' for x in dg['Number of reviews'] ]\n\t\tfig = go.Figure(data=[go.Bar(\n            x=['Stars_1','Stars_2','Stars_3','Stars_4','Stars_5'],\n            y=dg['Number of reviews'],\n            marker_color=clrs\n        )])\n\t\tfig.show()\n\tdef get_timeseries(self,df):\n\t\tdg=df.groupby(by=\"date\").agg(['count', 'mean'])\n\t\tdg.sort_index(inplace=True,ascending=False)\n\t\tdg.dropna(inplace=True)\n\t\tfig=go.Figure([go.Scatter(x=dg['score']['mean'].index, y=dg['score']['mean'].values)])\n\t\tfig.update_layout(paper_bgcolor='rgba(0,0,0,1)',  plot_bgcolor='rgba(0,0,0,1)',font=dict(size=10, color='#ffffff'),)\n\t\tfig.show()      ","metadata":{"_kg_hide-input":false,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-08-06T01:28:22.975421Z","iopub.execute_input":"2021-08-06T01:28:22.97574Z","iopub.status.idle":"2021-08-06T01:28:23.000457Z","shell.execute_reply.started":"2021-08-06T01:28:22.975709Z","shell.execute_reply":"2021-08-06T01:28:22.99873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Analyzing districts","metadata":{}},{"cell_type":"code","source":"report(all_df,'district',['MIRAFLORES','SANTIAGO DE SURCO']).generate_all()","metadata":{"execution":{"iopub.status.busy":"2021-08-06T01:28:23.002234Z","iopub.execute_input":"2021-08-06T01:28:23.002543Z","iopub.status.idle":"2021-08-06T01:28:30.961268Z","shell.execute_reply.started":"2021-08-06T01:28:23.002518Z","shell.execute_reply":"2021-08-06T01:28:30.959143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Analyzing restaurants","metadata":{}},{"cell_type":"code","source":"report(reviews_df,'service',[242558.0,275258.0]).generate_all() # Name of restaurants: Mango, El restaurante venezolano","metadata":{"execution":{"iopub.status.busy":"2021-08-06T01:28:30.962263Z","iopub.status.idle":"2021-08-06T01:28:30.962672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Distribution of score\n- Wordcloud\n- List of reviews\n- Evolution of mean score\n\nBy district, By restaurant","metadata":{}},{"cell_type":"markdown","source":"# Classification","metadata":{}},{"cell_type":"code","source":"def model(c=1):\n    return Pipeline([('vect', CountVectorizer(analyzer = \"word\",min_df=20,stop_words = stopwords_nltk)),\n                     ('tfidf', TfidfTransformer(norm = 'l2',use_idf = True)),\n                     ('model', LogisticRegression(solver = 'newton-cg',max_iter = 1000,tol=1e-4,C = c))])\ndef training_cv(X_train,y_train,mod):\n    skf=StratifiedKFold(n_splits = 10,shuffle = True,random_state = 60)\n    yv=np.zeros(len(X_train))\n    yvs=np.zeros((len(X_train),5))\n    fi=pd.DataFrame(columns=[f\"W_Class_{k}\" for k in range(5)])\n    for fold,(idx_tr,idx_vl) in enumerate(skf.split(X_train,y_train)):\n        X_tr,y_tr=X_train.iloc[idx_tr],y_train.iloc[idx_tr]\n        X_vl,y_vl=X_train.iloc[idx_vl],y_train.iloc[idx_vl]\n        model = mod.fit(X_tr,y_tr)\n        fi = pd.DataFrame(model['vect'].get_feature_names(), columns = [\"Features\"])\n        for k in range(5): fi[f\"W_Class_{k}\"] = +pow(math.e, model['model'].coef_[k])\n        yv[idx_vl]=model.predict(X_vl)\n        yvs[idx_vl]=model.predict_proba(X_vl)\n    return yv,yvs,fi\ndef evaluation(yreal,y,ys):\n    print(classification_report(yreal, y))\n    print('AUC: ',roc_auc_score(yreal, ys, multi_class='ovo', average='weighted'))\n    print('Accuracy: ',accuracy_score(yreal, y))\n    print('Log_Loss: ',log_loss(yreal, ys))\n    plt.figure(figsize=(6,5))\n    sns.heatmap(pd.DataFrame(confusion_matrix(yreal, y)), annot=True, linewidths=.5, fmt=\"d\")\n    plt.savefig('./confusion_matrix.png')\n    plt.show()\n    col=['red','orange','yellow','blue','green']\n    plt.figure(figsize=(7,6))\n    for k in range(5): sns.kdeplot(x=ys[:,k],fill=True,color = col[k])\n    plt.savefig('./distributions.png')\n    plt.show()\ndef model_weights(df):\n#    df[\"OddsRatio_4-3\"] = df['W_Class_4']/df['W_Class_3']\n    print(df)\n    i,j=0,0\n    fig, axes = plt.subplots(nrows=2, ncols=3,figsize=(8,7))\n    for k in range(5):\n        df=df.sort_values(by = [f\"W_Class_{k}\"], ascending=False)\n        plt.subplot(2,3,k+1)\n        if j>2: i=1;j=0\n        df[:10].plot.barh(x='Features', y=f\"W_Class_{k}\",color='blue',ax=axes[i,j])\n        j=j+1\n    plt.savefig(f'feat_importance.png')\t\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-06T01:28:30.963345Z","iopub.status.idle":"2021-08-06T01:28:30.963706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reviews_df.drop_duplicates(inplace=True,subset=['pre_review'])\nreviews_df.reset_index(inplace=True)\nyv,yvs,fi=training_cv(reviews_df['pre_review'],reviews_df['score'],model())\nmodel_weights(fi)\nevaluation(reviews_df['score'],yv,yvs)\ndfx=pd.DataFrame({'stars_1':yvs[:,0],'stars_2':yvs[:,1],'stars_3':yvs[:,2],'stars_4':yvs[:,3],'stars_5':yvs[:,4]})\npd.concat([reviews_df['id_review'],dfx],axis=1).to_csv('./model.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T01:28:30.964333Z","iopub.status.idle":"2021-08-06T01:28:30.964687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Saving the predictions to use in another moment.\n- The model is good but the metrics can be better. Trying another options as Convolutional or Recurrent Neural Networks.\n- The data have problems with lemmatization. Exist more resources using English language but i hope to find better results.","metadata":{}},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-success\">  \nWork in progress..</div>\n\nFuture Tasks here: A convolutional neural network model","metadata":{}}]}