{"cells":[{"metadata":{},"cell_type":"markdown","source":"# The Last of Us Reviews: a starter analysis\n\n![ellie!](https://www.hdwallpapers.in/download/the_last_of_us_part_ii_ellie-1366x768.jpg)\n\nNatural language processing (NLP) refers to the branch of artificial intelligence concerned with giving computers the ability to understand text and spoken words in much the same way human beings can. In fact, today the machines can analyze more language-based data than humans, without fatigue and in a consistent, unbiased way ([Sas Insight](https://www.sas.com/en_us/insights/analytics/what-is-natural-language-processing-nlp.html#close)). And is possible to see in the projects of this topics that those tools are increasing and developing awesome applications. One field (or first steps) of this is the sentiment analysis and the build of any classification model. This way transforms large-scaled unstructured text data into structured and quantitative measurements to be able to identify if the sentiment behind a piece of text is positive, negative, or neutral. \n\nIn the other hand, The Last of Us Part II is the 2nd best game and the most discussed last year ([Metacritic](https://www.metacritic.com/game/playstation-4/the-last-of-us-part-ii)) having a lot of different opinions. Certainly i was surprised with the level of divergence caused by this video-game: very positive and very negative reviews. If you visit the above web-page, you can see a large number of user's reviews and a weird distribution in the user's score. So, does it exist a way to analyze it in depth? why the bad reviews are very bad reviews? and why the good reviews are very good reviews?  At this oportunity, i tried to find a classification model using the reviews of that web-page.\n\nFirst of all, let's look at how the game was presented:  (more info in [PlaystationStore](https://www.playstation.com/en-us/games/the-last-of-us-part-ii/)) \n\n<div class=\"alert alert-block alert-success\">  \nFive years after their dangerous journey across the post-pandemic United States, Ellie and Joel have settled down in Jackson, Wyoming. Living amongst a thriving community of survivors has allowed them peace and stability, despite the constant threat of the infected and other, more desperate survivors. When a violent event disrupts that peace, Ellie embarks on a relentless journey to carry out justice and find closure. As she hunts those responsible one by one, she is confronted with the devastating physical and emotional repercussions of her actions.\n    <ul>\n    <li>A complex and emotional story</li>\n<li>Tense and desperate action-survival gameplay</li>\n<li>A beautiful yet dangerous world</li>\n    </ul>\n</div>\n\nInteresting. The continuation of one of the best PS4 video-games with a promising story being ellie a more complex character. And no less important, a post pandemic story in this times (well in its release). Personally, that game was great for me, it was very realistic and it has incredible graphics. However, all users don't agree. On this other side, some persons hate this game, they says it has a bad story, the characters doesn't have sense and more... and I understand that point of view too but not in a extreme case. \n\nAnyway, the opinions are very different and is a challenge to propose any model. Also, is possible define an interactive dashboard or app, surely I'll add this in an update. For the first case, i want to have something like the next gif with a good prediction power. So, let's get started.\n\nPd: Obviously, this work contains spoilers. If you don't know the story of the Last of Us (mainly the first game). Go to play!\n\n![sgif!](https://coinerblog.com/wp-content/uploads/2019/05/Can-We-Represent-Emotions-Using-Machine-Learning.gif)\n\n-- --\nHello everybody! ðŸ‘‹ Welcome to this starter notebook. At this oportunity I only used the user reviews for the second game. The kaggle dataset contain reviews about all saga and you can find [here](https://www.kaggle.com/lazaro97/the-last-of-us-reviews). About the recollection, this was obtained through web scraping, more info [here](https://github.com/Lazaro-97/Web-Scraping-Project). If you are interested in this project, don't hesitate to propose any notebook or topic. I'll read everything!\n\nPd: Don't forget to visit https://www.kaggle.com/lazaro97/the-last-of-us-reviews"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"!pip install langdetect\n!pip install nrclex\n!pip install spacy\n!pip install plotly\n#general packages\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom collections import Counter,OrderedDict\n#plots and visualizations\nfrom matplotlib import rc\nimport matplotlib.pyplot as plt\nfrom matplotlib_venn import venn2,venn3\n%matplotlib inline\nfrom mpl_toolkits.axes_grid1.inset_locator import mark_inset,zoomed_inset_axes\nimport altair as alt\nimport plotly.graph_objs as go\nimport plotly.offline as pyo\npyo.init_notebook_mode() # Set notebook mode to work in offline\nfrom plotly.subplots import make_subplots\nimport plotly.express as px\nfrom plotly.colors import n_colors\n#date preprocessing\nfrom datetime import datetime\n#text preprocessing\nimport spacy\n#from spacy.matcher import PhraseMatcher\nfrom spacy.lang.en import English\nfrom spacy.lang.en.stop_words import STOP_WORDS\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer,SnowballStemmer\nfrom nltk.tokenize import RegexpTokenizer\nfrom nltk.util import ngrams\nfrom nltk import word_tokenize\nfrom string import punctuation, digits\nfrom textblob import Word \nfrom wordcloud import WordCloud\nfrom langdetect import detect\nfrom nrclex import NRCLex\nfrom sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer,TfidfTransformer\n#modelling\nfrom sklearn.linear_model import LogisticRegression,RidgeClassifier\nfrom sklearn.model_selection import train_test_split,StratifiedKFold,KFold\nfrom sklearn.metrics import plot_confusion_matrix,roc_auc_score\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.cluster import DBSCAN,KMeans\nfrom sklearn.decomposition import PCA\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#GET DATA\n#list of reviews\ndat=pd.read_csv('../input/the-last-of-us-reviews/user_reviews_g2.csv')\n#specific stopwords\nvg_stopwords=['videogame','game','play','player','character','tlou','tlou2', 'neil','druckmann','naughty','dog','nc',\n 'aaa', 'na','youtube', 'youtuber','f','h','ng']\n#lexicons\nafinn=pd.read_csv('../input/sentiment-lexicons-for-text-mining/afinn.csv',encoding='iso-8859-1',index_col=0)\nbing=pd.read_csv('../input/sentiment-lexicons-for-text-mining/bing.csv',index_col=0)\nnrc=pd.read_csv('../input/sentiment-lexicons-for-text-mining/nrc.csv',index_col=0)\nloug=pd.read_csv('../input/sentiment-lexicons-for-text-mining/loughran.csv',index_col=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"#CLEANING\n#Replace null values\n#sns.heatmap(dat.isna().T,cbar=False,cmap=\"rocket\",xticklabels=False) #This set doesn't have null values \ndat.fillna('',inplace=True)\n#Create some variables\n#general features\ndat['sug']=dat.votes/dat.views\n#possible Target\ndef new_label(x): \n    if x>7: return 'Excellent'\n    elif x<3: return 'Bad'\n    else: return 'Ok'\ndat['label']=dat.score.apply(new_label)\n#datetime features\ndat['date']=dat.date.astype('datetime64[ns]')\ndat['month']=dat.date.apply(lambda x: x.strftime(\"%B\"))\ndat['day_of_month']=dat.date.apply(lambda x: x.strftime(\"%d\"))\ndat['day_of_week']=dat.date.apply(lambda x: x.strftime(\"%A\"))\n#text features\ndat['review_length'] = dat.review.apply(len)\ndat.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Summary of reviews\ntemp=pd.DataFrame(dat.score.value_counts())\ntemp.sort_index(inplace=True)\ntemp.columns=['Number of reviews']\nclrs=['red' if (x > 5000) else 'lightcoral' for x in temp['Number of reviews'] ] #highlight bars\nsns.countplot(data=dat,x='score',palette=clrs) \nprint(temp.T)\nprint('Mean score: ', dat.score.mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* The aprecciation of this game is very opposite. See the two high bars in the graph. \n* In general, this type of graph should be unbiased for a side with a little weight in the extremes."},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"#Analyze reviews for each score\nfor i in range(11):\n    temp=dat[(dat.score==10-i) & (dat.type_review=='normal')].review.iloc[np.random.randint(1,100)] #For each score, choose a random review\n    print('*'*100)\n    print(f'SCORE {10-i} ------- {temp}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In this way, you can see 10 random reviews and have a general idea of the user's reviews. I don't know what reviews that you see, but in my case i think that the reviews can classified as follows:\n* The good reviews says that all people in that universe are bad persons, is not correct no feel sad to abby. Others says that the gameplay and graphics are enough.\n* The ok reviews cheer that you buy the game and is necessary to improve the story. And more nostalgia..\n* The bad reviews require that this 2nd game should be the same than the 1st, the 1st is much better than this sequel. Also claim that the 'inclusion' is not the problem, the problem is the force in the story.\n\nI read some reviews with bad score and your arguments sounds logic..\n\n![zombie](https://th.bing.com/th/id/R2da419735dbba740609458b9da22e34e?rik=zG%2bMDaGEd6vKbg&riu=http%3a%2f%2fwww.reviewstl.com%2fwp-content%2fuploads%2f2013%2f07%2fThe-Last-of-Us-Zombies.jpg&ehk=lvawsmdk6rqABLUYEWUIqKwyq5Tpi6NGKp1UHC8i3nU%3d&risl=&pid=ImgRaw)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Analyze the user's score over the time\ndef plot_line(var,txt):\n    '''\n    usage: plot some filter of the dataframe\n    '''\n    temp=Counter(dat[dat.label==var].date)\n    plt.plot(list(temp.keys()),list(temp.values()),color=txt)\ndef subplot_line(var,txt):\n    '''\n    usage: plot some filter of the dataframe; but in this case, over the axes\n    '''\n    temp=Counter(dat[(dat.date>'2020-09-25')&(dat.label==var)].date)\n    sub_axes.plot(list(temp.keys()),list(temp.values()),color=txt) \n#Define the main figure\nfig, ax=plt.subplots(figsize=(8,5))\nplot_line('Excellent','blue')\nplot_line('Ok','green')\nplot_line('Bad','red')\n#Add sections\nax.axvspan('2020-06-17', '2020-06-23', alpha=0.1, color='red') #06-19 Release date. I assume 4 days to finish the game\nax.axvspan('2020-06-23', '2020-09-23', alpha=0.1, color='orange') # I didn't know the mean time in finish the game(and buy). In my case was three months. So for a player was one to two months\nax.axvspan('2020-06-23', str(dat.date.max()), alpha=0.09, color='yellow')\n# ax.text('2020-06-21',1800,'Early\\n reviews', fontsize=7,color='red')\n# ax.text('2020-07-15',1700,'Mean\\n reviews', fontsize=14,color='orange')\n# ax.text('2020-09-25',1700,'Latest\\n reviews', fontsize=14,color='black')\n# #Add common layers\nplt.xlabel('Date');plt.ylabel('Number of votes')\nax.legend(['Excellent','Ok','Bad'])\n#Add a zoom portion \nsub_axes =plt.axes([.55, .3, .28, .25]) \nsubplot_line('Excellent','blue')\nsubplot_line('Ok','green')\nsubplot_line('Bad','red')\nplt.setp(sub_axes,xticks=[], yticks=[])\n#Draw the connection between plots\nmark_inset(ax, sub_axes, loc1=2, loc2=4, fc=\"none\", ec=\"0.1\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Interesting. Most of all bad reviews are very early. The duration of the game is 25 to 30 hours, did they play the game? Maybe, they didn't want to keep playing, is very possible, i understand that. Also is possible that they finished the game in a pair of days.\n* Also, if you add a zoom to the latest reviews you can see a more normal process where the good reviews are higher.\n* About the graph. The first section are the early reviews, the second sections are mean reviews and the final section are the latest reviews."},{"metadata":{"trusted":true},"cell_type":"code","source":"# DATE AND SCORE\nearly=dat[dat.date<'2020-06-20'].index\nbad=dat[dat.score==0].index\nlast=dat[dat.date>'2020-09-25'].index\ngood=dat[dat.score==10].index\nfig,ax=plt.subplots(figsize=(12,8),nrows=1,ncols=2)\nvenn3([set(early),set(last),set(bad)], set_labels = ('A', 'B','C'),ax=ax[0])\nvenn3([set(early),set(last),set(good)], set_labels = ('A', 'B','C'),ax=ax[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#DATE, SCORE AND WEIRD REVIEWS\nweird=dat[(dat.sug>0.7)& (dat.views<10)].index\nfig,ax=plt.subplots(figsize=(12,8),nrows=1,ncols=2)\nvenn3([set(early),set(weird),set(bad)], set_labels = ('Early review', 'Weird\\n review','Bad sentiment'),ax=ax[0])\nvenn3([set(early),set(weird),set(good)], set_labels = ('Early review', 'Weird\\n review','Good sentiment'),ax=ax[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*  If the review is old, have few views and have various votes is weird. And the intersection between *early* and *weird* is *possible bot*. But this is a hypothesis, i didn't find studies with this step.\n* **In the first graph** the asociation between sentiment and date is more clear.\n* **In the 2nd graph** see the intersection between the three sets in the two images. The bad sentiment have more possible bots reviews (100 than 2)."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Distribution of the languages\ntemp=dat.language.value_counts().iloc[:5] #Only the languages with more reviews\ntemp.index=['English', 'Spanish', 'Portuguese', 'Russian','Others']\ntemp.iloc[4]=dat.language.value_counts().iloc[4:].sum()\nmy_colors = [ 'red','#00008b','#483d8b', \"#3498db\", \"#95a5a6\",\"#34495e\"]\nplt.figure(figsize = (6,6))\nplt.pie(temp.values,labels=temp.keys(),autopct = '%1.1f%%',colors=my_colors,\n        explode=[0.1,0,0,0,0],startangle=45,shadow=True,wedgeprops = {'linewidth': 5})\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Only the english reviews\ndat=dat[dat.language=='English'].reset_index(drop=True)\n#Translate and use all reviews\n# gs = goslate.Goslate()\n# dat[dat.language!='English'].review=dat[dat.language!='English'].review.apply(lambda x: gs.translate(x,'en'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax=plt.subplots(figsize=(8,5))\nsns.histplot(data=dat,x='review_length',fill=True,hue='type_review')\nsns.histplot(data=dat,x='review_length',color='black',alpha=0.1,fill=True)\nplt.axvline(410,color='red') #Literally this line is the limit of words in a review of the web-page\nplt.xlabel('Game users');plt.ylabel('Length of reviews')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Text preprocessing\n* Converting all letters to lower or upper case\n* Converting numbers into words or removing numbers\n* Removing punctuations, accent marks and other diacritics\n* Removing white spaces\n* Expanding abbreviations\n* Removing stop words, sparse terms, and particular words\n* Text canonicalization\n\nMore detail info in this [blog](https://medium.com/@datamonsters/text-preprocessing-in-python-steps-tools-and-examples-bf025f872908).\n\n![world](https://multiplayer.net-cdn.it/thumbs/images/2020/06/21/the-last-of-us-part-ii-seattle-guida_jpg_750x400_crop_upscale_q85.jpg)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#A first model\n# dat=dat[dat.label!='Ok'] #Remove the neutral review\n# dat.reset_index(inplace=True,drop=True)\ndat.target=dat.score.apply(lambda x: 0 if x<5 else 1)  #Another option is only to use scpre 0 and score 10\nprint(f'Dimentions of data: {dat.shape}')\nx_train,x_test,y_train,y_test = train_test_split(dat.review,dat.target, test_size=0.2, random_state=60)\npipe = Pipeline([('vect', CountVectorizer(analyzer = \"word\",min_df=50,stop_words='english')),\n                 ('tfidf', TfidfTransformer()),\n                 ('model', LogisticRegression())]).fit(x_train, y_train)\nprediction = pipe.predict(x_test)\nprint(roc_auc_score(pipe.predict(x_train),y_train))\nprint(roc_auc_score(prediction,y_test))\nplot_confusion_matrix(pipe,x_test,y_test,cmap='rocket')\n#That looks great. The model has a good prediction power and no exist overfitting","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nlp=English()\ndef preprocess_text(text): #In this way you can define specific conditions (compared to countvectorizer)\n    '''\n    input:a string\n    usage: vectorize the vector and cuantify the string. Is possible add conditions compared to CountVectorizer()\n    '''\n    list_words = nlp(text)\n    sentence=[]\n    #Remove stopwords\n    for token in list_words: \n        val=token.text.lower()#to lower\n        stop1=val in vg_stopwords #specific\n        stop2=nlp.vocab[val].is_stop #general\n        if (not stop2) and (not stop1): sentence.append(val)\n    filtered_sentence =[]\n    #Lemmatize\n    for val in sentence:  \n        word = Word(val).lemmatize(\"n\")\n        word = Word(word).lemmatize(\"v\")\n        word = Word(word).lemmatize(\"a\")\n        word=WordNetLemmatizer().lemmatize(word,'v')\n        filtered_sentence.append(word) \n    final_sentence=[]\n    #Remove some stopwords again\n    for val in filtered_sentence:\n        if not (val in vg_stopwords): final_sentence.append(val) #Some specific stopwords can appear again; example:gamer to game\n    final_sentence=' '.join(final_sentence)\n    #Remove sign and punctuation\n    tokenizer = RegexpTokenizer(r'\\w+')\n    final_sentence=tokenizer.tokenize(final_sentence)  \n    return ' '.join(final_sentence)\ndat['pre_review']=dat.review.apply(preprocess_text) \n#This steps were realized with other package above but i want to have this information in objects. Also is possible to see the algorithm\nvectorizer=CountVectorizer(analyzer = \"word\",min_df=50,stop_words='english') #Only with the most repeated words\nfeature_matrix = vectorizer.fit_transform(dat.pre_review).toarray()\nfeatures=pd.DataFrame(feature_matrix, columns=vectorizer.get_feature_names())\n# bow=features.sum(axis=0) Another way to define 1-gram and its count, bag of words","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# WorldCloud\nData visualization technique where words from a given text are displayed in a chart, with the more important words being written with bigger, bold fonts, while less important words are displayed with smaller, thinner fonts or not displayed at all.\n\nSome important words that I remove becaused it's appear in all reviews and it couldn't see any pattern in the user'scores.\n- Good. All reviews had good, include the bad reviews. If you draw the worlcloud in every plot, this word appear and have a high size. \n- Story. And i agree, that is the most controversial part in this game. Justly, The Last of Us (1st game) had that excellent reputation for that story, so the sequel would be awesome..\n- Ellie, Joel, Abby. Similar reason.there are the main characters, all users tell of him\n- Naughty Dog. The institution, creators of the video-game. Here, i saw more size when the score was 0, but it always appear.\n\n**Obs:** Only in the worldclouds and tables in the next images, **not** in the model\n\n![zbie](https://cdn.mos.cms.futurecdn.net/Mz3heMHRTTD6GRa45ikjLC-1200-80.jpg)"},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_worldcloud(x,txt,show_table=True):\n    '''\n    input:a dataframe, the title, a boolean\n    output: a worldcloud, (a summary table)\n    '''\n    #WorldCloud\n    cloud = WordCloud(width=1640, height=1200,random_state=60,\n                    stopwords=['game','story','character','play','gameplay','good','end','like','ellie','joel','abby','nt','s','ll','n','t']).generate(\" \".join(x.pre_review))\n    fig = plt.figure(figsize=(15,12))\n    ax = fig.add_subplot(111)\n    plt.imshow(cloud)\n    plt.axis('off')\n    #Summary table\n    if show_table==True:\n        lst=x.review.iloc[:12].apply(lambda x: [' '+x[:100]+'\\n'+x[100:200]+'\\n'+x[200:300]+'...'])  \n        tab=plt.table(cellText=list(lst), rowLabels=np.arange(12)+1, \n                  colLabels=[txt],colColours=['red'], loc='right',cellLoc='center',colLoc='center')\n        tab.auto_set_font_size(False); tab.set_fontsize(14)\n        tab.scale(1, 4)\n        set_pad_for_column(tb=tab,col=0, pad=0.01) \n    plt.show() \ndef subplot_worldcloud(x):\n    '''\n    input:a dataframe\n    output: a worldcloud\n    obs: maybe is better combine this and generate world_cloud in a function, or in a class\n    '''\n    cloud = WordCloud(width=140, height=108,random_state=60,\n                      stopwords=set(['game','story','character','play','gameplay','good','end','like','ellie','joel','abby','nt','s','ll','n','t'])).generate(\" \".join(x.pre_review))\n    plt.imshow(cloud)\n    plt.title(f'Score: {i}',loc='left')\n    plt.axis('off')\ndef create_report(df):\n    '''\n    input: a dataframe\n    output: return a table that shows its reviews and scores\n    usage: filter the dataframe and obtain that specific report\n    '''\n    #Add colors by score\n    fill_color = []; n = len(df)\n    for i in range(n):  \n        if df.iloc[i].label=='Excellent':fill_color.append('rgb(102, 178, 255)')\n        elif df.iloc[i].label=='Ok':fill_color.append('rgb(153, 255, 204)')\n        else:fill_color.append(\"rgb(255, 102, 102)\")\n    #Create figure\n    fig = go.Figure(data=[  \n        go.Table(columnorder = [1,2], columnwidth = [440,40],\n      header=dict(values=['<b>Reviews</b>', '<b>Score</b>'],\n        line_color='black', fill_color='black',\n        align='center',font=dict(color='white', size=12)),\n      cells=dict(values=[df.review, df.score],\n        line_color=['black']*2,fill_color=[fill_color,fill_color],\n        align='center', font=dict(color='black', size=11)))\n    ])\n    fig.show()\ndef set_pad_for_column(tb,col, pad=0.1):\n    '''\n    usage: fix the pad of a plt.table\n    '''\n    cells = tb.get_celld()\n    column = [cell for cell in tb.get_celld() if cell[1] == col]\n    for cell in column: cells[cell].PAD = pad","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(15, 7))\nfor i in range(11): \n    plt.subplot(4,3,i+1)\n    subplot_worldcloud(dat[dat.score==i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"* We can see the pattern {0->10:(bad,kill)->(think)}. However the intermediate scores contradict this idea. Maybe this graph only suggest to take the score 0 and 10 for the modeling.\n* Other pattern can be {10:love},{9:people},{8:people}... Words that only stands out in its score.\n* When the words mentioned above are not deleted all graphs are very similar. Try in your pc if you are esceptic with this. Ex: Good appear in every cloud."},{"metadata":{"trusted":true},"cell_type":"code","source":"generate_worldcloud(dat[dat.label=='Excellent'],'Excellent Reviews') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"generate_worldcloud(dat[dat.label=='Bad'],'Bad Reviews',show_table=False)\n#You can analyze any case. More examples:\n# generate_world_cloud(dat[dat.date<'2020-06-20'],'Earlier reviews')\n# generate_world_cloud(dat[dat.date>'2020-09-25'],'Last reviews')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Then if you want to see its reviews..\ncreate_report(dat.iloc[:30])  #First reviews\n# create_report(dat[dat.date<'2020-06-20'])  #Early reviews\n# create_report(dat[dat.date>'2020-09-25']) #Latest reviews","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Reduction of dimention\nI only show the manner of work in this way. In this step i didn't analyze in depth, that was not the main theme in this notebook. \n\nSome steps that i didn't consider: the analysis of explained variance or inertia, and the use of more accurate algorithms like tsne or dbscan."},{"metadata":{"trusted":true},"cell_type":"code","source":"def reduction(df,n_components):\n    '''\n    input: p features\n    output: k components that explain that features\n    usage: reduction of dimension (feature space)\n    '''\n    df = PCA(n_components=n_components,random_state=60).fit_transform(df)\n#     df=TSNE( n_components=n_components,init='random' method='barnes_hut',n_iter=1000,verbose=2,angle=0.5).fit_transform(data)\n\n    names=[]\n    for i in range(n_components): names.append(f'Component {i+1}')\n    df=pd.DataFrame(df,columns=names)\n    return df\ndef clustering(df,n_clusters):\n    '''\n    input: n observations\n    output: m clusters that group those observations\n    usage: reduction of dimension (observation space)\n    '''\n    kmeans = KMeans(n_clusters = n_clusters, n_init = 20,random_state=60)\n#     kmeans=DBSCAN(eps=3, min_samples=3).fit_predict(df)\n    df['label']=kmeans.fit_predict(df)\n    df['label']=df.label.apply(lambda x: f'cluster {x+1}')\n    return df\nnew_ft=reduction(features,3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Remove outliers. In this way is more easy remove if a variable is an outlier. I also see this step after the segmentation\noutlier=new_ft[new_ft['Component 1']>30]\nprint(outlier)\n# new_ft.drop(outlier.index,axis=0,inplace=True)\n# new_ft.boxplot()\ncreate_report(dat.iloc[outlier.index].sort_index(ascending=False))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"clustering(new_ft,3)\nsns.pairplot(new_ft,palette= 'Dark2', diag_kind='kde',hue='label',height=1.85)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_ft=new_ft[new_ft.label!='cluster 2'] #The cluster 2 are outlier. It should be remove\nsns.pairplot(new_ft,palette= 'Dark2', diag_kind='kde',hue='label')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig=px.scatter_3d(new_ft,\n    x='Component 1',y='Component 2',z='Component 3',\n    color='label')\nfig.show() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cluster1_idx=new_ft[new_ft.label=='cluster 1'].index\ncluster2_idx=new_ft[new_ft.label=='cluster 3'].index\ncreate_report(dat.iloc[cluster1_idx])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Unigram, Bigram, Trigram\n<center><b>How can a machine understand linguistic structures and their meanings? What is the elementary text object?</b></center>\nThis is the word. But only this is not sufficient. If we join this elements (only <b>adjacents</b>) we'll obtain n-grams. Then if we count the cases, we obtain a <b>bag</b> of elements. Surely separated words can be useful but this is another perspective.\n\n![lou](https://media.giphy.com/media/pZnubf8FJxONO/giphy.gif)"},{"metadata":{"trusted":true},"cell_type":"code","source":"def n_grams(word,k):  \n    '''\n    input:a string, the number of characters\n    output: a dictionary {set(k-gram):count}\n    usage: as function to transform the strings\n    '''\n    token = word_tokenize(word)\n    gram = ngrams(token,k)\n    return Counter(gram)\n\ndef get_ngram(df,k,c):\n    '''\n    input:a dataframe, the number of characters\n    output: a dataframe that shows the k-gram with its count\n    usage: obtain bag of word, set of n-gram\n    '''\n    #get the k-set\n    aux=''; n=len(df)\n    for i in range(n): aux=aux+dat.pre_review.iloc[i]  #I use theprocessed text. I think is more logic to remove stopwords\n    gramk=n_grams(aux,k)\n    gramk=join_repeats(gramk)\n    #drop duplicate keys\n    try: gramk=filter_dict(gramk,lambda x,y: x[0]!=x[1])  #for bigram\n    except:gramk=gramk\n    try: \n        gramk=filter_dict(gramk,lambda x,y: x[0]!=x[2])  #for trigram\n        gramk=filter_dict(gramk,lambda x,y: x[1]!=x[2])\n    except:gramk=gramk\n    #only select the most counts\n    gramk=filter_dict(gramk,lambda x,y:y>c)\n    gramk_df=pd.DataFrame({f'{k}-gram':gramk.keys(),'counts':gramk.values()})\n    return(gramk_df.sort_values('counts',ascending=False))\n\ndef join_repeats(dic):\n    '''\n    usage: sum elements with the same key\n    '''\n    newDict = dict()\n    for key, value in dic.items():\n        nkey=tuple(sorted(key))\n        if nkey in newDict.keys(): newDict[nkey]=value+newDict[nkey]\n        else: newDict[nkey]=value\n    return newDict \ndef filter_dict(dic, f):\n    '''\n    usage: Filter the items of a dictionary'''\n    newDict = dict()\n    for key, value in dic.items():\n        if f(key, value): newDict[key] = value\n    return newDict  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def my_palette(ar):\n    '''\n    usage:highlight bars\n    '''\n    lst=[]\n    for i in range(len(ar)):\n        if ar.iloc[i]=='Good':lst.append('#08439A')\n        else: lst.append(\"#e33f2c\")\n    return lst\ndef plot_ngram(df):\n    '''\n    input: A dataframe {set, count}\n    otput: Plot the predictions of that set\n    '''\n    fig,ax=plt.subplots(figsize=(10,6))\n#     sns.barplot(y=df.iloc[:,0],x=df.iloc[:,1],palette=['gray']*len(df),ax=ax[0])    \n    df['label']=pipe.predict(df.iloc[:,0].apply(str))\n    df['label']=df.label.apply(lambda x: 'Good' if x==1 else 'Bad')\n    sns.barplot(y=df.iloc[:,0],x=df.iloc[:,1],palette=my_palette(df.label))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grams1=get_ngram(dat,1,4000)  #Another way: CountVectorizer() DataFrame() sum.axis()\ngrams1.iloc[:,0]=grams1.iloc[:,0].apply(lambda x:x[0])\nplot_ngram(grams1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Remember under this way, the review only contain this word\n* \"Like\" should be good. But in this particular case is not possible. (Example: I like the graphics, but the story is horrible, score=0)"},{"metadata":{"trusted":true},"cell_type":"code","source":"gp_idx=features[(features.graphic==1)].index\nprint('Summary of one word')\nprint(dat.iloc[gp_idx].label.value_counts()) #dat and features have the same index\ncreate_report(dat.iloc[gp_idx])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grams2=get_ngram(dat,2,700)\nplot_ngram(grams2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If you read some reviews above you can see why 'good story' is more near to excellent review, but I understand why the model can be wrong. A pair of words can represent opposite things."},{"metadata":{"trusted":true},"cell_type":"code","source":"ind_gs=features[(features.like==1)&(features.story==1)].index\nprint('Summary of one bigram')\nprint(dat.iloc[ind_gs].label.value_counts())\ncreate_report(dat.iloc[ind_gs])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grams3=get_ngram(dat,3,100)\nplot_ngram(grams3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ind_gs=features[(features.gameplay==1)&(features.graphic==1)&(features.story==1)].index\nprint('Summary of one trigram')\nprint(dat.iloc[ind_gs].label.value_counts())\ncreate_report(dat.iloc[ind_gs])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Another try: Bigram,trigram\ndat.target=dat.score.apply(lambda x: 0 if x<5 else 1)\nx_train,x_test,y_train,y_test = train_test_split(dat.review,dat.target, test_size=0.2, random_state=60)\npipe_bt = Pipeline([('vect',CountVectorizer(analyzer='char',ngram_range=(2,3),min_df=20,stop_words='english') ),\n                 ('tfidf', TfidfTransformer()),\n                 ('model', LogisticRegression())]).fit(x_train, y_train)\nprediction = pipe_bt.predict(x_test)\nprint(roc_auc_score(pipe_bt.predict(x_train),y_train))\nprint(roc_auc_score(prediction,y_test))\nplot_confusion_matrix(pipe_bt,x_test,y_test,cmap='rocket')\n#Again, that looks great. The model has a good prediction power and no exist overfitting","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Sentiment and emotion lexicons\nThe lexicon approach has a dictionary that contains a comprehensive list of sentiment features. All the lexical features were rated for the polarity and intensity of the sentiment (or emotion). Then, the average score can be used as the sentiment indicator. Under this way we can obtain emotion and sentiment of a review.\n\nOne advantage of this is to remove some not useful words -in addition to stopwords- in the review, but this method has its limits.\n\n![joel](https://i.ytimg.com/vi/RVINxPk0190/maxresdefault.jpg)"},{"metadata":{"trusted":true},"cell_type":"code","source":"def emotion(x):\n    '''\n    input: a string\n    output: a dictionary that shows the emotions of that string\n    usage: function of a column'''\n    x = NRCLex(x)\n    return x.affect_frequencies\ndat['emotion'] = dat.review.apply(emotion)\nfeature_matrix = vectorizer.fit_transform(dat.review).toarray()#considering all original words\nfeatures=pd.DataFrame(feature_matrix, columns=vectorizer.get_feature_names())\nbow=features.sum(axis=0) \nbow=pd.DataFrame({'word':bow.keys(),'count':bow.values})\nbow=bow.merge(nrc,how='inner',on='word')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#bag of words\nbow.sort_values(['sentiment','count'],ascending=False,inplace=True)\nbow.reset_index(drop=True,inplace=True)\n#merge the sentiment (or emotion)\naux=pd.DataFrame(columns=['word','count','sentiment'])\nfor i in bow.sentiment.unique():\n    aux=pd.concat([aux,bow[bow.sentiment==i].iloc[:5]],axis=0)\nalt.Chart(aux).mark_bar().encode(y='word',\n    x='count',color='sentiment',facet=alt.Facet('sentiment',columns=5,align='none')).resolve_scale(y='independent').properties(width=250,\n    height=250)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#threemap\nthmap1 = pd.DataFrame({'scenario' : nrc.sentiment.value_counts().index,\n                          'percentage':nrc.sentiment.value_counts(normalize=True).tolist(),\n                        'dataset':\"Original's lexicon\" })\nthmap2 = pd.DataFrame({'scenario' : bow.sentiment.value_counts().index,\n                          'percentage':bow.sentiment.value_counts(normalize=True).tolist(),\n                          'dataset':\"Dataset's lexicon\"})\nthmap=pd.concat([thmap1,thmap2],axis=0)\nthmap.reset_index(inplace=True,drop=True)\nfig = px.treemap(thmap, path= [\"scenario\",\"dataset\"], values =\"percentage\",\n                 color='percentage',color_continuous_scale='viridis_r')\nfig.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* The treemap shows the number of words associated with each affect category\n* For this case, i add a step in the graph: original's lexicon and dataset'lexicon \n* The original's lexicon is the original NRCLex. This set contains the **original** proportion of the sentiment (or emotion) intensity \n* The dataset's lexicon contains the **actual** proportion of the sentiment (or emotion) intensity\n* See the differences between this two groups and the see specific conditions in the sentiment's intensity of this dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Word count distribution over sentiment intensity\ndel bow['count']\nbow=bow.merge(afinn,how='inner',on='word')\nbow.dropna(inplace=True)\nplt.figure(figsize=(10,6))\nsns.kdeplot(data=bow,x='value',hue='sentiment',fill=True, palette=\"seismic\",\n   alpha=.7, linewidth=0.3,)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Well, it's curious. The emotions fit appropriately in each subgroup\n* See the bimodal distribution. This can be calibrated with a mixture gaussian kernel.\n* Honestly i'm surprised. I see this graph in other notebook and the sobgroups are not separated but i'm not sure how to take advantage of that"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_lexicon(dat):\n    '''\n    input:a dataframe\n    otput:a tuple: the emotion, the score in the review (mean proportion)\n    '''\n    n=len(dat);aux={'fear':0,'anger':0,'anticipation':0,'trust':0,'surprise':0,'positive':0,'negative':0,'sadness':0,\n'disgust':0,'joy':0};newDict1=dict();newDict2=dict()\n    #Obtain the sets: emotion, score\n    for i in range(n): \n        aux=sum_dictionary(aux,dat.emotion.iloc[i])\n    for key, value in aux.items(): \n        if (key!='positive')&(key!='negative'):\n            newDict1[key]=value\n        else: newDict2[key]=value\n    #Define proportions in each one\n    s1=sum(list(newDict1.values()));s2=sum(list(newDict2.values()))\n    return(function_dic(newDict1,lambda x:x/s1),function_dic(newDict2,lambda x:x/s2))\ndef sum_dictionary(dic1,dic2):\n    '''\n    usage: sum all dictionaries in the column\n    '''\n    newDict=dict()\n    for key, value in dic1.items():\n        if key in dic2.keys(): newDict[key]=value+dic2[key]\n    return newDict\ndef function_dic(dic,f):\n    '''\n    usage:change the values in a dictionary\n    '''\n    newDict=dict()\n    for key, value in dic.items(): newDict[key]=f(value)\n    return newDict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Define scenarios\njoel=features[(features.joel!=0)&(features.kill!=0)&(features.death!=0)]\nellie=features[(features.ellie!=0)&(features.story!=0)] #an observation. The users maybe write incorrectly(Ex: elie)\nscore10=features[features.feel!=0&(features.love!=0)] \njoel_emotion,joel_score=get_lexicon(dat.iloc[joel.index])\nellie_emotion,ellie_score=get_lexicon(dat.iloc[ellie.index])\nscore10_emotion,score10_score=get_lexicon(dat.iloc[score10.index])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax=plt.subplots(figsize=(8,7),nrows=3,ncols=2)\ndef my_palette(ar):\n    '''\n    usage: highlight bars\n    '''\n    n=len(ar);lst=[]\n    lim_ar=sum(ar)/n+0.02\n    for i in range(n):\n        if ar[i]>lim_ar: lst.append('#008000')\n        else: lst.append(\"#15B01A\")\n    return lst\n#bar chart\nsns.barplot(y=list(joel_emotion.keys()),x=list(joel_emotion.values()),palette=my_palette(list(joel_emotion.values())),\n            label=list(joel_emotion.keys()),ax=ax[0,0])\n#adjust format to the bar\nax[0,0].set_ylabel(\"Joel's death\",fontsize=10,fontweight=\"bold\",\n                   bbox=dict(facecolor='wheat', edgecolor='gold', pad=3))\nax[0,0].set_xlim([0,0.2])\n#pie chart\nax[0,1].pie(list(joel_score.values()),colors=[\"#3498db\",\"#e74c3c\"],autopct = '%1.1f%%',\n            shadow=True,explode=[0,0.1],labels=list(joel_score.keys()))\nsns.barplot(y=list(ellie_emotion.keys()),x=list(ellie_emotion.values()),\n            palette=my_palette(list(ellie_emotion.values())),ax=ax[1,0])\nax[1,0].set_ylabel('Ellie and her story',fontsize=10,fontweight=\"bold\",bbox=dict(facecolor='wheat', edgecolor='gold', pad=3))\nax[1,0].set_xlim([0,0.2])\nax[1,1].pie(list(ellie_score.values()),colors=[\"#3498db\",\"#e74c3c\"],autopct = '%1.1f%%',\n            shadow=True,explode=[0,0.1],labels=list(joel_score.keys()))\nsns.barplot(y=list(score10_emotion.keys()),x=list(score10_emotion.values()),palette=my_palette(list(score10_emotion.values())),ax=ax[2,0])\nax[2,0].set_ylabel('Great game!',fontsize=10,fontweight=\"bold\",bbox=dict(facecolor='wheat', edgecolor='gold', pad=3))\nax[2,0].set_xlim([0,0.2])\nax[2,1].pie(list(score10_score.values()),colors=[\"#3498db\",\"#e74c3c\"],autopct = '%1.1f%%',\n            shadow=True,explode=[0.1,0],labels=list(joel_score.keys()))\nplt.subplots_adjust(wspace=1e-2,hspace=0.15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* *Joel's death* was the emotions: sad, fear and anger. Its reviews had more negative reviews\n* *Ellie and her story* was the emotions: fear and sadness. Its reviews had more negative reviews\n* *Great game!* was the emotions: trust and fear. Its reviews had more positive reviews"},{"metadata":{"trusted":true},"cell_type":"code","source":"categories = np.array(list(joel_emotion.keys())) #list of emotions\nfig = go.Figure()\n#figure 1\nfig.add_trace(go.Scatterpolar(\n      r=np.array(list(joel_emotion.values())), theta=categories,fill='toself',name=\"Joel's death\")\n             )\n#figure 2\nfig.add_trace(go.Scatterpolar(\n      r=np.array(list(ellie_emotion.values())),\n      theta=categories,\n       fill='toself',\n      name='Ellie and her story'\n))\n#figure 3\nfig.add_trace(go.Scatterpolar(\n      r=np.array(list(score10_emotion.values())),theta=categories,fill='toself',name='Great game!')\n             )\nfig.update_layout(\n  polar=dict(radialaxis=dict(\n      visible=True,\n      range=[0, 0.21])\n            ), showlegend=False\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* This radar char complements the previous graph\n* The *Joel's death* have interesting extremes. It is sadness and fear\n* The *great game!* have interesting extremes. It is joy and trust\n* *Ellie and her story* and *Great game!* are similar (a little). That's funny\n![1st](https://31.media.tumblr.com/b7847cf1da3d34f9229955dbb1f3c3ab/tumblr_nod44mTfeJ1tyvnamo1_500.gif)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#nrclex prediction\ndef get_lexicon_element(dat):\n    '''\n    input:a string\n    otput:a tuple: the emotion, the score in the review (for each review)\n    '''\n    newDict1=dict();newDict2=dict()\n    #Obtain the sets: emotion, score\n    for key, value in dat.items(): \n        if (key!='positive')&(key!='negative'):\n            newDict1[key]=value\n        else: newDict2[key]=value\n    #Return each one\n    return(newDict1,newDict2)\ndef predict_lexicon(df):\n    '''\n    input: a tuple (dic1,dic2)\n    usage: obtain predictions\n    '''\n    dic=get_lexicon_element(df)\n    if dic[1]['positive']>dic[1]['negative']: return 1\n    elif dic[1]['positive']<dic[1]['negative']: return 0\n    else: return('-')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Finally, we evaluate this models with new reviews\nmy_reviews=pd.DataFrame({'review':[\"The gameplay and graphics were great. The game was entertaining.\",\"I enjoy to play\",\n                      'Play as Abby was a horrible idea, what they though?',\n                      \"Last of Us don't deserve this sequel. Do it again\",\"Last of Us don't deserve this sequel. Joel shouldn't die. \"]})\nprint(f'Bag of word: {pipe.predict(my_reviews.review)}')\nprint(f'Bigram and trigram: {pipe_bt.predict(my_reviews.review)}')\n\nmy_reviews['emotion']=my_reviews.review.apply(lambda x: emotion(str(x)))\nprint(f'NRCLex: {np.array(my_reviews.emotion.apply(predict_lexicon))}') #that's bad, here is possible to see its limits, maybe is more useful add a probabilistic distribution","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclussions and recommendations\n* The worldclouds and reports show that the game presents simmiliarities between intermediate scores. Therefore is suggested to follow this perspective (only score 0 and 10) in the next modelling.\n* In the seen two ways (n-gram,lexicon) you can obtain interesting insights.\n* In the first case, many words (or grams) can represent opposite representations.\n* The vectorization -with other conditions- is an excellent way to cuantify text features.\n* In the second case, you can view the emotion and sentiment in each review. I plotted some graphs to help the visualization.\n* The list of NRCLex can detect the emotion and the sentiment automatically.\n* In terms of prediction, models based in unigram, bigram and trigram are better because this depend on the specific data.\n* NRCLex is based only in the word, not in its context in the sentence. Maybe this alternative is great if you use a probabilistic approach.\n* I always think that a convolutional neural network is the best option in this type of modeling. That's a future task.\n\n# Additional resources\nI know that exists other specialized packages in this topic but i tried to define my proper code because i want to understand better the algorithm. If you find any improvement please let me know. In the other hand, i mention additional resources below.\n\n**Kaggle notebooks:**\n* https://www.kaggle.com/andradaolteanu/sentiment-analysis-rick-and-morty-scripts#3.-Dialogues-:-Who-talks-the-most?-%F0%9F%92%AC\n* https://www.kaggle.com/ruchi798/sentiment-analysis-the-simpsons\n* https://www.kaggle.com/arthurtok/principal-component-analysis-with-kmeans-visuals?scriptVersionId=1524454\n* https://www.kaggle.com/meesalasaidhanush/review-scores-of-fall-guys-game-acc-99\n\n**Courses and books:**\n* https://www.tidytextmining.com/index.html\n* https://www.kaggle.com/learn/natural-language-processing\n\n ![end](https://64.media.tumblr.com/0ff977cfd2fd40b9ff304af285acd14a/tumblr_phloi1SAjK1vrquye_540.gif)\n\n<div class=\"alert alert-block alert-info\">  \nThat's all. Thanks for read this notebook. If you think this material is useful please upvote. That motivates me to still do this types of projects.\n</div>"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}