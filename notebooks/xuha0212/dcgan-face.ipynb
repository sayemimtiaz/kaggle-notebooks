{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import  os\nimport  numpy as np\nimport  tensorflow as tf\nfrom    tensorflow import keras\n#from    scipy.misc import toimage\nfrom PIL import Image\nimport  glob\n#from    gan import Generator, Discriminator\nimport time\n#from    dataset import make_anime_dataset\nimport  tensorflow as tf\nfrom    tensorflow import keras\nfrom    tensorflow.keras import layers\nimport multiprocessing\nimport tensorflow as tf\n\n\ndef make_anime_dataset(img_paths, batch_size, resize=64, drop_remainder=True, shuffle=True, repeat=1):#drop_remainder=True防止调用次数不是整数\n    @tf.function\n    def _map_fn(img):\n        img = tf.image.resize(img, [resize, resize])\n        img = tf.clip_by_value(img, 0, 255)\n        img = img / 127.5 - 1\n        return img\n\n    dataset = disk_image_batch_dataset(img_paths,\n                                          batch_size,\n                                          drop_remainder=drop_remainder,\n                                          map_fn=_map_fn,\n                                          shuffle=shuffle,\n                                          repeat=repeat)\n    img_shape = (resize, resize, 3)\n    len_dataset = len(img_paths) // batch_size\n\n    return dataset, img_shape, len_dataset\n\n\ndef batch_dataset(dataset,\n                  batch_size,\n                  drop_remainder=True,\n                  n_prefetch_batch=1,\n                  filter_fn=None,\n                  map_fn=None,\n                  n_map_threads=None,\n                  filter_after_map=False,\n                  shuffle=True,\n                  shuffle_buffer_size=None,\n                  repeat=None):\n    # set defaults\n    if n_map_threads is None:\n        n_map_threads = multiprocessing.cpu_count()\n    if shuffle and shuffle_buffer_size is None:\n        shuffle_buffer_size = max(batch_size * 128, 2048)  # set the minimum buffer size as 2048\n\n    # [*] it is efficient to conduct `shuffle` before `map`/`filter` because `map`/`filter` is sometimes costly\n    if shuffle:\n        dataset = dataset.shuffle(shuffle_buffer_size)\n\n    if not filter_after_map:\n        if filter_fn:\n            dataset = dataset.filter(filter_fn)\n\n        if map_fn:\n            dataset = dataset.map(map_fn, num_parallel_calls=n_map_threads)\n\n    else:  # [*] this is slower\n        if map_fn:\n            dataset = dataset.map(map_fn, num_parallel_calls=n_map_threads)\n\n        if filter_fn:\n            dataset = dataset.filter(filter_fn)\n\n    dataset = dataset.batch(batch_size, drop_remainder=drop_remainder)\n\n    dataset = dataset.repeat(repeat).prefetch(n_prefetch_batch)\n\n    return dataset\n\n\ndef memory_data_batch_dataset(memory_data,\n                              batch_size,\n                              drop_remainder=True,\n                              n_prefetch_batch=1,\n                              filter_fn=None,\n                              map_fn=None,\n                              n_map_threads=None,\n                              filter_after_map=False,\n                              shuffle=True,\n                              shuffle_buffer_size=None,\n                              repeat=None):\n    \"\"\"Batch dataset of memory data.\n\n    Parameters\n    ----------\n    memory_data : nested structure of tensors/ndarrays/lists\n\n    \"\"\"\n    dataset = tf.data.Dataset.from_tensor_slices(memory_data)\n    dataset = batch_dataset(dataset,\n                            batch_size,\n                            drop_remainder=drop_remainder,\n                            n_prefetch_batch=n_prefetch_batch,\n                            filter_fn=filter_fn,\n                            map_fn=map_fn,\n                            n_map_threads=n_map_threads,\n                            filter_after_map=filter_after_map,\n                            shuffle=shuffle,\n                            shuffle_buffer_size=shuffle_buffer_size,\n                            repeat=repeat)\n    return dataset\n\n\ndef disk_image_batch_dataset(img_paths,\n                             batch_size,\n                             labels=None,\n                             drop_remainder=True,\n                             n_prefetch_batch=1,\n                             filter_fn=None,\n                             map_fn=None,\n                             n_map_threads=None,\n                             filter_after_map=False,\n                             shuffle=True,\n                             shuffle_buffer_size=None,\n                             repeat=None):\n    \"\"\"Batch dataset of disk image for PNG and JPEG.\n\n    Parameters\n    ----------\n        img_paths : 1d-tensor/ndarray/list of str\n        labels : nested structure of tensors/ndarrays/lists\n\n    \"\"\"\n    if labels is None:\n        memory_data = img_paths\n    else:\n        memory_data = (img_paths, labels)\n\n    def parse_fn(path, *label):\n        img = tf.io.read_file(path)\n        img = tf.image.decode_png(img, 3)  # fix channels to 3\n        return (img,) + label\n\n    if map_fn:  # fuse `map_fn` and `parse_fn`\n        def map_fn_(*args):\n            return map_fn(*parse_fn(*args))\n    else:\n        map_fn_ = parse_fn\n\n    dataset = memory_data_batch_dataset(memory_data,\n                                        batch_size,\n                                        drop_remainder=drop_remainder,\n                                        n_prefetch_batch=n_prefetch_batch,\n                                        filter_fn=filter_fn,\n                                        map_fn=map_fn_,\n                                        n_map_threads=n_map_threads,\n                                        filter_after_map=filter_after_map,\n                                        shuffle=shuffle,\n                                        shuffle_buffer_size=shuffle_buffer_size,\n                                        repeat=repeat)\n\n    return dataset\n\n\n\nclass Generator(keras.Model):\n\n    def __init__(self):\n        super(Generator, self).__init__()\n\n        # z: [b, 100] => [b, 3*3*512] => [b, 3, 3, 512] => [b, 64, 64, 3]\n        self.fc = layers.Dense(3*3*512)\n\n        self.conv1 = layers.Conv2DTranspose(256, 3, 3, 'valid')\n        self.bn1 = layers.BatchNormalization()\n\n        self.conv2 = layers.Conv2DTranspose(128, 5, 2, 'valid')\n        self.bn2 = layers.BatchNormalization()\n\n        self.conv3 = layers.Conv2DTranspose(3, 4, 3, 'valid')\n\n    def call(self, inputs, training=None):\n        # [z, 100] => [z, 3*3*512]\n        x = self.fc(inputs)\n        x = tf.reshape(x, [-1, 3, 3, 512])\n        x = tf.nn.leaky_relu(x)\n\n        #\n        x = tf.nn.leaky_relu(self.bn1(self.conv1(x), training=training))\n        x = tf.nn.leaky_relu(self.bn2(self.conv2(x), training=training))\n        x = self.conv3(x)\n        x = tf.tanh(x)\n\n        return x\n\n\nclass Discriminator(keras.Model):\n\n    def __init__(self):\n        super(Discriminator, self).__init__()\n\n        # [b, 64, 64, 3] => [b, 1]\n        self.conv1 = layers.Conv2D(64, 5, 3, 'valid')\n\n        self.conv2 = layers.Conv2D(128, 5, 3, 'valid')\n        self.bn2 = layers.BatchNormalization()\n\n        self.conv3 = layers.Conv2D(256, 5, 3, 'valid')\n        self.bn3 = layers.BatchNormalization()\n\n        # [b, h, w ,c] => [b, -1]\n        self.flatten = layers.Flatten()\n        self.fc = layers.Dense(1)\n\n\n    def call(self, inputs, training=None):\n\n        x = tf.nn.leaky_relu(self.conv1(inputs))\n        x = tf.nn.leaky_relu(self.bn2(self.conv2(x), training=training))\n        x = tf.nn.leaky_relu(self.bn3(self.conv3(x), training=training))\n\n        # [b, h, w, c] => [b, -1]\n        x = self.flatten(x)\n        # [b, -1] => [b, 1]\n        logits = self.fc(x)\n\n        return logits\n\n\n\n\n\n\n\ndef save_result(val_out, val_block_size, image_path, color_mode):#将多个图片的内容拼在一起方便查看\n    def preprocess(img):\n        img = ((img + 1.0) * 127.5).astype(np.uint8)\n        # img = img.astype(np.uint8)\n        return img\n\n    preprocesed = preprocess(val_out)\n    final_image = np.array([])\n    single_row = np.array([])\n    for b in range(val_out.shape[0]):\n        # concat image into a row\n        if single_row.size == 0:\n            single_row = preprocesed[b, :, :, :]\n        else:\n            single_row = np.concatenate((single_row, preprocesed[b, :, :, :]), axis=1)\n\n        # concat image row to final_image\n        if (b+1) % val_block_size == 0:\n            if final_image.size == 0:\n                final_image = single_row\n            else:\n                final_image = np.concatenate((final_image, single_row), axis=0)\n\n            # reset single row\n            single_row = np.array([])\n\n    if final_image.shape[2] == 1:\n        final_image = np.squeeze(final_image, axis=2)\n    Image.fromarray(final_image).save(image_path)\n    #toimage(final_image).save(image_path)\n\n\ndef celoss_ones(logits):\n    # [b, 1]\n    # [b] = [1, 1, 1, 1,]\n    loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=logits,\n                                                   labels=tf.ones_like(logits))#送进去的labels全部为1，因为我们这里送进来的是真的图片\n    return tf.reduce_mean(loss)\n\n\ndef celoss_zeros(logits):\n    # [b, 1]\n    # [b] = [1, 1, 1, 1,]\n    loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=logits,\n                                                   labels=tf.zeros_like(logits))\n    return tf.reduce_mean(loss)\n\ndef d_loss_fn(generator, discriminator, batch_z, batch_x, is_training):\n    # 1. treat real image as real\n    # 2. treat generated image as fake\n    fake_image = generator(batch_z, is_training)\n    d_fake_logits = discriminator(fake_image, is_training)\n    d_real_logits = discriminator(batch_x, is_training)\n\n    d_loss_real = celoss_ones(d_real_logits)#我们用1表示真，用0表示假\n    d_loss_fake = celoss_zeros(d_fake_logits)\n\n    loss = d_loss_fake + d_loss_real\n\n    return loss\n\n\ndef g_loss_fn(generator, discriminator, batch_z, is_training):\n\n    fake_image = generator(batch_z, is_training)\n    d_fake_logits = discriminator(fake_image, is_training)\n    loss = celoss_ones(d_fake_logits)#我们希望generator生成的图片越接近与1越好\n\n    return loss\n\ndef main():\n    os.mkdir('/kaggle/working/images')\n\n    tf.random.set_seed(22)#随机种子\n    np.random.seed(22)\n    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n    assert tf.__version__.startswith('2.')\n\n\n    # hyper parameters\n    z_dim = 100\n    epochs = 50000\n    batch_size = 512\n    learning_rate = 0.002\n    is_training = True\n\n\n    #img_path = glob.glob(r'C:\\Users\\Jackie Loong\\Downloads\\DCGAN-LSGAN-WGAN-GP-DRAGAN-Tensorflow-2-master\\data\\faces\\*.jpg')\n    #img_path = glob.glob(r'/Users/xuhao/Downloads/GAN实战/faces/*.jpg')#图片的路径\n    img_path = glob.glob(r'/kaggle/input/celeba-dataset/img_align_celeba/img_align_celeba/*.jpg')  # 图片的路径\n\n    dataset, img_shape, _ = make_anime_dataset(img_path, batch_size)#调用dataset.py中的函数\n    print(dataset, img_shape)\n    sample = next(iter(dataset))\n    print(sample.shape, tf.reduce_max(sample).numpy(),\n          tf.reduce_min(sample).numpy())#[512,64,64,3]\n    dataset = dataset.repeat()\n    db_iter = iter(dataset)#使其可以无限制的从dataset中间sample\n\n\n    generator = Generator()\n    generator.build(input_shape = (None, z_dim))#\n    discriminator = Discriminator()\n    discriminator.build(input_shape=(None, 64, 64, 3))#\n\n    g_optimizer = tf.optimizers.Adam(learning_rate=learning_rate, beta_1=0.5)#创建两个优化器,beta为GAN的参数,两个优化器是分开的\n    d_optimizer = tf.optimizers.Adam(learning_rate=learning_rate, beta_1=0.5)\n\n\n    for epoch in range(epochs):\n\n        batch_z = tf.random.uniform([batch_size, z_dim], minval=-1., maxval=1.)#随机sample的值,generator的输入\n        batch_x = next(db_iter)\n\n        # train D\n        with tf.GradientTape() as tape:\n            d_loss = d_loss_fn(generator, discriminator, batch_z, batch_x, is_training)\n        grads = tape.gradient(d_loss, discriminator.trainable_variables)\n        d_optimizer.apply_gradients(zip(grads, discriminator.trainable_variables))\n\n\n        with tf.GradientTape() as tape:\n            g_loss = g_loss_fn(generator, discriminator, batch_z, is_training)\n        grads = tape.gradient(g_loss, generator.trainable_variables)\n        g_optimizer.apply_gradients(zip(grads, generator.trainable_variables))\n\n\n        if epoch == 49990:\n            generator._set_inputs(batch_z)\n            discriminator._set_inputs(batch_x)\n            saved_model_path = \"./saved_models/{}\".format(int(time.time()))\n            tf.keras.models.save_model(generator, saved_model_path)\n            saved_model_path = \"./saved_models/{}\".format(int(time.time()))\n            tf.keras.models.save_model(discriminator, saved_model_path)\n\n\n        if epoch % 100 == 0:\n            print(epoch)\n            print(epoch, 'd-loss:',float(d_loss), 'g-loss:', float(g_loss))\n\n            z = tf.random.uniform([100, z_dim])\n            fake_image = generator(z, training=False)\n            img_path = os.path.join('/kaggle/working/images', 'gan-%d.png'%epoch)\n            save_result(fake_image.numpy(), 10, img_path, color_mode='P')#10为行列\n\n\n\nif __name__ == '__main__':\n    main()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]}]}