{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Load various imports \nfrom datetime import datetime\nfrom os import listdir\nfrom os.path import isfile, join\n\nimport librosa\nimport librosa.display\n\nimport numpy as np\nimport pandas as pd\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, GlobalAveragePooling2D\nfrom keras.utils import to_categorical\nfrom tensorflow.keras.callbacks import ModelCheckpoint\n\nfrom sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mypath = \"/kaggle/input/respiratory-sound-database/Respiratory_Sound_Database/Respiratory_Sound_Database/audio_and_txt_files/\"\nfilenames = [f for f in listdir(mypath) if (isfile(join(mypath, f)) and f.endswith('.wav'))] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p_id_in_file = [] # patient IDs corresponding to each file\nfor name in filenames:\n    p_id_in_file.append(int(name[:3]))\n\np_id_in_file = np.array(p_id_in_file) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_pad_len = 862 # to make the length of all MFCC equal\n\ndef extract_features(file_name):\n    \"\"\"\n    This function takes in the path for an audio file as a string, loads it, and returns the MFCC\n    of the audio\"\"\"\n   \n    try:\n        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast', duration=20) \n        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n        pad_width = max_pad_len - mfccs.shape[1]\n        mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n        \n    except Exception as e:\n        print(\"Error encountered while parsing file: \", file_name)\n        return None \n     \n    return mfccs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filepaths = [join(mypath, f) for f in filenames] # full paths of files","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p_diag = pd.read_csv(\"/kaggle/input/respiratory-sound-database/Respiratory_Sound_Database/Respiratory_Sound_Database/patient_diagnosis.csv\",header=None) # patient diagnosis file","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = np.array([p_diag[p_diag[0] == x][1].values[0] for x in p_id_in_file]) # labels for audio files","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = [] \n\n# Iterate through each sound file and extract the features\nfor file_name in filepaths:\n    data = extract_features(file_name)\n    features.append(data)\n\nprint('Finished feature extraction from ', len(features), ' files')\nfeatures = np.array(features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot an MFCC\nplt.figure(figsize=(10, 4))\nlibrosa.display.specshow(features[7], x_axis='time')\nplt.colorbar()\nplt.title('MFCC')\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = np.array(features) # convert to numpy array","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# delete the very rare diseases\nfeatures1 = np.delete(features, np.where((labels == 'Asthma') | (labels == 'LRTI'))[0], axis=0) \n\nlabels1 = np.delete(labels, np.where((labels == 'Asthma') | (labels == 'LRTI'))[0], axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print class counts\nunique_elements, counts_elements = np.unique(labels1, return_counts=True)\nprint(np.asarray((unique_elements, counts_elements)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot class counts\ny_pos = np.arange(len(unique_elements))\nplt.figure(figsize=(12,8))\nplt.bar(unique_elements, counts_elements, align='center', alpha=0.5)\nplt.xticks(y_pos, unique_elements)\nplt.ylabel('Count')\nplt.xlabel('Disease')\nplt.title('Disease Count in Sound Files (No Asthma or LRTI)')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# One-hot encode labels\nle = LabelEncoder()\ni_labels = le.fit_transform(labels1)\noh_labels = to_categorical(i_labels) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# add channel dimension for CNN\nfeatures1 = np.reshape(features1, (*features1.shape,1)) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train test split\nx_train, x_test, y_train, y_test = train_test_split(features1, oh_labels, stratify=oh_labels, \n                                                    test_size=0.2, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Convolutional Neural Network (CNN) model architecture**\n\nOur model will be a Convolutional Neural Network (CNN) using Keras and a Tensorflow backend.\n\nWe will use a sequential model, with a simple model architecture, consisting of four Conv2D convolution layers, with our final output layer being a dense layer.\n\nThe convolution layers are designed for feature detection. It works by sliding a filter window over the input and performing a matrix multiplication and storing the result in a feature map. This operation is known as a convolution.\n\nThe filter parameter specifies the number of nodes in each layer. Each layer will increase in size from 16, 32, 64 to 128, while the kernel_size parameter specifies the size of the kernel window which in this case is 2 resulting in a 2x2 filter matrix.\n\nThe first layer will receive the input shape of (40, 862, 1) where 40 is the number of MFCC's, 862 is the number of frames taking padding into account and the 1 signifying that the audio is mono.\n\nThe activation function we will be using for our convolutional layers is ReLU. We will use a small Dropout value of 20% on our convolutional layers.\n\nEach convolutional layer has an associated pooling layer of MaxPooling2D type with the final convolutional layer having a GlobalAveragePooling2D type. The pooling layer is to reduce the dimensionality of the model (by reducing the parameters and subsquent computation requirements) which serves to shorten the training time and reduce overfitting. The Max Pooling type takes the maximum size for each window and the Global Average Pooling type takes the average which is suitable for feeding into our dense output layer.\n\nOur output layer will have 6 nodes (num_labels) which matches the number of possible classifications. The activation is for our output layer is softmax. Softmax makes the output sum up to 1 so the output can be interpreted as probabilities. The model will then make its prediction based on which option has the highest probability."},{"metadata":{"trusted":true},"cell_type":"code","source":"num_rows = 40\nnum_columns = 862\nnum_channels = 1\n\nnum_labels = oh_labels.shape[1]\nfilter_size = 2\n\n# Construct model \nmodel = Sequential()\nmodel.add(Conv2D(filters=16, kernel_size=filter_size,\n                 input_shape=(num_rows, num_columns, num_channels), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(filters=32, kernel_size=filter_size, activation='relu'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(filters=64, kernel_size=filter_size, activation='relu'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(filters=128, kernel_size=filter_size, activation='relu'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Dropout(0.2))\n\nmodel.add(GlobalAveragePooling2D())\n\nmodel.add(Dense(num_labels, activation='softmax')) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compile the model\nmodel.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display model architecture summary \nmodel.summary()\n\n# Calculate pre-training accuracy \nscore = model.evaluate(x_test, y_test, verbose=1)\naccuracy = 100*score[1]\n\nprint(\"Pre-training accuracy: %.4f%%\" % accuracy)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Training**\n\nHere we will train the model. If we have a trained model, we can load it instead from the next cell."},{"metadata":{"trusted":true},"cell_type":"code","source":"# train model\nnum_epochs = 250\nnum_batch_size = 128\n\ncallbacks = [\n    ModelCheckpoint(\n        filepath='mymodel2_{epoch:02d}.h5',\n        # Path where to save the model\n        # The two parameters below mean that we will overwrite\n        # the current checkpoint if and only if\n        # the `val_accuracy` score has improved.\n        save_best_only=True,\n        monitor='val_accuracy',\n        verbose=1)\n]\nstart = datetime.now()\n\nmodel.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs,\n          validation_data=(x_test, y_test), callbacks=callbacks, verbose=1)\n\n\nduration = datetime.now() - start\nprint(\"Training completed in time: \", duration)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Test the model**\n\nHere we will review the accuracy of the model on both the training and test data sets."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluating the model on the training and testing set\nscore = model.evaluate(x_train, y_train, verbose=0)\nprint(\"Training Accuracy: \", score[1])\n\nscore = model.evaluate(x_test, y_test, verbose=0)\nprint(\"Testing Accuracy: \", score[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = model.predict(x_test) # label scores \n\nclasspreds = np.argmax(preds, axis=1) # predicted classes \n\ny_testclass = np.argmax(y_test, axis=1) # true classes\n\nn_classes=6 # number of classes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compute ROC curve and ROC area for each class\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], preds[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c_names = ['Bronchiectasis', 'Bronchiolitis', 'COPD', 'Healthy', 'Pneumonia', 'URTI']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot ROC curves\nfig, ax = plt.subplots(figsize=(16, 10))\nax.plot([0, 1], [0, 1], 'k--')\nax.set_xlim([0.0, 1.0])\nax.set_ylim([0.0, 1.05])\nax.set_xlabel('False Positive Rate')\nax.set_ylabel('True Positive Rate')\nax.set_title('ROC Curve for Each Class')\nfor i in range(n_classes):\n    ax.plot(fpr[i], tpr[i], linewidth=3, label='ROC curve (area = %0.2f) for %s' % (roc_auc[i], c_names[i]))\nax.legend(loc=\"best\", fontsize='x-large')\nax.grid(alpha=.4)\nsns.despine()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Classification Report\nprint(classification_report(y_testclass, classpreds, target_names=c_names))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Confusion Matrix\nprint(confusion_matrix(y_testclass, classpreds))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}