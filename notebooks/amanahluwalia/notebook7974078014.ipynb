{"nbformat":4,"nbformat_minor":2,"cells":[{"outputs":[],"cell_type":"markdown","metadata":{"_cell_guid":"600c2249-0bf1-430d-8c0e-a23d917892a7","_uuid":"45ce0a3259f802e8595881da050280ca230693e0"},"source":"Breast Cancer Diagnosis","execution_count":null},{"outputs":[],"cell_type":"markdown","metadata":{"_cell_guid":"4dcc7e89-97ec-4abd-a73e-25ef44446db9","_uuid":"55b522004849ad8c3a45f70225264f70c31c6375"},"source":" ### Load the Data","execution_count":null},{"outputs":[],"cell_type":"code","metadata":{"trusted":false,"_cell_guid":"43f584d5-f21e-46d7-8886-202787377af3","_execution_state":"idle","_uuid":"8213ec11762bcf18bdc2a7d9874e13cce1296aa8","collapsed":false},"source":"# Import libraries\nimport numpy as np\nimport pandas as pd\nfrom time import time\nfrom sklearn.metrics import f1_score\n\n# Read student data\ncancer_data = pd.read_csv(\"../input/data.csv\", header=0)\nprint (\"Cancer data read successfully!\")\ncancer_data.head()","execution_count":3},{"outputs":[],"cell_type":"markdown","metadata":{"_cell_guid":"b01ff064-7ea3-4425-a7f1-553b3fc51c37","_uuid":"92e08a70e5be5317fa0e3a1677f3d24dbdb68c25"},"source":"### Exploring the Data","execution_count":null},{"outputs":[],"cell_type":"code","metadata":{"trusted":false,"_cell_guid":"bce324dd-df1d-4ca8-ab48-a1e210e911f8","_execution_state":"idle","_uuid":"f893e132620cde101e93e24a3dced87ee8711a5e","collapsed":false},"source":"n_cases = cancer_data.shape[0]\n\nn_features = len(list(cancer_data.columns[:-1]))\n\nn_malignant = cancer_data[cancer_data.diagnosis == 'M'].shape[0]\n\nn_benign = cancer_data[cancer_data.diagnosis == 'B'].shape[0]\n\nmalignancy_rate = (float(n_malignant)/n_benign) * 100\n\n# Print the results\nprint (\"Total number of cases: {}\".format(n_cases))\nprint (\"Number of features: {}\".format(n_features))\nprint (\"Number of cases which were positive: {}\".format(n_malignant))\nprint (\"Number of students which were negative: {}\".format(n_benign))\nprint (\"Malignancy rate in patients: {:.2f}%\".format(malignancy_rate))","execution_count":7},{"outputs":[],"cell_type":"code","metadata":{"trusted":false,"_cell_guid":"5af521c5-5990-4183-b8f3-7bfc269feb1c","_execution_state":"idle","_uuid":"ff0108deab5e06ca3939f45bc06fa88b11388699","collapsed":false},"source":"import matplotlib.pyplot as plt\nimport seaborn as sns \n%matplotlib inline\n\n# Plotting frequency of cancer types (in our dataset)\nsns.countplot(cancer_data['diagnosis'],label=\"Count\")","execution_count":13},{"outputs":[],"cell_type":"markdown","metadata":{"_cell_guid":"c2c033f3-d698-44b9-a5bb-11e994bdbb5e","_uuid":"730f5ef83c7ae13852dbe031059fb4df8c32c5e5"},"source":"### Cleaning the data","execution_count":null},{"outputs":[],"cell_type":"code","metadata":{"trusted":false,"_cell_guid":"df5833aa-0482-4ea1-b4ee-0665ec49601f","_execution_state":"idle","_uuid":"53ea4d21dab7fa50ef5681214c44a289917598fa","collapsed":false},"source":"cancer_data.drop('id',axis=1,inplace=True)\ncancer_data.drop('Unnamed: 32',axis=1,inplace=True)\ncancer_data['diagnosis'] = cancer_data['diagnosis'].map({'M':1,'B':0})\ncancer_data.describe()","execution_count":14},{"outputs":[],"cell_type":"markdown","metadata":{"_cell_guid":"c940a8aa-8da8-4de3-a619-958ff7e33a39","_uuid":"0476bda9526874fabe8b6d46da3bbb97e0b29bf3"},"source":"### Visualize Feature Distributions","execution_count":null},{"outputs":[],"cell_type":"code","metadata":{"trusted":false,"_cell_guid":"ec0a9a45-8b2e-47df-ad42-0eedd75968d7","_execution_state":"idle","_uuid":"ef1d576727d34b13d99a2338f4c847e7942999a1","collapsed":false},"source":"# Plotting a correlation graph, to remove any correlated features.\nplt.figure(figsize=(14,14))\nmean_features = list(cancer_data.columns[1:11])\ncorr = cancer_data[mean_features].corr()\nsns.heatmap(corr, cbar = True,  square = True, annot=True, fmt= '.2f',annot_kws={'size': 15},\n           xticklabels= mean_features, yticklabels= mean_features,\n           cmap= 'coolwarm') # for more on heatmap you can visit Link(http://seaborn.pydata.org/generated/seaborn.heatmap.html)","execution_count":15},{"outputs":[],"cell_type":"markdown","metadata":{"_cell_guid":"82d14a33-b566-495d-90c5-345bb1830c93","_uuid":"c03be2d2eff31148b2833009f309f781d2494c23"},"source":"### Preparing the Data","execution_count":null},{"outputs":[],"cell_type":"code","metadata":{"trusted":false,"_cell_guid":"05e47a56-3d49-42d1-b828-719b261a7cae","_execution_state":"idle","_uuid":"e3ed0a260ba42126a78e072de3b7406150e6390b","collapsed":false},"source":"# Extract feature columns\nfeature_cols = ['texture_mean','perimeter_mean','smoothness_mean','compactness_mean','symmetry_mean', 'fractal_dimension_mean']\n\n# Extract target column 'diagnosis'\ntarget_col = cancer_data.columns[0] \n\n# Show the list of columns\nprint (\"Feature columns:\\n{}\".format(feature_cols))\nprint (\"\\nTarget column: {}\".format(target_col))\n\n# Separate the data into feature data and target data (X_all and y_all, respectively)\nX_all = cancer_data[mean_features]\ny_all = cancer_data[target_col]\n\n# Show the feature information by printing the first five rows\nprint (\"\\nFeature values:\")\nprint (X_all.head())","execution_count":17},{"outputs":[],"cell_type":"markdown","metadata":{"_cell_guid":"c3b9ffa0-68b8-4420-b3ef-fa750dd99e5f","_uuid":"aa00f63293f8a9e81cf69f3c9cc2f4026c10350b"},"source":"### Training and Testing Data Split","execution_count":null},{"outputs":[],"cell_type":"code","metadata":{"trusted":false,"_cell_guid":"95629289-d0bf-4582-8189-2ff7ab812377","_execution_state":"idle","_uuid":"aa32d95615a0884c7111c8e385945aa9e7f64a19","collapsed":false},"source":"from sklearn import cross_validation\n\n# Set the number of training points\nnum_train = 425\n\n# Set the number of testing points\nnum_test = X_all.shape[0] - num_train\n\n# Shuffle and split the dataset into the number of training and testing points above\nX_train, X_test, y_train, y_test = cross_validation.train_test_split(X_all, y_all, test_size=num_test, random_state=10)\nX_train_feat = X_train[feature_cols]\nX_test_feat = X_test[feature_cols]\n\n# Show the results of the split\nprint (\"Training set has {} samples.\".format(X_train.shape[0]))\nprint (\"Testing set has {} samples.\".format(X_test.shape[0]))","execution_count":19},{"outputs":[],"cell_type":"markdown","metadata":{"_cell_guid":"542850a7-760f-4b72-9e05-c024b90dd980","_uuid":"e9c404e552d78f96bec8fd16bc75084720e05c73"},"source":"### Training and Evaluating Models","execution_count":null},{"outputs":[],"cell_type":"code","metadata":{"trusted":false,"_cell_guid":"2fe52645-09f6-4509-9ad3-b320ce359161","_execution_state":"idle","_uuid":"3850855f5b4862b415618525ae310e77e91b86f3","collapsed":true},"source":"def train_classifier(clf, X_train, y_train):\n    ''' Fits a classifier to the training data. '''\n    \n    # Start the clock, train the classifier, then stop the clock\n    start = time()\n    clf.fit(X_train, y_train)\n    end = time()\n    \n    # Print the results\n    print (\"Trained model in {:.4f} seconds\".format(end - start))\n\n    \ndef predict_labels(clf, features, target):\n    ''' Makes predictions using a fit classifier based on F1 score. '''\n    \n    # Start the clock, make predictions, then stop the clock\n    start = time()\n    y_pred = clf.predict(features)\n    end = time()\n    \n    # Print and return results\n    print (\"Made predictions in {:.4f} seconds.\".format(end - start))\n    return f1_score(target.values, y_pred, pos_label=1)\n\n\ndef train_predict(clf, X_train, y_train, X_test, y_test):\n    ''' Train and predict using a classifer based on F1 score. '''\n    \n    # Indicate the classifier and the training set size\n    print (\"Training a {} using a training set size of {}. . .\".format(clf.__class__.__name__, len(X_train)))\n    \n    # Train the classifier\n    train_classifier(clf, X_train, y_train)\n    \n    # Print the results of prediction for both training and testing\n    print (\"F1 score for training set: {:.4f}.\".format(predict_labels(clf, X_train, y_train)))\n    print (\"F1 score for test set: {:.4f}.\".format(predict_labels(clf, X_test, y_test)))","execution_count":20},{"outputs":[],"cell_type":"markdown","metadata":{"_cell_guid":"49cafd78-ff1a-4b44-a999-f67700fdf396","_uuid":"bb47cdb9f25a87016c354641d541acff745907b3"},"source":"### Model Performance Metrics","execution_count":null},{"outputs":[],"cell_type":"code","metadata":{"trusted":false,"_cell_guid":"9a7e8b20-d509-4f1c-9383-5ee5fcb12132","_execution_state":"idle","_uuid":"402eafe307c4defab9982affbad14b6b8e90b44c","collapsed":false},"source":"# Import the five supervised learning models from sklearn\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import svm\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Initialize the three models\nclf_A = GaussianNB()\nclf_B = DecisionTreeClassifier()\nclf_C = svm.SVC()\nclf_D = KNeighborsClassifier()\nclf_E = RandomForestClassifier()\n\n# Run trainign and prediction for each model\ntrain_predict(clf_A, X_train_feat, y_train, X_test_feat, y_test)\ntrain_predict(clf_B, X_train_feat, y_train, X_test_feat, y_test)\ntrain_predict(clf_C, X_train_feat, y_train, X_test_feat, y_test)\ntrain_predict(clf_D, X_train_feat, y_train, X_test_feat, y_test)\ntrain_predict(clf_E, X_train_feat, y_train, X_test_feat, y_test)","execution_count":25},{"outputs":[],"cell_type":"markdown","metadata":{"_cell_guid":"0529574a-6ef5-4344-8df6-67eafd68832d","_uuid":"c4f389913b4ee3afd378c73076606aece237d163"},"source":"** Classifer Comparison**  \n\n| Classifier        | Training Time           | Prediction Time (test) | F1 Score (train) | F1 Score (test) |\n| :---------------: | :---------------------: | :--------------------: | :--------------: | :-------------: |\n| GaussianNB        |          0.0091         |           0.0006       |        0.8758    |    0.9216       |\n| DecisionTree      |          0.0036         |           0.0005       |        1.0000    |    0.8909       |\n| SVM               |          0.0218         |           0.0022       |        0.9000    |    0.8381       |\n| KNN               |          0.0011         |           0.0010       |        0.9032    |    0.8491       |\n| RandomForest      |          0.0472         |           0.0025       |        0.9905    |    0.9216       |\n","execution_count":null},{"outputs":[],"cell_type":"markdown","metadata":{"_cell_guid":"44fa2d2b-9af4-4aca-ac8d-ad9a533fb56c","_uuid":"1289b53d949df53d081b015bb441774845baa108"},"source":"## Model Tuning","execution_count":null},{"outputs":[],"cell_type":"code","metadata":{"trusted":false,"_cell_guid":"1481c7f7-a3eb-4cab-a3aa-d807c01ab146","_execution_state":"idle","_uuid":"5b91a13a3bde1f935d2347341912eb20502bd15b","collapsed":true},"source":"# Will take in the parameters and try all combinations, to find the best parameters for the model.\nfrom sklearn.grid_search import GridSearchCV\nfrom sklearn.metrics import make_scorer\ndef train_predict_gridsearch(clf, parameters, X_train, y_train, X_test, y_test):\n    f1_scorer = make_scorer(f1_score,pos_label=1)\n\n    grid_obj = GridSearchCV(estimator = clf, param_grid = parameters, scoring = f1_scorer)\n\n    grid_obj = grid_obj.fit(X_train, y_train)\n\n    clf = grid_obj.best_estimator_\n\n    # Report the final F1 score for training and testing after parameter tuning\n    print (\"Tuned model has a training F1 score of {:.4f}.\".format(predict_labels(clf, X_train, y_train)))\n    print (\"Tuned model has a testing F1 score of {:.4f}.\".format(predict_labels(clf, X_test, y_test)))\n    print (\"The best params are: \",grid_obj.best_params_)","execution_count":26},{"outputs":[],"cell_type":"markdown","metadata":{"_cell_guid":"f629f7df-3dce-4166-b6cd-f41daaddebc5","_uuid":"c444b4798292e4b74f3cdd00f104a6df7b950fd2"},"source":"### Decision Tree","execution_count":null},{"outputs":[],"cell_type":"code","metadata":{"trusted":false,"_cell_guid":"5c50c25e-dc46-4a4b-bcf3-f430254e4e23","_execution_state":"idle","_uuid":"7cf970efd9fafdab95d42a8f760ebd8bf5e07bdc","collapsed":false},"source":"# taking parameters for Decison tree Classifier\nparameters = {'max_features': ['auto', 'sqrt', 'log2'],\n              'min_samples_split': list(range(2, 11)), \n              'min_samples_leaf': list(range(2, 11))}\n\nclf = DecisionTreeClassifier()\ntrain_predict_gridsearch(clf,parameters,X_train,y_train, X_test, y_test)","execution_count":28},{"outputs":[],"cell_type":"markdown","metadata":{"_cell_guid":"234ef19d-f7da-49bd-a4ad-05ae88ea9a14","_uuid":"e2781eaca2b468a814f5b78bf45161151d33e20d"},"source":"### SVM","execution_count":null},{"outputs":[],"cell_type":"code","metadata":{"trusted":false,"_cell_guid":"2037252a-8c1a-4c89-9262-562dff448ab9","_execution_state":"idle","_uuid":"372f93d9ff6230165215fd28c08c2a5ca299d2f3","collapsed":false},"source":"# taking parameters for SVM\nparameters = {'kernel':('linear', 'rbf'),  'gamma':[0.001, 0.01, 0.1, 1]}\nclf = svm.SVC()\ntrain_predict_gridsearch(clf,parameters,X_train,y_train, X_test, y_test)","execution_count":31},{"outputs":[],"cell_type":"markdown","metadata":{"_cell_guid":"0e7e67f8-7e86-4b60-a838-b0b0d3f32ba5","_uuid":"4ac268c4bcb06340cb13851074e3fd23576cdb5c"},"source":"### KNN","execution_count":null},{"outputs":[],"cell_type":"code","metadata":{"trusted":false,"_cell_guid":"eced5406-cbf6-4b8d-80bf-99c63e612e0b","_execution_state":"idle","_uuid":"5e1c8e1a7927a8ce0bbd555cf8a2e18d7b499705","collapsed":false},"source":"clf = KNeighborsClassifier()\n# taking parameters for KNN\nparameters = {'n_neighbors': list(range(1, 11)),\n              'leaf_size': list(range(1,11)),\n              'weights': ['uniform', 'distance']}\ntrain_predict_gridsearch(clf,parameters,X_train,y_train, X_test, y_test)","execution_count":32},{"outputs":[],"cell_type":"markdown","metadata":{"_cell_guid":"8849214e-d908-4012-82fe-637c1505bb55","_uuid":"9db2db5253ccd84a0e4f99887199c2f4453741ef"},"source":"### Random Forest","execution_count":null},{"outputs":[],"cell_type":"code","metadata":{"trusted":false,"_cell_guid":"e2cdfc9e-e1d6-4954-978d-996b2bf32ae5","_execution_state":"idle","_uuid":"98a9facde1750902931f25392c880592e1046f40","collapsed":false},"source":"# Training on all the 10 real valued features\nrandom_forest_classifier = RandomForestClassifier()\ntrain_predict(random_forest_classifier, X_train, y_train, X_test, y_test)","execution_count":33},{"outputs":[],"cell_type":"code","metadata":{"trusted":false,"_cell_guid":"3a028f86-fb31-401f-a110-a7ac8a63e758","_execution_state":"idle","_uuid":"9f889bb5df89c116d0b84df0d9ff0b9a90d20d0c","collapsed":false},"source":"#Create a series with feature importances:\nfeatimp = pd.Series(random_forest_classifier.feature_importances_, index=mean_features).sort_values(ascending=False)\nprint(featimp)","execution_count":34},{"outputs":[],"cell_type":"code","metadata":{"trusted":false,"_cell_guid":"ed7b4a2a-4084-4187-bb7f-2ff1544f3807","_execution_state":"idle","_uuid":"270f642d59ed2363a8ec204eb2f47da28a99bff1","collapsed":false},"source":"# Training on the dataset with the 5 important features\nimp_features = ['concave points_mean','radius_mean','perimeter_mean','area_mean','concavity_mean']\nX_train_imp = X_train[imp_features]\nX_test_imp = X_test[imp_features]\nrandom_forest_classifier = RandomForestClassifier()\ntrain_predict(random_forest_classifier, X_train_imp, y_train, X_test_imp, y_test)","execution_count":35},{"outputs":[],"cell_type":"code","metadata":{"trusted":false,"_cell_guid":"78c3d9d2-3e86-4c51-9550-2d0a8e5b9868","_execution_state":"idle","_uuid":"c2332a1efdb26f556e9894cde9622b4bdae383aa","collapsed":false},"source":"# taking parameters for Random Forest classifier with all the 10 real valued features\nparameters = {'max_depth': [3, None],\n              'max_features': [1,3,10],\n              'min_samples_split': [2,5,10],\n              'min_samples_leaf': [2,5,10],\n              'bootstrap': [True, False],\n              'criterion': ['gini', 'entropy']}\nclf = RandomForestClassifier()\ntrain_predict_gridsearch(clf,parameters,X_train,y_train, X_test, y_test)","execution_count":37},{"outputs":[],"cell_type":"markdown","metadata":{"_cell_guid":"65dd0350-a8f7-4101-8383-df432f07698b","_uuid":"675c9fe49c657a9d10b690fc2c1eeaa011285a3a"},"source":"** Resulatant Classifer Comparison (with tuning)**  \n\n| Classifier        | Prediction Time (train) | Prediction Time (test) | F1 Score (train) | F1 Score (test) |\n| :---------------: | :---------------------: | :--------------------: | :--------------: | :-------------: |\n| GaussianNB        |          0.0007         |           0.0007       |        0.8758    |    0.9216       |\n| DecisionTree      |          0.0001         |           0.0005       |        0.9350    |    0.9126       |\n| SVM               |          0.0009         |           0.0005       |        0.9038    |    0.8679       |\n| KNN               |          0.0040         |           0.0021       |        0.8472    |    0.8125       |\n| RandomForest      |          0.0011         |           0.0012       |        0.9554    |    0.9515       |","execution_count":null},{"outputs":[],"cell_type":"markdown","metadata":{"_cell_guid":"ee9723d2-6051-40df-9313-12981136deb3","_uuid":"9a3974c8b7609df30ccf503e9c19f2fb0ca5fdcf"},"source":"#### Confusion matrix of the final Random Forest Model","execution_count":null},{"outputs":[],"cell_type":"code","metadata":{"trusted":false,"_cell_guid":"49687197-eb11-4bb3-89a3-1a037f4079e2","_execution_state":"idle","_uuid":"8e8f4b45e2ccb7798d3c334d989240096968fe93","collapsed":true},"source":"def plot_confusion_matrix(cm, classes,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n    \n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","execution_count":41},{"outputs":[],"cell_type":"code","metadata":{"trusted":false,"_cell_guid":"cf6300f2-5238-4929-8a6f-6b75b21fb5a3","_execution_state":"idle","_uuid":"adb701b2415ef3b7698c178b18e93e0cafcd6268","collapsed":false},"source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix\nimport itertools\nclf = RandomForestClassifier(bootstrap=True, min_samples_leaf=3, min_samples_split=10, criterion='entropy', max_features=3, max_depth=None)\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\n# save confusion matrix and slice into four pieces\nconfusion = confusion_matrix(y_test, y_pred)\nclass_names = [0,1]\n# print(confusion)\n#[row, column]\nTP = confusion[1, 1]\nTN = confusion[0, 0]\nFP = confusion[0, 1]\nFN = confusion[1, 0]\n\nprint (\"True Positive: \", TP)\nprint (\"True Negative: \", TN)\nprint (\"False Positive: \", FP)\nprint (\"False Negative: \", FN)\n\nplt.figure()\nplot_confusion_matrix(confusion, classes=class_names,\n                      title='Confusion matrix')","execution_count":69},{"outputs":[],"cell_type":"markdown","metadata":{"_cell_guid":"ac8aa9ac-e72e-475c-8d2e-335e088d7cee","_uuid":"d29869f22cdca1051f8cda66c0e70ff60b6dd737"},"source":"### Robustness","execution_count":null},{"outputs":[],"cell_type":"code","metadata":{"trusted":false,"_cell_guid":"849e0ed2-8956-43e3-b0b6-f654fdf8bab5","_execution_state":"idle","_uuid":"31a0cb547d3f51ea1cbf5d9802d8134272e38a1b","collapsed":false},"source":"from sklearn.model_selection import KFold\nX = np.array(X_all)\ny = np.array(y_all)\nkf = KFold(n_splits=5)\nkf.get_n_splits(X)\nprint(kf) \nclf = RandomForestClassifier(bootstrap=True, min_samples_leaf=3, min_samples_split=10, criterion='entropy', max_features=3, max_depth=None)\nfor train_index, test_index in kf.split(X):\n    X_train, X_test = X[train_index], X[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n    clf.fit(X_train, y_train)\n    y_pred = clf.predict(X_test)\n    print (\"F1 score for test set: {:.4f}.\".format(f1_score(y_test, y_pred, pos_label=1)))","execution_count":77},{"outputs":[],"cell_type":"markdown","metadata":{"_cell_guid":"4dcb14d5-8934-462c-82db-5d3bad72022a","_uuid":"522f8a79c9a4bc1577d6ac37c1b0ed2f94b7d8bf"},"source":"The above results suggest that our model is robust (atleast to some extent, given such limited data) even to random new inputs. Its results are moreover consistent with some deviation from 89.76% to 96.30%, hence it seems to be working well even if trained and tested on random data. So we can expect if the new data comes in it would perform in similar spirit.","execution_count":null},{"outputs":[],"cell_type":"markdown","metadata":{"_cell_guid":"d61b541e-4ba6-4e7d-b073-fc85c7311333","_uuid":"82f01b15f96e240434e12e04355cda466961984b"},"source":"### Result","execution_count":null},{"outputs":[],"cell_type":"markdown","metadata":{"_cell_guid":"adbc9726-153a-412c-8ef1-f90ee9aff2b1","_uuid":"c30c208fdb7f9aa7e58f500b009a0127c5fead1d"},"source":"The final and best F1 score which we achieved for training is 0.9554 and for test is 0.9515. The corresponding best model was Random Forest Classifier with bootstrap: True, min_samples_leaf: 3, min_samples_split: 10, criterion: entropy, max_features: 3, max_depth: None being the tuned Parameters.","execution_count":null},{"outputs":[],"cell_type":"markdown","metadata":{"_cell_guid":"7b5f9d58-cb97-4eb4-9294-f145273fbaff","_uuid":"0f6b007a89168ddb4a7b0d9f159d1e30e9a97391"},"source":"### Conclusion","execution_count":null},{"outputs":[],"cell_type":"markdown","metadata":{"_cell_guid":"97aa9fe7-b677-47de-9469-061096992ce9","_uuid":"4f92c522f0f9e648eab3ec5f7e3184fcd22672ed"},"source":"Using the Random Forest ensemble learning model with proper tuning, we were able to achieve 95.15% accuracy on the test set. That means our purpose of reducing the false negatives is reduced by a lot, and our model will be able to make efficient predictions. Still it is around 95% correct, not the 100%, but still for our purpose it is best, as humanâ€™s eye or doctors were not able to achieve this much accuracy in diagnosis of breast cancer, and it often leads to wrong medication. Our model improves in the accuracy aspect, trying to judge the type more accurately.","execution_count":null}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"anaconda-cloud":{},"language_info":{"codemirror_mode":{"version":3,"name":"ipython"},"pygments_lexer":"ipython3","name":"python","nbconvert_exporter":"python","version":"3.6.1","file_extension":".py","mimetype":"text/x-python"}}}