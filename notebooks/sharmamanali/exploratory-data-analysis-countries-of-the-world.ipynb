{"cells":[{"metadata":{"_uuid":"c3a09324e382ad8e5593619057e17865606a66e5"},"cell_type":"markdown","source":"# <p style=\"text-align: center;\">Countries_of_the_World_EDA </p>"},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"931c45c79c905a8908a24bbd55ee126376d5bf69"},"cell_type":"code","source":"from IPython.display import HTML\nfrom IPython.display import Image\nImage(url= \"https://upload.wikimedia.org/wikipedia/commons/b/b4/2002_six-color_world_political_map.png\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"645fade48c73cce6c7ed442c35ed4bd11aa09c8f"},"cell_type":"markdown","source":"### ABSTRACT   \n##### [Reference](#1)\n\nIn this Kernel , The following dataset \"Countries of the World\" by Fernando Lasso has been analyzed. The main focus of this project is GDP (Gross Domestic Product), factors that affects GDP per capita and on the basis of the effects trying to create a model , which uses the data of 227 countries from the given dataset. Also in the following project there is a brief explanation of how total GDPs is related with all the factors. The key methods used for analysis of data is Correlation and Linear Regression. Our key findings leads us to know that GDP per capita is highly correlated with the factors such Literacy, Phones, Service, Infant mortality, Birthrate and Agriculture. \nThis project is a good practice for EDA and visualization. \nExploratory Data Analysis (EDA) is the first step in your data analysis process.we take a broad look at patterns, trends, outliers, unexpected results and so on in the dataset, using visual and quantitative methods to get a sense of the story it tells. "},{"metadata":{"trusted":true,"_uuid":"3cdd29df22468aa4faaf55b395ae10afc7482d48"},"cell_type":"code","source":"from IPython.core.display import HTML\nHTML('''<script>\ncode_show=true; \nfunction code_toggle() {\n if (code_show){\n $('div.input').hide();\n } else {\n $('div.input').show();\n }\n code_show = !code_show\n} \n$( document ).ready(code_toggle);\n</script>\nThe raw code for this IPython notebook is by default hidden for easier reading.\nTo toggle on/off the raw code, click <a href=\"javascript:code_toggle()\">here</a>.''')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d8a9a81756301c71c997d1ca279e42d833a31f10"},"cell_type":"code","source":"# importing libraries \n%matplotlib inline \nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom scipy import stats\nimport seaborn as sns\nimport re\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_log_error\nfrom sklearn.metrics import mean_squared_error\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1c347662766796620d151690e23c2d0316da4bfe"},"cell_type":"code","source":"# importing the dataset\ndf=pd.read_csv('../input/countries of the world.csv', decimal = ',')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5be5c0ab2d14bcd3d6a2e59d6fc3420870ae081a"},"cell_type":"markdown","source":"### The following table shows the first five rows of the given dataset, thereby giving us insight about what sort of dataset it is. And what are the attributes included in the dataset."},{"metadata":{"trusted":true,"_uuid":"83f957684c829bc4307d08328ab698d565628dbd"},"cell_type":"code","source":"#first 5 rows of the data set to see what sort of data is there\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6a964ec278ba406e571e4e5b9d6f9b278428812b"},"cell_type":"markdown","source":"### Statistcal analysis of given dataset"},{"metadata":{"trusted":true,"_uuid":"b4a22ec808cdbdedadd69e2401b4e431477b3c1f"},"cell_type":"code","source":"#statistcal analysis of given data set\ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e370e22e65bcd0d844e99e68767f42ca6cdfc544"},"cell_type":"markdown","source":"### Table Overview"},{"metadata":{"_uuid":"6eae36b33e696d30dc11bf7b53ab184f516819f8"},"cell_type":"markdown","source":"We are checking whether are dataset has any missing values . If it results in true then it does otherwise it doesn't."},{"metadata":{"trusted":true,"_uuid":"f10720b4fa4cb174375499650d799aa6569b5be7"},"cell_type":"code","source":"# Checking for null values\nprint('Dataset has null values?')\ndf.isnull().values.any()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b07a8016ff79893f32ba871adc502f0cd9c98060"},"cell_type":"markdown","source":"#### Now that we know that our dataset has missing values, we need to find the columns which has those values alongwith, the percentage effect it has with respect to whole dataset."},{"metadata":{"_uuid":"bfc517b1daf9db92f5336ec2493d4ce2979f2b8f"},"cell_type":"markdown","source":"Table Overview:- Following table gives us the column names with the number of missing values and percentage effect it has with respect to dataset"},{"metadata":{"trusted":true,"_uuid":"ffa917dc600da2815d99efa5901d90419a370417"},"cell_type":"code","source":"#Finding missing values in the data set \ntotal = df.isnull().sum()[df.isnull().sum() != 0].sort_values(ascending = False)\npercent = pd.Series(round(total/len(df)*100,2))\npd.concat([total, percent], axis=1, keys=['total_missing', 'percent'])\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"205c7190f3878346d9e5baea30135750f123c03f"},"cell_type":"markdown","source":"### HOW TO FIND THE MISSING VALUES "},{"metadata":{"_uuid":"1e9dcb30c5cd562d5472997bb42a74320a44658e"},"cell_type":"markdown","source":"We know that our Dataset contains missing values and we don't have any idea what collective effect it has on whole of dataset , as in how it changes the distribution and by what percentage. Though we can ignore the missing values and run our analysis. But this wholly depends on the collective effect the missing values has on dataset and since we don't have any idea about that it is better if we fill in the missing values and then do our analysis as it will give us better and complete results.\n\nInorder to find the missing values, we need to know what sort of distribution our dependent variable has."},{"metadata":{"_uuid":"1a289f55484fa2ff7ea7e76ea2f24a51d855a28a"},"cell_type":"markdown","source":"Plot overview:- \nThe following Barplot gives us the distribution of \"GDP per capita\" with \"Countries\". By the plots we will be able to know what measure of central tendency we should use in order to fill in our missing values.\n\n1. Plot 1:- Top 33 Countries vs GDP per capita\n2. Plot 2:- Last 33 Countries vs GDP per capita"},{"metadata":{"trusted":true,"_uuid":"6cefcf87fdd943c61f5e2699692fb8c5bb90b729"},"cell_type":"code","source":"#Sorting the values of GDP for different countries in descending order\ntop_gdp_countries = df.sort_values('GDP ($ per capita)',ascending=False)\n#Visual Representation of the graph using seaborn for first 33 values\nfig, ax = plt.subplots(figsize=(16,6))\nsns.barplot(x='Country', y='GDP ($ per capita)', data=top_gdp_countries.head(33), palette='Set1')\nax.set_title('Top 33 Countries vs GDP per capita')\nax.set_xlabel(ax.get_xlabel(), labelpad=15)\nax.set_ylabel(ax.get_ylabel(), labelpad=30)\nax.xaxis.label.set_fontsize(16)\nax.yaxis.label.set_fontsize(16)\nplt.xticks(rotation=90)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"56709cdc45fe8f8a4ea0d3cfaa1e65ffa762476b"},"cell_type":"code","source":"#Visual Representation of the graph using seaborn for last 33 values \nfig, ax = plt.subplots(figsize=(16,6))\nsns.barplot(x='Country', y='GDP ($ per capita)', data=top_gdp_countries.tail(33), palette='Set1')\nax.set_title('Last 33 Countries vs GDP per capita')\nax.set_xlabel(ax.get_xlabel(), labelpad=15)\nax.set_ylabel(ax.get_ylabel(), labelpad=30)\nax.xaxis.label.set_fontsize(16)\nax.yaxis.label.set_fontsize(16)\nplt.xticks(rotation=90)\nplt.show()\n\n#","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"24e87e87ddeca46d28c22f5b7c59ac3736d8f827"},"cell_type":"markdown","source":"### Which mode of central tendency we are using to fill in missing values?\nReasoning:- By looking at both plot we can say that the distribution for GDP per capita with respect to countries is rightly skewed. And for the distributions that are generally skewed and not normal we use median as a measure of central tendency. Mean is not used because it is greatly affected by outliers which would may result in mean being skewed between outliers but median retains its position and is not as strongly influenced by the skewed values. And as for mode, it is generally used for categorical data . Also in mode's case , two or more datapoints have same frequency, as in mode may have more than one value. So, we use median to fill in our missing values."},{"metadata":{"_uuid":"6607b280b2a912373d6d1a12bae9e37e972c01b9"},"cell_type":"markdown","source":"We are going to group data by region . Since, regions are areas that are broadly divided by physical characteristics (physical geography), human impact characteristics (human geography), and the interaction of humanity and the environment (environmental geography) and consists of land and/or countries which have similar attributes. So we have grouped independent variables i.e attributes together by region and calculated the median for the same. \n\nAnd as for the climate , we use mode because it is a categorical data and mean and median won't make much sense for filling in the missing values.\n"},{"metadata":{"trusted":true,"_uuid":"81319dd0226b057bc2ca3eae35a3caaa5c391fbc"},"cell_type":"code","source":"df.groupby('Region')[['GDP ($ per capita)', 'Literacy (%)', 'Agriculture']].median()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"43b30ff4bc7141da6f6e86fbf1aaa911a05c296f"},"cell_type":"markdown","source":"### Missing values being filled in columns"},{"metadata":{"trusted":true,"_uuid":"0864c6004e73f403f379e024dd603b0b9de866d3"},"cell_type":"code","source":"#Missing values being filled in columns\nfor col in df.columns.values:\n    if df[col].isnull().sum() == 0:\n        continue\n    if col == 'Climate':\n        guess_values = df.groupby('Region')['Climate'].apply(lambda x: x.mode().max())\n    else:\n        guess_values = df.groupby('Region')[col].median()\n    for region in df['Region'].unique():\n        df[col].loc[(df[col].isnull())&(df['Region']==region)] = guess_values[region]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6b660b73c34aa259e85842ceaf74f0c2c7c7b2af"},"cell_type":"code","source":"print('Are there anymore null values?')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ea28f7a619f15b4eeb8c0625e8a83efe02daafe1"},"cell_type":"code","source":"df.isnull().values.any()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4037969ef760a7318ff454ccbbfb1d3721d9237f"},"cell_type":"markdown","source":"Table Overview:- Showing columns with number of missing values"},{"metadata":{"trusted":true,"_uuid":"1000f78a5f7d9714c08bf4614d000f4c1d07ee6f"},"cell_type":"code","source":"#check if we filled all missing values\nprint(df.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3752a8c4e7147d522362caa8ec32e6d86e823622"},"cell_type":"markdown","source":"Now that we have a definitive dataset, that is one without null values we can employ various machine learning algorithms to see how are dependent and independent variable is related."},{"metadata":{"_uuid":"3b4b742e894d7cd655c8af9367a272f4e3357e52"},"cell_type":"markdown","source":" ### 1.Correlation:- \nCorrelation is any statistical association, though in common usage it most often refers to how close two variables are to having a linear relationship with each other.\nThe correlation coefficient r measures the strength and direction of a linear relationship between two variables on a scatterplot. \nif r>0 higher the correlation and if r<0 correlation is inversely related"},{"metadata":{"_uuid":"b9e55b560def4b12f30c923c760bd5c89379d238"},"cell_type":"markdown","source":"#### Table Overview:- Gives the Correlated values of each column with each other in a dataframe"},{"metadata":{"trusted":true,"_uuid":"1409b661255d93ca36c191206242191edc290406"},"cell_type":"code","source":"#correlation\ndf.corr()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"27331894350490813f2a5d2cb12927fbc685b859"},"cell_type":"markdown","source":"### Visual representation in form of heatmap for correlated data"},{"metadata":{"trusted":true,"_uuid":"1afaadf3aa35d91d68a32ed368dabb85992e099b"},"cell_type":"code","source":"#Visual representation in form of heatmap for correlated data\nplt.figure(figsize=(16,12))\nax=plt.axes()\nsns.heatmap(data=df.iloc[:,2:].corr(),annot=True,fmt='.2f',cmap='coolwarm',ax=ax)\nax.set_title('Heatmap showing correlated values for the Dataset')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3d20fa828ad93214a343e7df3a3092541789483e"},"cell_type":"markdown","source":"### By looking at the heatmap for a given dataset we can say that following factors are positively correlated with GDP per capita:-\n\n### r>0 for:-\n1. Literacy (%) - 0.51\n2. Phones (per 1000) - 0.83 (Highly correlated)\n3. Service - 0.55\n\n### Following values are inversely correlated with GDP per capita:-\n### r<0 for:-\n1. Infant mortality (per 1000 births) - -0.6\n2. Birthrate - -0.64(Highly negatively correlated)\n3. Agriculture- -0.59"},{"metadata":{"_uuid":"28e993b396a701fb04f645518d9aa84a6e3f042a"},"cell_type":"markdown","source":"#### Visual representation in form of heatmap for data that are maximum correlated with GDP per capita"},{"metadata":{"trusted":true,"_uuid":"ed46a28ad62ea06779fad9d4d136a4d4e8786064"},"cell_type":"code","source":"# choose attributes which shows relation\nx = df[['GDP ($ per capita)','Literacy (%)','Phones (per 1000)','Service','Infant mortality (per 1000 births)','Birthrate','Agriculture']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4d50293e6b54f9ca12aba0849a8690694131fec9"},"cell_type":"code","source":"# show corr of the same\nplt.figure(figsize=(10,5))\nax=plt.axes()\nsns.heatmap(x.corr(), annot=True,ax=ax)\nax.set_title('Heatmap showing correlated values for the Dataset')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c8488e72a81c243353dd42457b93b5192fe67cc2"},"cell_type":"markdown","source":"### Scatterplot\n\nScatterplot uses dots to represent the values obtained for two different variable i.e Independent variable vs dependent variable(x vs y), which is (Factors vs GDP per capita) in this case. It basically shows how strongly two variables have linear relationship. \n\nSince we have some factors which are inversely correlated with GDP per capita , we are going to take the absolute value of correlation coefficient and plot it."},{"metadata":{"trusted":true,"_uuid":"d53aa84bc8bc239093e60f6989a9fef2283255bd"},"cell_type":"code","source":"#scatter plot to show correlation between GDP and other attributes\nfig, axes = plt.subplots(nrows=3, ncols=3, figsize=(23,20))\nplt.subplots_adjust(hspace=0.4)\n\ncorr_to_gdp = pd.Series()\nfor col in df.columns.values[2:]:\n    if ((col!='GDP ($ per capita)')&(col!='Climate')&(col!='Coastline (coast/area ratio)') &(col!='Pop. Density (per sq. mi.)')):\n        corr_to_gdp[col] = df['GDP ($ per capita)'].corr(df[col])\nabs_corr_to_gdp = corr_to_gdp.abs().sort_values(ascending=False)\ncorr_to_gdp = corr_to_gdp.loc[abs_corr_to_gdp.index]\n\n\nfor i in range(3):\n    for j in range(3):\n        sns.regplot(x=corr_to_gdp.index.values[i*3+j], y='GDP ($ per capita)', data=df,\n                   ax=axes[i,j], fit_reg=False, marker='.')\n        title = 'correlation='+str(corr_to_gdp[i*3+j])\n        axes[i,j].set_title(title)\naxes[1,2].set_xlim(0,102)\nfig.suptitle('Scatterplot between GDP per capita and factors', fontsize='30')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7f70bebbd0d1e05c87ed9c97b7277c6f4272adad"},"cell_type":"markdown","source":"### Pairplot\nPairs plot (also known as scatterplot matrix). In a pair plot we can see the distribution for both of the single variables and relationships between two variables(Here GDP per capita, Phones per (1000) and Service). Here we have grouped our data on basis of regions and then plotted it.\n\nThe histogram on the diagonal gives us the distribution of a single variable while the scatter plots on the upper and lower triangles show the relationship between two variables."},{"metadata":{"trusted":true,"_uuid":"b520c4ce373abd3c187f297d7c21fdd2c17a3210"},"cell_type":"code","source":"x = df[['GDP ($ per capita)','Phones (per 1000)','Service','Region']]\n\ng=sns.pairplot(x, hue=\"Region\", diag_kind='hist')\ng.fig.suptitle('Pairplot showing GDP per capita, Services and Phones per(1000)',y=1.05)\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bb5988845186d1f6973759ffd28c17108b0026e9"},"cell_type":"markdown","source":"### CORRELATED ATTRIBUTES\n\n#### 1. Distplot Distribution\n\n#### Positively Correlated Attribute\nThe following figure gives a plot for density of positively correlated factors (where r>0). And it is a univariate distribution"},{"metadata":{"trusted":true,"_uuid":"2c20a91ce0d0b9e83d4ba03de89506dd14e3d287"},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(23,20))\nplt.subplots_adjust(hspace=0.4)\n\nz = pd.Series()\nfor col in df.columns.values[2:]:\n    if ((col!='Deathrate')&(col!='Net migration')&(col!='Industry')&(col!='Agriculture')&(col!='Birthrate')&(col!='Area (sq. mi.)')&(col!='Population')&(col!='Other (%)')&(col!='Crops (%)')&(col!='Arable (%)')&(col!='Infant mortality (per 1000 births)')&(col!='Climate')&(col!='Coastline (coast/area ratio)') &(col!='Pop. Density (per sq. mi.)')):\n      \n        colums=np.array(df[col])\n        z[col]=colums\n#p=z.loc[z.index]\n#print (z)\n\nfor i in range(2):\n    for j in range(2):\n        \n        #x=z.index.values[i*3+j]\n        #sns.barplot(z.index[i*3+j],z.values[i*3+j])\n        #x=z.index.values[i*3+j]\n        \n        y=z.index[i*2+j]\n        x=z[i*2+j]\n        print(y)\n        sns.distplot(x,axlabel=y,ax=axes[i,j])\n\nfig.suptitle('Univariate Distribution of Positively Correlated Factors', fontsize='25')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9171fe865159d18fff3116a49078fd2686de8dc6"},"cell_type":"markdown","source":"####  Negatively Correlated Attribute\nThe following figure gives a plot for density of negatively correlated factors (where r<0). And it is a univariate distribution"},{"metadata":{"trusted":true,"_uuid":"edc4677608791fb318aa3b3ba5a80b513f7cd8c8"},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(10,4))\nplt.subplots_adjust(hspace=0.1)\n\nz = pd.Series()\nfor col in df.columns.values[2:]:\n     if ((col!='Service')&(col!='Deathrate')&(col!='Net migration')&(col!='Industry')&(col!='Literacy (%)')&(col!='GDP ($ per capita)')&(col!='Area (sq. mi.)')&(col!='Population')&(col!='Other (%)')&(col!='Crops (%)')&(col!='Arable (%)')&(col!='Phones (per 1000)')&(col!='Climate')&(col!='Coastline (coast/area ratio)') &(col!='Pop. Density (per sq. mi.)')):\n            \n        colums=np.array(df[col])\n        z[col]=colums\np=z\n#print (p)\n\nfor i in range(1):\n    for j in range(3):\n        y=z.index[j]\n        x=z[j]\n        #print(x)\n        #print(y)\n        #print(z[j].size)\n        sns.distplot(x,ax=axes[j],axlabel=y)\n\nfig.suptitle('Univariate Distribution of Negatively Correlated Factors', fontsize='20')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"70cf0506cc5994053738313538d2965f605cd38c"},"cell_type":"markdown","source":"#### 2. Boxplot\nIt is often used in explanatory data analysis in order to show the shape of the distribution, its central value, and its variability. The following figure gives us the boxplot for the first three factors that are highly positively and negatively correlated."},{"metadata":{"trusted":true,"_uuid":"0b59ed9cde73b392e97889206dd9406e6cdb7608"},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(23,20))\nplt.subplots_adjust(hspace=0.4)\n\nz = pd.Series()\nfor col in df.columns.values[2:]:\n     if ((col!='Deathrate')&(col!='Net migration')&(col!='Industry')&(col!='GDP ($ per capita)')&(col!='Area (sq. mi.)')&(col!='Population')&(col!='Other (%)')&(col!='Crops (%)')&(col!='Arable (%)')&(col!='Climate')&(col!='Coastline (coast/area ratio)') &(col!='Pop. Density (per sq. mi.)')):\n        colums=np.array(df[col])\n        z[col]=colums\n\nfor i in range(2):\n    for j in range(3):\n        \n        x=z.index[i*3+j]\n        y=z[i*3+j]\n        sns.boxplot(z[i*3+j],ax=axes[i,j])\n        title = str(z.index[i*3+j])\n        axes[i,j].set_title(title)\n        axes[0,0].set_xlim(0,175)\n\nfig.suptitle('Boxplot Distribution for Correlated Attributes', fontsize='30')\n      \nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d5ba4b986deb444833908d59b5ca13a964b52d28"},"cell_type":"markdown","source":"### Overview of our Dataset"},{"metadata":{"trusted":true,"_uuid":"f592a11faad43772b9095d2a4704d6d2169c726d"},"cell_type":"code","source":"df.head(5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8c7254ef134231f40091f3de32f69343a0e1f26b"},"cell_type":"markdown","source":"### Data Modeling using Linear Regression"},{"metadata":{"_uuid":"05e582b2c0bb0142e261eedb052109b30a22f02f"},"cell_type":"markdown","source":"Since we know from above given Dataset , that two of the columns i.e Region and Climate have non-numeric values , so before we proceed forward we need to convert it into numeric values , so that we can run different machine learning algorithms on it . Inorder to run analysis. For that very reason we use labelencoder.\n\nLabel encoder basically encodes categorical values and the technique is called as label encoding. Label encoding  simply converts each value of a column to a number."},{"metadata":{"_uuid":"9ee29135c5afb16c8b8eb42db38da96937b7f873"},"cell_type":"markdown","source":"Table Overview:- Following table gives us the columns with non numeric values and encoded numeric values for the same"},{"metadata":{"trusted":true,"_uuid":"3f3c3c207c6c840fff10719f459c2216c9502378"},"cell_type":"code","source":"LE = LabelEncoder()\ndf['Regional_label'] = LE.fit_transform(df['Region'])\ndf1 = df[['Region','Regional_label']]\ndf1.head(5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b0fa203bb744d25e2a722e57fa2eb6adb27cc5e0"},"cell_type":"markdown","source":"[Reference](#2)"},{"metadata":{"_uuid":"ee047a7909269ab58c138f84d83bf019e1c8ebf3"},"cell_type":"markdown","source":"### Linear Regression\n\nLinear regression is basically a linear approach to model the relationship shared between a scalar response (or dependent variable) i.e GDP per capita and one or more explanatory variables (or independent variables) i.e Literacy rate, services etc in our case. "},{"metadata":{"_uuid":"ad6191f3b6311a8046410a5d4c7b7912ede91ba0"},"cell_type":"markdown","source":"### Multiple Linear Regression\n\n#### The case of multiple explanatory variable (independent variable) is called multiple linear regression.\nTo build a well-performing machine learning (ML) model, it is important to seperate data into training and testing dataset . Basically we are training the model on and testing it against the data that comes from the same set of target distribution. "},{"metadata":{"trusted":true,"_uuid":"929dd0ca35528d13b63bfda654b926245a8a5763"},"cell_type":"code","source":"train, test = train_test_split(df, test_size=0.3, shuffle=True)\ntraining_features = ['Population', 'Area (sq. mi.)',\n       'Pop. Density (per sq. mi.)', 'Coastline (coast/area ratio)',\n       'Net migration', 'Infant mortality (per 1000 births)',\n       'Literacy (%)', 'Phones (per 1000)',\n       'Arable (%)', 'Crops (%)', 'Other (%)', 'Birthrate',\n       'Deathrate', 'Agriculture', 'Industry', 'Service', 'Regional_label',\n       'Service']\ntarget = 'GDP ($ per capita)'\ntrain_X = train[training_features]\ntrain_Y = train[target]\ntest_X = test[training_features]\ntest_Y = test[target]\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a4a577bf6261ada84637968d620e61d3ccacf8ec"},"cell_type":"markdown","source":"#### We applied linear regression model on our dataset and calculated the value for Root Mean Squared Error and Mean Squared Error(log).\n\nRoot Mean Squared Error:-\nRoot Mean Square Error (RMSE) mathematically is the standard deviation of the residuals. Residuals is the measure od how far the data points are spreaded across the line of regression which we get by our training data set. RMSE is the measure of how spread out these residuals are. In other words, it tells you how concentrated the data is around the line of best fit.\n\nMean Squared Error:-\nThe Mean Squared Error (MSE) is a measure of how close a fitted line is to data points. It is the sum, over all the data points, of the square of the difference between the predicted and actual target variables, divided by the number of data points. RMSE is the square root of MSE.\n\n"},{"metadata":{"_uuid":"3aca62905700ff371a8c1cdc227f8604c8072b40"},"cell_type":"markdown","source":"#### Calculated Value for RMSE AND MSE  [Reference](#1)"},{"metadata":{"trusted":true,"_uuid":"6d259239de701520c1230f3764d5787f4d3e7046"},"cell_type":"code","source":"model = LinearRegression()\nmodel.fit(train_X, train_Y)\ntrain_pred_Y = model.predict(train_X)\ntest_pred_Y = model.predict(test_X)\ntrain_pred_Y = pd.Series(train_pred_Y.clip(0, train_pred_Y.max()), index=train_Y.index)\ntest_pred_Y = pd.Series(test_pred_Y.clip(0, test_pred_Y.max()), index=test_Y.index)\n\nrmse_train = np.sqrt(mean_squared_error(train_pred_Y, train_Y))\nmsle_train = mean_squared_log_error(train_pred_Y, train_Y)\nrmse_test = np.sqrt(mean_squared_error(test_pred_Y, test_Y))\nmsle_test = mean_squared_log_error(test_pred_Y, test_Y)\n\n#q=model.score(rmse_test,rmse_train)\n\nprint('rmse_train: %.2f '% (rmse_train),'msle_train: %.2f ' %(msle_train))\nprint('rmse_test: %.2f ' %(rmse_test),'msle_test:%.2f ' %(msle_test))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4cc53264e12dedf4286f6f5736d53cf399e3356a"},"cell_type":"markdown","source":"### Simple Linear Regression\n\nThe case of single explanatory variable (independent variable) is called single linear regression.Â¶    [1](#1)"},{"metadata":{"_uuid":"8d1a21feb7dc512bda78f7b430c43d1928f8b866"},"cell_type":"markdown","source":"#### Linear Regression using a positively correlated factor(highest)"},{"metadata":{"trusted":true,"_uuid":"96481f3a3d0ab12fdca7c0af54e2e1f41e41e5d3"},"cell_type":"code","source":"train, test = train_test_split(df, test_size=0.3, shuffle=True)\ntraining_features = ['Phones (per 1000)']\ntarget = 'GDP ($ per capita)'\ntrain_X = train[training_features]\ntrain_Y = train[target]\ntest_X = test[training_features]\ntest_Y = test[target]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4b0aeefdcbdc4cb12231ef555eb7f2a124f2cc34"},"cell_type":"code","source":"model = LinearRegression()\nmodel.fit(train_X, train_Y)\ntrain_pred_Y = model.predict(train_X)\ntest_pred_Y = model.predict(test_X)\ntrain_pred_Y = pd.Series(train_pred_Y.clip(0, train_pred_Y.max()), index=train_Y.index)\ntest_pred_Y = pd.Series(test_pred_Y.clip(0, test_pred_Y.max()), index=test_Y.index)\n\nrmse_train = np.sqrt(mean_squared_error(train_pred_Y, train_Y))\nmsle_train = mean_squared_log_error(train_pred_Y, train_Y)\nrmse_test = np.sqrt(mean_squared_error(test_pred_Y, test_Y))\nmsle_test = mean_squared_log_error(test_pred_Y, test_Y)\n\nprint('rmse_train:%.2f '%(rmse_train),'msle_train:%.2f '%(msle_train))\nprint('rmse_test:%.2f '% (rmse_test),'msle_test:%.2f '%(msle_test))\n\nplt.scatter(test_X, test_Y, color = 'red')\nplt.plot(train_X, train_pred_Y, color = 'blue')\nplt.xlabel('Phones per 1000')\nplt.ylabel('GDP per capita')\nplt.title('Linear Regression between Phones per 1000 and GDP per capita')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0fe51c69d51e407aff9ee5c3fbc326800a1799a6"},"cell_type":"markdown","source":"### Calculating the total GDP and Plotting top 10 countries with highest Total GDP"},{"metadata":{"trusted":true,"_uuid":"89eb5146fc5930568da0aef70e122957cd1dba7a"},"cell_type":"code","source":"df['Total_GDP ($)'] = df['GDP ($ per capita)'] * df['Population']\ntop_gdp_countries = df.sort_values('Total_GDP ($)',ascending=False).head(10)\nother = pd.DataFrame({'Country':['Other'], 'Total_GDP ($)':[df['Total_GDP ($)'].sum() - top_gdp_countries['Total_GDP ($)'].sum()]})\ngdps = pd.concat([top_gdp_countries[['Country','Total_GDP ($)']],other],ignore_index=True)\n\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20,7),gridspec_kw = {'width_ratios':[2,1]})\nsns.barplot(x='Country',y='Total_GDP ($)',data=gdps,ax=axes[0],palette='Set2')\naxes[0].set_xlabel('Country',labelpad=30,fontsize=16)\naxes[0].set_ylabel('Total_GDP',labelpad=30,fontsize=16)\n\ncolors = sns.color_palette(\"Set2\", gdps.shape[0]).as_hex()\naxes[1].pie(gdps['Total_GDP ($)'], labels=gdps['Country'],colors=colors,autopct='%1.1f%%',shadow=True)\naxes[1].axis('equal')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d72d5bcdefece19874b5ed19bce8b6b4d9641ffe"},"cell_type":"markdown","source":"Table Overview:- Rank of countries on basis of total GDP and Rank of countries on basis of GDP per capita"},{"metadata":{"trusted":true,"_uuid":"ec5339a4f169636251ae85bc76fa10b5d05bd504"},"cell_type":"code","source":"Rank_total_gdp = df[['Country','Total_GDP ($)']].sort_values('Total_GDP ($)', ascending=False).reset_index()\nRank_gdp = df[['Country','GDP ($ per capita)']].sort_values('GDP ($ per capita)', ascending=False).reset_index()\nRank_total_gdp= pd.Series(Rank_total_gdp.index.values+1, index=Rank_total_gdp.Country)\nRank_gdp = pd.Series(Rank_gdp.index.values+1, index=Rank_gdp.Country)\nRank_change = (Rank_gdp-Rank_total_gdp).sort_values(ascending=False)\nprint('rank of total GDP - rank of GDP per capita:')\nRank_change.loc[top_gdp_countries.Country]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"02c0f1d8d6a574c8c16382136adb8767769e1af0"},"cell_type":"markdown","source":"### Correlation between Total GDP and factors"},{"metadata":{"trusted":true,"_uuid":"beedd2813bd53c1313c9a044794b6e88168a4e64"},"cell_type":"code","source":"plt.figure(figsize=(16,12))\nax=plt.axes()\ny=df[df.columns[2:]].apply(lambda x: x.corr(df['Total_GDP ($)']))\nprint(y)\nsns.heatmap(data=df.iloc[:,2:].corr(),annot=True,fmt='.2f',cmap='coolwarm',ax=ax)\nax.set_title('Heatmap showing correlated values for the Dataset with respect to total ')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"70d6680769ee23dd1fb378266ae936b123a0351b"},"cell_type":"markdown","source":"# Conclusions\n1. Given Dataset is rightly skewed and hence therefore it's measure of central tendency is median.\n2. GDP per capita is highly correlated with phones, services ,literacy rate(positively correlated) and infant mortality rate, agriculture ,birthrate (negatively correlated).\n3. On being grouped region wise, GDP per capita is positively correlated with phones and services. As in the region where people tend to buy more phones those regions tend to have more GDP per capita and as for services , more the services more is the GDP per capita.\n4. For highly correlated factors , the density distribution is mostly skewed. \n5. Climate has no effect on GDP per capita.\n6. For multiple linear regression, we found the RMSE and MSLE values for test data, and RMSE value is low in the range (55000) is a good measure and hence tells us that model is a good predictor as in we can make theoritical claims and also the vakue for MSLE is low so our model is also a good estimator.(lower value of MSE shows that whether our model is a good estimator. (As in test data fits well with line of regression or not).\n7. For single linear regression (phones per 1000 vs GDP per capita), we see that both RMSE and MSE values are good measure. Phones per 1000 is a good factor that can predict GDP per capita values.\n8. According to total GDP countries like India and China which have low GDP per capita (Rank 146 and Rank 118 respectively) jump to positions 4 and 2 respectively. This shows that although GDP per capita per country is low they have high purchasing power(total GDP).\n9. Countries with high total GDP is quite different from countries with high GDP per capita.\n10. Total GDP is highly correlated with Area and Population.\n11. Factors which were highly correlated with GDP per capita has almost no effect on total GDP except for Phones per 1000 , which has correlation of 0.23.\n"},{"metadata":{"_uuid":"b0ab71cf1d6ca33cd01f02eb778efc93b4650547"},"cell_type":"markdown","source":"# Contributions\n\nThe Dataset had many null values , so cleaning of data was done by me . Also there were few plots which were not presented well, I had aligned those with respect to my code (Barplot & Distplot). Then I did linear regression on the given dataset and calculated the goodness of the model.Also , additionally I calculated the value of total GDP per country and compared those with GDP per capita and found interesting results. Also , i did simple correlation for total GDP with factors.All in all most part of the code was given to us but I contributed around 30% in terms of coding for the given assignment.\n"},{"metadata":{"_uuid":"41e0858f39027ca33259cb158457a6c03be98777"},"cell_type":"markdown","source":"# Citations\n\n1. https://www.kaggle.com/stieranka/predicting-gdp-world-countries/notebook\n<a id='1'></a>\n2. https://www.youtube.com/watch?v=E5RjzSK0fvY&feature=youtu.be\n<a id='2'></a>\n3. https://github.com/nikbearbrown?tab=repositories\n4. https://scikitlearn.org/stable/auto_examples/linear_model/plot_ols.html\n5. https://docs.python.org/3/library/"},{"metadata":{"_uuid":"9a3721b479823d018dbd6f6953725997776fe9d2"},"cell_type":"markdown","source":"# License\n\nCopyright (c) 2019 Manali Sharma\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."},{"metadata":{"trusted":true,"_uuid":"4d99bbc5c0642d1c94ced57b5262e47fd4f38330"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"nbformat":4,"nbformat_minor":1}