{"cells":[{"metadata":{},"cell_type":"markdown","source":"## [Google Colaboratory Variant](https://colab.research.google.com/drive/1ZT6ujInkGn_U0cqkPLsoOW8KzTmGQzFi)","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"from IPython import display\ndef dhtml(st):\n    display.display(display.HTML(\"\"\"<style>\n    @import url('https://fonts.googleapis.com/css?family=Roboto|Orbitron&effect=3d');      \n    </style><p class='font-effect-3d' onclick='setStyle(this,\"#ff6600\")'\n    style='font-family:Roboto; font-size:25px; color:#ff355e;'>\n    %s</p>\"\"\"%st+\"\"\"<script>\n    function setStyle(element,c) {\n     var docs=document.getElementsByClassName('font-effect-3d');\n     for (var i=0; i<docs.length; i++) {\n         docs[i].style='font-family:Orbitron; font-size:22px;'; \n         docs[i].style.color=c;}; };\n    </script>\"\"\"))\ndhtml('Code Modules & Parameters')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true,"collapsed":true},"cell_type":"code","source":"!pip install git+https://github.com/tensorflow/docs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np,pylab as pl,pandas as pd\nimport sys,h5py,imageio,PIL\nimport tensorflow as tf\nimport tensorflow_hub as th\nfrom tensorflow_docs.vis import embed","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seed_size=16; noise_dim=100; epochs=120\nbuffer_size=60000; batch_size=128\nnorm_img=tf.random.normal([1,noise_dim])\nseed_imgs=tf.random.normal([seed_size,noise_dim])","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"dhtml('Data')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(x,y),(_, _)=tf.keras.datasets.mnist.load_data()\nx=x.reshape(x.shape[0],28,28,1).astype('float32')\nx=(x-127.5)/127.5\ndigits=tf.data.Dataset.from_tensor_slices(x)\\\n.shuffle(buffer_size).batch(batch_size)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"dhtml('Deep Convolutional Generative Adversarial Network')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def tfgenerator():\n    model=tf.keras.Sequential()\n    model.add(tf.keras.layers\\\n    .Dense(7*7*256,use_bias=False,input_shape=(noise_dim,)))\n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.LeakyReLU())\n    model.add(tf.keras.layers.Reshape((7,7,256)))\n    model.add(tf.keras.layers\\\n    .Conv2DTranspose(256,(5,5),strides=(1,1),\n                     padding='same',use_bias=False))\n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.LeakyReLU())\n    model.add(tf.keras.layers\\\n    .Conv2DTranspose(16,(5,5),strides=(2,2),\n                     padding='same',use_bias=False))\n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.LeakyReLU())\n    model.add(tf.keras.layers\\\n    .Conv2DTranspose(1,(5,5),strides=(2,2),\n                     padding='same',use_bias=False,\n                     activation='tanh'))\n    return model\ntfgenerator=tfgenerator()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def tfdiscriminator():\n    model=tf.keras.Sequential()\n    model.add(tf.keras.layers\\\n    .Conv2D(16,(5,5),strides=(2,2),\n            padding='same',input_shape=[28,28,1]))\n    model.add(tf.keras.layers.LeakyReLU())\n    model.add(tf.keras.layers.Dropout(.2))\n    model.add(tf.keras.layers\\\n    .Conv2D(256,(5,5),strides=(2,2),padding='same'))\n    model.add(tf.keras.layers.LeakyReLU())\n    model.add(tf.keras.layers.Dropout(.2))\n    model.add(tf.keras.layers.Flatten())\n    model.add(tf.keras.layers.Dense(1))\n    return model\ntfdiscriminator=tfdiscriminator()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"generated_img=tfgenerator(norm_img,training=False)\npl.imshow(generated_img[0,:,:,0],cmap=pl.cm.bone)\npl.title(generated_img.shape)\ntfdiscriminator(generated_img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cross_entropy=tf.keras.losses.BinaryCrossentropy(from_logits=True)\ndef discriminator_loss(real_output,fake_output):\n    real_loss=cross_entropy(tf.ones_like(real_output),real_output)\n    fake_loss=cross_entropy(tf.zeros_like(fake_output),fake_output)\n    total_loss=real_loss+fake_loss\n    return total_loss\ndef generator_loss(fake_output):\n    return cross_entropy(tf.ones_like(fake_output),fake_output)\ngenerator_optimizer=tf.keras.optimizers.Adam(1e-4)\ndiscriminator_optimizer=tf.keras.optimizers.Adam(1e-4)\ncheckpoint=tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n                               discriminator_optimizer=discriminator_optimizer,\n                               generator=tfgenerator,\n                               discriminator=tfdiscriminator)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"dhtml('Training')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"@tf.function\ndef train_step(imgs):\n    random_imgs=tf.random.normal([batch_size,noise_dim])\n    with tf.GradientTape() as gen_tape,tf.GradientTape() as disc_tape:\n        generated_imgs=tfgenerator(random_imgs,training=True)\n        real_output=tfdiscriminator(imgs,training=True)\n        fake_output=tfdiscriminator(generated_imgs,training=True)\n        gen_loss=generator_loss(fake_output)\n        disc_loss=discriminator_loss(real_output,fake_output)\n        gradients_of_generator=\\\n        gen_tape.gradient(gen_loss,tfgenerator.trainable_variables)\n        gradients_of_discriminator=\\\n        disc_tape.gradient(disc_loss,tfdiscriminator.trainable_variables)\n        generator_optimizer\\\n        .apply_gradients(zip(gradients_of_generator,\n                             tfgenerator.trainable_variables))\n        discriminator_optimizer\\\n        .apply_gradients(zip(gradients_of_discriminator,\n                             tfdiscriminator.trainable_variables))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_images(model,epoch,test_input):\n    predictions=model(test_input,training=False)\n    fig=pl.figure(figsize=(4,4))\n    for i in range(predictions.shape[0]):\n        pl.subplot(4,4,i+1)\n        pl.imshow(predictions[i,:,:,0]*127.5+127.5,\n                  cmap=pl.cm.bone)\n        pl.axis('off')\n    pl.savefig('epoch_{:04d}.png'.format(epoch+1))\n    pl.suptitle('Epoch: %04d'%(epoch+1),\n                color='#ff355e',fontsize=20)\n    pl.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(data,epochs):\n    for epoch in range(epochs):\n        for image_batch in data:\n            train_step(image_batch)\n #           display.clear_output(wait=True)\n        if (epoch+1)%20==0:\n            generate_images(tfgenerator,epoch,seed_imgs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"train(digits,epochs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PIL.Image.open('epoch_{:04d}.png'.format(epochs))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dhtml('Interpolation')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def animate(images):\n    converted_images=np.clip(images*255,0,255)\\\n    .astype(np.uint8)\n    imageio.mimsave('animation.gif',converted_images)\n    return embed.embed_file('animation.gif')\ndef interpolate_hypersphere(v1,v2,steps):\n    v1norm=tf.norm(v1)\n    v2norm=tf.norm(v2)\n    v2normalized=v2*(v1norm/v2norm)\n    vectors=[]\n    for step in range(steps):\n        interpolated=v1+(v2normalized-v1)*step/(steps-1)\n        interpolated_norm=tf.norm(interpolated)\n        interpolated_normalized=\\\n        interpolated*(v1norm/interpolated_norm)\n        vectors.append(interpolated_normalized)\n    return tf.stack(vectors)\ndef interpolate_between_vectors(steps):\n    tf.random.set_seed(1)\n    v1=tf.random.normal([noise_dim])\n    v2=tf.random.normal([noise_dim])\n    vectors=interpolate_hypersphere(v1,v2,steps)\n    interpolated_imgs=tfgenerator(vectors,training=False)\n    interpolated_imgs=\\\n    tf.image.resize(interpolated_imgs,[128,128])\n    return interpolated_imgs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imgs=interpolate_between_vectors(120)\nanimate(imgs)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"dhtml('Parameters 2 & Data 2')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seed_size=16; noise_dim=256; img_size=42\nepochs=200; buffer_size=11000; batch_size=128\nnorm_img=tf.random.normal([1,noise_dim])\nseed_imgs=tf.random.normal([seed_size,noise_dim])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fpath='../input/classification-of-handwritten-letters/'\nzf='LetterColorImages_123.h5'\nf=h5py.File(fpath+zf,'r')\nkeys=list(f.keys()); print(keys)\nx=np.array(f[keys[1]],dtype='float32')\nx=tf.image.resize(x,[img_size,img_size]).numpy()\nx=np.dot(x,[.299,.587,.114])\nx=x.reshape(-1,img_size,img_size,1)\ny=np.array(f[keys[2]],dtype='int32')\\\n.reshape(-1,1)-1\nN=len(y); n=int(.1*N)\nshuffle_ids=np.arange(N)\nnp.random.RandomState(23).shuffle(shuffle_ids)\nx,y=x[shuffle_ids],y[shuffle_ids]","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"x=(x-127.5)/127.5\npl.imshow((255-x[0]).reshape(img_size,img_size),\n          cmap=pl.cm.bone)\npl.title(x[0].shape)\nletters=tf.data.Dataset.from_tensor_slices(x)\\\n.shuffle(buffer_size).batch(batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dhtml('DCGAN 2')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def tfgenerator2():\n    model=tf.keras.Sequential()\n    model.add(tf.keras.layers\\\n    .Dense(7*7*256,use_bias=False,input_shape=(noise_dim,)))\n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.LeakyReLU())\n    model.add(tf.keras.layers.Reshape((7,7,256)))\n    model.add(tf.keras.layers\\\n    .Conv2DTranspose(256,(7,7),strides=(3,3),\n                     padding='same',use_bias=False))\n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.LeakyReLU())\n    model.add(tf.keras.layers\\\n    .Conv2DTranspose(32,(7,7),strides=(2,2),\n                     padding='same',use_bias=False))\n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.LeakyReLU())\n    model.add(tf.keras.layers\\\n    .Conv2DTranspose(1,(7,7),strides=(1,1),\n                     padding='same',use_bias=False,\n                     activation='tanh'))\n    return model\ntfgenerator2=tfgenerator2()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def tfdiscriminator2():\n    model=tf.keras.Sequential()\n    model.add(tf.keras.layers\\\n    .Conv2D(32,(7,7),strides=(2,2),padding='same',\n            input_shape=[img_size,img_size,1]))\n    model.add(tf.keras.layers.LeakyReLU())\n    model.add(tf.keras.layers.Dropout(.2))\n    model.add(tf.keras.layers\\\n    .Conv2D(256,(7,7),strides=(2,2),padding='same'))\n    model.add(tf.keras.layers.LeakyReLU())\n    model.add(tf.keras.layers.Dropout(.2))\n    model.add(tf.keras.layers.Flatten())\n    model.add(tf.keras.layers.Dense(1))\n    return model\ntfdiscriminator2=tfdiscriminator2()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"generated_img=tfgenerator2(norm_img,training=False)\npl.imshow(generated_img[0,:,:,0],cmap=pl.cm.bone)\npl.title(generated_img.shape);\ntfdiscriminator2(generated_img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cross_entropy=tf.keras.losses.BinaryCrossentropy(from_logits=True)\ndef discriminator_loss(real_output,fake_output):\n    real_loss=cross_entropy(tf.ones_like(real_output),real_output)\n    fake_loss=cross_entropy(tf.zeros_like(fake_output),fake_output)\n    total_loss=real_loss+fake_loss\n    return total_loss\ndef generator_loss(fake_output):\n    return cross_entropy(tf.ones_like(fake_output),fake_output)\ngenerator_optimizer2=tf.keras.optimizers.Adam(1e-3)\ndiscriminator_optimizer2=tf.keras.optimizers.Adam(1e-3)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"dhtml('Training')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"@tf.function\ndef train_step2(imgs):\n    random_imgs=tf.random.normal([batch_size,noise_dim])\n    with tf.GradientTape() as gen_tape,tf.GradientTape() as disc_tape:\n        generated_imgs=tfgenerator2(random_imgs,training=True)\n        real_output=tfdiscriminator2(imgs,training=True)\n        fake_output=tfdiscriminator2(generated_imgs,training=True)\n        gen_loss=generator_loss(fake_output)\n        disc_loss=discriminator_loss(real_output,fake_output)\n        gradients_of_generator=\\\n        gen_tape.gradient(gen_loss,tfgenerator2.trainable_variables)\n        gradients_of_discriminator=\\\n        disc_tape.gradient(disc_loss,tfdiscriminator2.trainable_variables)\n        generator_optimizer2\\\n        .apply_gradients(zip(gradients_of_generator,\n                             tfgenerator2.trainable_variables))\n        discriminator_optimizer2\\\n        .apply_gradients(zip(gradients_of_discriminator,\n                             tfdiscriminator2.trainable_variables))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_images2(model,epoch,test_input):\n    predictions=model(test_input,training=False)\n    fig=pl.figure(figsize=(4,4))\n    for i in range(predictions.shape[0]):\n        pl.subplot(4,4,i+1)\n        pl.imshow(127.5-predictions[i,:,:,0]*127.5,\n                  cmap=pl.cm.bone)\n        pl.axis('off')\n    pl.savefig('epoch_{:04d}.png'.format(epoch+1))\n    pl.suptitle('Epoch: %04d'%(epoch+1),\n                color='#ff355e',fontsize=20)\n    pl.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train2(data,epochs):\n    for epoch in range(epochs):\n        for image_batch in data:\n            train_step2(image_batch)\n        if (epoch+1)%10==0:\n            generate_images2(tfgenerator2,epoch,seed_imgs)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"train2(letters,epochs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PIL.Image.open('epoch_{:04d}.png'.format(epochs))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def interpolate_between_vectors2(steps):\n    tf.random.set_seed(123)\n    v1=tf.random.normal([noise_dim])\n    v2=tf.random.normal([noise_dim])\n    vectors=interpolate_hypersphere(v1,v2,steps)\n    interpolated_imgs=tfgenerator2(vectors,training=False)\n    interpolated_imgs=\\\n    tf.image.resize(interpolated_imgs,[128,128])\n    return interpolated_imgs\ndef animate2(images):\n    converted_images=np.clip(127.5-images*255,0,255)\\\n    .astype(np.uint8)\n    imageio.mimsave('animation.gif',converted_images)\n    return embed.embed_file('animation.gif')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imgs=interpolate_between_vectors2(180)\nanimate2(imgs)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}