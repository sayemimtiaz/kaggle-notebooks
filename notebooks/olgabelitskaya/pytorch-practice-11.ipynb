{"cells":[{"metadata":{},"cell_type":"markdown","source":"Reading classics [Deep Learning Models](https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/cnn/cnn-densenet121-mnist.ipynb)\n\nCode Modules, Classes & Functions","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np,pandas as pd,pylab as pl\nimport h5py,torch,re\nfrom tensorflow import image as timage\nfrom torchvision.datasets import CIFAR10 as tcifar10\nfrom torchvision import transforms,utils\nfrom torch.utils.data import DataLoader as tdl\nfrom torch.utils.data import Dataset as tds\nfrom torch.utils.data.dataset import Subset\nimport torch.nn as tnn\nimport torch.utils.checkpoint as tcp\nfrom collections import OrderedDict as od\nfrom IPython.core.magic import register_line_magic\ndev=torch.device(\"cuda:0\" \\\nif torch.cuda.is_available() else \"cpu\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"class TData(tds):\n    def __init__(self,X,y):   \n        self.X=torch.tensor(X,dtype=torch.float32)\n        self.y=torch.tensor(y,dtype=torch.int32)\n    def __getitem__(self,index):\n        train_img,train_lbl=self.X[index],self.y[index]\n        return train_img,train_lbl\n    def __len__(self):\n        return self.y.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def load_h5py(path,img_size):\n    f=h5py.File(path,'r')\n    keys=list(f.keys()); print(keys)\n    x=np.array(f[keys[1]],dtype='float32')/255\n    x=x.reshape(-1,3,img_size,img_size)\n    y=np.array(f[keys[2]],dtype='int32')-1\n    N=len(y); n=int(.2*N)\n    shuffle_ids=np.arange(N)\n    np.random.RandomState(23).shuffle(shuffle_ids)\n    x,y=x[shuffle_ids],y[shuffle_ids]\n    x_test,x_valid,x_train=x[:n],x[n:2*n],x[2*n:]\n    y_test,y_valid,y_train=y[:n],y[n:2*n],y[2*n:]\n    df=pd.DataFrame([[x_train.shape,x_valid.shape,x_test.shape],\n                     [x_train.dtype,x_valid.dtype,x_test.dtype],\n                     [y_train.shape,y_valid.shape,y_test.shape],\n                     [y_train.dtype,y_valid.dtype,y_test.dtype]],\n                    columns=['train','valid','test'],\n                    index=['image shape','image type',\n                           'label shape','label type'])\n    display(df)    \n    return [[x_train,x_valid,x_test],\n            [y_train,y_valid,y_test]]","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def display_examples(data_loader,img_size):\n    for images,labels in data_loader:  \n        print('Image dimensions: %s'%str(images.shape))\n        print('Label dimensions: %s'%str(labels.shape))\n        n=np.random.randint(1,50)\n        fig=pl.figure(figsize=(11,4))\n        for i in range(n,n+5):\n            ax=fig.add_subplot(1,5,i-n+1,\\\n            xticks=[],yticks=[],title=labels[i].item())\n            ax.imshow((images[i]).reshape(img_size,img_size,3))\n        break\ndef show_image(img):\n    npimg=img.numpy()/2.+.5; tr=(1,2,0)\n    pl.figure(figsize=(10,2))\n    pl.imshow(np.transpose(npimg,tr))\n    pl.xticks([]); pl.show()\ndef show_examples(data_loader,classes,num_examples):\n    dataiter=iter(data_loader)\n    images,labels=dataiter.next()\n    show_image(utils.make_grid(images[0:num_examples]))\n    print('^'.join('%9s'%classes[labels[j]] \n                   for j in range(num_examples)),end='^')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def model_acc(model,data_loader):\n    model.eval()\n    correct_preds,num_examples=0,0    \n    for features,targets in data_loader:\n        features=features.to(dev)\n        targets=targets.to(dev)\n        logits,probs=model(features)\n        _,pred_labels=torch.max(probs,1)\n        num_examples+=targets.size(0)\n        correct_preds+=(pred_labels==targets).sum()        \n    return correct_preds.float()/num_examples*100\n@register_line_magic\ndef print_acc(n):\n    if int(n)==1:\n        data_loader=\\\n        [train_loader,valid_loader,test_loader]\n    if int(n)==2:\n        data_loader=\\\n        [train_loader2,valid_loader2,test_loader2]\n    print('Train accuracy: %.4f%%'%\\\n    (model_acc(model,data_loader[0])))\n    print('Valid accuracy: %.4f%%'%\\\n    (model_acc(model,data_loader[1])))\n    print('Test accuracy: %.4f%%'%\\\n    (model_acc(model,data_loader[2])))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data","execution_count":null},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"random_seed=12; batch_size=128\ntrain_ids=torch.arange(0,44000)\nvalid_ids=torch.arange(44000,50000)\ntr0=(.5,.5,.5)\ntransform=transforms\\\n.Compose([transforms.ToTensor(),\n          transforms.Normalize(tr0,tr0)])\ntrain_valid=tcifar10(root='data',transform=transform,\n                     download=True,train=True)\ntrain=Subset(train_valid,train_ids)\nvalid=Subset(train_valid,valid_ids)\ntest=tcifar10(root='data',train=False, \n              transform=transform)\ntrain_loader=tdl(dataset=train,shuffle=True, \n                 batch_size=batch_size)\nvalid_loader=tdl(dataset=valid,shuffle=True, \n                 batch_size=batch_size)\ntest_loader=tdl(dataset=test,shuffle=False, \n                batch_size=batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classes=('plane','car','bird','cat','deer',\n         'dog','frog','horse','ship','truck')\nshow_examples(valid_loader,classes,7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fpath='../input/classification-of-handwritten-letters/'\nf='LetterColorImages_123.h5'\n[[x_train,x_valid,x_test],\n [y_train,y_valid,y_test]]=\\\nload_h5py(fpath+f,32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_seed=23; batch_size2=128\ntrain2=TData(x_train,y_train)\nvalid2=TData(x_valid,y_valid)\ntest2=TData(x_test,y_test)\ntrain_loader2=tdl(dataset=train2,\n                  batch_size=batch_size2,shuffle=True)\nvalid_loader2=tdl(dataset=valid2,\n                  batch_size=batch_size2,shuffle=True)\ntest_loader2=tdl(dataset=test2,\n                 batch_size=batch_size2,shuffle=False)\ndisplay_examples(valid_loader2,32)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## DenseNet","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def _bn_function_call(norm,relu,conv):\n    def bn_function(*inputs):\n        concated_features=torch.cat(inputs,1)\n        bottleneck_output=conv(relu(norm(concated_features)))\n        return bottleneck_output\n    return bn_function\nclass _DenseLayer(tnn.Sequential):\n    def __init__(self,num_input_features,growth_rate,\n                 bn_size,drop_rate,memory_efficient=False):\n        super(_DenseLayer,self).__init__()\n        self.add_module('norm1',\n                        tnn.BatchNorm2d(num_input_features)),\n        self.add_module('relu1',tnn.ReLU(inplace=True)),\n        self.add_module('conv1',\\\n        tnn.Conv2d(num_input_features,bn_size*growth_rate,\n                   kernel_size=1,stride=1,bias=False)),\n        self.add_module('norm2',\n                        tnn.BatchNorm2d(bn_size*growth_rate)),\n        self.add_module('relu2',tnn.ReLU(inplace=True)),\n        self.add_module('conv2',\\\n        tnn.Conv2d(bn_size*growth_rate,growth_rate,\n                   kernel_size=3,stride=1,\n                   padding=1,bias=False)),\n        self.drop_rate=drop_rate\n        self.memory_efficient=memory_efficient\n    def forward(self,*prev_features):\n        bn_function=_bn_function_call(self.norm1,\n                                      self.relu1,self.conv1)\n        if self.memory_efficient and \\\n        any(prev_feature.requires_grad \\\n            for prev_feature in prev_features):\n            bottleneck_output=tcp.checkpoint(bn_function,*prev_features)\n        else:\n            bottleneck_output=bn_function(*prev_features)\n        new_features=self.conv2(self.relu2(\n            self.norm2(bottleneck_output)))\n        if self.drop_rate>0:\n            new_features=tnn.functional.dropout(new_features,\\\n            p=self.drop_rate,training=self.training)\n        return new_features","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"class _DenseBlock(tnn.Module):\n    def __init__(self,num_layers,num_input_features,\n                 bn_size, growth_rate,drop_rate,\n                 memory_efficient=False):\n        super(_DenseBlock,self).__init__()\n        for i in range(num_layers):\n            layer=_DenseLayer(\n                num_input_features+i*growth_rate,\n                growth_rate=growth_rate,\n                bn_size=bn_size,drop_rate=drop_rate,\n                memory_efficient=memory_efficient)\n            self.add_module('denselayer%d'%(i+1),layer)\n    def forward(self,init_features):\n        features=[init_features]\n        for name,layer in self.named_children():\n            new_features=layer(*features)\n            features.append(new_features)\n        return torch.cat(features,1)\nclass _Transition(tnn.Sequential):\n    def __init__(self,num_input_features,num_output_features):\n        super(_Transition,self).__init__()\n        self.add_module('norm',\n                        tnn.BatchNorm2d(num_input_features))\n        self.add_module('relu',tnn.ReLU(inplace=True))\n        self.add_module('conv',\\\n        tnn.Conv2d(num_input_features,num_output_features,\n                   kernel_size=1,stride=1,bias=False))\n        self.add_module('pool',\n                        tnn.AvgPool2d(kernel_size=2,stride=2))   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DenseNN121(tnn.Module):\n    def __init__(self,growth_rate=32,block_config=(6,12,24,16),\n                 num_init_featuremaps=64,bn_size=4,drop_rate=0,\n                 num_classes=1000,memory_efficient=False,\n                 grayscale=False):\n        super(DenseNN121,self).__init__()\n        if grayscale: in_channels=1\n        else: in_channels=3       \n        self.features=tnn.Sequential(od([\n            ('conv0',tnn.Conv2d(in_channels=in_channels,\n                                out_channels=num_init_featuremaps,\n                                kernel_size=7,stride=2,\n                                padding=3,bias=False)),\n            ('norm0',tnn.BatchNorm2d(num_features=num_init_featuremaps)),\n            ('relu0',tnn.ReLU(inplace=True)),\n            ('pool0',tnn.MaxPool2d(kernel_size=3,stride=2,padding=1))]))\n        num_features=num_init_featuremaps\n        for i,num_layers in enumerate(block_config):\n            block=_DenseBlock(\n                num_layers=num_layers,\n                num_input_features=num_features,\n                bn_size=bn_size,drop_rate=drop_rate,\n                growth_rate=growth_rate,\n                memory_efficient=memory_efficient)\n            self.features.add_module('denseblock%d'%(i+1),block)\n            num_features=num_features+num_layers*growth_rate\n            if i!=len(block_config)-1:\n                trans=_Transition(num_input_features=num_features,\n                                  num_output_features=num_features//2)\n                self.features.add_module('transition%d'%(i+1),trans)\n                num_features=num_features//2\n        self.features.add_module('norm5',tnn.BatchNorm2d(num_features))\n        self.classifier=tnn.Linear(num_features,num_classes)\n        for m in self.modules():\n            if isinstance(m,tnn.Conv2d):\n                tnn.init.kaiming_normal_(m.weight)\n            elif isinstance(m,tnn.BatchNorm2d):\n                tnn.init.constant_(m.weight,1)\n                tnn.init.constant_(m.bias,0)\n            elif isinstance(m,tnn.Linear):\n                tnn.init.constant_(m.bias,0)\n    def forward(self,x):\n        y=self.features(x)\n        y=tnn.functional.relu(y,inplace=True)\n        y=tnn.functional.adaptive_avg_pool2d(y,(1,1))\n        y=torch.flatten(y,1)\n        logits=self.classifier(y)\n        probs=tnn.functional.softmax(logits,dim=1)\n        return logits,probs","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"random_seed=34; num_classes=10\nlearning_rate=.001; grayscale=False\nmodel=DenseNN121(num_classes=num_classes,\n                 grayscale=grayscale)\nmodel.to(dev)\noptimizer=torch.optim.Adam(model.parameters(),\n                           lr=learning_rate) ","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"@register_line_magic\ndef train_run(epochs):\n    epochs=int(epochs)\n    for epoch in range(epochs):\n        model.train()\n        for batch_ids,(features,targets) in enumerate(train_loader):        \n            features=features.to(dev); targets=targets.to(dev)\n            logits,probs=model(features)\n            cost=tnn.functional.cross_entropy(logits,targets)\n            optimizer.zero_grad(); cost.backward()\n            optimizer.step()\n            if not batch_ids%100:\n                print ('Epoch: %03d/%03d | Batch %03d/%03d | Cost: %.4f' \n                       %(epoch+1,epochs,batch_ids, \n                         len(train)//batch_size,cost))\n        model.eval()         \n        with torch.set_grad_enabled(False):\n            print('Epoch: %03d/%03d train acc: %.2f%% valid acc: %.2f%%'%\\\n                  (epoch+1,epochs,\n                   model_acc(model,train_loader),\n                   model_acc(model,valid_loader)))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"%train_run 20","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%print_acc 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_seed=45; num_classes=33\nlearning_rate=.001; grayscale=False\nmodel=DenseNN121(num_classes=num_classes,\n                 grayscale=grayscale)\nmodel.to(dev)\noptimizer=torch.optim.Adam(model.parameters(),\n                           lr=learning_rate) ","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"@register_line_magic\ndef train_run2(epochs):\n    epochs=int(epochs)\n    for epoch in range(epochs):\n        model.train()\n        for batch_ids,(features,targets) in enumerate(train_loader2):        \n            features=features.to(dev); targets=targets.to(dev)\n            logits,probs=model(features)\n            cost=tnn.functional.cross_entropy(logits,targets.long())\n            optimizer.zero_grad(); cost.backward()\n            optimizer.step()\n            if not batch_ids%50:\n                print ('Epoch: %03d/%03d | Batch %03d/%03d | Cost: %.4f' \n                       %(epoch+1,epochs,batch_ids, \n                         len(train2)//batch_size2,cost))\n        model.eval()         \n        with torch.set_grad_enabled(False):\n            print('Epoch: %03d/%03d train acc: %.2f%% valid acc: %.2f%%'%\\\n                  (epoch+1,epochs,\n                   model_acc(model,train_loader2),\n                   model_acc(model,valid_loader2)))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"%train_run2 30","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%print_acc 2","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}