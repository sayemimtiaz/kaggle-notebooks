{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Classification \n\nThis notebook deals with whether a customer will default on the loan payment or not. The file consists of the following columns *ClientId*,*Income*,*Age*,*Loan* and *Default*.\n\n*ClientId* can be dropped as it is not a deciding factor in whether a client will default on the loan payment or not. *Income*,*Age* and *Loan* are important features in decinding whether a client will default.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Importing the necessary libraries","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport itertools\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import StandardScaler","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*confusion_matrix* is used to show towards which class the model is biased towards. *accuracy_score* calculates the accuracy, but it does not show how good the model behaves.\n\n*train_test_split* is used to split the features and output into train and test datasets. This is recommened as the model shoould not be tested on the complete dataset. If it is the model may overfit.\n\n*KNeighboursClassifier* is the scikit-learn implement of the k-NN classification algorithm.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Reading the file using `read_csv` module of `pandas`.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/credit-risk/original.csv\")\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"0 is not default while 1 is default","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\"Age\" has three rows with NaN as values, we are filling them with the mean of the column.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.fillna(data.mean(),inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dropping the *clientid* as it does not define whether the client defaults or not.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop(columns=\"clientid\",inplace=True)\ndata[\"age\"] = data[\"age\"].astype(\"int\")\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Splitting the dataset into features and output. \n\n> X -> *income*, *age* and *loan*\n\n> y -> *default*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data[[\"income\",\"age\",\"loan\"]]\ny = data[\"default\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Splitting the features and output into train and test dataset with test as 20% of features and default.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Initializing the k-NN algorithm with minimum number of neighbours to classify in a class at 4","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"neigh = KNeighborsClassifier(n_neighbors=4)\n\nmodel = neigh.fit(X_train,y_train)\n\ny_pred = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Printing the *Mean Squared Error* and *Accuracy Score* of the classifier.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Mean Squared Error{:.3f}\".format(mean_squared_error(y_pred,y_test)))\nprint(\"Accuracy score:{:.3f}\".format(accuracy_score(y_pred,y_test)*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"An accuracy of *84.750* is achieved with a mean squared error of *0.152*.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Comparing the predicted values and actual values and storing in in a CSV file.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"results = pd.DataFrame({\"Actual Values\":y_test,\n                        \"Predicted Values\":y_pred})\nresults.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results.to_csv(\"k-NN.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plotting the confusion matrix to determine towards which model is the class biased towards.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(y_pred,y_test)\n\ndef plot_confusion_matrix(cm,classes,title='Confusion Matrix',cmap=plt.cm.Blues):\n    \n    cm = cm.astype('float')/cm.sum(axis=1)[:,np.newaxis]\n    plt.figure(figsize=(10,10))\n    plt.imshow(cm,interpolation='nearest',cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n    \n    fmt = '.2f'\n    thresh = cm.max()/2.\n    for i,j in itertools.product(range(cm.shape[0]),range(cm.shape[1])):\n        plt.text(j,i,format(cm[i,j],fmt),\n                horizontalalignment=\"center\",\n                color=\"white\" if cm[i,j] > thresh else \"black\")\n        pass\n    \n    plt.ylabel('True Label')\n    plt.xlabel('Predicted Label')\n    pass\n\nclasses=['0','1']\n\nplt.figure()\nplot_confusion_matrix(cm,classes,title=\"KNN\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As it can be seen that the model is biased towards the customer not defaulting. The accuracy should not be the only metric to be used for comparing models.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Normalising the Data\n\nIn the previous model the feature data was not normalised. Normalisation allows the data to be on the same plane or within similar ranges.\n\nTake this for example, features with values (10000,1,100) and (20000,0,200). Using euclidean or  minkowski distance the second values change is overshadowed by the other first and third values change. By normalising all the changes in each value ar given similar measure. This allows the model to train more precisely and efficiently.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Using StandardScaler from scikit-learn. \n\nThe mean and standard variance is calculated. The mean is subtracted from each value and subsequently divided by the variance.\n\nThe MinMaxScaler can also be used where the minimum is subtracted from each value and divided by the difference between maximum and minimum values.\n\nThis done with every column in the features data before the splitting into train and test datasets.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\n\nX = scaler.fit_transform(X)\nX = pd.DataFrame(X)\nX.columns = [\"income\",\"age\",\"loan\"]\nX.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using the normalised data and making a model.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"neigh = KNeighborsClassifier(n_neighbors=3)\n\nmodel = neigh.fit(X_train,y_train)\n\ny_pred = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Calculating the accuracy and mean squared error.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Mean Squared Error: {:.3f}\".format(mean_squared_error(y_pred,y_test)))\nprint(\"Accuracy score: {:.3f}\".format(accuracy_score(y_pred,y_test)*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"An accuracy of *97.500* is obtained with a mean squared error of *0.025*.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"results_normalized = pd.DataFrame({\"Actual Values\":y_test,\n                        \"Predicted Values\":y_pred})\nresults_normalized.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results_normalized.to_csv(\"k-NN_normalized.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plotting the confusion matrix to comapre with the previous model.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(y_pred,y_test)\n\ndef plot_confusion_matrix(cm,classes,title='Confusion Matrix',cmap=plt.cm.Blues):\n    \n    cm = cm.astype('float')/cm.sum(axis=1)[:,np.newaxis]\n    plt.figure(figsize=(10,10))\n    plt.imshow(cm,interpolation='nearest',cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n    \n    fmt = '.2f'\n    thresh = cm.max()/2.\n    for i,j in itertools.product(range(cm.shape[0]),range(cm.shape[1])):\n        plt.text(j,i,format(cm[i,j],fmt),\n                horizontalalignment=\"center\",\n                color=\"white\" if cm[i,j] > thresh else \"black\")\n        pass\n    \n    plt.ylabel('True Label')\n    plt.xlabel('Predicted Label')\n    pass\n\nclasses=['0','1']\n\nplt.figure()\nplot_confusion_matrix(cm,classes,title=\"Normalized KNN\");\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As it can be seen that this model is definitely better than the previous model.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}