{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# to prevent unnecessary warnings\nimport warnings\nwarnings.simplefilter(action='ignore')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# importing useful libraries\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport xgboost as xgb\n\n#import helper modules\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Exploratory Data Analysis (EDA)**","metadata":{}},{"cell_type":"code","source":"#reading the data set with pandas\nstroke_df = pd.read_csv('../input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv')\n\nstroke_df.head() #get the first 5 rows of the dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stroke_df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stroke_df.describe() #numerically describing the characteristics of the dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stroke_df.isnull().sum() #checking the null values of each column of the dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#we have only one column with missing value which is bmi, we can fill the missing values with mode\n\nstroke_df['bmi']= stroke_df['bmi'].fillna(stroke_df['bmi'].mode().iloc[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stroke_df.isnull().sum().sum() #checking the total number of null values in the dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking the value counts for the label column\n\nprint(stroke_df['stroke'].value_counts())\n\n#plotting the values\nsns.countplot(stroke_df['stroke'])\n\n# we can see there is a huge gap in the data for those patient with stroke and those without stroke \n# which can cause our model to be biased in prediction or behave poorly if used directly without any change","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#converting the categorical columns to that with numeric value\n\nstroke_df['gender'] = stroke_df['gender'].astype('category').cat.codes\nstroke_df['ever_married'] = stroke_df['ever_married'].astype('category').cat.codes\nstroke_df['work_type'] = stroke_df['work_type'].astype('category').cat.codes\nstroke_df['Residence_type'] = stroke_df['Residence_type'].astype('category').cat.codes\nstroke_df['smoking_status'] = stroke_df['smoking_status'].astype('category').cat.codes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stroke_df.info() #information on the characteristics of the datasset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (25,10)) #set figure size for the plot generated\n\nsns.heatmap(stroke_df.corr(), annot= True)#visualization of the numerical correlation of each feature of the dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.pairplot(stroke_df, kind = 'scatter', diag_kind= 'kde',hue = 'stroke')\n#for distribution and relationship of each feature","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#from the correlation plot, the age and ever married column seems highly correlated\n#well drop the ever married column and also id column\n\ns_df = stroke_df.drop(columns= ['ever_married'], axis = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Preprocessing","metadata":{}},{"cell_type":"code","source":"#splitting the data into train and test set\n\nX = s_df.drop('stroke', axis= 1) # all columns except the target column\ny = s_df['stroke'] #the target column\n\n\n#splitting the data set into train and test sample\n# using 30% of the dataset as the test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state= 42)\n\nprint(X_train.shape)\nprint(X_test.shape)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**SMOTE - Synthetic Minority Over-sampling Technique**","metadata":{}},{"cell_type":"code","source":"# dealing with the imabalnce dataset with imblearn library (SMOTE)\n\nfrom imblearn.over_sampling import SMOTE\n#SMOTE is an oversampling technique that generates synthetic samples\n#from the dataset which increases the predictive power for minority classes.\n\nsmote = SMOTE() \n\n# call the smote module only on the training sample\nX_smote, y_smote = smote.fit_resample(X_train, y_train)\n\nprint(X_smote.shape)\n\nsns.countplot(y_smote) #plotting to see the data distribution of the target after using SMOTE\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testing = X_test['id'] #taking ID column for the purpose of submission","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# drop the id column from both the train and test set\nX_smote = X_smote.drop(columns =['id'])# could have been .drop('id', axis = 1) if columns= wasn't set\nX_test = X_test.drop(columns =['id'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#scaling the data with min max\n\n# import module\nfrom sklearn.preprocessing import MinMaxScaler\n  \n# scale features\nscaler = MinMaxScaler() # minimum-maximum scaler module\nX_smote = scaler.fit_transform(X_smote) #call both fit and transform on the resampled training data\n\nX_test = scaler.transform(X_test) #call just transfrom on the test data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Building Models**","metadata":{}},{"cell_type":"markdown","source":"**Logistic Regression model**","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression #import the Logistic Regression from library\n\nlog = LogisticRegression()\nlog.fit(X_smote,y_smote) #fit the model on the train data\n\n\n#use the model to evaluate the performance on the test set\npred = log.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import the metrics used for evaluation from sklearn library\nfrom sklearn.metrics import (f1_score, roc_auc_score,accuracy_score,\n                             precision_recall_curve, auc, roc_curve, recall_score)\n\nclf_log = classification_report(y_test, pred) #get classification report for performance of the logistic model\nprint(clf_log)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#confusion matrix for the prediction\ncm = confusion_matrix(y_test, pred)\ncm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Voting Classifier","metadata":{}},{"cell_type":"code","source":"#import from sklearn library\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import  VotingClassifier \n\n\nrdf = RandomForestClassifier(random_state = 42) #base random forest model\n\ndt = DecisionTreeClassifier(random_state = 42) #base decision tree model\n\nvoting = VotingClassifier(estimators = [('tree',dt), #build the voting model with decision tree and random forest \n                                        #as the two base sub model\n          ('rdf', rdf)],\n         voting = 'soft')\n          \n          \nvoting.fit(X_smote, y_smote) #fit the classifier on the resampled training data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dtc, rd = voting.estimators_ #get the estimators for the two sub model\n\n#check performance of the voting classifier and the ones for the individuals\n\n#print the score for the individual model\nprint(voting.score(X_test, y_test))\nprint(dtc.score(X_test, y_test))\nprint(rd.score(X_test, y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#get the performance of the voting model on the prediction \n#as compared to the y_test values as classification report\nclf_v = classification_report(y_test, voting.predict(X_test))\nprint(clf_v)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#confusion matrix for the prediction\ncv = confusion_matrix(y_test, voting.predict(X_test))\ncv","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#get the performance of the random forest model on the prediction \n#as compared to the y_test values as classification report\n\nclf_r = classification_report(y_test, rd.predict(X_test))\nprint(clf_r) #print the report","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#confusion matrix for the prediction\ncr = confusion_matrix(y_test, rd.predict(X_test))\ncr","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Xgboost model","metadata":{}},{"cell_type":"code","source":"xg = xgb.XGBClassifier() # generate the model\nxg.fit(X_smote, y_smote) #fit the model on the resampled training data\n\n\n#use the model to evaluate the performance on the test set\nxgpred = xg.predict(X_test)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf_x = classification_report(y_test, xgpred) #get the performance of the xgboost model on the \n#prediction as compared to the y_test values as classification report \nprint(clf_x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#confusion matrix for the predictions using the xgboost model\ncx = confusion_matrix(y_test, xgpred)\ncx","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgprd = xg.predict_proba(X_test)[:,1]\n\n#Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC) from prediction scores.\nfpr_log, tpr_log, _ = roc_curve(y_test, xgprd)\nroc_auc_log = auc(fpr_log, tpr_log)\n\n#plot the AUC_ROC area\nsns.set_style(\"white\")\nplt.figure(figsize=(10, 7)) #to set the size of the figure generated\nplt.plot(fpr_log, tpr_log, color='darkorange',\n         label='ROC curve (area = %0.2f)' % roc_auc_log)\nplt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n\nplt.xlim([0.0, 1.0])#value range and limit on x axis\nplt.ylim([0.0, 1.05]) #value range and limit on y axis\n\nplt.xlabel('False Positive Rate',fontsize=18,labelpad =10) #Label for x axis\nplt.ylabel('True Positive Rate',fontsize=18) #Label for y axis\n\nplt.title('Receiver Operating Characteristic',fontsize=22).set_position([.5, 1.02]) #Plot title\nplt.legend(loc=\"lower right\",fontsize=13)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({'Id': testing, 'Stroke': xgpred}) #form a dataframe with only the id and predictions column\nsubmission.to_csv('submission.csv', index=False) #make the dataframe into a csv file  \nsubmission = pd.read_csv('submission.csv')\nsubmission","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}