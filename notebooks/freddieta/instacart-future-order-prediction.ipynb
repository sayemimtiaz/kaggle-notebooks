{"cells":[{"metadata":{},"cell_type":"markdown","source":"# InstaCart Future Order Prediction"},{"metadata":{},"cell_type":"markdown","source":"## Problem Statement\n\nThe Instacart data set is anonymized and contains samples of over 3 million grocery orders from 200,000+ Instacart users. Orders include 32 million basket items and 50,000 unique products.\n\nInstacart indicates each order in the datasets as prior, train, or test. \n- Prior orders within the prior dataset can describe the past behavior of a user. \n- The train and test data set can be used to help predict the future behavior of users.\n\n\nThe goal is to predict which of these products will be in the customer's future order.\n\n"},{"metadata":{},"cell_type":"markdown","source":"### Dataset for Instacart Orders (open sourced)\n- Download: https://www.instacart.com/datasets/grocery-shopping-2017\n- Data dictionary: https://gist.github.com/jeremystan/c3b39d947d9b88b3ccff3147dbcf6c6b"},{"metadata":{},"cell_type":"markdown","source":"#### Dataset Dictionary for Instacart\n\norders (3.4m rows, 206k users):\n\n- order_id: order identifier\n- user_id: customer identifier\n- eval_set: which evaluation set this order belongs in (see SET described below)\n- order_number: the order sequence number for this user (1 = first, n = nth)\n- order_dow: the day of the week the order was placed on\n- order_hour_of_day: the hour of the day the order was placed on\n- days_since_prior: days since the last order, capped at 30 (with NAs for order_number = 1)\n\nproducts (50k rows):\n\n- product_id: product identifier\n- product_name: name of the product\n- aisle_id: foreign key\n- department_id: foreign key\n\naisles (134 rows):\n\n- aisle_id: aisle identifier\n- aisle: the name of the aisle\n\ndepartments (21 rows):\n\n- department_id: department identifier\n- department: the name of the department\n\norder_products__SET (30m+ rows):\n\n- order_id: foreign key\n- product_id: foreign key\n- add_to_cart_order: order in which each product was added to cart\n- reordered: 1 if this product has been ordered by this user in the past, 0 otherwise\n\nwhere SET is one of the four following evaluation sets (eval_set in orders):\n\n- \"prior\": orders prior to that users most recent order (~3.2m orders)\n- \"train\": training data supplied to participants (~131k orders)\n- \"test\": test data reserved for machine learning competitions (~75k orders)\n\n\n\n"},{"metadata":{},"cell_type":"markdown","source":"#### NOTES:\n- previously purchased products (prior orders)\n- user's next order (train and test orders)\n- The orders from the train dataset contains ordered products while orders from the test dataset does not.\n- The'order_id' of each customers' future order is contained within the dataset.\n"},{"metadata":{},"cell_type":"markdown","source":"### Importing Necessary Modules"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt \nimport re\nimport seaborn as sns\ncolor = sns.color_palette()\nfrom tqdm import tqdm # progress bar\n\n# Limit floats output to 3 decimal points\npd.set_option('display.float_format', lambda x: '%.3f' % x)\n\nplt.style.use('fivethirtyeight')\n%matplotlib inline \n\n# Increase default figure and font sizes for easier viewing.\nplt.rcParams['figure.figsize'] = (8, 6)\nplt.rcParams['font.size'] = 14\n\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Loading Files into DataFrames"},{"metadata":{"trusted":true},"cell_type":"code","source":"# List of files\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input/instacart-market-basket-analysis/\"]).decode(\"utf8\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"order_products_train = pd.read_csv(\"../input/instacart-market-basket-analysis/order_products__train.csv\")\norder_products_prior = pd.read_csv(\"../input/instacart-market-basket-analysis/order_products__prior.csv\")\norders = pd.read_csv(\"../input/instacart-market-basket-analysis/orders.csv\")\nproducts = pd.read_csv(\"../input/instacart-market-basket-analysis/products.csv\")\naisles = pd.read_csv(\"../input/instacart-market-basket-analysis/aisles.csv\")\ndepartments = pd.read_csv(\"../input/instacart-market-basket-analysis/departments.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"order_products_train.head() # order_id and product_id\n\n# Includes training orders\n# Indicates whether product is a reorder (one or zero) via reordered variable","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"order_products_prior.head() # order_id and product_id\n\n# Like above, indicates whether a product is a reorder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"orders.head() # order_id\n\n# Includes all orders (prior, train, test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"products.head() # product_id","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"aisles.head() # aisle_id","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"departments.head() # department_id","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check for missing data\norders.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(orders.shape, order_products_prior.shape, order_products_train.shape, aisles.shape, products.shape, departments.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Product Portfolio\n- Orders in Dataset (prior, train, test)\n- Number of orders from three datasets.\n- Bargraph for comparison."},{"metadata":{"trusted":true},"cell_type":"code","source":"orders.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"combine_dataset = orders.groupby('eval_set')['order_id'].aggregate({'Total_orders': 'count'}).reset_index()\n\ncombine_dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"combine_dataset  = combine_dataset.groupby(['eval_set']).sum()['Total_orders'].sort_values(ascending=False)\n\nsns.set_style('whitegrid')\nf, ax = plt.subplots(figsize=(10,10))\nsns.barplot(combine_dataset.index, combine_dataset.values, palette=\"RdBu\")\nplt.ylabel('Number of Orders', fontsize=14)\nplt.title('Types of Datasets', fontsize=16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert variables into categories:\n\naisles['aisle'] = aisles['aisle'].astype('category')\ndepartments['department'] = departments['department'].astype('category')\norders['eval_set'] = orders['eval_set'].astype('category')\nproducts['product_name'] = products['product_name'].astype('category')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create DataFrame with ORDERS and PRODUCTS purchased on PRIOR ORDERS\n# po = 'orders' + 'order_products_prior' (only prior orders)\n\n# For every 'user_id', there is 'order_id' and 'product_id'\n\npo = orders.merge(order_products_prior, on='order_id', how='inner') #merge fx to help return info with matching values in both df.\npo.head()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create Predictors"},{"metadata":{},"cell_type":"markdown","source":"### Customer Predictors\n- Number of Orders per Customer\n- Frequency of Reorders from Customers"},{"metadata":{},"cell_type":"markdown","source":"#### Number of Orders per Customer\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"po.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a customer/user dataframe\n# ID highest order # in each of these groups\n# Save column into a dataframe\n\nuser = po.groupby('user_id')['order_number'].max().to_frame('c_total_orders')\n\nuser.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Frequency of Reorders from Customers\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# prob reordered = \n## (total times of reorder) / (total # of ordered products)\n\n# (total times of reorder) : all the times customer has reordered\n# (total # of ordered products) : products that have been purchased; binary reorder value (0,1)\n\n# 'reordered' info from 'order_products_prior'('po')\n# Calculate mean of reordered\n\nc_reorder = po.groupby('user_id')['reordered'].mean().to_frame('c_reordered_ratio')\n\n# c_reorder = c_reorder.reset_index()\n\nc_reorder.head()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Average Day of the Week Customers Make a Purchase"},{"metadata":{"trusted":true},"cell_type":"code","source":"dow = po.groupby('user_id')['order_dow'].mean().to_frame('average_dow')\n\ndow.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Merge Customer Predictors\n- Features based on users."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Left join to keep users/customers created to be in the user DataFrame:\n\nuser = user.merge(c_reorder, on='user_id', how='left')\n\nuser.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"user = user.merge(dow, on='user_id', how='left')\n\nuser.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Product Predictors\n- Number of Purchases for Each Product\n- Probability for a Product to be Reordered"},{"metadata":{},"cell_type":"markdown","source":"#### Number of Purchases for Each Product"},{"metadata":{"trusted":true},"cell_type":"code","source":"po.head(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create product dataframe to store results\n# Total number of purchases (count)\n\nprod = po.groupby('product_id')['order_id'].count().to_frame('p_total_purchases')\n\nprod = prod.reset_index() # reset to bring 'product_id' from index to column\n\nprod.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Probability for a Product to be Reordered\n- Products with the highest probability of being reordered"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove products < 50 purchases\n# Create groups for each product and keep groups with more than 50 rows.\n\np_reorder = po.groupby('product_id').filter(lambda x: x.shape[0] > 50)\n\np_reorder.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p_reorder.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Group products\n\n# Calculate mean of reorders to get reorder ratio\n## (# times product reordered)/ (total # times has been ordered)\n## reordered = 1, not reordered = 0\n\np_reorder = p_reorder.groupby('product_id')['reordered'].mean().to_frame('p_reorder_ratio')\n\np_reorder = p_reorder.reset_index()\n\np_reorder.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Average order of product added to cart\n\naddtocart = po.groupby('product_id')['add_to_cart_order'].mean().to_frame('Ave_Added_To_Cart')\n\naddtocart = addtocart.reset_index()\n\naddtocart.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Merge Product Predictors"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Combine 'prod' and 'reorder' dataframes together:\n\nprod = prod.merge(p_reorder, on='product_id', how='left')\n\nprod.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Merge in 'addtocart' columns\n\nprod = prod.merge(addtocart, on='product_id', how='left')\n\nprod.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Replace NaN values in 'p_reorder_ratio' column:\n\nprod['p_reorder_ratio'] = prod['p_reorder_ratio'].fillna(value=0)\n\nprod.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### User-Product Predictors\n- Number of Times a Customer Bought a Product.\n- How Often Customer Bought a Product After its First Purchase\n- Times a Customer Bought a Product on its last Few Orders (3)"},{"metadata":{},"cell_type":"markdown","source":"#### Number of Times a Customer Bought a Product"},{"metadata":{"trusted":true},"cell_type":"code","source":"po.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create unique groups for each combo of user and product.\n# Get how many times each user bought a product using .count()\n# New dataframe 'userprod'\n\nuserprod = po.groupby(['user_id','product_id'])['order_id'].count().to_frame('userprod_total_bought')\n\nuserprod = userprod.reset_index() \n\nuserprod.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### How Often Customer Bought a Product After its First Purchase"},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nreorder_ratio = times_bought / order_range\n\nThis ratio will help us see how many times a user bought a product out of how many times they had \na chance to purchase it starting from the first purchase of the item.\n\n\"\"\"\n\n## times_bought : number of times user bought a product\n## order_range : total orders placed since user's order of product\n\n# order_range = \n## total_orders : total number of orders per user\n## first_order_num : order number where user bought product for first time\n\n\"\"\"\nfinal ratio is our 'userprod_reorder_ratio'\n\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# times_bought\n\n# Group 'user_id' and 'product_id'\n# Count events of 'order_id' per group\n\ntimes_bought = po.groupby(['user_id', 'product_id'])[['order_id']].count()\n\ntimes_bought.columns = ['times_bought']\n\ntimes_bought.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"po.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"total_orders\"\"\"\n# Calculate total orders of each user\n\ntotal_orders = po.groupby('user_id')['order_number'].max().to_frame('total_orders')\n\ntotal_orders.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"first_order_num\"\"\"\n# Calculate first order number for every user and product bought\n## Group 'user_id' and 'product_id' \n## Select 'order_number' column and get .min value\n\nfirst_order_num = po.groupby(['user_id', 'product_id'])['order_number'].min().to_frame('first_order_num')\nfirst_order_num = first_order_num.reset_index()\nfirst_order_num.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Merge 'total_orders' and 'first_order_num' dataframes\n\n# Join right for'first_order_num' because it refers to unique combinations of user/prod\n# 'total_orders' apply to all users\n\norder_range = pd.merge(total_orders, first_order_num, on='user_id', how='right')\norder_range.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"order_range\"\"\"\n# Within 'pre_order_range', subtract 'first_order_num' from 'total_orders'\n# Add 1 for the difference between the first order where the product has been purchased.\n\norder_range['order_range'] = order_range.total_orders - order_range.first_order_num + 1\n\norder_range.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# reorder_ratio = times_bought / order_range\n\n## Both variables from combination of users/products; any join will do.\n## Merge 'times_bought' and 'order_range'\n\nreorder_ratio = pd.merge(times_bought, order_range, on=['user_id','product_id'], how='left')\n\nreorder_ratio.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate reorder_ratio = (times_bought / order_range) --> 'userprod_reorder_ratio'\n# Add column for 'userprod_reorder_ratio'\n\nreorder_ratio['userprod_reorder_ratio'] = reorder_ratio.times_bought / reorder_ratio.order_range\n\nreorder_ratio.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Only need columns 'user_id', 'product_id', and 'userprod_reorder_ratio'\n# Remove other columns\n\nreorder_ratio = reorder_ratio.drop(['times_bought', 'total_orders', 'first_order_num', \n                                   'order_range'], axis=1)\n\nreorder_ratio.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"userprod.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Merge 'reorder_ratio' with 'userprod'\n# Left join to keep all user/products made in 'userprod'\n\nuserprod = userprod.merge(reorder_ratio, on=['user_id','product_id'], how= 'left')\n\nuserprod.head()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Times a Customer Bought a Product on Its last Few Orders"},{"metadata":{"trusted":true},"cell_type":"code","source":"po[po.user_id==1].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create variable that keeps 'order_number' in reverse order\n\n## This will indicate last order as a sequence (1st, 2nd, etc) from the end.\n## Need max order number for 'user_id' and subtract 'order_number' from it.\n\n\n\"\"\"\norder_number_rev = max order number - order_number + 1 \n\"\"\"\n# .transform(max) to request highest number of 'order_number' column for each group\n# Subtract 'order_number' from each row with '- po.order_number'\n# Add +1 because it's the last order to be marked first\n\npo['order_number_rev'] = po.groupby('user_id')['order_number'].transform(max) - po.order_number + 1 \n\n\n\npo.head(15)\n","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# Confirm it's been applied to users other than the first\n\npo[po.user_id==4].head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Keep last few orders of each user with 'order_number_rev':\n\npo3 = po[po.order_number_rev <= 3]\n\npo3.head(15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Group users and products to see how frequent a customer ordered on their last three orders 'last_three_orders_times':\n\n\"\"\" last_three = (times user bought product on its last 3 orders) / (total orders) \"\"\"\n\nlast_three = po3.groupby(['user_id','product_id'])[['order_id']].count()\n\nlast_three.columns = ['last_three_orders_times']\n\nlast_three.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note: Product 10258 has been ordered on all of its three orders where as product 13032 has only been ordered once."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Merge 'last_three' dataframe to the 'userprod' dataframe:\n# Left join to keep all user-products on 'userprod' dataframe\n\nuserprod = userprod.merge(last_three, on=['user_id','product_id'], how='left')\n\nuserprod.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fill in NaN values (see product_id 10326 with NaN)\n\nuserprod = userprod.fillna(0)\nuserprod.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Merge Features\n- Merge dataframes with the three types of predictors:\n    - users ('user')\n    - products ('prod')\n    - combination of users & products ('userprod')"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Merge 'user' with 'userprod' dataframe, store into new dataframe 'data'\n# Match 'user_id' key\n# Left join to keep all data from 'userprod'\n\ndata = userprod.merge(user, on='user_id', how='left')\n\ndata.head()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Merge 'prod' with 'data' dataframe\n# Match 'product_id' key\n# Left join to keep data from 'data' (features of users and combination of users/products)\n\ndata = data.merge(prod, on='product_id', how='left')\n\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Create Train / Test Dataframes"},{"metadata":{},"cell_type":"markdown","source":"#### Prepare TRAIN Dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"orders.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# From 'orders' dataframe, select 'eval_set', 'order_id', and 'user_id' (matching key) and \n# merge into 'data' dataframe:\n\n## 'eval_set' : train/test type\n## 'order_id' : future orders\n## 'user_id' : will be the matching key during merge\n\n\"\"\" 'data_train' will contain 'eval_set', 'order_id', and 'user_id' \"\"\"\n\nfuture_orders = orders[((orders.eval_set=='train') | (orders.eval_set=='test'))]\n\nfuture_orders = future_orders[ ['user_id', 'eval_set', 'order_id'] ]\n\nfuture_orders.head(10)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Transfer info of 'future_orders' to 'data' dataframe:\n\ndata = data.merge(future_orders, on='user_id', how='left')\n\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Prepare TRAIN Dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"order_products_train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Keep users labeled 'train'\n\ndata_train = data[data.eval_set=='train']\n\n# Create variable that will show all products that the users buy in their future order\n## Source: 'order_products_train'\n## Matching keys of 'product_id' and 'order_id'\n## Left join to 'data_train' to keep all observations\n\ndata_train = data_train.merge(order_products_train[['product_id','order_id', 'reordered']], on=['product_id','order_id'], how='left' )\n\ndata_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove NaN in column 'reordered' and set to zero\n## reordered status (1 or zero)\n\ndata_train['reordered'] = data_train['reordered'].fillna(0)\n\n# data_train.head()\ndata_train.reordered.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 'user_id' and 'product_id' as index\n\n# data_train = data_train.set_index(['user_id','product_id'])\n\n# Remove non-predictor columns\n\ndata_train = data_train.drop(['eval_set', 'order_id'], axis=1)\n\ndata_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Prepare TEST Dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Will be used for prediction model\n# Keep users who have eval_set as 'test'\n\ndata_test = data[data.eval_set=='test']\n\ndata_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set 'user_id' and 'pruduct_id' as index to describe each row\n\ndata_test = data_test.set_index(['user_id', 'product_id'])\n\n# Remove non-predictor variables; 'eval_set', 'order_id'\n\ndata_test = data_test.drop(['eval_set','order_id'], axis=1)\n\ndata_test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Predictive Model"},{"metadata":{},"cell_type":"markdown","source":"Installation\n- https://xgboost.readthedocs.io/en/latest/build.html#python-package-installation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check where XGBoost was installed (pip3 install xgboost)\n# Append that directory to sys.path\n# Finally import xgboost\n\nimport sys\nsys.path.append(\"/usr/local/lib/python3.7/site-packages\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import the xgboost package\nimport xgboost as xgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.head(0), data_test.head(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split dataframe to: 'X_train' and 'y_train' ; axis= 1\n\nX_train, y_train = data_train.drop('reordered', axis = 1), data_train.reordered","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# XGBoost parameters: 'eval_metric', 'max_depth', 'colsample_bytreeÎ¹', 'subsample'\n\nparameters = {'eval_metric':'logloss', \n              'max_depth':'5', \n              'colsample_bytree':'0.4', # 0.3 - 0.8 if many columns\n              'subsample':'0.8',\n              'n_estimators':100, # 100 if large data, 1000 if med-low\n              'verbose': 1 # prints progress - takes awhile to fit 'model'\n             }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Instantiate XGBClassifier() 'xgbc'\n\nxgbc = xgb.XGBClassifier(objective='binary:logistic', parameters=parameters, num_boost_round=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train the model using xgbc.fit on train data\n\nmodel = xgbc.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot model to observe feature importance:\nxgb.plot_importance(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\n# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n# ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# TRIM 'data_train' to 10%\n\n# data_train.reset_index(inplace=True)\n\ntrimmed_data_train = data_train.loc[data_train.user_id.isin(data_train.user_id.drop_duplicates().sample(frac=0.1, random_state=25))].set_index(['user_id', 'product_id'])\n\nX_train, y_train = trimmed_data_train.drop('reordered', axis=1), trimmed_data_train.reordered","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Adjust Booster's parameters (range)\n\ngridparam = {\"max_depth\":[5,10], \n             \"colsample_bytree\":[0.3, 0.4]}  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Instantiate XGBClassifier()\n\n# xgbc = xgb.XGBClassifier(objective='binary:logistic', eval_metric='logloss', num_boost_round=10)\n\n# n_jobs=-1\n\nxgbc = xgb.XGBClassifier(objective='binary:logistic', eval_metric='logloss', num_boost_round=10)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define how to train different models:\n## xgbc\n## gridparam\n# .GridSearchCV() : to tune parameters to find best accuracy.\n\n# gridsearch = GridSearchCV(xgbc, gridparam, cv=3, verbose=2, n_jobs=-1)\ngridsearch = GridSearchCV(xgbc, gridparam, cv=3, verbose=2)\n\n# n_jobs -1 number of jobs to run in parallel. -1 runs all.\n# Memory leak: https://stackoverflow.com/questions/55848101/memory-leak-using-gridsearchcv\n## Putting 'n_jobs=-1' in classifier() instead of gridsearch","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\n# Train models with combination of parameters.\n# GridSearch function : to tune parameters to find best accuracy.\n\nmodel_best = gridsearch.fit(X_train, y_train)\n\n# print(\"Top parameters are: /n\", gridsearch.best_parameters_)\n\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"import scipy\nscipy.test()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_best = gridsearch.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"# With test data predict values with 'model'\n\nprediction_test = model.predict(data_test) #.astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction_test[0:20] # Display the first 10 predictions of numpy array","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save prediction\n\ndata_","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":4}