{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\npath = \"/kaggle/input/iris-flower-dataset/IRIS.csv\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A sample of active learning on svm classifiers. \n\nFirst we'll train an svm classifier using supervisied learing, thus utilizing all of the labels.","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"df = pd.read_csv(path).reset_index(drop=True)\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating a subset of feature-set\nf1, f2, target = 'petal_length','petal_width', 'species'\nX = df[[f1,f2]].reset_index(drop=True)\nY = df[target].reset_index(drop=True)\nprint(\"Unique classes: \",Y.unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# one-hot encode the target\n# from sklearn.preprocessing import OneHotEncoder\n# ohe = OneHotEncoder()\n# ohe.fit(Y.reshape(-1, 1))\nY[Y=='Iris-setosa'] = 0\nY[Y=='Iris-versicolor'] = 1\nY[Y=='Iris-virginica'] = 2\nY=Y.astype(dtype=np.uint8)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's visualize the distribution. \n","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.figure()\nplt.scatter(X[f1][Y==1], X[f2][Y==1], c='r')\nplt.scatter(X[f1][Y==2], X[f2][Y==2], c='g')\nplt.scatter(X[f1][Y==0], X[f2][Y==0], c='b')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import svm\nclf_ovo = svm.SVC(decision_function_shape='ovo')\nclf_Linear = svm.LinearSVC(C=1.0, max_iter=10000)\n\nmodels = [clf_ovo, clf_Linear]\nmodels = [clf.fit(X, Y) for clf in models]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_meshgrid(x, y, h=.02):\n    \"\"\"Create a mesh of points to plot in\n\n    Parameters\n    ----------\n    x: data to base x-axis meshgrid on\n    y: data to base y-axis meshgrid on\n    h: stepsize for meshgrid, optional\n\n    Returns\n    -------\n    xx, yy : ndarray\n    \"\"\"\n    x_min, x_max = x.min() - 1, x.max() + 1\n    y_min, y_max = y.min() - 1, y.max() + 1\n    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n                         np.arange(y_min, y_max, h))\n    return xx, yy\n\n\ndef plot_contours(ax, clf, xx, yy, **params):\n    \"\"\"Plot the decision boundaries for a classifier.\n\n    Parameters\n    ----------\n    ax: matplotlib axes object\n    clf: a classifier\n    xx: meshgrid ndarray\n    yy: meshgrid ndarray\n    params: dictionary of params to pass to contourf, optional\n    \"\"\"\n    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n    Z = Z.reshape(xx.shape)\n    out = ax.contourf(xx, yy, Z, **params)\n    return out\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's train a couple of different svm classifiers on this data.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"\n    X0, X1 = X[f1], X[f2]\n    xx, yy = make_meshgrid(X0, X1)\n\n    fig, sub = plt.subplots(1, 2,figsize=(20,10))\n\n\n    titles = (\"decision_function_shape='ovo'\" , 'LinearSVC (linear kernel)')\n    # models=[clf]/\n    for clf, title, ax in zip(models, titles, sub.flatten()):\n        plot_contours(ax, clf, xx, yy, cmap=plt.cm.coolwarm, alpha=0.8)\n        ax.scatter(X0, X1, c=Y, cmap=plt.cm.coolwarm, s=20, edgecolors='k')\n        ax.set_xlim(xx.min(), xx.max())\n        ax.set_ylim(yy.min(), yy.max())\n        ax.set_xlabel('Sepal length')\n        ax.set_ylabel('Sepal width')\n        ax.set_xticks(())\n        ax.set_yticks(())\n        ax.set_title(title)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we will train using active learning in which the model querries about the ambigious data points.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_pool, X_test, y_pool, y_test = train_test_split(X, Y, test_size=0.6, random_state=6)\nX_pool, X_test, y_pool, y_test = X_pool.reset_index(drop=True), X_test.reset_index(drop=True), y_pool.reset_index(drop=True), y_test.reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getdatapoint4activelearning(clf,pts):\n    idxs = []\n    for clf in clfs:\n        decisions = (np.abs(list(clf.decision_function((X_pool.reset_index(drop=True))[min(pts):max(pts)]))))\n        idx = np.argmin(np.array(decisions),axis=0)\n        idxs.append(idx)\n    return idxs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"clf_ovo = svm.SVC(decision_function_shape='ovo')\nclf_Linear = svm.LinearSVC(C=1.0, max_iter=10000)\n\nclass models():\n    def __init__(self):\n        self.models = [clf_ovo, clf_Linear] \n\n    def fit(self,x,y,idxs):\n        self.models = [clf_ovo, clf_Linear] \n        models = [clf.fit(x.iloc[idxs],y.iloc[idxs]) for clf in self.models]\n        return models\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"\ndef plot_svm_amb(idx, models=None,ambigious=None):\n    X0, X1 = X_pool[f1].iloc[idx], X_pool[f2].iloc[idx]\n    xx, yy = make_meshgrid(X0, X1)\n\n    fig, sub = plt.subplots(1, 2,figsize=(10,5))\n\n    titles = (\"decision_function_shape='ovo'\" , 'LinearSVC (linear kernel)')\n\n\n    \n    for clf, title, ax in zip(models, titles, sub.flatten()):\n        plot_contours(ax, clf, xx, yy, cmap=plt.cm.coolwarm, alpha=0.8)\n        ax.scatter(X0, X1, c=y_pool.iloc[idx], s=20, edgecolors='k')\n        ax.set_xlim(xx.min(), xx.max())\n        ax.set_ylim(yy.min(), yy.max())\n        ax.set_xlabel('Sepal length')\n        ax.set_ylabel('Petal width')\n        ax.set_xticks(())\n        ax.set_yticks(())\n        ax.set_title(title)\n        \n    \n    new_points = []\n    clf1_pt = []\n    clf2_pt = []\n    \n    if ambigious is not None:\n            points = [np.squeeze(a).tolist() for a in ambigious]\n            for clf_id,trio in enumerate(points):\n                for pt in trio:\n                    if pt not in idx:\n                        new_points.append(pt)\n                        if clf_id == 0 :\n                            clf1_pt.append(pt)\n                        else:\n                            clf2_pt.append(pt)\n\n    new_sample_data = list(random.sample(range(20, len(X_pool)), 10))\n    idx.extend(new_sample_data)\n\n\n        \n\n        \n    clf_pts=[clf1_pt,clf2_pt]\n    for id_,ax in enumerate(sub.flatten()):\n        for pt in clf_pts[id_]:\n            ax.scatter(X_pool[f1][pt], X_pool[f2][pt], c='pink', marker=\"*\", s=125)\n\n    idx.extend(new_points)\n    plt.plot()\n    return list(set(idx))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\nbegining_thesh = 5#initial observation\nidxs = list(random.sample(range(0, len(X_pool)), begining_thesh))\nambigious_pts = None\nclfs_combo = models()\nfor i in range(10):\n    clfs = clfs_combo.fit(X_pool,y_pool,idxs)\n    unknown_idxs = [i for i in range(len(X_pool)) if i not in idxs]\n    idxs = plot_svm_amb(idxs, models=clfs,ambigious=ambigious_pts)\n    ambigious_pts = getdatapoint4activelearning(clfs,unknown_idxs)\n    ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}