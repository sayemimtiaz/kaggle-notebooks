{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Hotel Booking Model"},{"metadata":{},"cell_type":"markdown","source":"---\n#### *Introduction*:\nThe dataset can be found at https://www.kaggle.com/jessemostipak/hotel-booking-demand\n\nThis data set contains booking information for a city hotel and a resort hotel, and includes information such as when the booking was made, length of stay, the number of adults, children, and/or babies, and the number of available parking spaces, among other things.\n\nPer the description for the dataset listed above, an exploratory data analysis will be performed, then a model will be built to predict whether a reservation will be canceled.  This could be a useful tool for hotels and resorts when predicting or forecasting profits.\n"},{"metadata":{},"cell_type":"markdown","source":"---\n### EDA:\nFirst we will begin by importing all the necessary libraries needed for the analysis.  Some libraries may be imported later to support packages that were initially thought to be needed."},{"metadata":{"trusted":false},"cell_type":"code","source":"# load libraries\nimport pandas as pd\nimport numpy as np\nimport csv\nimport time\nfrom datetime import datetime, time\nfrom plotnine import *\nfrom mizani.breaks import date_breaks\nfrom dfply import *\nimport seaborn as sns\nimport pprint as p","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# load data set using pandas csv reader\nhotel_data = pd.read_csv('hotel_bookings.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### View Basic Attributes of Data:"},{"metadata":{"trusted":false},"cell_type":"code","source":"# View first 5 rows of data\nhotel_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# how many rows of data and how many variables?\nvariables = hotel_data.shape[1]\nrows = hotel_data.shape[0]\n\nprint(\"There are {:d} varaibles with {:d} rows in this dataset\\n\".format(variables, rows))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This data set has 32 variables with 119390 rows.  It looks like there are a lot of categorical variables in this dataset mixed with dates as well.  An interesting metric they keep track of is number of special requests.  Who knew hotels/resorts kept track of such things."},{"metadata":{},"cell_type":"markdown","source":"---\nWhat is the data range for reservations?"},{"metadata":{"trusted":false},"cell_type":"code","source":"# convert reservation_status_date into datetime type\ndate_temp = pd.to_datetime(hotel_data.reservation_status_date, format = '%Y-%m-%d')\n\n#display(date_temp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# overwrite date time column to proper data type\nhotel_data['reservation_status_date'] = date_temp\n\n#display(hotel_data.reservation_status_date.dt.strftime(\"%B\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# determine date range\nmin_res_date = hotel_data.reservation_status_date.min()\nmax_res_date = hotel_data.reservation_status_date.max()\nprint(\"min date: {}\\nmax date: {}\".format(min_res_date, max_res_date))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It appears that this data spans from 2014 to 2017."},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"### Visualizations:\n\nLets explore the data with a couple of visualizations that may answer some interesting questions.  How does number of reservations trend on a monthly basis? "},{"metadata":{"trusted":false},"cell_type":"code","source":"# visualize results:\n\n# create month list\nmonth_list = ('January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December')\n\n# extract time data out of column and convert to proper format\nhotel_data['res_status_month'] = hotel_data.reservation_status_date.dt.strftime(\"%B\")\nhotel_data['res_status_year'] = hotel_data.reservation_status_date.dt.year\nhotel_data['res_status_year'] = hotel_data['res_status_year'].astype(\"str\")\n\n# create the visualization\nhotel_hist = (ggplot(hotel_data, aes(x='res_status_month', fill='res_status_year'))+\n              geom_bar(stat=\"count\", alpha=0.8)+\n              scale_x_discrete(limits = month_list)+\n              labs(x='Reservation Month', y='Number of Reservations', fill='Year of Res.', title='Reservations by Month')+\n              theme_minimal()+\n              theme(axis_text_x=element_text(rotation=45, hjust=1))\n             )\n\nhotel_hist","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The plot above shows the number of hotel and resort reservations with color encoded to year of reservation.  By encoding color to year of reservations, we can see that there are almost no reservations made in 2014 and no reservations made from October on in 2017.  There are also not many reservations made in the early months of 2015.  It’s very important to note that the reason for these differences unknown and we can only speculate.  Perhaps the hotels started collecting data in 2014 but didn’t start regularly collecting data till July 2015.  In the next plot, we will normalize the column height to enable more accurate comparisons across months."},{"metadata":{"trusted":false},"cell_type":"code","source":"# normalize height of bars\nhotel_hist_normalized = (ggplot(hotel_data, aes(x='res_status_month', fill='res_status_year'))+\n              geom_bar(stat=\"count\", alpha=0.8, position='fill')+\n              scale_x_discrete(limits = month_list)+\n              labs(x='Reservation Month', y='Percent of Reservations', fill='Year of Res.', title='Reservations by Month')+\n              theme_minimal()+\n              theme(axis_text_x=element_text(rotation=45, hjust=1))\n             )\n\nhotel_hist_normalized","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"By normalizing column height, it is easy to compare the number of reservations across months."},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Plot city vs hotel reservation count\nhotel_data['is_canceled'] = hotel_data['is_canceled'].astype('str')\n\nc_vs_h = (ggplot(hotel_data, aes(x='hotel', fill='is_canceled'))+\n          geom_bar(alpha=0.8)+\n          geom_text(aes(label='stat(count)'),\n                        position =position_stack(vjust=0.5),\n                        stat='count',\n                        size=12, \n                        va='top',\n                        format_string='{}')+\n          labs(x='Hotel Type', y='Number of Reservations', fill='Canceled(0=No)', title='Reservations by Hotel Type')+\n          theme_minimal()\n         )\nc_vs_h","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The figure above shows the distribution of reservations by hotel type.  We can see that the City Hotel has about twice as many reservations as the Resort Hotel.  It also looks like the City Hotel has a higher percentage of cancelations."},{"metadata":{"trusted":false},"cell_type":"code","source":"# Calculate percent of cancelations for the total, then resort and city hotels\ntotal_cancel = hotel_data['is_canceled'].sum()\nresort_cancel = hotel_data.loc[hotel_data['hotel'] == \"Resort Hotel\"]['is_canceled'].sum()\ncity_cancel = hotel_data.loc[hotel_data['hotel'] == \"City Hotel\"]['is_canceled'].sum()\n\ntotal_canc_percent = (total_cancel/hotel_data.shape[0])*100\nresort_canc_percent = (resort_cancel/hotel_data.loc[hotel_data['hotel'] == \"Resort Hotel\"].shape[0])*100\ncity_canc_percent = (city_cancel/hotel_data.loc[hotel_data['hotel'] == \"City Hotel\"].shape[0])*100\n\nprint(f\"Total bookings canceled: {total_cancel:,} ({total_canc_percent:.0f} %)\")\nprint(f\"Resort hotel bookings canceled: {resort_cancel:,} ({resort_canc_percent:.0f} %)\")\nprint(f\"City hotel bookings canceled: {city_cancel:,} ({city_canc_percent:.0f} %)\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\nLets investigate how cancelations are different between the two types of hotels in the data set, City and Resort."},{"metadata":{"trusted":false},"cell_type":"code","source":"# plot of reservation month colored by cancelation\ndodge_text = position_dodge(width=0.9)\nplot3 = (ggplot(hotel_data, aes(x='res_status_month', fill='is_canceled'))+\n              geom_bar(stat=\"count\", alpha=0.8, position='dodge')+\n              scale_x_discrete(limits = month_list)+\n              facet_wrap(\"hotel\")+\n              geom_text(aes(label='stat(count)/100'),\n                        ha='right',\n                        position=dodge_text, stat='count',\n                        size=8, \n                        format_string='{}%')+\n             coord_flip()+\n             labs(x='Reservation Month', y='Count of Reservations', fill='Canceled(0=No)')+#, title='Reservations by Month')+\n             theme_minimal()\n        )\n\nplot3","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The cancelations at the Resort Hotel appear to be much more consistent across months when compared to the City Hotel.  The reservations that were not canceled seem to follow a parabolic trend peaking in August for both hotels.  "},{"metadata":{},"cell_type":"markdown","source":"---\n### Create Correlation Matrix\nBefore we begin modeling, lets examine a correlation matrix for our data set to see if any variables are highly correlated with cancelations. "},{"metadata":{"trusted":false},"cell_type":"code","source":"# create correlation matrix\ncorr = hotel_data.corr()\nsns.heatmap(corr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ADD DESRCRIPTION AFTER HYPERPARAMETER TUNING"},{"metadata":{},"cell_type":"markdown","source":"---\n### Build ML Model with XGBoost:\nI chose the XGBoost as my machine learning model mainly due to the fact that I am trying to increase my familiarity with the package and algorithm.  XGBoost is a decision-tree-based ensemble machine leaning algorithm that uses gradient boosting.  Check out this article for more: https://towardsdatascience.com/https-medium-com-vishalmorde-xgboost-algorithm-long-she-may-rein-edd9f99be63d"},{"metadata":{"trusted":false},"cell_type":"code","source":"# import more libs\nimport matplotlib.pyplot as plt\nfrom xgboost.sklearn import XGBClassifier\nfrom sklearn.model_selection import cross_validate\nfrom sklearn import metrics\nimport xgboost as xgb\nfrom xgboost import plot_importance\n%matplotlib inline\nfrom matplotlib.pylab import rcParams\nrcParams['figure.figsize'] = 12, 4\nfrom sklearn.metrics import f1_score, precision_score, recall_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We'll begin by defining a function to run XGBoost"},{"metadata":{"trusted":false},"cell_type":"code","source":"def modelfit(alg, x_train, y_train, useTrainCV=True, cv_folds=5, early_stopping_rounds=50, feat_plot=False):\n    '''\n    INPUTS:\n        alg     = Algorithm to pass to function (ex: XGBClassifier/XGBRegressor)\n        x train = test and training data to pass\n        y train = test and training for predictors\n    '''\n    \n    if useTrainCV:\n        xgb_param = alg.get_xgb_params()\n        xgtrain = xgb.DMatrix(x_train.values, label=y_train) #convert training data into DMatrix\n        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n            metrics='auc', # metric needs to change based on Algorithm passed in\n            early_stopping_rounds=early_stopping_rounds)\n        alg.set_params(n_estimators=cvresult.shape[0])\n    print(\"Optimal estimators for learning rate: \",cvresult.shape[0])\n    \n    #Fit the algorithm on the data\n    alg.fit(x_train, y_train)# ,eval_metric='auc')\n        \n    #Predict training set:\n    dtrain_predictions = alg.predict(x_train)\n    dtrain_predprob = alg.predict_proba(x_train)[:,1]\n        \n    #Print model report:\n    print (\"\\nModel Report\")\n    print (\"Accuracy : %.4g\" % metrics.accuracy_score(y_train.values, dtrain_predictions))\n    print (\"AUC Score (Train): %f\" % metrics.roc_auc_score(y_train.values.flatten(), dtrain_predprob))\n                    \n    # plot feature importance\n    if feat_plot:\n        plot_importance(alg, grid=False)\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Select Features for Model:"},{"metadata":{"trusted":false},"cell_type":"code","source":"# create new df with just original data\nhotel_data_original = hotel_data >> select(~X.res_status_month, ~X.res_status_year)\nhotel_data_original.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# #display(hotel_data_original)\n# hotel_data['is_canceled'] = hotel_data['is_canceled'].astype('str')\n\n# #create correlation list\n# cancel_corr = hotel_data_original.corr()['is_canceled']\n\n# display(cancel_corr)\n# cancel_corr.abs().sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Drop variables that will poorly influence the model or don't make sense to include (like reservation status).  Separate numeric and categorical variables.  One-hot encode categorical variables."},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\n\n# create numeric features\nnum_feat = [\"lead_time\", \"total_of_special_requests\", \"required_car_parking_spaces\", \"previous_cancellations\", \"is_repeated_guest\",\n            \"agent\", \"adults\", \"previous_bookings_not_canceled\", \"days_in_waiting_list\", \"adr\"]\n\n# create categorical features\ncat_feat = [\"hotel\",\"arrival_date_month\",\"meal\",\"market_segment\",\"distribution_channel\",\"reserved_room_type\",\"deposit_type\",\n            \"customer_type\"]\nhotel_cat = hotel_data_original[cat_feat]\n#display(hotel_cat)\n# # create instance of one-hot encoder\n# enc = OneHotEncoder(handle_unknown='ignore')\n\n# # pass values in\n# enc_df = pd.DataFrame(enc.fit_transform(hotel_cat).toarray())\n# display(enc_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Run model again but use pd.get_dummies instead of OneHotEncoder\nhotel_cat2 = pd.get_dummies(hotel_data[cat_feat], dtype='int64')\n\n# merge data frames\nhotel_df2 = pd.concat([hotel_data_original[num_feat], hotel_cat2], axis=1)\ndisplay(hotel_data_original[num_feat])\n#p.pprint(hotel_df2.columns.to_series().groupby(hotel_df2.dtypes).groups)\n\npredictors = hotel_data_original['is_canceled']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# split into test train set, this was a 60-40 split\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(hotel_df2, predictors, test_size = 0.4,\n                                                    random_state=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check distribution of test data to ensure its been evenly split:"},{"metadata":{"trusted":false},"cell_type":"code","source":"#list(x_train.columns.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# plot training data\nplot_train = (ggplot(x_train, aes(x='hotel_Resort Hotel'))+\n              geom_bar(stat='count', position='stack')+\n              labs(x='Hotel Type')\n)\nplot_train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":false},"cell_type":"code","source":"# build model, note that I left all the default input parameters and will edit them during hyperparameter tuning\nxgb2 = XGBClassifier(seed=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"import time","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# run model\nstart = time.time() # start timer\n\nmodelfit(xgb2, x_train, y_train) \n\nprint(\"Building time : \" + str(time.time()-start))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plot_importance(xgb2, grid=False, max_num_features=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This model produced an accuracy of 85.5%.  This is not bad given that we have default parameters and it only took just under 2 minutes to train.  We can see that the top 3 most important features in the model were *adr*, *lead_time*, and *agent*.  This makes sense as people who put down a lot of money on their reservation are less likely to cancel."},{"metadata":{"trusted":false},"cell_type":"code","source":"# Predict on test set:\npredictions = xgb2.predict(x_test)\npredprob = xgb2.predict_proba(x_test)[:,1]\n\n# Print model report:\nprint (\"\\nModel Report\")\nprint (\"Accuracy: %.4g\" % metrics.accuracy_score(y_test.values, predictions))\nprint (\"AUC Score (Test): %f\" % metrics.roc_auc_score(y_test.values.flatten(), predprob))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looks like accuracy decreased slightly when run on the test set."},{"metadata":{"trusted":false},"cell_type":"code","source":"# calculate other classification metrics\n\nf1 = f1_score(y_test.values, predictions)\nprecision =  precision_score(y_test.values, predictions)\nrecall = recall_score(y_test.values, predictions)\n\nprint(\"f1 Score: {:f}\\nPrecision: {:f}\\nRecall: {:f}\".format(f1, precision, recall))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To get a better understanding of the performance of our model, the precision, recall, and f1 score will be calculated.  The precision of a model is the ratio of true positives/(true positives + false positives).  The recall of a model is the true positives/(true positives + false negatives).  Precision and recall can be easily understood through a fishing example.  Recall is the size of the fishing net cast and precision is how many of whatever you catch are fish.  The best of both worlds is a net that is just the right size that catches only fish.  The F1 score is the harmonic mean of precision and recall. \n\nHere the model has a good combination of precision and recall.  Time to see if it can be improved through hyperparameter tuning.\n"},{"metadata":{},"cell_type":"markdown","source":"### Build Model for Just Hotel and Just Resort:"},{"metadata":{"trusted":false},"cell_type":"code","source":"hotel_resort = hotel_data_original >> mask(X.hotel=='Resort Hotel')\npredictors_R = hotel_resort['is_canceled']\nhotel_cat_resort = hotel_resort[cat_feat]\n# Run model again but use pd.get_dummies instead of OneHotEncoder\nhotel_cat_resort2 = pd.get_dummies(hotel_resort[cat_feat], dtype='int64')\n# merge data frames\nhotel_resort2 = pd.concat([hotel_resort[num_feat], hotel_cat_resort2], axis=1)\n#display(hotel_resort2)\n\n\nhotel_city = hotel_data_original >> mask(X.hotel=='City Hotel')\npredictors_C = hotel_city['is_canceled']\nhotel_cat_city = hotel_city[cat_feat]\n# Run model again but use pd.get_dummies instead of OneHotEncoder\nhotel_cat_city2 = pd.get_dummies(hotel_city[cat_feat], dtype='int64')\n# merge data frames\nhotel_city2 = pd.concat([hotel_city[num_feat], hotel_cat_city2], axis=1)\n#display(hotel_city2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Resort Hotel Model"},{"metadata":{"trusted":false},"cell_type":"code","source":"import time","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# split into test train set, this was a 60-40 split\n\nx_trainR, x_testR, y_trainR, y_testR = train_test_split(hotel_resort2, predictors_R, test_size = 0.4,\n                                                    random_state=1)\n# build model, note that I left all the default input parameters and will edit them during hyperparameter tuning\nxgb_R = XGBClassifier(seed=2)\n\n# run model\nstart = time.time() # start timer\n\nmodelfit(xgb_R, x_trainR, y_trainR) \n\nprint(\"Building time : \" + str(time.time()-start))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plot_importance(xgb_R, grid=False, max_num_features=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Run Test\n# Predict on test set:\npredictions_R = xgb_R.predict(x_testR)\npredprob = xgb_R.predict_proba(x_testR)[:,1]\n\n# Print model report:\nprint (\"\\nModel Report\")\nprint (\"Accuracy: %.4g\" % metrics.accuracy_score(y_testR.values, predictions_R))\nprint (\"AUC Score (Test): %f\" % metrics.roc_auc_score(y_testR.values.flatten(), predprob))\n\nf1 = f1_score(y_testR.values, predictions_R)\nprecision =  precision_score(y_testR.values, predictions_R)\nrecall = recall_score(y_testR.values, predictions_R)\n\nprint(\"f1 Score: {:f}\\nPrecision: {:f}\\nRecall: {:f}\".format(f1, precision, recall))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### City Hotel Model"},{"metadata":{"trusted":false},"cell_type":"code","source":"# split into test train set, this was a 60-40 split\n\nx_trainC, x_testC, y_trainC, y_testC = train_test_split(hotel_city2, predictors_C, test_size = 0.4,\n                                                    random_state=1)\n# build model, note that I left all the default input parameters and will edit them during hyperparameter tuning\nxgb_C = XGBClassifier(seed=2)\n\n# run model\nstart = time.time() # start timer\n\nmodelfit(xgb_C, x_trainC, y_trainC) \n\nprint(\"Building time : \" + str(time.time()-start))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plot_importance(xgb_C, grid=False, max_num_features=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# test model\n# Predict on test set:\npredictions_C = xgb_C.predict(x_testC)\npredprob = xgb_C.predict_proba(x_testC)[:,1]\n\n# Print model report:\nprint (\"\\nModel Report\")\nprint (\"Accuracy: %.4g\" % metrics.accuracy_score(y_testC.values, predictions_C))\nprint (\"AUC Score (Test): %f\" % metrics.roc_auc_score(y_testC.values.flatten(), predprob))\n\nf1 = f1_score(y_testC.values, predictions_C)\nprecision =  precision_score(y_testC.values, predictions_C)\nrecall = recall_score(y_testC.values, predictions_C)\n\nprint(\"f1 Score: {:f}\\nPrecision: {:f}\\nRecall: {:f}\".format(f1, precision, recall))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Hyper-parameter Tuning"},{"metadata":{"trusted":false},"cell_type":"code","source":"'''\nnote the following format for inputs to xgb:\nxgb1 = XGBClassifier(learning_rate = 0.1,\n                     n_estimators = 1000,\n                     max_depth = 5,          # max depth of tree\n                     min_child_weight = 1,   # min sum of weights of all observ. required in a child\n                     gamma = 0,              # min loss required to make split\n                     subsample = 0.8,        # fraction of observ. to be randomly selected for each tree\n                     colsample_bytree = 0.8, # denotes frac. of col. to be randomly smapled for each tree\n                     scale_pos_weight = 1    # parameter for high class imbalanc,[default=1]\n)\n'''\nfrom sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Train new model with new hyper-parameters\nxgb3 = XGBClassifier(learning_rate = 0.1,\n                     n_estimators = 439,     # 439 comes from previous iterations of training\n                     max_depth = 5,          # max depth of tree\n                     min_child_weight = 1,   # min sum of weights of all observ. required in a child\n                     gamma = 0,              # min loss required to make split\n                     subsample = 0.8,        # fraction of observ. to be randomly selected for each tree\n                     colsample_bytree = 0.8, # denotes frac. of col. to be randomly smapled for each tree\n                     scale_pos_weight = 1    # parameter for high class imbalanc,[default=1]\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# run model\nstart = time.time() # start timer\n\nmodelfit(xgb3, x_train, y_train) \n\nprint(\"Building time : \" + str(time.time()-start))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Predict on test set:\npredictions = xgb3.predict(x_test)\npredprob = xgb3.predict_proba(x_test)[:,1]\n\n# Print model report:\nprint (\"\\nModel Report\")\nprint (\"Accuracy: %.4g\" % metrics.accuracy_score(y_test.values, predictions))\nprint (\"AUC Score (Test): %f\" % metrics.roc_auc_score(y_test.values.flatten(), predprob))\n\nf1 = f1_score(y_test.values, predictions)\nprecision =  precision_score(y_test.values, predictions)\nrecall = recall_score(y_test.values, predictions)\n\nprint(\"f1 Score: {:f}\\nPrecision: {:f}\\nRecall: {:f}\".format(f1, precision, recall))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Tune max_depth and min_child_weight first\nparam_test1 = {\n    'max_depth':range(3,10,2),\n    'min_child_weight':range(1,6,2)  \n}\ngsearch1 = GridSearchCV(estimator=XGBClassifier(learning_rate=0.1, n_estimators=439,\n                     min_child_weight = 1,   # min sum of weights of all observ. required in a child\n                     gamma = 0,              # min loss required to make split\n                     subsample = 0.8,        # fraction of observ. to be randomly selected for each tree\n                     colsample_bytree = 0.8, # denotes frac. of col. to be randomly smapled for each tree\n                     scale_pos_weight = 1,    # parameter for high class imbalanc,[default=1]\n                     seed=2),\n                        param_grid=param_test1,\n                        scoring='roc_auc',\n                        n_jobs=4,\n                        iid=False,\n                        cv=5\n                       )\ngsearch1.fit(x_train, y_train)\n#gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_\n\nprint('Best parameter set found on development site: ',gsearch1.best_params_,'\\n')\nprint('Best ROC_AUC: ',gsearch1.best_score_,'\\n')\nprint('Mean test score: ',gsearch1.cv_results_['mean_test_score'],'\\n')\nprint('std. on test score: ',gsearch1.cv_results_['std_test_score'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# test tuned model on test set\nxgb_tuned = XGBClassifier(learning_rate = 0.1,\n                     n_estimators = 439,     # 439 comes from previous iterations of training\n                     max_depth = 9,          # max depth of tree\n                     min_child_weight = 1,   # min sum of weights of all observ. required in a child\n                     gamma = 0,              # min loss required to make split\n                     subsample = 0.8,        # fraction of observ. to be randomly selected for each tree\n                     colsample_bytree = 0.8, # denotes frac. of col. to be randomly smapled for each tree\n                     scale_pos_weight = 1    # parameter for high class imbalanc,[default=1]\n)\n\n# run model\nstart = time.time() # start timer\n\nmodelfit(xgb_tuned, x_train, y_train) \n\nprint(\"Building time : \" + str(time.time()-start))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Predict on test set:\npredictions = xgb_tuned.predict(x_test)\npredprob = xgb_tuned.predict_proba(x_test)[:,1]\n\n# Print model report:\nprint (\"\\nModel Report\")\nprint (\"Accuracy: %.4g\" % metrics.accuracy_score(y_test.values, predictions))\nprint (\"AUC Score (Test): %f\" % metrics.roc_auc_score(y_test.values.flatten(), predprob))\n\nf1 = f1_score(y_test.values, predictions)\nprecision =  precision_score(y_test.values, predictions)\nrecall = recall_score(y_test.values, predictions)\n\nprint(\"f1 Score: {:f}\\nPrecision: {:f}\\nRecall: {:f}\".format(f1, precision, recall))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Results:\nThe grid search performed above took about 40 minutes.  The best parameters found for the two hyperparameters were max_depth=9 and min_child_weight=1.  Ideally we would continue to perform grid searches on the remaining parameters, intermittently retraining our model to get the output of the optimal number of estimators (ex:” Optimal estimators for learning rate:  100”) as that can change.  For times sake no more grid searches will be performed.\n\nParameters|Value|Description\n---|---|:---\nlearning_rate|0.1|learning rate\nn_estimators|439|number of boosting rounds\nmax_depth|9|max depth of tree\nnin_child_weight|1|min sum of weights of all observ. required in a child\ngamma|0|min loss required to make split\nsubsample|0.8|fraction of observ. to be randomly selected for each tree\ncolsample_bytree|0.8|denotes frac. of col. to be randomly smapled for each tree\nscale_pos_weight|1|parameter for high class imbalance [default=1]\n\nSummary of Model Results:\n\nMetric|Before (defualt)|After (tuning)\n---|---|---\nAccuracy|0.8440|0.8546|\nAUC Score|0.9103|0.9213|\nf1 Score|0.7693|0.7919|\nPrecision|0.8488|0.8408|\nRecall|0.7034|0.7484|\n\n\n\n\n"},{"metadata":{},"cell_type":"markdown","source":"Looks like this model has managed to produce an accuracy of 85.46% on the test set after some minimal hyperparamter tuning."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}