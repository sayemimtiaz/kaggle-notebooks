{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# [HEALTHCARE PROVIDER FRAUD DETECTION ANALYSIS](https://www.kaggle.com/rohitrox/healthcare-provider-fraud-detection-analysis)"},{"metadata":{},"cell_type":"markdown","source":"![MediCare](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcT7EqGpB-UkZNUi3pcVWVX1nsaXAHzZpM5z7E37Ps71VHD9nFYK)"},{"metadata":{"trusted":true},"cell_type":"code","source":"### import packages\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split, ShuffleSplit, learning_curve, GridSearchCV, KFold\nfrom sklearn.linear_model import LogisticRegression, Perceptron\nfrom sklearn.metrics import roc_curve, accuracy_score, confusion_matrix, classification_report, roc_auc_score, make_scorer, precision_recall_curve, average_precision_score \nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.ensemble import RandomForestClassifier, IsolationForest, VotingClassifier\nfrom sklearn.neural_network import MLPClassifier\n\n%matplotlib inline\nplt.style.use('ggplot')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_data(tp = \"Train\", N = 1542865627584):\n    target = pd.read_csv(\"/kaggle/input/healthcare-provider-fraud-detection-analysis/{}-{}.csv\".format(tp.title(), N))\n    pt = pd.read_csv(\"/kaggle/input/healthcare-provider-fraud-detection-analysis/{}_Beneficiarydata-{}.csv\".format(tp.title(), N))\n    in_pt = pd.read_csv(\"/kaggle/input/healthcare-provider-fraud-detection-analysis/{}_Inpatientdata-{}.csv\".format(tp.title(), N))\n    out_pt = pd.read_csv(\"/kaggle/input/healthcare-provider-fraud-detection-analysis/{}_Outpatientdata-{}.csv\".format(tp.title(), N))\n    return (in_pt, out_pt, pt, target)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Explore datasets "},{"metadata":{"trusted":true},"cell_type":"code","source":"### Load Train data\nin_pt, out_pt, asl, target = read_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"asl = asl.replace({'ChronicCond_Alzheimer': 2, 'ChronicCond_Heartfailure': 2, 'ChronicCond_KidneyDisease': 2,\n                           'ChronicCond_Cancer': 2, 'ChronicCond_ObstrPulmonary': 2, 'ChronicCond_Depression': 2, \n                           'ChronicCond_Diabetes': 2, 'ChronicCond_IschemicHeart': 2, 'ChronicCond_Osteoporasis': 2, \n                           'ChronicCond_rheumatoidarthritis': 2, 'ChronicCond_stroke': 2, 'Gender': 2 }, 0)\nasl = asl.replace({'RenalDiseaseIndicator': 'Y'}, 1).astype({'RenalDiseaseIndicator': 'int64'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(asl.shape)\nasl.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(target.shape)\ntarget.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title(\"Potential Fraud Test distribution\")\ntarget.groupby( [\"PotentialFraud\"] ).Provider.count().plot(kind = \"bar\", figsize = (10,6))\nplt.xlabel('Status')\nplt.ylabel('Count')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(in_pt.shape)\nin_pt.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(out_pt.shape)\nout_pt.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Adding features and combine datasets"},{"metadata":{},"cell_type":"markdown","source":"- 1. Add Flag column 'WhetherDead' using DOD values to tell whether beneficiary is dead on not"},{"metadata":{"trusted":true},"cell_type":"code","source":"asl['WhetherDead']= 0\nasl.loc[asl.DOD.notna(),'WhetherDead'] = 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- 2. Adding Target numeric variable. "},{"metadata":{"trusted":true},"cell_type":"code","source":"target[\"target\"] = np.where(target.PotentialFraud == \"Yes\", 1, 0) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- 3. Combine Inpatient and Outpatient datasets "},{"metadata":{"trusted":true},"cell_type":"code","source":"MediCare = pd.merge(in_pt, out_pt, left_on = [ x for x in out_pt.columns if x in in_pt.columns], right_on = [ x for x in out_pt.columns if x in in_pt.columns], how = 'outer')\nMediCare.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- 4. Add Patients information"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.merge(MediCare, asl,left_on='BeneID',right_on='BeneID',how='inner')\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- 5. Create a new variable \"NumPhysicians\" with number of physians(from 0 to 3): 'AttendingPhysician' not missing + 'OperatingPhysician' not missing +  'OtherPhysician' not missing"},{"metadata":{"trusted":true},"cell_type":"code","source":"### Check Physicians columns for stange records and value length.\ndef len_check(data , l):\n    S = dict()\n    for i in data.columns:\n         S[i] = [x for x in data.loc[ np.any(data[[i]].notnull().to_numpy(), axis = 1)][i].unique() if (len(str(x)) < l | len(str(x)) > l ) ]\n    \n    print(S)\n\nlen_check(data[['AttendingPhysician', 'OperatingPhysician', 'OtherPhysician']], len('PHY388358'))  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def uniq(a):\n    return np.array([len(set([i for i in x[~pd.isnull(x)]])) for x in a.values])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Create new variable and drop 'AttendingPhysician', 'OperatingPhysician', 'OtherPhysician'\ndata['NumPhysicians'] = uniq(data[['AttendingPhysician', 'OperatingPhysician', 'OtherPhysician']]) \ndata = data.drop(['AttendingPhysician', 'OperatingPhysician', 'OtherPhysician'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- 6. Count number of procedures 'NumProc' for each claim."},{"metadata":{"trusted":true},"cell_type":"code","source":"ClmProcedure_vars = ['ClmProcedureCode_{}'.format(x) for x in range(1,7)]\n### Create new variable \ndata['NumProc'] = data[ClmProcedure_vars].notnull().to_numpy().sum(axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"keep = ['BeneID', 'ClaimID', 'ClmAdmitDiagnosisCode', 'NumProc' ] + ClmProcedure_vars\n### Checking if procedures is unique\nprint(data[keep].loc[data['NumProc'] != uniq( data[ClmProcedure_vars])])\n\ndata = data.drop(ClmProcedure_vars, axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- 7. Count number of claims, extra reported claims and unique."},{"metadata":{"trusted":true},"cell_type":"code","source":"ClmDiagnosisCode_vars =['ClmAdmitDiagnosisCode'] + ['ClmDiagnosisCode_{}'.format(x) for x in range(1, 11)]\n\n### Create new variable \ndata['NumClaims'] = data[ClmDiagnosisCode_vars].notnull().to_numpy().sum(axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"keep = ['BeneID', 'ClaimID', 'ClmAdmitDiagnosisCode', 'NumClaims'] + ClmDiagnosisCode_vars\n\n### Create new variable \ndata['NumClaims'] = data[ClmDiagnosisCode_vars].notnull().to_numpy().sum(axis = 1)\n\nprint(data[keep].loc[data['NumClaims'] != uniq( data[ClmDiagnosisCode_vars])].head())\n### if checking result of unique claims is not missing, we are going to add number of unique claims.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['NumUniqueClaims'] = uniq(data[ClmDiagnosisCode_vars])\n\ndata['ExtraClm'] = data['NumClaims'] - data['NumUniqueClaims']\n\ndata = data.drop(ClmDiagnosisCode_vars, axis = 1)\ndata = data.drop(['NumClaims'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- 8. Convert Dates and calculate days for Claim and for Admission. Calculate patient age at time of claim. "},{"metadata":{"trusted":true},"cell_type":"code","source":"### \ndata['AdmissionDt'] = pd.to_datetime(data['AdmissionDt'] , format = '%Y-%m-%d')\ndata['DischargeDt'] = pd.to_datetime(data['DischargeDt'],format = '%Y-%m-%d')\n\ndata['ClaimStartDt'] = pd.to_datetime(data['ClaimStartDt'] , format = '%Y-%m-%d')\ndata['ClaimEndDt'] = pd.to_datetime(data['ClaimEndDt'],format = '%Y-%m-%d')\n\ndata['DOB'] = pd.to_datetime(data['DOB'] , format = '%Y-%m-%d')\ndata['DOD'] = pd.to_datetime(data['DOD'],format = '%Y-%m-%d')\n\n### Number of hospitalization days\ndata['AdmissionDays'] = ((data['DischargeDt'] - data['AdmissionDt']).dt.days) + 1\n### Number of claim days \ndata['ClaimDays'] = ((data['ClaimEndDt'] - data['ClaimStartDt']).dt.days) + 1\n\ndata['Age'] = round(((data['ClaimStartDt'] - data['DOB']).dt.days + 1)/365.25)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- 9. Hospitalization flag 'Hospt'"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Hospt'] = np.where(data.DiagnosisGroupCode.notnull(), 1, 0)\ndata = data.drop(['DiagnosisGroupCode'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Check if there were any actions after death. \ndata['DeadActions'] = np.where(np.any(np.array([ data[x] > data['DOD'] for x in ['AdmissionDt', 'DischargeDt', 'ClaimStartDt', 'ClaimEndDt']]), axis = 0), 1, 0)\n\nprint(data.loc[data['DeadActions'] > 0])\n\n### If there is no actions after death date, we will drop this variable. \ndata = data.drop(['AdmissionDt', 'DeadActions', 'DischargeDt', 'ClaimStartDt', 'ClaimEndDt', 'DOD', 'DOB'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Descriptive stats"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe(exclude = ['object'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Checking and impute missing records"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Fill missing results using 0\ndata = data.fillna(0).copy()\ndata.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Group by provider each column"},{"metadata":{"trusted":true},"cell_type":"code","source":"### Sum all results\ndf1 = data.groupby(['Provider'], as_index = False)[['InscClaimAmtReimbursed', 'DeductibleAmtPaid', 'RenalDiseaseIndicator', \n                                                  'ChronicCond_Alzheimer', 'ChronicCond_Heartfailure',\n                                                  'ChronicCond_KidneyDisease', 'ChronicCond_Cancer', \n                                                  'ChronicCond_ObstrPulmonary', 'ChronicCond_Depression', \n                                                  'ChronicCond_Diabetes', 'ChronicCond_IschemicHeart', \n                                                  'ChronicCond_Osteoporasis', 'ChronicCond_rheumatoidarthritis',\n                                                  'ChronicCond_stroke', 'WhetherDead', 'NumPhysicians', \n                                                  'NumProc','NumUniqueClaims', 'ExtraClm', 'AdmissionDays',\n                                                  'ClaimDays', 'Hospt']].sum()\n### Count number of records\ndf2 = data[['BeneID', 'ClaimID']].groupby(data['Provider']).nunique().reset_index()\n### Calculate mean\ndf3 = data.groupby(['Provider'], as_index = False)[['NoOfMonths_PartACov', 'NoOfMonths_PartBCov',\n                                                    'IPAnnualReimbursementAmt', 'IPAnnualDeductibleAmt',\n                                                    'OPAnnualReimbursementAmt', 'OPAnnualDeductibleAmt', 'Age']].mean()\n### Combine all together\ndf = df2.merge(df1, on='Provider', how='left').merge(df3, on='Provider', how='left')\nprint(df.shape, target.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Machine Learning for fraud detection "},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = df.merge(target, on='Provider', how='left').drop(['Provider', 'target'], axis = 1)\ndf2 = df.merge(target, on='Provider', how='left').drop(['Provider', 'PotentialFraud'], axis = 1)\nprint(df.shape, target.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.pairplot(df1, hue = 'PotentialFraud', markers=\"+\")\ng.fig.suptitle('Plot pairwise relationships in a dataset')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20, 20))\nplt.title('Correlation heatmap')\nsns.heatmap(df2.corr())\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"countFraud = target.target.value_counts()\nprint('No:', countFraud[0])\nprint('Yes:', countFraud[1])\nprint('Proportion:', round(countFraud[1] / countFraud[0], 2))\n### We should keep in mind that we are using unbalanced data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Splitting the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"### Only Train dataset is labeled that why we split it to two sets train and validation\nX_train, X_val, y_train, y_val = train_test_split(df.drop(['Provider'], axis = 1), target.target.to_numpy(), test_size=0.25, random_state=1)\n\ncols = X_train.columns\n\nX_train = StandardScaler().fit_transform(X_train)\nX_val = StandardScaler().fit_transform(X_val)\n\nprint(\"Train obs: {}; Features Number: {}\".format(X_train.shape[0], X_train.shape[1]))\nprint(\"Validation obs: {};\".format(X_val.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## write Master Learn class which we are going to use for our analysis\nclass MasterL:\n    \n    def __init__(self, model, #### model is a method which we are going to use for detecting FRAUDS. For example: sklearn.svm\n                 X= X_train, y= y_train, test= X_val, ### data\n                 **kvars  #### additional key parameters for model\n                ):\n        self.clf = model( **kvars)\n        self.methodname = model.__name__\n        self.X_train = X\n        self.y_train = y\n        self.X_test = test\n        self.fit(self.X_train, self.y_train)\n        self.predicted = self.predict(test)\n        \n    def fit (self, X, y):\n        self.clf.fit(X, y)\n    \n    def predict(self, x):\n        return self.clf.predict(x)\n       \n    def get_score(self, y = y_val, roc = True, params = False):\n        accuracy = accuracy_score(self.predicted, y)\n        if params:\n            print(self.clf.get_params())\n        print(self.methodname+ \" metrics:\\n\")\n        print(\" Accuracy Score: %.2f%%\" % (accuracy * 100.0))\n        print(\" Confusion matrix:\", \"\\n\",confusion_matrix(y_true=y, y_pred=self.predicted))\n        print( 'Classification report:\\n', classification_report(y, self.predicted))\n        if roc:\n            print(\" ROC Score: %.2f%%\" % (roc_auc_score(y, self.clf.predict_proba(self.X_test)[:,1])))\n        \n    def plot_curves(self, y = y_val):   \n        plt.figure(figsize=(17, 5))\n        plt.subplot(131)\n        # Plot the recall precision tradeoff        \n        self.plot_pr_curve(y)\n        plt.subplot(132)        \n        self.plot_lern_curve(accuracy_score)     \n        plt.subplot(133)\n        self.plot_lern_curve(roc_auc_score)\n        plt.show()\n        \n    def plot_pr_curve(self, y = y_val):\n        \n        plt.subplot(122)\n        # Calculate average precision and the PR curve\n        average_precision = average_precision_score(y, self.predicted)\n\n        # Obtain precision and recall \n        precision, recall, _ = precision_recall_curve(y, self.clf.predict_proba(self.X_test)[:,1])\n        \n        plt.step(recall, precision, where='post')\n        plt.xlabel('Recall')\n        plt.ylabel('Precision')\n        plt.ylim([0.0, 1.05])\n        plt.xlim([0.0, 1.05])\n        plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format( average_precision))\n    \n    def plot_lern_curve(self, metrics):\n        plt.title(self.methodname + \" Learning Curves\")\n        plt.xlabel(\"Training examples\")\n        plt.ylabel(\"{}\".format(' '.join(metrics.__name__.split('_')).title()))\n        \n        train_sizes, train_scores, test_scores = learning_curve(self.clf, self.X_train, self.y_train, n_jobs=-1, \n                                                                cv = ShuffleSplit(n_splits=5, test_size=.25 , random_state = 5), \n                                                                train_sizes=np.linspace(0.5, 1.0, 10), scoring = make_scorer(metrics))\n        train_scores_mean = np.mean(train_scores, axis=1) \n        test_scores_mean = np.mean(test_scores, axis=1) \n        #plt.grid()\n\n        plt.plot(train_sizes,  train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n        plt.plot(train_sizes,  test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n        \n        plt.legend(loc=\"best\")\n    \n    def plot_roc_curve(self, y = y_val, models = None, fig = None):\n        fig = plt.figure(figsize=(15, 7))\n        ax = fig.add_subplot(121)\n        \n        self.roc_curves(ax, y, models)\n        \n        ax.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n        \n        ax.set_xlabel('False Positive Rate')\n        ax.set_ylabel('True Positive Rate')\n        plt.title('Receiver Operating Characteristic (ROC) Curve')\n        \n        plt.legend(loc=\"best\")\n        \n        #if fig != None:\n            #plt.savefig( fig, bbox_inches = 'tight')\n       \n    def roc_curves(self, p, y, M):\n        if M == None:\n            fpr, tpr, thresholds = roc_curve(y, self.clf.predict_proba(self.X_test)[:,1] )\n            p.plot(fpr, tpr,  label=self.methodname )\n        else:\n            fpr, tpr, thresholds = roc_curve(y, self.clf.predict_proba(self.X_test)[:,1] )\n            p.plot(fpr, tpr,  label=self.methodname )\n            for i in M:\n                fpr, tpr, thresholds = roc_curve(y, i.clf.predict_proba(i.X_test)[:,1] )\n                p.plot(fpr, tpr,  label=i.methodname )\n\n#### Function for serching best parameters which is fiting the model and shows best results for specified method.               \ndef grid(method, parameters):\n    \n    grid_1 = GridSearchCV(method, parameters, scoring = make_scorer(accuracy_score), cv=5, n_jobs = -1)\n    grid_2 = GridSearchCV(method, parameters, scoring = make_scorer(roc_auc_score), cv=5, n_jobs = -1)\n    \n    grid_1.fit(X_train, y_train)\n    print('Best parameters using accuracy score:')\n    print(grid_1.best_params_)\n\n    grid_2.fit(X_train, y_train)\n    print('Best parameters usin ROC accuracy score:')\n    print(grid_2.best_params_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1. Logistic regression"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Grid Seach best Parametes for Log-reg L2 regularization\n```pyhon\nparameters = { \n        'C' : np.linspace(0.001, 1.0, 1000)\n}\n\ngrid(LogisticRegression(solver= 'liblinear', class_weight='balanced', random_state = 5), parameters)\n```"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Grid Seach best Parametes for Log-reg L1 regularization\n```\nparameters = { \n        'C' : np.linspace(0.001, 1.0, 1000)\n}\n\ngrid(LogisticRegression(penalty = 'l1', solver= 'liblinear', class_weight='balanced', random_state = 5), parameters)\n```"},{"metadata":{"trusted":true},"cell_type":"code","source":"### Logistic regression \n### Balanced Weight and Scaled data\nML1 = MasterL(LogisticRegression, \n              penalty= 'l1',\n              solver= 'liblinear', class_weight='balanced', random_state = 5 , C = 0.001)\n# Get your performance metrics\nML1.get_score()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plot validation results"},{"metadata":{"trusted":true},"cell_type":"code","source":"ML1.plot_roc_curve()\nML1.plot_pr_curve()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Support Vector Machines(SVM)"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Grid Seach best Parametes for SVM\n```\nparameters = { \n        #'gamma' : np.linspace(0.01, .1, 5),\n        'C' : np.linspace(0.1, 1.0, 10)\n}\n\ngrid(SVC( gamma = 'auto', probability = True, random_state= 5, class_weight= 'balanced'), parameters)\n```"},{"metadata":{"trusted":true},"cell_type":"code","source":"# SVM(scaled data)\nML2 = MasterL(SVC, \n              gamma = 'auto', probability = True, random_state= 5, class_weight= 'balanced', C=1 )\n\n# Get your performance metrics\nML2.get_score()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plot validation results"},{"metadata":{"trusted":true},"cell_type":"code","source":"ML2.plot_roc_curve(models = [ML1])\nML2.plot_pr_curve()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Random Forest Clasifier"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Search best parametes**\n```\nkf = KFold(n_splits=5)\nest = np.linspace(10, 200, 39)\n\nRandFo = dict() \ndef kind_GridSearchCV(i):\n    acScore = list()\n    rocScore = list()    \n    for train_index, test_index in kf.split(X_train):\n        Xtrain, Xtest = X_train[train_index], X_train[test_index]\n        ytrain, ytest = y_train[train_index], y_train[test_index]\n        RandFo[i] = RandomForestClassifier(n_estimators =  i, n_jobs = -1, random_state = 5, \n                                           class_weight = 'balanced_subsample', min_samples_split = 0.25 )\n        RandFo[i].fit(Xtrain, ytrain)\n        acScore.append(accuracy_score(RandFo[i].predict(X_val), y_val))\n        rocScore.append(roc_auc_score(y_val, RandFo[i].predict_proba(X_val)[:,1]))\n        \n    return  [ i, np.mean(acScore), np.mean(rocScore) ]\n\nscores = list()\nfor i in est:\n    scores.append(kind_GridSearchCV(int(i)))\n\nscoresD = pd.DataFrame(scores, columns = ['N_est', 'Accuracy', \"ROC accuracy\"])\n\nprint(scoresD.sort_values(by=['Accuracy'], ascending=False).iloc[0])\nprint(scoresD.sort_values(by=[\"ROC accuracy\"], ascending=False).iloc[0])\n```"},{"metadata":{"trusted":true},"cell_type":"code","source":"### Random Forest Clasifier\n# Continue fitting the model and obtain predictions\n\nML3 = MasterL(RandomForestClassifier, \n              n_estimators = 60, n_jobs = -1, random_state = 5, class_weight = 'balanced_subsample', \n              min_samples_split = 0.25\n             )\n \n# Get your performance metrics\nML3.get_score() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plot validation results"},{"metadata":{"trusted":true},"cell_type":"code","source":"ML3.plot_roc_curve(models = [ML1, ML2])\nML3.plot_pr_curve()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Top highest scoring Random Forest Features\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"features = ML3.clf.feature_importances_\nFeatures_score = pd.DataFrame(np.array([cols, features]).T, columns = [\"VarName\", \"Importamce\"]).sort_values(by=[\"Importamce\"], ascending=False)\n\nFeatures_score.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4. Ensemble method clasifier (log-reg + Random Forest)"},{"metadata":{"trusted":true},"cell_type":"code","source":"### Generate ensemble\nML4 = MasterL(VotingClassifier, \n              estimators=[ ('lr', ML1.clf), (\"rf\", ML3.clf)], voting='soft', n_jobs = -1\n             )\n \n# Get your performance metrics\nML4.get_score()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* ### Plot validation results"},{"metadata":{"trusted":true},"cell_type":"code","source":"ML4.methodname = \"log-reg + RandomForestCl\"\nML4.plot_roc_curve(models = [ML1, ML2, ML3])\nML4.plot_pr_curve()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5. Multi-layer Perceptron classifier(MLP)"},{"metadata":{},"cell_type":"markdown","source":"### Grid Seach best Parametes for MLP\n```\nx = np.array(list(map(int, np.linspace(1, 31, 31))))\n\nparameters = { \n        'hidden_layer_sizes' : list(zip(np.tile(x, len(x)), np.repeat(x, len(x))))\n}\n\ngrid(MLPClassifier ( activation = 'logistic', random_state = 5, max_iter= 1000), parameters)\n```"},{"metadata":{"trusted":true},"cell_type":"code","source":"### Multy Layer Perceptron\nML5 = MasterL( MLPClassifier, \n              activation = 'logistic',\n              hidden_layer_sizes = (1, 3),random_state = 5, max_iter= 1000 )\n# Get your performance metrics \nML5.get_score()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plot validation results"},{"metadata":{"trusted":true},"cell_type":"code","source":"ML5.plot_roc_curve(models = [ML1, ML2, ML3, ML4])\nML5.plot_pr_curve()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}