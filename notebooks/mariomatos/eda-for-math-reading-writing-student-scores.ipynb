{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# Import all libraries to be used\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split, learning_curve, cross_val_score, cross_validate, validation_curve, GridSearchCV\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_auc_score, roc_curve, plot_roc_curve\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Reading Data","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#data = pd.read_csv('/kaggle/input/students-performance-in-exams/StudentsPerformance.csv')\ndata = pd.read_csv('/kaggle/input/exams6k/exams.csv')\ndata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import os\n\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\ndata.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# NOTE: # dev_null is used to produce no unnecessary output. Also it will not be used anywhere because it is just a variable to put anything meaningless. like /dev/null in linux\ndev_null = sns.distplot(data[\"math score\"])\ndev_null.set(xlabel=\"Math Score\", ylabel=\"Frequency\")\ndev_null = dev_null.set_title(\"Math Scores Distributions\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see in this graph, there is a normal distribution skewed towards ~63% for math test scores.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dev_null = sns.distplot(data[\"reading score\"])\ndev_null.set(xlabel=\"Reading Score\", ylabel=\"Frequency\")\ndev_null = dev_null.set_title(\"Reading Scores Distributions\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Reading scores are more skewed towards 70%. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dev_null = sns.distplot(data[\"writing score\"])\ndev_null.set(xlabel=\"Writing Score\", ylabel=\"Frequency\")\ndev_null = dev_null.set_title(\"Writing Scores Distributions\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This yields similar results as the reading exams, but seems to be more skewed towards the median at 72%.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Check data for empty values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.select_dtypes('object').nunique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Compiling number of categories in the data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Our data seems to be clean of missing values. ðŸ‘","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Math test scores for students by group. Male and Female labeled.\nAs we can see members of group E seem to do the best in the test. Males seem to do slightly better on these tests. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dev_null = sns.barplot(x=\"race/ethnicity\", y=\"math score\", hue=\"gender\", data=data)\ndev_null.set(xlabel=\"Group\", ylabel=\"Math Score\")\ndev_null = dev_null.set_title(\"Math Scores By Group\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Reading test scores for students by group. Male and Female labeled.\nAgain members on the group E did best, followed by group D. In this case however females seem to do better. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dev_null = sns.barplot(x=\"race/ethnicity\", y=\"reading score\", hue=\"gender\", data=data)\ndev_null.set(xlabel=\"Reading Score\", ylabel=\"Frequency\")\ndev_null = dev_null.set_title(\"Reading Scores Distributions\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Writing test scores for students by group. Male and Female labeled.\nAgain members on the group E did best, followed by group D. In this case however females seem to do better. Overall scores seem to be sligthly lower than reading tests","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\n\nplt.figure(figsize=(25,6))\nplt.subplot(1, 3, 1)\nsns.distplot(data['math score'])\n\nplt.subplot(1, 3, 2)\nsns.distplot(data['reading score'])\n\nplt.subplot(1, 3, 3)\nsns.distplot(data['writing score'])\n\nplt.suptitle('Checking for Skewness', fontsize = 15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Overall it doesn't seem that fail or passing scores in any of the tests can be completely predicted from any of the categories grouped above. Unless there is some variation. Let's see if we can catch that using boxplot:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dev_null = sns.heatmap(data.corr(), annot=True, fmt=\".2f\")\ndev_null = dev_null.set_title(\"Frequency Distributions comparing scores\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dev_null = sns.countplot(x=\"race/ethnicity\", data=data)\ndev_null.set(xlabel=\"Group\", ylabel=\"Count\")\ndev_null = dev_null.set_title(\"Count of Group members\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dev_null = sns.barplot(x=\"race/ethnicity\", y=\"writing score\", hue=\"gender\", data=data)\ndev_null.set(xlabel=\"Group\", ylabel=\"Writing Score\")\ndev_null = dev_null.set_title(\"Writing Scores by Group\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"countplot = sns.countplot(x=\"parental level of education\", data=data)\ncountplot.set_xticklabels(countplot.get_xticklabels(), rotation=40, ha=\"right\")\ncountplot.set(xlabel=\"Parental Education Lvl\", ylabel=\"Count\")\ndev_null = countplot.set_title(\"Count of Students by Education attained by their parents\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dev_null = sns.boxplot(x=\"race/ethnicity\", y=\"math score\", hue=\"gender\", data=data)\ndev_null.set(xlabel=\"Group\", ylabel=\"Math Score\")\ndev_null = dev_null.set_title(\"Math Scores by Group\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see there is some variation among all the groups, and even some outliers. The goal then, is to find what causes these variations with respect to the other fields in the data. \n\nThose are the categories that we should put emphasis on for further analysis and modeling. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"What if we check the relationship between race/ethnicity and parental education level. Will this answer the question of what causes group E to do better than any other group.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# check counts for relationship between race/ethnicity and parental education level. \nparent_edu_vs_eth_race = pd.crosstab(index=data[\"race/ethnicity\"], columns=data[\"parental level of education\"])\ndev_null = sns.heatmap(parent_edu_vs_eth_race)\ndev_null.set(xlabel=\"Parent Education Lvl\", ylabel=\"Group\")\ndev_null = dev_null.set_title(\"Correlation between Groups and Parent Educ. Lvl\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The heatmap above illustrates the relationship between the groups in the data vs parental education.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"parent_edu_vs_eth_race","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bar = sns.barplot(x=\"parental level of education\", y=\"math score\", hue=\"race/ethnicity\", data=data)\nbar.set_xticklabels(bar.get_xticklabels(), rotation=40, ha=\"right\")\nbar.set(xlabel=\"Parental Educ. Lvl\", ylabel=\"Math Score\")\ndev_null = bar.set_title(\"Relating Parental Educ. Lvl to Math Score\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It seems, even if by a small degree, that parental level of education has an impact on the student core, improving it slightly when parents of the student attain a higher level of education.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"bar = sns.boxplot(x=\"parental level of education\", y=\"math score\", hue=\"race/ethnicity\", data=data)\nbar.set_xticklabels(bar.get_xticklabels(), rotation=40, ha=\"right\")\nbar.set(xlabel=\"Parent Educ. Lvl\", ylabel=\"Math Score\")\ndev_null = bar.set_title(\"Math Score and Parent Educ. Lvl\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A boxplot graph can help see more clearly the distribution of students of different group.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# MLP Model To Predict P/F of Students","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Preparing data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"Pass\"] = data.apply(lambda x: 1 if x[\"math score\"] >= 65 and x[\"reading score\"] >= 65 and x[\"writing score\"] >= 65 else 0, axis=1)\ndata = data.drop([\"math score\", \"reading score\", \"writing score\"], axis=1)\ndata.select_dtypes(include=\"object\")\ndata\n\nX = data.drop([\"Pass\"], axis=1)\ny = data[\"Pass\"]\nX,y","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Implement MLP Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Add using different parameters.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Encoding categorical inputs\nencoder = OneHotEncoder(handle_unknown=\"ignore\")\nencoder.fit(X)\nX = encoder.transform(X)\n\n# 80/20 train split ratio\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, stratify=y, random_state=1)\n\nmlp = MLPClassifier(\n    max_iter=3000,\n    hidden_layer_sizes=[17, 13, 7], \n    solver=\"sgd\", \n    random_state=1,\n    verbose=False\n).fit(X_train, y_train)\n\ny_predicted = mlp.predict(X_test)\n\ny_predicted, y_test.to_numpy() # Todo compare \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"oneHotEncoder is used to encode categiorical columns into values that can be digested by the used algorithm implementation, in our case it.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The MLP configured above will iterate 3000 times, use hidden layers and 17, 13, 7, solver stochastic gradient descent. Our data was devided into a 80/20 train/set splits to train and evaluate your classifier. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Compute learning curve","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def format_scores_as_dataframe(labels, train_scores, test_scores):\n    learning_data = {\"labels\": [], \"type\": [], \"score\": []}\n\n    for i in range(len(train_sizes)):\n        for j in range(len(train_scores)):\n            learning_data[\"labels\"].append(labels[i])\n            learning_data[\"type\"].append(\"train\")\n            learning_data[\"score\"].append(train_scores[i][j])\n            learning_data[\"labels\"].append(labels[i])\n            learning_data[\"type\"].append(\"test\")\n            learning_data[\"score\"].append(test_scores[i][j])\n            \n    return pd.DataFrame.from_dict(learning_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Learning Curve | Complexity Curve\ntrain_sizes, train_scores, test_scores = learning_curve(mlp, X, y)\n\nlearning_curve_df = format_scores_as_dataframe(train_sizes, train_scores, test_scores)\n\n# train and test learning scores results\nax = sns.lineplot(x=\"labels\", y=\"score\", hue=\"type\", data=learning_curve_df, marker=\"o\", ci=None)\nax.set_title(\"Learning Curve for MLP Algorithm\")\ndev_null = ax.set(xlabel=\"Samples\", ylabel=\"Error\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Learning curve is a measurement to check how well the model learns. This is measured by taking a reading of the accuracy of the algorithm as it trains and also while it is testing. This are plotting to see the convergence.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Compute cross-validation curve","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = cross_val_score(mlp, X, y)\n\nscores, scores.mean(), scores.std()\n\ndev_null = sns.lineplot(x=[1,2,3,4,5], y=scores)\ndev_null.set_title(\"Cross Score Distribution\")\ndev_null = dev_null.set(xlabel=\"# of runs\", ylabel=\"Accuracy\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The curve above shows the cross-validation scores for the default 5 runs in the cross-validation process for the MLP model.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cross_val_result = cross_validate(mlp, X, y, return_train_score=True)\n\n#validation_curve(mlp, X, y, param_name=\"alpha\", param_range=[0.0001, 0.001, 0.05])\ntrain_scores, test_scores = validation_curve(mlp, X, y, param_name=\"hidden_layer_sizes\", param_range=([5], [10], [10,5], [15, 10], [25,10,5]))\n\nval_curve_data = {\"labels\": [], \"type\": [], \"scores\": []}\nparam_ranges = [\"[5]\", \"[10]\", \"[10,5]\", \"[15,10]\", \"[25,10,5]\"]\n\nfor i in range(len(train_scores)):\n    for j in range(len(train_scores[i])):\n        val_curve_data[\"labels\"].append(param_ranges[i])\n        val_curve_data[\"type\"].append(\"train\")\n        val_curve_data[\"scores\"].append(train_scores[i][j])\n        val_curve_data[\"labels\"].append(param_ranges[i])\n        val_curve_data[\"type\"].append(\"test\")\n        val_curve_data[\"scores\"].append(test_scores[i][j])\n        \nval_curve_df = pd.DataFrame.from_dict(val_curve_data)\n\nax = sns.lineplot(x=\"labels\", y=\"scores\", hue=\"type\", data = val_curve_df, marker=\"o\", ci=None)\nax.set_title(\"Validation Curve for our MLP model\")\ndev_null = ax.set(xlabel=\"Layers/Neurons\", ylabel=\"Accuracy Score\")\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Cross validation is a measure of how well our model can generalize from what it learns. How well will it perform with data it has neven seen before. This is done by saving part of the data to later predict and measure the accuracy. The training data is split with differing testing folds to be used. Default in this case is k=5 folds.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Compute confusion matrix","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_mtrx = confusion_matrix(y_test, y_predicted)\nclassification_rprt = classification_report(y_test, y_predicted)\naccuracy_scr = accuracy_score(y_test, y_predicted)\n# TN FP\n# FN TP\nprint(\"Confusion Matrix\")\nprint(confusion_mtrx)\nprint(\"Classification Report\")\nprint(classification_rprt)\nprint(\"Accuracy\")\nprint(accuracy_scr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The confusion matrix shows the frequency for True Positives, True Negatives, False Positives, and False Negative. Also a summary of the different properties can be presented here, along with the accuracy for predicted values.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### AUC curve","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Computing AUC score\nroc = roc_auc_score(y_test, y_predicted)\ndev_null = plot_roc_curve(mlp, X_test, y_test, name=\"AUC/ROC Curve for MLP\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The higher the area under the curve for this graph the better the model is in predicting values for a specific domain. In this graph seveal runs are made and accuracy measured.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### GridSearchCV","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"parameters = { # parameters commented to make running time shorter\n    \"hidden_layer_sizes\": [[8], [5], [2]],#, [8,8], [8,5], [5,8], [5,2], [2,2], [8,5,2], [8,5,5], [13,8,4], [17,13,7]],\n    \"activation\": [\"identity\", \"logistic\"],#, \"tanh\", \"relu\"], \n    \"solver\": [\"lbfgs\", \"sgd\"],#, \"adam\"], \n    \"max_iter\": [200, 500],#, 1000, 2000, 3000, 5000]\n}\n\n# Brace yourself, this will take a while\nmlp = MLPClassifier()\ngs = GridSearchCV(mlp, parameters)\ngs.fit(X_train, y_train)\ngs.predict(X_test)\ngs.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Running this overnight yielded the following configuration as the best one: MLPClassifier(activation='identity', hidden_layer_sizes=[2], max_iter=3000). We will therefore run a model and analysis for this configuration as well. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"A grid search will help us determine the optimal configurations to run our models. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Exploring MLP with different characteristcics\nLet us check the MLP using logistic as activation function.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data.drop([\"Pass\"], axis=1)\ny = data[\"Pass\"]\nX,y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Encoding categorical inputs\nencoder = OneHotEncoder(handle_unknown=\"ignore\")\nencoder.fit(X)\nX = encoder.transform(X)\n\n# 80/20 train split ratio\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, stratify=y, random_state=1)\n\nmlp = MLPClassifier(\n    max_iter=10000,\n    hidden_layer_sizes=[100], \n    activation=\"logistic\",\n    random_state=1,\n    verbose=False\n).fit(X_train, y_train)\n\ny_predicted = mlp.predict(X_test)\n\ny_predicted, y_test.to_numpy() # Todo compare ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Learning Curve | Complexity Curve\n\ntrain_sizes, train_scores, test_scores = learning_curve(mlp, X, y)\n\nlearning_curve_df = format_scores_as_dataframe(train_sizes, train_scores, test_scores)\n\n# train and test learning scores results\nax = sns.lineplot(x=\"labels\", y=\"score\", hue=\"type\", data=learning_curve_df, marker=\"o\", ci=None)\nax.set_title(\"Learning Curve for MLP Algorithm\")\ndev_null = ax.set(xlabel=\"Samples\", ylabel=\"Error\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = cross_val_score(mlp, X, y)\n\nscores, scores.mean(), scores.std()\n\ndev_null = sns.lineplot(x=[1,2,3,4,5], y=scores)\ndev_null.set_title(\"Cross Score Distribution\")\ndev_null = dev_null.set(xlabel=\"# of runs\", ylabel=\"Accuracy\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cross_val_result = cross_validate(mlp, X, y, return_train_score=True)\n\n#validation_curve(mlp, X, y, param_name=\"alpha\", param_range=[0.0001, 0.001, 0.05])\ntrain_scores, test_scores = validation_curve(mlp, X, y, param_name=\"hidden_layer_sizes\", param_range=([5], [10], [10,5], [15, 10], [25,10,5]))\n\nval_curve_data = {\"labels\": [], \"type\": [], \"scores\": []}\nparam_ranges = [\"[5]\", \"[10]\", \"[10,5]\", \"[15,10]\", \"[25,10,5]\"]\n\nfor i in range(len(train_scores)):\n    for j in range(len(train_scores[i])):\n        val_curve_data[\"labels\"].append(param_ranges[i])\n        val_curve_data[\"type\"].append(\"train\")\n        val_curve_data[\"scores\"].append(train_scores[i][j])\n        val_curve_data[\"labels\"].append(param_ranges[i])\n        val_curve_data[\"type\"].append(\"test\")\n        val_curve_data[\"scores\"].append(test_scores[i][j])\n        \nval_curve_df = pd.DataFrame.from_dict(val_curve_data)\n\nax = sns.lineplot(x=\"labels\", y=\"scores\", hue=\"type\", data = val_curve_df, marker=\"o\", ci=None)\nax.set_title(\"Validation Curve for our MLP model\")\ndev_null = ax.set(xlabel=\"Layers/Neurons\", ylabel=\"Accuracy Score\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_mtrx = confusion_matrix(y_test, y_predicted)\nclassification_rprt = classification_report(y_test, y_predicted)\naccuracy_scr = accuracy_score(y_test, y_predicted)\n# TN FP\n# FN TP\nprint(\"Confusion Matrix\")\nprint(confusion_mtrx)\nprint(\"Classification Report\")\nprint(classification_rprt)\nprint(\"Accuracy\")\nprint(accuracy_scr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Computing AUC score\nroc = roc_auc_score(y_test, y_predicted)\ndev_null = plot_roc_curve(mlp, X_test, y_test, name=\"AUC/ROC Curve for MLP\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Running Grid Search suggested model.\nMLPClassifier(activation='identity', hidden_layer_sizes=[2], max_iter=3000), very simplistic as you can see.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data.drop([\"Pass\"], axis=1)\ny = data[\"Pass\"]\nX,y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Encoding categorical inputs\nencoder = OneHotEncoder(handle_unknown=\"ignore\")\nencoder.fit(X)\nX = encoder.transform(X)\n\n# 80/20 train split ratio\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, stratify=y, random_state=1)\n\nmlp = MLPClassifier(\n    max_iter=3000,\n    hidden_layer_sizes=[2], \n    solver=\"sgd\",\n    activation=\"identity\",\n    random_state=1,\n    verbose=False\n).fit(X_train, y_train)\n\ny_predicted = mlp.predict(X_test)\n\ny_predicted, y_test.to_numpy() # Todo compare ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Learning Curve | Complexity Curve\n\ntrain_sizes, train_scores, test_scores = learning_curve(mlp, X, y)\n\nlearning_curve_df = format_scores_as_dataframe(train_sizes, train_scores, test_scores)\n\n# train and test learning scores results\nax = sns.lineplot(x=\"labels\", y=\"score\", hue=\"type\", data=learning_curve_df, marker=\"o\", ci=None)\nax.set_title(\"Learning Curve for MLP Algorithm\")\ndev_null = ax.set(xlabel=\"Samples\", ylabel=\"Error\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = cross_val_score(mlp, X, y)\n\nscores, scores.mean(), scores.std()\n\ndev_null = sns.lineplot(x=[1,2,3,4,5], y=scores)\ndev_null.set_title(\"Cross Score Distribution\")\ndev_null = dev_null.set(xlabel=\"# of runs\", ylabel=\"Accuracy\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cross_val_result = cross_validate(mlp, X, y, return_train_score=True)\n\ntrain_scores, test_scores = validation_curve(mlp, X, y, param_name=\"alpha\", param_range=[0.1, 5, 10])\n#train_scores, test_scores = validation_curve(mlp, X, y, param_name=\"hidden_layer_sizes\", param_range=([2], [7], [2,2], [7, 2], [10,7,2]))\n\nval_curve_data = {\"labels\": [], \"type\": [], \"scores\": []}\nparam_ranges = [\"[2]\", \"[7]\", \"[2,2]\", \"[7,2]\", \"[10,7,2]\"]\n\nfor i in range(len(train_scores)):\n    for j in range(len(train_scores[i])):\n        val_curve_data[\"labels\"].append(param_ranges[i])\n        val_curve_data[\"type\"].append(\"train\")\n        val_curve_data[\"scores\"].append(train_scores[i][j])\n        val_curve_data[\"labels\"].append(param_ranges[i])\n        val_curve_data[\"type\"].append(\"test\")\n        val_curve_data[\"scores\"].append(test_scores[i][j])\n        \nval_curve_df = pd.DataFrame.from_dict(val_curve_data)\n\nax = sns.lineplot(x=\"labels\", y=\"scores\", hue=\"type\", data = val_curve_df, marker=\"o\", ci=None)\nax.set_title(\"Validation Curve for our MLP model\")\ndev_null = ax.set(xlabel=\"Layers/Neurons\", ylabel=\"Accuracy Score\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_mtrx = confusion_matrix(y_test, y_predicted)\nclassification_rprt = classification_report(y_test, y_predicted)\naccuracy_scr = accuracy_score(y_test, y_predicted)\n# TN FP\n# FN TP\nprint(\"Confusion Matrix\")\nprint(confusion_mtrx)\nprint(\"Classification Report\")\nprint(classification_rprt)\nprint(\"Accuracy\")\nprint(accuracy_scr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Computing AUC score\nroc = roc_auc_score(y_test, y_predicted)\ndev_null = plot_roc_curve(mlp, X_test, y_test, name=\"AUC/ROC Curve for MLP\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}