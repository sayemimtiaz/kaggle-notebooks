{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h1> SACSD - Strategies affecting COVID-19 Spread and Deaths </h1>\n\n<h2> Hunting for insights that could help to understand COVID-19 and ongoing clinical trials - Working on the Alternative Hypothesis</h2>"},{"metadata":{},"cell_type":"markdown","source":"# What is included in this Notebook?\n\nThis notebook speaks on the alternate hypothesis of the TASK2 of BCG - COVID-19 AI Challenge. The main things included in this notebook for analyses are:\n\n* **PART 1:** Detail study on how the number of social mitigation steps taken by the government reduced the cases of covid-19. Special emphasis on China's mitigation policies and its control measures of COVID-19. \n\n* **PART 2:** Understanding the Mobility data of People during COVID-19 and how it has affected mortality rates of COVID-19 Cases across countries.\n\n* **PART 3:** Building an Epidemiological Model to assess the impact of social intervention and goverment strategies to contain COVID-19.\n\nFeel free to connect - https://www.linkedin.com/in/amankumar01/"},{"metadata":{},"cell_type":"markdown","source":"# General Overview\n\n<H3> Task Details </H3>\n\nThe initiative is prompted by the suggestion that there may be a link between reduced rates of infection and lower case fatality rates associated with COVID-19 in countries that recommend BCG vaccine for all as opposed to countries that recommend BCG only for specific high-risk groups. We hope that the analysis done as part of this task might help discover useful information about the BCG - COVID-19 clinical trials. For example, some insights that may come from this analysis is whether factors such as the strain of BCG, the age at which people have been vaccinated, revaccination, or how long ago people have been vaccinated are important.\n\n<h3> Key Questions for Consideration </h3>\n\n* Is BCG vaccination causally related to reduced COVID‐19 mortality or other factors like lockdown and average age of the population are responsible for the different mortality rates?\n\n* Do government mitigation and strategies adopted for COVID-19 like Lockdowns, Travel Restrictions helped in reduction of COVID-19 Cases and overall mortalilty rates?\n"},{"metadata":{},"cell_type":"markdown","source":"# Understanding the Datasets\n\n1. We read the Novel-Corona-Virus-2019-dataset managed by SRK into this notebook. The dataset hold s information about the cumulative case counts of COVID-19 Across the world. The dataset can be viewed and download from [here](https://www.kaggle.com/sudalairajkumar/novel-corona-virus-2019-dataset)\n\n2. A dataset for COVID-19 Cases in China created by me is uploaded for this notebook.\n\n3. The UNCOVER Dataset as a part of UNCOVER COVID-19 Challenge is also loaded into this notebook.\n\n4. COVID19 Containment and Mitigation Measures Dataset uploaded by Paul Mooney. [See here](//https://www.kaggle.com/paultimothymooney/covid19-containment-and-mitigation-measures)\n\n5. China Geo-JSON Document uploaded by sauravmishra1710.\n\n6. Hackathon Dataset, for the BCG COVID-19 AI Challenge.\n\n7. Countries ISO-CODES : To Geotag conutries with specific set of alphabetical codes. Done to merge the datasets together."},{"metadata":{},"cell_type":"markdown","source":"# PART 1 - Understanding the Social Mitigation Steps - China\n\n<h3> Implementation of the Problem </h3>\n\nThe General Question which we require to study in this notebook is how the implementation of existing strategies affecting the rate of COVID-19 Infection. For the sake of this notebook we proceed with the following analogies ans steps.\n\n1. Checking which countries are somewhat successful in controlling the rate of COVID-19 Spreads.\n2. Figuring out the various measures adopted by that very countries to understand how did it affected spreads.\n3. Checking the countries that displayed a much higher COVID-19 Infections and the growth is exponential as of now.\n4. Figuring out where the country lacked in implementation tools.\n\nFinally we can compare how the country that controlled the COVID-19 Proceeded with the community measures than that to the countries that currently exhibit a near to exponential growth of the COVID-19 Infections.\n\n<h3> Importing the Essential Libraries for the notebook</h3>"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Importing Libraries for data manipulation and loading files.\nimport re\nimport pandas as pd                              \nimport numpy as np       \nimport json\nimport datetime\nimport sqlite3 as sql\nfrom scipy.integrate import odeint\n\n#Importing libraries for graphical analyses.\nimport matplotlib.pyplot as plt                  \nimport plotly.express as px                      \nimport plotly.offline as py                     \nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport seaborn as sns                            \n\n#Other essential libraries to import.\nimport glob                             \nimport os     \nfrom urllib.request import urlopen\nimport warnings\nwarnings.filterwarnings('ignore')\n\n#Required Libraries for analyses\n!pip install pivottablejs\nfrom pivottablejs import pivot_ui\nimport matplotlib.dates as mdates\nfrom datetime import datetime, timedelta\n!pip install lmfit\nimport lmfit","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3> Analysis of COVID-19 Confirmed Cases and Deaths for multiple countries </h3>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Reading the cumulative cases dataset\ncovid_cases = pd.read_csv('../input/novel-corona-virus-2019-dataset/covid_19_data.csv')\n\n#Viewing the dataset\ncovid_cases.head()\n\n#Grouping the coutries together for further analyses\ncountry_list = covid_cases['Country/Region'].unique()\n\ncountry_grouped_covid = covid_cases[0:1]\n\nfor country in country_list:\n    test_data = covid_cases['Country/Region'] == country   \n    test_data = covid_cases[test_data]\n    country_grouped_covid = pd.concat([country_grouped_covid, test_data], axis=0)\n    \ncountry_grouped_covid.reset_index(drop=True)\ncountry_grouped_covid.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3> Plotting a Running Map for observing the spread of COVID-19 Confirmed Cases </h3>"},{"metadata":{},"cell_type":"markdown","source":"<iframe src='https://flo.uri.sh/visualisation/2025509/embed' frameborder='0' scrolling='no' style='width:100%;height:600px;'></iframe><div style='width:100%!;margin-top:4px!important;text-align:right!important;'><a class='flourish-credit' href='https://public.flourish.studio/visualisation/2025509/?utm_source=embed&utm_campaign=visualisation/2025509' target='_top' style='text-decoration:none!important'><img alt='Made with Flourish' src='https://public.flourish.studio/resources/made_with_flourish.svg' style='width:105px!important;height:16px!important;border:none!important;margin:0!important;'></a></div>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotting a bar graph for confirmed cases vs deaths due to COVID-19 in World.\n\nunique_dates = country_grouped_covid['ObservationDate'].unique()\nconfirmed_cases = []\nrecovered = []\ndeaths = []\n\nfor date in unique_dates:\n    date_wise = country_grouped_covid['ObservationDate'] == date  \n    test_data = country_grouped_covid[date_wise]\n    \n    confirmed_cases.append(test_data['Confirmed'].sum())\n    deaths.append(test_data['Deaths'].sum())\n    recovered.append(test_data['Recovered'].sum())\n    \n#Converting the lists to a pandas dataframe.\n\ncountry_dataset = {'Date' : unique_dates, 'Confirmed' : confirmed_cases, 'Recovered' : recovered, 'Deaths' : deaths}\ncountry_dataset = pd.DataFrame(country_dataset)\n\n#Plotting the Graph of Cases vs Deaths Globally.\n\nfig = go.Figure()\nfig.add_trace(go.Bar(x=country_dataset['Date'], y=country_dataset['Confirmed'], name='Confirmed Cases of COVID-19', marker_color='rgb(55, 83, 109)'))\nfig.add_trace(go.Bar(x=country_dataset['Date'],y=country_dataset['Deaths'],name='Total Deaths because of COVID-19',marker_color='rgb(26, 118, 255)'))\n\nfig.update_layout(title='Confirmed Cases and Deaths from COVID-19',xaxis_tickfont_size=14,\n                  yaxis=dict(title='Reported Numbers',titlefont_size=16,tickfont_size=14,),\n    legend=dict(x=0,y=1.0,bgcolor='rgba(255, 255, 255, 0)',bordercolor='rgba(255, 255, 255, 0)'),\n    barmode='group',bargap=0.15, bargroupgap=0.1)\nfig.show()\n\n\nfig = go.Figure()\nfig.add_trace(go.Bar(x=country_dataset['Date'], y=country_dataset['Confirmed'], name='Confirmed Cases of COVID-19', marker_color='rgb(55, 83, 109)'))\nfig.add_trace(go.Bar(x=country_dataset['Date'],y=country_dataset['Recovered'],name='Total Recoveries because of COVID-19',marker_color='rgb(26, 118, 255)'))\n\nfig.update_layout(title='Confirmed Cases and Recoveries from COVID-19',xaxis_tickfont_size=14,\n                  yaxis=dict(title='Reported Numbers',titlefont_size=16,tickfont_size=14,),\n    legend=dict(x=0,y=1.0,bgcolor='rgba(255, 255, 255, 0)',bordercolor='rgba(255, 255, 255, 0)'),\n    barmode='group',bargap=0.15, bargroupgap=0.1)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3> General Observations from the above Running Graph </h3>\n\n1. The cases of COVID-19 starts from China as the epicenter with first initial COVID-19 Cases reported in Australia, US, Canada.\n\n2. Gradually cases in China increases and the confirmed cases is more than anywhere else in the world.\n\n3. Europe emerges later as the new epicenter for the virus, where there is a rapid rise in COVID-19 Cases in European Countries. This outbreak occurs where the confirmed number of COVID-19 Cases in China saturates.\n\n4. The confirmed cases of COVID-19 gradually spreads throughout the world, with spike in confirmed cases seen in European regions and US.\n\n5. As of April 21st 2020, USA has the highest number of confimed COVID-19 Cases reported, with some European Countries emerging as the 2nd-4th highest cases of COVID-19"},{"metadata":{},"cell_type":"markdown","source":"<h3> Digging down further for analyses </h3>\n\nWe observe COVID-19 Confirmed Cases saturation for countries like China, South Korea and Japan. Hence we look much deep into the dataset of Confrimed cases for these countries to understand it in a better context. Also various data measures available from the UNCOVER dataset are taken into consideration.\n\n<h3> Analysis with the China COVID-19 Cases </h3>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Reading the dataset\nsearch_data_china = country_grouped_covid['Country/Region'] == 'Mainland China'       \nchina_data = country_grouped_covid[search_data_china]\n\n#Viewing the dataset\nchina_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('../input/china-geo-json/china_geojson.json') as json_file:\n    china = json.load(json_file)\n    \n\n#GroupingBy the dataset for the map\n\nformated_gdf = china_data.groupby(['ObservationDate', 'Province/State'])['Confirmed', 'Deaths', 'Recovered'].max()\nformated_gdf = formated_gdf.reset_index()\nformated_gdf['Date'] = pd.to_datetime(formated_gdf['ObservationDate'])\nformated_gdf['Date'] = formated_gdf['Date'].dt.strftime('%m/%d/%Y')\n\nformated_gdf['log_ConfirmedCases'] = np.log(formated_gdf.Confirmed + 1)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3> Analogies </h3>\n\nAs observed in the Hubei province a much similar trends are seen over the Last week of Feb - Early March during the period of which the cases stabilizes. We again confirm with plotting of all the provinces in China which I'd already done as saved as image for this dataset.\n\n<h3> Plotting data for China Provinces </h3>"},{"metadata":{"trusted":true},"cell_type":"code","source":"%pylab inline\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nplt.figure(figsize=(15,5))\nimg=mpimg.imread('../input/china-covid19-data/Anhui.png')\nimgplot = plt.imshow(img)\nplt.show()\n\nplt.figure(figsize=(15,5))\nimg=mpimg.imread('../input/china-covid19-data/Beijing.png')\nimgplot = plt.imshow(img)\nplt.show()\n\nfor i in range(1,17):\n    plt.figure(figsize=(15,5))\n    img=mpimg.imread('../input/china-covid19-data/Screenshot ({}).png'.format(303+i))\n    imgplot = plt.imshow(img)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3> Deciphering the pattern </h3>\n\n1. We observe past 22-02-2012 to 28-02-2020, cases in China stabilizes, post which not new much cases are reported. \n2. The pattern goes on same for all the provinces of China.\n\n<h3> Hunting down for the Possible Causes </h3>\n\n1. We look through the entire section of data available under uncover section to search for the events that occured in China during the period.\n2. I'll update this section regualrly with new analyses to get the best possible reasons out for this saturation curve. \n\n<h3> Analysis of Stragegical Factors that Might have contributed to the case stabilization </h3>\n\nWe take help of the the pivotui tool to create a filterable drage and drop dataset to customize the views for mitigation measures taken across world. The tool's install command is uploaded into the libraries section of this notebook.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Importing the dataset\nmitigation_policies = pd.read_csv(\"/kaggle/input/uncover/UNCOVER/HDE/acaps-covid-19-government-measures-dataset.csv\")\n\n#Generating the pivoting toolkit\npivot_ui(mitigation_policies)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3> Using the tool generated above. </h3>\n\n1. We could select values - (say, country/region add drag it to the 2nd column box \n2. The value measure is dragged to the 2nd column to generate country wise view of the mitigation measures taken.\n\nThis tool is highly customizable hence feel free to fork the notebook and incorporate the tool in your analyses."},{"metadata":{},"cell_type":"markdown","source":"<h3> Analysis of Social Measures adopted in China </h3>\n\nFrom the above analyses we observe the following trends in China"},{"metadata":{},"cell_type":"markdown","source":"<iframe src='https://flo.uri.sh/visualisation/2038617/embed' frameborder='0' scrolling='no' style='width:100%;height:600px;'></iframe><div style='width:100%!;margin-top:4px!important;text-align:right!important;'><a class='flourish-credit' href='https://public.flourish.studio/visualisation/2038617/?utm_source=embed&utm_campaign=visualisation/2038617' target='_top' style='text-decoration:none!important'><img alt='Made with Flourish' src='https://public.flourish.studio/resources/made_with_flourish.svg' style='width:105px!important;height:16px!important;border:none!important;margin:0!important;'> </a></div>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Analysis for all the important keywords from the dataset\n\nplt.figure(figsize=(15,20))\nframe1 = plt.gca()\n\n\nimg=mpimg.imread('../input/china-covid19-data/Word Art.png')\nframe1.axes.get_xaxis().set_visible(False)\nframe1.axes.get_yaxis().set_visible(False)\nimgplot = plt.imshow(img)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3> Understanding the Chinese Government Action Plan </h3>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#We load one more dataset avaialable on Mitigation measures to analyze the cases vs mitigation  measures adopted.\nmitigation_measures_tot = pd.read_csv('../input/covid19-containment-and-mitigation-measures/COVID 19 Containment measures data.csv')\n\n#Generating the pivoting toolkit\npivot_ui(mitigation_measures_tot)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# What was the amount of measures taken by China during the initial days of COVID-19?"},{"metadata":{},"cell_type":"markdown","source":"<h3> 1. Government Rapid Action Implementation </h3>\n\nThe first case of Covid-19 was reported in 18th December 2020. Though the disease wasn't clear at the moment and it was spelled as \"Viral Pneumonia\", complusory isolation and confirmed case isolations were adopted and this measure forced by the government was implemented in Hubei province in Wuhan. Domestic Travel restrictions were sooner placed.\n\nDuring the initial stages, lockdown imposed. State of emergency was declared in China on January 20th. Further health care systems were rapidly boosted to ensure the curve of COVID-19 stays flat are hospitals arent under stress.\n\n<h3> 2. Did the mitigation measures in China helped to reduce the COVID-19 Cases which might have been higher? </h3>\n\nTo look forward with this we analyze the day of adoption of a mitigation measure in China vs. the actual case count. For this task the above dataset is concatenated for the daily cases report for that day and further analysis is done over the resultant dataset.\n\n<iframe src='https://flo.uri.sh/visualisation/2053680/embed' frameborder='0' scrolling='no' style='width:100%;height:600px;'></iframe><div style='width:100%!;margin-top:4px!important;text-align:right!important;'><a class='flourish-credit' href='https://public.flourish.studio/visualisation/2053680/?utm_source=embed&utm_campaign=visualisation/2053680' target='_top' style='text-decoration:none!important'><img alt='Made with Flourish' src='https://public.flourish.studio/resources/made_with_flourish.svg' style='width:105px!important;height:16px!important;border:none!important;margin:0!important;'> </a></div>"},{"metadata":{},"cell_type":"markdown","source":"<h3> Analysis from the graph above </h3>\n\nWe plot the number of social measures and mitigation policies adopted across China and plotted them against the growth rate of new confirmed cases in China. Hubei (the outbreak) location in China was excluded from the analyses as it might saturate the cases. I guess the social measures are taken as to prevent the newer infection across newer locations so that there is no communal spread of the virus. Hence we exclude the outbreak location and plot the graph.\n\n1. We observe the Growth of cases in China (excluding Hubei) on Feb 1, 2020 was 20.42%\n2. Post this mark the level and growth rate of cases declined.\n3. A high amount of social measures were taken across the China during this period. \n4. This might have further contributed to decline of COVID-19 virus to reach newer locations."},{"metadata":{},"cell_type":"markdown","source":"<h3> What the world saw in mitigation measures? </h3>\n\nWe take help of various open source charts and analyses available on Statista as the data for analyses of the trends are insufficient to draw conclusions from it. The following are the details that we would look over."},{"metadata":{},"cell_type":"markdown","source":"<iframe src='https://flo.uri.sh/visualisation/2048271/embed' frameborder='0' scrolling='no' style='width:100%;height:600px;'></iframe><div style='width:100%!;margin-top:4px!important;text-align:right!important;'><a class='flourish-credit' href='https://public.flourish.studio/visualisation/2048271/?utm_source=embed&utm_campaign=visualisation/2048271' target='_top' style='text-decoration:none!important'><img alt='Made with Flourish' src='https://public.flourish.studio/resources/made_with_flourish.svg' style='width:105px!important;height:16px!important;border:none!important;margin:0!important;'> </a></div>"},{"metadata":{},"cell_type":"markdown","source":"\n<h3> The extent till which lockdown restricted people movement across Eurpoean Unioun </h3>\n\n<iframe src='https://flo.uri.sh/visualisation/2049461/embed' frameborder='0' scrolling='no' style='width:100%;height:600px;'></iframe><div style='width:100%!;margin-top:4px!important;text-align:right!important;'><a class='flourish-credit' href='https://public.flourish.studio/visualisation/2049461/?utm_source=embed&utm_campaign=visualisation/2049461' target='_top' style='text-decoration:none!important'><img alt='Made with Flourish' src='https://public.flourish.studio/resources/made_with_flourish.svg' style='width:105px!important;height:16px!important;border:none!important;margin:0!important;'> </a></div> "},{"metadata":{},"cell_type":"markdown","source":"<h3> Understanding Mitigation Measures Across Europe </h3>\n\n<h4> Reduction in citizen movement across places during COVID-19 lockdown </h4>\n\n<img src=\"https://www.statista.com/graphic/1/1106086/european-city-movements-during-coronavirus-outbreak.jpg\" alt=\"Statistic: Percentage of people moving in selected European cities in the week ending March 22, 2020 compared to typical period prior to coronavirus outbreak* | Statista\" style=\"width: 100%; height: auto !important; max-width:1000px;-ms-interpolation-mode: bicubic;\"/></a>\n\n"},{"metadata":{},"cell_type":"markdown","source":"In the following graph obtained above, we see still notice people movement in the cities that today has the highest COVID-19 Cases across Europe, even if lockdown and restrictions were imposed on these cities. Under the PART 2 of this analyses, I would try to look ahead with how these factors affects COVID-19 Mortalities."},{"metadata":{},"cell_type":"markdown","source":"# PART 2 - How Mobility Factors affects COVID-19 Mortality?"},{"metadata":{},"cell_type":"markdown","source":"<h3> About Google's COVID-19 Mobility Data </h3>\n\n\"The data show how visits and length of stayat different places change compared to a baseline. The calculation of these changes is done using thesame kind of aggregated and anonymised dataused to show popular times for places in Google Maps. Changes for each day are compared to a baseline value for that day of the week:\n\n● The baseline is the median value, for the corresponding day of the week, during the fiveweek period 3 Jan – 6 Feb 2020.  \n● The reports show trends over several weeks.\" - Sources : https://www.google.com/covid19/mobility/\n\n<h3> What the data contains? </h3>\n\nThe data contains the details about the increase/reduction of Mobility by people across regions. The categories on which this is measured are:\n\n* **Retail and Recreation** : Mobility trends for places such as restaurants, cafés, shopping centres,theme parks, museums, libraries and cinemas.\n* **Supermarket and Pharmacy** : trends for places such as supermarkets, food warehouses, farmers markets, specialty foodshops and pharmacies.\n* **Parks** : Mobility trends for places like national parks, public beaches, marinas, dog parks, plazas and public gardens.\n* **Public Transport** : Mobility trends for places that are public transport hubs, such as underground, bus and train stations.\n* **Workplaces** : Mobility trends for places of work.\n* **Residential** : Mobility trends for places of residence.\n\n\n\n\n"},{"metadata":{},"cell_type":"markdown","source":"<h3> Observing the Trends - Graphical Case Study : Italy </h3>"},{"metadata":{},"cell_type":"markdown","source":"<img src=\"https://www.statista.com/graphic/1/1109402/mobility-trend-in-retail-and-recreation-during-coronavirus-italy.jpg\" alt=\"Statistic: Percentage change in visits to retail and recreation facilities by mobile users during coronavirus (COVID-19) in Italy in selected months of 2020, by region | Statista\" style=\"width: 100%; height: auto !important; max-width:1000px;-ms-interpolation-mode: bicubic;\"/></a>"},{"metadata":{},"cell_type":"markdown","source":"<h3> Understanding the Trends </h3>\n\nA greater percentage of reduction in mobility trends for recreation were seen across Italy in March and April, however Post April, lesser percentage of reduction in mobility activities due to COVID-19 was observed in Italy. When we compare this with Mortality across months due to COVID-19 in Italy (in the graph below) we observe increase in Mortality rates after April in Italy (the country that had the highest mortality rate during these months, globally). In our later analyses we look forward much to understand mitigation measures vs. mortality rates.\n\n<img src=\"https://www.statista.com/graphic/1/1076314/covid-19-case-fatality-rates-select-countries-worldwide.jpg\" alt=\"Statistic: Case fatality rates of COVID-19 in select countries worldwide from February 25 to August 17, 2020 | Statista\" style=\"width: 100%; height: auto !important; max-width:1000px;-ms-interpolation-mode: bicubic;\"/>"},{"metadata":{},"cell_type":"markdown","source":"<h3> Importing the Datasets </h3>\n\n**ECDC Dataset** : From OurWorldinData, speaks about population demographics and COVID Cases, Mortality and Deaths across countries.  \n**Google Mobility Trends Dataset** : Regarding Mobility Trends across countries.  \n**Isocodes Dataset** : For Fetching the unique codes for conutries. (Used for merging datasets)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Taking the Isocodes Data into consideration\n\nisocodes = pd.read_csv('../input/countries-iso-codes/wikipedia-iso-country-codes.csv')\nisocodes.columns = isocodes.columns.str.replace(' ', '_').str.lower()\nisocodes = isocodes.rename({\"english_short_name_lower_case\": 'country_name'}, axis=1)\n\n\n\n#ACAPS Data Import\n\nacaps = pd.read_csv('../input/uncover/RDSC-07-30-Update/RDSC-07-30-Update/HDE/acaps-covid-19-government-measures-dataset.csv')\nacaps.columns = acaps.columns.str.lower()\nacaps['date_implemented'] = pd.to_datetime(acaps['date_implemented'])\nacaps = acaps.merge(isocodes, left_on='iso', right_on='alpha-3_code')\n\n\n\n#Reading ECDC Dataset\n\necdc = (pd.read_csv('https://covid.ourworldindata.org/data/owid-covid-data.csv')\n        .assign(date=lambda f: f['date'].pipe(pd.to_datetime)))\nlocation_code = ecdc.groupby(['location', 'iso_code']).first().iloc[:, 0].reset_index().iloc[:,:2]\n\n\n\n#Reading Google Mobility Trends Dataset and structuring it to be used foe analyses\n\ndef fetch_google(isocodes, location_code):\n    google_mobility = pd.read_csv('https://www.gstatic.com/covid19/mobility/Global_Mobility_Report.csv', parse_dates=['date'])\n\n    def safe_match(pat, text):\n        match = re.match(pat, text)\n        return match.groups()[0] if match else text\n\n    google_mobility.columns = google_mobility.columns.map(lambda col: safe_match(\"(.*)_percent\", col))\n    google_mobility = (google_mobility\n                .merge(isocodes, left_on='country_region_code', right_on='alpha-2_code', how='left')\n                .merge(location_code, left_on='alpha-3_code', right_on='iso_code', how='left'))\n\n    google_mobility = google_mobility.loc[lambda f: f['sub_region_1'].isna()].set_index(['iso_code', 'date']).select_dtypes(float).div(100)\n    return google_mobility\n\ngoogle = fetch_google(isocodes, location_code)\ngoogle.reset_index(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3> Wrangling the Datasets </h3>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Taking only necessary columns from ECDC Dataset.\necdc = ecdc[['iso_code', 'continent', 'location', 'date', 'total_cases', 'total_deaths']]\n            \n#Making a column to calculate mortalilty rate.\necdc['mortality'] = ecdc['total_deaths']/ecdc['total_cases']*100\n\n#Merging the Google Mobility Dataset and ECDC Dataset\nmitigation = pd.merge(google,ecdc,how='inner',on=['iso_code','date'])\n\n#Replacing NaN Values with 0 \nmitigation['mortality'].replace(np.nan,0,inplace=True)\n\n#Viewing the dataset\nmitigation.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3> How Mortality Rates differ Across Continents? </h3>\n\nUnder this section we would know how mortality rates had varied across continents and how the rates are dependent on Mitigation Measures. (Continent Level)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Finding the mortality of all the countries mentioned in the mitigation dataset\nmitigation_mortality = mitigation[mitigation['date'] == '2020-12-25']\nprint('In the Dataset we have {} Countries'.format(mitigation_mortality.shape[0]))\n\n#Grouping the data continent wise\ncontinent_wise = mitigation_mortality.groupby(by=['continent']).mean(['mortality'])\ncontinent_wise","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3> Graph 1 : Mortality in COVID-19 across Continents. (As of December 25th, 2020) </h3>\n    \n\n<iframe src='https://flo.uri.sh/visualisation/4816090/embed' title='Interactive or visual content' frameborder='0' scrolling='no' style='width:100%;height:600px;'></iframe><div style='width:100%!;margin-top:4px!important;text-align:right!important;'><a class='flourish-credit' href='https://public.flourish.studio/visualisation/4816090/?utm_source=embed&utm_campaign=visualisation/4816090' target='_top' style='text-decoration:none!important'><img alt='Made with Flourish' src='https://public.flourish.studio/resources/made_with_flourish.svg' style='width:105px!important;height:16px!important;border:none!important;margin:0!important;'> </a></div>"},{"metadata":{},"cell_type":"markdown","source":"<h3> Graph 2 : The Amount by which Mobility Factors were related to COVID-19 Mortalities. (Continent Level: Mortality Rates as of 25th December, 2020) </h3>\n\n* We observe that tough Europe has the least mortality rate, there was very less mobility on the public places, strict mobility restrictions were seen on retail and transit however.\n\n* South America, that has the highest mortality has all mobility restrictions and reductions unders place which are strict yet a surge in mortality were seen.\n\nHence its evident that we can't generalize a trend on a continent scale regarding the mobility patterns and mortality in COVID-19.\n    \n\n<iframe src='https://flo.uri.sh/visualisation/4816224/embed' title='Interactive or visual content' frameborder='0' scrolling='no' style='width:100%;height:600px;'></iframe><div style='width:100%!;margin-top:4px!important;text-align:right!important;'><a class='flourish-credit' href='https://public.flourish.studio/visualisation/4816224/?utm_source=embed&utm_campaign=visualisation/4816224' target='_top' style='text-decoration:none!important'><img alt='Made with Flourish' src='https://public.flourish.studio/resources/made_with_flourish.svg' style='width:105px!important;height:16px!important;border:none!important;margin:0!important;'> </a></div>"},{"metadata":{},"cell_type":"markdown","source":"# Drilling Down to Country-Level\n\n<h3> Understanding the various mobility patterns vs the COVID-19 Mortality </h3>\n\nBelow are the set of some of Folium Charts generated, the charts can be:\n\n* Each chart is divided on Continent Level.\n* Charts can be drilled down to Country Level for countries that are found in each continent.\n* Under the filter option, filter can be applied to select data in chart. For e.g. Mortality and transit_restriction can be compared with each other.\n\nThese charts provide a good method to compare the people's mobility and how that has affected the COVID-19 Mortalities. The axes are:\n\n* The RHS Y-axis shows the % of increase or reduction in Mobility. (Values shown are /100. i.e a value of -0.6 denotes 60% reduction in mobility)\n* The LHS Y-axis shows the Mortality Rate / 100. i.e. a value of 0.02 shows 2% mortality rate of COVID-19.\n* Via the arrow keys, slides can be navigated to view the continent/region, and accordingly the country can be selected.\n"},{"metadata":{},"cell_type":"markdown","source":"<iframe src='https://flo.uri.sh/story/701267/embed' title='Interactive or visual content' frameborder='0' scrolling='no' style='width:100%;height:600px;'></iframe><div style='width:100%!;margin-top:4px!important;text-align:right!important;'><a class='flourish-credit' href='https://public.flourish.studio/story/701267/?utm_source=embed&utm_campaign=story/701267' target='_top' style='text-decoration:none!important'><img alt='Made with Flourish' src='https://public.flourish.studio/resources/made_with_flourish.svg' style='width:105px!important;height:16px!important;border:none!important;margin:0!important;'> </a></div>"},{"metadata":{},"cell_type":"markdown","source":"# Observations from Mobility vs COVID-19 Mortality\n\nVia the use of the tool, graphically and numerically the most recent mobility data can be viewed and can be compared easily with mortality rates of COVID-19. Some of the most evident findings from this section are:\n\n**For Retail and Recreational Mobility**\n\nCountries least affected seem to have maintained a low mobility of 20 percent from the baseline since the beginning of february. There seems to be a steady decline and the mobility towards these places has reduced to almost nil recently. All these countries seem to follow a similar curve. The countries worst affected have high mobilities to these places from the beginning, and dont seem to reduce much. Though some cases the mobility has reduced by 50 percent, it is gradual and there still seems to be 100 percent mobility above the baseline, even in recent times. We can see that France, Italy and Spain have reduced their mobility recently by almost 200 percent, but the US still seems to have higher mobility, which explains the rapidly increasing number of cases till date.\n\n\n**For Grocery and Pharmacy Mobility**\n\nThere is a low mobility in all the least affected countries right from the beginning. There is a slight peak in between, for New Zealand and australia, which might be explained by people deciding to buy essentials before the complete lockdown phase is initiated. It then remains quite low, with people probably going only if necessary. New Zealand sees a huge dip in mobility almost by 80 percent from baseline, which might be explained by the government mandating home deliveries of groceries and medicines, if required, after implementing of phase 4- complete lockdown. AMong the badly affected countries, while Spain, France and Italy, do see a slight dip in mobility, people in the US still seem to have widely varying mobilities, with most of it 50 percent above the baseline.\n\n\n**Mobility in Parks and Public Places**\n\nAll of the least affected countries seem to have consistently maintained low and reduced mobility to parks, except Finland. This has a rise in mobility,probably due to people wanting to go outside, yet maintain distance from other people. This probably did not affect the cases as much due to the large number of urban parks that can still function as spaces for people to visit, while adhering to social distancing norms.The US continues to see people going to parks more and more, probably as staying at home all day may add to wanting to go outdoors. Without strict lockdown measures, large numbers of people are able to move around and this number is extremely high. The other countries see a reduction in mobility to parks.\n\n\n**Transit Stations Mobility**\n\nThe countries least affected implemented travel bans almost immediately, sometimes even before the first cases were reported. They also implemented intra country transit bans unless absolutely necessary. New Zealand allows transport only after testing and making sure the person does not test positive, has had no contact with other positively tested individuals, and no recent travel history. These countries do see a reduction in transit, except in the US again. We see France, Italy and Spain have also stopped people from traveling to different places. But the US still has steady 50 percent above the baseline transit mobility.\n\n\n**General Conclusions**\n\nFrom all this, we can conclude, that social distancing is the key factor that determines the ability for a country to reduce the number of Covid-19 cases. In the countries least affected, there has been a rapid change in the behaviour of people with mobility reducing by 90 percent over all categories. It is important to acrue from this visualisation that countries which had initially mandated social distancing and followed through with strict implementation, have the least number of cases and a nearly flatlining growth rate of cases. The worst affected countries seem to have had late and relaxed implementation, which helps form a strong correlation to number of cases in the country. Overall, the reduction of mobility,even for essential services , has to be reduced drastically in order to contain the spread of Covid-19."},{"metadata":{},"cell_type":"markdown","source":"# PART 3 - Evaluation : Epidemiological Modelling\n\n<h3> What are we looking for? </h3>\n\nWe try to estimate the rates of COVID-19 using the data of reported infected, recovered and deceased cases in each country. Additionally, we used the effective reproduction number to quantify the effectiveness of taken measures and the impact of social interventions such as social lockdown or closure of schools on the number of reported infected cases in Germany, Italy and Spain. The general steps of our analysis are:\n\n* Building SEIR Model\n* Comparing the SEIR Model with respective dates w.r.t Mobility Data to understand what has happened during that tenure.\n\n**Special Thanks to resources under CORD-19 Challenge. The codes in this section were a result of the analyses done there by multiple contributors with slight adjustments.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Databank related functions:\n\ndef read_dataset(connection,min_date,max_date,country,region): \n    df = pd.DataFrame()\n    if (country == \"all\" or region == \"all\"):\n        cq = \"SELECT ROWID FROM DimCountry\"\n    else:              \n        cq = \"SELECT ROWID FROM DimCountry WHERE convert_name IN %s OR continent IN %s \"%(country,region) \n    cid = pd.read_sql_query(cq,connection)\n    sq = \"SELECT DISTINCT source_id FROM data\"\n    sid = pd.read_sql_query(sq,connection)\n    for n in range(cid.size):\n        for m in range(sid.size):\n            sql = \"SELECT \"\\\n                \"dc.country_code \"\\\n            \t\",dc.convert_name \"\\\n                \",dc.continent \"\\\n                \",dt.id \"\\\n            \t\",dt.date \"\\\n            \t\",CASE dt.day_of_week WHEN 1 THEN 'monday' \"\\\n            \t\"\t\t\t\t\t WHEN 2 THEN 'tuesday' \"\\\n            \t\"\t\t\t\t\t WHEN 3 THEN 'wednesday' \"\\\n            \t\"\t\t\t\t\t WHEN 4 THEN 'thursday' \"\\\n            \t\"\t\t\t\t\t WHEN 5 THEN 'friday' \"\\\n            \t\"\t\t\t\t\t WHEN 6 THEN 'saturday' \"\\\n            \t\"\t\t\t\t\t WHEN 7 THEN 'sunday' \"\\\n            \t\"\t\t\t\t\t ELSE 'n/a' END day_of_week \"\\\n            \t\",dt.cw calender_week \"\\\n            \t\",d.cases \"\\\n                \",d.deaths \"\\\n                \",d.recovered \"\\\n                \",d.cumulate_cases \"\\\n                \",d.cumulate_deaths \"\\\n                \",d.cumulate_recovered \"\\\n                \",ds.name source \"\\\n                \"FROM DimTime dt \"\\\n                \"LEFT JOIN data d ON d.time_id = dt.id AND country_id = %i AND d.source_id = %i \"\\\n                \"LEFT JOIN DimCountry dc ON dc.ROWID = %i \"\\\n                \"LEFT JOIN DimSource ds ON ds.id = %i \"\\\n                \"WHERE dt.date BETWEEN '%s' AND '%s' \"\\\n                \"ORDER by dt.date\"%(cid[\"rowid\"][n],sid[\"source_id\"][m],cid[\"rowid\"][n],sid[\"source_id\"][m],min_date,max_date)            \n            tmp = pd.read_sql_query(sql,connection)\n            df = pd.concat([tmp,df])    \n            \n    obj_columns = list(df.select_dtypes(include=['object']).columns.values)\n    df[obj_columns] = df[obj_columns].replace([None], np.nan)\n    return df\n\n\n# Database connection\npath = \"../input/covid19-database\"    # Path to the database\ndb = path + '/database.db'\nconn = sql.connect(db)                # SQL connection to the database\nmin_date = \"2020-03-20\"\nmax_date = \"2020-06-30\" \ndata = read_dataset(conn,min_date,max_date,('all'),()) \ndata","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The Dataset contains details about the cases, deaths, recoveries and their respective cumulative values on the basis of data, day-of-week. The source from which the data was extracted is also mentioned under the column name - 'Source'\n\n<h3> Making Functions and Fitting Models </h3>\n\n\nAn epidemiological compartmental model andused the Least Squares Error (LSE) method to fit the model to data. \n\n\nThis model consists of seven compartments of the population of a country <br>\n{$S(t), E(t), I(t), Q(t), R(t), D(t), P(t)$} denoting time by $t$, with the following states:\n*     $S\\rightarrow Susceptible$\n*     $E\\rightarrow Exposed$\n*     $I\\rightarrow Infected$\n*     $Q\\rightarrow Quarantined$\n*     $R\\rightarrow Recovered$\n*     $D\\rightarrow Deceased$\n*     $P\\rightarrow Insusceptible$    \n\nUsing this model, we assumed that a secondary infection in the investigated timespan is so unlikely that it does not warrant consideration here. Moreover the model is implemented under the assumption that every person with a positive test result goes to quarantine.\n\nThese states are connected via six transition parameters, each representing the rate of passing over from a state to the next one.\n\n* $\\alpha\\rightarrow$ Protection rate\n* $\\beta\\rightarrow$ Infection rate\n* $\\gamma\\rightarrow$ Inverse of the average latent time \n* $\\delta\\rightarrow$ The rate at which infectious people enter in quarantine\n* $\\lambda(t)\\rightarrow$ Time-dependent coefficient for recovery rate\n* $\\kappa(t)\\rightarrow$ Time-dependent coefficient for mortality rate\n\nDepending on whether the recovery or mortality rate in the corresponding timespan is ascending or descending, one of the three following functions is selected to fit the changes in the parameters:\n\n\\begin{equation*}\n \\lambda (t)=\\qquad\t\n \\left\\{\n \\begin{array}{c1}\n\t\\dfrac{\\lambda_{0}}{1 + e^{-\\lambda_{1} (t + \\lambda_{2})}}  \\\\ \\\\\n\t\\lambda_{0} + e^{-\\lambda_{1} (t + \\lambda_{2})} \\\\ \\\\\n    \\lambda_{0} e^{-\\lambda_{1} (t - \\lambda_{2})^{2}}\n \\end{array}\n\t\\right.\n\\end{equation*}\nwhere $\\lambda_{0}$, $\\lambda_{1}$ and $\\lambda_{2}$ are empirical coefficients. \n\n\\begin{equation*}\n \\kappa (t)=\\qquad\t\n \\left\\{\n \\begin{array}{c1}\n\t\\dfrac{\\kappa_{0}}{1 + e^{-\\kappa_{1} (t + \\kappa_{2})}}  \\\\ \\\\\n\t\\kappa_{0} + e^{-\\kappa_{1} (t + \\kappa_{2})} \\\\ \\\\\n    \\kappa_{0} e^{-\\kappa_{1} (t - \\kappa_{2})^{2}}\n \\end{array}\n\t\\right.\n\\end{equation*}\nwhere $\\kappa_{0}$, $\\kappa_{1}$ and $\\kappa_{2}$ are empirical coefficients. "},{"metadata":{},"cell_type":"markdown","source":"<H3> Priors for the transition parameters </H3>  \n\nAccording to the [Robert Koch Institute](https://edoc.rki.de/handle/176904/6547.2), we initialize the transition parameters $\\alpha$, $\\beta$ and $\\gamma$ with the values 0.05, 0.4, and 0.4. To initialize the coefficients $\\lambda_{0}$, $\\lambda_{1}$ and $\\lambda_{2}$ such as $\\kappa_{0}$, $\\kappa_{1}$ and $\\kappa_{2}$ we first fitted the model with data from the first ten days and then we perform the fitting for the whole dataset in ten days periods.\n\n\n<H3> Mathematical Modelling </H3>\n\nThe dynamics of the above states and transition parameters are mathematically characterized by ordinary differential equations (ODE) as follows:\n\\begin{equation*}\n \\qquad\t\n \\left\\{\n \\begin{array}{l0.5}\n\t\\dfrac{dS(t)}{dt} = -\\alpha S(t) - \\beta \\dfrac{S(t)I(t)}{N} \\\\ \n    \\dfrac{dE(t)}{dt} = -\\gamma E(t) + \\beta \\dfrac{S(t)I(t)}{N} \\\\ \n    \\dfrac{dI(t)}{dt} = \\gamma E(t) - \\delta I(t) \\\\ \n    \\dfrac{dQ(t)}{dt} = \\delta I(t) - \\lambda (t) Q(t) - \\kappa (t) Q(t) \\\\ \n    \\dfrac{dR(t)}{dt} = \\lambda (t) Q(t) \\\\ \n    \\dfrac{dD(t)}{dt} = \\kappa (t) Q(t) \\\\ \n    \\dfrac{dP(t)}{dt} = \\alpha S(t) \\\\ \n \\end{array}\n       \\right.\n\\end{equation*}\nwhere $N$ corresponds to the population of the considered country and it can be expressed as $S + E + I + Q + R + D + P = N$\n\n\n<H3> Effective Reproduction Number </H3>  \n\nThe effective reproduction number $R(t) = \\beta\\delta^{-1}S(t)/N$ is a strong tool to evaluate the intensity of interventions required to control the spread of the virus. Generally, $R(t)>1$ corresponds to $\\dfrac{dI(t)}{dt} + \\dfrac{dE(t)}{dt} >1$, which can be interpreted as the epidemical spread of disease. Similarly, $R(t)<1$ corresponds to controlling the spread of the disease."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Loading the datetime module again\n\nfrom datetime import datetime\n\n# Functions of equations\n\ndef getlambda(tspan, Q, R, initial_guess):\n    \"\"\"\n    Parameters\n    ----------\n    tspan : numpy.ndarray\n        time vector [days,].\n    Q : numpy.ndarray\n        time series of quarantiened cases [days,].\n    R : numpy.ndarray\n        time series of recovered cases [days,].\n    initial_guess: list\n        list of initial guess for the parameters lambda0, lambda1, lambda2\n        \n    Returns\n    -------\n    lambda0 : float\n        estimated value of lambda0.\n    lambda1 : float\n        estimated value of lambda1.\n    lambda2 : float\n        estimated value of lambda2.\n    lambdafun : function\n        estimation function for lambdafun(lambda0, lambda1, lambda2, time_span)\n\n    \"\"\"\n    if np.max(R)<20:                    # Assumption: Recovered cases less than 20 can either increase or decrease\n        lambdafun = lambda l0,l1,l2,t: l0 *np.exp(-(l1 *(t - l2)) **2)       # Hill-shaped sigmoide fuction\n        rate = (np.diff(R)/np.median(np.diff(tspan[:])))/Q[1:]\n        x = tspan[1:]\n        if initial_guess == []:  \n            lambda0 = np.max(rate)\n            lambda1 = 0.5\n            lambda2 = len(tspan)/2\n        else:\n            lambda0, lambda1, lambda2 = initial_guess\n        params = lmfit.Parameters()\n        if np.max(rate)< 1e-10:   # To prevent dividing by zero\n            params.add('lambda0',lambda0,min=0,max=1)\n            print('\\nWarning! Recovery rate is too low for Lambda estimation. Poor estimation is expected!\\n')\n        else:\n            params.add('lambda0',lambda0,min=0,max=np.max(rate))\n        params.add('lambda1',lambda1,min=0,max=1)\n        params.add('lambda2',lambda2,min=0,max=100)\n        res1 = lambda params, rate, x: lambdafun(params['lambda0'].value,params['lambda1'].value,params['lambda2'].value,x) - rate\n        \n        fit1 = lmfit.minimize(res1,params,args=(rate,x),method='least_squares')\n        lambda0 = fit1.params['lambda0'].value\n        lambda1 = fit1.params['lambda1'].value\n        lambda2 = fit1.params['lambda2'].value\n        # lmfit.report_fit(fit1)\n\n    else: \n        myfun1 = lambda l0,l1,l2,t: l0/(1+np.exp(-l1*(t-l2)))            # Ascending sigmoide function\n        myfun2 = lambda l0,l1,l2,t: l0 + np.exp(-l1 *(t + l2))           # Descending sigmoide function\n        myfun3 = lambda l0,l1,l2,t: l0 *np.exp(-(l1 *(t - l2)) **2)      # Hill-shaped sigmoide function\n    \n        rate = (np.diff(R)/np.median(np.diff(tspan[:])))/Q[1:]\n        x = tspan[1:]\n          \n        if initial_guess == []:  \n            lambda0 = np.max(rate)\n            lambda1 = 0.5\n            lambda2 = len(tspan)/2\n        else:\n            lambda0, lambda1, lambda2 = initial_guess\n            \n        params = lmfit.Parameters()\n        if np.max(rate)< 1e-10:   # To prevent dividing by zero\n            params.add('lambda0',lambda0,min=0,max=1)\n            print('\\nWarning! Recovery rate is too low for Lambda estimation. Poor estimation is expected!\\n')\n        else:\n            params.add('lambda0',lambda0,min=0,max=np.max(rate))\n  \n        params.add('lambda1',lambda1,min=0,max=1)\n        params.add('lambda2',lambda2,min=0,max=100)\n        res1 = lambda params, rate, x: myfun1(params['lambda0'].value,params['lambda1'].value,params['lambda2'].value,x) - rate\n        res2 = lambda params, rate, x: myfun2(params['lambda0'].value,params['lambda1'].value,params['lambda2'].value,x) - rate\n        res3 = lambda params, rate, x: myfun3(params['lambda0'].value,params['lambda1'].value,params['lambda2'].value,x) - rate\n        \n        fit1 = lmfit.minimize(res1,params,args=(rate,x),method='least_squares')\n        lf10 = fit1.params['lambda0'].value\n        lf11 = fit1.params['lambda1'].value\n        lf12 = fit1.params['lambda2'].value\n        lamda1 = myfun1(lf10,lf11,lf12,x)\n        dlambda1 = abs(lamda1[0]-lamda1[-1])\n        # lmfit.report_fit(fit1)\n        \n        fit2 = lmfit.minimize(res2,params,args=(rate,x),method='least_squares')\n        lf20 = fit2.params['lambda0'].value\n        lf21 = fit2.params['lambda1'].value\n        lf22 = fit2.params['lambda2'].value\n        lamda2 = myfun2(lf20,lf21,lf22,x)\n        dlambda2 = abs(lamda2[0]-lamda2[-1])\n        # lmfit.report_fit(fit2)\n        \n        fit3 = lmfit.minimize(res3,params,args=(rate,x),method='least_squares')\n        lf30 = fit3.params['lambda0'].value\n        lf31 = fit3.params['lambda1'].value\n        lf32 = fit3.params['lambda2'].value\n        lamda3 = myfun3(lf30,lf31,lf32,x)\n        dlambda3 = abs(lamda3[0]-lamda3[-1])\n        # lmfit.report_fit(fit2)\n        \n        if  (dlambda1>dlambda2) and (dlambda1>dlambda2):\n            lambdaGuess = [lf10,lf11,lf12]\n            lambdafun = myfun1\n\n        elif (dlambda2>dlambda1) and (dlambda2>dlambda3): \n            lambdaGuess = [lf20,lf21,lf22]\n            lambdafun = myfun2\n\n        else:\n            lambdaGuess = [lf30,lf31,lf32]\n            lambdafun = myfun3\n\n        lambda0, lambda1, lambda2 = lambdaGuess\n    return lambda0, lambda1, lambda2, lambdafun\n\n\ndef getkappa(tspan, Q, D, initial_guess):\n    \"\"\"\n    Parameters\n    ----------\n    tspan : numpy.ndarray\n        time vector [days,].\n    D : numpy.ndarray\n        time series of death cases [days,].\n    R : numpy.ndarray\n        time series of recovered cases [days,].\n    initial_guess: list\n        list of initial guess for the parameters kappa0, kappa1, kappa2\n    Returns\n    -------\n    lambda0 : float\n        estimated value of lambda0.\n    lambda1 : float\n        estimated value of lambda1.\n    lambda2 : float\n        estimated value of lambda2.\n    lambdafun : function\n        estimation function for lambdafun(lambda0, lambda1, lambda2, time_span)\n\n    \"\"\"\n    if np.max(D)<10:      # Assumption: Deceased cases less than 10 can either increase or decrease\n        kappafun = lambda k0,k1,k2,t: k0 *np.exp(-(k1 *(t - k2)) **2)   # Hill-shaped sigmoide function\n        rate = (np.diff(D)/np.median(np.diff(tspan[:])))/Q[1:]\n        x = tspan[1:]\n        if initial_guess == []:\n            kappa0 = np.max(rate)\n            kappa1 = 0.5\n            kappa2 = len(tspan)/2 \n        else:\n            kappa0, kappa1, kappa2 = initial_guess\n        params = lmfit.Parameters()\n        if np.max(rate)< 1e-10:   # To prevent dividing by zero\n            params.add('kappa0',kappa0,min=0,max=1)\n            print('\\nWarning! Mortality rate is too low for Kappa estimation. Poor estimation is expected!\\n')\n        else:\n            params.add('kappa0',kappa0,min=0,max=np.max(rate))\n  \n        params.add('kappa0',kappa0,min=0,max=np.max(rate))\n        params.add('kappa1',kappa1,min=0,max=1)\n        params.add('kappa2',kappa2,min=0,max=len(tspan))\n\n        res1 = lambda params, rate, x: kappafun(params['kappa0'].value,params['kappa1'].value,params['kappa2'].value,x) - rate\n        \n        fit1 = lmfit.minimize(res1,params,args=(rate,x),method='least_squares')\n        kappa0 = fit1.params['kappa0'].value\n        kappa1 = fit1.params['kappa1'].value\n        kappa2 = fit1.params['kappa2'].value\n        # lmfit.report_fit(fit1)\n\n\n    else:\n        myfun1 = lambda k0,k1,k2,t: k0 /(1 + np.exp(-k1 *(t - k2)))            # Ascending sigmoide function\n        myfun2 = lambda k0,k1,k2,t: k0 + np.exp(-k1 *(t + k2))                 # Descending sigmoide function\n        myfun3 = lambda k0,k1,k2,t: k0 *np.exp(-(k1 *(t - k2)) **2)            # Hill-shaped sigmoide function\n        rate = (np.diff(D)/np.median(np.diff(tspan[:])))/Q[1:]\n        x = tspan[1:]\n        if initial_guess == []:\n            kappa0 = np.max(rate)\n            kappa1 = 0.5\n            kappa2 = 2 \n        else:\n            kappa0, kappa1, kappa2 = initial_guess        \n        params = lmfit.Parameters()\n        if np.max(rate)< 1e-10:   # To prevent dividing by zero\n            params.add('kappa0',kappa0,min=0,max=1)\n            print('\\nWarning! Mortality rate is too low for Kappa estimation. Poor estimation is expected!\\n')\n        else:\n            params.add('kappa0',kappa0,min=0,max=np.max(rate))\n        params.add('kappa1',kappa1,min=0,max=1)\n        params.add('kappa2',kappa2,min=0,max=len(tspan))\n        res1 = lambda params, rate, x: myfun1(params['kappa0'].value,params['kappa1'].value,params['kappa2'].value,x) - rate\n        res2 = lambda params, rate, x: myfun2(params['kappa0'].value,params['kappa1'].value,params['kappa2'].value,x) - rate\n        res3 = lambda params, rate, x: myfun3(params['kappa0'].value,params['kappa1'].value,params['kappa2'].value,x) - rate\n\n        fit1 = lmfit.minimize(res1,params,args=(rate,x),method='least_squares')\n        kf10 = fit1.params['kappa0'].value\n        kf11 = fit1.params['kappa1'].value\n        kf12 = fit1.params['kappa2'].value\n        kappa1 = myfun1(kf10,kf11,kf12,x)\n        dkappa1 = abs(kappa1[0]-kappa1[-1])\n        # lmfit.report_fit(fit1)\n        \n        fit2 = lmfit.minimize(res2,params,args=(rate,x),method='least_squares')\n        kf20 = fit2.params['kappa0'].value\n        kf21 = fit2.params['kappa1'].value\n        kf22 = fit2.params['kappa2'].value\n        kappa2 = myfun2(kf20,kf21,kf22,x)\n        dkappa2 = abs(kappa2[0]-kappa2[-1])\n        # lmfit.report_fit(fit2)\n        \n        fit3 = lmfit.minimize(res3,params,args=(rate,x),method='least_squares')\n        kf30 = fit3.params['kappa0'].value\n        kf31 = fit3.params['kappa1'].value\n        kf32 = fit3.params['kappa2'].value\n        kappa3 = myfun2(kf30,kf31,kf32,x)\n        dkappa3 = abs(kappa3[0]-kappa3[-1])\n        # lmfit.report_fit(fit2)\n\n        if  dkappa1>dkappa2 and (dkappa1>dkappa3):\n            kappaGuess = [kf10,kf11,kf12]\n            kappafun = myfun1\n            # lmfit.report_fit(fit1)\n\n        elif (dkappa2>dkappa1) and (dkappa2>dkappa3): \n            kappaGuess = [kf20,kf21,kf22]\n            kappafun = myfun2\n            # report = lmfit.report_fit(fit2)\n\n        else:\n            kappaGuess = [kf30,kf31,kf32]\n            kappafun = myfun3\n            # report = lmfit.report_fit(fit3)\n            \n        kappa0, kappa1, kappa2 = kappaGuess\n    return kappa0, kappa1, kappa2, kappafun \n\ndef ode_model(conditions, time_span, alpha, beta, gamma, delta, lamda, kappa):\n    # For the range of Lambda\n    S, E, I, Q , R, D, P = conditions\n    N = S + E + I + Q + R + D + P\n    dSdt = -alpha*S - beta*S*I/N\n    dEdt = beta*S*I/N - gamma*E\n    dIdt = gamma*E - delta*I\n    dQdt = delta*I - lamda*Q - kappa*Q\n    dRdt = lamda*Q\n    dDdt = kappa*Q\n    dPdt = alpha*S\n    \n    dSdt = np.clip(dSdt, -N, N)\n    dEdt = np.clip(dEdt, -N, N)\n    dIdt = np.clip(dIdt, -N, N)\n    dQdt = np.clip(dQdt, -N, N)\n    dRdt = np.clip(dRdt, -N, N)\n    dDdt = np.clip(dDdt, -N, N)\n    dPdt = np.clip(dPdt, -N, N)\n    return [dSdt, dEdt, dIdt, dQdt, dRdt, dDdt, dPdt]\n\n\ndef SEIQRDP(initial_conditions, parameter_guess, lambdafun, kappafun, tspan):\n    \"\"\"\n    Parameters\n    ----------\n    initial_conditions : list\n        list of initial conditions and population [6,]\n        initial_conditions = [initE, initI, initQ, initR, initD, initN]\n    parameters_guess: lmfit.parameter.Parameters\n        initial guess of transition parameters\n    lambdafun: function\n        estimation function for lambdafun(lambda0, lambda1, lambda2, time_span)\n    kappafun: function\n        estimation function for lambdafun(kappa0, kappa1, kappa2, time_span)\n    tspan : numpy.ndarray\n        time vector [days,].\n\n    Returns\n    -------\n    ode results\n    \"\"\"\n    alpha = parameter_guess['alpha'].value\n    beta = parameter_guess['beta'].value\n    gamma = parameter_guess['gamma'].value\n    delta = parameter_guess['delta'].value\n    \n    lambda0 = parameter_guess['lambda0'].value\n    lambda1 = parameter_guess['lambda1'].value\n    lambda2 = parameter_guess['lambda2'].value\n    \n    kappa0 = parameter_guess['kappa0'].value\n    kappa1 = parameter_guess['kappa1'].value\n    kappa2 = parameter_guess['kappa2'].value\n\n    lamda = lambdafun(lambda0, lambda1, lambda2, tspan)\n    kappa = kappafun(kappa0, kappa1, kappa2, tspan)\n\n    model = initial_conditions\n    # ODE is solved using time-varying Lambda and Kappa parameters\n    for ii in range(1,len(lamda)):\n        t = [tspan[ii-1],tspan[ii]]\n        sol = odeint(ode_model, initial_conditions,\n                   t,\n                   args=(alpha, beta, gamma, delta, lamda[ii-1], kappa[ii-1])) \n        initial_conditions = [sol[1][0],sol[1][1],sol[1][2],sol[1][3],sol[1][4],sol[1][5],sol[1][6]]\n        model = np.vstack((model,sol[1]))\n    return model\n\ndef residual(parameter_guess, initial_conditions, QRD, lambdafun, kappafun, tspan):\n    sol = SEIQRDP(initial_conditions, parameter_guess, lambdafun, kappafun, tspan)\n    QRD_sim = np.vstack((sol[:,3],sol[:,4], sol[:,5]))\n    error = (QRD_sim-QRD).ravel()\n    return error\n\n\ndef model_fitting(alpha, beta, gamma, delta, lambdaGuess, kappaGuess, Q, R, D, initS, initE, initI, initP, tspan):\n    \n    initial_conditions = [initS,initE, initI, Q[0], R[0], D[0], initP]\n    QRD = np.vstack((Q,R,D))\n\n    recovery_rate = (np.diff(R)/np.median(np.diff(tspan[:])))/Q[1:]\n    death_rate = (np.diff(D)/np.median(np.diff(tspan[:])))/Q[1:]\n\n    lambda0, lambda1, lambda2, lambdafun = getlambda(tspan, Q, R, lambdaGuess) \n    kappa0, kappa1, kappa2, kappafun = getkappa(tspan, Q, D, kappaGuess)\n    \n    params = lmfit.Parameters()\n    params.add('alpha', value=alpha, vary=False, min=0, max=1)\n    params.add('beta', value=beta, vary=True, min=0, max=1)\n    params.add('gamma', value=gamma,  vary=False, min=0, max=1)\n    params.add('delta', value=delta, vary=True, min=0, max=1)\n    if max(recovery_rate)<1e-10:\n        params.add('lambda0', value=lambda0, vary=True, min=0, max=1)    \n    else:\n        params.add('lambda0', value=lambda0, vary=True, min=0, max=np.max(recovery_rate))\n    params.add('lambda1', value=lambda1, vary=True, min=0, max=1)\n    params.add('lambda2', value=lambda2,vary=True, min=0, max=len(tspan))\n    \n    if np.max(death_rate) == np.min(death_rate):\n        params.add('kappa0', value=kappa0, vary=True, min=0, max=1)\n    else:\n        params.add('kappa0', value=kappa0, vary=True, min=0, max=np.max(death_rate))\n    params.add('kappa1', value=kappa1, vary=True, min=0, max=1)\n    params.add('kappa2', value=kappa2,vary=True, min=0, max=len(tspan))\n    \n    fit = lmfit.minimize(residual,params,args=(initial_conditions, QRD, lambdafun, kappafun, tspan),\n                          method='least_squares')\n\n    \n    return fit, lambdafun, kappafun","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<H3> Fitting the Data and Predictive Tasks </H3>  \n\n\nFor this task, we used data from cumulative cases. Under assumption that every person with a positive test result goes to quarantine, we fitted our model to data in ten-day periods. The data from the last ten days is used to evaluate the fitting results and to predict the trend of changes in states and parameters in the subsequent days.\n\nTo this aim, we implemented the function `data_fit_prediction(min_date, max_date, country, region, N, conn)` with the follwing in- and outputs:\n-    In:\n    - min_date; Begin date of the timespan (string, format: yyyy-mm-dd)\n    - max_date; End date of the timespan (string, format: yyyy-mm-dd)\n    - country; Name of selected countries (tuple of strings)\n    - region; Name of selected region(s) (tuple of strings)\n    - N; population of selected countries (intiger)\n    - conn; SQL connection\n-    Out:\n    - S_f; Trend of changes in susceptible cases using fitted parameters\n    - I_f; Trend of changes in infected cases using fitted parameters\n    - Q; Quarantined cases from reported data\n    - Q_f; Trend of changes in quarantined cases using fitted parameters\n    - R; Recovered cases from reported data\n    - R_f; Trend of changes in recovered cases using fitted parameters\n    - D; Deceased cases from reported data\n    - D_f; Trend of changes in deceased cases using fitted parameters\n    - model_rest; List of predicted changes in model conditions\n    - beta; Changes in infection rate\n    - gamma; Inverse of latent time (fixed parameter)\n    - delta; Changes in infected to quarantined rate\n    - lambda; Recovery rate\n    - kappa; Mortality rate\n    - tspan_fit; Timespan of fitting\n    - tspan_pred; Timespan of prediction\n    - num_days; Total number of investigated timespan\n    - rest; mod(num_days,10)\n\nKnowing that the initial values of transition parameters may vary in different countries, we initialized the varying parameters such as, infection rate $\\beta$, infected to quarantined rate $\\delta$, recovery rate $\\lambda$, and mortality rate $\\kappa$, with a preliminary fitting with the data of the first ten days. "},{"metadata":{"trusted":true},"cell_type":"code","source":"def data_fit_prediction(min_date,max_date, country, region, N,  conn):\n    # Use query to get dataframe - Measure    \n    # Database query \n    if np.size(country) == 1:\n        countries = (country,'')\n    else:\n        countries = country\n    \n    if region == '':\n        region = ()\n    data = read_dataset(conn,min_date,max_date,countries,region)   \n    # cw_data = data.groupby(['calender_week']).mean()\n    day_data =data.groupby(data.index).mean()\n    \n    days = 10    # Data is analyzed in 10 days periods\n    rest = np.mod(len(day_data), days)\n    train_data = day_data[:-(10+rest)]\n    tspan_fit = len(train_data.index) - np.mod(len(train_data),days)\n    pred_data = day_data[-(10+rest):]\n    \n    # Assumption: Any person with a positive test result is in quarantine until their state changes.\n    Q = day_data['cumulate_cases'].values - day_data['cumulate_recovered'].values - day_data['cumulate_deaths'].values\n    R = day_data['cumulate_recovered'].values\n    D = day_data['cumulate_deaths'].values\n    I = day_data['cumulate_cases'].values\n    \n    # Memory reserve / Parameter initialization\n    beta = np.zeros(int(tspan_fit/days)+1)\n    beta[0] = 0.4\n    delta = np.zeros(int(tspan_fit/days)+1)\n    alpha = 0.05\n    gamma = 0.4\n    delta[0] = 0.04\n    lamda = []\n    kappa = []\n    \n    S_f = []\n    I_f = []\n    Q_f = []\n    D_f = []\n    R_f = []\n\n    jj = 1\n    \n    # Initial states in the corresponding country\n    Q_begin = Q[:days]\n    R_begin = R[:days]\n    D_begin = D[:days]\n    initI = gamma*I[0] \n    initE = (1-gamma)*I[0]\n    initP = alpha*N\n    initS = N - (initE + initI + Q_begin[0] + R_begin[0] + D_begin[0] + initP)\n    \n    # Initial values of parameters may vary in different countries. \n    # The aim of following fitting is to prevent wrong initialization of infection rate, infected to quarantined rate, recovery rate and mortality rate\n    tspan = np.linspace(0,days,days)\n    fit, lambdafun, kappafun = model_fitting(alpha, beta[0], gamma, delta[0],[],[], Q_begin, R_begin, D_begin, initS, initE, initI, initP, tspan)\n    beta[0] = fit.params['beta'].value\n    delta[0] = fit.params['delta'].value\n    lambdaGuess = [fit.params['lambda0'].value,fit.params['lambda1'].value,fit.params['lambda2'].value]\n    kappaGuess = [fit.params['kappa0'].value,fit.params['kappa1'].value,fit.params['kappa2'].value]\n\n    # Fitting in ten-day periods\n    for ii in range(0,tspan_fit,days):\n        tspan = np.linspace(0,days-1,days)\n        Q_fit = Q[ii:days+ii]\n        R_fit = R[ii:days+ii]\n        D_fit = D[ii:days+ii]\n        \n        fit, lambdafun, kappafun = model_fitting(alpha, beta[jj-1], gamma, delta[jj-1],lambdaGuess, kappaGuess, Q_fit, R_fit, D_fit, initS, initE, initI, initP, tspan)\n        #lmfit.report_fit(fit)\n        \n        # To prevent underfitting and adjust to sudden changes\n        if fit.params['beta'].value < 1e-7:\n            beta[jj] = beta[jj-1]\n        else:\n            beta[jj] = fit.params['beta'].value\n        \n        delta[jj] = fit.params['delta'].value\n        lambdaGuess = fit.params['lambda0'].value,fit.params['lambda1'].value,fit.params['lambda2'].value\n        lambda_tmp = days * [np.mean(lambdafun(lambdaGuess[0],lambdaGuess[1],lambdaGuess[2],tspan))]\n        lamda= np.hstack((lamda,lambda_tmp))\n        kappaGuess = fit.params['kappa0'].value,fit.params['kappa1'].value,fit.params['kappa2'].value\n        kappa_tmp = days * [np.mean(kappafun(kappaGuess[0],kappaGuess[1],kappaGuess[2],tspan))]\n        kappa = np.hstack((kappa, kappa_tmp))\n        \n        # Updating the initial conditions\n        initial_conditions = [initS,initE, initI, Q_fit[0], R_fit[0], D_fit[0], initP]\n        model = SEIQRDP(initial_conditions, fit.params, lambdafun, kappafun, tspan)\n        S_f = np.hstack((S_f, model[:,0]))\n        I_f = np.hstack((I_f, model[:,2]))\n        Q_f = np.hstack((Q_f, model[:,3]))\n        R_f = np.hstack((R_f,model[:,4]))\n        D_f = np.hstack((D_f,model[:,5]))\n        jj +=1\n        initS = model[:,0][-1]\n        initE = model[:,1][-1]\n        initI = model[:,2][-1]\n        initP = model[:,6][-1]\n        \n    del jj   \n    \n\n    \n    \n    # Time dimension\n    num_days = len(day_data.index)\n    tspan_pred = np.linspace(0,len(pred_data), len(pred_data)+1)\n    # Prediction of rest + 10 days with the fitted parameters\n    initial_conditions = [initS,initE, initI, Q_f[-1], R_f[-1], D_f[-1], initP]\n    model_rest = SEIQRDP(initial_conditions,fit.params,lambdafun,kappafun,tspan_pred)\n    S_f = np.hstack((S_f,model_rest[:,0][:-1]))    \n    I_f = np.hstack((I_f,model_rest[:,2][:-1]))\n    \n    return S_f, I_f, Q, Q_f, R, R_f, D, D_f, model_rest, beta, gamma, delta, lamda, kappa, tspan_fit, tspan_pred, num_days, rest","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<H3> Understanding the Case of Germany </H3> \n\nWe would first plot our model, understand the reproduction rate of new cases and then compare it with mobility measures that were adopted during this tenure in Germany."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Building the Functions to select and query - Germany from the dataset\n\ncountry = 'Germany'\nregion = ''\nN = 83.02e06           # Population of Germany\nmin_date = \"2020-03-20\"\nmax_date = \"2020-06-30\" \n\nS_f, I_f, Q, Q_f, R, R_f, D, D_f, model_rest, beta, gamma,  delta, lamda, kappa, tspan_fit, tspan_pred, num_days, rest = data_fit_prediction(min_date,max_date, country, region, N,  conn)\n\nfirst_day = datetime.strptime(min_date, '%Y-%m-%d')\ndate_list = [first_day + timedelta(days=x) for x in range(0, num_days)]\nd_locator = mdates.DayLocator() \nfmt = mdates.DateFormatter('%b-%d')\nplt.style.use('fivethirtyeight') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting the data\n\nQ_f_rest = model_rest[:,3]\nR_f_rest = model_rest[:,4]\nD_f_rest = model_rest[:,5]\n\nfig,ax = plt.subplots(1,1,figsize=(12,8)) \n\nax.plot(date_list,Q,'d',color='dimgrey',label='Data')\nax.plot(date_list[:tspan_fit],Q_f,color='darkorange', lw=3,label='Quarantined cases')\nax.plot(date_list[tspan_fit-1:],Q_f_rest,'--',color='darkorange',lw=3) \nax.fill_between(date_list[:tspan_fit],0.875*Q_f,1.125*Q_f,alpha=0.3,color='orange') \nax.fill_between(date_list[tspan_fit-1:],0.875*Q_f_rest,1.125*Q_f_rest,alpha=0.3,color='orange') \nax.fill_between(date_list[tspan_fit-1:],0.93*Q_f_rest,1.07*Q_f_rest,alpha=0.4,color='orange') \n\nax.plot(date_list,I_f,color='darkmagenta', lw=3,label='Infected cases')\n\nax.plot(date_list,R,'d',color='dimgrey')\nax.plot(date_list[:tspan_fit],R_f,color='green', lw=3,label='Recovered cases')\nax.plot(date_list[tspan_fit-1:],R_f_rest,'--',color='green',lw=3) \nax.fill_between(date_list[:tspan_fit],0.875*R_f,1.125*R_f,alpha=0.3,color='limegreen') \nax.fill_between(date_list[tspan_fit-1:],0.875*R_f_rest,1.125*R_f_rest,alpha=0.3,color='limegreen') \nax.fill_between(date_list[tspan_fit-1:],0.93*R_f_rest,1.07*R_f_rest,alpha=0.4,color='limegreen') \n\nax.plot(date_list,D,'d',color='dimgrey')\nax.plot(date_list[:tspan_fit],D_f,color='red', lw=3,label='Fetalities')\nax.plot(date_list[tspan_fit-1:],D_f_rest,'--',color='red',lw=3) \nax.fill_between(date_list[:tspan_fit],0.875*D_f,1.125*D_f,alpha=0.3,color='salmon') \nax.fill_between(date_list[tspan_fit-1:],0.875*D_f_rest,1.125*D_f_rest,alpha=0.3,color='salmon') \nax.fill_between(date_list[tspan_fit-1:],0.93*D_f_rest,1.07*D_f_rest,alpha=0.4,color='salmon') \n\nax.set_title('Cases in '+country, fontsize=16)\nax.set_xlabel('Date', fontsize=14)\nax.autoscale(enable=True, axis='x', tight=True)\nax.legend()\nax.xaxis.set_minor_locator(d_locator)\nax.xaxis.set_major_formatter(fmt)\nfig.autofmt_xdate()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Understanding the Reproduction Number from the model\n\ns_fit = np.zeros((int(num_days/10)+1,))\njj = 0\nfor ii in range(0,len(S_f),10):\n    s_fit[jj] = np.mean(S_f[ii:ii+10])   \n    jj += 1\ndel jj\n# Calculating the reproduction number\nRt = beta*s_fit[:-1]/(delta*N)\n\n# I&Q vs R(t)\nfig, axes = plt.subplots(2, 1, figsize=(12, 8), gridspec_kw={'height_ratios': [3,7]})\n\nax = axes[1]\nax.plot(date_list[:num_days],Q,'d',color='dimgrey',label='Data')\nax.plot(date_list[:tspan_fit],Q_f,color='darkorange', lw=3,label='Quarantined cases')\nax.plot(date_list[tspan_fit-1:],Q_f_rest,'--',color='darkorange',lw=3) \nax.fill_between(date_list[:tspan_fit],0.875*Q_f,1.125*Q_f,alpha=0.3,color='orange') \nax.fill_between(date_list[tspan_fit-1:],0.875*Q_f_rest,1.125*Q_f_rest,alpha=0.3,color='orange') \nax.fill_between(date_list[tspan_fit-1:],0.93*Q_f_rest,1.07*Q_f_rest,alpha=0.4,color='orange') \nax.set_title('Quarantined cases vs. Infected cases in '+country, fontsize=16)\nax.set_xlabel('Date', fontsize=14)\nax.plot(date_list,I_f,color='darkmagenta', lw=3,label='Infected cases')\nax.autoscale(enable=True, axis='x', tight=True)\nax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\nax.xaxis.set_minor_locator(d_locator)\nax.xaxis.set_major_formatter(fmt)\n\nax = axes[0]\nax.plot(date_list[0:tspan_fit:9], Rt)\nax.fill_between(date_list[0:tspan_fit:9],0.93*Rt,1.07*Rt,alpha=0.4,color='skyblue') \nax.plot(date_list[0:tspan_fit:9], len(date_list[0:tspan_fit:9])*[1],'--', color='royalblue', lw=1)\nax.set_title(r'Effective reproduction number in '+country+' - $R(t)$', fontsize=16)\nax.autoscale(enable=True, axis='x', tight=True)\nax.xaxis.set_minor_locator(d_locator)\nax.xaxis.set_major_formatter(fmt)\n\nfig.autofmt_xdate()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3> Looking in terms of Mobility Data - Germany </h3>\n\n<iframe src='https://flo.uri.sh/visualisation/4820480/embed' title='Interactive or visual content' frameborder='0' scrolling='no' style='width:100%;height:600px;'></iframe><div style='width:100%!;margin-top:4px!important;text-align:right!important;'><a class='flourish-credit' href='https://public.flourish.studio/visualisation/4820480/?utm_source=embed&utm_campaign=visualisation/4820480' target='_top' style='text-decoration:none!important'><img alt='Made with Flourish' src='https://public.flourish.studio/resources/made_with_flourish.svg' style='width:105px!important;height:16px!important;border:none!important;margin:0!important;'> </a></div>"},{"metadata":{},"cell_type":"markdown","source":"If we look more closely at the changes of infected and quarantined cases between March 20 and June 30, and compare them with the trend of changes in the effective reproduction number, we can draw two conclusions:\n* The increasing number of the infected cases in the beginning of April is controlled and begins to fall due to the social lockdown, and the reproduction number reaches $R(t)<1$\n* As in the beginning of May the number of infected cases begins to gradually increase, the obligatory social distancing and partial lockdown in Germany, which has been taken until 15. May, controls this rising trend. The latter can also be seen in the changes of effective reproduction number as its value decreases and remains below one."},{"metadata":{},"cell_type":"markdown","source":"<H3> Understanding the Case of Italy </H3> \n\nItaly was amongst one of the most affected countries in Europe that highlighted a very high mortality rate of COVID. Using similar as did in Germany, we would first plot our model, understand the reproduction rate of new cases and then compare it with mobility measures that were adopted during this tenure in Italy."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Building the Functions to select and query - Italy from the dataset\n\ncountry = 'Italy'\nregion = ''\nN = 60.36e06            # Population of Italy\nmin_date = \"2020-03-20\"\nmax_date = \"2020-06-30\" \n\nS_f, I_f, Q, Q_f, R, R_f, D, D_f, model_rest, beta, gamma,  delta, lamda, kappa, tspan_fit, tspan_pred, num_days, rest = data_fit_prediction(min_date,max_date, country, region, N,  conn)\n\nfirst_day = datetime.strptime(min_date, '%Y-%m-%d')\ndate_list = [first_day + timedelta(days=x) for x in range(0, num_days)]\nd_locator = mdates.DayLocator() \nfmt = mdates.DateFormatter('%b-%d')\nplt.style.use('fivethirtyeight') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotting the data\n\nQ_f_rest = model_rest[:,3]\nR_f_rest = model_rest[:,4]\nD_f_rest = model_rest[:,5]\n\nfig,ax = plt.subplots(1,1,figsize=(12,8)) \n\nax.plot(date_list,Q,'d',color='dimgrey',label='Data')\nax.plot(date_list[:tspan_fit],Q_f,color='darkorange', lw=3,label='Quarantined cases')\nax.plot(date_list[tspan_fit-1:],Q_f_rest,'--',color='darkorange',lw=3) \nax.fill_between(date_list[:tspan_fit],0.875*Q_f,1.125*Q_f,alpha=0.3,color='orange') \nax.fill_between(date_list[tspan_fit-1:],0.875*Q_f_rest,1.125*Q_f_rest,alpha=0.3,color='orange') \nax.fill_between(date_list[tspan_fit-1:],0.93*Q_f_rest,1.07*Q_f_rest,alpha=0.4,color='orange') \n\nax.plot(date_list,I_f,color='darkmagenta', lw=3,label='Infected cases')\n\nax.plot(date_list,R,'d',color='dimgrey')\nax.plot(date_list[:tspan_fit],R_f,color='green', lw=3,label='Recovered cases')\nax.plot(date_list[tspan_fit-1:],R_f_rest,'--',color='green',lw=3) \nax.fill_between(date_list[:tspan_fit],0.875*R_f,1.125*R_f,alpha=0.3,color='limegreen') \nax.fill_between(date_list[tspan_fit-1:],0.875*R_f_rest,1.125*R_f_rest,alpha=0.3,color='limegreen') \nax.fill_between(date_list[tspan_fit-1:],0.93*R_f_rest,1.07*R_f_rest,alpha=0.4,color='limegreen') \n\nax.plot(date_list,D,'d',color='dimgrey')\nax.plot(date_list[:tspan_fit],D_f,color='red', lw=3,label='Fetalities')\nax.plot(date_list[tspan_fit-1:],D_f_rest,'--',color='red',lw=3) \nax.fill_between(date_list[:tspan_fit],0.875*D_f,1.125*D_f,alpha=0.3,color='salmon') \nax.fill_between(date_list[tspan_fit-1:],0.875*D_f_rest,1.125*D_f_rest,alpha=0.3,color='salmon') \nax.fill_between(date_list[tspan_fit-1:],0.93*D_f_rest,1.07*D_f_rest,alpha=0.4,color='salmon') \n\nax.set_title('Cases in '+country, fontsize=16)\nax.set_xlabel('Date', fontsize=14)\nax.autoscale(enable=True, axis='x', tight=True)\nax.legend()\nax.xaxis.set_minor_locator(d_locator)\nax.xaxis.set_major_formatter(fmt)\nfig.autofmt_xdate()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Understanding the Reproduction Number from the model\n\ns_fit = np.zeros((int(num_days/10)+1,))\njj = 0\nfor ii in range(0,len(S_f),10):\n    s_fit[jj] = np.mean(S_f[ii:ii+10])   \n    jj += 1\ndel jj\n# Calculating the reproduction number\nRt = beta*s_fit[:-1]/(delta*N)\n\n\n#The Final Plot\n\nfig, axes = plt.subplots(2, 1, figsize=(12, 8), gridspec_kw={'height_ratios': [3,7]})\n\nax = axes[1]\nax.plot(date_list[:num_days],Q,'d',color='dimgrey',label='Data')\nax.plot(date_list[:tspan_fit],Q_f,color='darkorange', lw=3,label='Quarantined cases')\nax.plot(date_list[tspan_fit-1:],Q_f_rest,'--',color='darkorange',lw=3) \nax.fill_between(date_list[:tspan_fit],0.875*Q_f,1.125*Q_f,alpha=0.3,color='orange') \nax.fill_between(date_list[tspan_fit-1:],0.875*Q_f_rest,1.125*Q_f_rest,alpha=0.3,color='orange') \nax.fill_between(date_list[tspan_fit-1:],0.93*Q_f_rest,1.07*Q_f_rest,alpha=0.4,color='orange') \nax.set_title('Quarantined cases vs. Infected cases in '+country, fontsize=16)\nax.set_xlabel('Date', fontsize=14)\nax.plot(date_list,I_f,color='darkmagenta', lw=3,label='Infected cases')\nax.autoscale(enable=True, axis='x', tight=True)\nax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\nax.xaxis.set_minor_locator(d_locator)\nax.xaxis.set_major_formatter(fmt)\n\nax = axes[0]\nax.plot(date_list[0:tspan_fit:9], Rt)\nax.fill_between(date_list[0:tspan_fit:9],0.93*Rt,1.07*Rt,alpha=0.4,color='skyblue') \nax.plot(date_list[0:tspan_fit:9], len(date_list[0:tspan_fit:9])*[1],'--', color='royalblue', lw=1)\nax.set_title(r'Effective reproduction number in '+country+' - $R(t)$', fontsize=16)\nax.autoscale(enable=True, axis='x', tight=True)\nax.xaxis.set_minor_locator(d_locator)\nax.xaxis.set_major_formatter(fmt)\n\nfig.autofmt_xdate()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3> Looking in terms of Mobility Data - Italy </h3>   \n\n<iframe src='https://flo.uri.sh/visualisation/4821281/embed' title='Interactive or visual content' frameborder='0' scrolling='no' style='width:100%;height:600px;'></iframe><div style='width:100%!;margin-top:4px!important;text-align:right!important;'><a class='flourish-credit' href='https://public.flourish.studio/visualisation/4821281/?utm_source=embed&utm_campaign=visualisation/4821281' target='_top' style='text-decoration:none!important'><img alt='Made with Flourish' src='https://public.flourish.studio/resources/made_with_flourish.svg' style='width:105px!important;height:16px!important;border:none!important;margin:0!important;'> </a></div>\n"},{"metadata":{},"cell_type":"markdown","source":"Considering the changes of infected and quarantined cases in Italy and comparing them with the trend of changes of effective reproduction number in the corresponding timespan, we can see that the spreading of the virus is well controlled until about May 1, and the effective reproduction number had reached values less than one.\n\n\nHowever, as the number of quarantined cases decrease, the effective reproduction number increases rapidly and reaches values near to one, which may indicate the instant need for further social interventions such as social distancing."},{"metadata":{},"cell_type":"markdown","source":"# Next Big Steps - Conclusions\n\nThis notebook talks and studies about the Government strategies, People Mobility and how it has affected the Mortality and surge of cases in COVID-19. Under the BCG - AI Challenge, working over this alternate hypothesis, I tried to answer the various questions that may arise on these very strategies, as since Govt. Policies and policymakers are of the key people that would streamline COVID-19 Vaccination delivery and help the public in Pandemic escalation.\n\nThis notebook would be updated by me to check for much newer and diverse data to analyze more trends in spread of COVID-19 and understand it through the terms of more goverment strategies and olicies. I would love to further test on more datasets across countries. Would update the notebooks with the new findings.\nContact LinkedIn - https://www.linkedin.com/in/amankumar01/\n\nDo drop a comment if you wish to suggest something."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}