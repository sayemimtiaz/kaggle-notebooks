{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e137a255-49bf-837d-8511-a49e6c84aef7"},"outputs":[],"source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport xgboost\nimport math\nfrom __future__ import division\nfrom scipy.stats import pearsonr\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import cross_validation, tree, linear_model\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import explained_variance_score"},{"cell_type":"markdown","metadata":{"_cell_guid":"fae38191-489d-ba9c-858c-f0b09d028f13"},"source":"# 1. Exploratory Data Analysis"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fe625774-6184-5cb2-819c-ff840e08e392"},"outputs":[],"source":"# Read the data into a data frame\ndata = pd.read_csv('../input/kc_house_data.csv')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f9afd217-a50b-9f37-755d-072af53522ca"},"outputs":[],"source":"# Check the number of data points in the data set\nprint(len(data))\n# Check the number of features in the data set\nprint(len(data.columns))\n# Check the data types\nprint(data.dtypes.unique())"},{"cell_type":"markdown","metadata":{"_cell_guid":"c2021183-8a42-5787-bff7-da3181c08fb7"},"source":"- Since there are Python objects in the data set, we may have some categorical features. Let's check them. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"608870cd-16d1-0f6f-9594-603c455da8a5"},"outputs":[],"source":"data.select_dtypes(include=['O']).columns.tolist()"},{"cell_type":"markdown","metadata":{"_cell_guid":"a8199e20-8553-da22-4b75-99f6fbc60523"},"source":"- We only have the date column which is a timestamp that we will ignore."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c9d01805-192d-06f0-5e0a-aff8f7bb75bf"},"outputs":[],"source":"# Check any number of columns with NaN\nprint(data.isnull().any().sum(), ' / ', len(data.columns))\n# Check any number of data points with NaN\nprint(data.isnull().any(axis=1).sum(), ' / ', len(data))"},{"cell_type":"markdown","metadata":{"_cell_guid":"619e716e-efcf-3c50-3b5c-5b8826967619"},"source":"- The data set is pretty much structured and doesn't have any NaN values. So we can jump into finding correlations between the features and the target variable"},{"cell_type":"markdown","metadata":{"_cell_guid":"c041ee9f-937b-5df2-100c-4ef6d4f39c3d"},"source":"# 2. Correlations between features and target"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"71b41bea-27dc-ff5f-d2ba-caa214ed661a"},"outputs":[],"source":"features = data.iloc[:,3:].columns.tolist()\ntarget = data.iloc[:,2].name"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ccdb0159-6285-29e1-7ecc-fdd34442519c"},"outputs":[],"source":"correlations = {}\nfor f in features:\n    data_temp = data[[f,target]]\n    x1 = data_temp[f].values\n    x2 = data_temp[target].values\n    key = f + ' vs ' + target\n    correlations[key] = pearsonr(x1,x2)[0]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a5861b15-d8b3-76bf-9903-31995a68cd41"},"outputs":[],"source":"data_correlations = pd.DataFrame(correlations, index=['Value']).T\ndata_correlations.loc[data_correlations['Value'].abs().sort_values(ascending=False).index]"},{"cell_type":"markdown","metadata":{"_cell_guid":"df828a29-f738-a88c-996f-b14bfea07e3b"},"source":"- We can see that the top 5 features are the most correlated features with the target \"price\"\n- Let's plot the best 2 regressors jointly"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6c128db4-0179-cce8-44ec-d2ad8b300e1a"},"outputs":[],"source":"y = data.loc[:,['sqft_living','grade',target]].sort_values(target, ascending=True).values\nx = np.arange(y.shape[0])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d01ee728-764b-f67d-3293-73fbc673c159"},"outputs":[],"source":"%matplotlib inline\nplt.subplot(3,1,1)\nplt.plot(x,y[:,0])\nplt.title('Sqft and Grade vs Price')\nplt.ylabel('Sqft')\n\nplt.subplot(3,1,2)\nplt.plot(x,y[:,1])\nplt.ylabel('Grade')\n\nplt.subplot(3,1,3)\nplt.plot(x,y[:,2],'r')\nplt.ylabel(\"Price\")\n\nplt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"bb08193b-d54e-a4b6-00f9-ccd1b618b7af"},"source":"# 3. Predicting House Sales Prices"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6b5f6b66-bb8c-1142-84dc-a5b5542f6f6f"},"outputs":[],"source":"# Train a simple linear regression model\nregr = linear_model.LinearRegression()\nnew_data = data[['sqft_living','grade', 'sqft_above', 'sqft_living15','bathrooms','view','sqft_basement','lat','waterfront','yr_built','bedrooms']]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b696daf9-ce83-a581-c98f-13631b496108"},"outputs":[],"source":"X = new_data.values\ny = data.price.values"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"29fca21d-880e-6eb3-557d-b45035c32d26"},"outputs":[],"source":"X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y ,test_size=0.2)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"51cc9733-ce21-0a71-2bb4-531fb4f79213"},"outputs":[],"source":"regr.fit(X_train, y_train)\nprint(regr.predict(X_test))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8281a2cd-9c2b-27aa-554d-9a65f057bcd5"},"outputs":[],"source":"regr.score(X_test,y_test)"},{"cell_type":"markdown","metadata":{"_cell_guid":"8a1302a7-def8-1c23-fbcb-cda1bfd61dac"},"source":"- Prediction score is about 70 which is not really optimal"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e0e7cbaf-13a0-7d88-519d-a7857f2c4f36"},"outputs":[],"source":"# Calculate the Root Mean Squared Error\nprint(\"RMSE: %.2f\"\n      % math.sqrt(np.mean((regr.predict(X_test) - y_test) ** 2)))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"22c9f865-513a-3a37-9d62-bbd2c120d323"},"outputs":[],"source":"# Let's try XGboost algorithm to see if we can get better results\nxgb = xgboost.XGBRegressor(n_estimators=100, learning_rate=0.08, gamma=0, subsample=0.75,\n                           colsample_bytree=1, max_depth=7)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2a5002e9-d390-333e-bb38-0effd4972e20"},"outputs":[],"source":"traindf, testdf = train_test_split(X_train, test_size = 0.3)\nxgb.fit(X_train,y_train)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"96662a3d-4751-82dc-ba4a-05862a9f03e6"},"outputs":[],"source":"predictions = xgb.predict(X_test)\nprint(explained_variance_score(predictions,y_test))"},{"cell_type":"markdown","metadata":{"_cell_guid":"8865579e-b2e5-edef-5354-1613a414f7ec"},"source":"- Our accuracy is changing between 79%-84%. I think it is close to an optimal solution."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"54f7eb10-c65a-17b4-7a13-d65d78907ed4"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}