{"cells":[{"cell_type":"markdown","metadata":{},"source":"# Meta Kaggle: Kernel Only Competitions\n\nA quick query to see all kernel only competitions to date. Daily submission counts are now plotted too.\n\n## Contents\n\n * [Table of Kernel-Only Competitions ](#Table-of-Kernel-Only-Competitions-)\n * [Plot Rate of Kernel-Only Competitions Over Time](#Plot-Rate-of-Kernel-Only-Competitions-Over-Time)\n * [Plot Submission Counts](#Plot-Submission-Counts)\n * [Count Teams With Worst Score](#Count-Teams-With-Worst-Score)\n * [Conclusions](#Conclusions)\n"},{"cell_type":"code","execution_count":1,"metadata":{"_kg_hide-input":true},"outputs":[],"source":"import os, sys\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom IPython.display import HTML, Image, display"},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":"from jt_mk_utils import *"},{"cell_type":"code","execution_count":3,"metadata":{"_kg_hide-input":true},"outputs":[],"source":"plt.rc('figure', figsize=(15, 9))   \nplt.rc('font', size=14)   \nplt.style.use('bmh')"},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":"DATE_COLS = [\n    'EnabledDate', 'DeadlineDate', 'ProhibitNewEntrantsDeadlineDate',\n    'TeamMergerDeadlineDate', 'TeamModelDeadlineDate',\n    'ModelSubmissionDeadlineDate'\n]\ncomps = read_competitions()\ncomps['Days'] = (comps.DeadlineDate - comps.EnabledDate).dt.days\ncomps.shape"},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":"comps.columns"},{"cell_type":"markdown","metadata":{},"source":"**OnlyAllowKernelSubmissions** is the one we need; choose some other columns to show if you like :)"},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":"ko = comps.query('OnlyAllowKernelSubmissions').sort_values('DeadlineDate', ascending=False)\nko.shape"},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":"ko.DeadlineDate.dt.year.value_counts().sort_index()"},{"cell_type":"markdown","metadata":{},"source":"# Table of Kernel-Only Competitions "},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":"show = ['Slug', 'DeadlineDate', 'Days', 'TotalTeams', 'RewardType', 'RewardQuantity']\n\ndef make_clickable(val):\n    return f'<a href=\"https://www.kaggle.com/c/{val}\">{val}</a>'\n\nko.set_index('Title')[show].style.format({'RewardQuantity': lambda x: f'${x:.0f}', 'Slug': make_clickable})"},{"cell_type":"markdown","metadata":{},"source":"# Plot Rate of Kernel-Only Competitions Over Time\n\nActive competitions are not in the dataset (yet) so the drop at the end is not real"},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":"dates = comps.DeadlineDate.dt.strftime('%Y-%m')\ncomps.query('HostSegmentTitle!=\"InClass\"').groupby(dates).OnlyAllowKernelSubmissions.mean().plot();\nplt.ylabel('Fraction of Competitions')\nplt.title('Mean Rate of Competitions that are Kernel-Only');"},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":"teams = read_teams(filter=('CompetitionId', ko.Id)).set_index('Id')\nteams.shape"},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":"teams.count()"},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":"subs = read_csv_filtered(MKDIR / 'Submissions.csv', 'TeamId', teams.index).set_index('Id')\nparse_date(subs, 'SubmissionDate')\nsubs.shape"},{"cell_type":"markdown","metadata":{},"source":"# Plot Submission Counts\n\nIllustrate the growth or participation rate in these competitions over time. *Team Count* may look high - it includes all those who accepted the rules but did not submit.\n\nNote: Competitions that required re-runs of Kernels seem to have odd submission data...\n\ne.g.\n\n- PetFinder.my Adoption Prediction\n- Freesound Audio Tagging 2019\n- Quora Insincere Questions Classification\n- Jigsaw Unintended Bias in Toxicity Classification\n- iMet Collection 2019 - FGVC6\n- NFL Big Data Bowl\n\nIt seems original (public LB) submissions are not in the data, only the re-runs are here?"},{"cell_type":"code","execution_count":13,"metadata":{"_kg_hide-input":true},"outputs":[],"source":"for cid, df in teams.groupby('CompetitionId'):\n    comp = comps.query('Id==@cid').iloc[0]\n    sdf = subs[subs.TeamId.isin(df.index) & (subs.SubmissionDate <= comp.DeadlineDate)]\n    cdf = sdf.groupby('SubmissionDate').agg({'TeamId':['size', 'nunique']})\n    cdf.columns = ['Submissions', 'Unique Teams']\n    display(HTML(\n        f'<h1 id=\"{comp.Slug}\">{comp.Title}</h1>'\n        f'<ul>'\n        f'<li>Deadline Date: {comp.DeadlineDate}'\n        f'<li>Teams Ranked: {df.PublicLeaderboardRank.count()}'\n        f'<li>Team Count: {df.shape[0]}'\n        f'<li>Submission Count: {sdf.shape[0]}'\n        f'</ul>'\n        )\n    )\n    cdf.plot()\n    plt.title(f'{comp.Title} â€” Daily Submissions')\n    plt.ylabel('Count')\n    plt.grid(True, axis='both')\n    plt.show()"},{"cell_type":"markdown","metadata":{},"source":"# Count Teams With Worst Score\n\nThis is prompted by \n\n - [HuBMAP - Hacking the Kidney](https://www.kaggle.com/c/hubmap-kidney-segmentation)\n - [Human Protein Atlas - Single Cell Classification](https://www.kaggle.com/c/hpa-single-cell-image-classification)\n\nwhere many teams scored 0 on the private LB because of highly popular publicly shared code that silently failed\n\nNote that the first code competition\n\n - [Mercari Price Suggestion Challenge](https://www.kaggle.com/c/mercari-price-suggestion-challenge)\n \nwas a two stage competition but very similar: the stage 2 test set was multiple times bigger than in stage 1 and nearly 1/3 of teams failed to run, scoring 99"},{"cell_type":"code","execution_count":14,"metadata":{"_kg_hide-input":true},"outputs":[],"source":"teams_on_lb = teams.dropna(subset=['PrivateLeaderboardRank']).copy()\nworst_sub_ids = teams_on_lb.sort_values('PrivateLeaderboardRank').groupby('CompetitionId', sort=False).PrivateLeaderboardSubmissionId.last()\nworst_scores = worst_sub_ids.map(subs.PrivateScoreLeaderboardDisplay).dropna()\nteams_on_lb['PrivateScore'] = teams_on_lb.PrivateLeaderboardSubmissionId.map(subs.PrivateScoreLeaderboardDisplay)\nteams_on_lb['WorstScore'] = teams_on_lb.CompetitionId.map(worst_scores)\nteams_on_lb['IsWorst'] = teams_on_lb.eval('PrivateScore==WorstScore')"},{"cell_type":"code","execution_count":15,"metadata":{"_kg_hide-input":true},"outputs":[],"source":"stats = ['count', 'sum', 'mean']\ngb = teams_on_lb.groupby('CompetitionId')\ndf = gb['IsWorst'].agg(stats)\ndf['Score'] = worst_scores\ndf = df.join(comps.set_index('Id')[['Title', 'DeadlineDate']])\ndf = df.set_index('Title')\ndf = df.sort_values('mean', ascending=False)\ndf.style.bar(width=85, subset=stats, color='#47e87f').format({'sum': lambda x: f'{x:.0f}'})"},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":"plt.scatter(df.DeadlineDate.dt.date, df['mean'])\nplt.xlabel('DeadlineDate')\nplt.ylabel('Fraction of Teams')\nplt.title('Mean Rate of Teams with Worst Score');"},{"cell_type":"markdown","metadata":{},"source":"# Conclusions\n\nI don't think kernel-only competitions are going to go away!"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"nbformat":4,"nbformat_minor":1}