{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Importing libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom wordcloud import WordCloud\nimport re\n\nimport nltk\nfrom nltk.corpus import stopwords\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import confusion_matrix, f1_score, classification_report, accuracy_score","metadata":{"execution":{"iopub.status.busy":"2021-07-19T08:08:17.916024Z","iopub.execute_input":"2021-07-19T08:08:17.916912Z","iopub.status.idle":"2021-07-19T08:08:20.029847Z","shell.execute_reply.started":"2021-07-19T08:08:17.916756Z","shell.execute_reply":"2021-07-19T08:08:20.028482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading the dataset","metadata":{}},{"cell_type":"code","source":"true = pd.read_csv('../input/fake-and-real-news-dataset/True.csv')\nfake = pd.read_csv('../input/fake-and-real-news-dataset/Fake.csv')","metadata":{"execution":{"iopub.status.busy":"2021-07-19T08:08:20.031859Z","iopub.execute_input":"2021-07-19T08:08:20.032285Z","iopub.status.idle":"2021-07-19T08:08:23.104001Z","shell.execute_reply.started":"2021-07-19T08:08:20.032213Z","shell.execute_reply":"2021-07-19T08:08:23.102669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"true.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-07-19T08:08:23.106502Z","iopub.execute_input":"2021-07-19T08:08:23.10695Z","iopub.status.idle":"2021-07-19T08:08:23.139029Z","shell.execute_reply.started":"2021-07-19T08:08:23.106904Z","shell.execute_reply":"2021-07-19T08:08:23.137654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fake.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-07-19T08:08:23.141111Z","iopub.execute_input":"2021-07-19T08:08:23.141565Z","iopub.status.idle":"2021-07-19T08:08:23.156545Z","shell.execute_reply.started":"2021-07-19T08:08:23.141518Z","shell.execute_reply":"2021-07-19T08:08:23.155156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"true['label'] = 0\nfake['label'] = 1\n\n# Concatening the datasets\ndf = pd.concat([true, fake], ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-19T08:08:23.158665Z","iopub.execute_input":"2021-07-19T08:08:23.159225Z","iopub.status.idle":"2021-07-19T08:08:23.180503Z","shell.execute_reply.started":"2021-07-19T08:08:23.159163Z","shell.execute_reply":"2021-07-19T08:08:23.178793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2021-07-19T08:08:23.181954Z","iopub.execute_input":"2021-07-19T08:08:23.182441Z","iopub.status.idle":"2021-07-19T08:08:23.204362Z","shell.execute_reply.started":"2021-07-19T08:08:23.182372Z","shell.execute_reply":"2021-07-19T08:08:23.202649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<b> The dataset has 44,898 records and 5 columns. </b>","metadata":{}},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2021-07-19T08:08:23.206389Z","iopub.execute_input":"2021-07-19T08:08:23.206946Z","iopub.status.idle":"2021-07-19T08:08:23.2532Z","shell.execute_reply.started":"2021-07-19T08:08:23.206894Z","shell.execute_reply":"2021-07-19T08:08:23.252418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<b>Four columns are of object datatype and one column is integer.</b>","metadata":{}},{"cell_type":"code","source":"# Checking if any duplicate records are present\n\nduplicate=df[df.duplicated()] \nduplicate","metadata":{"execution":{"iopub.status.busy":"2021-07-19T08:08:23.255758Z","iopub.execute_input":"2021-07-19T08:08:23.256059Z","iopub.status.idle":"2021-07-19T08:08:23.63179Z","shell.execute_reply.started":"2021-07-19T08:08:23.25603Z","shell.execute_reply":"2021-07-19T08:08:23.630775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<b> There are 209 duplicate records in the dataset. </b>","metadata":{}},{"cell_type":"code","source":"# Removing duplicate records\n\ndf.drop_duplicates(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-19T08:08:23.63427Z","iopub.execute_input":"2021-07-19T08:08:23.63501Z","iopub.status.idle":"2021-07-19T08:08:23.945765Z","shell.execute_reply.started":"2021-07-19T08:08:23.634962Z","shell.execute_reply":"2021-07-19T08:08:23.945012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Again check if any duplicate records are left\n\nduplicate = df[df.duplicated()] \nduplicate","metadata":{"execution":{"iopub.status.busy":"2021-07-19T08:08:23.947492Z","iopub.execute_input":"2021-07-19T08:08:23.948179Z","iopub.status.idle":"2021-07-19T08:08:24.249268Z","shell.execute_reply.started":"2021-07-19T08:08:23.948134Z","shell.execute_reply":"2021-07-19T08:08:24.247969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<b>Hence, all duplicate records are removed.</b>","metadata":{}},{"cell_type":"code","source":"df.describe(include='object')","metadata":{"execution":{"iopub.status.busy":"2021-07-19T08:08:24.250896Z","iopub.execute_input":"2021-07-19T08:08:24.251272Z","iopub.status.idle":"2021-07-19T08:08:24.65659Z","shell.execute_reply.started":"2021-07-19T08:08:24.251241Z","shell.execute_reply":"2021-07-19T08:08:24.655288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking for null values\n\ndf.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-07-19T08:08:24.658094Z","iopub.execute_input":"2021-07-19T08:08:24.658423Z","iopub.status.idle":"2021-07-19T08:08:24.694021Z","shell.execute_reply.started":"2021-07-19T08:08:24.658368Z","shell.execute_reply":"2021-07-19T08:08:24.692707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<b>The dataset doesn't have any missing values.</b>","metadata":{}},{"cell_type":"code","source":"# Visualizing the disribution of true and fake news\n\nsns.countplot(df['label'])","metadata":{"execution":{"iopub.status.busy":"2021-07-19T08:08:24.696527Z","iopub.execute_input":"2021-07-19T08:08:24.696922Z","iopub.status.idle":"2021-07-19T08:08:24.856388Z","shell.execute_reply.started":"2021-07-19T08:08:24.696888Z","shell.execute_reply":"2021-07-19T08:08:24.85518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<b> The count of fake news is a bit more than true news. </b>","metadata":{}},{"cell_type":"markdown","source":"## Text Preprocessing","metadata":{}},{"cell_type":"code","source":"# Expanding contractions\n\n# Dictionary of English Contractions\ncontractions_dict = { \"ain't\": \"are not\",\"'s\":\" is\",\"aren't\": \"are not\",\n                     \"can't\": \"cannot\",\"can't've\": \"cannot have\",\n                     \"'cause\": \"because\",\"could've\": \"could have\",\"couldn't\": \"could not\",\n                     \"couldn't've\": \"could not have\", \"didn't\": \"did not\",\"doesn't\": \"does not\",\n                     \"don't\": \"do not\",\"hadn't\": \"had not\",\"hadn't've\": \"had not have\",\n                     \"hasn't\": \"has not\",\"haven't\": \"have not\",\"he'd\": \"he would\",\n                     \"he'd've\": \"he would have\",\"he'll\": \"he will\", \"he'll've\": \"he will have\",\n                     \"how'd\": \"how did\",\"how'd'y\": \"how do you\",\"how'll\": \"how will\",\n                     \"I'd\": \"I would\", \"I'd've\": \"I would have\",\"I'll\": \"I will\",\n                     \"I'll've\": \"I will have\",\"I'm\": \"I am\",\"I've\": \"I have\", \"isn't\": \"is not\",\n                     \"it'd\": \"it would\",\"it'd've\": \"it would have\",\"it'll\": \"it will\",\n                     \"it'll've\": \"it will have\", \"let's\": \"let us\",\"ma'am\": \"madam\",\n                     \"mayn't\": \"may not\",\"might've\": \"might have\",\"mightn't\": \"might not\", \n                     \"mightn't've\": \"might not have\",\"must've\": \"must have\",\"mustn't\": \"must not\",\n                     \"mustn't've\": \"must not have\", \"needn't\": \"need not\",\n                     \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\"oughtn't\": \"ought not\",\n                     \"oughtn't've\": \"ought not have\",\"shan't\": \"shall not\",\"sha'n't\": \"shall not\",\n                     \"shan't've\": \"shall not have\",\"she'd\": \"she would\",\"she'd've\": \"she would have\",\n                     \"she'll\": \"she will\", \"she'll've\": \"she will have\",\"should've\": \"should have\",\n                     \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\",\"so've\": \"so have\",\n                     \"that'd\": \"that would\",\"that'd've\": \"that would have\", \"there'd\": \"there would\",\n                     \"there'd've\": \"there would have\", \"they'd\": \"they would\",\n                     \"they'd've\": \"they would have\",\"they'll\": \"they will\",\n                     \"they'll've\": \"they will have\", \"they're\": \"they are\",\"they've\": \"they have\",\n                     \"to've\": \"to have\",\"wasn't\": \"was not\",\"we'd\": \"we would\",\n                     \"we'd've\": \"we would have\",\"we'll\": \"we will\",\"we'll've\": \"we will have\",\n                     \"we're\": \"we are\",\"we've\": \"we have\", \"weren't\": \"were not\",\"what'll\": \"what will\",\n                     \"what'll've\": \"what will have\",\"what're\": \"what are\", \"what've\": \"what have\",\n                     \"when've\": \"when have\",\"where'd\": \"where did\", \"where've\": \"where have\",\n                     \"who'll\": \"who will\",\"who'll've\": \"who will have\",\"who've\": \"who have\",\n                     \"why've\": \"why have\",\"will've\": \"will have\",\"won't\": \"will not\",\n                     \"won't've\": \"will not have\", \"would've\": \"would have\",\"wouldn't\": \"would not\",\n                     \"wouldn't've\": \"would not have\",\"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n                     \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\n                     \"y'all've\": \"you all have\", \"you'd\": \"you would\",\"you'd've\": \"you would have\",\n                     \"you'll\": \"you will\",\"you'll've\": \"you will have\", \"you're\": \"you are\",\n                     \"you've\": \"you have\"}\n\n# Regular expression for finding contractions\ncontractions_re=re.compile('(%s)' % '|'.join(contractions_dict.keys()))\n\n# Function for expanding contractions\ndef expand_contractions(text,contractions_dict=contractions_dict):\n    def replace(match):\n        return contractions_dict[match.group(0)]\n    return contractions_re.sub(replace, text)\n\n# Expanding Contractions in the title, text\ndf['title'] = df['title'].apply(lambda x:expand_contractions(x))\ndf['text'] = df['text'].apply(lambda x:expand_contractions(x))","metadata":{"execution":{"iopub.status.busy":"2021-07-19T08:08:24.857895Z","iopub.execute_input":"2021-07-19T08:08:24.858192Z","iopub.status.idle":"2021-07-19T08:08:57.766657Z","shell.execute_reply.started":"2021-07-19T08:08:24.858163Z","shell.execute_reply":"2021-07-19T08:08:57.765389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Converting text to lowercase\n\ndf['title'] = df['title'].apply(lambda x:x.lower())\ndf['text'] = df['text'].apply(lambda x:x.lower())","metadata":{"execution":{"iopub.status.busy":"2021-07-19T08:08:57.768143Z","iopub.execute_input":"2021-07-19T08:08:57.768477Z","iopub.status.idle":"2021-07-19T08:08:58.158348Z","shell.execute_reply.started":"2021-07-19T08:08:57.76844Z","shell.execute_reply":"2021-07-19T08:08:58.157042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Removing digits and words containing digits\n\ndf['title'] = df['title'].apply(lambda x: re.sub('\\w*\\d\\w*','', x))\ndf['text'] = df['text'].apply(lambda x: re.sub('\\w*\\d\\w*','', x))","metadata":{"execution":{"iopub.status.busy":"2021-07-19T08:08:58.160674Z","iopub.execute_input":"2021-07-19T08:08:58.161194Z","iopub.status.idle":"2021-07-19T08:09:24.875872Z","shell.execute_reply.started":"2021-07-19T08:08:58.161146Z","shell.execute_reply":"2021-07-19T08:09:24.874525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Removing punctuations\n\ndf['title'] = df['title'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\ndf['text'] = df['text'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))","metadata":{"execution":{"iopub.status.busy":"2021-07-19T08:09:24.880272Z","iopub.execute_input":"2021-07-19T08:09:24.880616Z","iopub.status.idle":"2021-07-19T08:09:29.49182Z","shell.execute_reply.started":"2021-07-19T08:09:24.880584Z","shell.execute_reply":"2021-07-19T08:09:29.490338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Removing extra spaces\n\ndf['title'] = df['title'].apply(lambda x: re.sub(' +',' ',x))\ndf['text'] = df['text'].apply(lambda x: re.sub(' +',' ',x))","metadata":{"execution":{"iopub.status.busy":"2021-07-19T08:09:29.493504Z","iopub.execute_input":"2021-07-19T08:09:29.493969Z","iopub.status.idle":"2021-07-19T08:09:36.419758Z","shell.execute_reply.started":"2021-07-19T08:09:29.493915Z","shell.execute_reply":"2021-07-19T08:09:36.41854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Applying lemmatization\n\nw_tokenizer = nltk.tokenize.WhitespaceTokenizer()\nlemmatizer = nltk.stem.WordNetLemmatizer()\n\ndef lemmatize_text(text):\n    rev = [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text) if w not in stopwords.words('english')]\n    rev = ' '.join(rev)\n    return rev\n\ndf['title'] = df.title.apply(lemmatize_text)\ndf['text'] = df.text.apply(lemmatize_text)","metadata":{"execution":{"iopub.status.busy":"2021-07-19T08:09:36.423099Z","iopub.execute_input":"2021-07-19T08:09:36.423464Z","iopub.status.idle":"2021-07-19T08:50:05.608842Z","shell.execute_reply.started":"2021-07-19T08:09:36.423429Z","shell.execute_reply":"2021-07-19T08:50:05.607652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Displaying title, text after cleaning\n\nprint(\"Title\\n\")\nfor index,text in enumerate(df['title'][0:3]):\n    print('Title %d:\\n'%(index+1), text)\n    \nprint(\"\\nText\\n\")\nfor index,txt in enumerate(df['text'][0:3]):\n    print('Text %d:\\n'%(index+1), txt)","metadata":{"execution":{"iopub.status.busy":"2021-07-19T08:50:05.611548Z","iopub.execute_input":"2021-07-19T08:50:05.611886Z","iopub.status.idle":"2021-07-19T08:50:05.624372Z","shell.execute_reply.started":"2021-07-19T08:50:05.611848Z","shell.execute_reply":"2021-07-19T08:50:05.622216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Wordcloud of title, text in True news\n\n# Cleaned dataframe of True labels\ndf_true = df[df.label == 0]\n\ntitle_true = \" \".join(tit for tit in df_true['title'])\ntext_true = \" \".join(txt for txt in df_true['text'])\n\nplt.figure(figsize=(40, 30))\n\n# Title\ntitle_cloud = WordCloud(collocations=False, background_color='black').generate(title_true)\nplt.subplot(1, 2, 1)\nplt.axis(\"off\")\nplt.title(\"Title\", fontsize=40)\nplt.imshow(title_cloud, interpolation='bilinear')\n\n# Title\ntext_cloud = WordCloud(collocations=False, background_color='black').generate(text_true)\nplt.subplot(1, 2, 2)\nplt.axis(\"off\")\nplt.title(\"Text\", fontsize=40)\nplt.imshow(text_cloud, interpolation='bilinear')","metadata":{"execution":{"iopub.status.busy":"2021-07-19T08:50:05.626798Z","iopub.execute_input":"2021-07-19T08:50:05.627268Z","iopub.status.idle":"2021-07-19T08:50:16.873426Z","shell.execute_reply.started":"2021-07-19T08:50:05.627218Z","shell.execute_reply":"2021-07-19T08:50:16.872254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<b> Common words in title:- </b>trump, korea, republican, house, russia, say, new, leader, white, senate, etc.\n\n\n<b> Common words in text:- </b>trump, state, republican, president, said, reuters, party, official, country, people, etc.","metadata":{}},{"cell_type":"code","source":"# Wordcloud of title, text in Fake news\n\n# Cleaned dataframe of Fake labels\ndf_fake = df[df.label == 1]\n\ntitle_fake = \" \".join(tit for tit in df_fake['title'])\ntext_fake = \" \".join(txt for txt in df_fake['text'])\n\nplt.figure(figsize=(40, 30))\n\n# Title\ntitle_cloud = WordCloud(collocations=False, background_color='black').generate(title_fake)\nplt.subplot(1, 2, 1)\nplt.axis(\"off\")\nplt.title(\"Title\", fontsize=40)\nplt.imshow(title_cloud, interpolation='bilinear')\n\n# Title\ntext_cloud = WordCloud(collocations=False, background_color='black').generate(text_fake)\nplt.subplot(1, 2, 2)\nplt.axis(\"off\")\nplt.title(\"Text\", fontsize=40)\nplt.imshow(text_cloud, interpolation='bilinear')","metadata":{"execution":{"iopub.status.busy":"2021-07-19T08:50:16.874723Z","iopub.execute_input":"2021-07-19T08:50:16.875096Z","iopub.status.idle":"2021-07-19T08:50:29.598525Z","shell.execute_reply.started":"2021-07-19T08:50:16.875066Z","shell.execute_reply":"2021-07-19T08:50:29.596961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<b> Common words in title:- </b>trump, video, watch, clinton, obama, tweet, president, woman, muslim, democrat, etc.\n\n\n<b> Common words in text:- </b>trump, people, said, president, new, obama, state, clinton, time, one, etc.","metadata":{}},{"cell_type":"code","source":"# Subject-wise distriution of news \n\nsns.countplot(df['subject'])\nplt.xticks(rotation=90)","metadata":{"execution":{"iopub.status.busy":"2021-07-19T08:50:29.602596Z","iopub.execute_input":"2021-07-19T08:50:29.602944Z","iopub.status.idle":"2021-07-19T08:50:29.878116Z","shell.execute_reply.started":"2021-07-19T08:50:29.60291Z","shell.execute_reply":"2021-07-19T08:50:29.876787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<b> Observations:- </b>\n\n<ul>\n    <li>Most of the news in the dataset is politicsNews.</li>\n    <li>It is followed by worldNews, News and politics.</li>\n    <li>Government News, US_News and Middle-east have less than 2000 records.</li>\n</ul>","metadata":{}},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"tf = TfidfVectorizer(max_features=3000, ngram_range=(1,4))\n\nX = tf.fit_transform(df['text']).toarray()\nX","metadata":{"execution":{"iopub.status.busy":"2021-07-19T08:50:29.880141Z","iopub.execute_input":"2021-07-19T08:50:29.880491Z","iopub.status.idle":"2021-07-19T08:54:14.419963Z","shell.execute_reply.started":"2021-07-19T08:50:29.880445Z","shell.execute_reply":"2021-07-19T08:54:14.418248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = df['label']","metadata":{"execution":{"iopub.status.busy":"2021-07-19T08:54:14.422912Z","iopub.execute_input":"2021-07-19T08:54:14.42341Z","iopub.status.idle":"2021-07-19T08:54:14.42922Z","shell.execute_reply.started":"2021-07-19T08:54:14.423338Z","shell.execute_reply":"2021-07-19T08:54:14.428342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Splitting the dataset into train and test \n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nprint(\"X_train:\", X_train.shape)\nprint(\"X_test:\", X_test.shape)\nprint(\"y_train:\", y_train.shape)\nprint(\"y_test:\", y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-19T08:54:14.431013Z","iopub.execute_input":"2021-07-19T08:54:14.431353Z","iopub.status.idle":"2021-07-19T08:54:14.832638Z","shell.execute_reply.started":"2021-07-19T08:54:14.431324Z","shell.execute_reply":"2021-07-19T08:54:14.831576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training the model using Naive Bayes classifier\n\nnb = MultinomialNB().fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-07-19T08:54:14.834206Z","iopub.execute_input":"2021-07-19T08:54:14.834526Z","iopub.status.idle":"2021-07-19T08:54:15.152305Z","shell.execute_reply.started":"2021-07-19T08:54:14.834493Z","shell.execute_reply":"2021-07-19T08:54:15.151179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Score of train data:\", nb.score(X_train, y_train))\nprint(\"Score of test data:\", nb.score(X_test, y_test))","metadata":{"execution":{"iopub.status.busy":"2021-07-19T08:54:15.15406Z","iopub.execute_input":"2021-07-19T08:54:15.154717Z","iopub.status.idle":"2021-07-19T08:54:15.559871Z","shell.execute_reply.started":"2021-07-19T08:54:15.154665Z","shell.execute_reply":"2021-07-19T08:54:15.558755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<b> The model performs well on train as well as test data. </b>","metadata":{}},{"cell_type":"code","source":"y_pred = nb.predict(X_test)\ny_pred","metadata":{"execution":{"iopub.status.busy":"2021-07-19T08:54:15.561608Z","iopub.execute_input":"2021-07-19T08:54:15.562277Z","iopub.status.idle":"2021-07-19T08:54:15.640617Z","shell.execute_reply.started":"2021-07-19T08:54:15.562228Z","shell.execute_reply":"2021-07-19T08:54:15.63951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# F1 score and accuracy\n\nf1_score = f1_score(y_test, y_pred, average='weighted')\naccuracy = accuracy_score(y_test, y_pred)\n\nprint(\"F1 Score:\", f1_score)\nprint(\"Accuracy Score:\", accuracy)","metadata":{"execution":{"iopub.status.busy":"2021-07-19T08:54:15.642592Z","iopub.execute_input":"2021-07-19T08:54:15.64321Z","iopub.status.idle":"2021-07-19T08:54:15.666458Z","shell.execute_reply.started":"2021-07-19T08:54:15.643161Z","shell.execute_reply":"2021-07-19T08:54:15.665306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Classification Report\n\nprint(classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-07-19T08:54:15.668097Z","iopub.execute_input":"2021-07-19T08:54:15.668762Z","iopub.status.idle":"2021-07-19T08:54:15.715444Z","shell.execute_reply.started":"2021-07-19T08:54:15.668711Z","shell.execute_reply":"2021-07-19T08:54:15.714239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm = confusion_matrix(y_test, y_pred)\n\ngroup_names = ['True Neg', 'False Pos', 'False Neg', 'True Pos']\ngroup_counts = [\"{0:0.0f}\".format(value) for value in\n                cm.flatten()]\ngroup_percentages = [\"{0:.2%}\".format(value) for value in\n                     cm.flatten()/np.sum(cm)]\nlabels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n          zip(group_names,group_counts,group_percentages)]\nlabels = np.asarray(labels).reshape(2,2)\nsns.heatmap(cm, annot=labels, fmt='', cmap='PuRd')","metadata":{"execution":{"iopub.status.busy":"2021-07-19T08:54:15.717347Z","iopub.execute_input":"2021-07-19T08:54:15.718107Z","iopub.status.idle":"2021-07-19T08:54:16.015371Z","shell.execute_reply.started":"2021-07-19T08:54:15.718056Z","shell.execute_reply":"2021-07-19T08:54:16.014572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}