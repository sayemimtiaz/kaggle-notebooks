{"cells":[{"metadata":{},"cell_type":"markdown","source":"**<center style=\"font-size: 16pt;\"><a href=\"https://www.kaggle.com/atmarouane/covid-19-search-engine-indexing-by-lda-enm\">Ensemble Model (EnM) for document retrieval results</a></center>**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<h1><span class=\"tocSkip\"></span>Table of Contents</h1>\n<div id=\"toc-wrapper\"></div>\n<div id=\"toc\"></div>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Technical","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Configuration class\n\nWe set variables like from where we load, where to store and some parameters (Explained later).","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"class config():\n    CORPUS_FN = '/kaggle/input/cord-19-step2-corpus/corpus.pkl'\n    ENM_FN = '/kaggle/input/cord-19-step3-enm/ranker_enm.pickle'\n    TOC2_FN='/kaggle/input/toc2js/toc2.js'\n    \n    n_relevant = 150\n    rm1_lambda = 0.6\n    rm3_lambda = 0.7\n    \n    n_display = 15\n    \n    query_txt = 'Is BCG vaccination causally related to reduced COVID‚Äê19 mortality or other factors \\\nlike lockdown and average age of the population are responsible for the different mortality rates?' \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Libraries","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Our libraries\n\nAll our libraries are made public under open source.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import cord_19_container as container\nimport cord_19_rankers as rankers\nimport cord_19_lm as lm\nimport cord_19_vis as vis\n\nfrom cord_19_container import Sentence, Document, Paper, Corpus\n\nfrom cord_19_metrics import compute_queries_perf\n\nfrom cord_19_helpers import load, save\nfrom cord_19_text_cleaner import Cleaner\nfrom cord_19_wn_phrases import wn_phrases","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Commun libraries","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from gensim import matutils\nfrom sklearn.metrics.pairwise import cosine_similarity\n\nimport copy\nfrom collections import defaultdict\nimport re\n\nimport numpy as np\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualization libraries","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"%matplotlib inline\n\nfrom IPython.display import display, HTML, Markdown, Latex\n\nimport wordcloud\n\nimport matplotlib.pyplot as plt\nimport bokeh\nimport holoviews as hv\n\nhv.extension('bokeh', logo=False)\nhv.output(size=260)\n\nHTML(\"\"\"\n<style>\n.output_png {\n    text-align: center;\n    vertical-align: middle;\n}\n\n.rendered_html table{\n    display: table;\n}\n</style>\n\"\"\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Load the corpus, papers talking about COVID-19/SARS-CoV-2, done in our previous kernel.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"corpus = load(config.CORPUS_FN)\ndictionary = corpus.dictionary\n\n# Rebuild id2token from token2id, only token2id is saved\nfor k,v in dictionary.token2id.items():\n    dictionary.id2token[v]=k\n\n# Set the dictionary as global, we have to find better way\ncontainer.dictionary = dictionary\nrankers.dictionary = dictionary\nvis.dictionary = dictionary\n\nprint(f'#Papers {len(corpus)}, #Tokens {len(dictionary)}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load model","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Loading our model.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"ranker_enm = load(config.ENM_FN)\nranker_nmf = ranker_enm.models['NMF']\nranker_ldi = ranker_enm.models['LDI']\n\nranker_ql = rankers.ranker_QL(corpus, config.rm1_lambda)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Original query","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"query = container.Document([Cleaner(True).clean(config.query_txt)])\nquery.tokenize()\nwn_phrases(query)\n\ndisplay(HTML(f'We are searching for:<br><br>'))\nq_original_text = '<br>'.join([s.original_text for s in query.sentences])\ndisplay(HTML(f'<p style=\"font-size: 18pt;\">{q_original_text}</p>'))\n\n#When debuging print query.text","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Topics importance","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def plot_topics_dist(q):\n    score = ranker_nmf[q]\n    _, R = lm.get_relevant(corpus, score, config.n_relevant)\n    \n    fig_1, (ax1_nmf, ax1_ldi) = plt.subplots(1, 2, figsize=(14,6), sharey=True)\n    fig_2, (ax2_nmf, ax2_ldi) = plt.subplots(1, 2, figsize=(14,6), sharey=True)\n\n    vis.plot_topics_dist(ranker_nmf, R, ax1_nmf, ax2_nmf, \"NMF\", set_y_label=True)\n    fig_1.suptitle(f'Number of Documents by Dominant Topic.')\n\n    vis.plot_topics_dist(ranker_ldi, R, ax1_ldi, ax2_ldi, \"LDI\", set_y_label=False)\n    fig_2.suptitle(f'Mean topic probability over corpus.')\n\n    plt.show()\n    \nplot_topics_dist(query)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Cooccurrences importance","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# https://notes.mikejarrett.ca/connecting-neighbourhoods/\ndef rotate_label(plot, element):\n    text_cds = plot.handles['text_1_source']\n    length = len(text_cds.data['angle'])\n    text_cds.data['angle'] = [0]*length\n    xs = text_cds.data['x']\n    text = np.array(text_cds.data['text'])\n    xs[xs<0] -= np.array([len(t)*0.03 for t in text[xs<0]])\n\ndef display_coi(ranker, q, n_words=100):\n    \"\"\"Cooccurrences importance\n    \"\"\"\n    \n    score = ranker[q]\n    query_likelihood = ranker_ql[q]\n    \n    I, R = lm.get_relevant(corpus, score, config.n_relevant)\n    query_likelihood = query_likelihood[I]\n    query_likelihood = query_likelihood / sum(query_likelihood)\n    \n    rm1 = lm.compute_rm1(R.TRF, corpus.p_coll, query_likelihood, lambda_=config.rm1_lambda)\n    \n    # NOTE: Here we are using RM1 and not RM3, we haven't to emphasize query terms\n    lda_tm_rm = lm.compute_tm_rm(ranker_ldi, R, q, query_likelihood, rm1, lambda_=0.7)\n    nmf_tm_rm = lm.compute_tm_rm(ranker_nmf, R, q, query_likelihood, rm1, lambda_=0.7)\n    tm_rm = 0.7*nmf_tm_rm + 0.3*lda_tm_rm\n    \n    top_tokens = np.argsort(tm_rm)[::-1][:n_words]\n    top_tokens_set = set(top_tokens)\n    tokens_subset_id = list(range(len(top_tokens_set)))\n    \n    map_to_new = dict(zip(top_tokens_set, tokens_subset_id))\n    map_to_old = dict(zip(tokens_subset_id, top_tokens_set))\n\n    def to_new_id(X):\n        return [map_to_new[x] for x in X]\n    \n    def to_old_id(X):\n        return [map_to_old[x] for x in X]\n    \n    def to_word(X):\n        return [dictionary.id2token[x] for x in X]\n    \n    # Cooccurrences matrix\n    CoM = np.zeros([n_words, n_words])\n    \n    for paper in R:\n        for sent in paper:\n            sent_words = list(sent.tokensid_set.intersection(top_tokens_set))\n            words_p = [tm_rm[w] for w in sent_words]\n            sent_words = to_new_id(sent_words)\n            \n            pseudo_corpus = list(zip(sent_words, words_p))\n            vec = matutils.corpus2dense([pseudo_corpus], n_words)\n            \n            # [n_words,1]*[1,n_words]=[n_words,n_words]\n            CoM += vec@vec.T\n    \n    I,J = np.triu_indices(n_words, 1)\n    co_score = CoM[I,J]\n    \n    df = pd.DataFrame({'source':to_word(to_old_id(I)),\n                       'target':to_word(to_old_id(J)),\n                       'value':co_score})\n    df.sort_values(by=['value'], inplace=True, ascending=False)\n    \n    links = 0\n    words_set = set()\n    max_words = 20 # It can be 21 or 22\n    for row_i, row in df.iterrows():\n        words_set.update([row.source, row.target])\n        if len(words_set) < max_words:\n            links += 1\n        else:\n            break\n    \n    # print(f'#links {links}')\n    df = df.head(links)\n    \n    #display(df)\n    \n    chord = hv.Chord(df)\n    chord.opts(\n        hv.opts.Chord(cmap='Category20', edge_cmap='Category20', \n                      node_color='index', labels='index', edge_color='source',\n                      edge_line_width=3,\n                      hooks=[rotate_label])\n    )\n    \n    display(chord)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display_coi(ranker_enm, query)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Words importance","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def display_wi(ranker, q):\n    \"\"\"\n    Word importance\n    \"\"\"\n\n    score = ranker[q]\n    query_likelihood = ranker_ql[q]\n    \n    I, R = lm.get_relevant(corpus, score, config.n_relevant)\n    query_likelihood = query_likelihood[I]\n    query_likelihood = query_likelihood / sum(query_likelihood)\n    \n    rm1 = lm.compute_rm1(R.TRF, corpus.p_coll, query_likelihood, lambda_=config.rm1_lambda)\n    \n    # NOTE: Here we are using RM1 and not RM3, we haven't to emphasize query terms\n    lda_tm_rm = lm.compute_tm_rm(ranker_ldi, R, q, query_likelihood, rm1, lambda_=0.7)\n    nmf_tm_rm = lm.compute_tm_rm(ranker_nmf, R, q, query_likelihood, rm1, lambda_=0.7)\n    tm_rm = 0.7*nmf_tm_rm + 0.3*lda_tm_rm\n    \n    freq = {}\n    for i,p in enumerate(tm_rm):\n        token = dictionary.id2token[i]\n        freq[token] = p\n    \n    tm_rm = np.sort(tm_rm)\n    \n    wc = wordcloud.WordCloud(width=800, height=400, max_words=100).generate_from_frequencies(freq)\n    plt.figure(figsize=[7,3], dpi=120)\n    plt.imshow(wc, interpolation='bilinear')\n    plt.title(f'Top100 Word/Relevants probality [{tm_rm[-100]:.3f}, {tm_rm[-1]:.3f}]')\n    plt.axis(\"off\")\n    plt.tight_layout(pad=0)\n    plt.show()\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display_wi(ranker_enm, query)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Results","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def display_results(ranker, q):\n    \n    scores = ranker[q]\n    \n    I, R = lm.get_relevant(corpus, scores, config.n_display)\n    \n    for i, paper in enumerate(R):\n        paper_id = I[i]\n        enm = scores[paper_id]\n        \n        table_html = \"<table>\"\n        \n        # Please add the link (Kaggle kernel) from where you got the 'doi link'\n        link='<a href=\"https://doi.org/'+paper.doi+'\" target=blank>'+paper.title+'</a>'\n        table_html += f\"<tr><th style='text-align:left; width: 5%;'>Title:</th><td style='text-align:left;'><b>{link}</b></td></tr>\"\n        table_html += f\"<tr><th style='text-align:left;'>Score:</th><td style='text-align:left;'>{enm:.3f}</td></tr>\"\n        \n        sentences = [sent for sent in paper if len(sent.bow)>1]\n        \n        a = ranker_nmf.project(sentences)\n        b = ranker_nmf.project(q)\n        \n        sim = cosine_similarity(a, b)\n        sim = sim[:,0]\n        \n        for j,sent in enumerate(sentences):\n            jaccard_sim = 1-matutils.jaccard(q.bow, sent.bow)\n            sim[j] = (sim[j] + jaccard_sim)*0.5\n        \n        sI = np.argsort(sim)[::-1]\n        top5_tbl = \"<table>\"\n        top5_tbl += \"<tr><th>Score</th><th style='text-align:left;'>Sentence</th></tr>\"\n        for j in sI[:5]:\n            top5_tbl += f\"<tr><td>{sim[j]:.3f}</td><td style='text-align:left;'>{sentences[j].original_text}</td></tr>\"\n        top5_tbl += \"</table>\"\n        \n        table_html += \"<tr><td colspan='2' style='text-align:left;'><b>Top5 sentences:</b></td></tr>\"\n        table_html += \"<tr><td colspan='2'>\"+top5_tbl+\"</td></tr>\"\n        \n        table_html += \"</table>\"\n        \n        display(HTML(table_html))\n        #display(HTML('<hr>'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\ndisplay_results(ranker_enm, query)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Expanded query","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def get_top_terms(q, score, query_likelihood, lambda_ = 0.6, topk=20):\n    I, R = lm.get_relevant(corpus, score, config.n_relevant)\n    \n    query_likelihood = query_likelihood[I]\n    query_likelihood = query_likelihood / sum(query_likelihood)\n    \n    rm1 = lm.compute_rm1(R.TRF, corpus.p_coll,\n                         query_likelihood,\n                         lambda_=config.rm1_lambda)\n    \n    TF = R.TF.copy()\n    # Set to 0 words not in query\n    mask = np.isin(np.arange(len(corpus.dictionary)), list(q.tokensid_set), invert=True)\n    TF[:,mask] = 0\n    p_w_q = lm.mle(TF) # P_mle(w|Q)\n    rm3 = lm.compute_rm3(rm1, p_w_q, lambda_=config.rm3_lambda)\n\n    # Combine topics models with RM\n    lda_tm_rm = lm.compute_tm_rm(ranker_ldi, R, q, query_likelihood, rm3, lambda_=lambda_)\n    nmf_tm_rm = lm.compute_tm_rm(ranker_nmf, R, q, query_likelihood, rm3, lambda_=lambda_)\n    tm_rm = 0.7*nmf_tm_rm + 0.3*lda_tm_rm\n    \n    return np.argsort(tm_rm)[::-1][:topk]\n\ndef expand_query(q):\n    oq = copy.deepcopy(q)\n    best_q = oq\n    \n    n_expanded = 0\n\n    best_clarity_score = 0\n    max_iter = 3\n\n    while max_iter:\n        max_iter -= 1\n        expanded = False\n\n        q_score = ranker_enm[q]\n        query_likelihood = ranker_ql[q]\n        \n        prev_clarity_score = compute_queries_perf(corpus, q, q_score, query_likelihood,\n                                                  kind='uef', n_relevant=config.n_relevant,\n                                                  rm1_lambda=config.rm1_lambda, rm3_lambda=config.rm3_lambda).item()\n\n        best_clarity_score = prev_clarity_score\n        best_lambda = 0\n        best_topk = 0\n        min_k = len(q.text)+1\n        for topk in np.arange(min_k, 20):\n            for lambda_ in np.linspace(0.2,0.8,7):\n                top_terms = get_top_terms(q, q_score, query_likelihood, lambda_=lambda_, topk=topk)\n                new_q = defaultdict(int, q.bow)\n                for tokenid in top_terms:\n                    new_q[tokenid] += 1\n                new_q_bow = list(new_q.items())\n                new_q = copy.deepcopy(q)\n                new_q._bow = new_q_bow\n\n                new_q_score = ranker_enm[new_q]\n                new_query_likelihood = ranker_ql[new_q]\n\n                clarity_score = compute_queries_perf(corpus, new_q, new_q_score, query_likelihood,\n                                                     kind='uef', n_relevant=config.n_relevant,\n                                                     rm1_lambda=config.rm1_lambda,\n                                                     rm3_lambda=config.rm3_lambda).item()\n                if clarity_score>best_clarity_score:\n                    best_clarity_score = clarity_score\n                    best_q = new_q\n                    best_lambda = lambda_\n                    best_topk = topk\n                    break\n\n        if best_topk != 0:\n            q = best_q\n            delta = best_clarity_score - prev_clarity_score\n        else:\n            delta = 0\n            best_lambda = 0\n        print(f'CS: {best_clarity_score:.6f} \\u0394: +{delta:.6f} Lambda: {best_lambda:.2f}')\n\n        if best_topk == 0:\n            break\n                \n    return best_q","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nexpanded_query = expand_query(query)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df_o = pd.DataFrame([(dictionary.id2token[k], v) for k,v in query.bow], columns=['word', 'original'])\ndf_e = pd.DataFrame([(dictionary.id2token[k], v) for k,v in expanded_query.bow], columns=['word', 'expanded'])\n\ndf = pd.merge(df_e, df_o, how='left', on='word')\ndf.fillna(0, inplace=True)\ndf.sort_values(by=['expanded', 'word'], ascending=[True, False], inplace=True)\ndf['expanded'] -= df['original']\n\ndf.plot.barh(x='word', y=['original', 'expanded'], colormap='bwr', stacked=True,\n             figsize=[12,8], rot=0, title=\"Expanded\" )\nplt.tight_layout(pad=0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Topics importance","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def plot_topics_dist(q):\n    score = ranker_nmf[q]\n    _, R = lm.get_relevant(corpus, score, config.n_relevant)\n    \n    fig_1, (ax1_nmf, ax1_ldi) = plt.subplots(1, 2, figsize=(14,6), sharey=True)\n    fig_2, (ax2_nmf, ax2_ldi) = plt.subplots(1, 2, figsize=(14,6), sharey=True)\n\n    vis.plot_topics_dist(ranker_nmf, R, ax1_nmf, ax2_nmf, \"NMF\", set_y_label=True)\n    fig_1.suptitle(f'Number of Documents by Dominant Topic.')\n\n    vis.plot_topics_dist(ranker_ldi, R, ax1_ldi, ax2_ldi, \"LDI\", set_y_label=False)\n    fig_2.suptitle(f'Mean topic probability over corpus.')\n\n    plt.show()\n    \nplot_topics_dist(query)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Cooccurrences importance","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"display_coi(ranker_enm, expanded_query)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Words importance","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"display_wi(ranker_enm, expanded_query)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Results","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"display_results(ranker_enm, expanded_query)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"from IPython.display import HTML\n\nwith open(config.TOC2_FN, 'r') as file:\n    js = file.read()\n\n    display(HTML('<script type=\"text/Javascript\">'+js+'</script>'))\n    \n    del js","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"%%javascript\n\n// Autonumbering & Table of Contents\n// Using: https://github.com/ipython-contrib/jupyter_contrib_nbextensions/tree/master/src/jupyter_contrib_nbextensions/nbextensions/toc2\ntable_of_contents(default_cfg);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}