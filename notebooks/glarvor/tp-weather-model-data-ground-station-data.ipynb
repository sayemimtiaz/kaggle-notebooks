{"cells":[{"metadata":{},"cell_type":"markdown","source":"# TP : explore 2D weather model data and ground station data\n\nThe aim of this notebook is to indicate how to explore and overlap weather model data and ground station data. You can find [here](https://github.com/meteofrance/meteonet/tree/master/course_slides) the slides associated to that tutorial.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Note\n\n<font size=\"4.5\">To use <span style=\"color:blue\">**Cartopy**</span>, a library to plot data with basemaps (see cells below), it is necessary to <span style=\"color:red\">activate the internet connection</span> of that notebook (in edit mode, you can find on the right column, in the *Settings* section, a row entitled *Internet*, put the slider bar on **on**).  </font>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport xarray as xr\nimport datetime as dt\nfrom datetime import timedelta  \n\nimport cartopy.crs as ccrs\nimport cartopy.feature as cfeature\n\nimport matplotlib.gridspec as gridspec\nfrom scipy.interpolate import griddata\n\n\n# Input data files are available in the \"../input/\" directory.\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# I - Open & explore the data\n## I.a - Ground station data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Hundreds of observation stations are built throughout the French territory and fitted with several weather sensors (temperature, pressure, wind...). \nEach parameter is measured every 6 minutes and each file contains 1 year of data for the geographical area 'NW' for North-West of France.  \n\nFor more information about data, cf [documentation](https://meteofrance.github.io/meteonet/english/data/ground-observations/).\n\n## Data overview\n\n### Metadata parameters\n\n* **number_sta** : ground station number\n\n* **lat** : latitude into decimal degrees\n\n* **lon** : longitude into decimal degrees\n\n* **height_sta** : station height into meters\n\nThe date parameter is a datetime object with the format 'YYYY-MM-DD HH:mm:ss'.\n\n### Meteorological parameters\n\n* **dd** : wind direction in degrees\n\n* **ff** : wind speed in m.s<sup>-1</sup>\n\n* **precip** : precipitation during the reporting period in kg.m<sup>2</sup>\n\n* **hu** : humidity in %\n\n* **td** : dew point temperature** in Kelvin\n\n* **t** : temperature in Kelvin\n\n* **psl** : pressure reduced to sea level in Pa\n\n\n** : temperature for which it is needed to refresh an air volume at constant pressure and humidity to become it saturated (i.e. condensation temperature)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Select the year you want to study:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"year = '2016'\nfname = '/kaggle/input/meteonet/NW_Ground_Stations/NW_Ground_Stations/NW_Ground_Stations_'+year+\".csv\"\ndf = pd.read_csv(fname,parse_dates=[4],infer_datetime_format=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. Let's have a look at the dataframe!","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"display(df.head())\ndisplay(df.tail())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plot a given parameter for a given date \n\nLet's start by selecting a date and displaying a subpart of the dataframe.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"date = '2016-01-01T06:00:00'\nd_sub = df[df['date'] == date]\n\ndisplay(d_sub.head())\ndisplay(d_sub.tail())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, let's plot the data!","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Simple scatter plot","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"param = 't'\nplt.scatter(d_sub['lon'], d_sub['lat'], c=d_sub[param], cmap='jet')\nplt.colorbar()\nplt.title(date+' - param '+param)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plot with Cartopy","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Coordinates of studied area boundaries (in °N and °E)\nlllat = 46.25  #lower left latitude\nurlat = 51.896  #upper right latitude\nlllon = -5.842  #lower left longitude\nurlon = 2  #upper right longitude\nextent = [lllon, urlon, lllat, urlat]\n\nfig = plt.figure(figsize=(9,5))\n\n# Select projection\nax = plt.axes(projection=ccrs.PlateCarree())\n\n# Plot the data\nplt.scatter(d_sub['lon'], d_sub['lat'], c=d_sub[param], cmap='jet')  # Plot\nplt.colorbar()\nplt.title(date+' - param '+param)\n\n\n# Add coastlines and borders\nax.coastlines(resolution='50m', linewidth=1)\nax.add_feature(cfeature.BORDERS.with_scale('50m'))\n\n# Adjust the plot to the area we defined \n#/!\\# this line causes a bug of the kaggle notebook and clears all the memory. That is why this line is commented and so\n# the plot is not completely adjusted to the data\n# Show only the area we defined\n#ax.set_extent(extent)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Now, let's play with the parameters!","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def choose_parameters_and_display(date,param,df):\n    #select the data corresponding to the selected date\n    d_sub = df[df['date'] == date]\n    \n    # Coordinates of studied area boundaries (in °N and °E)\n    lllat = 46.25  #lower left latitude\n    urlat = 51.896  #upper right latitude\n    lllon = -5.842  #lower left longitude\n    urlon = 2  #upper right longitude\n    extent = [lllon, urlon, lllat, urlat]\n\n    fig = plt.figure(figsize=(9,5))\n\n    # Select projection\n    ax = plt.axes(projection=ccrs.PlateCarree())\n\n    # Plot the data\n    plt.scatter(d_sub['lon'], d_sub['lat'], c=d_sub[param], cmap='jet')  # Plot\n    plt.colorbar()\n    plt.title(date+' - param '+param)\n\n    # Add coastlines and borders\n    ax.coastlines(resolution='50m', linewidth=1)\n    ax.add_feature(cfeature.BORDERS.with_scale('50m'))\n\n    # Adjust the plot to the area we defined \n    #/!\\# this line causes a bug of the kaggle notebook and clears all the memory. That is why this line is commented and so\n    # the plot is not completely adjusted to the data\n    # Show only the area we defined\n    #ax.set_extent(extent)\n\n    plt.show()\n    return d_sub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"date = '2016-12-31T12:24:00'\nparam = 'td'\ndata = choose_parameters_and_display(date,param,df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Exercice\n\n1. Get the temperature value for the station_id *14066001* at 02/02/2016 06h00.\n2. Get the wind speed value for the station_id *86137003* at 10/10/2016 12h06.\n3. Get the humidity value for the lat 48.527 and lon 1.995 at 25/12/2016 15h12.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#question 1\n\ndate = '2016-02-02T06:00:00'\nstation_id = 14066001\nparam = 't'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Execute the following cell to get the correction (it is necessary to execute twice : one about loading and one about executing)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#%load /kaggle/usr/lib/tp_solutions_answer_obs_1/tp_solutions_answer_obs_1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#to execute the correction\n#d_sub = obs_answer_1(year,date,station_id,param)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#question 2 \n\ndate = '2016-10-10T12:06:00'\nstation_id = 86137003\nparam = 'ff'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#to execute the correction\n#d_sub = obs_answer_1(year,date,station_id,param)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#question 3 \n\ndate = '2016-12-25T15:12:00'\nlat = 48.527\nlon = 1.995\nparam = 'hu'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Execute the following cell to get the correction (it is necessary to execute twice : one about loading and one about executing)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# %load /kaggle/usr/lib/tp_solutions_answer_obs_2/tp_solutions_answer_obs_2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#to execute the correction\n#d_sub = obs_answer_2(year,date,station_id,param)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## I.b - 2D weather model data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**/!\\ only February 2016 is available for now. In the near future, all the 2D and 3D weather model data will be available for 2016, 2017 and 2018 at netcdf format on Kaggle. Meanwhile, you can already find all the data at GRIB format on this server : https://meteonet.umr-cnrm.fr/dataset/. So a conversion step (from GRIB to netcdf) has to be performed to put the rest on Kaggle.**\n\nFor more information about data, cf [documentation](https://meteofrance.github.io/meteonet/english/data/weather-models/).\n\nThere are 2 weather models:\n* a fine-mesh french weather model called 'AROME' (spatial resolution of 0.025°)\n* a large-mesh french weather model called 'ARPEGE' (spatial resolution of 0.1°)\n\nPer model and day, for the geographic zone 'NW' (for North-West of France), you have the model run of 00h with range forecasts from 00h to 24h. The time step is 1h.\n\nThe 2D data are stored in 4 different netCDF files, according to the vertical level:\n\n* at 2m (*2m* in the file name) : temperature (in K), dew point temperature** (in K) and relative humidity (in %)\n* at 10m (*10m* in the file name): wind speed (in m.s<sup>-1</sup>), wind direction (in degrees), U and V wind components*** (in m.s<sup>-1</sup>)\n* at the sea level (*P_sea_level* in the file name) : mean sea level pressure (in Pa)\n* at the ground level (*PRECIP* in the file name)  : total precipitation (in kg m<sup>-2</sup> which is equivalent to mm) since the beginning of the model run \n\n** : temperature for which it is needed to refresh an air volume at constant pressure and humidity to become it saturated (i.e. condensation temperature)\n\n*** : horizontal wind speed components, U : from west to east and V : from south to north. \n\n**/!\\ : about the total precipitation parameter, the range forecast begins to 1h and not 0h as the other parameters. It is planned in a future version to modify that parameter in order to have the total precipitation between two time steps instead.**\n/!\\ : Some files in the model files are incomplete/corrupted. It comes from the database of our corporation. There are archiving anomalies. We are working on a new version of MeteoNet and will take into account these anomalies. Meanwhile, you can detect these anomalies by checking the file sizes. For a given file category (zone, level, model type), the files must have exactly the same size. So if some files are smaller than the other one, then these files have anomalies. This has been reported in kaggle in this discussion https://www.kaggle.com/katerpillar/meteonet/discussion/157206 and in Github (https://github.com/meteofrance/meteonet/issues/14).","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Select the model, date and level you want to study :","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model = 'arome' #weather model (arome or arpege)\nlevel = '2m'      #vertical level (2m, 10m, P_sea_level or PRECIP)\n#date /!\\ only available for February 2016!\ndate = dt.datetime(2016, 2, 14,0,0) #/!\\ you can not modify the hour (always 00h) -> 1 possible run date only\n\ndirectory = '/kaggle/input/meteonet/NW_weather_models_2D_parameters_' + str(date.year) + str(date.month).zfill(2) + '/' + str(date.year) + str(date.month).zfill(2) + '/'\nfname = directory + f'{model.upper()}/{level}/{model}_{level}_NW_{date.year}{str(date.month).zfill(2)}{str(date.day).zfill(2)}000000.nc'\ndata = xr.open_dataset(fname)  \nprint(data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Quick field visualization\nThe following comand shows the weather forecast at different steps, at the chosen run date and parameter.\nFor each file, the run chosed is the midnight run. The temperature at step 12 (figure 3) is the midday temperature. \nYou can see that this temperature is higher than midnight (fig 1 and 4) or at 6AM (figure 2)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"param = 't2m'\ndata.isel(step=[0, 6, 12, 23])[param].plot(x='longitude',\n                                           y='latitude',\n                                           col='step',\n                                           col_wrap=2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Get the information about coordinates (latitude and longitude):","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"coord = 'longitude'\nprint(data[coord])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[coord].units","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[coord].values[0:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Get the information about the run date and the different range forecasts:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"run_date = data['time']\n#run_date.values     #get the values\nprint(run_date)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"range_forecasts_dates = data['valid_time']\nprint(range_forecasts_dates)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#if you want information about vertical level\n# if (level =='2m' or level == '10m'):\n#     level_name = 'heightAboveGround'\n# elif (level =='P_sea_level'):\n#     level_name = 'meanSea'\n# else:\n#     level_name = 'surface'\n# info_level = data[level_name]\n# print(info_level)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Get the information about one parameter: \nthe parameter names in the file are indicated in the field *Data variables* (cf print(data) above)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"d = data[param]     #param : parameter name defined at the beginning of the Notebook \nd_vals=d.values     #get the values\n###examples to get the information from attributes\n#d.units                      #unit\n#d.long_name                      #long name\nprint(d)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The structure of the parameter (3 dimensions):\n* number of steps or range forecasts\n* number of points in latitude\n* number of points in longitude  ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(d.dims)\nprint(d_vals.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"About the parameter names, here are the correspondences between the \"comprehensive\" names and the names in the files:\n\n* temperature at 2m : t2m\n* dew point temperature at 2m : d2m\n* relative humidity at 2m : r\n* wind speed at 10m : ws\n* wind direction at 10m : p3031\n* U wind component at 10m : u10\n* V wind component at 10m : v10\n* mean sea level pressure : msl\n* total precipitation since the beginning of the model run : tp  -> **/!\\ : about the total precipitation parameter, the range forecast begins to 1h and not 0h as the other parameters.**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Exercice\n\n1. Get the temperature value for the run date 10/02/2016 00h, arome model, lat 51.696 ,lon 0.008 (nearest point method) and step 3 (10/02/2016 3h)\n2. Get the wind speed value for the run date 01/02/2016 00h, arpege model, lat 48.896 ,lon 0.558 (nearest point method)  and step 6 (01/02/2016 06h)\n3. Get the precipitation value for the run date 20/02/2016 00h, arpege model, lat 47.496 ,lon 1.858 (nearest point method)  and step 19 (20/02/2016 20h) -> because there is no data for 00h about precipitation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#question 1\n\nrun_date = '2016-02-10T00:00:00'\nparam = 't2m'  #cf the cell above to know the parameter names in the observation file \nmodel = 'arome' #weather model (arome or arpege)\nlat = 51.696\nlon = 0.008\nstep = 3","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Help\n\n* to select a data subset by parameter value : **data.sel(parameter_name=parameter_value,method='nearest')** -> nearest for nearest point (ex lat/lon)\n* to select a data subset by value parameter index : **data.isel(parameter_name=value_parameter_index,method='nearest')** -> nearest for nearest point (ex lat/lon)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Execute the following cell to get the correction (it is necessary to execute twice : one about loading and one about executing)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# %load /kaggle/usr/lib/tp_solutions_answer_mod/tp_solutions_answer_mod","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#to execute the correction\n#result1 = open_and_select(run_date,param,model,lat,lon,step)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#question 2\n\nrun_date = '2016-02-01T00:00:00'\nparam = 'ws'  #cf the cell above to know the parameter names in the observation file \nmodel = 'arpege' #weather model (arome or arpege)\nlat = 48.896\nlon = 0.558\nstep = 6\n\n#to execute the correction\n#result2 = open_and_select(run_date,param,model,lat,lon,step)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#question 3 \n\nrun_date = '2016-02-20T00:00:00'\nparam = 'tp'  #cf the cell above to know the parameter names in the observation file \nmodel = 'arpege' #weather model (arome or arpege)\nlat = 47.496\nlon = 1.858\nstep = 19\n\n#to execute the correction\n#result3 = open_and_select(run_date,param,model,lat,lon,step)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plotting data with Cartopy","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Plot the parameter values for 1 given time step with Cartopy:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#index for the studied time step\nstep = 0  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Coordinates of studied area boundaries (in °N and °E)\nlllat = 46.25  #lower left latitude\nurlat = 51.896  #upper right latitude\nlllon = -5.842  #lower left longitude\nurlon = 2  #upper right longitude\nextent = [lllon, urlon, lllat, urlat]\n\nfig=plt.figure(figsize=(9,10))\n\n# Select projection\nax = plt.axes(projection=ccrs.PlateCarree())\n\n#plot the data and the background map (coastlines and borders)\nimg = ax.imshow(d_vals[step,:,:], interpolation='none', origin='upper', extent=extent)\nax.coastlines(resolution='50m', linewidth=1)\nax.add_feature(cfeature.BORDERS.with_scale('50m'))\n\n\nplt.colorbar(img, orientation= 'horizontal').set_label(d.long_name+ ' (in '+d.units+ ')')\nplt.title(model +\" model - \"+str(d['valid_time'].values[step])+\" - \" +\"NW zone\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Now, let's play with the parameters!","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def choose_parameters_and_display(model,run_date,step,param):\n    \n    #open the corresponding file according to the chosen parameter    \n    if param == 't2m' or param == 'd2m' or param == 'r':\n        level = '2m'\n    elif param == 'ws' or param =='p3031' or param == 'u10' or param == 'v10':\n        level = '10m'\n    elif param == 'msl':\n        level = 'P_sea_level'\n    else:\n        level = 'PRECIP'\n    \n    directory = '/kaggle/input/meteonet/NW_weather_models_2D_parameters_' + str(run_date.year) + str(run_date.month).zfill(2) + '/' + str(run_date.year) + str(run_date.month).zfill(2) + '/'\n    fname = directory + f'{model.upper()}/{level}/{model}_{level}_NW_{run_date.year}{str(run_date.month).zfill(2)}{str(run_date.day).zfill(2)}000000.nc'\n    sub_data = xr.open_dataset(fname)      \n    \n    # Coordinates of studied area boundaries (in °N and °E)\n    lllat = 46.25  #lower left latitude\n    urlat = 51.896  #upper right latitude\n    lllon = -5.842  #lower left longitude\n    urlon = 2  #upper right longitude\n    extent = [lllon, urlon, lllat, urlat]\n\n    fig=plt.figure(figsize=(9,10))\n\n    # Select projection\n    ax = plt.axes(projection=ccrs.PlateCarree())\n\n    #plot the data and the background map (coastlines and borders)\n    img = ax.imshow(sub_data[param].values[step,:,:], interpolation='none', origin='upper', extent=extent)\n    ax.coastlines(resolution='50m', linewidth=1)\n    ax.add_feature(cfeature.BORDERS.with_scale('50m'))\n\n\n    plt.colorbar(img, orientation= 'horizontal').set_label(sub_data[param].long_name+ ' (in '+sub_data[param].units+ ')')\n    plt.title(model +\" model - \"+str(sub_data['valid_time'].values[step])+\" - \" +\"NW zone\")\n    plt.show()\n    \n    return sub_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"About the parameter names, here are the correspondences between the \"comprehensive\" names and the names in the files:\n\n* temperature at 2m : t2m\n* dew point temperature at 2m : d2m\n* relative humidity at 2m : r\n* wind speed at 10m : ws\n* wind direction at 10m : p3031\n* U wind component at 10m : u10\n* V wind component at 10m : v10\n* mean sea level pressure : msl\n* total precipitation since the beginning of the model run : tp  -> **/!\\ : about the total precipitation parameter, the range forecast begins to 1h and not 0h as the other parameters.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model = 'arpege' #weather model (arome or arpege)\n#run date /!\\ only available for February 2016!\nrun_date = dt.datetime(2016, 2,10,0,0) #/!\\ you can not modify the hour (always 00h) -> 1 possible run date only\nparam = 'ws'    #parameter name in the file (cf correspondences in the cell below)\nstep = 3   #index of chosen time step (from 0 to 24 and about precipitation, from 0 to 23)\n\nsub_data = choose_parameters_and_display(model,run_date,step,param)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# III - Superimpose the data for a given position and a given time interval\n\nWe have here 2 data categories :\n* data projected on a grid : weather models\n* data on points with a given latitude and longitude : observations from ground stations\n\nSo, for a given ground station and a given time interval, we will interpolate **spatially** model data to the position of the chosen ground station to be able to compare data on the same point.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"First, let's choose our parameter values!","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Note\n\nHere are the parameter names in the observations files:\n\n* **number_sta** : ground station number\n* **lat** : latitude into decimal degrees\n* **lon** : longitude into decimal degrees\n* **height_sta** : station height into meters\n* **date** : datetime object with the format 'YYYY-MM-DD HH:mm:ss'.\n* **dd** : wind direction in degrees\n* **ff** : wind speed in m.s<sup>-1</sup>\n* **precip** : precipitation during the reporting period in kg.m<sup>2</sup>\n* **hu** : humidity in %\n* **td** : dew point temperature** in Kelvin\n* **t** : temperature in Kelvin\n* **psl** : pressure reduced to sea level in Pa","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#date\ndate = '2016-02-13' \n\n#observation\nparam_obs = 'dd'  #cf the cell below to know the parameter names in the observation file \n\n#model\nmodel = 'arpege' #weather model (arome or arpege)\nMODEL = 'ARPEGE' #weather model (AROME or ARPEGE)\nparam_mod = 'p3031'   #cf correspondences in the cell below\n\n#algorithm about interpolation\nalgo = 'linear' #or 'nearest' for nearest neighbors","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Get the observation values\n* get the values for the chosen time period (from d day 00h to 24h included)\n* choose one station : **/!\\ the stations do not have necessarily the same time coverage!**\n* get the latitude and longitude of the chosen station (necessary to perform the interpolation of forecast data)\n* get all the hourly data (because the forecast data have a hourly step):resampling...etc","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#first part : open and filtering on the day\nyear = date[0:4]\nfname = '/kaggle/input/meteonet/NW_Ground_Stations/NW_Ground_Stations/NW_Ground_Stations_'+year+\".csv\"\n\ndef open_and_date_filtering(year,fname,date):    \n    #open the observation data\n    #df = pd.read_csv(fname,parse_dates=[4],infer_datetime_format=True) #execution time ~1 min \n\n    #filtering on the date \n    study_date = pd.Timestamp(date)  #study date\n    d_sub = df[(df['date'] >= study_date) & (df['date'] <= study_date + timedelta(days=1))]\n    d_sub = d_sub.set_index('date')\n    display(d_sub.head())\n    display(d_sub.tail())\n    return(d_sub)\n\nd_sub = open_and_date_filtering(year,fname,date)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#second part : choose the station_id, get the lat/lon of the station and resample the data to the hourly step!\nstation_id = 86137003\n\ndef station_lat_lon_resample(station_id,d_sub):\n    #filtering on the station_id\n    d_sub = d_sub[d_sub['number_sta'] == station_id]\n\n    #get the lat/lon values of the station \n    lat_sta = d_sub['lat'][0]\n    lon_sta = d_sub['lon'][0]\n\n    #resample the 6 min data to get hourly data (by using the mean on one hour)\n    d_sub = d_sub[param_obs].resample('H').mean()\n    print('station_id:',station_id)\n    print('lat/lon:',lat_sta,'/',lon_sta)\n    print('weather parameter',param_obs)\n    display(d_sub)\n    return(d_sub,station_id,lat_sta,lon_sta)\n\nd_sub, station_id, lat_sta, lon_sta = station_lat_lon_resample(station_id,d_sub)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Get the forecast values\n* **/!\\ the data are only available for February 2016**\n* get the values for the chosen time period (from d day 00h to 24h included) -> all the necessary data are in one single file corresponding to the chosen run date\n* get the latitude and longitude of the forecast data (necessary to perform the interpolation of forecast data)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Steps proposal:\n* open the corresponding file according to the chosen parameter\n* get the forecast values and the lat/lon of the grid data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def open_get_values(param_mod,date):\n    #open the corresponding file according to the chosen parameter\n    if param_mod == 't2m' or param_mod == 'd2m' or param_mod == 'r':\n        level = '2m'\n    elif param_mod == 'ws' or param_mod =='p3031' or param_mod == 'u10' or param_mod == 'v10':\n        level = '10m'\n    elif param_mod == 'msl':\n        level = 'P_sea_level'\n    else:\n        level = 'PRECIP'\n\n    year = date[0:4]\n    month = date[5:7]\n    day = date[8:10]\n\n    directory = '/kaggle/input/meteonet/NW_weather_models_2D_parameters_' + year + month + '/' + year + month + '/'\n    fname = directory + f'{MODEL}/{level}/{model}_{level}_NW_{year}{month}{day}000000.nc'\n    dm = xr.open_dataset(fname)\n    print('dataset overview:',dm)\n\n    #get the forecast values and the lat/lon of the grid data\n    grid_values = dm[param_mod].values\n    grid_lat = dm['latitude'].values\n    grid_lon = dm['longitude'].values\n    print('shape of the forecast values array:',grid_values.shape)\n    print('ten first latitudes:',grid_lat[0:10])\n    print('ten first longitudes',grid_lon[0:10])\n    return(grid_values,grid_lat,grid_lon)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_values,grid_lat,grid_lon = open_get_values(param_mod,date)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Perform the interpolation\nFor each time step, we interpolate the forecast data on the chosen station position ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.interpolate import griddata\n\ndef interpolation(grid_values,grid_lat,grid_lon,lat_sta,lon_sta):\n    #initialization\n    model_values = []\n    grid_on_points = np.empty(grid_values.shape[0], dtype = object) \n    \n    #loop per time step \n    for step in range(0,grid_values.shape[0]):\n        latlon_grid = []\n        val_grid = []\n        latlon_obs = []\n\n        #grid data preprocessing\n        for i in range(0,grid_lat.shape[0]):        \n            for j in range(0,grid_lon.shape[0]):\n                #put coordinates (lat,lon) in list of tuples\n                latlon_grid.append([grid_lat[i],grid_lon[j]])\n                #put grid values into a list\n                val_grid.append(grid_values[step,i,j])\n\n        grid_latlon = np.array(latlon_grid)\n        grid_val2 = np.array(val_grid)\n\n        #ground station position (lat/lon) preprocessing\n        latlon_obs.append([lat_sta,lon_sta])\n        latlon_obs = np.array(latlon_obs)\n\n        #compute the interpolation\n        grid_on_points[step] = griddata(grid_latlon ,grid_val2, latlon_obs,  method=algo)[0]\n        print('step ',step, ' OK!')\n    return(grid_on_points)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_on_points = interpolation(grid_values,grid_lat,grid_lon,lat_sta,lon_sta)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Rearrange the data to plot them!\n* put the interpolated forecasted data into a pandas series with the date in index ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"obs = d_sub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preproc_output(obs,grid_on_points,param_mod):\n    mod = pd.Series(grid_on_points,index=obs.index)\n    print('interpolated forecasted data, param ',param_mod)\n    return (mod)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mod = preproc_output(obs,grid_on_points,param_mod)\ndisplay(mod)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plot the results on a plot!\n* Let's plot the 2 curves to compare them!","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def plots(obs,mod,MODEL,param_obs,lat_sta,lon_sta):\n    plt.plot(obs, label ='Observation')\n    plt.plot(mod, label = MODEL +' forecast')\n    plt.title('Parameter '+param_obs+' / lat='+str(lat_sta)+' and lon='+str(lon_sta))\n    plt.xlabel('Time')\n    plt.ylabel(param_obs)\n    plt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plots(obs,mod,MODEL,param_obs,lat_sta,lon_sta)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Annex - Superimpose the data for a given date ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"For a given date, we will interpolate **spatially** model data to positions of ground stations to be able to compare data on the same points for the same weather parameter!","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"First, let's choose our parameter values!","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#observation\ndate_obs = '2016-02-10T10:00:00' \nparam_obs = 'ff'\n\n#model\nmodel = 'arpege' #weather model (arome or arpege)\nMODEL = 'ARPEGE' #weather model (AROME or ARPEGE)\ndate_mod = dt.datetime(2016, 2,10,10,0) # Day example \nparam_mod = 'ws'\n\n#algorithm about interpolation\nalgo = 'linear' #or 'nearest' for nearest neighbors","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Get the observation values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fname = '/kaggle/input/meteonet/NW_Ground_Stations/NW_Ground_Stations/NW_Ground_Stations_'+date_obs[0:4]+\".csv\"\n#df = pd.read_csv(fname,parse_dates=[4],infer_datetime_format=True)\nstudy_date = pd.Timestamp(date_obs)  #study date\nd_sub = df[df['date'] == study_date]\nprint('observation data',d_sub)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Get the forecast values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"directory = '/kaggle/input/meteonet/NW_weather_models_2D_parameters_' + str(date_mod.year) + str(date_mod.month).zfill(2) + '/' + str(date_mod.year) + str(date_mod.month).zfill(2) + '/'\n\nif param_mod == 't2m' or param_mod == 'd2m' or param_mod == 'r':\n    level = '2m'\nelif param_mod == 'ws' or param_mod =='p3031' or param_mod == 'u10' or param_mod == 'v10':\n    level = '10m'\nelif param_mod == 'msl':\n    level = 'P_sea_level'\nelse:\n    level = 'PRECIP'\n\nfname = directory + f'{model.upper()}/{level}/{model}_{level}_NW_{date_mod.year}{str(date_mod.month).zfill(2)}{str(date_mod.day).zfill(2)}000000.nc'\n\nmod = xr.open_dataset(fname)\ngrid_lat = mod['latitude'].values\ngrid_lon = mod['longitude'].values\ngrid_val = mod[param_mod].values[date_mod.hour,:,:]\nprint('latitudes on the model grid:',grid_lat)\nprint('longitudes on the model grid:',grid_lon)\nprint('forecast values:',grid_val)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Interpolation function:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def interpolate_grid_on_points(grid_lat,grid_lon,grid_val,data_obs,algo):\n    \n    #initialisation\n    latlon_grid = []\n    latlon_obs = []\n    val_grid = []\n    \n    #grid data preprocessing\n    for i in range(0,grid_lat.shape[0]):        \n        for j in range(0,grid_lon.shape[0]):\n            #put coordinates (lat,lon) in list of tuples\n            latlon_grid.append([round(grid_lat[i],3),round(grid_lon[j],3)])\n            #put grid values into a list\n            val_grid.append(grid_val[i,j])\n    grid_latlon = np.array(latlon_grid)\n    grid_val2 = np.array(val_grid)\n\n    #obs data preprocessing : put coordinates (lat,lon) in list of tuples\n    for i in range(0,data_obs.shape[0]):\n        latlon_obs.append([data_obs['lat'].values[i],data_obs['lon'].values[i]])\n    latlon_obs = np.array(latlon_obs)\n    \n    #interpolation\n    grid_val_on_points=griddata(grid_latlon ,grid_val2, latlon_obs,  method=algo)\n    return latlon_obs,grid_val_on_points","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Perform the interpolation:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"latlon_obs,grid_val_on_points = interpolate_grid_on_points(grid_lat,grid_lon,grid_val,d_sub,algo)\nprint('10 first lat/lon couple per station:',latlon_obs[0:10,:])\nprint('associated forecast values interpolated on ground station points:',grid_val_on_points[0:10])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Note : if we want to use another interpolation method, let's test yours!","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Now, plot the different data!","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plot the different data\nfig=plt.figure()\ngs = gridspec.GridSpec(4, 4)\n\n#Min and max boundaries about colorbar\nvmin_obs = d_sub[param_obs].min()\nvmax_obs = d_sub[param_obs].max()\nvmin_model_ori= grid_val.min()\nvmax_model_ori= grid_val.max()\nvmin_model_inter=grid_val_on_points.min()\nvmax_model_inter=grid_val_on_points.max()\nvmin=np.min([vmin_obs,vmin_model_ori,vmin_model_inter])\nvmax=np.max([vmax_obs,vmax_model_ori,vmax_model_inter])\n\n#observation data\nax1 = plt.subplot(gs[:2, :2])\nplt.tight_layout(pad=3.0)\nim=ax1.scatter(d_sub['lon'], d_sub['lat'], c=d_sub[param_obs], cmap='jet',vmin=vmin,vmax=vmax)\nax1.set_title('Observation data')\n\n#weather model data (original grid)\nax2 = plt.subplot(gs[:2, 2:])\nax2.pcolor(grid_lon,grid_lat,grid_val,cmap=\"jet\",vmin=vmin,vmax=vmax)\nax2.set_title('Weather model data (original grid)')\n\n#weather model data (interpolated on observation points)\nax3 = plt.subplot(gs[2:4, 1:3])\nim3=ax3.scatter(latlon_obs[:,1], latlon_obs[:,0], c=grid_val_on_points, cmap='jet',vmin=vmin,vmax=vmax)\nax3.set_title('Weather model data (interpolated on observation points)')\n\nfig.colorbar(im,ax=[ax2,ax3]).set_label(mod[param_mod].long_name+ ' (in '+mod[param_mod].units+ ')')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Now, let's play with the parameters!","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def choose_and_display(model,date_mod,date_obs,param_obs,param_mod,algo,d_sub):\n    \n    #get the observation values \n    study_date = pd.Timestamp(date_obs)  #study date\n    d_sub = df[df['date'] == study_date]\n    \n    #get the model data \n    directory = '/kaggle/input/meteonet/NW_weather_models_2D_parameters_' + str(date_mod.year) + str(date_mod.month).zfill(2) + '/' + str(date_mod.year) + str(date_mod.month).zfill(2) + '/'\n\n    if param_mod == 't2m' or param_mod == 'd2m' or param_mod == 'r':\n        level = '2m'\n    elif param_mod == 'ws' or param_mod =='p3031' or param_mod == 'u10' or param_mod == 'v10':\n        level = '10m'\n    elif param_mod == 'msl':\n        level = 'P_sea_level'\n    else:\n        level = 'PRECIP'\n\n    fname = directory + f'{model.upper()}/{level}/{model}_{level}_NW_{date_mod.year}{str(date_mod.month).zfill(2)}{str(date_mod.day).zfill(2)}000000.nc'\n\n    mod = xr.open_dataset(fname)\n    grid_lat = mod['latitude'].values\n    grid_lon = mod['longitude'].values\n    grid_val = mod[param_mod].values[date_mod.hour,:,:]\n    \n    #perform the interpolation\n    latlon_obs,grid_val_on_points = interpolate_grid_on_points(grid_lat,grid_lon,grid_val,d_sub,algo)\n    \n    #Plot the different data\n    fig=plt.figure()\n    gs = gridspec.GridSpec(4, 4)\n\n    #Min and max boundaries about colorbar\n    vmin_obs = d_sub[param_obs].min()\n    vmax_obs = d_sub[param_obs].max()\n    vmin_model_ori= grid_val.min()\n    vmax_model_ori= grid_val.max()\n    vmin_model_inter=grid_val_on_points.min()\n    vmax_model_inter=grid_val_on_points.max()\n    vmin=np.min([vmin_obs,vmin_model_ori,vmin_model_inter])\n    vmax=np.max([vmax_obs,vmax_model_ori,vmax_model_inter])\n\n    #observation data\n    ax1 = plt.subplot(gs[:2, :2])\n    plt.tight_layout(pad=3.0)\n    im=ax1.scatter(d_sub['lon'], d_sub['lat'], c=d_sub[param_obs], cmap='jet',vmin=vmin,vmax=vmax)\n    ax1.set_title('Observation data')\n\n    #weather model data (original grid)\n    ax2 = plt.subplot(gs[:2, 2:])\n    ax2.pcolor(grid_lon,grid_lat,grid_val,cmap=\"jet\",vmin=vmin,vmax=vmax)\n    ax2.set_title('Weather model data (original grid)')\n\n    #weather model data (interpolated on observation points)\n    ax3 = plt.subplot(gs[2:4, 1:3])\n    im3=ax3.scatter(latlon_obs[:,1], latlon_obs[:,0], c=grid_val_on_points, cmap='jet',vmin=vmin,vmax=vmax)\n    ax3.set_title('Weather model data (interpolated on observation points)')\n\n    fig.colorbar(im,ax=[ax2,ax3]).set_label(mod[param_mod].long_name+ ' (in '+mod[param_mod].units+ ')')\n    plt.show()\n    \n    return d_sub, mod[param_mod][date_mod.hour,:,:], latlon_obs,grid_val_on_points","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#observation\ndate_obs = '2016-02-10T10:00:00' \nparam_obs = 'hu'\n\n#model\nmodel = 'arome' #weather model (arome or arpege)\ndate_mod = dt.datetime(2016, 2,10,10,0) # Day example \nparam_mod = 'r'\n\n#algorithm about interpolation\nalgo = 'nearest' #'linear' or 'nearest' for nearest neighbors","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"obs_output, mod_output, latlon_obs,grid_val_on_points =  choose_and_display(model,date_mod,date_obs,param_obs,param_mod,algo,d_sub)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}