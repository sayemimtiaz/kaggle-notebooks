{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import sklearn\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier, plot_tree\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom xgboost import XGBClassifier\nfrom xgboost import plot_tree as plot_xgboost","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/league-of-legends-diamond-ranked-games-10-min/high_diamond_ranked_10min.csv')\ndf.sample(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"blueWins = 1 ---> Blue Team Wins  \nblueWins = 0 ---> Red Team Wins","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df['blueWins'].value_counts())  # checking the dataset is balanced","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"df.dtypes # checking if any of the input values need to be turned into numbers e.g. if had categorical info. Not the case here.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking if any entries are duplicates - all entries unique so all good\nprint(len(df['gameId'].unique()))\nprint(df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop('gameId', axis=1) # unnecessary column","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Selection  \n## Remove highly correlated features that don't add info  \ne.g. blueKills gives same info as redDeaths  \ne.g. redFirstBlood is inverse of blueFirstBlood","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# looking at edge cases i.e. pure white and pure black\ncorr = df.corr()\nplt.figure(figsize=(15,10))\nax= plt.subplot()\nsns.heatmap(corr, ax=ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# removing columns that have correlated values greater than 0.9, or less than -0.9\ncolumns = np.full((corr.shape[0],), True, dtype=bool)\nfor i in range(corr.shape[0]):\n    for j in range(i+1, corr.shape[0]):\n        if corr.iloc[i,j] >= 0.9:\n            if columns[j]:\n                columns[j] = False\n        if corr.iloc[i,j] <= -0.9:\n            if columns[j]:\n                columns[j] = False\nselected_columns = df.columns[columns]\ndf = df[selected_columns]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape # 12 unecessary columns have been removed","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Selection","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.drop('blueWins', axis=1)\ny = df['blueWins']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\nX_scaled = preprocessing.scale(X)\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y,random_state=1) \nclf = SVC(kernel = 'linear')\nclf.fit(X_train,y_train)\nclf.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y,random_state=1)\nrf = RandomForestClassifier(n_estimators=10, max_depth=3)\nrf.fit(X_train,y_train)\nrf.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 5x2cv significance test (Deittrich, 1998)\n# p value indicates no significance difference in model performance on the datasets\n# will proceed with RF as can use analysis tools (e.g. SHAP, eli5)\n\nclf1 = RandomForestClassifier(n_estimators=10, max_depth=3,random_state=1)\nclf2 = SVC(kernel='linear', random_state=1)\n\nfrom mlxtend.evaluate import paired_ttest_5x2cv\n\n\nt, p = paired_ttest_5x2cv(estimator1=clf1,\n                          estimator2=clf2,\n                          X=X, y=y, random_seed=123)\n\nprint('t statistic: %.3f' % t)\nprint('p value: %.3f' % p)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# RF Model Analysis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# confusion matrix\n\npredictions = rf.predict(X_test)\ncm = confusion_matrix(y_test, predictions)\ncm","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Learning Curve  \n\nCurve indicates that model isn't overtraining, and that adding more training samples is unlikely to improve performance.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.model_selection import ShuffleSplit\n\n\ndef plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n\n    plt.figure()\n    plt.title(title)\n    if ylim is not None:\n        plt.ylim(*ylim)\n    plt.xlabel(\"Training examples\")\n    plt.ylabel(\"Score\")\n    train_sizes, train_scores, test_scores = learning_curve(\n        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    plt.grid()\n\n    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1,\n                     color=\"r\")\n    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n             label=\"Training score\")\n    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n             label=\"Cross-validation score\")\n\n    plt.legend(loc=\"best\")\n    return plt\n\ntitle = \"Learning Curve (RF)\"\ncv = ShuffleSplit(n_splits=10, test_size=0.25, random_state=0)\n\nestimator = RandomForestClassifier(n_estimators=10, max_depth=3)\nplot_learning_curve(estimator, title, X, y, ylim=(0.5, 1.01), cv=cv, n_jobs=4)\n\n# plt.savefig('learningcurve.png', format='png', dpi=600)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import eli5\nfrom eli5.sklearn import PermutationImportance\nperm = PermutationImportance(rf).fit(X_test, y_test)\ndfs = eli5.formatters.as_dataframe.explain_weights_df(perm)\ndfs.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"replacing feature numbers with names","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# replacing feature numbers with names\n\nfeatures  = dfs.iloc[:,0]\nfeatures = features.values.tolist()\n\na = np.hstack(features)\na\nfeature = []\nfor n in range(0,27):\n    string = str(a[n])\n    cut = int(string[1:])\n    feature.append(cut)\n    \nfeature_list = []\n\nfor n in range(0,27):\n    num = feature[n] +1                # adding 1 as first column is blueWins\n    name = df.columns[num]\n    feature_list.append(name)\n    \ndfs.insert(0, 'Features', feature_list)\ndfs=dfs.drop('feature',axis=1)\ndfs.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import shap\nshap.initjs()\nexplainer = shap.TreeExplainer(rf)\nshap_values = explainer.shap_values(X)\nshap.summary_plot(shap_values, X)\n\n#class 0 = Red win\n#class 1 = Blue win","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# shows correlation between blue having more gold and getting more kills\n\nshap.dependence_plot(\"blueGoldDiff\", shap_values[1], X, interaction_index=\"blueKills\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"conf = []\n\nfor i in range(0,len(X_test)):\n    x = rf.predict_proba([X_test.iloc[i]])\n    y = tuple(x[0])\n    conf.append(y)\nsortedd = sorted(conf, key=lambda tup: tup[1])\nrank = [i[0] for i in sortedd]\nimport matplotlib.pyplot  as plt\nplt.figure(figsize=(5,4))\nplt.xlabel('Ranked Test Samples')\nplt.ylabel('Prediction Confidence')\nplt.title('Confidence Ranking')\nplt.plot(rank)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Printing a list of the most confident predictions in each category, so can be further analysed","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"blue_wins = sorted(range(len(conf)),key = lambda k: conf[k])\nred_wins = sorted(range(len(conf)),key = lambda k: conf[k], reverse = True)\ntop_blue = blue_wins[0:10]\ntop_red = red_wins[0:10]\nprint(top_blue)\nprint(top_red)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eli5.show_prediction(rf, X_test.iloc[55], show_feature_values=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eli5.show_prediction(rf, X_test.iloc[80], show_feature_values=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"selected_columns = selected_columns[1:]\nimport statsmodels.api as sm\ndef backwardElimination(x, Y, sl, columns):\n    numVars = len(x[0])\n    for i in range(0, numVars):\n        regressor_OLS = sm.OLS(Y, x).fit()\n        maxVar = max(regressor_OLS.pvalues).astype(float)\n        if maxVar > sl:\n            for j in range(0, numVars - i):\n                if (regressor_OLS.pvalues[j].astype(float) == maxVar):\n                    x = np.delete(x, j, 1)\n                    columns = np.delete(columns, j)\n                    \n    regressor_OLS.summary()\n    return x, columns\nSL = 0.05\ndata_modeled, selected_columns = backwardElimination(df.iloc[:,1:].values, df.iloc[:,0].values, SL, selected_columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = pd.DataFrame()\nresult['blueWin'] = df.iloc[:,0]\ndata = pd.DataFrame(data = data_modeled, columns = selected_columns)\ndata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# remove these categories as predominatley value is 0\ndata1 = data.drop(['blueTowersDestroyed','redTowersDestroyed'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize = (20, 25))\nj = 0\n\nfor i in data1.columns:\n    plt.subplot(6, 4, j+1)\n    j += 1\n    sns.distplot(data1[i][result['blueWin']==0], color='r', label = 'Red Win')\n    sns.distplot(data1[i][result['blueWin']==1], color='b', label = 'Blue Win')\n    plt.legend(loc='best')\nfig.suptitle('LoL Data Analysis')\nfig.tight_layout()\nfig.subplots_adjust(top=0.95)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}