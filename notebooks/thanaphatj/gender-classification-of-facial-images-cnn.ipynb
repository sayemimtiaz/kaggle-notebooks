{"cells":[{"metadata":{},"cell_type":"markdown","source":"# **Getting Started**"},{"metadata":{},"cell_type":"markdown","source":"   **Gender classification** plays a crucial role in many scenarios. As one of the demographic classification attributes, gender information belongs to soft biometrics that provides ancillary information of an individualâ€™s identity information. Moreover, it can improve the performance of face recognition. Thus, it is widely used in many applications to provide smart services in human-computer interaction, such as visual surveillance, intelligent interface, and intelligent advertising.\n\n**Reference**: https://www.hindawi.com/journals/mpe/2018/1924151/"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os # accessing directory structure\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt # plotting\n%matplotlib inline\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom  IPython.display import display\nimport plotly.express as px\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, experimental, MaxPool2D, BatchNormalization\nfrom tensorflow.keras.losses import sparse_categorical_crossentropy, binary_crossentropy\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau \nfrom tensorflow.data import Dataset\nfrom tensorflow.keras import Input, Model\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.random import set_seed\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow import test\nimport random\n\n# Set Seed\nnp.random.seed(11)\nset_seed(11)\nrandom.seed(11)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Data Preparation**"},{"metadata":{},"cell_type":"markdown","source":"**Data Overview**\n* *Age*: range from 1 to 116\n* *Ethnicity*: 0 - White, 1 - Black, 2 - Asian, 3 - Indian, 4 - Other\n* *Gender*: 0 - male, 1 - female"},{"metadata":{},"cell_type":"markdown","source":"**Gender  Data Scope**\n* **Biology:**\n    * a boy is usually a fully physically developed man at the age of 18. \n    * a girl is usually a fully physically developed woman at the age of 16."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nage_gender_data = pd.read_csv(\"/kaggle/input/age-gender-and-ethnicity-face-data-csv/age_gender.csv\")\nage_gender_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"age_gender_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='age', data=age_gender_data) #age distribution","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='gender', data=age_gender_data) #gender distribution","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Data Preprocessing**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select only person who has age more than 18 \nage_gender_data = age_gender_data[age_gender_data['age'] >= 18]\nsns.countplot(x='age', data=age_gender_data) #age distribution","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"age_gender_data.reset_index(drop=True, inplace=True)\nage_gender_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"age_gender_data.isnull().sum() # Check null data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Input image configuration\nnum_pixels = len(age_gender_data['pixels'][0].split(' '))\ndimension = int(np.sqrt(num_pixels))\nimg_width = dimension\nimg_height = dimension\n\nprint(\"Pixels: {}\".format(num_pixels))\nprint(\"Width: {0}, Height: {1}\".format(img_width, img_height))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting dataset into X and y\nX_img = age_gender_data.iloc[:,4].copy()\ny_age = age_gender_data.iloc[:,0].copy()\ny_ethnicity = age_gender_data.iloc[:,1].copy()\ny_gender = age_gender_data.iloc[:,2].copy()\n\n# splitting the data into train and te sets.\nX_train, X_te, y_train, y_te = train_test_split(X_img,y_gender,test_size=0.3,random_state=11)\n# splitting 'te' set into validation and test set\nX_val, X_test, y_val, y_test = train_test_split(X_te,y_te,test_size=0.15,random_state=11)\n\ndef str_to_npArr(x):\n    '''\n    Function to convert pixel data (string) into numpy_array of pixels\n    '''\n    x = x.reset_index(drop=True)\n    x = x.apply(lambda x: np.array(x.split(), dtype=\"float32\")) #converting data to numpy array\n    return np.array([x[i].reshape(img_width, img_height, 1) for i in range(x.shape[0])])\n\n# Converting the string of pixels into image array for each of train, val and test set and normalization\nX_train = str_to_npArr(X_train)\nX_test = str_to_npArr(X_test)\nX_val = str_to_npArr(X_val)\n\nprint(\"Traget: shape = (16593, 48, 48, 1), type = <class 'numpy.ndarray'>\")\nprint(\"Current: shape = {}, type = {}\".format(X_train.shape, type(X_train)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_columns = ['gender', 'ethnicity', 'age']\n\nage_gender_data_preprocess = age_gender_data.drop('img_name', axis=1)\ny = age_gender_data_preprocess[target_columns]\nX = age_gender_data_preprocess.drop(target_columns, axis=1)\n\nprint(X)\nprint(\"--------------------------------------------------------\")\nprint(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = X['pixels'].apply(lambda x: np.array(x.split(), dtype=\"float32\")) #converting data to numpy array\nX = np.array(X)/255.0 # normalization\nX = np.array([ X[i].reshape(48,48,1) for i in range(X.shape[0]) ])\n\nprint(\"Traget: X Shape: {}\".format(X.shape))\nprint(\"Current: X Shape: {}\".format(X.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_gender = np.array(y['gender'])\ny_ethnicity = np.array(y['ethnicity'])\ny_age = np.array(y['age'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Data Visualization**"},{"metadata":{"trusted":true},"cell_type":"code","source":"rows = 20 # rows in subplots\ncols = 5 # columns in subplots\nsamp = random.sample(range(X.shape[0]),rows*cols) #selecting 100 random samples\nx_samp = X[samp,:,:,:]\ny_samp_gender = y_gender[samp]\ny_samp_age = y_age[samp]\n    \nfig,ax = plt.subplots(rows,cols,figsize=(16,60))\nr = 0\nc = 0   \n\nfor i in range(rows*cols):\n    aa = x_samp[i,:,:,:].reshape(48,48)\n    ax[r,c].axis(\"off\")\n    ax[r,c].imshow(aa,cmap=\"gray\")\n    ax[r,c].set_title(f\"Gender: {'Female' if y_samp_gender[i]==1 else 'Male'}, Age: {y_samp_age[i]}\")\n    c+=1\n    if c == cols:\n        c=0\n        r+=1\n        \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Image Augmentation**"},{"metadata":{},"cell_type":"markdown","source":"**Data augmentation**: a technique to increase the diversity of your training set by applying random (but realistic) transformations such as image rotation.\nThis code below shows 100 samples of Data augmentation."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data_gen = ImageDataGenerator(rotation_range=30,\n                                   width_shift_range=1,\n                                    brightness_range=[0.8,1.2],\n                                    zoom_range=[0.8,1.2],\n                                    rescale=1/255\n                                   )\nval_data_gen = ImageDataGenerator(rescale=1/255)\n\ntest_data_gen = ImageDataGenerator(rescale=1/255)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"set_seed(11)\nrandom.seed(11)\nnp.random.seed(11)\n\nval_data = val_data_gen.flow(X_val,y_val,\n                                   seed=11,shuffle=False)\n\ntest_data = test_data_gen.flow(X_test,y_test,\n                                   seed=11,shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(10,5,figsize=(15,25))\nfor n in range(10):    \n    r = random.sample(range(X.shape[0]),1)[0]\n    ax[n,0].imshow(X[r].reshape(48,48),cmap=\"gray\")\n    ax[n,0].set_title(\"Original\")\n    ax[n,0].axis(\"off\")\n    for i in range(1,5):\n        ax[n,i].imshow(train_data_gen.random_transform(X[r]).reshape(48,48),cmap=\"gray\")\n        ax[n,i].set_title(\"Augmented\")\n        ax[n,i].axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> # **K-FOLD CV**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model configuration\nbatch_size = 32\nimg_width, img_height, img_num_channels = 48, 48, 1\nloss_function = sparse_categorical_crossentropy\nno_classes = 2\nno_epochs = 50\noptimizer = Adam()\nverbosity = 1\nnum_folds = 10\nactivation='softmax'\n\n# Determine shape of the data\ninput_shape = (img_width, img_height, img_num_channels)\ninput_shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set Seed\nrandom.seed(11)\nset_seed(11)\nnp.random.seed(11)\n\n# Define the K-fold Cross Validator\nkfold = KFold(n_splits=num_folds, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define per-fold score containers\nacc_per_fold = []\nloss_per_fold = []\n\n# K-fold Cross Validation model evaluation\nfold_no = 1\nfor train, test in kfold.split(X, y_gender):\n    \n  # Set Seed\n  random.seed(11)\n  set_seed(11)\n  np.random.seed(11)\n  \n  # Define the model architecture\n  model = Sequential()\n  \n  model.add(Conv2D(64, kernel_size=(3,3), input_shape=input_shape, activation='relu'))\n  model.add(MaxPooling2D(pool_size=(2,2)))\n  model.add(BatchNormalization())\n\n  model.add(Conv2D(128, kernel_size=(3,3), activation='relu', padding='same'))\n  model.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n  model.add(MaxPooling2D(pool_size=(2,2)))\n  model.add(Dropout(0.3))\n  model.add(BatchNormalization())\n\n  model.add(Conv2D(256, kernel_size=(3,3), activation='relu', padding='same'))\n  model.add(Conv2D(256, kernel_size=(3,3), activation='relu'))\n  model.add(MaxPooling2D(pool_size=(2,2)))\n  model.add(Dropout(0.3))\n  model.add(BatchNormalization())\n\n  model.add(Conv2D(512, kernel_size=(3,3), activation='relu', padding='same'))\n  model.add(MaxPooling2D(pool_size=(2,2)))\n  model.add(Dropout(0.5))\n  model.add(BatchNormalization())\n\n  model.add(Flatten())\n  model.add(Dense(128, activation='relu'))\n  model.add(Dense(128, activation='softmax'))\n\n  # Compile the model\n  model.compile(loss=loss_function,\n              optimizer=optimizer,\n              metrics=['accuracy'])\n  \n  # Generate a print\n  print('------------------------------------------------------------------------')\n  print(f'Training for fold {fold_no} ...')\n    \n  early_stop = EarlyStopping(monitor=\"val_loss\",patience=5,mode=\"min\") # Ensure the model doesn't overfit\n  \n  # Set Seed\n  random.seed(11)\n  set_seed(11)\n  np.random.seed(11)\n    \n  # Fit data to model\n  history = model.fit(train_data_gen.flow(X[train], y_gender[train], seed=11),\n            callbacks=early_stop,\n            batch_size=batch_size,\n            epochs=no_epochs,\n            verbose=verbosity,\n            validation_data=train_data_gen.flow(X[test], y_gender[test],\n                                   seed=11))\n  \n  # Generate generalization metrics\n  fig = px.line(\n  history.history, y=['loss', 'val_loss'],\n  labels={'index': 'epoch', 'value': 'loss'}, \n  title='Training History')\n  fig.show()\n    \n  scores = model.evaluate(train_data_gen.flow(X[test], y_gender[test],\n                                   seed=11), verbose=0)\n  print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n  acc_per_fold.append(scores[1] * 100)\n  loss_per_fold.append(scores[0])\n  \n  # Increase fold number\n  fold_no = fold_no + 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# == Provide average scores ==\nprint('------------------------------------------------------------------------')\nprint('Score per fold')\nfor i in range(0, len(acc_per_fold)):\n  print('------------------------------------------------------------------------')\n  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\nprint('------------------------------------------------------------------------')\nprint('Average scores for all folds:')\nprint(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\nprint(f'> Loss: {np.mean(loss_per_fold)}')\nprint('------------------------------------------------------------------------')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set Seed\nrandom.seed(11)\nset_seed(11)\nnp.random.seed(11)\n  \n# Define the model architecture\nmodel = Sequential()\n  \nmodel.add(Conv2D(64, kernel_size=(3,3), input_shape=input_shape, activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(128, kernel_size=(3,3), activation='relu', padding='same'))\nmodel.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.3))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(256, kernel_size=(3,3), activation='relu', padding='same'))\nmodel.add(Conv2D(256, kernel_size=(3,3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.3))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(512, kernel_size=(3,3), activation='relu', padding='same'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.5))\nmodel.add(BatchNormalization())\n\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(128, activation='softmax'))\n\n# Compile the model\nmodel.compile(loss=loss_function,\n              optimizer=optimizer,\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Training**"},{"metadata":{"trusted":true},"cell_type":"code","source":"Final_train = np.append(X_train, X_val, axis=0)\nFinal_val = np.append(y_train, y_val, axis=0)\nfinal_training_data = train_data_gen.flow(Final_train, Final_val,\n                                   seed=11)\n\nrandom.seed(11)\nset_seed(11)\nnp.random.seed(11)\nfinal_model_history = model.fit(train_data_gen.flow(X, y_gender, seed=11),batch_size=32,epochs=20, validation_data=val_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Generate generalization metrics\nfig = px.line(\nfinal_model_history.history, y=['loss', 'val_loss'],\nlabels={'index': 'epoch', 'value': 'val_loss'}, \ntitle='Training History')\nfig.show()\n\n\n# Generate generalization metrics\nfig = px.line(\nfinal_model_history.history, y=['accuracy', 'val_accuracy'],\nlabels={'index': 'epoch', 'value': 'accuracy'}, \ntitle='Training History')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pwd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save(\"backup\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Metrics\nmodel.evaluate(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict_classes(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Confusion matrix\ncm = confusion_matrix(y_test, y_pred)\nsns.heatmap(cm, cmap='Greens', cbar=False, annot=True, fmt='d');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Error Analysis**"},{"metadata":{"trusted":true},"cell_type":"code","source":"error_index = (y_test != y_pred)#finding error indices\ny_test_error = y_test[error_index]\nX_test_error = X_test[error_index]\nprediction_error = y_pred[error_index]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rows=int(np.floor(sum(error_index)/3)) #rows in subplots\ncols=3 #columns in subplots\nx_samp = X_test_error\ny_samp = y_test_error\n\nfig,ax = plt.subplots(rows,cols,figsize=(15,50))\nr = 0\nc = 0\nfor i in range((rows*cols)-1):\n    aa = x_samp[i].reshape(48,48)\n    ax[r,c].axis(\"off\")\n    ax[r,c].imshow(aa,cmap=\"gray\")\n    actual_lab = \"Female\" if y_samp.iloc[i]==1 else \"Male\"\n    pred_lab = \"Female\" if int(prediction_error[i])==1 else \"Male\"\n    ax[r,c].set_title(f'Actual: {actual_lab}\\nPred: {pred_lab}')\n    c+=1\n    if c == cols:\n        c=0\n        r+=1\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img = cv2.imread('../input/testset/mind-long.jpg',0)\nplt.imshow(img, cmap=\"gray\")\nimg = cv2.resize(img, (48,48))\nimg = np.reshape(img,[1,48,48,1])\nimg_pixels = img.astype(\"float32\") / 255.0\nclasses = model.predict_classes(img_pixels)\n\nmapper=['male','female']\nprint(mapper[classes[0]])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}