{"cells":[{"metadata":{},"cell_type":"markdown","source":"<hr/>\n[**Tolgahan Cepel**](https://www.kaggle.com/tolgahancepel)\n<hr/>\n<font color=green>\n1. [Overview](#1)\n1. [Importing Libraries and Reading the Dataset](#2)\n1. [Data Visualization and Preprocessing](#3)\n1. [Classification Models](#4) \n    * [Logistic Regression](#5) \n    * [K-Nearest Neighbors(K-NN)](#6)\n    * [Support Vector Machine (SVM - Linear)](#7)\n    * [Support Vector Machine (SVM - Kernel)](#8)\n    * [Naive Bayes](#9) \n    * [Decision Tree Classification](#10) \n    * [Random Forest Classification](#11) \n1. [Measuring the Error](#12)\n    * [Visualizing Models Performance](#13) \n1. [Conclusion](#14)\n<hr/>"},{"metadata":{},"cell_type":"markdown","source":"## <span id=\"1\"></span> ** 1. Overview **"},{"metadata":{},"cell_type":"markdown","source":"Input Variables:\n- **fixed acidity: ** most acids involved with wine or fixed or nonvolatile\n- **volatile acidity: ** the amount of acetic acid in wine\n- **citric acid: ** found in small quantities, citric acid can add 'freshness' and flavor to wines \n- **residual sugar: ** the amount of sugar remaining after fermentation stops\n- **chlorides: ** the amount of salt in the wine\n- **free sulfur dioxide: ** the free form of SO2 exists in equilibrium between molecular SO2 (as a dissolved gas) and bisulfite ion\n- **total sulfur dioxide: ** amount of free and bound forms of S02\n- **density: ** the density of water is close to that of water depending on the percent alcohol and sugar content\n- **pH: ** describes how acidic or basic a wine is on a scale from 0 (very acidic) to 14 (very basic)\n- **sulphates: ** a wine additive which can contribute to sulfur dioxide gas (S02) levels \n- **alcohol: ** the percent alcohol content of the wine<br>\n\nOutput Variable:\n- **quality: ** output variable (based on sensory data, score between 0 and 10)"},{"metadata":{},"cell_type":"markdown","source":"## <span id=\"2\"></span> ** 2. Importing Libraries and Reading the Dataset **"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import confusion_matrix\nfrom collections import Counter\nfrom IPython.core.display import display, HTML\nsns.set_style('darkgrid')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"dataset = pd.read_csv('../input/winequality-red.csv')\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <span id=\"3\"></span> ** 3. Data Visualization and Preprocessing **"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bins = (2, 6.5, 8)\nlabels = ['bad', 'good']\ndataset['quality'] = pd.cut(x = dataset['quality'], bins = bins, labels = labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['quality'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Not bad! I mean the result :)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nlabelencoder_y = LabelEncoder()\ndataset['quality'] = labelencoder_y.fit_transform(dataset['quality'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = dataset.corr()\n#Plot figsize\nfig, ax = plt.subplots(figsize=(10, 8))\n#Generate Heat Map, allow annotations and place floats in map\nsns.heatmap(corr, cmap='coolwarm', annot=True, fmt=\".2f\")\n#Apply xticks\nplt.xticks(range(len(corr.columns)), corr.columns);\n#Apply yticks\nplt.yticks(range(len(corr.columns)), corr.columns)\n#show plot\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(1,2,figsize=(14,4))\n\nsns.distplot(dataset['fixed acidity'], ax = axes[0])\naxes[0].set_xlabel('Fixed Acidity', fontsize=14)\naxes[0].set_ylabel('Count', fontsize=14)\naxes[0].yaxis.tick_left()\n\nsns.violinplot(x = 'quality', y = 'fixed acidity', data = dataset, hue = 'quality',ax = axes[1])\naxes[1].set_xlabel('Quality', fontsize=14)\naxes[1].set_ylabel('Fixed Acidity', fontsize=14)\naxes[1].yaxis.set_label_position(\"right\")\naxes[1].yaxis.tick_right()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(1,2,figsize=(14,4))\n\nsns.distplot(dataset['volatile acidity'], ax = axes[0])\naxes[0].set_xlabel('Volatile Acidity', fontsize=14)\naxes[0].set_ylabel('Count', fontsize=14)\naxes[0].yaxis.tick_left()\n\nsns.violinplot(x = 'quality', y = 'volatile acidity', data = dataset, hue = 'quality',ax = axes[1])\naxes[1].set_xlabel('Quality', fontsize=14)\naxes[1].set_ylabel('Volatile Acidity', fontsize=14)\naxes[1].yaxis.set_label_position(\"right\")\naxes[1].yaxis.tick_right()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(1,2,figsize=(14,4))\n\nsns.distplot(dataset['citric acid'], ax = axes[0])\naxes[0].set_xlabel('Citric Acid', fontsize=14)\naxes[0].set_ylabel('Count', fontsize=14)\naxes[0].yaxis.tick_left()\n\nsns.boxenplot(x = 'quality', y = 'citric acid', data = dataset, hue = 'quality',ax = axes[1])\naxes[1].set_xlabel('Quality', fontsize=14)\naxes[1].set_ylabel('Citric Acid', fontsize=14)\naxes[1].yaxis.set_label_position(\"right\")\naxes[1].yaxis.tick_right()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(1,2,figsize=(14,4))\n\nsns.distplot(dataset['residual sugar'], ax = axes[0])\naxes[0].set_xlabel('Residual Sugar', fontsize=14)\naxes[0].set_ylabel('Count', fontsize=14)\naxes[0].yaxis.tick_left()\n\nsns.violinplot(x = 'quality', y = 'residual sugar', data = dataset, hue = 'quality',ax = axes[1])\naxes[1].set_xlabel('Quality', fontsize=14)\naxes[1].set_ylabel('Residual Sugar', fontsize=14)\naxes[1].yaxis.set_label_position(\"right\")\naxes[1].yaxis.tick_right()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(1,2,figsize=(14,4))\n\nsns.distplot(dataset['chlorides'], ax = axes[0])\naxes[0].set_xlabel('Chlorides', fontsize=14)\naxes[0].set_ylabel('Count', fontsize=14)\naxes[0].yaxis.tick_left()\n\nsns.violinplot(x = 'quality', y = 'chlorides', data = dataset, hue = 'quality',ax = axes[1])\naxes[1].set_xlabel('Quality', fontsize=14)\naxes[1].set_ylabel('Chlorides', fontsize=14)\naxes[1].yaxis.set_label_position(\"right\")\naxes[1].yaxis.tick_right()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(2,2,figsize=(14,8))\n\nsns.distplot(dataset['free sulfur dioxide'], ax = axes[0,0])\naxes[0,0].set_xlabel('Free Sulfur Dioxide', fontsize=14)\naxes[0,0].set_ylabel('Count', fontsize=14)\naxes[0,0].yaxis.tick_left()\n\nsns.boxenplot(x = 'quality', y = 'free sulfur dioxide', data = dataset, hue = 'quality',ax = axes[0,1])\naxes[0,1].set_xlabel('Quality', fontsize=14)\naxes[0,1].set_ylabel('Free Sulfur Dioxide', fontsize=14)\naxes[0,1].yaxis.set_label_position(\"right\")\naxes[0,1].yaxis.tick_right()\n\nsns.distplot(dataset['total sulfur dioxide'], ax = axes[1,0])\naxes[1,0].set_xlabel('Total Sulfur Dioxide', fontsize=14)\naxes[1,0].set_ylabel('Count', fontsize=14)\naxes[1,0].yaxis.tick_left()\n\nsns.boxenplot(x = 'quality', y = 'total sulfur dioxide', data = dataset, hue = 'quality',ax = axes[1,1])\naxes[1,1].set_xlabel('Quality', fontsize=14)\naxes[1,1].set_ylabel('Total Sulfur Dioxide', fontsize=14)\naxes[1,1].yaxis.set_label_position(\"right\")\naxes[1,1].yaxis.tick_right()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(1,2,figsize=(14,4))\n\nsns.distplot(dataset['density'], ax = axes[0])\naxes[0].set_xlabel('Density', fontsize=14)\naxes[0].set_ylabel('Count', fontsize=14)\naxes[0].yaxis.tick_left()\n\nsns.violinplot(x = 'quality', y = 'density', data = dataset, hue = 'quality',ax = axes[1])\naxes[1].set_xlabel('Quality', fontsize=14)\naxes[1].set_ylabel('Density', fontsize=14)\naxes[1].yaxis.set_label_position(\"right\")\naxes[1].yaxis.tick_right()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(1,2,figsize=(14,4))\n\nsns.distplot(dataset['pH'], ax = axes[0])\naxes[0].set_xlabel('pH', fontsize=14)\naxes[0].set_ylabel('Count', fontsize=14)\naxes[0].yaxis.tick_left()\n\nsns.violinplot(x = 'quality', y = 'pH', data = dataset, hue = 'quality',ax = axes[1])\naxes[1].set_xlabel('Quality', fontsize=14)\naxes[1].set_ylabel('pH', fontsize=14)\naxes[1].yaxis.set_label_position(\"right\")\naxes[1].yaxis.tick_right()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(1,2,figsize=(14,4))\n\nsns.distplot(dataset['sulphates'], ax = axes[0])\naxes[0].set_xlabel('Sulphates', fontsize=14)\naxes[0].set_ylabel('Count', fontsize=14)\naxes[0].yaxis.tick_left()\n\nsns.violinplot(x = 'quality', y = 'sulphates', data = dataset, hue = 'quality',ax = axes[1])\naxes[1].set_xlabel('Quality', fontsize=14)\naxes[1].set_ylabel('Sulphates', fontsize=14)\naxes[1].yaxis.set_label_position(\"right\")\naxes[1].yaxis.tick_right()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(1,2,figsize=(14,4))\n\nsns.distplot(dataset['alcohol'], ax = axes[0])\naxes[0].set_xlabel('Alcohol', fontsize=14)\naxes[0].set_ylabel('Count', fontsize=14)\naxes[0].yaxis.tick_left()\n\nsns.violinplot(x = 'quality', y = 'alcohol', data = dataset, hue = 'quality',ax = axes[1])\naxes[1].set_xlabel('Quality', fontsize=14)\naxes[1].set_ylabel('Alcohol', fontsize=14)\naxes[1].yaxis.set_label_position(\"right\")\naxes[1].yaxis.tick_right()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['quality'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = dataset.drop('quality', axis = 1).values\ny = dataset['quality'].values.reshape(-1,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Shape of X_train: \",X_train.shape)\nprint(\"Shape of X_test: \", X_test.shape)\nprint(\"Shape of y_train: \",y_train.shape)\nprint(\"Shape of y_test\",y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## <span id=\"4\"></span> ** 4. Classification Models **"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train_scaled = sc.fit_transform(X_train)\nX_test_scaled = sc.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <span id=\"5\"></span> ** Logistic Regression **"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fitting Logistic Regression to the Training set\nfrom sklearn.linear_model import LogisticRegression\nclassifier_lr = LogisticRegression(C=1, fit_intercept=True, max_iter=1000, penalty = 'l2', solver='liblinear')\nclassifier_lr.fit(X_train_scaled, y_train.ravel())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predicting Cross Validation Score\ncv_lr = cross_val_score(estimator = classifier_lr, X = X_train_scaled, y = y_train.ravel(), cv = 10)\nprint(\"CV: \", cv_lr.mean())\n\ny_pred_lr_train = classifier_lr.predict(X_train_scaled)\naccuracy_lr_train = accuracy_score(y_train, y_pred_lr_train)\nprint(\"Training set: \", accuracy_lr_train)\n\ny_pred_lr_test = classifier_lr.predict(X_test_scaled)\naccuracy_lr_test = accuracy_score(y_test, y_pred_lr_test)\nprint(\"Test set: \", accuracy_lr_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(y_test, y_pred_lr_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tp_lr = confusion_matrix(y_test, y_pred_lr_test)[0,0]\nfp_lr = confusion_matrix(y_test, y_pred_lr_test)[0,1]\ntn_lr = confusion_matrix(y_test, y_pred_lr_test)[1,1]\nfn_lr = confusion_matrix(y_test, y_pred_lr_test)[1,0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <span id=\"6\"></span> ** K-Nearest Neighbors (K-NN) **"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fitting classifier to the Training set\nfrom sklearn.neighbors import KNeighborsClassifier\nclassifier_knn = KNeighborsClassifier(leaf_size = 1, metric = 'minkowski', n_neighbors = 32, weights = 'distance')\nclassifier_knn.fit(X_train_scaled, y_train.ravel())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predicting Cross Validation Score\ncv_knn = cross_val_score(estimator = classifier_knn, X = X_train_scaled, y = y_train.ravel(), cv = 10)\nprint(\"CV: \", cv_knn.mean())\n\ny_pred_knn_train = classifier_knn.predict(X_train_scaled)\naccuracy_knn_train = accuracy_score(y_train, y_pred_knn_train)\nprint(\"Training set: \", accuracy_knn_train)\n\ny_pred_knn_test = classifier_knn.predict(X_test_scaled)\naccuracy_knn_test = accuracy_score(y_test, y_pred_knn_test)\nprint(\"Test set: \", accuracy_knn_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(y_test, y_pred_knn_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tp_knn = confusion_matrix(y_test, y_pred_knn_test)[0,0]\nfp_knn = confusion_matrix(y_test, y_pred_knn_test)[0,1]\ntn_knn = confusion_matrix(y_test, y_pred_knn_test)[1,1]\nfn_knn = confusion_matrix(y_test, y_pred_knn_test)[1,0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <span id=\"7\"></span> ** Support Vector Machine (SVM - Linear) **"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fitting classifier to the Training set\nfrom sklearn.svm import SVC\nclassifier_svm_linear = SVC(kernel = 'linear')\nclassifier_svm_linear.fit(X_train_scaled, y_train.ravel())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predicting Cross Validation Score\ncv_svm_linear = cross_val_score(estimator = classifier_svm_linear, X = X_train_scaled, y = y_train.ravel(), cv = 10)\nprint(\"CV: \", cv_svm_linear.mean())\n\ny_pred_svm_linear_train = classifier_svm_linear.predict(X_train_scaled)\naccuracy_svm_linear_train = accuracy_score(y_train, y_pred_svm_linear_train)\nprint(\"Training set: \", accuracy_svm_linear_train)\n\ny_pred_svm_linear_test = classifier_svm_linear.predict(X_test_scaled)\naccuracy_svm_linear_test = accuracy_score(y_test, y_pred_svm_linear_test)\nprint(\"Test set: \", accuracy_svm_linear_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(y_test, y_pred_svm_linear_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tp_svm_linear = confusion_matrix(y_test, y_pred_svm_linear_test)[0,0]\nfp_svm_linear = confusion_matrix(y_test, y_pred_svm_linear_test)[0,1]\ntn_svm_linear = confusion_matrix(y_test, y_pred_svm_linear_test)[1,1]\nfn_svm_linear = confusion_matrix(y_test, y_pred_svm_linear_test)[1,0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <span id=\"8\"></span> ** Support Vector Machine (SVM - Kernel) **"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fitting classifier to the Training set\nfrom sklearn.svm import SVC\nclassifier_svm_kernel = SVC(kernel = 'rbf', C = 10, tol = 0.001, gamma = 'scale')\nclassifier_svm_kernel.fit(X_train_scaled, y_train.ravel())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predicting Cross Validation Score\ncv_svm_kernel = cross_val_score(estimator = classifier_svm_kernel, X = X_train_scaled, y = y_train.ravel(), cv = 10)\nprint(\"CV: \", cv_svm_kernel.mean())\n\ny_pred_svm_kernel_train = classifier_svm_kernel.predict(X_train_scaled)\naccuracy_svm_kernel_train = accuracy_score(y_train, y_pred_svm_kernel_train)\nprint(\"Training set: \", accuracy_svm_kernel_train)\n\ny_pred_svm_kernel_test = classifier_svm_kernel.predict(X_test_scaled)\naccuracy_svm_kernel_test = accuracy_score(y_test, y_pred_svm_kernel_test)\nprint(\"Test set: \", accuracy_svm_kernel_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(y_test, y_pred_svm_kernel_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tp_svm_kernel = confusion_matrix(y_test, y_pred_svm_kernel_test)[0,0]\nfp_svm_kernel = confusion_matrix(y_test, y_pred_svm_kernel_test)[0,1]\ntn_svm_kernel = confusion_matrix(y_test, y_pred_svm_kernel_test)[1,1]\nfn_svm_kernel = confusion_matrix(y_test, y_pred_svm_kernel_test)[1,0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <span id=\"9\"></span> ** Naive Bayes **"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fitting classifier to the Training set\nfrom sklearn.naive_bayes import GaussianNB\nclassifier_nb = GaussianNB()\nclassifier_nb.fit(X_train_scaled, y_train.ravel())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predicting Cross Validation Score\ncv_nb = cross_val_score(estimator = classifier_nb, X = X_train_scaled, y = y_train.ravel(), cv = 10)\nprint(\"CV: \", cv_nb.mean())\n\ny_pred_nb_train = classifier_nb.predict(X_train_scaled)\naccuracy_nb_train = accuracy_score(y_train, y_pred_nb_train)\nprint(\"Training set: \", accuracy_nb_train)\n\ny_pred_nb_test = classifier_nb.predict(X_test_scaled)\naccuracy_nb_test = accuracy_score(y_test, y_pred_nb_test)\nprint(\"Test set: \", accuracy_nb_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(y_test, y_pred_nb_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tp_nb = confusion_matrix(y_test, y_pred_nb_test)[0,0]\nfp_nb = confusion_matrix(y_test, y_pred_nb_test)[0,1]\ntn_nb = confusion_matrix(y_test, y_pred_nb_test)[1,1]\nfn_nb = confusion_matrix(y_test, y_pred_nb_test)[1,0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <span id=\"10\"></span> ** Decision Tree Classification **"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fitting classifier to the Training set\nfrom sklearn.tree import DecisionTreeClassifier\nclassifier_dt = DecisionTreeClassifier(criterion = 'gini', max_features=6, max_leaf_nodes=400, random_state = 33)\nclassifier_dt.fit(X_train_scaled, y_train.ravel())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predicting Cross Validation Score\ncv_dt = cross_val_score(estimator = classifier_dt, X = X_train_scaled, y = y_train.ravel(), cv = 10)\nprint(\"CV: \", cv_dt.mean())\n\ny_pred_dt_train = classifier_dt.predict(X_train_scaled)\naccuracy_dt_train = accuracy_score(y_train, y_pred_dt_train)\nprint(\"Training set: \", accuracy_dt_train)\n\ny_pred_dt_test = classifier_dt.predict(X_test_scaled)\naccuracy_dt_test = accuracy_score(y_test, y_pred_dt_test)\nprint(\"Test set: \", accuracy_dt_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(y_test, y_pred_dt_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tp_dt = confusion_matrix(y_test, y_pred_dt_test)[0,0]\nfp_dt = confusion_matrix(y_test, y_pred_dt_test)[0,1]\ntn_dt = confusion_matrix(y_test, y_pred_dt_test)[1,1]\nfn_dt = confusion_matrix(y_test, y_pred_dt_test)[1,0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <span id=\"11\"></span> ** Random Forest Classification **"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fitting Random Forest Classification to the Training set\nfrom sklearn.ensemble import RandomForestClassifier\nclassifier_rf = RandomForestClassifier(criterion = 'entropy', max_features = 4, n_estimators = 800, random_state=33)\nclassifier_rf.fit(X_train_scaled, y_train.ravel())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predicting Cross Validation Score\ncv_rf = cross_val_score(estimator = classifier_rf, X = X_train_scaled, y = y_train.ravel(), cv = 10)\nprint(\"CV: \", cv_rf.mean())\n\ny_pred_rf_train = classifier_rf.predict(X_train_scaled)\naccuracy_rf_train = accuracy_score(y_train, y_pred_rf_train)\nprint(\"Training set: \", accuracy_rf_train)\n\ny_pred_rf_test = classifier_rf.predict(X_test_scaled)\naccuracy_rf_test = accuracy_score(y_test, y_pred_rf_test)\nprint(\"Test set: \", accuracy_rf_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(y_test, y_pred_rf_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tp_rf = confusion_matrix(y_test, y_pred_rf_test)[0,0]\nfp_rf = confusion_matrix(y_test, y_pred_rf_test)[0,1]\ntn_rf = confusion_matrix(y_test, y_pred_rf_test)[1,1]\nfn_rf = confusion_matrix(y_test, y_pred_rf_test)[1,0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <span id=\"12\"></span> ** 6. Measuring The Error **"},{"metadata":{"trusted":true},"cell_type":"code","source":"models = [('Logistic Regression', tp_lr, fp_lr, tn_lr, fn_lr, accuracy_lr_train, accuracy_lr_test, cv_lr.mean()),\n          ('K-Nearest Neighbors (KNN)', tp_knn, fp_knn, tn_knn, fn_knn, accuracy_knn_train, accuracy_knn_test, cv_knn.mean()),\n          ('SVM (Linear)', tp_svm_linear, fp_svm_linear, tn_svm_linear, fn_svm_linear, accuracy_svm_linear_train, accuracy_svm_linear_test, cv_svm_linear.mean()),\n          ('SVM (Kernel)', tp_svm_kernel, fp_svm_kernel, tn_svm_kernel, fn_svm_kernel, accuracy_svm_kernel_train, accuracy_svm_kernel_test, cv_svm_kernel.mean()),\n          ('Naive Bayes', tp_nb, fp_nb, tn_nb, fn_nb, accuracy_nb_train, accuracy_nb_test, cv_nb.mean()),\n          ('Decision Tree Classification', tp_dt, fp_dt, tn_dt, fn_dt, accuracy_dt_train, accuracy_dt_test, cv_dt.mean()),\n          ('Random Forest Tree Classification', tp_rf, fp_rf, tn_rf, fn_rf, accuracy_rf_train, accuracy_rf_test, cv_rf.mean())\n         ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict = pd.DataFrame(data = models, columns=['Model', 'True Positive', 'False Positive', 'True Negative',\n                                               'False Negative', 'Accuracy(training)', 'Accuracy(test)',\n                                               'Cross-Validation'])\npredict","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <span id=\"13\"></span> ** Visualizing Models Performance **"},{"metadata":{"trusted":true},"cell_type":"code","source":"f, axe = plt.subplots(1,1, figsize=(18,6))\n\npredict.sort_values(by=['Cross-Validation'], ascending=False, inplace=True)\n\nsns.barplot(x='Cross-Validation', y='Model', data = predict, ax = axe)\n#axes[0].set(xlabel='Region', ylabel='Charges')\naxe.set_xlabel('Cross-Validaton Score', size=16)\naxe.set_ylabel('Model')\naxe.set_xlim(0,1.0)\naxe.set_xticks(np.arange(0, 1.1, 0.1))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(2,1, figsize=(14,10))\n\npredict.sort_values(by=['Accuracy(training)'], ascending=False, inplace=True)\n\nsns.barplot(x='Accuracy(training)', y='Model', data = predict, palette='Blues_d', ax = axes[0])\n#axes[0].set(xlabel='Region', ylabel='Charges')\naxes[0].set_xlabel('Accuracy (Training)', size=16)\naxes[0].set_ylabel('Model')\naxes[0].set_xlim(0,1.0)\naxes[0].set_xticks(np.arange(0, 1.1, 0.1))\n\npredict.sort_values(by=['Accuracy(test)'], ascending=False, inplace=True)\n\nsns.barplot(x='Accuracy(test)', y='Model', data = predict, palette='Reds_d', ax = axes[1])\n#axes[0].set(xlabel='Region', ylabel='Charges')\naxes[1].set_xlabel('Accuracy (Test)', size=16)\naxes[1].set_ylabel('Model')\naxes[1].set_xlim(0,1.0)\naxes[1].set_xticks(np.arange(0, 1.1, 0.1))\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict.sort_values(by=(['Accuracy(test)']), ascending=True, inplace=True)\n\nf, axe = plt.subplots(1,1, figsize=(24,8))\nsns.barplot(x = predict['Model'], y=predict['False Positive'] + predict['False Negative'], ax = axe)\naxe.set_xlabel('Model', size=20)\naxe.set_ylabel('False Observations', size=20)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <span id=\"14\"></span> ** 7. Conclusion **"},{"metadata":{},"cell_type":"markdown","source":"In this kernel, I have built 7 classification models using Red Wine Quality Dataset. These are logistic, k-nn, svm(linear), svm(kernel), naive bayes, decision tree and random forest classification. Then measured and visualized the performance of the models. Please make a comment and let me know how to improve model performance, visualization or something in this kernel. This will also help me on my future analysis.\n\n<b><font color=\"red\">Don't forget to </font></b> <b><font color=\"green\">UPVOTE </font></b> if you liked this kernel, thank you. üôÇüëç"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}