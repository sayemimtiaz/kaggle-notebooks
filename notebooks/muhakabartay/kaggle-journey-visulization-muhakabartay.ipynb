{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Kaggle Journey\nCurrent notebook url: [www.kaggle.com/muhakabartay/kaggle-journey-visulization-muhakabartay](https://www.kaggle.com/muhakabartay/kaggle-journey-visulization-muhakabartay)  \nFeel free to use, change and track your journey just changing `user_name` variable to yours.  \nUpvote is you like it, together with [notebook](https://www.kaggle.com/yassinealouini/yassine-s-journey), [notebook](https://www.kaggle.com/sudalairajkumar/a-look-back-at-your-kaggle-journey), and [notebook](https://www.kaggle.com/shivamb/analyse-your-kaggle-profile-framework) I used to prepare this report."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"## Main imports for journey report\nimport string\nimport datetime\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ncolor = sns.color_palette()\n\n%matplotlib inline\n\nfrom plotly import tools\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\n\npd.options.mode.chained_assignment = None\npd.options.display.max_columns = 999","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Additional imports for autoreports\nimport re \nimport warnings\nimport operator\nfrom plotly.offline import init_notebook_mode, iplot\nfrom wordcloud import WordCloud, STOPWORDS \nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import stopwords \nfrom collections import Counter\nimport IPython.display\nfrom IPython.core.display import HTML\nfrom PIL import Image ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Username"},{"metadata":{"trusted":true},"cell_type":"code","source":"user_name = \"muhakabartay\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"users_df = pd.read_csv(\"../input/meta-kaggle/Users.csv\")\nuser_df = users_df[users_df[\"UserName\"]==user_name]\nuser_id = user_df[\"Id\"].values[0]\nuser_display = user_df[\"DisplayName\"].values[0]\nprint(\"The user id for the given user name is : \",user_id)\nprint(\"The display name for the given user name is : \",user_display)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Competitions"},{"metadata":{"trusted":true},"cell_type":"code","source":"team_members_df = pd.read_csv(\"../input/meta-kaggle/TeamMemberships.csv\")\nteam_df = pd.read_csv(\"../input/meta-kaggle/Teams.csv\")\ncomp_df = pd.read_csv(\"../input/meta-kaggle/Competitions.csv\")\n\ntemp_df = team_members_df[team_members_df[\"UserId\"]==user_id]\ntemp_df = pd.merge(temp_df, team_df, left_on=\"TeamId\", right_on=\"Id\", how=\"left\")\ntemp_df = pd.merge(temp_df, comp_df, left_on=\"CompetitionId\", right_on=\"Id\", how=\"left\")\n\ntemp_df[\"DeadlineDate\"] = pd.to_datetime(temp_df[\"DeadlineDate\"], format=\"%m/%d/%Y %H:%M:%S\")\ntemp_df[\"DeadlineYear\"] = temp_df[\"DeadlineDate\"].dt.year\ntemp_df[\"DeadlineDate\"] = temp_df[\"DeadlineDate\"].apply(lambda x: datetime.date(x.year,x.month,1))\n\ntemp_df = temp_df[~np.isnan(temp_df[\"PrivateLeaderboardRank\"])]\ntemp_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Competition types"},{"metadata":{"trusted":true},"cell_type":"code","source":"cnt_srs = temp_df[\"HostSegmentTitle\"].value_counts()\n\nlabels = (np.array(cnt_srs.index))\nsizes = (np.array((cnt_srs / cnt_srs.sum())*100))\n\ntrace = go.Pie(labels=labels, values=sizes)\nlayout = go.Layout(\n    title='Competition Type Distribution',\n    font=dict(size=14),\n    width=700,\n    height=700,\n)\ndata = [trace]\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig, filename=\"usertype\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data types in competitions"},{"metadata":{"trusted":true},"cell_type":"code","source":"comp_tags_df = pd.read_csv(\"../input/meta-kaggle/CompetitionTags.csv\")\ntags_df = pd.read_csv(\"../input/meta-kaggle/Tags.csv\")\ncnt_df = pd.merge(temp_df[[\"CompetitionId\"]], comp_tags_df, on=\"CompetitionId\", how=\"inner\")\ncnt_df = pd.merge(cnt_df, tags_df, left_on=\"TagId\", right_on=\"Id\", how=\"inner\")\ncnt_df[\"Name\"].value_counts()\n\ndef bar_chart(cnt_srs, color):\n    trace = go.Bar(\n        x=cnt_srs.index,\n        y=cnt_srs.values,\n        showlegend=False,\n        marker=dict(\n            color=color,\n        ),\n    )\n    return trace\n\ncnt_srs = cnt_df[\"Name\"].value_counts().head(10)\ntraces = [bar_chart(cnt_srs, \"orange\")]\nlayout = go.Layout(\n    title='Data type of competitions',\n    font=dict(size=14),\n    barmode='stack',\n    width=1000,\n    height=600,\n)\n\nfig = go.Figure(data=traces, layout=layout)\npy.iplot(fig, filename='stacked-bar')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Seems I like Computer Vision competitions as well as tabular data.**"},{"metadata":{},"cell_type":"markdown","source":"### My teams"},{"metadata":{"trusted":true},"cell_type":"code","source":"cnt_srs = temp_df[\"TeamName\"].value_counts().head(5)\ntraces = [bar_chart(cnt_srs, \"green\")]\nlayout = go.Layout(\n    title='Favorite Team Name',\n    font=dict(size=14),\n    barmode='stack',\n    width=1000,\n    height=600,\n)\n\nfig = go.Figure(data=traces, layout=layout)\npy.iplot(fig, filename='stacked-bar')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Seems my team names mostly is used once, and surely I use my name when I Kaggle alone.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"temp_df = team_members_df[team_members_df[\"UserId\"]==user_id]\ntemp_df = pd.merge(team_members_df, temp_df, on=\"TeamId\", how=\"inner\", suffixes=('', '_y'))\ntemp_df = temp_df[temp_df[\"UserId\"]!=user_id]\ntemp_df = pd.merge(temp_df, users_df, left_on=\"UserId\", right_on=\"Id\", how=\"left\")\n\ncnt_srs = temp_df[\"DisplayName\"].value_counts().head(7)\ntraces = [bar_chart(cnt_srs, \"red\")]\nlayout = go.Layout(\n    title='Number of competitions with favorite team members ',\n    font=dict(size=14),\n    barmode='stack',\n    width=1000,\n    height=600,\n)\n\nfig = go.Figure(data=traces, layout=layout)\npy.iplot(fig, filename='stacked-bar')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**My brilliant teammates**\n* [Ashish Gupta](https://www.kaggle.com/roydatascience) 42\n* [Manoj Prabhakar](https://www.kaggle.com/manojprabhaakr) 13\n* [Carlo Lepelaars](https://www.kaggle.com/carlolepelaars) 13 \n* [Yassine Alouini](https://www.kaggle.com/yassinealouini) 8\n* [Firat Gonen](https://www.kaggle.com/frtgnn) 7\n* [Stanislav Blinov](https://www.kaggle.com/stanislavblinov) 5 \n* [Rohit Agarwal](https://www.kaggle.com/rohitagarwal) 4\n* [Vladimir Sydorskyy](https://www.kaggle.com/vladimirsydor) 2 (not plotted but worth mentioning -we did 2 great silvers together)\n\nPlease,  check [Yassine Alouini](https://www.kaggle.com/yassinealouini)'s journey in this amazing [notebook](https://www.kaggle.com/yassinealouini/yassine-s-journey) on which this one is based on. Original [notebook](https://www.kaggle.com/sudalairajkumar/a-look-back-at-your-kaggle-journey). Upvote are welcome."},{"metadata":{},"cell_type":"markdown","source":"### Ranks"},{"metadata":{"trusted":true},"cell_type":"code","source":"## We redefine here\nteam_members_df = pd.read_csv(\"../input/meta-kaggle/TeamMemberships.csv\")\nteam_df = pd.read_csv(\"../input/meta-kaggle/Teams.csv\")\ncomp_df = pd.read_csv(\"../input/meta-kaggle/Competitions.csv\")\n\ntemp_df = team_members_df[team_members_df[\"UserId\"]==user_id]\ntemp_df = pd.merge(temp_df, team_df, left_on=\"TeamId\", right_on=\"Id\", how=\"left\")\ntemp_df = pd.merge(temp_df, comp_df, left_on=\"CompetitionId\", right_on=\"Id\", how=\"left\")\n\ntemp_df[\"DeadlineDate\"] = pd.to_datetime(temp_df[\"DeadlineDate\"], format=\"%m/%d/%Y %H:%M:%S\")\ntemp_df[\"DeadlineYear\"] = temp_df[\"DeadlineDate\"].dt.year\ntemp_df[\"DeadlineDate\"] = temp_df[\"DeadlineDate\"].apply(lambda x: datetime.date(x.year,x.month,1))\n\ntemp_df = temp_df[~np.isnan(temp_df[\"PrivateLeaderboardRank\"])]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def scatter_plot(cnt_srs, color):\n    trace = go.Scatter(\n        x=cnt_srs.index[::-1],\n        y=cnt_srs.values[::-1],\n        showlegend=False,\n        marker=dict(\n            color=color,\n        ),\n    )\n    return trace\n\ncnt_df = temp_df.groupby('DeadlineYear')['PrivateLeaderboardRank'].agg([\"size\", \"mean\", \"min\"])\ncnt_srs = cnt_df[\"size\"]\ncnt_srs = cnt_srs.sort_index()\ntrace = go.Bar(\n    x=cnt_srs.index,\n    y=cnt_srs.values,\n    marker=dict(color=\"green\",),\n)\n\nlayout = go.Layout(\n    title='Count of competitions over years',\n    font=dict(size=14),\n    width=700,\n    height=600,\n)\n\ndata = [trace]\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig, filename=\"TargetCount\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Mean Private Rank \ncnt_srs = cnt_df[\"mean\"]\ncnt_srs = cnt_srs.sort_index()\ntrace = go.Bar(\n    x=cnt_srs.index,\n    y=cnt_srs.values,\n    marker=dict(color=\"blue\",),\n)\n\nlayout = go.Layout(\n    title='Mean Rank over years',\n    font=dict(size=14),\n    width=700,\n    height=600,\n)\n\ndata = [trace]\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig, filename=\"TargetCount\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Best rank each year \ncnt_srs = cnt_df[\"min\"]\ncnt_srs = cnt_srs.sort_index()\ntrace = go.Bar(\n    x=cnt_srs.index,\n    y=cnt_srs.values,\n    marker=dict(color=\"red\",),\n)\n\nlayout = go.Layout(\n    title='Best Rank in each year',\n    font=dict(size=14),\n    width=700,\n    height=600,\n)\n\ndata = [trace]\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig, filename=\"TargetCount\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Medals"},{"metadata":{"trusted":true},"cell_type":"code","source":"temp_df[\"Medal\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"{} Silver medals\".format(temp_df[\"Medal\"].value_counts().iloc[1]))\nprint(\"{} Bronze medals\".format(temp_df[\"Medal\"].value_counts().iloc[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cnt_df = temp_df.pivot_table(index=\"DeadlineYear\", columns=\"Medal\", values=\"PrivateLeaderboardRank\", aggfunc=\"count\")\ncnt_df = cnt_df.fillna(0)\n\ndef get_bar_chart(cnt_srs, name, color):\n    trace = go.Bar(\n        x=cnt_srs.index,\n        y=cnt_srs.values,\n        name=name,\n        marker=dict(color=color,),\n    )\n    return trace\n\nmedal_map = {1.:\"Gold\", 2.:\"Silver\", 3.:\"Bronze\"}\ncolor_map = {1.:\"gold\", 2.:\"silver\", 3.:\"darkorange\"}\ntraces = []\nfor col in np.array(cnt_df.columns)[::-1]:\n    cnt_srs = cnt_df[col]\n    traces.append(get_bar_chart(cnt_srs, medal_map[col], color_map[col]))\n\nlayout = go.Layout(\n    title='Competition Medals in each year',\n    font=dict(size=14),\n    barmode='stack',\n    width=700,\n    height=600,\n)\n\nfig = go.Figure(data=traces, layout=layout)\npy.iplot(fig, filename='stacked-bar')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Seems I become better, more silvers in 2020 after 1 year of experience in competitions**"},{"metadata":{},"cell_type":"markdown","source":"## Kernels/Notebooks"},{"metadata":{"trusted":true},"cell_type":"code","source":"kernels_df = pd.read_csv(\"../input/meta-kaggle/Kernels.csv\")\ntemp_df = kernels_df[kernels_df[\"AuthorUserId\"]==user_id]\ntemp_df[\"MadePublicDate\"] = pd.to_datetime(temp_df[\"MadePublicDate\"], format=\"%m/%d/%Y\")\ntemp_df[\"MadePublicYear\"] = temp_df[\"MadePublicDate\"].dt.year\ntemp_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Number of kernels\ncnt_srs = temp_df[\"MadePublicYear\"].value_counts()\ntraces = [bar_chart(cnt_srs, \"blue\")]\nlayout = go.Layout(\n    title='Number of kernels in each year',\n    font=dict(size=14),\n    width=500,\n    height=500,\n)\n\nfig = go.Figure(data=traces, layout=layout)\npy.iplot(fig, filename='stacked-bar')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Seems number of notebooks I create is growing, almost x2. Will try to double it in 2021 too.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Number of views\ncnt_srs = temp_df.groupby(\"MadePublicYear\")[\"TotalViews\"].mean()\ntraces = [bar_chart(cnt_srs, \"green\")]\nlayout = go.Layout(\n    title='Mean number of views per kernel',\n    font=dict(size=14),\n    width=500,\n    height=500,\n)\n\nfig = go.Figure(data=traces, layout=layout)\npy.iplot(fig, filename='stacked-bar')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Seems I should promote my notebooks better. Almost x4 times decrease in views per notebook (x2 in total while I made x2 more notebooks in 2020).**"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Number of votes\ncnt_srs = temp_df.groupby(\"MadePublicYear\")[\"TotalVotes\"].mean()\ntraces = [bar_chart(cnt_srs, \"red\")]\nlayout = go.Layout(\n    title='Mean number of votes per kernel',\n    font=dict(size=14),\n    width=500,\n    height=500,\n)\n\nfig = go.Figure(data=traces, layout=layout)\npy.iplot(fig, filename='stacked-bar')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Seems I should promote my notebooks better. Almost 50% decrease in upvote rate per notebook.**"},{"metadata":{},"cell_type":"markdown","source":"### Medals"},{"metadata":{"trusted":true},"cell_type":"code","source":"cnt_df = temp_df.pivot_table(index=\"MadePublicYear\", columns=\"Medal\", values=\"AuthorUserId\", aggfunc=\"count\")\ncnt_df = cnt_df.fillna(0)\n\ndef get_bar_chart(cnt_srs, name, color):\n    trace = go.Bar(\n        x=cnt_srs.index,\n        y=cnt_srs.values,\n        name=name,\n        marker=dict(\n            color=color,\n        ),\n    )\n    return trace\n\nmedal_map = {1.:\"Gold\", 2.:\"Silver\", 3.:\"Bronze\"}\ncolor_map = {1.:\"gold\", 2.:\"silver\", 3.:\"darkorange\"}\ntraces = []\nfor col in np.array(cnt_df.columns)[::-1]:\n    cnt_srs = cnt_df[col]\n    traces.append(get_bar_chart(cnt_srs, medal_map[col], color_map[col]))\n\nlayout = go.Layout(\n    title='Kernel Medals in each year',\n    font=dict(size=14),\n    barmode='stack',\n    width=700,\n    height=600,\n)\n\nfig = go.Figure(data=traces, layout=layout)\npy.iplot(fig, filename='stacked-bar')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Seems I become better in 2020, more bronze medals, new gold medal. Willing to get more gold medals in 2021.**"},{"metadata":{},"cell_type":"markdown","source":"### Tags"},{"metadata":{"trusted":true},"cell_type":"code","source":"temp_df = kernels_df[kernels_df[\"AuthorUserId\"]==user_id]\nkernel_tags_df = pd.read_csv(\"../input/meta-kaggle/KernelTags.csv\")\ntemp_df = pd.merge(temp_df, kernel_tags_df, left_on=\"Id\", right_on=\"KernelId\", how=\"inner\")\ntemp_df = pd.merge(temp_df, tags_df, left_on=\"TagId\", right_on=\"Id\", how=\"inner\")\n\ncnt_srs = temp_df[\"Name\"].value_counts().head(15)\ntraces = [bar_chart(cnt_srs, \"orange\")]\nlayout = go.Layout(\n    title='Tag count of the kernels',\n    font=dict(size=14),\n    barmode='stack',\n    width=1300,\n    height=600,\n)\n\nfig = go.Figure(data=traces, layout=layout)\npy.iplot(fig, filename='stacked-bar')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**My notebooks are mostly EDA with few DL oriented. Plan for 2021 to have more ML/DL models oriented notebooks.**"},{"metadata":{},"cell_type":"markdown","source":"## Discussions"},{"metadata":{"trusted":true},"cell_type":"code","source":"#temp_df = kernels_df[kernels_df[\"AuthorUserId\"]==user_id]\nforum_message_df = pd.read_csv(\"../input/meta-kaggle/ForumMessages.csv\")\ntemp_df = forum_message_df[forum_message_df[\"PostUserId\"]==user_id]\ntemp_df[\"PostDate\"] = pd.to_datetime(temp_df[\"PostDate\"], format=\"%m/%d/%Y %H:%M:%S\")\ntemp_df[\"PostYear\"] = temp_df[\"PostDate\"].dt.year\ntemp_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Number of kernels\ncnt_srs = temp_df[\"PostYear\"].value_counts()\ntraces = [bar_chart(cnt_srs, \"blue\")]\nlayout = go.Layout(\n    title='Number of forum posts in each year',\n    font=dict(size=14),\n    width=700,\n    height=600,\n)\n\nfig = go.Figure(data=traces, layout=layout)\npy.iplot(fig, filename='stacked-bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cnt_df = temp_df.pivot_table(index=\"PostYear\", columns=\"Medal\", values=\"PostUserId\", aggfunc=\"count\")\ncnt_df = cnt_df.fillna(0)\n\ndef get_bar_chart(cnt_srs, name, color):\n    trace = go.Bar(\n        x=cnt_srs.index,\n        y=cnt_srs.values,\n        name=name,\n        marker=dict(\n            color=color,\n        ),\n    )\n    return trace\n\nmedal_map = {1.:\"Gold\", 2.:\"Silver\", 3.:\"Bronze\"}\ncolor_map = {1.:\"gold\", 2.:\"silver\", 3.:\"darkorange\"}\ntraces = []\nfor col in np.array(cnt_df.columns)[::-1]:\n    cnt_srs = cnt_df[col]\n    traces.append(get_bar_chart(cnt_srs, medal_map[col], color_map[col]))\n\nlayout = go.Layout(\n    title='Discussion Medals in each year',\n    font=dict(size=14),\n    barmode='stack',\n    width=700,\n    height=600,\n)\n\nfig = go.Figure(data=traces, layout=layout)\npy.iplot(fig, filename='stacked-bar')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**I was very active in 2019 and took some break in 2020. Seems I should come back in 2021.**"},{"metadata":{},"cell_type":"markdown","source":"## Nice "},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\ndef clean_string(txt):\n    txt = str(txt)\n    txt = re.sub(\"<.*?>\", \"\", txt)\n    txt = re.sub(' +', ' ', txt)\n    return txt\n\ntemp_df[\"Message\"] = temp_df[\"Message\"].apply(lambda x: clean_string(x))\n#temp_df.head()\n\nfrom wordcloud import WordCloud, STOPWORDS\n\n# Thanks : https://www.kaggle.com/aashita/word-clouds-of-various-shapes ##\ndef plot_wordcloud(text, mask=None, max_words=300, max_font_size=100, figure_size=(24.0,16.0), \n                   title = None, title_size=40, image_color=False):\n    stopwords = set(STOPWORDS)\n    more_stopwords = {'one', 'br', 'Po', 'th', 'sayi', 'fo', 'Unknown'}\n    stopwords = stopwords.union(more_stopwords)\n\n    wordcloud = WordCloud(background_color='black',\n                    stopwords = stopwords,\n                    max_words = max_words,\n                    max_font_size = max_font_size, \n                    random_state = 42,\n                    width=800, \n                    height=400,\n                    mask = mask)\n    wordcloud.generate(str(text))\n    \n    plt.figure(figsize=figure_size)\n    if image_color:\n        image_colors = ImageColorGenerator(mask);\n        plt.imshow(wordcloud.recolor(color_func=image_colors), interpolation=\"bilinear\");\n        plt.title(title, fontdict={'size': title_size,  \n                                  'verticalalignment': 'bottom'})\n    else:\n        plt.imshow(wordcloud);\n        plt.title(title, fontdict={'size': title_size, 'color': 'black', \n                                  'verticalalignment': 'bottom'})\n    plt.axis('off');\n    plt.tight_layout()  \n    \nplot_wordcloud(temp_df[\"Message\"], title=\"Word Cloud of the common words in forum messages\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## AutoReport "},{"metadata":{"trusted":true},"cell_type":"code","source":"## Environment Preparation\nwarnings.filterwarnings(\"ignore\")\ninit_notebook_mode(connected=True)\nstopwords = stopwords.words(\"english\")\npunc = string.punctuation \nlem = WordNetLemmatizer()\n\n## Load dataset\nuser_followers = pd.read_csv(\"../input/meta-kaggle/UserFollowers.csv\")\nkernels_tag_df = pd.read_csv(\"../input/meta-kaggle/KernelTags.csv\")\nmessages = pd.read_csv(\"../input/meta-kaggle/ForumMessages.csv\")\nforums_df = pd.read_csv(\"../input/meta-kaggle/Forums.csv\")\nkernels_df = pd.read_csv(\"../input/meta-kaggle/Kernels.csv\")\ntags_df = pd.read_csv(\"../input/meta-kaggle/Tags.csv\")\nusers = pd.read_csv(\"../input/meta-kaggle/Users.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## function to clean the text\ndef clean_text(txt):    \n    txt = txt.lower()\n    txt = re.sub('<[^<]+?>', '', txt)\n    txt = \"\".join(x for x in txt if x not in punc)\n    words = txt.split()\n    words = [wrd for wrd in words if wrd not in stopwords]\n    words = [wrd for wrd in words if not wrd.startswith(\"http\")]\n    txt = \" \".join(words)\n    return txt\n\n## function to generate ngrams\ndef ngrams(txt, n):\n    txt = txt.split()\n    output = []\n    for i in range(len(txt)-n+1):\n        output.append(\" \".join(txt[i:i+n]))\n    return output\n\n## function to create bins \ndef wordmap(val):\n    if val < 10:\n        return \"0-10\"\n    elif val < 20:\n        return \"10-25\"\n    elif val < 50:\n        return \"25-50\"\n    elif val < 100:\n        return \"50-100\"\n    else:\n        return \"100+\"\n\n## main Analysis Function\ndef _analyze_profile(username):\n    account_id = users[users[\"UserName\"] == username][\"Id\"].iloc(0)[0]\n    name = users[users[\"UserName\"] == username][\"DisplayName\"].iloc(0)[0]\n\n    mydf = messages[messages[\"PostUserId\"] == account_id]\n    mydf['PostDate'] = pd.to_datetime(mydf[\"PostDate\"])\n    mydf[\"weekday\"] = mydf[\"PostDate\"].dt.weekday\n    mydf[\"monthday\"] = mydf[\"PostDate\"].dt.day\n    mydf[\"hour\"] = mydf[\"PostDate\"].dt.hour\n    mydf[\"clean_message\"] = mydf[\"Message\"].fillna(\"\").apply(lambda x : clean_text(x))\n    mydf[\"word_len\"] = mydf[\"clean_message\"].apply(lambda x : len(x.split()))\n    mydf[\"char_len\"] = mydf[\"clean_message\"].apply(lambda x : len(x.replace(\" \",\"\")))\n\n    text = \" \".join(mydf[\"clean_message\"].dropna())\n    unigrams = Counter(ngrams(text, 1))\n    bigrams = Counter(ngrams(text, 2))\n    unigrams_d = dict(unigrams)\n    bigrams_d = dict(bigrams)\n\n    mydf[\"word_len_bin\"] = mydf[\"word_len\"].apply(wordmap)\n    mydf[\"char_len_bin\"] = mydf[\"char_len\"].apply(wordmap)\n\n    mydf['Date'] = mydf['PostDate'].dt.date\n    mydf['month'] = mydf['PostDate'].dt.month\n    dateComments = mydf['Date'].value_counts().to_frame().reset_index().sort_values(\"index\")\n\n    mytags = []\n    forumIDs = list(mydf['ForumTopicId'].values)\n    for forum_id in forumIDs:\n        try:\n            kernel_id = kernels_df[kernels_df[\"ForumTopicId\"] == forum_id]['Id'].iloc(0)[0]\n            taglist = list(kernels_tag_df[kernels_tag_df[\"KernelId\"] == kernel_id][\"TagId\"].values)\n            mytags.extend(tags_df[tags_df[\"Id\"].isin(taglist)]['Name'].values)\n        except Exception as E:\n            pass\n    \n    metrics = {\"mytags\" : mytags, \"unigrams\" : unigrams, \"unigrams_d\" : unigrams_d,\n               \"bigrams\" : bigrams, \"bigrams_d\" : bigrams_d, \"dateComments\" : dateComments, \n               \"name\" : name, \"account_id\" : account_id}\n    return mydf, metrics\n\n## Main Visualization Function\ndef _prepare(mydf, metrics):\n    mytags = metrics[\"mytags\"]\n    unigrams = metrics[\"unigrams\"]\n    bigrams = metrics[\"bigrams\"]\n    bigrams_d = metrics[\"bigrams_d\"]\n    unigrams_d = metrics[\"unigrams_d\"]\n    dateComments = metrics[\"dateComments\"] \n    account_id = metrics[\"account_id\"]\n    name = metrics[\"name\"]\n\n    mpp = {0 : \"Mon\", 1: \"Tue\", 2: \"Wed\", 3:\"Thu\", 4:\"Fri\", 5:\"Sat\", 6:\"Sun\"}\n    mydf[\"word_density\"] = mydf[\"char_len\"] / (1+mydf[\"word_len\"])\n    mydf[\"word_density\"] = mydf[\"word_density\"].apply(lambda x : round(x,2))\n\n    daymp = {}\n    lst = mydf[\"weekday\"].value_counts().to_frame().reset_index()\n    for l,day in lst.iterrows():\n        daymp[day[\"index\"]] = day[\"weekday\"]\n    sorted_x = sorted(daymp.items(), key=operator.itemgetter(1), reverse = True)\n    \n    # insights_t = {\n    #     \"Total Discussions\" : len(mydf),\n    #     \"Average Discussions Per Day\" : int(np.mean(np.array(dateComments[\"Date\"].values))),\n    #     \"Average Discussions Per Month\" : int(np.mean(mydf[\"month\"].value_counts().values)),\n    #     \"Maximum Discussions on Single Day\" : int(np.max(np.array(dateComments[\"Date\"].values))),\n    #     \"Maximum Discussions Date\" : str(dateComments[dateComments[\"Date\"] == np.max(np.array(dateComments[\"Date\"].values))][\"index\"].iloc(0)[0]),\n    #     \"Most Discussions WeekDay\" : mpp[sorted_x[0][0]],\n    #     \"Least Discussions WeekDay\" : mpp[sorted_x[-1][0]],\n    #     \"Average Words Per Discussions\" : int(np.mean(mydf[\"word_len\"])),\n    #     \"Average Characters Per Discussions\" : int(np.mean(mydf[\"char_len\"])),\n    #     \"Average Word Density Per Discussions\" : round(np.mean(mydf[\"word_density\"]),2),\n    #     \"Top KeyWord Used\" : unigrams.most_common()[0][0],\n    #     \"Top Tag Followed\" : Counter(mytags).most_common(1)[0][0],\n    #     \"Total Discussions\" : len(mydf),\n    #    \"Average Discussions Per Day\" : int(np.mean(np.array(dateComments[\"Date\"].values))),\n    #    \"Average Discussions Per Month\" : int(np.mean(mydf[\"month\"].value_counts().values)),\n    #     \"Maximum Discussions on Single Day\" : int(np.max(np.array(dateComments[\"Date\"].values))),\n    #     \"Maximum Discussions Date\" : str(dateComments[dateComments[\"Date\"] == np.max(np.array(dateComments[\"Date\"].values))][\"index\"].iloc(0)[0]),\n    #    \"Most Discussions WeekDay\" : mpp[sorted_x[0][0]],\n    #    \"Least Discussions WeekDay\" : mpp[sorted_x[-1][0]],\n    #    \"Average Words Per Discussions\" : int(np.mean(mydf[\"word_len\"])),\n    #    \"Average Characters Per Discussions\" : int(np.mean(mydf[\"char_len\"])),\n    #    \"Average Word Density Per Discussions\" : round(np.mean(mydf[\"word_density\"]),2),\n    #    \"Top KeyWord Used\" : unigrams.most_common()[0][0],\n    #    \"Top Tag Followed\" : Counter(mytags).most_common(1)[0][0],\n    #}\n    \n    insights = {\n        \"Total Discussions\" : len(mydf),\n        \"Average Discussions Per Day\" : int(np.mean(np.array(dateComments[\"Date\"].values))),\n        \"Average Discussions Per Month\" : int(np.mean(mydf[\"month\"].value_counts().values)),\n        \"Maximum Discussions on Single Day\" : int(np.max(np.array(dateComments[\"Date\"].values))),\n        \"Maximum Discussions Date\" : str(dateComments[dateComments[\"Date\"] == np.max(np.array(dateComments[\"Date\"].values))][\"index\"].iloc(0)[0]),\n        \"Most Discussions WeekDay\" : mpp[sorted_x[0][0]],\n        \"Least Discussions WeekDay\" : mpp[sorted_x[-1][0]],\n        \"Average Words Per Discussions\" : int(np.mean(mydf[\"word_len\"])),\n        \"Average Characters Per Discussions\" : int(np.mean(mydf[\"char_len\"])),\n        \"Average Word Density Per Discussions\" : round(np.mean(mydf[\"word_density\"]),2),\n        \"Top KeyWord Used\" : unigrams.most_common()[0][0],\n        \"Top Tag Followed\" : Counter(mytags).most_common(1)[0][0],\n    }\n\n    tabs1 = list(insights.keys())\n    tabvals1 = list(insights.values())\n    tr9 = go.Table(header=dict(values=['Metric', 'Value'], line = dict(color='#7D7F80'), fill = dict(color='#a1c3d1'), align = ['left'] * 2),\n                     cells=dict(values=[tabs1, tabvals1], line = dict(color='#7D7F80'), fill = dict(color='#EDFAFF'), align = ['left'] * 2))\n\n    layout = dict(title=\"Report Summary : \" + name, height=500)\n    data = [tr9]\n    fig = dict(data=data, layout=layout)\n    iplot(fig)\n\n    lst = unigrams.most_common(15)\n    tr1 = go.Bar(y= [c[0] for c in lst][::-1], x= [c[1] for c in lst][::-1], orientation=\"h\") \n    lst = bigrams.most_common(15)\n    tr2 = go.Bar(y= [c[0] for c in lst][::-1], x= [c[1] for c in lst][::-1], orientation=\"h\") \n\n    dvals = [daymp[0], daymp[1], daymp[2], daymp[3], daymp[4], daymp[5], daymp[6]]\n    tr3 = go.Bar(x= [\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"], y= dvals, marker=dict(color=\"#c7a6ea\")) \n    lst = mydf[\"monthday\"].value_counts()\n    tr4 = go.Bar(x= lst.index, y= lst.values, marker=dict(color=\"#c7a6ea\")) \n\n    lst = dict(mydf[\"word_len_bin\"].value_counts())\n   # xx = [\"0-10\", \"10-25\", \"25-50\", \"50-100\", \"100+\"]\n    xx = [\"0-10\", \"10-25\", \"25-50\", \"50-100\"]\n    yy = [lst[v] for v in xx]\n    tr5 = go.Bar(x= xx, y= yy, marker=dict(color=\"#eaa5b8\")) \n    lst = mydf[\"char_len_bin\"].value_counts()\n    yy = [lst[v] for v in xx]\n    tr6 = go.Bar(x= xx, y= yy, marker=dict(color=\"#eaa5b8\")) \n\n    lst = Counter(mytags).most_common(15)\n    tr7 = go.Scatter(x=[c+3 for c in range(len(lst))], y = [c[1] for c in lst], text=[c[0] for c in lst], \n                     textposition='top right', textfont=dict(size=10), mode='markers+text', marker=dict(color=\"#42f4a4\", size=25 ))\n\n    fig = tools.make_subplots(rows=5, cols=2, vertical_spacing = 0.05, print_grid=False, specs = [[{\"colspan\" : 2},None], [{},{}], [{},{}], [{\"colspan\" : 2},None], [{\"colspan\" : 2},None]], \n                             subplot_titles=[\"Discussions by Date\", \"Day of the Week - Discussion Activity\", \"Day of the Month - Discussion Activity\",\n                                             \"Number of Words per Discussions\", \"Number of Characters used per Discussions\", \n                                             \"Top Kernel Tags Followed\", \"Followers Gained Since 2017\" ])\n\n    tr8 = go.Scatter(x = dateComments[\"index\"], y = dateComments[\"Date\"], mode=\"lines+markers\", line=dict(color=\"orange\", width=3))\n    myfol = user_followers[user_followers[\"FollowingUserId\"] == account_id]\n    myfol[\"Date\"] = pd.to_datetime(myfol[\"CreationDate\"])\n    tmp = myfol[\"Date\"].value_counts().to_frame().reset_index().sort_values(\"index\")\n    tr10 = go.Scatter(x = tmp[\"index\"], y = tmp[\"Date\"], mode=\"lines+markers\", line=dict(color=\"pink\", width=3))\n\n    fig.append_trace(tr8, 1, 1)\n    fig.append_trace(tr3, 2, 1)\n    fig.append_trace(tr4, 2, 2)\n    fig.append_trace(tr5, 3, 1)\n    fig.append_trace(tr6, 3, 2)\n    fig.append_trace(tr7, 4, 1)\n    fig.append_trace(tr10, 5, 1)\n\n    fig['layout'].update(barmode='group', title = 'Kaggle Discussions Analysis Report: ' + name,\n        titlefont=dict(size=22,color='#000'),                     \n        margin=dict(t=100, b=100),\n        paper_bgcolor='rgb(254, 247, 234)',\n        plot_bgcolor='rgb(254, 247, 234)',\n        height=1300,\n        showlegend=False)\n    iplot(fig);\n    \n## main wordcloud function\ndef _wc(mydf):\n    wordcloud = WordCloud(max_font_size=40, max_words=12000, colormap='Dark2_r', random_state=42).generate(str(mydf['clean_message']))\n    fig = plt.figure(figsize=(12,8))\n    plt.imshow(wordcloud)\n    plt.title(\"Top Used Words\")\n    plt.axis('off')\n    plt.show()\n\n## Function to generate Ngram Bubble Cloud\ndef _ngramCloud(bigrams, username):\n    strr = \"id,value,value1\\nproject,\\n\"\n    num = 1\n    cnt = 1\n    sizes =[9000,7500,6000,5000,4000,2500,2200,1900,1800,1860]\n    for j, each in enumerate(bigrams.most_common(100)):\n        val = each[1]\n        strr += \"project.\" +str(num)+\".\"+ str(each[0]) + \",\" + str(val) + \",\" + str(val) + \"\\n\"\n        if cnt % 2 == 0:\n            num += 1\n        cnt += 1\n        if cnt == 100:\n            break\n    fout = open(\"flare\"+username+\".csv\", \"w\")\n    fout.write(strr)\n\n    html_p1 = \"\"\"<!DOCTYPE html><svg id='idd_\"\"\"+username+\"\"\"' width=\"760\" height=\"760\" font-family=\"sans-serif\" font-size=\"10\" text-anchor=\"middle\"></svg>\"\"\"\n    js_p1 = \"\"\"require.config({paths: {d3: \"https://d3js.org/d3.v4.min\"}});\n    require([\"d3\"], function(d3) {var svg=d3.select(\"#idd_\"\"\"+username+\"\"\"\"),width=+svg.attr(\"width\"),height=+svg.attr(\"height\"),format=d3.format(\",d\"),color=d3.scaleOrdinal(d3.schemeCategory20c);var pack=d3.pack().size([width,height]).padding(1.5);d3.csv(\"flare\"\"\"+username+\"\"\".csv\",function(t){if(t.value=+t.value,t.value)return t},function(t,e){if(t)throw t;var n=d3.hierarchy({children:e}).sum(function(t){return t.value}).each(function(t){if(e=t.data.id){var e,n=e.lastIndexOf(\".\");t.id=e,t.package=e.slice(0,n),t.class=e.slice(n+1)}}),a=(d3.select(\"body\").append(\"div\").style(\"position\",\"absolute\").style(\"z-index\",\"10\").style(\"visibility\",\"hidden\").text(\"a\"),svg.selectAll(\".node\").data(pack(n).leaves()).enter().append(\"g\").attr(\"class\",\"node\").attr(\"transform\",function(t){return\"translate(\"+t.x+\",\"+t.y+\")\"}));a.append(\"circle\").attr(\"id\",function(t){return t.id}).attr(\"r\",function(t){return t.r}).style(\"fill\",function(t){return color(t.package)}),a.append(\"clipPath\").attr(\"id\",function(t){return\"clip-\"+t.id}).append(\"use\").attr(\"xlink:href\",function(t){return\"#\"+t.id}),a.append(\"svg:title\").text(function(t){return t.value}),a.append(\"text\").attr(\"clip-path\",function(t){return\"url(#clip-\"+t.id+\")\"}).selectAll(\"tspan\").data(function(t){return t.class.split(/(?=[A-Z][^A-Z])/g)}).enter().append(\"tspan\").attr(\"x\",0).attr(\"y\",function(t,e,n){return 13+10*(e-n.length/2-.5)}).text(function(t){return t})});});\"\"\"\n    h = display(HTML(html_p1))\n    j = IPython.display.Javascript(js_p1)\n    IPython.display.display_javascript(j)\n\n## master function to generate the complete report \ndef _generate_report(username):\n    mydf, metrics = _analyze_profile(username)\n    _prepare(mydf, metrics)\n    display(HTML(\"Top Ngrams Used\"))\n    _ngramCloud(metrics[\"bigrams\"], username)\n    _wc(mydf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_generate_report(\"muhakabartay\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}