{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pydotplus","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import itertools\nfrom collections import Counter\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns;sns.set()\nimport xgboost as xgb\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split,StratifiedKFold,cross_validate\nfrom sklearn.metrics import classification_report,confusion_matrix\nfrom sklearn.preprocessing import LabelEncoder,LabelBinarizer,OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom io import StringIO\nfrom IPython.display import Image,display_html\nfrom sklearn import tree\nimport pydotplus\nimport eli5\nfrom eli5.sklearn import PermutationImportance\nimport shap\nimport lime\nimport statsmodels.api as sm\nimport scipy.stats as ss\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RS=405\npd.set_option('max_columns',25)\nshap.initjs()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mush=pd.read_csv('/kaggle/input/mushroom-classification/mushrooms.csv',dtype='category')\nmush.columns=mush.columns.str.replace('-','_')\nmush.rename(columns={'class':'toxic'},inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mush.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Exploratory Data Analysis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"mush.toxic.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mush.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mush.stalk_root.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mush.nunique().sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mush_enc=mush.drop(columns='veil_type').apply(lambda x:x.cat.codes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X,y=mush.drop(columns=['toxic','veil_type']),mush.toxic\nX_enc,y_enc=X.apply(lambda x:x.cat.codes),y.cat.codes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# categorical encoded dataset\nX_train,X_test,y_train,y_test=train_test_split(X_enc,y_enc,test_size=.20,random_state=RS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#One-hot encoded dataset\nXoh=pd.get_dummies(X,drop_first=False)\nXoh_train,Xoh_test,yoh_train,yoh_test=train_test_split(Xoh,y_enc,test_size=.20,random_state=RS)\nX.shape,Xoh.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Xoh.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ftnames=X.columns.values#feature names\nftnames_oh=Xoh.columns.values#One-hot encoded feature names","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def conditional_entropy(x,y):\n    y=y.astype(np.int64)\n    y_counter=np.bincount(y)\n    xy_counter=Counter(list(zip(x,y)))\n    total_occurrences=y_counter.sum()\n    entropy=0\n    for k,v in xy_counter.items():\n        p_xy=v/total_occurrences\n        p_y=y_counter[k[1]]/total_occurrences\n        entropy +=p_xy*np.log(p_y/p_xy)\n    return entropy\ndef cramers_v(x,y):\n    \"Calculates Cramer's V statistic for categorical-categorical association.this is a symmetric coefficient:V(x,y)=v(y,x)\"\n    confusion_matrix=pd.crosstab(x,y)\n    chi2=ss.chi2_contingency(confusion_matrix)[0]\n    n=confusion_matrix.sum().sum()\n    phi2=chi2/n\n    r,k=confusion_matrix.shape\n    phi2corr=max(0,phi2-((k-1)*(r-1))/(n-1))\n    rcorr=r-((r-1)**2)/(n-1)\n    kcorr=k-((k-1)**2)/(n-1)\n    return np.sqrt(phi2corr/min((kcorr-1),(rcorr-1)))\ndef theils_u(x,y):\n    \"\"\"Calculates Theil's U statistic (Uncertainty coefficient) for categorical-categorical association.\n          This is the uncertainity of x given y:value is on the range of [0,1]\n             -where 0 means y priovides no information about x,and 1 means y priovides full information about x. This is an asymmetric coefficient :U(x,y)!=U(y,x)\"\"\"\n    x=x.astype(np.int64)\n    s_xy=conditional_entropy(x,y)\n    x_counter=np.bincount(x)\n    total_occurrences=x_counter.sum()\n    p_x=x_counter/total_occurrences\n    s_x=ss.entropy(p_x)\n    if s_x==0:\n        return 1\n    return (s_x-s_xy)/s_x\ndef catcorr(data,method='theils'):\n    \"\"\"Compute categorical correlations using uncertainty coefficients (Theil's U) or Cramer's V\"\"\"\n    if method=='cramers':\n        return data.corr(method=cramers_v)\n    elif method !='theils':\n        raise NotImplementedError(f\"method:'{method}'not implemented,choose either 'cramers'or 'theils'\")\n        cols=data.columns\n        clen=cols.size\n        pairings=list(itertools.product(data.columns,repeat=2))\n        theils_mat=np.reshape([theils_u(data[p[1]],data[p[0]]) for p in pairings],(clen,clen))\n        return pd.DataFrame(theils_mat,index=cols,columns=cols)\n        \n        \n    \n\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Models\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def multi_table(*dfs):\n    html_str=''\n    for df in dfs:\n        html_str+=df.to_html()\n    display_html(html_str.replace('table','table style=\"display:inline\"'),raw=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def pplot_cm(y_true,y_pred,labels=None,filename=None,ymap=None,cf_report=False,figsize=(7,5),**kwargs):\n    if ymap is not None:\n        y_pred=[ymap[yi] for yi in y_pred]\n        y_true=[ymap[yi]for yi in y_true]\n        labels=[ymap[yi]for yi in labels]\n    if cf_report:\n        print(classification_report(y_true,y_pred))\n    labels=labels if labels is not None else y_true.unique()\n    cm=confusion_matrix(y_true,y_pred,labels=labels)\n    cm_sum=np.sum(cm,axis=1,keepdims=True)\n    cm_perc=cm/cm_sum.astype(float)*100\n    annot=np.empty_like(cm).astype(str)\n    nrows,ncols=cm.shape\n    for i in range(nrows):\n        for j in range(ncols):\n            c=cm[i,j]\n            p=cm_perc[i,j]\n            if i==j:\n                s=cm_sum[i]\n                annot[i,j]='%.1f%%\\n%d/%d'%(p,c,s)\n            elif c==0:\n                annot[i,j]=''\n            else:\n                annot[i,j]='%.1f%%\\n%d'%(p,c)\n    cm=pd.DataFrame(cm,index=labels,columns=labels)\n    cm.index.name='Actual'\n    cm.columns.name='Predicted'\n    fig,ax=plt.subplots(figsize=figsize)\n    sns.heatmap(cm,annot=annot,fmt='',ax=ax,**kwargs)\n    plt.savefig(filename) if filename is not None else plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_tree(dtree,featnames,cnames=None,width=600,height=800):\n    dot_data=StringIO()\n    tree.export_graphviz(dtree,out_file=dot_data,feature_names=featnames,class_names=cnames,filled=True,rounded=True,special_characters=True)\n    graph=pydotplus.graph_from_dot_data(dot_data.getvalue())\n    return Image(graph.create_png(),width=width,height=height)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc=RandomForestClassifier(100,n_jobs=-1,random_state=RS)\nrfc.fit(X_train,y_train)\npreds=rfc.predict(X_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pplot_cm(y_test,preds,rfc.classes_,cf_report=True,figsize=(7,5),cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"skf=StratifiedKFold(5,shuffle=True,random_state=RS)\nfor train_idx,test_idx in skf.split(X_enc,y_enc):\n    X_train,X_test,y_train,y_test=X_enc.loc[train_idx],X_enc.loc[test_idx],y_enc[train_idx],y_enc[test_idx]\n    rfc.fit(X_train,y_train)\n    y_pred=rfc.predict(X_test)\n    print(classification_report(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metrics=['precision','recall','f1','roc_auc']\nscores=cross_validate(rfc,X_enc,y_enc,scoring=metrics,cv=10,return_train_score=True,n_jobs=-1)\nfor m in metrics:\n    test_score,train_score=[scores[x] for x in scores.keys() if m in x]\n    print(m+':\\n','{:>4} train scores:{}'.format('',list(train_score)))\n    print('{:>5}test scores :{}'.format('',list(test_score)))\n    print('{:>5}test mean:{}'.format('',test_score.mean()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc_fi=pd.DataFrame({'feature':X.columns,'importance':rfc.feature_importances_}).sort_values(by='importance',ascending=False)\nsns.catplot(x='feature',y='importance',data=rfc_fi,kind='bar',aspect=1.5).set_xticklabels(rotation=90);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#filter out non perfect scoring decision trees,then take tree with fewest leaves\nsmallest_dt=min(filter(lambda dt:dt.score(X_test,y_test)==1,rfc.estimators_),key=lambda dt:dt.get_n_leaves())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_tree(smallest_dt,ftnames,['edible','poisonous'],500,600)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"One hot encoded","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc_oh=RandomForestClassifier(100,n_jobs=-1,random_state=RS)\nrfc_oh.fit(Xoh_train,yoh_train)\npreds_oh=rfc_oh.predict(Xoh_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pplot_cm(yoh_test,preds_oh,rfc_oh.classes_,cf_report=True,figsize=(7,5),cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc_oh_fi=pd.DataFrame({'feature':Xoh.columns,'importance':rfc_oh.feature_importances_}).sort_values(by='importance',ascending=False)\nsns.catplot(x='feature',y='importance',data=rfc_oh_fi[:21],kind='bar',aspect=1.5).set_xticklabels(rotation=90)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"odorXtox=pd.crosstab(mush.odor,mush.toxic)\ngsizXtox=pd.crosstab(mush.gill_size,mush.toxic)\ngcolXtox=pd.crosstab(mush.gill_color,mush.toxic)\nmulti_table(odorXtox,gsizXtox,gcolXtox)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"smallest_dt_oh=min(filter(lambda dt:dt.score(Xoh_test,yoh_test)==1.0,rfc_oh.estimators_),key=lambda dt:dt.get_n_leaves())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_tree(smallest_dt_oh,ftnames_oh,['edilble','posionous'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"XGBoost","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"xgbc=xgb.XGBClassifier(n_jobs=-1,random_state=RS)\nxgbc.fit(X_train,y_train)\npreds=xgbc.predict(X_test)\npplot_cm(y_test,preds,xgbc.classes_,cf_report=True,figsize=(7,5),cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgbc_fi=pd.DataFrame({'feature':X.columns,'importance':xgbc.feature_importances_}).sort_values(by='importance',ascending=False)\nsns.catplot(x='feature',y='importance',data=xgbc_fi,kind='bar',aspect=1.5).set_xticklabels(rotation=90)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgbc_oh=xgb.XGBClassifier(n_jobs=-1,random_state=RS)\nxgbc_oh.fit(Xoh_train,yoh_train)\npreds=xgbc_oh.predict(Xoh_test)\npplot_cm(yoh_test,preds_oh,rfc_oh.classes_,cf_report=True,figsize=(7,5),cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgbc_oh_fi=pd.DataFrame({'feature':Xoh.columns,'importance':xgbc_oh.feature_importances_}).sort_values(by='importance',ascending=False)\nsns.catplot(x='feature',y='importance',data=xgbc_oh_fi[:21],kind='bar',aspect=1.5).set_xticklabels(rotation=90);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Model Exploration","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(RS)\nRNIDX=np.random.choice(X_test.index)#Random index from test dataset\nposidx=X_test.index.get_loc(RNIDX)#positional index within the test dataset of the index label\nprint(f\"Index label(full=split):{RNIDX}\\nPostional index (X_test):{posidx}\")\n(X_enc.loc[RNIDX]==X_test.iloc[posidx]).all()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fi_merge=rfc_fi.merge(xgbc_fi,on='feature',suffixes=('_rf','_xgb')).set_index('feature')\n#One-hot encoded feature importances\nfi_oh_merge=rfc_oh_fi.merge(xgbc_oh_fi,on='feature',suffixes=('_rf','_xgb')).set_index('feature')\nunc_coef=X_enc.corrwith(y_enc,method=theils_u).sort_values(ascending=False)\nunc_coef_oh=Xoh.corrwith(y_enc,method=theils_u).sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,axs=plt.subplots(1,2,figsize=(12,6))\nfi_merge.plot.bar(ax=axs[0])\nunc_coef.plot.bar(ax=axs[1])\naxs[0].set_xlabel(None)\naxs[0].set_title('Feature Importance [Random Forest,XGBoost]')\naxs[1].set_title('Uncertainty Coefficients [toxic]')\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,axs=plt.subplots(1,2,figsize=(14,6),gridspec_kw=dict(width_ratios=[3,2]))\nfi_oh_merge.query('importance_rf>0.01 | importance_xgb>0.01').plot.bar(ax=axs[0])\n#filter out low coefficient values\nunc_coef_oh[unc_coef_oh>0.05].plot.bar(ax=axs[1])\naxs[0].set_xlabel(None)\naxs[0].set_title('Feature Importance [Random Forest,XGBoost]')\naxs[1].set_title('Uncertainty Coefficients[toxic]')\nplt.tight_layout()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Permutation Importance******","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def multi_eli5(*explainers):\n    html_str=''\n    for expl in explainers:\n        html_str +=expl._repr_html_().replace('style=\"border-collapse:collapse;','style=\"display:inline;border-collapse:collapse;')\n    display_html(html_str,raw=True)\n                                             ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Random Forest","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc_pi=PermutationImportance(rfc,random_state=RS,cv='prefit').fit(X_test,y_test)\nrfc_oh_pi=PermutationImportance(rfc_oh,random_state=RS,cv='prefit').fit(Xoh_test,yoh_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc_weights=eli5.show_weights(rfc,feature_names=ftnames)\nrfc_pi_weights=eli5.show_weights(rfc_pi,feature_names=ftnames)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"multi_eli5(rfc_weights,rfc_pi_weights)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eli5.show_prediction(rfc,X_test.loc[RNIDX],feature_names=ftnames,show_feature_values=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eli5.show_prediction(rfc_oh,Xoh.loc[RNIDX],feature_names=ftnames_oh,show_feature_values=True,top=20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"XGBoost","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"xgbc_pi=PermutationImportance(xgbc,random_state=RS,cv='prefit').fit(X_test,y_test)\nxgbc_oh_pi=PermutationImportance(xgbc_oh,random_state=RS,cv='prefit').fit(Xoh_test,yoh_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"multi_eli5(eli5.show_weights(xgbc_pi,feature_names=ftnames),eli5.show_weights(xgbc_oh_pi,feature_names=ftnames_oh))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"LIME(Local Interpretable Model-Agnostic Explanation)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"catname_map={i:X[c].cat.categories.values for i,c in enumerate(X)}\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def strip_html(htmldoc,strip_tags=['html','meta','head','body'],outfile=None,verbose=False):\n    \"\"\"Strip out HTML boilerplate tags but perserve inner content Only will strip out the first occurrence of each tag ,if multiple occurences are desired,function must be modified.\"\"\"\n    from bs4 import BeautifulSoup\n    soup=BeautifulSoup(htmldoc)\n    for tag in strip_tags:\n        rmtag=soup.find(tag)\n        if rmtag is not None:\n            rmtag.unwrap()\n            if verbose:print(tag,'tags removed')\n    stripped=soup.prettify()\n    if outfile is not None:\n        with open(outfile,'w',encoding='utf-8') as f:\n            f.write(stripped)\n            if verbose:\n                print(f'file saved to:{outfile}')\n    else:\n        return stripped","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"limeparams=dict(training_data=X_enc.values,\n                training_labels=y_enc.values,\n               feature_names=ftnames,\n               categorical_features=range(X.shape[1]),\n               categorical_names=catname_map,\n               class_names=['edible','poisonous'])\nlte=lime.lime_tabular.LimeTabularExplainer(**limeparams)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"limeparams_oh=dict(training_data=Xoh.values,\n                  training_labels=y_enc.values,\n                  feature_names=ftnames_oh,categorical_features=range(Xoh.shape[1]),class_names=['edible','poisonous'])\nlte_oh=lime.lime_tabular.LimeTabularExplainer(**limeparams_oh)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lte_expl=lte.explain_instance(X_test.loc[RNIDX],rfc.predict_proba)\ndisplay_html(strip_html(lte_expl.as_html()),raw=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lte_expl_oh=lte_oh.explain_instance(Xoh.loc[RNIDX],rfc_oh.predict_proba)\ndisplay_html(strip_html(lte_expl_oh.as_html()),raw=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"SHAP(SHapley Additive exPlanations)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"yv=y_enc[RNIDX];yv #True label of y @ RNIDX for indexing shap valeus","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shap_xgbc=shap.TreeExplainer(xgbc)\nshapvals_xgbc=shap_xgbc.shap_values(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shap.force_plot(shap_xgbc.expected_value,shapvals_xgbc[posidx],features=X.loc[RNIDX],link='logit')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fp_glb=shap.force_plot(shap_xgbc.expected_value,shapvals_xgbc[:25],features=X.iloc[:25],out_names='toxic',link='logit')\ndisplay_html(fp_glb.data,raw=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shap.summary_plot(shapvals_xgbc,X_test,feature_names=ftnames,class_names=['edible','poisonous'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shap.summary_plot(shapvals_xgbc,X_test,feature_names=ftnames,class_names=['edible','poisonous'],plot_type='bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"siv_xgbc=shap_xgbc.shap_interaction_values(X_test)\nshap.summary_plot(siv_xgbc,X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from shap.plots.dependence import *\ndef dependence_plot(ind, shap_values, features, feature_names=None, display_features=None,\n                    interaction_index=\"auto\",\n                    color=\"#1E88E5\", axis_color=\"#333333\", cmap=None,\n                    dot_size=16, x_jitter=0, alpha=1, title=None, xmin=None, xmax=None, ax=None, show=True):\n    \"\"\" Create a SHAP dependence plot, colored by an interaction feature.\n    Plots the value of the feature on the x-axis and the SHAP value of the same feature\n    on the y-axis. This shows how the model depends on the given feature, and is like a\n    richer extenstion of the classical parital dependence plots. Vertical dispersion of the\n    data points represents interaction effects. Grey ticks along the y-axis are data\n    points where the feature's value was NaN.\n    Parameters\n    ----------\n    ind : int or string\n        If this is an int it is the index of the feature to plot. If this is a string it is\n        either the name of the feature to plot, or it can have the form \"rank(int)\" to specify\n        the feature with that rank (ordered by mean absolute SHAP value over all the samples).\n    shap_values : numpy.array\n        Matrix of SHAP values (# samples x # features).\n    features : numpy.array or pandas.DataFrame\n        Matrix of feature values (# samples x # features).\n    feature_names : list\n        Names of the features (length # features).\n    display_features : numpy.array or pandas.DataFrame\n        Matrix of feature values for visual display (such as strings instead of coded values).\n    interaction_index : \"auto\", None, int, or string\n        The index of the feature used to color the plot. The name of a feature can also be passed\n        as a string. If \"auto\" then shap.common.approximate_interactions is used to pick what\n        seems to be the strongest interaction (note that to find to true stongest interaction you\n        need to compute the SHAP interaction values).\n        \n    x_jitter : float (0 - 1)\n        Adds random jitter to feature values. May increase plot readability when feature\n        is discrete.\n    alpha : float\n        The transparency of the data points (between 0 and 1). This can be useful to the\n        show density of the data points when using a large dataset.\n    xmin : float or string\n        Represents the lower bound of the plot's x-axis. It can be a string of the format\n        \"percentile(float)\" to denote that percentile of the feature's value used on the x-axis.\n    xmax : float or string\n        Represents the upper bound of the plot's x-axis. It can be a string of the format\n        \"percentile(float)\" to denote that percentile of the feature's value used on the x-axis.\n    ax : matplotlib Axes object\n         Optionally specify an existing matplotlib Axes object, into which the plot will be placed.\n         In this case we do not create a Figure, otherwise we do.\n    \"\"\"\n\n    if cmap is None:\n        cmap = colors.red_blue\n        \n    # create a matplotlib figure, if `ax` hasn't been specified.\n    if not ax:\n        figsize = (7.5, 5) if interaction_index != ind else (6, 5)\n        fig = pl.figure(figsize=figsize)\n        ax = fig.gca()\n    else:\n        fig = ax.get_figure()\n\n    # convert from DataFrames if we got any\n    if str(type(features)).endswith(\"'pandas.core.frame.DataFrame'>\"):\n        if feature_names is None:\n            feature_names = features.columns\n        features = features.values\n    if str(type(display_features)).endswith(\"'pandas.core.frame.DataFrame'>\"):\n        if feature_names is None:\n            feature_names = display_features.columns\n        display_features = display_features.values\n    elif display_features is None:\n        display_features = features\n\n    if feature_names is None:\n        feature_names = [labels['FEATURE'] % str(i) for i in range(shap_values.shape[1])]\n\n    # allow vectors to be passed\n    if len(shap_values.shape) == 1:\n        shap_values = np.reshape(shap_values, len(shap_values), 1)\n    if len(features.shape) == 1:\n        features = np.reshape(features, len(features), 1)\n\n    ind = convert_name(ind, shap_values, feature_names)\n    \n    # plotting SHAP interaction values\n    if len(shap_values.shape) == 3 and len(ind) == 2:\n        ind1 = convert_name(ind[0], shap_values, feature_names)\n        ind2 = convert_name(ind[1], shap_values, feature_names)\n        if ind1 == ind2:\n            proj_shap_values = shap_values[:, ind2, :]\n        else:\n            proj_shap_values = shap_values[:, ind2, :] * 2  # off-diag values are split in half\n\n        # TODO: remove recursion; generally the functions should be shorter for more maintainable code\n        dependence_plot(\n            ind1, proj_shap_values, features, feature_names=feature_names,\n            interaction_index=ind2, display_features=display_features, ax=ax, show=False,\n            xmin=xmin, xmax=xmax\n        )\n        if ind1 == ind2:\n            ax.set_ylabel(labels['MAIN_EFFECT'] % feature_names[ind1])\n        else:\n            ax.set_ylabel(labels['INTERACTION_EFFECT'] % (feature_names[ind1], feature_names[ind2]))\n\n        if show:\n            pl.show()\n        return\n\n    assert shap_values.shape[0] == features.shape[0], \\\n        \"'shap_values' and 'features' values must have the same number of rows!\"\n    assert shap_values.shape[1] == features.shape[1], \\\n        \"'shap_values' must have the same number of columns as 'features'!\"\n\n    # get both the raw and display feature values\n    oinds = np.arange(shap_values.shape[0]) # we randomize the ordering so plotting overlaps are not related to data ordering\n    np.random.shuffle(oinds)\n    xv = features[oinds, ind].astype(np.float64)\n    xd = display_features[oinds, ind]\n    s = shap_values[oinds, ind]\n    if type(xd[0]) == str:\n        name_map = {}\n        for i in range(len(xv)):\n            name_map[xd[i]] = xv[i]\n        xnames = list(name_map.keys())\n\n    # allow a single feature name to be passed alone\n    if type(feature_names) == str:\n        feature_names = [feature_names]\n    name = feature_names[ind]\n\n    # guess what other feature as the stongest interaction with the plotted feature\n    if interaction_index == \"auto\":\n        interaction_index = approximate_interactions(ind, shap_values, features)[0]\n    interaction_index = convert_name(interaction_index, shap_values, feature_names)\n    categorical_interaction = False\n\n    # get both the raw and display color values\n    color_norm = None\n    if interaction_index is not None:\n        cv = features[:, interaction_index]\n        cd = display_features[:, interaction_index]\n        clow = np.nanpercentile(cv.astype(np.float), 5)\n        chigh = np.nanpercentile(cv.astype(np.float), 95)\n        if type(cd[0]) == str:\n            cname_map = {}\n            for i in range(len(cv)):\n                cname_map[cd[i]] = cv[i]\n            cnames = list(cname_map.keys())\n            categorical_interaction = True\n        elif clow % 1 == 0 and chigh % 1 == 0 and chigh - clow < 10:\n            categorical_interaction = True\n\n        # discritize colors for categorical features\n        if categorical_interaction and clow != chigh:\n            clow = np.nanmin(cv.astype(np.float))\n            chigh = np.nanmax(cv.astype(np.float))\n            bounds = np.linspace(clow, chigh, int(chigh - clow + 2))\n            color_norm = matplotlib.colors.BoundaryNorm(bounds, cmap.N-1)\n\n    # optionally add jitter to feature values\n    if x_jitter > 0:\n        if x_jitter > 1: x_jitter = 1\n        xvals = xv.copy()\n        if isinstance(xvals[0], float):\n            xvals = xvals.astype(np.float)\n            xvals = xvals[~np.isnan(xvals)]\n        xvals = np.unique(xvals)\n        if len(xvals) >= 2:\n            smallest_diff = np.min(np.diff(np.sort(xvals)))\n            jitter_amount = x_jitter * smallest_diff\n            xv += (np.random.ranf(size = len(xv))*jitter_amount) - (jitter_amount/2)\n\n    # the actual scatter plot, TODO: adapt the dot_size to the number of data points?\n    xv_nan = np.isnan(xv)\n    xv_notnan = np.invert(xv_nan)\n    if interaction_index is not None:\n\n        # plot the nan values in the interaction feature as grey\n        cvals = features[oinds, interaction_index].astype(np.float64)\n        cvals_imp = cvals.copy()\n        cvals_imp[np.isnan(cvals)] = (clow + chigh) / 2.0\n        cvals[cvals_imp > chigh] = chigh\n        cvals[cvals_imp < clow] = clow\n        p = ax.scatter(\n            xv[xv_notnan], s[xv_notnan], s=dot_size, linewidth=0, c=cvals[xv_notnan],\n            cmap=cmap, alpha=alpha, vmin=clow, vmax=chigh,\n            norm=color_norm, rasterized=len(xv) > 500\n        )\n        p.set_array(cvals[xv_notnan])\n    else:\n        p = ax.scatter(xv, s, s=dot_size, linewidth=0, color=color,\n                       alpha=alpha, rasterized=len(xv) > 500)\n\n    if interaction_index != ind and interaction_index is not None:\n        # draw the color bar\n        if type(cd[0]) == str:\n            tick_positions = [cname_map[n] for n in cnames]\n            if len(tick_positions) == 2:\n                tick_positions[0] -= 0.25\n                tick_positions[1] += 0.25\n            cb = pl.colorbar(p, ticks=tick_positions)\n            cb.set_ticklabels(cnames)\n        else:\n            cb = pl.colorbar(p)\n\n        cb.set_label(feature_names[interaction_index], size=13)\n        cb.ax.tick_params(labelsize=11)\n        if categorical_interaction:\n            cb.ax.tick_params(length=0)\n        cb.set_alpha(1)\n        cb.outline.set_visible(False)\n        bbox = cb.ax.get_window_extent().transformed(fig.dpi_scale_trans.inverted())\n        cb.ax.set_aspect((bbox.height - 0.7) * 20)\n\n    # handles any setting of xmax and xmin\n    # note that we handle None,float, or \"percentile(float)\" formats\n    if xmin is not None or xmax is not None:\n        if type(xmin) == str and xmin.startswith(\"percentile\"):\n            xmin = np.nanpercentile(xv, float(xmin[11:-1]))\n        if type(xmax) == str and xmax.startswith(\"percentile\"):\n            xmax = np.nanpercentile(xv, float(xmax[11:-1]))\n\n        if xmin is None or xmin == np.nanmin(xv):\n            xmin = np.nanmin(xv) - (xmax - np.nanmin(xv))/20\n        if xmax is None or xmax == np.nanmax(xv):\n            xmax = np.nanmax(xv) + (np.nanmax(xv) - xmin)/20\n        \n        ax.set_xlim(xmin, xmax)\n\n    # plot any nan feature values as tick marks along the y-axis\n    xlim = ax.get_xlim()\n    if interaction_index is not None:\n        p = ax.scatter(\n            xlim[0] * np.ones(xv_nan.sum()), s[xv_nan], marker=1,\n            linewidth=2, c=cvals_imp[xv_nan], cmap=cmap, alpha=alpha,\n            vmin=clow, vmax=chigh\n        )\n        p.set_array(cvals[xv_nan])\n    else:\n        ax.scatter(\n            xlim[0] * np.ones(xv_nan.sum()), s[xv_nan], marker=1,\n            linewidth=2, color=color, alpha=alpha\n        )\n    ax.set_xlim(xlim)\n\n    # make the plot more readable\n    ax.set_xlabel(name, color=axis_color, fontsize=13)\n    ax.set_ylabel(labels['VALUE_FOR'] % name, color=axis_color, fontsize=13)\n    if title is not None:\n        ax.set_title(title, color=axis_color, fontsize=13)\n    ax.xaxis.set_ticks_position('bottom')\n    ax.yaxis.set_ticks_position('left')\n    ax.spines['right'].set_visible(False)\n    ax.spines['top'].set_visible(False)\n    ax.tick_params(color=axis_color, labelcolor=axis_color, labelsize=11)\n    for spine in ax.spines.values():\n        spine.set_edgecolor(axis_color)\n    if type(xd[0]) == str:\n        ax.set_xticks([name_map[n] for n in xnames])\n        ax.set_xticklabels(xnames, dict(rotation='vertical', fontsize=11))\n    if show:\n        with warnings.catch_warnings(): # ignore expected matplotlib warnings\n            warnings.simplefilter(\"ignore\", RuntimeWarning)\n            pl.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(5):\n    dependence_plot(f'rank({i})',shapvals_xgbc,X_test,display_features=X.loc[X_test.index])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Manual Modeling","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(mush.odor,[mush.toxic])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def toxcor(X):\n    return X.drop('toxic',1).apply(lambda x:x.cat.codes).corrwith(X.toxic.cat.codes,method=theils_u).sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"odorN=mush[mush.odor==\"n\"].drop('veil_type',1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"toxcor(odorN)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab([odorN.toxic],[odorN.spore_print_color])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"odorN_spcW=odorN[odorN.spore_print_color=='w']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"toxcor(odorN_spcW)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"odorN_spcW_habLD=odorN_spcW[odorN_spcW.habitat.isin(['l','d'])]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"toxcor(odorN_spcW_habLD)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab([odorN_spcW_habLD.toxic],[odorN_spcW_habLD.stalk_root],)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"odorN_spcW_habLD_stkB=odorN_spcW_habLD[odorN_spcW_habLD.stalk_root=='b']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"toxcor(odorN_spcW_habLD_stkB)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab([odorN_spcW_habLD_stkB.toxic],[odorN_spcW_habLD_stkB.cap_color])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def logic_tree(X):\n    preds=[]\n    for i,r in X.iterrows():\n        if r.odor in ['a','l']:\n            preds.append(0)\n        elif r.odor=='n':\n            if r.spore_print_color=='r':\n                preds.append(1)\n            elif r.spore_print_color=='w':\n                if r.habitat not in ['l','d']:\n                    preds.append(0)\n                else:\n                    if r.stalk_root!='b':\n                            preds.append(1)\n                    else:\n                        preds.append(1 if r.cap_color=='w' else 0)\n            else:\n                preds.append(0)\n        else:\n            preds.append(1)\n    return preds\n                    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ltpreds=logic_tree(X)\npplot_cm(y_enc,ltpreds,cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"References\n1.https://gist.github.com/hitvoice/36cf44689065ca9b927431546381a3f7\n\n2.https://xgboost.readthedocs.io/en/latest/get_started.html\n\n3.https://towardsdatascience.com/the-search-for-categorical-correlation-a1cf7f1888c9\n\n4.https://marcotcr.github.io/lime/tutorials/Tutorial%20-%20continuous%20and%20categorical%20features.html\n\n5.https://slundberg.github.io/shap/notebooks/NHANES%20I%20Survival%20Model.html","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}