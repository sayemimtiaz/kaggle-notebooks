{"cells":[{"metadata":{"_uuid":"c784d61bbd70a73b66b8fb1ea8ae3d198a5e5651"},"cell_type":"markdown","source":"# TELCO CUSTOMER CHURN\n### Focused customer retention programs"},{"metadata":{"_uuid":"a26f342558b64b7821ebb2cdde2cc833ca6f2a34"},"cell_type":"markdown","source":"### Who is Telco ?\nTelco Systems is market-leading solutions enable service providers to create and operate high quality, service assured, carrier-grade, intelligent networks. They bring over 40 years of experience to the design and development of advanced, high-performance telecom network communications solutions. \n\nTelco provide the capabilities for service differentiation that enable new forms of revenue production, maximizing network profitability. Service providers, large and small, depend on our consistent delivery of advanced solutions, enabling them to stay ahead of the capacity crunch while keeping total cost of ownership to a minimum.\n\n(Refrence - http://www.telco.com/index.php?page=company-profile)"},{"metadata":{"_uuid":"50434e67b541e98c6c43b638d1faa3c64381f077"},"cell_type":"markdown","source":"### Business Objective\n\nEvery retailer is concerned about high customer churn rate. Churn rate the number of customers who drop out of the buying cycle. It could be non renewal of a loyalty program, or unhappy customers going in search of a better service. One of the key things for the busines to run is loyal customeers , meaning minimize the churn rate.\n\n#### Business objective of this exercise :\n1. Analyze customer data to understand reason for churn  and who could be the next potential customer to leave the company\n2. What contributes to the higher churn rate of customer and what could be some of the probable solution to address the same.\n\n#### What type of problem is it ?\nSupervised Machine Learning -  Classfication problem\n\n#### How should performance be measured ?\nModel performance of at least 70% is expected\n\n#### Assumptions made :\n1. The sample data is correct represetation of the entire population and is randomly selected\n2. The columns in the dataset are exhaustive list of features that determine churn rate"},{"metadata":{"_uuid":"4aae3d2b933c9d506624855a9e484202706b2f1e"},"cell_type":"markdown","source":"### Content of the dataset\nEach row represents a customer, each column contains customer’s attributes described on the column Metadata.\n\nThe data set includes information about:\n\n1. Customers who left within the last month – the column is called Churn\n2. Services that each customer has signed up for – phone, multiple lines, internet, online security, online backup, device protection, tech support, and streaming TV and movies\n3. Customer account information – how long they’ve been a customer, contract, payment method, paperless billing, monthly charges, and total charges\n4. Demographic info about customers – gender, age range, and if they have partners and dependents"},{"metadata":{"_uuid":"3e14d730f36b85bd64c76b9daffc3728cc144a1a"},"cell_type":"markdown","source":"## Import Libraries"},{"metadata":{"trusted":true,"_uuid":"540c2905d6cb04092126c093770ae20a2b7ea8d7"},"cell_type":"code","source":"#importing the libraries\n\n#Data Processing Libraries\nimport numpy as np\nimport pandas as pd\n\n#Data Vizualization Libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Pretty display for notebooks\n%matplotlib inline\n\n# Machine Learning Library\nfrom sklearn.preprocessing import LabelEncoder # Encode Categorical Variable to Numerical Variable\nfrom sklearn.preprocessing import Imputer # Imputer Class to replace missing values\nfrom sklearn.metrics import confusion_matrix # Library for model evaluation\nfrom sklearn.metrics import accuracy_score # Library for model evaluation\nfrom sklearn.model_selection import train_test_split # Library to split datset into test and train\n\nfrom sklearn.linear_model  import LogisticRegression # Logistic Regression Classifier\nfrom sklearn.linear_model import SGDClassifier # Stochastic Gradient Descent Classifier\nfrom sklearn.tree import DecisionTreeClassifier # Decision Tree Classifier\nfrom sklearn.ensemble  import RandomForestClassifier # Random Forest Classifier\nfrom sklearn.neighbors import KNeighborsClassifier # K Nearest neighbors Classifier\nfrom sklearn.naive_bayes import GaussianNB #Naive Bayes Classifier\nfrom sklearn.svm import SVC #Support vector Machine Classifier\nfrom sklearn.ensemble import AdaBoostClassifier # Ada Boost Classifier\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import average_precision_score\n\n#Ignoring the warnings\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c862f007711f9334e41a465a1ea0dde82afdaad6"},"cell_type":"markdown","source":"## Get Data\n\n1. Source of data  - https://www.kaggle.com/blastchar/telco-customer-churn\n2. Space - 955 KB\n3. Legal Obligations - Free Dataset"},{"metadata":{"trusted":true,"_uuid":"831988b00e8a4e42bbc813873d2350b2049f357a"},"cell_type":"code","source":"# Read .csv file from location and load into pandas DataFrame\ndatset_churn = pd.read_csv('../input/WA_Fn-UseC_-Telco-Customer-Churn.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d5ae764597464c2d51d152d79a9f8e0e2b0ae7ea"},"cell_type":"code","source":"# Keeping a backup of original datset.Always a good practice\ndatset_churn_copy = datset_churn.copy()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9bff81f3e43faf0bfe203fdf02fd3a7b705f8013"},"cell_type":"markdown","source":"### Basic Overview of dataset"},{"metadata":{"_uuid":"5187a9e5ac2cba628f36e1b36a804ae8d1aee543"},"cell_type":"markdown","source":"#### Find out total rows and columns or shapes of the dataset"},{"metadata":{"trusted":true,"_uuid":"ced0936048bba764f16ad05d23aa9419885245a0"},"cell_type":"code","source":"datset_churn.shape  # output = (rows, columns)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4625a9027977c1fc09df3433cf04e1741cbca9c6"},"cell_type":"markdown","source":"There are 7043 rows and 21 columns including the target/output variable."},{"metadata":{"_uuid":"bc8aa821ca65ac31dd664bc98aa378c9435ea9f8"},"cell_type":"markdown","source":"#### Let's get the column names/information"},{"metadata":{"trusted":true,"_uuid":"6bdae58788d0f4bc5056fd80897f1c1c4d5a584a"},"cell_type":"code","source":"# Getting the column names\ndatset_churn.columns.values","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6ad12bddd7541b23c191c022ba533fcd92120bd4"},"cell_type":"markdown","source":"Observation -   'customerID' , 'gender' and 'tenure' in lowercase. We will rename to convert the first letter to uppercase"},{"metadata":{"trusted":true,"_uuid":"eadde28ba61239b2ee99b723dca22cfe188717d3"},"cell_type":"code","source":"# Renaming the 3 columns.\ndatset_churn = datset_churn.rename(columns={'customerID' : 'CustomerID' , 'gender': 'Gender', 'tenure':'Tenure'})\nprint(datset_churn.columns.values)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2ceb35c57af9768acbafaf537d55886ec80d8e08"},"cell_type":"markdown","source":"Target Variable or The variable we want to predict is 'Churn'\n\nFeature Variable  - All Other columns (First 20 columnns)\n\n1. Customers who left within the last month –  'Churn'\n2. Customer Services – 'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup' 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies'\n3. Customer Account information – 'Tenure', 'Contract', 'PaperlessBilling', 'PaymentMethod', 'MonthlyCharges', 'TotalCharges'\n4. Customer Personal Information – 'Gender', 'SeniorCitizen', 'Partner', 'Dependents'"},{"metadata":{"trusted":true,"_uuid":"e70dbc402cc8c18cfde2ed7b5305c043a0f2da8e"},"cell_type":"code","source":"datset_churn.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"899380c6c831a69a9759ef7d7a258a11b422998a"},"cell_type":"markdown","source":"Observation -   TotalCharges is object variable. By column name, we can guess it as amount field. \n### Let's take a look into the data"},{"metadata":{"trusted":true,"_uuid":"78f2f915e48d3e7340d2b2ca16ac846e49cc3c9c"},"cell_type":"code","source":"datset_churn.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c1bbc8c2752f901297c910ba7dc21f6fd115919e"},"cell_type":"markdown","source":"Observation - \n1. TotalCharges is left aligned. Numeric variables should be right aligned\n2. It's defines as object variable. We will convert it to numeric variable"},{"metadata":{"_uuid":"e0e79fa28e3ec4bd9176b46daec6f2536814c0ad"},"cell_type":"markdown","source":"### Converting the object variable into Numeric variable."},{"metadata":{"trusted":true,"_uuid":"7be8321c03d021f89d64d1377e5f25469f0dc075"},"cell_type":"code","source":"datset_churn['TotalChargesNum']=pd.to_numeric(datset_churn['TotalCharges'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"78bd47a121de8f09bd3ea4ed10e2ee477a89add0"},"cell_type":"markdown","source":"Observation - Column has \" \" . Let's find the columns containing spaces."},{"metadata":{"trusted":true,"_uuid":"3172522c27243c2a47b128c0e74aa09713eed5b2"},"cell_type":"code","source":"#Identifying the rows containing missing data\nmissing_value_row = list(datset_churn[datset_churn['TotalCharges'] == \" \"].index)\nprint('Missing Value Rows-->', missing_value_row , '\\nTotal rows-->', len(missing_value_row))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4241d8f28cecbf4a5f6720c79ba1dc251333991f"},"cell_type":"code","source":"# Replacing the spaces with 0\nfor missing_row in missing_value_row :\n    datset_churn['TotalCharges'][missing_row] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a7d3a17683ca6af05395a9b5d103300179c6bc9e"},"cell_type":"code","source":"# Let's try to convert it back to Numeric\ndatset_churn['TotalCharges']=pd.to_numeric(datset_churn['TotalCharges'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0774163f234d43cbb785c9a56ae9b5ea3343bd4a"},"cell_type":"markdown","source":"No Errors! Let's view the column details"},{"metadata":{"trusted":true,"_uuid":"23122bca99ea33a2def07b4e8b806697cec0d6bf"},"cell_type":"code","source":"datset_churn.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2ea0694f51be5770829933592c13d06591dd960b"},"cell_type":"markdown","source":"#### Which features are numerical?\nSeniorCitizen, Tenure, MonthlyCharges, TotalCharges\n\nContinous - Tenure, MonthlyCharges, TotalCharges\n\nDiscrete  - SeniorCitizen\n\n#### Which features are categorical?\nPhoneService, MultipleLines, InternetService, OnlineSecurity, OnlineBackup DeviceProtection, TechSupport, StreamingTV, StreamingMovies, Contract, PaperlessBilling, PaymentMethod, gender, Partner, Dependents\n\n#### Which features are Nominal or Ordinal ?\nOrdinal data (variables with a meaningful order) - No.\n\nNominal data (categories that have no meaningful order) - All Columns.\n\n#### Which features are mixed data types?\nNone"},{"metadata":{"_uuid":"4174e7e56235eab98141c55a0ca811ab0b2e6c4e"},"cell_type":"markdown","source":"### Taking first look into data"},{"metadata":{"trusted":true,"_uuid":"c2c7b98914c9830611fa5522249f45666ce3893d"},"cell_type":"code","source":"datset_churn.head() # This will print first 5 rows in pandas dataset.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"73064e2c4cb8809bf86b8126e80d7f06d461fb13"},"cell_type":"markdown","source":"### Understanding the summary statistics , central tendency and dispersion of dataset"},{"metadata":{"_uuid":"5ce4b5bedde8eff7ef71aaf53b85fec5b9390e8b"},"cell_type":"markdown","source":"#### Summary Statistics of Object/Categorical variable. "},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"0de4c9366584daa4cad33e34a9439aa66218def0"},"cell_type":"code","source":"datset_churn.describe(include=['O'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eb47b4d748fb4ea68e341b12c30322553a128e58"},"cell_type":"code","source":"#Creating the list of columns\ndatset_churn_column = list(datset_churn.columns)\n\n#Removing numerical columns & CustomerID\ndatset_churn_column.remove('CustomerID')\ndatset_churn_column.remove('SeniorCitizen')\ndatset_churn_column.remove('Tenure')\ndatset_churn_column.remove('MonthlyCharges')\ndatset_churn_column.remove('TotalCharges')\n\n# Printing Unique values in each categorical column\nfor col in datset_churn_column:\n    print(col, \"-\", datset_churn[col].unique())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3f180318e7379c45be9eae4699cce151084d67b7"},"cell_type":"markdown","source":"#### Observations :\n1. Gender, Partner, Dependents, PhoneService, PaperlessBilling and Churn - They have 2 unique categories - Yes/No and for gender Male/Female\n2. MultipleLines, InternetService, OnlineSecurity, OnlineBackup, DeviceProtection, TechSupport, StreamingTV, StreamingMovies, Contract - They have 3 unique categories\n3. Payment Method -  4 unique categories or 4 methods by which customer pays for their service"},{"metadata":{"_uuid":"93d57988d326ec465afb6a275ed0191d2da7731a"},"cell_type":"markdown","source":"#### Summary Statistics of Numeric variable."},{"metadata":{"trusted":true,"_uuid":"62085e962e17c151833376a961b9931abaf17394"},"cell_type":"code","source":"datset_churn.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2a1dd312e020a6b03824f80f4dcec0ed9b86d81a"},"cell_type":"markdown","source":"#### Observations:\n1. We have 4 numeric variables\n2. Tenure can vary from 0 months to 72 months. This is how long customer is with Telco.\n3. Total Charges = Monthly Charges * Tenure\n4. Looking at the count column, all columns have count as 7043 . TotalCharges have count of 7032, a differece of 11 records. These are missing records"},{"metadata":{"_uuid":"808fbd84db6b3b2473a044cb7840397142058fa5"},"cell_type":"markdown","source":"### Assess missing values in dataset"},{"metadata":{"trusted":true,"_uuid":"9e2933bed8987507f66f1b029cd81a2fb3b91ed0"},"cell_type":"code","source":"print(\"Assess missing values in dataset\")\ntotal = datset_churn.isnull().sum().sort_values(ascending=False)\npercent = (datset_churn.isnull().sum()/datset_churn.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nprint(missing_data)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3f157f2f2c8d93a37880da29f9f4a176a4264db3"},"cell_type":"markdown","source":"\nObservation - No missing values. But remember, we replaced columns with 0 values. We need data to be filled into that columns. Now let's find a way."},{"metadata":{"trusted":true,"_uuid":"d4dc8998340520237133721321fbb32813c6b86b"},"cell_type":"code","source":"datset_churn[['MonthlyCharges','Tenure','TotalCharges']].head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c47cb79113dad77c40822d4f971cc45c4bb6b0f2"},"cell_type":"markdown","source":"TotalCharges looks like close to product of MonthlyCharges & Tenure , although not exact but close. We will replace the 0 values with \n( MonthlyCharges * Tenure)"},{"metadata":{"trusted":true,"_uuid":"de172f5ca43d2733dc80d7679cb265483462b42f"},"cell_type":"code","source":"#Identifying the rows containing 0 value in Total Charges\nzero_value_row = list(datset_churn[datset_churn['TotalCharges'] == 0].index)\nprint('0 Value Rows-->', missing_value_row , '\\nTotal rows-->', len(missing_value_row))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3c232952c786b175aa41b48ace46ac24ae796ded"},"cell_type":"code","source":"# Replacing the spaces with 0\nfor zero_row in zero_value_row :\n    datset_churn['TotalCharges'][zero_row] = datset_churn['Tenure'][zero_row] * datset_churn['MonthlyCharges'][zero_row]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7c59890f3206cad5eff3595059d18c2a4fd61197"},"cell_type":"code","source":"#Validating the data\nfor zero_row in zero_value_row :\n    print( datset_churn['MonthlyCharges'][zero_row],datset_churn['Tenure'][zero_row],datset_churn['TotalCharges'][zero_row])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6f28a2fc8495a6f48d6d555ccb725cba54871d4f"},"cell_type":"markdown","source":"Interesting ! So Tenure is 0 for the cstomers with TotalCharges as 0, that initially had a space. We will leave it as it and move ahead."},{"metadata":{"_uuid":"a23d411a97f722e21dd93ad0b88f3936ad332237"},"cell_type":"markdown","source":"## Univariate Analysis"},{"metadata":{"_uuid":"9a0bd336f63ece8843732d5d809583fb4c228d5e"},"cell_type":"markdown","source":"### Vizualizing the Categorical variables with bar chart"},{"metadata":{"trusted":true,"_uuid":"1abc00f5e148e6daf4a19d205e49be166cf0eec5"},"cell_type":"code","source":"# Getting the list of all columns\ncolumns_hist = list(datset_churn.columns)\n\n#Removing the Numerical Variables\ncolumns_hist.remove('CustomerID')\ncolumns_hist.remove('SeniorCitizen')\ncolumns_hist.remove('Tenure')\ncolumns_hist.remove('MonthlyCharges')\ncolumns_hist.remove('TotalCharges')\n\n#Creating Column into 4X4 matrix to display 16 bar charts in 4X4 form:\ncolumns_hist_nparray = np.array(columns_hist)\ncolumns_hist_nparray = np.reshape(columns_hist_nparray, (4,4)) # reshaping the columns into 4X4 matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1f17f04d6d3e876acb0b553cd81f9640687280ac"},"cell_type":"code","source":"# Plotting the bar chart\nrows = 4 ; columns = 4\nf, axes = plt.subplots(rows, columns, figsize=(20, 20))\nprint('Univariate Analysis of each categorical Variables')\nfor row in range(rows):\n    for column in range(columns):\n        sns.countplot(datset_churn[columns_hist_nparray[row][column]], palette = \"Set1\", ax = axes[row, column])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f88f9b4cc12ce73b472585c09bd0b141727cb017"},"cell_type":"markdown","source":"#### Observations :\n1. We have almost equal genders in our dataset\n2. Almost 50% have partners\n3. Around 30% have dependants\n4. 85% of the customers have phone service\n5. Around 40% customers have multiple lines\n6. People prefer Fiber Optics over DSL for Internet\n7. Around 30% have taken online security.Majority of Customer don't have Online security or backup\n8. Close 35% prefer device protection\n9. Majority of Customer don't have Tech Support\n10. Around 37% have registered for Streaming TV & MOvie\n11. Contract - Majority of customers are subscribed for Month to Month contract (55%)\n12. Majority of customers have opted Paperless billing\n13. Majority of customers pay eletronic check. 43 % prefer Automatic payment (Bank Transfer and Credit Card)\n14. Target Variable - \"Churn\" - We have unbalanced distribution (Yes - Approx 1800 ; No - Approx 5000). So Churn positive is 25% (Approx)."},{"metadata":{"_uuid":"5f3ff1a4cce7a7153b2f9da1b24585568afe2856"},"cell_type":"markdown","source":"### Vizualizing the Numeric variables\n#### Histogram to see data distribution of Quantitative Variables(SeniorCitizen, tenure, MonthlyCharges, TotalCharges)\n"},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"095557f48923c6a5dfcfd6f8549d6aa362912384"},"cell_type":"code","source":"print('Univariate Analysis of each numerical Variables')\nf, axes = plt.subplots(2, 3, figsize=(20,10))\n#Charting the histogram\ndatset_churn[\"Tenure\"].plot.hist(color='DarkBlue', alpha=0.7, bins=50, title='Tenure',ax=axes[0, 0])\ndatset_churn[\"MonthlyCharges\"].plot.hist(color='DarkBlue', alpha=0.7, bins=50, title='MonthlyCharges',ax=axes[0, 1])\ndatset_churn[\"TotalCharges\"].plot.hist(color='DarkBlue', alpha=0.7, bins=50, title='TotalCharges',ax=axes[0, 2])\n\n#Charting the density plot\nsns.distplot( datset_churn[\"Tenure\"] , kde=True, rug=False, color=\"skyblue\", ax=axes[1, 0])\nsns.distplot( datset_churn[\"MonthlyCharges\"] , kde=True, rug=False, color=\"olive\", ax=axes[1, 1])\nsns.distplot( datset_churn[\"TotalCharges\"] , kde=True, rug=False, color=\"gold\", ax=axes[1, 2])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"35e841a24be74574025e4f6589400c4d18563cd6"},"cell_type":"markdown","source":"#### Observations:\n1. Tenure:\n\n    1.1. Not a normal distribution. Bi-Modal distribution (having 2 peaks) which means data is concentrated across two different groups\n    \n    1.2 We have major chunk of customers in 0-1 month period. Lot of them might be cutomers who tried the service and left or liked the service and continued\n    \n    1.3. Between 10 months to 65 months, we can see flat distribution of data.\n    \n    1.4. We have lot customers in 69-72 months range. They are the loyal customers\n   \n   \n 2. Monthly Charges  - \n \n     2.1. Not a normal distribution.Close to Bi-Modal distribution\n     \n     2.2. Majority of customers are paying $18 to $20 dollars. Must be the service charge for basic service. Majority of customers are subscribed to basic package.\n     \n     2.3. Between $70-$100 dollars, we  have quite a number of customers. They might be the ones subscribed for multiple services.\n     \n     \n 3. Total Charges - \n \n    3.1. Data is positively skewed.\n    \n    3.2. Majority of the population have spent close to $1,100 dollars\n    \n    3.3. Cutomers have spent upto $9,000  dollars \n"},{"metadata":{"_uuid":"eba9518403e038637558d60b3e74fa3d7a9cf277"},"cell_type":"markdown","source":"#### Barchart for the Gender (0 is No , 1 is Yes)"},{"metadata":{"trusted":true,"_uuid":"92820a98726c7106c955456c8c564ade94a98bab"},"cell_type":"code","source":"sns.countplot(datset_churn['SeniorCitizen'], palette = \"Set1\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9e34b89317ab2e55e9c9ed8f371976bb994c056f"},"cell_type":"markdown","source":"16% of customers are senior citizens"},{"metadata":{"_uuid":"f90b2f1e06b16badcbb6d11babd641ff37d01691"},"cell_type":"markdown","source":"#### Let's Check for Outliers using Box Plot  for Tenure, MonthlyCharges, TotalCharges"},{"metadata":{"trusted":true,"_uuid":"4b6cdffb988080338581b4f9612d3420887ede54"},"cell_type":"code","source":"f, axes = plt.subplots(1, 3, figsize=(15,5))\nsns.boxplot(x=datset_churn[\"Tenure\"], orient=\"v\", color=\"olive\",ax=axes[0])\nsns.boxplot(x=datset_churn[\"MonthlyCharges\"], orient=\"v\", color=\"gold\",ax=axes[1])\nsns.boxplot(x=datset_churn[\"TotalCharges\"] , orient=\"v\", color=\"skyblue\",ax=axes[2])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8aa658c3f2f4039f4225ad681f8ee39eb638e991"},"cell_type":"markdown","source":"Observation - Seems like we dont have outliers !"},{"metadata":{"_uuid":"cda79f2d9de5aa3359a9311989c1df012df73c98"},"cell_type":"markdown","source":"## Bivariate Analysis\nCorrelating the features with Target column (Churn)\nLet us start by understanding correlations between numerical features and our solution goal (Churn).\n\nA histogram chart is useful for analyzing continous numerical variables like tenure , Monthly Charges and Total Charges where banding or ranges will help identify useful patterns. The histogram can indicate distribution of samples using automatically defined bins or equally ranged bands. This helps us answer questions relating to specific bands."},{"metadata":{"trusted":true,"_uuid":"eb42b68c9b8faca219943b728e639c1e825e8cda"},"cell_type":"code","source":"# Converting the categorical variable to numerical variable\ndatset_churn['Churn_Num'] = datset_churn['Churn'].map( {'Yes': 1, 'No': 0} ).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6fb05df84bf53dfcb99d27a59dd12cd7866a240c"},"cell_type":"code","source":"# Validating the mappaing\ndatset_churn[['Churn','Churn_Num']].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a6cae4ce94b2e30eac5779816a568b8eb7ee7dd5"},"cell_type":"code","source":"# Plotting Tenure Column with Churn\n# Churn_num indicates customer who left the company. 0 indicates customer who stayed.\nfighist = sns.FacetGrid(datset_churn, col='Churn_Num')\nfighist.map(plt.hist, 'Tenure', bins=20) ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b95c4a54eb19205d321258e2503485250187070e"},"cell_type":"markdown","source":"#### Observations:\n\n1. Customer who left the Telco are mostly customers within 1st month (600+) and churn steady declines with time.\n2. If customer can be retained between 10-20 months, there are high chances, customer will stay very long. Churn decreases over time\n3. Customer at 72 month tenure, mostly stayed (Churn=0).\n\n#### Decisions:\n\n1. We should definitely use 'Tenure' column in our model training.\n2. We should band 'Tenure'"},{"metadata":{"trusted":true,"_uuid":"717466d28f80848be39e9420d32461dcb97cfd94"},"cell_type":"code","source":"# Plotting MonthlyCharges Column with Churn\n# Churn_num indicates customer who left the company. 0 indicates customer who stayed.\nfighist = sns.FacetGrid(datset_churn, col='Churn_Num')\nfighist.map(plt.hist, 'MonthlyCharges', bins=20)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9b113f6dfa280feec99ff3c8dffd2bfc0dff262d"},"cell_type":"markdown","source":"#### Observation :\n1. Majority of customers are in 18 to 20 range and they didn't leave\n2. Customer Leaving are mostly in the bannd of 75-100  who have opted for multiple services.\n\n#### Decisions :\n1. We will use 'MonthlyCharges' column in our model training.\n2. We should band 'MonthlyCharges'"},{"metadata":{"trusted":true,"_uuid":"54a3e11f898a89bbb5d500807fc89f6bc88c025c"},"cell_type":"code","source":"# Plotting TotalCharges Column with Churn\n# Churn_num indicates customer who left the company. 0 indicates customer who stayed.\nfighist = sns.FacetGrid(datset_churn, col='Churn_Num')\nfighist.map(plt.hist, 'TotalCharges', bins=20)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3aac2c778fcd82ade309f73e0ede0764c2a97ab5"},"cell_type":"markdown","source":"#### Observation:\nIt's difficult to conclude anything using this column. Total charges are Tenure * MonthlyCharges . Tenur might me high and Monthly charges may be low and vice-versa. Data is positively skewed.\n\n#### Decision\nWe will not use this column\n"},{"metadata":{"_uuid":"c150726a6485bc14b35cad53e05df6e069267688"},"cell_type":"markdown","source":"### Now we will use the Categorical variables and their relationships with Churn\n\n#### We will use Seaborn Categorical Plot"},{"metadata":{"trusted":true,"_uuid":"36fba172626d61556f44095aee6c5d99aaa7708f"},"cell_type":"code","source":"col_list = columns_hist\ncol_list.remove('Churn')\nfor col in col_list:\n    if col == 'PaymentMethod':\n        aspect_ratio = 2.0\n    else:\n        aspect_ratio = 0.8\n        \n    plot_cat_data = sns.catplot(x=col, col='Churn_Num', data = datset_churn, kind='count', height=4, aspect=aspect_ratio)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"15d593670bbedb6eef889ec111ed36ac275a88ee"},"cell_type":"markdown","source":"#### Observations (Churn_Num - 1 is \"Yes\" ; 0 is \"No\") :\n1. 'Gender'  : Difficult to determine Churn using this field. Counts are almost same  in either category\n2. 'Partner' : Customer with partner have lower chance of leaving\n3. 'Dependents' :Customer with dependants have lower chance of leaving. We will merge Partner & Dependant Columns as 1 column\n4. 'PhoneService' & 'MultipleLines' : We will merge these columns into PhoneLines - Single & Multiple and determine\n5. 'InternetService' : Customer with Fiber Optic Interner Service have higher chances of leaving\n6. 'OnlineSecurity' & 'OnlineBackup' : We will merge these columns for better visibility\n7. 'DeviceProtection' : Customers without device protection have likely higher chances of leaving\n8. 'TechSupport' - Customer not opting for TechSupport have higher chances of leaving \n9. 'StreamingTV', 'StreamingMovies' - We will merge these columns into streaming and check again\n10. 'Contract' - Month to Month customers have likely higher chances to leave\n11. 'PaperlessBilling' - Customers with paperless billing have higher chances of leaving\n12. 'PaymentMethod' - People paying with electronic check have higher chances of leaving"},{"metadata":{"_uuid":"6f4be1fc319d8bddeae96a33725f3d4cac660158"},"cell_type":"markdown","source":"### Creating new feature from existing set of columns using the above observations"},{"metadata":{"_uuid":"a2036e0b70d7f3141bd5d74ae04b6914e5fe8ac2"},"cell_type":"markdown","source":"#### Creating bands for numerical variables - Tenure & Monthly Charges"},{"metadata":{"trusted":true,"_uuid":"ec1080351588dcc8199ff6616695c4e0d0054b48"},"cell_type":"code","source":"# Creating tenure band and co-relation with Churn\ndatset_churn['TenureRange'] = pd.cut(datset_churn['Tenure'], 5)\ndatset_churn[['TenureRange', 'Churn_Num']].groupby(['TenureRange'], as_index=False).mean().sort_values(by='TenureRange', ascending=True)\n\n# Replacing Age band with ordinals based on these bands\ndatset_churn.loc[ datset_churn['Tenure'] <= 8, 'TenureCat'] = 0\ndatset_churn.loc[(datset_churn['Tenure'] > 8) & (datset_churn['Tenure'] <= 15), 'TenureCat'] = 1\ndatset_churn.loc[(datset_churn['Tenure'] > 15) & (datset_churn['Tenure'] <= 30), 'TenureCat'] = 2\ndatset_churn.loc[(datset_churn['Tenure'] > 30) & (datset_churn['Tenure'] <= 45 ), 'TenureCat'] = 3\ndatset_churn.loc[(datset_churn['Tenure'] > 45) & (datset_churn['Tenure'] <= 60 ), 'TenureCat'] = 4\ndatset_churn.loc[ datset_churn['Tenure'] > 60, 'TenureCat'] = 5\n\ndatset_churn[['Tenure','TenureRange','TenureCat']].head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3488400cd5a190cb39e0468c8a7f1696b4ede653"},"cell_type":"code","source":"# Creating MonthlyCharges Band and co-relation with Churn\ndatset_churn['MonthlyChargesRange'] = pd.cut(datset_churn['MonthlyCharges'], 5)\ndatset_churn[['MonthlyChargesRange', 'Churn_Num']].groupby(['MonthlyChargesRange'], as_index=False).mean().sort_values(by='MonthlyChargesRange', ascending=True)\n\n# Replacing Age band with ordinals based on these bands\ndatset_churn.loc[ datset_churn['MonthlyCharges'] <= 20, 'MonthlyChargesCat'] = 0\ndatset_churn.loc[(datset_churn['MonthlyCharges'] > 20) & (datset_churn['MonthlyCharges'] <= 40), 'MonthlyChargesCat'] = 1\ndatset_churn.loc[(datset_churn['MonthlyCharges'] > 40) & (datset_churn['MonthlyCharges'] <= 60), 'MonthlyChargesCat'] = 2\ndatset_churn.loc[(datset_churn['MonthlyCharges'] > 60) & (datset_churn['MonthlyCharges'] <= 80 ), 'MonthlyChargesCat'] = 3\ndatset_churn.loc[(datset_churn['MonthlyCharges'] > 80) & (datset_churn['MonthlyCharges'] <= 100 ), 'MonthlyChargesCat'] = 4\ndatset_churn.loc[ datset_churn['MonthlyCharges'] > 100, 'MonthlyChargesCat'] = 5\n\n#Checking the categories\ndatset_churn[['MonthlyCharges','MonthlyChargesRange','MonthlyChargesCat']].head(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"537d3f2cd68b678be954a5c6eadf40295c32d99a"},"cell_type":"markdown","source":"#### Creating new derived columns for Categorical variables"},{"metadata":{"trusted":true,"_uuid":"9c1460fb619ac7cd9551072091aa7600b9261d4d"},"cell_type":"code","source":"#Creating a new column for family. If a customer has dependant or Partner, I am considering it as family .\nlist_family = []\nfor rows in range(len(datset_churn['Partner'])):\n    if ((datset_churn['Partner'][rows] == 'No') and (datset_churn['Dependents'][rows] == 'No')):\n        list_family.append('No')\n    else:\n        list_family.append('Yes')\ndatset_churn['Family'] = list_family\n#print(datset_churn[['Partner', 'Dependents', 'Family' ]].head(10))\n\n#Creating a new column for Online Services (Online Security & Online Backup) . If a customer has Online Security or Online Backup services\n#then , I am considering it as \"Yes\" else \"No\"\nlist_online_services = []\nfor rows_os in range(len(datset_churn['OnlineSecurity'])):\n    if ((datset_churn['OnlineSecurity'][rows_os] == 'No') and (datset_churn['OnlineBackup'][rows_os] == 'No')):\n        list_online_services.append('No')\n    else:\n        list_online_services.append('Yes')\ndatset_churn['OnlineServices'] = list_online_services\n\n#print(datset_churn[['OnlineSecurity', 'OnlineBackup', 'OnlineServices' ]].head(10))\n \n#Creating a new column for Streaming Services (StreamingTV & StreamingMovies) . If a customer has StreamingTV or StreamingMovies\n#then , I am considering it as \"Yes\" else \"No\"\nlist_streaming_services = []\nfor rows_stv in range(len(datset_churn['StreamingTV'])):\n    if ((datset_churn['StreamingTV'][rows_stv] == 'No') and (datset_churn['StreamingMovies'][rows_stv] == 'No')):\n        list_streaming_services.append('No')\n    else:\n        list_streaming_services.append('Yes')\ndatset_churn['StreamingServices'] = list_streaming_services\n\n#print(datset_churn[['StreamingTV', 'StreamingMovies', 'StreamingServices' ]].head(10))\n\nplot_cat_data = sns.catplot(x='Family', col='Churn_Num', data = datset_churn, kind='count', height=4, aspect=0.8)\nplot_cat_data = sns.catplot(x='OnlineServices', col='Churn_Num', data = datset_churn, kind='count', height=4, aspect=0.8)\nplot_cat_data = sns.catplot(x='StreamingServices', col='Churn_Num', data = datset_churn, kind='count', height=4, aspect=0.8)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"02502ed0baa7f714cc3cf3e7a943243b48882216"},"cell_type":"markdown","source":"#### Observation\n - Customers with family are less likely to Churn\n - Customers not opted for online services (online backup or security) have slightly higher chances of churn\n - Customer opted for Streaming Services seems to have slightly higher chances of churn"},{"metadata":{"_uuid":"986eb3cdd28bd86a9dc2a1800bd955e1fb58acf5"},"cell_type":"markdown","source":"## Preparing Columns for Classification"},{"metadata":{"_uuid":"e6daa797283285e6c5d44279e27dbfcda63f473a"},"cell_type":"markdown","source":"### Converting the Object/Categorical Variable to Numerical Variable"},{"metadata":{"trusted":true,"_uuid":"bdbd98daac0c008597ab4805267363eb9d6cb1d9"},"cell_type":"code","source":"datset_churn.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eb18ebbcf8d93d7c19151ebb633a318d2da52323"},"cell_type":"code","source":"#Converting Gender column to numeric value\n#datset_churn['Gender'].unique() # Print unique values in the column\ndatset_churn['Gender_Num'] = datset_churn['Gender'].map( {'Female': 1, 'Male': 0} ).astype(int) #Map Categorical to Numerical Values\ndatset_churn[['Gender','Gender_Num']].head(2) # Test the mapping","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"24ae7cc62fa31125d9cd839e62cbc688aba1faa8"},"cell_type":"code","source":"# For Partner & Dependant , we created Family Column . Converting Family column to numeric value\n#datset_churn['Family'].unique() # Print unique values in the column\ndatset_churn['Family_Num'] = datset_churn['Family'].map( {'Yes': 1, 'No': 0} ).astype(int) #Map Categorical to Numerical Values\ndatset_churn[['Family','Family_Num']].head(2) # Test the mapping","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a81461521d93280a4f9192d424688f9ac0d80b26"},"cell_type":"code","source":"datset_churn['PhoneService_Num'] = datset_churn['PhoneService'].map( {'Yes': 1, 'No': 0} ).astype(int)\ndatset_churn['MultipleLines_Num'] = datset_churn['MultipleLines'].map( {'No': 0, 'Yes': 1, 'No phone service':2} ).astype(int)\ndatset_churn['InternetService_Num'] = datset_churn['InternetService'].map( {'DSL': 0, 'Fiber optic': 1, 'No':2} ).astype(int)\ndatset_churn['OnlineServices_Num'] = datset_churn['OnlineServices'].map( {'Yes': 1, 'No': 0} ).astype(int)\n\ndatset_churn['DeviceProtection_Num'] = datset_churn['DeviceProtection'].map( {'No': 0, 'Yes': 1, 'No internet service':2} ).astype(int)\ndatset_churn['StreamingServices_Num'] = datset_churn['StreamingServices'].map( {'Yes': 1, 'No': 0} ).astype(int)\ndatset_churn['TechSupport_Num'] = datset_churn['TechSupport'].map( {'No': 0, 'Yes': 1, 'No internet service':2} ).astype(int)\ndatset_churn['Contract_Num'] = datset_churn['Contract'].map( {'Month-to-month': 0, 'One year': 1, 'Two year': 2} ).astype(int)\ndatset_churn['PaperlessBilling_Num'] = datset_churn['PaperlessBilling'].map( {'Yes': 1, 'No': 0} ).astype(int)\ndatset_churn['PaymentMethod_Num'] = datset_churn['PaymentMethod'].map( {'Electronic check': 0, 'Mailed check': 1, 'Bank transfer (automatic)': 2 , 'Credit card (automatic)' : 3} ).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"48d693a90c2cabc5008bf99bf54a58ddefbf0536"},"cell_type":"code","source":"datset_churn.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"520c52df6b305ad28c20ff61b653f8bb4c5a571e"},"cell_type":"markdown","source":"### Now we will delete the non-required rows and prepare the dataset for classification"},{"metadata":{"trusted":true,"_uuid":"1b8e7a39a9e53c3446b15c4734819db1436dd3ce"},"cell_type":"code","source":"# Take a copy of dataset\ndatset_churn_copy = datset_churn.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"82fe6410f5dea13eba322e7f089d799e26b50617"},"cell_type":"code","source":"#Dropping the Categorical columns and keeping their equivalent numeric column\ncolumns_to_drop = ['Gender', 'Partner', 'Dependents', 'Tenure', 'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod', 'TotalCharges', 'Churn', 'Family', 'OnlineServices', 'StreamingServices']\ndatset_churn = datset_churn.drop(columns_to_drop, axis=1)\n\n#Re-arranging the columns as per origial dataset\ndatset_churn = datset_churn[['CustomerID', 'Gender_Num', 'SeniorCitizen', 'Family_Num', 'TenureCat', 'PhoneService_Num', 'MultipleLines_Num', 'InternetService_Num', 'OnlineServices_Num', 'DeviceProtection_Num', 'TechSupport_Num', 'StreamingServices_Num', 'Contract_Num', 'PaperlessBilling_Num', 'PaymentMethod_Num', 'MonthlyChargesCat', 'Churn_Num']]\ndatset_churn = datset_churn.rename(columns={'Gender_Num' : 'Gender', \n                             'Family_Num' : 'Family',\n                             'PhoneService_Num' : 'PhoneService',\n                             'MultipleLines_Num': 'MultipleLines', \n                             'InternetService_Num' : 'InternetService', \n                             'OnlineServices_Num' : 'OnlineServices', \n                             'DeviceProtection_Num' : 'DeviceProtection',\n                             'TechSupport_Num' : 'TechSupport', \n                             'StreamingServices_Num' : 'StreamingServices', \n                             'Contract_Num' : 'Contract', \n                             'PaperlessBilling_Num' : 'PaperlessBilling', \n                             'PaymentMethod_Num' : 'PaymentMethod', \n                             'MonthlyCharges' : 'MonthlyCharges', \n                             'Churn_Num' :  'Churn' })\ndatset_churn.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eda1765adb78b6cc8514bcb0496d3bc9a4fbb70a"},"cell_type":"code","source":"datset_churn.head(10) # Taking a quick look into the new data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8e1b54014e45a7afc077c321979ef90994d764ee"},"cell_type":"code","source":"X = datset_churn.iloc[:,1:16].values # Feature Variable\ny = datset_churn.iloc[:,16].values # Target Variable\n\n#Dividing data into test & train splitting 70% data for training anf 30% for test\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)\nprint('There are {} samples in the training set and {} samples in the test set'.format(X_train.shape[0], X_test.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cbb648fef36d5737b092a477b6754ae94c08a1c9"},"cell_type":"markdown","source":"## Classification\n### We will run all classifiers to have an initial look at the performance"},{"metadata":{"_uuid":"7e11917ca21ffd0d5bf3c5c14bcc8948aab3e3ba"},"cell_type":"markdown","source":"#### Defining function for Confusion Matrix , Precision, Recall and F1 Score"},{"metadata":{"trusted":true,"_uuid":"76eccd67b83eeffa416861d1e6d532f08d198ad5"},"cell_type":"code","source":"#Creating function for Confusion Matrix , Precsion, Recall and F1 Score\ndef plot_confusion_matrix(classifier, y_test, y_pred_test):\n    cm = confusion_matrix(y_test, y_pred_test)\n    \n    print(\"\\n\",classifier,\"\\n\")\n    plt.clf()\n    plt.imshow(cm, interpolation='nearest', cmap='RdBu')\n    classNames = ['Churn-No','Churn-Yes']\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    tick_marks = np.arange(len(classNames))\n    plt.xticks(tick_marks, classNames, rotation=45)\n    plt.yticks(tick_marks, classNames)\n    s = [['TN','FP'], ['FN', 'TP']]\n    \n    for i in range(2):\n        for j in range(2):\n            plt.text(j,i, str(s[i][j])+\" = \"+str(cm[i][j]), \n                     horizontalalignment='center', color='White')\n    \n    plt.show()\n        \n    tn, fp, fn, tp = cm.ravel()\n\n    recall = tp / (tp + fn)\n    precision = tp / (tp + fp)\n    F1 = 2*recall*precision/(recall+precision)\n\n    print('Recall={0:0.3f}'.format(recall),'\\nPrecision={0:0.3f}'.format(precision))\n    print('F1={0:0.3f}'.format(F1))\n    return;","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"240a3c2ab9478998630adba4ccc5f9d964742b35"},"cell_type":"markdown","source":"#### Defining function for Precision Recall Curve"},{"metadata":{"trusted":true,"_uuid":"70f0053c61a5718029fb07484af7ce61c2b95f43"},"cell_type":"code","source":"from sklearn.metrics import average_precision_score, precision_recall_curve\ndef plot_prec_rec_curve(classifier, y_test, y_pred_score):\n    precision, recall, _ = precision_recall_curve(y_test, y_pred_score)\n    average_precision = average_precision_score(y_test, y_pred_score)\n\n    print('Average precision-recall score: {0:0.3f}'.format(\n          average_precision))\n\n    plt.plot(recall, precision, label='area = %0.3f' % average_precision, color=\"green\")\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.title('Precision Recall Curve')\n    plt.legend(loc=\"best\")\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f64595ccf361c26728f6dcafd4386e8b173a6dda"},"cell_type":"markdown","source":"### Master Classification Engine"},{"metadata":{"trusted":true,"_uuid":"7209b13985c88ca5ed21eea632f93db9ef1e651c"},"cell_type":"code","source":"# Making a list of all classifiers\nclassifier_model = [LogisticRegression(),KNeighborsClassifier(),GaussianNB(),SVC(),DecisionTreeClassifier(),RandomForestClassifier(), SGDClassifier(), AdaBoostClassifier()]\n\n# Creating empty list to store the performance details\nclassifier_model_list= []\nclassifier_accuracy_test = []\nclassifier_accuracy_train = []\nf1score = []\nprecisionscore = []\nrecallscore = []\navg_pre_rec_score = []\ncv_score = []\n\nfor classifier_list in classifier_model:\n    classifier = classifier_list\n \n    # Fitting the training set into classification model\n    classifier.fit(X_train,y_train)\n    \n    # Predicting the output on test datset\n    y_pred_test = classifier.predict(X_test)    \n    score_test = accuracy_score(y_test, y_pred_test)\n    \n    # Predicting the output on training datset\n    y_pred_train = classifier.predict(X_train) \n    score_train = accuracy_score(y_train, y_pred_train)\n    \n    # Cross Validation Score on training test\n    scores = cross_val_score(classifier, X_train,y_train, cv=10)\n    cv_score.append(scores.mean())\n    \n    #Keeping the model and accuracy score into a list\n    classifier_model_list.append(classifier_list.__class__.__name__)\n    classifier_accuracy_test.append(round(score_test,4))\n    classifier_accuracy_train.append(round(score_train,4))\n    \n    #Precision, Recall and F1 score\n    f1score.append(f1_score(y_test, y_pred_test))\n    precisionscore.append(precision_score(y_test, y_pred_test))\n    recallscore.append(recall_score(y_test, y_pred_test))\n    \n    #Calculating Average Precision Recall Score\n    try:\n        y_pred_score = classifier.decision_function(X_test)\n    except:\n        y_pred_score = classifier.predict_proba(X_test)[:,1]\n    \n    from sklearn.metrics import average_precision_score\n    average_precision = average_precision_score(y_test, y_pred_score)\n    avg_pre_rec_score.append(average_precision)\n    \n    \n    #Confusion Matrix\n    plot_confusion_matrix(classifier_list.__class__.__name__, y_test, y_pred_test)\n    plot_prec_rec_curve(classifier_list.__class__.__name__, y_test, y_pred_score)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8ee0a29f09beb63c1d26c37414b2ab1382e88ffe"},"cell_type":"markdown","source":"### CLASSIFICATION MODEL PERFORMANCE EVALUATION"},{"metadata":{"trusted":true,"_uuid":"e6141437fc0643d1badcb7fb61844ab7be5d3df6"},"cell_type":"code","source":"#Creating pandas dataframe with Model and corresponding accuracy\n#accuracy_df = pd.DataFrame({'Model':classifier_model_list , 'Test Accuracy':classifier_accuracy_test, 'Train Accuracy' :classifier_accuracy_train , 'Precision':precisionscore, 'Recall':recallscore ,'F1 Score':f1score},index=None)\naccuracy_df = pd.DataFrame({'Model':classifier_model_list , 'Cross Val Score':cv_score, 'Test Accuracy' :classifier_accuracy_train , 'Precision':precisionscore, 'Recall':recallscore ,'Avg Precision Recall':avg_pre_rec_score ,'F1 Score':f1score})\n\n# Calculating Average Accuracy = (Test + Train)/2\naccuracy_df['Average_Accuracy'] =  (accuracy_df['Cross Val Score'] + accuracy_df['Test Accuracy'] )/ 2\n\n#Arranging the Columns\nprint(\"\\n*------------------------------    CLASSIFICATION MODEL PERFORMANCE EVALUATION      ---------------------*\\n\")\naccuracy_df = accuracy_df[['Model','Cross Val Score', 'Test Accuracy', 'Average_Accuracy','Precision', 'Recall','Avg Precision Recall','F1 Score']]  # This will arrange the columns in the order we want\n\n#Sorting the Columns based on Average Accuracy\naccuracy_df.sort_values('Average_Accuracy', axis=0, ascending=False, inplace=True) # Sorting the data with highest accuracy in the top\naccuracy_df\n#accuracy_df.transpose()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3356581460e6e8f24c8570158158f15e4813e3e0"},"cell_type":"markdown","source":"#### Observations\n\n1. Since our dataset class is imbalanced. Churn \"Yes\" is almost 3 times as \"No', Accuracy is not the right measure and we have to consider Precision, Recall and F1 Score for further evaluation and improvement of model\n    \n    1.1 Precision: A measure of a classifiers exactness.A low precision can also indicate a large number of False Positives.\n    \n    1.2 Recall: A measure of a classifiers completeness.A low recall indicates many False Negatives.\n    \n    1.3 F1 Score (or F-score): A weighted average or Harmonic Mean of precision and recall.\n\n2. Logistic Regression (AUC = 0.65) and Adaboost model (AUC = 0.65) looks promising. Let's try to improve the model"},{"metadata":{"_uuid":"e6d0834afe539ed1a216c4d832f4fab4ba344b56"},"cell_type":"markdown","source":"## Improving our Model: Model Tuning\n### Grid Search for Logistic Regression Classifier and running with optimized hyperparameters"},{"metadata":{"trusted":true,"_uuid":"4559229cd1ee0ddcc20dde4c4850c239d1bb1137"},"cell_type":"code","source":"from sklearn.grid_search import GridSearchCV\nfrom sklearn.metrics import make_scorer\nfrom sklearn.metrics import fbeta_score, accuracy_score\nfrom sklearn.linear_model  import LogisticRegression # Logistic Regression Classifier\n\n#Logistic Regression Classifier\nclf = LogisticRegression()\n\n#Hyperparameters\nparameters = {'C':np.logspace(0, 4, 10), \n              'penalty' : ['l1', 'l2']\n             }\n\n# Make an fbeta_score scoring object\nscorer = make_scorer(fbeta_score,beta=0.5)\n\n# Perform grid search on the classifier using 'scorer' as the scoring method\ngrid_obj = GridSearchCV(clf, parameters,scorer)\n\n# Fit the grid search object to the training data and find the optimal parameters\ngrid_fit = grid_obj.fit(X_train,y_train)\n\n# Get the estimator\nbest_clf = grid_fit.best_estimator_\n\n# View best hyperparameters\n#print(grid_srchfit.best_params_)\n\n# Make predictions using the unoptimized and model\npredictions = (clf.fit(X_train, y_train)).predict(X_test)\nbest_predictions = best_clf.predict(X_test)\n\n# Report the before-and-afterscores\nprint (\"Unoptimized model\\n------\")\nprint (\"Accuracy score on testing data: {:.4f}\".format(accuracy_score(y_test, predictions)))\nprint (\"F-score on testing data: {:.4f}\".format(fbeta_score(y_test, predictions, beta = 0.5)))\nprint (\"\\nOptimized Model\\n------\")\nprint (\"Final accuracy score on the testing data: {:.4f}\".format(accuracy_score(y_test, best_predictions)))\nprint (\"Final F-score on the testing data: {:.4f}\".format(fbeta_score(y_test, best_predictions, beta = 0.5)))\nprint (best_clf)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"21b91dd74cdbb87ae9271faa072f6111f18f1d4b"},"cell_type":"markdown","source":"### Grid Search for Adaboost Classifier and running with optimized hyperparameters"},{"metadata":{"trusted":true,"_uuid":"805d962e095965df6a8274164c163a0ce7b31ef0"},"cell_type":"code","source":"# TODO: Import 'GridSearchCV', 'make_scorer', and any other necessary libraries\nfrom sklearn.grid_search import GridSearchCV\nfrom sklearn.metrics import make_scorer\nfrom sklearn.metrics import fbeta_score, accuracy_score\n\n# TODO: Initialize the classifier\nclf = AdaBoostClassifier(base_estimator=DecisionTreeClassifier())\n\n# TODO: Create the parameters list you wish to tune\nparameters = {'n_estimators':[50, 120], \n              'learning_rate':[0.1, 0.5, 1.],\n              'base_estimator__min_samples_split' : np.arange(2, 8, 2),\n              'base_estimator__max_depth' : np.arange(1, 4, 1)\n             }\n\n# TODO: Make an fbeta_score scoring object\nscorer = make_scorer(fbeta_score,beta=0.5)\n\n# TODO: Perform grid search on the classifier using 'scorer' as the scoring method\ngrid_obj = GridSearchCV(clf, parameters,scorer)\n\n# TODO: Fit the grid search object to the training data and find the optimal parameters\ngrid_fit = grid_obj.fit(X_train,y_train)\n\n# Get the estimator\nbest_clf = grid_fit.best_estimator_\n\n# Make predictions using the unoptimized and model\npredictions = (clf.fit(X_train, y_train)).predict(X_test)\nbest_predictions = best_clf.predict(X_test)\n\n# Report the before-and-afterscores\nprint (\"Unoptimized model\\n------\")\nprint (\"Accuracy score on testing data: {:.4f}\".format(accuracy_score(y_test, predictions)))\nprint (\"F-score on testing data: {:.4f}\".format(fbeta_score(y_test, predictions, beta = 0.5)))\nprint (\"\\nOptimized Model\\n------\")\nprint (\"Final accuracy score on the testing data: {:.4f}\".format(accuracy_score(y_test, best_predictions)))\nprint (\"Final F-score on the testing data: {:.4f}\".format(fbeta_score(y_test, best_predictions, beta = 0.5)))\nprint (best_clf)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b6e14b426b9d5a4a046cd425b71bce4fb27e93c0"},"cell_type":"markdown","source":"Observations:\nBoth Logistic Regression & Adaboost Classifier gives us final F score of 0.65  and accuracy of 0.80 post grid search."},{"metadata":{"_uuid":"ac845982b11427f861528579e5260d23decba07b"},"cell_type":"markdown","source":"## Feature Importance\n### In this section , we will run scikit learn feature importances to evaluate which columns are being give higher weights"},{"metadata":{"trusted":true,"_uuid":"b308554a4cb886aa01ee7e3b07f4ec5ef6bcacec"},"cell_type":"code","source":"# Feature Importance for Adaboost\nfrom sklearn.feature_selection import RFE\nfeatures = list(datset_churn.columns[1:16])\n\n# Feature Importance for AdaBoostClassifier\nadboost_cls = AdaBoostClassifier()\nadboost_cls .fit(X_train, y_train)\nfeature_imp_adboost = np.round(adboost_cls.feature_importances_, 5)\n\nfeature_imp_df = pd.DataFrame({'Features' :features, 'Adaboost_Score': feature_imp_adboost})\nfeature_imp_df.sort_values('Adaboost_Score', axis=0, ascending=False, inplace=True)\nprint(feature_imp_df)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"42216c95228b0c3d3e491b36b9d1a8ab44b33cd7"},"cell_type":"markdown","source":"#### Observation:"},{"metadata":{"_uuid":"0635507de6c6c21f56ad5a939a95ab68e3b6111f"},"cell_type":"markdown","source":"1. Overall - Contract, Monthly Charges, Tenure and Payment Method and Internet Service are leading columns contributing to churn. They consitute 60% weight from Mean_Feature_Importance\n\n2. Gender has no impact on Churn"},{"metadata":{"_uuid":"e91b2a5b68e2bc14359a233b22cefce64d40959c"},"cell_type":"markdown","source":"### Now we will create the dataset with top 5 columns and run Adaboost classifier to see if there is any improvement in performance"},{"metadata":{"trusted":true,"_uuid":"9cda70ad0b11bd27899b031e2efaa63ecc704386"},"cell_type":"code","source":"dataset_churn_new = datset_churn[['MonthlyChargesCat', 'TenureCat', 'Contract', 'InternetService', 'MultipleLines', 'PaymentMethod', 'Churn']]\nX_new = dataset_churn_new.iloc[:,:-1].values # Feature Variable\ny_new = dataset_churn_new.iloc[:,-1].values # Target Variable\n\n#Dividing data into test & train splitting 80% data for training and 20% for test\nX_train_new, X_test_new, y_train_new, y_test_new = train_test_split(X_new , y_new, test_size=0.20)\nprint('There are {} samples in the training set and {} samples in the test set'.format(X_train_new.shape[0], X_test_new.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7c72a77fdc88377652fdeb97fa7b98a9781a03ce"},"cell_type":"code","source":"#Adaboost Classifier , filled the hyperparameter from the Grid Search\nclassifier = AdaBoostClassifier(algorithm='SAMME.R',\n          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n            max_features=None, max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=1, min_samples_split=2,\n            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n            splitter='best'),\n          learning_rate=0.5, n_estimators=120, random_state=None)\n \n# Fitting the training set into classification model\nclassifier.fit(X_train_new, y_train_new)\n    \n# Predicting the output on test datset\ny_pred_new = classifier.predict(X_test_new)    \n\ntry:\n    y_pred_new_score = classifier.decision_function(X_test_new)\nexcept:\n    y_pred_new_score = classifier.predict_proba(X_test_new)[:,1]\n    \n#Confusion Matrix and Precision Recall Curve\nplot_confusion_matrix('Adaboost Classifier', y_test_new, y_pred_new)\nplot_prec_rec_curve('Adaboost Classifier', y_test_new, y_pred_new_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7121f5359581633a14e9b6007227363ed793bbc6"},"cell_type":"code","source":"#Logistic Regression , filled the hyperparameter from the Grid Search\nclassifier_logreg = LogisticRegression(C=2.7825594022071245, class_weight=None, dual=False,\n          fit_intercept=True, intercept_scaling=1, max_iter=100,\n          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n \n# Fitting the training set into classification model\nclassifier_logreg.fit(X_train_new, y_train_new)\n    \n# Predicting the output on test datset\ny_pred_new = classifier_logreg.predict(X_test_new)    \n\ntry:\n    y_pred_new_score = classifier_logreg.decision_function(X_test_new)\nexcept:\n    y_pred_new_score = classifier_logreg.predict_proba(X_test_new)[:,1]\n    \n#Confusion Matrix and Precision Recall Curve\nplot_confusion_matrix('Logistic Regression', y_test_new, y_pred_new)\nplot_prec_rec_curve('Logistic Regression', y_test_new, y_pred_new_score)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"71b50755d922bbe101a80e54786f3c46b72c13b2"},"cell_type":"markdown","source":"## Conclusion\n1.  Adaboost classifier performed well with Precision Recall Curve -  0.65\n2. MonthlyChargesCat, TenureCat, Contract, InternetService, MultipleLines, PaymentMethod are leading contributing to churn\n\nModel can be further improved using the strategies discussed in next paragragh.\n\n### Handling Imbalaced Dataset :\n\n1. Increasing the number of instances of the minority class (This case Churn = 'Yes') . We need more data with Churn Class as \"Yes\".\n2. Decreasing the number of instances of majority class\n3. Random Under-Sampling\n4. Random Over-Sampling\n5. Cluster-Based Over Sampling\n6. Synthetic Minority Over-sampling Technique(SMOTE)\n\nDetailed explanation - https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/"},{"metadata":{"_uuid":"78e9838bcb7f994889f1218981d196a1b94f7dab"},"cell_type":"markdown","source":"Hope you enjoyed the kernel. Thank You!\nJagannath Banerjee |https://jagannathbanerjee.com | https://www.linkedin.com/in/jagannath-banerjee/ | Aug 2018"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":1}