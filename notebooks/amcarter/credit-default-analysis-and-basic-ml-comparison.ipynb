{"nbformat_minor":1,"cells":[{"cell_type":"markdown","source":"# Analysis of credit default data\n<HR>\n\n## Introduction\n\nThis notebook is separated into three main sections:\n\n1) Exploratory data analysis and feature simplification\n\n2) Identification and weighting of factors affecting risk of default\n\n3) Predictive modelling: Feature engineering and outline comparison of 4 ML algorithms\n","metadata":{"_cell_guid":"db86fc5f-cd43-444e-b8df-032ecae3fbc4","_uuid":"6cf214ef5b2081e8faae8fff69fc4ce8ebe99c72"}},{"cell_type":"code","outputs":[],"source":"# standard imports\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set_style('whitegrid')","execution_count":null,"metadata":{"_cell_guid":"0b51fdc6-5118-4633-8f8c-bf2e4eaf0e26","_uuid":"4b5fc51d10ab1beaf7a7fe2c30c9458b8c68eaee","collapsed":true}},{"cell_type":"code","outputs":[],"source":"# sklearn imports\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\n\n# from sklearn.preprocessing import StandardScaler\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.tree import DecisionTreeClassifier","execution_count":null,"metadata":{"_cell_guid":"c7226b80-5fa5-4433-95cd-110dd38a5638","_uuid":"f2ccb3d0f5deaaa9d68cdf17d859735c5dde16db","collapsed":true}},{"cell_type":"markdown","source":"## Section 1: EDA and feature simplification","metadata":{"_cell_guid":"a978b11a-3f3f-4ade-9f79-2c48b6868633","_uuid":"58b02e47e14d47397a54742acd40155307c87c8c"}},{"cell_type":"code","outputs":[],"source":"df = pd.read_excel('data.xls', sheetname='Data', skiprows=1, index_col='ID')\ndf.head()","execution_count":null,"metadata":{"_cell_guid":"b93d5381-8a11-4ba3-993b-43af13eb12da","_uuid":"614f6dd5709cbfd8b95b291806e24525caaa197f","collapsed":true}},{"cell_type":"code","outputs":[],"source":"# check for nulls and correct data import type - expect all rows to be int64\ndf.info()","execution_count":null,"metadata":{"_cell_guid":"1a42c092-ea6d-472f-b716-bb442c4a1136","_uuid":"b9c5db0a50a27058522630144d54c87f9e2c17b3","collapsed":true,"scrolled":true}},{"cell_type":"code","outputs":[],"source":"# examine distribution of values\nfig = plt.figure(figsize=(10, 10))\nax1 = plt.subplot2grid((3, 3), (0, 0), colspan=3)\nax2 = plt.subplot2grid((3, 3), (1, 0),)\nax3 = plt.subplot2grid((3, 3), (1, 1),)\nax4 = plt.subplot2grid((3, 3), (1, 2),)\nax5 = plt.subplot2grid((3, 3), (2, 0), colspan=3)\nsns.distplot(df.LIMIT_BAL, ax=ax1);\nsns.countplot(df.SEX, ax=ax2)\nsns.countplot(df.EDUCATION, ax=ax3)\nsns.countplot(df.MARRIAGE, ax=ax4)\nsns.distplot(df.AGE, ax=ax5);\nplt.tight_layout()\nplt.suptitle('Exploratory analysis of uncleaned data',y=1.02,fontsize=16,weight='bold');","execution_count":null,"metadata":{"_cell_guid":"c49d7e38-2b49-447f-8d31-602569f7ce21","_uuid":"46ac70563317b217a74cfff8c244fabf9bea23df","collapsed":true,"scrolled":false}},{"cell_type":"markdown","source":"### Insights\n##### Handling categoricals\nThere are some categorical values which are not listed in the attribute information (e.g. EDUCATION 4, 5, MARRIAGE 3). Given \nthan these are a relatively small fraction of the overall data, it makes sense to remove them rather than risk polluting data with approximated replacement values.\n##### Continuous variables\nCutoffs of $500,000 for credit limit and 70 for age will be applied.\n<hr>\n","metadata":{"_cell_guid":"bda2d805-3e60-4cc4-b8d1-3227864df126","_uuid":"d6a9ff89e38467e3c1f63cd54dfc90e048eff945"}},{"cell_type":"markdown","source":"### Feature simplification","metadata":{"_cell_guid":"972c878c-d861-45c2-9c03-f399ce61b139","_uuid":"069a647a228f1f517773061ceb131d90e0a03193"}},{"cell_type":"code","outputs":[],"source":"# create dictionaries of the known data types,rename final column for ease of access by name\nsexdict = {1:'Male', 2:'Female'}\nedudict = {1:'Grad School', 2:'University', 3:'High School'}\nmarriagedict = {1:'Married', 2:'Single'}\ndf.rename(columns={'default payment next month':'default'}, inplace=True)","execution_count":null,"metadata":{"_cell_guid":"5a2140b4-0e3b-48cc-9c5e-220bbd9d5cf0","_uuid":"da64cfcac47b27fcd58d074c5de03477e2e13dce","collapsed":true}},{"cell_type":"code","outputs":[],"source":"# Filter the dataset to exclude undefined categorical values for education and marriage\n\nedulist= [1,2,3]\nmarriagelist = [1, 2]\ndf = df[df['EDUCATION'].isin(edulist)]\ndf = df[df['MARRIAGE'].isin(marriagelist)]\n\n# Apply names from the dictionaries above\ndf.SEX = df.SEX.map(sexdict)\ndf.EDUCATION = df.EDUCATION.map(edudict)\ndf.MARRIAGE = df.MARRIAGE.map(marriagedict)","execution_count":null,"metadata":{"_cell_guid":"87a5a2a0-8b2c-4550-9b49-cb733fa92755","_uuid":"e595e3176bba312ac32f4e0976acd92337e3aba9","collapsed":true}},{"cell_type":"code","outputs":[],"source":"# Convert the continuous distributions of age and credit limit into binned values\n# Benefits ease of analysis and machine learning algorithms\nagebins = np.arange(20, 80, 10)\nagebinlabels = ['{}s'.format(i, j) for i, j in zip(agebins, agebins[1:])]\ndf['AGE_GROUP'] = pd.cut(df.AGE, bins=agebins, labels=agebinlabels, right=False)\n\ncreditlimitbins = np.arange(0, 550000, 50000)\ncreditbinlabels = ['{}-{}k'.format(i//1000, j//1000) for i, j in zip(creditlimitbins, creditlimitbins[1:])]\ndf['LIMIT_BAL_GROUP'] = pd.cut(df.LIMIT_BAL, bins=creditlimitbins, labels=creditbinlabels)","execution_count":null,"metadata":{"_cell_guid":"ed812201-b5e8-4fb4-ae5a-c03b1d44604b","_uuid":"da4c01e6615d119cad04346f36695bba87722cf2","collapsed":true}},{"cell_type":"code","outputs":[],"source":"# examine distribution of values following data cleaning\nfig = plt.figure(figsize=(10, 10))\nax1 = plt.subplot2grid((3, 3), (0, 0), colspan=3)\nax2 = plt.subplot2grid((3, 3), (1, 0),)\nax3 = plt.subplot2grid((3, 3), (1, 1),)\nax4 = plt.subplot2grid((3, 3), (1, 2),)\nax5 = plt.subplot2grid((3, 3), (2, 0), colspan=3)\nplotlist = ['LIMIT_BAL_GROUP', 'SEX', 'MARRIAGE', 'EDUCATION', 'AGE_GROUP']\nfor col, ax in zip(plotlist, fig.get_axes()):\n    sns.countplot(x=col, data=df, ax=ax)\nplt.suptitle('Exploratory analysis of cleaned data', y=1.01, fontsize=16, weight='bold')\nplt.tight_layout()","execution_count":null,"metadata":{"_cell_guid":"e878e225-d29a-427f-b605-087e17c48b53","_uuid":"b97e26b27dab1eab22e218dc6ca478f16faf062d","collapsed":true}},{"cell_type":"markdown","source":"The data is suitably clean to begin analysing for factors which contribute to default.\n<HR>","metadata":{"_cell_guid":"04d35732-eff1-4ab6-adfb-b783c37d5790","_uuid":"feb2377d1b6c460c421328b08516d4c5f3947a9c"}},{"cell_type":"markdown","source":"## Section 2: Identification of factors\n\nThe pointplot is a useful tool to compare how each variable contributes to the probability of default.","metadata":{"_cell_guid":"d1e3af71-dd67-4d81-86e4-c68d70aab74f","_uuid":"554b9a8bc67576af8a25b3a5ec4a3f4d16bd8afd"}},{"cell_type":"code","outputs":[],"source":"# construct figure from pointplots\nfig = plt.figure(figsize=(10, 10))\nax1 = plt.subplot2grid((3, 3), (0, 0), colspan=3)\nax2 = plt.subplot2grid((3, 3), (1, 0), sharey=ax1)\nax3 = plt.subplot2grid((3, 3), (1, 1), sharey=ax1)\nax4 = plt.subplot2grid((3, 3), (1, 2), sharey=ax1)\nax5 = plt.subplot2grid((3, 3), (2, 0), colspan=3, sharey=ax1)\nplotlist = ['LIMIT_BAL_GROUP', 'SEX', 'MARRIAGE', 'EDUCATION', 'AGE_GROUP']\nfor col, ax in zip(plotlist, fig.get_axes()):\n    sns.pointplot(x=col, y='default', data=df, ax=ax, markers='')\n    ax.set_ylabel('Correlation with default')\nax1.set_ylim(0.0, 1)\nplt.suptitle('Correlation with default for each variable', y=1.01, fontsize=16, weight='bold')\nplt.tight_layout()","execution_count":null,"metadata":{"_cell_guid":"acdd185c-73db-4e5a-9a02-ad65c6a7f164","_uuid":"d4156b7cb7a570586ed36842db486af5c3e9ff19","collapsed":true}},{"cell_type":"markdown","source":"### Insights\nThe categorical factors are quite weakly linked to the risk of default, with no single value weighting more than 0.4. However, there are a few insights that can be gleaned:\n\n1) Risk of default is higher when the limit balance is lower\n\n2) Risk of default is at a minimum for customers in their 30s\n\n3) Highest risk: Married men with a high school education in their later years)\n\n4) Lowest risk: Single women with a grad school education in their 30s\n\nNext steps: Continue search for additional features which have a higher correlation with default.\n<hr>","metadata":{"_cell_guid":"b8143ceb-fbdc-4401-8b28-9dfcf5540118","_uuid":"8aecc67b9acd79e116f70d3499ded9d0e13698dd"}},{"cell_type":"markdown","source":"### History of past payment\n\nHistory of past payment may be an indicator of the risk of default. We might expect a customer missing payments as an indicator that default may be about to occur. This analysis will examine how payment delay in previous periods is connected with risk of default.","metadata":{"_cell_guid":"b57ec205-2a04-44f9-9abf-9d01a613488b","_uuid":"71a30c52fc22fb61d8efa3c04fb9764f17d1a97a"}},{"cell_type":"code","outputs":[],"source":"ax1 = sns.countplot(x='PAY_2', data=df)\nax2 = ax1.twinx()\nax2 = sns.pointplot(x='PAY_2', y='default', data=df, zorder=10, ax=ax2)\nax1.grid(False)\nax2.grid(False)\nplt.suptitle('Risk of default with payment delay in months');","execution_count":null,"metadata":{"_cell_guid":"b06c8a1b-8d0d-442d-98ff-7f83d0cb4079","_uuid":"f9722a61444fcd2152f9e4898a905f02bc0815b1","collapsed":true}},{"cell_type":"markdown","source":"### Insights\nPayment codes of -2,-1 or 0 make up the majority of values (coloured bars), and they correlate with very low risk of default (blue dotted line). When there is a payment delay of 2 months or more (green bar), the risk of default jumps up significantly to ~0.5. \n\nThere are very few datapoints for payment delays of 3 months or more. Therefore, a feature which links payment delays of <b>2 months or more</b> to risk of default may be useful in a predictive model. The next stage will investigate if a 2 month cut off is appropriate for the other pay periods too.","metadata":{"_cell_guid":"01453f12-644d-464a-bfb4-070f82c20e74","_uuid":"3da28ce8f0544e753afa0db8efc7748cfa6ba9ca"}},{"cell_type":"code","outputs":[],"source":"payment_delay_cols = ['PAY_2', 'PAY_3', 'PAY_4', 'PAY_5']\nfig, ax = plt.subplots(1, 4, figsize=(12, 4), sharey=True)\nfor i,(column, ax) in enumerate(zip(payment_delay_cols, ax)):\n    sns.pointplot(x=column, y='default', data=df[df[column]!=1], ax=ax, color=sns.color_palette()[i])\nplt.suptitle('Risk of default with payment delay across four past periods');","execution_count":null,"metadata":{"_cell_guid":"8e94b7c9-ce3e-411b-8e7a-e55a65c9fb7a","_uuid":"41f0c7c4972f9ba1155a0274eac8fe317d157493","collapsed":true}},{"cell_type":"markdown","source":"Choice of cut off: \n- Assign a cut off of <b>2 months</b> for 'PAY_2', 'PAY_3', 'PAY_4', and 'PAY_5' columns\n- Create a new binary feature (with 'TEST' suffix) for each of these columns.","metadata":{"_cell_guid":"da8215bf-8cd5-4516-9f6d-d4034658a9dd","_uuid":"62a4f5ca8b0575a1446bb10575744cb90fa921b7"}},{"cell_type":"code","outputs":[],"source":"cutoff_point = {'PAY_2': 2, 'PAY_3': 2, 'PAY_4': 2, 'PAY_5': 2}\nfor color, column in enumerate(cutoff_point.keys()):\n    df[column+'_TEST'] =  df[column].map(lambda x: 'Delay' if x >= cutoff_point[column] else 'Paid')\n    sns.pointplot(x=column+'_TEST', y='default', data=df, order=['Paid', 'Delay'], color=sns.color_palette()[color])\nplt.xlabel('')\nplt.ylim(0, 1);\nplt.suptitle('Risk of default with a timely payment or delay beyond a 2 or 3 month cut off');","execution_count":null,"metadata":{"_cell_guid":"7e6fc0a3-3a00-4cb4-a976-e89f9dd281af","_uuid":"8ce9e74a4aad44bba79541736176831ff44a32ea","collapsed":true}},{"cell_type":"markdown","source":"### Insights\nThis feature engineering has produced four new features which have a much larger probability of identifying risk of default than the original personal data alone.\n\n<hr>","metadata":{"_cell_guid":"e1def438-130c-434c-8094-5a45a6001e9d","_uuid":"4ac26e3da8f116599725ddcfbeb570936b621e48"}},{"cell_type":"markdown","source":"## Section 3: Machine learning analysis\n\nThis section will prepare and analyse the data with machine learning algorithms. Analysis will occur firstly \n\n1) on the <b>personal data alone</b>, which would be available at the point where the credit is applied for.\n\n2) on the <b> personal data plus the payment history</b>, which would become available over time.\n ","metadata":{"_cell_guid":"af4c628a-7811-47f5-a02e-b5d0064ca40f","_uuid":"8a81c4cc9dfe60b235e038c5c7e017ddb6f36ed6"}},{"cell_type":"code","outputs":[],"source":"def compare4models():\n    \"\"\" returns a figure based from four machine learning models\"\"\"\n    \n    names = [\"Nearest Neighbors\",\n             \"Linear SVM\",\n             \"Decision Tree\",\n             \"Naive Bayes\"]\n\n    classifiers = [KNeighborsClassifier(),\n                   SVC(),\n                   DecisionTreeClassifier(),\n                   GaussianNB()]\n    \n    cmaps = ['Reds',\n             'Greens',\n             'Blues',\n             'Oranges']\n    \n    numrows = int(np.ceil(len(names)/2))\n    fig, ax = plt.subplots(nrows=numrows, ncols=2, figsize=(8, numrows*4))\n    \n    for name,clf,ax,cmap in zip(names, classifiers, ax.ravel(), cmaps):\n        clf.fit(X_train, y_train)\n        y_pred = clf.predict(X_test)\n        score = clf.score(X_test, y_test)\n        confmatrix = confusion_matrix(y_test, y_pred)\n        true0,true1 = [sum(confmatrix[i]) for i in [0,1]]\n        pred0,pred1 = [sum(i) for i in zip(*confmatrix)]\n        ylabels=['Not default: {}'.format(true0), 'Default: {}'.format(true1)]\n        xlabels=['Not default: {}'.format(pred0), 'Default: {}'.format(pred1)]\n        sns.heatmap(confusion_matrix(y_test, y_pred),\n                    annot=True,\n                    xticklabels=xlabels,\n                    yticklabels=ylabels,\n                    fmt='g',\n                    ax=ax,\n                    vmax=len(X_test),\n                    vmin=0,\n                    cbar=False,\n                    cmap=cmap)\n        ax.set_xlabel('Truth')\n        ax.set_ylabel('Predicted')\n        ax.set_title('{} (Score: {})'.format(name, np.round(score, decimals=3)), size=14)\n    return fig,confmatrix","execution_count":null,"metadata":{"_cell_guid":"0bd5ee66-d384-4a72-9ba7-480c090810e5","_uuid":"6fe46f1a56c3afba3e0575d87058537794b72b58","collapsed":true}},{"cell_type":"markdown","source":"### Analysis with personal data only","metadata":{"_cell_guid":"7e58549b-e4e9-4a1e-96f9-cd8e4cd42981","_uuid":"0bfbf00b49e43df37fbfeeaaa11461d0e49a0bc7"}},{"cell_type":"code","outputs":[],"source":"# One-hot encoding to produce a sparse matrix suitable for input to sklearn\nmodeldata = df[['LIMIT_BAL_GROUP', 'AGE_GROUP', 'SEX', 'MARRIAGE', 'EDUCATION']]\nX = pd.get_dummies(modeldata)\ny = df.default\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=31)","execution_count":null,"metadata":{"_cell_guid":"269ca43e-899f-4689-a943-197fc97adbae","_uuid":"579b49603024a09742af3487d700a32b3acf0cdc","collapsed":true}},{"cell_type":"code","outputs":[],"source":"fig,confmatrix = compare4models()\nplt.suptitle('Comparison of 4 algorithms - Personal Data only', y=1.02, size=16, weight='bold')\nplt.tight_layout()","execution_count":null,"metadata":{"_cell_guid":"355d6b65-8288-460f-ba91-fd97e5579915","_uuid":"0e9da759804bbb1ac7a14bf37ffb29a7192a81b8","collapsed":true}},{"cell_type":"markdown","source":"### Insights\n- The scoring system of the models can be somewhat misleading when there is a small proportion of positives (i.e. defaults) compared to negatives. \n\n- The Linear SVM model scores highly overall, but the confusion matrix reveals that the model simply asserts no-one will default, and is correct 75% of the time!\n\n- The Naive Bayes model scores the lowest, but is much better at predicting defaults, with 48% of defaults identified. However, the NB model also predicts many false positives. On the assumption that false positives have a smaller financial impact than false negatives, the NB model might be prefered at the pre-approval stage.\n\n<HR>","metadata":{"_cell_guid":"1300a983-25c7-4338-a15a-2b8654132aec","_uuid":"a613d6d3b0ca5db059e2c719bb3be773aaf24a97"}},{"cell_type":"markdown","source":"### Analysis with personal data + payment history data","metadata":{"_cell_guid":"d63e5d1b-2f9e-407b-bdcb-14dbb60108d5","_uuid":"1619b3f7fd47052602feb399098b4a49b46cabc5"}},{"cell_type":"code","outputs":[],"source":"# One-hot encoding to produce a sparse matrix suitable for input to sklearn\n# Add extra columns with payment history data\nmodeldata = df[['LIMIT_BAL_GROUP', 'AGE_GROUP', 'SEX', 'MARRIAGE', 'EDUCATION',\n                'PAY_2_TEST', 'PAY_3_TEST', 'PAY_4_TEST', 'PAY_5_TEST']]\nX = pd.get_dummies(modeldata)\ny = df.default\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=31)","execution_count":null,"metadata":{"_cell_guid":"9288bade-61e0-41b9-bcbe-2025b0114ed2","_uuid":"779e0fc50b1ee7508139c64acb19f6d807126d4d","collapsed":true}},{"cell_type":"code","outputs":[],"source":"compare4models()\nplt.suptitle('Comparison of 4 algorithms - Personal and Payment History data', y=1.02, size=16, weight='bold')\nplt.tight_layout()","execution_count":null,"metadata":{"_cell_guid":"fe1eb63e-b635-471b-ab3f-2ad67538a2e8","_uuid":"a6c67f24a25390cb33a5399f0cc2cbe7e4ab06f9","collapsed":true}},{"cell_type":"markdown","source":"### Insights\n- Including features derived from information on missed payments increases the score of all four models. These are clearly useful features. \n\n- Model scores have converged; no single model idenfies both positives and negatives better than any other. The SVM and Decision Tree models now correctly identify some positives.\n\n- The Naive Bayes model performs even better at identifying true positives, with an additional 19 identified with the extra data.","metadata":{"_cell_guid":"9aaa2d07-6c4d-4ae6-8c22-43c49da361c1","_uuid":"62d00b9ed3c7304b971a02e9054a03df4189e6eb"}},{"cell_type":"markdown","source":"## Key findings\n\n- Given this data set, personal data alone is insufficient to reliably predict a default. There are significant differences in risk with age and credit limit, but few strong indicators.\n- A history of delayed payment can be a stronger indicator; with some models able to predict a default ~50% of the time given personal data and payment history.\n\n### Future work\n\n- Analyse credit used as a proportion of limit: are people using more of their limit more likely to default?\n- Analyse payment record: are people making regular payments less likely to default than those who pay erratically?\n- Investigate further cross-validation and hyperparameter tuning of models with extended dataset when available.","metadata":{"_cell_guid":"1f97bec4-48c3-404e-8fe7-1bb6b37ad0f9","_uuid":"e9c165d0cf5671981a1c40d7f957809511f017ad"}}],"nbformat":4,"metadata":{"language_info":{"file_extension":".py","nbconvert_exporter":"python","name":"python","version":"3.6.1","mimetype":"text/x-python","pygments_lexer":"ipython3","codemirror_mode":{"version":3,"name":"ipython"}},"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"}}}