{"cells":[{"metadata":{},"cell_type":"markdown","source":"# 1. Purpose of this notebook:\n\nTo answer the simple question: **\"The mean of the price of the books of fiction genre is less than that of their non-fiction counterparts\"**"},{"metadata":{},"cell_type":"markdown","source":"The notebook in no way defines or explains what an Hypothesis testing is or some, perhaps, esoteric terms associated with it. But, both as a learner and a teacher, I understand the importance of premises (building blocks) of any concept. Therefore, if any of my generous audience would want me to explain or dwell more on the topic, I'll certainly do that by making a new notebook. So feel free to reach me through comments."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom matplotlib import style\nimport random\nimport math\nstyle.use('ggplot')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/amazon-top-50-bestselling-books-2009-2019/bestsellers with categories.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Genre'] = df['Genre'].map(lambda x: 1 if x == 'Fiction'\n                             else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. Cumulative Distribution Function"},{"metadata":{},"cell_type":"markdown","source":"Defining a cumulative distribution function (cdf)"},{"metadata":{"trusted":true},"cell_type":"code","source":"def EvalCdf(sample, x):\n    count = 0\n    for i in sample:\n        if i <= x:\n            count += 1\n    prob = count / len(sample)\n    return prob","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Categorizing the data into fiction and non fiction and plotting the cdfs of the price of the books belonging to these genres"},{"metadata":{"trusted":true},"cell_type":"code","source":"fiction = df[df.Genre == 1]\nnon_fiction = df[df.Genre == 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"price_fiction = sorted(fiction['Price'].values)\ncdf_price_fiction = [EvalCdf(price_fiction, x) for x in price_fiction]\n\nprice_nonfiction = sorted(non_fiction['Price'].values)\ncdf_price_nonfiction = [EvalCdf(price_nonfiction, x) for x in price_nonfiction]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (15, 8))\n\nplt.plot(price_fiction, cdf_price_fiction, label = 'Fiction price')\nplt.plot(price_nonfiction, cdf_price_nonfiction, label = 'Non Fiction price')\n\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**What does the graph tell us?**\n\n1. The graph looks like an exponential distribution\n2. The price of the books belonging to the non-fiction genre is slightly more than that of their fiction counterparts\n3. More than 90% of the books of fiction genre is less than and equal to 20 units(probably USD), whereas the about 85% of the books of non fiction genre fall in the same range"},{"metadata":{},"cell_type":"markdown","source":"# 3. Using Estimation to find out which is a better estimator for estimating the mean of the price of both fiction and non fiction books - sample mean or median?"},{"metadata":{},"cell_type":"markdown","source":"**Why do we do it?**\n\n1. Presence of outliers - Although sample mean is a good estimator of mean but we cannot rule out the possibility of having outliers in out data. That is, there might be some books that have a price much higher or much lower than one might expect those to be. In that case, the mean would be misleading.\n2. In that case, the median would be a better estimator."},{"metadata":{},"cell_type":"markdown","source":"**How do we do it?**\n\n1. Run the experiment m no. of times each time using a sample of n no. of elements from the sample. \n2. Note the sample mean and median of the sample thus used.\n3. Put the means and the median in separate lists.\n4. Find the RMSE (Root Mean Square Error) for both the means and medians.\n5. If the RMSE of the means is less than that of the medians, we will use the mean of our sample as the estimator for estimating the mean, else otherwise."},{"metadata":{},"cell_type":"markdown","source":"***The codes below will give a better understanding***"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('mean of price of fiction books: ', fiction.Price.mean())\nprint('mean of price of non fiction books: ', non_fiction.Price.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('median of price of fiction books: ', fiction.Price.median())\nprint('median of price of non fiction books: ', non_fiction.Price.median())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def Estimate(df=fiction, mu=0, n=7, m=1000):\n    \n    means = []\n    medians = []\n    \n    for _ in range(m):\n        xs = [random.sample(list(df.Price.values), n)]\n        xbar = np.mean(xs)\n        median = np.median(xs)\n        means.append(xbar)\n        medians.append(median)\n        \n    print('rmse of xbar: ', RMSE(means, mu))\n    print('rmse of median: ', RMSE(medians, mu))\n    \ndef RMSE(estimates, actual):\n    e2 = [(estimate - actual) ** 2 for estimate in estimates]\n    mse = np.mean(e2)\n    return math.sqrt(mse)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Estimate(mu = 10.85)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Estimate(df = non_fiction, mu = 14.841935483870968)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**What does the outcomes tell us?**\n\n1. The rmse of xbar (sample mean) of the price of the books of fiction genre is more than that of the median\n2. this portrays that the median is a better estimator as compared to that of the mean. So we'll use median as mean for this distribution.\n3. The same is also true for the other distribution (non friction books data)"},{"metadata":{},"cell_type":"markdown","source":"# 4. Answer/Justify the question/statement: \"The mean of the price of the books of fiction genre is less than that of their non-fiction counterparts\""},{"metadata":{},"cell_type":"markdown","source":"***To answer that question, we need to assume a \"Null Hypothesis\"***\n\n**What is a null hypothesis?**\n\nThe opposite of what we are trying to prove. [Wikipedia definiton of Null Hypothesis](https://en.wikipedia.org/wiki/Null_hypothesis)\n\n**Null Hypothesis** - *The prices for both fiction and non fiction books are same, because to prove that the the non fiction books on average are less expensive than that of their non fiction counterparts, we need to prove that their distribution is dissimilar* \n\n**Wait a minute! Haven't we done that before by plotting the cdfs of both the distributions?**\n\nYes, but now we need to see if that conclusion holds true for all cases (larger population) or had that effect (apparent effect) appeared by chance!"},{"metadata":{"trusted":true},"cell_type":"code","source":"class HypothesisTest(object):\n    \n    def __init__(self, data):\n        self.data = data\n        self.MakeModel()\n        self.actual = self.TestStatistic(data)\n        \n    def PValue(self, iters=1000):\n        self.test_stats = [self.TestStatistic(self.RunModel()) for _ in range(iters)]\n        self.test_cdf = [EvalCdf(self.test_stats, x) for x in self.test_stats]\n        count = sum(1 for x in self.test_stats if x >= self.actual)\n        return count / iters\n    \n    def TestStatistic(self, data):\n        raise UnimplementedMethodException()\n        \n    def MakeModel(self):\n        pass\n    \n    def RunModel(self):\n        raise UnimplementedMethodException()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DiffMediansPermute(HypothesisTest):\n    \n    def TestStatistic(self, data):\n        group1, group2 = data\n        test_stat = abs(np.median(group1) - np.median(group2))\n        return test_stat\n    \n    def MakeModel(self):\n        group1, group2 = self.data\n        self.n, self.m = len(group1), len(group2)\n        self.pool = np.hstack((group1, group2))\n        \n    def RunModel(self):\n        np.random.shuffle(self.pool)\n        data = self.pool[:self.n], self.pool[self.n:]\n        return data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***Note that we used \"DiffMediansPermute\" not \"DiffMeansPermute\" because we saw that the median is a the better estimator for estimating mean for our both distributions***"},{"metadata":{},"cell_type":"markdown","source":"***In case one is interested in knowing more about the functions, please comment***"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = fiction.Price.values, non_fiction.Price.values\nht = DiffMediansPermute(data)\npvalue = ht.PValue()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('the PValue of the null hypothesis is: ', pvalue)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**What does the P Value tell us?**\n\n1. If it is less (certainly less than 5%), it means that the null hypothesis is false or that the vice versa is true (which is our assumption).\n2. If it is more than 10%, we can say that our assumption is false or that our assumption/outcome is not \"statistically important\" to be more precise and technical.\n3. If it is between  5 to 10%, we cannot say or assume much/anything about the estimation/outcome that we get because Hypothesis Testing tells us if there is strong evidence to believe that fact or not. It does not always give us a precise answer.\n\n**What does the outcome tell us?**\n\nThe outcome is between 0 and 1%, which means that our estimation(i.e. \"The mean of the price of the books of fiction genre is less than that of their non-fiction counterparts\") is statistically important and also holds true for a larger population."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}