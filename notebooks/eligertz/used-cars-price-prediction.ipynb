{"cells":[{"metadata":{},"cell_type":"markdown","source":"# In this Kernel I will conduct a rather simplified EDA and predict pricing results using several simple regression\nModels that will be used will be models such as - KNN, linear regression & simple tree regression\n\nChangelist commits - \n1. First EDA & data cleaning - commit\n2. Starting to work and predicting the price using a simple regression - commit\n3. Adding categorical features - commit\n4. Adding a KNN regression - commit"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"vehicles_df = pd.read_csv('../input/craigslistVehicles.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vehicles_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vehicles_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Lets drop all useless columns at this stage (images, links etc)**"},{"metadata":{"trusted":true},"cell_type":"code","source":"vehicles_df = vehicles_df.drop(columns=['city_url', 'image_url', 'lat', 'long'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vehicles_df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Lets drop duplicates, massive Nans and illogic pricings"},{"metadata":{"trusted":true},"cell_type":"code","source":"vehicles_df.drop_duplicates(subset='url')\nvehicles_df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finding average amount of Nans and dropping rows with more Nans than 95% quntile (9 missing values and more are dropped)"},{"metadata":{"trusted":true},"cell_type":"code","source":"vehicles_df.isnull().sum(axis=1).quantile(.95)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 9 missing values per row or more are being dropped (~9300 rows dropped)"},{"metadata":{"trusted":true},"cell_type":"code","source":"vehicles_df = vehicles_df[vehicles_df.isnull().sum(axis=1) < 9]\nvehicles_df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Now we drop all prices that are equal to 0 (approximately 45k cars!) \n\n# +\n\n# all crazy high irrelevant prices of cars - above 100k (~460 prices) - some of those are just wrong due to an addition of 0 in comparison to the description"},{"metadata":{"trusted":true},"cell_type":"code","source":"vehicles_df = vehicles_df[vehicles_df.price != 0]\nvehicles_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(3,6))\nsns.boxplot(y='price', data=vehicles_df);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vehicles_df = vehicles_df[vehicles_df.price < 100000]\nvehicles_df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Looking at the relevant years -"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,9))\nax = sns.countplot(x='year',data=vehicles_df);\nax.set_xticklabels(ax.get_xticklabels(), rotation=90, ha=\"right\",fontsize=10);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# We decide to keep only cars with year above the year of 1985 (~18k)"},{"metadata":{"trusted":true},"cell_type":"code","source":"vehicles_df = vehicles_df[vehicles_df.year > 1985]\nvehicles_df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Odometer / Milage  (\"A typical mileage before overhaul for trucks is around 700K - 1000K miles\") - dropping all mileage above 1000k Miles - usually due to wrong adding 0 to the final result (~1150 cars)."},{"metadata":{"trusted":true},"cell_type":"code","source":"vehicles_df.odometer.quantile(.999)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vehicles_df = vehicles_df[~(vehicles_df.odometer > 500000)]\nvehicles_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(3,6))\nsns.boxplot(y='odometer', data=vehicles_df);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vehicles_df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Now we can start working on the columns that could[](http://) predict price - \n(final shape after cleaning - 474166, 18)"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(style=\"ticks\", color_codes=True)\nsns.pairplot(vehicles_df, hue=\"condition\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Start with a simple Linear Regression\nusing only numeric features"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error as MSE\nfrom sklearn.model_selection import train_test_split as split\nimport warnings\nfrom sys import modules","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vehicles_df_to_learn = vehicles_df[['odometer','year','price']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"for now we will have to drop rows with odometer as Nan (just for simplicity)"},{"metadata":{"trusted":true},"cell_type":"code","source":"vehicles_df_to_learn = vehicles_df_to_learn.dropna()\nvehicles_df_to_learn.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vehicles_df_train, vehicles_df_test = split(vehicles_df_to_learn, train_size=0.6, random_state=4222)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = vehicles_df_train[['odometer','year']]\ny_train = vehicles_df_train['price']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cars_lm = LinearRegression(fit_intercept=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cars_lm.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The model intercept is: {}\".format(cars_lm.intercept_))\nprint(\"The model coefficients are: {}\".format(cars_lm.coef_[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train['Price_prediction'] = cars_lm.predict(X_train)\nX_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cars_train_rmse = np.sqrt(MSE(y_train, X_train['Price_prediction']))\nprint(\"RMSE = {:.2f}\".format(cars_train_rmse))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cars_lm_test = LinearRegression()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = vehicles_df_test[['odometer','year']]\ny_test = vehicles_df_test['price']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cars_lm_test.fit(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test['price_prediction'] = cars_lm_test.predict(X_test)\nX_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cars_test_rmse = np.sqrt(MSE(y_test, X_test['price_prediction']))\nprint(\"RMSE = {:.2f}\".format(cars_test_rmse))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Continuing with the simplicity - adding categorical parameters and lets see if the prediction improves:\n\ncondition\n\ntitle_status\n\ntransmission"},{"metadata":{"trusted":true},"cell_type":"code","source":"vehicles_df_to_learn2 = vehicles_df[['odometer','year','price', 'transmission', 'title_status', 'condition']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vehicles_df_to_learn2.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we can see that the condition has 200000 nans and therefor we will not include this parameter atm"},{"metadata":{"trusted":true},"cell_type":"code","source":"vehicles_df_to_learn2 = vehicles_df[['odometer','year','price', 'transmission', 'title_status']]\nvehicles_df_to_learn2 = vehicles_df_to_learn2.dropna()\nvehicles_df_to_learn2.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vehicles_df_to_learn2.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Here is the first way to set dummies for categorical value:"},{"metadata":{"trusted":true},"cell_type":"code","source":"vehicles_df_to_learn2['transmission_automatic'] = vehicles_df_to_learn2['transmission'].apply(lambda x: 1 if x == 'automatic' else 0)\nvehicles_df_to_learn2['transmission_manual'] = vehicles_df_to_learn2['transmission'].apply(lambda x: 1 if x == 'manual' else 0)\nvehicles_df_to_learn2['transmission_other'] = vehicles_df_to_learn2['transmission'].apply(lambda x: 1 if x == 'other' else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vehicles_df_to_learn2 = vehicles_df_to_learn2.reset_index()\nvehicles_df_to_learn2.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here is the second \"Pythonic\" way:"},{"metadata":{"trusted":true},"cell_type":"code","source":"dum = pd.get_dummies(vehicles_df_to_learn2['title_status']).reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dum.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vehicles_df_to_learn2 = pd.merge(vehicles_df_to_learn2, dum, on='index')\nvehicles_df_to_learn2 = vehicles_df_to_learn2.drop(columns=['index', 'transmission', 'title_status'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vehicles_df_to_learn2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vehicles_df_train2, vehicles_df_test2 = split(vehicles_df_to_learn2, train_size=0.6, random_state=4222)\nX_train2 = vehicles_df_train2[['odometer','year', 'transmission_automatic', 'transmission_manual', 'transmission_other', 'clean', 'lien', 'missing', 'parts only', 'rebuilt', 'salvage']]\ny_train2 = vehicles_df_train2['price']\ncars_lm2 = LinearRegression(fit_intercept=True)\ncars_lm2.fit(X_train2, y_train2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The model intercept is: {}\".format(cars_lm2.intercept_))\nprint(\"The model coefficients are: {}\".format(cars_lm2.coef_[0]))\nX_train2['Price_prediction'] = cars_lm2.predict(X_train2)\ncars_train_rmse2 = np.sqrt(MSE(y_train2, X_train2['Price_prediction']))\nprint(\"RMSE = {:.2f}\".format(cars_train_rmse2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"only ~ 0.1% less mistake than previously\nlets do the same actions on the test data set"},{"metadata":{"trusted":true},"cell_type":"code","source":"cars_lm_test2 = LinearRegression()\nX_test2 = vehicles_df_test2[['odometer','year', 'transmission_automatic', 'transmission_manual', 'transmission_other', 'clean', 'lien', 'missing', 'parts only', 'rebuilt', 'salvage']]\ny_test2 = vehicles_df_test2['price']\ncars_lm_test2.fit(X_test2, y_test2)\nX_test2['price_prediction'] = cars_lm_test2.predict(X_test2)\nX_test2.head()\ncars_test_rmse2 = np.sqrt(MSE(y_test2, X_test2['price_prediction']))\nprint(\"RMSE = {:.2f}\".format(cars_test_rmse2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A bit worth actually than the original test on the numerical datasets"},{"metadata":{},"cell_type":"markdown","source":"Continuing with the simplicity - applying a quick KNN regression:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.metrics import pairwise_distances\nfrom sklearn import neighbors\nfrom math import sqrt\nfrom sklearn.metrics import mean_squared_error ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"create train and test sets:"},{"metadata":{"trusted":true},"cell_type":"code","source":"vehicles_df_knn_train, vehicles_df_knn_test = split(vehicles_df_to_learn, train_size=0.6, random_state=4222)\nX_first = vehicles_df_knn_train.drop('price', axis=1)\ny_first = vehicles_df_knn_train['price']\n\nX_second = vehicles_df_knn_test.drop('price', axis=1)\ny_second = vehicles_df_knn_test['price']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Preprocessing â€“ Scaling the features"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range=(0, 1))\n\nX_first_scaled = scaler.fit_transform(X_first)\nX_first = pd.DataFrame(X_first_scaled)\n\nX_second_scaled = scaler.fit_transform(X_second)\nX_second = pd.DataFrame(X_second_scaled)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" Let us have a look at the error rate for different k values"},{"metadata":{"trusted":true},"cell_type":"code","source":"rmse_val2 = [] #to store rmse values for different k\nfor K in range(20):\n    K += 1\n    model = neighbors.KNeighborsRegressor(n_neighbors = K)\n\n    model.fit(X_first, y_first)  #fit the model\n    pred=model.predict(X_second) #make prediction on test set\n    error = sqrt(mean_squared_error(y_second, pred)) #calculate rmse\n    rmse_val2.append(error) #store rmse values\n    print('RMSE value for k= ' , K , 'is:', error)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plotting the rmse values against k values\ncurve = pd.DataFrame(rmse_val2) #elbow curve \ncurve.plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# we can  see K neighbours 4-7 being the best predictor in terms of error\nThe rmse is also significantly lower than the simple linear regression"},{"metadata":{},"cell_type":"markdown","source":"Lets try and run the same model on additional categorical parameters:"},{"metadata":{"trusted":true},"cell_type":"code","source":"vehicles_df_to_learn2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vehicles_df_knn_train2, vehicles_df_knn_test2 = split(vehicles_df_to_learn2, train_size=0.6, random_state=4222)\nX_first2 = vehicles_df_knn_train2.drop('price', axis=1)\ny_first2 = vehicles_df_knn_train2['price']\n\nX_second2 = vehicles_df_knn_test2.drop('price', axis=1)\ny_second2 = vehicles_df_knn_test2['price']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = MinMaxScaler(feature_range=(0, 1))\n\nX_first_scaled2 = scaler.fit_transform(X_first2)\nX_first2 = pd.DataFrame(X_first_scaled2)\n\nX_second_scaled2 = scaler.fit_transform(X_second2)\nX_second2 = pd.DataFrame(X_second_scaled2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rmse_val3 = [] \nK = 2\nfor i in range(5):\n    K += 1\n    model2 = neighbors.KNeighborsRegressor(n_neighbors = K)\n    model2.fit(X_first2, y_first2)  \n    pred2=model2.predict(X_second2) \n    error2 = sqrt(mean_squared_error(y_second2, pred2)) \n    rmse_val3.append(error2) \n    print('RMSE value for k= ' , K , 'is:', error2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We still see K neihbours 4-6 being the best predictors, however adding the features actually created a larger mistake"},{"metadata":{},"cell_type":"markdown","source":"# The end for now.. Next steps would be adding more features and checking RMSE. Also run additional regression models to create a better prediction."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}