{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# Last updated: Sat, February 20, 2021 - 15:41\n\n############################################################\n# Reference: \n# https://www.kaggle.com/dansbecker/basic-data-exploration\n# https://www.youtube.com/watch?v=T64Pjykib9M\n############################################################\n\nStep 1: Importing the module\n=====\nimport pandas as pd\n# as pd is optional, to make it more easier to be called\n\nStep 2: Setting up the csv and to retrieve the data\n=====\n# save filepath to variable for easier access\nfishFilePath = '../input/fishData.csv'\n\n# read the data and store data in DataFrame titled fish_data\nfish_data = pd.read_csv(fishFilePath) \n\n# print a summary of the data in Fish data\nfish_data.describe()\n\nSteps to get the information of the dataset\n=====\n# Identifying the rows and columns of the csv\nfish_data.shape\n>>> (1000, 5) # 1000 rows of data (observations) and 5 columns (variables)\n\n# Getting the name of the column attributes\nfish_data.columns\n>>> Index(['Tastiness', 'Size', 'Type', 'Age', 'Color'])\n\n# Getting the first few rows of the dataframes\nfish_data.head()\n\n# Checking if there is any missing data in the dataframes\nfish_data.isnull().sum()\n\n\"\"\"\nTastiness\t0\nSize\t\t1\nType\t\t0\nAge\t\t\t4\nColor\t\t2\n>>> The value right beside it means how many data are missing for that particular column\n\"\"\"\n\n# Getting the summary statistics for the dataframe\nfish_data.describe()\n>>> Summary for count, mean, std, min, 25%, 50%, 75% percentile & max percentile\n\nRECAP\n=====\n1. Pandas is the primary tool we use for exploring and manipulating data, abbreviated in code as `pd`\n2. DataFrames hold the type of data we think of as a table\n3. `dataVar = ps.read_csv()` loads the data\n4. `dataVar.shape` lets us see the column and rows of the data in the csv file\n5. `dataVar.describe()` creates a statistics summary for the dataset","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Using Pandas to Get Familiar With Your Data\n\nThe first step in any machine learning project is familiarize yourself with the data.  You'll use the Pandas library for this.  Pandas is the primary tool data scientists use for exploring and manipulating data.  Most people abbreviate pandas in their code as `pd`.  We do this with the command"},{"metadata":{"collapsed":true,"trusted":false},"cell_type":"code","source":"import pandas as pd","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The most important part of the Pandas library is the DataFrame.  A DataFrame holds the type of data you might think of as a table. This is similar to a sheet in Excel, or a table in a SQL database. \n\nPandas has powerful methods for most things you'll want to do with this type of data.  \n\nAs an example, we'll look at [data about home prices](https://www.kaggle.com/dansbecker/melbourne-housing-snapshot) in Melbourne, Australia. In the hands-on exercises, you will apply the same processes to a new dataset, which has home prices in Iowa.\n\nThe example (Melbourne) data is at the file path **`../input/melbourne-housing-snapshot/melb_data.csv`**.\n\nWe load and explore the data with the following commands:"},{"metadata":{"collapsed":true,"trusted":false},"cell_type":"code","source":"# save filepath to variable for easier access\nmelbourne_file_path = '../input/melbourne-housing-snapshot/melb_data.csv'\n# read the data and store data in DataFrame titled melbourne_data\nmelbourne_data = pd.read_csv(melbourne_file_path) \n# print a summary of the data in Melbourne data\nmelbourne_data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Interpreting Data Description\nThe results show 8 numbers for each column in your original dataset. The first number, the **count**,  shows how many rows have non-missing values.  \n\nMissing values arise for many reasons. For example, the size of the 2nd bedroom wouldn't be collected when surveying a 1 bedroom house. We'll come back to the topic of missing data.\n\nThe second value is the **mean**, which is the average.  Under that, **std** is the standard deviation, which measures how numerically spread out the values are.\n\nTo interpret the **min**, **25%**, **50%**, **75%** and **max** values, imagine sorting each column from lowest to highest value.  The first (smallest) value is the min.  If you go a quarter way through the list, you'll find a number that is bigger than 25% of the values and smaller than 75% of the values.  That is the **25%** value (pronounced \"25th percentile\").  The 50th and 75th percentiles are defined analogously, and the **max** is the largest number.\n\n\n# Your Turn\nGet started with your **[first coding exercise](https://www.kaggle.com/kernels/fork/1258954)**"},{"metadata":{},"cell_type":"markdown","source":"---\n\n\n\n\n*Have questions or comments? Visit the [Learn Discussion forum](https://www.kaggle.com/learn-forum/161285) to chat with other Learners.*"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}