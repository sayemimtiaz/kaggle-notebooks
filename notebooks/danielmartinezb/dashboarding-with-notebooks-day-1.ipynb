{"cells":[{"metadata":{"_uuid":"3c3f233b68d88c237bd452ce0105f4a401a9874a"},"cell_type":"markdown","source":"Welcome to the first day of Dashboarding with scheduled notebooks. Today we're going to do two things:\n\n* Pick a dataset to work with\n* Figure out what data we should include in our dashboard\n\nToday's timeline: \n\n* **5 minutes:** Read notebook\n* **5 minutes:** Pick dataset and read over the documentation, determining what the most important information should be\n* **5 minutes:** Start kernel and read in data\n* **5 minutes:** Create one or more visualizations (no need to worry about pretty; quick and dirty will work!)\n\n# Picking a dataset\n\nNot every dataset needs to be dashboarded. Dashboards are useful because they make it easy to monitor things that change over time, which means it only makes sense to use datasets that are updated; there's usually no reason to go to all the trouble of building a dashboard for a static dataset when a plain notebook or markdown document will do just as well. \n\nThe method we're going to be using--scheduling our notebooks rather than continuously updating them--works best for datasets that are batch processed. \n\n> **Batch data processing** refers to data processing that happens at a single point in time, usually by running a script. It's opposed to **streaming data processing** which happens continuously. \n\nI've put together a list of Kaggle datasets that are batch processed and updated daily for you here. It’s mostly public data that’s provided by cities in the US, but Kaggle’s own public data, Meta Kaggle, is also updated daily. Pick one that you like and create a new Kernel using it as a data source. \n\n* [Meta Kaggle](https://www.kaggle.com/kaggle/meta-kaggle)\n* [Procurement Notices](https://www.kaggle.com/theworldbank/procurement-notices)\n* [Chicago Red Light and Speed Camera Data](https://www.kaggle.com/chicago/chicago-red-light-and-speed-camera-data)\n* [Chicago 311 Service Requests](https://www.kaggle.com/chicago/chicago-311-service-requests)\n* [Seattle Road Weather Information Stations](https://www.kaggle.com/city-of-seattle/seattle-road-weather-information-stations)\n* [Seattle Use of Force](https://www.kaggle.com/city-of-seattle/seattle-use-of-force) (There's currently a problem with our mirror of this dataset. You can also access the data [here](https://www.seattle.gov/police/information-and-data/use-of-force-data).)\n* [Seattle Crisis Data](https://www.kaggle.com/city-of-seattle/seattle-crisis-data)\n* [Los Angeles Parking Citations](https://www.kaggle.com/cityofLA/los-angeles-parking-citations)\n* [What's Happening LA Calendar Dataset](https://www.kaggle.com/cityofLA/what's-happening-la-calendar-dataset)\n* [Oakland Call Center & Public Work Service Requests](https://www.kaggle.com/cityofoakland/oakland-call-center-public-work-service-requests)\n* [NY Bus Breakdown and Delays](https://www.kaggle.com/new-york-city/ny-bus-breakdown-and-delays)\n* [NYPD Motor Vehicle Collisions](https://www.kaggle.com/new-york-city/nypd-motor-vehicle-collisions)\n* [NY Daily Inmates In Custody](https://www.kaggle.com/new-york-city/ny-daily-inmates-in-custody)\n* [NYS Turnstile Usage Data](https://www.kaggle.com/new-york-state/nys-turnstile-usage-data)\n* [NOAA Global Surface Summary of the Day](https://www.kaggle.com/noaa/noaa-global-surface-summary-of-the-day/)\n* [SF Fire Data (Incidents, Violations, and more)](https://www.kaggle.com/san-francisco/sf-fire-data-incidents-violations-and-more)\n* [SF Restaurant Scores - LIVES Standard](https://www.kaggle.com/san-francisco/sf-restaurant-scores-lives-standard)\n\n# Figure out what data should be dashboarded\n\nBecause we're picking public datasets rather than working from one we've been given by our co-workers, we unfortunately can't use the most effective technique to figure out what information to include: asking whoever gave you the data. \n\n> The easiest way to figure out what to include in a dashboard is to ask stakeholders (other people that care about what's in your data and you would want to use the dashboard) what they'd consider the most important information.\n\nFailing that, there are some general guidelines you can use to figure out what information to include in a dashboard. \n\n* *What information is changing relatively quickly (every day or hour)?* Information that only changes every quarter or year probably belong in a report, not a dashboard. \n* *What information is the most important to your mission?* If you're a company, things like money or users are probably going to be pretty important, but if you're a school district you probably care more about things like attendance or grades.\n* *What will affect the choices you or others will need to make?* Are you running A/B tests and need to choose which model to keep in production based on them? Then it's probably important that you track your metrics and other things that might affect those metrics, like sales that are running at the same time. Is there some outside factor that might affect your business, like the weather forecast next week? Then it might make sense to pull in another dataset and show that as well.\n* *What changes have you made?* If you're tuning parameters or adjusting teaching schedules, you want to track the fact that you've made those changes and also how they've affected outcomes.\n\n# Your turn!\n\nPick a dataset that's updated daily by Kaggle from this list. Imagine you work for the organization that produced it and identify factors in the dataset that might represent:\n\n* The goals of your organization (like users or measures of pollution)\n* Things that you (or your colleagues) can change to affect those goals (like advertising spending or the number of factory inspections)\n* Thing you can't change but that will affect the outcome (like the school year, or weather conditions)\n\nYou might not find all three in the same dataset, but you should be able to pinpoint at least one. I'd recommend using the summary statistics in the Data tab of the dataset or reading the documentation in the Overview tab to help identify them.\n\nThen start a kernel on that dataset ([this video has a quick walk-through if you need a quick refresher on how to do this](https://youtu.be/fvF2H85ko9c)) and put together two quick visualizations or summary tables that show two of the factors you've identified in the first step.\n\nIf you like, you can make your kernel public and share a link to it in the comments on this dataset to share with other participants. (And you can take a peek at other people's work to see what they've chosen to look at!) I'll pick a couple that I especially like to highlight as examples. :)"},{"metadata":{"_uuid":"b56b18ae98f8b6dfb991f0aab7f20a7aaa7ffc17"},"cell_type":"markdown","source":"# Plots\n* Monthly Number of Incidents\n* Number of Incidents of top 10 locations\n* Top 10 violated codes\n* Monthly Fine amount"},{"metadata":{"trusted":true,"_uuid":"4fdd5c85633543cb31330b2dc894cff9c387bde3"},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sbn\n\ndf = pd.read_csv('../input/parking-citations.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"65b7fc56201eea32675e1c8d7b67cff5bf36e45c"},"cell_type":"code","source":"#Issue Date to datetime\ndf['Issue Date'] = df['Issue Date'].apply(lambda x: str(x).split('T')[0])\ndf['Issue Date'] = pd.to_datetime(df['Issue Date'], infer_datetime_format=True)\ndf.set_index(df[\"Issue Date\"],inplace=True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"50091e2cadb403aedcad471b8434670e303724ee"},"cell_type":"code","source":"#Monthly Number of Incidents\nfig = plt.figure()\nax = fig.add_subplot(1,1,1)\nsbn.lineplot(data=df['Ticket number'].resample('M').count().truncate(before='2014'), ax=ax)\nax.set(title='Monthly Number of Incidents', xlabel='Time', ylabel='NO. of Incidents')\nplt.show()\nplt.rcParams['figure.figsize'] = 15,5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"898abbbd4695cbdfbfb6cccb8e012ab7138df132"},"cell_type":"code","source":"#group by Location\ndf_group = (df.groupby('Location', as_index=True)).agg({'Ticket number':'count'}).rename(columns={'Ticket number': 'Incidents Size'})\n#select top 10 location based on incidents\ndf_group = df_group.sort_values(by='Incidents Size', ascending=False).iloc[0:10, :]\ndf_group.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5ba40670c1b9e39d98fae7a14bc86db09e0f09fe"},"cell_type":"code","source":"#Number of Incidents of top 10 locations\nfig = plt.figure()\nax = fig.add_subplot(1,1,1)\nsbn.barplot(x=df_group.index, y=df_group['Incidents Size'], ax=ax)\nax.set(title='Incidents by Location', xlabel='Location', ylabel='NO. of Incidents')\nplt.show()\nplt.rcParams['figure.figsize'] = 28,5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bd57079057bec3b0573bc9ced7f880d9a8b36a66"},"cell_type":"code","source":"#group by Violation code\ndf_group = (df.groupby('Violation code', as_index=True)).agg({'Ticket number':'count'}).rename(columns={'Ticket number': 'Incidents Size'})\n#select top 10 location based on incidents\ndf_group = df_group.sort_values(by='Incidents Size', ascending=False).iloc[0:10, :]\ndf_group.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"76be28c421c5a98bdaf0274f1baeef96e303f726"},"cell_type":"code","source":"#Top 10 violation codes\nfig = plt.figure()\nax = fig.add_subplot(1,1,1)\nsbn.barplot(x=df_group.index, y=df_group['Incidents Size'], ax=ax)\nax.set(title='Incidents by Violation Code', xlabel='Violation Code', ylabel='NO. of Incidents')\nplt.show()\nplt.rcParams['figure.figsize'] = 23,8","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bc154a4a5717732cb138241b1163981a09eb9fd6"},"cell_type":"code","source":"#Monthly Amount Collected\nfig = plt.figure()\nax = fig.add_subplot(1,1,1)\nsbn.lineplot(data=df['Fine amount'].resample('M').sum().truncate(before='2014'), ax=ax)\nax.set(title='Monthly Fine Amount', xlabel='Time', ylabel='Fine Amount')\nplt.show()\nplt.rcParams['figure.figsize'] = 15,5","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}