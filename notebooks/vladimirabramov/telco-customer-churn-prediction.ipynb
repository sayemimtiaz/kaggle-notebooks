{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport eli5\nfrom eli5.sklearn import PermutationImportance\n\nimport numpy as np\nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom IPython.display import set_matplotlib_formats\nset_matplotlib_formats('retina')\nimport seaborn as sns\nsns.set(palette='viridis_r',context='notebook',\n        font='ubuntu', style='white')\n\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV, train_test_split, StratifiedKFold\nfrom sklearn.ensemble import StackingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import plot_precision_recall_curve\nfrom sklearn.metrics import plot_roc_curve\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import f1_score\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import MinMaxScaler\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv').\\\ndrop(['customerID'], axis=1)\ntrain.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## A Brief Exploratory Analysis\n-----------","metadata":{}},{"cell_type":"code","source":"train.info()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for column in train.drop(['tenure','MonthlyCharges','TotalCharges'], axis=1).columns:\n    print(column,'-',train[column].unique())","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.describe(include='object').T","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.TotalCharges = train.TotalCharges.apply(pd.to_numeric, errors='coerce')\ntrain.TotalCharges = train.TotalCharges.fillna(train.TotalCharges.median())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(2,6))\nsns.countplot(x=train.Churn, edgecolor='darkgray', \n              alpha=.95)\nsns.despine()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.TotalCharges = train.TotalCharges.apply(pd.to_numeric, errors='coerce')\ntrain.TotalCharges = train.TotalCharges.fillna(train.TotalCharges.median())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.pairplot(train, hue='Churn', markers='x')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(ncols=3, figsize=(8,3))\n\nsample = train[['tenure','MonthlyCharges','TotalCharges']]\n\nfor ax, column in zip(axes.ravel(),sample):\n    sns.boxplot(x=train.Churn,\n          y=sample[column], ax=ax)\nsns.despine()\nplt.tight_layout()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Non-surprisingly, **churned have a lower median tenure than a non-churned**. But they are much higher in terms of MontlyCharges and spend lesser money in total.\n\nSo, there could be some insights from tenure & monthly charges.","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\nmelted = pd.melt(train, id_vars=['Churn'], value_vars = ['gender', 'SeniorCitizen',\n        'Contract','PhoneService','MultipleLines','TechSupport'])\nmelted = melted.sort_values(['value','variable']).rename(\n                            columns={'variable':'var.'})\n\ng = sns.FacetGrid(melted, col='Churn', row='var.', aspect=1.15,\n                  hue = 'Churn',sharex=False)\ng.map(sns.countplot, 'value')\n\ng.set_xticklabels(rotation=25)\nplt.tight_layout()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It also looks like that those who have no internet service on Tech Support are at the group of risk.\n\nType of contact could also have a significant meaning to Churn. It is interesting to look at Month-to-Month Contracts closely.","metadata":{}},{"cell_type":"markdown","source":"## Preprocessing the Data\n---\n\nI would take a transition from categorical values to scaled features by using some steps to further prediction\n\n1. Scaling of non-bool values like `tenure`,`TotalCharges`,`Monthly Charges` with a help of `MinMaxScaler`\n2. Encode categorical values with $>2$ choices and redistribute them as a new binary feature (with `OneHotEncoder`).\n3. Transform categorical values with binary choice to `[0,1]` view","metadata":{}},{"cell_type":"code","source":"train2 = train.copy()\n\nlec = LabelEncoder()\n\ntrain2.loc[:,'gender':'Dependents']=train2.loc[:,'gender':'Dependents'].transform(lec.fit_transform)\ntrain2.loc[:,'PhoneService':'PaymentMethod']=train2.loc[:,'PhoneService':'PaymentMethod'].\\\ntransform(lec.fit_transform)\ntrain2['Churn'] = lec.fit_transform(train2['Churn'])\n\nmms = MinMaxScaler()\ntrain2[['tenure','MonthlyCharges','TotalCharges']] =\\\nmms.fit_transform(train2[['tenure','MonthlyCharges','TotalCharges']])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = train2.loc[:,'gender':'TotalCharges']\ntarget = train2['Churn']\n\nfig = plt.figure(figsize=(24,12))\nax = sns.heatmap(train2.corr(), cmap='viridis_r',\n      linecolor='black', lw=.65,annot=True, alpha=.95)\nax.set_xticklabels([x[:7] for x in train2.columns])\nax.set_yticklabels([y[:7] for y in train2.columns])\n\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The dataset is imbalanced. That is why I wouldn't use ROC AUC score as a primary metric (but for some reasons, I will caluclate it as an additional one).\n\nFor this task of churn classification **accuracy score** is used.","metadata":{}},{"cell_type":"markdown","source":"## Model Selection & Prediction\n---------","metadata":{}},{"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(\n    features, target,test_size=.2,random_state=42)\n\ngbc = GradientBoostingClassifier(random_state=42)\nrfc = RandomForestClassifier(random_state=42,min_samples_leaf=30)\nsvc = SVC(random_state=42,degree=3)\nlgc = LogisticRegression(random_state=42)\nknn = KNeighborsClassifier(n_jobs=5)\n\nestimators = [('Random Forest Classifier',rfc),\n              ('Support Vector Machines',svc),\n              ('Logistic Regression',lgc), \n              ('Gradient Boosting Classifier',gbc),\n              ('KNN Classifier',knn)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def confusion_plot(label, y_valid, y_pred, ax=None):\n    \n    co_ma = confusion_matrix(y_valid, y_pred)\n    groups = ['True Neg','False Pos','False Neg','True Pos']\n    counts = [int(value) for value in co_ma.flatten()]\n    shares = ['{0:.2%}'.format(value) for value in\n             co_ma.flatten()/np.sum(co_ma)]\n    labels = [f'{v1}\\n{v2}\\n{v3}' for v1, v2, v3 in\n              zip(groups,counts,shares)]\n    labels = np.asarray(labels).reshape(2,2)\n    sns.heatmap(co_ma,annot=labels,cmap='binary', alpha=.55, ax=ax,\n             cbar=True, fmt='', linewidth=1,linecolor='black')\n    plt.axis('off')\n    plt.title(f'Confusion Matrix for {label}')\n\n                                            \ndef show_metrics(metrics):\n    try:return pd.DataFrame(metrics)\n    except:return pd.DataFrame([metrics])","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metrics = []\n\nfor est in estimators:\n    \n    fig, axes = plt.subplots(ncols=3, figsize=(15,4))\n   \n    mod = est[1].fit(X_train, y_train)\n    y_pred = mod.predict(X_valid)\n    plot_precision_recall_curve(mod, X_valid, y_valid, \n                    y_pred, ax=axes[0], color='black')\n    plot_roc_curve(mod, X_valid, y_valid,ax = axes[1], color='black')\n\n    axes[0].set_title(f'Precision-Recall Curve for {est[0]}')\n    axes[1].set_title(f'ROC Curve for {est[0]}')\n    axes[1].plot([1,0],[1,0], c='green',ls='--')\n    confusion_plot(est[0],y_valid, y_pred, axes[2])\n    for ax in axes.ravel():\n        ax.legend(frameon=False)\n        \n    scores = {}\n    scores['classifier'] = est[0]\n    scores['accuracy_score'] = accuracy_score(y_valid, y_pred)\n    scores['roc_auc_score']=roc_auc_score(y_valid, y_pred)\n    scores['f1_score'] = f1_score(y_valid,y_pred)\n\n    plt.tight_layout()\n    metrics.append(scores)\n\nshow_metrics(metrics)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params={'colsample_bytree': 0.6, 'gamma': 5, 'max_depth': 3, 'min_child_weight': 5.0, 'subsample': 1.0}\n\n\nxgb = XGBClassifier(random_state=42,\n                    **params,cv=5, verbosity=0)\n\nstacked_metrics={}\n\nreg = StackingClassifier(estimators=estimators,\n    final_estimator=xgb)\ncls_name = 'Stacking Classifier'\n\nregmodel = reg.fit(X_train, y_train)\ny_pred = reg.predict(X_valid)\n\nfig, axes = plt.subplots(ncols=3, figsize=(14,4))\n\nplot_precision_recall_curve(regmodel,X_valid,y_valid, \n            y_pred, color='black', ax=axes[0])\nplot_roc_curve(regmodel,X_valid,y_valid, \n               color='black', ax=axes[1])\n\naxes[0].set_title(f'Precision-Recall Curve for {cls_name}')\naxes[1].plot([1,0],[1,0], c='green',ls='--')\naxes[1].set_title(f'ROC Curve for {cls_name}')\nconfusion_plot(cls_name,y_valid, y_pred, axes[2])\nfor ax in axes:\n    ax.legend(frameon=False)\n\nstacked_metrics['classifier'] = cls_name\nstacked_metrics['accuracy_score'] = accuracy_score(y_valid, y_pred)\nstacked_metrics['ROC AUC score'] = roc_auc_score(y_valid, y_pred)\nstacked_metrics['f1_score'] = f1_score(y_valid, y_pred)\n    \nplt.tight_layout()\n\npd.DataFrame([stacked_metrics])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" <sub>1: these parameters for XGBoost Classifier were got after a GridSearch</sub>","metadata":{}},{"cell_type":"code","source":"perm = PermutationImportance(regmodel,random_state=17).fit(X_valid,y_valid)\neli5.show_weights(perm, feature_names=X_valid.columns.values)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"$\\implies$ A stacked model has accuracy score of $0.811923$... after a grid search and can be used for predictions.","metadata":{}}]}