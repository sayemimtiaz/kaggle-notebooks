{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction"},{"metadata":{},"cell_type":"markdown","source":"Predicting customer churn is a common and valuable application of data science. This activity focuses on understanding which customers are likely to leave a company. By understanding which customers will churn, and perhaps when or why they might churn, companies can proactively manage these customers and attempt to increase retention. This dataset was provided from the public datasets available on Kaggle."},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys # access to system parameters\nprint(\"Python version: {}\". format(sys.version))\n\nimport pandas as pd # functions for data processing and analysis modeled after R dataframes with SQL like features\nimport pandas_profiling\nprint(\"pandas version: {}\". format(pd.__version__))\n\nimport numpy as np # foundational package for scientific computing\nprint(\"NumPy version: {}\". format(np.__version__))\n\nimport scipy as sp # collection of functions for scientific computing and advance mathematics\nprint(\"SciPy version: {}\". format(sp.__version__)) \nimport scipy.stats as ss\n\nimport sklearn # collection of machine learning algorithms\nprint(\"scikit-learn version: {}\". format(sklearn.__version__))\n\n\n#misc libraries\nimport random\nimport time\nimport datetime\nimport os\nimport glob\nimport math\n\n\n# Visualisation\nimport matplotlib #collection of functions for scientific and publication-ready visualization\n%matplotlib inline\nimport matplotlib.pyplot as plt\npd.plotting.register_matplotlib_converters()\nprint(\"matplotlib version: {}\". format(matplotlib.__version__))\nimport plotly\nprint(\"plotly version: {}\". format(plotly.__version__))\nimport plotly.graph_objects as go\nfrom plotly.offline import init_notebook_mode, iplot # Offline mode\ninit_notebook_mode(connected=True)\nimport seaborn as sns\nfrom xgboost import plot_importance\n\n\n# Import common MLA libraries\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\nfrom xgboost import XGBClassifier\n\n\n#Common Model Helpers\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn import feature_selection, model_selection, metrics\nfrom sklearn.model_selection import train_test_split, cross_validate, StratifiedKFold, GridSearchCV\nfrom sklearn.metrics import mean_absolute_error, roc_curve, auc, confusion_matrix, plot_confusion_matrix, accuracy_score\n\n\n\n# Default Global settings\npd.set_option('max_columns', None)\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nprint(\"Setup Successful\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Import the data\ndata = pd.read_csv(\"../input/telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Copy the data so it doesn't have to be reloaded in each time\ndf = data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## View the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# View the pandas profiling report to understand the variables better\n#pandas_profiling.ProfileReport(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Wrangling"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check for nulls\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check for errors or bad data\ndf.sample(50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop ID as its not valuable to the model\ndf.drop(columns=[\"customerID\"], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# View the data types\ndf.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Gather a list of the column names\ndf.columns.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print out all unique values for each variable\nfor col in df.columns:\n    print(col, \":\", df[col].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Change columns to correct data types\ncol_int = [] # create a list of column names to convert to integer\ncol_float = ['TotalCharges'] # create a list of column names to convert to float\ncol_string = [] # create a list of column names to convert to string\ncol_ordinal = [] # create a list of column names to convert to ordinal\ncol_nominal = ['gender',\n 'SeniorCitizen',\n 'Partner',\n 'Dependents',\n 'PhoneService',\n 'MultipleLines',\n 'InternetService',\n 'OnlineSecurity',\n 'OnlineBackup',\n 'DeviceProtection',\n 'TechSupport',\n 'StreamingTV',\n 'StreamingMovies',\n 'Contract',\n 'PaperlessBilling',\n 'PaymentMethod'] # create a list of column names to convert to nominal\ncol_numeric = ['TotalCharges', 'MonthlyCharges', 'tenure']\ncol_date = [] # create a list of column names to convert to date\n\n\ndef change_dtypes(col_int, col_float, col_string, col_ordinal, col_nominal, col_date, df): \n    '''\n    AIM    -> Changing dtypes to save memory\n    INPUT  -> List of int column names, float column names, df\n    OUTPUT -> updated df with smaller memory  \n    '''\n    df[col_int] = df[col_int].apply(pd.to_numeric)\n    df[col_string] = str(df[col_string])\n    df[col_ordinal] = df[col_ordinal].astype('object')\n    df[col_nominal] = df[col_nominal].astype('object')\n    for col in col_date:\n        df[col] = pd.to_datetime(df[col])\n    \nchange_dtypes(col_int, col_float, col_string, col_ordinal, col_nominal, col_date, df)\ndf['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# save the target variable\ntarget = df[\"Churn\"]\ndf.drop(columns=[\"Churn\"], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploratory Data Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Distribution of the target variable\nsns.countplot(x=target)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Examining numeric correlations with the target variable with the absolute value of pearson R correlation\n\ncorrdata = pd.concat([df,target],axis=1)\ncorr = corrdata.corr()\nsns.heatmap(corr, annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Engineering"},{"metadata":{},"cell_type":"markdown","source":"TBC"},{"metadata":{},"cell_type":"markdown","source":"## Pre-Processing for modelling"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Standardising numeric variables, labelencoding ordinal variabnles, one-hot encoding nominal variables\n# No null values to be imputed\nnumerical_transformer = StandardScaler()\nnominal_transformer = OneHotEncoder(handle_unknown='ignore')\nordinal_transformer = LabelEncoder()\npreprocessor = ColumnTransformer(transformers=[\n        ('num', numerical_transformer, col_numeric),\n        ('ord', ordinal_transformer, col_ordinal),\n        ('nom', nominal_transformer, col_nominal)],\n        remainder='passthrough')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split dataset into train and test\nX_train, X_test, y_train, y_test = train_test_split(df, target)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fit the pipeline on the training set and then transform the training and test set\npreprocessor.fit(X_train)\nX_train = preprocessor.transform(X_train)\nX_train = pd.DataFrame(X_train)\n\nX_test = preprocessor.transform(X_test)\nX_test = pd.DataFrame(X_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.columns.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preprocessor.named_transformers_['nom'].get_feature_names()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col_dict = dict(zip([\n    0,1,2,3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24,\n 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45], \n                    ['tenure', 'MonthlyCharges','TotalCharges','gender_Female', 'gender_Male', 'SeniorCitizen_0', 'SeniorCitizen_1', 'Partner_No', 'Partner_Yes', 'Dependents_No',\n       'Dependents_Yes', 'PhoneService_No', 'PhoneService_Yes', 'MultipleLines_No', 'MultipleLines_No phone service',\n       'MultipleLines_Yes', 'InternetService_DSL', 'InternetService_Fiber optic', 'InternetService_No', 'OnlineSecurity_No',\n       'OnlineSecurity_No internet service', 'OnlineSecurity_Yes', 'OnlineBackup_No',\n       'OnlineBackup_No internet service', 'OnlineBackup_Yes', 'DeviceProtection_No',\n       'DeviceProtection_No internet service', 'DeviceProtection_Yes', 'TechSupport_No',\n       'TechSupport_No internet service', 'TechSupport_Yes', 'StreamingTV_No',\n       'StreamingTV_No internet service', 'StreamingTV_Yes', 'StreamingMovies_No',\n       'StreamingMovies_No internet service', 'StreamingMovies_Yes', 'Contract_Month-to-month',\n       'Contract_One year', 'Contract_Two year', 'PaperlessBilling_No', 'PaperlessBilling_Yes',\n       'PaymentMethod_Bank transfer (automatic)', 'PaymentMethod_Credit card (automatic)',\n       'PaymentMethod_Electronic check', 'PaymentMethod_Mailed check'])\n               )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = X_train.rename(columns=col_dict)\nX_test = X_test.rename(columns=col_dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Encode the y variable\nle = LabelEncoder()\nle.fit(y_train)\ny_train = le.transform(y_train)\ny_train = pd.DataFrame(y_train)\n\ny_test = le.transform(y_test)\ny_test = pd.DataFrame(y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Handle NAs\nX_train = X_train.fillna(0)\nX_test = X_test.fillna(0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Machine Learning Modelling"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create objects of classification algorithms\n\nMLA = [\n    #Ensemble Methods\n    ensemble.AdaBoostClassifier(random_state = 10),\n    ensemble.BaggingClassifier(random_state = 10),\n    ensemble.ExtraTreesClassifier(random_state = 10),\n    ensemble.GradientBoostingClassifier(random_state = 10),\n    ensemble.RandomForestClassifier(random_state = 10),\n\n    #Gaussian Processes\n    gaussian_process.GaussianProcessClassifier(random_state = 10),\n    \n    #GLM\n    linear_model.LogisticRegressionCV(random_state = 10),\n    linear_model.PassiveAggressiveClassifier(random_state = 10),\n    linear_model.RidgeClassifierCV(),\n    linear_model.SGDClassifier(random_state = 10),\n    linear_model.Perceptron(random_state = 10),\n    \n    #Navies Bayes\n    naive_bayes.BernoulliNB(),\n    naive_bayes.GaussianNB(),\n    \n    #Nearest Neighbor\n    neighbors.KNeighborsClassifier(),\n    \n    #SVM\n    svm.SVC(probability=True, random_state = 10),\n    svm.NuSVC(probability=True, random_state = 10),\n    svm.LinearSVC(random_state = 10),\n    \n    #Trees    \n    tree.DecisionTreeClassifier(random_state = 10),\n    tree.ExtraTreeClassifier(random_state = 10),\n    \n    #Discriminant Analysis\n    discriminant_analysis.LinearDiscriminantAnalysis(),\n    discriminant_analysis.QuadraticDiscriminantAnalysis(),\n\n    \n    #xgboost\n    XGBClassifier(random_state = 10)    \n    ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a dataframe for the model results\nresult_table = pd.DataFrame(columns=[\"MLA\", \"train_score\", \"test_score\"])\n\nrow_index = 0\n\n# Score each algorithm and add its training and test results to result_table\nfor alg in MLA:\n    alg.fit(X_train, y_train)\n    y_train_pred = alg.predict(X_train)\n    y_pred = alg.predict(X_test)\n    result_table.loc[row_index, 'train_score'] = accuracy_score(y_train, y_train_pred)\n    result_table.loc[row_index, 'test_score'] = accuracy_score(y_test, y_pred)\n    result_table.loc[row_index, 'MLA'] = alg\n\n    #result[\"MLA\"] = alg\n    #result_table.append(row, ignore_index = True)\n    \n    row_index+=1\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display the results table, sorted in descending order\nresult_table = result_table.sort_values(by=\"test_score\", ascending=False)\nresult_table","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cross validate the best performing algorithm - Ridge Classifier performed the best (with random_state = 10) with default paramaters. \n# We will Ridge Classifier this further as it fits quickly, performs well and has high interperability\n\n# Typically I would do cross validation now, however RidgeClassifierCV has built in CV so its not required. I will do it below anyway as good practice.\n\nRC = linear_model.RidgeClassifierCV()\nRC.fit(X_train, y_train)\ncv_results = cross_validate(RC, X_test, y_test, cv=5)\ncv_results['test_score'].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot the confusion matrix as a percentage of the whole\ncf_matrix = confusion_matrix(y_test, y_pred)\nsns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, \n            fmt='.2%', cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In this domain, false-positives and false-negatives are not significantly costly and these error rates would need to be judged whether they are within an acceptable threshold by the business decision makers."},{"metadata":{"trusted":true},"cell_type":"code","source":"# To help the business focus its activities, visualise the variable coefficients to understand the drivers of churn\ncols = X_train.columns.tolist()\ncoefs = RC.coef_\ncoefs = coefs[0].tolist()\n#coef_dict = dict(zip([cols, coefs]))\ncoefdf = pd.DataFrame(coefs)\ncoefdf = coefdf.rename(columns={0:'coefficient'})\ncoefdf[\"variable\"] = cols\ncoefdf = coefdf.sort_values(\"coefficient\", ascending=False)\n\n\n\nfig, ax = plt.subplots(figsize=(20, 5))\ncoefdf.plot(x=\"variable\", y=\"coefficient\", kind='bar', \n             ax=ax, legend=False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Conclusion"},{"metadata":{},"cell_type":"markdown","source":"This model can predict whether a customer will churn with 80.92% accuracy.\n\n\nNext steps would be:\n* Feature Engineering\n* Optimise the algorithm's paramaters\n* Check the fit and predict time of the models, although Ridge Regression is usually quite fast\n* Investigate possible model discrimination through the use of personal data (e.g. Gender) \n* Clean up pipeline, remove not useful variables, remove unused algorithsm ,remove cross validation steps, prepare for production"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}