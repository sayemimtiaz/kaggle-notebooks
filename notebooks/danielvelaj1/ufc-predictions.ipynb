{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Blue vs Red prediction across time V1\n "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#set pandas so that it doesnt sumarize print outputs hiding with \"...\" in the middle\npd.set_option(\"display.max_rows\", None, \"display.max_columns\", None) \n# import dataset \ndf=pd.read_csv('../input/ufcdata/data.csv')\npd.set_option('display.max_columns', None)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"df.info(verbose=True, null_counts=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# General Preprocessing and Cleaning\n1. We will get rid of features that are not usefull for the model such as the fighter names ('It is allways Red and Blue'), the location of the fight and the referee\n2. Change date to datetime object for chronological sorting"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(columns=['Referee','R_fighter','B_fighter']);\ndf['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d');\n\n#Drop fights where result is \"Draw\" instead of 'Red' or 'Blue'\ndf=df.loc[df[\"Winner\"].isin(['Blue','Red'])]\n\n#Encode Red=1,Blue=0 and drop names\ndf['Winner']=(df['Winner']=='Red').astype(int)\ndf=df.drop(columns=['R_fighter','B_fighter'])\n\n#Encode title bout as int\ndf['title_bout']=df['title_bout'].astype(float)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data split\nSplit before preprocessing to avoid problems with data leakage. The split is done in a chronological order. "},{"metadata":{"trusted":true},"cell_type":"code","source":"def split_chrono(X,frac=0.15,test=True,delta=None):\n    '''This function splits data from X chronologically in training, validation and testing (if test=True).\n    X must contain a datetime column with column name 'date' which will be dropped.\n    '''\n    #Sort X chronologically \n    X.sort_values(by=['date'], axis=0)\n    X=X.drop(columns=['date'])\n    #split data between train, validation and test:\n    valid_size = int(len(df) * frac)\n    \n    if(test):\n        train = X[:-2 * valid_size]\n        valid = X[-2 * valid_size:-valid_size]\n        test = X[-valid_size:]\n    else:\n        train = X[:-valid_size]\n        valid = X[-valid_size:]\n        \n    return train,valid,test\n  \n        \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_valid,X_test=split_chrono(df,frac=0.2,test=True)\n  \n#Separate targets from variables\ny_train=X_train['Winner']\nX_train=X_train.drop(columns=['Winner'])\n    \n    \ny_valid=X_valid['Winner']\nX_valid=X_valid.drop(columns=['Winner'])\n    \n    \ny_test=X_test['Winner']\nX_test=X_test.drop(columns=['Winner'])\n\n#for cross validation fold metrics\nfrac=0.2\nvalid_size = int(len(df) * frac)\nX=df[:-valid_size].drop(columns=['Winner'])\nY=df[:-valid_size]['Winner']\n\nprint('training:\\n',y_train.value_counts())\nprint('validation:\\n',y_valid.value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Pipeline\n1. Imputing numerical values with mean.\n2. Imputing B_Stance and R_Stance with mode.\n3. Scaling all numerical values with Simple Scaler\n4. Apply label encoder to "},{"metadata":{"trusted":true},"cell_type":"code","source":"#LABEL ENCODER PROBLEM\nclass LabelEncoderExt(object):\n    def __init__(self):\n        \"\"\"\n        It differs from LabelEncoder by handling new classes and providing a value for it [Unknown]\n        Unknown will be added in fit and transform will take care of new item. It gives unknown class id\n        \"\"\"\n        self.label_encoder = LabelEncoder()\n        # self.classes_ = self.label_encoder.classes_\n\n    def fit(self, data_list):\n        \"\"\"\n        This will fit the encoder for all the unique values and introduce unknown value\n        :param data_list: A list of string\n        :return: self\n        \"\"\"\n        self.label_encoder = self.label_encoder.fit(list(data_list) + ['Unknown'])\n        self.classes_ = self.label_encoder.classes_\n\n        return self\n\n    def transform(self, data_list):\n        \"\"\"\n        This will transform the data_list to id list where the new values get assigned to Unknown class\n        :param data_list:\n        :return:\n        \"\"\"\n        new_data_list = list(data_list)\n        for unique_item in np.unique(data_list):\n            if unique_item not in self.label_encoder.classes_:\n                new_data_list = ['Unknown' if x==unique_item else x for x in new_data_list]\n\n        return self.label_encoder.transform(new_data_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#determine numerical and categorical columns\ncat_cols=[col for col in X_train.columns if X_train[col].dtype=='object']\nshared_cat_cols=[col for col in cat_cols if ((set(X_train[col]))==set(X_valid[col])\n                                          and (set(X_train)==set(X_test)))] #shared amongst training,validation and test set\n\n\nnum_cols=[col for col in X_train.columns if X_train[col].dtype in ['int64','float64']]\nprint ('categorical columns:', cat_cols,'\\n\\n')\nprint ('shared categorical columns:', shared_cat_cols,'\\n\\n')\n\nprint('numerical columns:', num_cols)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#There are no shared categorical columns, drop them to avoid problems with encoder, I'll see how to fix this. \nX_train=X_train.drop(columns=cat_cols)\nX_test=X_test.drop(columns=cat_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nnumerical_transformer=Pipeline(steps=[\n    ('mean_imputer',SimpleImputer(strategy='mean')),\n    ('standard_scaler',StandardScaler())\n])\n\ncategorical_transformer=Pipeline(steps=[\n    ('mode_imputer',SimpleImputer(strategy='most_frequent')),\n    ('label_encoder',LabelEncoderExt())\n])\n\npreprocessor=ColumnTransformer([\n    ('num_preprocessing',numerical_transformer,num_cols),\n #   ('cat_preprocessing',categorical_transformer,cat_cols)\n    \n])\n\nXGB_pipe=Pipeline(steps=[\n    ('preprocessing',preprocessor),\n    ('model',XGBClassifier())\n    \n])\n\nRF_pipe=Pipeline(steps=[\n    ('preprocessing',preprocessor),\n    ('model',RandomForestClassifier(max_depth=15))])\n    \nLR_pipe=Pipeline(steps=[\n    ('preprocessing',preprocessor),\n    ('model',LogisticRegression())])\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training and evaluating models\n"},{"metadata":{},"cell_type":"markdown","source":"## 1. XGB"},{"metadata":{"trusted":true},"cell_type":"code","source":"XGB_pipe.fit(X_train,y_train)\npred = model_pipe.predict(X_valid)\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_valid,pred))\nfrom sklearn.model_selection import cross_val_score\n\nscores = cross_val_score(XGB_pipe, X, Y,\n                              cv=5,\n                              scoring='f1')\n\nprint(\"MAE scores:\\n\", scores)\n\nfrom sklearn.metrics import plot_roc_curve;\nfrom sklearn.metrics import plot_confusion_matrix;\nplot_roc_curve(XGB_pipe,X_valid,y_valid);\nplot_confusion_matrix(XGB_pipe,X_valid,y_valid);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"RF_pipe.fit(X_train,y_train)\npred = RF_pipe.predict(X_valid)\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_valid,pred))\nfrom sklearn.model_selection import cross_val_score\n\nscores = cross_val_score(RF_pipe, X, Y,\n                              cv=5,\n                              scoring='f1')\n\nprint(\"MAE scores:\\n\", scores)\n\nfrom sklearn.metrics import plot_roc_curve;\nfrom sklearn.metrics import plot_confusion_matrix;\nplot_roc_curve(RF_pipe,X_valid,y_valid);\nplot_confusion_matrix(RF_pipe,X_valid,y_valid);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"LR_pipe.fit(X_train,y_train)\npred = LR_pipe.predict(X_valid)\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_valid,pred))\nfrom sklearn.model_selection import cross_val_score\n\nscores = cross_val_score(LR_pipe, X, Y,\n                              cv=5,\n                              scoring='f1')\n\nprint(\"MAE scores:\\n\", scores)\n\nfrom sklearn.metrics import plot_roc_curve;\nfrom sklearn.metrics import plot_confusion_matrix;\nplot_roc_curve(LR_pipe,X_valid,y_valid);\nplot_confusion_matrix(LR_pipe,X_valid,y_valid);","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}