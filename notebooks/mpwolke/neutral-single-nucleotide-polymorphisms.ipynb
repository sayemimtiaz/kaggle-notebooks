{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom sklearn import preprocessing\nfrom sklearn.linear_model import LogisticRegression\n\nfrom scipy.stats import norm\nimport scipy.stats as st\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"background-color:#DC143C; font-family:'Brush Script MT',cursive;color:white;font-size:200%; text-align:center;border-radius: 50% 20% / 10% 40%\">Variation Dataset Affecting Protein Tolerance</h1>\n\nReference: Thusberg J, Olatubosun A, Vihinen M. Performance of mutation pathogenicity prediction methods on missense variants. Hum Mutat. 2011, 32(4):358-68.   PUBMED  \n\n**<span style=\"color:#DC143C;\">Dataset of neutral single nucleotide polymorphisms</span>**\n\n\nThis is the neutral dataset or non synonymous coding SNV dataset comprising 23,683 human non synonymous coding SNVs with allele frequency >0.01 and chromosome sample count >49 from the dbSNP database build 131. This dataset was filtered for the disease-associated SNVs. The variant position mapping for this dataset was extracted from dbSNP database.\n\nhttp://structure.bmc.lu.se/VariBench/tolerance_dataset1.php","metadata":{}},{"cell_type":"code","source":"nRowsRead = 1000 # specify 'None' if want to read whole file\ndf = pd.read_csv('../input/cusersmarildownloadsneutralcsv/neutral.csv', delimiter=';', encoding = \"ISO-8859-2\", nrows = nRowsRead)\ndf.dataframeName = 'neutral.csv'\nnRow, nCol = df.shape\nprint(f'There are {nRow} rows and {nCol} columns')\ndf.head()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **<span style=\"color:#DC143C;\">VariBench and ClinVar Datasets</span>**\n\nCitation: Alfredo Iacoangeli, Ahmad Al Khleifat, William Sproviero, Aleksey Shatunov, Ashley R. Jones, Sarah Opie-Martin, Ersilia Naselli, Simon D. Topp, Isabella Fogh, Angela Hodges, Richard J. Dobson, Stephen J. Newhouse & Ammar Al-Chalabi (2019) ALSgeneScanner: a pipeline for the analysis and interpretation of DNA sequencing data of ALS patients, Amyotrophic Lateral Sclerosis and Frontotemporal Degeneration, 20:3-4, 207-215, DOI: 10.1080/21678421.2018.1562553\n\n\n\"To assess their variant prioritization approach, we used a set of non-synonymous variants from the VariBench dataset for which the effect is known and all ALS-associated non-synonymous variants stored in ClinVar (71 benign and 121 pathogenic).\"\n\n\"The VariBench variants are not ALS genes specifically, but because they are all annotated depending on whether or not they are deleterious, the general principles of the method could be tested. The dataset includes VariBench protein tolerance dataset (http://structure.bmc.lu.se/VariBench/tolerance_dataset1.php) comprising 23,683 human non-synonymous coding neutral SNPs and 19,335 pathogenic missense mutations.\"\n\nAbove is the respective (csv file) Variation Affecting Protein Tolerance: Neutral dataset or non synonymous coding SNV dataset. \n\n\"None of the tools used in their pathogenicity score were trained on the VariBench dataset. However, it is possible that some VariBench variants were present in the training datasets. In order to minimize the overlap between training and evaluation sets, the authors derived a subset of variants (VariBenchFiltered) from the VariBench dataset by filtering out its overlap with HumVar, the CADD training dataset and ExoVar, which are commonly used to train the tools. The resulting dataset comprising 5051 pathogenic and 14,077 neutral variants, was balanced by randomly subsampling 5051 neutral variants.\n\nhttps://www.tandfonline.com/action/showCitFormats?doi=10.1080%2F21678421.2018.1562553","metadata":{}},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"_kg_hide-output":true,"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cont_FEATURES = ['ContigPositionStart_0_based', 'ContigPositionEnd_0_based', 'mRNA_start_position_0_based', 'mRNA_end_position_0_based', 'ReadingFrame_base_position_in_codon', 'AminoAcidPosition_0_based']\n\ncat_FEATURES = ['Contig_Acc_version', 'GenomeBuild', 'mRNA_acc_version']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#I didn't list all the the categorical features and the continuous features to plot less charts.\n\n#Besides, I didn't know if the code will perform without returning errors. ","metadata":{}},{"cell_type":"markdown","source":"# **<span style=\"color:#DC143C;\">(Some of the ) Outliers</span>**","metadata":{}},{"cell_type":"code","source":"#Code by Tom C  https://www.kaggle.com/tjcdev/tps-outliers-hidden-features-baseline/notebook\n\ndef plot_outliers(df, feature, threshold=5):\n    mean, std = np.mean(df), np.std(df)\n    z_score = np.abs((df-mean) / std)\n    good = z_score < threshold\n\n    print(f\"Rejection {(~good).sum()} points\")\n    visual_scatter = np.random.normal(size=df.size)\n    plt.scatter(df[good], visual_scatter[good], s=2, label=\"Good\", color=\"#4CAF50\")\n    plt.scatter(df[~good], visual_scatter[~good], s=8, label=\"Bad\", color=\"#F44336\")\n    plt.legend(loc='upper right')\n    plt.title(feature)\n    plt.show();\n    \n    return good\n\ndef plot_lof_outliers(df, feature):\n    lof = LocalOutlierFactor(n_neighbors=20, contamination=0.001, p=1)\n    good = lof.fit_predict(df) > 0.5 # change this value to set the threshold for outliers\n    print(f\"Rejection {(~good).sum()} points\")\n    \n    visual_scatter = np.random.normal(size=df.size)\n    plt.scatter(df[good], visual_scatter[good], s=2, label=\"Good\", color=\"#4CAF50\")\n    plt.scatter(df[~good], visual_scatter[~good], s=8, label=\"Bad\", color=\"#F44336\")\n    plt.legend(loc='upper right')\n    plt.title(feature)\n    plt.show();\n    \n    return good","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" **<span style=\"color:#DC143C;\">Feature Outliers</span>**","metadata":{}},{"cell_type":"code","source":"#Code by Tom C  https://www.kaggle.com/tjcdev/tps-outliers-hidden-features-baseline/notebook\n\nfor feature in cont_FEATURES:\n    print(feature)\n    plot_outliers(df[feature], feature)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code by Tom C  https://www.kaggle.com/tjcdev/tps-outliers-hidden-features-baseline/notebook\n\nfor feature in cont_FEATURES:\n    # There some reshaping done here for syntax sake\n    data = df[~df[feature].isna()][feature]\n    plot_lof_outliers(data.values.reshape(data.shape[0], -1), feature)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code by Tom C  https://www.kaggle.com/tjcdev/tps-outliers-hidden-features-baseline/notebook\n\nfor feature in cont_FEATURES:\n    sns.violinplot(x='ContigPositionStart_0_based', y=feature, data=df, inner='quartile');\n    plt.title(feature)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#It was suppose to be a violin. Maybe Violin Strings from a broken violin.","metadata":{}},{"cell_type":"code","source":"#Code by Tom C  https://www.kaggle.com/tjcdev/tps-outliers-hidden-features-baseline/notebook\n\nfor feature in cat_FEATURES:\n    sns.histplot(df[feature].values)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Messy charts.","metadata":{}},{"cell_type":"code","source":"#Code by Tom C  https://www.kaggle.com/tjcdev/tps-outliers-hidden-features-baseline/notebook\n\ndef plot_cdf(df, feature):\n    ps = 100 * st.norm.cdf(np.linspace(-4, 4, 10)) # The last number in this tuple is the number of percentiles\n    x_p = np.percentile(df, ps)\n\n    xs = np.sort(df)\n    ys = np.linspace(0, 1, len(df))\n\n    plt.plot(xs, ys * 100, label=\"ECDF\")\n    plt.plot(x_p, ps, label=\"Percentiles\", marker=\".\", ms=10)\n    plt.legend()\n    plt.ylabel(\"Percentile\")\n    plt.title(feature)\n    plt.show();\n\nfor feature in cont_FEATURES:\n    plot_cdf(df[feature], feature)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Code by Tom C  https://www.kaggle.com/tjcdev/tps-outliers-hidden-features-baseline/notebook\n# This plots a 16x16 matrix of correlations between all the features and the target\n# Note: I sometimes comment this out because it takes a few minutes to run and doesn't show any useful information.\n\npd.plotting.scatter_matrix(df, figsize=(10, 10));","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10,10)) \nsns.heatmap(df.drop(columns=['AminoAcidPosition_0_based']).corr(), annot=True, cmap='viridis', fmt='0.2f', ax=ax)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code by Puru Behl https://www.kaggle.com/accountstatus/mt-cars-data-analysis\n\nsns.distplot(df['AminoAcidPosition_0_based'])\nplt.axvline(df['AminoAcidPosition_0_based'].values.mean(), color='red', linestyle='dashed', linewidth=1)\nplt.title('AminoAcid Position 0 based Distribution')","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code by Olga Belitskaya https://www.kaggle.com/olgabelitskaya/sequential-data/comments\nfrom IPython.display import display,HTML\nc1,c2,f1,f2,fs1,fs2=\\\n'#eb3434','#eb3446','Akronim','Smokum',30,15\ndef dhtml(string,fontcolor=c1,font=f1,fontsize=fs1):\n    display(HTML(\"\"\"<style>\n    @import 'https://fonts.googleapis.com/css?family=\"\"\"\\\n    +font+\"\"\"&effect=3d-float';</style>\n    <h1 class='font-effect-3d-float' style='font-family:\"\"\"+\\\n    font+\"\"\"; color:\"\"\"+fontcolor+\"\"\"; font-size:\"\"\"+\\\n    str(fontsize)+\"\"\"px;'>%s</h1>\"\"\"%string))\n    \n    \ndhtml('Thank you Tom C @tjcdev  for all the script')","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]}]}