{"cells":[{"metadata":{},"cell_type":"markdown","source":"![](https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcSmsmOyS47IpWRquRvW9jLRAnSwI1OPRs7m5g&usqp=CAU)virkpersonalinjurylawyers.com","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.graph_objs as go\nimport plotly.offline as py\nimport plotly.express as px\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"nRowsRead = 1000 # specify 'None' if want to read whole file\ndf = pd.read_csv('../input/divorce-prediction/divorce_data.csv', delimiter=';', encoding = \"ISO-8859-1\", nrows = nRowsRead)\ndf.dataframeName = 'divorce_data.csv'\nnRow, nCol = df.shape\nprint(f'There are {nRow} rows and {nCol} columns')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"# checking dataset\n\nprint (\"Rows     : \" ,df.shape[0])\nprint (\"Columns  : \" ,df.shape[1])\nprint (\"\\nFeatures : \\n\" ,df.columns.tolist())\nprint (\"\\nMissing values :  \", df.isnull().sum().values.sum())\nprint (\"\\nUnique values :  \\n\",df.nunique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Question1: If one of us apologizes when our discussion deteriorates, the discussion ends.\n\nQuestion2: I know we can ignore our differences, even if things get hard sometimes.\n\nQuestion3: When we need it, we can take our discussions with my spouse from the beginning and correct it.\n\nQuestion4: When I discuss with my spouse, to contact him will eventually work.\n\nQuestion5: The time I spent with my wife is special for us.\n\nQuestion6: We don't have time at home as partners.\n\nQuestion7: We are like two strangers who share the same environment at home rather than family.\n\nQuestion8: I enjoy our holidays with my wife.\n\nQuestion9: I enjoy traveling with my wife.\n\nQuestion10: Most of our goals are common to my spouse.\n\nQuestion11: I think that one day in the future, when I look back, I see that my spouse and I have been in harmony with each other.\n\nQuestion31: I feel aggressive when I argue with my spouse.\n\nQuestion32: When discussing with my spouse, I usually use expressions such as ‘you always’ or ‘you never’.\n\nQuestion33: I can use negative statements about my spouse's personality during our discussions.\n\nQuestion34: I can use offensive expressions during our discussions.\n\nQuestion35: I can insult my spouse during our discussions.\n\nQuestion43: I mostly stay silent to calm the environment a little bit.\n\nQuestion46: Even if I'm right in the discussion, I stay silent to hurt my spouse.\n\nQuestion53: When I discuss, I remind my spouse of her/his inadequacy.\n\nQuestion55: Whether divorce occured or not.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = df.corr()\ncorr.style.background_gradient(cmap = 'coolwarm')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Codes from Utku Engin   https://www.kaggle.com/vssseel/eda-various-ml-models-and-nn-with-roc-curves/notebook","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.formula.api as smf\n\nfrom sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, confusion_matrix, auc\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler \n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.neural_network import MLPClassifier\n\nfrom warnings import filterwarnings\nfilterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Decision Tree Model ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df[\"Divorce\"]\nX = df.drop([\"Divorce\"], axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cart = DecisionTreeClassifier(max_depth = 12)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cart_model = cart.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = cart_model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Decision Tree Model')\n\nprint('Accuracy Score: {}\\n\\nConfusion Matrix:\\n {}\\n\\nAUC Score: {}'\n      .format(accuracy_score(y_test,y_pred), confusion_matrix(y_test,y_pred), roc_auc_score(y_test,y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(data = cart_model.feature_importances_*100,\n                   columns = [\"Importances\"],\n                   index = X_train.columns).sort_values(\"Importances\", ascending = False)[:20].plot(kind = \"barh\", color = \"r\")\n\nplt.xlabel(\"Feature Importances (%)\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We can use the functions to apply the models and roc curves to save space.\ndef model(algorithm, X_train, X_test, y_train, y_test):\n    alg = algorithm\n    alg_model = alg.fit(X_train, y_train)\n    global y_prob, y_pred\n    y_prob = alg.predict_proba(X_test)[:,1]\n    y_pred = alg_model.predict(X_test)\n\n    print('Accuracy Score: {}\\n\\nConfusion Matrix:\\n {}'\n      .format(accuracy_score(y_test,y_pred), confusion_matrix(y_test,y_pred)))\n    \n\ndef ROC(y_test, y_prob):\n    \n    false_positive_rate, true_positive_rate, threshold = roc_curve(y_test, y_prob)\n    roc_auc = auc(false_positive_rate, true_positive_rate)\n    \n    plt.figure(figsize = (10,10))\n    plt.title('Receiver Operating Characteristic')\n    plt.plot(false_positive_rate, true_positive_rate, color = 'red', label = 'AUC = %0.2f' % roc_auc)\n    plt.legend(loc = 'lower right')\n    plt.plot([0, 1], [0, 1], linestyle = '--')\n    plt.axis('tight')\n    plt.ylabel('True Positive Rate')\n    plt.xlabel('False Positive Rate')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Model and ROC Curve Comparison","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#Logistic Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Model: Logistic Regression\\n')\nmodel(LogisticRegression(solver = \"liblinear\"), X_train, X_test, y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"LogR = LogisticRegression(solver = \"liblinear\")\ncv_scores = cross_val_score(LogR, X, y, cv = 8, scoring = 'accuracy')\nprint('Mean Score of CV: ', cv_scores.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ROC(y_test, y_prob)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Gaussian Naive Bayes Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Model: Gaussian Naive Bayes\\n')\nmodel(GaussianNB(), X_train, X_test, y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NB = GaussianNB()\ncv_scores = cross_val_score(NB, X, y, cv = 8, scoring = 'accuracy')\nprint('Mean Score of CV: ', cv_scores.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ROC(y_test, y_prob)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Support Vector Classification Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#I excluded probability in the function for SVC, also I could not use other kernel methods because it takes really long and I don't think SVC as a good model for this dateset. \nprint('Model: SVC\\n')\n\ndef model1(algorithm, X_train, X_test, y_train, y_test):\n    alg = algorithm\n    alg_model = alg.fit(X_train, y_train)\n    global y_pred\n    y_pred = alg_model.predict(X_test)\n    \n    print('Accuracy Score: {}\\n\\nConfusion Matrix:\\n {}'\n      .format(accuracy_score(y_test,y_pred), confusion_matrix(y_test,y_pred)))\n    \nmodel1(SVC(kernel = 'linear'), X_train, X_test, y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Decision Tree Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Model: Decision Tree\\n')\nmodel(DecisionTreeClassifier(max_depth = 12), X_train, X_test, y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DTC = DecisionTreeClassifier(max_depth = 12)\ncv_scores = cross_val_score(DTC, X, y, cv = 8, scoring = 'accuracy')\nprint('Mean Score of CV: ', cv_scores.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ROC(y_test, y_prob)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Random Forest","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Model: Random Forest\\n')\nmodel(RandomForestClassifier(), X_train, X_test, y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RFC = RandomForestClassifier()\ncv_scores = cross_val_score(RFC, X, y, cv = 8, scoring = 'accuracy')\nprint('Mean Score of CV: ', cv_scores.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ROC(y_test, y_prob)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Random Forest Model Tuning","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_parameters = {\"max_depth\": [10,13],\n                 \"n_estimators\": [10,100,500],\n                 \"min_samples_split\": [2,5]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_model = RandomForestClassifier()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_cv_model = GridSearchCV(rf_model,\n                           rf_parameters,\n                           cv = 10,\n                           n_jobs = -1,\n                           verbose = 2)\n\nrf_cv_model.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Best parameters: ' + str(rf_cv_model.best_params_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_tuned = RandomForestClassifier(max_depth = 13,\n                                  min_samples_split = 2,\n                                  n_estimators = 500)\n\nprint('Model: Random Forest Tuned\\n')\nmodel(rf_tuned, X_train, X_test, y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Tuned model has worse accuracy score than default one. In the default model there is no limit for max depth. Increasing max depth gives us better accuracy scores but may decrease generalization.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#XGBoost Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Model: XGBoost\\n')\nmodel(XGBClassifier(), X_train, X_test, y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"XGB = XGBClassifier()\ncv_scores = cross_val_score(XGB, X, y, cv = 8, scoring = 'accuracy')\nprint('Mean Score of CV: ', cv_scores.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ROC(y_test, y_prob)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Neural Network Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\nscaler.fit(X_train)\nX_train_scaled = scaler.transform(X_train)\nX_test_scaled = scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Model: Neural Network\\n')\nmodel(MLPClassifier(), X_train_scaled, X_test_scaled, y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ROC(y_test, y_prob)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Neural Network Model Tuning","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"mlpc_parameters = {\"alpha\": [1, 0.1, 0.01, 0.001],\n                   \"hidden_layer_sizes\": [(50,50,50),\n                                          (100,100)],\n                   \"solver\": [\"adam\", \"sgd\"],\n                   \"activation\": [\"logistic\", \"relu\"]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mlpc = MLPClassifier()\nmlpc_cv_model = GridSearchCV(mlpc, mlpc_parameters,\n                             cv = 10,\n                             n_jobs = -1,\n                             verbose = 2)\n\nmlpc_cv_model.fit(X_train_scaled, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Best parameters: ' + str(mlpc_cv_model.best_params_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mlpc_tuned = MLPClassifier(activation = 'relu',\n                           alpha = 0.1,\n                           hidden_layer_sizes = (100,100),\n                           solver = 'adam')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Model: Neural Network Tuned\\n')\nmodel(mlpc_tuned, X_train_scaled, X_test_scaled, y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ROC(y_test, y_prob)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Conclusion\n\n#Feature Importances","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"randomf = RandomForestClassifier()\nrf_model1 = randomf.fit(X_train, y_train)\n\npd.DataFrame(data = rf_model1.feature_importances_*100,\n                   columns = [\"Importances\"],\n                   index = X_train.columns).sort_values(\"Importances\", ascending = False)[:15].plot(kind = \"barh\", color = \"r\")\n\nplt.xlabel(\"Feature Importances (%)\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Summary Table of the Models","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"table = pd.DataFrame({\"Model\": [\"Decision Tree (reservation status included)\", \"Logistic Regression\",\n                                \"Naive Bayes\", \"Support Vector\", \"Decision Tree\", \"Random Forest\",\n                                \"Random Forest Tuned\", \"XGBoost\", \"Neural Network\", \"Neural Network Tuned\"],\n                     \"Accuracy Scores\": [\"0.88\", \"0.98\", \"0.98\", \"1.00\", \"0.846\",\n                                         \"1.00\", \"0.851\", \"0.98\", \"0.98\", \"0.98\"],\n                     \"ROC | Auc\": [\"0.88\", \"1.00\", \"0.98\", \"0.88\",\n                                   \"0.92\", \"0.98\", \"0\", \"0.99\",\n                                   \"1.00\", \"1.00\"]})\n\n\ntable[\"Model\"] = table[\"Model\"].astype(\"category\")\ntable[\"Accuracy Scores\"] = table[\"Accuracy Scores\"].astype(\"float32\")\ntable[\"ROC | Auc\"] = table[\"ROC | Auc\"].astype(\"float32\")\n\npd.pivot_table(table, index = [\"Model\"]).sort_values(by = 'Accuracy Scores', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see from the summary table, the best algorithm is random forest for this data set.\n0 values are uncalculated ones.\nWe do not count decision tree with reservatiton status which is broken. All algorithms would give 100% accuracy scores while reservation status is included.\nTuning for XGBoost would be a good challenge too.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The conclusion above isn't mine. It's from Utku Engin  https://www.kaggle.com/vssseel/eda-various-ml-models-and-nn-with-roc-curves/notebook","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Das War's Kaggle Notebook Runner: Marília Prata   @mpwolke","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}