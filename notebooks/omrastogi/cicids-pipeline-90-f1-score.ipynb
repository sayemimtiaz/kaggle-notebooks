{"cells":[{"metadata":{},"cell_type":"markdown","source":"# CICIDS ML PipeLine - 90% F1-score"},{"metadata":{},"cell_type":"markdown","source":"Since this data is very imbalanced, F1-score is given more priority over accuracy of the model. This model has been made to optimize the f1-macro score of the model. Steps are as following - \n1. Data Loading\n2. Data Preprocessing\n3. Balancing Imbalanced Dataset\n4. Machine Learning Models\n5. Ensemble Model "},{"metadata":{},"cell_type":"markdown","source":"## Data Loading"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib\nimport seaborn as sns\nimport sklearn\nimport imblearn\nimport matplotlib.pyplot as plt\nimport time\nimport sklearn.metrics as m\nimport xgboost as xgb\n# Ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n#Settings\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\n#Probably can`t be finished because of huge amount of data with kaggle hardware, add nrows parameter to run here\n#Load Data\n\ncols = [' Bwd Packet Length Std',' PSH Flag Count',' min_seg_size_forward',' Min Packet Length',' ACK Flag Count',' Bwd Packet Length Min',' Fwd IAT Std','Init_Win_bytes_forward',' Flow IAT Max',' Bwd Packets/s',' URG Flag Count','Bwd IAT Total',' Label']\ndf1=pd.read_csv(\"/kaggle/input/cicids2017/MachineLearningCSV/MachineLearningCVE/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\", usecols = cols)#,nrows = 50000\ndf2=pd.read_csv(\"/kaggle/input/cicids2017/MachineLearningCSV/MachineLearningCVE/Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv\", usecols = cols)\ndf3=pd.read_csv(\"/kaggle/input/cicids2017/MachineLearningCSV/MachineLearningCVE/Friday-WorkingHours-Morning.pcap_ISCX.csv\", usecols = cols)\ndf5=pd.read_csv(\"/kaggle/input/cicids2017/MachineLearningCSV/MachineLearningCVE/Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv\", usecols = cols)\ndf6=pd.read_csv(\"/kaggle/input/cicids2017/MachineLearningCSV/MachineLearningCVE/Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv\", usecols = cols)\n\n# df4, df7 and df8 are being left out as they only have the benign samples","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.concat([df1,df2])\ndel df1,df2\ndf = pd.concat([df,df3])\ndel df3\ndf = pd.concat([df,df5])\ndel df5\ndf = pd.concat([df,df6])\ndel df6\n\ndata = df.copy()\n\nfor column in data.columns:\n    if data[column].dtype == np.int64:\n        maxVal = data[column].max()\n        if maxVal < 120:\n            data[column] = data[column].astype(np.int8)\n        elif maxVal < 32767:\n            data[column] = data[column].astype(np.int16)\n        else:\n            data[column] = data[column].astype(np.int32)\n            \n    if data[column].dtype == np.float64:\n        maxVal = data[column].max()\n        minVal = data[data[column]>0][column]\n        if maxVal < 120 and minVal>0.01 :\n            data[column] = data[column].astype(np.float16)\n        else:\n            data[column] = data[column].astype(np.float32)\n            \n            \n\nattackType = data[' Label'].unique()\ndata[' Label'] = data[' Label'].astype('category')\ndata[' Label'] = data[' Label'].astype(\"category\").cat.codes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = data[' Label'].copy()\nX = data.drop([' Label'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Balancing The Imbalanced Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.under_sampling import RandomUnderSampler\n\nrus = RandomUnderSampler('majority')\nX_rus, y_rus = rus.fit_sample(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_rus.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = X_rus\ndf[' Label'] = y_rus\nminor = pd.DataFrame(df[(df[' Label']!=4) & (df[' Label']!=2)])\nmajor = pd.DataFrame(df[(df[' Label']==4) | (df[' Label']==2)])\nminor[' Label'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\ny_rus_ =  minor[' Label']\nX_rus_ =  minor.drop([' Label'],axis=1)\nstrategy = {1:2000, 5:1600, 7:800, 3:300, 6:200, 0:200}\nsm = SMOTE(sampling_strategy=strategy)\nX_sm, y_sm = sm.fit_sample(X_rus_, y_rus_)\nX_min,y_min = X_sm, y_sm ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"major[' Label'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.under_sampling import RandomUnderSampler\ny_rus_ =  major[' Label']\nX_rus_ =  major.drop([' Label'],axis=1)\nstrategy = {4:10000, 2:6000}\ntom = RandomUnderSampler(sampling_strategy=strategy)\nX_tom, y_tom = tom.fit_sample(X_rus_, y_rus_)\ny_tom.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_maj,y_maj = X_tom, y_tom\nX,y = pd.concat([X_maj,X_min]), pd.concat([y_maj,y_min])\nX.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Machine Learning Models"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\n\n# extract numerical attributes and scale it to have zero mean and unit variance  \ncols = X.select_dtypes(include=['float32','float16','int32','int16','int8']).columns\ntrain_X = scaler.fit_transform(X.select_dtypes(include=['float32','float16','int32','int16','int8']))\n\n\n\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,Y_train,Y_test = train_test_split(train_X,y,train_size=0.70, random_state=2)\n\n\nfrom sklearn import tree\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\n\n# Train Random Forest\nRFC_Classifier = RandomForestClassifier(max_depth=40)\nRFC_Classifier.fit(X_train, Y_train)\nprint ('RF Classifier run')\n\n# Train SVC\nSVM_Classifier = SVC()\nSVM_Classifier.fit(X_train, Y_train)\nprint ('SV Classifier run')\n# Train Decision Tree Model\nDTC_Classifier = tree.DecisionTreeClassifier(criterion='gini', max_depth=33, random_state=20, max_features=12, splitter='random')\nDTC_Classifier.fit(X_train, Y_train)\nprint ('DTC Classifier run')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\n\nmodels = []\nmodels.append(('Random Forest Classifier', RFC_Classifier))\nmodels.append(('Decision Tree Classifier', DTC_Classifier))\nmodels.append(('Support Vector Classifier',SVM_Classifier))\n\n\nfor i, v in models:\n    Xpred =  v.predict(X_train)\n    scores = cross_val_score(v, X_train, Y_train, cv=10)\n    accuracy = metrics.accuracy_score(Y_train, Xpred)\n    confusion_matrix = metrics.confusion_matrix(Y_train, Xpred)\n    classification = metrics.classification_report(Y_train, Xpred)\n    print()\n    print('============================== {} Model Evaluation =============================='.format(i))\n    print()\n    print (\"Cross Validation Mean Score:\" \"\\n\", scores.mean())\n    print()\n    print (\"Model Accuracy:\" \"\\n\", accuracy)\n    print()\n    print(\"Confusion matrix:\" \"\\n\", confusion_matrix)\n    print()\n    print(\"Classification report:\" \"\\n\", classification) \n    print()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, v in models:\n    pred = v.predict(X_test)\n    accuracy = metrics.accuracy_score(Y_test,pred)\n    confusion_matrix = metrics.confusion_matrix(Y_test, pred)\n    classification = metrics.classification_report(Y_test, pred)\n    print()\n    print('============================== {} Model Test Results =============================='.format(i))\n    print()\n    print (\"Model Accuracy:\" \"\\n\", accuracy)\n    print()\n    print(\"Confusion matrix:\" \"\\n\", confusion_matrix)\n    print()\n    print(\"Classification report:\" \"\\n\", classification) \n    print()    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"DecisionTreeClassifier(max_depth=35, random_state=10, splitter='random') - 0.85\n\nDecisionTreeClassifier(max_depth=33, random_state=20, splitter='random') - 0.88"},{"metadata":{},"cell_type":"markdown","source":"## Ensemble Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import VotingClassifier\n\nclf1 = tree.DecisionTreeClassifier(criterion='gini', max_depth=33, random_state=20, max_features=12, splitter='random')\nclf2 = RandomForestClassifier(criterion='gini', max_depth=40, random_state=20)\nclf3 = SVC()\n\nvotingC = VotingClassifier(estimators=[('dc',clf1), ('rf', clf2),('svc',clf3)],voting='hard', weights=[2,2,1],flatten_transform=True)\nvotingC.fit(X_train,Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = votingC.predict(X_test)\naccuracy = metrics.accuracy_score(Y_test,pred)\nconfusion_matrix = metrics.confusion_matrix(Y_test, pred)\nclassification = metrics.classification_report(Y_test, pred)\nprint()\nprint('============================== {} Model Test Results =============================='.format('Voting Classifier'))\nprint()\nprint (\"Model Accuracy:\" \"\\n\", accuracy)\nprint()\nprint(\"Confusion matrix:\" \"\\n\", confusion_matrix)\nprint()\nprint(\"Classification report:\" \"\\n\", classification) \nprint()    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Hence we have been able to achive an accuracy of 96% and F1-score of 89%. "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}