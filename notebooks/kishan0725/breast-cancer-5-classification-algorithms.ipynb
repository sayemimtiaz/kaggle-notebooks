{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Importing Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/breast-cancer-wisconsin-data/data.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# removing id and unnamed: 32 column which is not necessary for our model\ndata = data.drop(['id','Unnamed: 32'],axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# As our dataset is balanced (around 60-40 ratio), there is no need to balance our data\ndata.diagnosis.value_counts(normalize = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Mapping our target variable to 1 and 0\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ndata['diagnosis'] = le.fit_transform(data['diagnosis'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.diagnosis.value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Finding correlation among features using sns' heatmap\nplt.figure(figsize=(20,20))\nsns.heatmap(data.corr(),annot=True,cmap='coolwarm')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# removing features that are less correlated with our target variable\ndata.corr().diagnosis[data.corr().diagnosis<=0.2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"less_corr = data.corr().diagnosis[data.corr().diagnosis<=0.2].index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.drop(less_corr,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Standardizing our features except target variable\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.preprocessing import StandardScaler\nstand_scale = data.drop(['diagnosis'],axis = 1)\ncol_trans = make_column_transformer(\n            (StandardScaler(), stand_scale.columns),\n            remainder = 'passthrough')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train Test Split"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX = data.drop(['diagnosis'], axis = 1)\ny = data['diagnosis']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col_trans.fit_transform(X_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Classification Models\n\n### 1.Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import make_pipeline\nlogreg = LogisticRegression(solver='lbfgs')\npipe = make_pipeline(col_trans,logreg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nprint('Accuracy score on Train data: {}'.format(cross_val_score(pipe, X_train, y_train, cv=10, scoring='accuracy').mean()*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pipe = make_pipeline(col_trans,logreg)\npipe.fit(X_train, y_train)\ny_pred = pipe.predict(X_test)\nfrom sklearn import metrics\nprint('Accuracy score on Test data: {}'.format(metrics.accuracy_score(y_test,y_pred)*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. K Nearest Neighbors Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nknn_scores = []\nfor k in range(1,31):\n    knn_classifier = KNeighborsClassifier(n_neighbors = k)\n    pipe = make_pipeline(col_trans,knn_classifier)\n    knn_scores.append(cross_val_score(pipe, X_train, y_train, cv=5, scoring='accuracy').mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,16))\nplt.plot([k for k in range(1, 31)], knn_scores, color = 'red')\nfor i in range(1,31):\n    plt.text(i, knn_scores[i-1], (i, round(knn_scores[i-1]*100,2)))\nplt.xticks([i for i in range(1, 31)])\nplt.xlabel('Number of Neighbors (K)')\nplt.ylabel('Scores')\nplt.title('K Neighbors Classifier scores for different K values')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Accuracy score on Train data: {}'.format(knn_scores[4]*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn_classifier = KNeighborsClassifier(n_neighbors = 4)\npipe = make_pipeline(col_trans,knn_classifier)\npipe.fit(X_train, y_train)\ny_pred = pipe.predict(X_test)\nprint('Accuracy score on Test Data: {}'.format(metrics.accuracy_score(y_test,y_pred)*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3. Support Vector Classifier (SVC)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nsvc_scores = []\nkernels = ['linear', 'poly', 'rbf', 'sigmoid']\nfor i in range(len(kernels)):\n    svc_classifier = SVC(kernel = kernels[i])\n    pipe = make_pipeline(col_trans,svc_classifier)\n    svc_scores.append(cross_val_score(pipe, X_train, y_train, cv=5, scoring='accuracy').mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib.cm import rainbow\nimport numpy as np\ncolors = rainbow(np.linspace(0, 1, len(kernels)))\nplt.figure(figsize=(10,7))\nplt.bar(kernels, svc_scores, color = colors)\nfor i in range(len(kernels)):\n    plt.text(i, svc_scores[i], svc_scores[i])\nplt.xlabel('Kernels')\nplt.ylabel('Scores')\nplt.title('Support Vector Classifier scores for different kernels')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Accuracy score on Train data: {}'.format(svc_scores[2]*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svc_classifier = SVC(kernel = 'rbf')\npipe = make_pipeline(col_trans,svc_classifier)\npipe.fit(X_train, y_train)\ny_pred = pipe.predict(X_test)\nprint('Accuracy score on Test data: {}'.format(metrics.accuracy_score(y_test,y_pred)*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4. Decision Tree Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\ndt_scores = []\nfor i in range(1, len(X.columns) + 1):\n    dt_classifier = DecisionTreeClassifier(max_features = i, random_state = 0)\n    pipe = make_pipeline(col_trans,dt_classifier)\n    dt_scores.append(cross_val_score(pipe, X_train, y_train, cv=5, scoring='accuracy').mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,10))\nplt.plot([i for i in range(1, len(X.columns) + 1)], dt_scores, color = 'green')\nfor i in range(1, len(X.columns) + 1):\n    plt.text(i, dt_scores[i-1], (i, dt_scores[i-1]))\nplt.xticks([i for i in range(1, len(X.columns) + 1)])\nplt.xlabel('Max features')\nplt.ylabel('Scores')\nplt.title('Decision Tree Classifier scores for different number of maximum features')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Accuracy score on Train data: {}'.format(dt_scores[3]*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dt_classifier = DecisionTreeClassifier(max_features = 4, random_state = 0)\npipe = make_pipeline(col_trans,dt_classifier)\npipe.fit(X_train, y_train)\ny_pred = pipe.predict(X_test)\nprint('Accuracy  score on Test data: {}'.format(metrics.accuracy_score(y_test,y_pred)*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 5. Random Forest Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrf_scores = []\nestimators = [10, 100, 200, 500, 1000]\nfor i in estimators:\n    rf_classifier = RandomForestClassifier(n_estimators = i, random_state = 0)\n    pipe = make_pipeline(col_trans,rf_classifier)\n    rf_scores.append(cross_val_score(pipe, X_train, y_train, cv=5, scoring='accuracy').mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,7))\ncolors = rainbow(np.linspace(0, 1, len(estimators)))\nplt.bar([i for i in range(len(estimators))], rf_scores, color = colors, width = 0.8)\nfor i in range(len(estimators)):\n    plt.text(i, rf_scores[i], round(rf_scores[i],5))\nplt.xticks(ticks = [i for i in range(len(estimators))], labels = [str(estimator) for estimator in estimators])\nplt.xlabel('Number of estimators')\nplt.ylabel('Scores')\nplt.title('Random Forest Classifier scores for different number of estimators')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Accuracy score on Train data: {}'.format(rf_scores[4]*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_classifier = RandomForestClassifier(n_estimators = 1000, random_state = 0)\npipe = make_pipeline(col_trans,rf_classifier)\npipe.fit(X_train, y_train)\ny_pred = pipe.predict(X_test)\nprint('Accuracy score on Test data: {}'.format(metrics.accuracy_score(y_test,y_pred)*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Logisitc Regression performed well compared with other models. Let's run our model using Logistic Regression and have a look at its confusion matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"pipe = make_pipeline(col_trans,logreg)\npipe.fit(X_train, y_train)\ny_pred = pipe.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Confusion Matrix - Training Dataset')\nprint(pd.crosstab(y_train, pipe.predict(X_train), rownames = ['True'], colnames = ['Predicted'], margins = True))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's check our False Negative rate which makes sense especially in health care field. "},{"metadata":{"trusted":true},"cell_type":"code","source":"4/165","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Around 2.42% of observations are misclassified as Benign which actually is Malignant"},{"metadata":{},"cell_type":"markdown","source":"Let's take a look at confusion matrix in out testing dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Confusion Matrix - Testing Dataset')\nprint(pd.crosstab(y_test, y_pred, rownames = ['True'], colnames = ['Predicted'], margins = True))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking False Negative Rate\n2/47","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"4.25% of observations in testing data are misclassified as Benign"},{"metadata":{},"cell_type":"markdown","source":"## Other Evaluation Metrics"},{"metadata":{},"cell_type":"markdown","source":"### Precision, Recall and F1 Score"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import precision_score,recall_score,f1_score\nprint('Precision Score: {}'.format(precision_score(y_test,y_pred)));\nprint('Recall Score: {}'.format(recall_score(y_test,y_pred)))\nprint('F1 Score: {}'.format(f1_score(y_test,y_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Average Precision Score"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import average_precision_score\naverage_precision = average_precision_score(y_test, y_pred)\n\nprint('Average precision-recall score: {0:0.2f}'.format(\n      average_precision))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Precision-Recall Plot"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import precision_recall_curve\nimport matplotlib.pyplot as plt\nfrom inspect import signature\n\nprecision, recall, _ = precision_recall_curve(y_test, y_pred)\n\n# In matplotlib < 1.5, plt.fill_between does not have a 'step' argument\nstep_kwargs = ({'step': 'post'}\n               if 'step' in signature(plt.fill_between).parameters\n               else {})\nplt.step(recall, precision, color='b', alpha=0.2,\n         where='post')\nplt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.ylim([0.0, 1.05])\nplt.xlim([0.0, 1.0])\nplt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(\n          average_precision))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ROC-AUC Score"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nprint('ROC AUC Score: {}'.format(roc_auc_score(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ROC Curve"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve\nfpr, tpr, thresholds = roc_curve(y_test,y_pred)\nplt.plot(fpr, tpr)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.title('ROC curve for breast cancer prediction')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\nplt.grid(True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"You can improve the performance of the model to some more extent by performing Hyper parameter tuning in KNN, Random forest, etc. and append it to the pipeline model and test the model.\n\nThanks for viewing. Please do upvote, if you like my notebook. Any Suggestions are welcome!"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}