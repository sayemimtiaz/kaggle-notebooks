{"cells":[{"metadata":{},"cell_type":"markdown","source":"<div style=\"text-align: center;\">\n\n# Estonia Disaster Passanger List: EDA + Classification\n\n<h3 align=\"center\">Made by üöÄ <a href=\"https://www.kaggle.com/rafanthx13\"> Rafael Morais de Assis</a></h3>\n    \n<img src=\"https://upload.wikimedia.org/wikipedia/commons/1/1a/MS_Estonia_model.jpg\" width=\"50%\"/>\n    \n</div> <br>\n\n\nCreated: 2020-08-21; \n\nLast updated: 2020-08-23;\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Kaggle Description\n\n[Kaggle Link](https://www.kaggle.com/christianlillelund/passenger-list-for-the-estonia-ferry-disaster)\n\nRead more: https://en.wikipedia.org/wiki/MS_Estonia\n\n### Facts\n\nWhen was the Sinking of the Estonia: September 28, 1994\nWhere was the Sinking of the Estonia: Near the Turku Archipelago, in the Baltic Sea\nWhat was the Sinking of the Estonia death toll: 852 passengers and crew\n\nInteresting things to investigate about the data:\n\nWho's more likely to survive the sinking based on data?\nIs age an indicator for survival?\nIs gender an indicator for survival?\nDid the crew aboard have a higher chance of survival than passengers?\nSince the death toll is well above 80%, can you make a classifier that beats the baseline (all passengers died)?\n\n### Data Dictionary\n\n| Variable  | Definition                              | Key                     |\n| :-------- | :-------------------------------------- | :---------------------- |\n| Country   | Country of origin                       |                         |\n| Firstname | Firstname of passenger                  |                         |\n| Lastname  | Lastname of passenger                   |                         |\n| Sex       | Gender of passenger                     | M = Male, F = Female    |\n| Age       | Age of passenger at the time of sinking |                         |\n| Category  | The type of passenger                   | C = Crew, P = Passenger |\n| Survived  | Survival                                | 0 = No, 1 = Yes   ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Table Of Contents (TOC) <a id=\"top\"></a>\n\n+ [Import Libs and DataSet](#index01) \n+ [Snippets](#index02)\n+ [EDA](#index03)\n  - [Check Missing Data](#index04)\n  - [Check Duplicate Data](#index05)\n  - [Each Feature Individually](#index06)\n  - [With Survived](#index07)\n+ [Correlation](#index11)\n+ [Unbalanced DataSet](#index09)\n+ [Pre-Processing](#index23)\n+ [Split in Train Test a Unbalanced DataSet](#index24)\n+ [Test various ways to correct unbalanced dataset](#index25)\n+ [Fit multiple models and Compare](#index26)\n+ [Best Individual Model: AdaBoost](#index27)\n+ [Super Leaner (MLens)](#index28)\n+ [Save and Load a Model](#index29)\n+ [Conclusion](#index30)\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Import Libs and DataSet Snippets <a id='index01'></a> <a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white; margin-left: 20px;\" data-toggle=\"popover\">Go to TOC</a>","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \npd.options.display.float_format = '{:,.4f}'.format\nsns.set(style=\"whitegrid\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/passenger-list-for-the-estonia-ferry-disaster/estonia-passenger-list.csv\")\nprint(\"Shape of DataSet:\", df.shape[0], 'rows |', df.shape[1], 'columns')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Snippets <a id='index02'></a> <a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white; margin-left: 20px;\" data-toggle=\"popover\">Go to TOC</a>","execution_count":null},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"def eda_categ_feat_desc_plot(series_categorical, title = \"\"):\n    \"\"\"Generate 2 plots: barplot with quantity and pieplot with percentage. \n       @series_categorical: categorical series\n       @title: optional\n    \"\"\"\n    series_name = series_categorical.name\n    val_counts = series_categorical.value_counts()\n    val_counts.name = 'quantity'\n    val_percentage = series_categorical.value_counts(normalize=True)\n    val_percentage.name = \"percentage\"\n    val_concat = pd.concat([val_counts, val_percentage], axis = 1)\n    val_concat.reset_index(level=0, inplace=True)\n    val_concat = val_concat.rename( columns = {'index': series_name} )\n    \n    fig, ax = plt.subplots(figsize = (12,4), ncols=2, nrows=1) # figsize = (width, height)\n    if(title != \"\"):\n        fig.suptitle(title, fontsize=18)\n        fig.subplots_adjust(top=0.8)\n\n    s = sns.barplot(x=series_name, y='quantity', data=val_concat, ax=ax[0])\n    for index, row in val_concat.iterrows():\n        s.text(row.name, row['quantity'], row['quantity'], color='black', ha=\"center\")\n\n    s2 = val_concat.plot.pie(y='percentage', autopct=lambda value: '{:.2f}%'.format(value),\n                             labels=val_concat[series_name].tolist(), legend=None, ax=ax[1],\n                             title=\"Percentage Plot\")\n\n    ax[1].set_ylabel('')\n    ax[0].set_title('Quantity Plot')\n\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def eda_horiz_plot(df, x, y, title, figsize = (8,5), palette=\"Blues_d\", formating=\"int\"):\n    \"\"\"Using Seaborn, plot horizonal Bar with labels\n    !!! Is recomend sort_values(by, ascending) before passing dataframe\n    !!! pass few values, not much than 20 is recommended\n    \"\"\"\n    f, ax = plt.subplots(figsize=figsize)\n    sns.barplot(x=x, y=y, data=df, palette=palette)\n    ax.set_title(title)\n    for p in ax.patches:\n        width = p.get_width()\n        if(formating == \"int\"):\n            text = int(width)\n        else:\n            text = '{.2f}'.format(width)\n        ax.text(width + 1, p.get_y() + p.get_height() / 2, text, ha = 'left', va = 'center')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def eda_categ_feat_desc_df(series_categorical):\n    \"\"\"Generate DataFrame with quantity and percentage of categorical series\n    @series_categorical = categorical series\n    \"\"\"\n    series_name = series_categorical.name\n    val_counts = series_categorical.value_counts()\n    val_counts.name = 'quantity'\n    val_percentage = series_categorical.value_counts(normalize=True)\n    val_percentage.name = \"percentage\"\n    val_concat = pd.concat([val_counts, val_percentage], axis = 1)\n    val_concat.reset_index(level=0, inplace=True)\n    val_concat = val_concat.rename( columns = {'index': series_name} )\n    return val_concat","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def eda_numerical_feat(series, title=\"\", with_label=True, number_format=\"\"):\n    f, (ax1, ax2) = plt.subplots(ncols=2, figsize=(18, 5), sharex=False)\n    print(series.describe())\n    if(title != \"\"):\n        f.suptitle(title, fontsize=18)\n    sns.distplot(series, ax=ax1)\n    sns.boxplot(series, ax=ax2)\n    if(with_label):\n        describe = series.describe()\n        labels = { 'min': describe.loc['min'], 'max': describe.loc['max'], \n              'Q1': describe.loc['25%'], 'Q2': describe.loc['50%'],\n              'Q3': describe.loc['75%']}\n        if(number_format != \"\"):\n            for k, v in labels.items():\n                ax2.text(v, 0.3, k + \"\\n\" + number_format.format(v), ha='center', va='center', fontweight='bold',\n                         size=8, color='white', bbox=dict(facecolor='#445A64'))\n        else:\n            for k, v in labels.items():\n                ax2.text(v, 0.3, k + \"\\n\" + str(v), ha='center', va='center', fontweight='bold',\n                     size=8, color='white', bbox=dict(facecolor='#445A64'))\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def check_balanced_train_test_binary(x_train, y_train, x_test, y_test, original_size, labels):\n    \"\"\" To binary classification\n    each paramethes is pandas.core.frame.DataFrame\n    @total_size = len(X) before split\n    @labels = labels in ordem [0,1 ...]\n    \"\"\"\n    train_unique_label, train_counts_label = np.unique(y_train, return_counts=True)\n    test_unique_label, test_counts_label = np.unique(y_test, return_counts=True)\n\n    prop_train = train_counts_label/ len(y_train)\n    prop_test = test_counts_label/ len(y_test)\n\n    print(\"Original Size:\", '{:,d}'.format(original_size))\n    print(\"\\nTrain: must be 80% of dataset:\\n\", \n          \"the train dataset has {:,d} rows\".format(len(x_train)),\n          'this is ({:.2%}) of original dataset'.format(len(x_train)/original_size),\n                \"\\n => Classe 0 ({}):\".format(labels[0]), train_counts_label[0], '({:.2%})'.format(prop_train[0]), \n                \"\\n => Classe 1 ({}):\".format(labels[1]), train_counts_label[1], '({:.2%})'.format(prop_train[1]),\n          \"\\n\\nTest: must be 20% of dataset:\\n\",\n          \"the test dataset has {:,d} rows\".format(len(x_test)),\n          'this is ({:.2%}) of original dataset'.format(len(x_test)/original_size),\n                  \"\\n => Classe 0 ({}):\".format(labels[0]), test_counts_label[0], '({:.2%})'.format(prop_test[0]),\n                  \"\\n => Classe 1 ({}):\".format(labels[1]),test_counts_label[1], '({:.2%})'.format(prop_test[1])\n         )","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def class_report(y_target, y_preds, name=\"\", labels=None):\n    if(name != ''):\n        print(name,\"\\n\")\n    print(confusion_matrix(y_test, y_pred))\n    print(classification_report(y_test, y_pred, target_names=labels))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploratory Data Analysis <a id='index03'></a> <a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white; margin-left: 20px;\" data-toggle=\"popover\">Go to TOC</a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Missing Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"No Missing Data:\")\n\nprint(\"\\t\", df.isnull().sum().max(), \"invalid Data\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Check Duplicate\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# No duplicate Rows\nprint(\"Check duplicated rows\")\nprint(\"\\t\", df.duplicated(subset=None, keep='first').sum(), 'rows Duplicates')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Each Feature Individually <a id='index06'></a> <a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white; margin-left: 20px;\" data-toggle=\"popover\">Go to TOC</a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<span style='font-size: 15pt'>PassengerId</span>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['PassengerId'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.query('PassengerId in [463, 767]')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<span style='font-size: 15pt'>Country</span>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"eda_categ_feat_desc_plot(df['Country'], 'Analysis \"Contry\" Distribution')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eda_categ_feat_desc_df(df['Country'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<span style='font-size: 15pt'>Firstname</span>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_names = eda_categ_feat_desc_df(df['Firstname'])\nprint(\"unique first names: \", df_names.shape[0] )\ndf_names.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<span style='font-size: 15pt'>Lastname</span>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_names = eda_categ_feat_desc_df(df['Lastname'])\nprint(\"unique last names: \", df_names.shape[0] )\ndf_names.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<span style='font-size: 15pt'>Sex</span>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"eda_categ_feat_desc_plot(df['Sex'], 'Analysis \"Sex\" Distribution')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<span style='font-size: 15pt'>Age</span>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"eda_numerical_feat(df['Age'], '\"Age\" Distribution', with_label=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Min Ages and Max Ages\ntop_int = 5\n\npd.concat([df.sort_values(by=\"Age\").head(top_int), df.sort_values(by=\"Age\").tail(top_int)])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<span style='font-size: 15pt'>Category</span>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"eda_categ_feat_desc_plot(df['Category'], 'Analysis \"Category\" Distribution')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<span style='font-size: 15pt'>Survived</span>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"eda_categ_feat_desc_plot(df['Survived'], 'Analysis \"Survived\" Distribution')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<span style='font-size: 15pt; color: darkblue;'>Conclusion</span>\n\n+ `PassengerId`:\n   - Number and unique values for each passenger. Except 2 Ids, \\[463, 767 \\] these divided between a man and a woman of class mems, probably known. The curious thing is that, even though Ids are different and of different categories \\[P (Passenger - Passenger), C (Crew - Technical Team)\\] in both cases the woman survived and the man did not.\n+ `Country`:\n   - 90% of Estonia (35%) and Sweden (55%) and the rest of other countries\n+ `Firstname`:\n   - Unique values, there is nothing to be analyzed\n+ `Lastname`:\n   - Unique values, there is nothing to be analyzed\n+ `Sex`:\n   - On the ship, there was the same disposition between men and women\n+ `Age`:\n   - Most adults, with children and old people. Ages range from 0 years to 80\n+ `Category`:\n   - About 80% class P and 20% class C\n+ `Survived`: Class\n   - 806% died and 14% survived\n\n\n*PassengerId*, *Firstname*, *Lastname* will no longer be analyzed for not providing relevant information to the problem\n\n<!--\nüáßüá∑\n\n+ `PassengerId`:\n  -  N√∫merico e valores √∫nicos para cada passageiros. Exceto 2 Ids, \\[463, 767\\] esses divididos entre um homem e uma mulher de mems classe, provavelmente conhecidos. O curioso √© que, mesmo sendo Ids diferente e de categorias diferentes \\[P (Passenger - Passageiro), C (Crew - Equipe T√©cnica)\\] em ambos os casos a mulher sobreviveu e o homem n√£o.\n+ `Country`: \n  -  90% da Estonia (35%) e Su√©cia (55%) e o restante de outros paises\n+ `Firstname`:\n  - Valores √∫nicos, n√£o h√° o que ser analizado\n+ `Lastname`:\n  - Valores √∫nicos, n√£o h√° o que ser analizado\n+ `Sex`:\n  - No navio, havia mesma disposi√ß√£o entre homens e mulheres\n+ `Age`:\n  - Maioria Adultos, com crian√ßas e velhos. Idades variam entre 0 anos a 80\n+ `Category`:\n  - Cerca de 80% classe P e 20% classe C\n+ `Survived`: Classe\n  - 806% morreram e 14% sobreviveram\n\n\n*PassengerId*, *Firstname*, *Lastname* n√£o ser√£o mais analizados por n√£o oferencerem informa√ß√£o relevante ao problema\n-->","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### With Survived <a id='index02'></a> <a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white; margin-left: 20px;\" data-toggle=\"popover\">Go to TOC</a>\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(list(df.columns))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<span style='font-size: 15pt'>Relationship Sex, Age and Survived</span>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(df, hue=\"Survived\", corner=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"f, (ax1, ax2) = plt.subplots(ncols=2, figsize=(14, 5), sharex=False)\nf.suptitle('Age x Survived', fontsize=18)\n\nsns.boxplot(y=\"Age\", x=\"Survived\", data=df, ax=ax1)\nsns.violinplot(y=\"Age\", x=\"Survived\", data=df, ax=ax2)\nax1.set_title(\"BoxPlot\")\nax2.set_title(\"ViolinPlot\")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"f, (ax1, ax2) = plt.subplots(ncols=2, figsize=(14, 5), sharex=False)\nf.suptitle('Age x Survived by Sex', fontsize=18)\n\nsns.boxplot(y=\"Age\", x=\"Survived\", hue=\"Sex\", data=df, ax=ax1)\nsns.violinplot(y=\"Age\", x=\"Survived\", hue=\"Sex\", data=df, ax=ax2)\nax1.set_title(\"BoxPlot\")\nax2.set_title(\"ViolinPlot\")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"f, ax1 = plt.subplots(figsize=(10, 5))\n\nsns.countplot(x=\"Sex\", hue=\"Survived\", data=df, ax=ax1)\nax1.set_title(\"Sex x Survived\", size=15)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<span style='font-size: 15pt; color: darkblue;'>Conclusion</span>\n\nAnalyzing the BoxPlots and ViolinPlots, we can see that younger people tended to survive, and this occurs mainly for women\n\n<!--\nAnalisandos os BoxPlots e ViolinPlots podemos perceber que pessoas mais jovens tenderam a sobreviver, e isso ocorre principalmente para as mulheres\n-->\n\n<span style='font-size: 15pt'>features x Survived</span>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = df.groupby([\"Survived\",\"Sex\"]).count().reset_index().rename({\"Firstname\": \"Quantity\"}, axis=1)\ndf1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"f, (ax1, ax2) = plt.subplots(ncols=2, figsize=(18, 5), sharex=False)\nf.suptitle('Percentage of Survivors by Sex', fontsize=18)\n\nalist = df1['Quantity'].tolist()\n\ndf1.query('Sex == \"M\"').plot.pie(y='Quantity', figsize=(10, 5), autopct='%1.2f%%', \n                                 labels = ['Not Survived = ' + str(alist[1]), 'Survived = ' + str(alist[3]) ],\n                                 title=\"% of male survivors \" + \"(Total = \" + str(alist[1] + alist[3]) + \")\",\n                                 ax=ax1, labeldistance=None)\n\ndf1.query('Sex == \"F\"').plot.pie(y='Quantity', figsize=(10, 5), autopct='%1.2f%%', \n                                 labels = ['Not Survived = ' + str(alist[0]), 'Survived =' + str(alist[2]) ],\n                                title=\"% of female survivors \" + \"(Total = \" + str(alist[0] + alist[2]) + \")\", \n                                 ax=ax2, labeldistance=None)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"f, (ax1, ax2) = plt.subplots(ncols=2, figsize=(18, 5), sharex=False)\nf.suptitle('Percentage of Sex that Survivors', fontsize=18)\n\nalist = df1['Quantity'].tolist()\n\ndf1.query('Survived == 0').plot.pie(y='Quantity', figsize=(10, 5), autopct='%1.2f%%',\n                                    labels = ['Female = ' + str(alist[0]), 'Male = ' + str(alist[1]) ],\n                                    title=\"% to sex of deaths \" + \"(Total = \" + str(alist[0] + alist[1]) + \")\",\n                                    ax=ax1, labeldistance=None)\n\ndf1.query('Survived == 1').plot.pie(y='Quantity', figsize=(10, 5), autopct='%1.2f%%',\n                                    labels = ['Female = ' + str(alist[2]), 'Male = ' + str(alist[3]) ],\n                                    title=\"% to sex of survivors \"  + \"(Total = \" + str(alist[2] + alist[3]) + \")\",\n                                    ax=ax2, labeldistance=None)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2 = df.groupby([\"Survived\",\"Category\"]).count().reset_index().rename({\"Firstname\": \"Quantity\"}, axis=1)\ndf2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"f, (ax1, ax2) = plt.subplots(ncols=2, figsize=(18, 5), sharex=False)\nf.suptitle('Percentage of Categories that Survived', fontsize=18)\n\nalist = df2['Quantity'].tolist()\n\ndf2.query('Category == \"P\"').plot.pie(y='Quantity', figsize=(10, 5), autopct='%1.2f%%',\n                                      labels = ['Not Survived = ' + str(alist[1]), 'Survived = ' + str(alist[3]) ],\n                                      title=\"% of class P that survived \" + \"(Total = \" + str(alist[1] + alist[3]) + \")\",\n                                      ax=ax1, labeldistance=None)\n\ndf2.query('Category == \"C\"').plot.pie(y='Quantity', figsize=(10, 5), autopct='%1.2f%%',\n                                      labels = ['Not Survived = ' + str(alist[0]), 'Survived = ' + str(alist[2]) ],\n                                      title=\"% of class C that survived \" + \"(Total = \" + str(alist[0] + alist[2]) + \")\",\n                                      ax=ax2, labeldistance=None)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"<span style='font-size: 15pt; color: darkblue;'>Conclusion</span>\n\nPercentage of Survivors by Sex\n+ Men tended to outlive women\n\nPercentage of Sex that Survivors\n+ The percentage of deaths is similar between genders, 43% of women died and 46% of men died, but of the survivors, the majority who survived were men\n+ probably, the previous graphics of violin plot that spoke of the young age of the women who survived, referred to a few women\n\nPercentage of Categories that Survived\n+ Although more passengers have survived (because there are 4x more passengers than people on the technical team), the technical team (Crew) had a higher survival rate.\n\n\n<!--\nPercentage of Survivors by Sex\n+ Os homens tenderam a sobreviver mais que as mulheres\n\nPercentage of Sex that Survivors\n+ A porcentagem de mortes √© parecida entre os sexo, 43% das mulhres morreram e 46% dos homens morreram, mas dos sobreviventes, a maioria que sobreviveu foram homens\n+ provavelmente, os graficos anteriores de violin plot que falaram de pouca idade das mulheres que sobreviream, se referiam a poucas mulhres\n\nPercentage of Categories that Survived\n+ Apesar de mais passageiros terem sobrevivido (Pois h√° 4x mais passageiros que gente da equipe t√©cnica), a equipe t√©cnica (Crew) apresentram uma maior taxa de sobreviv√™ncia.\n-->","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Correlation <a id='index11'></a> <a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white; margin-left: 20px;\" data-toggle=\"popover\">Go to TOC</a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"replace_list = {\"Sex\":{\"M\":0,\"F\":1}, \"Category\":{\"P\":0,\"C\":1}}\n\ndf_corr = df.replace(replace_list).drop(['PassengerId', 'Country','Firstname','Lastname'], axis = 1)\ndf_corr.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = df_corr.corr()\nmask = np.zeros_like(corr)\nmask[np.triu_indices_from(mask)] = True\n\nf, ax1 = plt.subplots(figsize=(8,6))\nsns.heatmap(corr, cmap='coolwarm_r', \n            annot=True, annot_kws={'size':15}, ax=ax1, mask=mask)\n\nax1.set_title(\"Correlation\", fontsize=14)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As correla√ß√µes s√£o em sua maioria fraca, mas a melhor √© 'Age'\n\n## Unbalanced DataSet <a id='index09'></a> <a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white; margin-left: 20px;\" data-toggle=\"popover\">Go to TOC</a>\n\nSignifica que, se se chutarmos sempre que todo mundo vai morrer, ent√£o: Nunca teriamos acertariamos que alguem iria sobreveier e teriamos um score de 87% que √© alto. Uma m√©trica melhor para avliar as duas tarefas do modelo: Classifica se sobrivive ou n√¢o corretamente, √© usar f1-score que avalia precisao (acerta) e recall (detectar)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"eda_categ_feat_desc_plot(df['Survived'], 'Remember, is a Unbalanced DataSet: Survived Rate')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n\n## Pre-Processing <a id='index23'></a> <a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white; margin-left: 20px;\" data-toggle=\"popover\">Go to TOC</a>\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import LabelEncoder","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Commun Pre-Processing\n\nTake Sex, Age and Category\n\nMedium Results","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# x = df.loc[:,[\"Sex\",\"Age\",\"Category\"]]\n# y = df.loc[:,[\"Survived\"]]\n\n# # OneHotEncoding\n# x = pd.get_dummies(x)\n\n# # Scaling Age\n# sc = StandardScaler()  # Normal Distribution: mean 0, min -1 and max 1\n# x['Age'] = sc.fit_transform(x['Age'].values.reshape(-1,1))\n\n# x.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Country Influence Pre-Processing (BEST)\n\nBased in https://www.kaggle.com/abhijithchandradas/pen-random-forest-model-beating-baseline-88-47\n\nMake good Results","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x = df.loc[:,[\"Sex\",\"Age\",\"Category\",\"Country\"]]\ny = df.loc[:,[\"Survived\"]]\n\nx.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Separate Country in Estonia, Sweden and Others\nx['Country'] = x['Country'].apply(lambda x: 'Estonia' if x == 'Estonia' \n                                  else ('Sweden' if x == 'Sweden' else 'Others'))\n\nsc = StandardScaler()  # Normal Distribution: mean 0, min -1 and max 1\nx['Age'] = sc.fit_transform(x['Age'].values.reshape(-1,1))\n\nx = pd.get_dummies(x, drop_first=True) # Remove EstoniaColumn\n\nx.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### LastName Pre-Processing\n\nInclude LastName encodig with label encondig (0,1,2,3 ... to each unique value)\n\nMade Poor Results","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# x = df.loc[:,[\"Sex\",\"Age\",\"Category\",\"Country\", \"Lastname\"]]\n# y = df.loc[:,[\"Survived\"]]\n\n# x['Country']= [1 if el =='Estonia' or el =='Sweden' else 0 for el in x['Country']] \n\n# sc = StandardScaler()  \n# x['Age'] = sc.fit_transform(x['Age'].values.reshape(-1,1))\n\n# encode = LabelEncoder()\n# x['Sex']=encode.fit_transform(x['Sex'])\n# x['Lastname']=encode.fit_transform(x['Lastname'])\n# x['Category'] =encode.fit_transform(x['Category'])\n\n# x.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Split in Train Test a Unbalanced DataSet <a id='index24'></a> <a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white; margin-left: 20px;\" data-toggle=\"popover\">Go to TOC</a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold, StratifiedKFold\n\nkfold = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n\nfor train_index, test_index in kfold.split(x, y):\n    x_train, x_test = x.iloc[train_index].values, x.iloc[test_index].values\n    y_train, y_test = y.iloc[train_index].values, y.iloc[test_index].values\n\ncheck_balanced_train_test_binary(x_train, y_train, x_test, y_test, len(df), ['Death', 'Survives'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Test various ways to correct unbalanced dataset <a id='index25'></a> <a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white; margin-left: 20px;\" data-toggle=\"popover\">Go to TOC</a>\n\nDont produce good results, decreases accuracy and increases f1 score\n\nTo use just exchange x_train, y_train by xsm_train, ysm_train","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN, SVMSMOTE, BorderlineSMOTE\nfrom imblearn.under_sampling import RandomUnderSampler, TomekLinks, NearMiss\nfrom imblearn.combine import SMOTEENN, SMOTETomek # over and under sampling\nfrom imblearn.metrics import classification_report_imbalanced\n\nimb_models = {\n    'ADASYN': ADASYN(),\n    'SMOTE': SMOTE(random_state=42),\n    'SMOTEENN': SMOTEENN(\"minority\", random_state=42),\n    'SMOTETomek': SMOTETomek(tomek=TomekLinks(sampling_strategy='majority')),\n    'RandomUnderSampler': RandomUnderSampler()\n}\n\nimb_strategy = \"SMOTE\"\n\nif(imb_strategy != \"None\"):\n    print(\"train dataset before\", x_train.shape[0])\n    print(\"imb_strategy:\", imb_strategy)\n\n    imb_tranformer = imb_models[imb_strategy]\n    \n    # x_train, y_train | xsm_train, ysm_train\n    xsm_train, ysm_train = imb_tranformer.fit_sample(x_train, y_train)\n\n    print(\"train dataset before\", xsm_train.shape[0],\n          'generate', xsm_train.shape[0] - x_train.shape[0] )\nelse:\n    print(\"Dont correct unbalanced dataset\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Fit multiple models and Compare <a id='index26'></a> <a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white; margin-left: 20px;\" data-toggle=\"popover\">Go to TOC</a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# use: x_train, y_train, x_test, y_test\n\n# Classifier Libraries\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\n\n# Ensemble Classifiers\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\n\n# Others Linear Classifiers\nfrom sklearn.linear_model import SGDClassifier, RidgeClassifier\nfrom sklearn.linear_model import Perceptron, PassiveAggressiveClassifier\n\n# xboost\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\n\n# scores\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import accuracy_score\n\n# neural net of sklearn\nfrom sklearn.neural_network import MLPClassifier\n\n# others\nimport time\nimport operator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def neural nets\nmlp = MLPClassifier(verbose = False, max_iter=1000, tol = 0.000010,\n                    solver = 'adam', hidden_layer_sizes=(100), activation='relu')\n\n# def classifiers\n\nnn_classifiers = {\n    \"Multi Layer Perceptron\": mlp\n}\n\nlinear_classifiers = {\n    \"SGDC\": SGDClassifier(),\n    \"Ridge\": RidgeClassifier(),\n    \"Perceptron\": Perceptron(),\n    \"PassiveAggressive\": PassiveAggressiveClassifier()\n}\n\ngboost_classifiers = {\n    \"XGBoost\": XGBClassifier(),\n    \"LightGB\": LGBMClassifier(),\n}\n\nclassifiers = {\n    \"Naive Bayes\": GaussianNB(),\n    \"Logisitic Regression\": LogisticRegression(),\n    \"KNearest\": KNeighborsClassifier(),\n    \"Support Vector Machine\": SVC(),\n    \"Decision Tree\": DecisionTreeClassifier()\n}\n\nensemble_classifiers = {\n    \"AdaBoost\": AdaBoostClassifier(),\n    \"GBoost\": GradientBoostingClassifier(),\n    \"Bagging\": BaggingClassifier(),\n    \"Random Forest\": RandomForestClassifier(),\n    \"Extra Trees\": ExtraTreesClassifier()    \n}\n\nall_classifiers = {\n    \"Simple Models\": classifiers,\n    \"Ensemble Models\": ensemble_classifiers,\n    \"GBoost Models\": gboost_classifiers,\n    \"NeuralNet Models\": nn_classifiers,\n    \"Others Linear Models\": linear_classifiers,\n}\n\nmetrics = {\n    'cv_scores': {},\n    'acc_scores': {},\n    'f1_mean_scores': {},\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"format_float = \"{:.4f}\"\n\nis_print = False # True/False\n\ntime_start = time.time()\n\nprint(\"Fit Many Classifiers\")\n\nfor key, classifiers in all_classifiers.items():\n    if (is_print):\n        print(\"\\n{}\\n\".format(key))\n    for key, classifier in classifiers.items():\n        t0 = time.time()\n        # xsm_train, ysm_train || x_train, y_train\n        classifier.fit(x_train, y_train) \n        t1 = time.time()\n        # xsm_train, ysm_train || x_train, y_train\n        training_score = cross_val_score(classifier, x_train, y_train, cv=5) \n        y_pred = classifier.predict(x_test)\n        cv_score = round(training_score.mean(), 4) * 100\n        acc_score = accuracy_score(y_test, y_pred)\n        f1_mean_score = f1_score(y_test, y_pred, average=\"macro\") # average =  'macro' or 'weighted'\n        if (is_print):\n            print(key, \"\\n\\tHas a training score of\", \n                  cv_score, \"% accuracy score on CrossVal with 5 cv \")\n            print(\"\\tTesting:\")\n            print(\"\\tAccuracy in Test:\", format_float.format(acc_score))\n            print(\"\\tF1-mean Score:\", format_float.format(f1_mean_score)) \n            print(\"\\t\\tTime: The fit time took {:.2} s\".format(t1 - t0), '\\n')\n        metrics['cv_scores'][key] = cv_score\n        metrics['acc_scores'][key] = acc_score\n        metrics['f1_mean_scores'][key] = f1_mean_score\n        \ntime_end = time.time()\n        \nprint(\"\\nDone in {:.5} s\".format(time_end - time_start), '\\n')\n        \nprint(\"Best cv score:\", max( metrics['cv_scores'].items(), key=operator.itemgetter(1) ))\nprint(\"Best Accuracy score:\", max( metrics['acc_scores'].items(), key=operator.itemgetter(1) ))\nprint(\"Best F1 score:\", max( metrics['f1_mean_scores'].items(), key=operator.itemgetter(1) ))\n\nlists = [list(metrics['cv_scores'].values()),\n         list(metrics['acc_scores'].values()),\n         list(metrics['f1_mean_scores'].values())\n        ]\n\na_columns = list(metrics['cv_scores'].keys())\n\ndf_metrics = pd.DataFrame(lists , columns = a_columns,\n                    index = ['cv_scores', 'acc_scores', 'f1_scores'] )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lists = [list(metrics['cv_scores'].values()),\n         list(metrics['acc_scores'].values()),\n         list(metrics['f1_mean_scores'].values())\n        ]\n\na_columns = list(metrics['cv_scores'].keys())\n\ndfre1 = pd.DataFrame(lists , columns = a_columns,\n                    index = ['cv_scores', 'acc_scores', 'f1_scores'] )\n\ndfre1 = dfre1.T.sort_values(by=\"acc_scores\", ascending=False)\ndfre1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Best Individual Model: AdaBoost <a id='index27'></a> <a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white; margin-left: 20px;\" data-toggle=\"popover\">Go to TOC</a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\n\n# AdaBoost\nadaB = AdaBoostClassifier()\nadaB.fit(x_train,y_train)\ny_pred = adaB.predict(x_test)\n\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred, target_names=['Death', 'Survives']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Super Learner (MLens) <a id='index28'></a> <a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white; margin-left: 20px;\" data-toggle=\"popover\">Go to TOC</a>\n\nreference: https://www.kaggle.com/nishantbhadauria/meta-learner-with-mlens-for-predicting-survival\n\nlink to see more of SuperLeaner of mlens\n+ https://machinelearningmastery.com/super-learner-ensemble-in-python/\n+ http://flennerhag.com/\n\nGenerates different results each time it is run","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from mlens.ensemble import SuperLearner\n\n# Define Models List\nmodels = list()\nmodels.append(LogisticRegression(solver='liblinear'))\nmodels.append(DecisionTreeClassifier())\nmodels.append(SVC(kernel='linear'))\nmodels.append(GaussianNB())\nmodels.append(KNeighborsClassifier())\nmodels.append(AdaBoostClassifier())    \nmodels.append(BaggingClassifier(n_estimators=100))\nmodels.append(RandomForestClassifier(n_estimators=100))\nmodels.append(ExtraTreesClassifier(n_estimators=100))\nmodels.append(XGBClassifier(scale_pos_weight=2))\n\n# Create Super Model\nensemble = SuperLearner(scorer=accuracy_score, folds=10, shuffle=False, sample_size=len(x))\nensemble.add(models)\nensemble.add_meta(DecisionTreeClassifier()) # can change\n\n# Fit \nensemble.fit(x_train, y_train)\nprint(ensemble.data)\n\n# Pred\ny_pred = ensemble.predict(x_test)\n\n# Evaluate\nclass_report(y_test, y_pred, name='SuperLeaner', labels=['Death', 'Survives'])\n\n# One time out: acc: 0.89, f1: 0.59","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Save and Load Model <a id='index29'></a> <a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white; margin-left: 20px;\" data-toggle=\"popover\">Go to TOC</a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\nPkl_Filename = \"Pickle_Model.pkl\"  \n\n# Save the Modle to file in the current working directory\nwith open(Pkl_Filename, 'wb') as file:  \n    pickle.dump(ensemble, file)\n    \n# Load the Model back from file\nwith open(Pkl_Filename, 'rb') as file:  \n    Pickled_ensemble = pickle.load(file)\n\nPickled_ensemble","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Conclusion <a id='index30'></a> <a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white; margin-left: 20px;\" data-toggle=\"popover\">Go to TOC</a>\n\nThe best strategy to achieve the highest accuracy was:\n+ Pre-Processing\n   - OneHotEnconding to Country and remove Estonia Column.\n   - LabelEnconding to 'Sex' and 'Category'\n   - StandScale to 'Age'\n+ Do not use any corrected unbalanced data set technique because it decreases accuracy to increase f1-score\n+ The best model was the SuperLeaner that combines several models, while individually it was AdaBoost\n\n**Nexts Steps**\n\n+ Tuning AdaBoost and SuperLeaner","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}