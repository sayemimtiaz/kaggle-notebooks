{"cells":[{"metadata":{},"cell_type":"markdown","source":"This is a general purpose image classifier. No intimate knowledge of neural networks is required to use this program to do image\nclassification. A limited knowledge ofpython may be required.\nThe program uses a modfied version of the MobileNet CNN. Top layers of the networkare modified as required for the classification task specifics.\nImage Inputs and Storage Locations:\n    The are two modes by which input images can be supplies as indicated by the call parameter mode. First create a directory to hold all the files. \n    I refer to this as the source_dir. Files in the source directory may be stored in one of two ways. If the parameter mode='SEP' then within the\n    source_dir you must have 3 subdirectoriesw specifically named as train, test and valid. The train sub directory should contain the training\n    images. The test sub directory should contain the test images and the valid sub directory should contain the validation images. Within each of \n    these the subdirectories are identically named 'class' sub directories. For example if your trying to classify images as to whether it is a dog\n    or a cat you would create class sub directories Cats and Dogs in the train, test and valid directories. Store the cat training images in the train\n    directory within the Cats subdirectory, similarly for the dog training images in the Dogs subdirectory. Do the same for the test and validation\n    images respectively. \n    If the parameter mode='All' the source_dir must have a single subdirectory named consolidated. All image files are stored in this subdirectory.\n    Within the consolidated sub directory are 'class' subdirectories, one subdirectory per class. For the dog/cat example there would be a class\n    subdirectory Cats and a class sub directory Dogs. All cat images should be placed in the Cats sub directory and similarly for dog images in the Dogs\n    subdirectory. A training set and a validation set are created from these images based on the parameter split. Split is an integer value between 0 and 100\n    and indicates the percentage of images which will be used to create the validation set of images. A typical value might be 15. Parameter split is\n    not used when the parameter mode is set to \"SEP\".\n USE:\n     status=TF2_classify(source_dir,output_dir,subject, split, epochs,lr_rate,image_size, model_size, dropout, rand_seed,dwell, kaggle) where:\n     souurce_dir is a string indicating the full path to where your image files are stored\n     output_dir is a string indicating the full path where output files will be stored. The program will create the following output files:\n       the trained model file labeled in the form subject-model_size-image_size-accuracy.h5. For example a file named birds-s-224-98.66.h5 is the\n       trained model with the subject birds, model size of s for small model, images size of 224 pixels and a test accuracy of 9.66%.\n       a text file labeled as subject-numberof classes.txt. For example a file labeled birds-200.txt is a file where the subject was birds and there\n       are 200 classes of birds.\n       Note: the above two files are used by a companion program Predictions.py which uses the trained model to make predictions on input bird image\n       files. I will post this program as a kernel on kaggle shortly.\n       An optional file may also be produced labelled error list-model_size-accuracy.txt. This file contains a listing of all test files that were\n       classified incorrectly.\n    subject is a stringindicating the subject of the classification/ For example if classifying bird species you might use \"birds\" as the subject.\n    split is an integer between 0 and 100. AS noted above it defines the percentage of files in the consolidated directory that will be used as\n        validation files when mode is set to \"All\". It is not used if mode is setto \"SEP\"\n    epochs - is an integer and specifies the number of epochs for training. At the end of the training the test set accuracy is determined and the\n        result is printed. Based on the result the user is given the option to enter an integer value for the number of additional training epochs\n        you may wish to run. This is convenient if the accuracy achieved was below that desired and you want to continue training for more epochs.\n    lr_rate is a float that indicates the initial learning rate for the network. A good value to use is .002. During training the learning rate\n        is automatically adjusted based on training and validation accuracy.\n    image_size is an integer indicating the size of images to be used by the model. Allowable values are 224, 192, 160 or 128. This limitation is\n        present so that the model can load the pre=trained weights from Imagnet which enables faster convergence.\n    model_size is a string limited to one of the single charactrs \"S\", \"M\", or \"L\". When set to \"S\" a small model is used, when set to \"M\" a medium\n        size model is used. When set to \"L\" a large model is used. All models use the MobilNet model as the base model and add top layers\n        to achieve different levels of model complexity. It is best to set model_size=\"S\" initially. Only use the larger models if the training\n        results are unsatisfactory.\n    dropout is a float value between 0.0 and 1.0. A good value to use is .4. Dropout is used when you are using a medium or larger model and\n        you experience over fitting.\n    rand_seed is an integer used to set the seed for randomization processes. It's value is arbitrary.\n    dwell is a boolean, either set to True or False. Normally set it to false. dwell is used as an experimental parameter that modifies the\n        training scheme. You may try setting dwell=True and see if you get a better result for Validation accuracy.\n    kagle is a boolean set to either True or False. Normally set kagle=False. This parameter should only be set to trueif you are on the\n        kagle websiteandrunninga \"commit\" on your kernel.\n In Process Printed Outputs:\n     This programs checks input parameters for errors. If an error is detected a message is printed and the functions returns False.\n     If all input are correct training is initiated. During training information is printed out at the end of each epoch that shows\n     the training loss and accuracy and the validation loss and accuracy. When all epochs are completed the test set is predicted and\n     the accuracy on the test set is provided. You can optionally save a listor errors asa file in the output_dir.\n     After running the test set you are given the option to halt or to enter an integer that indicates how many additional epochs\n     you want to train for.\n \n ","execution_count":null},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.layers import Dense, Activation,Dropout,Conv2D, MaxPooling2D,BatchNormalization\nfrom tensorflow.keras.optimizers import Adam, Adamax\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Model, load_model, Sequential\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport time\nimport os\nfrom IPython.core.display import display, HTML\ndisplay(HTML(\"<style>.container { width:100% !important; }</style>\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def wrapup (output_dir,subject, accuracy, image_size, model, weights,run_num, kaggle):\n    if accuracy >= 95:\n        msg=f'With an accuracy of {accuracy:5.2f} % the results appear satisfactory'\n        print_in_color(msg, (0,255,0),(0,0,0))\n        if kaggle:\n            save_model(output_dir, subject, accuracy, image_size ,model_size, model, weights)            \n            print ('*********************Process is completed******************************')            \n            return [False, None]        \n    elif accuracy >=85 and accuracy < 95:\n        if kaggle:\n            if run_num==2:\n                save_model(output_dir, subject, accuracy, image_size ,model_size, model, weights) \n                print ('*********************Process is completed******************************')\n                return [False, None]\n            else:\n                print('running for 6 more epochs to see if accuracy improves')\n                return[True,6] # run for 8 more epochs\n        else:\n            msg=f'With an accuracy of {accuracy:5.2f} % the results are mediocure. Try running more epochs'\n            print_in_color(msg, (255,0,0),(0,0,0))\n            \n    else:\n        if kaggle:\n            if run_num==2:\n                save_model(output_dir, subject, accuracy, image_size ,model_size, model, weights) \n                print ('*********************Process is completed******************************')\n                return [False, None]\n            else:\n                print('Running for 8 more epochs to see if accuracy improves')\n                return[True,8] # run for 8 more epochs\n        else:\n            msg=f'With an accuracy  of {accuracy:5.2f} % the results would appear to be unsatisfactory'\n            print_in_color(msg, (255,0,0),(0,0,0))\n            msg='You might try to run for more epochs or get more training data '\n            msg=msg + 'or perhaps crop your images so the desired subject takes up most of the image'\n            print_in_color(msg, (255,255,255), (0,0,0))\n            \n    \n    tryagain=True\n    if kaggle==False:\n        while tryagain==True:\n            ans=input('To continue training from where it left off enter the number of additional epochs or enter H to halt  ')\n            if ans =='H' or ans == 'h':\n                run=False\n                tryagain=False\n                save_model(output_dir, subject, accuracy, image_size ,model_size, model, weights) \n                print ('*********************Process is completed******************************')\n                return [run,None]\n            else:\n                try:\n                    epochs=int(ans)\n                    run=True\n                    tryagain=False\n                    return [run,epochs]\n                except ValueError:\n                    msg=f'\\nyour entry {ans} was neither H nor an integer- re-enter your response'\n                    print_in_color(msg, (255,0,0), (0,0,0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def display_pred(output_dir, pred, file_names, labels, subject, model_size,classes, kaggle):    \n    trials=len(labels)\n    errors=0\n    e_list=[]\n    prob_list=[]\n    true_class=[]\n    pred_class=[]\n    x_list=[]\n    index_list=[]\n    pr_list=[]\n    error_msg=''    \n    for i in range (0,trials):\n        p_class=pred[i].argmax()\n        if p_class !=labels[i]: #if the predicted class is not the same as the test label it is an error\n            errors=errors + 1\n            fname=os.path.basename(file_names[i])\n            e_list.append(fname)  # list of file names that are in error\n            true_class.append(classes[labels[i]]) # list classes that have an eror\n            pred_class.append(classes[p_class]) #class the prediction selected\n            prob_list.append(100 *pred[i][p_class])# probability of the predicted class\n            add_msg='{0:^24s}{1:5s}{2:^20s}\\n'.format(classes[labels[i]], ' ', file_names[i])\n            error_msg=error_msg + add_msg\n            \n    accuracy=100*(trials-errors)/trials\n    msg=f'\\n There were {errors} errors in {trials} trials for an accuracy of {accuracy:7.3f}'\n    print_in_color(msg, (0,255,0),(0,0,0))\n    if kaggle==True and errors<26:\n        ans='Y'\n    else:\n        ans='N'\n    if kaggle==False:\n        ans=input('To see a listing of prediction errors enter Y to skip press Enter\\n ')\n    if ans== 'Y' or ans  =='y':\n        msg='{1:^20s}{0:3s}{2:^20s}{0:3s}{3:^20s}{0:5s}{4}'\n        msg=msg.format( ' ', 'File Name', 'True Class', 'Predicted Class', 'Probability')\n        print_in_color(msg, (0,0,255), (255,255,0))\n        for i in range(0,errors):\n            msg='{0}{1:^20s}{0:3s}{2:^20s}{0:3s}{3:^20s}{0:5s}{4:^6.2f}'\n            print (msg.format(' ',e_list[i], true_class[i], pred_class[i], prob_list[i]))\n    if kaggle==True:\n        ans='Y'\n    else:\n        ans=input('\\nDo you want to save the list of error files?. Enter Y to save or press Enter to not save  ')\n    if ans=='Y' or ans=='y':\n        acc='{0:6.2f}'.format(accuracy)\n        if model_size=='L':\n            ms='Large'\n        elif model_size=='M':\n            ms= 'Medium'\n        else:\n            ms= 'Small'\n        header='Classification subject: {0} There were {1} errors in {2} tests for an accuracy of {3} using a {4} model\\n'.format(subject,errors,trials,acc,ms)\n        header= header +'{0:^24s}{1:5s}{2:^20s}\\n'.format('CLASS',' ', 'FILENAME') \n        error_msg=header + error_msg\n        file_id='error list-' + model_size + acc +'.txt'\n        file_path=os.path.join(output_dir,file_id)\n        f=open(file_path, 'w')\n        f.write(error_msg)\n        f.close()\n    for c in classes:\n        count=true_class.count(c)\n        x_list.append(count)\n        pr_list.append(c)\n    for i in range(0, len(x_list)):  # only plot classes that have errors\n        if x_list[i]==0:\n            index_list.append(i)\n    for i in sorted(index_list, reverse=True):  # delete classes with no errors\n        del x_list[i]\n        del pr_list[i]      # use pr_list - can't change class_list must keep it fixed\n    fig=plt.figure()\n    fig.set_figheight(len(pr_list)/4)\n    fig.set_figwidth(6)\n    plt.style.use('fivethirtyeight')\n    for i in range(0, len(pr_list)):\n        c=pr_list[i]\n        x=x_list[i]\n        plt.barh(c, x, )\n        plt.title( subject +' Classification Errors on Test Set')\n    if errors>0:\n        plt.show()\n    if kaggle==False:\n        ans=input('Press Enter to continue')\n    return accuracy        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def save_model(output_dir,subject, accuracy, image_size,model_size, model, weights):\n    # save the model with the  subect-accuracy.h5\n    acc=str(accuracy)[0:5]\n    id=subject + '-' + model_size + '-' +str(image_size) + '-' + acc + '.h5'    \n    model.set_weights(weights)\n    model_save_path=os.path.join(output_dir,id)    \n    model.save(model_save_path)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_predictions( model, weights, test_gen, lr):\n    config = model.get_config()\n    pmodel = Model.from_config(config)  # copy of the model\n    pmodel.set_weights(weights) #load saved weights with lowest validation loss\n    pmodel.compile(Adam(lr=lr), loss='categorical_crossentropy', metrics=['accuracy'])    \n    print('Training has completed. Now loading test set to see how accurate the model is')\n    results=pmodel.evaluate(test_gen, verbose=0)\n    accuracy=results[1]*100\n    print('Model accuracy on Test Set is {0:7.2f} %'.format(results[1]* 100))\n    predictions=pmodel.predict_generator(test_gen, verbose=0)        \n    return (predictions,accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def tr_plot(tacc,vacc,tloss,vloss):\n    #Plot the training and validation data\n    Epoch_count=len(tloss)\n    Epochs=[]\n    for i in range (0,Epoch_count):\n        Epochs.append(i+1)\n    index_loss=np.argmin(vloss)#  this is the epoch with the lowest validation loss\n    val_lowest=vloss[index_loss]\n    index_acc=np.argmax(vacc)\n    val_highest=vacc[index_acc]\n    plt.style.use('fivethirtyeight')\n    sc_label='best epoch= '+ str(index_loss+1)\n    vc_label='best epoch= '+ str(index_acc + 1)\n    fig,axes=plt.subplots(nrows=1, ncols=2, figsize=(15,5))\n    axes[0].plot(Epochs,tloss, 'r', label='Training loss')\n    axes[0].plot(Epochs,vloss,'g',label='Validation loss' )\n    axes[0].scatter(index_loss+1,val_lowest, s=150, c= 'blue', label=sc_label)\n    axes[0].set_title('Training and Validation Loss')\n    axes[0].set_xlabel('Epochs')\n    axes[0].set_ylabel('Loss')\n    axes[0].legend()\n    axes[1].plot (Epochs,tacc,'r',label= 'Training Accuracy')\n    axes[1].plot (Epochs,vacc,'g',label= 'Validation Accuracy')\n    axes[1].scatter(index_acc+1,val_highest, s=150, c= 'blue', label=vc_label)\n    axes[1].set_title('Training and Validation Accuracy')\n    axes[1].set_xlabel('Epochs')\n    axes[1].set_ylabel('Accuracy')\n    axes[1].legend()\n    plt.tight_layout\n    #plt.style.use('fivethirtyeight')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(model, callbacks, generators, epochs,start_epoch):\n    # steps_list[0]=training steps, steps_list[2]=validations steps\n    start=time.time()\n    data = model.fit_generator(generator = generators[0], validation_data= generators[2], \n                               epochs=epochs, initial_epoch=start_epoch,\n                               callbacks = callbacks, verbose=1)\n    #data=model.fit(x=generators[0],  epochs=epochs, verbose=1, \n    #               callbacks=callbacks,  validation_data=generators[2], shuffle=True,  initial_epoch=start_epoch) \n       \n    stop=time.time()\n    duration = stop-start\n    hrs=int(duration/3600)\n    mins=int((duration-hrs*3600)/60)\n    secs= duration-hrs*3600-mins*60\n    msg=f'Training took\\n {hrs} hours {mins} minutes and {secs:6.2f} seconds'\n    print_in_color(msg, (0,0,255),(0,0,0))\n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_model(classes,lr_rate, image_size,model_size,dropout, rand_seed):\n    size=len(classes)\n    mobile = tf.keras.applications.mobilenet.MobileNet( include_top=False,\n                                                           input_shape=(image_size,image_size,3),\n                                                           pooling='max', weights='imagenet',\n                                                           alpha=1, depth_multiplier=1,dropout=.4)\n    x=mobile.layers[-1].output\n    if model_size=='S':\n        pass\n       # x=Dense(128, kernel_regularizer = regularizers.l2(l = 0.016),activity_regularizer=regularizers.l1(0.006),\n                #bias_regularizer=regularizers.l1(0.006) ,activation='relu')(x)\n        #x=Dropout(rate=dropout, seed=rand_seed)(x) \n    elif model_size=='M':\n        x=Dense(256, kernel_regularizer = regularizers.l2(l = 0.016),activity_regularizer=regularizers.l1(0.006),\n                bias_regularizer=regularizers.l1(0.006),activation='relu')(x)\n        x=Dropout(rate=dropout, seed=rand_seed)(x) \n        x=keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001 )(x)\n        x=Dense(16, kernel_regularizer = regularizers.l2(l = 0.016),activity_regularizer=regularizers.l1(0.006),\n                bias_regularizer=regularizers.l1(0.006),activation='relu')(x)\n        x=Dropout(rate=dropout, seed=rand_seed)(x)\n    else:\n        x=Dense(1024, kernel_regularizer = regularizers.l2(l = 0.016),activity_regularizer=regularizers.l1(0.006),\n                bias_regularizer=regularizers.l1(0.006),activation='relu')(x)\n        x=Dropout(rate=dropout, seed=rand_seed)(x) \n        x=keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001 )(x)\n        x=Dense(128, kernel_regularizer = regularizers.l2(l = 0.016),activity_regularizer=regularizers.l1(0.006),\n                bias_regularizer=regularizers.l1(0.006),activation='relu')(x)\n        x=Dropout(rate=dropout, seed=rand_seed)(x)\n        x=keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001 )(x)\n        x=Dense(16, kernel_regularizer = regularizers.l2(l = 0.016),activity_regularizer=regularizers.l1(0.006),\n                bias_regularizer=regularizers.l1(0.006),activation='relu')(x)\n        x=Dropout(rate=dropout, seed=rand_seed)(x)        \n    x=keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001 )(x)\n    predictions=Dense (len(classes), activation='softmax')(x)\n    model = Model(inputs=mobile.input, outputs=predictions)    \n    for layer in model.layers:\n        layer.trainable=True\n    model.compile(Adamax(lr=lr_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n    return model\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_generators( paths, mode, split, classes, image_size, rand_seed):\n    #paths[0]=train path,paths[1]=test path paths[2]= valid path paths[3]=classes\n    split=split/100.0    \n    if image_size==224:\n        batch_size=85\n    elif image_size==192:\n        batch_size=120\n    elif image_size==160:\n        batch_size=170\n    else:\n        batch_size=260\n    if mode == 'SEP': \n        train_gen=ImageDataGenerator(preprocessing_function=keras.applications.mobilenet.preprocess_input).flow_from_directory(paths[0],\n                target_size=(image_size, image_size), batch_size=batch_size, seed=rand_seed, class_mode='categorical', color_mode='rgb')\n        \n        valid_gen=ImageDataGenerator(preprocessing_function=keras.applications.mobilenet.preprocess_input) .flow_from_directory(paths[2], \n                target_size=(image_size, image_size), batch_size=batch_size,\n                seed=rand_seed, class_mode='categorical',color_mode='rgb', shuffle=False)\n        \n        test_gen=ImageDataGenerator(preprocessing_function=keras.applications.mobilenet.preprocess_input).flow_from_directory(paths[1],\n                target_size=(image_size, image_size), batch_size=batch_size, class_mode='categorical',color_mode='rgb',\n                seed=rand_seed, shuffle=False )\n        file_names=test_gen.filenames          \n        labels=test_gen.labels               \n        return [[train_gen, test_gen, valid_gen], file_names, labels]                  \n    else:        \n        # all data is in a single directory there are no test images use validation images as test images\n        train_gen=ImageDataGenerator(preprocessing_function=keras.applications.mobilenet.preprocess_input,\n                             validation_split=split).flow_from_directory(paths[0],\n                                                                                    target_size=(image_size, image_size),\n                                                                                    batch_size=batch_size,\n                                                                                    subset='training',seed=rand_seed)\n        valid_gen=ImageDataGenerator(preprocessing_function=keras.applications.mobilenet.preprocess_input,\n                                    validation_split=split).flow_from_directory(paths[0],\n                                                                                    target_size=(image_size, image_size),\n                                                                                    batch_size=batch_size,\n                                                                                    subset='validation',\n                                                                                    seed=rand_seed, shuffle=False)\n        file_names= valid_gen.filenames\n        labels= valid_gen.labels\n    return [[train_gen, valid_gen, valid_gen], file_names, labels]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_paths(source_dir,output_dir,mode,subject,classes): \n    class_count=len(classes)\n    if mode =='ALL':\n        # all data is in a single directory must be split into train, test, valid data sets \n        train_path=source_dir\n        test_path=None        \n        valid_path=None       \n    else:\n        # data is seperated in 3 directories train, test, valid\n        test_path=os.path.join(source_dir,'test')\n        train_path=os.path.join(source_dir, 'train')\n        valid_path=os.path.join(source_dir,'valid')                  \n    # save the class dictionary as a text file so it can be used by predictor.py in the future\n    #saves file as subject.txt  structure is similar to a python dictionary\n    msg=''\n    for i in range(0, class_count):\n        msg=msg + str(i) + ':' + classes[i] +','\n    id=subject +'-' + str(class_count)  + '.txt'   \n    dict_path=os.path.join (output_dir, id)\n    f=open(dict_path, 'w')\n    f.write(msg)\n    f.close()    \n    return [train_path, test_path, valid_path]\n      ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def check_inputs(source_dir, out_dir, split, image_size,model_size,dropout):\n    status=True\n    if os.path.isdir(source_dir)==False:\n        msg=f'The source directory you specified {source_dir} does not exist - program terminating'\n        status=False\n    elif len(os.listdir(source_dir))<2:\n        msg=f'directory {source_dir} must have at least 2 sub directories'\n        status=False\n    elif image_size not in [224,192,160,128]:\n        msg=f'the images size you specified {image_size} is not one of 224,192,160 or 128 - program terminating' \n        status=False\n    elif dropout <0.0 or dropout>1.0:\n        msg=f'The drop out value you specified {dropout} must be a value between 0.0 and 1.0 - program terminating'\n        status=False\n    elif model_size not in ['L', 'M', 'S']:\n        msg=f'The model size you specified {model_size} must be as single charater string either L, M, or S'\n        status=False\n    elif os.path.isdir(out_dir)==False:\n        msg=f'The output directory you specified {out_dir} does not exist - program terminating'\n        status=False\n    else:        \n        status=True\n        msg=f'ERROR you must have a test, train and a valid subdirectory in {source_dir}'\n        source_list=os.listdir(source_dir)       \n        if ('test' in source_list and 'train' not in source_list) or ('test' in source_list and 'valid' not in source_list):\n            print_in_color(msg,(255,0,0),(0,0,0))\n            status=False                \n        elif ('train' in source_list and 'test' not in source_list) or ('train' in source_list and 'valid' not in source_list):\n            print_in_color(msg,(255,0,0),(0,0,0))\n            status=False                \n        elif ('valid' in source_list and 'train' not in source_list) or ('valid' in source_list and 'test' not in source_list): \n            print_in_color(msg,(255,0,0),(0,0,0))\n            status=False                 \n        else: \n            if 'test' in source_list:\n                test_path=os.path.join(source_dir,'test')\n                train_path=os.path.join(source_dir,'train')\n                valid_path=os.path.join(source_dir,'valid')\n                test_list=sorted(os.listdir(test_path))\n                train_list=sorted(os.listdir(train_path))\n                valid_list=sorted(os.listdir(valid_path)) \n                for i in range (0, len(test_list)):\n                    if test_list[i] != train_list[i] or test_list[i] !=valid_list[i] or train_list[i] != valid_list[i]:\n                        print(i, test_list[i], train_list[i], valid_list[i])\n                if train_list != test_list or train_list != valid_list or test_list !=valid_list:\n                    status=False\n                    msg='class directories must have identical names in the train, test and valid directories- program terminating'\n                elif len(test_list) <2 or len(valid_list)<2 or len(train_list)<2:\n                    status=False\n                    msg=' the train, test and valid directories must have at least 2 class sub directories - program terminating'\n            else:\n                if len(os.listdir(source_dir))<2:\n                    msg=f'The must be at least 2 subdirectories in {source_dir}'\n                    status=False\n                elif split==None or split<1 or split>100:\n                    msg=f'the split parameter you specied {split} must be between 0 and 100 when class directories are in the source directory- program terminating'\n                    status=False\n                else:\n                    mode='ALL'\n                \n    if status==False:\n        print_in_color(msg, (255,0,0), (0,0,0))\n        return (False, None,None)\n    else:\n        source_list=os.listdir(source_dir)\n        if 'test' in source_list:\n            mode='SEP'\n            class_path=os.path.join(source_dir, 'test')\n            classes=os.listdir(class_path)\n        else:\n            mode='ALL'\n            classes=source_list\n        return(True, mode, classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def TF2_classify(source_dir,out_dir,subject, split, epochs,lr_rate,image_size, model_size, dropout, rand_seed,dwell, kaggle):\n    model_size=model_size.upper()\n    if kaggle:\n        out_dir=r'/kaggle/working'\n    status, mode, classes=check_inputs(source_dir, out_dir,split, image_size,model_size, dropout) \n    if status==False:\n        return False\n    paths=get_paths(source_dir,output_dir,mode,subject,classes)\n    generators, file_names,labels= make_generators( paths, mode, split, classes, image_size, rand_seed)\n    model=make_model(classes,lr_rate, image_size,model_size,dropout, rand_seed)\n    \n                           \n    class lradjust(tf.keras.callbacks.Callback):\n        # functions in this class adjust the learning rate \n        lowest_loss=np.inf\n        best_weights=model.get_weights()\n        lr=float(tf.keras.backend.get_value(model.optimizer.lr))\n        epoch=0\n        tr_highest_acc=0        \n        def __init__(self):\n            super(lradjust, self).__init__()\n            self.lowest_loss=np.inf\n            self.best_weights=model.get_weights()\n            self.lr=float(tf.keras.backend.get_value(model.optimizer.lr))\n            self.epoch=0\n            self.tr_highest_acc=0            \n        def on_epoch_end(self, epoch, logs=None):                     \n            lradjust.lr=float(tf.keras.backend.get_value(self.model.optimizer.lr))\n            lradjust.epoch=lradjust.epoch +1            \n            v_loss=logs.get('val_loss')  # get the validation loss for this epoch\n            tr_acc=logs.get('accuracy')  # get the training accuracy for this epoch\n            if lradjust.tr_highest_acc<tr_acc:  # check if the accuracy for this epoch is the highest accuracy thus far\n                lradjust.tr_highest_acc=tr_acc  # replace the highest accuracy with the accuracy for this epoch\n                if lradjust.tr_highest_acc<.95:  # check if accuracy exceecs .95 if it is then save the weights\n                    lradjust.best_weights=model.get_weights()\n                    msg=f' \\n saving weights with new highest accuracy of  {lradjust.tr_highest_acc:7.4f} '\n                    print_in_color(msg, (255, 255,0), (0,0,0))\n            if tr_acc<=.95 and tr_acc<lradjust.tr_highest_acc:\n                # reduce lr because training accuracy went below highest accuracy\n                lr=float(tf.keras.backend.get_value(self.model.optimizer.lr))\n                ratio=tr_acc/lradjust.tr_highest_acc  # add a factor to lr reduction\n                new_lr=lr * .5 * ratio\n                tf.keras.backend.set_value(model.optimizer.lr, new_lr)\n                msg=f'\\n current accuracy {tr_acc:7.4f} is below the highest accuracy of {lradjust.tr_highest_acc:7.4f},reducing learning rate to {new_lr:11.9f}'\n                print_in_color(msg, (255,0,0),(0,0,0)) \n                if dwell:\n                    model.set_weights(lradjust.best_weights)  # ignore the new weights and load the best weights\n                    msg='\\nsetting weights back to best weights'\n                    print_in_color(msg,( 255,0,0),(0,0,0))\n            if lradjust.lowest_loss > v_loss and lradjust.tr_highest_acc>.95:\n                #accuracy is above 95% and the new validation loss is the lowest loss thus far so save the weights\n                msg=f'\\n validation loss improved to {v_loss:7.4f} from {lradjust.lowest_loss:7.4f} saving weights'\n                print_in_color(msg, (0,255,0), (0,0,0))\n                lradjust.lowest_loss=v_loss\n                lradjust.best_weights=model.get_weights()\n                \n            else:\n                 if tr_acc>.95 and lradjust.lowest_loss<v_loss:\n                        # reduce learning rate based on validation loss> val.best_loss\n                        lr=float(tf.keras.backend.get_value(self.model.optimizer.lr))\n                        ratio=lradjust.lowest_loss/v_loss  # add a factor to lr reduction\n                        new_lr=lr * .7 * ratio\n                        tf.keras.backend.set_value(model.optimizer.lr, new_lr)\n                        msg=f'\\n current validation loss {v_loss:7.4f} exceeds lowest loss of {lradjust.lowest_loss:7.4f}, reducing lr to {new_lr:11.9f}'\n                        print_in_color(msg, (255,0,0), (0,0,0))\n                        if dwell:\n                            model.set_weights(lradjust.best_weights)  # ignore the new weights and load the best weights\n                            msg='\\nsetting weights back to best weights'\n                            print_in_color(msg,( 255,0,0),(0,0,0))\n                \n    callbacks=[lradjust()] \n    run_num=0\n    run=True\n    tacc=[]\n    tloss=[]\n    vacc=[]\n    vloss=[]\n    start_epoch=0\n    while run:\n        run_num=run_num +1\n        if run_num==1:\n            print(' Starting Training Cycle')\n        else:\n            print('Resuming training from epoch {0}'.format(start_epoch))\n        results=train(model,callbacks, generators, epochs,start_epoch) \n        # returns data from training the model - append the results for plotting\n        tacc_new=results.history['accuracy']\n        tloss_new=results.history['loss']\n        vacc_new =results.history['val_accuracy']\n        vloss_new=results.history['val_loss']\n        for d in tacc_new:  # need to append new data from training to plot all epochs\n            tacc.append(d)\n        for d in tloss_new:\n            tloss.append(d)\n        for d in vacc_new:\n            vacc.append(d)\n        for d in vloss_new:\n            vloss.append(d)       \n        last_epoch=results.epoch[len(results.epoch)-1] # this is the last epoch run\n        tr_plot(tacc,vacc,tloss,vloss) # plot the data on loss and accuracy\n        bestw=lradjust.best_weights  # these are the saved weights with the lowest validation loss\n        lr_rate=lradjust.lr \n        pred, accuracy=make_predictions( model, bestw, generators[1], lr_rate)\n        display_pred(out_dir, pred, file_names, labels, subject, model_size,classes, kaggle)\n        decide=wrapup(out_dir,subject, accuracy, image_size, model, bestw,run_num, kaggle)\n        run=decide[0]        \n        if run==True:\n            epochs=last_epoch + decide[1]+1\n            start_epoch=last_epoch +1 \n        else:\n            return True\n        \n        \n            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def print_in_color(txt_msg,fore_tupple,back_tupple,):\n    #prints the text_msg in the foreground color specified by fore_tupple with the background specified by back_tupple \n    #text_msg is the text, fore_tupple is foregroud color tupple (r,g,b), back_tupple is background tupple (r,g,b)\n    rf,gf,bf=fore_tupple\n    rb,gb,bb=back_tupple\n    msg='{0}' + txt_msg\n    mat='\\33[38;2;' + str(rf) +';' + str(gf) + ';' + str(bf) + ';48;2;' + str(rb) + ';' +str(gb) + ';' + str(bb) +'m' \n    print(msg .format(mat))\n    print('\\33[0m') # returns default print color to back to black\n    return","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"source_dir=r'/kaggle/input/100-bird-species'\noutput_dir=r'/kaggle/working'\nsubject='birds'\nsplit=8\nepochs=20\nlr_rate=.005\nimage_size=224\nmodel_size='s'\ndropout=.1\nrand_seed=12357\ndwell=False\nkaggle=True\nstatus=TF2_classify(source_dir,output_dir,subject, split, epochs,lr_rate,image_size, model_size, dropout, rand_seed,dwell, kaggle)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}