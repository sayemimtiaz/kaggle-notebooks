{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nimport math\n\ndf = pd.read_csv('/kaggle/input/data-analyst-jobs/DataAnalyst.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Import and Cleaning\nWhat I would like to do:\n1. Parse Lower and Upper Bound of Salary Estiamte\n2. Remove Rating from Company Name\n3. Remove Unnamed: 0 Column\n4. Properly handle missing data\n\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.replace(['-1'], [np.nan], inplace=True)\ndf.drop(columns = ['Unnamed: 0'], inplace=True)\n\ndef get_salary_lb(text):\n    if text != text:\n        lb = np.nan\n    else:\n        text = text.replace(\"$\", \"\")\n        lower, _ = text.split('-')\n        lb = int(lower.replace(\"K\", \"\"))\n    return lb\n\n\ndef get_salary_ub(text):\n    if text != text:\n        ub = np.nan\n    else:\n        text = text.replace(\"$\", \"\")\n        _, upper = text.split('-')\n        upper, _ = upper.split(\"(\")\n        upper = upper.replace(\"K\", \"\")\n        ub = int(upper.strip())\n    return ub\n\n\ndef clean_name(text):\n    name = np.nan\n    if text == text:\n        if '\\n' in text:\n            name, _ = text.split('\\n')\n    return name\n    \ndf['salary_lb'] = df['Salary Estimate'].apply(lambda x: get_salary_lb(x))\ndf['salary_ub'] = df['Salary Estimate'].apply(lambda x: get_salary_ub(x))\ncol_salary = df.loc[: , [\"salary_lb\", \"salary_ub\"]]\ndf['salary_mean'] = col_salary.mean(axis=1)\n\ndf['company_name_clean'] = df['Company Name'].apply(lambda x: clean_name(x))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Exploration and Visualization","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"sns.set(style=\"ticks\", color_codes=True)\nplt.style.use('fivethirtyeight')\n\nplt.figure(figsize=(15,5))\ng = sns.countplot(x='Industry',data=df, order=df.Industry.value_counts().iloc[:50].index)\ng.set_xticklabels(g.get_xticklabels(), rotation=40, ha=\"right\")\n#g.fig.set_size_inches(20, 10)\nplt.title('Top 50 Industries by Job Posts')\nplt.ylabel('')\nplt.xlabel('')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The top 2 industries (IT Services and Staffing & Outsourcing) make up 34% of all Data Analyst jobs with a non-null Industry label. My guess would be that a lot of hiring is done by an intermediary Staffing & Outsourcing company, which might be recorded as the Industry for the job as opposed to the actual job Industry. \n\nThe top 10 industries account for 70% of all Data Analyst jobs. This is as expected, since different industries have different needs.","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"sns.set(style=\"ticks\", color_codes=True)\nplt.style.use('fivethirtyeight')\n\n\ng = sns.catplot(x=\"salary_lb\", y=\"Industry\", kind=\"box\", data=df, order=df.Industry.value_counts().iloc[:20].index)\ng.set(xlim=(20, 125))\ng.fig.set_size_inches(30, 10)\ng.ax.set_xticks([25,50,75,100,125], minor=True)\nplt.title(\"Salary Lower Bound - Ordered by Most Common Industries\")\nplt.ylabel(\"\")\nplt.xlabel(\"\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Not all Industries are created equal. Which industries are the most and lest lucrative? ","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df_sal = df.groupby(\"Industry\").median().sort_values(by = 'salary_lb', ascending=False)\ng = sns.catplot(x=\"salary_lb\", y=\"Industry\", kind=\"box\", data=df, order=df_sal.iloc[:25].index)\ng.set(xlim=(20, 125))\ng.fig.set_size_inches(30, 10)\ng.ax.set_xticks([25,50,75,100,125], minor=True)\nplt.title(\"Salary Lower Bound - Ordered by Median Salary\")\nplt.ylabel(\"\")\nplt.xlabel(\"\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This would be more useful if we had some sort of cutoff for number of job postings by industry. Let's only look at Industries with more than 10 job postings (this accounts for 88% of all non-null Job Postings).","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"industry_counts = df.Industry.value_counts()\nCUTOFF = 10\n\ndroprows = []\nfor i in range(df.shape[0]):\n    industry = str(df.loc[i, \"Industry\"])\n    if industry != 'nan':\n        val = industry_counts[industry]\n        if val <= CUTOFF:\n            droprows.append(i)\n        \ndf_trim = df.drop(droprows)\n\ndf_sal = df_trim.groupby(\"Industry\").median().sort_values(by = 'salary_lb', ascending=False)\ng = sns.catplot(x=\"salary_lb\", y=\"Industry\", kind=\"box\", data=df, order=df_sal.iloc[:25].index)\ng.set(xlim=(20, 125))\ng.fig.set_size_inches(30, 10)\ng.ax.set_xticks([25,50,75,100,125], minor=True)\nplt.title(\"Salary Lower Bound - Ordered by Median Salary\")\nplt.ylabel(\"\")\nplt.xlabel(\"\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here is the salary upper bound version of the previous plot:","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"industry_counts = df.Industry.value_counts()\nCUTOFF = 10\n\ndroprows = []\nfor i in range(df.shape[0]):\n    industry = str(df.loc[i, \"Industry\"])\n    if industry != 'nan':\n        val = industry_counts[industry]\n        if val <= CUTOFF:\n            droprows.append(i)\n        \ndf_trim = df.drop(droprows)\n\ndf_sal = df_trim.groupby(\"Industry\").median().sort_values(by = 'salary_ub', ascending=False)\ng = sns.catplot(x=\"salary_ub\", y=\"Industry\", kind=\"box\", data=df, order=df_sal.iloc[:25].index)\ng.set(xlim=(30, 180))\ng.fig.set_size_inches(30, 10)\ng.ax.set_xticks([25,50,75,100,125], minor=True)\nplt.title(\"Salary Upper Bound - Ordered by Median Salary\")\nplt.ylabel(\"\")\nplt.xlabel(\"\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"from geopy.geocoders import Nominatim\nfrom tqdm.notebook import tqdm\n\ngeolocator = Nominatim(user_agent = \"jb_kaggle\")\nunique_locs = df[\"Location\"].unique()\nlocs_dict = {}\n\ndf.replace('Northbrook, IL', 'Deerfield, IL', inplace=True)\n\nfor loc_name in tqdm(unique_locs):\n    if str(loc_name) != 'nan':\n        if 'CA' in loc_name:\n            loc_name = loc_name.replace(\"CA\", \"California\")\n        if 'IL' in loc_name:\n            loc_name = loc_name.replace(\"IL\", \"Illinois\")\n        if 'PA' in loc_name:\n            loc_name = loc_name.replace(\"PA\", \"Pennsylvania\")\n        if 'Monaco,' in loc_name:\n            loc_name = 'Lawndale, California, United States'\n        location = geolocator.geocode(loc_name)\n        if location is not None:\n            lat = location.latitude\n            long = location.longitude\n            locs_dict[loc_name] = [lat, long]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import folium\n\ndf.reset_index(inplace=True)\n\nfor i in range(df.shape[0]):\n    long = np.nan\n    lat = np.nan\n    my_loc = str(df.loc[i, 'Location'])\n    if 'CA' in my_loc:\n        my_loc = my_loc.replace('CA', 'California')\n    if 'IL' in my_loc:\n        my_loc = my_loc.replace(\"IL\", \"Illinois\")\n    if 'PA' in my_loc:\n        my_loc = my_loc.replace(\"PA\", \"Pennsylvania\")\n    if 'Monaco,' in my_loc:\n        my_loc = 'Lawndale, California, United States'\n    if my_loc != 'nan' and my_loc in locs_dict.keys():\n        coords = locs_dict[my_loc]\n        long = coords[1]\n        lat = coords[0]\n    df.loc[i, 'long'] = long\n    df.loc[i, 'lat'] = lat\n    \nfrom folium import plugins\n\ndf_loc = df.dropna(subset=['long'])\nheat_map = folium.Map([41.8781, -87.6298], zoom_start=3)\nlocationArr = df_loc[['lat', 'long']]\nheat_map.add_child(plugins.HeatMap(locationArr, radius=15))\nheat_map","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"from sklearn.cluster import KMeans\nfrom sklearn.datasets import make_blobs\nfrom yellowbrick.cluster import KElbowVisualizer\n\nX = df_loc[['lat', 'long']]\n\n# Instantiate the clustering model and visualizer\nmodel = KMeans()\nvisualizer = KElbowVisualizer(model, k=(4,20))\n\nvisualizer.fit(X)        # Fit the data to the visualizer\nvisualizer.show() \n\nkmeans = KMeans(n_clusters = 8, random_state=0).fit(X)\nkmeans.cluster_centers_\n\ncluster_map = folium.Map([41.8781, -87.6298], zoom_start=3)\nfor i in range(kmeans.cluster_centers_.shape[0]):\n    num = sum(kmeans.labels_ == i)\n    folium.CircleMarker([kmeans.cluster_centers_[i,0], kmeans.cluster_centers_[i,1]],\n                        radius=15,\n                        popup=str(num) + ' Jobs Associated with this Cluster',\n                        fill_color=\"#3db7e4\", # divvy color\n                        ).add_to(cluster_map)\ncluster_map\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This clustering gives us approximate job \"regions\":\n1. The Northeast [604 Jobs]\n2. Southeastern Texas [397 Jobs]\n3. Southern California [365 Jobs]\n4. Northern California [355 Jobs]\n5. The Midwest [222 Jobs]\n6. Rocky Mountain [129 Jobs]\n7. The South [124 Jobs]\n8. Pacific Northwest [54 Jobs]","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"my_colors = ['#E6B0AA', '#EC7063', '#AF7AC5', '#7D3C98', '#5499C7', '#AED6F1 ', '#A3E4D7', '#16A085', '#229954', '#58D68D', '#F7DC6F', '#F5B041', '#AF601A', '#6E2C00', '#7F8C8D', '#D3D633', '#751693', '#684050', '#8493C6', '#9948CD', '#1A3F71', '#5BD474', '#044E13', '#DA7E1D', '#EEACE6']\nkmeans = KMeans(n_clusters = 24, random_state=0).fit(X)\nkmeans.cluster_centers_\n\nm = folium.Map([41.8781, -87.6298], zoom_start=3)\nfor i in range(kmeans.cluster_centers_.shape[0]):\n    num = sum(kmeans.labels_ == i)\n    folium.CircleMarker([kmeans.cluster_centers_[i,0], kmeans.cluster_centers_[i,1]],\n                        radius=30,\n                        popup=str(num) + ' Jobs Associated with Cluster ' + str(i),\n                        fill_color=my_colors[i],\n                        fill_opacity = 0.8,# divvy color\n                        ).add_to(m)\nfor i in range(df_loc.shape[0]):\n    folium.CircleMarker([df_loc.loc[i, 'lat'], df_loc.loc[i, 'long']],\n                        radius=15,\n                        popup=df_loc.loc[i, 'Location'],\n                        fill_color=my_colors[kmeans.labels_[i]],\n                        fill_opacity = 1,# divvy color\n                        ).add_to(m)\nm","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we can see which metro area each job is associated with. There are a few minor discrepancies, like how SF Bay is split into two metro areas and a job that should be associated with Louisville is grouped with Indianapolis, but we can deal with that later.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"metro_areas = ['Chicago, IL',\n               'Los Angeles, CA',\n               'New York City, NY',\n               'Dallas, TX',\n               'SF Bay (San Francisco), CA',\n               'Denver, CO',\n               'Charlotte, NC',\n               'Seattle, WA',\n               'Phoenix, AZ',\n               'Austin, TX',\n               'Salt Lake City, UT',\n               'Norfolk, VA',\n               'Columbus, OH',\n               'Jacksonville, FL',\n               'Houston, TX',\n               'Philadelphia, PA',\n               'San Diego, CA',\n               'Indianapolis, IN',\n               'Topeka, KS',\n               'SF Bay (San Jose), CA',\n               'San Antonio, TX',\n               'Atlanta, GA',\n               'Hanford, CA',\n               'Gainesville, FL']\n\nfor i in range(df_loc.shape[0]):\n    cluster = kmeans.labels_[i]\n    df_loc.loc[i, 'metro_area'] = metro_areas[cluster]\n\n    \nsns.set(style=\"ticks\", color_codes=True)\nplt.style.use('fivethirtyeight')\n\ng = sns.catplot(x=\"salary_lb\", y=\"metro_area\", kind=\"box\", data=df_loc, order=df_loc['metro_area'].value_counts().iloc[:25].index)\ng.set(xlim=(25, 150))\ng.fig.set_size_inches(30, 10)\ng.ax.set_xticks([50,75,100,125,150], minor=True)\nplt.title(\"Salary Lower Bound - Ordered by Most Common Metro Areas\")\nplt.show()\n\ndf_sal = df_loc.groupby(\"metro_area\").median().sort_values(by = 'salary_lb', ascending=False)\ng = sns.catplot(x=\"salary_lb\", y=\"metro_area\", kind=\"box\", data=df_loc, order=df_sal.iloc[:25].index)\ng.set(xlim=(25, 150))\ng.fig.set_size_inches(30, 10)\ng.ax.set_xticks([50,75,100,125,150], minor=True)\nplt.title(\"Salary Lower Bound - Ordered by Median Salary\")\nplt.show()\n\n               \n               \n               \n               \n               \n               \n               \n               \n               \n               \n               ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_loc.metro_area.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}