{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**FIRST WE GONNA READ OUR DATA**\n\n*Generally we don't need to write encoding='latin-1' but for this data we have to*\n\n*We have two data one of them fro crimes other one is for crime codes*"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"crime_df = pd.read_csv(\"../input/crime.csv\", encoding=\"latin-1\")\noffense_df = pd.read_csv(\"../input/offense_codes.csv\", encoding=\"latin-1\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**THEN WE JUST CHECKING OUR DATA **"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(crime_df.iloc[5],\"\\n############\") \nprint(offense_df.head(),\"\\n###########\")\nprint(crime_df.isnull().sum())     # it's showing nan values ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**DATA CLEANING**\n\n*I just drop shooting column cause it's have lots of nan values*\n\n*Then for the other nan values we just drop the line not the column*"},{"metadata":{"trusted":true},"cell_type":"code","source":"crime_df = crime_df.drop(columns='SHOOTING')\ncrime_df = crime_df.dropna(axis=0)\nprint(crime_df.isnull().sum(),\"\\nShape:\",crime_df.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**CRIME COUNT FOR EVERYDAY AND EVERY HOUR**\n\n*Friday is the first, it might be cause of last day of work for the most of people so people more aggresive in that day*\n\n*And at 17.00 there is more crime compared to other hours of day it's olsa might be cause of work *"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,8))    #We are giving the size of figure\nsns.countplot(x=crime_df.DAY_OF_WEEK)  #countplot taking counts of the columns which you choose \nplt.show() \n\nplt.figure(figsize=(8,8))    \nsns.countplot(x=crime_df.HOUR)  \nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**PIE PLOTTING**\n\n*It's look like people do more crazy things in the summer*"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,8))    #first size of figure\n\n#giving the name of piecies\nlabels = 'January', 'Febuary', 'March', 'April', 'May', 'Jun', 'July', 'August', 'September', 'October', 'November', 'December'\nsizes_month = []    \nfor i in range(12):\n    i+=1\n    sizes_month.append(len(crime_df[crime_df['MONTH']==i]))#count of crime for every month\n    \n\nexplode = (0, 0,0,0,0,0,0,0.2,0,0,0,0)  #In here we are choosing one piece of pie it's going out from the middle\n                               \nplt.pie(sizes_month, explode = explode, labels=labels,  \nautopct='%1.1f%%', shadow=True, startangle=90)\n\nplt.axis('equal')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**WORDCLOUD**\n\n*It's showing the most used words in the array if a word more used than others it will look much bigger*\n\n*As we can see in this data Vehicle Accident is the most bigger one*\n\n*for making wordcloud you have to merge every word and put them in an one array*\n\n*It must be like this [LarencyHomicideRobbery]*"},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud\ntext = []\nfor i in crime_df.OFFENSE_CODE_GROUP:\n    text.append(i)#here we are adding word to text array but it's looking like this ['Larency','Homicide','Robbery']\ntext = ''.join(map(str, text)) #Now we make all of them like this [LarencyHomicideRobbery]\n\nwordcloud = WordCloud(width=1600, height=800, max_font_size=300,background_color='white').generate(text)\nplt.figure(figsize=(20,17))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"year_count = []\n\nfor i in crime_df.YEAR.unique():\n    year_count.append(len(crime_df[crime_df['YEAR']==i]))\n\nplt.figure(figsize=(10,5))\nsns.pointplot(x=crime_df.YEAR.unique(),y=year_count,color='red',alpha=0.8)\nplt.xlabel('Year',fontsize = 15,color='blue')\nplt.xticks(rotation=45)\nplt.ylabel('Crime Count',fontsize = 15,color='blue')\nplt.title('Crime vs Year',fontsize = 15,color='blue')\nplt.grid()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**HERE IS BOSTON**\n\n*You can change projection from basemap and resolution we have 3 type c, l, h but we can't use h. Resolution is for quality of the map*\n\n*I try to use this plotting for Boston but I couldn't make it. It's not good for the city plotting cause it's doesn't matter which projection you use this plotting is not for the cityies.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"from mpl_toolkits.basemap import Basemap\n\nm = Basemap(projection='mill',llcrnrlat=25,urcrnrlat=49.5,\\\n            llcrnrlon=-140,urcrnrlon=-50,resolution='l')\n\nplt.figure(figsize=(25,17))\nm.drawcountries() #for drawing country borders\nm.drawstates()    #for drawing states borders\nm.drawcoastlines()\n#m.fillcontinents(color='#04BAE3', lake_color='#FFFFFF') #giving color \n\nlat = 42.361145\nlon = -71.057083\n\nx,y = m(lon,lat)\nm.plot(x, y, 'ro', markersize=20, alpha=.8) #alpha is making your marker transparent\n\nm.bluemarble() #With this it's make your map like from satellite but if you give colors it will not work\nm.drawmapboundary(color = '#FFFFFF')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**FOLIUM AND HEATMAP IT'S REALLY EASY TO USE AND IT'S GREAT**\n\n*You should only careful for data I mean if you give a big data to folium heatmap it will not gonna plotting or it take lots of time so you have to separate your data to piecies *\n\n*#We have to give latitude and longitude like this [[lat, lon],[lat, lon],[lat, lon],[lat, lon],[lat, lon]]*\n\n**ABOUT LARCENY**\n\n*Most of them around Newburry Street, Boylston Street, State Street and Downtown Crossing*"},{"metadata":{"trusted":true},"cell_type":"code","source":"import folium\nfrom folium.plugins import HeatMap\n\nmap_hooray = folium.Map(location=[42.361145,-71.057083],\n                    zoom_start = 12, min_zoom=12) #Giving the location just write boston coordinat to google\n\nheat_df = crime_df[crime_df['YEAR']==2017] # I take 2017 cause there is more crime against to other years\nheat_df = heat_df[heat_df['OFFENSE_CODE_GROUP']=='Larceny'] \nheat_df = heat_df[['Lat', 'Long']] #giving only latitude and longitude now in heat_df just latitude and longitude\n                                        #from 2017 larceny responde\n\n\n    \n    \nfolium.CircleMarker([42.356145,-71.064083],\n                    radius=50,\n                    popup='Homicide',\n                    color='red',\n                    ).add_to(map_hooray) #Adding mark on the map but it's hard to find correct place. \n                                         #it's take to muhc time\n    \n    \nheat_data = [[row['Lat'],row['Long']] for index, row in heat_df.iterrows()]\n#We have to give latitude and longitude like this [[lat, lon],[lat, lon],[lat, lon],[lat, lon],[lat, lon]]\n\nHeatMap(heat_data, radius=10).add_to(map_hooray) #Adding map_hooray to HeatMap\nmap_hooray #Plotting","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**ABOUT MOTOR VEHICLE ACCIDENT RESPONSE**\n\n*It's look everywhere is almost same accident it's mean thoese accident not cause of city road planning*\n\n*Probably it's cause of human mistakes*"},{"metadata":{"trusted":true},"cell_type":"code","source":"map_hooray = folium.Map(location=[42.361145,-71.057083],\n                    zoom_start = 12, min_zoom=12) \n\nheat_df = crime_df[crime_df['YEAR']==2017]\nheat_df = heat_df[heat_df['OFFENSE_CODE_GROUP']=='Motor Vehicle Accident Response']\nheat_df = heat_df[['Lat', 'Long']]\n\n\nheat_data = [[row['Lat'],row['Long']] for index, row in heat_df.iterrows()]\nHeatMap(heat_data, radius=10).add_to(map_hooray)\nmap_hooray","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**ABOUT DRUGS**\n\n*Downtown Crossing and Chinetown Crossing are the most drugs reporting *\n\n*Araound Boston Medical Center ??? *"},{"metadata":{"trusted":true},"cell_type":"code","source":"map_hooray = folium.Map(location=[42.340145,-71.057083],\n                    zoom_start = 13, min_zoom=13) \n\nheat_df = crime_df[crime_df['YEAR']==2017] \nheat_df = heat_df[heat_df['OFFENSE_CODE_GROUP']=='Drug Violation']\nheat_df = heat_df[['Lat', 'Long']]\n\n\nheat_data = [[row['Lat'],row['Long']] for index, row in heat_df.iterrows()]\nHeatMap(heat_data, radius=10).add_to(map_hooray)\nmap_hooray","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**ABOUT PROSTITUTION**\n\n*Honan-Allston Branch library and Dorchester Avenue road*"},{"metadata":{"trusted":true},"cell_type":"code","source":"map_hooray = folium.Map(location=[42.351145,-71.057083],\n                    zoom_start = 12, min_zoom=12) \n\nheat_df = crime_df[crime_df['YEAR']==2017] \nheat_df = heat_df[heat_df['OFFENSE_CODE_GROUP']=='Prostitution']\nheat_df = heat_df[['Lat', 'Long']]\n\nheat_data = [[row['Lat'],row['Long']] for index, row in heat_df.iterrows()]\nHeatMap(heat_data, radius=10).add_to(map_hooray)\nmap_hooray","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**ABOUT HOMICIDE**\n\n*Most of them between and around Roxbury, Dorchester and South Boston*"},{"metadata":{"trusted":true},"cell_type":"code","source":"map_hooray = folium.Map(location=[42.341145,-71.057083],\n                    zoom_start = 12, min_zoom = 12) \n\n\nheat_df = crime_df[crime_df['YEAR']==2017]\nheat_df = heat_df[heat_df['OFFENSE_CODE_GROUP']=='Homicide']\nheat_df = heat_df[['Lat', 'Long']]\n\nfolium.CircleMarker([42.313145,-71.078083],\n                    radius=80,\n                    popup='Homicide',\n                    color='red',\n                    ).add_to(map_hooray) #Adding mark on the map but it's hard to find correct place. \n                                         #it's take to muhc time\n\nheat_data = [[row['Lat'],row['Long']] for index, row in heat_df.iterrows()]\nHeatMap(heat_data, radius=10).add_to(map_hooray)\nmap_hooray","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**THERE IS A HEAT MAP BY THE MONTH ABOUT DRUG VIOLATION**\n\n*The boxes about lower left corner of the map: You can see the differences by the moth just use the buttons.*\n\n1-Backward\n\n2-Play reverse\n\n3-Play\n\n4-Foreward\n\n5-Loops"},{"metadata":{"trusted":true},"cell_type":"code","source":"from folium import plugins\nmap_hooray = folium.Map(location=[42.341145,-71.057083],\n                    zoom_start = 12, min_zoom = 12) \n\n\nheat_df = crime_df[crime_df['YEAR']==2017]\nheat_df = heat_df[heat_df['OFFENSE_CODE_GROUP']=='Drug Violation']\nheat_df = heat_df[['Lat', 'Long']]\n\nheat_df['Month'] = crime_df['MONTH']\n\n# List comprehension to make out list of lists\nheat_data = [[[row['Lat'],row['Long']] for index, row in heat_df[heat_df['Month'] == i].iterrows()] for i in range(1,13)]\n\n# Plot it on the map\nhm = plugins.HeatMapWithTime(heat_data,auto_play=True,max_opacity=0.8)\nhm.add_to(map_hooray)\n# Display the map\nmap_hooray","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}