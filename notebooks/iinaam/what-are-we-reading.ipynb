{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Dataset Overview\nThe dataset contains sales records of *Gufhtugu Publications* from January 2019 to January 2021.  \nGP is an emerging startup in Pakistan's e-commerce market.  \n\n## In this report:\nWe wiil try to answer following queries.\n1. What are the top 10 best selling books\n1. Which are the cities with the most customers\n1. What is the best seller in top-selling cities\n\nIn particular, we will, \n- Split orders with multiple books\n- Standardize language of book titles\n- Extract city name from detailed address\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n\n# plotting and coding utils\nplt.style.use('fivethirtyeight')\n%config IPCompleter.use_jedi = False\n%matplotlib inline\nplt.rcParams[\"figure.figsize\"] = (12, 8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/gufhtugu-publications-dataset-challenge/GP Orders - 5.csv', parse_dates= ['Order Date & Time'], encoding = 'utf-8')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"\ndf.columns = [c.lower().replace(\" \",\"_\") for c in df.columns]\ndups = df.duplicated().sum()\nrows, cols = df.shape\nnans = df.isna().sum()\nprint(f\"Dataset includes {rows} rows and {cols} feature columns.\")\nprint(f\"Among these records, {dups} are duplicated.\\n\")\nfor c,n in nans.items():\n    if n>0:\n        print(f\"Column {c} contains {n} missing values\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We have only a few records with missing values.  \nSince we are not interested in the payment_method for now, We will drop rows with missing values from the 'city' and 'book_name' columns.**"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"df.dropna(subset = [\"book_name\",\"city\"], inplace= True)\ndf.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# Type casting\ndf[\"book_name\"] = df.book_name.astype(str)\ndf[\"city\"] = df.city.astype(str)\ndf.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Top selling books\n**We are given a list of sold books in string format, where each book title is saperated by '/'.**\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('max_colwidth', 100)\ndf.book_name.sample(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Books and orders have an N:N relationship. We will transform this dataset in a way that each row will contain one and only one book.  \nIn other words, orders with multiple items are split into multiple rows (0 axis)."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"books_df = pd.DataFrame(df.book_name.str.split('/').tolist(), index=df.order_number).stack()\nbooks_df = books_df.reset_index([0, 'order_number'])\nbooks_df.columns = [\"order_id\",\"book_name\"]\nbooks_df[\"book_name\"] = books_df.book_name.str.lower()\nbooks_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Books with titles in both English and Urdu\nBooks with their title written in urdu are:"},{"metadata":{"trusted":true},"cell_type":"code","source":"mask = books_df.book_name.str.contains(\"[a-zZ-Z]\", case = 0)\nbooks_df[~mask].book_name.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Instead of renaming all these records, we will rename only those titles which are good candidates for top-10 best sellers.  \nFirst, we find the 30 top selling books, and then we manually merge their names into one standard language."},{"metadata":{"trusted":true},"cell_type":"code","source":"books_df.book_name.value_counts()[:30]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for top-30 we will find their english titles\nmask = books_df.book_name.str.contains(\"Internet|Data|Machine|algo|bit\", case = 0)\nbooks_df[mask].book_name","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"renaming_dict = {\n    \"Ø§Ù†Ù¹Ø±Ù†ÛŒÙ¹ Ø³Û’ Ù¾ÛŒØ³Û Ú©Ù…Ø§Ø¦ÛŒÚº\": \"earn from internet\",\n    \"ÚˆÛŒÙ¹Ø§ Ø³Ø§Ø¦Ù†Ø³\": \"data science\",\n    \"Ù…Ø´ÛŒÙ† Ù„Ø±Ù†Ù†Ú¯\": \"machine learning\",\n    \"ÚˆÛŒÙ¹Ø§ Ø³Ø§Ø¦Ù†Ø³ Û” Ø§ÛŒÚ© ØªØ¹Ø§Ø±Ù\": \"data science\",\n    \"Ø§ÛŒÚ© ØªÚ¾Ø§ Ø§Ù„Ú¯ÙˆØ±ØªÚ¾Ù…\": \"ek tha algorithm\",\n    \"Ø§Ù†Ù¹Ø±Ù†ÛŒÙ¹ Ø³Û’ Ù¾ÛŒØ³Û Ú©Ù…Ø§Ø¦ÛŒÚºØŸ- Ù…Ø³ØªØ­Ù‚ÛŒÙ† Ø²Ú©ÙˆØ§Ø©\": \"earn from internet\",\n    \"(c++)\": \"cpp\",\n    \"Ø³ÛŒ\": 'cpp',\n    \"(c++) ++Ø³ÛŒ\":\"cpp\",\n    \"Bit Coin Block Chain Aur Crypto Currency Ø¨Ù¹ Ú©ÙˆØ§Ø¦Ù†ØŒ Ø¨Ù„Ø§Ú© Ú†ÛŒÙ† Ø§ÙˆØ± Ú©Ø±Ù¾Ù¹Ùˆ Ú©Ø±Ù†Ø³ÛŒ\":\"blockchain, cryptocurrency and bitcoin\",\n    'Ø¨Ù„Ø§Ú© Ú†ÛŒÙ† Ø§ÙˆØ± Ú©Ø±Ù¾Ù¹Ùˆ Ú©Ø±Ù†Ø³ÛŒ': \"blockchain, cryptocurrency and bitcoin\",\n    'python programming- release date: august 14, 2020': 'python programming'\n}\n\nbooks_df.book_name.replace(renaming_dict,inplace=True)\nbooks_df[\"book_name\"] = books_df.book_name.str.title()\n\nprint(\"top-10 best sellers:\")\ntop_books = books_df.book_name.value_counts()[:10].reset_index()\ntop_books.columns = [\"book_name\", \"total_sales\"]\ntop_books = top_books.sort_values(\"total_sales\", ascending = False)\ntop_books","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize= (14,8))\nsns.barplot(y = top_books.book_name, x= top_books.total_sales, palette='flare_r')\n\nN = df.shape[0]\ni = 0\nfor _, v in top_books.total_sales.items():\n    plt.text(v + 15, i - .1, f\"{v/N *100:.1f}%\", color='#555c63', fontweight='bold', fontsize = 12, va = 'center')\n    i += 1\n    \nplt.title(\"Top 10 Bestsellers\", fontdict={'fontsize': \"30\", \"fontweight\":\"heavy\"}, loc = 'left')\nplt.grid(True, axis = 'x')\nplt.yticks(fontsize= 18)\nplt.xticks(fontsize= 14)\n\nplt.xlabel(\"Sales\", fontdict={'fontsize': \"20\"})\nplt.ylabel(\"\")\nplt.text(-1200,10,\"Book Title\", fontdict= {\"fontsize\":16,\"fontweight\":\"heavy\"})\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Remarks**\n- During the 2020s pandemic people were forced to reevaluate their methods of earnings. It is no wonder that people tried to learn about earning online. \n- Python, Data Science, AI, and Blockchain have become the backbone of information technology. These topics are going to stay at the top in upcoming years."},{"metadata":{},"cell_type":"markdown","source":"# Top selling cities\nTo find out cities with most number of orders, we will use original dataset.  \nDetailed address is converted into city name."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df[\"city\"] = df.city.str.title()\n# 100 most famous cities\ncities = df.city.value_counts()[:100].index\nfor city in cities:\n    # Rows with detailed address are replaced with city name'only'\n    mask = df.city.str.contains(city, case = 0)\n    df.loc[mask, \"city\"] = city\n    \ntop_cities = df.city.value_counts()[:10]\nprint(\"Top 10 selling cities:\\n\" , top_cities, sep=\"\\n\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"sns.barplot(y= top_cities.index, x = top_cities, palette='flare_r')\n\nN = df.shape[0]\ni = 0\nfor _, v in top_cities.items():\n    plt.text(v + 15, i - .1, f\"{v/N *100:.1f}%\", color='#555c63', fontweight='bold', va = 'center')\n    i += 1\n\nplt.title(\"Cities with most sales\", fontdict={'fontsize': \"30\",\"fontweight\":\"heavy\"}, loc = 'left')\nplt.grid(True, axis = 'x')\n\nplt.yticks(fontsize= 18)\nplt.xticks(fontsize= 14)\n\nplt.xlabel(\"Sales\",fontdict={'fontsize': \"20\"})\nplt.ylabel(\"\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The distribution of orders is highly correlated with population of the city.  \n50% of the orders are from these top-10 cities. 28% of total market is from Karachi and Lahore only."},{"metadata":{},"cell_type":"markdown","source":"# Best seller in major cities\nWe would like to find out the best seller in the major cities of Pakistan.  \nTo extract these statistics, we will merge books dataframe with source dataframe.  "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# merge two dataframes on order id\ncols = [\"order_id\", \"book_name_x\", \"city\"]\ncity_book_df = pd.merge(books_df, df, left_on= 'order_id', right_on= 'order_number')[cols]\ncity_book_df.rename(columns={\"book_name_x\":\"book_name\"}, inplace=True)\n\n# only top 10 cities\nmask = city_book_df.city.isin(top_cities.index)\n# group by to find number of sales for each city and each book\ngroup_cols = [\"city\",\"book_name\"]\ngrouped = city_book_df.loc[mask].groupby(group_cols)\ntmp = grouped.count().reset_index()\ntmp.rename(columns={\"order_id\":\"sales\"}, inplace = True)\n# find best seller for each city\ntop_bookPerCity = tmp.loc[tmp.groupby(\"city\").idxmax()[\"sales\"]]\ntop_bookPerCity.sort_values(by = 'sales', inplace = True, ascending = 0)\ntop_bookPerCity","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"ax = sns.barplot(x= 'city', y = 'sales', hue='book_name', data = top_bookPerCity, dodge=False)\n\nplt.title(\"Top selling book per city\", fontdict={'fontsize': \"30\"})\nplt.yticks(fontsize= 18)\nplt.xticks(fontsize= 14, ha = 'center')\nplt.legend(loc = 'upper right', prop = {'size':15})\nplt.xlabel(\"City\",fontdict={'fontsize': \"24\"})\nplt.ylabel(\"Sales\", fontdict={'fontsize': \"20\"})\n\n\nticks_and_labels = plt.xticks(range(len(top_bookPerCity)), top_bookPerCity.city, rotation=0)\nfor i, label in enumerate(ticks_and_labels[1]):\n    label.set_y(label.get_position()[1] - (i % 2) * 0.05)\n    \n    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Earn Money online is the best seller in 9/10 major cities.  \nSialkot is known for its exports worldwide, no wonder customers in Sialkot bought 'Product Management' the most."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Upcoming\nEven after extracting city names from detailed addresses, we have a huge number of distinct cities.  In the next step we will perform in-detail data cleaning of city attribute.  \n"},{"metadata":{},"cell_type":"markdown","source":"# Any comments are most welcome.  \n## If you liked the analysis, Please upvote â˜ to show the support ğŸ‘"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}