{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport keras\nimport keras.layers as L\nimport keras.models as M\nimport tensorflow as tf\nfrom PIL import Image\nimport os\nimport matplotlib.pyplot as plt\nimport cv2\nfrom keras.utils import Sequence","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=pd.read_csv('../input/handwriting-recognition/written_name_train_v2.csv')\nvalidation=pd.read_csv('../input/handwriting-recognition/written_name_validation_v2.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[train['IDENTITY']=='zucchi']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Length']=train['IDENTITY'].apply(lambda x : len(str(x)))\ntrain=train[train['Length']<=21]\ntrain['IDENTITY']=train['IDENTITY'].str.upper()\ntrain[train['Length']==max(train['Length'])]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=train.sample(frac=0.8,random_state=42)\nvalidation=validation.sample(frac=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"characters=set()\ntrain['IDENTITY']=train['IDENTITY'].apply(lambda x: str(x))\nfor i in train['IDENTITY'].values:\n    for j in i :\n        if j not in characters :\n            characters.add(j)\ncharacters=sorted(characters)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 2 Dictionaries  :   Turn all ur characters to num and vice versa\nchar_to_label = {char:label for label,char in enumerate(characters)}\nlabel_to_char = {label:char for label,char in enumerate(characters)}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path_train='../input/handwriting-recognition/train_v2/train'\npath_validation='../input/handwriting-recognition/validation_v2/validation'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data Generator\nclass DataGenerator(Sequence):\n    def __init__(self,dataframe,path,char_map,batch_size=128,img_size=(256,64),\n                 downsample_factor=4,max_length=22,shuffle=True):\n        self.dataframe=dataframe\n        self.path=path\n        self.char_map=char_map\n        self.batch_size=batch_size\n        self.width=img_size[0]\n        self.height=img_size[1]\n        self.downsample_factor=downsample_factor\n        self.max_length=max_length\n        self.shuffle=shuffle\n        self.indices = np.arange(len(dataframe))\n        self.on_epoch_end()\n        \n    def __len__(self):\n        return len(self.dataframe)//self.batch_size\n    \n    def __getitem__(self,idx):\n        curr_batch_idx=self.indices[idx*self.batch_size:(idx+1)*self.batch_size]\n        batch_images=np.ones((self.batch_size,self.width,self.height,1),dtype=np.float32)\n        batch_labels=np.ones((self.batch_size,self.max_length),dtype=np.float32)\n        input_length=np.ones((self.batch_size,1),dtype=np.float32)*(self.width//self.downsample_factor-2)\n        label_length=np.zeros((self.batch_size,1),dtype=np.int64)\n        for i,idx in enumerate(curr_batch_idx):\n            img_path=self.dataframe['FILENAME'].values[idx]\n            img=cv2.imread(self.path+'/'+img_path)\n            img=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n            img=cv2.resize(img,(self.width,self.height))\n            img=(img/255).astype(np.float32)\n            img=img.T\n            img=np.expand_dims(img,axis=-1)\n            text=self.dataframe['IDENTITY'].values[idx]\n            text=str(text)\n            label=[]\n            for j in text: \n                if j in self.char_map :\n                    label.append(self.char_map[j])\n                else:\n                    label.append(100)\n            label.extend([100]*(22-len(label)))\n            batch_images[i]=img\n            batch_labels[i]=label\n            label_length[i]=len(label)\n        batch_inputs= {\n                'input_data':batch_images,\n                'input_label':batch_labels,\n                'input_length':input_length,\n                'label_length':label_length\n                \n            }\n        return batch_inputs,np.zeros((self.batch_size),dtype=np.float32)\n    def on_epoch_end(self):\n        if self.shuffle == True :\n            np.random.shuffle(self.indices)\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator=DataGenerator(train,path_train,char_to_label)\nvalidation_generator=DataGenerator(validation,path_validation,char_to_label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making CTC Function\nclass CTCLayer(L.Layer):\n    def __init__(self, name=None):\n        super().__init__(name=name)\n        self.loss_fn = keras.backend.ctc_batch_cost\n\n    def call(self, y_true, y_pred, input_length, label_length):\n        # Compute the training-time loss value and add it\n        # to the layer using `self.add_loss()`.\n        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n        self.add_loss(loss)\n        \n        # On test time, just return the computed loss\n        return loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making the Model now\ndef make_model():\n    inp=L.Input(shape=(256,64,1),dtype=np.float32,name='input_data')\n    labels=L.Input(shape=[22],dtype=np.float32,name='input_label')\n    input_length=L.Input(shape=[1],dtype=np.int64,name='input_length')\n    label_length=L.Input(shape=[1],dtype=np.int64,name='label_length')\n    x=L.Conv2D(64,(3,3),activation='relu',padding='same',kernel_initializer='he_normal')(inp)\n    x=L.MaxPooling2D(pool_size=(2,2))(x)\n    x=L.Dropout(0.3)(x)\n    x=L.Conv2D(128,(3,3),activation='relu',padding='same',kernel_initializer='he_normal')(x)\n    x=L.MaxPooling2D(pool_size=(2,2))(x)\n    x=L.Dropout(0.3)(x)\n    new_shape=((256//4),(64//4)*128)\n    x=L.Reshape(new_shape)(x)\n    x=L.Dense(64,activation='relu')(x)\n    x=L.Dropout(0.2)(x)\n    x=L.Bidirectional(L.LSTM(128,return_sequences=True,dropout=0.2))(x)\n    x=L.Bidirectional(L.LSTM(64,return_sequences=True,dropout=0.25))(x)\n    x=L.Dense(len(characters)+1,activation='softmax',kernel_initializer='he_normal',name='Dense_output')(x)\n    output=CTCLayer(name='outputs')(labels,x,input_length,label_length)\n    model=M.Model([inp,labels,input_length,label_length],output)\n    # Optimizer\n    sgd = keras.optimizers.SGD(learning_rate=0.002,\n                               decay=1e-6,\n                               momentum=0.9,\n                               nesterov=True,\n                               clipnorm=5)\n    model.compile(optimizer=sgd)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=make_model()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Add early stopping\nes = keras.callbacks.EarlyStopping(monitor='val_loss',\n                                   patience=5,\n                                   restore_best_weights=True)\n\n# Train the model\nif 'prediction_model_ocr.h5' not in os.listdir('./'):\n    history = model.fit(train_generator,steps_per_epoch=1000,validation_data=validation_generator,\n                        epochs=8)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction_model = keras.models.Model(model.get_layer(name='input_data').input,\n                                        model.get_layer(name='Dense_output').output)\nprediction_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if 'prediction_model_ocr.h5' not in os.listdir('./'):\n    prediction_model.save('prediction_model_ocr.h5')\n    prediction_model=M.load_model('prediction_model_ocr.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label_to_char[100]=''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# A utility to decode the output of the network\ndef decode_batch_predictions(pred):\n    pred = pred[:, :-2]\n    input_len = np.ones(pred.shape[0])*pred.shape[1]\n    \n    # Use greedy search. For complex tasks, you can use beam search\n    results = keras.backend.ctc_decode(pred, \n                                        input_length=input_len,\n                                        greedy=True)[0][0]\n    \n    # Iterate over the results and get back the text\n    output_text = []\n    for res in results.numpy():\n        outstr = ''\n        for c in res:\n            if c < len(characters) and c >=0:\n                outstr += label_to_char[c]\n        output_text.append(outstr)\n    \n    # return final text results\n    return output_text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for p, (inp_value, _) in enumerate(validation_generator):\n    bs = inp_value['input_data'].shape[0]\n    X_data = inp_value['input_data']\n    labels = inp_value['input_label']\n    plt.imshow(X_data[0])\n    preds = prediction_model.predict(X_data)\n    pred_texts = decode_batch_predictions(preds)\n    \n    \n    orig_texts = []\n    for label in labels:\n        text = ''.join([label_to_char[int(x)] for x in label])\n        orig_texts.append(text)\n        \n    for i in range(bs):\n        print(f'Ground truth: {orig_texts[i]} \\t Predicted: {pred_texts[i]}')\n    break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_images=np.ones((128,256,64,1),dtype=np.float32)\nimg=cv2.imread('../input/handwriting-recognition/test_v2/test/TEST_0004.jpg')\nimg=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\nimg=cv2.resize(img,(256,64))\nimg=(img/255).astype(np.float32)\nimg=img.T\nimg=np.expand_dims(img,axis=-1)\nbatch_images[0]=img\nx=prediction_model.predict(batch_images)\npred_texts = decode_batch_predictions(x)\npred_texts = pred_texts[0]\nim=cv2.imread('../input/handwriting-recognition/test_v2/test/TEST_0004.jpg')\nplt.imshow(im)\nprint('Predicted Text:',pred_texts)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# I Feel Awesome after this","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}