{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Animated EDA and Tweets Analysis\n\n**Remark**: Many great kernels have already been posted. My goal is to explore the data using the *Plotly* animation feature in scatter and geo plots!\n\n**Update**: I recently gathered some tweets following the *coronavirus* hashtag and trying to analyze them.\n\nFor the moment this kernel has no predictions.\n\n* [EDA](#eda)\n    - [nCoV in Asia](#asia)\n    - [nCoV in the World](#world)\n    - [Confirmed/Deaths/Recovered over Time](#scatter)\n* [Tweets Analysis](#tweets)\n    - [Sentiment Distribution](#sentiment)\n    - [WordCloud](#wordcloud)\n    - [Hashtags](#hashtags)"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"eda\"></a>\n# (Geographic) EDA"},{"metadata":{},"cell_type":"markdown","source":"Load libraries and the dataset."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import pandas as pd\npd.set_option('display.max_columns', 100)\npd.set_option('display.max_rows', 100)\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport scipy.stats as stats\n%matplotlib inline\n\nimport plotly.express as px\nimport plotly.graph_objs as go\nfrom plotly.offline import iplot, init_notebook_mode\nimport plotly.figure_factory as ff\nfrom plotly import subplots\nfrom plotly.subplots import make_subplots\ninit_notebook_mode(connected=True)\n\nfrom datetime import date, datetime, timedelta\nimport time\n\nfrom textblob import TextBlob\nfrom textblob.sentiments import NaiveBayesAnalyzer\n\nfrom wordcloud import WordCloud\nfrom collections import Counter\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n        \n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def resumetable(df):\n    print(f\"Dataset Shape: {df.shape}\")\n    summary = pd.DataFrame(df.dtypes, columns=['dtypes'])\n    summary = summary.reset_index()\n    summary['Name'] = summary['index']\n    summary = summary[['Name','dtypes']]\n    summary['Missing'] = df.isnull().sum().values    \n    summary['Uniques'] = df.nunique().values\n\n    return summary","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/novel-corona-virus-2019-dataset/covid_19_data.csv\",)\nresumetable(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's rename columns, change datetime to date format, drop rows with (0,0,0) triplets."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.rename(columns={'Last Update': 'LastUpdate',\n                   'ObservationDate':'Date',\n                   'Country/Region': 'Country',\n                   'Province/State': 'PS'},\n         inplace=True)\ndf['Date'] = pd.to_datetime(df['Date']).dt.date\n\nvirus_cols=['Confirmed', 'Deaths', 'Recovered']\n\ndf = df[df[virus_cols].sum(axis=1)!=0]\n\nresumetable(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that there are lots of missing values in the Province/State column, let's fill with Country value if there are no other Province/State, and drop the remaining 2 rows."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[(df['PS'].isnull()) & (df.groupby('Country')['PS'].transform('nunique') == 0), 'PS'] = \\\n        df.loc[(df['PS'].isnull()) & (df.groupby('Country')['PS'].transform('nunique') == 0), 'Country'].to_numpy()\n\ndf['Country'] = np.where(df['Country']=='Mainland China', 'China', df['Country'])\ndf.dropna(inplace=True)\nresumetable(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Retrieve latitute and longitude for each Country-Province pair using the time series dataset.\n(Remark, previously I was using the geopy package). \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"usecols=['Province/State', 'Country/Region', 'Lat', 'Long']\npath= '../input/novel-corona-virus-2019-dataset/time_series_covid_19_'\ncsvs=['confirmed.csv', 'deaths.csv', 'recovered.csv']\n\ncoords_df = pd.concat([pd.read_csv(path + csv, usecols=usecols) for csv in csvs])\n\ncoords_df.rename(columns={'Country/Region': 'Country',\n                          'Province/State': 'PS'}, \n                inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"coords_df.loc[(coords_df['PS'].isnull()) & (coords_df.groupby('Country')['PS'].transform('nunique') == 0), 'PS'] =\\\n    coords_df.loc[(coords_df['PS'].isnull()) & (coords_df.groupby('Country')['PS'].transform('nunique') == 0), 'Country'].to_numpy()\n\ncoords_df['Country'] = np.where(coords_df['Country']=='Mainland China', 'China', coords_df['Country'])\n\n\ncoords_df = coords_df.drop_duplicates()\ndf = pd.merge(df, coords_df, on=['Country', 'PS'], how='left')\ndf","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#import time\n#import geopy\n#locator = geopy.Nominatim(user_agent='uagent')\n#\n#pairs = df[['Country', 'PS']].drop_duplicates().to_numpy()\n##d={}\n#for p in pairs:\n#    if p[0] + ', ' + p[1] not in d:\n#        l = p[0] + ', ' + p[1] if p[0]!=p[1] else p[0]\n#        location = locator.geocode(l)\n#\n#        d[l] = [location.latitude, location.longitude]\n#        print(l, location.latitude, location.longitude)\n#        time.sleep(1)\n\n#def coords(row):\n#    \n#    k = row['Country'] +', '+ row['PS'] if row['Country'] != row['PS'] else row['Country']\n#    row['lat'] = d[k][0]\n#    row['lon'] = d[k][1]\n#    return row\n#\n#df = df.apply(coords, axis=1)\n#df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.groupby(['PS', 'Country', 'Date']).agg({'Confirmed': 'sum',\n                                                'Deaths': 'sum',\n                                                'Recovered': 'sum',\n                                                'Lat': 'max',\n                                                'Long': 'max'}).reset_index()\ndf = df[df['Date']>date(2020,1,20)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's plot the virus spreading in Asia and in the rest of the world over time. \n* Size is proportional to number of confirmed cases.\n* Colorscale depends upon the number of deaths."},{"metadata":{},"cell_type":"markdown","source":"<a id=\"asia\"></a>\n### Asia Scattergeo"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"dates = np.sort(df['Date'].unique())\ndata = [go.Scattergeo(\n            locationmode='country names',\n            lon = df.loc[df['Date']==dt, 'Long'],\n            lat = df.loc[df['Date']==dt, 'Lat'],\n            text = df.loc[df['Date']==dt, 'Country'] + ', ' + df.loc[df['Date']==dt, 'PS'] +   '-> Deaths: ' + df.loc[df['Date']==dt, 'Deaths'].astype(str) + ' Confirmed: ' + df.loc[df['Date']==dt,'Confirmed'].astype(str),\n            mode = 'markers',\n            marker = dict(\n                size = (df.loc[df['Date']==dt,'Confirmed'])**(1/2.7)+3,\n                opacity = 0.6,\n                reversescale = True,\n                autocolorscale = False,\n                line = dict(\n                    width=0.5,\n                    color='rgba(0, 0, 0)'\n                        ),\n                cmin=0,\n                color=df.loc[df['Date']==dt,'Deaths'],\n                cmax=df['Deaths'].max(),\n                colorbar_title=\"Number of Deaths\"\n            )) \n        for dt in dates]\n\n\nfig = go.Figure(\n    data=data[0],\n    layout=go.Layout(\n        title = {'text': f'Corona Virus spreading in Asia, {dates[0]}',\n                                'y':0.98,\n                                'x':0.5,\n                                'xanchor': 'center',\n                                'yanchor': 'top'},\n        geo = dict(\n            scope='asia',\n            projection_type='robinson',\n            showland = True,\n            landcolor = \"rgb(252, 240, 220)\",\n            showcountries=True,\n            showocean=True,\n            oceancolor=\"rgb(219, 245, 255)\",\n            countrycolor = \"rgb(128, 128, 128)\",\n            lakecolor =\"rgb(219, 245, 255)\",\n            showrivers=True,\n            showlakes=True,\n            showcoastlines=True,\n            countrywidth = 1,\n            \n            ),\n     updatemenus=[dict(\n            type=\"buttons\",\n            buttons=[dict(label=\"Play\",\n                          method=\"animate\",\n                          args=[None])])]),\n    \n    frames=[go.Frame(data=dt, \n                     layout=go.Layout(\n                          title={'text': f'Corona Virus spreading in Asia, {date}',\n                                'y':0.98,\n                                'x':0.5,\n                                'xanchor': 'center',\n                                'yanchor': 'top'}\n                           ))\n            for dt,date in zip(data[1:],dates[1:])])\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"world\"></a>\n### World Scattergeo"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"dates = np.sort(df['Date'].unique())\ndata = [go.Scattergeo(\n            locationmode='country names',\n            lon = df.loc[df['Date']==dt, 'Long'],\n            lat = df.loc[df['Date']==dt, 'Lat'],\n            text = df.loc[df['Date']==dt, 'Country'] + ', ' + df.loc[df['Date']==dt, 'PS'] +   '-> Deaths: ' + df.loc[df['Date']==dt, 'Deaths'].astype(str) + ' Confirmed: ' + df.loc[df['Date']==dt,'Confirmed'].astype(str),\n            mode = 'markers',\n            marker = dict(\n                size = (df.loc[df['Date']==dt,'Confirmed'])**(1/2.7)+3,\n                opacity = 0.6,\n                reversescale = True,\n                autocolorscale = False,\n                line = dict(\n                    width=0.5,\n                    color='rgba(0, 0, 0)'\n                        ),\n                #colorscale='rdgy', #'jet',rdylbu, 'oryel', \n                cmin=0,\n                color=df.loc[df['Date']==dt,'Deaths'],\n                cmax=df['Deaths'].max(),\n                colorbar_title=\"Number of Deaths\"\n            )) \n        for dt in dates]\n\n\nfig = go.Figure(\n    data=data[0],\n    layout=go.Layout(\n        title = {'text': f'Corona Virus, {dates[0]}',\n                                'y':0.98,\n                                'x':0.5,\n                                'xanchor': 'center',\n                                'yanchor': 'top'},\n        geo = dict(\n            scope='world',\n            projection_type='robinson',\n            showland = True,\n            landcolor = \"rgb(252, 240, 220)\",\n            showcountries=True,\n            showocean=True,\n            oceancolor=\"rgb(219, 245, 255)\",\n            countrycolor = \"rgb(128, 128, 128)\",\n            lakecolor =\"rgb(219, 245, 255)\",\n            showrivers=True,\n            showlakes=True,\n            showcoastlines=True,\n            countrywidth = 1,\n            \n            ),\n     updatemenus=[dict(\n            type=\"buttons\",\n            buttons=[dict(label=\"Play\",\n                          method=\"animate\",\n                          args=[None])])]),\n    \n    frames=[go.Frame(data=dt, \n                     layout=go.Layout(\n                          title={'text': f'Corona Virus, {date}',\n                                'y':0.98,\n                                'x':0.5,\n                                'xanchor': 'center',\n                                'yanchor': 'top'}\n                           ))\n            for dt,date in zip(data[1:],dates[1:])])\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"scatter\"></a>\n### Confirmed/Deaths/Recovered over Time\n\nAlso let's check how number of confirmed, deaths and recovered evolve over time, in China and the rest of the world.\n\n**Take care**, y-scales are very different!"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"china=df.loc[df['Country']=='China']\nhubei=china.loc[china['PS']=='Hubei']\nrest_of_china=china.loc[china['PS']!='Hubei'].groupby('Date').sum().reset_index()\n\nchina=china.groupby('Date').sum().reset_index()\n\nagg_df=df.groupby(['Country', 'Date']).sum().reset_index()\n\nrest_df=agg_df.loc[agg_df['Country']!='China'].groupby('Date').sum().reset_index()\n\n\n\ndates = np.sort(df['Date'].unique())\ndt_range = [np.min(dates)-timedelta(days=1), np.max(dates)+timedelta(days=1)]\n\n# Row 1\nframes_hubei = [go.Scatter(x=hubei['Date'],\n                           y=hubei.loc[hubei['Date']<=dt, 'Confirmed'],\n                           name='Hubei, Confirmed',\n                           legendgroup=\"21\") for dt in dates]\n\nframes_rchina = [go.Scatter(x=rest_of_china['Date'],\n                           y=rest_of_china.loc[rest_of_china['Date']<=dt, 'Confirmed'],\n                           name='Rest of China, Confirmed',\n                           legendgroup=\"21\") for dt in dates]\n\n\nframes_world = [go.Scatter(x=rest_df['Date'],\n                           y=rest_df.loc[rest_df['Date']<=dt, 'Confirmed'],\n                           name='Rest of the World, Confirmed',\n                           legendgroup=\"22\") for dt in dates]\n\n\n# Row 2\nframes_china_d = [go.Scatter(x=china['Date'],\n                           y=china.loc[china['Date']<=dt, 'Deaths'],\n                           name='China, Deaths',\n                           legendgroup=\"31\") for dt in dates]\n\nframes_china_r = [go.Scatter(x=china['Date'],\n                           y=china.loc[china['Date']<=dt, 'Recovered'],\n                           name='China, Recovered',\n                           legendgroup=\"31\") for dt in dates]\n\n\nframes_world_d = [go.Scatter(x=rest_df['Date'],\n                           y=rest_df.loc[rest_df['Date']<=dt, 'Deaths'],\n                           name='Rest of World, Deaths',\n                           legendgroup=\"32\") for dt in dates]\n\nframes_world_r = [go.Scatter(x=rest_df['Date'],\n                           y=rest_df.loc[rest_df['Date']<=dt, 'Recovered'],\n                           name='Rest of World, Recovered',\n                           legendgroup=\"32\") for dt in dates]\n\n\n\n\nfig = make_subplots(\n    rows=2, cols=2,\n    specs=[[{}, {}],\n           [{}, {}]],\n    subplot_titles=(\"China, Confirmed\", 'Rest of the World, Confirmed',\n                    \"China, Deaths & Recovered\", 'Rest of the World, Deaths & Recovered'))\n\n\n# Row 1: Confirmed\nfig.add_trace(frames_hubei[0], row=1, col=1)\nfig.add_trace(frames_rchina[0], row=1, col=1)\nfig.add_trace(frames_world[0], row=1,col=2)\n\n\n# Row 2: Deaths & Recovered\nfig.add_trace(frames_china_d[0], row=2, col=1)\nfig.add_trace(frames_china_r[0], row=2, col=1)\nfig.add_trace(frames_world_d[0], row=2,col=2)\nfig.add_trace(frames_world_r[0], row=2,col=2)\n\n\n# Add Layout\nfig.update_xaxes(showgrid=False)\n\nfig.update_layout(\n        title={\n            'text': 'Corona Virus: Confirmed, Deaths & Recovered',\n            'y':0.98,\n            'x':0.5,\n            'xanchor': 'center',\n            'yanchor': 'top'},\n        height=820,\n        legend_orientation=\"h\",\n        #legend=dict(x=1, y=0.4),\n        xaxis1=dict(range=dt_range, autorange=False),\n        yaxis1=dict(range=[-10, hubei['Confirmed'].max()*1.1 ], autorange=False),\n        xaxis2=dict(range=dt_range, autorange=False),\n        yaxis2=dict(range=[-10, rest_df['Confirmed'].max()*1.1 ], autorange=False),\n        xaxis3=dict(range=dt_range, autorange=False),\n        yaxis3=dict(range=[-10, np.max([china['Recovered'].max(), china['Deaths'].max()])*1.1 ], autorange=False),\n        xaxis4=dict(range=dt_range, autorange=False),\n        yaxis4=dict(range=[-0.5, np.max([rest_df['Recovered'].max(), rest_df['Deaths'].max()])*1.1], autorange=False),\n        )\n\n\nframes = [dict(\n               name = str(dt),\n               data = [frames_hubei[i], frames_rchina[i], frames_world[i],\n                       frames_china_d[i], frames_china_r[i],\n                       frames_world_d[i], frames_world_r[i]\n                       ],\n               traces=[0, 1, 2, 3, 4 ,5 ,6, 7]\n              ) for i, dt in enumerate(dates)]\n\n\n\nupdatemenus = [dict(type='buttons',\n                    buttons=[dict(label='Play',\n                                  method='animate',\n                                  args=[[str(dt) for dt in dates[1:]], \n                                         dict(frame=dict(duration=500, redraw=False), \n                                              transition=dict(duration=0),\n                                              easing='linear',\n                                              fromcurrent=True,\n                                              mode='immediate'\n                                                                 )])],\n                    direction= 'left', \n                    pad=dict(r= 10, t=85), \n                    showactive =True, x= 0.6, y= -0.1, xanchor= 'right', yanchor= 'top')\n            ]\n\nsliders = [{'yanchor': 'top',\n            'xanchor': 'left', \n            'currentvalue': {'font': {'size': 16}, 'prefix': 'Date: ', 'visible': True, 'xanchor': 'right'},\n            'transition': {'duration': 500.0, 'easing': 'linear'},\n            'pad': {'b': 10, 't': 50}, \n            'len': 0.9, 'x': 0.1, 'y': -0.2, \n            'steps': [{'args': [[str(dt)], {'frame': {'duration': 500.0, 'easing': 'linear', 'redraw': False},\n                                      'transition': {'duration': 0, 'easing': 'linear'}}], \n                       'label': str(dt), 'method': 'animate'} for dt in dates     \n                    ]}]\n\n\n\nfig.update(frames=frames),\nfig.update_layout(updatemenus=updatemenus,\n                  sliders=sliders);\nfig.show() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that China's kinda hit inflection point in mid February, on the other hand the rest of the world just began the exponential phase. "},{"metadata":{},"cell_type":"markdown","source":"<a id=\"tweets\"></a>\n# Tweets Analysis\n\nI tried to retrieve some tweets with the *coronavirus* hashtag during the last day, you can find the dataset among my inputs.\nThe csv has already filtered out all the retweets.\n\n### Load data and Clean Text\nPreprocess each tweet, removing some patterns as *http*, *https*, *@[..]* and others.."},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df_tweets = pd.read_csv(\"../input/tweets/nCoV_tweets.csv\", index_col=0)\ndf_tweets.rename(columns={'txt': 'tweets',\n                         'dt':'date'}, inplace=True)\n\nimport re\ndef tweet_parser(text, pattern_regex):\n    \n    for pr in pattern_regex:\n        text = re.sub(pr, ' ', text)\n        \n    return text.strip()\n\npattern_regex = ['\\n', '\\t', ':', ',', ';', '\\.', '\"', \"''\", \n                 '@.*?\\s+', 'RT.*?\\s+', 'http.*?\\s+', 'https.*?\\s+']\n\ndf_tweets['tidy_tweets'] = df_tweets.apply(lambda r: tweet_parser(r['tweets'], pattern_regex), axis=1)\ndf_tweets['date'] = pd.to_datetime(df_tweets['date']).dt.date\n\ndf_tweets.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's use TextBlob library to infer tweet sentiments, and later categorize them into *Negative*, *Neutral* and *Positive*."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df_tweets['sentiment'] = df_tweets.apply(lambda r: TextBlob(r['tidy_tweets']).sentiment.polarity, axis=1)\ndf_tweets['sent_adj'] = np.where(df_tweets['sentiment']<0, 'Negative', np.where(df_tweets['sentiment']>0, 'Positive', 'Neutral'))\ndf_tweets['sent_adj'] = df_tweets['sent_adj'].astype('category')\nsizes = df_tweets.groupby('sent_adj').size()\n\ndf_tweets.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"sentiment\"></a>\n### Raw Sentiment Distribution and Adjusted Sentiment Histogram"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = ff.create_distplot([df_tweets['sentiment']], group_labels = ['sentiment'], bin_size=[.05], colors=['indianred'])\nfig.update_layout(\n        title={'text': 'Sentiment Distribution',\n               'y':0.95, 'x':0.5,\n               'xanchor': 'center', 'yanchor': 'top'},\n        showlegend=False)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = go.Figure()\nfig.add_trace(\n    go.Bar(x=sizes.index,\n           y=sizes.values,\n           opacity=0.9,\n           text = sizes.values,\n           textposition='outside',\n           marker={'color':'indianred'}\n                   ))\nfig.update_layout(\n      title={'text': 'Sentiment Adjusted Histogram',\n             'y':0.95, 'x':0.5,\n            'xanchor': 'center', 'yanchor': 'top'},\n       showlegend=False,\n       xaxis_title_text='Sentiment',\n        yaxis_title_text='Count',\n    bargap=0.3)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"wordcloud\"></a>\n### Tweets WordCloud"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def render_wordcloud(df, sent='Positive'):\n    \n    color = {'Positive': 'Set2', 'Negative': 'RdGy', 'Neutral': 'Accent_r'}\n    \n    words = ' '.join([text for text in df.loc[df['sent_adj']==sent, 'tidy_tweets']])\n    \n    wordcloud = WordCloud(width=800, height=500, \n                          background_color='black',\n                          max_font_size=100, \n                          relative_scaling=0.1, \n                          colormap=color[sent]).generate(words)\n\n    plt.figure(figsize=(14, 10))\n    plt.imshow(wordcloud, interpolation=\"bilinear\")\n    plt.title(sent + ' Wordcloud', fontsize=20)\n    plt.axis('off')\n    plt.show()\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for s in ['Positive', 'Negative', 'Neutral']:\n    render_wordcloud(df_tweets, s)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" At least at first sight, all wordclouds look pretty similar, and I cannot see huge differences in the words displayed.\n Let's see if there are differences among the hashtags used.\n \n <a id=\"hashtags\"></a>\n\n ### Hashtag Analysis \n Let's check hashtags counts, both overall and split by sentiment. From the hashtags I am excluding the #coronavirus one, since it's my tweet research key. "},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def get_hashtag(series):\n    s = series.str.lower()\n    s = s.str.extractall(r'(\\#\\w*)')[0].value_counts()\n    return pd.DataFrame(data={'hashtag': s.index,\n                              'count': s.values})\n\ndef get_hashtag_by_sent(df):\n    d={}\n    for s in df['sent_adj'].unique():\n        tmp = get_hashtag(df.loc[df['sent_adj']==s, 'tidy_tweets'])\n        d[s] = tmp[(tmp['hashtag'].str.len()>2) & (~tmp['hashtag'].str.contains('coronavirus'))]\n    return d\n\nall_hashtag = get_hashtag(df_tweets['tidy_tweets'])\nall_hashtag = all_hashtag[(all_hashtag['hashtag'].str.len()>2) & (~all_hashtag['hashtag'].str.contains('coronavirus'))]\n\nd = get_hashtag_by_sent(df_tweets)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = make_subplots(\n    rows=2, cols=3,\n    specs=[[{\"colspan\": 3}, None, None],\n           [{},{},{}]],\n    subplot_titles=('Overall Most Frequent Hashtags',\n                    'Positive Hashtags', 'Neutral Hashtags', 'Negative Hashtags' )\n)\n\nfig.add_trace(\n     go.Bar(\n         x=all_hashtag.loc[:20,'hashtag'].to_numpy(),\n         y=all_hashtag.loc[:20, 'count'].to_numpy(),\n         opacity=0.8,\n         orientation='v'),\n    row=1, col=1)\n\nfor i, k in enumerate(['Positive', 'Negative', 'Neutral']):\n    \n    fig.add_trace(\n         go.Bar(x =  d[k].loc[:10,'hashtag'].to_numpy(),\n               y =d[k].loc[:10, 'count'].to_numpy(),\n               opacity=0.8,\n               orientation='v'),\n        row=2, col=i+1)\n\nfig.update_layout(\n      title={'text': 'Most Frequent Hashtags',\n             'y':1, 'x':0.5,\n            'xanchor': 'center', 'yanchor': 'top'},\n      height = 1000,\n    showlegend=False\n    )\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As in the case of wordclouds, all *sentiments* seems to share the same hashtags.\n\nIf you got this far, please let me know what are your thoughts and feedbacks."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}