{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":false},"cell_type":"code","source":"import math\nimport random\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tqdm.notebook as tqdm # progress bars\nimport implicit # Fast, sparse ALS implementation\n\nfrom itertools import product\n\nfrom scipy.sparse import csr_matrix\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Common Utilities"},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nData Preprocessing\n'''\n\ndef safe_train_test_split(users, items, test_size=0.25, random_state=0):\n    '''\n    Performs a train test split on interactions, guaranteeing that every user \n    will be represented in both the train and the test split (assuming each user appears twice).\n    Note that sklearn's train_test_split function, even when stratified by user does not guarantee this,\n    unless the test_size is such that every user should be in both splits (0.5 if only 2 reviews/user)\n    \n    users is a list of user_ids\n    items is a list of items_ids\n    test_size is the approximate proportion of samples to be considered \"test samples\"\n    \n    The indices of users and items should correlate to represent all positive interactions\n    '''\n    \n    user_train = []\n    user_test = []\n    \n    item_train = []\n    item_test = []\n    \n    random.seed(random_state)\n    \n    for user_id in tqdm.tqdm(users.unique()):\n        examples = list(users[users.values == user_id].index)\n        random.shuffle(examples)\n        \n        # Not enough samples to perform proper split: pull one into test, then throw the rest in train\n        if len(examples) * test_size < 1:\n            user_test.append(user_id)\n            item_test.append(items[examples[0]])\n            \n            for i in range(1, len(examples)):\n                user_train.append(user_id)\n                item_train.append(items[examples[i]])\n            \n        # Enough to perform proper split: throw into train and test according to test_size\n        else:\n            test_samples = int(len(examples) * test_size)\n            \n            for i in range(0, test_samples):\n                user_test.append(user_id)\n                item_test.append(items[examples[i]])\n                \n            for j in range(test_samples, len(examples)):\n                user_train.append(user_id)\n                item_train.append(items[examples[j]])\n            \n    return user_train, user_test, item_train, item_test\n\ndef make_recipe_ingr_xref(recipes):\n    '''\n    recipes is the pandas dataframe for preprceossed recipes. The ingredient_ids column should store lists of integers\n    \n    Returns new pandas dataframe, a cross-reference table for all recipes and ingredients\n    '''\n    \n    recipe_ids = []\n    ingr_ids = []\n    \n    for row in tqdm.tqdm(recipes['ingredient_ids'].index):\n        for ingr_id in recipes['ingredient_ids'][row]:\n            recipe_ids.append(recipes.loc[row, 'i'])\n            ingr_ids.append(ingr_id)\n            \n    return pd.DataFrame.from_dict({'i': recipe_ids, 'ingr': ingr_ids})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"'''\nReccomendation Generation\n'''\n\ndef get_positive_interactions(interactions, user_id):\n    '''\n    interactions is a pandas dataframe describing all known positive interactions, for filtering purposes\n    user_id is an integer specifying the user for which to pull the positive interactions\n    \n    returns a list of recipe_ids, specifying the recipes the given user has interacted with\n    '''\n    \n    return interactions[interactions['u'] == user_id]['i'].values\n\ndef get_reccomendations(predictions, k, filtered_recipe_ids=[], filter_val=-100):\n    '''\n    General purpose function for pulling reccomendations based on a value for each recipe\n    \n    predictions is a numpy array of length num_recipes, that assigns a value to each recipe\n    k is an integer, the number of reccomendations to generate\n    filtered_recipe_ids is a list of recipe_ids, specifying which recipes should not be included in the reccomendations\n    filter_val is the value that replaces filtered recipe_ids for filtering purposes\n    \n    Returns recipe_ids, a list of the top k reccomended recipes, with index 0 being the most reccomended\n    '''\n    \n    # Replace all recipes to be filtered out with the filter value, which should be a lower value\n    predictions[filtered_recipe_ids] = filter_val\n    \n    # Get the top k reccomendations for the user (NOTE: these are not in order)\n    unsorted_recs = np.argpartition(predictions, -k)[-k:]\n    \n    # Sort the reccomendations by their predictions values, in descending order\n    sorted_recs = sorted(unsorted_recs, key=lambda rec: predictions[rec], reverse=True)\n\n    return sorted_recs\n\ndef collab_filter_reccomendations(item_embedding, user_embedding, user_id, k, interactions=None, filter_recs=False):\n    '''\n    item embedding is of shape (items, features) describing the features for each item\n    user_embedding is of shape (users, features) describing the features for each user\n    user_id is an integer specifying the user to get reccomendations for\n    k is an integer specifying the number of reccomendations to pull\n    interactions is a pandas dataframe describing all known positive interactions, for filtering purposes\n        Note: interactions is only required if filter_recs is true\n    filter_recs is a boolean, specifying whether or not to filter known positive interactions specified in interactions\n    \n    Returns a list of recipe_ids similar to the general-purpose get_reccomendations function\n    '''\n    \n    predictions = item_embedding @ user_embedding[user_id, :]\n    \n    filtered_recipe_ids = get_positive_interactions(interactions, user_id) if filter_recs else []\n\n    return get_reccomendations(predictions, k, filtered_recipe_ids)\n\ndef collab_filter_train_test_matrix(item_embedding, user_embedding, k, interactions):\n    '''\n    parameters are defined as for collab_filter_reccomendations\n    \n    Returns a tuple (train_rec_matrix, test_rec_matrix) where both are matrices of size (num_users, k) providing\n        the top k reccomendations for each user (most reccomended at index 0). train_rec_matrix does not filter known\n        positive interactions, while test_rec_matrix does filter known positive interactions\n    '''\n    \n    train_rec_matrix = []\n    test_rec_matrix = []\n    \n    for user_id in tqdm.tqdm(range(user_embedding.shape[0])):\n        predictions = item_embedding @ user_embedding[user_id, :]\n        filtered_recipe_ids = get_positive_interactions(interactions, user_id)\n        \n        train_recs = get_reccomendations(predictions, k)\n        test_recs = get_reccomendations(predictions, k, filtered_recipe_ids)\n\n        train_rec_matrix.append(train_recs)\n        test_rec_matrix.append(test_recs)\n\n    return np.array(train_rec_matrix), np.array(test_rec_matrix)\n\ndef similar_recipes(embeddings, recipe_id, k):\n    '''\n    Embeddings is a matrix of shape (num_recipes, num_feature)\n    recipe_id is an integer, the recipe to find similar recipes to\n    \n    Note that embeddings could be tf-idf embeddings to produce content-based reccomendations (\"similar recipes\")\n        OR embeddings could be item_embeddings generated from collaborative filtering (\"customers who liked this recipe also liked\")\n    \n    Returns a list of recipe_ids, the most similar recipes to the given recipe\n    '''\n    \n    # Values for each recipe based on similarity to given recipe\n    similarities = cosine_similar_predictions(embeddings, embeddings[recipe_id])\n    \n    # Get reccomendations, filtering out the queries recipe\n    return get_reccomendations(similarities, k, filtered_recipe_ids=[recipe_id])\n\ndef mean_profile_reccomendations(embeddings, user_id, k, interactions, filter_recs=False):\n    '''\n    Parameters defined as above\n    \n    Returns a list of recipe_ids, reccomended based on the mean embedding of all recipes the user has interacted with\n    '''\n    \n    interacted_ids = get_positive_interactions(interactions, user_id)\n    \n    interacted_embeddings = embeddings[interacted_ids]\n\n    average_embedding = np.mean(interacted_embeddings, axis=0)\n\n    similarities = cosine_similar_predictions(embeddings, average_embedding)\n\n    return get_reccomendations(similarities, k, filtered_recipe_ids=interacted_ids if filter_recs else [])\n\ndef mean_profile_train_test_matrix(embeddings, k, interactions):\n    '''\n    Produces a matrix of size (num_users, k) providing the top k reccomendations for each user\n    \n    This takes like 12 minutes to run with tf_idf embeddings, I think because of the ~8000 features\n    This takes 6 minutes for collab_filter embeddings, with only 8 features. Probably longer b/c it normalizes similarities\n    '''\n    \n    train_rec_matrix = []\n    test_rec_matrix = []\n    \n    for user_id in tqdm.tqdm(range(max(interactions['u']) + 1)):\n    #for user_id in tqdm.tqdm(range(10)):\n        interacted_ids = get_positive_interactions(interactions, user_id)\n        interacted_embeddings = embeddings[interacted_ids]\n\n        average_embedding = np.mean(interacted_embeddings, axis=0)\n        similarities = cosine_similar_predictions(embeddings, average_embedding)\n\n        train_recs = get_reccomendations(similarities, k)\n        test_recs = get_reccomendations(similarities, k, filtered_recipe_ids=interacted_ids)\n\n        train_rec_matrix.append(train_recs)\n        test_rec_matrix.append(test_recs)\n        \n    return np.array(train_rec_matrix), np.array(test_rec_matrix)\n\ndef random_rec_matrix(num_users, num_recipes, k):\n    '''\n    Function to create a dummy reccomendation matrix, as a baseline for other models\n    '''\n    \n    rec_matrix = []\n    \n    for user_id in tqdm.tqdm(range(num_users)):\n        rec_matrix.append([random.randint(0, num_recipes - 1) for i in range(k)])\n        \n    return np.array(rec_matrix)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(mean_profile_reccomendations(tf_idf_embeddings, 0, 20, train_interactions))\n#print(mean_profile_reccomendations(model.item_factors, 0, 20, train_interactions))\n#print(collab_filter_reccomendations(model.item_factors, model.user_factors, 0, 20, train_interactions))\n#print(train_interactions[train_interactions['u'] == 0]['i'].values)\n\n# Performance suggests this method is poor at generalizing to new recipes...\n'''\ntrain_rec_matrix, test_rec_matrix = mean_profile_train_test_matrix(tf_idf_embeddings, 10, train_interactions)\nprint(mean_precision_at_k(train_matrix, positive_train_interactions, train_rec_matrix, adjusted=True)) # 0.597\nprint(mean_precision_at_k(test_matrix, positive_test_interactions, test_rec_matrix, adjusted=True)) # 0.001286\n'''\n\n# Performance also suggests poor generalization, but better generalization than tf_idf reccomendations\n'''\ntrain_rec_matrix, test_rec_matrix = mean_profile_train_test_matrix(model.item_factors, 10, train_interactions)\nprint(mean_precision_at_k(train_matrix, positive_train_interactions, train_rec_matrix, adjusted=True)) # 0.222729\nprint(mean_precision_at_k(test_matrix, positive_test_interactions, test_rec_matrix, adjusted=True)) # 0.00817\n'''","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# TF-IDF Similarity Measurements (Content-Based Filtering)"},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nContent-based filtering utilities\n'''\n\ndef get_tf_idf_embeddings(recipe_ingr_xref):\n    '''\n    recipe_ingr_xref is a pandas Dataframe, like the one returned from makr_recipe_ingr_xref\n    \n    returns a sparse matrix of tf-idf embeddings for each recipe\n    ''' \n    \n    # Create the document frequency matrix\n    ingr_freq = csr_matrix((np.ones(len(recipe_ingr_xref)), (recipe_ingr_xref['i'], recipe_ingr_xref['ingr'])))\n    \n    # Generate the tf-idf embeddings from the document frequency matrix\n    tf = TfidfTransformer()\n    tf_idf_embeddings = tf.fit_transform(ingr_freq) \n    \n    return tf_idf_embeddings\n\ndef cosine_similar_predictions(embeddings, query):\n    '''\n    embeddings is a matrix of shape (num_recipes, num_features)\n    query is a list of length num_features\n    '''\n    \n    return cosine_similarity(embeddings, query.reshape(1, -1)).squeeze()\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"# Load the data\nrecipes = pd.read_csv('/kaggle/input/food-com-recipes-and-user-interactions/PP_recipes.csv')\ningr_map = pd.read_pickle('/kaggle/input/food-com-recipes-and-user-interactions/ingr_map.pkl')\nraw_recipes = pd.read_csv('/kaggle/input/food-com-recipes-and-user-interactions/RAW_recipes.csv')\n\n# Transform all the ingredient id strings into lits of integers\nrecipes['ingredient_ids'] = recipes['ingredient_ids'].map(lambda str: [int(ingr_id) for ingr_id in str[1:-1].split(', ')])\n\n# Create a cross-reference tables for all recipes and ingredients\nrecipe_ingr_xref = make_recipe_ingr_xref(recipes)\n\n# Get the tf-idf embeddings\ntf_idf_embeddings = get_tf_idf_embeddings(recipe_ingr_xref)\n\n# Merge preprocessed and raw recipe tables\nfull_recipes = recipes.merge(raw_recipes, left_on='id', right_on='id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"recipe_id = 13\nk = 10\n\ncontent_recs = similar_recipes(tf_idf_embeddings, recipe_id, k)\ncollab_recs = similar_recipes(model.item_factors, recipe_id, k)\n\nprint(f'If you liked {full_recipes[full_recipes[\"i\"] == recipe_id].iloc[0][\"name\"]}, you might also like:')\nfor i, rec in enumerate(content_recs):\n    print(full_recipes[full_recipes['i'] == rec].iloc[0]['name'])\n    \nprint()    \n\nprint(f'Customers who liked {full_recipes[full_recipes[\"i\"] == recipe_id].iloc[0][\"name\"]} also liked:')\nfor i, rec in enumerate(collab_recs):\n    print(full_recipes[full_recipes['i'] == rec].iloc[0]['name'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"# Old-style content-based reccomendations\n\n# Pull so many more similar recipes to a given recipe\n# We can't compute the entire similarity matrix: it's too much data\n# Seems to work reasonably well, though, based on recipe names!\n'''\nTEST_RECIPE = 0\nNUM_RECIPES = 10 # (the first one is the recipe itself)\n\nsimilarities = cosine_similarity(embeddings, embeddings[TEST_RECIPE])\nmost_similar = np.argsort(similarities.squeeze())[-NUM_RECIPES:][::-1]\nprint(most_similar)\nraw_recipes[raw_recipes['id'].isin(recipes[recipes.index.isin(most_similar)]['id'].values)]\n'''","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Collaborative Filtering Model (Matrix Completion)"},{"metadata":{},"cell_type":"markdown","source":"A parameter search across iterations revealed that a model with 8 factors, 8 alpha performed much better at 30 iterations than at 15 (relatively speaking)"},{"metadata":{},"cell_type":"markdown","source":"### Run the following 2 cells to get all functions for collaborative filtering"},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"\n'''\nVarious metrics for evaluating collaborative filtering models\n\nMetric implementations based in part from: https://github.com/benhamner/Metrics/blob/master/Python/ml_metrics/average_precision.py\nFormulas from: http://sdsawtelle.github.io/blog/output/mean-average-precision-MAP-for-recommender-systems.html\n'''\n\n# Individual user metrics\n###########################\n\ndef precision_at_k(interaction_matrix, positive_interactions, user_id, recs):\n    '''\n    interaction_matrix is a matrix of shape (items, users) that you wish to evaluate reccomendations on\n    positive_interactions should be a Pandas Series mapping user_id to the number positive interactions they have in the given matrix\n    user_id is the integer of the user to evaluate\n    recs is a list of k recipes ids that are being reccomended, in order\n    \n    Returns the precision@k: the proportion of reccomendations made that are relevant out of total reccomendations\n    '''\n    \n    relevant_reccomendations = interaction_matrix[recs, user_id].sum()\n    \n    return relevant_reccomendations / len(recs)\n\ndef adjusted_precision_at_k(interaction_matrix, positive_interactions, user_id, recs):\n    '''\n    Similar to precision_at_k, but will adjust the precision if there are fewer relevant items than reccomendations made\n    '''\n\n    relevant_reccomendations = interaction_matrix[recs, user_id].sum()\n    max_possible_relevant = min(len(recs), positive_interactions[user_id])\n    \n    return relevant_reccomendations / max_possible_relevant\n    \ndef average_precision(interaction_matrix, positive_interactions, user_id, recs, adjusted=False):\n    '''\n    Parameters defined as above\n    \n    adjusted determines whether or not to use adjust precision@k when computing average precision\n    '''\n    \n    precision_func = adjusted_precision_at_k if adjusted else precision_at_k\n    \n    precisions = [precision_func(interaction_matrix, positive_interactions, user_id, recs[:k+1]) for k in range(len(recs)) if interaction_matrix[recs[k], user_id] == 1]\n    \n    return (1 / positive_interactions[user_id]) * sum(precisions)\n\n# Aggregate metrics\n######################\n\ndef mean_precision_at_k(interaction_matrix, positive_interactions, rec_matrix, adjusted=False):\n    '''\n    rec_matrix is a matrix of shape (users, reccomendations) with item_ids recomended for each user\n    \n    Computes the mean precision at k across all users\n    '''\n    \n    precision_func = adjusted_precision_at_k if adjusted else precision_at_k\n    \n    total = 0\n    \n    for user_id in tqdm.tqdm(range(interaction_matrix.shape[1])):\n        total += precision_func(interaction_matrix, positive_interactions, user_id, rec_matrix[user_id])\n    \n    return total / interaction_matrix.shape[1]\n\ndef mean_average_precision(interaction_matrix, positive_interactions, rec_matrix, adjusted=False):\n    '''\n    Computes the mean average precision across all users (excuse the double \"mean\")\n    '''\n\n    total = 0\n    \n    for user_id in tqdm.tqdm(range(interaction_matrix.shape[1])):\n        total += average_precision(interaction_matrix, positive_interactions, user_id, rec_matrix[user_id], adjusted=adjusted)\n    \n    return total / interaction_matrix.shape[1]\n    \n'''\ninteraction_matrix = np.array([[0, 0, 1, 0, 0, 1, 1, 0, 0], [0, 0, 0, 1, 0, 0, 1, 0, 0]]).T\npositive_interactions = interaction_matrix.sum(axis=0)\n\nuser_id = 0\nrecs = [2, 3, 4, 5, 6]\n\naverage_precision(interaction_matrix, positive_interactions, user_id, recs) # Should be 0.7 if everything is correct\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"'''\nData loading and splitting\n'''\n\n# NOTE: these splits do not all represent all users. Training data does, but test and validation are missing some users\n# Also note there is a very large range in interaction number: between 2 and 6000 reviews per person (25% are just 2)\ndf1 = pd.read_csv('/kaggle/input/food-com-recipes-and-user-interactions/interactions_train.csv')\ndf2 = pd.read_csv('/kaggle/input/food-com-recipes-and-user-interactions/interactions_test.csv')\ndf3 = pd.read_csv('/kaggle/input/food-com-recipes-and-user-interactions/interactions_validation.csv')\n\n# Combine the interaction data together, so that we can create our own splits\n# 718379 interactions (raw)\ndf = pd.concat((df1, df2, df3), ignore_index=True)\n\n# Dropping all the interactions that are less than 3\n# This complicates things, because we need to reset the user ids\n# I think this is something to do in the future, but will require some more work\n'''\n# Dropping all ratings that are less than 3 (consider those negative interations)\n# 689321 interactions (losing 29,000 interactions)\ndf.drop(df[df['rating'] < 3].index, inplace=True)\n\n# Dropping all users that now have less than 2 interactions (lose 552 users, 552 interactions)\n# 688769 interactions\ntoo_few = df.groupby('u')['rating'].count() < 2 # Dataframe storing True/False for each user having too few ratings\ntoo_few_users = too_few.index[too_few] # Stores a list of user ids with too few ratings\n\ndf.drop(df[df['u'].isin(too_few_users)].index, inplace=True)\n\n# Resulting interaction matrix is 24392 x 173600 (99.98% sparse, which does seem high...)\n# Can consider eliminating some recipes with fewer than 1 rating (but that is 80601 recipes, nearly 50%)\n'''\n\n# In theory, we could do k-fold cross validation, but then we'd need to have k interactions per user\n# So I think deciding to change the minimum number of reviews is a precondition to even attempting k-fold cross validation\n\nuser_train, user_test, item_train, item_test, =\\\n    safe_train_test_split(df['u'], df['i'], test_size=0.25, random_state=1)\n\n# Total users: 25075\n# Total items: 178264\n\n# Build the new dataframes from the train-test split\ntrain_interactions = pd.DataFrame({'u': user_train, 'i': item_train, 'rating': 1})\ntest_interactions = pd.DataFrame({'u': user_test, 'i': item_test, 'rating': 1})\n\n# Store the number of positive interactions associated with each user to avoid recomputing for precision@k metrics\npositive_train_interactions = train_interactions.groupby('u')['rating'].count()\npositive_test_interactions = test_interactions.groupby('u')['rating'].count()\n\n# Supplement both with a 0 rating at the max user and recipe id to make matrices the same size\n# This is a dumb solution to the problem of some recipes only appearing once\n# I can only stratify across one thing anyways, so I think we're going to have problems with some recipes\n# having a learned embedding. The good news is the metrics will be more user-focused, so it should be OK\n\n# Basically, this is a hacky solution, but I think it's the best way to do it (without eliminating massive\n# swathes of data and creating a complicated dual-class stratification algorithm which probably won't even\n# end up working because users and recipes probably aren't distributed nicely)\n\ntrain_interactions = train_interactions.append({'u': max(df['u']), 'i': max(df['i']), 'rating': 0}, ignore_index=True)\ntest_interactions = test_interactions.append({'u': max(df['u']), 'i': max(df['i']), 'rating': 0}, ignore_index=True)\n\ntrain_matrix = csr_matrix((np.ones(len(train_interactions)), (train_interactions['i'], train_interactions['u'])))\ntest_matrix = csr_matrix((np.ones(len(test_interactions)), (test_interactions['i'], test_interactions['u'])))\ncomplete_matrix = train_matrix + test_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"# Note: mean precision takes a lot longer when you include 100 reccomendations\n'''\ntrain_p_at_k = mean_precision_at_k(train_matrix, positive_train_interactions, train_rec_matrix[:, :10], adjusted=False)\ntest_p_at_k = mean_precision_at_k(test_matrix, positive_test_interactions, test_rec_matrix[:, :10], adjusted=False)\n\ntrain_adj_p_at_k = mean_precision_at_k(train_matrix, positive_train_interactions, train_rec_matrix[:, :10], adjusted=True)\ntest_adj_p_at_k = mean_precision_at_k(test_matrix, positive_test_interactions, test_rec_matrix[:, :10], adjusted=True)\n\ntrain_mean_p = mean_average_precision(train_matrix, positive_train_interactions, train_rec_matrix[:, :10], adjusted=False)\ntest_mean_p = mean_average_precision(test_matrix, positive_test_interactions, test_rec_matrix[:, :10], adjusted=False)\n\ntrain_mean_p_adj = mean_average_precision(train_matrix, positive_train_interactions, train_rec_matrix[:, :10], adjusted=True)\ntest_mean_p_adj = mean_average_precision(test_matrix, positive_test_interactions, test_rec_matrix[:, :10], adjusted=True)\n\nrand_p_at_k = mean_precision_at_k(test_matrix, positive_test_interactions, random_matrix[:, :10], adjusted=False)\nrand_adj_p_at_k = mean_precision_at_k(test_matrix, positive_test_interactions, random_matrix[:, :10], adjusted=True)\nrand_mean_p = mean_average_precision(test_matrix, positive_test_interactions, random_matrix[:, :10], adjusted=False)\nrand_mean_p_adj = mean_average_precision(test_matrix, positive_test_interactions, random_matrix[:, :10], adjusted=True)\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"scrolled":false},"cell_type":"code","source":"'''\ntrain_rec_matrix, test_rec_matrix = train_test_rec_matrix(model.item_factors, model.user_factors, 100, train_interactions)\nrandom_matrix = random_rec_matrix(train_matrix, 100)\n\nassert mean_precision_at_k(train_matrix, positive_train_interactions, test_rec_matrix, adjusted=False) == 0\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"'''\nprint(train_p_at_k, test_p_at_k, rand_p_at_k)\nprint(train_adj_p_at_k,test_adj_p_at_k, rand_adj_p_at_k)\nprint(train_mean_p, test_mean_p, rand_mean_p)\nprint(train_mean_p_adj, test_mean_p_adj, rand_mean_p_adj)\n'''\n'''\nPre proper filtering (10 recs):\n0.09332828202262554 0.006751475514435921 2.7915137980539158e-05\n0.24018909499248356 0.024444925521652214 4.320199925559632e-05\n0.1406715379458244 0.00753182893600831 5.866304081570052e-06\n0.17384917444761513 0.0185085742058478 7.638693794620157e-06\n\nProper filtering @10 recs\n0.09339208805229554 0.00802759610783195 4.386664539799011e-05\n0.2378505058906556 0.02794409756245771 7.975753708725475e-05\n0.13841172806680735 0.009886528168548337 2.1529499979817866e-05\n0.17088549890951885 0.021114400425549178 4.146888425163155e-05\n\nProper filtering @100 recs\n0.02811652576167531 0.003499361939703625 4.426543308342641e-05\n0.3901281604724576 0.09905876639766126 0.0007262624622543001\n0.15152008275914267 0.012511155940690546 3.548401140167055e-05\n0.25815126573941893 0.07473983983342303 0.0004636069582234532\n\n\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"def make_results_dict():\n    return {\n        'factors': [],\n        'regularization': [],\n        'alpha': [],\n        'iterations': [],\n        'train_p_at_k': [],\n        'test_p_at_k': [],\n        'train_mean_p': [],\n        'test_mean_p': []\n    }\n\ndef compute_metrics(model, step, k, train_interactions, factors, regularization, alpha, results):\n    def compute(iteration, time):\n        if (iteration + 1) % step == 0:\n            train_rec_matrix, test_rec_matrix = collab_filter_train_test_matrix(model.item_factors, model.user_factors, k, train_interactions)\n            \n            train_adj_p_at_k = mean_precision_at_k(train_matrix, positive_train_interactions, train_rec_matrix, adjusted=True)\n            test_adj_p_at_k = mean_precision_at_k(test_matrix, positive_test_interactions, test_rec_matrix, adjusted=True)\n\n            train_mean_p_adj = mean_average_precision(train_matrix, positive_train_interactions, train_rec_matrix, adjusted=True)\n            test_mean_p_adj = mean_average_precision(test_matrix, positive_test_interactions, test_rec_matrix, adjusted=True)\n            \n            results['factors'].append(factors)\n            results['regularization'].append(regularization)\n            results['alpha'].append(alpha)\n            results['iterations'].append(iteration+1)\n            \n            results['train_p_at_k'].append(train_adj_p_at_k)\n            results['test_p_at_k'].append(test_adj_p_at_k)\n            results['train_mean_p'].append(train_mean_p_adj)\n            results['test_mean_p'].append(test_mean_p_adj)\n            \n            print(f'Iteration: {iteration + 1}')\n            print(f'Adjusted precision@k: Train: {train_adj_p_at_k}, Test: {test_adj_p_at_k}')\n            print(f'Adjusted mean precision: Train: {train_mean_p_adj}, Test: {test_mean_p_adj}')\n            print()\n    \n    return compute\n\ndef train_model(factors, regularization, alpha, iterations, metric_steps, train_interactions, results, k=10, random_state=0):\n    model = implicit.als.AlternatingLeastSquares(factors=factors, iterations=iterations, regularization=regularization, random_state=random_state)\n    \n    model.fit_callback = compute_metrics(model, metric_steps, k, train_interactions, factors, regularization, alpha, results)\n    \n    model.fit(alpha * train_matrix)\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"factors = [8]\nregularizations = [0.1]\nalphas = [64]\niteration_step = 30\nmax_iterations = 30\n\nk = 10\n\nresults = make_results_dict()\n\nfor factor, regularization, alpha in product(factors, regularizations, alphas):\n    print(f'Factors: {factor}, regularization: {regularization}, alpha: {alpha}')\n    \n    model = train_model(factor, regularization, alpha, max_iterations, iteration_step, train_interactions, results)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nA bunch of functions that I don't think I need anymore, but am keeping just in case\n\nImplementations for collaborative filtering reccomendation generation that compute things in blocks.\nThis was an attempt to speed up reccomendation generation b/c it allows for faster matrix multiplication.\nHowever, getting the top k elements takes far longer, so the improvement is margianl on CPU, and non-existent on GPU\n\nAlso, some older implemenetations of reccomendation generation\n'''\n\ndef get_block_predictions(item_matrix, user_matrix, start_user_id, step):\n    return (item_matrix @ user_matrix[start_user_id:start_user_id + step, :].T).T\n\ndef get_block_reccomendations(predictions, k):\n    # Get the top k reccoemndations for each user (row) in the prediction matrix provided\n    unsorted_recs = np.argpartition(predictions, -k)[:, -k:]\n    \n    # Pull the predicted values for those reccomendations\n    rec_values = np.take_along_axis(predictions, unsorted_recs, axis=1)\n    \n    # Get the indices to sort the reccoemndation by predicted values\n    rec_order = np.argsort(rec_values)[:, ::-1]\n    \n    # Use the sorted indices to get the reccomendations in sorted order\n    sorted_recs = np.take_along_axis(unsorted_recs, rec_order, axis=1)\n    \n    return sorted_recs\n\ndef get_block_rec_matrix(item_matrix, user_matrix, k, block_size=4):\n    rec_matrix = []\n    \n    for start_user_id in tqdm.tqdm(range(0, user_matrix.shape[0], block_size)):\n        predictions = get_block_predictions(item_matrix, user_matrix, start_user_id, block_size)\n        recs = get_block_reccomendations(predictions, k, train_interactions, filter_recs)\n        \n        rec_matrix.append(recs)\n\n    return np.vstack(rec_matrix)\n\ndef train_test_block_rec_matrix(item_matrix, user_matrix, k, train_interactions, block_size=4):\n    train_rec_matrix = []\n    test_rec_matrix = []\n    \n    for start_user_id in tqdm.tqdm(range(0, user_matrix.shape[0], block_size)):\n        # Get the predictions without filtering out known-positives from the test set\n        predictions = get_block_predictions(item_matrix, user_matrix, start_user_id, block_size)\n        train_recs = get_block_reccomendations(predictions, k)\n        \n        # Get the ids of the interactions to filter out\n        filter_idxs = np.array([train_interactions[train_interactions['u'] == user_id]['i'].values for user_id in range(start_user_id, start_user_id+block_size)])\n        print(filter_idxs)\n        \n        # Give the reccomendations from the train set low values to prevent them from being reccomended\n        zeros = np.array([np.full_like(f, 0) for f in filter_idxs])\n        test_predictions = np.put_along_axis(predictions, filter_idxs, zeros, axis=1)\n        \n        # Regenerate reccomendations with the filtered predictions\n        test_recs = get_block_reccomendations(test_predictions, k)\n        \n        train_rec_matrix.append(train_recs)\n        test_rec_matrix.append(test_recs)\n\n    return np.vstack(train_rec_matrix), np.vtack(test_rec_matrix)\n\ndef custom_create_rec_matrix(item_matrix, user_matrix, k, train_interactions=None, filter_recs=False):\n    '''\n    Returns a numpy array of size (users, k) with the top k reccomendations for each user\n    '''\n\n    rec_matrix = []\n    \n    for user_id in tqdm.tqdm(range(user_matrix.shape[0])):\n        recs = get_reccomendations(item_matrix, user_matrix, user_id, k, train_interactions, filter_recs)[0]\n        \n        rec_matrix.append(recs)\n\n    return np.array(rec_matrix)\n\ndef create_rec_matrix(model, train_matrix, k, test_mode=False):\n    '''\n    model is implicit reccomendation model\n    train_matrix is the interaction matrix the model trained on\n    k is the number of reccomendations to generate per user\n    test mode: if true, will filter out recomendations from the train matrix\n    '''\n    \n    rec_matrix = []\n    \n    for user_id in tqdm.tqdm(range(train_matrix.shape[1])):\n        recs = [rec[0] for rec in model.recommend(user_id, train_matrix.T, k, filter_already_liked_items=test_mode)]\n        \n        rec_matrix.append(recs)\n\n    return np.array(rec_matrix)\n\ndef get_reccomendations(item_matrix, user_matrix, user_id, k, train_interactions=None, filter_recs=False):\n    '''\n    item matrix is of shape (items, features) describing the features for each item\n    user_matrix is of shape (users, features) describing the features for each user\n    user_id is an integer, the user to get reccomendations for\n    train_interactions is a pandas dataframe describing all positive interactions the model trained on (faster than interaction matrix)\n    filter determines whether or not to eliminate reccomendations that have a positive interaction in the train_matrix\n    \n    Returns a tuple, (reccomendations, values) where reccomendations is a list of length k with reccomendation indices, and values gives \n    \n    Note: this was created because implicit's built in reccomend function is slow, and doesn't filter out the training reccomendations\n    '''\n    \n    # Get all predicted values for the user\n    predictions = item_matrix @ user_matrix[user_id, :]\n    \n    if filter_recs:\n        #trained_recs_a = np.nonzero(train_matrix[:, user_id])[0]\n        trained_recs = train_interactions[train_interactions['u'] == user_id]['i'].values\n        \n        predictions[trained_recs] = 0\n    \n    # Get the top k reccomendations for the user(NOTE: this function does not return them in sorted order)\n    unsorted_recs = np.argpartition(predictions, -k)[-k:]\n    \n    # Sort the reccomendations produced by their values, in descending order (that's how the metrics expect them)\n    sorted_recs = sorted(unsorted_recs, key=lambda rec: predictions[rec], reverse=True)\n    \n    # Get the values associated with these reccomendations\n    sorted_values = predictions[sorted_recs]\n    \n    return sorted_recs, sorted_values\n    \ndef train_test_reccomendations(item_matrix, user_matrix, user_id, k, train_interactions):\n    '''\n    Produces both train and test reccomendations for a user at once, which should be more efficient\n    '''\n    \n    # Get all predicted values for the user\n    predictions = item_matrix @ user_matrix[user_id, :]\n    \n    # Get unfiltered reccomendations\n    unsorted_recs = np.argpartition(predictions, -k)[-k:]\n    sorted_recs = sorted(unsorted_recs, key=lambda rec: predictions[rec], reverse=True)\n    \n    # Filter the predictions\n    trained_recs = train_interactions[train_interactions['u'] == user_id]['i'].values\n    predictions[trained_recs] = 0\n        \n    # Get the filtered predictions\n    unsorted_filtered_recs = np.argpartition(predictions, -k)[-k:]\n    sorted_filtered_recs = sorted(unsorted_filtered_recs, key=lambda rec: predictions[rec], reverse=True)\n    \n    return sorted_recs, sorted_filtered_recs\n    \ndef train_test_rec_matrix(item_matrix, user_matrix, k, train_interactions):\n    '''\n    Produces a train and test reccomendation matrix\n    \n    This is about 30% faster than generating them seperately\n    '''\n    \n    train_rec_matrix = []\n    test_rec_matrix = []\n    \n    for user_id in tqdm.tqdm(range(user_matrix.shape[0])):\n        train_recs, test_recs = train_test_reccomendations(item_matrix, user_matrix, user_id, k, train_interactions)\n        \n        train_rec_matrix.append(train_recs)\n        test_rec_matrix.append(test_recs)\n\n    return np.array(train_rec_matrix), np.array(test_rec_matrix)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"df1 = pd.DataFrame(results)\n#df2.groupby(['factors', 'regularization', 'alpha']).max()\ndf = pd.concat((df, df1))\ndf.to_csv('param_search1.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby(['factors', 'regularization', 'alpha']).max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"scrolled":false},"cell_type":"code","source":"# Non-negative matrix factorization\n# I don't NMF is what we want. The matrix is far too sparse, and this was too slow\n\nfrom sklearn.decomposition import NMF\n\n# Ratings matrix\n# 16 components: 257 iterations, 3790.7093189610523 error, 0.0275 reconstructed\n# 32 components: 87 iterations, 3707.651615877227 error, 0.0917 reconstructed\n# 64 components: 172 iterations, 3583.3304672483646 error, 0.1284 reconstructed\n# 128 components: 137 iterations, 3404.455889599025 error, 0.1835 reconstructed, found a new reccoemendation\n#      (very slow, 20+ minutes, violation started going up at about 100 iterations in)\n# 256 components: 237 iterations, 3167 error, 0.3119 reconstructed\n#      (very, very slow, 3+ hours, violation also went up at about 100 iterations)\n\nmodel = NMF(n_components=256, random_state=0, max_iter=500, verbose=1)\n\nW = model.fit_transform(ratings_matrix)\n\nH = model.components_\n\nprint(model.n_iter_)\nprint(model.reconstruction_err_)\n\ngood = 0\ntotal = 0\nfor i in range(0, 100):\n    for j in range(0, 100):\n        if ratings_matrix[i, j] != 0:\n            total += 1\n            print(i, j, ratings_matrix[i, j], W[i] @ H[:, j])\n            if W[i] @ H[:, j] > 1:\n                good += 1\n        elif W[i] @ H[:, j] > 1:\n            print('NEW ONE!')\nprint(good / total)\nprint(good, total)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"scrolled":false},"cell_type":"code","source":"# Matrix Factorization in Keras: requires sampling from negative interactions, handling balance\n# Overfit like crazy with the metrics I had selected (unsure how that compares to other metrics)\n# Does allow for custom, tunable objective functions\n# Is the direction we may go in with neural collaborative filtering...\n\ndef mf_model(num_users, num_recipes, rank):\n    user_input = keras.Input((1, ))\n    recipe_input = keras.Input((1, ))\n    \n    user_embedding = layers.Embedding(num_users, rank)(user_input)\n    recipe_embedding = layers.Embedding(num_recipes, rank)(recipe_input)\n    \n    dot_product = layers.Dot(axes=(2))([user_embedding, recipe_embedding])\n    \n    return keras.Model(inputs=[user_input, recipe_input], outputs=dot_product)\n\n# A rank of 5 stopped the validation loss from going below 19.5421 (which is really bad)\n# Rank 32: increase trainable paramters to 6 million. Validation loss is still awful\n# Increasing batch size to 512 sped things up, unsure on performance differences\n\n# Rank 16, still overfitting very strongly\n\nmodel = mf_model(max(df['u'] + 1), max(df['i'] + 1), 16)\nmodel.summary()\n\nmodel.compile(loss='mean_squared_error', optimizer=keras.optimizers.Adam(learning_rate=0.001))\n\nhistory = model.fit(x=X_train, y=y_train, batch_size=512, epochs=10, validation_data=(X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"scrolled":false},"cell_type":"code","source":"# Parameter search for implicit ALS weighted regularized matrix factorization (WRMF)\n# This method is the most hopeful of any of the methods explores thus far\n\nimport itertools\n\ndef get_rmse(y_true, y_w, y_h, block_size=4):\n    total_rmse = 0\n    \n    for i in tqdm.tqdm(range(0, y_true.shape[0], block_size)):\n        total_rmse += mean_squared_error(y_true[:, i:i + block_size].toarray(), y_w @ y_h[i:i + block_size].T, squared=False)\n\n    total_rmse /= (binary_matrix.shape[0] / block_size)\n    \n    return total_rmse\n    \nalphas = [32, 64, 128]\nfactors = [32, 64, 128]\nregularizations = [0.1, 1, 10]\niterations = 15\n\ncombos = itertools.product(alphas, factors, regularizations)\nmse_scores = {}\nhit_rate_scores = {}\n\nfor alpha, factor, regularization in combos:\n    # initialize a model\n    model = implicit.als.AlternatingLeastSquares(factors=factor, random_state=0, calculate_training_loss=True, iterations=iterations, regularization=regularization)\n\n    # train the model on a sparse matrix of item/user/confidence weights\n    model.fit(alpha * binary_matrix)\n\n    mse = get_mse(binary_matrix, model.item_factors, model.user_factors)\n    \n    W = model.item_factors\n    H = model.user_factors\n\n    good = 0\n    total = 0\n    for i in range(0, 100):\n        for j in range(0, 100):\n            if binary_matrix[i, j] != 0:\n                total += 1\n                if W[i] @ H[j] > 0.5:\n                    good += 1\n                    \n    hit_rate = good / total\n    \n    print(alpha, factor, regularization, mse, hit_rate)\n    \n    mse_scores[(alpha, factor, regularization)] = mse\n    hit_rate_scores[(alpha, factor, regularization)] = hit_rate","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Doc2Vec Embeddings\n(Didn't seem to work very well, on hold until later)\nNote: may not have worked well due to swapping the i column, and the index of the recipes"},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n\n# Following documentation here: https://radimrehurek.com/gensim/models/doc2vec.html","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"ingr_map","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"simple_ingr_map = ingr_map[['id', 'replaced']].set_index('id').drop_duplicates().to_dict()['replaced']\nrecipes['ingredients'] = recipes['ingredient_ids'].map(lambda ingredient_ids: [simple_ingr_map[ingregient_id] for ingregient_id in ingredient_ids])\ndocuments = [TaggedDocument(doc, [i]) for i, doc in enumerate(recipes['ingredients'])]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"model = Doc2Vec(vector_size=5, window=2, min_count=1, workers=4)\nmodel.build_vocab(documents, progress_per=1000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"model.train(documents=documents, total_examples=model.corpus_count, epochs=30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"TEST_RECIPE = 2\nNUM_RECIPES = 10 # (the first one is the recipe itself)\n\nsimilarities = model.docvecs.distances(TEST_RECIPE)\nmost_similar = np.argsort(similarities.squeeze())[-NUM_RECIPES:]\nraw_recipes[raw_recipes['id'].isin(recipes[recipes.index.isin(most_similar)]['id'].values)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"#reads in all of the datasets \nrecipes = pd.read_csv('/kaggle/input/food-com-recipes-and-user-interactions/PP_recipes.csv')\nraw_recipes = pd.read_csv('/kaggle/input/food-com-recipes-and-user-interactions/RAW_recipes.csv')\nraw_interactions = pd.read_csv('/kaggle/input/food-com-recipes-and-user-interactions/RAW_interactions.csv')\n\n#combines the raw recipes and numbered recipes into one table\n#merges them by the recipe id number\nrecipes_info = recipes.merge(raw_recipes, left_on='id', right_on='id')\n\n#merges all of the recipe information with the ratings\nrecipes_interact = recipes_info.merge(raw_interactions, left_on='id', right_on='recipe_id')\n\n#can easily change which columns we want to output by updating this \nkeep_cols = ['name','id','minutes', 'contributor_id', 'description', 'submitted', 'tags', 'nutrition', 'n_steps', 'ingredient_tokens', 'ingredient_ids', 'steps','steps_tokens', 'user_id', 'date', 'rating', 'review']\n\n#prints out the merged table with only the desired columns\nnew_recipes_info = recipes_interact[keep_cols]\nnew_recipes_info","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}