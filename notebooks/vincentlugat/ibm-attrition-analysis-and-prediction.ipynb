{"cells":[{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"----------\n**IBM Attrition Analysis and Prediction**\n=====================================\n\n***XGB : CV - Accuracy (5 folds) =  .891***\n\n***Vincent Lugat***\n\n*October 2018*\n\n----------"},{"metadata":{"_uuid":"21c1be5c32b1987bff4d827804778f1db54a23c6"},"cell_type":"markdown","source":"![](http://image.noelshack.com/fichiers/2018/41/1/1539014632-1-bye.png)\n\nsource : http://thecontextofthings.com/2017/01/06/employee-attrition/"},{"metadata":{"_uuid":"c05d96007d517ef7c498690daed5a9b80db645c0"},"cell_type":"markdown","source":"- <a href='#1'>1. Load libraries and read the data</a>  \n    - <a href='#1.1'>1.1. Load libraries</a> \n    - <a href='#1.2'>1.2. Read the data</a> \n    - <a href='#1.3'>1.3. Missing values</a> \n    - <a href='#1.4'>1.4. Reassign target and drop useless features</a> \n- <a href='#2'>2. Exploratory Data Analysis (EDA)</a> \n    - <a href='#2.1'>2.1. Head and describe</a> \n    - <a href='#2.2'>2.2. Target distribution (number and %)</a> \n    - <a href='#2.3'>2.3. Features distribution and barplot (hue = Attrition)</a> \n    - <a href='#2.4'>2.4. Pie plot and barplot</a> \n- <a href='#3'>3. Feature engineering and selection</a>\n    - <a href='#3.1'>3.1. New features (24) </a> \n    - <a href='#3.2'>3.2. Drop some features</a> \n    - <a href='#3.3'>3.3. Features encoding and scaling</a>\n    - <a href='#3.4'>3.4. Correlation Matrix</a>\n    - <a href='#3.5'>3.5. Remove collinear features</a>\n- <a href='#4'>4. Define functions</a>\n    - <a href='#4.1'>4.1. Define model performance plot </a> \n    - <a href='#4.2'>4.2. Define feature importance plot </a> \n    - <a href='#4.3'>4.3. Define cumulative gains curve</a>\n    - <a href='#4.4'>4.4. Define cross validation metrics</a>\n- <a href='#5'>5. Prepare dataset</a>\n    - <a href='#5.1'>5.1. Define (X,  y)</a> \n    - <a href='#5.2'>5.2. Train test split</a> \n- <a href='#6'>6. XGBoost - RandomizedSearchCV to optimize hyperparameters (800 comb)</a> \n\n- <a href='#7'>7. XGBoost - With best hyperparameters = 89.11</a>\n    - <a href='#7.1'>7.1. XGBoost - Modeling and performance plot</a> \n    - <a href='#7.2'>7.2. XGBoost - Feature importance </a> \n    - <a href='#7.3'>7.3. XGBoost - Cumulative gains curve</a> \n    - <a href='#7.4'>7.4. XGBoost - Cross validation (5 folds)</a> "},{"metadata":{"_uuid":"f2a6a17180340827442bbd04fd673376388d0826"},"cell_type":"markdown","source":"# <a id='1'>1. Load libraries and read the data</a> "},{"metadata":{"_uuid":"f23306927fb09ce1eab26c6d36b9f70f62783dd6"},"cell_type":"markdown","source":"## <a id='1.1'>1.1. Load libraries</a> "},{"metadata":{"trusted":true,"_uuid":"e747c5e20f9fd17baff29a26b302a86638c700f3"},"cell_type":"code","source":"# Python libraries\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_val_score, learning_curve, train_test_split\nfrom sklearn.metrics import precision_score, roc_auc_score, recall_score, confusion_matrix, roc_curve, precision_recall_curve, accuracy_score\nimport xgboost as xgb\nimport warnings\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nimport plotly.figure_factory as ff\n\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5c97342a31c13633a60e206be88f80db3e25fbce"},"cell_type":"markdown","source":"## <a id='1.2'>1.2. Read the data</a>"},{"metadata":{"trusted":true,"_uuid":"e3768ada4565e9354e814b7ff978270fa86dee61"},"cell_type":"code","source":"data = pd.read_csv('../input/WA_Fn-UseC_-HR-Employee-Attrition.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e10bd81750d48d6fa1efaff7bfd657bbf956b442"},"cell_type":"markdown","source":"## <a id='1.3'>1.3. Missing values</a>"},{"metadata":{"trusted":true,"_uuid":"2e4e64be3951b9e7bcd57eb4a7ddad37773dfd51"},"cell_type":"code","source":"null_feat = pd.DataFrame(len(data['Attrition']) - data.isnull().sum(), columns = ['Count'])\n\ntrace = go.Bar(x = null_feat.index, y = null_feat['Count'] ,opacity = 0.8, marker=dict(color = 'lightgrey',\n        line=dict(color='#000000',width=1.5)))\n\nlayout = dict(title =  \"Missing Values\")\n                    \nfig = dict(data = [trace], layout=layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b7606cecfcf02bf329bbeba4b94701cb59f82b44"},"cell_type":"markdown","source":"## <a id='1.4'>1.4. Reassign target and drop useless features</a>"},{"metadata":{"trusted":true,"_uuid":"53ebb3d71ba18c719c7ea5e8b309a058672bc582"},"cell_type":"code","source":"# Reassign target\ndata.Attrition.replace(to_replace = dict(Yes = 1, No = 0), inplace = True)\n# Drop useless feat\ndata = data.drop(columns=['StandardHours', \n                          'EmployeeCount', \n                          'Over18',\n                        ])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"963bdedb797062249197b1a13683010631f51f06"},"cell_type":"markdown","source":"# <a id='2'>2. Exploratory Data Analysis (EDA)</a>"},{"metadata":{"_uuid":"383644d56422567306ab05e6f12b05b764e778a8"},"cell_type":"markdown","source":"## <a id='2.1'>2.1. Head and describe</a> "},{"metadata":{"trusted":true,"_uuid":"248f53119c5c080364151bfefed47f77d1319e5d"},"cell_type":"code","source":"# head\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"705f70983fc75e0db96ab97e851c32e53d51092f"},"cell_type":"code","source":"# describe\ndata.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7a99febaf823220027a167ae6cedec751657a1e1"},"cell_type":"markdown","source":"## <a id='2.2'>2.2. Target distribution (number and %)</a> "},{"metadata":{"trusted":true,"_uuid":"74ad8bfadf7fb6a0fdc4c1b34c57d707c9692af5"},"cell_type":"code","source":"attrition = data[(data['Attrition'] != 0)]\nno_attrition = data[(data['Attrition'] == 0)]\n\n#------------COUNT-----------------------\ntrace = go.Bar(x = (len(attrition), len(no_attrition)), y = ['Yes_attrition', 'No_attrition'], orientation = 'h', opacity = 0.8, marker=dict(\n        color=['gold', 'lightskyblue'],\n        line=dict(color='#000000',width=1.5)))\n\nlayout = dict(title =  'Count of attrition variable')\n                    \nfig = dict(data = [trace], layout=layout)\npy.iplot(fig)\n\n#------------PERCENTAGE-------------------\ntrace = go.Pie(labels = ['No_attrition', 'Yes_attrition'], values = data['Attrition'].value_counts(), \n               textfont=dict(size=15), opacity = 0.8,\n               marker=dict(colors=['lightskyblue','gold'], \n                           line=dict(color='#000000', width=1.5)))\n\n\nlayout = dict(title =  'Distribution of attrition variable')\n           \nfig = dict(data = [trace], layout=layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4d27ccfbebae0c3f707298c3d5b3cf3cc41ecef1"},"cell_type":"markdown","source":"## <a id='2.3'>2.3. Features distribution and barplot (hue = Attrition)</a> "},{"metadata":{"trusted":true,"_uuid":"2f13f26c190b15d9b1fe64dfbdb660e5c5ebbc50"},"cell_type":"code","source":"def plot_distribution(var_select, bin_size) : \n# Calculate the correlation coefficient between the new variable and the target\n    corr = data['Attrition'].corr(data[var_select])\n    corr = np.round(corr,3)\n    tmp1 = attrition[var_select]\n    tmp2 = no_attrition[var_select]\n    hist_data = [tmp1, tmp2]\n    \n    group_labels = ['Yes_attrition', 'No_attrition']\n    colors = ['#FFD700', '#7EC0EE']\n\n    fig = ff.create_distplot(hist_data, group_labels, colors = colors, show_hist = True, curve_type='kde', bin_size = bin_size)\n    \n    fig['layout'].update(title = var_select+' '+'(corr target ='+ str(corr)+')')\n\n    py.iplot(fig, filename = 'Density plot')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1ef21a5944ac7c3939631417292ae17cc586c6a4"},"cell_type":"code","source":"def barplot(var_select, x_no_numeric) :\n    tmp1 = data[(data['Attrition'] != 0)]\n    tmp2 = data[(data['Attrition'] == 0)]\n    tmp3 = pd.DataFrame(pd.crosstab(data[var_select],data['Attrition']), )\n    tmp3['Attr%'] = tmp3[1] / (tmp3[1] + tmp3[0]) * 100\n    if x_no_numeric == True  : \n        tmp3 = tmp3.sort_values(1, ascending = False)\n\n    color=['lightskyblue','gold' ]\n    trace1 = go.Bar(\n        x=tmp1[var_select].value_counts().keys().tolist(),\n        y=tmp1[var_select].value_counts().values.tolist(),\n        name='Yes_Attrition',opacity = 0.8, marker=dict(\n        color='gold',\n        line=dict(color='#000000',width=1)))\n\n    \n    trace2 = go.Bar(\n        x=tmp2[var_select].value_counts().keys().tolist(),\n        y=tmp2[var_select].value_counts().values.tolist(),\n        name='No_Attrition', opacity = 0.8, marker=dict(\n        color='lightskyblue',\n        line=dict(color='#000000',width=1)))\n    \n    trace3 =  go.Scatter(   \n        x=tmp3.index,\n        y=tmp3['Attr%'],\n        yaxis = 'y2',\n        name='% Attrition', opacity = 0.6, marker=dict(\n        color='black',\n        line=dict(color='#000000',width=0.5\n        )))\n\n    layout = dict(title =  str(var_select),\n              xaxis=dict(), \n              yaxis=dict(title= 'Count'), \n              yaxis2=dict(range= [-0, 75], \n                          overlaying= 'y', \n                          anchor= 'x', \n                          side= 'right',\n                          zeroline=False,\n                          showgrid= False, \n                          title= '% Attrition'\n                         ))\n\n    fig = go.Figure(data=[trace1, trace2, trace3], layout=layout)\n    py.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"86fdc54cc7f24aecb49361bb76c5f9701c193627"},"cell_type":"code","source":"plot_distribution('Age', False)\nbarplot('Age', False)\nplot_distribution('DailyRate', 100)\nplot_distribution('DistanceFromHome', False)\nbarplot('DistanceFromHome', False)\nplot_distribution('HourlyRate', False)\nplot_distribution('MonthlyIncome', 100)\nplot_distribution('MonthlyRate', 100)\nplot_distribution('NumCompaniesWorked', False)\nbarplot('NumCompaniesWorked',False)\nplot_distribution('PercentSalaryHike', False)\nbarplot('PercentSalaryHike', False) \nplot_distribution('TotalWorkingYears', False)\nbarplot('TotalWorkingYears', False)\nplot_distribution('TrainingTimesLastYear', False)\nbarplot('TrainingTimesLastYear',False)\nplot_distribution('YearsAtCompany', False)\nbarplot('YearsAtCompany', False)\nplot_distribution('YearsInCurrentRole', False)\nbarplot('YearsInCurrentRole', False)\nplot_distribution('YearsSinceLastPromotion', False)\nbarplot('YearsSinceLastPromotion', False)\nplot_distribution('YearsWithCurrManager', False)\nbarplot('YearsWithCurrManager', False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c60c19375138e16aebe02bcebef7bec18b245061"},"cell_type":"markdown","source":"## <a id='2.4'>2.4. Pie plot and barplot</a> "},{"metadata":{"trusted":true,"_uuid":"921f00f9fb0b5b5e17faae8d0e806b93a1a70779"},"cell_type":"code","source":"def plot_pie(var_select) :\n    \n    colors = ['gold', 'lightgreen', 'lightcoral', 'lightskyblue', 'lightgrey', 'orange', 'white', 'lightpink']\n    trace1 = go.Pie(values  = attrition[var_select].value_counts().values.tolist(),\n                    labels  = attrition[var_select].value_counts().keys().tolist(),\n                    textfont=dict(size=15), opacity = 0.8,\n                    hoverinfo = \"label+percent+name\",\n                    domain  = dict(x = [0,.48]),\n                    name    = \"attrition employes\",\n                    marker  = dict(colors = colors, line = dict(width = 1.5)))\n    trace2 = go.Pie(values  = no_attrition[var_select].value_counts().values.tolist(),\n                    labels  = no_attrition[var_select].value_counts().keys().tolist(),\n                    textfont=dict(size=15), opacity = 0.8,\n                    hoverinfo = \"label+percent+name\",\n                    marker  = dict(colors = colors, line = dict(width = 1.5)),\n                    domain  = dict(x = [.52,1]),\n                    name    = \"Non attrition employes\" )\n\n    layout = go.Layout(dict(title = var_select + \" distribution in employes attrition \",\n                            annotations = [dict(text = \"Yes_attrition\",\n                                                font = dict(size = 13),\n                                                showarrow = False,\n                                                x = .22, y = -0.1),\n                                            dict(text = \"No_attrition\",\n                                                font = dict(size = 13),\n                                                showarrow = False,\n                                                x = .8,y = -.1)]))\n                                          \n\n    fig  = go.Figure(data = [trace1,trace2],layout = layout)\n    py.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6899ff7a536c2d86543e81eeb57a08ddd38de8c2"},"cell_type":"code","source":"plot_pie(\"Gender\")\nbarplot('Gender',True)\nplot_pie('OverTime')\nbarplot('OverTime',True)\nplot_pie('BusinessTravel')\nbarplot('BusinessTravel',True)\nplot_pie('JobRole')\nbarplot('JobRole',True)\nplot_pie('Department') \nbarplot('Department',True)\nplot_pie('MaritalStatus') \nbarplot('MaritalStatus',True)\nplot_pie('EducationField') \nbarplot('EducationField',True)\nplot_pie('Education') \nbarplot('Education',False)\nplot_pie('EnvironmentSatisfaction')\nbarplot('EnvironmentSatisfaction',False)\nplot_pie('JobInvolvement')\nbarplot('JobInvolvement', False)\nplot_pie('JobLevel')\nbarplot('JobLevel',False)\nplot_pie('JobSatisfaction')\nbarplot('JobSatisfaction',False)\nplot_pie('PerformanceRating')\nbarplot('PerformanceRating',False)\nplot_pie('RelationshipSatisfaction')\nbarplot('RelationshipSatisfaction', False)\nplot_pie('StockOptionLevel')\nbarplot('StockOptionLevel', False)\nplot_pie('WorkLifeBalance')\nbarplot('WorkLifeBalance', False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ec03ef2f78d489945b25a265c01b4a72a23cda92"},"cell_type":"markdown","source":"# <a id='3'>3. Feature engineering and selection</a>"},{"metadata":{"_uuid":"88fcd7e83d07e99f02263b07eb5ef87371290160"},"cell_type":"markdown","source":"## <a id='3.1'>3.1. New features : 24</a> "},{"metadata":{"trusted":true,"_uuid":"8c9de44eabebe4bed64a973fe66bebfec99f7bc2"},"cell_type":"code","source":"def SalesDpt(data) :\n    if data['Department'] == 'Sales':\n        return 1\n    else:\n        return 0\ndata['SalesDpt'] = data.apply(lambda data:SalesDpt(data) ,axis = 1)\n\ndef JobInvCut(data) :\n    if data['JobInvolvement'] < 2.5 :\n        return 1\n    else:\n        return 0\ndata['JobInvCut'] = data.apply(lambda data:JobInvCut(data) ,axis = 1)\n\ndef MiddleTraining(data) :\n    if data['TrainingTimesLastYear'] >= 3 and data['TrainingTimesLastYear'] <= 6:\n        return 1\n    else:\n        return 0\ndata['MiddleTraining'] = data.apply(lambda data:MiddleTraining(data) ,axis = 1)\n\ndef MoovingPeople(data) :\n    if data['NumCompaniesWorked'] > 4:\n        return 1\n    else:\n        return 0\ndata['MoovingPeople'] = data.apply(lambda data:MoovingPeople(data), axis = 1)\n\ndata['TotalSatisfaction_mean'] = (data['RelationshipSatisfaction']  + data['EnvironmentSatisfaction'] + data['JobSatisfaction'] + data['JobInvolvement'] + data['WorkLifeBalance'])/5\n\ndef NotSatif(data) : \n    if  data['TotalSatisfaction_mean'] < 2.35 :\n        return 1\n    else : \n        return 0\ndata['NotSatif'] = data.apply(lambda data:NotSatif(data) ,axis = 1)\n\ndef LongDisWL1(data) : \n    if  data['DistanceFromHome'] > 11 and data['WorkLifeBalance'] == 1 :\n        return 1\n    else : \n        return 0\ndata['LongDisWL1'] = data.apply(lambda data:LongDisWL1(data) ,axis = 1)\n\ndef LongDis(data) : \n    if  data['DistanceFromHome'] > 11:\n        return 1\n    else : \n        return 0\ndata['LongDis'] = data.apply(lambda data:LongDis(data) ,axis = 1)\n\ndef LongDisJobS1(data) : \n    if  data['DistanceFromHome'] > 11 and data['JobSatisfaction'] == 1 :\n        return 1\n    else : \n        return 0\ndata['LongDisJobS1'] = data.apply(lambda data:LongDisJobS1(data) ,axis = 1)\n\ndef LongDisJL1(data) : \n    if  data['DistanceFromHome'] > 11 and data['JobLevel'] == 1 :\n        return 1\n    else : \n        return 0\ndata['LongDisJL1'] = data.apply(lambda data:LongDisJL1(data) ,axis = 1)\n\ndef ShortDisNotSingle(data) : \n    if  data['MaritalStatus'] != 'Single' and data['DistanceFromHome'] < 5:\n        return 1\n    else : \n        return 0\ndata['ShortDisNotSingle'] = data.apply(lambda data:ShortDisNotSingle(data) ,axis = 1)\n\ndef LongDisSingle(data) : \n    if  data['MaritalStatus'] == 'Single' and data['DistanceFromHome'] > 11:\n        return 1\n    else : \n        return 0\ndata['LongDisSingle'] = data.apply(lambda data:LongDisSingle(data) ,axis = 1)\n\ndef Engaged(data) : \n    if data['Age'] > 35 and data['MaritalStatus'] != 'Single':\n        return 1\n    else : \n        return 0\ndata['Engaged'] = data.apply(lambda data:Engaged(data) ,axis = 1)\n\ndef YoungAndBadPaid(data) : \n    if data['Age'] < 35 and data['Age'] > 23 and (data['MonthlyIncome'] < 3500):\n        return 1\n    else : \n        return 0\ndata['YoungAndBadPaid'] = data.apply(lambda data:YoungAndBadPaid(data) ,axis = 1)\n\ndef YoungNeverEngaged(data) : \n    if data['Age'] < 24 and data['MaritalStatus'] == 'Single' :\n        return 1\n    else : \n        return 0\ndata['YoungNeverEngaged'] = data.apply(lambda data:YoungNeverEngaged(data) ,axis = 1)\n\ndata['Time_in_each_comp'] = (data['Age'] - 20) / ((data)['NumCompaniesWorked'] + 1)\ndata['RelSatisf_mean'] = (data['RelationshipSatisfaction']  + data['EnvironmentSatisfaction']) / 2\ndata['JobSatisf_mean'] = (data['JobSatisfaction'] + data['JobInvolvement']) / 2\ndata['Income_Distance'] = data['MonthlyIncome'] / data['DistanceFromHome']\ndata['Hrate_Mrate'] = data['HourlyRate'] / data['MonthlyRate']\ndata['Stability'] = data['YearsInCurrentRole'] / data['YearsAtCompany']\ndata['Stability'].fillna((data['Stability'].mean()), inplace=True)\ndata['Income_YearsComp'] = data['MonthlyIncome'] / data['YearsAtCompany']\ndata['Income_YearsComp'] = data['Income_YearsComp'].replace(np.Inf, 0)\ndata['Fidelity'] = (data['NumCompaniesWorked']) / data['TotalWorkingYears']\ndata['Fidelity'] = data['Fidelity'].replace(np.Inf, 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a1b486fb7a9d45bb654a4f338055d64326856428"},"cell_type":"code","source":"barplot('Engaged', False)\nbarplot('YoungAndBadPaid', False)\nbarplot('YoungNeverEngaged', False)\nbarplot('LongDisSingle', False)\nbarplot('LongDisJL1', False)\nbarplot('ShortDisNotSingle', False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7fc41e99382306b741084e2a46a90aefcba6b422"},"cell_type":"markdown","source":"## <a id='3.2'>3.2. Drop some features</a> "},{"metadata":{"trusted":true,"_uuid":"bc12dc2e387797ad03743b6d2c021ff6fc3dbdd1"},"cell_type":"code","source":"data = data.drop(columns=[\n                        'Age',\n                        'MonthlyIncome',\n                        'YearsAtCompany',\n                        'DistanceFromHome',\n                        'PerformanceRating',\n                        'NumCompaniesWorked'\n                     ])\n\nprint (\"\\nMissing values :  \", data.isnull().sum().values.sum())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6bc8fb27e5778aac4225dcb71e8f219f0cf9d8d3"},"cell_type":"markdown","source":"## <a id='3.3'>3.3. Features encoding and scaling</a> "},{"metadata":{"trusted":true,"_uuid":"cb6db23a0f250b5e128fa77e34ce20b3f9340a89"},"cell_type":"code","source":"#customer id col\nId_col     = ['EmployeeNumber']\n#Target columns\ntarget_col = [\"Attrition\"]\n#categorical columns\ncat_cols   = data.nunique()[data.nunique() < 10].keys().tolist()\ncat_cols   = [x for x in cat_cols if x not in target_col]\n#numerical columns\nnum_cols   = [x for x in data.columns if x not in cat_cols + target_col + Id_col]\n#Binary columns with 2 values\nbin_cols   = data.nunique()[data.nunique() == 2].keys().tolist()\n#Columns more than 2 values\nmulti_cols = [i for i in cat_cols if i not in bin_cols]\n\n#Label encoding Binary columns\nle = LabelEncoder()\nfor i in bin_cols :\n    data[i] = le.fit_transform(data[i])\n    \n#Duplicating columns for multi value columns\ndata = pd.get_dummies(data = data,columns = multi_cols )\n\n#Scaling Numerical columns\nstd = StandardScaler()\nscaled = std.fit_transform(data[num_cols])\nscaled = pd.DataFrame(scaled,columns=num_cols)\n\n#dropping original values merging scaled values for numerical columns\ndf_data_og = data.copy()\ndata = data.drop(columns = num_cols,axis = 1)\ndata = data.merge(scaled,left_index=True,right_index=True,how = \"left\")\ndata = data.drop(['EmployeeNumber'],axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fa59bc1ff371813a16e207ec5751a4dfa1cfbadd"},"cell_type":"markdown","source":"## <a id='3.4'>3.4. Correlation Matrix</a> "},{"metadata":{"trusted":true,"_uuid":"42c618f0e8862a67f1197fc865fea3186febc992"},"cell_type":"code","source":"#correlation\ncorrelation = data.corr()\n#tick labels\nmatrix_cols = correlation.columns.tolist()\n#convert to array\ncorr_array  = np.array(correlation)\n\n#Plotting\ntrace = go.Heatmap(z = corr_array,\n                   x = matrix_cols,\n                   y = matrix_cols,\n                   colorscale='Viridis',\n                   colorbar   = dict() ,\n                  )\nlayout = go.Layout(dict(title = 'Correlation Matrix for variables',\n                        autosize = False,\n                        #height  = 1400,\n                        #width   = 1600,\n                        margin  = dict(r = 0 ,l = 210,\n                                       t = 25,b = 210,\n                                     ),\n                        yaxis   = dict(tickfont = dict(size = 9)),\n                        xaxis   = dict(tickfont = dict(size = 9)),\n                       )\n                  )\nfig = go.Figure(data = [trace],layout = layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ffeded839d00de6506547f849d5c1fcccc39a1c9"},"cell_type":"markdown","source":"## <a id='3.5'>3.5. Remove collinear features</a>"},{"metadata":{"trusted":true,"_uuid":"32fd969262e3eb2d3f1c1dd97d0f3b358e215b4c"},"cell_type":"code","source":"# Threshold for removing correlated variables\nthreshold = 0.8\n\n# Absolute value correlation matrix\ncorr_matrix = data.corr().abs()\ncorr_matrix.head()\n\n# Upper triangle of correlations\nupper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\nupper.head()\n\n# Select columns with correlations above threshold\nto_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n\nprint('There are %d columns to remove :' % (len(to_drop)))\n\ndata = data.drop(columns = to_drop)\n\nto_drop","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e2d75c810daf8d0c487fe294f0c5f0919ffdfc23"},"cell_type":"markdown","source":"# <a id='4'>4. Define functions</a>"},{"metadata":{"_uuid":"03fef192a42eb24829fd985f13bf3e5c20986293"},"cell_type":"markdown","source":"## <a id='4.1'>4.1. Define model performance plot</a> "},{"metadata":{"trusted":true,"_uuid":"e6e86485b204eefa2337023a4d30d4074f887a30"},"cell_type":"code","source":"def model_performance_plot(model) : \n    #conf matrix\n    conf_matrix = confusion_matrix(y_test, y_pred)\n    trace1 = go.Heatmap(z = conf_matrix  ,x = [\"0 (pred)\",\"1 (pred)\"],\n                        y = [\"0 (true)\",\"1 (true)\"],xgap = 2, ygap = 2, \n                        colorscale = 'Viridis', showscale  = False)\n\n    #show metrics\n    tp = conf_matrix[1,1]\n    fn = conf_matrix[1,0]\n    fp = conf_matrix[0,1]\n    tn = conf_matrix[0,0]\n    Accuracy  =  ((tp+tn)/(tp+tn+fp+fn))\n    Precision =  (tp/(tp+fp))\n    Recall    =  (tp/(tp+fn))\n    F1_score  =  (2*(((tp/(tp+fp))*(tp/(tp+fn)))/((tp/(tp+fp))+(tp/(tp+fn)))))\n\n    show_metrics = pd.DataFrame(data=[[Accuracy , Precision, Recall, F1_score]])\n    show_metrics = show_metrics.T\n\n    colors = ['gold', 'lightgreen', 'lightcoral', 'lightskyblue']\n    trace2 = go.Bar(x = (show_metrics[0].values), \n                   y = ['Accuracy', 'Precision', 'Recall', 'F1_score'], text = np.round_(show_metrics[0].values,4),\n                    textposition = 'auto',\n                   orientation = 'h', opacity = 0.8,marker=dict(\n            color=colors,\n            line=dict(color='#000000',width=1.5)))\n    \n    #plot roc curve\n    model_roc_auc = round(roc_auc_score(y_test, y_score) , 3)\n    fpr, tpr, t = roc_curve(y_test, y_score)\n    trace3 = go.Scatter(x = fpr,y = tpr,\n                        name = \"Roc : \",\n                        line = dict(color = ('rgb(22, 96, 167)'),width = 2), fill='tozeroy')\n    trace4 = go.Scatter(x = [0,1],y = [0,1],\n                        line = dict(color = ('black'),width = 1.5,\n                        dash = 'dot'))\n    \n    # Precision-recall curve\n    precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n    trace5 = go.Scatter(x = recall, y = precision,\n                        name = \"Precision\" + str(precision),\n                        line = dict(color = ('lightcoral'),width = 2), fill='tozeroy')\n    \n    #subplots\n    fig = tls.make_subplots(rows=2, cols=2, print_grid=False, \n                        subplot_titles=('Confusion Matrix',\n                                        'Metrics',\n                                        'ROC curve'+\" \"+ '('+ str(model_roc_auc)+')',\n                                        'Precision - Recall curve'))\n    \n    fig.append_trace(trace1,1,1)\n    fig.append_trace(trace2,1,2)\n    fig.append_trace(trace3,2,1)\n    fig.append_trace(trace4,2,1)\n    fig.append_trace(trace5,2,2)\n    \n    fig['layout'].update(showlegend = False, title = '<b>Model performance</b><br>'+str(model),\n                        autosize = False, height = 900,width = 830,\n                        plot_bgcolor = 'rgba(240,240,240, 0.95)',\n                        paper_bgcolor = 'rgba(240,240,240, 0.95)',\n                        margin = dict(b = 195))\n    fig[\"layout\"][\"xaxis2\"].update((dict(range=[0, 1])))\n    fig[\"layout\"][\"xaxis3\"].update(dict(title = \"false positive rate\"))\n    fig[\"layout\"][\"yaxis3\"].update(dict(title = \"true positive rate\"))\n    fig[\"layout\"][\"xaxis4\"].update(dict(title = \"recall\"), range = [0,1.05])\n    fig[\"layout\"][\"yaxis4\"].update(dict(title = \"precision\"), range = [0,1.05])\n    fig.layout.titlefont.size = 14\n    \n    py.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"af404ccf3dcda5bcb56df94f23130beeff42ae0c"},"cell_type":"markdown","source":"## <a id='4.2'>4.2. Define feature importance plot</a> "},{"metadata":{"trusted":true,"_uuid":"58d0d4c7f2d3c0c685368e4036f09d6b47532887"},"cell_type":"code","source":"def features_imp(model, cf) : \n\n    coefficients  = pd.DataFrame(model.feature_importances_)\n    column_data     = pd.DataFrame(list(data))\n    coef_sumry    = (pd.merge(coefficients,column_data,left_index= True,\n                              right_index= True, how = \"left\"))\n    coef_sumry.columns = [\"coefficients\",\"features\"]\n    coef_sumry    = coef_sumry.sort_values(by = \"coefficients\",ascending = False)\n    coef_sumry = coef_sumry[coef_sumry[\"coefficients\"] !=0]\n    trace = go.Bar(x = coef_sumry[\"features\"],y = coef_sumry[\"coefficients\"],\n                    name = \"coefficients\",\n                    marker = dict(color = coef_sumry[\"coefficients\"],\n                                  colorscale = \"Viridis\",\n                                  line = dict(width = .6,color = \"black\")))\n    layout = dict(title =  'Feature Importances xgb_cfl')\n                    \n    fig = dict(data = [trace], layout=layout)\n    py.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8e8ab5de083f6b73358e0d8c5c6890f8fba28e84"},"cell_type":"markdown","source":"## <a id='4.3'>4.3. Define cumulative gains curve</a> "},{"metadata":{"trusted":true,"_uuid":"427a09623dfc0ae849224ba32d32ecb9776d5a98"},"cell_type":"code","source":"#cumulative gain curve\ndef cum_gains_curve(model):\n    pos = pd.get_dummies(y_test).as_matrix()\n    pos = pos[:,1] \n    npos = np.sum(pos)\n    index = np.argsort(y_score) \n    index = index[::-1] \n    sort_pos = pos[index]\n    #cumulative sum\n    cpos = np.cumsum(sort_pos) \n    #recall\n    recall = cpos/npos \n    #size obs test\n    n = y_test.shape[0] \n    size = np.arange(start=1,stop=369,step=1) \n    #proportion\n    size = size / n \n    #plots\n    model = 'xgb_cfl'\n    trace1 = go.Scatter(x = size,y = recall,\n                        name = \"Lift curve\",\n                        line = dict(color = ('rgb(22, 96, 167)'),width = 2))\n    trace2 = go.Scatter(x = size,y = size,\n                        name = \"Baseline\",\n                        showlegend=False,\n                        line = dict(color = ('black'),width = 1.5,\n                        dash = 'dot'))\n\n    layout = dict(title = 'Cumulative gains curve'+' '+str(model),\n                  yaxis = dict(title = 'Percentage positive targeted',zeroline = False),\n                  xaxis = dict(title = 'Percentage contacted', zeroline = False)\n                 )\n\n    fig  = go.Figure(data = [trace1,trace2], layout = layout)\n    py.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2acadd1870360a727485fdeb2a8af0115458f7a9"},"cell_type":"markdown","source":"## <a id='4.4'>4.4. Define cross validation metrics</a> "},{"metadata":{"trusted":true,"_uuid":"c64cc90dcef8c8f7046f510bad33e5e5d56af062"},"cell_type":"code","source":"# Cross val metric\ndef cross_val_metrics(model) :\n    scores = ['accuracy', 'precision', 'recall']\n    for sc in scores:\n        scores = cross_val_score(model, X, y, cv = 5, scoring = sc)\n        print('[%s] : %0.5f (+/- %0.5f)'%(sc, scores.mean(), scores.std()))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aafb162df41b9a71fa7ecb2e0cd8750812dc0579"},"cell_type":"markdown","source":"# <a id='5'>5. Prepare dataset</a>"},{"metadata":{"_uuid":"c19355d7890d0b32d532294948fffe20c7c5b31d"},"cell_type":"markdown","source":"## <a id='5.1'>5.1. Define (X, y)</a> "},{"metadata":{"trusted":true,"_uuid":"e169cfa2ed00779a2f64ec2be421d91b18c12643"},"cell_type":"code","source":"# Def X and Y\ny = np.array(data.Attrition.tolist())\ndata = data.drop('Attrition', 1)\nX = np.array(data.as_matrix())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d83599730eebf224cdadde69944f98002296e835"},"cell_type":"markdown","source":"## <a id='5.2'>5.2. Train test split</a> "},{"metadata":{"trusted":true,"_uuid":"69294fae2584c2719ffc8a8f2068f2cf84b0c6df"},"cell_type":"code","source":"# Train_test split\nrandom_state = 42\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = random_state)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8b3e7dc4ad741fc204e00f5d7c870c4f3f1d0310"},"cell_type":"markdown","source":"# <a id='6'>6. XGBoost - RandomizedSearchCV to optimize hyperparameters</a>"},{"metadata":{"trusted":true,"_uuid":"25ea2f73bcbd891d95623f3de322236452c58d75"},"cell_type":"code","source":"def timer(start_time=None):\n    if not start_time:\n        start_time = datetime.now()\n        return start_time\n    elif start_time:\n        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n        tmin, tsec = divmod(temp_sec, 60)\n        print('\\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))\n        \n        \nxgb_cfl = xgb.XGBClassifier(n_jobs = -1)\n\n\n# A parameter grid for XGBoost\nparams = {\n        'n_estimators' : [100, 200, 500, 750],\n        'learning_rate' : [0.01, 0.02, 0.05, 0.1, 0.25],\n        'min_child_weight': [1, 5, 7, 10],\n        'gamma': [0.1, 0.5, 1, 1.5, 5],\n        'subsample': [0.6, 0.8, 1.0],\n        'colsample_bytree': [0.6, 0.8, 1.0],\n        'max_depth': [3, 4, 5, 10, 12]\n        }\n\nfolds = 5\nparam_comb = 800\n\nrandom_search = RandomizedSearchCV(xgb_cfl, param_distributions=params, n_iter=param_comb, scoring='accuracy', n_jobs=-1, cv=5, verbose=3, random_state=42)\n\n# Here we go\nstart_time = timer(None) # timing starts from this point for \"start_time\" variable\n#----------------------------# random_search.fit(X, y)\ntimer(start_time) # timing ends here for \"start_time\" variable","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"19ea691d7cf7b37d12c28df1daf9c03aa69604e0"},"cell_type":"markdown","source":"Remove \"#----------------------------#\" to lunch random_search"},{"metadata":{"trusted":true,"_uuid":"13c7bc3e83e56fb021b15862a4b3127b00175ef5"},"cell_type":"code","source":"#print('\\n All results:')\n#print(random_search.cv_results_)\n#print('\\n Best estimator:')\n#print(random_search.best_estimator_)\n#print('\\n Best accuracy for %d-fold search with %d parameter combinations:' % (folds, param_comb))\n#print(random_search.best_score_ )\n#print('\\n Best hyperparameters:')\n#print(random_search.best_params_)\n#results = pd.DataFrame(random_search.cv_results_)\n#results.to_csv('xgb-random-grid-search-results-01.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b390918f77cc9250ec184b013cfad0b71921df6d"},"cell_type":"markdown","source":"\n\n**RESULT : **\n\nBest estimator:\nXGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n       colsample_bytree=0.8, gamma=1.5, learning_rate=0.05,\n       max_delta_step=0, max_depth=3, min_child_weight=7, missing=None,\n       n_estimators=200, n_jobs=-1, nthread=None,\n       objective='binary:logistic', random_state=0, reg_alpha=0,\n       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n       subsample=0.6)\n\n Best accuracy for 5-fold search with 800 parameter combinations:\n0.891156462585034\n\n Best hyperparameters:\n{'subsample': 0.6, 'n_estimators': 200, 'min_child_weight': 7, 'max_depth': 3, 'learning_rate': 0.05, 'gamma': 1.5, 'colsample_bytree': 0.8}"},{"metadata":{"_uuid":"448e48609f713fc9eac15409018138656049dcca"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"8b1c816721a77c5eb63940ec14d6bbce8cdd08cd"},"cell_type":"markdown","source":"# <a id='7'>7. XGBoost - Modeling with best hyperparameters = 89.11</a>"},{"metadata":{"_uuid":"44a5cf497de23ece4be0faf61f7d3cf534c2edfd"},"cell_type":"markdown","source":"## <a id='7.1'>7.1. XGBoost - Modeling and performance plot</a> "},{"metadata":{"trusted":true,"_uuid":"85b225a5e5b024339c3449afd934e815164b001b"},"cell_type":"code","source":"# xgb \nxgb_clf = xgb.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n                           colsample_bytree=0.8, gamma=1.5, learning_rate=0.05,\n                           max_delta_step=0, max_depth=3, min_child_weight=7, missing=None,\n                           n_estimators=200, n_jobs=-1, nthread=None,\n                           objective='binary:logistic', random_state=0, reg_alpha=0,\n                           reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n                           subsample=0.6)\n\nxgb_clf.fit(X_train, y_train)\ny_pred = xgb_clf.predict(X_test)\ny_score = xgb_clf.predict_proba(X_test)[:,1]\n\nmodel_performance_plot('xgb_clf')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"93442a1d6dae9d0de6a34724e22a57645a10b773"},"cell_type":"markdown","source":"## <a id='7.2'>7.2. XGBoost - Feature importance </a>"},{"metadata":{"trusted":true,"_uuid":"ac2d9efb66f89dead68ed2d6079e8498ec8244d7"},"cell_type":"code","source":"features_imp(xgb_clf, 'features')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fd40ff6d8c0b252283303ac91e2669e6c2b3291e"},"cell_type":"code","source":"#feature importance plot TOP 40\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\ndef plot_feature_importance(model):\n    tmp = pd.DataFrame({'Feature': list(data), 'Feature importance': model.feature_importances_})\n    tmp = tmp.sort_values(by='Feature importance',ascending=False).head(30)\n    plt.figure(figsize = (10,12))\n    plt.title('Top 30 - Features importance - XGBoost',fontsize=14)\n    s = sns.barplot(y='Feature',x='Feature importance',data=tmp, orient='h')\n    s.set_xticklabels(s.get_xticklabels(),rotation=90)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"741b2cf4991aa647e7c47331aaeb45d771aa4d97"},"cell_type":"code","source":"plot_feature_importance(xgb_clf)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3d55e2c0d3079b8730819908081bc225284ffb46"},"cell_type":"markdown","source":"## <a id='7.3'>7.3. XGBoost - Cumulative gain curve</a> "},{"metadata":{"trusted":true,"_uuid":"4d99faf6bbb4ec1e261ecb599040d7b80c22229c"},"cell_type":"code","source":"cum_gains_curve(xgb_clf)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fb4df284bf134f992dad689dcc296c8aaac7d1a4"},"cell_type":"markdown","source":"## <a id='7.4'>7.4. XGBoost - Cross validation (5 folds)</a> "},{"metadata":{"trusted":true,"_uuid":"cc6c077c24968c75ce53856eabe215d4dd6388b7"},"cell_type":"code","source":"# Cross val score\ncross_val_metrics(xgb_clf)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9d406e45e72d85b091d2bad1688b63fc88da3ff1"},"cell_type":"markdown","source":"**Thank you all ! Merci Ã  tous ! :)**"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}