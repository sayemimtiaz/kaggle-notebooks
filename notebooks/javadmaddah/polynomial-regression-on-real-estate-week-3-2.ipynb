{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Hello everyone!**\n\nIn this notebook we continue to know one more ML algorithms. I recently write a notebook for using simple Linear Regression that you can check it here : https://www.kaggle.com/javadmaddah/linear-regression-on-real-estate-ds-week-3-1\n\nBut now we are gonna use Polynomial Regression that gives us more power to predict Target variables when realationship with features are non-linear.\n\nYou can learn more about Polynomial Regression here: \n\nhttps://en.wikipedia.org/wiki/Polynomial_regression (English)\n\nhttps://b.fdrs.ir/3xe (Persian)\n    \nlike before, We use Real Estate dataset to make a model that predict house prices based on 6 features. In the following, You can realize more about dataset.","metadata":{}},{"cell_type":"code","source":"#first we import all the libraries we're gonna need.\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Import & getting basic info of Dataset","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/real-estate-price-prediction/Real estate.csv')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Exploratory Data Analysis","metadata":{}},{"cell_type":"code","source":"sns.pairplot(df)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we could see, there are 5 factors that maybe have effects on price. Transaction date, house age, distance to the nearest MRT station, number of convenience stores, latitude and longitude.\n\nwith correlation analysis we can figure out the basis information about dependence between features.","metadata":{}},{"cell_type":"code","source":"df.corr()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Based on this information X3 factor had the most negetive correlation with price. (Although in Linear model the Coefficient of this feature was near 0) \n\nAlso we can see the strong correlation between longitude and distance to the nearest MRT station.","metadata":{}},{"cell_type":"markdown","source":"# 3. Features and Target Variable","metadata":{}},{"cell_type":"code","source":"#we can delet 'No' column to increase power of model.\n\ndf.drop(['No'], axis = 1, inplace = True)\n\n#X : Features\n#y : Target variable\n\nX = df.drop(['Y house price of unit area'], axis = 1)\ny = df['Y house price of unit area']\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Train & Test set","metadata":{}},{"cell_type":"code","source":"#we use train_test_split from sklearn.model_selection to devide dataset to train and test set.\n\nfrom sklearn.model_selection import train_test_split \n\n#train set in a bigger sample of dataset that model uses to learn.\n#test set in smaller sample of dataset that model should be evaluated in.\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Adjusting Model Parameters\n\nWhen we want to create a Polynomial Regression model we should know the \"degree\" parametere. Degree parametere consider interaction terms between features. In consider the interaction of 2 or more features Coefficient on the target variable. \n\nSo here we make a loop that build model with a range of degrees to realize which degree cause the minimum error of all.","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import PolynomialFeatures #we use this for creating new columns of interaction terms\nfrom sklearn import metrics ##we use this function to compare sets\n\n# Train List of RMSE per degree\n\ntrain_RMSE_list = []\n\n#Test List of RMSE per degree\n\ntest_RMSE_list = []\n\nfor d in range(1,10):\n    \n    #1: Preprocessing\n    #1-1 : create poly data set for degree (d)\n    \n    polynomial_converter = PolynomialFeatures(degree=d, include_bias=False) #it makes new dataset with considernig interaction terms\n    poly_features= polynomial_converter.fit(X) \n    poly_features= polynomial_converter.transform(X)\n    \n    #2: Split the dataset\n    \n    X_train, X_test, y_train, y_test = train_test_split(poly_features, y, test_size=0.3, random_state=101)\n    \n    #3: Train the Model\n    \n    polymodel = LinearRegression() #our model is a Linear Regression\n    polymodel.fit(X_train, y_train) #model.fit builds the model base on train set and returns the Coefficient of each feature.\n    \n    #4: Predicting on both Train & Test Data\n    \n    y_train_pred = polymodel.predict(X_train) \n    y_test_pred = polymodel.predict(X_test)\n    \n    #5: Evaluating the Model\n    \n    #5-1: RMSE of Train set\n    train_RMSE = np.sqrt(metrics.mean_squared_error(y_train, y_train_pred))\n    \n    #5-2: RMSE of Test Set\n    test_RMSE=np.sqrt(metrics.mean_squared_error(y_test, y_test_pred))\n    \n    #Append the RMSE to the Train and Test List\n    \n    train_RMSE_list.append(train_RMSE)\n    test_RMSE_list.append(test_RMSE)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Plot the Polynomial degree VS RMSE**\n\nNow we have to list with different values of total error for each value of degree in our Specified range. We can plot a line bar to see which degree is the best choice for builing model.","metadata":{}},{"cell_type":"code","source":"plt.plot(range(1,6), train_RMSE_list[:5], label='Train RMSE')\nplt.plot(range(1,6), test_RMSE_list[:5], label='Test RMSE')\n\nplt.xlabel('Polynomial Degree')\nplt.ylabel('RMSE')\nplt.legend()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It seems degree = 2 is the best choice for model.","metadata":{}},{"cell_type":"markdown","source":"# 6. Build the Model\n\nIn this step we know what's the best parameter for model and we can build model. Of course we created 10 model in last step, But for generating the model compeletly we build the Specific model again.","metadata":{}},{"cell_type":"code","source":"#1: Preprocessing\n\npolynomial_converter = PolynomialFeatures(degree = 2, include_bias=False)\npoly_features= polynomial_converter.fit(X) \npoly_features= polynomial_converter.transform(X)\n\n#2: Split the dataset\n    \nX_train, X_test, y_train, y_test = train_test_split(poly_features, y, test_size=0.3, random_state=101)\n    \n#3: Train the Model\n    \npolymodel = LinearRegression() #our model is a Linear Regression\npolymodel.fit(X_train, y_train) #model.fit builds the model base on train set and returns the Coefficient of each feature.\n    \n#4: Predicting on both Train & Test Data\n    \ny_pred = polymodel.predict(X_test)\n\n#4: Evaluating the Model\n\nMAE = metrics.mean_absolute_error(y_test, y_pred) \nMSE = metrics.mean_squared_error(y_test, y_pred)  \nRMSE = np.sqrt(MSE) \n\npd.DataFrame([MAE, MSE, RMSE], index=['MAE', 'MSE', 'RMSE'], columns=['Metrics'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Predict mean =',np.mean(y_pred),'\\nReal mean =',np.mean(df['Y house price of unit area']))\nprint(abs(np.mean(y_pred) - np.mean(df['Y house price of unit area'])),' is diffrence.')","metadata":{},"execution_count":null,"outputs":[]}]}