{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.read_csv('/kaggle/input/sars-coronavirus-accession/SARS_CORONAVIRUS_287BP_MN975263.1_accession_nucleotide.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/sars-coronavirus-accession/MN997409.1-4NY0T82X016-Alignment-HitTable.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.rename(columns={\"MN997409.1\": \"query acc.ver\", \"MN997409.1.1\": \"subject acc.ver\",\n                            \"100.000\":\"% identity\",\"29882\":\"alignment length\",\"0\":\"mismatches\",\n                            \"0.1\":\"gap opens\",\"1\":\"q. start\",\"29882.1\":\"q. end\",\"1.1\":\"s. start\",\n                           \"29882.2\t\":\"s. end\",\"0.0\":\"evalue\",\"55182\":\"bit score\"})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.append(pd.Series(['MN997409.1',\t'MN997409.1.1',\t\n                    100.000,\t29882,\t\n                    0,\t0.1,\t1,\t29882.1,\t\n                    1.1,\t29882.2,\t0.0,\t55182], index=data.columns), ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(14,8))\nsns.heatmap(data.corr(), vmax=1, square=True,annot=True,cmap='viridis')\n\nplt.title('Correlation between different fearures')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# K-Means Clustering\n\nWe will see the genome information clusters"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.cluster import KMeans","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['subject acc.ver'] = data['subject acc.ver'].astype(\"category\").cat.codes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data.iloc[:,1:].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import silhouette_samples, silhouette_score\nimport matplotlib.cm as cm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nstandardized_data = StandardScaler().fit_transform(X)\nprint(standardized_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"range_n_clusters = [2, 3, 4, 5, 6, 7, 8, 9, 10]\nsilohuette_scores = []\nfor n_clusters in range_n_clusters:\n    # Create a subplot with 1 row and 2 columns\n    fig, (ax1, ax2) = plt.subplots(1, 2)\n    fig.set_size_inches(18, 7)\n\n    # The 1st subplot is the silhouette plot\n    # The silhouette coefficient can range from -1, 1 but in this example all\n    # lie within [-0.1, 1]\n    ax1.set_xlim([-0.1, 1])\n    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n    # plots of individual clusters, to demarcate them clearly.\n    ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n\n    # Initialize the clusterer with n_clusters value and a random generator\n    # seed of 10 for reproducibility.\n    clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n    cluster_labels = clusterer.fit_predict(X)\n\n    # The silhouette_score gives the average value for all the samples.\n    # This gives a perspective into the density and separation of the formed\n    # clusters\n    silhouette_avg = silhouette_score(X, cluster_labels)\n    print(\"For n_clusters =\", n_clusters,\n          \"The average silhouette_score is :\", silhouette_avg)\n    silohuette_scores.append(silhouette_avg)\n\n    # Compute the silhouette scores for each sample\n    sample_silhouette_values = silhouette_samples(X, cluster_labels)\n\n    y_lower = 10\n    for i in range(n_clusters):\n        # Aggregate the silhouette scores for samples belonging to\n        # cluster i, and sort them\n        ith_cluster_silhouette_values = \\\n            sample_silhouette_values[cluster_labels == i]\n\n        ith_cluster_silhouette_values.sort()\n\n        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n        y_upper = y_lower + size_cluster_i\n\n        color = cm.nipy_spectral(float(i) / n_clusters)\n        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n                          0, ith_cluster_silhouette_values,\n                          facecolor=color, edgecolor=color, alpha=0.7)\n\n        # Label the silhouette plots with their cluster numbers at the middle\n        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n\n        # Compute the new y_lower for next plot\n        y_lower = y_upper + 10  # 10 for the 0 samples\n\n    ax1.set_title(\"The silhouette plot for the various clusters.\")\n    ax1.set_xlabel(\"The silhouette coefficient values\")\n    ax1.set_ylabel(\"Cluster label\")\n\n    # The vertical line for average silhouette score of all the values\n    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n\n    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n\n    # 2nd Plot showing the actual clusters formed\n    colors = cm.nipy_spectral(cluster_labels.astype(float) / n_clusters)\n    ax2.scatter(X[:, 0], X[:, 1], marker='.', s=30, lw=0, alpha=0.7,\n                c=colors, edgecolor='k')\n\n    # Labeling the clusters\n    centers = clusterer.cluster_centers_\n    # Draw white circles at cluster centers\n    ax2.scatter(centers[:, 0], centers[:, 1], marker='o',\n                c=\"white\", alpha=1, s=200, edgecolor='k')\n\n    for i, c in enumerate(centers):\n        ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1,\n                    s=50, edgecolor='k')\n\n    ax2.set_title(\"The visualization of the clustered data.\")\n    ax2.set_xlabel(\"Feature space for the 1st feature\")\n    ax2.set_ylabel(\"Feature space for the 2nd feature\")\n\n    plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n                  \"with n_clusters = %d\" % n_clusters),\n                 fontsize=14, fontweight='bold')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"silohuette_scores = [float(i) for i in silohuette_scores]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"silohuette_scores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(6,6))\nsns.barplot([2,3,4,5,6,7,8,9,10],\n            [0.6051456304424345,\n 0.7737574709178652,\n 0.9304299438199628,\n 0.9626586534510194,\n 0.9625756535242548,\n 0.9585239650538647,\n 0.9614207899227608,\n 0.9626169262248865,\n 0.9644636830559539],palette='viridis')\nplt.xlabel('Clusters')\nplt.ylabel('Silhouette Score')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clusterer = KMeans(n_clusters=5, random_state=10)\ncluster = clusterer.fit(X).labels_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cluster","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nplt.figure(figsize=(15,4))\nscaler = StandardScaler()\nsns.heatmap(scaler.fit(cluster.cluster_centers_).transform(cluster.cluster_centers_)\n            ,annot=True,xticklabels = data.columns.drop('query acc.ver'),yticklabels=['Cluster 1',\n                                                            'Cluster 2',\n                                                            'Cluster 3',\n                                                            'Cluster 4',\n                                                            'Cluster 5',])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"covar_matrix = np.matmul(standardized_data.T , standardized_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"covar_matrix.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.linalg import eigh ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#top2 eigenvalue\nvalues, vectors = eigh(covar_matrix, eigvals=(9,10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vectors.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#transpose\nvectors = vectors.T\nvectors.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_coordinates = np.matmul(vectors, standardized_data.T)\nprint (\"Resultant at new data shape: \", vectors.shape, \"*\", standardized_data.T.shape,\" = \", new_coordinates.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_coordinates = np.vstack((new_coordinates)).T\n\ndf = pd.DataFrame(data=new_coordinates, columns=(\"1st_principal\", \"2nd_principal\"))\nprint(df.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\npca = PCA(n_components=2)\npca.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,2.5))\nsns.heatmap(pca.components_,annot=True,xticklabels = data.columns.drop('query acc.ver'),yticklabels=['Component 1','Component 2'])\nplt.title('Principal Component Linear Coefficients of Columns')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(style='whitegrid')\nplt.figure(figsize=(6,6))\nsns.scatterplot(X[:,0],X[:,1],hue=cluster,palette='coolwarm')\n#sns.FacetGrid(df, size=6).map(plt.scatter, '1st_principal', '2nd_principal').add_legend()\nplt.title('PCA Visualization of Sequences')\nplt.xlabel('Principal Component 1')\nplt.ylabel('Principal Component 2')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca.explained_variance_ratio_.sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}