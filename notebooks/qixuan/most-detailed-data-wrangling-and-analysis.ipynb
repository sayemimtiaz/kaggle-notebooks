{"cells":[{"metadata":{},"cell_type":"markdown","source":"Hi, thank you for clicking my Kernel :)\n\nHere, you will see the most detailed data wrangling for this House Sales in King Countrydataset[](https://www.kaggle.com/harlfoxem/housesalesprediction) and may give you a future-inspiration on data wrangling.\n\nAlso, I introduce three different methods to help people to find outliers. After using this kernel, the data will be clean and tidy and I believe it would help you to do predictions or build machine learning models better. \n\nHopefully this kernel would be helpful for you. Enjoy the reading! :)\n"},{"metadata":{},"cell_type":"markdown","source":"## Step 1. Loading A CSV Into pandas"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \nimport os\nimport pandas as pd\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np  \n# Configure visualisations\n%matplotlib inline\nmpl.style.use('ggplot') #with this, your figures would be more beautiful","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#loading the dataset \ndf_house=pd.read_csv(\"../input/housesalesprediction/kc_house_data.csv\")\ndf_house.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#remove some columns that we do not need for the following steps\ndf_house.drop(['id', 'sqft_living15','sqft_lot15'], axis = 1, inplace = True)\ndf_house.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data types and missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_house.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are no missing values, but 'zipcode' should be a categorical variable instead of quantitative variable."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_house['zipcode'] = df_house['zipcode'].astype('category')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_house.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"What the table above tells us:\n\n1. We have a total of 21,613 samples but no missing values are found.\n2. For 'price', standard deviation(367,127) is a large number. It seems not way too smaller than the mean(540,088), which indicates some individual prices may vary a lot from the mean. However, outliers may affect the mean as well.\n3. For sqft_living, standard deviation(918) is way smaller than the mean(2079). It means most of individual living spaces do not vary a lot around the mean.\n4. The mean of condition is more than 3.4. Most of properties have average-above conditions even though they do not have any Views.\n5. Mean of the Waterfront(0.086517) is much less than the mean(0.5), which means most of properties are not living next to water.\n6. The proerty built between the year of 1900 and the year of 2015."},{"metadata":{},"cell_type":"markdown","source":"Let's see the distribution of the object variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_house.describe(include=['O'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"What the table above tells us:\n\n1. 372 properties have been sold at the day of 23/06/2014, the frequency is 142.\n2. There are total of 21613 different days"},{"metadata":{},"cell_type":"markdown","source":"Let's see the distribution of the categorical variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_house.describe(include=['category'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"What the table above tells us:\n\n1. there are 70 areas in King County\n2. zipcode 98103 is the most hot area that selling properties, sold 602 times\n"},{"metadata":{},"cell_type":"markdown","source":"# Step 2. Auditing and cleansing the loaded data"},{"metadata":{},"cell_type":"markdown","source":"## Checking irregularities"},{"metadata":{},"cell_type":"markdown","source":"#### Checking irregularity of zipcodes"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_house.zipcode.unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Checking irregularity of bathrooms"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_house.bathrooms.unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is very common to see a beathroom is 0.25 or 0.5 or 0.75, just because what we consider a bathing facility does not exist doesn’t mean you can’t “bathe”. "},{"metadata":{},"cell_type":"markdown","source":"#### Checking irregularity of bedrooms"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_house.bedrooms.unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Holy crap, there are some houses with 33 bedrooms! I guess they are either hotels or palaces."},{"metadata":{},"cell_type":"markdown","source":"#### Checking irregularity of views"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_house.view.unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Checking irregularity of conditions"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_house.condition.unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Checking irregularity of year renovated"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_house.yr_renovated.unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Checking irregularity of waterfront"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_house.waterfront.unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Checking irregularity of grade"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_house.grade.unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hey buddy, where is the grade 2?"},{"metadata":{},"cell_type":"markdown","source":"#### Checking irregularity of floors"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_house.floors.unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The minimum floor is 1, and the reason it allows decimals might be because some of the house have a mezzanine or an attic, and some might be built on a slope."},{"metadata":{},"cell_type":"markdown","source":"## Checking any lexical errors in the data\nTypos are the most common errors, particularly whenever the data collection process involves human. Let's look at the date. Firstly using the 'value_counts()' function to check if there are some unique errors."},{"metadata":{},"cell_type":"markdown","source":"#### Checking attribute of date"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_house.date.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I suspect a date that appears only once or twice might have some issues. So I check them one by one, but this dataset is too damn perfect. Everything is correct here."},{"metadata":{"trusted":true},"cell_type":"code","source":"#remove 'T000000'\ndf_house['date'] = df_house.date.str.replace('T000000' , '')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's use a regular expression to check whether they have other errors in date or not"},{"metadata":{"trusted":true},"cell_type":"code","source":"regex = r'''(?x)\n    # Year\n    (?:(?:(?:\\d{2})?\\d{2})\n    #30-day months\n    (?:(?:(?:0[469]|11)(?:30|[12][0-9]|0[1-9]))|\n    #31-day months\n    (?:(?:0[13578]|1[02])(?:3[01]|[12][0-9]|0[1-9]))|\n    #February (29 days every year)\n    (?:(?:0?2)(?:[12][0-9]|0?[1-9]))))\n'''\n\ndf_house[~df_house[\"date\"].str.match(regex)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"OMG! The datset is too perfect!\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#change the datetime format\ndf_house['date']= pd.to_datetime(df_house['date'])\ndf_house.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Checking lexical errors of zipcode attribute"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_house.zipcode.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Nothing wrong here. But I won't give up!"},{"metadata":{},"cell_type":"markdown","source":"##  Checking Inconsistency , Integrity and Semantic errors\n### Checking the values of \"sqft_living\" consistent with the values of \"sqft_above\" and \"sqft_basement\""},{"metadata":{"trusted":true},"cell_type":"code","source":"df_house.loc[(df_house.sqft_living!=df_house.sqft_above+df_house.sqft_basement)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Checking whether there are any year of last renovation earlier than the year of initially built"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_house.loc[(df_house.yr_renovated<=df_house.yr_built) & (df_house.yr_renovated !=0) ]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"What should I say? This dataset is too clean!"},{"metadata":{},"cell_type":"markdown","source":"### Checking whether there are no bathroom and bedroom exist simultaneously"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_house[(df_house.bathrooms==0) & (df_house.bedrooms==0)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finally, I find something. According to the features above, I think the datas are reasonable even though the properties do not have any bedroms and bathrooms. We can see that yr_renovated are 0 here. We assume this property has not been renovated yet. And most of properties are very old. Keeping them in the database could be a good indicator for someone who would like to sell the house without bedrooms and bathrooms. We can assume those type of properties are unfurnished and do not need any paintings. Therefore, I decide to keep them and do not make any changes."},{"metadata":{},"cell_type":"markdown","source":"### Checking if there is a property which has only 1 floor but does not have basement space, while living space is larger than its land space"},{"metadata":{},"cell_type":"markdown","source":"Before we move on, let's check the houses which just have 1 floor."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_house[(df_house.floors==1)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the table above, we can see that the basement space does not be counted as a part of floors.\n\nNow let's check is there any living space larger than land space when the property only has 1 floor and no basement."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_house[(df_house.floors==1) & (df_house.sqft_basement==0) & (df_house.sqft_living > df_house.sqft_lot)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Technically, it does not make any sense that the living space is larger than the land space when a property has only 1 floor and does not have any basements. Therefore, I count it as an error and decide to remove it."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_house.drop(df_house.index[13278],inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_house[(df_house.floors==1) & (df_house.sqft_basement==0) & (df_house.sqft_living > df_house.sqft_lot)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Checking duplicated records\n\nIf we assume that location, date, \"yr_built\", \"sqft_living\", \"sqft_lot\" can uniquely identify a property bacause there will not be a property sold twice in one day. We can then use the five values to check whether the dataset has duplicated records or not."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_house[df_house.duplicated([\"lat\", \"long\", \"date\", \"yr_built\",\n                               \"sqft_living\", \"sqft_lot\"], keep=False)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Oh, we have duplicates here. Let's just remove the first record and keep the second one for this property."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_house.drop_duplicates([\"lat\", \"long\", \"date\", \"yr_built\",\n                          \"sqft_living\", \"sqft_lot\"], keep='last', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Outliers\n\n### Univariate Outlier Detection Methods\n* The 3σ Edit Rule\n* The Boxplots graphical Detections"},{"metadata":{},"cell_type":"markdown","source":"##### 1.The 3σ Edit Rule\n\nThe most common way to detect outliers in this case is the 3σ edit rule, which declares any point lying farther than three standard deviations from the mean is an outlier"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_house['price'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#calculate the distance of 3*standard deviation\nthree_sigma=3*(df_house.price.std())\n#finding the rows that has 3sd far away from the mean\nprice_Editrule=[]\nfor i in range(len(df_house)):\n    #calculate the mean of price\n    price_mean=df_house.price.mean()\n    #absolute value of price\n    absolute_value=abs(df_house.price.iloc[i])\n    #distance of 3sd away from mean\n    a=price_mean+three_sigma\n    #justify the price of property larger than 3sd from the mean\n    if absolute_value>a:\n        price_Editrule.append(i)\n\ndf_house.iloc[price_Editrule]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 406 outliers detected from the calculations(seems impossible). A common difficulty for this edit rule method is the sensitivity to mean and SD value that are themselves affected by the outliers. According to the definition, a nice property is: if a data point is farther than an outlier, itself is an outlier. So I would like to use more methods to check with outliers accurately."},{"metadata":{},"cell_type":"markdown","source":"##### 2.Boxplots Detection\n\nGraphical methods are very important for visualising and identifying outliers especially with data represented in few dimensions. Boxplot is a common graphical method that has an advantage of robustness against outliers because it the usage of quartiles. Here, I build a boxplot in next step."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_house.boxplot(column='price',sym='k.')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the boxplot and price decribiton showned above, we can see the the y-axis is shown in million. The median value as shown in the box plot is at the bottom and it is hard to distinguish deviations below the median. Therefore, we use a natural log for the house prices and take a look for other deviations clearly."},{"metadata":{"trusted":true},"cell_type":"code","source":"#log of each price\ndf_house['price']=np.log(df_house.price)\n#Now plot a boxplot again\ndf_house.boxplot(column='price',sym='k.')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the boxplot showed above, we can clearly find the outlier which biased from the median value"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_house[df_house.price>15.5]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the four obervations above, the properties are resonable because they all have larger living and land space, and mulitiple bedrooms and bathrooms. More importantly, 2 properties have been renovated in 2001."},{"metadata":{},"cell_type":"markdown","source":"### ● Multivariate Outlier Detection Methods\n\n* Mahalanobis Distance"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,10))\nsns.heatmap(df_house.corr(), annot=True, fmt=\".2f\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot a price histgram\ndf_house['price'].hist(bins=100)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot living space histogram\nsns.distplot(df_house['sqft_living'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#2-dimention mahalanobis distance detect outliers\n#The greater the value of mahalanobis distance, the higher probability of outlier it is.\n\nfrom pandas import Series\nfrom scipy.spatial import distance \n#build a new dataframe which contains juat column for price and sqft_living \nhw=df_house[['price','sqft_living']]\n#define number of outliers\nn_outliers =6\n#use mahalanobis distance to detect each point\n#series used to generate distance for each property\n#hw.iloc stands for the outside index of each row; hw.mean stands for value of mean for 2 columns; np.mat create correlation matrix and reverse the matrix\nm_dist_order = Series([float(distance.mahalanobis(hw.iloc[i], hw.mean(), np.mat(hw.cov().as_matrix()).I) ** 2) for i in range(len(hw))]).sort_values(ascending=False).index.tolist()  \n#If the property is outlier return True, otherwise return False\nis_outlier = [False, ] * (len(hw)) \nfor i in range(n_outliers):  \n    is_outlier[m_dist_order[i]] = True \n#outliers are displayed in red, others are displayed in blue\ncolor = ['b', 'r']  \n#turn True to 1, False to 0\npch = [1 if is_outlier[i] == True else 0 for i in range(len(is_outlier))]  \n#turn 1 to 'r', turn 0 to 'b'\ncValue = [color[is_outlier[i]] for i in range(len(is_outlier))]  \n\n#plotting\nfig = plt.figure()  \n#set title\nplt.title('Scatter Plot')  \n#set x label\nplt.xlabel('sqft_living')  \n#set y label\nplt.ylabel('price')  \n#draw scatter\nplt.scatter(hw['sqft_living'],  hw['price'], s=40, c=cValue) \nplt.show()  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The outliers found from 2-dimention mahalanobis distance showed as following:"},{"metadata":{"trusted":true},"cell_type":"code","source":"index_list1=[]\nfor i in range(len(pch)):\n    #if value in pch is 1, it is an outlier\n    if pch[i]==1:\n        index_list1.append(i)\n#show outliers from 2-dimention mahalanobis distance\ndf_house.iloc[index_list1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"6 outliers has been detected based on mahalanobis distance, which include the outliers detected by using univariate methods. In order to get more accurate outliers, I build a 3-dimention mahalanobis distance model to find outliers by using the most 2 correlated variables (sqft_living and grades)."},{"metadata":{"trusted":true},"cell_type":"code","source":"#3-dimention mahalanobis distance detect outliers\n#The greater the value of mahalanobis distance, the higher probability of outlier it is.  \nfrom mpl_toolkits.mplot3d import Axes3D\n\n#build a new dataframe including three columns\nhw=df_house[['price','sqft_living','grade']]    \n  \nn_outliers = 6 #select 6 outliers \n#iloc[]take 3 columns and 1 row   hw.mean()here is an array of three variables    np.mat(hw.cov().as_matrix()).I is the inverse matrix of covariance   **为乘方  \n#Series's output is: the index is on the left, the value is on the right\n#m_dist_order is a one-dimensional array that holds the index in descending order of Series\nm_dist_order =  Series([float(distance.mahalanobis(hw.iloc[i], hw.mean(), np.mat(hw.cov().as_matrix()).I) ** 2)  \n       for i in range(len(hw))]).sort_values(ascending=False).index.tolist()  \nis_outlier = [False, ] * len(hw)\nfor i in range(n_outliers):#mahalanobis distance value is marked as True\n    is_outlier[m_dist_order[i]] = True  \n\n#outliers are displayed in red, others are displayed in blue\ncolor = ['b', 'r']  \n#turn True to 1, False to 0\npch = [1 if is_outlier[i] == True else 0 for i in range(len(is_outlier))]  \n#turn 1 to 'r', turn 0 to 'b'\ncValue = [color[is_outlier[i]] for i in range(len(is_outlier))]  \n\n#plotting\nfig = plt.figure()  \n#using 3 dimention \nax1 = fig.gca(projection='3d')  \n#set title and labels\nax1.set_title('Scatter Plot')  \nax1.set_xlabel('price')  \nax1.set_ylabel('sqft_living')  \nax1.set_zlabel('grade')  \n#plot scatter plot\nax1.scatter(hw['sqft_living'], hw['price'], hw['grade'], s=30, c=cValue)  \nplt.show()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"index_list2=[]\n#pch return True to 1. Here we can find the index of the outliers \nfor i in range(len(pch)):\n    if pch[i]==1:\n        index_list2.append(i)\n#show outliers from 3-dimention mahalanobis distance\ndf_house.iloc[index_list2]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"6 outliers has been detected. The result is completely the same as the outliers has been found from 2 dimention. We can keep the outliers or remove them. Here, I decide to remove them since I think they would influence the prediction models if we want to use it in the future."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Set values for particular cell in index_list\ndf_house.iloc[index_list1,1]=0\n#replace 0 with NaN\ndf_house['price'].replace(0,np.NaN,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Right now, we have a very clean and tidy dataset after data wrangling. And we can write data to a csv file."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_house\n#Writing a CSV file with the pandas library if you want\n#df_house.to_csv('house.csv', encoding='utf-8',index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thank you for reading!"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}