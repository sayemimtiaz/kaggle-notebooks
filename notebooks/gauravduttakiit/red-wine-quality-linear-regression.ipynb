{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wine = pd.read_csv(\"../input/red-wine-quality-cortez-et-al-2009/winequality-red.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wine.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wine.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wine.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wine.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Quality Check "},{"metadata":{"trusted":true},"cell_type":"code","source":"round(100*(wine.isnull().sum()/len(wine)),2).sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"round(100*(wine.isnull().sum(axis=1)/len(wine)),2).sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **No missing / Null value in either rows or columns**"},{"metadata":{"trusted":true},"cell_type":"code","source":"dub_wine=wine.copy()\ndub_wine.drop_duplicates(subset=None,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dub_wine.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wine.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **The shape after running the drop duplicate command is not same as the original dataframe.Hence we can conclude that there were duplicate values in the dataset.**"},{"metadata":{},"cell_type":"markdown","source":"### Assign non duplicate data to original data "},{"metadata":{"trusted":true},"cell_type":"code","source":"wine=dub_wine","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in wine:\n    print(wine[col].value_counts(ascending=False), '\\n\\n\\n')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **There seems to be no Junk/Unknown values in the entire dataset**"},{"metadata":{},"cell_type":"markdown","source":"# *Data Split*"},{"metadata":{"trusted":true},"cell_type":"code","source":"wine.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wine.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nnp.random.seed(0)\ndf_train,df_test=train_test_split(wine,train_size=0.7,test_size=0.3,random_state=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **EDA**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(df_train) \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Correlation Matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,25))\nsns.heatmap(wine.corr(), annot=True,cmap='RdBu')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Rescaling"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler=MinMaxScaler()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train[:]=scaler.fit_transform(df_train[:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train=df_train.pop('quality')\nX_train=df_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LinearRegression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lm = LinearRegression()\nlm.fit(X_train, y_train)\nrfe = RFE(lm,9)             \nrfe = rfe.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list(zip(X_train.columns,rfe.support_,rfe.ranking_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col = X_train.columns[rfe.support_]\ncol","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.columns[~rfe.support_]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_rfe = X_train[col]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Building Linear Model"},{"metadata":{},"cell_type":"markdown","source":"## Model 1"},{"metadata":{},"cell_type":"markdown","source":"### VIF Check"},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.stats.outliers_influence import variance_inflation_factor\nvif = pd.DataFrame()\nvif['Features'] = X_train_rfe.columns\nvif['VIF'] = [variance_inflation_factor(X_train_rfe.values, i) for i in range(X_train_rfe.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm\nX_train_lm1 = sm.add_constant(X_train_rfe)\nlr1 = sm.OLS(y_train, X_train_lm1).fit()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr1.params","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(lr1.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model 2"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_new = X_train_rfe.drop([\"residual sugar\"], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### VIF"},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.stats.outliers_influence import variance_inflation_factor\nvif = pd.DataFrame()\nvif['Features'] = X_train_new.columns\nvif['VIF'] = [variance_inflation_factor(X_train_new.values, i) for i in range(X_train_new.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_lm2 = sm.add_constant(X_train_new)\nlr2 = sm.OLS(y_train, X_train_lm2).fit()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr2.params","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(lr2.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model 3"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_new = X_train_new.drop([\"density\"], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### VIF"},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.stats.outliers_influence import variance_inflation_factor\nvif = pd.DataFrame()\nvif['Features'] = X_train_new.columns\nvif['VIF'] = [variance_inflation_factor(X_train_new.values, i) for i in range(X_train_new.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_lm3 = sm.add_constant(X_train_new)\nlr3 = sm.OLS(y_train, X_train_lm3).fit()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr3.params","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(lr3.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model 4"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_new = X_train_new.drop([\"free sulfur dioxide\"], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### VIF"},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.stats.outliers_influence import variance_inflation_factor\nvif = pd.DataFrame()\nvif['Features'] = X_train_new.columns\nvif['VIF'] = [variance_inflation_factor(X_train_new.values, i) for i in range(X_train_new.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_lm4 = sm.add_constant(X_train_new)\nlr4 = sm.OLS(y_train, X_train_lm4).fit()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr4.params","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(lr4.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model 5"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_new = X_train_new.drop([\"pH\"], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### VIF"},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.stats.outliers_influence import variance_inflation_factor\nvif = pd.DataFrame()\nvif['Features'] = X_train_new.columns\nvif['VIF'] = [variance_inflation_factor(X_train_new.values, i) for i in range(X_train_new.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_lm5 = sm.add_constant(X_train_new)\nlr5 = sm.OLS(y_train, X_train_lm5).fit()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr5.params","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(lr5.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model 6"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_new = X_train_new.drop([\"sulphates\"], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### VIF"},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.stats.outliers_influence import variance_inflation_factor\nvif = pd.DataFrame()\nvif['Features'] = X_train_new.columns\nvif['VIF'] = [variance_inflation_factor(X_train_new.values, i) for i in range(X_train_new.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_lm6 = sm.add_constant(X_train_new)\nlr6 = sm.OLS(y_train, X_train_lm6).fit()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr6.params","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(lr6.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model 7"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_new = X_train_new.drop([\"chlorides\"], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### VIF"},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.stats.outliers_influence import variance_inflation_factor\nvif = pd.DataFrame()\nvif['Features'] = X_train_new.columns\nvif['VIF'] = [variance_inflation_factor(X_train_new.values, i) for i in range(X_train_new.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_lm7 = sm.add_constant(X_train_new)\nlr7 = sm.OLS(y_train, X_train_lm7).fit()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr7.params","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(lr7.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model 8 "},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_new = X_train_new.drop([\"total sulfur dioxide\"], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### VIF"},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.stats.outliers_influence import variance_inflation_factor\nvif = pd.DataFrame()\nvif['Features'] = X_train_new.columns\nvif['VIF'] = [variance_inflation_factor(X_train_new.values, i) for i in range(X_train_new.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_lm8 = sm.add_constant(X_train_new)\nlr8 = sm.OLS(y_train, X_train_lm8).fit()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr8.params\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(lr8.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Final Model Interpretation"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Hypothesis Testing:\n\nHypothesis testing states that:\n\nH0:B1=B2=...=Bn=0\nH1: at least one Bi!=0\n\nlr8 model coefficient values\n- const                0.4990\n- volatile acidity    -0.3828     \n- alcohol              0.4148 "},{"metadata":{},"cell_type":"markdown","source":"### F Statistics\nF-Statistics is used for testing the overall significance of the Model: Higher the F-Statistics, more significant the Model is.\n\nF-statistic:                     227.8\nProb (F-statistic):           1.68e-81\nThe F-Statistics value of 227.8 (which is greater than 1) and the p-value of '~0.0000' states that the overall model is significant"},{"metadata":{},"cell_type":"markdown","source":"### The equation of best fitted surface based on model lr8:\nquality = 0.4990 - (volatile acidity × 0.3828) + (alcohol × 0.4148 ) "},{"metadata":{},"cell_type":"markdown","source":"### Interpretation of Coefficients:\nvolatile acidity: A coefficient value of ‘0.3838’ indicated that a unit decrease in volatite acidity variable, increases the quality numbers by 0.3828 units.\n\nalcohol: A coefficient value of ‘0.4148’ indicated that a unit increase in alcohol variable, increases the quality numbers by 0.4148 units."},{"metadata":{},"cell_type":"markdown","source":"# ASSUMPTIONS\n\n## Error terms are normally distributed with mean zero (not X, Y)\n\n### Residual Analysis Of Training Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred = lr8.predict(X_train_lm8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res = y_train-y_train_pred\n# Plot the histogram of the error terms\nfig = plt.figure()\nsns.distplot((res), bins = 20)\nfig.suptitle('Error Terms', fontsize = 20)                  # Plot heading \nplt.xlabel('Errors', fontsize = 18)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## There is a linear relationship between X and Y"},{"metadata":{"trusted":true},"cell_type":"code","source":"wine_num=wine[[ 'volatile acidity', 'alcohol', 'quality']]\n\nsns.pairplot(wine_num)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### There is No Multicollinearity between the predictor variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"vif = pd.DataFrame()\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nvif['Features'] = X_train_new.columns\nvif['VIF'] = [variance_inflation_factor(X_train_new.values, i) for i in range(X_train_new.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# MAKING PREDICTION USING FINAL MODEL"},{"metadata":{},"cell_type":"markdown","source":"## Applying the scaling on the test sets"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test[:]=scaler.fit_transform(df_test[:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dividing into X_test and y_test"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test = df_test.pop('quality')\nX_test = df_test\nX_test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Selecting the variables that were part of final model.\ncol1=X_train_new.columns\nX_test=X_test[col1]\n# Adding constant variable to test dataframe\nX_test_lm8 = sm.add_constant(X_test)\nX_test_lm8.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = lr8.predict(X_test_lm8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure()\nplt.scatter(y_test, y_pred, alpha=.5)\nfig.suptitle('y_test vs y_pred', fontsize = 20)              # Plot heading \nplt.xlabel('y_test', fontsize = 18)                          # X-label\nplt.ylabel('y_pred', fontsize = 16) \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df= pd.DataFrame({'Actual':y_test,'Predictions':y_pred})\ndf['Predictions']= round(df['Predictions'],2)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.regplot('Actual','Predictions',data=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### R^2 Value for TEST"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import r2_score\nr2_score(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Adjusted R^2 Value for TEST"},{"metadata":{"trusted":true},"cell_type":"code","source":"r2=0.32264089150785114\nX_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n = X_test.shape[0]\n\n\n# Number of features (predictors, p) is the shape along axis 1\np = X_test.shape[1]\n\n# We find the Adjusted R-squared using the formula\n\nadjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\nadjusted_r2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Final Result Comparison"},{"metadata":{},"cell_type":"markdown","source":"Train R^2 :0.325\n\nTrain Adjusted R^2 :0.323\n\nTest R^2 :0.322\n\nTest Adjusted R^2 :0.319"},{"metadata":{},"cell_type":"markdown","source":"### Evaluating Model Performance:\nMean Absolute Error (MAE) is the mean of the absolute value of the errors.\n\nMean Squared Error (MSE) is the mean of the squared errors.\n\nRoot Mean Squared Error (RMSE) is the square root of the mean of the squared errors."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\n\nprint('MAE:', metrics.mean_absolute_error(y_test, y_pred))\nprint('MSE:', metrics.mean_squared_error(y_test, y_pred))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We want the value of RMSE to be as low as possible, as lower the RMSE value is, the better the model is with its predictions"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}