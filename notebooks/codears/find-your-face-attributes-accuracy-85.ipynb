{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Attributes Classification by Seeing Faces of people\n\n---\n\n## Introduction\n\nIn this notebook i will implement the attributes classifier using the `celeba_dataset`. We can understand about this task by the following points.\n- `Task` : If we think about task this task will fall under the **Computer Vision** task with **Supervise Learning**.\n- `Classifier` : For the classifier we can say that this is a **multilabel classification** problem so we will use the same type of classifier.","metadata":{}},{"cell_type":"markdown","source":"### 0. Installing Required Libraries","metadata":{}},{"cell_type":"code","source":"!pip install gdown","metadata":{"execution":{"iopub.status.busy":"2021-07-25T06:23:46.736782Z","iopub.execute_input":"2021-07-25T06:23:46.737234Z","iopub.status.idle":"2021-07-25T06:24:07.892556Z","shell.execute_reply.started":"2021-07-25T06:23:46.737124Z","shell.execute_reply":"2021-07-25T06:24:07.891397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1. Importing Libraries\n\nIn this section of notebook we are just importing libraries required to complete this task. As you can see in following code cell i divided cell into 3 parts\n(seperated by blank line) <br>In *first part* i am importing `tensorflow specific libraries`, <br>In *second part* i am importing `helping libraries but specific to task` and <br>In *thirt part* i am importing `helping libraries (general purpose)`","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow.keras as keras\nfrom tensorflow.keras.applications import VGG16, ResNet50\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Conv2D, BatchNormalization, Dropout, GlobalAveragePooling2D, Activation, Dense\nfrom tensorflow.keras.losses import BinaryCrossentropy\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport gdown\nimport glob\n\nimport os","metadata":{"execution":{"iopub.status.busy":"2021-07-25T06:24:07.894871Z","iopub.execute_input":"2021-07-25T06:24:07.895342Z","iopub.status.idle":"2021-07-25T06:24:14.927849Z","shell.execute_reply.started":"2021-07-25T06:24:07.895274Z","shell.execute_reply":"2021-07-25T06:24:14.926763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2. Dataset Exploration and Big Picture\n\nIn this section of notebook i'll try to explore dataset as much as i can so that i can\ngrab the big picture.","metadata":{}},{"cell_type":"code","source":"IMGS_ATTR_PATH = '/kaggle/input/celeba-dataset/list_attr_celeba.csv'\nIMGS_PATH = '/kaggle/input/celeba-dataset/img_align_celeba/img_align_celeba'\n\nFACE_WEIGHT_VGG16 = 'https://github.com/rcmalli/keras-vggface/releases/download/v2.0/rcmalli_vggface_tf_notop_vgg16.h5'\n\nMODEL_20_EPOCHS = 'https://drive.google.com/uc?id=18N6-jvBPCODlgyyo0YiPiPTUxeyGBk0q'\nMODEL_NAME = 'model_20_epoch.h5'","metadata":{"execution":{"iopub.status.busy":"2021-07-25T06:24:14.930322Z","iopub.execute_input":"2021-07-25T06:24:14.930753Z","iopub.status.idle":"2021-07-25T06:24:14.935889Z","shell.execute_reply.started":"2021-07-25T06:24:14.930708Z","shell.execute_reply":"2021-07-25T06:24:14.93471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gdown.download(MODEL_20_EPOCHS, MODEL_NAME)","metadata":{"execution":{"iopub.status.busy":"2021-07-25T06:24:14.938139Z","iopub.execute_input":"2021-07-25T06:24:14.938966Z","iopub.status.idle":"2021-07-25T06:24:19.709975Z","shell.execute_reply.started":"2021-07-25T06:24:14.938909Z","shell.execute_reply":"2021-07-25T06:24:19.708554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_attr_names(dataframe):\n    '''\n    This function returns attr names using in dataset.\n    \n    Params:\n        dataframe (pd.Dataframe)\n        \n    Return:\n        attr_names (list): A list object containing the name of attribute name of celeb faces.\n    '''\n    attr_names = []\n    attr_names = list(dataframe.columns)\n    # removing images_id column\n    del attr_names[0]\n    \n    return attr_names\n\ndef attr_to_onehot(array):\n    '''\n    This function just make attr values in array to onehot by changing -1 to 0.\n    '''\n    result = np.copy(array)\n    result[result == -1] = 0\n    return result\n\ndef split_dataset(ds, percentage=0.2):\n    '''\n    This function can split the dataset in two parts with given percentage.\n    \n    Params: \n        ds (np.array): Numpy array representing dataset.\n        percentage (float, optional): Between 0 and 1.\n        \n    Returns:\n        main (np.array): This array contains lenght of 1-percentage of total dataset.\n        other (np.array): This array contains length of percentage of total dataset.\n    '''\n    cut_size = int(percentage * len(ds))\n    cut_indices = np.random.randint(0, len(ds), size=(cut_size, ))\n    \n    other = ds[cut_indices]\n    main = np.delete(ds, cut_indices, axis=0)\n    \n    print('--------------------------------------')\n    print(\"TOTAL:\\t{} \\nFIRST:\\t{} \\nSECOND:\\t{}\".format(len(ds), len(main), len(other)))\n    print('--------------------------------------')\n    \n    return main, other\n\ndef plot_attr(attr_names):\n    f = plt.figure(figsize=(20, 15))\n    for i, attr_name in enumerate(attr_names):\n        f.add_subplot(4, 10, i+1)\n        col = attr_df[attr_name]\n        g = sns.barplot(x=col.value_counts().index, y=col.value_counts(normalize=True))\n        g.set(ylim=(0, 1))\n        plt.yticks([])\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-25T06:24:19.711998Z","iopub.execute_input":"2021-07-25T06:24:19.712614Z","iopub.status.idle":"2021-07-25T06:24:19.727359Z","shell.execute_reply.started":"2021-07-25T06:24:19.712566Z","shell.execute_reply":"2021-07-25T06:24:19.725776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"attr_df = pd.read_csv(IMGS_ATTR_PATH)\nattr_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-25T06:24:19.729045Z","iopub.execute_input":"2021-07-25T06:24:19.729574Z","iopub.status.idle":"2021-07-25T06:24:20.775144Z","shell.execute_reply.started":"2021-07-25T06:24:19.729529Z","shell.execute_reply":"2021-07-25T06:24:20.774005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"attr_names = get_attr_names(attr_df)\nplot_attr(attr_names)","metadata":{"execution":{"iopub.status.busy":"2021-07-25T06:24:20.777278Z","iopub.execute_input":"2021-07-25T06:24:20.777637Z","iopub.status.idle":"2021-07-25T06:24:23.961732Z","shell.execute_reply.started":"2021-07-25T06:24:20.777606Z","shell.execute_reply":"2021-07-25T06:24:23.960248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"attr2idx = {v:i for i, v in enumerate(attr_names)}\n\nattr2idx","metadata":{"execution":{"iopub.status.busy":"2021-07-25T06:24:23.96835Z","iopub.execute_input":"2021-07-25T06:24:23.968679Z","iopub.status.idle":"2021-07-25T06:24:23.983832Z","shell.execute_reply.started":"2021-07-25T06:24:23.968648Z","shell.execute_reply":"2021-07-25T06:24:23.981933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"attr_np = np.array(attr_df)\nattr_np.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-25T06:24:23.985962Z","iopub.execute_input":"2021-07-25T06:24:23.986543Z","iopub.status.idle":"2021-07-25T06:24:24.3876Z","shell.execute_reply.started":"2021-07-25T06:24:23.9865Z","shell.execute_reply":"2021-07-25T06:24:24.386405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"celeb_dataset = attr_to_onehot(attr_np)\nceleb_dataset[:5]","metadata":{"execution":{"iopub.status.busy":"2021-07-25T06:24:24.389657Z","iopub.execute_input":"2021-07-25T06:24:24.390224Z","iopub.status.idle":"2021-07-25T06:24:24.858832Z","shell.execute_reply.started":"2021-07-25T06:24:24.390176Z","shell.execute_reply":"2021-07-25T06:24:24.857487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_np, test_np = split_dataset(celeb_dataset, 0.1)","metadata":{"execution":{"iopub.status.busy":"2021-07-25T06:24:24.860553Z","iopub.execute_input":"2021-07-25T06:24:24.861187Z","iopub.status.idle":"2021-07-25T06:24:25.097161Z","shell.execute_reply.started":"2021-07-25T06:24:24.861141Z","shell.execute_reply":"2021-07-25T06:24:25.096054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3. Dataset Proprocessing\n\nIn this section i'll convert the dataset to trainable form with respect to model.","metadata":{}},{"cell_type":"code","source":"def load_to_tfds(array):\n    \"\"\"\n    This function just take np.array and extract imgs_path and attr_list\n    seperately and then make seperate tensorflow dataset for both. Return \n    tensorflow dataset by zipping these two generated datasets.\n\n    Args:\n        array (np.array): Numpy array representing dataset\n\n    Returns:\n        ds (tf.data.Dataset): Tensorflow dataset containing zipped image and \n                              Respective attributes list.\n    \"\"\" \n    img_path = array[:, 0]\n    img_attrs = array[:, 1:]\n    \n    path_ds = tf.data.Dataset.from_tensor_slices(img_path)\n    attrs_ds = tf.data.Dataset.from_tensor_slices(img_attrs.astype(np.int16))\n    \n    ds = tf.data.Dataset.zip((path_ds, attrs_ds))\n    \n    return ds\n\ndef load_and_process_image(name, attrs, augment=False):\n    \"\"\"\n    This function take name(of image) and attrs(of image) and returns\n    loaded image with attrs.\n\n    Args:\n        name (tf.string): String representing the name of image.\n        attrs (tf.int): List representing the attributes of image.\n\n    Returns:\n        (image, attrs): Loaded image with attributes list.\n    \"\"\"\n    full_path = IMGS_PATH + os.sep + name\n    image = tf.io.read_file(full_path)\n    image = tf.io.decode_jpeg(contents=image, channels=3)\n    image = tf.cast(image, tf.float32)\n    image = tf.divide(image, 255.)\n    image = tf.image.resize(image, size=(112, 112))\n    if (augment):\n        image = tf.image.random_flip_left_right(image)\n    return image, attrs\n\ndef preprocess_ds(ds, batch_size=128):\n    \"\"\"\n    Batch and prefetch batched thats it.\n\n    Args:\n        ds (tf.data.Dataset): Tensorflow dataset\n        batch_size (int, optional): Number of items to be in single batch. Defaults to 128.\n\n    Returns:\n        ds: Tensorflow dataset\n    \"\"\"\n    ds = ds.shuffle(256)\n    ds = ds.batch(batch_size)\n    ds = ds.prefetch(tf.data.AUTOTUNE)\n    return ds","metadata":{"execution":{"iopub.status.busy":"2021-07-25T06:24:25.098719Z","iopub.execute_input":"2021-07-25T06:24:25.099162Z","iopub.status.idle":"2021-07-25T06:24:25.11117Z","shell.execute_reply.started":"2021-07-25T06:24:25.099118Z","shell.execute_reply":"2021-07-25T06:24:25.109874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds = load_to_tfds(train_np)\ntest_ds = load_to_tfds(test_np)\n\ntrain_ds = train_ds.map(lambda x, y: load_and_process_image(x, y, True))\ntest_ds = test_ds.map(load_and_process_image)\n\ntrain_ds = preprocess_ds(train_ds, batch_size=64)\ntest_ds = preprocess_ds(test_ds, batch_size=64)","metadata":{"execution":{"iopub.status.busy":"2021-07-25T06:24:25.113366Z","iopub.execute_input":"2021-07-25T06:24:25.11443Z","iopub.status.idle":"2021-07-25T06:24:27.985279Z","shell.execute_reply.started":"2021-07-25T06:24:25.114383Z","shell.execute_reply":"2021-07-25T06:24:27.984196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4. Dataset Visualization\n\nIn this part of task we generally Visualize the data with respective labels. As this dataset contains images so i will plot images with\nattributes.","metadata":{}},{"cell_type":"code","source":"def get_label_string(label):\n    '''\n    This function return string representation of label list\n    \n    Params:\n        label (list) : A onehot representation of labels\n        \n    Return:\n        joined by \\n string from every element of list\n    '''\n    true_label = np.array(list(attr2idx.keys()))[label==1]\n    return ', '.join(true_label)\n\ndef plot_images(images, labels, pred_labels=[]):\n    '''\n    This function plot the images one by one in 1x5 grid with string representation of label as title of\n    respective image.\n    \n    Params:\n        images (np.ndarray) : images to plot\n        labesl (np.ndarray) : labels to plot as title\n        pred_labels (nd.ndarray) : predicted labels to compare with true labels\n    '''\n    for i, image in enumerate(images):\n        _ = plt.figure(figsize=(4, 4))\n        print('-----------------------')\n        print('True Attributes:', get_label_string(labels[i]))\n        if len(pred_labels) != 0:\n            print('Predicted Attributes:', get_label_string(pred_labels[i]))\n        plt.imshow(image)\n        plt.xticks([])\n        plt.yticks([])\n        plt.show()\n        print('-----------------------')","metadata":{"execution":{"iopub.status.busy":"2021-07-25T06:24:27.986894Z","iopub.execute_input":"2021-07-25T06:24:27.987374Z","iopub.status.idle":"2021-07-25T06:24:27.996428Z","shell.execute_reply.started":"2021-07-25T06:24:27.98733Z","shell.execute_reply":"2021-07-25T06:24:27.995182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images, labels = next(iter(train_ds))\nimages, labels = images.numpy()[:5], labels.numpy()[:5]\n\nplot_images(images, labels)","metadata":{"execution":{"iopub.status.busy":"2021-07-25T06:24:27.998263Z","iopub.execute_input":"2021-07-25T06:24:27.998994Z","iopub.status.idle":"2021-07-25T06:24:31.298103Z","shell.execute_reply.started":"2021-07-25T06:24:27.998945Z","shell.execute_reply":"2021-07-25T06:24:31.297012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Deleting the unused vars\ndel train_np, test_np","metadata":{"execution":{"iopub.status.busy":"2021-07-25T06:24:31.29979Z","iopub.execute_input":"2021-07-25T06:24:31.300174Z","iopub.status.idle":"2021-07-25T06:24:31.324852Z","shell.execute_reply.started":"2021-07-25T06:24:31.300135Z","shell.execute_reply":"2021-07-25T06:24:31.323391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5. Model Training with Validation\n\nThis section is all about training the model.","metadata":{}},{"cell_type":"code","source":"def vgg16_model():\n    '''\n    This function is used to create the model. In this model i'll be using vgg16 pretrained model on vggface dataset.\n    Notice i'm using GlobalAveragePooling instead of Dense layer.\n    \n    Returns:\n        classifier (tf.keras.Model) : Custom model with resnet_50 pretrained.\n    '''\n    vgg_features = VGG16(include_top=False, input_shape=(112, 112, 3), pooling='avg', weights=None)\n    face_weights = tf.keras.utils.get_file('vgg16_notop_weights', FACE_WEIGHT_VGG16)\n    vgg_features.load_weights(face_weights)\n    for layer in vgg_features.layers:\n        layer.trainable = False\n    classifier = Sequential([\n        vgg_features,\n        Dense(len(attr2idx)),\n        Activation('sigmoid')\n    ])\n    return classifier\n\ndef resnet50_model():\n    '''\n    This function is used to create the model. In this model i'll be using resnet50 pretrained model on imagenet dataset.\n    Notice i'm using GlobalAveragePooling instead of Dense layer.\n    \n    Returns:\n        classifier (tf.keras.Model) : Custom model with resnet_50 pretrained.\n    '''\n    resnet_features = ResNet50(include_top=False, input_shape=(112, 112, 3), pooling='avg')\n    for layer in resnet_features.layers:\n        layer.trainable = False\n    classifier = Sequential([\n        resnet_features,\n        Dense(len(attr2idx)),\n        Activation('sigmoid')\n    ])\n    return classifier\n\ndef initializer_model(optimizer, loss, metrics):\n    '''\n    This function declare and compile the model with given params.\n    \n    Params:\n        optimizer (string) : Optimizer for model\n        loss (string) : Loss to minimize\n        metrics (list) : Metrics to visualize while training\n        \n    Returns:\n        model (tf.keras.Model) : Compiled model\n    '''\n    model = resnet50_model()\n    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n    return model\n\ndef load_or_initialize_model(path, loss, optimizer='adam', metrics=['accuracy']):\n    '''\n    This function load checkpoint weights to the model if there is present any otherwise just initialize model.\n    \n    Params:\n        path (string) : Path to the model checkpoint\n        loss (string) : Loss to minimize\n        optimizer (string, optional) : Optimizer for the model\n        metrics (list, optional) : Metrics to visualize while training\n        \n    Returns:\n        model (tf.keras.Model) : Loaded model if checkpoint present otherwise new instance of model.\n    '''\n    model = initializer_model(optimizer, loss, metrics)\n    print('Initialized Model...')\n    checkpoint_dir = os.path.dirname(path)\n    if len(glob.glob('./*.h5')) > 0:\n        model = keras.models.load_model(glob.glob('./*.h5')[0])\n        print(\"Loaded pretrained Model...\")\n    if not os.path.exists(checkpoint_dir):\n        os.mkdir(checkpoint_dir)\n        print('Created checkpoint directory...')\n    elif len(os.listdir(checkpoint_dir)) > 0:\n        model.load_weights(path)\n        print(\"Loading Weights...\")\n        \n    return model\n\ndef generate_class_weights(attr_names):\n    '''\n    This function used attr_names and attr_df to generate class_weight for losses to deal with\n    unbalanced data as you can see in above histograms. This should e noticed that function returning\n    value_counts[-1] due to we are more concerned for minorities class and mapping that to weights.\n    \n    Params:\n        attr_name (list) : list of columns of attr_df to generate class_weight\n        \n    Returns:\n        weights (dict) : Generated weight dict mapping label index to weights.\n    '''\n    weights = dict()\n    for i, attr_name in enumerate(attr_names):\n        value_counts = dict(attr_df[attr_name].value_counts(normalize=True))\n        weights[i] = value_counts[-1]\n    total_sum = sum(list(weights.values()))\n    weights = {k: v/total_sum for k, v in weights.items()}\n    return weights","metadata":{"execution":{"iopub.status.busy":"2021-07-25T06:25:46.639685Z","iopub.execute_input":"2021-07-25T06:25:46.640158Z","iopub.status.idle":"2021-07-25T06:25:46.658559Z","shell.execute_reply.started":"2021-07-25T06:25:46.640121Z","shell.execute_reply":"2021-07-25T06:25:46.656918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint_filepath = './checkpoint/cp.ckpt'\n\n# Hyperparameters\noptimizer = 'adam'\nbc_loss = 'binary_crossentropy'\nmetrics = ['binary_accuracy']\nEPOCHS = 20\n\n# Loading or Initializing model\nmodel = load_or_initialize_model(checkpoint_filepath, bc_loss, optimizer, metrics)","metadata":{"execution":{"iopub.status.busy":"2021-07-25T06:25:47.513163Z","iopub.execute_input":"2021-07-25T06:25:47.513605Z","iopub.status.idle":"2021-07-25T06:25:52.170789Z","shell.execute_reply.started":"2021-07-25T06:25:47.513575Z","shell.execute_reply":"2021-07-25T06:25:52.168749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-07-25T06:25:54.362862Z","iopub.execute_input":"2021-07-25T06:25:54.363275Z","iopub.status.idle":"2021-07-25T06:25:54.390822Z","shell.execute_reply.started":"2021-07-25T06:25:54.363244Z","shell.execute_reply":"2021-07-25T06:25:54.389426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# callback definitions\nearly_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True, verbose=1)\nmodel_checkpoint = ModelCheckpoint(filepath=checkpoint_filepath, save_weights_only=True, verbose=1)\nclass_weights = generate_class_weights(attr_names)\n\n# training\nhistory = model.fit(train_ds, validation_data=test_ds, epochs=EPOCHS, callbacks=[early_stopping, model_checkpoint],\n                   class_weight=class_weights)\nmodel.save('./model_vggface_loss_{}.h5'.format(history.history['val_loss'][-1]))","metadata":{"execution":{"iopub.status.busy":"2021-07-25T06:25:56.464092Z","iopub.execute_input":"2021-07-25T06:25:56.464539Z","iopub.status.idle":"2021-07-25T07:15:31.521943Z","shell.execute_reply.started":"2021-07-25T06:25:56.4645Z","shell.execute_reply":"2021-07-25T07:15:31.520821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Notice** there is big difference between `loss` and `val_loss` due to `class_weights` which sums up to **1**.","metadata":{}},{"cell_type":"markdown","source":"### 6. Model Interference and Visualization\n\nIn this section i will plot the images with there true labels as well as predicted labels.","metadata":{}},{"cell_type":"code","source":"# Tuning Parameter\nthershold = 0.4\n#--------\nbatch = next(iter(test_ds))\ntest_images, test_labels = batch\n\n# Predicting Labels\npred_labels = model.predict(test_images)\n\n# Changing Predicted labels to One-Hot\npred_labels[pred_labels >= thershold] = 1\npred_labels[pred_labels < thershold] = 0\n\n# Processing for plotting\ntest_images = test_images.numpy()[:5]\ntest_labels = test_labels.numpy()[:5]\npred_labels = pred_labels[:5]\n\n# Finally Plotting\nplot_images(test_images, test_labels, pred_labels)","metadata":{"execution":{"iopub.status.busy":"2021-07-25T07:16:31.155271Z","iopub.execute_input":"2021-07-25T07:16:31.155732Z","iopub.status.idle":"2021-07-25T07:16:32.22678Z","shell.execute_reply.started":"2021-07-25T07:16:31.155702Z","shell.execute_reply":"2021-07-25T07:16:32.225063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"If results are not impressive then not that bad also.","metadata":{}},{"cell_type":"markdown","source":"# Thanks for Reading this Notebook\n\nPlease **UpVote** this notebook if you like this it means a lot to me.<br>\n**PS**: We should be together too. :)","metadata":{}}]}