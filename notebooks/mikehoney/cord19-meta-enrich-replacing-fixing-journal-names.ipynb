{"cells":[{"metadata":{},"cell_type":"markdown","source":"# CORD-19 Metadata Enrichment [4/x]: Replacing and Fixing Journal Names using Scimago Journal & Country Rank Website Query\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## [CORD-19 Metadata Enrichment Dataset](https://www.kaggle.com/dannellyz/cord19-metadata-enrichment)\n\nThis notebook builds on other work seeking to provide additional, augmented, and normalized data across the CORD-19 dataset. Those other notebooks can be found here:\n1. [CORD-19 Metadata Enrich: NIH API](https://www.kaggle.com/dannellyz/cord19-metadata-enrich-nih-api)\n2. [CORD-19 Metadata Enrich: Altmetric API](https://www.kaggle.com/dannellyz/cord19-metadata-enrich-altmetric-api)\n2. [CORD-19 Metadata Enrich: Microsoft Academic API](https://www.kaggle.com/dannellyz/cord19-metadata-enrich-microsoft-academic-api)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"This notebook is a simple script that takes all of the journal names which are present in the metadata but not in the Scimago rankings and searches the SJR site for their closest match. It then takes this and makes a replace dictionary which is saved to a csv for future loading.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nbase_file_path = \"/kaggle/input/CORD-19-research-challenge/\"\nenrich_file_path = \"/kaggle/input/cord19-metadata-enrichment/\"\n\n#Can either go ahead with the enriched metdata or the base\nmetadata = pd.read_csv(base_file_path + \"metadata.csv\", index_col=\"cord_uid\")\njournal_rankings = pd.read_csv(enrich_file_path + \"scimago_journal_rankings.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import requests\nfrom bs4 import BeautifulSoup\nimport concurrent.futures\nfrom tqdm.notebook import tqdm\n\ndef get_journal_name(search):\n    if pd.notnull(search):\n        #repalce spaces with +\n        prepared = search.replace(\" \", \"+\")\n        r = requests.get(\"https://www.scimagojr.com/journalsearch.php?q=\" + prepared)\n        soup = BeautifulSoup(r.text, 'html.parser')\n        #Find first and return\n        for_return = soup.find(\"span\", {\"class\": \"jrnlname\"})\n        if for_return:\n            return search.lower(),for_return.text.lower(),\n        else:\n            return None\n    else:\n        return None\n\n#Get list of all journals not found in the Scimago Rankings but in the Metadata\nmissing_ranking = list(set(metadata[\"journal\"]) - set(journal_rankings[\"Title\"]))\njrnl_names_dict = {}\n\n#Use threading to speed up process\nwith concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:\n    map_obj = tqdm(executor.map(get_journal_name, missing_ranking), total=len(missing_ranking))\n    jrnl_names_dict = {item[0]:item[1] for item in map_obj if item}\npd.DataFrame.from_dict(jrnl_names_dict, orient=\"index\").to_csv(\"journal_abrv_replace.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Comparing before and after","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Before Replace\nMatrix of those with a value in the metadata journal column but not found in the journal rankings","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Send both journal columns to lower in case of odd caps\nmetadata[\"journal\"] = metadata[\"journal\"].str.lower()\njournal_rankings[\"Title\"] = journal_rankings[\"Title\"].str.lower()\n\n#Merge before request\npaper_significance = metadata.merge(journal_rankings[[\"Title\",\"SJR\"]], left_on=\"journal\", right_on=\"Title\", how=\"left\")\nprint(paper_significance.notnull().groupby([\"journal\", \"SJR\"]).size())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Top journals found in the metadata that are not found in the rankings","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"paper_significance[paper_significance.journal.notnull() & paper_significance.SJR.isnull()].journal.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Before Replace","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Replace and rerun statistics\nmetadata[\"journal\"] = metadata[\"journal\"].replace(jrnl_names_dict)\npaper_significance = metadata.merge(journal_rankings[[\"Title\",\"SJR\"]], left_on=\"journal\", right_on=\"Title\", how=\"left\")\nprint(paper_significance.notnull().groupby([\"journal\", \"SJR\"]).size())\nprint(paper_significance[paper_significance.journal.notnull() & paper_significance.SJR.isnull()].journal.value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Load from Enrichment Dataset example\njrnl_names = pd.read_csv(enrich_file_path + \"journal_abrv_replace.csv\", names=[\"metadata_name\", \"sjr_name\"])\njrnl_dict = dict(zip(jrnl_names.metadata_name, jrnl_names.sjr_name))\nlen(jrnl_dict)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"### Let me know if I can help with any other metadata enrichment and please upvote if this was helpful","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}