{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"%reset -f\n# 1.1 Data manipulation\n\nimport pandas as pd\nimport numpy as np\n# 1.2 Import GaussianMixture class\nfrom sklearn.mixture import GaussianMixture\n# 1.3 Plotting\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import imshow\nfrom matplotlib.colors import LogNorm\nimport seaborn as sns\n# 1.4 For data processing\nfrom sklearn.preprocessing import StandardScaler\n# 1.4\nimport time\nfrom sklearn.cluster import KMeans\n# 1.1 For creating elliptical-shaped clusters\nfrom sklearn.datasets import make_blobs\n# 1.4 TSNE\nfrom sklearn.manifold import TSNE\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***i)    Read dataset and rename columns appropriately***","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# reading dataset\ndf = pd.read_csv('../input/customer-segmentation-tutorial-in-python/Mall_Customers.csv')\n#df.info()\n\n#print(df.columns)\ndf.shape\ndf.head()\n\n#df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# renaming the columns \nprint(df.columns)  \ndf.rename(columns = {'CustomerID':'CID','Gender':'GEN','Age':'AGE', 'Annual Income (k$)':'AI (Rs)','Spending Score (1-100)':'SCORE'\n                              },inplace=True) \ndf.shape\ndf.head()\n#df.describe()    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***ii)   Drop customerid column and also transform Gender column to [0,1]*********","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# dropping customerid column and transforming Gender column to [0,1]\n\ndf.drop(['CID'], axis=1,inplace=True)\n#df.info()\n\ndf['GEN'].replace(['Male','Female'],[0,1])\n\n#df.shape\n#df.head()\ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*iii)  Use seaborn to understand each feature and relationships among features.*****","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df[\"GEN\"])\nsns.stripplot(x=\"GEN\", y=\"AGE\", data=df)\nsns.pairplot(hue=\"GEN\",data=df)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pointplot(x=\"GEN\", y=\"SCORE\", data=df)\nsns.catplot(x=\"GEN\", y=\"AGE\", data=df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nsns.barplot(x=\"GEN\", y=\"SCORE\", data=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***iv)  Use sklearn's StandardScaler() to scale dataset*******","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create Scatter Plot:\n\n#df.shape     # (1000,2)\ndf.plot.scatter(x='GEN', y='SCORE', c='blue', s=5)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***v)   Perform clustering using Gaussian Mixture Modeling.*******","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# 4.0 Import GaussianMixture class\nfrom sklearn.mixture import GaussianMixture\n\n# 4.1 Perform clsutering\ngm = GaussianMixture(\n                     n_components = 3,\n                     n_init = 10,\n                     max_iter = 100)\n\n# 4.2 Train the algorithm\ngm.fit(X)\n\n# 4.3 Where are the clsuter centers\ngm.means_\n\n# 4.6 Clusters labels\ngm.predict(X)\n\n# 5.0 Plot cluster and cluster centers\n#     both from kmeans and from gmm\n\nfig = plt.figure()\n\n# 5.1 from kmeans\nplt.scatter(X[:, 0], X[:, 1],\n            c=gm.predict(X),\n            s=2)\nplt.show()\n# 5.2 from gmm\nplt.scatter(gm.means_[:, 0], gm.means_[:, 1],\n            marker='v',\n            s=5,               # marker size\n            linewidths=5,      # linewidth of marker edges\n            color='red'\n            )\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 3.0 Apply kmeans\nkmeans = KMeans(n_clusters=3,\n                    n_init =10,\n                    max_iter = 800)\nkmeans.fit(X)\n\n# 3.1 Get cluster centers\ncentroids=kmeans.cluster_centers_\n\n# 3.2 Plot clusters and cluster centers\nfig = plt.figure()\nplt.scatter(X[:, 0], X[:, 1],\n            c=kmeans.labels_,\n            s=2)\nplt.scatter(centroids[:, 0], centroids[:, 1],\n            marker='x',\n            s=100,               # marker size\n            linewidths=150,      # linewidth of marker edges\n            color='red'\n            )\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 4.1 Perform clsutering\ngm = GaussianMixture(\n                     n_components = 3,\n                     n_init = 10,\n                     max_iter = 100)\n\n# 4.2 Train the algorithm\ngm.fit(X)\n\n# 4.3 Where are the clsuter centers\ngm.means_\n\n# 4.4 Did algorithm converge?\ngm.converged_\n\n# 4.5 How many iterations did it perform?\ngm.n_iter_\n\n# 4.6 Clusters labels\ngm.predict(X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***vi)  Use aic and bic measures to draw a scree plot and discover ideal number of clusters*******","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# 8.0 How many clusters?\n#     Use either AIC or BIC as criterion\n\nbic = []\naic = []\nfor i in range(8):\n    gm = GaussianMixture(\n                     n_components = i+1,\n                     n_init = 10,\n                     max_iter = 100)\n    gm.fit(X)\n    bic.append(gm.bic(X))\n    aic.append(gm.aic(X))\n    \n    gm = GaussianMixture(\n                     n_components = 3,\n                     n_init = 10,\n                     max_iter = 100)\n    gm.fit(X)\n       \n    \nfig = plt.figure()\nplt.plot([1,2,3,4,5,6,7,8], aic)\nplt.plot([1,2,3,4,5,6,7,8], bic)\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***viii) Lookup anomalous customers and try to understand their behavior.*****","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Anomaly detection\ndensities = gm.score_samples(X)\ndensities\n\ndensity_threshold = np.percentile(densities,4)\ndensity_threshold\n\nanomalies = X[densities < density_threshold]\nanomalies\nanomalies.shape\n\n# Show anomalous points\nfig = plt.figure()\nplt.scatter(X[:, 0], X[:, 1], c = gm.predict(X))\nplt.scatter(anomalies[:, 0], anomalies[:, 1],\n            marker='x',\n            s=50,               # marker size\n            linewidths=5,      # linewidth of marker edges\n            color='red'\n            )\nplt.show()\n\n#  Get first unanomalous data\nunanomalies = X[densities >= density_threshold]\nunanomalies.shape    # (1200, 2)\n\n#  Transform both anomalous and unanomalous data\n#     to pandas DataFrame\ndf_anomalies = pd.DataFrame(anomalies, columns = ['x', 'y'])\ndf_anomalies['z'] = 'anomalous'   # Create a IIIrd constant column\ndf_normal = pd.DataFrame(unanomalies, columns = ['x','y'])\ndf_normal['z'] = 'unanomalous'    # Create a IIIrd constant column\n\n\n#  Let us see density plots\nsns.distplot(df_anomalies['x'])\nsns.distplot(df_normal['x'])\n\n#  Draw side-by-side boxplots\n#  Ist stack two dataframes\ndf = pd.concat([df_anomalies,df_normal])\n#  Draw featurewise boxplots\nsns.boxplot(x = df['z'], y = df['y'])\nsns.boxplot(x = df['z'], y = df['x'])\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}