{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt \n%matplotlib inline\nimport seaborn as sns\nimport time\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import LinearSVC, SVC\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss, fbeta_score\nfrom sklearn.metrics import auc, roc_curve, roc_auc_score, precision_recall_curve\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv\")\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# remove 11 rows with spaces in TotalCharges (0.15% missing data)\ndf['TotalCharges'] = df['TotalCharges'].replace(' ',np.nan)   \ndf = df.dropna(how = 'any') \ndf['TotalCharges'] = df['TotalCharges'].astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['TotalCharges'].isnull().sum()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# data overview\nprint ('Rows     : ', df.shape[0])\nprint ('Columns  : ', df.shape[1])\nprint ('\\nFeatures : \\n', df.columns.tolist())\nprint ('\\nMissing values :  ', df.isnull().sum().values.sum())\nprint ('\\nUnique values :  \\n', df.nunique())\ndf.info()\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df.Churn.value_counts())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Churn'].value_counts().plot('bar').set_title('Churn')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n# percentage of churn customers\n1869/(5163+1869)= 0.26\n"},{"metadata":{},"cell_type":"markdown","source":"**In this dataset of over 7000 customers, 26% of them has left in the last month. This is critical to business because it is often more expensive to acquire new customers than to keep existing ones.\n**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['SeniorCitizen'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**The features in this dataset include the following:\n\n* · demographic data: Gender, SeniorCitizen, Partner, Dependents\n* · subscribed services: PhoneService, MultipleLine, InternetService, OnlineSecurity, OnlineBackup, DeviceProtection, TechSupport, StreamingTV, StreamingMovies\n* · customer account information: CustomerID, Contract, PaperlessBilling, PaymentMethod, MonthlyCharges, TotalCharges, Tenure\n\n\nTarget is Churn, which has binary classes 1 and 0.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# replace values for SeniorCitizen as a categorical feature\ndf['SeniorCitizen'] = df['SeniorCitizen'].replace({1:'Yes',0:'No'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.dropna(how='all') # remove samples with null fields\ndf = df[~df.duplicated()] # remove duplicates\ndf[df.TotalCharges == ' '] # display all 11 rows with spaces in TotalCharges column (0.15% missing data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# see all numerical columns\ndf.describe()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_cols = ['tenure', 'MonthlyCharges', 'TotalCharges']\ndf[num_cols].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(df[['tenure', 'MonthlyCharges', 'TotalCharges', 'Churn']], \n             hue='Churn', plot_kws=dict(alpha=.3, edgecolor='none'), height=2, aspect=1.1);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correlation Matrix for variables\nsns.set(rc={'figure.figsize':(8,6)})\nsns.heatmap(df.corr(), cmap=\"seismic\", annot=False, vmin=-1, vmax=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# to view numerical features in charts\nfig, ax = plt.subplots(1, 3, figsize=(15, 3))\ndf[num_cols].hist(bins=20, figsize=(10, 7), ax=ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# To analyse categorical feature distribution\n# Note: senior citizens and customers without phone service are minority (less represented) in the data\n# Note: \"No Internet Service\" is a repeated feature in 6 other charts\n\ncategorical_features = [\n 'gender',\n 'SeniorCitizen',\n 'Partner',\n 'Dependents',\n 'PhoneService',\n 'MultipleLines',\n 'InternetService',\n 'OnlineSecurity',\n 'OnlineBackup',\n 'DeviceProtection',\n 'TechSupport',\n 'StreamingTV',\n 'StreamingMovies',\n 'PaymentMethod',\n 'PaperlessBilling',\n 'Contract' ]\n\nROWS, COLS = 4, 4\nfig, ax = plt.subplots(ROWS, COLS, figsize=(18, 20) )\nrow, col = 0, 0\nfor i, categorical_feature in enumerate(categorical_features):\n    if col == COLS - 1:\n        row += 1\n    col = i % COLS\n#     df[categorical_feature].value_counts().plot('bar', ax=ax[row, col]).set_title(categorical_feature)\n    df[df.Churn=='No'][categorical_feature].value_counts().plot('bar', \n                width=.5, ax=ax[row, col], color='blue', alpha=0.5).set_title(categorical_feature)\n    df[df.Churn=='Yes'][categorical_feature].value_counts().plot('bar', \n                width=.3, ax=ax[row, col], color='orange', alpha=0.7).set_title(categorical_feature)\n    plt.legend(['No Churn', 'Churn'])\n    fig.subplots_adjust(hspace=0.7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# to look at Contract & Payment Method in relation to the target variable\n# note: users who have a month-to-month contract and Electronic check PaymentMethod are more likely to churn\nfig, ax = plt.subplots(1, 2, figsize=(10, 4), sharey=True)\ndf[df.Churn == 'No']['Contract'].value_counts().plot('bar', ax=ax[0], color='blue', alpha=0.5).set_title('Contract')\ndf[df.Churn == 'Yes']['Contract'].value_counts().plot('bar', width=.3, ax=ax[0], color='orange', alpha=0.7)\ndf[df.Churn == 'No']['PaymentMethod'].value_counts().plot('bar', ax=ax[1], color='blue', alpha=0.5).set_title('PaymentMethod')\ndf[df.Churn == 'Yes']['PaymentMethod'].value_counts().plot('bar', width=.3, ax=ax[1], color='orange', alpha=0.7)\nplt.legend(['No Churn', 'Churn'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# look at distributions of numerical features in relation to the target variable\n# the greater TotalCharges and tenure are the less is the probability of churn\n\nfig, ax = plt.subplots(1, 3, figsize=(15, 3))\ndf[df.Churn == \"No\"][num_cols].hist(bins=35, color=\"blue\", alpha=0.5, ax=ax)\ndf[df.Churn == \"Yes\"][num_cols].hist(bins=35, color=\"orange\", alpha=0.7, ax=ax)\nplt.legend(['No Churn', 'Churn'], shadow=True, loc=9)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**How do we select features?\nFeatures are selected mainly based on Lasso coefficient and using Random Forest. The p-values and coefficients from Statsmodels have also been considered.**"},{"metadata":{},"cell_type":"markdown","source":"# Feature Engineering\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# change MonthlyCharges to categorical column\ndef monthlycharges_split(df) :   \n    if df['MonthlyCharges'] <= 30 :\n        return '0-30'\n    elif (df['MonthlyCharges'] > 30) & (df['MonthlyCharges'] <= 70 ):\n        return '30-70'\n    elif (df['MonthlyCharges'] > 70) & (df['MonthlyCharges'] <= 99 ):\n        return '70-99'\n    elif df['MonthlyCharges'] > 99 :\n        return '99plus'\ndf['monthlycharges_group'] = df.apply(lambda df:monthlycharges_split(df), axis = 1)\n\n# change TotalCharges to categorical column\ndef totalcharges_split(df) :   \n    if df['TotalCharges'] <= 2000 :\n        return '0-2k'\n    elif (df['TotalCharges'] > 2000) & (df['TotalCharges'] <= 4000 ):\n        return '2k-4k'\n    elif (df['TotalCharges'] > 4000) & (df['TotalCharges'] <= 6000) :\n        return '4k-6k'\n    elif df['TotalCharges'] > 6000 :\n        return '6kplus'\ndf['totalcharges_group'] = df.apply(lambda df:totalcharges_split(df), axis = 1)\n\n# change Tenure to categorical column\ndef tenure_split(df) :   \n    if df['tenure'] <= 20 :\n        return '0-20'\n    elif (df['tenure'] > 20) & (df['tenure'] <= 40 ):\n        return '20-40'\n    elif (df['tenure'] > 40) & (df['tenure'] <= 60) :\n        return '40-60'\n    elif df['tenure'] > 60 :\n        return '60plus'\ndf['tenure_group'] = df.apply(lambda df:tenure_split(df), axis = 1)\n\n# # Separating categorical and numerical columns\n# Id_col     = ['customerID']\n# target_col = ['Churn']\n# cat_cols   = df.nunique()[df.nunique() < 6].keys().tolist()\n# cat_cols   = [x for x in cat_cols if x not in target_col]\n# num_cols   = [x for x in df.columns if x not in cat_cols + target_col + Id_col]\n\n# target_col","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# new features monthlycharges_group\nplt.figure(figsize = [10,5])\ndf[df.Churn == \"No\"]['monthlycharges_group'].value_counts().plot('bar', color=\"blue\", alpha=0.5).set_title('monthlycharges_group')\ndf[df.Churn == \"Yes\"]['monthlycharges_group'].value_counts().plot('bar', color=\"orange\", alpha=0.7, width=0.3)\nplt.legend(['No Churn', 'Churn'], shadow=True, loc=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# new features totalcharges_group\nplt.figure(figsize = [10,5])\ndf[df.Churn == \"No\"]['totalcharges_group'].value_counts().plot('bar', color=\"blue\", alpha=0.5).set_title('totalcharges_group')\ndf[df.Churn == \"Yes\"]['totalcharges_group'].value_counts().plot('bar', color=\"orange\", alpha=0.7, width=0.3)\nplt.legend(['No Churn', 'Churn'], shadow=True, loc=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# new features tenure_group\nplt.figure(figsize = [10,5])\ndf[df.Churn == \"No\"]['tenure_group'].value_counts().plot('bar', color=\"blue\", alpha=0.5).set_title('tenure_group')\ndf[df.Churn == \"Yes\"]['tenure_group'].value_counts().plot('bar', color=\"orange\", alpha=0.7, width=0.3)\nplt.legend(['No Churn', 'Churn'], shadow=True, loc=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# store df to csv file\ndf.to_csv('/kaggle/working/df.csv', index=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/working/df.csv')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data preprocessing\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\n\n# customer id col\nId_col     = ['customerID']\n# Target columns\ntarget_col = ['Churn']\n#categorical columns\ncat_cols   = df.nunique()[df.nunique() < 6].keys().tolist()\ncat_cols   = [x for x in cat_cols if x not in target_col]\n#numerical columns\nnum_cols   = [x for x in df.columns if x not in cat_cols + target_col + Id_col]\n#Binary columns with 2 values\nbin_cols   = df.nunique()[df.nunique() == 2].keys().tolist()\n#Columns more than 2 values\nmulti_cols = [i for i in cat_cols if i not in bin_cols]\n\n#Label encoding Binary columns\nle = LabelEncoder()\nfor i in bin_cols :\n    df[i] = le.fit_transform(df[i])\n    \n#Duplicating columns for multi value columns\ndf = pd.get_dummies(data = df, columns = multi_cols)\n\n#Scaling Numerical columns\nstd = StandardScaler()\nscaled = std.fit_transform(df[num_cols])\nscaled = pd.DataFrame(scaled,columns=num_cols)\n\n#dropping original values merging scaled values for numerical columns\ndf1 = df.drop(columns = num_cols, axis = 1)\ndf1 = df1.merge(scaled, left_index=True, right_index=True, how = \"left\")\n\n# note: df has 21 columns including unscaled num_cols; df1 has 54 columns including scaled num_cols\n# I defined 2 separate df & df1 for comparison, to check if the columns are correctly labelled after encoding/get_dummies","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check if there is any null fields (ie, ensure all fields are filled)\ndf1[df1.TotalCharges.isnull()]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.describe()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.columns\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.dtypes\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correlation Matrix for variables\nsns.set(rc={'figure.figsize':(15,13)})\nsns.heatmap(df1.corr(), cmap=\"seismic\", annot=False, vmin=-1, vmax=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# drop 'customerID' column, feature not needed in model selection\ndf1 = df1.drop('customerID', axis=1)\n\n# there are a lot of repeated features (no internet service), so drop them\ndf1 = df1.drop(columns=['OnlineSecurity_No internet service', 'OnlineBackup_No internet service', \n                        'DeviceProtection_No internet service', 'TechSupport_No internet service', \n                        'StreamingTV_No internet service', 'StreamingMovies_No internet service'], axis=1)\n\n# original 54 columns, reduced to 47 columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correlation Matrix for variables\nsns.set(rc={'figure.figsize':(12,10)})\nsns.heatmap(df1.corr(), cmap=\"seismic\", annot=False, vmin=-1, vmax=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# store df1 to csv file\ndf1.to_csv('/kaggle/working/df1.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Selection¶\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = pd.read_csv('df1.csv')\nX, y = df1.drop('Churn',axis=1), df1[['Churn']]\n\nimport statsmodels.api as sm\nX = sm.add_constant(X)  # need to add this to define the Intercept\n# model / fit / summarize results\nmodel = sm.OLS(y, X)\nresult = model.fit()\nresult.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Warnings:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The smallest eigenvalue is 2.82e-28. This might indicate that there are\nstrong multicollinearity problems or that the design matrix is singular."},{"metadata":{"trusted":true},"cell_type":"code","source":"## to find significant features using LassoCV (all X_scaled)\nfrom sklearn.linear_model import LassoCV, RidgeCV, ElasticNetCV\nfrom sklearn.preprocessing import StandardScaler, PolynomialFeatures\n\nprint('Use LassoCV to find the optimal ALPHA value for L1 regularization')\n# Scale the Predictors on both the train and validation set\nstd = StandardScaler()\nstd.fit(X.values)\nX_scaled = std.transform(X.values)\nprint('X_scaled', X_scaled.shape)\n# Run the cross validation, find the best alpha, refit the model on all the data with that alpha\nalphavec = 10**np.linspace(-3,3,200)   # alpha varies from 0.001 to 1000\nlasso_model = LassoCV(alphas = alphavec, cv=5)\nlasso_model.fit(X_scaled, y)\n# This is the best alpha value found\nprint('LASSO best alpha: ', lasso_model.alpha_ )\n# display all coefficients in the model with optimal alpha\nlist(zip(X.columns, lasso_model.coef_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# see if you can extract the above results using Regular Expression\n\nplot_feature = ['TotalCharges', 'InternetService_Fiber optic', 'tenure_group_60plus', 'tenure', 'Contract_Month-to-month', \n                'totalcharges_group_6kplus', 'monthlycharges_group_99plus', 'PaymentMethod_Electronic check', \n                'totalcharges_group_0-2k', 'OnlineSecurity_No', 'TechSupport_No', 'tenure_group_40-60', \n                'totalcharges_group_4k-6k', 'PaperlessBilling', 'StreamingTV_Yes', 'MultipleLines_No', 'StreamingMovies_Yes', \n                'SeniorCitizen', 'monthlycharges_group_70-9', 'tenure_group_20-40', 'OnlineBackup_No', 'MonthlyCharges', \n                'monthlycharges_group_0-30', 'Dependents', 'InternetService_No', 'MultipleLines_Yes', 'DeviceProtection_No', \n                'Contract_One year', 'PaymentMethod_Mailed check', 'gender', 'PaymentMethod_Credit card (automatic)']\n\nlasso_coeff = [0.209954752, 0.075144498, 0.061184581, 0.061182631, 0.046630292, 0.036007041, 0.034846244, 0.031775227, \n               0.029645254, 0.024949481, 0.024875392, 0.024679595, 0.021639644, 0.020966614, 0.020143496, 0.019954793, \n               0.019936301, 0.016463024, 0.015436581, 0.012221305, 0.011015587, 0.008054301, 0.007701626, 0.006895811, \n               0.00642757, 0.005009993, 0.002481356, 0.002102214, 0.001449537, 0.001066809, 0.000525379]\n\nsns.barplot(y = plot_feature, x = lasso_coeff, color='b')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n## To look for top features using Random Forest\n# Create decision tree classifer object\nrfc = RandomForestClassifier(random_state=0, n_estimators=100)\n\n# Train model, note that NO scaling is required\nmodel = rfc.fit(X, y)\n\n# Plot the top features based on its importance\n(pd.Series(model.feature_importances_, index=X.columns)\n   .nlargest(47)   # can adjust based on how many top features you want\n   .plot(kind='barh', figsize=[20,15])\n    .invert_yaxis()) # Ensures that the feature with the most importance is on top, in descending order\n\nplt.yticks(size=15)\nplt.title('Top Features derived by Random Forest', size=20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Selection¶\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = pd.read_csv('df1.csv')\nX, y = df1.drop('Churn',axis=1), df1[['Churn']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# split data to 80:20 ratio for train/test\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=71)\nprint('X_train', X_train.shape)\nprint('y_train', y_train.shape)\nprint('X_test', X_test.shape)\nprint('y_test', y_test.shape)\n\ndef model_report(model_name, model):\n    print('\\nSearch for OPTIMAL THRESHOLD, vary from 0.0001 to 0.9999, fit/predict on train/test data')\n    model.fit(X_train, y_train)\n    optimal_th = 0.5   # start with default threshold value\n    \n    for i in range(0,3):\n        score_list = []\n        print('\\nLooping decimal place', i+1) \n        th_list = [np.linspace(optimal_th-0.4999, optimal_th+0.4999, 11), \n                  # eg [ 0.0001 , 0.1008, 0.2006, 0.3004, 0.4002, 0.5, 0.5998, 0.6996, 0.7994, 0.8992, 0.9999 ]\n                 np.linspace(optimal_th-0.1, optimal_th+0.1, 21), \n                  # eg 0.3xx [ 0.2 , 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3 , 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4 ]\n                 np.linspace(optimal_th-0.01, optimal_th+0.01, 21)]\n                  # eg 0.30x [ 0.29 , 0.291, 0.292, 0.293, 0.294, 0.295, 0.296, 0.297, 0.298, 0.299, 0.3  , 0.301, 0.302, 0.303, 0.304, 0.305, 0.306, 0.307, 0.308, 0.309, 0.31 ]\n        for th in th_list[i]:\n            y_pred = (model.predict_proba(X_test)[:,1] >= th)\n            f1scor = f1_score(y_test, y_pred)\n            score_list.append(f1scor)\n            print('{:.3f}->{:.4f}'.format(th, f1scor), end=',  ')   # display score in 4 decimal pl\n        optimal_th = float(th_list[i][score_list.index(max(score_list))])\n\n    print('optimal F1 score = {:.4f}'.format(max(score_list)))\n    print('optimal threshold = {:.3f}'.format(optimal_th))\n\n    print(model_name, 'accuracy score is')\n    print('Training: {:.2f}%'.format(100*model.score(X_train, y_train)))  # score uses accuracy\n    print('Test set: {:.2f}%'.format(100*model.score(X_test, y_test)))   # should use cross validation\n\n    y_pred = (model.predict_proba(X_test)[:,1] >= 0.25)\n    print('\\nAdjust threshold to 0.25:')\n    print('Precision: {:.4f},   Recall: {:.4f},   F1 Score: {:.4f}'.format(\n        precision_score(y_test, y_pred), recall_score(y_test, y_pred), f1_score(y_test, y_pred)))\n    print(model_name, 'confusion matrix: \\n', confusion_matrix(y_test, y_pred))\n\n    y_pred = model.predict(X_test)\n    print('\\nDefault threshold of 0.50:')\n    print('Precision: {:.4f},   Recall: {:.4f},   F1 Score: {:.4f}'.format(\n        precision_score(y_test, y_pred), recall_score(y_test, y_pred), f1_score(y_test, y_pred)))\n    print(model_name, 'confusion matrix: \\n', confusion_matrix(y_test, y_pred))\n\n    y_pred = (model.predict_proba(X_test)[:,1] >= 0.75)\n    print('\\nAdjust threshold to 0.75:')\n    print('Precision: {:.4f},   Recall: {:.4f},   F1 Score: {:.4f}'.format(\n        precision_score(y_test, y_pred), recall_score(y_test, y_pred), f1_score(y_test, y_pred)))\n    print(model_name, 'confusion matrix: \\n', confusion_matrix(y_test, y_pred))\n\n    y_pred = (model.predict_proba(X_test)[:,1] >= optimal_th)\n    print('\\nOptimal threshold {:.3f}'.format(optimal_th))\n    print('Precision: {:.4f},   Recall: {:.4f},   F1 Score: {:.4f}'.format(\n        precision_score(y_test, y_pred), recall_score(y_test, y_pred), f1_score(y_test, y_pred)))\n    print(model_name, 'confusion matrix: \\n', confusion_matrix(y_test, y_pred))\n    \n    global model_f1, model_auc, model_ll, model_roc_auc\n    model_f1 = f1_score(y_test, y_pred)\n\n    y_pred = model.predict_proba(X_test)\n    model_ll = log_loss(y_test, y_pred)\n    print(model_name, 'Log-loss: {:.4f}'.format(model_ll))\n    y_pred = model.predict(X_test)\n    model_roc_auc = roc_auc_score(y_test, y_pred)\n    print(model_name, 'roc_auc_score: {:.4f}'.format(model_roc_auc)) \n    y_pred = model.predict_proba(X_test)[:,1]\n    fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n    model_auc = auc(fpr, tpr)\n    print(model_name, 'AUC: {:.4f}'.format(model_auc))\n\n    # plot the ROC curve\n    plt.figure(figsize = [6,6])\n    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % model_auc)\n    plt.plot([0, 1], [0, 1],'r--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.0])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic')\n    plt.legend(loc=\"lower right\")\n    # plt.savefig('roc_auc_score')\n    plt.show()\n  \n    return\n\n# initialise lists to collect the results to plot later\nmodel_list = []\nf1_list = []\nauc_list = []\nll_list = []\nroc_auc_list = []\ntime_list = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('\\n\"\"\"\"\"\" GaussianNB \"\"\"\"\"\"')\ntime1 = time.time()\ngnb = GaussianNB()\nmodel_report('GaussianNB', gnb)\n\nmodel_list.append('GaussianNB')\nf1_list.append(model_f1)\nauc_list.append(model_auc)\nll_list.append(model_ll)\nroc_auc_list.append(model_roc_auc)\ntime_list.append(time.time() - time1)\n\nprint('\\n\"\"\"\"\"\" BernoulliNB \"\"\"\"\"\"')\ntime1 = time.time()\nbnb = BernoulliNB()\nmodel_report('BernoulliNB', bnb)\n\nmodel_list.append('BernoulliNB')\nf1_list.append(model_f1)\nauc_list.append(model_auc)\nll_list.append(model_ll)\nroc_auc_list.append(model_roc_auc)\ntime_list.append(time.time() - time1)\n\n### this model does not work\n# print('\\n\"\"\"\"\"\" MultinomialNB \"\"\"\"\"\"')\n# mnb = MultinomialNB()\n# model_report('MultinomialNB', mnb)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Optimal threshold 0.983\n# Precision: 0.5640,   Recall: 0.7231,   F1 Score: 0.6337\n# GaussianNB confusion matrix: \n#  [[799 218]\n#  [108 282]]\n# GaussianNB Log-loss: 2.3984\n# GaussianNB roc_auc_score: 0.7554\n# GaussianNB AUC: 0.8265\n    \n# Optimal threshold 0.764\n# Precision: 0.5849,   Recall: 0.7154,   F1 Score: 0.6436\n# BernoulliNB confusion matrix: \n#  [[819 198]\n#  [111 279]]\n# BernoulliNB Log-loss: 1.1281\n# BernoulliNB roc_auc_score: 0.7563\n# BernoulliNB AUC: 0.8355"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('\\n\"\"\"\"\"\" LogisticRegression \"\"\"\"\"\"')\nprint('\\nSearch for optimal hyperparameter C in LogisticRegresssion, vary C from 0.001 to 1000, using KFold(5) Cross Validation on train data')\nkf = KFold(n_splits=5, random_state=21, shuffle=True)  #produce the k folds\nscore_list = []\nc_list = 10**np.linspace(-3,3,200)\nfor c in c_list:\n    logit = LogisticRegression(C = c)\n    cvs = (cross_val_score(logit, X_train, y_train, cv=kf, scoring='f1')).mean()\n    score_list.append(cvs)\n    print('{:.4f}'.format(cvs), end=\", \")   # 4 decimal pl\nprint('optimal cv F1 score = {:.4f}'.format(max(score_list)))\noptimal_c = float(c_list[score_list.index(max(score_list))])\nprint('optimal value of C = {:.3f}'.format(optimal_c))\n\ntime1 = time.time()\nlogit = LogisticRegression(C = optimal_c)\nmodel_report('LogisticRegression', logit)\n\nmodel_list.append('LogisticRegression')\nf1_list.append(model_f1)\nauc_list.append(model_auc)\nll_list.append(model_ll)\nroc_auc_list.append(model_roc_auc)\ntime_list.append(time.time() - time1)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# logit = LogisticRegression(C = 0.1825)\n# Adjust threshold to 0.3181:\n# Precision: 0.5659,   Recall: 0.7787,   F1 Score: 0.6554\n# Logistic confusion matrix: \n#  [[806 224]\n#  [ 83 292]]\n# Log-loss on logit: 0.4073"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('\\n\"\"\"\"\"\" KNN \"\"\"\"\"\" (quite slow)')\nprint('\\nSearch for optimal hyperparameter K in KNN, vary K from 1 to 20, using KFold(5) Cross Validation on train data')\nkf = KFold(n_splits=5, random_state=21, shuffle=True)  #produce the k folds\nk_scores = []\nfor k in range(1, 21):\n    knn = KNeighborsClassifier(n_neighbors = k)\n    cvs = cross_val_score(knn, X_train, y_train, cv=kf, scoring='f1').mean()\n    k_scores.append(cvs)\n    print('{:.4f}'.format(cvs), end=\", \")\nprint('optimal cv F1 score = {:.4f}'.format(max(k_scores)))   # 4 decimal pl\noptimal_k = k_scores.index(max(k_scores))+1   # index 0 is for k=1\nprint('optimal value of K =', optimal_k)\n\ntime1 = time.time()\nknn = KNeighborsClassifier(n_neighbors = optimal_k)\nmodel_report('KNN', knn)\n\nprint('\\nCompare with KNN classification_report (same as default threshold 0.50)')\nknn.fit(X_train, y_train)\ny_pred = knn.predict(X_test)\nprint(metrics.classification_report(y_test, y_pred))\n\nmodel_list.append('KNN')\nf1_list.append(model_f1)\nauc_list.append(model_auc)\nll_list.append(model_ll)\nroc_auc_list.append(model_roc_auc)\ntime_list.append(time.time() - time1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n# Optimal threshold 0.264\n# Precision: 0.5104,   Recall: 0.8205,   F1 Score: 0.6293\n# KNN confusion matrix: \n#  [[710 307]\n#  [ 70 320]]\n# KNN Log-loss: 0.6104\n# KNN roc_auc_score: 0.7172\n# KNN AUC: 0.8309"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('\\n\"\"\"\"\"\" DecisionTreeClassifier \"\"\"\"\"\"')\n\nprint('\\nSearch for optimal max_depth in DecisionTree, vary 2 to 10, using KFold(5) Cross Validation on train data')\nkf = KFold(n_splits=5, random_state=21, shuffle=True)  #produce the k folds\nd_scores = []\nfor d in range(2, 11):\n    decisiontree = DecisionTreeClassifier(max_depth=d)\n    cvs = cross_val_score(decisiontree, X_train, y_train, cv=kf, scoring='f1').mean()\n    d_scores.append(cvs)\n    print('{:.4f}'.format(cvs), end=\", \")\nprint('optimal F1 score = {:.4f}'.format(max(d_scores)))   # 4 decimal pl\noptimal_d = d_scores.index(max(d_scores))+2   # index 0 is for d=2\nprint('optimal max_depth =', optimal_d)\n\ntime1 = time.time()\ndecisiontree = DecisionTreeClassifier(max_depth=optimal_d)\nmodel_report('DecisionTreeClassifier', decisiontree)\n\nmodel_list.append('DecisionTreeClassifier')\nf1_list.append(model_f1)\nauc_list.append(model_auc)\nll_list.append(model_ll)\nroc_auc_list.append(model_roc_auc)\ntime_list.append(time.time() - time1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Optimal threshold 0.2866\n# Precision: 0.5687,   Recall: 0.6154,   F1 Score: 0.5911\n# DecisionTreeClassifier confusion matrix: \n#  [[835 182]\n#  [150 240]]\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('\\n\"\"\"\"\"\" RandomForestClassifier \"\"\"\"\"\" (quite slow)')\n\nprint('\\nSearch for optimal n_estimators in RandomForest, vary 100 to 500, using KFold(5) Cross Validation on train data')\nkf = KFold(n_splits=5, random_state=21, shuffle=True)  #produce the k folds\nscore_list = []\nn_list = []\nfor n in [100, 150, 200, 250, 300, 350, 400, 450, 500]:\n    randomforest = RandomForestClassifier(n_estimators=n)\n    cvs = (cross_val_score(randomforest, X_train, y_train, cv=kf, scoring='f1')).mean()\n    score_list.append(cvs)\n    n_list.append(n)\n    print('{:.0f}->{:.4f}'.format(n, cvs), end=\", \")   # display score in 4 decimal place\nprint('optimal F1 score = {:.4f}'.format(max(score_list)))\noptimal_n = int(n_list[score_list.index(max(score_list))])\nprint('optimal n_estimators = {:.0f}'.format(optimal_n))\n\ntime1 = time.time()\nrandomforest = RandomForestClassifier(n_estimators=optimal_n)\nmodel_report('RandomForestClassifier', randomforest)\n\nmodel_list.append('RandomForestClassifier')\nf1_list.append(model_f1)\nauc_list.append(model_auc)\nll_list.append(model_ll)\nroc_auc_list.append(model_roc_auc)\ntime_list.append(time.time() - time1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n# Optimal threshold 0.340\n# Precision: 0.5830,   Recall: 0.7026,   F1 Score: 0.6372\n# RandomForestClassifier confusion matrix: \n#  [[821 196]\n#  [116 274]]\n# RandomForestClassifier Log-loss: 0.4724\n# RandomForestClassifier roc_auc_score: 0.6946\n# RandomForestClassifier AUC: 0.8272"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('\\n\"\"\"\"\"\" LinearSVC \"\"\"\"\"\"')\ntime1 = time.time()\nlinearsvc = LinearSVC()\n# model_report('LinearSVC', linearsvc)   # model has no attribute 'predict_proba'\nlinearsvc.fit(X_train, y_train)\nprint('LinearSVC accuracy score is')\nprint('Training: {:.2f}%'.format(100*linearsvc.score(X_train, y_train)))  # score uses accuracy\nprint('Test set: {:.2f}%'.format(100*linearsvc.score(X_test, y_test)))   # should use cross validation\n\ny_pred = linearsvc.predict(X_test)\nprint(metrics.classification_report(y_test, y_pred))\nprint('LinearSVC confusion matrix: \\n', confusion_matrix(y_test, y_pred))\n\nmodel_f1 = f1_score(y_test, y_pred)\n\nmodel_ll = log_loss(y_test, y_pred)\nprint('LinearSVC Log-loss: {:.4f}'.format(model_ll))\nmodel_roc_auc = roc_auc_score(y_test, y_pred)\nprint('LinearSVC roc_auc_score: {:.4f}'.format(model_roc_auc)) \nfpr, tpr, thresholds = roc_curve(y_test, y_pred)\nmodel_auc = auc(fpr, tpr)\nprint('LinearSVC AUC: {:.4f}'.format(model_auc))\n\n# plot the ROC curve\nplt.figure(figsize = [6,6])\nplt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % model_auc)\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic')\nplt.legend(loc=\"lower right\")\n# plt.savefig('roc_auc_score')\nplt.show()\n\nmodel_list.append('LinearSVC')\nf1_list.append(model_f1)\nauc_list.append(model_auc)\nll_list.append(model_ll)\nroc_auc_list.append(model_roc_auc)\ntime_list.append(time.time() - time1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# LinearSVC confusion matrix: \n#  [[933  84]\n#  [201 189]]\n# LinearSVC Log-loss: 6.9962\n# LinearSVC roc_auc_score: 0.7010\n# LinearSVC AUC: 0.7010"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('\\n\"\"\"\"\"\" SVC \"\"\"\"\"\" (extremely slow)')\ntime1 = time.time()\nsvc = SVC(gamma='scale', probability=True)\nmodel_report('SVC', svc)\n\nmodel_list.append('SVC')\nf1_list.append(model_f1)\nauc_list.append(model_auc)\nll_list.append(model_ll)\nroc_auc_list.append(model_roc_auc)\n# time_list.append(time.time() - time1)   # use this line for actual time spent, or\ntime_list.append(0)                       # use this line to be able to see time spent for other models","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n# Optimal threshold 0.184\n# Precision: 0.5884,   Recall: 0.7256,   F1 Score: 0.6498\n# SVC confusion matrix: \n#  [[819 198]\n#  [107 283]]\n# SVC Log-loss: 0.4682\n# SVC roc_auc_score: 0.6921\n# SVC AUC: 0.7970"},{"metadata":{"trusted":true},"cell_type":"code","source":"## plot the classification report scores\nfig, ax = plt.subplots(5, 1, figsize=(18, 28))\n# fig.set_figwidth(10)\n# fig.set_figheight(6)\n# fig.suptitle('Main Title',fontsize = 16)\nax[0].bar(model_list, f1_list)\nax[0].set_title('F1-score')\nax[1].bar(model_list, auc_list)\nax[1].set_title('AUC-score');\nax[2].bar(model_list, ll_list)\nax[2].set_title('Log-Loss-Score')\nax[3].bar(model_list, roc_auc_list)\nax[3].set_title('ROC AUC Score')\nax[4].bar(model_list, time_list)\nax[4].set_title('Time taken')\n# Fine-tune figure; make subplots farther from each other, or nearer to each other.\nfig.subplots_adjust(hspace=0.2, wspace=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot the ROC curves\nplt.figure(figsize=(10,10))\n\ny_pred = gnb.predict_proba(X_test)[:,1]\nfpr, tpr, thresholds = roc_curve(y_test, y_pred)\nplt.plot(fpr, tpr, color='blue',\n        lw=3, label='GaussianNB (area = %0.2f)' % auc_list[0])\n\ny_pred = bnb.predict_proba(X_test)[:,1]\nfpr, tpr, thresholds = roc_curve(y_test, y_pred)\nplt.plot(fpr, tpr, color='green',\n        lw=3, label='BernoulliNB (area = %0.2f)' % auc_list[1])\n\ny_pred = logit.predict_proba(X_test)[:,1]\nfpr, tpr, thresholds = roc_curve(y_test, y_pred)\nplt.plot(fpr, tpr, color='red',\n        lw=2, label='LogisticRegression (area = %0.2f)' % auc_list[2])\n\ny_pred = knn.predict_proba(X_test)[:,1]\nfpr, tpr, thresholds = roc_curve(y_test, y_pred)\nplt.plot(fpr, tpr, color='yellow',\n        lw=3, label='KNN (area = %0.2f)' % auc_list[3])\n\ny_pred = decisiontree.predict_proba(X_test)[:,1]\nfpr, tpr, thresholds = roc_curve(y_test, y_pred)\nplt.plot(fpr, tpr, color='purple',\n        lw=2, label='DecisionTree (area = %0.2f)' % auc_list[4])\n\ny_pred = randomforest.predict_proba(X_test)[:,1]\nfpr, tpr, thresholds = roc_curve(y_test, y_pred)\nplt.plot(fpr, tpr, color='brown',\n        lw=2, label='RandomForest (area = %0.2f)' % auc_list[5])\n\ny_pred = linearsvc.predict(X_test)\nfpr, tpr, thresholds = roc_curve(y_test, y_pred)\nplt.plot(fpr, tpr, color='cyan',\n        lw=2, label='LinearSVC (area = %0.2f)' % auc_list[6])\n\ny_pred = svc.predict_proba(X_test)[:,1]\nfpr, tpr, thresholds = roc_curve(y_test, y_pred)\nplt.plot(fpr, tpr, color='magenta',\n        lw=2, label='SVC (area = %0.2f)' % auc_list[7])\n\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.xlabel('False Positive Rate', fontsize=13)\nplt.ylabel('True Positive Rate', fontsize=14)\nplt.title('Receiver Operating Characteristic', fontsize=17)\nplt.legend(loc='lower right', fontsize=13)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_confusion_matrix(model, threshold=0.5):\n    # Predict class 1 if probability of being in class 1 is greater than threshold\n    # (model.predict(X_test) does this automatically with a threshold of 0.5)\n    y_pred = (logit.predict_proba(X_test)[:, 1] >= threshold)\n    conf = confusion_matrix(y_test, y_pred)\n    plt.figure(figsize = [5,5])\n    sns.heatmap(conf, cmap=plt.cm.Blues, annot=True, square=True, fmt='d',\n           xticklabels=['no churn', 'churn'],\n           yticklabels=['no churn', 'churn']);\n    plt.xlabel('prediction')\n    plt.ylabel('actual')\n# Let's see how our confusion matrix changes with changes to the cutoff! \nfrom ipywidgets import interactive, FloatSlider\nlogit = LogisticRegression(C = optimal_c)\nlogit.fit(X_train, y_train)\ninteractive(lambda threshold: make_confusion_matrix(logit, threshold), threshold=(0.0,1.0,0.01))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# compare above Confusion Matrix with the Optimal threshold 0.318\n# Precision: 0.5812,   Recall: 0.7615,   F1 Score: 0.6593\n# LogisticRegression confusion matrix: \n#  [[803 214]\n#  [ 93 297]]"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}