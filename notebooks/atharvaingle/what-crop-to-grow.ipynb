{"cells":[{"metadata":{},"cell_type":"markdown","source":"# CROP RECOMMENDATION SYSTEM "},{"metadata":{},"cell_type":"markdown","source":"![](https://images.unsplash.com/photo-1560493676-04071c5f467b?ixid=MXwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHw%3D&ixlib=rb-1.2.1&auto=format&fit=crop&w=968&q=80)","attachments":{}},{"metadata":{},"cell_type":"markdown","source":"## Motivation üí™üí™\n\nPrecision agirculture is in trend nowadays. Precision agriculture is a modern farming technique that uses the data of soil charachteristics, soil types, crop yield data, weather conditions and suggests the farmers with the most optimal crop to grow in their farms for maximum yield and profit. This technique can reduce the crop failures and will help the farmers to take informed decision about their farming strategy.\n\nIn order to mitigate the agrarian crisis in the current status quo, there is a need for better recommendation systems to alleviate the crisis by helping the farmers to make an informed decision before starting the cultivation of crops."},{"metadata":{},"cell_type":"markdown","source":"## Read this kernel till the last, there's a cool thing at the end :)"},{"metadata":{},"cell_type":"markdown","source":"# Goal üéØ\n**To recommend optimum crops to be cultivated by farmers based on several parameters and help them make an informed decision before cultivation**"},{"metadata":{},"cell_type":"markdown","source":"# About the data"},{"metadata":{},"cell_type":"markdown","source":"The data used in this project is made by augmenting and combining various publicly available datasets of India like weather, soil, etc. You can access the dataset [here](https://www.kaggle.com/atharvaingle/crop-recommendation-dataset). This data is relatively simple with very few but useful features unlike the complicated features affecting the yield of the crop.\n\nThe data have Nitrogen, Phosphorous, Pottasium and pH values of the soil. Also, it also contains the humidity, temperature and rainfall required for a particular crop. "},{"metadata":{},"cell_type":"markdown","source":"### **So, without further ado, Let's dive in and code ...**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing libraries\n\nfrom __future__ import print_function\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import classification_report\nfrom sklearn import metrics\nfrom sklearn import tree\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PATH = '../input/crop-recommendation-dataset/Crop_recommendation.csv'\ndf = pd.read_csv(PATH)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.size","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['label'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['label'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(df.corr(),annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Seperating features and target label"},{"metadata":{"trusted":true},"cell_type":"code","source":"features = df[['N', 'P','K','temperature', 'humidity', 'ph', 'rainfall']]\ntarget = df['label']\nlabels = df['label']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initializing empty lists to append all model's name and corresponding name\nacc = []\nmodel = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting into train and test data\n\nfrom sklearn.model_selection import train_test_split\nXtrain, Xtest, Ytrain, Ytest = train_test_split(features,target,test_size = 0.2,random_state =2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Decision Tree"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\nDecisionTree = DecisionTreeClassifier(criterion=\"entropy\",random_state=2,max_depth=5)\n\nDecisionTree.fit(Xtrain,Ytrain)\n\npredicted_values = DecisionTree.predict(Xtest)\nx = metrics.accuracy_score(Ytest, predicted_values)\nacc.append(x)\nmodel.append('Decision Tree')\nprint(\"DecisionTrees's Accuracy is: \", x*100)\n\nprint(classification_report(Ytest,predicted_values))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cross validation score (Decision Tree)\nscore = cross_val_score(DecisionTree, features, target,cv=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Saving trained Decision Tree model"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\n# Dump the trained Naive Bayes classifier with Pickle\nDT_pkl_filename = 'DecisionTree.pkl'\n# Open the file to save as pkl file\nDT_Model_pkl = open(DT_pkl_filename, 'wb')\npickle.dump(DecisionTree, DT_Model_pkl)\n# Close the pickle instances\nDT_Model_pkl.close()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Guassian Naive Bayes"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\n\nNaiveBayes = GaussianNB()\n\nNaiveBayes.fit(Xtrain,Ytrain)\n\npredicted_values = NaiveBayes.predict(Xtest)\nx = metrics.accuracy_score(Ytest, predicted_values)\nacc.append(x)\nmodel.append('Naive Bayes')\nprint(\"Naive Bayes's Accuracy is: \", x)\n\nprint(classification_report(Ytest,predicted_values))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cross validation score (NaiveBayes)\nscore = cross_val_score(NaiveBayes,features,target,cv=5)\nscore","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Saving trained Guassian Naive Bayes model"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\n# Dump the trained Naive Bayes classifier with Pickle\nNB_pkl_filename = 'NBClassifier.pkl'\n# Open the file to save as pkl file\nNB_Model_pkl = open(NB_pkl_filename, 'wb')\npickle.dump(NaiveBayes, NB_Model_pkl)\n# Close the pickle instances\nNB_Model_pkl.close()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Support Vector Machine (SVM)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\n\nSVM = SVC(gamma='auto')\n\nSVM.fit(Xtrain,Ytrain)\n\npredicted_values = SVM.predict(Xtest)\n\nx = metrics.accuracy_score(Ytest, predicted_values)\nacc.append(x)\nmodel.append('SVM')\nprint(\"SVM's Accuracy is: \", x)\n\nprint(classification_report(Ytest,predicted_values))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cross validation score (SVM)\nscore = cross_val_score(SVM,features,target,cv=5)\nscore","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nLogReg = LogisticRegression(random_state=2)\n\nLogReg.fit(Xtrain,Ytrain)\n\npredicted_values = LogReg.predict(Xtest)\n\nx = metrics.accuracy_score(Ytest, predicted_values)\nacc.append(x)\nmodel.append('Logistic Regression')\nprint(\"Logistic Regression's Accuracy is: \", x)\n\nprint(classification_report(Ytest,predicted_values))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cross validation score (Logistic Regression)\nscore = cross_val_score(LogReg,features,target,cv=5)\nscore","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Saving trained Logistic Regression model"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\n# Dump the trained Naive Bayes classifier with Pickle\nLR_pkl_filename = 'LogisticRegression.pkl'\n# Open the file to save as pkl file\nLR_Model_pkl = open(DT_pkl_filename, 'wb')\npickle.dump(LogReg, LR_Model_pkl)\n# Close the pickle instances\nLR_Model_pkl.close()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nRF = RandomForestClassifier(n_estimators=20, random_state=0)\nRF.fit(Xtrain,Ytrain)\n\npredicted_values = RF.predict(Xtest)\n\nx = metrics.accuracy_score(Ytest, predicted_values)\nacc.append(x)\nmodel.append('RF')\nprint(\"RF's Accuracy is: \", x)\n\nprint(classification_report(Ytest,predicted_values))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cross validation score (Random Forest)\nscore = cross_val_score(RF,features,target,cv=5)\nscore","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Saving trained Random Forest model"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\n# Dump the trained Naive Bayes classifier with Pickle\nRF_pkl_filename = 'RandomForest.pkl'\n# Open the file to save as pkl file\nRF_Model_pkl = open(RF_pkl_filename, 'wb')\npickle.dump(RF, RF_Model_pkl)\n# Close the pickle instances\nRF_Model_pkl.close()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# XGBoost"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"import xgboost as xgb\nXB = xgb.XGBClassifier()\nXB.fit(Xtrain,Ytrain)\n\npredicted_values = XB.predict(Xtest)\n\nx = metrics.accuracy_score(Ytest, predicted_values)\nacc.append(x)\nmodel.append('XGBoost')\nprint(\"XGBoost's Accuracy is: \", x)\n\nprint(classification_report(Ytest,predicted_values))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cross validation score (XGBoost)\nscore = cross_val_score(XB,features,target,cv=5)\nscore","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Saving trained XGBoost model"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\n# Dump the trained Naive Bayes classifier with Pickle\nXB_pkl_filename = 'XGBoost.pkl'\n# Open the file to save as pkl file\nXB_Model_pkl = open(XB_pkl_filename, 'wb')\npickle.dump(XB, XB_Model_pkl)\n# Close the pickle instances\nXB_Model_pkl.close()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Accuracy Comparison"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=[10,5],dpi = 100)\nplt.title('Accuracy Comparison')\nplt.xlabel('Accuracy')\nplt.ylabel('Algorithm')\nsns.barplot(x = acc,y = model,palette='dark')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_models = dict(zip(model, acc))\nfor k, v in accuracy_models.items():\n    print (k, '-->', v)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Making a prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = np.array([[104,18, 30, 23.603016, 60.3, 6.7, 140.91]])\nprediction = RF.predict(data)\nprint(prediction)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = np.array([[83, 45, 60, 28, 70.3, 7.0, 150.9]])\nprediction = RF.predict(data)\nprint(prediction)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## So here comes the fun part üòÑ\n\nI have also made a web application for this and deployed it in cloud. You can view it [here](https://ml-crop-consultant.herokuapp.com/).\n\nI have also combined a fertilizer recommendation system and a disease detection system in this project.\nYou can check my kernel of disease detection using ResNet [here](https://www.kaggle.com/atharvaingle/plant-disease-classification-resnet-99-2)\n\nAlso, I have made the project open source. So, feel free to suggest more improvements and submit a pull request.\n\n### Github links:\n- [Full project](https://github.com/Gladiator07/AI-Agriculture) - has all the data and notebooks used for developing the application\n- [Deployed project](https://github.com/Gladiator07/ML-based-crop-consultant) - only has the code of deployed application\n\n*PS: Ignore my frontend skills :)*"},{"metadata":{},"cell_type":"markdown","source":"Thanks for sticking till the end\n\nHope you enjoyed this notebook :)\n\nShow your appreciation by a upvote ...\n\nHappy learning !!\n\nCatch you guys on the next one\n\nPeace ‚úåÔ∏è"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}