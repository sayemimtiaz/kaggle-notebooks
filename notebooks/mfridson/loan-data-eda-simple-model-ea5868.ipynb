{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"f5f6a7b5-0957-80ba-ee63-fe6fd1c522e8"},"source":"## Loan Data\n\n**Recap Overview**\n\nThis data set includes customers who have paid off their loans, who have been past due and put into collection without paying back their loan and interests, and who have paid off only after they were put in collection. The financial product is a bullet loan that customers should pay off all of their loan debt in just one time by the end of the term, instead of an installment schedule. Of course, they could pay off earlier than their pay schedule.\n\n**Notebook objective**\n\nThis notebook will provide the initial analysis and EDA finding. I will probably add some other parts, including ML, to this notebook later."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"feeadeda-0aa5-76d3-2140-07f762c3a5f6"},"outputs":[],"source":"import os\nimport numpy as np\nimport pandas as pd\nimport datetime \nimport seaborn as sns\nsns.set_style(\"dark\")\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"28cbf65c-f37c-5663-a20f-e2a841af9f37"},"outputs":[],"source":"def my_read_file(filename):\n    df = pd.read_csv(filename)\n    print(\"{}: Reading {}.\".format(now(), filename))\n    print(\"{}: The data contains {} observations with {} columns\".format(now(), df.shape[0], df.shape[1]))\n    return df\n\ndef now():\n    tmp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n    return tmp\n\n# Self-defined function to read dataframe and find the missing data on the columns and # of missing\ndef checking_na(df):\n    try:\n        if (isinstance(df, pd.DataFrame)):\n            df_na_bool = pd.concat([df.isnull().any(), df.isnull().sum(), (df.isnull().sum()/df.shape[0])*100],\n                                   axis=1, keys=['df_bool', 'df_amt', 'missing_ratio_percent'])\n            df_na_bool = df_na_bool.loc[df_na_bool['df_bool'] == True]\n            return df_na_bool\n        else:\n            print(\"{}: The input is not panda DataFrame\".format(now()))\n\n    except (UnboundLocalError, RuntimeError):\n        print(\"{}: Something is wrong\".format(now()))\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e5f15f21-1f19-0380-e0df-293e9a9ebfde"},"outputs":[],"source":"loan_data = my_read_file(\"../input/Loan payments data.csv\")\nprint(\"\\n\\n\")\nprint(checking_na(loan_data))"},{"cell_type":"markdown","metadata":{"_cell_guid":"7e866e82-5f42-c9e9-e00e-925a0d436578"},"source":"Look from above, there are some missing data in 2 fields. Recap the data content and definition by the author.\n\n### Data Content\n\n- ***Loan_id*** : A unique loan number assigned to each loan customers\n- ***Loan_status*** : Whether a loan is paid off, in collection, new customer yet to payoff, or paid off after the collection efforts\n- ***Principal*** : Basic principal loan amount at the origination\n- ***terms*** : Can be weekly (7 days), biweekly, and monthly payoff schedule\n- ***Effective_date*** : When the loan got originated and took effects\n- ***Due_date*** : Since it’s one-time payoff schedule, each loan has one single due date\n- ***Paidoff_time*** : The actual time a customer pays off the loan\n- ***Pastdue_days*** : How many days a loan has been past due\n- ***Age, education, gender*** : A customer’s basic demographic information\n\nLet's look at some sample data."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c2f2701c-ccb7-e112-77cd-a78837279c30"},"outputs":[],"source":"loan_data.head(2)"},{"cell_type":"markdown","metadata":{"_cell_guid":"dd96a1bf-efce-3400-ce3e-41cb42f7fc4b"},"source":"OK from the sample, we can see that it's making senses for those who have paid the loan off to not have data in **past_due_days** columns."},{"cell_type":"markdown","metadata":{"_cell_guid":"6e469723-f404-ec67-4e6f-2baf664bdb0c"},"source":"### 1. EDA\n\nIn this section, let's explore the data in-depth.\n\n#### 1. Loan_ID - This is just the identifier for each loan by each customers, we can ignore this field and will drop it at the end of EDA process"},{"cell_type":"markdown","metadata":{"_cell_guid":"59fd83d9-5a59-4e79-4fea-e5807129fb5f"},"source":"##### 2. loan_status\nThis field is actually the target variables we are trying to predict. Let's look at the LoV within the column and the sizing."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"88477be3-7dcd-9874-3e7a-9dc9f6ce9b15"},"outputs":[],"source":"print(loan_data.loan_status.unique())\n\nfig = plt.figure(figsize=(5,5))\nax = sns.countplot(loan_data.loan_status)\nax.set_title(\"Count of Loan Status\")\nfor p in ax.patches:\n    ax.annotate(str(format(int(p.get_height()), ',d')), (p.get_x(), p.get_height()*1.01))\nplt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"69fc1640-025d-1cd4-650d-5128374c27c0"},"source":"We have 3 labels for this target variables with the ratio of 3:1:1 (paid off: collection : collection paid off)."},{"cell_type":"markdown","metadata":{"_cell_guid":"84c8acfa-a5d5-266a-bed5-9f4ea8a48c87"},"source":"##### 3. Principal\nThis is the loan amount at the origination. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"71b9a8d7-ba49-f6d4-5a69-90598780821f"},"outputs":[],"source":"fig, axs = plt.subplots(1, 2, figsize=(16, 5))\nsns.boxplot(x='loan_status', y='Principal', data=loan_data, hue='loan_status', ax=axs[0])\nsns.distplot(loan_data.Principal, bins=range(300, 1000, 100), ax=axs[1], kde=True)\nplt.show();"},{"cell_type":"markdown","metadata":{"_cell_guid":"5c4823ec-a989-a8bb-ef69-595dfb725be9"},"source":"Based on the distribution alone, majority of the principal is 1,000 (USD??). Below aggregation shows more detail of the **Principal** with **loan_status**."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5fcf9cdf-92eb-ff03-3b0d-94ab82d857f0"},"outputs":[],"source":"print(loan_data[['loan_status', 'Principal', 'Loan_ID']].groupby(['loan_status', 'Principal']).agg(['count']))"},{"cell_type":"markdown","metadata":{"_cell_guid":"c8e9138e-44b3-1d92-4658-db7bc33ec0c5"},"source":"##### 4. Terms\nThis is the payoff schedule, which can be in week, month etc."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2fca208d-8457-abd1-b9bb-92a5c68ad873"},"outputs":[],"source":"fig, axs = plt.subplots(1, 2, figsize=(16,5))\nsns.countplot(loan_data.terms, ax=axs[0])\naxs[0].set_title(\"Count of Terms of loan\")\nfor p in axs[0].patches:\n    axs[0].annotate(str(format(int(p.get_height()), ',d')), (p.get_x(), p.get_height()*1.01))\n\nsns.countplot(x='terms', hue='loan_status', data=loan_data, ax=axs[1])\naxs[1].set_title(\"Term count breakdown by loan_status\")\nfor t in axs[1].patches:\n    if (np.isnan(float(t.get_height()))):\n        axs[1].annotate(0, (t.get_x(), 0))\n    else:\n        axs[1].annotate(str(format(int(t.get_height()), ',d')), (t.get_x(), t.get_height()*1.01))\n\naxs[1].legend(loc='upper left')\nplt.show();"},{"cell_type":"markdown","metadata":{"_cell_guid":"4ad39705-9898-c9c8-dadf-10a6ff7a667d"},"source":"##### 5, 6, 7, 8. effective_date, due_date, paid_off_time, and past_due_days\n\nThese data points are essentially related to the date of the loan and payment."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c1edc3af-c004-6efa-f622-337e60421d87"},"outputs":[],"source":"fig = plt.figure(figsize=(10,5))\nax = sns.countplot(x='effective_date', hue='loan_status', data=loan_data)\nax.set_title('Loan date')\nfor t in ax.patches:\n    if (np.isnan(float(t.get_height()))):\n        ax.annotate(0, (t.get_x(), 0))\n    else:\n        ax.annotate(str(format(int(t.get_height()), ',d')), (t.get_x(), t.get_height()*1.01))\nplt.show();\n\n# Note: if we think that the day of week, or month has the significant factor to the loan status\n# Below is the function which we can use to extract the year, month, or day:\n# pd.DatetimeIndex(loan_data.effective_date).year\n# pd.DatetimeIndex(loan_data.effective_date).month\n# pd.DatetimeIndex(loan_data.effective_date).day"},{"cell_type":"markdown","metadata":{"_cell_guid":"e3d3c14b-b585-0f2f-4066-233ac77f0078"},"source":"It looks like this is snapshot of the 7-day loan data, with 11-September has the most loan.\n\nIn the next figure, is there any pattern of the pay off date? In this section, we add new column **paid_off_date** from the paid_off_time."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5faedea0-ac49-be5f-99b1-f54503fbba4e"},"outputs":[],"source":"loan_data['paid_off_date'] = pd.DatetimeIndex(loan_data.paid_off_time).normalize()\nfig = plt.figure(figsize=(16, 6))\nax = sns.countplot(x='paid_off_date', data=loan_data.loc[loan_data.loan_status.isin(['COLLECTION_PAIDOFF', 'PAIDOFF'])] , hue='loan_status')\nax.set_xticklabels(ax.get_xticklabels(), rotation=90)\nfor t in ax.patches:\n    if (np.isnan(float(t.get_height()))):\n        ax.annotate(0, (t.get_x(), 0))\n    else:\n        ax.annotate(str(format(int(t.get_height()), ',d')), (t.get_x(), t.get_height()*1.01))\n\nax.legend(loc='upper right')\nplt.show();"},{"cell_type":"markdown","metadata":{"_cell_guid":"31db567c-c7b9-efcb-f56c-16eb7b1189d6"},"source":"As expected, people are more likely to pay off the loan on the last day. Big spike on day 14 and day 29 for 15-day and 30-day terms, respectively."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"abfca673-cca6-7ad1-765e-dc1177d8035e"},"outputs":[],"source":"# Compute the day to pay-off the loan\nloan_data['day_to_pay'] = (pd.DatetimeIndex(loan_data.paid_off_time).normalize() - pd.DatetimeIndex(loan_data.effective_date).normalize()) / np.timedelta64(1, 'D')\n\nfig = plt.figure(figsize=(15, 5))\nax = sns.countplot(x='day_to_pay', hue='terms', data=loan_data)\nax.set_xticklabels(ax.get_xticklabels(), rotation=90)\nfor t in ax.patches:\n    if (np.isnan(float(t.get_height()))):\n        ax.annotate('', (t.get_x(), 0))\n    else:\n        ax.annotate(str(format(int(t.get_height()), ',d')), (t.get_x(), t.get_height()*1.01))\n        \nplt.show();"},{"cell_type":"markdown","metadata":{"_cell_guid":"4c950e07-958a-caf5-2396-3141234d5445"},"source":"Let's see the distribution of **PAIDOFF**, what days do they normally pay off the loan?"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9fdd6f75-b7c6-12bd-a6a6-415545a062d9"},"outputs":[],"source":"fig = plt.figure(figsize=(15, 5))\nax = sns.countplot(x='day_to_pay', hue='terms', data=loan_data.loc[loan_data.loan_status == 'PAIDOFF'])\nax.set_xticklabels(ax.get_xticklabels(), rotation=90)\nfor t in ax.patches:\n    if (np.isnan(float(t.get_height()))):\n        ax.annotate('', (t.get_x(), 0))\n    else:\n        ax.annotate(str(format(int(t.get_height()), ',d')), (t.get_x(), t.get_height()*1.01))\n        \nplt.show();"},{"cell_type":"markdown","metadata":{"_cell_guid":"3e739b42-b032-00de-12dc-f5431728c5c6"},"source":"Hmmm ... Not sure why there're some records which have been paying late. Let's look at those records."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bb0a8109-3891-6ee1-f49c-0f3ddf2be0e5"},"outputs":[],"source":"tmp = loan_data.loc[(loan_data.day_to_pay > 30) & (loan_data.loan_status == 'PAIDOFF')]\nprint(\"{}: Incorrect status: {} observations\".format(now(), tmp.shape[0]))\nprint(tmp[['loan_status', 'terms', 'effective_date', 'due_date', 'paid_off_time']])"},{"cell_type":"markdown","metadata":{"_cell_guid":"0431be2f-8b72-c610-b959-5b14f815531c"},"source":"This is odd by looking at the effective_date and the terms period, these doesn't add up to the due_date of the loan application.\n\nWe can correct these records assuming that **paid_off_time** column is correct and change the value of **loan_status** to be COLLECTION_PAIDOFF.\n\nHowever, I will ignore this for now, as I will not plan to put it through ML."},{"cell_type":"markdown","metadata":{"_cell_guid":"10fd542f-2bf7-e790-7de6-8db114e518c9"},"source":"##### 9, 10, 11. age, education, and gender\n\nThese data points are the demographic information of the applicant. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"363f15fb-bff8-fe26-e6c5-3c9eb24b4024"},"outputs":[],"source":"fig, axs = plt.subplots(3, 2, figsize=(16, 15))\nsns.distplot(loan_data.age, ax=axs[0][0])\naxs[0][0].set_title(\"Total age distribution across dataset\")\nsns.boxplot(x='loan_status', y='age', data=loan_data, ax=axs[0][1])\naxs[0][1].set_title(\"Age distribution by loan status\")\nsns.countplot(x='education', data=loan_data, ax=axs[1][0])\naxs[1][0].set_title(\"Education count\")\nfor t in axs[1][0].patches:\n    if (np.isnan(float(t.get_height()))):\n        axs[1][0].annotate('', (t.get_x(), 0))\n    else:\n        axs[1][0].annotate(str(format(int(t.get_height()), ',d')), (t.get_x(), t.get_height()*1.01))\n\nsns.countplot(x='education', data=loan_data, hue='loan_status', ax=axs[1][1])\naxs[1][1].set_title(\"Education by loan status\")\nfor t in axs[1][1].patches:\n    if (np.isnan(float(t.get_height()))):\n        axs[1][1].annotate('', (t.get_x(), 0))\n    else:\n        axs[1][1].annotate(str(format(int(t.get_height()), ',d')), (t.get_x(), t.get_height()*1.01))\n\naxs[1][1].legend(loc='upper right')\nsns.countplot(x='Gender', data=loan_data, ax=axs[2][0])\naxs[2][0].set_title(\"# of Gender\")\nfor t in axs[2][0].patches:\n    if (np.isnan(float(t.get_height()))):\n        axs[2][0].annotate('', (t.get_x(), 0))\n    else:\n        axs[2][0].annotate(str(format(int(t.get_height()), ',d')), (t.get_x(), t.get_height()*1.01))\n\nsns.countplot(x='Gender', data=loan_data, hue='education', ax=axs[2][1])\naxs[2][1].set_title(\"Education of the gender\")\nfor t in axs[2][1].patches:\n    if (np.isnan(float(t.get_height()))):\n        axs[2][1].annotate('', (t.get_x(), 0))\n    else:\n        axs[2][1].annotate(str(format(int(t.get_height()), ',d')), (t.get_x(), t.get_height()*1.01))\n\nplt.show();"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"91b4177f-8f43-b159-08a4-ea6400914d25"},"outputs":[],"source":"# Quick view on education + gender => impact to loan_status\npd.crosstab(loan_data.loan_status, loan_data.Gender + \"_\" + loan_data.education, margins=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"32dc818e-6eef-e8ba-3582-cfee6d62a41a"},"outputs":[],"source":"pd.crosstab(loan_data.loan_status, loan_data.Gender + \"_\" + loan_data.education, margins=True, normalize='all')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a0a4edd9-2d38-6f67-7f5c-08290b4b8e89"},"outputs":[],"source":"pd.crosstab(loan_data.loan_status, loan_data.Gender + \"_\" + loan_data.education, margins=True, normalize='index')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c68eb633-2d59-ee44-b32a-f608e11ef07c"},"outputs":[],"source":"pd.crosstab(loan_data.loan_status, loan_data.Gender + \"_\" + loan_data.education, margins=True, normalize='columns')"},{"cell_type":"markdown","metadata":{"_cell_guid":"53a59ca6-7cb1-aa80-4a47-c62ef765560a"},"source":"### 2. Classification Model \n\nMy aim of this model is to classify the one who will likely to pay the loan off on time. We will assume those who are in **COLLECTION** or **COLLECTION_PAIDOFF** the same, hence don't pay on the loan due date. This will provide the basic step, no tu\n\nFirst, let's prepare the data for model building purpose.\n\nAs per the above EDA, we will fix those mislead status loan records."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"38918d4d-b7c4-1171-377a-a999b6aa2076"},"outputs":[],"source":"loan_data.loc[(loan_data.loan_status == 'PAIDOFF') & (loan_data.day_to_pay > 30), 'loan_status'] = 'COLLECTION_PAIDOFF'"},{"cell_type":"markdown","metadata":{"_cell_guid":"e54a6b6b-71d6-0062-69ef-cef791625951"},"source":"Great, now let's change the categorical target variables to numeric one. As per stated earlier, I will merge COLLECTION and COLLECTION_PAIDOFF to the same category, hence didn't pay on-time.\n\n***NOTE***: This will depends on each individual objective, some model will interest on any loan paidoff without consideration of on-time or delay."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"65a5344d-988c-6a68-6dc0-4b512b5da29b"},"outputs":[],"source":"status_map = {\"PAIDOFF\": 1, \"COLLECTION\": 2, \"COLLECTION_PAIDOFF\": 2 }\nloan_data['loan_status_trgt'] = loan_data['loan_status'].map(status_map)\n\nfig, axs = plt.subplots(1, 2, figsize=(15, 5))\nsns.countplot(x='loan_status', data=loan_data, ax=axs[0])\naxs[0].set_title(\"Count using original target labels\")\nfor t in axs[0].patches:\n    if (np.isnan(float(t.get_height()))):\n        axs[0].annotate('', (t.get_x(), 0))\n    else:\n        axs[0].annotate(str(format(int(t.get_height()), ',d')), (t.get_x(), t.get_height()*1.01))\n\nsns.countplot(x='loan_status_trgt', data=loan_data, ax=axs[1])\naxs[1].set_title(\"Count using new target labels\")\nfor t in axs[1].patches:\n    if (np.isnan(float(t.get_height()))):\n        axs[1].annotate('', (t.get_x(), 0))\n    else:\n        axs[1].annotate(str(format(int(t.get_height()), ',d')), (t.get_x(), t.get_height()*1.01))\n    \nplt.show();"},{"cell_type":"markdown","metadata":{"_cell_guid":"dca39bca-aa75-12d7-3b09-33708b013178"},"source":"Next, we convert **education** and **Gender** to the dummy variables."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9f06844a-7bd4-9897-4f38-3f0ab6b3d848"},"outputs":[],"source":"dummies = pd.get_dummies(loan_data['education']).rename(columns=lambda x: 'is_' + str(x))\nloan_data = pd.concat([loan_data, dummies], axis=1)\nloan_data = loan_data.drop(['education'],  axis=1)\n\ndummies = pd.get_dummies(loan_data['Gender']).rename(columns=lambda x: 'is_' + str(x))\nloan_data = pd.concat([loan_data, dummies], axis=1)\nloan_data = loan_data.drop(['Gender'], axis=1)\n\nloan_data = loan_data.drop(['Loan_ID', 'loan_status', 'effective_date', 'due_date', 'paid_off_time', 'past_due_days', 'paid_off_date', 'day_to_pay'], axis=1)"},{"cell_type":"markdown","metadata":{"_cell_guid":"572fcfe3-3246-4aa4-c28f-7c6c0eb9cf07"},"source":"Normally, when we create **dummy variables**, we need to drop 1 variable of those to avoid dummy trap.\nIn this case, we will drop **is_female** and **is_Master or Above** variable."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"595fbcdf-c560-582d-17ea-6072fd2f4ddf"},"outputs":[],"source":"dummy_var = ['is_female', 'is_Master or Above']\nloan_data = loan_data.drop(dummy_var, axis = 1)\n\nprint(loan_data.head(2))"},{"cell_type":"markdown","metadata":{"_cell_guid":"d241dade-9e07-1baf-1c6a-a6488d7e5cb3"},"source":"Let's create X (model input) and y (target variable)."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5ce415f8-6fd3-9b67-61ef-79789f57c11c"},"outputs":[],"source":"X = loan_data.drop(['loan_status_trgt'], axis=1)\ny = loan_data.loan_status_trgt"},{"cell_type":"markdown","metadata":{"_cell_guid":"5f060dae-a156-5b74-4ae3-c57aff18cbf1"},"source":"We will see the performance of random forest, SVM, and keras."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ed267c7f-361d-0b6b-6b20-2e260a7bb3ce"},"outputs":[],"source":"# ML library\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import svm\n\n### Create function to evaluate the score of each classification model\ndef eval_model_classifier(model, data, target, split_ratio):\n    trainX, testX, trainY, testY = train_test_split(data, target, train_size=split_ratio, random_state=0)\n    model.fit(trainX, trainY)    \n    return model.score(testX,testY)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e930abee-63c6-0784-e082-ded6806f1447"},"outputs":[],"source":"### 1st round: RandomForestClassification\n\n# Initialise values\nnum_estimators_array = np.array([1,5,10,50,100,200,500]) \nnum_smpl = 5 # Test run the model according to samples_number\nnum_grid = len(num_estimators_array)\nscore_array_mu = np.zeros(num_grid) # Keep mean\nscore_array_sigma = np.zeros(num_grid) # Keep Standard deviation \nj=0\n\nprint(\"{}: RandomForestClassification Starts!\".format(now()))\nfor n_estimators in num_estimators_array:\n    score_array = np.zeros(num_smpl) # Initialize\n    for i in range(0,num_smpl):\n        rf_class = RandomForestClassifier(n_estimators = n_estimators, n_jobs=1, criterion=\"gini\")\n        score_array[i] = eval_model_classifier(rf_class, X, y, 0.8)\n        print(\"{}: Try {} with n_estimators = {} and score = {}\".format(now(), i, n_estimators, score_array[i]))\n    score_array_mu[j], score_array_sigma[j] = np.mean(score_array), np.std(score_array)\n    j=j+1\n\nprint(\"{}: RandomForestClassification Done!\".format(now()))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"940f2718-d9ad-767e-2b35-2ef149d39a3f"},"outputs":[],"source":"fig = plt.figure(figsize=(7,3))\nplt.errorbar(num_estimators_array, score_array_mu, yerr=score_array_sigma, fmt='k.-')\nplt.xscale(\"log\")\nplt.xlabel(\"number of estimators\",size = 16)\nplt.ylabel(\"accuracy\",size = 16)\nplt.xlim(0.9,600)\nplt.ylim(0.3,0.8)\nplt.title(\"Random Forest Classifier\", size = 18)\nplt.grid(which=\"both\")\nplt.show();"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"97c07e5a-5f79-9f92-4754-375f9aa58ec3"},"outputs":[],"source":"C_array = np.array([0.5, 0.1, 1, 5, 10])\nscore_array = np.zeros(len(C_array))\ni=0\nfor C_val in C_array:\n    svc_class = svm.SVC(kernel='linear', random_state=1, C = C_val)\n    score_array[i] = eval_model_classifier(svc_class, X, y, 0.8)\n    i=i+1\n\nscore_mu, score_sigma = np.mean(score_array), np.std(score_array)\n\nfig = plt.figure(figsize=(7,3))\nplt.errorbar(C_array, score_array, yerr=score_sigma, fmt='k.-')\nplt.xlabel(\"C assignment\",size = 16)\nplt.ylabel(\"accuracy\",size = 16)\nplt.title(\"SVM Classifier (Linear)\", size = 18)\nplt.grid(which=\"both\")\nplt.show();"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"95392877-8443-0f46-62b2-0f8f372c10e5"},"outputs":[],"source":"# Note: \n# Gamma: Kernel coefficient - the higher, it will try to exact fit to the training data, hence, can cause overfitting\n\ngamma_array = np.array([0.001, 0.01, 0.1, 1, 10])\nscore_array = np.zeros(len(gamma_array))\nscore_mu = np.zeros(len(gamma_array))\nscore_sigma = np.zeros(len(gamma_array))\ni=0\nfor gamma_val in gamma_array:\n    svc_class = svm.SVC(kernel='rbf', random_state=1, gamma = gamma_val)\n    score_array[i] = eval_model_classifier(svc_class, X, y, 0.8)\n    score_mu[i], score_sigma[i] = np.mean(score_array[i]), np.std(score_array[i])\n    i=i+1\n\n\nfig = plt.figure(figsize=(10,5))\nplt.errorbar(gamma_array, score_mu, yerr=score_sigma, fmt='k.-')\nplt.xscale('log')\nplt.xlabel(\"Gamma\",size = 16)\nplt.ylabel(\"accuracy\",size = 16)\nplt.title(\"SVM Classifier (RBF)\", size = 18)\nplt.grid(which=\"both\")\nplt.show();"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f1810d74-65e1-1f0e-f7cb-4e1120717170"},"outputs":[],"source":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation\nfrom keras.optimizers import SGD\n\n# Change to np.array type\nnew_x = np.array(X)\nnew_y = np.array(y)\n\n# fix random seed for reproducibility\nnp.random.seed(1234)\n\nmodel = Sequential()\nmodel.add(Dense(64, input_dim=7, init='uniform', activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"eb856ee2-521b-631e-36f3-352230137827"},"outputs":[],"source":"model.fit(new_x, new_y, epochs=150, batch_size=20)\nscores = model.evaluate(new_x, new_y)\nprint(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}