{"nbformat_minor":1,"nbformat":4,"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.1","nbconvert_exporter":"python","pygments_lexer":"ipython3","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"mimetype":"text/x-python"}},"cells":[{"source":"# Crypto-Correlations\n\nThe goal of this analysis is to create a correlation matrix for these crypto-currencies. ","cell_type":"markdown","metadata":{"_cell_guid":"3207b418-f193-4642-9313-665839b10dd4","_uuid":"a2732e4816cf3356a500c1623263d2337c8827c7"}},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"14791e9e-f541-4188-88ee-84713814287e","_uuid":"2cb534a31814f0e8974f4f969455027879afdb20"},"source":"import pandas as pd\nfrom pandas.plotting import lag_plot\nimport numpy as np\nimport sklearn as sk\nfrom sklearn import preprocessing as pr\nfrom sklearn.linear_model import LinearRegression\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\nfrom scipy.signal import correlate\nfrom scipy.stats.mstats import spearmanr\nfrom statsmodels.tsa.stattools import acf, adfuller\nfrom statsmodels.graphics.tsaplots import plot_pacf"},{"source":"## Data Handling\n \n ### Data representation and a quick clean","cell_type":"markdown","metadata":{"_cell_guid":"a1b04096-e52d-4b6b-95bd-d55f7d7cc903","_uuid":"9577e05b865aac845fbd39c4a1358dd9e6c97525"}},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{"collapsed":true,"_cell_guid":"4f179bc5-2318-4cf2-a2ec-b600c0237cb0","_uuid":"aef36b7e96463d18de1138c46e37569b8638e3b0"},"source":"crypto = {}\n\ncrypto['bitcoin'] = pd.read_csv('../input/cryptocurrencypricehistory/bitcoin_price.csv')\ncrypto['bitcoin_cash'] = pd.read_csv(\"../input/cryptocurrencypricehistory/bitcoin_cash_price.csv\")\ncrypto['dash'] = pd.read_csv(\"../input/cryptocurrencypricehistory/dash_price.csv\")\ncrypto['ethereum'] = pd.read_csv(\"../input/cryptocurrencypricehistory/ethereum_price.csv\")\ncrypto['iota'] = pd.read_csv(\"../input/cryptocurrencypricehistory/iota_price.csv\")\ncrypto['litecoin'] = pd.read_csv(\"../input/cryptocurrencypricehistory/litecoin_price.csv\")\ncrypto['monero'] = pd.read_csv(\"../input/cryptocurrencypricehistory/monero_price.csv\")\ncrypto['nem'] = pd.read_csv(\"../input/cryptocurrencypricehistory/nem_price.csv\")\ncrypto['neo'] = pd.read_csv(\"../input/cryptocurrencypricehistory/neo_price.csv\")\ncrypto['numeraire'] = pd.read_csv(\"../input/cryptocurrencypricehistory/numeraire_price.csv\")\ncrypto['ripple'] = pd.read_csv(\"../input/cryptocurrencypricehistory/ripple_price.csv\")\ncrypto['stratis'] = pd.read_csv(\"../input/cryptocurrencypricehistory/stratis_price.csv\")\ncrypto['waves'] = pd.read_csv(\"../input/cryptocurrencypricehistory/waves_price.csv\")"},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{"collapsed":true,"_cell_guid":"5b76c6bf-a268-4b3a-810e-c3962c0b83c2","_uuid":"28f3609438af096646bae77b5ce9250f5e885c76"},"source":"# For this analysis I will only be looking at closing price to make things more manageable\nfor coin in crypto:\n    for column in crypto[coin].columns:\n        if column not in ['Date', 'Close']:\n            crypto[coin] = crypto[coin].drop(column, 1)\n    # Make date the datetime type and reindex\n    crypto[coin]['Date'] = pd.to_datetime(crypto[coin]['Date'])\n    crypto[coin] = crypto[coin].sort_values('Date')\n    crypto[coin] = crypto[coin].set_index(crypto[coin]['Date'])\n    crypto[coin] = crypto[coin].drop('Date', 1)"},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"4dee53f0-a55d-4199-a7b2-e71e9c7cff10","_uuid":"907c912c55066968c8834a7d28ee2f4d3491650d"},"source":"for coin in crypto:\n    print(coin, len(crypto[coin]))"},{"source":"### Note: \nThe coins numeraire, iota, and bitcoin_cash all are relatively young and therefore do not have many data points. I will omit these currencies and for the time being consider only the most recent 350 data points for the remaining currencies.","cell_type":"markdown","metadata":{"_cell_guid":"0f17a898-a73a-400a-b7c4-56652ffafac2","_uuid":"c8f975b3b4899e6b0fc1f36c1e2950ba5d57ebf0"}},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{"collapsed":true,"_cell_guid":"456ee863-40c5-485f-abba-4abe20fd6547","_uuid":"8195ed09a53cb263465f4974c8c8316616d3c971"},"source":"del crypto['bitcoin_cash'], crypto['numeraire'], crypto['iota']"},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{"collapsed":true,"_cell_guid":"54f10987-4b5f-47d5-8303-6c9505904897","_uuid":"ce89402e44a745e20b7db68aee253f6967459fb4"},"source":"cryptoAll = {} # for later on\n\nfor coin in crypto:\n    cryptoAll[coin] = crypto[coin]\n    crypto[coin] = crypto[coin][-350:]"},{"source":"## Goal:\n\n As previously stated, the goal of this analysis is to create a correlation matrix for these currencies. One way to find correlation between timeseries is to look at *cross-correlation* of the timeseries. Cross-correlation is computed between two timeseries using a lag, so when creating the correlation matrix I will specify the correlation as well as the lag.\n \n Before computing the cross correlation, it is important to have wide-sense station (often just called stationary) data. There are a few ways to make data stationary-- one of which is through differencing. But even after this it is famously difficult to avoid spurious correlations between timeseries data that are often caused by autocorrelation. See this article for an in depth analysis of how spurious correlations arise and how to avoid them: https://link.springer.com/article/10.3758/s13428-015-0611-2.\n \n For now I employ daily differencing (as it is not seasonal) and test for stationarity to prepare for cross correlation testing.","cell_type":"markdown","metadata":{"_cell_guid":"86499dae-151d-44f3-b91f-c16a1f3bf770","_uuid":"c1cc92ce893188aa00f780bb335fff8ec90c1371"}},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"01a7f876-2337-493c-b750-e284582286a8","_uuid":"5ec21995a731253debc3c0de5ebffa37400b75bb"},"source":"# Differencing\nfor coin in crypto:\n    crypto[coin]['CloseDiff'] = crypto[coin]['Close'].diff().fillna(0)"},{"source":"### Graphing\n\nNow lets take a preliminary look at how our graph looks. Further steps may have to be taken to make the data stationary.","cell_type":"markdown","metadata":{"_cell_guid":"c1be4bf9-d292-4564-8b5f-dcc62f4ac859","_uuid":"77872d8d327df677f569c1f0623e22b2329b1845"}},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"04095141-8b27-4b83-a2cf-4712a429eb69","_uuid":"45b7ce3844a37deba2f3728d97093843a4a37d70"},"source":"for coin in crypto:\n    plt.plot(crypto[coin]['CloseDiff'], label=coin)\nplt.legend(loc=2)\nplt.title('Daily Differenced Closing Prices')\nplt.show()"},{"source":"### Note:\nHere we see that one of the coins (bitcoin) has much larger spikes than the other coins. While this may still have given us stationarity, it may be useful to also look at the percentage change per day of the timeseries.","cell_type":"markdown","metadata":{"_cell_guid":"82ed118a-1576-4882-acf8-4d02ae71f26f","_uuid":"92aa9a6e1a62b242971216ef5efe3e6c2cc3c711"}},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"9bc6c911-438a-4eb2-b952-f43322d7b950","_uuid":"00b136164062296edc7c3b8197b2053815d9e8b8"},"source":"# Percent Change\nfor coin in crypto:\n    crypto[coin]['ClosePctChg'] = crypto[coin]['Close'].pct_change().fillna(0)\n    "},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"95da6f84-2619-406b-8027-84e784b14c23","_uuid":"b8e75f104b7e4805a307e74eb0bfba10463c33b8"},"source":"for coin in crypto:\n    plt.plot(crypto[coin]['ClosePctChg'], label=coin)\nplt.legend(loc=2)\nplt.title('Daily Percent Change of Closing Price')\nplt.show()"},{"source":"### Note:\nAs before, we still have some very large peaks, but overall the data looks more contained than previously. Most importantly, we do not have a single coin dominating the others.\n\nFocus on one particular part of the graph to get an idea of any correlation going on.","cell_type":"markdown","metadata":{"_cell_guid":"d750adbe-bad9-4498-aed0-660007861d06","_uuid":"9b483c39d4ebba5b227e6fb9e2725fe693a517dd"}},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"8c666d05-28e0-4395-b61a-0787594f1c36","_uuid":"5af1356c4181985b6496fe624015605bfc902cb9"},"source":"for coin in crypto:\n    plt.plot(crypto[coin]['ClosePctChg'][-30:], label=coin)\nplt.legend(loc=2)\nplt.title('Daily Percent Change of Closing Price')\nplt.show()"},{"source":"### Note:\nLooks here as if we do in fact have some correlation going on, which is what we were hoping for.\n\nIt is also important to note that a number of other types of differencing or normalizations could have been applied. As this is only a preliminary analysis, this may not end up being the best way to prepare the data.","cell_type":"markdown","metadata":{"_cell_guid":"17226f16-1630-4b14-ac56-d50eae9fefa2","_uuid":"71c78ffa69bffb0d5116c4a0f99df0e9091519b8"}},{"source":"## Stationarity\n\nWe can test for stationarity by using *unit root tests*. One of which is the Augmented Dickey-Fuller Test. Dickey Fuller utilizes the following regression.\n\n$$ Y'_t \\space = \\space \\phi Y_{t-1} \\space + \\space b_1 Y'_{t-1} \\space + \\space b_2 Y'_{t-2} \\space +...+ \\space b_p Y'_{t-p} $$\n$$ $$\n$$ Y'_t \\space = \\space Y_t \\space - \\space Y_{t-1} $$\n\nUsing the Augmented Dickey Fuller test, we look at the following statistic.\n\n$$ DF_t \\space = \\space \\frac{\\hat{\\phi}}{SE(\\hat{\\phi}}) $$\n\nThen this statistic is compared to a table given by Dickey Fuller. Given the number of samples, we can guess with a % certainty whether or not our data is stationary.\n\n$$ H_{0} \\space : data \\space is \\space nonstationary $$\n$$ H_{A} \\space : data \\space is \\space stationary $$\n\nTo check these hypotheses, we look at the p-value of our given statistic using table (web.sgh.waw.pl/~mrubas/EP/TabliceStatystyczneDF.doc). On the table we look at model 2 with 250 < n < 500. Form here we can see that in order to know with 5% certainty whether or not our data is stationary, we can compare our $ DF_t $ statistic to the values 3.46 and 3.44.","cell_type":"markdown","metadata":{"_cell_guid":"74e24ae7-08d5-4f09-8941-b234b9d10e40","_uuid":"a8fb0bf39183d08a450e3ed0ca4366aca071caec"}},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{"scrolled":true,"_cell_guid":"d5645535-0666-493c-81a8-40e58b4fcf7e","_uuid":"5cce64817a9a862712e888fa109271f087f0c8ae"},"source":"for coin in crypto:\n    print('\\n',coin)\n    adf = adfuller(crypto[coin]['ClosePctChg'][1:])\n    print(coin, 'ADF Statistic: %f' % adf[0])\n    print(coin, 'p-value: %f' % adf[1])\n    print(coin, 'Critical Values', adf[4]['1%'])\n    print(adf)"},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{"scrolled":true,"_cell_guid":"037df3d9-63c2-4b34-8bb7-28f1fab55811","_uuid":"632dcbcf91628057de006327eddee3aeec12a3f9"},"source":"for coin in crypto:\n    print('\\n',coin)\n    adf = adfuller(crypto[coin]['CloseDiff'][1:])\n    print(coin, 'ADF Statistic: %f' % adf[0])\n    print(coin, 'p-value: %f' % adf[1])\n    print(coin, 'Critical Values', adf[4]['1%'])\n    print(adf)"},{"source":"### Note:\nHere we see that  our data is very stationary! This is clear because of the extremely low p-values.. \n\nIt is important here to note there are other wasy to detrend other than looking at differenced data or percent change. However some of these methods would not have proven fruitful for this data set. Take for example using the residuals of this data based on a simple linear regression. This can be easily done using scikit learn's linear regression tool.","cell_type":"markdown","metadata":{"_cell_guid":"c22d5c8c-0ab3-45ba-a860-e5d663227dd3","_uuid":"0bfa930be30867c47efe8d14dfd76c39ab384df0"}},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{"scrolled":true,"_cell_guid":"98298af9-c255-4944-abb6-cac6ace164f8","_uuid":"a5905bf439fc3f62de223d9fdcfc6c7d58b5a5c1"},"source":"for coin in crypto:\n    model = LinearRegression()\n    model.fit(np.arange(350).reshape(-1,1), crypto[coin]['Close'].values)\n    trend = model.predict(np.arange(350).reshape(-1,1))\n    plt.subplot(1, 2, 1)\n    plt.plot(trend, label='trend')\n    plt.plot(crypto[coin]['Close'].values)\n    plt.title(coin)\n    \n    plt.subplot(1, 2, 2)\n    plt.plot(crypto[coin]['Close'].values - trend, label='residuals')\n    plt.title(coin)\n    \n    plt.show()"},{"source":"### Note:\nWe are getting poor results, as many of these currencies only started gaining traction recently, this shows that the preferred method was what was done originally.","cell_type":"markdown","metadata":{"_cell_guid":"ad9699d3-31d4-43db-86e2-35462642df35","_uuid":"a7f3b3ec5c2903ce35be882956f4e82af06b5883"}},{"source":"## Correlations\n\nNow we will look at the cross correlations between the different series. To do this scipy's correlate function will be used. The cross-correlation will tell us if we should lag one of the series. Cross-correlation is often used in signal process to match signals.","cell_type":"markdown","metadata":{"_cell_guid":"df4f4823-f2b0-400c-a711-0c5ee0a99ca0","_uuid":"44d995d9c2ccee43999a50d58ecfc1855de97a90"}},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{"scrolled":true,"_cell_guid":"898a12be-2143-4cfe-901a-89653c719a3d","_uuid":"a48fcbbdeda7d86ffd0d5bb38d82588506e49e9d"},"source":"corrBitcoin = {}\ncorrDF = pd.DataFrame()\n\nfor coin in crypto: \n    corrBitcoin[coin] = correlate(crypto[coin]['ClosePctChg'], crypto['bitcoin']['ClosePctChg'])\n    lag = np.argmax(corrBitcoin[coin])\n    laggedCoin = np.roll(crypto[coin]['ClosePctChg'], shift=int(np.ceil(lag)))\n    corrDF[coin] = laggedCoin\n    \n    plt.figure(figsize=(15,10))\n    plt.plot(laggedCoin)\n    plt.plot(crypto['bitcoin']['ClosePctChg'].values)\n    title = coin + '/bitcoin PctChg lag: ' + str(lag-349)\n    plt.title(title)\n\n    plt.show()"},{"source":"Now that we have done that we will look at the correlations among these currencies. \nWe will compute the correlations using three different methods: pearson, spearman, and kendall.","cell_type":"markdown","metadata":{}},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"301c87a4-8f33-403e-a282-31454c4d1d9a","_uuid":"0e26d454d17babca828b13291647ecb9fb09911a"},"source":"font = {'family': 'serif',\n        'color':  'black',\n        'weight': 'normal',\n        'size': 20,\n        }\n\nplt.matshow(corrDF.corr(method='pearson'))\nplt.xticks(range(10), corrDF.columns.values, rotation='vertical')\nplt.yticks(range(10), corrDF.columns.values)\nplt.xlabel('Pearson Correlation', fontdict=font)\nplt.show()\ncorrDF.corr(method='pearson')"},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"b0717b7f-0c5a-4dff-98f6-bb38d3797408","_uuid":"e604b4c698618327912aebcd301f11ca010aedcf"},"source":"plt.matshow(corrDF.corr(method='spearman'))\nplt.xticks(range(10), corrDF.columns.values, rotation='vertical')\nplt.yticks(range(10), corrDF.columns.values)\nplt.xlabel('Spearman Correlation', fontdict=font)\nplt.show()\ncorrDF.corr(method='spearman')"},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"a7f41fd6-5b60-4969-9da1-f5588c692878","_uuid":"ef1a8ccaba72f43c064d7a3a5cd817fa5b683bb7"},"source":"plt.matshow(corrDF.corr(method='kendall'))\nplt.xticks(range(10), corrDF.columns.values, rotation='vertical')\nplt.yticks(range(10), corrDF.columns.values)\nplt.xlabel('Kendall Correlation', fontdict = font)\nplt.show()\ncorrDF.corr(method='kendall')"},{"source":"","cell_type":"markdown","metadata":{"_cell_guid":"e3ecddef-ac04-4846-b852-30ec8f097cfc","_uuid":"4c46ee6c32798537d5152c1077cf82daaa912529"}},{"source":"### Note:\nWe see here that with all of these correlation methods we get about the same results, but with slightly different magnitudes.\nAlso we should note that there are *no* correlations greater than .5\nThis is contrary to what may be found if we were to for example take the correlation of the nonstationary datasets. This leads me to believe that I have avoided spurious correlations between currencies. Also note that only two of the currencies showed to have better correlations with lagged data. This makes sense as these currencies have shown to be very responsive to media in the recent past.\n\nThanks for reading I hope you enjoyed this notebook. If you have any suggestions or if I missed anything please let me know in the comments!","cell_type":"markdown","metadata":{"_cell_guid":"6cd26564-7423-4ba5-a56a-749b1d03d844","_uuid":"8ed3bb49289a73c2a2d96d3e2605c1f08ccd0c44"}}]}