{"cells":[{"metadata":{},"cell_type":"markdown","source":"Classification Model in Machine Learning is a vital area to work. Used from classifing customer's reaction ðŸ§‘â€ to hotelðŸ¬ booking demand (which I used her).\nIt predict the class labels/categories for the new data.\n\nFor this particular dataset I used the following model to train over our data :\n\n1. Logistic Regression\n2. Decision Tree \n3. Random Forest\n4. Gaussian Naive Bayes\n5. XG Boost\n\nSo, let's find out which model work best for our dataset. So that our model could be used hotel's to find the answer to questions.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"â›”ï¸â›”ï¸â›”ï¸â›”ï¸\nBefore going forward :\n\nIf you liked my work doo give an upvote \nðŸ‘ðŸ¼ðŸ‘ðŸ¼ðŸ‘ðŸ¼ðŸ‘ðŸ¼ðŸ‘ðŸ¼ðŸ‘ðŸ¼ðŸ‘ðŸ¼ðŸ‘ðŸ¼ðŸ‘ðŸ¼\n\nIt not only motivates work but also boost my mind to work for much better than before. ðŸ˜‡ðŸ˜‡ðŸ˜‡\n\nand what's the best it does not cost anyone's pocket.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Import of functions and functions to be used\n\nSo, here I imported the all time greatest libraries first...\nNumpy, Pandas, Sklearn and respective.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport statsmodels.formula.api as smf\nfrom sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, confusion_matrix, auc\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.compose import ColumnTransformer","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"## Load of Dataset\nAs always using ðŸ¼ Pandas we read the dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/hotel-booking-demand/hotel_bookings.csv\") \ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ok! Now that we have imported data... Now let's have a lookðŸ‘“ over dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"At here, we have looked at our Output label\nAnd, have seen the correlation between different features.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"is_canceled\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_matrix = data.corr()\ncorr_matrix[\"is_canceled\"].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Is there any null values? ðŸš«ðŸš«","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"nulls = data.isnull().sum()\nnulls[nulls > 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.iloc[:,23].fillna(data.iloc[:,23].mean(), inplace=True)\ndata.iloc[:,10].fillna(data.iloc[:,10].mean(), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nulls = data.isnull().sum()\nnulls[nulls > 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.drop(['stays_in_weekend_nights','arrival_date_day_of_month', 'children', 'arrival_date_week_number', 'company', 'reservation_status_date'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"country\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Data shape BEFORE drop of rows where country is not especified : \",data.shape)\ndata = data[data['country'].notna()]\nprint(\"Data shape AFTER drop of rows where country is not especified : \",data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"country\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.drop(['country'], axis=1)\n# as it contains a lot of variety","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Found a Accuracy of 1 which is clearly not good as there can be anything ideal. So after checking the kerels of other I found that:\n*\"Reservation status dominates other features totally. By keeping reservation_status in data, it is possible to achieve 100% accuracy rate because that feature is direct way to predict cancellations.\"*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.drop(['reservation_status'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Spliting the data to X and Y","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = (data.loc[:, data.columns != 'is_canceled'])\ny = (data.loc[:, data.columns == 'is_canceled'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_columns = X.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"object_column_name = X.select_dtypes('object').columns\nprint (object_column_name)\n\nobject_column_index = X.columns.get_indexer(X.select_dtypes('object').columns)\nprint (object_column_index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X.shape)\n\ncolumnTransformer = ColumnTransformer([('encoder', OneHotEncoder(), object_column_index)], remainder='passthrough')\n\nX = columnTransformer.fit_transform(X)\nprint(X.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 25)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Defining Model Function","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def model(algo):\n    algo_model = algo.fit(X_train, y_train)\n    global y_prob, y_pred\n    y_prob = algo.predict_proba(X_test)[:,1]\n    y_pred = algo_model.predict(X_test)\n\n    print('Accuracy Score: {}\\n\\nConfusion Matrix:\\n {}'\n      .format(accuracy_score(y_test,y_pred), confusion_matrix(y_test,y_pred),roc_auc_score(y_test,y_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# From here we checked accuracy score of different Models","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Logistic Regression\\n')\nmodel(LogisticRegression(solver = \"saga\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Decision Tree\\n')\nmodel(DecisionTreeClassifier(max_depth = 12))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Random Forest\\n')\nmodel(RandomForestClassifier())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Gaussian Naive Bayes\\n')\nmodel(GaussianNB())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Model: XGBoost\\n')\nmodel(XGBClassifier())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And, Finally we have different accuracy for diiferent model and we found that **Random Forest** gaved the best result. And we could start working over it to increase our accuracy.\n\nTill then Happy Coding ðŸ˜‡ðŸ˜‡ðŸ˜‡ðŸ˜‡ðŸ˜‡","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}