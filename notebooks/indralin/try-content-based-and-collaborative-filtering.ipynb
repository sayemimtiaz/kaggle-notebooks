{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nimport os\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\npd.set_option('display.max_colwidth', -1)\nplt.style.use('fivethirtyeight')\nplt.rcParams['figure.figsize'] = [18, 8]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"rating = pd.read_csv('/kaggle/input/anime-recommendations-database/rating.csv')\nanime_df = pd.read_csv('/kaggle/input/anime-recommendations-database/anime.csv')\n\nprint('rating shape:', rating.shape)\nprint('anime_df shape:', anime_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"anime_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Cleaning\n\n- First, it easier for us to create a Recommendation System if the dataset doesn't have a NULL values\n- So we'll remove NULL values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"null_features = anime_df.columns[anime_df.isna().any()]\nanime_df[null_features].isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"anime_df.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Perhaps anime name uses japanese or special character so the dataframe couldn't read that\n# I just cleaned some error for better names for recommendation\n\ndef text_cleaning(text):\n    text = re.sub(r'&quot;', '', text)\n    text = re.sub(r'.hack//', '', text)\n    text = re.sub(r'&#039;', '', text)\n    text = re.sub(r'A&#039;s', '', text)\n    text = re.sub(r'I&#039;', 'I\\'', text)\n    text = re.sub(r'&amp;', 'and', text)\n    \n    return text\n\nanime_df['name'] = anime_df['name'].apply(text_cleaning)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## EDA","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"type_count = anime_df['type'].value_counts()\n\nsns.barplot(x=type_count.values,\n            y=type_count.index,\n            palette='muted').set_title('Anime Types')\n\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## What genres are in the anime dataset?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import defaultdict\n\nall_genres = defaultdict(int)\n\nfor genres in anime_df['genre']:\n    for genre in genres.split(','):\n        all_genres[genre.strip()] += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud\n\ngenres_cloud = WordCloud(width=800, height=400, background_color='white', colormap='gnuplot').generate_from_frequencies(all_genres)\n\nplt.imshow(genres_cloud, interpolation='bilinear')\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Which anime has a longest episodes?\n\n- If you check, why episodes dtype is object, not integer?\n- Because episodes has an Unknown values, from my opinion this means countless episodes\n- If you're more than 20 years old, most likely you know some of famous anime below","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"anime_df[anime_df['episodes'] == 'Unknown']['name'][:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"episodes_count = anime_df[anime_df['episodes'] != 'Unknown'][['name', 'episodes']]\nepisodes_count['episodes'] = pd.to_numeric(episodes_count['episodes'])\n\nepisodes_count.query('episodes>1500')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Which anime has the highest rating?\n\n- Here, i only included anime that have more than 500000 of community members\n- All top 5 anime are TV series","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"anime_df[['name', 'rating', 'members', 'type']].sort_values(by='rating', ascending=False).query('members>500000')[:5]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### How about movie and OVA (Original Animated Video)?\n\n> OVA is Japanese animated films and series made specially for release in home video formats without prior showings on television or in theatres","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"anime_df[anime_df['type'] == 'Movie'][['name', 'rating', 'members', 'type']].sort_values(by='rating', ascending=False).query('members>200000')[:5]","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"anime_df[anime_df['type'] == 'OVA'][['name', 'rating', 'members', 'type']].sort_values(by='rating', ascending=False).query('members>100000')[:5]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Content-Based Recommendation-System","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\ngenres_str = anime_df['genre'].str.split(',').astype(str)\n\ntfidf = TfidfVectorizer(analyzer='word', ngram_range=(1, 4), min_df=0)\ntfidf_matrix = tfidf.fit_transform(genres_str)\n\ntfidf_matrix.shape\n# tfidf.get_feature_names()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics.pairwise import linear_kernel\n\ncosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"indices = pd.Series(anime_df.index, index=anime_df['name'])\n\ndef genre_recommendations(title, similarity=False):\n    \n    if similarity == False:\n        \n        idx = indices[title]\n        sim_scores = list(enumerate(cosine_sim[idx]))\n        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n        sim_scores = sim_scores[1:11]\n        \n        anime_indices = [i[0] for i in sim_scores]\n        \n        return pd.DataFrame({'Anime name': anime_df['name'].iloc[anime_indices].values,\n                             'Type': anime_df['type'].iloc[anime_indices].values})\n    \n    elif similarity == True:\n        \n        idx = indices[title]\n        sim_scores = list(enumerate(cosine_sim[idx]))\n        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n        sim_scores = sim_scores[1:11]\n        \n        anime_indices = [i[0] for i in sim_scores]\n        similarity_ = [i[1] for i in sim_scores]\n        \n        return pd.DataFrame({'Anime name': anime_df['name'].iloc[anime_indices].values,\n                             'similarity': similarity_,\n                             'Type': anime_df['type'].iloc[anime_indices].values})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Make a recommendation based on cosine-similarity\n\n- you can choose to prioritize similarity or rating values on your recommendation functions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"indices = pd.Series(anime_df.index, index=anime_df['name'])\n\ndef genre_recommendations(title, highest_rating=False, similarity=False):\n    \n    if highest_rating == False:\n        if similarity == False:\n        \n            idx = indices[title]\n            sim_scores = list(enumerate(cosine_sim[idx]))\n            sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n            sim_scores = sim_scores[1:11]\n        \n            anime_indices = [i[0] for i in sim_scores]\n        \n            return pd.DataFrame({'Anime name': anime_df['name'].iloc[anime_indices].values,\n                                 'Type': anime_df['type'].iloc[anime_indices].values})\n    \n        elif similarity == True:\n        \n            idx = indices[title]\n            sim_scores = list(enumerate(cosine_sim[idx]))\n            sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n            sim_scores = sim_scores[1:11]\n        \n            anime_indices = [i[0] for i in sim_scores]\n            similarity_ = [i[1] for i in sim_scores]\n        \n            return pd.DataFrame({'Anime name': anime_df['name'].iloc[anime_indices].values,\n                                 'Similarity': similarity_,\n                                 'Type': anime_df['type'].iloc[anime_indices].values})\n        \n    elif highest_rating == True:\n        if similarity == False:\n        \n            idx = indices[title]\n            sim_scores = list(enumerate(cosine_sim[idx]))\n            sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n            sim_scores = sim_scores[1:11]\n        \n            anime_indices = [i[0] for i in sim_scores]\n        \n            result_df = pd.DataFrame({'Anime name': anime_df['name'].iloc[anime_indices].values,\n                                 'Type': anime_df['type'].iloc[anime_indices].values,\n                                 'Rating': anime_df['rating'].iloc[anime_indices].values})\n            \n            return result_df.sort_values('Rating', ascending=False)\n    \n        elif similarity == True:\n        \n            idx = indices[title]\n            sim_scores = list(enumerate(cosine_sim[idx]))\n            sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n            sim_scores = sim_scores[1:11]\n        \n            anime_indices = [i[0] for i in sim_scores]\n            similarity_ = [i[1] for i in sim_scores]\n        \n            result_df = pd.DataFrame({'Anime name': anime_df['name'].iloc[anime_indices].values,\n                                 'Similarity': similarity_,\n                                 'Type': anime_df['type'].iloc[anime_indices].values,\n                                 'Rating': anime_df['rating'].iloc[anime_indices].values})\n            \n            return result_df.sort_values('Rating', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"genre_recommendations('Doraemon (1979)', highest_rating=True, similarity=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"genre_recommendations('Naruto: Shippuuden', highest_rating=False, similarity=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Deep Learning for collaborative filtering\n\n- Neural networks are fundamentally matrix operations.\n- Matrix factorization techniques for recommendation systems also doing something similar.\n- For example: in SVD, We find matrices using weights calculated by SGD, Which is similar to Deep Learning\n- Even though by small margins, in some researches Deep Learning can outperformed SVD!","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"rating.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rating_count = rating['rating'].value_counts().sort_index()\n\nsns.barplot(x=rating_count.index,\n            y=rating_count.values,\n            palette='magma').set_title('Comparison of the number of ratings from -1 to 10');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Computational efficiency strategy\n\n- In real world, many users don't want to give a rating for any reason, maybe because they're lazy (like me)\n- Although we can include all ratings (with Null rating), i only use rating values from 6 to 10 for computational efficiency\n    - -1 means the user watched it but didn't assign a rating, so i decided to remove this, including 1,2,3,4,5\n- Last, we filter user_id from 1 - 10.000\n\n**Computational efficiency measures the amount of time or memory required for a given step in a calculation**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"### step 1 - filter only rating from 6 to 10\n\nmask = (rating['rating'] == -1) | (rating['rating'] == 1) | (rating['rating'] == 2) | (rating['rating'] == 3) | (rating['rating'] == 4) | (rating['rating'] == 5)\n\nrating = rating.loc[~mask]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### step 2 - changed rating value from 6 - 10, to 1 - 5\n\ndef change_rating(rating):\n    if rating == 6:\n        return 1\n    elif rating == 7:\n        return 2\n    elif rating == 8:\n        return 3\n    elif rating == 9:\n        return 4\n    elif rating == 10:\n        return 5\n    \nrating['rating'] = rating['rating'].apply(change_rating)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### step 3 - filter user_id from 1 to 10000 only\n\nrating = rating[rating['user_id'] < 10000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nuser_enc = LabelEncoder()\nrating['user_id'] = user_enc.fit_transform(rating['user_id'])\n\nanime_enc = LabelEncoder()\nrating['anime_id'] = anime_enc.fit_transform(rating['anime_id'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"userid_nunique = rating['user_id'].nunique()\nanime_nunique = rating['anime_id'].nunique()\n\nprint('User_id total unique:', userid_nunique)\nprint('Anime_id total unique:', anime_nunique)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.layers import Input, Embedding, Reshape, Dot, Flatten, concatenate, Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint\n\nfrom tensorflow.keras.utils import model_to_dot\nfrom IPython.display import SVG\n\nprint('Using tensorflow version:', tf.__version__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def RecommenderV2(n_users, n_movies, n_dim):\n    \n    # User\n    user = Input(shape=(1,))\n    U = Embedding(n_users, n_dim)(user)\n    U = Flatten()(U)\n    \n    # Anime\n    movie = Input(shape=(1,))\n    M = Embedding(n_movies, n_dim)(movie)\n    M = Flatten()(M)\n    \n    # Gabungkan disini\n    merged_vector = concatenate([U, M])\n    dense_1 = Dense(128, activation='relu')(merged_vector)\n    dropout = Dropout(0.5)(dense_1)\n    final = Dense(1)(dropout)\n    \n    model = Model(inputs=[user, movie], outputs=final)\n    \n    model.compile(optimizer=Adam(0.001),\n                  loss='mean_squared_error')\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = RecommenderV2(userid_nunique, anime_nunique, 100)\n\nSVG(model_to_dot(model, show_shapes=True, show_layer_names=True).create(prog='dot', format='svg'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX = rating.drop(['rating'], axis=1)\ny = rating['rating']\n\nX_train, X_val, y_train, y_val = train_test_split(X, y,\n                                                  test_size=.1,\n                                                  stratify=y,\n                                                  random_state=2020)\n\nX_train.shape, X_val.shape, y_train.shape, y_val.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint = ModelCheckpoint('model1.h5', monitor='val_loss', verbose=0, save_best_only=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true,"collapsed":true},"cell_type":"code","source":"history = model.fit(x=[X_train['user_id'], X_train['anime_id']],\n                    y=y_train,\n                    batch_size=64,\n                    epochs=20,\n                    verbose=1,\n                    validation_data=([X_val['user_id'], X_val['anime_id']], y_val),\n                    callbacks=[checkpoint])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get training and test loss histories\ntraining_loss2 = history.history['loss']\ntest_loss2 = history.history['val_loss']\n\n# Create count of the number of epochs\nepoch_count = range(1, len(training_loss2) + 1)\n\n# Visualize loss history\nplt.plot(epoch_count, training_loss2, 'r--')\nplt.plot(epoch_count, test_loss2, 'b-')\nplt.legend(['Training Loss', 'Test Loss'])\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.models import load_model\n\nmodel = load_model('model1.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_pred(user_id, anime_id, model):\n    return model.predict([np.array([user_id]), np.array([anime_id])])[0][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_topN_rec(user_id, model):\n    \n    user_id = int(user_id) - 1\n    user_ratings = rating[rating['user_id'] == user_id]\n    recommendation = rating[~rating['anime_id'].isin(user_ratings['anime_id'])][['anime_id']].drop_duplicates()\n    recommendation['rating_predict'] = recommendation.apply(lambda x: make_pred(user_id, x['anime_id'], model), axis=1)\n    \n    final_rec = recommendation.sort_values(by='rating_predict', ascending=False).merge(anime_df[['anime_id', 'name', 'type', 'members']],\n                                                                                       on='anime_id').head(10)\n    \n    return final_rec.sort_values('rating_predict', ascending=False)[['name', 'type', 'rating_predict']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_topN_rec(23, model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Closing\n\n- If you're interested, you can tuning model hyperparameter for better accuracy\n- BUT REMEMBER, accuracy isn't indicator whether this model can provide good recommendations or not\n- We should focus on TopN recommendation; you can upgrade a function to not only give recommendation based on rating (predict), but also based on members, episodes etc","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Also you can check my final project kernel (about recommendation system) if you're interested, 谢谢你\n\nhttps://www.kaggle.com/indralin/movielens-project-1-1-content-based\n\nhttps://www.kaggle.com/indralin/movielens-project-1-2-collaborative-filtering\n\nhttps://www.kaggle.com/indralin/movielens-project-1-3-deep-learning","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}