{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Introduction\nThis kernel is about data exploration and storytelling of the air pollution in Seoul.","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom bokeh.io import output_file,show,output_notebook,push_notebook\nfrom bokeh.plotting import figure\nfrom bokeh.models import BoxAnnotation\nfrom bokeh.models.widgets import Tabs,Panel\nfrom bokeh.models.formatters import DatetimeTickFormatter\noutput_notebook()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"df = pd.read_csv('../input/air-pollution-in-seoul/AirPollutionSeoul/Measurement_summary.csv')\ndf_item = pd.read_csv('../input/air-pollution-in-seoul/AirPollutionSeoul/Original Data/Measurement_item_info.csv')\ndf_measure = pd.read_csv('../input/air-pollution-in-seoul/AirPollutionSeoul/Original Data/Measurement_info.csv')\ndf_station = pd.read_csv('../input/air-pollution-in-seoul/AirPollutionSeoul/Original Data/Measurement_station_info.csv')\n\n# Change measurement date to datetime type, and separate them\n# Set indexing on station code, date, and time\ndf['Measurement date'] = pd.to_datetime(df['Measurement date'])\ndf['date'] = [d.date() for d in df['Measurement date']]\ndf['time'] = [d.time() for d in df['Measurement date']]\n\ndf_measure['Measurement date'] = pd.to_datetime(df_measure['Measurement date'])\n\nitem_codes = {\n    1:'SO2', \n    3:'NO2', \n    5:'CO',\n    6:'O3',\n    8:'PM10',\n    9:'PM2.5'\n}\n\n# Mapping item code\ndf_measure['pollutant'] = df_measure['Item code'].apply(lambda x: item_codes[x]) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Understanding the Data\n- **This data measures six pollutants.** (SO2, NO2, CO, O3, PM10, PM2.5).\n- **Data were measured every hour between 2017 and 2019 in 25 districts in Seoul.** Consistent timeframe makes the data easier to interpret.\n- **Not all data was recorded perfectly.** Some of them was either recorded with abnormalities or not recorded. We can approximate the original data by doing some either preprocessing, or approximation by prediction models.\n- **The Lower, The Better.** Pollution is a thing that can be measured by how worse it is or how safe it is. So how we read the pollution measurement data?  We can look at the `Measurement_info.csv` file, the less the value of the pollutant, the least pollution is happening.\n- **Item code indicates which measured pollutant.** (1 -> SO2; 3 -> NO2; 5 -> CO; 6 -> O3; 8 -> PM10; 9 -> PM2.5)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## What time of the day is the most pollution occurs?\n\nWe know that these measuring pollution instruments have some abnormality conditions. In this case, I only use the datas that recorded with no abnormalities to give the real condition of the pollution. By using the instrument status (0 status) on the measurement info, we can filter the datas that are normally recorded.\n\n","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"pollutant_cols = ['SO2', 'NO2', 'CO', 'O3', 'PM10', 'PM2.5']\ndef filter_normal(df_1, df_2, col):\n    return df_2[df_2['pollutant'] == col].merge(df_1[['Measurement date', 'Station code', col]], on=['Measurement date', 'Station code'])\n\ndf_pollutant = {}\nfor c in pollutant_cols:\n    df_merged = filter_normal(df, df_measure[df_measure['Instrument status'] == 0], c)\n    df_merged['date'] = df_merged['Measurement date'].dt.date\n    df_merged['time'] = df_merged['Measurement date'].dt.time\n    df_pollutant[c] = df_merged.copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"These are the average value in 24 hours (of all time) of each pollutant in each measurement station.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":false},"cell_type":"code","source":"# Tabs of mean in each station\nunits = {\n    'SO2':'ppm', \n    'NO2':'ppm', \n    'CO':'ppm',\n    'O3':'ppm',\n    'PM10':'Mircrogram/m3',\n    'PM2.5':'Mircrogram/m3'\n}\n\nlp = []\nfor c in pollutant_cols:\n    p = figure(plot_width=700, plot_height=400)\n    dt = df_pollutant[c].groupby(['Station code', 'time']).mean().reset_index()\n    for x in df_station['Station code'].unique():\n        dtemp = dt[dt['Station code'] == x]\n        p.line(dtemp['time'], dtemp['Average value'], line_width=1)\n    \n    label = df_item[df_item['Item name'] == c]\n    box = BoxAnnotation(top=float(label['Good(Blue)']), fill_alpha=0.1, fill_color='gray')\n    p.add_layout(box)\n    box = BoxAnnotation(bottom=float(label['Good(Blue)']), top=float(label['Normal(Green)']), fill_alpha=0.1, fill_color='blue')\n    p.add_layout(box)\n    box = BoxAnnotation(bottom=float(label['Normal(Green)']), top=float(label['Bad(Yellow)']), fill_alpha=0.1, fill_color='green')\n    p.add_layout(box)\n    box = BoxAnnotation(bottom=float(label['Bad(Yellow)']), top=float(label['Very bad(Red)']), fill_alpha=0.1, fill_color='yellow')\n    p.add_layout(box)\n    box = BoxAnnotation(bottom=float(label['Very bad(Red)']), fill_alpha=0.1, fill_color='red')\n    p.add_layout(box)\n\n    p.xaxis.formatter = DatetimeTickFormatter(hours='%Hh')\n    p.xaxis.axis_label = 'Time (h)'\n    p.yaxis.axis_label = units[c]\n\n    tab = Panel(child=p, title=c)\n    lp.append(tab)\n    \ntabs = Tabs(tabs=lp)\nshow(tabs)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Yes, I agree that drawing 100+ lines at a single plot is ugly. But by doing this, it helped us to see a pattern on the plots. It seems that every measurement have the similar function added by various offset. I decided to calculate the mean of those line, so there will be a single line that represents the pollution. ","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Tabs of overall means\nlp = []\nfor c in pollutant_cols:\n    p = figure(plot_width=700, plot_height=400, x_axis_type='datetime')\n    dt = df_pollutant[c].groupby(['time']).mean().reset_index()\n    p.line(dt['time'], dt['Average value'], line_width=1)\n    \n    label = df_item[df_item['Item name'] == c]\n    box = BoxAnnotation(top=float(label['Good(Blue)']), fill_alpha=0.1, fill_color='gray')\n    p.add_layout(box)\n    box = BoxAnnotation(bottom=float(label['Good(Blue)']), top=float(label['Normal(Green)']), fill_alpha=0.1, fill_color='blue')\n    p.add_layout(box)\n    box = BoxAnnotation(bottom=float(label['Normal(Green)']), top=float(label['Bad(Yellow)']), fill_alpha=0.1, fill_color='green')\n    p.add_layout(box)\n    box = BoxAnnotation(bottom=float(label['Bad(Yellow)']), top=float(label['Very bad(Red)']), fill_alpha=0.1, fill_color='yellow')\n    p.add_layout(box)\n    box = BoxAnnotation(bottom=float(label['Very bad(Red)']), fill_alpha=0.1, fill_color='red')\n    p.add_layout(box)\n    \n    p.xaxis.formatter = DatetimeTickFormatter(hours='%Hh')\n    p.xaxis.axis_label = 'Time (h)'\n    p.yaxis.axis_label = units[c]\n    \n    tab = Panel(child=p, title=c)\n    lp.append(tab)\n    \ntabs = Tabs(tabs=lp)\nshow(tabs)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Although all the plots seems to tell us that they have either low value or none (gray fill), there is a specific time of the day that the value of the pollution will changes. For example, the pollutant SO2 will start increasing at the morning drastically (about 6 a.m.) and will be reaching it's peak at 10, then slowly decreasing. This makes sense beacuse SO2 are produced by the emission of the fossil fuel.\nAnd the other plots continues..","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## The Bottom of the Notebook\n\nIn the end, i want to say again that this notebook provides the storytelling of the air pollution data in Seoul. Big thanks to Kaggle and [bappe](https://www.kaggle.com/bappekim) for providing the data.\nI will update this kernel if I find another story either by myself or other kernels on the kaggle community.\nI hope you learn something useful by reading this notebook.\n\nThank you.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}