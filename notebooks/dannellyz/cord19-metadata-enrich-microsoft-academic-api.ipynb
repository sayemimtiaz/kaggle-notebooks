{"cells":[{"metadata":{},"cell_type":"markdown","source":"# CORD-19 Metadata Enrichment [3/x]: Augmenting data with information from Microsoft Project Academic Knowledge"},{"metadata":{},"cell_type":"markdown","source":"[<img src = \"https://docs.microsoft.com/en-us/academic-services/media/project-academic-knowledge-banner.png\">](https://docs.microsoft.com/en-us/academic-services/project-academic-knowledge/introduction)\n\n"},{"metadata":{},"cell_type":"markdown","source":">Welcome to Project Academic Knowledge. With this service, you will be able to interpret user queries for academic intent and retrieve rich information from the Microsoft Academic Graph (MAG). The MAG knowledge base is a web-scale heterogeneous entity graph comprised of entities that model scholarly activities: field of study, author, institution, paper, venue, and event."},{"metadata":{},"cell_type":"markdown","source":"## [CORD-19 Metadata Enrichment Dataset](https://www.kaggle.com/dannellyz/cord19-metadata-enrichment)\n\nThis notebook builds on other work seeking to provide additional, augmented, and normalized data across the CORD-19 dataset. Those other notebooks can be found here:\n1. [CORD-19 Metadata Enrich NIH API](https://www.kaggle.com/dannellyz/cord19-metadata-enrich-nih-api)\n2. [CORD-19 Metadata Enrich Altmetric API](https://www.kaggle.com/dannellyz/cord19-metadata-enrich-altmetric-api)"},{"metadata":{},"cell_type":"markdown","source":"### Start by adding the Metadata Enrichment dataset with the * + Add data * button on right --> \n#### Search by url: https://www.kaggle.com/dannellyz/cord19-metadata-enrichment"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nbase_file_path = \"/kaggle/input/CORD-19-research-challenge/\"\nenrich_file_path = \"/kaggle/input/cord19-metadata-enrichment/\"\n\n#Can either go ahead with the enriched metdata or the base\nmetadata = pd.read_csv(base_file_path + \"metadata.csv\", index_col=\"cord_uid\")\n\n#Grab those that have DOIs as its the selector for the API\nmeta_has_doi = metadata[metadata.doi.notnull()]\nmeta_has_doi.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Get the API Features of the Microsoft Academic API\nmicsoft_api_feats = pd.read_csv(enrich_file_path + \"microsoft_api_features.csv\")\nmicsoft_api_feats","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Get a list of the attributes to add to the search strings\nmicro_attrib_list = list(micsoft_api_feats.Attribute)\n\n#Drop those you are not interested in\n#E: Extended metadata has been depreciated\nmicro_attrib_list.remove(\"E\")\n\n#Take the attributes and format the API search string\nsearch_string = \",\".join(list(micsoft_api_feats.Attribute))\nsearch_string","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Load API key from Kaggle Secret\n#Can add-on secret at top of notebook\n#Can apply for a free API key here: https://msr-apis.portal.azure-api.net/products\n\nfrom kaggle_secrets import UserSecretsClient\nsecret_label = \"microsoft_api_key\"\nsecret_value = UserSecretsClient().get_secret(secret_label)\napi_key = secret_value","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Utilize threading in order to greatly increase call speed"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"import requests\nimport json\nimport concurrent.futures\nimport itertools\nfrom tqdm.notebook import tqdm\n\n#Base API Url\nbase_url = \"https://api.labs.cognitive.microsoft.com/academic/v1.0/evaluate\"\n\n#Format the DOIs for query\n#Each should read \"DOI = '[DOI]'\"\ndoi_list = list(meta_has_doi.doi)\nquery_list = [\"DOI = '\" + doi +\"'\" for doi in doi_list]\n\n#Code to split the DOI list into sublsists len = 10\ndef chunks(lst, n):\n    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n    for i in range(0, len(lst), n):\n        yield lst[i:i + n]      \nsplit_querys = list(chunks(query_list,10))\n\n#DOI Query is all DOIs joined enclosed with OR(...)\ndef make_doi_query(dois):\n    prefix = \"OR(\"\n    dois = \",\".join(dois)\n    suffix = \")\"\n    return prefix + dois + suffix\n\napi_responses = []\nheaders = {'Ocp-Apim-Subscription-Key': api_key}\n\ndef api_call(query_list):\n    params = {\"expr\": make_doi_query(query_list), \"attributes\": search_string}\n    r = requests.get(base_url, headers=headers, params=params)\n    if r.ok:\n        return r.json()[\"entities\"]\n    else:\n        return \n\nwith concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:\n    map_obj = tqdm(executor.map(api_call, split_querys), total=len(split_querys))\n    microsoft_api_df = pd.DataFrame(list(itertools.chain(*map_obj)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Available Data\nval_counts = pd.DataFrame(microsoft_api_df.notna().sum(axis=0), columns=[\"present_count\"])\nval_counts[\"pct_avail_microsoft\"] = val_counts[\"present_count\"] / len(microsoft_api_df)\nval_counts[\"pct_avail_all_data\"] = val_counts[\"present_count\"] / len(metadata)\nval_counts[val_counts[\"present_count\"] > 0].sort_values(by=\"present_count\", ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Save to csv\nmicrosoft_api_df.to_csv(\"microsoft_academic_metadata.csv\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":4}