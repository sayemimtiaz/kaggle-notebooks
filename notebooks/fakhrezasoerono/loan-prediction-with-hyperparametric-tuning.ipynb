{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Project Summary\nThis project goal is to predict Loan_Status based on the best classifier. Algorithms tested for this project are K-NN, Logistic Regression, and Random Forest. Hyperparametric tuning for those algorithms is done by sklearn's GridSearchCV. I 'separated' the script into 3 parts:\n\n    A. ML Algorithms\n    B. Predictions\n    C. Results Analysis\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 00. Packages\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report\nfrom sklearn.preprocessing import scale","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# A.01. Import Train Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"# A.01. Import Data\nf_train = '../input/loan-prediction-problem-dataset/train_u6lujuX_CVtuZ9i.csv'\ndf_train = pd.read_csv(f_train, index_col=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# A.02. Cleaning Data"},{"metadata":{},"cell_type":"markdown","source":"# A.02.01. Replace 'Strange' Data \nIn 'Dependents' column of the dataframe, we should replace '3+' with '3' and convert the column's dtype to numeric."},{"metadata":{"trusted":true},"cell_type":"code","source":"# A.02.01. Replace 'strange' values and convert dtype\ndf_train['Dependents'] = df_train['Dependents'].replace('3+', '3')\ndf_train['Dependents'] = pd.to_numeric(df_train['Dependents'], errors='coerce')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# A.02.02. Numerical & Categorical Data Separation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# A.02.02. Features (Categorical & Numerical)\nX = df_train.drop(columns='Loan_Status') # feature\ncategorical = []\nnumerical = []\nfor feature in list(X.columns):\n\tif X[feature].dtypes == object:\n\t\tcategorical.append(X[feature])\n\telse:\n\t\tnumerical.append(X[feature])\ncategorical = pd.concat(categorical, axis=1)\nnumerical = pd.concat(numerical, axis=1)\ncol_name_cat = categorical.columns # for later use\ncol_name_num = numerical.columns # for later use","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# A.02.03. Filling Null Values (Imputing)\nFor numerical values, null values will be replaced by its mean and for categorical by its most frequent value."},{"metadata":{"trusted":true},"cell_type":"code","source":"# A.02.03 Fill na values (imputing)\nimp_num = SimpleImputer(strategy='mean')\nimp_cat = SimpleImputer(strategy='most_frequent')\nimp_num.fit(numerical)\nimp_cat.fit(categorical)\nnumerical = pd.DataFrame(imp_num.transform(numerical), index=df_train.index,\ncolumns = col_name_num)\ncategorical = pd.DataFrame(imp_cat.transform(categorical), index=df_train.index)\nprint(categorical.isnull().sum())\nprint(numerical.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# A.02.04 Encode Caterogical Data\nDone with pandas' pd.get_dummies(). It is similar to sklearn's OneHotEncoder()."},{"metadata":{"trusted":true},"cell_type":"code","source":"# A.02.04 Encode Categorical (with pd.get_dummies())\ncategorical = pd.get_dummies(categorical, drop_first=True)\ncategorical.columns = ['Male', 'Married', 'Not Graduate', 'Self-Employed', 'SemiUrban', 'Urban']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train = pd.concat([categorical, numerical, df_train['Loan_Status']], axis=1) # for Part C","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# A.03. ML Algorithms\nSet features, targets, train-test split, fitting, and scoring. The features will be scaled to get a better result."},{"metadata":{"trusted":true},"cell_type":"code","source":"X = pd.concat([categorical, numerical], axis=1) # features after imputing and encoding\nX = scale(X) # scaled features\ny = df_train['Loan_Status'] # target\nprint(X.shape)\nprint(y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=99) # train_test_split","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# A.03.01. K-NN Method Classifying\nHyperparametric tuning will be applied in 'n_neighbors' of KNN Classifier and cross-validated (5 folds)."},{"metadata":{"trusted":true},"cell_type":"code","source":"# A.03.01 K-NN Method\nparam_knn = {'n_neighbors' : np.arange(1,50)}\nknn = KNeighborsClassifier()\nknn_cv = GridSearchCV(knn, param_knn, cv=5)\nknn_cv.fit(X_train, y_train)\nprint('K-NN Best Parameter & Score:')\nprint(knn_cv.best_params_)\nprint(knn_cv.best_score_)\ny_pred = knn_cv.predict(X_test)\nknn_score = knn_cv.score(X_test, y_test)\nprint('\\nK-NN Accuracy Score: ', knn_score)\nprint('Classification Report: \\n')\nprint(classification_report(y_test, y_pred), '\\n')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# A.03.02 Logistic Regression\nHyperparametric tuning is applied to 'C' parameter and also cross-validated."},{"metadata":{"trusted":true},"cell_type":"code","source":"# A.03.02 Logistic Regression\nparam_log = {'C' : np.logspace(-4, 4, 20)}\nlogreg = LogisticRegression()\nlogreg_cv = GridSearchCV(logreg, param_log, cv=5)\nlogreg_cv.fit(X_train, y_train)\nprint('Log Reg Best Parameter & Score:')\nprint(logreg_cv.best_params_)\nprint(logreg_cv.best_score_)\ny_pred = logreg_cv.predict(X_test)\nlogreg_score = logreg_cv.score(X_test, y_test)\nprint('\\nLog Reg Accuracy Score: ', logreg_score)\nprint('Classification Report: \\n')\nprint(classification_report(y_test, y_pred), '\\n')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# A.03.02 Random Forest Method\nHyperparemtric tuning on 'n_estimators' parameter. This actually takes couple more seconds. You might lower the maximum n_estimators for the tuning."},{"metadata":{"trusted":true},"cell_type":"code","source":"# A.03.03 Random Forest Method\nparam_rf = {'n_estimators' : np.arange(100,550,100)}\nrf = RandomForestClassifier()\nrf_cv = GridSearchCV(rf, param_rf, cv=5)\nrf_cv.fit(X_train, y_train)\nprint('Random Forest Best Parameter & Score:')\nprint(rf_cv.best_params_)\nprint(rf_cv.best_score_)\ny_pred = rf_cv.predict(X_test)\nrf_score = rf_cv.score(X_test, y_test)\nprint('\\n Random Forest Accuracy Score: ', rf_score)\nprint('Classification Report: \\n')\nprint(classification_report(y_test, y_pred), '\\n')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# B.01. Import New Data For Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"f_new = '../input/loan-prediction-problem-dataset/test_Y3wMUE5_7gLdaTN.csv'\ndf_new = pd.read_csv(f_new, index_col=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# B.02. Cleaning New Data\nSimilar to **Part A.02**."},{"metadata":{"trusted":true},"cell_type":"code","source":"# B.02.01. Replace 'strange' values and convert dtype\ndf_new['Dependents'] = df_new['Dependents'].replace('3+', '3')\ndf_new['Dependents'] = pd.to_numeric(df_new['Dependents'], errors='coerce')\n# B.02.02. Features (Categorical & Numerical)\nX = df_new # feature\ncategorical = []\nnumerical = []\nfor feature in list(X.columns):\n\tif X[feature].dtypes == object:\n\t\tcategorical.append(X[feature])\n\telse:\n\t\tnumerical.append(X[feature])\ncategorical = pd.concat(categorical, axis=1)\nnumerical = pd.concat(numerical, axis=1)\n# B.02.03 Fill na values (imputing)\nimp_num.fit(numerical)\nimp_cat.fit(categorical)\nnumerical = pd.DataFrame(imp_num.transform(numerical), index=df_new.index,\ncolumns = col_name_num)\ncategorical = pd.DataFrame(imp_cat.transform(categorical), index=df_new.index)\n# B.02.04 Encode Categorical (with pd.get_dummies())\ncategorical = pd.get_dummies(categorical, drop_first=True)\ncategorical.columns = ['Male', 'Married', 'Not Graduate', 'Self-Employed', 'SemiUrban', 'Urban']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# B.03. Predictions\nSet features from new data, scale, and predict based on the best classifier."},{"metadata":{"trusted":true},"cell_type":"code","source":"# B.03. Predictions\nX = pd.concat([categorical, numerical], axis=1) # features after imputing and encoding\nX = scale(X) # scale features\nif (knn_score > logreg_score) & (knn_score > rf_score):\n\ty_pred = knn_cv.predict(X)\n\tprint('Chosen Method : K-NN')\n\tprint('Accuracy Score: ', knn_score)\nelif (logreg_score > knn_score) & (logreg_score > rf_score):\n\ty_pred = logreg_cv.predict(X)\n\tprint('Chosen Method : LogisticRegression')\n\tprint('Accuracy Score: ', logreg_score)\nelse:\n\ty_pred = rf_cv.predict(X)\n\tprint('Chosen Method : Random Forest')\n\tprint('Accuracy Score: ', rf_score)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# B.04. Save Results (csv)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# B.04. Save Results\ndf_result = df_new\ndf_result['Loan_Status'] = y_pred\ndf_result.to_csv('test result.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# C. Result Analysis\nOne of the insights that from the result is most of the **'Y' Loan_Status is given to entries with 1 in Credit_History**."},{"metadata":{"trusted":true},"cell_type":"code","source":"rejected = df_result[df_result['Loan_Status'] == 'N']\naccepted = df_result[df_result['Loan_Status'] == 'Y']\nprint(rejected['Credit_History'].value_counts())\nprint(accepted['Credit_History'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This corresponds well with the training data correlation heatmap."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.Loan_Status = data_train.Loan_Status.replace({'Y' : 1, 'N' : 0})\ncorr = data_train.corr()\n_ = sns.heatmap(corr)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}