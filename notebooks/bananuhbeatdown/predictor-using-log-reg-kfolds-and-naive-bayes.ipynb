{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"df25c66e-cad2-a1b7-3044-b07a027a3ec6"},"source":"# Stock Market Predictor using train_test_split, Logistic Regression, KFolds cross-validation and Naive Bayes\nI created a kernel that used random sampling to predict the `'Label'` rather than creating datasets from specified dates ranges"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"aa74a5f1-c5d9-23fb-5836-fcc4c10787ab"},"outputs":[],"source":"import pandas as pd\nimport numpy as np\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\nfrom sklearn.cross_validation import KFold, cross_val_score\nfrom sklearn.naive_bayes import MultinomialNB\n\npath = '../input/Combined_News_DJIA.csv'\ndata = pd.read_csv(path)\ndata.head()"},{"cell_type":"markdown","metadata":{"_cell_guid":"72e96d61-e2e0-1e93-2416-aca4220685f1"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"98771670-590e-8cf3-71e3-38a33eaa793b"},"outputs":[],"source":"# Create feature matrix (X) and the response vector (y)\nX = data.iloc[:, 2:27]\ny = data.Label"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5314f98f-e949-5cbe-37ad-e6b8b8d1947d"},"outputs":[],"source":"# train_test_split the data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.19, random_state=13)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c02ede85-d928-ed95-6e15-95873a6474c1"},"outputs":[],"source":"# the length of y_test is the same as testing data suggested by the dataset's creator\nlen(y_test)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0f6938e9-6a33-b424-5866-355a673306be"},"outputs":[],"source":"# combine all the headlines into a string per each row and add them to trainheadlines\ntrainheadlines = []\nfor row in range(0, len(X_train.index)):\n    trainheadlines.append(' '.join(str(x) for x in X_train.iloc[row, 0:25]))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d675301a-79cd-eefa-54ce-eeb9b5e2df1c"},"outputs":[],"source":"# instantiate and fit the CountVectorizer\nvect = CountVectorizer()\nvect_train = vect.fit_transform(trainheadlines)\nprint(vect_train.shape)"},{"cell_type":"markdown","metadata":{"_cell_guid":"abdd0e2c-5398-2945-a3e8-477bd3b66ece"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"394f43a8-5f2d-6a20-b222-32ca9eb0590c"},"outputs":[],"source":"# instantiate and fit the LogisticRegression model\nlogreg = LogisticRegression()\nlogreg.fit(vect_train, y_train)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"758b6cd8-60b9-5f02-7186-3cd5947535cc","collapsed":true},"outputs":[],"source":"# follow the same steps for the testing data as the training data\ntestheadlines = []\nfor row in range(0, len(X_test.index)):\n    testheadlines.append(' '.join(str(x) for x in X_test.iloc[row, 0:25]))\nvect_test = vect.transform(testheadlines)\npredictions = logreg.predict(vect_test)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9d21a49c-d9b3-267c-c5f3-503ac036de07"},"outputs":[],"source":"# calculate accuracy\nmetrics.accuracy_score(y_test, predictions)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7006e0bd-1592-5e8d-591b-32c2e25ce769"},"outputs":[],"source":"# Use crosstab to look at the results\npd.crosstab(y_test, predictions, rownames=['Actual'], colnames=['Predicted'])"},{"cell_type":"markdown","metadata":{"_cell_guid":"b06230b0-a8bb-bca0-84c9-36cd6f490735"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5af4fe88-b4e5-d66c-c5d8-a8bd139f9667","collapsed":true},"outputs":[],"source":"# create vector transforms of X\nheadlines = []\nfor x in range(0, len(X.index)):\n    headlines.append(' '.join(str(x) for x in X.iloc[row, 0:25]))\nvect_headlines = vect.transform(headlines)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"54b7bde4-b89c-f72e-5b75-d66809fb4e8d"},"outputs":[],"source":"# split the dataset using K-folds with shuffle=False\n# calculate the cross_val_scores\nkf = KFold(len(y), n_folds=10, shuffle=False)\nprint(cross_val_score(logreg, vect_headlines, y, cv=kf))\nprint(cross_val_score(logreg, vect_headlines, y, cv=kf).mean())"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6759c38e-19a9-5671-9180-f7dd09fa552d"},"outputs":[],"source":"# split the dataset using K-folds with shuffle=True\nkf = KFold(len(y), n_folds=10, shuffle=True)\nprint(cross_val_score(logreg, vect_headlines, y, cv=kf))\nprint(cross_val_score(logreg, vect_headlines, y, cv=kf).mean())"},{"cell_type":"markdown","metadata":{"_cell_guid":"b98c9335-4883-0879-8622-60096b9bb642"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bf130194-1368-db85-2793-044d1890a64e"},"outputs":[],"source":"# Building and evaluating a model\n# import and instantiate and fit a Multinominal Naive Bayes model\nnb = MultinomialNB(alpha=1.0)\n%time nb.fit(vect_train, y_train)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"de070962-e555-4588-9cd8-3474c270625e","collapsed":true},"outputs":[],"source":"# make class predictions for vect_test\npredictions = nb.predict(vect_test)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a649a45a-b8f7-9945-c519-60327c3a2750"},"outputs":[],"source":"# calculate accuracy of class predictions\nmetrics.accuracy_score(y_test, predictions)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f6a5c569-82f4-79f7-7ff0-20946c48dc4e"},"outputs":[],"source":"# print the confusion matrix\nmetrics.confusion_matrix(y_test, predictions)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}