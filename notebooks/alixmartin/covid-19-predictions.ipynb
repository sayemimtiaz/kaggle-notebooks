{"cells":[{"metadata":{},"cell_type":"markdown","source":"I copied the data collection part from this notebook : https://www.kaggle.com/imdevskp/covid-19-analysis-viz-prediction-comparisons","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# hide warnings\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dataset","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# importing datasets\nfull_table = pd.read_csv('../input/corona-virus-report/covid_19_clean_complete.csv', \n                         parse_dates=['Date'])\nfull_table.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Cleaning Data","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# cases \ncases = ['Confirmed', 'Deaths', 'Recovered', 'Active']\n\n# Active Case = confirmed - deaths - recovered\nfull_table['Active'] = full_table['Confirmed'] - full_table['Deaths'] - full_table['Recovered']\n\n# replacing Mainland china with just China\nfull_table['Country/Region'] = full_table['Country/Region'].replace('Mainland China', 'China')\n\n# filling missing values \nfull_table[['Province/State']] = full_table[['Province/State']].fillna('')\n# full_table[cases] = full_table[cases].fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_time_series(country):\n    # for some countries, data is spread over several Provinces\n    if full_table[full_table['Country/Region'] == country]['Province/State'].nunique() > 1:\n        country_table = full_table[full_table['Country/Region'] == country]\n        country_df = pd.DataFrame(pd.pivot_table(country_table, values = ['Confirmed'],\n                              index='Date', aggfunc=sum).to_records())\n        return country_df.set_index('Date')[['Confirmed']]\n    df = full_table[(full_table['Country/Region'] == country) \n                & (full_table['Province/State'].isin(['', country]))]\n    return df.set_index('Date')[['Confirmed']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"data looks a bit dirty, we might get an overly optimistic prediction because the last number is not the final one for instance.\n\nThe model is quite sensitive to this as it has only a handful of points to infer the dynamics from.\n\nToday (2020-03-17), if we change the last available point for France (2020-03-15 4499) to what is available on [COVID-19 en France](https://mapthenews.maps.arcgis.com/apps/opsdashboard/index.html#/5e09dff7cb434fb194e22261689e2887) , we go from a relatively mild dynamic to a much more exponential one\n\nFor Apr 4th, the Kaggle data source is suddenly annoucing 20000 more cases for France than the official site, so let's fix that too. Note that this data point is not fixed lower where I compare the different countries, it shows that a single point can make quite a difference. Our cost function that takes squared differences between model and reality, also exacerbates the influence of the biggest values, which are the latest points.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"New Zealand is supposed to be interesting because it has a climate equivalent to France, but in the Southern hemisphere. Let's take a look :","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"country = 'New Zealand'\ndf = get_time_series(country)\nif len(df) > 1 and df.iloc[-2,0] >= df.iloc[-1,0]:\n    df.drop(df.tail(1).index,inplace=True)\ndf.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"country = 'France'\ndf = get_time_series(country)\nif len(df) > 1 and df.iloc[-2,0] >= df.iloc[-1,0]:\n    df.drop(df.tail(1).index,inplace=True)\ndf.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I will use a model from a marketing paper by Emmanuelle Le Nagard and Alexandre Steyer, that attempts to reflect the social structure of a diffusion process. Their application was the diffusion of innovations, not epidemics. However, there are commonalities in both domains, as the number of contacts each infected person / innovation adopter has seems relevant. It also has the added benefit to allow fitting parameters to the beginning of a time series.\n\npaper is available (in French) [here](https://www.jstor.org/stable/40588987)\n\nThe model is also sensitive to when we define the origin of time for the epidemic process. Here, I just took the first point of the time series available, but adding a lag parameter could be attempted.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import math\ndef model_with_lag(N, a, alpha, lag, t):\n    # we enforce N, a and alpha to be positive numbers using min and max functions\n    lag = min(max(lag, -100), 100) # lag must be less than +/- 100 days \n    return max(N, 0) * (1 - math.e ** (min(-a, 0) * (t - lag))) ** max(alpha, 0)\n\ndef model(N, a, alpha, t):\n    return max(N, 0) * (1 - math.e ** (min(-a, 0) * t)) ** max(alpha, 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef model_loss(params):\n#     N, a, alpha, lag = params\n    N, a, alpha = params\n    model_x = []\n    r = 0\n    for t in range(len(df)):\n        r += (model(N, a, alpha, t) - df.iloc[t, 0]) ** 2\n#         r += (math.log(1 + model(N, a, alpha, t)) - math.log(1 + df.iloc[t, 0])) ** 2 \n#         r += (model_with_lag(N, a, alpha, lag, t) - df.iloc[t, 0]) ** 2\n#         print(model(N, a, alpha, t), df.iloc[t, 0])\n    return math.sqrt(r) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we need to explore the 3d parameter space to find a minimum, using gradient descent. There are a number of algorithms to do that in scipy.optimize, I stopped at the first one that seemed to work. Generalized Reduced Gradient as in Excel solver also works.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom scipy.optimize import minimize\nuse_lag_model = False\nif use_lag_model:\n    opt = minimize(model_loss, x0=np.array([200000, 0.05, 15, 0]), method='Nelder-Mead', tol=1e-5).x\nelse:\n    opt = minimize(model_loss, x0=np.array([200000, 0.05, 15]), method='Nelder-Mead', tol=1e-5).x\nopt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib\nimport matplotlib.pyplot as plt\n%matplotlib inline \n\nmodel_x = []\nfor t in range(len(df)):\n    model_x.append([df.index[t], model(*opt, t)])\nmodel_sim = pd.DataFrame(model_x, dtype=int)\nmodel_sim.set_index(0, inplace=True)\nmodel_sim.columns = ['model']\npd.concat([model_sim, df], axis=1).plot()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"let's extend the prediction curve","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime\nstart_date = df.index[0]\nn_days = 210\nextended_model_x = []\nfor t in range(n_days):\n    extended_model_x.append([start_date + datetime.timedelta(days=t), model(*opt, t)])\nextended_model_sim = pd.DataFrame(extended_model_x, dtype=int)\nextended_model_sim.set_index(0, inplace=True)\nextended_model_sim.columns = ['model']\npd.concat([extended_model_sim, df], axis=1).plot()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"let's display predictions for future weeks","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.options.display.float_format = '{:20,.0f}'.format\nconcat_df = pd.concat([df, extended_model_sim], axis=1)\nconcat_df[concat_df.index.day % 7 == 0].astype({'model': 'int32'})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"now let's compare the dynamic in different countries","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def display_fit(df, opt, ax):\n    model_x = []\n    for t in range(len(df)):\n        model_x.append([df.index[t], model(*opt, t)])\n    model_sim = pd.DataFrame(model_x, dtype=int)\n    model_sim.set_index(0, inplace=True)\n    model_sim.columns = ['model']\n    return pd.concat([model_sim, df], axis=1).plot(ax=ax, figsize=(12, 8))\n\ndef display_extended_curve(df, opt, ax):\n    start_date = df.index[0]\n    n_days = 200\n    extended_model_x = []\n    for t in range(n_days):\n        extended_model_x.append([start_date + datetime.timedelta(days=t), model(*opt, t)])\n    extended_model_sim = pd.DataFrame(extended_model_x, dtype=int)\n    extended_model_sim.set_index(0, inplace=True)\n    extended_model_sim.columns = ['model -> ' + str(int(opt[0]))]\n    return pd.concat([extended_model_sim, df], axis=1).plot(ax=ax, figsize=(12, 8))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stats = []\nfor country in full_table['Country/Region'].unique():\n# for country in ['Sweden']:\n    df = get_time_series(country)\n    # only consider countries with at least 5000 cases (plus Sweden)\n    if len(df) == 0 or (max(df['Confirmed']) < 5000 and country != 'Sweden'): \n        continue\n    df.columns = [df.columns[0] + ' ' + country]\n    # if the last data point repeats the previous one, or is lower, drop it\n    if len(df) > 1 and df.iloc[-2,0] >= df.iloc[-1,0]:\n        df.drop(df.tail(1).index,inplace=True)\n#     if country == 'France':\n#         display(df.tail())\n    opt = minimize(model_loss, x0=np.array([200000, 0.05, 15]), method='Nelder-Mead', tol=1e-5).x\n#     print(country, opt)\n    if min(opt) > 0:\n        stats.append([country, *opt])\n        n_plot = len(stats)\n        plt.figure(1)\n        ax1 = plt.subplot(221)\n        display_fit(df, opt, ax1)\n        ax2 = plt.subplot(222)\n        display_extended_curve(df, opt, ax2)\n        plt.show()\nstats_df = pd.DataFrame(stats)\n# stats_df.columns = ['country', 'N', 'a', 'alpha', 'lag']\nstats_df.columns = ['country', 'N', 'a', 'alpha']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"let's see if we can make some sense from the parameters. The N is the projected total number of cases in a given country","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_rows', 500)\npd.options.display.float_format = '{:20,.4f}'.format\nstats_df.astype({'N': 'int'}).sort_values(by='N', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"N is the potential spread in the country if the dynamics since the beginning of the epidemy persist. One problem is that sometimes we're measuring the spread of testing rather than of the epidemy. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = stats_df.plot.scatter(x='alpha', y='a')\n# ax.set_xlim([0, 100])\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}