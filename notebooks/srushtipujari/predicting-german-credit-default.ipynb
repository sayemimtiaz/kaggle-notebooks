{"cells":[{"metadata":{"id":"uOcS5s3VZKFq","colab_type":"text","_uuid":"6f9d55e2cd5792dc66d332ef3ccafde266046ce4"},"cell_type":"markdown","source":"The German Credit data set is a publically available data set downloaded from the UCI Machine Learning Repository. The data contains data on 20 variables and the classification whether an applicant is considered a Good or a Bad credit risk for 1000 loan applicants.\n\n### [Data Source](https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data))\n- Professor Dr. Hans Hofmann  \n- Institut f\"ur Statistik und \"Okonometrie  \n- Universit\"at Hamburg  \n- FB Wirtschaftswissenschaften  \n- Von-Melle-Park 5    \n- 2000 Hamburg 13\n\n### Benchmark\n![Credit Risk Classification: Faster Machine Learning with Intel Optimized Packages](https://i.imgur.com/nL1l7WI.png)\n\naccording to [1] the best model is Random Forest with balanced feature selection data. it's has Accuracy 82%, Precision 84%, Recall 82% and F1-Score 81%. \n\n<br>\n\n\nThe goal of this kernel is to beat The benchmark with  :\n- Convert dataset to Machine Learning friendly (Feature Engginering)\n- Develop XGBoost model to predict whether a loan is a good or bad risk.\n- Find the Best parameter for XGBoost Model (Hyperparameter Tunning)\n- Beat the Benchmark"},{"metadata":{"id":"BFIDjGe8BNiZ","colab_type":"text","_uuid":"12bfcccb8223f3c0039be46a701bff6b3311eb74"},"cell_type":"markdown","source":""},{"metadata":{"id":"kqRSZpTCfG10","colab_type":"text","_uuid":"63a5648103f48c821752a5b1f403dfb477159180"},"cell_type":"markdown","source":"# Table of Content\n\n**1. [Introduction](#Introduction)** <br>\n    - Import Library\n    - Evaluation Function\n    - XGBoost Model\n**2. [Preprocess](#Preprocess)** <br>\n    - Importing Dataset\n    - StandardScaler\n    - Encoding Categorical Feature\n    - Concate Transformed Dataset\n    - Split Training Dataset\n    - XGBoost  1a: Unbalance Dataset (Base Model: ROC_AUC:0.74)\n    - XGBoost  1b: Unbalance Dataset (ROC_AUC:0.79)\n**3. [Balanced Dataset](#Balanced Dataset)** <br>    \n    - XGBoost 2a: Balanced (Base Model: ROC_AUC:0.77)\n    - **XGBoost 2b: Balanced (ROC_AUC:0.80)**\n**4. [Others](#Others)** <br>  \n    - Lighgbm (ROC_AUC:0.73)\n    - LogisticRegression (ROC_AUC:0.77)\n    - RandomForestClassifier (ROC_AUC:0.69)\n    - ExtraTreesClassifier (ROC_AUC:0.74)\n    - DecisionTreeClassifier (ROC_AUC:0.64)\n    - GradientBoostingClassifier (ROC_AUC:0.76)\n    - AdaBoostClassifier (ROC_AUC:0.72)"},{"metadata":{"id":"BwWgAWVLC2Ln","colab_type":"text","_uuid":"afe3100b12ba5779b15f698a1975eaab170742c4"},"cell_type":"markdown","source":"<a id=\"Introduction\"></a> <br>\n# **1. Introduction:** \n- Import Library\n- Evaluation Function\n- XGBoost Model"},{"metadata":{"id":"oZH67UWnA915","colab_type":"text","_uuid":"86c6a56e4b0988d902401370b957f63f4f2754f1"},"cell_type":"markdown","source":"### Import Library"},{"metadata":{"id":"UQUQbCn-LIjR","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"trusted":true,"_uuid":"fa1b3ac82eb8fe1b02d69fab3a10b621f1392484"},"cell_type":"code","source":"#Importing necessary packages in Python \n%matplotlib inline \nimport matplotlib.pyplot as plt \n\nimport numpy as np ; np.random.seed(sum(map(ord, \"aesthetics\")))\nimport pandas as pd\n\nfrom sklearn.datasets import make_classification \nfrom sklearn.learning_curve import learning_curve \n#from sklearn.cross_validation import train_test_split \n#from sklearn.grid_search import GridSearchCV\n#from sklearn.cross_validation import ShuffleSplit\nfrom sklearn.metrics import classification_report,confusion_matrix, roc_curve, roc_auc_score, auc, accuracy_score\nfrom sklearn.model_selection import ShuffleSplit,train_test_split, cross_val_score, GridSearchCV\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder, label_binarize, StandardScaler, MinMaxScaler\n\nimport seaborn \nseaborn.set_context('notebook') \nseaborn.set_style(style='darkgrid')\n\nfrom pprint import pprint \n \n","execution_count":null,"outputs":[]},{"metadata":{"id":"HvfBj0KiBC1m","colab_type":"text","_uuid":"e53977fea8ba2969bb815820b810ae0798f79ff3"},"cell_type":"markdown","source":"### Evaluation Function\n"},{"metadata":{"id":"Y5FAGSW_K_il","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"trusted":true,"_uuid":"ad532098b4568aab69e710aa1b73097b0aeaa56a"},"cell_type":"code","source":"# Function for evaluation reports\ndef get_eval1(clf, X,y):\n    # Cross Validation to test and anticipate overfitting problem\n    scores1 = cross_val_score(clf, X, y, cv=2, scoring='accuracy')\n    scores2 = cross_val_score(clf, X, y, cv=2, scoring='precision')\n    scores3 = cross_val_score(clf, X, y, cv=2, scoring='recall')\n    scores4 = cross_val_score(clf, X, y, cv=2, scoring='roc_auc')\n    \n    # The mean score and standard deviation of the score estimate\n    print(\"Cross Validation Accuracy: %0.2f (+/- %0.2f)\" % (scores1.mean(), scores1.std()))\n    print(\"Cross Validation Precision: %0.2f (+/- %0.2f)\" % (scores2.mean(), scores2.std()))\n    print(\"Cross Validation Recall: %0.2f (+/- %0.2f)\" % (scores3.mean(), scores3.std()))\n    print(\"Cross Validation roc_auc: %0.2f (+/- %0.2f)\" % (scores4.mean(), scores4.std()))\n    \n    return \n\ndef get_eval2(clf, X_train, y_train,X_test, y_test):\n    # Cross Validation to test and anticipate overfitting problem\n    scores1 = cross_val_score(clf, X_test, y_test, cv=2, scoring='accuracy')\n    scores2 = cross_val_score(clf, X_test, y_test, cv=2, scoring='precision')\n    scores3 = cross_val_score(clf, X_test, y_test, cv=2, scoring='recall')\n    scores4 = cross_val_score(clf, X_test, y_test, cv=2, scoring='roc_auc')\n    \n    # The mean score and standard deviation of the score estimate\n    print(\"Cross Validation Accuracy: %0.2f (+/- %0.2f)\" % (scores1.mean(), scores1.std()))\n    print(\"Cross Validation Precision: %0.2f (+/- %0.2f)\" % (scores2.mean(), scores2.std()))\n    print(\"Cross Validation Recall: %0.2f (+/- %0.2f)\" % (scores3.mean(), scores3.std()))\n    print(\"Cross Validation roc_auc: %0.2f (+/- %0.2f)\" % (scores4.mean(), scores4.std()))\n    \n    return  \n  \n# Function to get roc curve\ndef get_roc (y_test,y_pred):\n    # Compute ROC curve and ROC area for each class\n    fpr = dict()\n    tpr = dict()\n    roc_auc = dict()\n    fpr, tpr, _ = roc_curve(y_test, y_pred)\n    roc_auc = auc(fpr, tpr)\n    #Plot of a ROC curve\n    plt.figure()\n    lw = 2\n    plt.plot(fpr, tpr, color='darkorange',\n             label='ROC curve (area = %0.2f)' % roc_auc)\n    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.0])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver operating characteristic')\n    plt.legend(loc=\"upper left\")\n    plt.show()\n    return\n","execution_count":null,"outputs":[]},{"metadata":{"id":"ktQtae8aBGPQ","colab_type":"text","_uuid":"148a2b3cfebaac7674b5bb78496d1cf0266a26cf"},"cell_type":"markdown","source":"#### XGBoost Model"},{"metadata":{"id":"qOM2Y0A8CGN8","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"trusted":true,"_uuid":"a7b80d642ccc18e23b9a0ece9c7f57eca3c67cfd"},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\n#print('XGBoost v',xgb.__version__)\n\n# fit, train and cross validate Decision Tree with training and test data \ndef xgbclf(params, X_train, y_train,X_test, y_test):\n  \n    eval_set=[(X_train, y_train), (X_test, y_test)]\n    \n    model = XGBClassifier(**params).\\\n      fit(X_train, y_train, eval_set=eval_set, \\\n                  eval_metric='auc', early_stopping_rounds = 100, verbose=100)\n        \n    #print(model.best_ntree_limit)\n\n    model.set_params(**{'n_estimators': model.best_ntree_limit})\n    model.fit(X_train, y_train)\n    #print(model,'\\n')\n    \n    # Predict target variables y for test data\n    y_pred = model.predict(X_test, ntree_limit=model.best_ntree_limit) #model.best_iteration\n    #print(y_pred)\n   \n    # Get Cross Validation and Confusion matrix\n    #get_eval(model, X_train, y_train)\n    #get_eval2(model, X_train, y_train,X_test, y_test)\n    \n    # Create and print confusion matrix    \n    abclf_cm = confusion_matrix(y_test,y_pred)\n    print(abclf_cm)\n    \n    #y_pred = model.predict(X_test)\n    print (classification_report(y_test,y_pred) )\n    print ('\\n')\n    print (\"Model Final Generalization Accuracy: %.6f\" %accuracy_score(y_test,y_pred) )\n    \n    # Predict probabilities target variables y for test data\n    y_pred_proba = model.predict_proba(X_test, ntree_limit=model.best_ntree_limit)[:,1] #model.best_iteration\n    get_roc (y_test,y_pred_proba)\n    return model\n\ndef plot_featureImportance(model, keys):\n  importances = model.feature_importances_\n\n  importance_frame = pd.DataFrame({'Importance': list(importances), 'Feature': list(keys)})\n  importance_frame.sort_values(by = 'Importance', inplace = True)\n  importance_frame.tail(10).plot(kind = 'barh', x = 'Feature', figsize = (8,8), color = 'orange')","execution_count":null,"outputs":[]},{"metadata":{"id":"b9VmiiUDCvRV","colab_type":"text","_uuid":"2e8d5ce5e9daf39d851ca53856f640a90156745a"},"cell_type":"markdown","source":"<a id=\"Preprocess\"></a> <br>\n# **2. Preprocess** \n- Importing Dataset\n- StandardScaler\n- Encoding Categorical Feature\n- Concate Transformed Dataset\n- Split Training Dataset\n- XGBoost  1a: Unbalance Dataset (Base Model: ROC_AUC:0.74)\n- XGBoost  1b: Unbalance Dataset (ROC_AUC:0.79)"},{"metadata":{"id":"L4G0iMwfKb4J","colab_type":"text","_uuid":"366cfb21b371f12c5bbf005342de219717fde974"},"cell_type":"markdown","source":"### Import Dataset\n\nOK let's get started. We'll download the data from the UCI website."},{"metadata":{"id":"YYgBTbPj1fbQ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":372},"outputId":"d5569d76-1c4f-432a-a2b7-2b9ceb3e3439","executionInfo":{"status":"ok","timestamp":1531200575113,"user_tz":-420,"elapsed":768,"user":{"displayName":"M Hendra Herviawan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"116685199798904688878"}},"trusted":true,"_uuid":"4807a2a54ddeb7ecb9142b586088ea672103d4ff"},"cell_type":"code","source":"file = '../input/germancreditdata/german.data'\nurl = \"http://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data\"\n\nnames = ['existingchecking', 'duration', 'credithistory', 'purpose', 'creditamount', \n         'savings', 'employmentsince', 'installmentrate', 'statussex', 'otherdebtors', \n         'residencesince', 'property', 'age', 'otherinstallmentplans', 'housing', \n         'existingcredits', 'job', 'peopleliable', 'telephone', 'foreignworker', 'classification']\n\ndata = pd.read_csv(file,names = names, delimiter=' ')\nprint(data.shape)\nprint (data.columns)\ndata.head(10)","execution_count":null,"outputs":[]},{"metadata":{"id":"B3FPJfz33xkK","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":68},"outputId":"9c678580-fb5a-4f2c-a788-676f3fda2d60","executionInfo":{"status":"ok","timestamp":1531189108051,"user_tz":-420,"elapsed":709,"user":{"displayName":"M Hendra Herviawan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"116685199798904688878"}},"trusted":true,"_uuid":"224c2c3967abdccd1e4527c18024e08288ba1ca9"},"cell_type":"code","source":"# Binarize the y output for easier use of e.g. ROC curves -> 0 = 'bad' credit; 1 = 'good' credit\ndata.classification.replace([1,2], [1,0], inplace=True)\n# Print number of 'good' credits (should be 700) and 'bad credits (should be 300)\ndata.classification.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"id":"Tr1A8ZIHzuFw","colab_type":"text","_uuid":"2d2774790c3f63cfc0eaa81517ce8f0eb4680478"},"cell_type":"markdown","source":"### StandardScaler"},{"metadata":{"id":"dKKUEqTo380x","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"trusted":true,"_uuid":"f03a76714ee08fe41f9b59aab287d68d481892b5"},"cell_type":"code","source":"#numerical variables labels\nnumvars = ['creditamount', 'duration', 'installmentrate', 'residencesince', 'age', \n           'existingcredits', 'peopleliable', 'classification']\n\n# Standardization\nnumdata_std = pd.DataFrame(StandardScaler().fit_transform(data[numvars].drop(['classification'], axis=1)))","execution_count":null,"outputs":[]},{"metadata":{"id":"X4ZzfmRy4M9I","colab_type":"text","_uuid":"19dce81fc16194265c5d8942fa81c64934d60855"},"cell_type":"markdown","source":"### Encoding Categorical Feature\n\nLabelencoding to transform categorical to numerical, Enables better Visualization than one hot encoding"},{"metadata":{"id":"xSnUU8E_4IgX","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":459},"outputId":"4325e306-c15b-4130-ee8b-105729ccd053","executionInfo":{"status":"ok","timestamp":1531189110846,"user_tz":-420,"elapsed":621,"user":{"displayName":"M Hendra Herviawan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"116685199798904688878"}},"trusted":true,"_uuid":"dab67695a0984af965a7dbea250276c4369b5875"},"cell_type":"code","source":"from collections import defaultdict\n\n#categorical variables labels\ncatvars = ['existingchecking', 'credithistory', 'purpose', 'savings', 'employmentsince',\n           'statussex', 'otherdebtors', 'property', 'otherinstallmentplans', 'housing', 'job', \n           'telephone', 'foreignworker']\n\nd = defaultdict(LabelEncoder)\n\n# Encoding the variable\nlecatdata = data[catvars].apply(lambda x: d[x.name].fit_transform(x))\n\n# print transformations\nfor x in range(len(catvars)):\n    print(catvars[x],\": \", data[catvars[x]].unique())\n    print(catvars[x],\": \", lecatdata[catvars[x]].unique())\n\n#One hot encoding, create dummy variables for every category of every categorical variable\ndummyvars = pd.get_dummies(data[catvars])","execution_count":null,"outputs":[]},{"metadata":{"id":"R3OBrifU4Zpb","colab_type":"text","_uuid":"6a15498bdd45a6b2d0c88edbe3059744294396c6"},"cell_type":"markdown","source":"### Concate Transformed Dataset\nappend the dummy variable of the initial numerical variables numvars# append "},{"metadata":{"id":"jkncbC1M4ZzD","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":68},"outputId":"4b596160-48a6-40c5-8fd2-2104e3afabe9","executionInfo":{"status":"ok","timestamp":1531189111653,"user_tz":-420,"elapsed":638,"user":{"displayName":"M Hendra Herviawan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"116685199798904688878"}},"trusted":true,"_uuid":"50738e0e4b89a8facc7c73581661f3110427d8e9"},"cell_type":"code","source":"data_clean = pd.concat([data[numvars], dummyvars], axis = 1)\n\nprint(data_clean.shape)","execution_count":null,"outputs":[]},{"metadata":{"id":"OI89YwDN4kXI","colab_type":"text","_uuid":"53f8db9397eeb56dae3d735e712b4ba251a36a7b"},"cell_type":"markdown","source":"### Split Training Dataset"},{"metadata":{"id":"cP6puz7s4hQr","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"trusted":true,"_uuid":"5f1724b5dc93f592481eb1c608553d1c5fad2108"},"cell_type":"code","source":"# Unscaled, unnormalized data\nX_clean = data_clean.drop('classification', axis=1)\ny_clean = data_clean['classification']\nX_train_clean, X_test_clean, y_train_clean, y_test_clean = train_test_split(X_clean,y_clean,test_size=0.2, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"id":"MkEfVz7rgssR","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":340},"outputId":"2545c4f2-9d69-4d50-dc1c-82525586f013","executionInfo":{"status":"ok","timestamp":1531189113358,"user_tz":-420,"elapsed":708,"user":{"displayName":"M Hendra Herviawan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"116685199798904688878"}},"trusted":true,"_uuid":"900557195bd519524bb3d46fb6b3d8d7344692dc"},"cell_type":"code","source":"X_train_clean.keys()","execution_count":null,"outputs":[]},{"metadata":{"id":"3LRHY79JAlbF","colab_type":"text","_uuid":"924ad3aaf8f771939fafab52352598b158d4d9bb"},"cell_type":"markdown","source":"### XGBoost  1a: Unbalance Dataset (Base Model: ROC_AUC:0.74)"},{"metadata":{"id":"trS6OdaaEoKL","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":1039},"outputId":"38c94f83-752e-4e6d-8439-b42692b6f9f1","executionInfo":{"status":"ok","timestamp":1531192485583,"user_tz":-420,"elapsed":1831,"user":{"displayName":"M Hendra Herviawan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"116685199798904688878"}},"trusted":true,"_uuid":"03740b4aa1ec34f7874001fe00f36496a607050b"},"cell_type":"code","source":"params={}\nxgbclf(params, X_train_clean, y_train_clean, X_test_clean, y_test_clean)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"10ebb57456ac4233b77b1ad284c15984aee73a1c"},"cell_type":"markdown","source":"### XGBoost  1b: Unbalance Dataset (ROC_AUC:0.79)"},{"metadata":{"trusted":true,"_uuid":"9b27e5641d57347d244ebc33a634c35a3a8e0947"},"cell_type":"code","source":"params={}\n\nparams1={\n    'n_estimators':3000,\n    'objective': 'binary:logistic',\n    'learning_rate': 0.05,\n    'gamma':0.1,\n    'subsample':0.8,\n    'colsample_bytree':0.3,\n    'min_child_weight':3,\n    'max_depth':3,\n    #'seed':1024,\n    'n_jobs' : -1\n}\n\nparams2={\n    'n_estimators':3000,\n    'objective': 'binary:logistic',\n    'learning_rate': 0.005,\n    #'gamma':0.01,\n    'subsample':0.555,\n    'colsample_bytree':0.7,\n    'min_child_weight':3,\n    'max_depth':8,\n    #'seed':1024,\n    'n_jobs' : -1\n}\n\nxgbclf(params2, X_train_clean, y_train_clean, X_test_clean, y_test_clean)","execution_count":null,"outputs":[]},{"metadata":{"id":"bFxEnRYVD_Xe","colab_type":"text","_uuid":"b14d322c24858a4b4ec4656bd96eb3a1843802e1"},"cell_type":"markdown","source":"<a id=\"Balanced Dataset\"></a> <br>\n# **3. Balanced Dataset** \n- XGBoost 2a: Balanced (Base Model: ROC_AUC:0.77)\n- XGBoost 2b: Balanced (ROC_AUC:0.80)"},{"metadata":{"id":"5NEgnXdM1U0J","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":170},"outputId":"d3404eb4-ed88-46ea-ab18-60b259a22ed2","executionInfo":{"status":"ok","timestamp":1531189121767,"user_tz":-420,"elapsed":664,"user":{"displayName":"M Hendra Herviawan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"116685199798904688878"}},"trusted":true,"_uuid":"bfba5a9de83536e8ee9635d98339dfd33b7d657a"},"cell_type":"code","source":"\nfrom imblearn.over_sampling import SMOTE\n\n# Oversampling\n# http://contrib.scikit-learn.org/imbalanced-learn/auto_examples/combine/plot_smote_enn.html#sphx-glr-auto-examples-combine-plot-smote-enn-py\n\n# Apply SMOTE\nsm = SMOTE(ratio='auto')\nX_train_clean_res, y_train_clean_res = sm.fit_sample(X_train_clean, y_train_clean)\n\n# Print number of 'good' credits and 'bad credits, should be fairly balanced now\nprint(\"Before/After clean\")\nunique, counts = np.unique(y_train_clean, return_counts=True)\nprint(dict(zip(unique, counts)))\nunique, counts = np.unique(y_train_clean_res, return_counts=True)\nprint(dict(zip(unique, counts)))","execution_count":null,"outputs":[]},{"metadata":{"id":"h2-muneU1U9H","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"trusted":true,"_uuid":"b8a7a3c79685af31aecb2ade360415f92a30460b"},"cell_type":"code","source":"#Great, before we do anything else, let's split the data into train/test.\nX_train_clean_res = pd.DataFrame(X_train_clean_res, columns=X_train_clean.keys())\n#y_train_clean_res = pd.DataFrame(y_train_clean_res)","execution_count":null,"outputs":[]},{"metadata":{"id":"C-yIxVQkUZyW","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":85},"outputId":"ae623e97-04e8-4417-8311-3da47f9b94e3","executionInfo":{"status":"ok","timestamp":1531189123494,"user_tz":-420,"elapsed":695,"user":{"displayName":"M Hendra Herviawan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"116685199798904688878"}},"trusted":true,"_uuid":"3a8b147901159dc4ac09fa2efd4d5d9578f97b99"},"cell_type":"code","source":"print(np.shape(X_train_clean_res))\nprint(np.shape(y_train_clean_res))\nprint(np.shape(X_test_clean)) \nprint(np.shape(y_test_clean))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"04626b0c29b5a77a013fedfee30b55b4d92b684b"},"cell_type":"markdown","source":"### XGBoost 2a: Balanced (Base Model: ROC_AUC:0.77)"},{"metadata":{"id":"NQ5P5oG0IwIS","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":886},"outputId":"3f402469-f7d9-496d-e772-059ef4ef0aec","executionInfo":{"status":"ok","timestamp":1531189328790,"user_tz":-420,"elapsed":1321,"user":{"displayName":"M Hendra Herviawan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"116685199798904688878"}},"trusted":true,"_uuid":"ca524e248c28f147289605a30f68b11ecabe4559"},"cell_type":"code","source":"#BASE MODEL\nparams={}\nxgbclf(params,X_train_clean_res, y_train_clean_res,X_test_clean, y_test_clean)","execution_count":null,"outputs":[]},{"metadata":{"id":"RjlSw9En1P4p","colab_type":"text","_uuid":"71a3040a7d73bfa3aba166e10d804f9257d8bde8"},"cell_type":"markdown","source":"### XGBoost 2b: Balanced (ROC_AUC:0.80)"},{"metadata":{"id":"x9PHpLlJoNFz","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":1403},"outputId":"ed2910d2-4508-49d9-d1be-575c07625fb6","executionInfo":{"status":"ok","timestamp":1531192901612,"user_tz":-420,"elapsed":2539,"user":{"displayName":"M Hendra Herviawan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"116685199798904688878"}},"trusted":true,"_uuid":"11855f908fb13b97d120ea375c75ab13885d9e43"},"cell_type":"code","source":"params = {}\n\nparams1={\n    'n_estimators':3000,\n    'objective': 'binary:logistic',\n    'learning_rate': 0.05,\n    'gamma':0.1,\n    'subsample':0.8,\n    'colsample_bytree':0.3,\n    'min_child_weight':3,\n    'max_depth':3,\n    #'seed':1024,\n    'n_jobs' : -1\n}\n\nparams2={\n    'n_estimators':3000,\n    'objective': 'binary:logistic',\n    'learning_rate': 0.005,\n    #'gamma':0.01,\n    'subsample':0.555,\n    'colsample_bytree':0.7,\n    'min_child_weight':3,\n    'max_depth':8,\n    #'seed':1024,\n    'n_jobs' : -1\n}\n\n#xgbclf(params, X_train, y_train,X_test,y_test)\nmodel = xgbclf(params2,X_train_clean_res, y_train_clean_res,X_test_clean, y_test_clean)\nmodel\n#plot_featureImportance(model, X_train_clean_res.keys())","execution_count":null,"outputs":[]},{"metadata":{"id":"T0uGUXyUa4h_","colab_type":"text","_uuid":"518227609cbeb12fa67390bd5a097ddc7bd2f71a"},"cell_type":"markdown","source":"# 4.  Feature Selection\n- XGBoost3 (Base Model:ROC_AUC:0.73)\n- GridSearchCV (ROC_AUC:0.70)"},{"metadata":{"id":"vOISYxySN4qJ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"trusted":true,"_uuid":"c9da497ba8de093a285cf4ffbec4535219c74466"},"cell_type":"code","source":"#model = xgbclf(params1,X_train_clean_res[importance_col], y_train_clean_res,X_test_clean[importance_col], y_test_clean)\n\nimportances = model.feature_importances_\nimportance_frame = pd.DataFrame({'Importance': list(importances), 'Feature': list(X_train_clean_res.keys())})\nimportance_frame.sort_values(by = 'Importance', inplace = True, ascending=False)\nimportance_col = importance_frame.Feature.head(10).values","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a2ce51442a79c7a28776f90153e4107737183abd"},"cell_type":"markdown","source":"### XGBoost3 (Base Model:ROC_AUC:0.73)"},{"metadata":{"id":"LwqK7dpAX7nn","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":1056},"outputId":"e4689e0c-52b0-476a-b84c-e47da4028a37","executionInfo":{"status":"ok","timestamp":1531195815598,"user_tz":-420,"elapsed":1923,"user":{"displayName":"M Hendra Herviawan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"116685199798904688878"}},"trusted":true,"_uuid":"17ef3ab68a22b1af2a31b58e0a452a72e0db19bd"},"cell_type":"code","source":"params = {}\n\nparams1={\n    'n_estimators':3000,\n    'objective': 'binary:logistic',\n    'learning_rate': 0.01,\n    #'gamma':0.1,\n    #'subsample':0.8,\n    #'colsample_bytree':0.3,\n    #'min_child_weight':3,\n    'max_depth':3,\n    #'seed':1024,\n    'n_jobs' : -1\n}\n\nxgbclf(params,X_train_clean_res[importance_col], y_train_clean_res,X_test_clean[importance_col], y_test_clean)","execution_count":null,"outputs":[]},{"metadata":{"id":"Wxgbu6HbrstB","colab_type":"text","_uuid":"f8037e33ee37292b23413304ceff57026c6b49e1"},"cell_type":"markdown","source":"### GridSearchCV (ROC_AUC:0.70)"},{"metadata":{"id":"m7lf_As9oUvh","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":187},"outputId":"6ff51851-0fe9-4c53-c5cf-315fa84143e4","executionInfo":{"status":"ok","timestamp":1531196561870,"user_tz":-420,"elapsed":3066,"user":{"displayName":"M Hendra Herviawan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"116685199798904688878"}},"trusted":true,"_uuid":"105346b26c0fe9e4cba1b68b6194be9d70b50701"},"cell_type":"code","source":"from sklearn.grid_search import GridSearchCV\n\nprint('XGBoost with grid search')\n# play with these params\nparams={\n    'learning_rate': [0.01, 0.02],\n    'max_depth': [3], # 5 is good but takes too long in kaggle env\n    #'subsample': [0.6], #[0.4,0.5,0.6,0.7,0.8,0.9,1.0],\n    #'colsample_bytree': [0.5], #[0.5,0.6,0.7,0.8],\n    'n_estimators': [50, 100, 200, 300, 400, 500]\n    #'reg_alpha': [0.03] #[0.01, 0.02, 0.03, 0.04]\n}\n\n\nxgb_clf = xgb.XGBClassifier()\n\nrs = GridSearchCV(xgb_clf,\n                  params,\n                  cv=2,\n                  scoring=\"roc_auc\",\n                  n_jobs=1,\n                  verbose=False)\nrs.fit(X_train_clean_res[importance_col], y_train_clean_res)\nbest_est = rs.best_estimator_\nprint(best_est)\nprint(rs.best_score_)\n\n# Roc AUC with test data\nprint(rs.score(X_test_clean[importance_col],y_test_clean))\n\n# Roc AUC with all train data\n#y_pred_proba = best_est.predict_proba(X_test_clean[importance_col])[:,1]\n#print(\"Roc AUC: \", roc_auc_score(y_test_clean, y_pred_proba))\n\n#xgbclf(params1,X_train_clean_res[importance_col], y_train_clean_res,X_test_clean[importance_col], y_test_clean)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d2fe0b7ea9b605569bdfa60b39faf7d6965bfde0"},"cell_type":"markdown","source":"<a id=\"Others\"></a> <br>\n# 5. Others\n- Lighgbm (ROC_AUC:0.73)\n- LogisticRegression (ROC_AUC:0.77)\n- RandomForestClassifier (ROC_AUC:0.69)\n- ExtraTreesClassifier (ROC_AUC:0.74)\n- DecisionTreeClassifier (ROC_AUC:0.64)\n- GradientBoostingClassifier (ROC_AUC:0.76)\n- AdaBoostClassifier (ROC_AUC:0.72)"},{"metadata":{"id":"Pce2PcrQryuY","colab_type":"text","_uuid":"360450a8797f752a9d9b09a4c4a16d72dbe0b071"},"cell_type":"markdown","source":"### Lighgbm (ROC_AUC:0.73)"},{"metadata":{"trusted":true,"_uuid":"432aa50546f660ed1ae9b4ab064bbea7b6f54e03"},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n\nimport lightgbm as lgb\n\n# fit, train and cross validate Decision Tree with training and test data \ndef lgbclf(X_train, y_train,X_test, y_test):\n\n    model = lgb.LGBMClassifier().fit(X_train, y_train)\n    print(model,'\\n')\n\n    # Predict target variables y for test data\n    y_pred = model.predict_proba(X_test)[:,1]\n\n    # Get Cross Validation and Confusion matrix\n    #get_eval(model, X_train, y_train,y_test,y_pred)\n    #get_eval2(model, X_train, y_train,X_test, y_test,y_pred)\n    get_roc (y_test,y_pred)\n    return\n\n# Logistic Regression\n#lgbclf(X_train, y_train,X_test,y_test)\nlgbclf(X_train_clean_res, y_train_clean_res,X_test_clean, y_test_clean)","execution_count":null,"outputs":[]},{"metadata":{"id":"tzhgWR1hry3s","colab_type":"text","_uuid":"318b9364794e6f1e2da5550bf961885bdccc5825"},"cell_type":"markdown","source":"### LogisticRegression (ROC_AUC:0.77)"},{"metadata":{"trusted":true,"_uuid":"e0b612a0bab5b2f06e038f37b35868716f97bd00"},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\n# fit, train and cross validate Decision Tree with training and test data \ndef logregclf(X_train, y_train,X_test, y_test):\n    print(\"LogisticRegression\")\n    model = LogisticRegression().fit(X_train, y_train)\n    print(model,'\\n')\n\n    # Predict target variables y for test data\n    y_pred = model.predict_proba(X_test)[:,1]\n\n    # Get Cross Validation and Confusion matrix\n    #get_eval(model, X_train, y_train,y_test,y_pred)\n    #get_eval2(model, X_train, y_train,X_test, y_test,y_pred)\n    get_roc (y_test,y_pred)\n    return\n\n# Logistic Regression\n#logregclf(X_train, y_train,X_test,y_test)\nlogregclf(X_train_clean_res, y_train_clean_res,X_test_clean, y_test_clean)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e95e51b587054a97daf75be89cd308b615feb8ca"},"cell_type":"markdown","source":"### RandomForestClassifier (ROC_AUC:0.69)"},{"metadata":{"trusted":true,"_uuid":"4b9f601bd07ff3253da4d89352ebd785fc3eeac2"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier \n\n# fit, train and cross validate Decision Tree with training and test data \ndef randomforestclf(X_train, y_train,X_test, y_test):\n    print(\"RandomForestClassifier\")\n    randomforest = RandomForestClassifier().fit(X_train, y_train)\n    print(randomforest,'\\n')\n    \n    # Predict target variables y for test data\n    y_pred = randomforest.predict_proba(X_test)[:,1]\n\n    # Get Cross Validation and Confusion matrix\n    #get_eval(randomforest, X_train, y_train,y_test,y_pred)\n    get_roc (y_test,y_pred)\n    return randomforest\n\n# Random Forest\n# Choose clean data, as tree is robust\nrf = randomforestclf(X_train_clean_res, y_train_clean_res,X_test_clean, y_test_clean)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"75fb46bd9b0ac1493449c6451b2f8a85974d4f86"},"cell_type":"markdown","source":"### ExtraTreesClassifier (ROC_AUC:0.74)"},{"metadata":{"trusted":true,"_uuid":"28df42b00dedfda6ffcfb8235ff0ad2ef42a4bec"},"cell_type":"code","source":"from sklearn.ensemble import ExtraTreesClassifier\n\n# fit, train and cross validate Decision Tree with training and test data \ndef extratreesclf(X_train, y_train,X_test, y_test):\n    print(\"ExtraTreesClassifier\")\n    extratrees = ExtraTreesClassifier().fit(X_train, y_train)\n    print(extratrees,'\\n')\n    \n    # Predict target variables y for test data\n    y_pred = extratrees.predict_proba(X_test)[:,1]\n\n    # Get Cross Validation and Confusion matrix\n    #get_eval(extratrees, X_train, y_train,y_test,y_pred)\n    \n    get_roc (y_test,y_pred)\n    return\n \n# Extra Trees\n# Choose clean data, as tree is robust\nextratreesclf(X_train_clean_res, y_train_clean_res,X_test_clean, y_test_clean)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d08be5c932aa326666c8865f5c1ce15f5f7984b4"},"cell_type":"markdown","source":"### DecisionTreeClassifier (ROC_AUC:0.64)"},{"metadata":{"trusted":true,"_uuid":"07c8334d26469b64ded21db507d7d246d0ba05f6"},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier \n# fit, train and cross validate Decision Tree with training and test data \ndef dectreeclf(X_train, y_train,X_test, y_test):\n    print(\"DecisionTreeClassifier\")\n    dec_tree = DecisionTreeClassifier(min_samples_split=10,min_samples_leaf=5).fit(X_train, y_train)\n    print(dec_tree,'\\n')\n    \n    # Predict target variables y for test data\n    y_pred = dec_tree.predict_proba(X_test)[:,1]\n\n    \n    # Get Cross Validation and Confusion matrix\n    #get_eval(dec_tree, X_train, y_train,y_test,y_pred)\n    get_roc (y_test,y_pred)\n    return\n\n# Decisiontree\ndectreeclf(X_train_clean_res, y_train_clean_res,X_test_clean, y_test_clean)","execution_count":null,"outputs":[]},{"metadata":{"id":"nA3tHbQDry_f","colab_type":"text","_uuid":"4ed9e0b8545196403507dde0a878ba1a5f7cc604"},"cell_type":"markdown","source":"### GradientBoostingClassifier (ROC_AUC:0.76)"},{"metadata":{"id":"JjxG_CYtekIA","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":648},"outputId":"42c5bdfd-94d2-47fd-e82b-7a9a5e664528","executionInfo":{"status":"ok","timestamp":1530921188337,"user_tz":-420,"elapsed":5896,"user":{"displayName":"M Hendra Herviawan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"116685199798904688878"}},"trusted":true,"_uuid":"72b88670afd0ba8487d1a3a98bbecde61427aa4f"},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\n\n# fit, train and cross validate GradientBoostingClassifier with training and test data \ndef gradientboostingclf(X_train, y_train, X_test, y_test):  \n    print(\"GradientBoostingClassifier\")\n    gbclf = GradientBoostingClassifier().fit(X_train, y_train)\n    print(gbclf,'\\n')\n    \n    # Predict target variables y for test data\n    y_pred = gbclf.predict_proba(X_test)[:,1]\n\n    # Get Cross Validation and Confusion matrix\n    #get_eval(gbclf, X_train, y_train,y_test,y_pred)\n    get_roc (y_test,y_pred)\n    return\n  \n# GradientBoostingClassifier\n# Choose clean data, as tree is robust\ngradientboostingclf(X_train_clean_res, y_train_clean_res,X_test_clean, y_test_clean)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e2d254a8b7a76f3fcd3f98277a52989c5df7d0c2"},"cell_type":"markdown","source":"### AdaBoostClassifier (ROC_AUC:0.75)"},{"metadata":{"id":"wdN9GgUUetH1","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":546},"outputId":"127b3cf9-a597-4d63-f296-b4ceeb0d6a19","executionInfo":{"status":"ok","timestamp":1530921206830,"user_tz":-420,"elapsed":4970,"user":{"displayName":"M Hendra Herviawan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"116685199798904688878"}},"trusted":true,"_uuid":"c8caa356aa7993faa1bd77afafd858b7f95e18b8"},"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\n\n# fit, train and cross validate GradientBoostingClassifier with training and test data \ndef adaboostclf(X_train, y_train, X_test, y_test):  \n    print(\"AdaBoostClassifier\")\n    abclf = AdaBoostClassifier().fit(X_train, y_train)\n    print(abclf,'\\n')\n    \n    # Predict target variables y for test data\n    y_pred = abclf.predict_proba(X_test)[:,1]\n\n    # Get Cross Validation and Confusion matrix\n    #get_eval(abclf, X_train, y_train,y_test,y_pred)\n    get_roc (y_test,y_pred)\n    return\n\n# AdaBoostClassifier\n# Choose clean data, as tree is robust\nadaboostclf(X_train_clean_res, y_train_clean_res,X_test_clean, y_test_clean)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import eli5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\nxgc = xgb.XGBClassifier(n_estimators=500, max_depth=5, base_score=0.5,\n                        objective='binary:logistic', random_state=42)\nxgc.fit(X_train_clean_res, y_train_clean_res)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_preds = xgc.predict(X_test_clean)\nfrom sklearn import metrics\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import mean_squared_error\nmetrics.accuracy_score(y_test_clean,y_preds)\nprint(\"confusion matrix=\",metrics.confusion_matrix(y_test_clean,y_preds))\nprint(\"classification report=\\n\",classification_report(y_test_clean,y_preds))\nprint(\"accuracy=\",metrics.accuracy_score(y_test_clean,y_preds))\nprint(\"mean squared error=\",mean_squared_error(y_test_clean, y_preds))\nprint(\"roc_auc score is=\",roc_auc_score(y_test_clean, y_preds))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize = (16, 12))\ntitle = fig.suptitle(\"Default Feature Importances from XGBoost\", fontsize=14)\n\nax1 = fig.add_subplot(2,2, 1)\nxgb.plot_importance(xgc, importance_type='weight', ax=ax1, max_num_features=20)\nt=ax1.set_title(\"Feature Importance - Feature Weight\")\n\nax2 = fig.add_subplot(2,2, 2)\nxgb.plot_importance(xgc, importance_type='gain', ax=ax2, max_num_features=20)\nt=ax2.set_title(\"Feature Importance - Split Mean Gain\")\n\nax3 = fig.add_subplot(2,2, 3)\nxgb.plot_importance(xgc, importance_type='cover', ax=ax3, max_num_features=20)\nt=ax3.set_title(\"Feature Importance - Sample Coverage\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import eli5\n\neli5.show_weights(xgc.get_booster())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test_clean.iloc[3]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ndoc_num = 2\nprint('Actual Label:', y_test_clean.iloc[doc_num])\nprint('Predicted Label:', y_preds[doc_num])\neli5.show_prediction(xgc.get_booster(), X_test_clean.iloc[doc_num], \n                     feature_names=list(X_test_clean.columns),\n                     show_feature_values=True)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test_clean.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndoc_num = 3\nprint('Actual Label:', y_test_clean.iloc[doc_num])\nprint('Predicted Label:', y_preds[doc_num])\neli5.show_prediction(xgc.get_booster(), X_test_clean.iloc[doc_num], \n                     feature_names=list(X_test_clean.columns),\n                     show_feature_values=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nfrom pdpbox import pdp, get_dataset, info_plots\n\ndef plot_pdp(model, df, feature, cluster_flag=False, nb_clusters=None, lines_flag=False):\n    \n    # Create the data that we will plot\n    pdp_goals = pdp.pdp_isolate(model=model, dataset=df, model_features=df.columns.tolist(), feature=feature)\n\n    # plot it\n    pdp.pdp_plot(pdp_goals, feature, cluster=cluster_flag, n_cluster_centers=nb_clusters, plot_lines=lines_flag)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n# plot the PD univariate plot\nplot_pdp(xgc, X_train_clean_res, 'creditamount')\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_pdp(xgc, X_train_clean_res, 'age')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_pdp(xgc, X_train_clean_res, 'duration')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import shap\n\n# load JS visualization code to notebook\nshap.initjs()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"explainer = shap.TreeExplainer(xgc)\nshap_values = explainer.shap_values(X_test_clean)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_shap = pd.DataFrame(shap_values)\nX_shap.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Expected Value: ', explainer.expected_value)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shap.summary_plot(shap_values, X_test_clean, plot_type=\"bar\", color='blue')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shap.summary_plot(shap_values, X_test_clean)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import lime\nimport lime.lime_tabular\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_features = np.argwhere(np.array([len(set(X_train_clean_res.values[:,x]))\nfor x in range(X_train_clean_res.values.shape[1])]) <= 10).flatten()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"explainer = lime.lime_tabular.LimeTabularExplainer(X_train_clean_res.values, \n                                                   feature_names=X_train_clean_res.columns.values.tolist(), \n                                                   categorical_features=categorical_features, \n                                                   verbose=True, mode='regression')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ni = 2\n \nexp = explainer.explain_instance(X_test_clean.iloc[i], rf.predict, num_features=5)\nexp.show_in_notebook(show_table=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i = 3\n \nexp = explainer.explain_instance(X_test_clean.iloc[i], rf.predict, num_features=5)\nexp.show_in_notebook(show_table=True)\n","execution_count":null,"outputs":[]}],"metadata":{"colab":{"name":"german-credit_XGB1.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}