{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport math\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nmatplotlib.style.use('ggplot')\n\n%matplotlib inline\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\n# print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# read in data\ndf_cwur = pd.read_csv('../input/cwurData.csv')\ndf_expend = pd.read_csv('../input/education_expenditure_supplementary_data.csv', sep=None)\ndf_attain = pd.read_csv('../input/educational_attainment_supplementary_data.csv', sep=None)\ndf_sac = pd.read_csv('../input/school_and_country_table.csv')\ndf_shanghai = pd.read_csv('../input/shanghaiData.csv')\ndf_times = pd.read_csv('../input/timesData.csv')\n\n# adding country data to the shanghai dataset\ndf_sac.columns = ['university_name','country']\ndf_shanghai = df_shanghai.merge(df_sac, how='left', on='university_name')\n\n# updating column name in cwur for consistency\ndf_cwur = df_cwur.rename(columns = {'institution':'university_name'})\n\n# updating country names in cwur for consistency\ndf_cwur.drop('country', inplace=True, axis=1)\ndf_cwur = df_cwur.merge(df_sac, how='left', on='university_name')\n\n# combine the 3 ranking dataframes into one dataframe\nfor df, l in [(df_times,'t'), (df_cwur,'c'), (df_shanghai,'s')]:\n    a = []\n    for col in df.columns.values:\n        if col not in ['university_name','year']:\n            a.append(l + '_' + col)\n        else:\n            a.append(col)\n    df.columns = a\n\ndf_full = df_times.merge(df_cwur, how='outer', on=['university_name','year'])\ndf_full = df_full.merge(df_shanghai, how='outer', on=['university_name','year'])"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# creating a dataframe that specifically looks at the rankings\ndf_ranks = df_full[['university_name','t_country','year','t_world_rank','c_world_rank',\n                    's_world_rank']].copy()\n\n# convert world rank columns to float (where necessary)\nf = lambda x: int((int(x.split('-')[0]) + int(x.split('-')[1])) / 2) if len(str(x).strip()) > 3 else x\n\ndf_ranks['t_world_rank'] = df_ranks['t_world_rank'].str.replace('=','').map(\n    f).astype('float')\n\ndf_ranks['s_world_rank'] = df_ranks['s_world_rank'].str.replace('=','').map(\n    f).astype('float')\n\ndf_ranks.dtypes"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# note that data is available in all datasets in 2012 - 2015\n# let's investigate 2015\ndf_ranks2015 = df_ranks[df_ranks.year == 2015].copy()\n\n# adding min_rank column to show the best rank for each school\ndef f(x):\n    a = []\n    for i in ['t_world_rank','s_world_rank','c_world_rank']:\n        try: \n            if x[i] == float(x[i]):\n                a.append(x[i])\n        except:\n            pass\n    return min(a)\n\ndf_ranks2015['min_rank'] = df_ranks2015.apply(f,axis=1)\n\n# adding average rank column\ndf_ranks2015['mean_rank'] = df_ranks2015.apply(lambda x: np.mean(\n    [x['s_world_rank'],x['t_world_rank'],x['c_world_rank']]).round(), axis=1)\n\n# adding standard deviation column\ndf_ranks2015['std_dev'] = df_ranks2015.apply(lambda x: np.std(\n        [x['s_world_rank'],x['t_world_rank'],x['c_world_rank']]), axis=1)\n\n# plot highest variance in schools that have at least one rank in the top 100\ndf_ranks2015[df_ranks2015['min_rank'] <=100].sort_values('std_dev',ascending=False)[0:10].iloc[::-1].plot(\n    x='university_name',y='std_dev',kind='barh', figsize=(12,6), fontsize=14,\n    title='Top 100 schools with the highest standard deviation in ranking')\n\nprint(df_ranks2015[df_ranks2015['min_rank'] <=100].sort_values('std_dev',ascending=False).drop(\n        't_country',axis=1)[0:10])"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# plot lowest variance in schools that have at least one rank in the top 100\ndf_ranks2015[df_ranks2015['min_rank'] <=100].sort_values('std_dev',ascending=True)[0:10].iloc[::-1].plot(\n    x='university_name',y='std_dev',kind='barh', figsize=(12,6), fontsize=14,\n    title='Top 100 schools with the lowest standard deviation in ranking')\n\nprint(df_ranks2015[df_ranks2015['min_rank'] <=100].sort_values('std_dev',ascending=True).drop(\n        't_country',axis=1)[0:10])"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# how do ratings change over time?\n# note rankings are only available for all 3 in years 2012-2015\ndf_rankstime = df_ranks[(df_ranks['year'] <=2015) & (df_ranks['year'] >= 2012)]\n\n# times rankings\ndf_tranks = df_rankstime.pivot('university_name','year','t_world_rank').reset_index()\ndf_tranks.columns = ['university_name','2012','2013','2014','2015']\ndf_tranks['std_dev'] = df_tranks.apply(lambda x: np.std(\n            [x['2012'],x['2013'],x['2014'],x['2015']]),axis=1)\ndf_tranks['mean'] = df_tranks.apply(lambda x: np.mean(\n            [x['2012'],x['2013'],x['2014'],x['2015']]),axis=1)\n\n# cwur rankings\ndf_cranks = df_rankstime.pivot('university_name','year','c_world_rank').reset_index()\ndf_cranks.columns = ['university_name','2012','2013','2014','2015']\ndf_cranks['std_dev'] = df_cranks.apply(lambda x: np.std(\n            [x['2012'],x['2013'],x['2014'],x['2015']]),axis=1)\ndf_cranks['mean'] = df_cranks.apply(lambda x: np.mean(\n            [x['2012'],x['2013'],x['2014'],x['2015']]),axis=1)\n\n# shanghai rankings\ndf_sranks = df_rankstime.pivot('university_name','year','s_world_rank').reset_index()\ndf_sranks.columns = ['university_name','2012','2013','2014','2015']\ndf_sranks['std_dev'] = df_sranks.apply(lambda x: np.std(\n            [x['2012'],x['2013'],x['2014'],x['2015']]),axis=1)\ndf_sranks['mean'] = df_sranks.apply(lambda x: np.mean(\n            [x['2012'],x['2013'],x['2014'],x['2015']]),axis=1)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"df_tranks[df_tranks['mean'] <= 100].sort_values('std_dev',ascending=False)[0:10].iloc[::-1].plot(\n    x='university_name',y='std_dev',kind='barh', figsize=(12,6), fontsize=14,\n    title='Top 100 schools with the highest standard deviation in times ranking (2012-2015)')"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"df_cranks[df_cranks['mean'] <= 100].sort_values('std_dev',ascending=False)[0:10].iloc[::-1].plot(\n    x='university_name',y='std_dev',kind='barh', figsize=(12,6), fontsize=14,\n    title='Top 100 schools with the highest standard deviation in CWUR ranking (2012-2015)')"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"df_sranks[df_sranks['mean'] <= 100].sort_values('std_dev',ascending=False)[0:10].iloc[::-1].plot(\n    x='university_name',y='std_dev',kind='barh', figsize=(12,6), fontsize=14,\n    title='Top 100 schools with the highest standard deviation in Shanghai ranking (2012-2015)')"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# which ranking was the most consistent for the top 100 schools?\nprint('Which ranking was the most consistent from 2012-2015 for the top 100 schools?')\nprint('\\n')\nprint('Below is the standard deviation for the top 100 schools from each ranking','\\n')\nprint('Times:', round(df_tranks[df_tranks['mean'] <= 100]['std_dev'].mean(),2))\nprint('CWUR:', round(df_cranks[df_cranks['mean'] <= 100]['std_dev'].mean(),2))\nprint('Shanghai:', round(df_sranks[df_sranks['mean'] <= 100]['std_dev'].mean(),2))\nprint('\\n')\nprint('The Shanghai ranking was substantially more consistent than the other two rankings. This suggests',\n      'that the Shanghai ranking is less prone to shaking up rankings just for attention.')"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}