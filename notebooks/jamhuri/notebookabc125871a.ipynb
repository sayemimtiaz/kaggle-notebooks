{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Kecenderungan Pembelajaran Mesin","metadata":{}},{"cell_type":"code","source":"# !pip install plotly\n# !pip install cufflinks\n# !pip install chart-studio","metadata":{"execution":{"iopub.status.busy":"2021-09-07T03:27:55.918701Z","iopub.execute_input":"2021-09-07T03:27:55.91929Z","iopub.status.idle":"2021-09-07T03:27:55.923716Z","shell.execute_reply.started":"2021-09-07T03:27:55.919203Z","shell.execute_reply":"2021-09-07T03:27:55.922516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## import libraries \n\nfrom collections import Counter \nimport pandas as pd \nimport numpy as np \nimport string \n\nfrom plotly.offline import init_notebook_mode, iplot\nimport plotly.graph_objs as go\nimport matplotlib.pyplot as plt\nimport plotly.plotly as py\n\n# import chart_studio.plotly as py\n\nfrom plotly import tools\nimport seaborn as sns\ninit_notebook_mode(connected=True)\nfrom itertools import zip_longest\nimport string \nimport re\n\nfrom nltk.corpus import stopwords \nfrom nltk.util import ngrams\nimport nltk ","metadata":{"execution":{"iopub.status.busy":"2021-09-07T03:27:55.9261Z","iopub.execute_input":"2021-09-07T03:27:55.92663Z","iopub.status.idle":"2021-09-07T03:27:56.127158Z","shell.execute_reply.started":"2021-09-07T03:27:55.926597Z","shell.execute_reply":"2021-09-07T03:27:56.125471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stopwords = stopwords.words('english')","metadata":{"execution":{"iopub.status.busy":"2021-09-07T03:27:56.128111Z","iopub.status.idle":"2021-09-07T03:27:56.128667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## dataset preparation\nmessages = pd.read_csv(\"../input/ForumMessages.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-09-07T03:27:56.129482Z","iopub.status.idle":"2021-09-07T03:27:56.12998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"messages.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-07T03:27:56.130755Z","iopub.status.idle":"2021-09-07T03:27:56.131275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"messages.info()","metadata":{"execution":{"iopub.status.busy":"2021-09-07T03:27:56.132021Z","iopub.status.idle":"2021-09-07T03:27:56.132593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"messages['CreationDate'] = pd.to_datetime(messages['PostDate'])\nmessages['CreationYear'] = messages['CreationDate'].dt.year\nmessages['CreationMonth'] = messages['CreationDate'].dt.month\nmessages['CreationMonth'] = messages['CreationMonth'].apply(lambda x : \"0\"+str(x) if len(str(x)) < 2 else x)\nmessages['CreationDay'] = \"29\"\nmessages['KernelDate'] = messages[\"CreationYear\"].astype(str) +\"-\"+ messages[\"CreationMonth\"].astype(str) +\"-\"+ messages[\"CreationDay\"].astype(str)\nmessages['Message'] = messages['Message'].fillna(\" \")\n\n## function to remove html entities from text\ndef striphtml(data):\n    p = re.compile(r'<.*?>')\n    return p.sub('', data)\n\n## function to clean a text\ndef clntxt(text):\n    text = text.lower()\n    text = striphtml(text)\n    text = \" \".join([c for c in text.split() if c not in stopwords])\n    for c in string.punctuation:\n        text = text.replace(c, \" \")\n    text = \" \".join([c for c in text.split() if c not in stopwords])\n    \n    words = []\n    ignorewords = [\"&nbsp;\", \"quot\", \"quote\", \"www\", \"http\", \"com\"]\n    for wrd in text.split():\n        if len(wrd) <= 2: \n            continue\n        if wrd in ignorewords:\n            continue\n        words.append(wrd)\n    text = \" \".join(words)    \n    return text\n\n## function to get top ngrams for a given year\ndef get_top_ngrams(yr, n, limit):\n    # get relevant text\n    temp = messages[messages['CreationYear'] == yr]\n    text = \" \".join(temp['Message']).lower()\n    \n    # cleaning\n    text = striphtml(text)\n    text = \" \".join([c for c in text.split() if c not in stopwords])\n    for c in string.punctuation:\n        text = text.replace(c, \" \")\n    text = \" \".join([c for c in text.split() if c not in stopwords])\n    \n    # ignore \n    words = []\n    ignorewords = [\"&nbsp;\", \"quot\", \"quote\", \"www\", \"http\", \"com\"]\n    for wrd in text.split():\n        if len(wrd) <= 2: \n            continue\n        if wrd in ignorewords:\n            continue\n        words.append(wrd)\n    text = \" \".join(words)\n    \n    # tokenize\n    token = nltk.word_tokenize(text)\n    grams = ngrams(token, n)\n    grams = [\" \".join(c) for c in grams]\n    return dict(Counter(grams).most_common(limit))\n\ndef check_presence(txt, wrds):    \n    cnt = 0\n    txt = \" \"+txt+\" \"\n    for wrd in wrds.split(\"|\"):\n        if \" \"+wrd+\" \" in txt:\n            cnt += 1 \n    return cnt\n\nmessages['CMessage'] = messages['Message'].apply(lambda x : clntxt(x))\n\nmessages['CreationDay'] = \"21\"\nmessages['KernelDate'] = messages[\"CreationYear\"].astype(str) +\"-\"+ messages[\"CreationMonth\"].astype(str) +\"-\"+ messages[\"CreationDay\"].astype(str)","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2021-09-07T03:27:56.133424Z","iopub.status.idle":"2021-09-07T03:27:56.133935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Kecenderungan data sains di Kaggle\n\nSejumlah kecenderungan telah berubah selama bertahun-tahun di bidang data sains. Kaggle adalah komunitas data sains terbesar dan terpopuler di seluruh dunia. Di paper ini, kita menggunakan meta data Kaggle untuk mengeksplorasi tren data sains selama bertahun-tahun.\n\n## 1. Linear Vs Logistic Regression\n\nMari kita lihat perbandingan antara regresi linier dan regresi logistik dalam forum diskusi, *kernels* dan jawaban-jawaban di kaggle.","metadata":{"_uuid":"e79320e11e9deca284ce5ad352deaa9986179acd"}},{"cell_type":"code","source":"def plotthem(listed, title):    \n    traces = []\n    for model in listed:\n        temp = messages.groupby('KernelDate').agg({model : \"sum\"}).reset_index()\n        trace = go.Scatter(x = temp[\"KernelDate\"], y = temp[model], name=model.split(\"|\")[0].title(), line=dict(shape=\"spline\", width=2), mode = \"lines\")\n        traces.append(trace)\n\n    layout = go.Layout(\n        paper_bgcolor='#fff',\n        plot_bgcolor=\"#fff\",\n        legend=dict(orientation=\"h\", y=1.1),\n        title=title,\n        xaxis=dict(\n            gridcolor='rgb(255,255,255)',\n            range = ['2010-04-21','2021-08-21'],\n            showgrid=True,\n            showline=False,\n            showticklabels=True,\n            tickcolor='rgb(127,127,127)',\n            ticks='outside',\n            zeroline=False\n        ),\n        yaxis=dict(\n            title=\"Number of Kaggle Discussions\",\n            gridcolor='rgb(255,255,255)',\n            showgrid=False,\n            showline=False,\n            showticklabels=True,\n            tickcolor='rgb(127,127,127)',\n            ticks='outside',\n            zeroline=False\n        ),\n    )\n\n    fig = go.Figure(data=traces, layout=layout)\n    iplot(fig)\n    \n## linear vs logistic regression\nmodels = [\"linear regression\", \"logistic regression\"]\nfor col in models:\n    messages[col] = messages[\"CMessage\"].apply(lambda x : check_presence(x, col))\nplotthem(models, \"Kaggle Discussions: Linear vs Logistic\")    \n","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_kg_hide-input":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.status.busy":"2021-09-07T03:27:56.134739Z","iopub.status.idle":"2021-09-07T03:27:56.135263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"messages.columns","metadata":{"execution":{"iopub.status.busy":"2021-09-07T03:27:56.136006Z","iopub.status.idle":"2021-09-07T03:27:56.136538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Dari grafik di atas, kita dapat mengamati bahwa selalu ada lebih banyak diskusi terkait regresi logistik daripada regresi linier. Kecenderungan umum adalah bahwa jumlah diskusi meningkat setiap bulan.\n* Salah satu indikasinya adalah ada lebih banyak masalah klasifikasi daripada masalah regresi di Kaggle termasuk kompetisi yang paling populer **Titanic Survival Prediction competition**. Kompetisi ini memiliki jumlah diskusi terbanyak dan merupakan salah satu kompetisi terlama di Kaggle. Ada kompetisi regresi juga: Harga Rumah regresi maju, tetapi orang lebih sering memulainya setelah titanic saja.\n* Jumlah diskusi regresi logistik di forum, komentar kernel, dan balasan melonjak ke angka yang tinggi pada Oktober 2017 dan Maret 2018. Salah satu alasannya adalah **Toxic Comments Classification Competition**, di mana sejumlah penulis berbagi informasi yang sangat baik terkait dengan model klasifikasi termasuk regresi logistik.\n\n## 2. The dominance of xgboost","metadata":{"_uuid":"49241b6446f3b31288a0dac82811459ce27ef204"}},{"cell_type":"code","source":"models = [\"decision tree\",\"random forest\", \"xgboost|xgb\", \"lightgbm|lgb\", \"catboost\"]\nfor col in models:\n    messages[col] = messages[\"CMessage\"].apply(lambda x : check_presence(x, col))\nplotthem(models, \"Kaggle Discussions: Tree based models\")    \n","metadata":{"_kg_hide-input":true,"_uuid":"33df16d557863133392187cfd12e8ea08368c3d5","execution":{"iopub.status.busy":"2021-09-07T03:27:56.137343Z","iopub.status.idle":"2021-09-07T03:27:56.137848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Sebelum 2014, Model Linier, *decision trees*, dan *Random Forest* sangat populer. Tetapi ketika XgBoost menjadi *open source* pada tahun 2014, ia mendapatkan popularitas dengan cepat dan **mendominasi kompetisi kaggle dan kernel**. Hari ini, xgboost masih digunakan secara mendalam dalam kompetisi dan merupakan bagian dari model pemenang banyak kompetisi. Beberapa contohnya adalah **Otto Group Classification Competition** di mana solusi yang mendapatkan tempat pertama menggunakan xgboost.\n* Namun dengan kedatangan **Lightgbm pada tahun 2016**, penggunaan xgboost menurun sampai batas tertentu dan popularitas lightgbm mulai meningkat dengan sangat cepat. Berdasarkan tren peningkatan lightgbm baru-baru ini (ditunjukkan dengan warna merah), kita dapat memperkirakan bahwa itu akan mendominasi beberapa tahun ke depan juga, kecuali jika ada perusahaan lain yang membuka sumber model yang lebih baik. Misalnya, lightgbm digunakan dalam solusi pemenang **Porto Seguroâ€™s Safe Driver Prediction** . Salah satu alasan popularitas gbm ringan adalah implementasi yang lebih cepat dan antarmuka yang sederhana dibandingkan dengan xgboost.\n* Misalnya, Catboost baru-baru ini dirilis dan mulai populer.\n\n\n## 3. Trends of Neural Networks and Deep Learning","metadata":{"_uuid":"dd49f95879a3c86ad6c0b979747d907d3112cb36"}},{"cell_type":"code","source":"models = [\"neural network\", \"deep learning\"]\nfor col in models:\n    messages[col] = messages[\"CMessage\"].apply(lambda x : check_presence(x, col))\nplotthem(models, \"Kaggle Discussions: Neural Networks vs Deep Learning\")    ","metadata":{"_kg_hide-input":true,"_uuid":"6748ff0cd362c639588a091634a50cb02824262a","execution":{"iopub.status.busy":"2021-09-07T03:27:56.138613Z","iopub.status.idle":"2021-09-07T03:27:56.139106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Jaringan saraf hadir di industri sejak beberapa dekade tetapi dalam beberapa tahun terakhir tren berubah karena akses ke data dan daya komputasi yang jauh lebih besar.\n* Era *deep learning* dimulai pada tahun 2014 dengan kedatangan *library* seperti theano, tensorflow pada tahun 2015, dan keras pada tahun 2016. Jumlah diskusi terkait pembelajaran mendalam meningkat secara teratur dan selalu lebih dari jaringan saraf. Juga, banyak penyedia instans cloud seperti Amazon AWS, Google cloud, dll. menunjukkan kemampuan mereka untuk melatih jaringan saraf *deep* di cloud.\n* Model *deeplearning* juga menjadi populer karena banyaknya kompetisi **Image Classification** di Kaggle seperti : Data Science Bowl, kompetisi dari Google dll. Selain itu, model *deeplearning* juga menjadi populer untuk masalah klasifikasi teks misalnya **Quora Duplicate Questions Classification**.\n* *Deep learning* juga menjadi populer setiap bulan karena varian model yang berbeda seperti RNN, CNN telah menunjukkan peningkatan besar pada kernel. Juga, pembelajaran transfer dan model pra-terlatih telah menunjukkan hasil yang bagus dalam kompetisi.\n* Kaggle dapat meluncurkan lebih banyak kompetisi / taman bermain yang terkait dengan Pemodelan Klasifikasi Gambar karena orang ingin banyak belajar darinya. Tidak lupa bahwa Kaggle telah menambahkan dukungan GPU di kernel yang memfasilitasi penggunaan Deep Learning di kaggle.\n\n## 4. ML Tools used on Kaggle","metadata":{"_uuid":"4b229c7dd4180be6952f3ad35f1ef90eb7e9b968"}},{"cell_type":"code","source":"models = [\"scikit\", \"tensorflow|tensor flow\", \"keras\", \"pytorch\"]\nfor col in models:\n    messages[col] = messages[\"CMessage\"].apply(lambda x : check_presence(x, col))\nplotthem(models, \"Kaggle Discussions: ML Tools\")    ","metadata":{"_kg_hide-input":true,"_uuid":"c97a35d1143b5a0b30cfc2a138c068c5ed0d9011","execution":{"iopub.status.busy":"2021-09-07T03:27:56.139887Z","iopub.status.idle":"2021-09-07T03:27:56.140411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* *Scikit Learn* adalah satu-satunya *library* yang digunakan di kaggle untuk tugas pembelajaran mesin, tetapi sejak 2015 tensorflow menjadi populer.\n* Di antara alat ML, Keras adalah yang paling populer karena implementasi *deep learning* yang sederhana.\n\n## 5. XgBoost vs Keras","metadata":{"_uuid":"cf2fdd6fa1635703d00d17cad3e54897f76d1a7b"}},{"cell_type":"code","source":"models = [\"xgboost|xgb\", \"keras\"]\nfor col in models:\n    messages[col] = messages[\"CMessage\"].apply(lambda x : check_presence(x, col))\nplotthem(models, \"Kaggle Discussions: Xgboost vs Deep Learning\")    \n\nmodels = [\"cnn|convolution\", \"lstm|rnn|gru\"]\nfor col in models:\n    messages[col] = messages[\"CMessage\"].apply(lambda x : check_presence(x, col))\nplotthem(models, \"Kaggle Discussions: CNN and LSTM\")    ","metadata":{"_kg_hide-input":true,"_uuid":"a2f6f0beaefe5d65726e8c777aa4a30676e93a10","execution":{"iopub.status.busy":"2021-09-07T03:27:56.159181Z","iopub.execute_input":"2021-09-07T03:27:56.159644Z","iopub.status.idle":"2021-09-07T03:27:56.175874Z","shell.execute_reply.started":"2021-09-07T03:27:56.159614Z","shell.execute_reply":"2021-09-07T03:27:56.174498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Di antara kedua teknik populer di Kaggle - xgboost dan deeplearning, xgboost tetap menjadi yang teratas karena lebih cepat dan membutuhkan **less computational infrastructure** daripada jaringan saraf yang sangat kompleks dan lebih dalam.\n\n## 6. What Kagglers are using for Data Visualizations ?","metadata":{"_uuid":"5e816fd3e661811b62caff2aec24c95a09e7206a"}},{"cell_type":"code","source":"models = [\"matplotlib\", \"seaborn\", \"plotly\"]\nfor col in models:\n    messages[col] = messages[\"CMessage\"].apply(lambda x : check_presence(x, col))\nplotthem(models, \"Kaggle Discussions: Python Data Visualization Libraries\")    \n\nmodels = [\"ggplot\", \"highchart\", \"leaflet\"]\nfor col in models:\n    messages[col] = messages[\"CMessage\"].apply(lambda x : check_presence(x, col))\nplotthem(models, \"Kaggle Discussions: R Data Visualization Libraries\")    ","metadata":{"_kg_hide-input":true,"_uuid":"7a16ec4c6d6e2b54aee93304d2b70993c6ed81fe","execution":{"iopub.status.busy":"2021-09-07T03:27:56.226266Z","iopub.execute_input":"2021-09-07T03:27:56.226857Z","iopub.status.idle":"2021-09-07T03:27:56.245609Z","shell.execute_reply.started":"2021-09-07T03:27:56.226821Z","shell.execute_reply":"2021-09-07T03:27:56.244366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Plotly telah mendapatkan begitu banyak popularitas sejak 2017 dan merupakan salah satu perpustakaan visualisasi data yang paling banyak digunakan di antara kernel. Yang terbaik kedua adalah seaborn yang juga digunakan secara luas. Beberapa kernel visualisasi berkualitas tinggi oleh grandmaster kaggle seperti SRK dan Anistropic dibuat dengan plotly. Secara pribadi, saya juga penggemar berat plotly. :P\n\n## 7. Important Data Science Techniques ","metadata":{"_uuid":"1305cacf15819ae9094bcd140cc653b796159ae1"}},{"cell_type":"code","source":"models = [\"exploration|explore|eda\" , 'feature engineering', 'parameter tuning|hyperparameter tuning|model tuning|tuning', \"ensembling|ensemble\"]\nfor col in models:\n    messages[col] = messages[\"CMessage\"].apply(lambda x : check_presence(x, col))\nplotthem(models, \"Kaggle Discussions: Important Data Science Techniques\")    ","metadata":{"_kg_hide-input":true,"_uuid":"e481f8c42f94104415c6e1d24001fa6ef2488847","execution":{"iopub.status.busy":"2021-09-07T03:27:56.251611Z","iopub.execute_input":"2021-09-07T03:27:56.25215Z","iopub.status.idle":"2021-09-07T03:27:56.267785Z","shell.execute_reply.started":"2021-09-07T03:27:56.2521Z","shell.execute_reply":"2021-09-07T03:27:56.266712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Di antara langkah-langkah *data sains* yang penting, pengguna kaggle banyak berfokus pada **Model Ensembling** karena banyak solusi pemenang dalam kompetisi kaggle adalah model ensemble - model campuran dan bertumpuk. Di hampir setiap kernel regresi atau klasifikasi, orang dapat melihat kernel ensemblling. Sebagai contoh - dalam Kompetisi Klasifikasi Komentar toxic, sejumlah besar kernel ensembling dibagikan.\n* **Eksplorasi Data** adalah teknik yang penting dan orang-orang mulai menekankan pentingnya eksplorasi di kernel EDA.\n* Mengejutkan melihat bahwa diskusi yang berkaitan dengan **Rekayasa Fitur dan Model Tuninig lebih sedikit daripada Ensembling**. Kedua tugas ini memiliki arti paling penting dalam model terbaik dan akurat. Orang cenderung lupa bahwa ensambling hanyalah tahap terakhir dari setiap proses pemodelan tetapi banyak waktu harus diberikan untuk tugas-tugas rekayasa fitur dan penyetelan model.\n\n## 8. Kaggle Components : What people talks about the most ","metadata":{"_uuid":"d620eeb199b1d6beec1dc6b5bdbe0cf858cad92d"}},{"cell_type":"code","source":"models = [\"dataset\" , 'kernel', 'competition', 'learn']\nfor col in models:\n    messages[col] = messages[\"CMessage\"].apply(lambda x : check_presence(x, col))\nplotthem(models, \"What is hottest on Kaggle\")    ","metadata":{"_kg_hide-input":true,"_uuid":"cc0498e99540724c2557dc635647742915cbb75e","execution":{"iopub.status.busy":"2021-09-07T03:27:56.268688Z","iopub.status.idle":"2021-09-07T03:27:56.269357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Komunitas Kaggle telah berbagi sejumlah diskusi terkait kompetisi di forum dan meningkat secara umum.\n* Dengan peluncuran kernel pada tahun 2016, penggunaannya meningkat pesat. Pertama kaggler berbagi kernel hanya dalam kompetisi, tetapi dengan lebih fokus pada **kaggle datasets, kernel awards**, jumlah diskusi terkait kernel mulai meningkat dan telah melampaui diskusi terkait kompetisi. Juga, sejumlah **Data Science for Good Challenges** dan **Kernels only competition** telah diluncurkan di kaggle yang merupakan salah satu alasan popularitas kernel.\n* Kaggle juga meluncurkan bagian **Kaggle Learn** yang luar biasa yang menjadi populer dan populer tetapi masih tertinggal dari kompetisi, kernel, dan diskusi. Ini karena audiens utamanya adalah pemula dan pemula, tetapi pasti di tahun-tahun mendatang dan dengan lebih banyak penambahan kursus, bagian belajar kaggle akan mencapai level yang sama seperti kompetisi dan kernel.","metadata":{"_uuid":"ab4b46ee1cd8fd990f8b936eecc98e49d4b2bc04"}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}