{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h1 style='background-color: #fed8b1; padding-bottom:4px;' align='center'><b>Bank Churn EDA & Modelling</b></h1>"},{"metadata":{},"cell_type":"markdown","source":"    We have been given the task of predicting the customers that are likely to churn so that the bank can proactively take action to prevent it from happening.\n\n    In this notebook, I have performed some exploratory data analysis.\n\n    I hope you find my notebook useful and make sure to upvote if you enjoyed it!"},{"metadata":{},"cell_type":"markdown","source":"<h2 style='background-color: #fed8b1;' align='center'>Loading Libraries</h2>"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nfrom pandas_profiling import ProfileReport\n\nfrom scipy.special import boxcox1p\nfrom scipy.stats import boxcox_normmax","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2 style='background-color: #fed8b1;' align='center'>Data Loading & Basic Analysis</h2>"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/credit-card-customers/BankChurners.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p>We are off to a great start as there appears to be no missing values!</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"for c in df.select_dtypes('object').columns:\n    print(df[c].value_counts())\n    print('--------------------')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    This is a cool trick I like to use that basically lists all the non-integer values and shows their respective value_counts. \n\n    We see that here we will more than likely need to LabelEncode all these features except the Gender, which would be an one-hot encoding. \n\n    However, some libraries such Catboost, can actually deal with text values by itself!"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    Here we are getting some basic statistics about the dataset to get a feel for what we are going to be working with.\n\n    Immediately we see that our features are on different scales. \n\n    For instance, the median value for Total_Relationship_Count is 4, but the median value for the Credit_Limit feature is 4549!\n\n    This shows us that we will require feature scaling if we choose to work with Linear models or Neural Networks."},{"metadata":{},"cell_type":"markdown","source":"<h2 style='background-color: #fed8b1;' align='center'>Exploratory Data Analysis</h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"ProfileReport(df,minimal=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    This is probably my new favorite tool for EDA. It's really simple but packs a lot of information in one line of code!\n\n    The main reason I enjoy using this library is because it given me a starting point as to where I should start my data analysis.\n\n    I have set mininal=True because it does use up a substantial amount of CPU, but nevertheless it is a useful tool to have in the toolkit!"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.pie(df,df['Attrition_Flag'],hole=0.5)\nfig.update_layout(title='Percentage of Attrited and Existing Customers',title_x=0.5)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df['Attrition_Flag'])\nplt.title('Boxplot of Attrited and Existing Customers')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Attrition_Flag'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>The key takeaways from here are:</b>\n\n    1. the dataset is HEAVILY imbalanced. \n\n       This means that we will have to address this when modelling.\n\n       We may have to use either Oversampling or Undersampling techniques to address this issue.\n\n    2.When splitting the data into a train and test set, or when using Cross Validation, it is important to stratify the split\n      so that the class distribtutions are  split proportionally to the original dataset's imbalance. \n\n      Specifically, if our data is imbalanced with only 16.1% belonging to the attrited class, we must reflect that in the split. \n      Not doing so is a common data leakage and gives an overly optimistic accuracy of the model when evaluating it. "},{"metadata":{"trusted":true},"cell_type":"code","source":"numeric_features = df.select_dtypes(exclude=['object'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in numeric_features:\n    sns.boxplot(df[feature])\n    plt.title('Boxplot of ' + str(feature))\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>Some key takeaways here</b>:\n\n    1. As the author of the dataset suggested, we should 100% remove the last 2 columns as they will jeopardize the accuracy of the model \n       and follow no clear distribution.\n\n    2. Some features, such as Total_Trans_Amt and Credit_Limit, have a few outliers in them. \n       This may hinder our model's performance and we should most likely deal with the outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.skew()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    While our features are not overly skewed, we have a couple of left tailed and right tailed skeweness present in our features. \n    Let's begin by analysing the Credit_Limit feautre."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df['Credit_Limit'])\nplt.title('Distribution of the Credit_Limit feature')\nplt.show()\nprint(df['Credit_Limit'].skew())\nprint(df['Credit_Limit'].kurt())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    So it seems that this feature fits inside a left-tailed distribution.\n    However, note that if we could possibly transform this feature to reduce this skewness"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df['CLIENTNUM'],bins=40)\nplt.title('Distribution of the CLIENTNUM feature')\nplt.show()\nprint(df['CLIENTNUM'].skew())\nprint(df['CLIENTNUM'].kurt())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    This feature is slightly different. It appears to somewhat follow a left tailed normal distribution, \n    but it is clear that there is a smaller distribution on the right, implying a high standard deviation\n    We also observe that this feature's kurtosis is ~ -0.62, meaning our distribution is light-tailed.\n    This means that exteme values will occur less often "},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(df['Attrition_Flag'],df['Credit_Limit'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    We see that Existing customers are likely to have a slightly larger Credit_Limit that Attrited Customers, but the narrow gap implies that this feature is\n    not a definitive one."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(df['Attrition_Flag'],df['Total_Revolving_Bal'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,10))\nage_groups = pd.cut(df['Customer_Age'],[20,30,40,50,60],labels=['0-20','20-30','30-40','40-50'])\nsns.barplot(age_groups,df['Total_Revolving_Bal'],hue=df['Attrition_Flag'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    Now we see a difference. Existing customers are more likely to have larger Revolving Balances than Attrited Customers. This is evident through all age groups"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(df['Attrition_Flag'],df['Total_Trans_Amt'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(age_groups,df['Total_Trans_Amt'],hue=df['Attrition_Flag'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    We can observe that Existing customers are more likely to have a higher transaction amount than attried customers.However, \n    the 0-20 bracket actually has more attrited customers with higher transaction amounts than existing customers. "},{"metadata":{},"cell_type":"markdown","source":"    We can see that the total transaction amount of existing customers in different Income_Categories is relatively uniform, \n    with the $120K+ category being slightly larger. However, on the attrited customers, the 80K-120K Group is the highest group of attrited customers"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.select_dtypes('object').columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.pie(df,df['Card_Category'],hole=0.5)\nfig.update_layout(title='Card Category of customers',title_x=0.5)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(df['Attrition_Flag'],df['Total_Revolving_Bal'],hue=df['Card_Category'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    In these two visualisations, we make 2 observations:\n    \n    1. The main card category of all customers(existing and churned) is blue. However, when we look at the data closely, we see that churned customers are actually more likely to be holding a Gold card rather than a blue card"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.pie(df,df['Education_Level'],hole=0.5)\nfig.update_layout(title='Education level of customers',title_x=0.5)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,15))\nsns.barplot(df['Attrition_Flag'],df['Total_Revolving_Bal'],hue=df['Education_Level'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    We see that the primary education level of customers is graduate, but the education level does not greatly impact the likeliness of a customer churning"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_corr = df.copy()\ndf_corr['Attrition_Flag'] = df_corr['Attrition_Flag'].map({'Existing Customer':0,'Attrited Customer':1})\n\nplt.figure(figsize=(20,20))\nsns.heatmap(df_corr.corr(),annot=True,cmap='plasma')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    We can observe that there is no real features that correlate with the target, but that does not mean that the features are useless; our analysis\n    showed that some features do have an impact on the likeliness of the customer to churn, \n    so it is not correct to solely base your usefullness for a feature on a correlation heatmap"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}