{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Wildfires and weather events in California 2016-2019"},{"metadata":{},"cell_type":"markdown","source":"***Goal:*** Combining weather events at different weather stations and wildfire incidents to get insights in possible relations that are less obvious. \n\n***Question:*** Can ML predict wildfires in California based on the number of different weather events reported in a single year? \n\n***Status:*** Still rough, not finished.\n\nThis by no way the most effective/complete way to investigate wildfire occurence and predictability but it's the one I was interested in. I want to see if statements like these : 'Fire behavioral experts and climatologists have warned that heavy rains from months early in the year have produced an excess of vegetation' could reflect back in this data.\n\nThe current version is a rought first try to visualize rain events and acres burned by wildfire. Machine learning is applied on a very small set which tries to predict if 2019 was a year with a lot of wildfires based on weather data. It would be very nice to also have wildfire data for other states and years.\n\nI know that some naive python code is present in this Notebook.  \n\nWeather Event data: https://www.kaggle.com/sobhanmoosavi/us-weather-events\nWild fire data : https://www.kaggle.com/ananthu017/california-wildfire-incidents-20132020\n\nThanks for providing this data! \n\nAcknowledgements: \n\nMoosavi, Sobhan, Mohammad Hossein Samavatian, Arnab Nandi, Srinivasan Parthasarathy, and Rajiv Ramnath. “Short and Long-term Pattern Discovery Over Large-Scale Geo-Spatiotemporal Data.” In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, ACM, 2019."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\n\n# Load Data, this step could take up to 60 seconds\nweather = pd.read_csv('../input/us-weather-events/US_WeatherEvents_2016-2019.csv')\nprint (\"Loaded weather data : \", weather.head(1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Retrieve CALIFORNIA weather events\nisCa = weather['State'] == 'CA'\nca = weather[isCa]\nprint(\"Number of weather events in CA:\", ca.size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime as dt\nimport warnings\n# Too lazy/busy to fix warnings, I know :(\nwarnings.filterwarnings('ignore')\nwarnings.simplefilter('ignore')\n\n#Aggregate and group weather data data\nstart = pd.DatetimeIndex(ca['StartTime(UTC)']);\nend = pd.DatetimeIndex(ca['EndTime(UTC)']);\nca['Mean_Duration'] = (end-start).total_seconds()\nca['Year'] = start.year\nca['Month'] = start.month\ngrouped = ca.groupby(by=['Year','Month','Type','Severity'] ,as_index=False).agg({'Mean_Duration': \"mean\", 'EventId': \"count\"})\ngrouped['Count'] = grouped.EventId\ncaGrouped = grouped[['Year','Month','Type','Severity','Count',\"Mean_Duration\"]]\ncaGrouped.head(12)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Prepare weather set for machine learning\ntypes = [{'Type': 'Cold', 'Severity': 'Severe'},{'Type': 'Fog', 'Severity': 'Moderate'},{'Type': 'Fog', 'Severity': 'Severe'},{'Type': 'Precipitation', 'Severity': 'UNK'},\n                {'Type': 'Rain', 'Severity': 'Heavy'},{'Type': 'Rain', 'Severity': 'Light'},{'Type': 'Rain', 'Severity': 'Moderate'},{'Type': 'Snow', 'Severity': 'Heavy'},\n                {'Type': 'Snow', 'Severity': 'Light'},{'Type': 'Snow', 'Severity': 'Moderate'},{'Type': 'Storm', 'Severity': 'Severe'}]\ncolumns = ['Count','Mean_Duration']\n\n# Create weather ML input set for year which contains duration and count of different weather events for each month\ndef createYearSet(year, uniqueTypes):\n    numberOfMonths = 12\n    array = [0.0]*(numberOfMonths * len(uniqueTypes) * len(columns))\n    \n    isYear =  caGrouped['Year'] == year\n    caYear = caGrouped[isYear]\n    i=0\n    for m in range(numberOfMonths):\n        isMonth =  caYear['Month'] == m+1\n        caMonth = caYear[isMonth]\n        for u in uniqueTypes:\n            isType = caMonth['Type'] == u['Type']\n            caType = caMonth[isType]\n            isSeverity = caType['Severity'] == u['Severity']\n            caSevType = caType[isSeverity]\n            countSize = caSevType[\"Count\"].size\n            durationSize = caSevType[\"Mean_Duration\"].size\n            if countSize == 1:\n                array[i] = caSevType[\"Count\"].item()\n            i = i + 1\n            if durationSize == 1:\n                array[i] = caSevType[\"Mean_Duration\"].item()    \n            i = i + 1\n    return array","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read wildfire events.\nfire =pd.read_csv('../input/california-wildfire-incidents-20132020/California_Fire_Incidents.csv')\n# Filter wildfire events for 2016-2019 years.\nisFireRecent = fire['ArchiveYear'].isin([2016,2017,2018,2019])\nfireNew = fire[isFireRecent]\nfireNew.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Group fire data same way as weather data, group on month. \nstart = pd.DatetimeIndex(fireNew['Started']);\nfireNew['Month'] = start.month\ngroupedFire = fireNew.groupby(by=['ArchiveYear','Month'] ,as_index=False).agg({'AcresBurned': \"sum\",'Active':'count'})\ngroupedFire['Count'] = groupedFire.Active\ncaGroupedFire = groupedFire[['ArchiveYear','Month','AcresBurned','Count']]\ncaGroupedFire.head(6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import scipy.stats as stats\nimport matplotlib.pyplot as plt\n\n#Visualize rain and acres burned each year.\nfor year in [2016,2017,2018,2019]:\n    # Prepare grouping for each year, rain vs fire events graph\n    caGroupedType = caGrouped.groupby(by=['Type','Month','Year'] ,as_index=False).agg({'Mean_Duration': \"mean\", 'Count': \"sum\"})\n    isRain= caGroupedType[\"Type\"] ==\"Rain\"\n    isYear= caGroupedType[\"Year\"] ==year\n    rain = caGroupedType[isRain][isYear]\n\n    # Rename columns to join and prevent overlap\n    renameFire = caGroupedFire.rename(columns={'ArchiveYear': 'Year','Count' :'FireEventCount'})\n    isFireYear= renameFire[\"Year\"] == year\n    renameFire = renameFire[isFireYear]\n    concatFireRain = pd.merge(rain, renameFire,  how='left', left_on=['Month','Year'], right_on = ['Month','Year'])\n\n    # Create plot \"California Wildfire and Rain comparison\"\n    ax = plt.gca()\n    concatFireRain.plot(kind='line',x='Month',y='Count',ax=ax)\n    plt.ylabel(\"Rain events\")\n    concatFireRain.plot(secondary_y=True,kind='line',x='Month',y='AcresBurned',color='red', ax=ax)\n    plt.ylabel(\"Acres burned\")\n    plt.suptitle(\"California wildfire acres burned and rain events comparison \" + str(year))\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Group per year for expected outputs.\ngroupedFireYear = caGroupedFire.groupby(by=['ArchiveYear'] ,as_index=False).agg({'AcresBurned': \"sum\",'Count':'sum'})\nmean = groupedFireYear[['AcresBurned']].mean()\ngroupedFireYear['BadYear'] =groupedFireYear['AcresBurned'] >  mean.item()\ngroupedFireYear.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prepare expected outputs Y for ML\ntrainingFireYears = groupedFireYear[groupedFireYear['ArchiveYear'].isin([2016,2017,2018])]\ntrainingYTransposed = trainingFireYears.BadYear.to_frame().T.astype(float)\ntrainingY = np.reshape(trainingYTransposed.to_numpy(), (3,1))\nprint(trainingY)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\n# Combine everything up to now and create ML model, train it, predict 2019.\ninput16 = createYearSet(2016,types) \ninput17 = createYearSet(2017,types) \ninput18 = createYearSet(2018,types)  \ninput19 = createYearSet(2019,types)\n\nfirstLayerSize = len(input16)\nsecondLayerSize = 90\nthirdLayerSize = 40\noutputSize = 1\n\nprint(\"Setting up model\") \nprint(\"Creating Input layer with size : \"+ str(len(input16)))\ninputs = keras.Input(shape=(len(input16),))\ndense1 = layers.Dense(firstLayerSize, activation=\"sigmoid\")(inputs)\ndense2 = layers.Dense(secondLayerSize, activation=\"relu\")(dense1)\ndense3 = layers.Dense(thirdLayerSize, activation=\"relu\")(dense2)\noutputs = layers.Dense(outputSize, activation=\"sigmoid\")(dense3)\n\nmodel = keras.Model(inputs=inputs, outputs=outputs, name=\"learnModel\")\nmodel.summary()\n\nopt = keras.optimizers.SGD(lr=0.05, momentum=0.5)\nmodel.compile(loss='mean_squared_error', optimizer=opt,metrics=[\"accuracy\"])\n\ntrainingX = np.array([input16,input17,input18])\nmodel.fit(trainingX,trainingY,batch_size=3, epochs=40)\n\ntest_scores = model.evaluate(trainingX, trainingY, verbose=2)\nprint(\"Test loss:\", test_scores[0])\nprint(\"Test accuracy:\", test_scores[1])\n\n# We predict for 2019, we know this is not a 'bad' year and should be predicted with a low value (smaller than 0.5)\n# This model is specialized in only three years and probably has quite some variance (overfitting problem) when applied to other years.\nmodel.predict([input19])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}