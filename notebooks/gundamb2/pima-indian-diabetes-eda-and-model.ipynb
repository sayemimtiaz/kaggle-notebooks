{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"diabetes_df = pd.read_csv('../input/pima-indians-diabetes-database/diabetes.csv')\nprint(diabetes_df.shape)\ndiabetes_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have 768 patients in the dataset and 9 columns. Lets discuss each column one by one.\n\nPregnancies is the number of times a person was pregnant. It's important to know the number of times a woman has become pregnant because each pregnancy has the risk of developing gestional diabetes (GDM) which itself is a risk factor for diabetes (DM). \n\nGlucose is the measure of plasma (or blood) glucose 2 hours after a oral glucose test. The elevated levels of glucose after 2 hours indicates impaired insulin function which can be a diagnostic for diabetes.\n\nBlood pressure itself can't be used to determine if one has diabetes or not, but high blood pressure usually coexists with diabetes.\n\nSkinThickness is how thick the tricep skin fold is. This test is a surrogate measure for body fat composition. Diabetics usually have high body fat.\n\nInsulin is the insulin level, 2 hours after ingesting oral glucose.\n\nBMI is body mass index. This column informs us if the patient is overweight for their height. Being overweight is a risk factor for diabetes.\n\nAge is self-explanatory. Diabetes is more common in the elderly due to various reasons.\n\nOutcome is the target variable. It tells us if someone has diabetes or not.\n\n## EDA\n\nLets explore each column and see how well correlated they are to the outcome."},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.heatmap(diabetes_df.corr(), annot=True, linewidths=1, cmap='YlGnBu')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see most of the variables are waekly correlated with Outcome. Glucose highly correlates with the outcome. Insulin surprisingly correlates more with SkinThickness than with Outcome. This could be due to the fact since high body fat is known to cause increased insulin resistance which leads to the pancreas to release more insulin. Increased SkinThickness leads to increased body fat.\n\nLets plot each column with outcome and deeply explore their relationship\n\n\n### What is the distribution of number of pregnancies?\n### What is the effect of number of pregnancies on the outcome?"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(diabetes_df['Pregnancies'], kde=False, bins=range(0,17))\nplt.show()\n\npregnancies_group = diabetes_df.groupby(['Pregnancies'], as_index=False)\npregnancies_group_count = pregnancies_group.count()['Outcome']\npregnancies_group_sum = pregnancies_group.sum()['Outcome']\npregnancies_group_percentage = pregnancies_group_sum / pregnancies_group_count * 100\n\nplt.bar(x=range(0,17), height=pregnancies_group_percentage, yerr=pregnancies_group_percentage.std(), tick_label=range(0,17))\nplt.title(\"Number of Pregnancies vs Diabetic Outcome\")\nplt.xlabel(\"Number of Pregnancies\")\nplt.ylabel(\"% Diabetic Outcome\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that most females have 0-2 babies. We can also so see that having high number of pregnancy increases the risk of diabetes significantly.\n\n### What is the effect of BMI on the Outcome?"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_bmi_groups(bmi):\n    if bmi >= 16 and bmi <18.5:\n        return \"Underweight\"\n    elif bmi >= 18.5 and bmi < 25 :\n        return \"Normal weight\"\n    elif bmi >= 25 and bmi < 30:\n        return \"Overweight\"\n    elif bmi >= 30 and bmi < 35:\n        return \"Obese Class I (Moderately obese)\"\n    elif bmi >= 35 and bmi < 40:\n        return \"Obese Class II (Severely obese)\"\n    elif bmi >= 40 and bmi < 45:\n        return \"Obese Class III (Very severely obese)\"\n    elif bmi >= 45 and bmi < 50:\n        return \"Obese Class IV (Morbidly Obese)\"\n    elif bmi >= 50 and bmi < 60:\n        return \"Obese Class V (Super Obese)\"\n    elif bmi >= 60:\n        return \"Obese Class VI (Hyper Obese)\"\n\n\ndiabetes_df['bmi_groups'] = diabetes_df['BMI'].apply(get_bmi_groups)\n\nbmi_groups_groupby = diabetes_df.groupby(['bmi_groups'])\nbmi_groups_groupby_count = bmi_groups_groupby.count()['Outcome']\nbmi_groups_groupby_sum = bmi_groups_groupby.sum()['Outcome']\nbmi_groups_groupby_percentage = bmi_groups_groupby_sum / bmi_groups_groupby_count * 100\nplt.figure(figsize=(16,4))\nplt.bar(x=range(0,9), height=bmi_groups_groupby_percentage, yerr=bmi_groups_groupby_percentage.std(), tick_label=[\"Normal Weight\", \"Class 1\", \"Class 2\", \n                                                                        \"Class 3\", \"Class 4\", \"Class 5\", \"Class 6\", \n                                                                        \"Overweight\", \"Underweight\"])\nplt.title(\"BMI class vs Diabetic Outcome\")\nplt.xlabel(\"BMI classes\")\nplt.ylabel(\"Diabetic Outcome\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that the more overweight a person is, the more likely they are diabetic. Next we are going to create some features to do additional analysis."},{"metadata":{},"cell_type":"markdown","source":"## Feature engineering\n\nLarge waist circumference (WC) is an important risk factor for cardiovascular disease. Large WC can also be an indicator for diabetes. WC measures abdominal obesity, and abdominal obesity is linked to numerous poor health outcomes such as metabolic disease, dyslipidemia, and high blood pressure.\n\nI have already talked about how to derive WC from BMI and Age in another notebook: Healthcare Dataset Stroke Data EDA and Modeling (https://www.kaggle.com/gundamb2/cardio-eda-and-ensemble-methods). Please check notebook out for a more indepth explanation.\n\nPaper where this equation was obtained from: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3441760/"},{"metadata":{"trusted":true},"cell_type":"code","source":"def predicted_women_waist(bmi, age):\n    c0 = 28.81919\n    c1BMI = 2.218007*(bmi)\n    age_35 = 0\n    if age > 35:\n        age_35 = 1\n    \n    c2IAGE35 = -3.688953 * age_35\n    IAGE35 = -0.6570163 * age_35\n            \n    c3AGEi = 0.125975*(age)\n    \n    return (c0 + c1BMI + c2IAGE35 + IAGE35 + c3AGEi)\n\ndiabetes_df['waist circumference'] = diabetes_df.apply(lambda row: predicted_women_waist(row['BMI'], row['Age']), axis=1)\n\n# Lets apply the same cut off from the previous paper and visualize the results\n\ndiabetes_df['waist_cut_off'] = diabetes_df['waist circumference'].apply(lambda size: 1 if size > 88 else 0)\n\nwaist_group = diabetes_df.groupby(['waist_cut_off'])\nwaist_group_count = waist_group.count()['Outcome']\nwaist_group_sum = waist_group.sum()['Outcome']\nwaist_group_percentage = waist_group_sum / waist_group_count * 100\n\nplt.bar(x=[0,1], height=waist_group_percentage, yerr=waist_group_percentage.std(), tick_label=['Under Cut Off', 'Over Cut Off'])\nplt.title(\"Waist Cut off vs Diabetic Outcome\")\nplt.xlabel(\"Waist Cut off\")\nplt.ylabel(\"% Diabetic Outcome\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that people above the cut off have a higher probability of having diabetes.\n\n## Model Prediction\n\nFor modelling we are going to keep it simple and use XGB classifier without any ensembling or hyperparamter optimization. We are not going to use any cross validation k-fold sets due to the very low number of inputs in this dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\n\nX = diabetes_df[['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', \n                 'DiabetesPedigreeFunction', 'Age', 'waist circumference']]\ny = diabetes_df['Outcome']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\ndata_dmatrix = xgb.DMatrix(data=X, label=y)\nxgb_clf = xgb.XGBClassifier()\nxgb_clf.fit(X_train, y_train)\n\npredictions = xgb_clf.predict(X_test)\n\nf1 = f1_score(y_test, predictions)\nprint(\"The F1 score is {}: \".format(f1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that our F score is some where around ~0.57-0.70. However the F score is hard to interpet and doesnt tell us if our model's sensitivity or specificity. Lets instead use a AUC-ROC curve to get more details of our model."},{"metadata":{"trusted":true},"cell_type":"code","source":"import sklearn.metrics as metrics\n\nfpr, tpr, threshold = metrics.roc_curve(y_test, predictions)\nroc_auc = metrics.auc(fpr, tpr)\n\nplt.title('ROC-AUC Curve')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.1f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see from the curve that our model is somewhat good in it's prediction. AUC is above the red line where AUC = 0.5, meaning that the classifer has a slightly higher true positive rate than false positive rate. However we ideally want our ROC-AUC closer to the top left corner where F would equal 1. In this cases the classifer would correctly classify all entries correctly. This unrealistic standard to acheive but we can still try to improve our model through feature selection.\n\n## Feature Selection\n\nFor feature selection we are going to use the properties of xgb_clf.feature_importances_ to choose the top 3 features to use in out model."},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_importance = pd.DataFrame()\nfeature_importance['columns'] = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', \n                                 'DiabetesPedigreeFunction', 'Age', 'waist circumference']\nfeature_importance['importances'] = xgb_clf.feature_importances_\nfeature_importance","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that XGB choose features that correlates closely with the Outcome. Lets pick the top 3 features (Glucose, BMI, and Age) and see if that improves out ROC-AUC curve."},{"metadata":{"trusted":true},"cell_type":"code","source":"X = diabetes_df[['Glucose', 'BMI', 'Age']]\ny = diabetes_df['Outcome']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\ndata_dmatrix = xgb.DMatrix(data=X, label=y)\nxgb_clf = xgb.XGBClassifier()\nxgb_clf.fit(X_train, y_train)\n\npredictions = xgb_clf.predict(X_test)\n\nf1 = f1_score(y_test, predictions)\nprint(\"The F1 score is {}: \".format(f1))\n\nfpr, tpr, threshold = metrics.roc_curve(y_test, predictions)\nroc_auc = metrics.auc(fpr, tpr)\n\nplt.title('ROC-AUC Curve')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.1f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}