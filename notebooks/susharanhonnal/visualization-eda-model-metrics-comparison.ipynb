{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Visualization, EDA and Model Metrics Comparison for Car Insurance Cold Calls"},{"metadata":{},"cell_type":"markdown","source":"****Let's Analyze the Data****"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Importing the required Libraries\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom datetime import datetime\nfrom matplotlib import pyplot\n\nfrom sklearn.feature_selection import SelectKBest,f_classif  # Feature Engineering\nfrom sklearn.model_selection import train_test_split  # Splitting the dataset into training & testing\n\n# Regression & Classification Models\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import RidgeClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom xgboost import XGBClassifier\n\n\n#Metrics\nfrom sklearn.metrics import classification_report,confusion_matrix,accuracy_score,f1_score,recall_score,precision_score\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loading the Dataset.\n\ndf_train=pd.read_csv('../input/carinsurance/carInsurance_train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Handling the Missing Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"# There are missing values in the fields -> \"Job\", \"Education\", \"Communication\" & \"Outcome\".\n# Let's check the percentage of missing values in them.\n\nprint(\"Missing values (Count):-\")\nprint(\"\\n\")\nprint(df_train.isnull().sum())\nprint(\"\\n\")\nprint(\"Missing values (Percentage (%)):-\")\nprint(\"\\n\")\nprint((df_train.isnull().sum()/len(df_train))*100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Highest percentage of missing data (76%) is in the \"Outcome\" field.\nLet's handle the Missing values."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Analyzing the Categorical values in the Missing value fields.\n\nprint(\"Job Field ->\")\nprint(df_train.Job.value_counts())\nprint(\"\\n\")\nprint(\"Education Field ->\")\nprint(df_train.Education.value_counts())\nprint(\"\\n\")\nprint(\"Communication Field ->\")\nprint(df_train.Communication.value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's determine the most commonly occuring values in the fields -> \"Job\", \"Education\" & \"Communication\".\n\nprint(\"Job Field\")\nprint(df_train.Job.mode())\nprint(\"\\n\")\nprint(\"Education Field\")\nprint(df_train.Education.mode())\nprint(\"\\n\")\nprint(\"Communication Field\")\nprint(df_train.Communication.mode())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's fill the missing values with their respective modes.\n\nfor i in [\"Job\",\"Education\",\"Communication\"]:\n    df_train[i]=df_train[i].fillna(df_train[i].mode()[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# As 76% of the data is missing in \"Outcome\" field, it's better to drop the column.\n\ndf_train.drop('Outcome',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converting the type of \"CallStart\" & \"CallEnd\" to Datetime.\n\ndf_train[['CallStart','CallEnd']]=df_train[['CallStart','CallEnd']].astype('datetime64[ns]')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculating the total Call Duration\n\ndf_train['Call_Duration']=df_train['CallEnd']-df_train['CallStart']\n\n# Extracting the time & converting it to seconds\n\ndf_train['Call_Duration']=df_train['Call_Duration'].dt.components['minutes']*60 + df_train['Call_Duration'].dt.components['seconds']\ndf_train['Call_Duration'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Adding a column with Age Ranges.\n\ndef agerange(age):\n    if age >= 18 and age <= 20:\n        return \"18-20\"\n    elif age >= 21 and age <= 30:\n        return \"21-30\"\n    elif age >= 31 and age <= 40:\n        return \"31-40\"\n    elif age >= 41 and age <= 50:\n        return \"41-50\"\n    elif age >= 51 and age <= 60:\n        return \"51-60\"\n    elif age >= 61 and age <= 70:\n        return \"61-70\"\n    elif age >= 71 and age <= 80:\n        return \"71-80\"\n    elif age >=81 and age <= 90:\n        return \"81-90\"\n    elif age > 90:\n        return \"Above 90\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Age Range']=df_train['Age'].apply(agerange)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's analyze the Age of the Customers w.r.t Jobs\n\nAgeRange_crosstab=pd.crosstab(index=df_train['Age Range'],columns=df_train['Job'])\nAgeRange_crosstab","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Almost all customers have been employed from the age of 21.\n* The oldest customers are above 90 yrs & both of them are retired.\n* Most of the Customers are in blue-collar or management Jobs & some are in technician & admin Jobs."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting the above values.\n\nAgeRange_crosstab.plot(kind='bar',stacked=False,figsize=(20,6))\nplt.xticks(rotation = 0)\nplt.xlabel('Age Ranges',fontsize=16)\nplt.ylabel('Job',fontsize=16)\nplt.title('Analyzing Age w.r.t Job',fontsize=18)\nplt.legend(title='Job',title_fontsize=15,prop={\"size\":12})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's check the age dependancy w.r.t Car Insurance Opting Decisions\n\nAge_crosstab=pd.crosstab(index=df_train['Age Range'],columns=df_train['CarInsurance'])\nAge_crosstab['Percentage Enrolled']=round(Age_crosstab[1]/(Age_crosstab[0]+Age_crosstab[1])*100,2)\nAge_crosstab","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Majority of the people who've Enrolled for the car insurance are in their 30s & also Majority of the rejectors are also in their 30s.\n* But Most of the people who've Enrolled range from 21 to 60 yrs of age maybe due to job securities."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting the above values.\n\nAge_crosstab.drop(['Percentage Enrolled'], axis=1).plot(kind='bar',stacked=False,figsize=(20,6))\nplt.xticks(rotation = 0,fontsize=12)\nplt.xlabel('Age Ranges',fontsize=16)\nplt.ylabel('Car Insurance',fontsize=16)\nplt.title('Car Insurance policy Decisions w.r.t Age',fontsize=18)\nplt.legend(['Rejected','Accepted'],title='Car Insurance',title_fontsize=15,prop={\"size\":12})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's check the Job dependancy w.r.t Car Insurance Opting Decisions\n\nJob_crosstab=pd.crosstab(df_train['Job'],df_train['CarInsurance'],colnames=['Car Insurance'])\nJob_crosstab['Percentage Enrolled']=round(Job_crosstab[1]/(Job_crosstab[0]+Job_crosstab[1])*100,2)\nJob_crosstab","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Most of the people who've enrolled for the insurance are working in management or Technician jobs.\n* Surprisingly, unemployed members Enrolled for the insurance are more than the ones who have rejected it."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting the above values.\n\nJob_crosstab.drop(['Percentage Enrolled'], axis=1).plot(kind='bar',stacked=False,figsize=(20,6))\nplt.xticks(rotation = 0,fontsize=12)\nplt.xlabel('Jobs',fontsize=16)\nplt.ylabel('Car Insurance',fontsize=16)\nplt.title('Car Insurance Policy Decisions w.r.t Job',fontsize=18)\nplt.legend(['Rejected','Accepted'],title='Car Insurance',title_fontsize=15,prop={\"size\":12})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's check the dependancy of marital status on Car Insurance Opting Decisions\n\nMarital_crosstab=pd.crosstab(df_train['Marital'],df_train['CarInsurance'],colnames=['Car Insurance'])\nMarital_crosstab['Percentage Enrolled']=round(Marital_crosstab[1]/(Marital_crosstab[0]+Marital_crosstab[1])*100,2)\nMarital_crosstab","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* people who are single have enrolled for the insurance more than the divorced ones & married people are the highest group to have enrolled in it."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting the above values.\n\nMarital_crosstab.drop(['Percentage Enrolled'], axis=1).plot(kind='bar',stacked=False,figsize=(20,6))\nplt.xticks(rotation = 0,fontsize=12)\nplt.xlabel('Marital Status',fontsize=16)\nplt.ylabel('Car Insurance',fontsize=16)\nplt.title('Car Insurance Policy Decisions w.r.t Marital Status',fontsize=18)\nplt.legend(['Rejected','Accepted'],title='Car Insurance',title_fontsize=15,prop={\"size\":12})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's check the dependancy of Education on Car Insurance Opting Decisions\n\nEducation_crosstab=pd.crosstab(df_train['Education'],df_train['CarInsurance'],colnames=['Car Insurance'])\nEducation_crosstab['Percentage Enrolled']=round(Education_crosstab[1]/(Education_crosstab[0]+Education_crosstab[1])*100,2)\nEducation_crosstab","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* People having secondary level of education are the highest enrollers. But, there are more rejectors than enrollers."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting the above values.\n\nEducation_crosstab.drop(['Percentage Enrolled'], axis=1).plot(kind='bar',stacked=False,figsize=(20,6))\nplt.xticks(rotation = 0,fontsize=12)\nplt.xlabel('Education',fontsize=16)\nplt.ylabel('Car Insurance',fontsize=16)\nplt.title('Car Insurance Policy Decisions w.r.t Education',fontsize=18)\nplt.legend(['Rejected','Accepted'],title='Car Insurance',title_fontsize=15,prop={\"size\":12})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's check the dependancy of House-Hold Insurance on Car Insurance Opting Decisions\n\nHHInsurance_crosstab=pd.crosstab(df_train['HHInsurance'],df_train['CarInsurance'],colnames=['Car Insurance'])\nHHInsurance_crosstab['Percentage Enrolled']=round(HHInsurance_crosstab[1]/(HHInsurance_crosstab[0]+HHInsurance_crosstab[1])*100,2)\nHHInsurance_crosstab","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Most of them having a House-Hold Insurance (1380 Customers) have rejected the car Insurance."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting the above values.\n\nHHInsurance_crosstab.drop(['Percentage Enrolled'], axis=1).plot(kind='bar',stacked=False,figsize=(20,6))\nplt.xticks(rotation = 0,fontsize=12)\nplt.xlabel('House-Hold Insurance',fontsize=16)\nplt.ylabel('Car Insurance',fontsize=16)\nplt.title('Car Insurance Policy Decisions w.r.t House-Hold Insurance',fontsize=18)\nplt.legend(['Rejected','Accepted','Percentage Accepted'],title='Car Insurance',title_fontsize=15,prop={\"size\":12})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's check the dependancy of Loan defaulting on Car Insurance Opting Decisions\n\nDefault_crosstab=pd.crosstab(df_train['Default'],df_train['CarInsurance'],colnames=['Car Insurance'])\nDefault_crosstab['Percentage Enrolled']=round(Default_crosstab[1]/(Default_crosstab[0]+Default_crosstab[1])*100,2)\nDefault_crosstab","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* About 40% of the Non-Defaulters have enrolled in the policy & 14 Defaulters have also enrolled themselves in the policy."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting the above values.\n\nDefault_crosstab.drop(['Percentage Enrolled'], axis=1).plot(kind='bar',stacked=False,figsize=(20,6))\nplt.xticks(rotation = 0,fontsize=12)\nplt.xlabel('Default',fontsize=16)\nplt.ylabel('Car Insurance',fontsize=16)\nplt.title('Car Insurance Policy Decisions w.r.t Loan Defaulting',fontsize=18)\nplt.legend(['Rejected','Accepted'],title='Car Insurance',title_fontsize=15,prop={\"size\":12})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's check the dependancy of Car Loan on Car Insurance Opting Decisions\n\nCarLoan_crosstab=pd.crosstab(df_train['CarLoan'],df_train['CarInsurance'],colnames=['Car Insurance'])\nCarLoan_crosstab['Percentage Enrolled']=round(CarLoan_crosstab[1]/(CarLoan_crosstab[0]+CarLoan_crosstab[1])*100,2)\nCarLoan_crosstab","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* About 42% of them without a car loan have enrolled in the policy.\n* So, it's likely that more people without a car loan (about 41%) may enroll in the policy."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting the above values.\n\nCarLoan_crosstab.drop(['Percentage Enrolled'], axis=1).plot(kind='bar',stacked=False,figsize=(20,6))\nplt.xticks(rotation = 0,fontsize=12)\nplt.xlabel('Car Loan',fontsize=16)\nplt.ylabel('Car Insurance',fontsize=16)\nplt.title('Car Insurance Policy Decisions w.r.t Car Loan',fontsize=18)\nplt.legend(['Rejected','Accepted'],title='Car Insurance',title_fontsize=15,prop={\"size\":12})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's check the dependancy of the Mode of Communication on Car Insurance Opting Decisions\n\nCommunication_crosstab=pd.crosstab(df_train['Communication'],df_train['CarInsurance'],colnames=['Car Insurance'])\nCommunication_crosstab['Percentage Enrolled']=round(Communication_crosstab[1]/(Communication_crosstab[0]+Communication_crosstab[1])*100,2)\nCommunication_crosstab","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Almost 40% of them who have been contacted through a cellular device have enrolled in the policy.\n* So, the probability of getting the people enrolled in the policy by contacting them through a cellular device is high."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting the above values.\n\nCommunication_crosstab.drop(['Percentage Enrolled'], axis=1).plot(kind='bar',stacked=False,figsize=(20,6))\nplt.xticks(rotation = 0,fontsize=12)\nplt.xlabel('Communication',fontsize=16)\nplt.ylabel('Car Insurance',fontsize=16)\nplt.title('Car Insurance Policy Decisions w.r.t Communication',fontsize=18)\nplt.legend(['Rejected','Accepted'],title='Car Insurance',title_fontsize=15,prop={\"size\":12})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's check the dependancy of the Contact Month on Car Insurance Opting Decisions\n\nLastContactMonth_crosstab=pd.crosstab(df_train['LastContactMonth'],df_train['CarInsurance'],colnames=['Car Insurance'])\nLastContactMonth_crosstab['Percentage Enrolled']=round(LastContactMonth_crosstab[1]/(LastContactMonth_crosstab[0]+\n                                                                                     LastContactMonth_crosstab[1])*100,2)\nLastContactMonth_crosstab","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* More People who have been contacted during the months of \"March\", \"April\", \"September\", \"October\" & \"December\" have enrolled in the policy than compared with the other months. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting the above values.\n\nLastContactMonth_crosstab.drop(['Percentage Enrolled'], axis=1).plot(kind='bar',stacked=False,figsize=(20,6))\nplt.xticks(rotation = 0,fontsize=12)\nplt.xlabel('Last Contact Month',fontsize=16)\nplt.ylabel('Car Insurance',fontsize=16)\nplt.title('Car Insurance Policy Decisions w.r.t Last Contact Month',fontsize=18)\nplt.legend(['Rejected','Accepted'],title='Car Insurance',title_fontsize=15,prop={\"size\":12})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's define a new column containing the categorical values of the days of a month.\n\ndef Day_Categories(day):\n    if(day >= 1 and day <= 11):\n        return \"Month Starting\"\n    elif(day >= 12 and day <= 21):\n        return \"Middle of the Month\"\n    elif(day >= 22 and day <= 31):\n        return \"Month Ending\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Day_Categories']=df_train['LastContactDay'].apply(Day_Categories)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's check the dependancy of Last Contacted Day on Car Insurance Opting Decisions\n\nLastContactDay_crosstab=pd.crosstab(df_train['Day_Categories'],df_train['CarInsurance'],colnames=['Car Insurance'])\nLastContactDay_crosstab['Percentage Enrolled']=round(LastContactDay_crosstab[1]/(LastContactDay_crosstab[0]+\n                                                                                     LastContactDay_crosstab[1])*100,2)\nLastContactDay_crosstab","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* More people have enrolled in the policy during the Starting & ending days of the month than compared with the middle of the month."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting the above values.\n\nLastContactDay_crosstab.drop(['Percentage Enrolled'], axis=1).plot(kind='bar',stacked=False,figsize=(20,6))\nplt.xticks(rotation = 0,fontsize=12)\nplt.xlabel('Last Contact Day',fontsize=16)\nplt.ylabel('Car Insurance',fontsize=16)\nplt.title('Car Insurance Policy Decisions w.r.t Last Contact Day',fontsize=18)\nplt.legend(['Rejected','Accepted'],title='Car Insurance',title_fontsize=15,prop={\"size\":12})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.NoOfContacts.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's categorize the No of times the bank has contacted the customers regarding the Insurance policy.\n\ndef update_contacts(contact):\n    if(contact == 1):\n        return \"Contacted once\"\n    elif(contact > 1 and contact <= 10):\n        return \"Contacted More than once\"\n    elif(contact > 10 and contact <= 20):\n        return \"Contacted more than 10 times\"\n    elif(contact > 20 and contact <= 30):\n        return \"Contacted more than 20\"\n    elif(contact > 30):\n        return \"Contacted more than 30 times\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['NoOfContacts_Category']=df_train['NoOfContacts'].apply(update_contacts)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.NoOfContacts_Category.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dependancy of No of contacts by the bank on Car Insurance Opting Decisions\n\nNoOfContacts_Category_crosstab=pd.crosstab(df_train['NoOfContacts_Category'],df_train['CarInsurance'],colnames=['Car Insurance'])\nNoOfContacts_Category_crosstab['Percentage Enrolled']=round(NoOfContacts_Category_crosstab[1]/(NoOfContacts_Category_crosstab[0]+\n                                                                                     NoOfContacts_Category_crosstab[1])*100,2)\nNoOfContacts_Category_crosstab","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* When contacted just once, almost 46% of them have enrolled in the policy.\n* So, there's a better chance of getting the people into enrolling themselves by contacting & convincing them once or more than once in       some cases.\n* So, higher the bank tries to contact the people, they're more likely to not opt the policy."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting the above values.\n\nNoOfContacts_Category_crosstab.drop(['Percentage Enrolled'], axis=1).plot(kind='bar',stacked=False,figsize=(20,6))\nplt.xticks(rotation = 90,fontsize=12)\nplt.xlabel('No of Contacts made',fontsize=16)\nplt.ylabel('Car Insurance',fontsize=16)\nplt.title('Car Insurance Policy Decisions w.r.t Contacts made',fontsize=18)\nplt.legend(['Rejected','Accepted'],title='Car Insurance',title_fontsize=15,prop={\"size\":12})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converting \"Call Duration\" to minutes.\n\ndf_train['Call_Duration']=df_train['Call_Duration'].apply(lambda x: round(x/60),2)\ndf_train['Call_Duration'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dependancy of Call Duration on Car Insurance Opting Decisions\n\nCall_Duration_crosstab=pd.crosstab(df_train['Call_Duration'],df_train['CarInsurance'],colnames=['Car Insurance'],\n                                   rownames=['Call Duration (in minutes)'])\nCall_Duration_crosstab['Percentage Enrolled']=round(Call_Duration_crosstab[1]/(Call_Duration_crosstab[0]+ Call_Duration_crosstab[1])*100,2)\nCall_Duration_crosstab","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* 1 person who hasen't received the call has enrolled themselves in the policy.\n* It can be observed that longer the call duration, more customers have enrolled themselves in the policy.\n* It may be that during longer calls with the customers, the bank officials may have gotten more time to convince the customers for \n  their enrollment."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting the above values.\n\nCall_Duration_crosstab.drop(['Percentage Enrolled'], axis=1).plot(kind='bar',stacked=False,figsize=(20,6))\nplt.xticks(rotation = 0,fontsize=12)\nplt.xlabel('Call Duration (in minutes)',fontsize=16)\nplt.ylabel('Car Insurance',fontsize=16)\nplt.title('Car Insurance Policy Decisions w.r.t Call Duration',fontsize=18)\nplt.legend(['Rejected','Accepted'],title='Car Insurance',title_fontsize=15,prop={\"size\":12})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's categorize the Call durations for better understanding according to the mean duration.\n\nmean=df_train.Call_Duration.mean()\nmean\n\ndef update_duration(call):\n    if(call < mean):\n        return \"Less than Mean Duration\"\n    elif(call > mean):\n        return \"More than Mean Duration\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Call_Duration_Mean']=df_train['Call_Duration'].apply(update_duration)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dependancy of Mean Call Duration on Car Insurance Opting Decisions\n\nMean_Call_Duration_crosstab=pd.crosstab(df_train['Call_Duration_Mean'],df_train['CarInsurance'],colnames=['Car Insurance'],\n                                   rownames=['Call Duration (in minutes)'])\nMean_Call_Duration_crosstab['Percentage Enrolled']=round(Mean_Call_Duration_crosstab[1]/(Mean_Call_Duration_crosstab[0]+ Mean_Call_Duration_crosstab[1])*100,2)\nMean_Call_Duration_crosstab","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* When the call duration b/w the customers & bank is greater than the mean call duration, more customers have enrolled themselves in the policy"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting the above values.\n\nMean_Call_Duration_crosstab.drop(['Percentage Enrolled'], axis=1).plot(kind='bar',stacked=False,figsize=(20,6))\nplt.xticks(rotation = 0,fontsize=12)\nplt.xlabel('Call Duration (in minutes)',fontsize=16)\nplt.ylabel('Car Insurance',fontsize=16)\nplt.title('Car Insurance Policy Decisions w.r.t Mean Call Duration',fontsize=18)\nplt.legend(['Rejected','Accepted'],title='Car Insurance',title_fontsize=15,prop={\"size\":12})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(21,7))\nres=sns.heatmap(df_train.corr(),annot=True)\nres.set_xticklabels (res.get_xmajorticklabels (), fontsize = 12,rotation=45)\nres.set_yticklabels (res.get_xmajorticklabels (), fontsize = 12)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* There is a correlation of 0.5 b/w \"DaysPassed\" & PrevAttempts.\n* There is a correlationof 0.48 b/w \"CarInsurance\" & \"Call_Duration\"."},{"metadata":{},"cell_type":"markdown","source":"# Data Preparation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's drop the columns \"Id\", \"CallStart\" & \"CallEnd\".\n\ndf_train.drop(['Id','CallStart','CallEnd'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's convert all the categorical valued features into numerical values by using get_dummies method in pandas. \n\ndf_train=pd.get_dummies(data=df_train,columns=['Job','Marital','Education','Communication','LastContactMonth','NoOfContacts_Category',\n                                      'Call_Duration_Mean','Day_Categories','Age Range','Call_Duration_Mean'],drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removing all the duplicate columns if any.\n\ndf_train = df_train.loc[:,~df_train.columns.duplicated()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluating the important features for consideration using SelectKBest method.\n\nX_temp=df_train.drop(['CarInsurance','NoOfContacts_Category_Contacted more than 10 times','NoOfContacts_Category_Contacted more than 20',\n               'NoOfContacts_Category_Contacted more than 30 times','NoOfContacts_Category_Contacted once',\n                'Call_Duration_Mean_More than Mean Duration','Day_Categories_Month Ending','Day_Categories_Month Starting',\n               'Age Range_21-30','Age Range_31-40','Age Range_41-50','Age Range_51-60','Age Range_61-70','Age Range_71-80',\n               'Age Range_81-90','Age Range_Above 90'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dropping all the columns created for the purpose of visualization in the above cell along with the target label column \"CarInsurance\"."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_temp.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_temp=df_train['CarInsurance']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"# As there are -ve values present in the data, we need to use \"f_classif\" scoring function.\n# Let's select top 35 features.\n\nBest_Params=SelectKBest(score_func=f_classif, k=35)\nBest_Params.fit(X_temp,y_temp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_scores=pd.DataFrame(Best_Params.scores_)                    # Feature Scores\ndf_columns=pd.DataFrame(X_temp.columns)                        # Feature Names\ndf_score_evaluation=pd.concat([df_scores,df_columns],axis=1)   # Concatinating both the dataframes\ndf_score_evaluation.columns=['Scores','Features']              # Renaming the columns\nprint(df_score_evaluation.nlargest(35,'Scores'))               # Sorting Scores in Descending order","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_temp.columns.sort_values()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import copy\nX_new=copy.deepcopy(X_temp)\nX_new.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_new=copy.deepcopy(y_temp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's split the data into Training & Test sets.\n\nX_train,X_test,y_train,y_test=train_test_split(X_new,y_new,test_size=0.20,random_state=42)\n\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"# LOGISTIC REGRESSION MODEL\n\nlr_model=LogisticRegression()\n\n# Hyper-parameter tuning\nsolvers = ['newton-cg', 'lbfgs', 'liblinear']\npenalty = ['l2']\nlr_c = [100, 10, 1.0, 0.1, 0.01]\n\nlr_grid = dict(solver=solvers,penalty=penalty,C=lr_c)\n\n# cross-validation using Repeated Stratified K-fold method.\nlr_cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n\n# Grid Search CV method loops through the different hyper parameters determining the optimal values.\nlr_grid_search = GridSearchCV(estimator=lr_model, param_grid=lr_grid, n_jobs=-1, cv=lr_cv, scoring='accuracy',error_score=0)\n\n# Fitting the Model to the Dataset.\nlr_grid_result=lr_grid_search.fit(X_train,y_train)\n\n# returns the best hyper parameters.\nlr_grid_result.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making predictions using our model.\nlr_grid_predictions=lr_grid_result.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model Metrics\n\nprint(\"LOGISTIC REGRESSION Model Performance Metrics:\")\nprint(classification_report(y_test,lr_grid_predictions))\n\nprint(\"CONFUSION MATRIX :\")\nprint(confusion_matrix(y_test,lr_grid_predictions))\nprint(\"\\n\")\n\nplt.figure(figsize=(12,6))\npyplot.plot([0, 1], [0, 1], linestyle='--', label='No Skill Classifier') # Let's define a no skill (Dummy) Classifier for reference.\n\nfpr, tpr, _ = roc_curve(y_test,lr_grid_predictions)             # passing the target labels & Model Predictions to the roc_curve method. \n\npyplot.plot(fpr, tpr, marker='.', label='Logistic Regression')  # Plotting the obtained results.\n\nns_probs = [0 for _ in range(len(y_test))]       # generating predictions from the no skill (Dummy) classifier for reference.\n\n# Calculating Area under Curve for the No Skill & the trained Model.\nns_auc = roc_auc_score(y_test, ns_probs)             \nlr_auc = roc_auc_score(y_test, lr_grid_predictions)\n\nprint('NO SKILL CLASSIFIER: ROC AUC=%.3f' % (ns_auc))\nprint('LOGISTIC REGRESSION: ROC AUC=%.3f' % (lr_auc))\n\npyplot.xlabel('False Positive Rate',fontsize=16)\npyplot.ylabel('True Positive Rate',fontsize=16)\npyplot.title(\"ROC Curve\",fontsize=18)\npyplot.legend(prop={'size':12})\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rc_model=RidgeClassifier()\n\nalpha = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n\nrc_grid = dict(alpha=alpha)\n\nrc_cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n\nrc_grid_search = GridSearchCV(estimator=rc_model, param_grid=rc_grid, n_jobs=-1, cv=rc_cv, scoring='accuracy',error_score=0)\n\nrc_grid_result=rc_grid_search.fit(X_train,y_train)\n\nrc_grid_result.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rc_grid_predictions=rc_grid_result.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"RIDGE CLASSIFIER Model Performance Metrics:\")\nprint(classification_report(y_test,rc_grid_predictions))\n\nprint(\"CONFUSION MATRIX :\")\nprint(confusion_matrix(y_test,rc_grid_predictions))\nprint(\"\\n\")\n\nplt.figure(figsize=(12,6))\npyplot.plot([0, 1], [0, 1], linestyle='--', label='No Skill Classifier') # Let's define a no skill (Dummy) Classifier for reference.\n\nfpr, tpr, _ = roc_curve(y_test,rc_grid_predictions)             # passing the target labels & Model Predictions to the roc_curve method. \n\npyplot.plot(fpr, tpr, marker='.', label='RIDGE CLASSIFIER')  # Plotting the obtained results.\n\nns_probs = [0 for _ in range(len(y_test))]       # generating predictions from the no skill (Dummy) classifier for reference.\n\n# Calculating Area under Curve for the No Skill & the trained Model.\nns_auc = roc_auc_score(y_test, ns_probs)             \nrc_auc = roc_auc_score(y_test, rc_grid_predictions)\n\nprint('NO SKILL CLASSIFIER: ROC AUC=%.3f' % (ns_auc))\nprint('RIDGE CLASSIFIER: ROC AUC=%.3f' % (rc_auc))\n\npyplot.xlabel('False Positive Rate',fontsize=16)\npyplot.ylabel('True Positive Rate',fontsize=16)\npyplot.title(\"ROC Curve\",fontsize=18)\npyplot.legend(prop={'size':12})\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtc_model=DecisionTreeClassifier()\n\ndtc_grid = { 'criterion':['gini','entropy'],'max_depth': np.arange(1, 10),'min_samples_split':range(1,10),'min_samples_leaf':range(1,5)}\n\ndtc_cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n\ndtc_grid_search = GridSearchCV(estimator=dtc_model, param_grid=dtc_grid, n_jobs=-1, cv=dtc_cv, scoring='accuracy',error_score=0)\n\ndtc_grid_result=dtc_grid_search.fit(X_train,y_train) \n\ndtc_grid_result.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtc_grid_predictions=dtc_grid_result.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"DECISION TREE CLASSIFIER Model Performance Metrics:\")\nprint(classification_report(y_test,dtc_grid_predictions))\n\nprint(\"CONFUSION MATRIX :\")\nprint(confusion_matrix(y_test,dtc_grid_predictions))\nprint(\"\\n\")\n\nplt.figure(figsize=(12,6))\npyplot.plot([0, 1], [0, 1], linestyle='--', label='No Skill Classifier') # Let's define a no skill (Dummy) Classifier for reference.\n\nfpr, tpr, _ = roc_curve(y_test,dtc_grid_predictions)             # passing the target labels & Model Predictions to the roc_curve method. \n\npyplot.plot(fpr, tpr, marker='.', label='DECISION TREE CLASSIFIER')  # Plotting the obtained results.\n\nns_probs = [0 for _ in range(len(y_test))]       # generating predictions from the no skill (Dummy) classifier for reference.\n\n# Calculating Area under Curve for the No Skill & the trained Model.\nns_auc = roc_auc_score(y_test, ns_probs)             \ndtc_auc = roc_auc_score(y_test, dtc_grid_predictions)\n\nprint('NO SKILL CLASSIFIER: ROC AUC=%.3f' % (ns_auc))\nprint('DECISION TREE CLASSIFIER: ROC AUC=%.3f' % (dtc_auc))\n\npyplot.xlabel('False Positive Rate',fontsize=16)\npyplot.ylabel('True Positive Rate',fontsize=16)\npyplot.title(\"ROC Curve\",fontsize=18)\npyplot.legend(prop={'size':12})\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bc_model=BaggingClassifier()\n\nbc_n_estimators = [1000]\n\nbc_grid = dict(n_estimators=bc_n_estimators)\n\nbc_cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n\nbc_grid_search = GridSearchCV(estimator=bc_model, param_grid=bc_grid, n_jobs=-1, cv=bc_cv, scoring='accuracy',error_score=0)\n\nbc_grid_result=bc_grid_search.fit(X_train,y_train)\n\nbc_grid_result.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bc_grid_predictions=bc_grid_result.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"BAGGING CLASSIFIER Model Performance Metrics:\")\nprint(classification_report(y_test,bc_grid_predictions))\n\nprint(\"CONFUSION MATRIX :\")\nprint(confusion_matrix(y_test,bc_grid_predictions))\nprint(\"\\n\")\n\nplt.figure(figsize=(12,6))\npyplot.plot([0, 1], [0, 1], linestyle='--', label='No Skill Classifier') # Let's define a no skill (Dummy) Classifier for reference.\n\nfpr, tpr, _ = roc_curve(y_test,bc_grid_predictions)             # passing the target labels & Model Predictions to the roc_curve method. \n\npyplot.plot(fpr, tpr, marker='.', label='BAGGING CLASSIFIER')  # Plotting the obtained results.\n\nns_probs = [0 for _ in range(len(y_test))]       # generating predictions from the no skill (Dummy) classifier for reference.\n\n# Calculating Area under Curve for the No Skill & the trained Model.\nns_auc = roc_auc_score(y_test, ns_probs)             \nbc_auc = roc_auc_score(y_test, bc_grid_predictions)\n\nprint('NO SKILL CLASSIFIER: ROC AUC=%.3f' % (ns_auc))\nprint('BAGGING CLASSIFIER: ROC AUC=%.3f' % (bc_auc))\n\npyplot.xlabel('False Positive Rate',fontsize=16)\npyplot.ylabel('True Positive Rate',fontsize=16)\npyplot.title(\"ROC Curve\",fontsize=18)\npyplot.legend(prop={'size':12})\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knc_model=KNeighborsClassifier()\n\nn_neighbors = range(1, 21)\nweights = ['uniform', 'distance']\nmetric = ['euclidean', 'manhattan', 'minkowski']\n\nknc_grid = dict(n_neighbors=n_neighbors,weights=weights,metric=metric)\n\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n\nknc_grid_search = GridSearchCV(estimator=knc_model, param_grid=knc_grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n\nknc_grid_result=knc_grid_search.fit(X_train,y_train)\n\nknc_grid_result.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knc_grid_predictions=knc_grid_result.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"K-NEIGHBOURS CLASSIFIER Model Performance Metrics:\")\nprint(classification_report(y_test,knc_grid_predictions))\n\nprint(\"CONFUSION MATRIX :\")\nprint(confusion_matrix(y_test,knc_grid_predictions))\nprint(\"\\n\")\n\nplt.figure(figsize=(12,6))\npyplot.plot([0, 1], [0, 1], linestyle='--', label='No Skill Classifier') # Let's define a no skill (Dummy) Classifier for reference.\n\nfpr, tpr, _ = roc_curve(y_test,knc_grid_predictions)             # passing the target labels & Model Predictions to the roc_curve method. \n\npyplot.plot(fpr, tpr, marker='.', label='K-NEIGHBOURS CLASSIFIER')  # Plotting the obtained results.\n\nns_probs = [0 for _ in range(len(y_test))]       # generating predictions from the no skill (Dummy) classifier for reference.\n\n# Calculating Area under Curve for the No Skill & the trained Model.\nns_auc = roc_auc_score(y_test, ns_probs)             \nknc_auc = roc_auc_score(y_test, knc_grid_predictions)\n\nprint('NO SKILL CLASSIFIER: ROC AUC=%.3f' % (ns_auc))\nprint('K-NEIGHBOURS CLASSIFIER: ROC AUC=%.3f' % (knc_auc))\n\npyplot.xlabel('False Positive Rate',fontsize=16)\npyplot.ylabel('True Positive Rate',fontsize=16)\npyplot.title(\"ROC Curve\",fontsize=18)\npyplot.legend(prop={'size':12})\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc_model=RandomForestClassifier()\n\nmax_features = ['sqrt', 'log2']\n\nrfc_n_estimators = [1000]\n\nrfc_grid = dict(n_estimators=rfc_n_estimators,max_features=max_features)\n\nrfc_cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n\nrfc_grid_search = GridSearchCV(estimator=rfc_model, param_grid=rfc_grid, n_jobs=-1, cv=rfc_cv, scoring='accuracy',error_score=0)\n\nrfc_grid_result=rfc_grid_search.fit(X_train,y_train)\n\nrfc_grid_result.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc_grid_predictions=rfc_grid_result.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"RANDOM FOREST CLASSIFIER Model Performance Metrics:\")\nprint(classification_report(y_test,rfc_grid_predictions))\n\nprint(\"CONFUSION MATRIX :\")\nprint(confusion_matrix(y_test,rfc_grid_predictions))\nprint(\"\\n\")\n\nplt.figure(figsize=(12,6))\npyplot.plot([0, 1], [0, 1], linestyle='--', label='No Skill Classifier') # Let's define a no skill (Dummy) Classifier for reference.\n\nfpr, tpr, _ = roc_curve(y_test,rfc_grid_predictions)             # passing the target labels & Model Predictions to the roc_curve method. \n\npyplot.plot(fpr, tpr, marker='.', label='RANDOM FOREST CLASSIFIER')  # Plotting the obtained results.\n\nns_probs = [0 for _ in range(len(y_test))]       # generating predictions from the no skill (Dummy) classifier for reference.\n\n# Calculating Area under Curve for the No Skill & the trained Model.\nns_auc = roc_auc_score(y_test, ns_probs)             \nrfc_auc = roc_auc_score(y_test, rfc_grid_predictions)\n\nprint('NO SKILL CLASSIFIER: ROC AUC=%.3f' % (ns_auc))\nprint('RANDOM FOREST CLASSIFIER: ROC AUC=%.3f' % (rfc_auc))\n\npyplot.xlabel('False Positive Rate',fontsize=16)\npyplot.ylabel('True Positive Rate',fontsize=16)\npyplot.title(\"ROC Curve\",fontsize=18)\npyplot.legend(prop={'size':12})\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svc_model=SVC()\n\n#kernel = ['poly', 'rbf', 'sigmoid']\n#C = [50, 10, 1.0, 0.1, 0.01]\n\nkernel=['rbf']\nC=[1000]\ngamma = ['scale']\n\nsvc_grid = dict(kernel=kernel,C=C,gamma=gamma)\n\nsvc_cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n\nsvc_grid_search = GridSearchCV(estimator=svc_model, param_grid=svc_grid, n_jobs=-1, cv=svc_cv, scoring='accuracy',error_score=0)\n\nsvc_grid_result=svc_grid_search.fit(X_train,y_train)\n\nsvc_grid_result.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svc_grid_predictions=svc_grid_result.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"SVM CLASSIFIER Model Performance Metrics:\")\nprint(classification_report(y_test,svc_grid_predictions))\n\nprint(\"CONFUSION MATRIX :\")\nprint(confusion_matrix(y_test,svc_grid_predictions))\nprint(\"\\n\")\n\nplt.figure(figsize=(12,6))\npyplot.plot([0, 1], [0, 1], linestyle='--', label='No Skill Classifier') # Let's define a no skill (Dummy) Classifier for reference.\n\nfpr, tpr, _ = roc_curve(y_test,svc_grid_predictions)             # passing the target labels & Model Predictions to the roc_curve method. \n\npyplot.plot(fpr, tpr, marker='.', label='SVM CLASSIFIER')  # Plotting the obtained results.\n\nns_probs = [0 for _ in range(len(y_test))]       # generating predictions from the no skill (Dummy) classifier for reference.\n\n# Calculating Area under Curve for the No Skill & the trained Model.\nns_auc = roc_auc_score(y_test, ns_probs)             \nsvc_auc = roc_auc_score(y_test, svc_grid_predictions)\n\nprint('NO SKILL CLASSIFIER: ROC AUC=%.3f' % (ns_auc))\nprint('SVM CLASSIFIER: ROC AUC=%.3f' % (svc_auc))\n\npyplot.xlabel('False Positive Rate',fontsize=16)\npyplot.ylabel('True Positive Rate',fontsize=16)\npyplot.title(\"ROC Curve\",fontsize=18)\npyplot.legend(prop={'size':12})\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gnb_model=GaussianNB()\n\ngnb_grid = {'var_smoothing': np.logspace(0,-9, num=100)}\n\ngnb_cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n\ngnb_grid_search = GridSearchCV(estimator=gnb_model, param_grid=gnb_grid, n_jobs=-1, cv=gnb_cv, scoring='accuracy',error_score=0)\n\ngnb_grid_result=gnb_grid_search.fit(X_train,y_train)\n\ngnb_grid_result.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gnb_grid_predictions=gnb_grid_result.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"GAUSSIANNB Model Performance Metrics:\")\nprint(classification_report(y_test,gnb_grid_predictions))\n\nprint(\"CONFUSION MATRIX :\")\nprint(confusion_matrix(y_test,gnb_grid_predictions))\nprint(\"\\n\")\n\nplt.figure(figsize=(12,6))\npyplot.plot([0, 1], [0, 1], linestyle='--', label='No Skill Classifier') # Let's define a no skill (Dummy) Classifier for reference.\n\nfpr, tpr, _ = roc_curve(y_test,gnb_grid_predictions)             # passing the target labels & Model Predictions to the roc_curve method. \n\npyplot.plot(fpr, tpr, marker='.', label='GAUSSIANNB CLASSIFIER')  # Plotting the obtained results.\n\nns_probs = [0 for _ in range(len(y_test))]       # generating predictions from the no skill (Dummy) classifier for reference.\n\n# Calculating Area under Curve for the No Skill & the trained Model.\nns_auc = roc_auc_score(y_test, ns_probs)             \ngnb_auc = roc_auc_score(y_test, gnb_grid_predictions)\n\nprint('NO SKILL CLASSIFIER: ROC AUC=%.3f' % (ns_auc))\nprint('GAUSSIANNB CLASSIFIER: ROC AUC=%.3f' % (gnb_auc))\n\npyplot.xlabel('False Positive Rate',fontsize=16)\npyplot.ylabel('True Positive Rate',fontsize=16)\npyplot.title(\"ROC Curve\",fontsize=18)\npyplot.legend(prop={'size':12})\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gbc_model=GradientBoostingClassifier()\n\n#n_estimators = [10, 100, 1000]\n#gbc_n_estimators = [0.001, 0.01, 0.1]\n#gbc_subsample = [0.5, 0.7, 1.0]\n#gbc_max_depth = [3, 7, 9]\n#gbc_learning_rate = [0.0001, 0.001, 0.01, 0.1]\n\ngbc_n_estimators = [1000]\ngbc_learning_rate = [0.01]\ngbc_subsample = [0.5]\ngbc_max_depth = [7]\n\ngbc_grid = dict(learning_rate=gbc_learning_rate, n_estimators=gbc_n_estimators, subsample=gbc_subsample, max_depth=gbc_max_depth)\n\ngbc_cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n\ngbc_grid_search = GridSearchCV(estimator=gbc_model, param_grid=gbc_grid, n_jobs=-1, cv=gbc_cv, scoring='accuracy',error_score=0)\n\ngbc_grid_result=gbc_grid_search.fit(X_train,y_train)\n\ngbc_grid_result.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gbc_grid_predictions=gbc_grid_result.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"GRADIENT BOOSTING Model Performance Metrics:\")\nprint(classification_report(y_test,gbc_grid_predictions))\n\nprint(\"CONFUSION MATRIX :\")\nprint(confusion_matrix(y_test,gbc_grid_predictions))\nprint(\"\\n\")\n\nplt.figure(figsize=(12,6))\npyplot.plot([0, 1], [0, 1], linestyle='--', label='No Skill Classifier') # Let's define a no skill (Dummy) Classifier for reference.\n\nfpr, tpr, _ = roc_curve(y_test,gbc_grid_predictions)             # passing the target labels & Model Predictions to the roc_curve method. \n\npyplot.plot(fpr, tpr, marker='.', label='GRADIENT BOOSTING MODEL')  # Plotting the obtained results.\n\nns_probs = [0 for _ in range(len(y_test))]       # generating predictions from the no skill (Dummy) classifier for reference.\n\n# Calculating Area under Curve for the No Skill & the trained Model.\nns_auc = roc_auc_score(y_test, ns_probs)             \ngbc_auc = roc_auc_score(y_test, gbc_grid_predictions)\n\nprint('NO SKILL CLASSIFIER: ROC AUC=%.3f' % (ns_auc))\nprint('GRADIENT BOOSTING MODEL: ROC AUC=%.3f' % (gbc_auc))\n\npyplot.xlabel('False Positive Rate',fontsize=16)\npyplot.ylabel('True Positive Rate',fontsize=16)\npyplot.title(\"ROC Curve\",fontsize=18)\npyplot.legend(prop={'size':12})\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgbc_model=XGBClassifier()\n\n#n_estimators = [10,100,1000]\n#xgbc_learning_rate = [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3]\n#xgbc_subsample = [0.3,0.4,0.5,.6,0.7,0.8,0.9]\n#xgbc_max_depth = [3, 4, 5, 6, 7, 8, 9]\n#colsample_bytree = [0.5,0.6,0.7,0.8,0.9],\n#xgbc_min_child_weight = [1, 2, 3, 4]\n\nxgbc_n_estimators = [1000]\nxgbc_learning_rate = [0.01]\nxgbc_subsample = [0.7]\nxgbc_max_depth = [8]\nxgbc_min_child_weight = [1]\n\ngrid = dict(n_estimators=xgbc_n_estimators,learning_rate=xgbc_learning_rate,subsample=xgbc_subsample,max_depth=xgbc_max_depth,\nmin_child_weight=xgbc_min_child_weight)\n\nxgbc_cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n\nxgbc_grid_search = GridSearchCV(estimator=xgbc_model, param_grid=grid, n_jobs=-1, cv=xgbc_cv, scoring='accuracy',error_score=0)\n\nxgbc_grid_result=xgbc_grid_search.fit(X_train,y_train)\n\nxgbc_grid_result.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgbc_grid_predictions=xgbc_grid_result.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"EXTREME GRADIENT BOOSTING Model Performance Metrics:\")\n#print(classification_report(y_test,xgbc_grid_predictions,output_dict=True))\nprint(classification_report(y_test,xgbc_grid_predictions))\n\nprint(\"CONFUSION MATRIX :\")\nprint(confusion_matrix(y_test,xgbc_grid_predictions))\nprint(\"\\n\")\n\nplt.figure(figsize=(12,6))\npyplot.plot([0, 1], [0, 1], linestyle='--', label='No Skill Classifier') # Let's define a no skill (Dummy) Classifier for reference.\n\nfpr, tpr, _ = roc_curve(y_test,xgbc_grid_predictions)             # passing the target labels & Model Predictions to the roc_curve method. \n\npyplot.plot(fpr, tpr, marker='.', label='EXTREME GRADIENT BOOSTING MODEL')  # Plotting the obtained results.\n\nns_probs = [0 for _ in range(len(y_test))]       # generating predictions from the no skill (Dummy) classifier for reference.\n\n# Calculating Area under Curve for the No Skill & the trained Model.\nns_auc = roc_auc_score(y_test, ns_probs)             \nxgbc_auc = roc_auc_score(y_test, xgbc_grid_predictions)\n\nprint('NO SKILL CLASSIFIER: ROC AUC=%.3f' % (ns_auc))\nprint('EXTREME GRADIENT BOOSTING MODEL: ROC AUC=%.3f' % (xgbc_auc))\n\npyplot.xlabel('False Positive Rate',fontsize=16)\npyplot.ylabel('True Positive Rate',fontsize=16)\npyplot.title(\"ROC Curve\",fontsize=18)\npyplot.legend(prop={'size':12})\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Let's Display all the Model Metrics in a dataframe for easier analysis**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model Names\nModel_Names=['LOGISTIC REGRESSION', 'RIDGE CLASSIFIER', 'DECISION TREE', 'BAGGING CLASSIFIER', 'K-NEIGHBOURS CLASSIFIER', 'RANDOM FOREST',\n            'SVM CLASSIFIER', 'GAUSSIANNB CLASSIFIER', 'GRADIENT BOOSTING', 'EXTREME GRADIENT BOOSTING']\n\n# DataFrame Index values\nIndex=['Accuracy','Precision','Recall','F1 Score','AUC Score']\n\n# Model Prediction values\nModel_Predictions=[lr_grid_predictions,rc_grid_predictions,dtc_grid_predictions,bc_grid_predictions,knc_grid_predictions,\n                   rfc_grid_predictions,svc_grid_predictions,gnb_grid_predictions,gbc_grid_predictions,xgbc_grid_predictions]\n\n# Model Metrics methods\nmodel_metrics=[accuracy_score,precision_score,recall_score,f1_score,roc_auc_score]\n\n# DataFrame Initialisation\nModel_Metrics_Comparison=pd.DataFrame(columns=Model_Names,index=Index)\n\n# Let's fill the dataframe with the model metrics values of all the trained models above.\nfor index,metric in zip(range(0,5),model_metrics):\n    for model_name,model_prediction in zip(Model_Names,Model_Predictions):\n        Model_Metrics_Comparison[model_name].values[index]=metric(y_test,model_prediction)*100\n\n# Metric values in Percentage (%).\nModel_Metrics_Comparison","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* From the above dataframe, we can see that \"Extreme Gradient Boosting Classifier\" has an accuracy of 84.3% which is the highest among all\n  the trained models & also \"Random Forest Classifier\" has an accuracy of 84.1%.\n\n* As we cannot always depend only on the accuracy of models, we also need to consider other metrics such as \"Precision\", \"Recall\" & \n  \"F1 Score\" for optimal results.\n  \n* When a model has high values for both precision & recall, then it can be told that, that model is performing well.\n\n*  So in this case, out of any of the following models i.e., (\"BAGGING CLASSIFIER\", \"RANDOM FOREST CLASSIFIER\", \"GRADIENT BOOSTING\" & \n   \"EXTREME GRADIENT BOOSTING\"), we can get good results as all 4 models are having almost same Precision & Recall values.\n   \n* In the case of \"F1 Score\", as it is the weighted average of both precision & Recall Metrics, it can be more useful than Accuracy most of   the time.\n* We can also observe from the AUC Scores that, the Models \"EXTREME GRADIENT BOOSTING\", \"GRADIENT BOOSTING\" & \"RANDOM FOREST CLASSIFIER\" have good Area under Curve values.\n\n* Moving ahead, I'll try to improve the model performances and Metric results."},{"metadata":{},"cell_type":"markdown","source":"**If you like my Kernel, Please Upvote. Please feel free to provide suggestions in the comments which helps me to improve myself. Thank you :)**"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}