{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h1>IMPORTING LIBRARIES<h1>","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nimport warnings\nwarnings.simplefilter(\"ignore\", UserWarning)\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport torch\nimport matplotlib.pyplot as plt\nimport PIL\nfrom matplotlib import image\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom tqdm import tqdm\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>THE SIGN LANGUAGE</h1>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data = image.imread('/kaggle/input/sign-language-mnist/american_sign_language.PNG')\nplt.imshow(data)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1> READING TRAIN DATA </h1>","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data_train =pd.read_csv('/kaggle/input/sign-language-mnist/sign_mnist_train.csv')\ndata_train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>USER DEFINED FUNCTION FOR SHOWING IMAGE</h1>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def showImage(row):\n    d = data_train.drop('label',axis = 1).loc[row,:]\n    print(data_train['label'][row])\n    plt.imshow(d.values.reshape(28,28))\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"showImage(15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>DEFINING OUR NEURAL NETWORK<h1>\n    \n<h4>The architecture is similar to LeNet- 5</h4>\n    \n<img src = \"https://i.ibb.co/BPCvrY4/Screenshot-50.png\">","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class Neural_Network(nn.Module):\n    def __init__(self):\n        super(Neural_Network, self).__init__()\n        self.conv1 = nn.Conv2d(1,6,kernel_size = 3,stride = 1,padding = 1) #input: (m,28,28,1) output: (m,28,28,6)\n        self.max1 = nn.MaxPool2d(kernel_size = (2,2),stride = 2) #input: (m,28,28,6) output: (m,14,14,6)\n        self.conv2 = nn.Conv2d(6,16,kernel_size = 5,stride = 1,padding = 0) #input: (m,14,14,6) output: (m,10,10,16)\n        self.max2 = nn.MaxPool2d(kernel_size = (2,2),stride = 2) #input: (m,10,10,16) output: (m,5,5,16)\n        self.fc1 = nn.Linear(400,120) #input: (m,400) output: (m,120)\n        self.fc2 = nn.Linear(120,84) #input: (m,120) output: (m,84)\n        self.fc3 = nn.Linear(84,25) #input: (m,84) output: (m,25)\n    def forward(self,x):\n        x = F.relu(self.conv1(x))\n        x = self.max1(x)\n        x = F.relu(self.conv2(x))\n        x = self.max2(x)\n        x = torch.flatten(x,start_dim = 1)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n            ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>INITIALIZING THE NEURAL NETWORK</h1>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"net = Neural_Network()\nnet\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>CONFIGURING GPU</h1>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(torch.cuda.is_available())\ndevice = torch.device(\"cuda:0\")\nnet.to(device)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>FUNCTION TO RUN THE NEURAL NETWORK</h1>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#STORE THE LOSS AT EACH EPOCH\nloss_list = []\n\n#FUNCTION\ndef RUN_NETWORK(train,EPOCHS,test,batch_size):\n    # WE USE THE ADAM OPTIMIZER\n    optimizer = optim.Adam(net.parameters(),lr = 0.001)\n    # WE USE SCHEDULER SO THAT AT EVERY 10 EPOCHS LEARNING REDUCES BY A FACTOR OF 10\n    scheduler = torch.optim.lr_scheduler.StepLR(optimizer,step_size = 10,gamma = 0.1)\n    # WE USE CROSS ENTROPY LOSS\n    loss = nn.CrossEntropyLoss()\n    \n    for epoch in (range(EPOCHS)):\n        scheduler.step()\n        print('Epoch:', epoch,'LR:', scheduler.get_last_lr())\n        \n        for i in (range(0,train.shape[0],batch_size)):\n            net.zero_grad()\n            \n            X_train = torch.from_numpy(train[i:i+batch_size].values).type(torch.float).view(-1,1,28,28)\n            y_train = torch.from_numpy(test[i:i+batch_size].values)\n            X_train, y_train = X_train.to(device),y_train.to(device)\n            \n            output = net(X_train)\n            l = loss(output,y_train)\n            \n            l.backward()\n            optimizer.step()\n        \n        print(\"train loss : \" + str(l))\n        loss_list.append(l)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>RUNNING THE NETWORK</h1>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"RUN_NETWORK(data_train.drop('label',axis = 1),50,data_train['label'],85)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>LOSS VS ITERATIONS GRAPH</h1>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(np.arange(50),list(map(torch.Tensor.item,loss_list)))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1> IMPORTING THE TEST DATA </h1>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_test = pd.read_csv('/kaggle/input/sign-language-mnist/sign_mnist_test.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>PREDICTING ON TRAIN AND TEST SET</h1>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_train = torch.argmax(net(torch.from_numpy(data_train.drop('label',axis = 1).values.reshape(-1,1,28,28)).type(torch.float).to(device)),dim = 1)\ny_pred_test = torch.argmax(net(torch.from_numpy(data_test.drop('label',axis = 1).values.reshape(-1,1,28,28)).type(torch.float).to(device)),dim = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>PRINTING ACCURACY<h1>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nprint(\"The obtained test accuracy is \" + str(accuracy_score(data_test['label'],np.array(y_pred_test.cpu()))))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}