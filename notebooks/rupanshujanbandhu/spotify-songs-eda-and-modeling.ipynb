{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go\nfrom sklearn.preprocessing import MinMaxScaler, LabelEncoder, OneHotEncoder\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import *\nimport warnings","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"warnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_genre = pd.read_csv(\"../input/dataset-of-songs-in-spotify/genres_v2.csv\")\ndf_playlist = pd.read_csv(\"../input/dataset-of-songs-in-spotify/playlists.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_genre.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_genre.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"px.imshow(img=df_genre.isna(), title='Missing values(yellow: missing, blue: not missing)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Interesting. The song_name column has missing values when `Unnamed: 0` and title columns are both null and vice versa. There's a little line for song_name at 20k but if you zoom in, it's gone. But the last 3 columns are a mystery. Why is there a missing pattern like that?  Let's see their content real quick."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_genre['song_name'].head(10), df_genre['Unnamed: 0'].tail(10), df_genre['title'].tail(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, `title` looks like it contains the name of playlist, `Unnamed: 0` is just increasing numbers and `song_name` is, well, song's name. We're just not going to take these features into consideration anymore. We'll also drop `id`, `uri`, `track_href` and `analysis_url`."},{"metadata":{},"cell_type":"markdown","source":"## What % values are missing for each feature?"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_pcmiss = df_genre.isna().sum(axis=0) / df_genre.shape[0] * 100\ndf_pcmiss = df_pcmiss.reset_index().rename(columns={'index': 'feature', 0: '% missing'})\npx.bar(df_pcmiss, x='feature', y='% missing', title='% of missing values for each feature')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets look at the data distribution for these features."},{"metadata":{"trusted":true},"cell_type":"code","source":"dist_columns = ['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness',\n       'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo',\n       'type', 'duration_ms', 'time_signature', 'genre']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(dist_columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rows = 3\ncols = 5\n\nfig = make_subplots(rows=rows, cols=cols, subplot_titles=dist_columns)\n\nx, y = np.meshgrid(np.arange(rows) + 1, np.arange(cols) + 1)\n\ncount = 0\nfor row, col in zip(x.T.reshape(-1), y.T.reshape(-1)):\n    fig.add_trace(\n            go.Histogram(x=df_genre[dist_columns[count]].values),\n            row=row, col=col\n        )\n    count += 1\n\nfig.update_layout(height=900, width=900, title_text=\"Feature distribution\", showlegend=False)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Observations:\n\n1. danceability - (almost) has a normal distribution\n2. energy - most of the songs are highly energetic\n3. key - many songs are in the key of 1, for others, key is distributed equally\n4. loudness - also distributed normally\n5. mode - not much interesting\n6. speechiness - follows a chi-square-esque distribution\n7. acousticness - also follows chi-square-esque distribution\n8. instrumentalness - most of the songs are not insrumental, as expected. Very few instrumental songs make it to the top. Most songs need to have vocals to be popular.\n9. liveness - distribution is weird, there's a peak at 0.11.\n10. valence - valence in music descibes the musical positiveness conveyed by the song. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry). (Source: https://towardsdatascience.com/what-makes-a-song-likeable-dbfdb7abe404#:~:text=Valence%3A%20Describes%20the%20musical%20positiveness,measure%20of%20intensity%20and%20activity). The distribution is linear with downward slope.\n11. tempo - (almost) follows a normal distribution\n12. type - there's just one value to this feature, redundant\n13. duration_ms - most songs are 2:30 min to 4:10. There's also a list of longer songs\n14. time_signature - no song has time_signature = 2. Most common time signature is 4.\n15. genre - most popular genres are Dark Trap and Underground Rap"},{"metadata":{"trusted":true},"cell_type":"code","source":"box_columns = ['danceability', 'energy', 'key', 'loudness', \n               'speechiness', 'acousticness', 'instrumentalness',\n               'liveness', 'valence', 'tempo', 'duration_ms']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(box_columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rows = 3\ncols = 4\n\nfig = make_subplots(rows=rows, cols=cols, subplot_titles=box_columns)\n\nx, y = np.meshgrid(np.arange(rows) + 1, np.arange(cols) + 1)\n\ncount = 0\nfor row, col in zip(x.T.reshape(-1), y.T.reshape(-1)):\n    try:\n        fig.add_trace(\n            go.Box(x=df_genre[box_columns[count]].values, name=''),\n            row=row, col=col\n        )\n        count += 1\n    #if we run out of features, stop plotting\n    except:\n        break\n\nfig.update_layout(height=900, width=900, title_text=\"Boxplots\", showlegend=False)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Observation:\n\nApart from instrumentalness, valence and key, all other features have a lot of outliers."},{"metadata":{},"cell_type":"markdown","source":"# Model Building: Predicting Genre"},{"metadata":{},"cell_type":"markdown","source":"## Feature Engineering"},{"metadata":{},"cell_type":"markdown","source":"## Scaling\n\nA lot of features have values between 0 and 1(e.g. instrumentalness) while others have values in 100 thousands(duration_ms). We need to scale these features in the range of 0-1. \n\nBut first, we need to divide the dataset into train, test and validation sets."},{"metadata":{"trusted":true},"cell_type":"code","source":"features = ['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness',\n       'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo',\n        'duration_ms', 'time_signature']\nlabel    = 'genre'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df_genre[features]\ny = df_genre[label]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n# X_train_, X_val, y_train_, y_val = train_test_split(X_train, y_train, test_size=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape)\nprint(X_test.shape)\n# print(X_val.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loudness_scaler = MinMaxScaler(feature_range=(0, 1))\nX_train.loc[:, 'loudness'] = loudness_scaler.fit_transform(X_train['loudness'].values.reshape(-1, 1))\nX_test.loc[:, 'loudness'] = loudness_scaler.transform(X_test['loudness'].values.reshape(-1, 1))\n# X_val.loc[:, 'loudness'] = loudness_scaler.transform(X_val['loudness'].values.reshape(-1, 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tempo_scaler = MinMaxScaler(feature_range=(0, 1))\nX_train.loc[:, 'tempo'] = tempo_scaler.fit_transform(X_train['tempo'].values.reshape(-1, 1))\nX_test.loc[:, 'tempo'] = tempo_scaler.transform(X_test['tempo'].values.reshape(-1, 1))\n# X_val.loc[:, 'tempo'] = tempo_scaler.transform(X_val['tempo'].values.reshape(-1, 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"duration_ms_scaler = MinMaxScaler(feature_range=(0, 1))\nX_train.loc[:, 'duration_ms'] = duration_ms_scaler.fit_transform(X_train['duration_ms'].values.reshape(-1, 1))\nX_test.loc[:, 'duration_ms'] = duration_ms_scaler.transform(X_test['duration_ms'].values.reshape(-1, 1))\n# X_val.loc[:, 'duration_ms'] = duration_ms_scaler.transform(X_val['duration_ms'].values.reshape(-1, 1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## One Hot Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = pd.concat([X_train, pd.get_dummies(X_train['key'], prefix='key', drop_first=True)], axis=1)\n\nX_test = pd.concat([X_test, pd.get_dummies(X_test['key'], prefix='key', drop_first=True)], axis=1)\n\n# X_val = pd.concat([X_val, pd.get_dummies(X_val['key'], prefix='key', drop_first=True)], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = pd.concat([X_train, pd.get_dummies(X_train['key'], prefix='key', drop_first=True)], axis=1)\n\nX_test = pd.concat([X_test, pd.get_dummies(X_test['key'], prefix='key', drop_first=True)], axis=1)\n\n# X_val = pd.concat([X_val, pd.get_dummies(X_val['key'], prefix='key', drop_first=True)], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = pd.concat([X_train, pd.get_dummies(X_train['time_signature'], prefix='time_signature', drop_first=True)], axis=1)\n\nX_test = pd.concat([X_test, pd.get_dummies(X_test['time_signature'], prefix='time_signature', drop_first=True)], axis=1)\n\n# X_val = pd.concat([X_val, pd.get_dummies(X_val['time_signature'], prefix='time_signature', drop_first=True)], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, drop `key` and `time_signature`"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.drop(['key', 'time_signature'], axis=1, inplace=True)\nX_test.drop(['key', 'time_signature'], axis=1, inplace=True)\n# X_val.drop(['key', 'time_signature'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ohe_label = OneHotEncoder()\ny_train = ohe_label.fit_transform(y_train.values.reshape(-1, 1)).toarray()\ny_test = ohe_label.transform(y_test.values.reshape(-1, 1)).toarray()\n# y_val = ohe_label.transform(y_val.values.reshape(-1, 1)).toarray()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params_dict = {\n    'n_estimators': [50, 75, 100, 125, 150],\n    'criterion': ['gini', 'entropy'],\n    'max_depth': np.arange(8, 40, 4)\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gs_cv = GridSearchCV(estimator=RandomForestClassifier(n_jobs=-1),\n                     param_grid=params_dict,\n                     cv=5,\n                     verbose=10,\n                     n_jobs=-1,\n                    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gs_cv.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('grid_search_result.pkl', 'wb') as f:\n    pickle.dump(gs_cv, f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_preds = gs_cv.best_estimator_.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"meaningfull_preds_test = ohe_label.inverse_transform(test_preds).reshape(-1)\nmeaningfull_true_test  = ohe_label.inverse_transform(y_test).reshape(-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = 14, 14\nsns.heatmap(confusion_matrix(meaningfull_true_test, meaningfull_preds_test), \n                            annot=True,\n                            xticklabels=ohe_label.categories_[0],\n                            yticklabels=ohe_label.categories_[0],\n                            fmt='d'\n           );","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# FUTURE WORK\n\n* Optimize the RF model on validation set\n* Try some more ML models\n* Try Deep Learning"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}