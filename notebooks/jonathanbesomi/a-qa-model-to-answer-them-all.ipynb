{"cells":[{"metadata":{},"cell_type":"markdown","source":"<font size=\"6\" >üëë A QA model to answer them all</font>\n\n<br>\n\n<font size=\"4\">An attempt to answer all tasks's questions with a single Question-Answering model</font>\n\n<br><br>\n\n<font size=\"3\">\n    <strong>Why:</strong> at the time of writing, there are more than 580 notebooks on the <a href=\"https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge/tasks\" >COVID-19 Open Research Dataset</a> challenge. The main reason why we are here, united, is that we want to help the research community <strong>find answers</strong>. We need to find answers now, as a deep understanding of the coronavirus infectious disease may save lives!\n</font>\n\n<br>\n \n<font size=\"3\">\n  <strong>Simple and intuitive:</strong> the second main reason we are here is to learn and grow together. This notebook has been designed and conceived to be easy-to-understand for beginners but, hopefully, full of valuable insights also for advanced Kagglers. The notebook runs in less than 5 minutes so feel free to fork and work on your own!\n</font>\n\n<br>\n\n<font size=\"3\">\n  <strong>Goal:</strong> in just a few lines of code we develop from <strong>start to finish</strong> universal question-answering systems able to answer (almost) any kind of question related to coronavirus. In particular, the notebook will attempt to answer all the questions from the <a href=\"https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge/tasks\">CORD-19 TASKS</a>. We then visualize the answer in a nice and readable format.\n</font>\n\n\n<br>\n\n<font size=\"3\">\nIf you have questions or feedback please leave a comment. Disclaimer: work in progress.\n</font>"},{"metadata":{},"cell_type":"markdown","source":"# 1. Web application and call-to-action\n\nUpdate: the output results of the model can now be visualized here: [Korono - Question and Answering model for COVID-19 paper](https://jbesomi.github.io/Korono/). This simple website let you chose the task and the questions and propose a collection of relevant papers with the answer to the questions highlighted. \n\n**I would like to know what do you think about it**. Also, if you feel like helping, I'm open to any kind of suggestions and  feedback and I'm **looking for collaborators to push further this project**. Anyone is warmly welcome to help; just leave a comment below and I'm sure we will find a way to work together!**\n\n\n<a href=\"https://jbesomi.github.io/Korono/\">\n    <img src=\"https://i.imgur.com/WUvp09u.png\" alt=\"Korono - Question and Answering model\">\n</a>"},{"metadata":{},"cell_type":"markdown","source":"# 2. Introduction\n\n### 2.1 Question-Answering (QA) model\n\nIn machine learning, a question-answering model is composed of three sources: the `question`, the `context` and the `answer`. The model inputs are the `question` and the `context` and the model output is the `answer`. In most cases, but not all, the `answer` is contained in the `context`. For simplicity, throughout the notebook, we will assume that this is indeed true.\n\nIt exists many datasets used to train the QA model. One of the most popular is she Stanford Question Answering Dataset, also known as [SQuAD](https://rajpurkar.github.io/SQuAD-explorer/). It contains thousands of tuples of the type (`question`, `context`, `answer`) used to teach the model what does it means to both **find** and **return** a question. During training, the model exploits and learn linguistical properties of the language.\n\n### 2.2 Using a search engine to produce the context\n\nIn general, the `context` is quite limited, about one page. In our case, instead, we are dealing with more than 40k papers. **We need therefore to reduce the size of the context**. We do so by selecting all the papers that are most similar to the `answer`. In the code, a very simple algorithm, [Okapi BM25](https://en.wikipedia.org/wiki/Okapi_BM25), is used. As you will see, even if Okapi BM25 is quite old (from 1980), it does a great job. In future, I plan to compare the Okapi solution against other most recent approaches and solutions such as transformers.\n\n\n### 2.3 From (context, question) to answer with transformers\n\nThis is the most interesting and magic part of all the notebook. Given a question `q` (we use the term query and question interchangeably), the previous section gives us a list of context. Now, for each context and for the same query `q`, we ask to a pre-trained and pretty-powerful transformer model what is the part of the context that **better represent** the query.\n\nYou may ask how in just a few lines of code we can build such a powerful model. The reason why is that we make use of the (great, you need to check it out if you haven't!) [Huggingface transformer library](https://github.com/huggingface/transformers) that permits us to work with ease with such complex and big neural networks.\n\nThe data obtained now, are dirty and hard to read. That's why for each task and for each question we visualize the context and the highlighted answer in a friendly way.\n\n### 2.4 Summarization abstract for each question [Coming Soon]\n\nThe code for the summarization has been written but hasn't been tested and visualized yet.\n\n### 2.5 Acknowledgement\n\nThis notebook has been inspired from the great work of:\n\n- https://www.kaggle.com/dgunning/building-a-cord19-research-engine-with-bm25 by DwightGunning\n- https://www.kaggle.com/dirktheeng/anserini-bert-squad-for-semantic-corpus-search by Dirk\n"},{"metadata":{},"cell_type":"markdown","source":"# 3. Load dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nLibraries\n\"\"\"\n\n!pip install rank_bm25 -q\n\nimport numpy as np\nimport pandas as pd \nfrom pathlib import Path, PurePath\n\nimport nltk\nfrom nltk.corpus import stopwords\nimport re\nimport string\nimport torch\n\nfrom rank_bm25 import BM25Okapi # Search engine","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nLoad metadata df\n\"\"\"\n\ninput_dir = PurePath('../input/CORD-19-research-challenge')\nmetadata_path = input_dir / 'metadata.csv'\nmetadata_df = pd.read_csv(metadata_path, low_memory=False)\nmetadata_df = metadata_df.dropna(subset=['abstract', 'title']) \\\n                            .reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Covid Search Engine\n\nWe define a python class `CovidSearchEngine`. It has two main methods, the `__init__` and `search(question)`. The `__init__` method is called only once when the class is initialized. It stores and index the dataframe passed as an argument. Once the indexing is complete, we can search similar papers simply by invoking `search(question)`. \n\n\nThe snippet of code below shows how it works:\n\n\n```python\n    metadata_df = pd.read_csv()\n    metadata_df = clean(metadata_df)\n    cse = CovidSearchEngine(metadata_df) # Covid Search Engine\n    cse.search(\"what is coronavirus?\")\n```"},{"metadata":{"trusted":true},"cell_type":"code","source":"from rank_bm25 import BM25Okapi\n\nenglish_stopwords = list(set(stopwords.words('english')))\n\nclass CovidSearchEngine:\n    \"\"\"\n    Simple CovidSearchEngine.\n    \"\"\"\n    \n    def remove_special_character(self, text):\n        #Remove special characters from text string\n        return text.translate(str.maketrans('', '', string.punctuation))\n\n    def tokenize(self, text):\n        # tokenize text\n        words = nltk.word_tokenize(text)\n        return list(set([word for word in words \n                         if len(word) > 1\n                         and not word in english_stopwords\n                         and not word.isnumeric() \n                        ])\n                   )\n    \n    def preprocess(self, text):\n        # Clean and tokenize text input\n        return self.tokenize(self.remove_special_character(text.lower()))\n\n\n    def __init__(self, corpus: pd.DataFrame):\n        self.corpus = corpus\n        self.columns = corpus.columns\n        \n        raw_search_str = self.corpus.abstract.fillna('') + ' ' \\\n                            + self.corpus.title.fillna('')\n        \n        self.index = raw_search_str.apply(self.preprocess).to_frame()\n        self.index.columns = ['terms']\n        self.index.index = self.corpus.index\n        self.bm25 = BM25Okapi(self.index.terms.tolist())\n    \n    def search(self, query, num):\n        \"\"\"\n        Return top `num` results that better match the query\n        \"\"\"\n        # obtain scores\n        search_terms = self.preprocess(query) \n        doc_scores = self.bm25.get_scores(search_terms)\n        \n        # sort by scores\n        ind = np.argsort(doc_scores)[::-1][:num] \n        \n        # select top results and returns\n        results = self.corpus.iloc[ind][self.columns]\n        results['score'] = doc_scores[ind]\n        results = results[results.score > 0]\n        return results.reset_index()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can now initialize the `cse` object class:"},{"metadata":{"trusted":true},"cell_type":"code","source":"cse = CovidSearchEngine(metadata_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Question-Answering model\n\nAs mentioned in the introduction part, we make use of a pre-trained question answering model. The first step consists of installing the dependencies and downloading the models."},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nDownload pre-trained QA model\n\"\"\"\n\nimport torch\nfrom transformers import BertTokenizer\nfrom transformers import BertForQuestionAnswering\n\ntorch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n\nBERT_SQUAD = 'bert-large-uncased-whole-word-masking-finetuned-squad'\n\nmodel = BertForQuestionAnswering.from_pretrained(BERT_SQUAD)\ntokenizer = BertTokenizer.from_pretrained(BERT_SQUAD)\n\nmodel = model.to(torch_device)\nmodel.eval()\n\nprint()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we define a function `answer_question(question, context)` that given a paper abstract and a question, it returns the span of text that better represent the question.\n\nFor instance, given as `question` _\"what is coronavirus?\"_ and as `context` _\"Coronavirus disease (COVID-19) is an infectious disease caused by a newly discovered coronavirus\"_ we expect to obtain as `answer` _\"infectious disease\"_.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def answer_question(question, context):\n    # anser question given question and context\n    encoded_dict = tokenizer.encode_plus(\n                        question, context,\n                        add_special_tokens = True,\n                        max_length = 256,\n                        pad_to_max_length = True,\n                        return_tensors = 'pt'\n                   )\n    \n    input_ids = encoded_dict['input_ids'].to(torch_device)\n    token_type_ids = encoded_dict['token_type_ids'].to(torch_device)\n    \n    start_scores, end_scores = model(input_ids, token_type_ids=token_type_ids)\n\n    all_tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n    start_index = torch.argmax(start_scores)\n    end_index = torch.argmax(end_scores)\n    \n    answer = tokenizer.convert_tokens_to_string(all_tokens[start_index:end_index+1])\n    answer = answer.replace('[CLS]', '')\n    return answer","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6. Tasks and questions\n\nIn this section, we store in a `dict` object a list of `tasks` and their `questions`. In the next parts, we will ask our model to answers them all.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"# adapted from https://www.kaggle.com/dirktheeng/anserini-bert-squad-for-semantic-corpus-search\n\ncovid_kaggle_questions = {\n\"data\":[\n          {\n              \"task\": \"What is known about transmission, incubation, and environmental stability?\",\n              \"questions\": [\n                  \"Is the virus transmitted by aerisol, droplets, food, close contact, fecal matter, or water?\",\n                  \"How long is the incubation period for the virus?\",\n                  \"Can the virus be transmitted asymptomatically or during the incubation period?\",\n                  \"How does weather, heat, and humidity affect the tramsmission of 2019-nCoV?\",\n                  \"How long can the 2019-nCoV virus remain viable on common surfaces?\"\n              ]\n          },\n          {\n              \"task\": \"What do we know about COVID-19 risk factors?\",\n              \"questions\": [\n                  \"What risk factors contribute to the severity of 2019-nCoV?\",\n                  \"How does hypertension affect patients?\",\n                  \"How does heart disease affect patients?\",\n                  \"How does copd affect patients?\",\n                  \"How does smoking affect patients?\",\n                  \"How does pregnancy affect patients?\",\n                  \"What is the fatality rate of 2019-nCoV?\",\n                  \"What public health policies prevent or control the spread of 2019-nCoV?\"\n              ]\n          },\n          {\n              \"task\": \"What do we know about virus genetics, origin, and evolution?\",\n              \"questions\": [\n                  \"Can animals transmit 2019-nCoV?\",\n                  \"What animal did 2019-nCoV come from?\",\n                  \"What real-time genomic tracking tools exist?\",\n                  \"What geographic variations are there in the genome of 2019-nCoV?\",\n                  \"What effors are being done in asia to prevent further outbreaks?\"\n              ]\n          },\n          {\n              \"task\": \"What do we know about vaccines and therapeutics?\",\n              \"questions\": [\n                  \"What drugs or therapies are being investigated?\",\n                  \"Are anti-inflammatory drugs recommended?\"\n              ]\n          },\n          {\n              \"task\": \"What do we know about non-pharmaceutical interventions?\",\n              \"questions\": [\n                  \"Which non-pharmaceutical interventions limit tramsission?\",\n                  \"What are most important barriers to compliance?\"\n              ]\n          },\n          {\n              \"task\": \"What has been published about medical care?\",\n              \"questions\": [\n                  \"How does extracorporeal membrane oxygenation affect 2019-nCoV patients?\",\n                  \"What telemedicine and cybercare methods are most effective?\",\n                  \"How is artificial intelligence being used in real time health delivery?\",\n                  \"What adjunctive or supportive methods can help patients?\"\n              ]\n          },\n          {\n              \"task\": \"What do we know about diagnostics and surveillance?\",\n              \"questions\": [\n                  \"What diagnostic tests (tools) exist or are being developed to detect 2019-nCoV?\"\n              ]\n          },\n          {\n              \"task\": \"Other interesting questions\",\n              \"questions\": [\n                  \"What is the immune system response to 2019-nCoV?\",\n                  \"Can personal protective equipment prevent the transmission of 2019-nCoV?\",\n                  \"Can 2019-nCoV infect patients a second time?\"\n              ]\n          }\n   ]\n}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 7. Compute answers\n\nNext, we define the function `get_results(question)`. \n\nGiven a question, `get_results(question)` returns a _JSON_ object with the following format:\n\n```json\n{ \n    \"question\": \"What is coronavirus?\"\n    \"results\": [\n        {\n            \"context\": \"Coronavirus disease (COVID-19) is an infectious disease ...\",\n            \"answer\": \"infectious disease\",\n            \"start_index\": 37,\n            \"end_index\": 55\n        },\n        ...\n    ]\n}\n```\n\nWhere `start_index` and `end_index` point at the start and end character of the answer in the question. This two values will be useful later to highlight the answer in the context.\n\nThe helper functions `get_all_context`, `get_all_answers` and `create_output_results` are here make the code more readable."},{"metadata":{"trusted":true},"cell_type":"code","source":"NUM_CONTEXT_FOR_EACH_QUESTION = 10\n\n\ndef get_all_context(query, num_results):\n    # Return ^num_results' papers that better match the query\n    \n    papers_df = cse.search(query, num_results)\n    return papers_df['abstract'].str.replace(\"Abstract\", \"\").tolist()\n\n\ndef get_all_answers(question, all_contexts):\n    # Ask the same question to all contexts (all papers)\n    \n    all_answers = []\n    \n    for context in all_contexts:\n        all_answers.append(answer_question(question, context))\n    return all_answers\n\n\ndef create_output_results(question, \n                          all_contexts, \n                          all_answers, \n                          summary_answer='', \n                          summary_context=''):\n    # Return results in json format\n    \n    def find_start_end_index_substring(context, answer):   \n        search_re = re.search(re.escape(answer.lower()), context.lower())\n        if search_re:\n            return search_re.start(), search_re.end()\n        else:\n            return 0, len(context)\n        \n    output = {}\n    output['question'] = question\n    output['summary_answer'] = summary_answer\n    output['summary_context'] = summary_context\n    results = []\n    for c, a in zip(all_contexts, all_answers):\n\n        span = {}\n        span['context'] = c\n        span['answer'] = a\n        span['start_index'], span['end_index'] = find_start_end_index_substring(c,a)\n\n        results.append(span)\n    \n    output['results'] = results\n        \n    return output\n\n    \ndef get_results(question, \n                summarize=False, \n                num_results=NUM_CONTEXT_FOR_EACH_QUESTION,\n                verbose=True):\n    # Get results\n\n    all_contexts = get_all_context(question, num_results)\n    \n    all_answers = get_all_answers(question, all_contexts)\n    \n    if summarize:\n        # NotImplementedYet\n        summary_answer = get_summary(all_answers)\n        summary_context = get_summary(all_contexts)\n    \n    return create_output_results(question, \n                                 all_contexts, \n                                 all_answers)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We now **iterate** over all **tasks** and all **questions** and store the results into `all_tasks`:"},{"metadata":{"trusted":true},"cell_type":"code","source":"all_tasks = []\n\nfor i, t in enumerate(covid_kaggle_questions['data']):\n    print(\"Answering questions to task {}. ...\".format(i+1))\n    answers_to_question = []\n    for q in t['questions']:\n            answers_to_question.append(get_results(q, verbose=False))\n    task = {}\n    task['task'] = t['task']\n    task['questions'] = answers_to_question\n    \n    all_tasks.append(task)\n\nall_answers = {}\nall_answers['data'] = all_tasks","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 8. Show results\n\nIn the first place, we specify an helper function, `dh()` (dh stands for _display html_) to visualize `html` tags in a proper way. "},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import display, Markdown, Latex, HTML\n\ndef layout_style():\n    style = \"\"\"\n        div {\n            color: black;\n        }\n        .single_answer {\n            border-left: 3px solid #dc7b15;\n            padding-left: 10px;\n            font-family: Arial;\n            font-size: 16px;\n            color: #777777;\n            margin-left: 5px;\n\n        }\n        .answer{\n            color: #dc7b15;\n        }\n        .question_title {\n            color: grey;\n            display: block;\n            text-transform: none;\n        }      \n        div.output_scroll { \n            height: auto; \n        }\n    \"\"\"\n    return \"<style>\" + style + \"</style>\"\n\ndef dm(x): display(Markdown(x))\ndef dh(x): display(HTML(layout_style() + x))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Subsequentely, we define some helper functions to visualize the tasks (and the questions). \n\nThe name of the functions are self-explanatory: `display_single_context`, `display_question_title`, `display_all_contexts`, `display_task_title` and `display_single_task`."},{"metadata":{"trusted":true},"cell_type":"code","source":"def display_single_context(context, start_index, end_index):\n    \n    before_answer = context[:start_index]\n    answer = context[start_index:end_index]\n    after_answer = context[end_index:]\n\n    content = before_answer + \"<span class='answer'>\" + answer + \"</span>\" + after_answer\n\n    return dh(\"\"\"<div class=\"single_answer\">{}</div>\"\"\".format(content))\n\ndef display_question_title(question):\n    return dh(\"<h2 class='question_title'>{}</h2>\".format(question.capitalize()))\n\n\ndef display_all_contexts(index, question):\n    \n    def answer_not_found(context, start_index, end_index):\n        return (start_index == 0 and len(context) == end_index) or (start_index == 0 and end_index == 0)\n\n    display_question_title(str(index + 1) + \". \" + question['question'].capitalize())\n    \n    # display context\n    for i in question['results']:\n        if answer_not_found(i['context'], i['start_index'], i['end_index']):\n            continue # skip not found questions\n        display_single_context(i['context'], i['start_index'], i['end_index'])\n\ndef display_task_title(index, task):\n    task_title = \"Task \" + str(index) + \": \" + task\n    return dh(\"<h1 class='task_title'>{}</h1>\".format(task_title))\n\ndef display_single_task(index, task):\n    \n    display_task_title(index, task['task'])\n    \n    for i, question in enumerate(task['questions']):\n        display_all_contexts(i, question)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we can invoke the function `display_single_task` for all eight tasks and visualize what does the model generated as answers. As you can notice, some of the answers are more relevant and to-the-point than others. In the next update, I will describe better the findings and try to improve further the results. If you notice something relevant in the spans of answers, let me know in the comment box!  "},{"metadata":{"trusted":true},"cell_type":"code","source":"task = 1\ndisplay_single_task(task, all_tasks[task-1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"task = 2\ndisplay_single_task(task, all_tasks[task-1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"task = 3\ndisplay_single_task(task, all_tasks[task-1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"task = 4\ndisplay_single_task(task, all_tasks[task-1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"task = 5\ndisplay_single_task(task, all_tasks[task-1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"task = 6\ndisplay_single_task(task, all_tasks[task-1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"task = 7\ndisplay_single_task(task, all_tasks[task-1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"task = 8\ndisplay_single_task(task, all_tasks[task-1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 9. Export solutions\n\nWe save in a _JSON_ file all the obtained answers. The same _JSON_ files might come in handy for further analysis and right now is used to visualize the same results in the [interactive interface](https://jbesomi.github.io/Korono/). "},{"metadata":{"trusted":true},"cell_type":"code","source":"import json\nwith open(\"covid_kaggle_answer_from_qa.json\", \"w\") as f:\n    json.dump(all_answers, f)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 10. Conclusions\n\nI hope your learned something along the way and had fun reading this notebook üëç\n\nAs you, I'm here for learning: your feedback and opinion it what makes me create better content. Please, tell me your opinion in the commentary box.\n\nThank you ü§ó"},{"metadata":{},"cell_type":"markdown","source":"##### Future relases: text summarization"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_summary(text):\n    \"\"\"\n    Get summary\n    \"\"\"\n    \n    \n    from transformers import BartTokenizer, BartForConditionalGeneration\n\n    tokenizer_summarize = BartTokenizer.from_pretrained('bart-large-cnn')\n    model_summarize = BartForConditionalGeneration \\\n            .from_pretrained('bart-large-cnn').to(torch_device)\n\n\n    model_summarize.to(torch_device)\n    model_summarize.eval()\n    \n    answers_input_ids = tokenizer_summarize.batch_encode_plus(\n        [text], return_tensors='pt', max_length=1024\n    )['input_ids']\n    \n    answers_input_ids = answers_input_ids.to(torch_device)\n    \n    summary_ids = model_summarize.generate(answers_input_ids,\n                                           num_beams=4,\n                                           max_length=5,\n                                           early_stopping=True\n                                          )\n        \n    return tokenizer_summarize.decode(summary_ids.squeeze(), \n                                      skip_special_tokens=True, \n                                      clean_up_tokenization_spaces=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}