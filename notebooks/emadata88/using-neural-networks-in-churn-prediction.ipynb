{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport sklearn\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport keras\nimport theano\nimport tensorflow\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder,OneHotEncoder\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nfrom sklearn.metrics import confusion_matrix ,classification_report\nfrom keras.wrappers.scikit_learn import KerasClassifier\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read Data\ncust = pd.read_csv(\"../input/telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Explore Dataset\nprint('Dimensions:{}'.format(cust.shape))\nprint(cust.dtypes)\ncust.head()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data Preprocessing**"},{"metadata":{},"cell_type":"markdown","source":"\"Total Charges\" feature is expected to be numeric but it\nis saved as  an 'object'. Searching for null or empty values."},{"metadata":{"trusted":true},"cell_type":"code","source":"cust.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\"Total Charges\" Feature has zero null values. Inspect if there are observations with blank values."},{"metadata":{"trusted":true},"cell_type":"code","source":"null_values=cust[cust['TotalCharges'] == ' ']\nnull_values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 'blank' values in \"Total charges\" . There are 11 observations in total. The amount of observations is small,deleting them will not cause problems in our analysis."},{"metadata":{"trusted":true},"cell_type":"code","source":"cust.drop(cust[(cust['TotalCharges'] == ' ')].index,inplace=True)\nnull_values=cust[cust['TotalCharges'] == ' ']\nnull_values\ncust['TotalCharges']=cust['TotalCharges'].astype('float64')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, lets do some changes into the raw data set:\n\n* drop CustomerID feature \n* encode categorical features \n* split the dataset into train and test set\n* Scale all features to have the same min and max values.\n\nApplying these steps will help the classifier perform better."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove Columns Customerid.\n\ncust.drop(['customerID'],axis=1,inplace=True)\n\n\n# Encode target feature as \"Yes\"=1 and \"No\"=0\n\ncust['Churn'].replace({\"Yes\":1,\"No\":0},inplace=True)\n\n#Encoding categorical data\nd=cust.select_dtypes(include=['object'])\nd=pd.get_dummies(d,prefix_sep='_',drop_first=True)\ncust=cust.iloc[:,[1,4,17,18,19]]\ncust=pd.concat([cust,d],axis=1)\ncust['TotalCharges'].astype('float64')\n\n\n\n# Splitting the dataset into Training and Test Set\n\nX=cust.drop(['Churn'],axis=1)\ny=cust['Churn']\n\nX_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.3,random_state=80)\n\nprint('Dimensions of the training feature table: {}'.format(X_train.shape))\nprint('Dimensions of the training target vector: {}'.format(y_train.shape))\nprint('Dimensions of the test feature table: {}'.format(X_test.shape))\nprint('Dimensions of the test target vector: {}'.format(y_test.shape))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Feature Scaling\nscal=StandardScaler()\nX_train=scal.fit_transform(X_train)\nX_test=scal.fit_transform(X_test)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Artificial Neural Networks**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# First Neural Network\n\ndef nn_classifier():\n    nn = Sequential()\n    nn.add(Dense(output_dim=16,init='uniform',activation='relu',input_dim=30)) # Initial Input and First hidden Layer\n    nn.add(Dropout(p = 0.1)) #Dropout Reg\n    nn.add(Dense(output_dim=16,init='uniform',activation='relu')) # Second hidden Layer\n    nn.add(Dropout(p = 0.1)) #Dropout Reg\n    nn.add(Dense(output_dim=1,init='uniform',activation='sigmoid')) # Output Layer\n    nn.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n    return nn\nnn = KerasClassifier(build_fn= nn_classifier,batch_size= 10,nb_epoch=100)\nacc = cross_val_score(estimator  = nn, X = X_train, y = y_train, cv = 10, n_jobs = -1)\nprint(\"Mean Accuracy : {}\".format(acc.mean()))\nprint(\"Variance : {}\".format(acc.std()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"****Tuning Neural Network parameters****"},{"metadata":{"trusted":true},"cell_type":"code","source":"def nn_classifier(optimizer):\n    nn = Sequential()\n    nn.add(Dense(output_dim=16,init='uniform',activation='relu',input_dim=30)) # Initial Input and First hidden Layer\n    nn.add(Dropout(p = 0.1)) #Dropout Reg\n    nn.add(Dense(output_dim=16,init='uniform',activation='relu')) # Second hidden Layer\n    nn.add(Dropout(p = 0.1)) #Dropout Reg\n    nn.add(Dense(output_dim=1,init='uniform',activation='sigmoid')) # Output Layer\n    nn.compile(optimizer=optimizer,loss='binary_crossentropy',metrics=['accuracy'])\n    return nn\nnn = KerasClassifier(build_fn= nn_classifier)\nparameters = {'batch_size' : [20, 33 ], \n              'nb_epoch' : [100, 300],\n              'optimizer': ['adam','rmsprop']}\ngs = GridSearchCV(estimator = nn,\n                 param_grid = parameters,\n                 scoring = 'accuracy',\n                 cv = 10)\n\n\ngs = gs.fit( X_train, y_train)\nopt_param = gs.best_params_\nopt_acc = gs.best_score_\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Optimal Parameters : {}\".format(opt_param))\nprint(\"Optimal Accuracy : {}\".format(opt_acc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}