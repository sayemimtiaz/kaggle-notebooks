{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Forecasting With Tensorflow: Comparing Model Architectures\n\nI made this notebook as practice in preparation for the TensorFlow certification. It is part of a series of notebooks and resources contained in this [github repo](https://github.com/nicholasjhana/tensorflow-certification-study-guide).\n\nThis notebook formulates a multi-variable forecasting problem to predict the next 24 hours of energy demand in Spain. In a [previous notebook I used a similar apparoch with a univariate model](https://www.kaggle.com/nicholasjhana/univariate-time-series-forecasting-with-keras) using the same dataset.\n\nThis notebook is distinct from the previous implementation because it uses multiple input variables of past energy load, price, hour of the day, day of the week, and month. It does not use the weather inputs. The implementation is also nearly all in Tensorflow, with the exception of data prep and plotting.\n\nHere I compare the forecasting performance of using several different model types. Each model uses the same final two DNN layers with dropout. One of 128 units, and the final layer of 24 (the output horizon). Each of the models unique layers are:\n1. A three layer DNN (one layer plus the common bottom two layers)\n2. A CNN with two layers of 1D convolutions with max pooling.\n3. A LSTM with two LSTM layers.\n4. A CNN stacked LSTM with layers from models 2 and 3 feeding into the common DNN layer.\n5. A CNN stacked LSTM with a skip connection to the common DNN layer. \n\nEach model is compared against baseline persistance models consisting of a one day persistence, and a three day average persistence. Added to the baseline error is the Transmission Service Operator's error."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom sklearn.preprocessing import MinMaxScaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":false},"cell_type":"code","source":"def load_data(col=None, path=\"/kaggle/input/energy-consumption-generation-prices-and-weather/energy_dataset.csv\", verbose=False):\n    df = pd.read_csv(path)\n    if col is not None:\n        df = df[col]\n    if verbose:\n        print(df.head())\n    return df\n\nprint(\"Multivariate Sample\")\nmultivar_df = load_data(['time','total load actual', 'price actual'], verbose=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Baseline Error Performance\n\nIn order to compare model perofrmance we need an estimate of bayes limit for the problem. In this case we do not have a human error reference. So we use the the lowest of the following:\n- ENTSOE recorded forecast. This is the collection of models used by the relevant energy authority.\n- Persistance 1 Day. Using the observed values from the previous days as the prediction of the next day.\n- Persistance 3 day mean. Using the observations from the previous 3 days as the prediction of the next day.\n\nBy establishing a baseline error we have a refernce to compare our training and validation set performance. This guides us to understand where and how a model is performance. For example, if our bayes error is MAE 5% and our model training and validation perform at MAE 6% and 9% respectively then the relevant obserevation is that our model performs with high variance with respect to the baseline. The contrary is true if we consider baseline, train, and validation MAEs of 5%, 8%, and 8.5% respectively. In the latter case we should work on the bias of the training set before considering the validation performance (low variance)."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df = load_data(col=[\"total load forecast\",\"total load actual\"])\n\n#fill nans with linear interpolation because this is how we will fill when using the data in the models.\ndf_filled = df.interpolate(\"linear\")\nmm = MinMaxScaler()\ndf_scaled = mm.fit_transform(df_filled)\n\ndf_prep = pd.DataFrame(df_scaled, columns=df.columns)\ny_true = df_prep[\"total load actual\"]\ny_pred_forecast = df_prep[\"total load forecast\"]\n\n### persistence 1 day\n#shift series by 24 hours\n# realign y_true to have the same length and time samples\ny_preds_persistance_1_day = y_true.shift(24).dropna()\npersistence_1_day_mae = tf.keras.losses.MAE(y_true[y_preds_persistance_1_day.index], y_preds_persistance_1_day).numpy()\npersistence_1_day_mape = tf.keras.losses.MAPE(np.maximum(y_true[y_preds_persistance_1_day.index], 1e-5), np.maximum(y_preds_persistance_1_day, 1e-5)).numpy()\n\n\n### persistence 3 day average\n#shift by 1, 2, 3 days. Realign to have same lengths. Average days and calcualte MAE.\n\nshift_dfs = list()\nfor i in range(1, 4):\n    shift_dfs.append(pd.Series(y_true.shift(24 * i), name=f\"d{i}\"))\n\ny_persistance_3d = pd.concat(shift_dfs, axis=1).dropna()\ny_persistance_3d[\"avg\"] = (y_persistance_3d[\"d1\"] + y_persistance_3d[\"d2\"] + y_persistance_3d[\"d3\"])/3\nd3_idx = y_persistance_3d.index\npersistence_3day_avg_mae = tf.keras.losses.MAE(y_true[d3_idx], y_persistance_3d['avg']).numpy()\npersistence_3day_avg_mape = tf.keras.losses.MAPE(np.maximum(y_true[d3_idx], 1e-5), np.maximum(y_persistance_3d['avg'], 1e-5)).numpy()\n\n\nref_error = pd.DataFrame({\n    \"Method\": [\"TSO Forecast\", \"Persistence 1 Day\", \"Persitence 3 Day Avg\"],\n    \"MAE\": [tf.keras.losses.MAE(y_true, y_pred_forecast).numpy(),\n            persistence_1_day_mae,\n            persistence_3day_avg_mae],\n    \"MAPE\":[tf.keras.losses.MAPE(np.maximum(y_true, 1e-5), np.maximum(y_pred_forecast, 1e-5)).numpy(),\n            persistence_1_day_mape,\n            persistence_3day_avg_mape]}, \n    index=[i for i in range(3)])\n\nprint(\"\\nSummary of Baseline Errors\")\nprint(ref_error)\nprint(f\"\\nAverage error in MW for TSO Forecast {round(df['total load forecast'].mean()*ref_error.iloc[0,1], 2)}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can interpret the MAE errors as the number of megawatts (MW) power deviation on average across the whole dataset. So, the TSO forecast is an average of 443.76 MW of error. MAPE is the average percentage deviation of the forecast per time period. In this case about 5.4% deviation."},{"metadata":{},"cell_type":"markdown","source":"# Preparing the Data\n\nWe will use tf.datasets to prepare the data. The general strategy is to clean, scale, and split the data before creating the tf.dataset object. These steps can alternatively be done within the tf.dataset itself.\n\n***Cleaning data:*** Fill any missing values with a linear interpolation of the value. Same as done in the persistence dataset.\n\n***Scaling data:*** In all cases the data is min max scaled.\n\n***Features:*** As part of this simple analysis of models two feature sets are prepared. The univariate that contains energy consumption data only. The multivariate that contains energy consumption, price, day of the week, and month of the year.\n\n***Splitting data:*** One year of test data (8769 hourly samples) is put aside to evaluate all the models. The train and validation sets are created with a 65/35 split, resulting in 9207 validation samples - just over one year."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def clean_data(series):\n    \"\"\"Fills missing values. \n    \n        Interpolate missing values with a linear approximation.\n    \"\"\"\n    series_filled = series.interpolate(method='linear')\n        \n    return series_filled\n        \n    \ndef min_max_scale(dataframe):\n    \"\"\" Applies MinMax Scaling\n    \n        Wrapper for sklearn's MinMaxScaler class.\n    \"\"\"\n    mm = MinMaxScaler()\n    return mm.fit_transform(dataframe)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def make_time_features(series):\n    \n    #convert series to datetimes\n    times = series.apply(lambda x: x.split('+')[0])\n    datetimes = pd.DatetimeIndex(times)\n    \n    hours = datetimes.hour.values\n    day = datetimes.dayofweek.values\n    months = datetimes.month.values\n    \n    hour = pd.Series(hours, name='hours')\n    dayofw = pd.Series(day, name='dayofw')\n    month = pd.Series(months, name='months')\n    \n    return hour, dayofw, month\n\nhour, day, month = make_time_features(multivar_df.time)\nprint(\"Hours\")\nprint(hour.head())\nprint(\"Day of Week\")\nprint(day.head())\nprint(\"Months\")\nprint(month.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def split_data(series, train_fraq, test_len=8760):\n    \"\"\"Splits input series into train, val and test.\n    \n        Default to 1 year of test data.\n    \"\"\"\n    #slice the last year of data for testing 1 year has 8760 hours\n    test_slice = len(series)-test_len\n\n    test_data = series[test_slice:]\n    train_val_data = series[:test_slice]\n\n    #make train and validation from the remaining\n    train_size = int(len(train_val_data) * train_fraq)\n    \n    train_data = train_val_data[:train_size]\n    val_data = train_val_data[train_size:]\n    \n    return train_data, val_data, test_data\n\n\nmultivar_df = clean_data(multivar_df)\n\n#add hour and month features\nhours, day, months = make_time_features(multivar_df.time)\nmultivar_df = pd.concat([multivar_df.drop(['time'], axis=1), hours, day, months], axis=1)\n\n#scale\nmultivar_df = min_max_scale(multivar_df)\ntrain_multi, val_multi, test_multi = split_data(multivar_df, train_fraq=0.65, test_len=8760)\nprint(\"Multivarate Datasets\")\nprint(f\"Train Data Shape: {train_multi.shape}\")\nprint(f\"Val Data Shape: {val_multi.shape}\")\nprint(f\"Test Data Shape: {test_multi.shape}\")\nprint(f\"Nulls In Train {np.any(np.isnan(train_multi))}\")\nprint(f\"Nulls In Validation {np.any(np.isnan(val_multi))}\")\nprint(f\"Nulls In Test {np.any(np.isnan(test_multi))}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Windowing the Dataset\n\nUse tf.dataset to create a window dataset. This is a vector of past timesteps (n_steps) that is used to predict on a target vector of future steps (n_horizon). The example below shows the output for n_steps = 72 and n_horizon = 24 and the 5 features. So we use the last 3 days (72 hours) to predict the next day (following 24 hours). \n\nThe resulting shape for X will be (batch size, n_steps, features) and Y will be (batch size, n_horizon, features)."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def window_dataset(data, n_steps, n_horizon, batch_size, shuffle_buffer, multi_var=False, expand_dims=False):\n    \"\"\" Create a windowed tensorflow dataset\n    \n    \"\"\"\n\n    #create a window with n steps back plus the size of the prediction length\n    window = n_steps + n_horizon\n    \n    #expand dimensions to 3D to fit with LSTM inputs\n    #creat the inital tensor dataset\n    if expand_dims:\n        ds = tf.expand_dims(data, axis=-1)\n        ds = tf.data.Dataset.from_tensor_slices(ds)\n    else:\n        ds = tf.data.Dataset.from_tensor_slices(data)\n    \n    #create the window function shifting the data by the prediction length\n    ds = ds.window(window, shift=n_horizon, drop_remainder=True)\n    \n    #flatten the dataset and batch into the window size\n    ds = ds.flat_map(lambda x : x.batch(window))\n    ds = ds.shuffle(shuffle_buffer)    \n    \n    #create the supervised learning problem x and y and batch\n    if multi_var:\n        ds = ds.map(lambda x : (x[:-n_horizon], x[-n_horizon:, :1]))\n    else:\n        ds = ds.map(lambda x : (x[:-n_horizon], x[-n_horizon:]))\n    \n    ds = ds.batch(batch_size).prefetch(1)\n    \n    return ds\n\ntf.random.set_seed(42)\n\nn_steps = 72\nn_horizon = 24\nbatch_size = 1\nshuffle_buffer = 100\n\n\nds = window_dataset(train_multi, n_steps, n_horizon, batch_size, shuffle_buffer, multi_var=True)\n\nprint('Example sample shapes')\nfor idx,(x,y) in enumerate(ds):\n    print(\"x = \", x.numpy().shape)\n    print(\"y = \", y.numpy().shape)\n    break","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dataset Loading Function\n\nWrap the above functions into a single function that allows us to build the dataset in the same way each time."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def build_dataset(train_fraq=0.65, \n                  n_steps=24*30, \n                  n_horizon=24, \n                  batch_size=256, \n                  shuffle_buffer=500, \n                  expand_dims=False, \n                  multi_var=False):\n    \"\"\"If multi variate then first column is always the column from which the target is contstructed.\n    \"\"\"\n    \n    tf.random.set_seed(23)\n    \n    if multi_var:\n        data = load_data(col=['time', 'total load actual', 'price actual'])\n        hours, day, months = make_time_features(data.time)\n        data = pd.concat([data.drop(['time'], axis=1), hours, day, months], axis=1)\n    else:\n        data = load_data(col=['total load actual'])\n        \n    data = clean_data(data)\n    \n    if multi_var:\n        mm = MinMaxScaler()\n        data = mm.fit_transform(data)\n    \n    train_data, val_data, test_data = split_data(data, train_fraq=train_fraq, test_len=8760)\n    \n    train_ds = window_dataset(train_data, n_steps, n_horizon, batch_size, shuffle_buffer, multi_var=multi_var, expand_dims=expand_dims)\n    val_ds = window_dataset(val_data, n_steps, n_horizon, batch_size, shuffle_buffer, multi_var=multi_var, expand_dims=expand_dims)\n    test_ds = window_dataset(test_data, n_steps, n_horizon, batch_size, shuffle_buffer, multi_var=multi_var, expand_dims=expand_dims)\n    \n    \n    print(f\"Prediction lookback (n_steps): {n_steps}\")\n    print(f\"Prediction horizon (n_horizon): {n_horizon}\")\n    print(f\"Batch Size: {batch_size}\")\n    print(\"Datasets:\")\n    print(train_ds.element_spec)\n    \n    return train_ds, val_ds, test_ds\n\ntrain_ds, val_ds, test_ds = build_dataset(multi_var=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Configurations\n\nDefine a set of model configurations so that we can call and run each model in the same way. The cgf_model_run dictionary will store the model, its history, and the test datasetset generated.\n\nThe default model parameters are:\n- n_steps: last 30 days\n- n_horizon: next 24 hours\n- learning rate: 3e-4"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def get_params(multivar=False):\n    lr = 3e-4\n    n_steps=24*30\n    n_horizon=24\n    if multivar:\n        n_features=5\n    else:\n        n_features=1\n        \n    return n_steps, n_horizon, n_features, lr\n\nmodel_configs = dict()\n\ndef cfg_model_run(model, history, test_ds):\n    return {\"model\": model, \"history\" : history, \"test_ds\": test_ds}\n\n\ndef run_model(model_name, model_func, model_configs, epochs):\n    \n    n_steps, n_horizon, n_features, lr = get_params(multivar=True)\n    train_ds, val_ds, test_ds = build_dataset(n_steps=n_steps, n_horizon=n_horizon, multi_var=True)\n\n    model = model_func(n_steps, n_horizon, n_features, lr=lr)\n\n    model_hist = model.fit(train_ds, validation_data=val_ds, epochs=epochs)\n\n    model_configs[model_name] = cfg_model_run(model, model_hist, test_ds)\n    return test_ds","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Define Each Model\n\n## DNN\nA single 128 unit layer plus the common 128 and 24 unit layyers with dropout."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def dnn_model(n_steps, n_horizon, n_features, lr):\n    tf.keras.backend.clear_session()\n    \n    model = tf.keras.models.Sequential([\n        tf.keras.layers.Flatten(input_shape=(n_steps, n_features)),\n        tf.keras.layers.Dense(128, activation='relu'),\n        tf.keras.layers.Dropout(0.3),\n        tf.keras.layers.Dense(128, activation='relu'),\n        tf.keras.layers.Dropout(0.3),\n        tf.keras.layers.Dense(n_horizon)\n    ], name='dnn')\n    \n    loss=tf.keras.losses.Huber()\n    optimizer = tf.keras.optimizers.Adam(lr=lr)\n    \n    model.compile(loss=loss, optimizer='adam', metrics=['mae'])\n    \n    return model\n\n\ndnn = dnn_model(*get_params(multivar=True))\ndnn.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## CNN\nTwo Conv 1D layers with 64 filters each, and kernel sizes of 6 and 3 respectively. After each Conv1D layer a maxpooling1D layer with size of 2. "},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def cnn_model(n_steps, n_horizon, n_features, lr=3e-4):\n    \n    tf.keras.backend.clear_session()\n    \n    model = tf.keras.models.Sequential([\n        tf.keras.layers.Conv1D(64, kernel_size=6, activation='relu', input_shape=(n_steps,n_features)),\n        tf.keras.layers.MaxPooling1D(2),\n        tf.keras.layers.Conv1D(64, kernel_size=3, activation='relu'),\n        tf.keras.layers.MaxPooling1D(2),\n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dropout(0.3),\n        tf.keras.layers.Dense(128),\n        tf.keras.layers.Dropout(0.3),\n        tf.keras.layers.Dense(n_horizon)\n    ], name=\"CNN\")\n    \n    loss= tf.keras.losses.Huber()\n    optimizer = tf.keras.optimizers.Adam(lr=lr)\n    \n    model.compile(loss=loss, optimizer='adam', metrics=['mae'])\n    \n    return model\n\ncnn = cnn_model(*get_params(multivar=True))\ncnn.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## LSTM\nTwo LSTM layers with 72 and 48 units each."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def lstm_model(n_steps, n_horizon, n_features, lr):\n    \n    tf.keras.backend.clear_session()\n    \n    model = tf.keras.models.Sequential([\n        tf.keras.layers.LSTM(72, activation='relu', input_shape=(n_steps, n_features), return_sequences=True),\n        tf.keras.layers.LSTM(48, activation='relu', return_sequences=False),\n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dropout(0.3),\n        tf.keras.layers.Dense(128, activation='relu'),\n        tf.keras.layers.Dropout(0.3),\n        tf.keras.layers.Dense(n_horizon)\n    ], name='lstm')\n    \n    loss = tf.keras.losses.Huber()\n    optimizer = tf.keras.optimizers.Adam(lr=lr)\n    \n    model.compile(loss=loss, optimizer='adam', metrics=['mae'])\n    \n    return model\n\nlstm = lstm_model(*get_params(multivar=True))\nlstm.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## CNN and LSTM Stacked\nUsing the same layers from the CNN and LSTM model, stack the CNN as input to the pair of LSTMs."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def lstm_cnn_model(n_steps, n_horizon, n_features, lr):\n    \n    tf.keras.backend.clear_session()\n    \n    model = tf.keras.models.Sequential([\n        tf.keras.layers.Conv1D(64, kernel_size=6, activation='relu', input_shape=(n_steps,n_features)),\n        tf.keras.layers.MaxPooling1D(2),\n        tf.keras.layers.Conv1D(64, kernel_size=3, activation='relu'),\n        tf.keras.layers.MaxPooling1D(2),\n        tf.keras.layers.LSTM(72, activation='relu', return_sequences=True),\n        tf.keras.layers.LSTM(48, activation='relu', return_sequences=False),\n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dropout(0.3),\n        tf.keras.layers.Dense(128),\n        tf.keras.layers.Dropout(0.3),\n        tf.keras.layers.Dense(n_horizon)\n    ], name=\"lstm_cnn\")\n    \n    loss = tf.keras.losses.Huber()\n    optimizer = tf.keras.optimizers.Adam(lr=lr)\n    \n    model.compile(loss=loss, optimizer='adam', metrics=['mae'])\n    \n    return model\n\nlstm_cnn = lstm_cnn_model(*get_params(multivar=True))\nlstm_cnn.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## CNN and LSTM with a skip connection\nThe same CNN and LSTM layers as the previous models this time with a skip connection direct to the common DNN layer."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def lstm_cnn_skip_model(n_steps, n_horizon, n_features, lr):\n    \n    tf.keras.backend.clear_session()\n    \n   \n    inputs = tf.keras.layers.Input(shape=(n_steps,n_features), name='main')\n    \n    conv1 = tf.keras.layers.Conv1D(64, kernel_size=6, activation='relu')(inputs)\n    max_pool_1 = tf.keras.layers.MaxPooling1D(2)(conv1)\n    conv2 = tf.keras.layers.Conv1D(64, kernel_size=3, activation='relu')(max_pool_1)\n    max_pool_2 = tf.keras.layers.MaxPooling1D(2)(conv2)\n    lstm_1 = tf.keras.layers.LSTM(72, activation='relu', return_sequences=True)(max_pool_2)\n    lstm_2 = tf.keras.layers.LSTM(48, activation='relu', return_sequences=False)(lstm_1)\n    flatten = tf.keras.layers.Flatten()(lstm_2)\n    \n    skip_flatten = tf.keras.layers.Flatten()(inputs)\n\n    concat = tf.keras.layers.Concatenate(axis=-1)([flatten, skip_flatten])\n    drop_1 = tf.keras.layers.Dropout(0.3)(concat)\n    dense_1 = tf.keras.layers.Dense(128, activation='relu')(drop_1)\n    drop_2 = tf.keras.layers.Dropout(0.3)(dense_1)\n    output = tf.keras.layers.Dense(n_horizon)(drop_2)\n    \n    model = tf.keras.Model(inputs=inputs, outputs=output, name='lstm_skip')\n    \n    loss = tf.keras.losses.Huber()\n    optimizer = tf.keras.optimizers.Adam(lr=lr)\n    \n    model.compile(loss=loss, optimizer='adam', metrics=['mae'])\n    \n    return model\n\nlstm_skip = lstm_cnn_skip_model(*get_params(multivar=True))\nlstm_skip.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.keras.utils.plot_model(lstm_skip, show_shapes=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train Models\nRun each model for 150 epochs."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"model_configs=dict()\nrun_model(\"dnn\", dnn_model, model_configs, epochs=150)\nrun_model(\"cnn\", cnn_model, model_configs, epochs=150)\nrun_model(\"lstm\", lstm_model, model_configs, epochs=150)\nrun_model(\"lstm_cnn\", lstm_cnn_model, model_configs, epochs=150)\nrun_model(\"lstm_skip\", lstm_cnn_skip_model, model_configs, epochs=150)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluation of Training/Validation Results\n\nLoss curves across the models are fairly stable. All models show a flat validation curve while training continues to decline. The LSTM appears to begin to become very overfit from about epoch 100 where the validation loss begins to rise. The lstm_skip also has a point around epoch 50 where the val loss stops decreasing. In all cases this is a sign the models are no longer learning against the validation set. Some options to help improve this are to introduce learning rate decline, or train on longer input sequences.\n\nPlots of the MAE show a similar pattern to the loss plots.\n"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"legend = list()\n\nfig, axs = plt.subplots(1, 5, figsize=(25,5))\n\ndef plot_graphs(metric, val, ax, upper):\n    ax.plot(val['history'].history[metric])\n    ax.plot(val['history'].history[f'val_{metric}'])\n    ax.set_title(key)\n    ax.legend([metric, f\"val_{metric}\"])\n    ax.set_xlabel('epochs')\n    ax.set_ylabel(metric)\n    ax.set_ylim([0, upper])\n    \nfor (key, val), ax in zip(model_configs.items(), axs.flatten()):\n    plot_graphs('loss', val, ax, 0.2)\nprint(\"Loss Curves\")","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print(\"MAE Curves\")\nfig, axs = plt.subplots(1, 5, figsize=(25,5))\nfor (key, val), ax in zip(model_configs.items(), axs.flatten()):\n    plot_graphs('mae', val, ax, 0.6)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluation of Test Results\nThe LSTM and the CNN stacked LSTM models clearly outperformed the other four models. Whats surprising is to see how well both a CNN and DNN did on their. LSTM would be expected to perform well because of its ability to learn and remember longer trends in the data.\n\nComparing to the baseline results the models' performance was poor. The dnn, cnn, lstm, and lstm_cnn models improved against the persistence error (MAE ~ 0.106) but did not improve against the TSO's prediction error (MAE ~0.015, MW error ~443). \n\nPutting the models' performance in perspective however the results show how with a limited lookback window, and simple features a lstm, and a cnn stacked with an lstm are a good starting choice for architecture."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"names = list()\nperformance = list()\n\nfor key, value in model_configs.items():\n    names.append(key)\n    mae = value['model'].evaluate(value['test_ds'])\n    performance.append(mae[1])\n    \nperformance_df = pd.DataFrame(performance, index=names, columns=['mae'])\nperformance_df['error_mw'] = performance_df['mae'] * df['total load forecast'].mean()\nprint(performance_df)    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualizing Predictions\n\nPlot the actual and predicted 24 hour intervals. Below is the first 14 days of predictions. Interesting to note how the LSTM appears to oscilate over a longer frequency compared with the other models. The CNN also seems to capture the intra day oscillations (within the 24 hour period). Looking at the CNN stacked LSTM we can see how these two characteristics of the model's learning combine."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig, axs = plt.subplots(5, 1, figsize=(18, 10))\ndays = 14\n\nvline = np.linspace(0, days*24, days+1)\n\nfor (key, val), ax in zip(model_configs.items(), axs):\n\n    test = val['test_ds']\n    preds = val['model'].predict(test)\n\n    xbatch, ybatch = iter(test).get_next()\n\n    ax.plot(ybatch.numpy()[:days].reshape(-1))\n    ax.plot(preds[:days].reshape(-1))\n    ax.set_title(key)\n    ax.vlines(vline, ymin=0, ymax=1, linestyle='dotted', transform = ax.get_xaxis_transform())\n    ax.legend([\"Actual\", \"Predicted\"])\n\nplt.xlabel(\"Hours Cumulative\")\nprint('First Two Weeks of Predictions')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# References\n1. [Sequences, Time Series and Prediction, Coursera by Laurence Moroney](https://www.coursera.org/learn/tensorflow-sequences-time-series-and-prediction)"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}