{"cells":[{"metadata":{},"cell_type":"markdown","source":"#overview\n<h1>Here we aim to use NLP, Random forest Classifier, XgBoost, Logistic Regression, Deep lerning LSTM to evaluate their performance on product recommenation\nthe data can be downloded from https://www.kaggle.com/datafiniti/grammar-and-online-product-reviews\nit contains approx 71000 reviews of 1000 different products"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2>importing the required libraries a.k.a Housekeeping<h2>"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n%pylab inline\n%config InlineBackend.figure_formats = ['retina'] #include it if you have high denisty retina display\nimport seaborn as sns #as it gives 2x plots with matplotlib and ipython notebook\nimport plotly.offline as py #to drew plotly\ncolor = sns.color_palette()#graphs from a \nimport plotly.offline as py#command line\npy.init_notebook_mode(connected=True) #to create offine grapgs with notebook\nimport plotly.tools as tls\nimport warnings\nwarnings.filterwarnings('ignore')\nimport os\nfrom sklearn.metrics import confusion_matrix, classification_report\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# change dir according to your dataset location\ndir = '/kaggle/input/grammar-and-online-product-reviews/GrammarandProductReviews.csv'\ndf = pd.read_csv(dir)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2>EDA and Data PreProcessing a.k.a Feature engineering<h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#data overivew\nprint('rows: ', df.shape[0])\nprint('columns: ', df.shape[1])\nprint('\\nfeatures: ', df.columns.to_list())\nprint('\\nmissing vlues: ', df.isnull().values.sum())\nprint('\\nUnique values: \\n', df.nunique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#see the data types of different columns\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#see the sum of missing values in each columns\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#drop the rows having null values for reviews text\ndf = df.dropna(subset=['reviews.text'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#there are many duplicate reveiws (exact same comments in review.text)\n#but I am not going to clean the data yet,so i just use the data as it is, to go through t process\ndf['reviews.text'].value_counts()[10:50]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2> How are the ratings distributed<h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot ratings frequency\nplt.figure(figsize=[10,5]) #[width, height]\nx = list(df['reviews.rating'].value_counts().index)\ny = list(df['reviews.rating'].value_counts())\nplt.barh(x, y)\n\nticks_x = np.linspace(0, 50000, 6) # (start, end, no of ticks)\nplt.xticks(ticks_x, fontsize=10, family='fantasy', color='black')\nplt.yticks(size=15)\n\nplt.title('Distribution of ratings', fontsize=20, weight='bold', color='navy', loc='center')\nplt.xlabel('Count', fontsize=15, weight='bold', color='navy')\nplt.ylabel('Ratings', fontsize=15, weight='bold', color='navy')\nplt.legend(['reviews Rating'], shadow=True, loc=4)\n#Loc =1 topright, loc=2 topleft, loc=3 bottomleft, loc=4 bottom right, loc=9 topmiddle\n#plt.grid() #add grid lines","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2>what words do people use in their reviews?\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud, STOPWORDS\nstopwords = set(STOPWORDS)\n\ndef show_wordcloud(data, title=None):\n    wordcloud = WordCloud(\n        background_color = 'white',\n        stopwords = stopwords,\n        max_words=300,\n        max_font_size=40,\n        scale=3,\n        random_state=1 ).generate(str(data))\n    fig = plt.figure(1, figsize=(15, 15))\n    plt.axis('off')\n    if title:\n        fig.subtitle(title, fontsize=20)\n        fig.subplots_adjust(top=2.3)\n    \n    plt.imshow(wordcloud)\n    plt.show()\n    \nshow_wordcloud(df['reviews.text'])    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#alternate code, seems to u=yeild diffent results\nwordcloud = WordCloud(background_color='white', stopwords=stopwords, max_words=300, max_font_size=40,\n                     scale=3, random_state=1).generate(str(df['reviews.text'].value_counts()))\nplt.figure(figsize=(15,15))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['reviews.title'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_wordcloud(df['reviews.title'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#alternate code, semms to yield different results\nwordcloud = WordCloud(background_color='white', stopwords=stopwords, max_words=400, max_font_size=\n                     40, scale=30, random_state=1).generate_from_frequencies((df['reviews.title'].value_counts()))\nplt.figure(figsize=(15,15))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# try to tokenize to individual word (uni-gram) - reviews.title\nsplit_title = []\nlistCounts = []\nsplit_title = [x.split(\" \") for x in df['reviews.title'].astype(str)]\nbig_list = []\nfor x in split_title:\n    big_list.extend(x)\n\nlistCounts = pd.Series(big_list).value_counts()\n\nwordcloud = WordCloud(background_color='white', max_words=400, max_font_size=40, scale=30,\n        random_state=1).generate((listCounts[listCounts > 2]).to_string())\nplt.figure(figsize=(15, 15))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(big_list) #reveiws.title","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# try to tokenize to individual word (uni-gram) - reviews.text\nsplit_title = []\nlistCounts = []\nsplit_title = [x.split(\" \") for x in df['reviews.text'].astype(str)]\nbig_list = []\nfor x in split_title:\n    big_list.extend(x)\n\nlistCounts = pd.Series(big_list).value_counts()\n\nwordcloud = WordCloud(background_color='white', max_words=400, max_font_size=40, scale=30,\n        random_state=1).generate((listCounts[listCounts > 2]).to_string())\nplt.figure(figsize=(15, 15))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(big_list) #reviews.text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#let's see what are the popular categories, looks quite messy\ndf['categories'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's see which are the popular products review\ndf['name'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2>DO review come from shoppers who did purchase the products\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#on the reviews.didpurchase column, replace 38,886 null filds with \"Null\"\ndf['reviews.didPurchase'].fillna('Null', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,8))\nax = sns.countplot(df['reviews.didPurchase'])\nax.set_xlabel(xlabel=\"Shoppers did purchase the product\", fontsize=17)\nax.set_ylabel(ylabel='Count of Reviews', fontsize=17)\nax.axes.set_title('Number of Genuine Reviews', fontsize=17)\nax.tick_params(labelsize=13)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['reviews.didPurchase'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#shoppers who did purchase the product and provided the reveiw = 5%\n3681/70008","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2> visualize the correlation map"},{"metadata":{"trusted":true},"cell_type":"code","source":"#not much info int the correlation map\nsns.set(font_scale=1.4)\nplt.figure(figsize=(10,5))\nsns.heatmap(df.corr(), cmap='coolwarm', annot=True, linewidths=.5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2> Which is the most popular product purchased?"},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = df[df['reviews.didPurchase'] == True]\ndf1['name'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The Foodsver174 10 cup fresh container is purchased almost 500 times"},{"metadata":{"trusted":true},"cell_type":"code","source":"df1['name'].value_counts()[0:10].plot('barh', figsize=[10,6], fontsize=20).invert_yaxis()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# filter most purchased product with 5 star rating\ndf1 = df1[df1['name'] == 'The Foodsaver174 10 Cup Fresh Container - Fac10-000']\ndf1 = df1[df1['reviews.rating']==5]\n# keep relevant columns only\ndf1 = df1[[ 'reviews.rating', 'reviews.text']]\ndf1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2> predictions of ratings<h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nfrom scipy.sparse import hstack\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nall_text = df['reviews.text']\ny = df['reviews.rating']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2> Uaing the n-gram tfidf vectorizer"},{"metadata":{"trusted":true},"cell_type":"code","source":"word_vectorizer = TfidfVectorizer(\n    sublinear_tf=True,\n    strip_accents='unicode',\n    analyzer='word',\n    token_pattern=r'\\w{1,}',\n    stop_words='english',\n    ngram_range=(1, 3) )  # try 1,3\n#     max_features=10000)\nword_vectorizer.fit(all_text)\ntrain_word_features = word_vectorizer.transform(all_text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"char_vectorizer = TfidfVectorizer(\n    sublinear_tf=True,\n    strip_accents='unicode',\n    analyzer='char',\n    stop_words='english',\n    ngram_range=(2, 6),\n    max_features=50000)\nchar_vectorizer.fit(all_text)\ntrain_char_features = char_vectorizer.transform(all_text)\n\ntrain_features = hstack([train_char_features, train_word_features])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import time \nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nseed = 71\n\nX_train, X_test, y_train, y_test = train_test_split(train_features, y, test_size=0.3, random_state=seed)\nprint('X_train', X_train.shape)\nprint('y_train', y_train.shape)\nprint('X_test', X_test.shape)\nprint('y_test', y_test.shape)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2> Model 1: Random Forest Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\ntime1 = time.time()\nclassifier = RandomForestClassifier(n_estimators=100, max_depth=None, random_state=seed, n_jobs=-1)\nclassifier.fit(X_train, y_train)\npreds1 = classifier.predict(X_test)\n\ntime_taken = time.time() -time1\nprint('Time taken: {:.2f} seconds'.format(time_taken))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Random Forest Model accuracy\", accuracy_score(preds1, y_test))\nprint(classification_report(preds1, y_test))\nprint(confusion_matrix(preds1, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# n_estimators=None\n\n# Random Forest Model accuracy 0.7014504999295874\n#               precision    recall  f1-score   support\n\n#            1       0.52      0.74      0.61       784\n#            2       0.16      0.79      0.27       120\n#            3       0.16      0.51      0.24       419\n#            4       0.25      0.46      0.33      2412\n#            5       0.93      0.74      0.82     17568\n\n#    micro avg       0.70      0.70      0.70     21303\n#    macro avg       0.41      0.65      0.45     21303\n# weighted avg       0.82      0.70      0.74     21303\n\n# [[  578    74    37    40    55]\n#  [   14    95     4     1     6]\n#  [   23    36   212    94    54]\n#  [   73    84   316  1114   825]\n#  [  426   288   772  3138 12944]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# n_estimators=300 \n# Time Taken:  955\n# Random Forest Model accuracy 0.7151105478101676\n#               precision    recall  f1-score   support\n\n#            1       0.41      0.90      0.56       510\n#            2       0.18      1.00      0.31        99\n#            3       0.11      0.95      0.19       150\n#            4       0.14      0.74      0.24       826\n#            5       0.99      0.71      0.83     19718\n\n#    micro avg       0.72      0.72      0.72     21303\n#    macro avg       0.37      0.86      0.42     21303\n# weighted avg       0.94      0.72      0.79     21303\n\n# [[  460    31    12     4     3]\n#  [    0    99     0     0     0]\n#  [    1     1   142     5     1]\n#  [    8    16   122   613    67]\n#  [  663   403  1037  3695 13920]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2> Model2 : XGBoost"},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\ntime1 = time.time()\n\nxgb = xgb.XGBClassifier(n_jobs=1)\nxgb.fit(X_train, y_train)\npreds2 = xgb.predict(X_test)\n\ntime_taken = time.time() - time1\nprint('Time taken: {:.2f} seconds'.format(time_taken))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n#        colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n#        max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n#        n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n#        reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n#        silent=True, subsample=1)\n\n# time taken 2410","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# manual method to check accuracy, see first 100 predictions, around 70% correct prediction\nfor i in range(100):\n    if preds2[i] == np.array(y_test)[i]:\n        print('1', end=', ')   # correct prediction\n    else:\n        print('0', end=', ')   # wrong prediction","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# manual method to check accuracy, see some prediction of rating\npreds2[0:100: 5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# manual method to check accuracy, see correct test label\nnp.array(y_test)[0:100: 5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#manuel method to check accuray, check on all 21303 test data set\ncorrect = 0\nwrong = 0\nfor i in range(21303):\n    if preds2[i] == np.array(y_test)[i]:\n        correct += 1\n    else:\n        wrong += 1\nprint(correct+wrong)\nprint(correct/21303)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"XGBoost Model accuracy\", accuracy_score(preds2, np.array(y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"XGBoost Model accuracy\", accuracy_score(preds2, y_test))\nprint(classification_report(preds2, y_test))\nprint(confusion_matrix(preds2, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2> Model3: Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import KFold, cross_val_score\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"time1 = time.time()\nlogit = LogisticRegression(C=1, multi_class = 'ovr')\nlogit.fit(X_train, y_train)\npreds3 = logit.predict(X_test)\n\ntime_taken = time.time() - time1\nprint('Time Taken: {:.2f} seconds'.format(time_taken))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Logistic Regression accuracy\", accuracy_score(preds3, y_test))\nprint(classification_report(preds3, y_test))\nprint(confusion_matrix(preds3, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2> Which one is better Bagging or Boosting\n<h3> Deep learning\nTo clssify ratings < 4 as sentiment, replace rating less than 4 as not happy\nlabel 1 = happy\nlabel 2 = uhappy"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['sentiment'] = df['reviews.rating'] < 4\nfrom sklearn.model_selection import train_test_split\ntrain_text, test_text, train_y, test_y = train_test_split(df['reviews.text'],df['sentiment'], test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Embedding, LSTM\nfrom keras.utils.np_utils import to_categorical\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import load_model\nfrom keras.optimizers import Adam","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MAX_NB_WORDS = 20000\n\n# get the raw text data\ntexts_train = train_text.astype(str)\ntexts_test = test_text.astype(str)\n\n# finally, vectorize the text samples into a 2D integer tensor\ntokenizer = Tokenizer(nb_words=MAX_NB_WORDS, char_level=False)\ntokenizer.fit_on_texts(texts_train)\nsequences = tokenizer.texts_to_sequences(texts_train)\nsequences_test = tokenizer.texts_to_sequences(texts_test)\n\nword_index = tokenizer.word_index\nprint('Found %s unique tokens.' % len(word_index))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MAX_SEQUENCE_LENGTH = 200\n#pad sequences are used to bring all sentences to same size.\n# pad sequences with 0s\nx_train = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\nx_test = pad_sequences(sequences_test, maxlen=MAX_SEQUENCE_LENGTH)\nprint('Shape of data tensor:', x_train.shape)\nprint('Shape of data test tensor:', x_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Embedding(MAX_NB_WORDS, 128))\nmodel.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2,input_shape=(1,)))\nmodel.add(Dense(1, activation='sigmoid'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='binary_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(x_train, train_y,\n          batch_size=128,\n          epochs=10,\n          validation_data=(x_test, test_y))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}