{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Introduction\n\nThis kernel aims to investigate the different approaches for pokemon type classification. \n\n1) A single multilabel model.\n\n2) Two multiclass models, one for each type. *not implemented yet*\n\n\n\nThis kernel uses a library called jcopdl that simplifies a lot of boilerplate code such as earlystopping and model checkpoints.","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import torch\nfrom torchvision.transforms import transforms\nfrom torch.utils.data import Dataset, DataLoader\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\n!pip install -q torchsummary\nfrom torchsummary import summary\n\nfrom tqdm.auto import tqdm\nfrom time import sleep\nimport os\n\n!pip -q install jcopdl\nimport jcopdl\nfrom jcopdl.callback import Callback, set_config\n\nWORKING_DIR = \"/kaggle/input/pokemon-images-and-types/\"\nINFO_DIR = \"pokemon.csv\"\nIMAGES_DIR = \"images/images/\"\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n\nconfig = set_config(dict(output_size=18, batch_size=4, image_size=(120, 120), lr=5e-4, dropout=0.5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Processing","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# %%write dataset.py\n\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\n\n\nclass PokemonDatasetBuilder():\n    \n    \"\"\"\n    A class used to generate the appropriate datasets.\n    \"\"\"\n    def __init__(self, dataset_class, file_path, transform=None, splits=True):\n        \"\"\"\n        dataset_class: one of {multilabel, multiclass}, determines the output of \n                       the dataset to be either one OneHotEncoded vector or two different labels.\n                       \n        file_path:     the file path to the csv file. \n        \n        splits:        An optional condition to create a training, validation and testing set.\n        \"\"\"\n        \n        self._splits = splits\n        self._dataset_class = dataset_class\n        self.df = pd.read_csv(file_path)\n        self.transform = transform\n        self._preprocess_frame()\n        \n    def __call__(self, test_split=0.1, val_split=0.1):\n        \"\"\"\n        Generates the datasets. \n        \"\"\"\n        \n        dfs = []\n        if self._splits:\n            dfs.extend(self._create_splits(test_split, val_split))\n        else:\n            dfs.append(self.df)\n        \n        datasets = []\n        \n        # If multilabel, we don't encode type2 differently\n        if self._dataset_class == \"multilabel\":\n            OHE = OneHotEncoder(sparse=False, handle_unknown=\"ignore\")\n            OHE.fit(self.df[[\"Type1\"]])\n            \n            for df in dfs:\n                datasets.append(PokemonDatasetMultilabel(df, OHE, self.transform))\n            \n        \n        # If multiclass, we have to encode type1 and type2 differently, \n        # as we now have 19 targets for type2 (including None)\n        else:\n            LE1 = LabelEncoder()\n            LE2 = LabelEncoder()\n            \n            LE1.fit(self.df[\"Type1\"])\n            LE2.fit(self.df[\"Type2\"])\n        \n            for df in dfs:\n                datasets.append(PokemonDatasetMulticlass(df, LE1, LE2, self.transform))\n        \n        return datasets\n            \n            \n    def _create_splits(self, test_split, val_split):\n        \"\"\"\n        Helper function to create the different splits. \n        \"\"\"\n        df_test = self.df.sample(frac=test_split, random_state=42)\n        df_train = self.df.drop(df_test.index)\n        df_val = df_train.sample(frac=val_split, random_state=42)\n        df_train = df_train.drop(df_val.index)\n\n            \n        return [df_train, df_val, df_test]\n\n    \n    def _preprocess_frame(self):\n        \"\"\"\n        Helper function to preprocess the dataframe.\n        \"\"\"\n        \n        # From gen 7 and above the images are stored in jpg... why? \n        self.df[\"Name\"].iloc[:721] = self.df[\"Name\"].iloc[:721].apply(lambda x : x + \".png\")\n        self.df[\"Name\"].iloc[721:] = self.df[\"Name\"].iloc[721:].apply(lambda x : x + \".jpg\")\n        self.df[\"Type2\"].fillna(\"None\", inplace=True)\n        \n    \n        \nclass PokemonDatasetMultilabel(Dataset):\n    \"\"\"\n    A dataset that returns a multilabel vector. The encoder passed to it should be a One hot encoder.\n    \"\"\"\n    \n    def __init__(self, df, encoder, transform=None):\n        \n        self.df = df\n        self.transform = transform\n        self.encoder = encoder\n        self.type1 = encoder.transform(self.df[[\"Type1\"]])\n        self.type2 = encoder.transform(self.df[[\"Type2\"]])\n    \n    def __getitem__(self, idx):\n        \n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n        \n        image_file = WORKING_DIR + IMAGES_DIR + self.df.iloc[idx, 0]\n        \n        image = process_image(image_file, self.transform)\n\n        return image, (self.type1[idx] + self.type2[idx])\n\n    \n    def __len__(self):\n        return self.df.shape[0]\n    \n    \n    def get_labels_from_vector(self, vector):\n        \"\"\"\n        Returns labels of a pokemon given a one hot encoded vector. \n        The output is formatted as type1, type2.\n        \n        >>> train_dataset = PokemonDatasetMultilabel(...)\n        >>> vector = np.array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n                     0.])\n        >>> train_dataset.get_labels_from_vector(vector)\n        (\"Dark\", \"Ground\")\n        \n        >>> vector = np.array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n                     0.])\n        >>> train_dataset.get_labels_from_vector(vector)\n        (\"Fire\", \"None\")\n        \"\"\"\n        \n        labels = self.encoder.categories_[0][vector==1]\n        if vector.sum() == 1:\n            return labels[0], \"None\"\n        else:\n            return tuple(labels)\n\n    def get_labels_from_id(self, type1, type2=None):\n        \"\"\"\n        Returns labels of a pokemon given both ids. \n        The output is formatted as type1, type2. \n        \n        >>> train_dataset = PokemonDatasetMultilabel(...)\n        >>> type1, type2  = (0, 15)\n        >>> train_dataset.get_labels_from_id(type1, type2)\n        (\"Bug\", \"Rock\")\n        >>> train_dataset.get_labels_from_id(0)\n        >>>(\"Bug\", \"None\")\n        \"\"\"\n        if type2 is not None: \n            return self.encoder.categories_[0][type1], self.encoder.categories_[0][type2]\n        else:\n            return self.encoder.categories_[0][type1], \"None\"\n    \n    \nclass PokemonDatasetMulticlass(Dataset):\n    \n    \"\"\"\n    A dataset that returns two outputs, which represent type1 and type2 respectively. \n    \"\"\"\n    def __init__(self, df, type_1_encoder, type_2_encoder, transform=None):\n        \n        self.df = df\n        self.transform = transform\n        \n        self.type_1_encoder = type_1_encoder\n        self.type_2_encoder = type_2_encoder\n        \n        self.type1 = type_1_encoder.transform(self.df[\"Type1\"])\n        self.type2 = type_2_encoder.transform(self.df[\"Type2\"])\n        \n    def __getitem__(self, idx):\n        \n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n            \n        image_file = WORKING_DIR + IMAGES_DIR + self.df.iloc[idx, 0]\n        image = process_image(image_file, self.transform)\n        \n        return image, self.type1[idx], self.type2[idx]\n    \n    def __len__(self):\n        return self.df.shape[0]\n    \n    \n    \n    def get_labels(self, type1, type2):\n        \"\"\"\n        Returns the labels of the pokemon given both ids.\n        The output is formatted as type1, type2.\n        \"\"\"\n        return self.type_1_encoder.classes_[type1], self.type_2_encoder.classes_[type2]\n            \n        \n        \n        \ndef process_image(image_file, transform=None):\n    \"\"\"\n    Returns the image given the image file, and applies transform to it. \n    \"\"\"\n        \n    # this converts PNG images to JPG images (RGBA to RGB), while giving both a white background instead of\n    # a black background. \n    if image_file.split(\".\")[-1] == \"png\":\n        pil_image = Image.open(image_file).convert(\"RGBA\")\n        image = Image.new('RGBA',pil_image.size,(255,255,255))\n        image.paste(pil_image, (0,0), pil_image)\n        image = image.convert(\"RGB\")\n\n    else:\n        image = Image.open(image_file)\n\n\n    if transform:\n        image = transform(image)\n        \n    return image\n\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_image(image, type1, type2):\n    \"\"\"\n    Shows the image as well as the type of the pokemon. \n    \"\"\"\n    plt.imshow(image.permute(1, 2, 0))\n    plt.axis(\"Off\")\n    title = f\"Type: {type1}\"\n    if type2 != \"None\":\n        title += f\", {type2}\"\n    plt.title(title)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"OUTPUT_TYPE = \"multilabel\" # can also be \"multiclass\"\n\n# transformations = transforms.Compose([transforms.Resize((120, 120)), transforms.ToTensor()])\ntransformations = transforms.Compose([transforms.ToTensor()])\ndataset_generator = PokemonDatasetBuilder(OUTPUT_TYPE, WORKING_DIR + INFO_DIR, transformations)\ntrain_dataset, val_dataset, test_dataset = dataset_generator()\n\ntrain_dataloader = DataLoader(train_dataset, batch_size = config.batch_size, shuffle=True)\nval_dataloader = DataLoader(val_dataset)\ntest_dataloader = DataLoader(test_dataset)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Peaking into the data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sample usage for multilabel \npokemon = train_dataset[1]\nshow_image(pokemon[0], *train_dataset.get_labels_from_vector(pokemon[1]))\n\n# Sample usage for multiclass\n# show_image(pokemon[0], *train_dataset.get_labels(*pokemon[1:]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Model Creation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import models\n\n\nclass UnknownModeException(Exception):\n    \n    def __str__(self):\n        return \"Unknown mode given. Use one of: 'logistic', 'softmax', 'none'.\"\n\nclass PokemonFCBlock(nn.Module):\n    \"\"\"\n    The final layer for a PokemonCNN. \n    \"\"\"\n    \n    def __init__(self, in_features, out_features, mode=\"none\", dropout=0.2):\n        \"\"\"\n        Initializes a new final layer.\n        \n        mode represents the final activation applied to the logits.\n        {\"logistic\", \"softmax\", \"none\"}\n        \"\"\"\n        super().__init__()\n        \n        self.fc = nn.Sequential(\n            nn.Linear(in_features, 1000),\n            nn.LeakyReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(1000, 1000),\n            nn.LeakyReLU(), \n            nn.Dropout(dropout),\n            nn.Linear(1000, out_features)\n        )\n        \n        self.mode = mode.lower()\n        \n        \n    def forward(self, x):\n        \n        if self.mode == \"logistic\":\n            return torch.sigmoid(self.fc(x))\n        elif self.mode == \"softmax\":\n            return F.softmax(self.fc(x))\n        elif self.mode == \"none\":\n            return self.fc(x)\n        else:\n            raise UnknownModeException\n    \n        \n\nclass PokemonMultilabelCNN(nn.Module):\n    \"\"\"\n    A CNN based on a base model that will output multilabel predictions. \n    The base model expects a ResNet architecture. \n    \"\"\"\n    \n    def __init__(self, base_model, output_size, dropout):\n        \n        super().__init__()\n    \n        self.base_model = base_model \n        in_features = self.base_model.fc.in_features\n        new_final = PokemonFCBlock(in_features, output_size, mode=\"logistic\")\n        self.base_model.fc = new_final\n\n        \n    def forward(self, x):\n        return self.base_model(x)\n    \n    def freeze(self):\n        # Freezes all the layers except for the final fully connected layer. \n        for name, child in self.base_model.named_children():\n            if name != \"fc\":\n                for param in child.parameters():\n                    param.requires_grad = False \n            \n    def unfreeze(self):\n        for param in self.base_model.parameters():\n            param.requires_grad = True\n    \n    \n#TODO: Create the multiclass version","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model = models.resnet50(pretrained=True, progress=False)\nmodel = PokemonMultilabelCNN(base_model, config.output_size, config.dropout)\nmodel.to(device)\nmodel.freeze()\nsummary(model, (3, *config.image_size))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"criterion = nn.BCELoss()\noptimizer= torch.optim.AdamW(model.parameters(), lr=config.lr)\ncallback = Callback(model, config, early_stop_patience=10, outdir=\"model\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ModelTrainer():\n    \"\"\"\n    Abstract base class for model trainers.\n    \"\"\"\n    \n    def __init__(self, model, optimizer, criterion, device, callback):\n        \n        self.model = model\n        self.optimizer = optimizer\n        self.criterion = criterion\n        self.device = device\n        self.callback = callback\n        self.epoch = 1\n        \n    def train_loop(self, dataloader, epoch=None):\n        \"\"\"\n        Trains the model for a single loop, i.e one epoch\n        The optional argument epoch indicates which epoch this training loop belongs to.\n        \"\"\"\n        raise NotImplementedError\n        \n    def validate_loop(self, dataloader):\n        \"\"\"\n        Validate the model. \n        \"\"\"\n        raise NotImplementedError\n        \n    def train(self, train_dataloader, val_dataloader):\n        \"\"\"\n        Trains the model for multiple epochs, and validates the model every epoch. \n        \"\"\"\n        raise NotImplementedError\n        \nclass MultilabelModelTrainer(ModelTrainer):\n    \"\"\"\n    A multilabel model trainer.\n    \"\"\"\n    \n    def __init__(self, model, optimizer, criterion, device, callback):\n        \n        super(MultilabelModelTrainer, self).__init__(model, optimizer, criterion, device, callback)\n    \n        \n    def train_loop(self, dataloader, epoch=True):\n        \n        self.model.train()\n        cost = 0 \n        t = tqdm(dataloader)\n        if epoch:\n            t.set_description(f\"Training mode, Epoch {self.epoch}\")\n            \n        for feature, target in t:\n            feature, target = feature.to(self.device), target.to(self.device)\n            output = self.model(feature).double() # resolves expected dtype Double but got dtype Float\n            loss = self.criterion(output, target)\n            loss.backward()\n            \n            self.optimizer.step()\n            self.optimizer.zero_grad()\n            \n            cost += loss.item() * feature.shape[0]\n        \n        return cost / len(dataloader.dataset)\n            \n        \n    def validate_loop(self, dataloader):\n        \n        self.model.eval()\n        cost = 0\n        with torch.no_grad():\n            for feature, target in tqdm(dataloader, desc=\"Validation mode\"):\n                feature, target = feature.to(self.device), target.to(self.device)\n                output = self.model(feature).double()\n                loss = self.criterion(output, target)\n                \n                cost += loss.item() * feature.shape[0]\n        \n        return cost/len(dataloader.dataset)\n        \n        \n    def train(self, train_dataloader, val_dataloader):\n        \n        while True: \n            train_cost = self.train_loop(train_dataloader)\n            val_cost = self.validate_loop(val_dataloader)\n            \n            self.epoch += 1\n\n            # Prevents weird output\n            _ = self.callback.log(train_cost, val_cost)\n            _ = self.callback.save_checkpoint()\n#             _ = self.callback.cost_runtime_plotting()\n        \n            if self.callback.early_stopping(model, monitor=\"test_cost\"):\n                self.callback.plot_cost()\n                break\n            \n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_trainer = MultilabelModelTrainer(model, optimizer, criterion, device, callback)\nmodel_trainer.train(train_dataloader, val_dataloader)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\n\nrandom_idx = random.randint(0, len(train_dataset)-1)\npokemon = train_dataset[random_idx]\nwith torch.no_grad():\n    feature = pokemon[0].to(device)\n    prediction = model(feature.unsqueeze(0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_image(pokemon[0], *train_dataset.get_labels_from_vector(pokemon[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_labels = prediction.squeeze(0).argsort()\ntype2, type1 = predicted_labels[-2], predicted_labels[-1]\n\nif prediction.squeeze(0)[type1] - prediction.squeeze(0)[type2] >= 0.2:\n    print(train_dataset.get_labels_from_id(type1))    \n    print(f\"{type1}: {prediction.squeeze(0)[type1]}\")\nelse:\n    print(train_dataset.get_labels_from_id(type1, type2))\n    print(f\"{type1}: {prediction.squeeze(0)[type1]}\")\n    print(f\"{type2}: {prediction.squeeze(0)[type2]}\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}