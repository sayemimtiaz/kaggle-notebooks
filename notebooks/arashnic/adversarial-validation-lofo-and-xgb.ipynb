{"cells":[{"metadata":{},"cell_type":"markdown","source":"### **Introduction**"},{"metadata":{},"cell_type":"markdown","source":"**Adversarial Validation** :If you were to study some of the competition-winning solutions on Kaggle, you might notice references to “adversarial validation” . What is Ad Val?\nIn short, we build a classifier to try to predict which data rows are from the training set, and which are from the test set. If the two datasets came from the same distribution, this should be impossible. But if there are systematic differences in the feature values of your training and test datasets, then a classifier will be able to successfully learn to distinguish between them. The better a model you can learn to distinguish them, the bigger the problem you have.\nBut the good news is that you can analyze the learned model to help you diagnose the problem. And once you understand the problem, you can go about fixing it."},{"metadata":{},"cell_type":"markdown","source":"![adval](https://www.thetalkingmachines.com/sites/default/files/styles/widescreen_large/public/2020-04/29_big_data_grid.jpg?itok=GoyDY8Rf)\n#  \n*image ref.[Adversarial Validation Overview](\"https://www.thetalkingmachines.com/article/adversarial-validation-overview-0\")* "},{"metadata":{},"cell_type":"markdown","source":"**LOFO** :Among several feature selection methods LOFO is a bit different LOFO (Leave One Feature Out) Importance calculates the importances of a set of features based on a metric of choice, for a model of choice, by iteratively removing each feature from the set, and evaluating the performance of the model, with a validation scheme of choice, based on the chosen metric.\n\nLOFO first evaluates the performance of the model with all the input features included, then iteratively removes one feature at a time, retrains the model, and evaluates its performance on a validation set. The mean and standard deviation (across the folds) of the importance of each feature is then reported.\n\nIf a model is not passed as an argument to LOFO Importance, it will run LightGBM as a default model.\n\nSee more: https://github.com/aerdem4/lofo-importance"},{"metadata":{},"cell_type":"markdown","source":"In this notebook we will walkthroug to how to use ad-val and LOFO to get better result from XGBoost"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline \nplt.style.use('fivethirtyeight')\nfrom scipy import stats\nfrom scipy.stats import rankdata, norm\n\n\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, MinMaxScaler, RobustScaler\nfrom sklearn.model_selection import train_test_split, KFold, GroupKFold, GridSearchCV, StratifiedKFold\n\nfrom sklearn.metrics import roc_auc_score\n\n\n\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import SimpleImputer, IterativeImputer\nimport time, os, warnings, random, string, re, gc, sys\n\nimport xgboost as xgb\nimport lightgbm as lgb\n\n\nif not sys.warnoptions:\n    import warnings\n    warnings.simplefilter(\"ignore\")\n    \nfrom IPython.display import display\n\n\ndef set_seed(seed=2021):\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\nset_seed()\n\n\n\n\n\ntrain = pd.read_csv('/kaggle/input/hr-analytics-job-change-of-data-scientists/aug_train.csv')\ntest = pd.read_csv('/kaggle/input/hr-analytics-job-change-of-data-scientists/aug_test.csv')\ntr_orig = train.copy()\nts_orig= test.copy()\ntarget = train.pop('target')\ndel train['enrollee_id']\ndel test['enrollee_id']\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cats = [c for c in train.columns if train[c].dtypes =='object']\n\n\n\nfor c in cats:\n    le=LabelEncoder()\n    le.fit(list(train[c].astype('str')) + list(test[c].astype('str')))\n    train[c] = le.transform(list(train[c].astype(str))) \n    test[c] = le.transform(list(test[c].astype(str))) \ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"sns.catplot(data=train, orient=\"h\", kind=\"box\", height=4.5, aspect=2, palette='Blues')\nsns.catplot(data=test, orient=\"h\", kind=\"box\", height=4.5, aspect=2, palette='Reds')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **XGBoost base model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nxgb_params = {\n    \n    'objective':'binary:logistic', \n    'max_depth': 5, \n    'learning_rate': 0.01, \n    'booster':'gbtree', \n    'max_leaves': 15, \n    'eval_metric': 'auc', \n    'colsample_bytree': 0.8, \n    'subsample':0.9, \n    'lambda': 2, \n    'alpha': 1, \n    'scale_pos_weight':5\n   \n}\n\n\nxgb_scores = []\n\noof_xgb = np.zeros(len(train))\npred_xgb = np.zeros(len(test))\n\nimportances = pd.DataFrame()\n\n\nfolds = StratifiedKFold(n_splits=3, shuffle=True, random_state=4242)\n\nfor fold_, (train_ind, val_ind) in enumerate(folds.split(train, target)):\n    print('fold : ----------------------------------------', fold_)\n    trn_data = xgb.DMatrix(data=train.iloc[train_ind], label=target.iloc[train_ind])\n    val_data = xgb.DMatrix(data= train.iloc[val_ind], label=target.iloc[val_ind])\n    \n       \n    xgb_model = xgb.train(xgb_params, trn_data, num_boost_round=1000, evals=[(trn_data, 'train'), (val_data, 'test')], verbose_eval=100, early_stopping_rounds=100)\n    oof_xgb[val_ind] = xgb_model.predict(xgb.DMatrix(train.iloc[val_ind]),  ntree_limit= xgb_model.best_ntree_limit)\n    \n    print(roc_auc_score(target.iloc[val_ind], oof_xgb[val_ind]))\n    xgb_scores.append(roc_auc_score(target.iloc[val_ind], oof_xgb[val_ind]))\n        \n    importance_score = xgb_model.get_score(importance_type='gain')\n    importance_frame = pd.DataFrame({'Importance': list(importance_score.values()), 'Feature': list(importance_score.keys())})\n    importance_frame['fold'] = fold_ +1\n    importances = pd.concat([importances, importance_frame], axis=0, sort=False)\n    \n    pred_xgb += xgb_model.predict(xgb.DMatrix(test), ntree_limit= xgb_model.best_ntree_limit)/folds.n_splits\n \nprint('model auc:', np.mean(xgb_scores))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"answer = np.load('../input/job-change-dataset-answer/jobchange_test_target_values.npy')\nroc_auc_score(answer, pred_xgb)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Adversarial Validation with lgb"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/hr-analytics-job-change-of-data-scientists/aug_train.csv')\ntest = pd.read_csv('/kaggle/input/hr-analytics-job-change-of-data-scientists/aug_test.csv')\n\ntarget = train['target']\n\ncats = [c for c in train.columns if train[c].dtypes =='object']\n\n\n\nfor c in cats:\n    le=LabelEncoder()\n    le.fit(list(train[c].astype('str')) + list(test[c].astype('str')))\n    train[c] = le.transform(list(train[c].astype(str))) \n    test[c] = le.transform(list(test[c].astype(str))) \ntrain.head()\n\nuse_cols  = [c for c in train.columns if c not in ['enrollee_id', 'target']]\n\nfeatures = list(train[use_cols].columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train[use_cols]\ntest = test[use_cols]\n\ntrain['target'] = 0\ntest['target'] = 1\ntrain_test = pd.concat([train, test], axis =0)\n\ntarget = train_test['target'].values\n\ntrain_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"param = {'num_leaves': 50,\n         'min_data_in_leaf': 30, \n         'objective':'binary',\n         'max_depth': 5,\n         'learning_rate': 0.001,\n         \"min_child_samples\": 20,\n         \"boosting\": \"gbdt\",\n         \"feature_fraction\": 0.9,\n         \"bagging_freq\": 1,\n         \"bagging_fraction\": 0.9 ,\n         \"bagging_seed\": 17,\n         \"metric\": 'auc',\n         \"lambda_l1\": 0.1,\n         \"verbosity\": -1}\n\n\nscores = []\noof = np.zeros(len(train_test))\nfeature_importances_gain = pd.DataFrame()\nfeature_importances_gain['feature'] = train_test[features].columns\n\nfeature_importances_split = pd.DataFrame()\nfeature_importances_split['feature'] = train_test[features].columns\n\n\nfolds = KFold(n_splits=5, shuffle=True, random_state=15)\n\n\n\nfor fold_, (trn_idx, val_idx) in enumerate(folds.split(train_test, target)):\n    print(\"fold n°{}\".format(fold_))\n    trn_data = lgb.Dataset(train_test.iloc[trn_idx][features], label=target[trn_idx])\n    val_data = lgb.Dataset(train_test.iloc[val_idx][features], label=target[val_idx])\n\n    num_round = 10000\n    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=100, early_stopping_rounds = 100)\n    oof[val_idx] = clf.predict(train_test.iloc[val_idx][features], num_iteration=clf.best_iteration)\n    \n    \n    feature_importances_gain['fold_{}'.format(fold_ + 1)] = clf.feature_importance(importance_type='gain')\n    feature_importances_split['fold_{}'.format(fold_ + 1)] = clf.feature_importance(importance_type='split')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We see that the oof AUC is VERY close to 0.5, so these two datasets seem very statistically similar. But let see which features affect train vs test distribution diff.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_importances_gain['average'] = feature_importances_gain[['fold_{}'.format(fold + 1) for fold in range(folds.n_splits)]].mean(axis=1)\nfeature_importances_gain.to_csv('feature_importances.csv')\n\nplt.figure(figsize=(20, 8))\nsns.barplot(data=feature_importances_gain.sort_values(by='average', ascending=False).head(100),  x='average', y='feature');\nplt.title('TOP feature importance over {} folds average affects train vs test distribution'.format(folds.n_splits));","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(ncols=2, figsize=(25, 7))\nsns.distplot(train.city,bins=50,  fit=norm,kde=True,kde_kws={\"shade\": True}, norm_hist=True,  color='darkcyan', ax=axs[0])\nsns.distplot(train.training_hours,bins=50,  fit=norm,kde=True,kde_kws={\"shade\": True}, norm_hist=True,  color='darkcyan', ax=axs[1])\naxs[0].set_title('Train Vs Test')\nsns.distplot(test.city,bins=50,  fit=norm,kde=True,kde_kws={\"shade\": True}, norm_hist=True,  color='darkred', ax=axs[0])\nsns.distplot(test.training_hours,bins=50,  fit=norm,kde=True,kde_kws={\"shade\": True},norm_hist=True,  color='darkred', ax=axs[1])\naxs[1].set_title('Train Vs Test')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"train.training_hours.hist(bins=70, color='darkcyan',figsize=(10, 5))\ntest.training_hours.hist(bins=70, color='darkred',figsize=(10, 5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.city.hist(bins=30, color='darkcyan',figsize=(10, 5))\ntest.city.hist(bins=30, color='darkred',figsize=(10, 5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **LOFO Importances**"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install lofo-importance","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom lofo import LOFOImportance, Dataset, plot_importance\n%matplotlib inline\n\n# import data\ntrain_df = tr_orig.copy()\ntest_df = ts_orig.copy()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### LOFO , Default algorithm: lgb"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# extract a sample of the data\nsample_df = train_df.sample(frac=1, random_state=0)\n#sample_df.sort_values(\"AvSigVersion\", inplace=True)\nfeats = [col for col in train_df.columns if col not in ['enrollee_id', 'target']]\n# define the validation scheme\ncv = KFold(n_splits=3, shuffle=True, random_state=0)\n\n# define the binary target and the features\ndataset = Dataset(df=sample_df, target=\"target\", features=feats)\n\n# define the validation scheme and scorer. The default model is LightGBM\nlofo_imp = LOFOImportance(dataset, cv=cv, scoring=\"roc_auc\")\n\n# get the mean and standard deviation of the importances in pandas format\nimportance_df = lofo_imp.get_importance()\n\n# plot the means and standard deviations of the importances\nplot_importance(importance_df, figsize=(20, 12))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Yet \"city\" and \"training_hours\" are harmful. Healing these features could be done by feat eng , statistical techniques and so on, but the simplest is to remove them and see the effect on xgb performance**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = tr_orig.copy()\ntest = ts_orig.copy()\n\ntarget = train.pop('target')\ndel train['enrollee_id']\ndel test['enrollee_id']\n\ncats = [c for c in train.columns if train[c].dtypes =='object']\n\n\n\nfor c in cats:\n    le=LabelEncoder()\n    le.fit(list(train[c].astype('str')) + list(test[c].astype('str')))\n    train[c] = le.transform(list(train[c].astype(str))) \n    test[c] = le.transform(list(test[c].astype(str))) \n\n\nfor df in [train, test]:\n    del df['city']\n    del df['training_hours']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nxgb_params = {\n    \n    'objective':'binary:logistic', \n    'max_depth': 5, \n    'learning_rate': 0.01, \n    'booster':'gbtree', \n    'max_leaves': 15, \n    'eval_metric': 'auc', \n    'colsample_bytree': 0.8, \n    'subsample':0.9, \n    'lambda': 2, \n    'alpha': 1, \n    'scale_pos_weight':5\n   \n}\n\n\nxgb_scores = []\n\noof_xgb = np.zeros(len(train))\npred_xgb = np.zeros(len(test))\n\nimportances = pd.DataFrame()\n\n\nfolds = StratifiedKFold(n_splits=3, shuffle=True, random_state=4242)\n\nfor fold_, (train_ind, val_ind) in enumerate(folds.split(train, target)):\n    print('fold : ----------------------------------------', fold_)\n    trn_data = xgb.DMatrix(data=train.iloc[train_ind], label=target.iloc[train_ind])\n    val_data = xgb.DMatrix(data= train.iloc[val_ind], label=target.iloc[val_ind])\n    \n       \n    xgb_model = xgb.train(xgb_params, trn_data, num_boost_round=1000, evals=[(trn_data, 'train'), (val_data, 'test')], verbose_eval=100, early_stopping_rounds=100)\n    oof_xgb[val_ind] = xgb_model.predict(xgb.DMatrix(train.iloc[val_ind]),  ntree_limit= xgb_model.best_ntree_limit)\n    \n    print(roc_auc_score(target.iloc[val_ind], oof_xgb[val_ind]))\n    xgb_scores.append(roc_auc_score(target.iloc[val_ind], oof_xgb[val_ind]))\n        \n    importance_score = xgb_model.get_score(importance_type='gain')\n    importance_frame = pd.DataFrame({'Importance': list(importance_score.values()), 'Feature': list(importance_score.keys())})\n    importance_frame['fold'] = fold_ +1\n    importances = pd.concat([importances, importance_frame], axis=0, sort=False)\n    \n    pred_xgb += xgb_model.predict(xgb.DMatrix(test), ntree_limit= xgb_model.best_ntree_limit)/folds.n_splits\n \nprint('model auc:', np.mean(xgb_scores))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nroc_auc_score(answer, pred_xgb)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":">#### _*CV boost ::::   0.8023 --------->0.8057*_\n\n>#### *test roc_auc boost: :::  0.7970 -----------> 0.7986*"},{"metadata":{},"cell_type":"markdown","source":"**So in terms of our objective function and roc_auc and our features used  \"city\" and \"training_hours\" are harmful !**"},{"metadata":{},"cell_type":"markdown","source":"### XGBoost Feature Importances"},{"metadata":{"trusted":true},"cell_type":"code","source":"#importances['gain_log'] = importances['gain']\nmean_gain = importances[['Importance', 'Feature']].groupby('Feature').mean()\n#importances['mean_score'] = importances['Feature'].map(mean_gain['Importance'])\nmean_gain = mean_gain.reset_index()\nplt.figure(figsize=(20, 15))\nsns.barplot(x='Importance', y='Feature', data=mean_gain.sort_values('Importance', ascending=False), palette='bone')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}