{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#imports\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom xgboost import XGBRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.ensemble import VotingRegressor\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom lightgbm import LGBMRegressor\nfrom catboost import CatBoostRegressor\nfrom sklearn.ensemble import StackingRegressor\nsns.set(rc={'figure.figsize':(15,10)})\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom sklearn.preprocessing import LabelEncoder,StandardScaler\nfrom xgboost import XGBRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error,mean_absolute_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/top50spotify2019/top50.csv',encoding='ISO-8859-1')\ndf.set_index('Unnamed: 0',inplace=True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.rename(columns={'Track.Name' : 'Track', \n                     'Artist.Name' : 'Artist', \n                     'Genre': 'Genre', \n                     'Beats.Per.Minute' : 'BPM',\n                     'Energy' : 'Energy', \n                     'Danceability' : 'Dance', \n                     'Loudness..dB..' : 'Loudness(dB)', \n                     'Liveness' : 'Liveness', \n                     'Valence.' : 'Valence',\n                     'Length.' : 'Length', \n                     'Acousticness..' : 'Acoustic', \n                     'Speechiness.' : 'Speech', \n                     'Popularity' : 'Popularity'}, inplace = True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Genre'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA"},{"metadata":{},"cell_type":"markdown","source":"lets see the correlation between the features."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(df.corr(),annot=True,cmap='BuPu')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Plotting differnt features against Popularity**"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x='Genre',y='Popularity',data=df,palette='rocket_r')\nplt.xticks(rotation=90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x='Artist',y='Popularity',data=df,palette='magma_r')\nplt.xticks(rotation=90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x='BPM',y='Popularity',hue='Energy',data=df,palette='rocket_r')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x='Loudness(dB)',y='Popularity',hue='Energy',data=df,palette='rocket_r')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x='Liveness',y='Popularity',hue='Energy',data=df,palette='rocket_r')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x='Dance',y='Popularity',hue='Energy',data=df,palette='rocket_r')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x='Length',y='Popularity',hue='Energy',data=df,palette='rocket_r')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x='Speech',y='Popularity',hue='Energy',data=df,palette='rocket_r')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x='Acoustic',y='Popularity',hue='Energy',data=df,palette='rocket_r')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"let us see the average of different features grouped together against Genres of songs from the dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"g_p = df.groupby('Genre')['Popularity','BPM','Liveness','Length'].mean()\ng_p","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g_p.plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Repeating the same process for different Artists from the dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"a_p = df.groupby('Artist')['Popularity','BPM','Dance','Length'].mean()\na_p","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a_p[0:10].plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a_p[10:20].plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a_p[20:30].plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a_p[30:].plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# MODELLING"},{"metadata":{},"cell_type":"markdown","source":"Trying to predict the Popularity of a song by training a model on different features."},{"metadata":{"trusted":true},"cell_type":"code","source":"enc = LabelEncoder()\ndf['Artist_enc'] = enc.fit_transform(df['Artist'])\ndf['Genre_enc'] = enc.fit_transform(df['Genre'])\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target = df['Popularity']\ntrain = df.drop(['Popularity','Artist','Genre','Track'],axis=1)\nprint(train.shape,target.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(train, target, test_size=0.1, random_state=42,shuffle=True)\nprint(X_train.shape, X_test.shape, y_train.shape, y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\nscaler.fit_transform(X_train)\nscaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#models\nrf = RandomForestRegressor(bootstrap=True,criterion='mse',random_state=42,max_depth=35,\n                           max_features=11,n_estimators=2500,n_jobs=-1)\nxgb = XGBRegressor(booster='gbtree', colsample_bylevel=1,colsample_bynode=1, colsample_bytree=0.6, gamma=0,\n             importance_type='gain', learning_rate=0.01, max_delta_step=0,\n             max_depth=6, min_child_weight=4, n_estimators=4500,\n             n_jobs=4, nthread=None, objective='reg:squarederror',\n             reg_alpha=0.6, reg_lambda=0.6, scale_pos_weight=1, \n             silent=None, subsample=0.8, verbosity=1)\ngbr = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.01, max_depth=4,\n                                max_features='sqrt', min_samples_leaf=15, min_samples_split=10,\n                                loss='huber', random_state =42) \ndtr = DecisionTreeRegressor(criterion='mse',random_state=42,max_depth=35,\n                           max_features='sqrt', min_samples_leaf=15, min_samples_split=10)\nabr = AdaBoostRegressor(dtr,n_estimators=4500,random_state=42,learning_rate=0.01)\ncat =  CatBoostRegressor(depth=6,learning_rate=0.1,n_estimators=2500,eval_metric = 'RMSE')\nlgb = LGBMRegressor(max_depth=25,num_leaves=120,learning_rate=0.01,n_jobs=-1,boosting_type='gbdt',\n                   objective='regression',mertic='rmse', verbosity=1,bagging_fraction=0.7,\n                   feature_fraction=0.5,bagging_frequency=6,bagging_seed=42,seed=42,\n                   colsample_bylevel=1,colsample_bynode=1, colsample_bytree=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb.fit(X_train,y_train)\nxgb_pred = xgb.predict(X_test)\nprint(np.sqrt(mean_squared_error(y_test,xgb_pred)),mean_absolute_error(y_test,xgb_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf.fit(X_train,y_train)\nrf_pred = rf.predict(X_test)\nprint(np.sqrt(mean_squared_error(y_test,rf_pred)),mean_absolute_error(y_test,rf_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtr.fit(X_train,y_train)\ndtr_pred = dtr.predict(X_test)\nprint(np.sqrt(mean_squared_error(y_test,dtr_pred)),mean_absolute_error(y_test,dtr_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"abr.fit(X_train,y_train)\nabr_pred = abr.predict(X_test)\nprint(np.sqrt(mean_squared_error(y_test,abr_pred)),mean_absolute_error(y_test,abr_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gbr.fit(X_train,y_train)\ngbr_pred = gbr.predict(X_test)\nprint(np.sqrt(mean_squared_error(y_test,gbr_pred)),mean_absolute_error(y_test,gbr_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat.fit(X_train,y_train)\ncat_pred = cat.predict(X_test)\nprint(np.sqrt(mean_squared_error(y_test,cat_pred)),mean_absolute_error(y_test,cat_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb.fit(X_train,y_train)\nlgb_pred = lgb.predict(X_test)\nprint(np.sqrt(mean_squared_error(y_test,lgb_pred)),mean_absolute_error(y_test,lgb_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"VR = VotingRegressor([('xgb',xgb),('lgb',lgb),('gbr',gbr),('cat',cat),('dtr',dtr)],n_jobs=-1)\nVR.fit(X_train,y_train)\nVR_pred = VR.predict(X_test)\nprint(np.sqrt(mean_squared_error(y_test,VR_pred)),mean_absolute_error(y_test,VR_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"level0 = [('xgb',xgb),('lgb',lgb),('gbr',gbr),('abr',abr),('cat',cat),('vr',VR)]\nlevel1 = LinearRegression()\nstack = StackingRegressor(estimators=level0, cv=5,n_jobs=-1)\nstack.fit(X_train,y_train)\nstack_pred = stack.predict(X_test)\nprint(np.sqrt(mean_squared_error(y_test,stack_pred)),mean_absolute_error(y_test,stack_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output = pd.DataFrame({'Actual':y_test,'Predicted_xgb':xgb_pred,'Predicted_lgb':lgb_pred,\n                      'Predicted_abr':abr_pred,'Predicted_gbr':gbr_pred,'Predicted_dtr':dtr_pred,\n                      'Predicted_rf':rf_pred,'Predicted_cat':cat_pred,\n                      'Predicted_VR':VR_pred,'Predicted_stack':stack_pred})\noutput","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output.to_csv('output.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}