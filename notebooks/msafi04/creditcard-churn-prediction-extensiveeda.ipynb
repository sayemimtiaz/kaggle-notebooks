{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Task 01\n- Improve performance of predicting churned customers - recall need to be higher"},{"metadata":{},"cell_type":"markdown","source":"# Task 02\n- An in-depth Exploratory Data Analysis that can help to visualize where the difference lies between churning and non-churning customers."},{"metadata":{},"cell_type":"markdown","source":"__Features Details__\n- Clientnum\t-\tClient number. Unique identifier for the customer holding the account\n- Attrition_Flag\t-\tInternal event (customer activity) variable - if the account is closed then 1 else 0\n- Customer_Age\t-\tDemographic variable - Customer's Age in Years\n- Gender\t-\tDemographic variable - M=Male, F=Female\n- Dependent_count\t-\tDemographic variable - Number of dependents\n- Education_Level\t-\tDemographic variable - Educational Qualification of the account holder (example: high school, college graduate, etc.)\n- Marital_Status\t-\tDemographic variable - Married, Single, Unknown\n- Income_Category\t-\tDemographic variable - Annual Income Category of the account holder (< $40K, $40K - 60K, $60K - $80K, $80K-$120K, > $120K, Unknown)\n- Card_Category\t-\tProduct Variable - Type of Card (Blue, Silver, Gold, Platinum)\n- Months_on_book\t-\tMonths on book (Time of Relationship)\n- Total_Relationship_Count\t-\tTotal no. of products held by the customer\n- Months_Inactive_12_mon\t-\tNo. of months inactive in the last 12 months\n- Contacts_Count_12_mon\t-\tNo. of Contacts in the last 12 months\n- Credit_Limit\t-\tCredit Limit on the Credit Card\n- Total_Revolving_Bal\t-\tTotal Revolving Balance on the Credit Card\n- Avg_Open_To_Buy\t-\tOpen to Buy Credit Line (Average of last 12 months)\n- Total_Amt_Chng_Q4_Q1\t-\tChange in Transaction Amount (Q4 over Q1) \n- Total_Trans_Amt\t-\tTotal Transaction Amount (Last 12 months)\n- Total_Trans_Ct\t-\tTotal Transaction Count (Last 12 months)\n- Total_Ct_Chng_Q4_Q1\tNum\tChange in Transaction Count (Q4 over Q1) \n- Avg_Utilization_Ratio\t-\tAverage Card Utilization Ratio"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"%matplotlib inline\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\npd.set_option('display.max_columns', None)\npd.set_option('display.max_colwidth', None)\n#pd.set_option('display.max_rows', None)\n\nimport gc\n\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\nfrom sklearn.utils import class_weight\nfrom sklearn.metrics import classification_report, roc_auc_score, recall_score, confusion_matrix\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom plotly.offline import iplot\n#to link plotly to pandas\nimport cufflinks as cf\ncf.go_offline()\ncf.set_config_file(offline = False, world_readable = True)\n\nfrom IPython.display import display\n\nplt.rcParams[\"figure.figsize\"] = (12, 8)\nplt.rcParams['axes.titlesize'] = 16\nplt.style.use('seaborn-whitegrid')\nsns.set_palette('Set2')\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nfrom time import time, strftime, gmtime\nstart = time()\nimport datetime\nprint(str(datetime.datetime.now()))\n\nimport warnings\nwarnings.simplefilter('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/credit-card-customers/BankChurners.csv')\nprint(df.shape)\ndf.rename(columns = {'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1': 'NBC 12_1', \n                    'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2': 'NBC 12_2'}, inplace = True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Task 02 - EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['CLIENTNUM'].nunique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- All client numbers are unique."},{"metadata":{},"cell_type":"markdown","source":"- Target feature is 'Attrition_Flag' in which 'Attrited Customer' means it's a churn (1) and 'Existing Customer' means there is no churn (0)\n- First we map these values for the target"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Attrition_Flag'] = df['Attrition_Flag'].map({'Existing Customer': 0, 'Attrited Customer': 1})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.countplot(data = df, x = 'Attrition_Flag')\nfor p in ax.patches:\n    ax.annotate(str(p.get_height()), (p.get_x() * 1.005, p.get_height() * 1.005))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- The dataset is highly imbalanced\n- We will have to do upsampling or downsampling"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Check for missing values__"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thera are no missing values in the dataset"},{"metadata":{},"cell_type":"markdown","source":"__Outliers Check__"},{"metadata":{"trusted":true},"cell_type":"code","source":"num_cols = [c for c in df.columns if (df[c].dtype != 'object') & (c != 'Attrition_Flag')]\ncat_cols = [c for c in df.columns if (c not in num_cols) & (c != 'Attrition_Flag')]\nlen(num_cols), cat_cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(int(18 / 2), 2, figsize = (16, 24))\nax = ax.flatten()\n\nfor i, c in enumerate(num_cols):\n    sns.boxplot(x = df[c], ax = ax[i])\nplt.suptitle('Outlier Analysis using BoxPlots', fontsize = 25, y = 1)\nplt.delaxes()\nfig.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- We can remove the two NBC features as NBC 12_1 values are closer to 1 and NBC 12_2 is closer to 0"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(['NBC 12_1', 'NBC 12_2'], axis = 1, inplace = True)\nnum_cols = [x for x in num_cols if x not in ['NBC 12_1', 'NBC 12_2']]\ndf.shape, num_cols","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Customer Age__"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Customer_Age'].iplot(\n    kind = 'hist',\n    bins = 50,\n    xTitle = 'Customer Age',\n    yTitle = 'Count',\n    title = 'Customer Age Distribution'\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Customer_Age'].max(), df['Customer_Age'].min()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Max age is 73 which is not an outlier"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plt.title('Unique Values Count of Gender')\nplt.pie(df['Gender'].value_counts().values, labels = df['Gender'].value_counts().index, autopct = '%1.2f%%', \nexplode = [0, 0.05], shadow = True);","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plt.title('Unique Values Count of Education_Level')\npct = df['Education_Level'].value_counts().values / np.sum(df['Education_Level'].value_counts()) * 100\n\nplt.pie(df['Education_Level'].value_counts().values, labels = df['Education_Level'].value_counts().index, autopct = '%1.2f%%', \n explode = (pct == max(pct)) * 0.1, shadow = True);","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plt.title('Unique Values Count of Income_Category')\npct = df['Income_Category'].value_counts().values / np.sum(df['Income_Category'].value_counts()) * 100\n\nplt.pie(df['Income_Category'].value_counts().values, labels = df['Income_Category'].value_counts().index, autopct = '%1.2f%%', \n explode = (pct == max(pct)) * 0.05, shadow = True);","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def show_value(x):\n    a  = np.round(x / 100.0 * np.sum(df['Marital_Status'].value_counts().values), 2)\n    return a\n\nplt.title('Unique Values Count of Marital_Status')\npct = df['Marital_Status'].value_counts().values / np.sum(df['Marital_Status'].value_counts()) * 100\n\nplt.pie(df['Marital_Status'].value_counts().values, labels = df['Marital_Status'].value_counts().index, autopct = show_value, \n explode = (pct == max(pct)) * 0.05, shadow = True);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- There are 749 customers whose marital status is given as Unknown, let's check their age before deciding whether to impute this category or leave it as a value"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['Marital_Status'] == 'Unknown']['Customer_Age'].iplot(kind = 'hist', bins = 50, linecolor = 'black')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The age distribution is between 25 and 65 years\n- We can consider one of the two options for Unknown category\n    1. Make the value as 'Married' for ages above 35, below 35 as 'Single'\n    2. Keep it as it is"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title('Unique Values Count of Card_Category')\n\nax = sns.countplot(data = df, x = 'Card_Category')\nfor p in ax.patches:\n    ax.annotate(str(p.get_height()), (p.get_x() * 1.005, p.get_height() * 1.005))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Blue category is highest - it must be entry-level card"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plt.title('Unique Values Count of Dependent_count')\n\nax = sns.countplot(data = df, x = 'Dependent_count')\nfor p in ax.patches:\n    ax.annotate(str(p.get_height()), (p.get_x() * 1.005, p.get_height() * 1.005))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Total_Relationship_Count is the\tTotal no. of products held by the customer__"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plt.title('Unique Values Count of Total_Relationship_Count')\n\nax = sns.countplot(data = df, x = 'Total_Relationship_Count')\nfor p in ax.patches:\n    ax.annotate(str(p.get_height()), (p.get_x() * 1.005, p.get_height() * 1.005))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Total_Trans_Ct'].iplot(\n    kind = 'hist',\n    bins = 100,\n    xTitle = 'Total Trans Count',\n    yTitle = 'Count',\n    title = 'Total Transaction Count Distribution for the last 12 months',\n    linecolor = 'black'\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Total_Trans_Amt'].iplot(\n    kind = 'hist',\n    bins = 100,\n    xTitle = 'Total Trans Amount',\n    yTitle = 'Count',\n    title = 'nsaction Amount Distribution for the last 12 months',\n    linecolor = 'black'\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title('Number of Customers Inactive - Months_Inactive_12_mon')\n\nax = sns.countplot(data = df, x = 'Months_Inactive_12_mon')\nfor p in ax.patches:\n    ax.annotate(str(p.get_height()), (p.get_x() * 1.005, p.get_height() * 1.005))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title('Number of Customers Contacted - Contacts_Count_12_mon')\n\nax = sns.countplot(data = df, x = 'Contacts_Count_12_mon')\nfor p in ax.patches:\n    ax.annotate(str(p.get_height()), (p.get_x() * 1.005, p.get_height() * 1.005))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (16, 10))\nplt.title('Number of Customers holding the card for months')\nax = sns.countplot(data = df, x = 'Months_on_book')\nfor p in ax.patches:\n    ax.annotate(str(p.get_height()), (p.get_x() * 1.005, p.get_height() * 1.005))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- There are 2463 customers who are holding the card for 36 months\n- There are 103 customers who are holding the catd for 56 months\n- 70 customers are holding for 13 months"},{"metadata":{"trusted":true,"_kg_hide-output":true,"_kg_hide-input":false},"cell_type":"code","source":"temp = pd.pivot_table(data = df, index = 'Card_Category', columns = ['Income_Category', 'Marital_Status', 'Education_Level', 'Gender'], \n                      values = ['Attrition_Flag'], aggfunc = 'mean', fill_value = 0)\ntemp.columns = temp.columns.ravel()\n#Drop columns with all 0\n#temp = temp.loc[:, temp.sum(axis = 0) != 0].T\ntemp = temp.T\ntemp.style.background_gradient(sns.light_palette('#2ecc71', as_cmap = True))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp.sum(axis = 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- The pivot table above gives a good insight into churning customers based on the card category by their income, marital status and their education level\n- The Blue card holders are ones which is churning more followed by Silver card holders\n- The churn is minimal in Platinum category"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"temp.loc[temp['Blue'] > 0.25].style.background_gradient(sns.light_palette('#2ecc71', as_cmap = True))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- The above gives the category where the mean churn is more than 0.25\n- Highest customer churn for Blue card holders is in the categories 80ùêæ‚àí120K Income, Unknown marital status with Post-Graduate education level and male\n- All the mean Attrition value equal to 1 is single cusotmer\n- It'll be interesting to select the customers(rows) based on these category groups"},{"metadata":{},"cell_type":"markdown","source":"- Let's create a dict with the index of temp as values"},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"categories = []\nfor each in temp.index.values:\n    #print(each)\n    categories.append('_'.join([each[1], each[2], each[3], each[4]]))\n#print(len(categories), categories[:10])\ncat_dict = {categories[i]: i for i, c in enumerate(categories)}\ncat_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_new = df.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df_new['new_cat'] = df_new['Income_Category'] + '_' + df_new['Marital_Status'] + '_' + df_new['Education_Level'] + '_' + df_new['Gender']\ndf_new.drop(['Income_Category', 'Marital_Status', 'Education_Level', 'Gender'], axis = 1, inplace = True)\ndf_new['new_cat'] = df_new['new_cat'].map(cat_dict)\ndf_new.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"pi_values = ['Customer_Age', 'Months_on_book', 'Total_Relationship_Count', 'Months_Inactive_12_mon', \n            'Credit_Limit', 'Total_Revolving_Bal', 'Contacts_Count_12_mon', 'Avg_Open_To_Buy', 'Total_Trans_Amt', \n            'Total_Trans_Ct', 'Avg_Utilization_Ratio', 'Dependent_count']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pivot1 = pd.pivot_table(data = df_new[df_new['Attrition_Flag'] == 1], index = 'new_cat', \n               values = pi_values, aggfunc = 'mean', fill_value = 0).T\n#pivot1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pivot0 = pd.pivot_table(data = df_new[df_new['Attrition_Flag'] == 0], index = 'new_cat', \n               values = pi_values, aggfunc = 'mean', fill_value = 0).T\n#pivot0.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Using amazing Plotly Express to plot interactive charts with pandas__"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"import plotly.express as px\n\ndef visualize_plotly(a, b, title):\n    t = pd.concat([a, b], axis = 1)\n    t.columns = ['Churn', 'NoChurn']\n    t['New Category'] = t.index\n    fig = px.line(t, x = 'New Category', y = ['Churn', 'NoChurn'], title = title, \n                 color_discrete_sequence = ['cyan', 'coral'])\n    fig.update_layout({'plot_bgcolor': 'white'})\n    fig.update_xaxes(showgrid = True, gridwidth = 1, gridcolor = 'floralwhite')\n    fig.update_yaxes(showgrid = True, gridwidth = 1, gridcolor = 'floralwhite')\n    fig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"for c in pivot1.index[:4]:\n    visualize_plotly(pivot1.loc[c, :], pivot0.loc[c, :], title = c)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Obeservations from Plotly Trendlines"},{"metadata":{},"cell_type":"markdown","source":"*__Avg_Open_To_Buy - Open to buy Credit Line__*\n- Both the Churn and No churn customers' trendline are almost the same for this feature\n\n*__Avg_Utilization_Ratio__*\n- Its clear that this feature follows a lower trendline for Churned customer when compared to the No churn cusotmers\n\n*__Contacts_Count_12_mon__*\n- The bank has contacted the churning customers more frequently than the no churn cusotmers\n- Maybe they would have seen the open to buy Credit Line customers' trend\n\n*__Credit_Limit__*\n- Not much difference between the two segments"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"for c in pivot1.index[4: 8]:\n    visualize_plotly(pivot1.loc[c, :], pivot0.loc[c, :], title = c)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*__Customer_Age__*\n- Customers' age doesn't play a part in churning accodring to the plot above\n\n*__Months_Inactive_12_mon__*\n- Customers who tend to churn were more inactive in the last 12 months than the customers who do not churn\n\n*__Months_on_book__*\n- On an average most of the customers who stay with the bank - no churn - are with then between 35 to 40 months"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"for c in pivot1.index[8:]:\n    visualize_plotly(pivot1.loc[c, :], pivot0.loc[c, :], title = c)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*__Total_Relationship_Count__*\n- There is a clear trend that customers who hold more products from the same bank stay with the bank while the customers holding fewer products churn\n\n*__Total_Revolving_Balance__*\n- Customers with lower revolving balance are churning more\n\n*__Total_Trans_Amt__*\n- Churning customers spend lesser than non churning customers\n\n*__Total_Trans_Ct__*\n- Customers who churn make fewer transactions using the bank's card than the customers stay with the bank"},{"metadata":{},"cell_type":"markdown","source":"# Task 01\n- Improve performance of predicting churned customers - recall need to be higher"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dropping CLIENTNUM\ndf.drop('CLIENTNUM', axis = 1, inplace = True)\nnum_cols.remove('CLIENTNUM')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Lets check the correlation between the Numerical Features__"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"corr1 = df[num_cols].corr(method = 'pearson')\ncorr2 = df[num_cols].corr(method = 'spearman')\n\nfig = plt.figure(figsize = (10, 8))\nmask = np.triu(np.ones_like(corr1, dtype = bool))\nsns.heatmap(corr1, mask = mask, annot = True, cmap = 'PiYG', vmin = -1, vmax = +1)\nplt.title('Pearson Correlation')\nplt.xticks(rotation = 50)\nplt.show()\n\nfig = plt.figure(figsize = (10, 8))\nmask = np.triu(np.ones_like(corr2, dtype = bool))\nsns.heatmap(corr2, mask = mask, annot = True, cmap = 'PiYG', vmin = -1, vmax = +1)\nplt.title('Spearman Correlation')\nplt.xticks(rotation = 50)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Obviously Total_Trans_Amt and Total_Amt_Chng_Q4_Q1 are highly correlated as they are interrelated, same for Total_Trans_Ct/Total_Ct_Chng_Q4_Q1"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# example of scatter plot - we pick pair having highest (Pearson) correlation\nsns.jointplot(data = df, x = 'Total_Trans_Amt', y = 'Total_Amt_Chng_Q4_Q1', hue = 'Attrition_Flag')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"sns.jointplot(data = df, x = 'Total_Trans_Ct', y = 'Total_Ct_Chng_Q4_Q1', hue = 'Attrition_Flag')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#High Negative Correlation\nsns.jointplot(data = df, x = 'Avg_Utilization_Ratio', y = 'Avg_Open_To_Buy', hue = 'Attrition_Flag')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Label Encode Categorical Features__"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"lbl = LabelEncoder()\n\nfor c in df[cat_cols]:\n    print(f\"Label Encoding Categorical Feature - {c.upper()}\")\n    df[c] = lbl.fit_transform(df[c])\nprint('Label Encoding done...')\ndf[cat_cols].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Standardize Numerical Features__"},{"metadata":{"trusted":true},"cell_type":"code","source":"std = StandardScaler()\n\ndf[num_cols] = std.fit_transform(df[num_cols])\nprint('Standardizing Numerical Features done...')\ndf[num_cols].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.drop('Attrition_Flag', axis = 1)\ny = df['Attrition_Flag'].copy()\n\n#Xtrain, Xvalid, ytrain, yvalid = train_test_split(X, y, stratify = y, random_state = 2021)\n#print(Xtrain.shape, ytrain.shape, Xvalid.shape, yvalid.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_confusion(mat):\n    plt.figure(figsize = (8, 4))\n    sns.heatmap(pd.DataFrame(mat), annot = True, annot_kws = {\"size\": 25}, cmap = 'PiYG', fmt = 'g')\n    plt.title('Confusion matrix', y = 1.1, fontsize = 22)\n    plt.ylabel('Actual', fontsize = 18)\n    plt.xlabel('Predicted', fontsize = 18)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_pos_samples = y.value_counts().values[1]\nnum_neg_samples = y.value_counts().values[0]\nnum_neg_samples / num_pos_samples","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\nimport xgboost as xgb\n\nxgb_params = {\n         'objective': 'binary:logistic',\n         'lambda': 0.0030282073258141168, \n         'alpha': 0.01563845128469084,\n         'colsample_bytree': 0.55,\n         'subsample': 0.7,\n         'learning_rate': 0.01,\n         'max_depth': 9,\n         'random_state': 2020, \n         'min_child_weight': 257,\n         'eval_metric': 'auc',\n         'seed': 2021,\n         'scale_pos_weight': num_neg_samples / num_pos_samples\n         }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_folds = 5\npreds_xg = []\nmean_recall = []\n\nskf = StratifiedKFold(n_splits = n_folds)\n\nfor i, (trn_idx, val_idx) in enumerate(skf.split(X, y)):\n    print(f\"Fold: {i + 1}\")\n    Xtrain, ytrain = X.iloc[trn_idx], y[trn_idx]\n    Xvalid, yvalid = X.iloc[val_idx], y[val_idx]\n    print(Xtrain.shape, ytrain.shape, Xvalid.shape, yvalid.shape)\n    \n    xg_train = xgb.DMatrix(Xtrain, label = ytrain)\n    xg_valid = xgb.DMatrix(Xvalid, label = yvalid)\n\n    xgboost_sim = xgb.train(xgb_params,\n                              xg_train,\n                              10000,\n                              verbose_eval = 200,\n                              evals = [(xg_train, 'train'), (xg_valid, 'valid')],\n                              early_stopping_rounds = 100)\n\n    valid_preds = xgboost_sim.predict(xg_valid)\n    print('XGBOOST ROC_AUC_SCORE: ', roc_auc_score(yvalid, valid_preds))\n    print('XGBOOST RECALL SCORE: ', recall_score(yvalid, valid_preds > 0.5, average = 'macro'))\n    mean_recall.append(recall_score(yvalid, valid_preds > 0.5, average = 'macro'))\n    conf_mat = confusion_matrix(yvalid, valid_preds > 0.5)\n    plot_confusion(conf_mat)\n    \n    preds_xg.append(valid_preds)\n    print()\nprint(f\"Mean Recall Score: {round(np.mean(mean_recall), 2)}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Managing Imbalanced Dataset\nThere are two ways to manage imbalanced dataset:\n\n- OverSampling\n- UnderSampling"},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler\nfrom imblearn.under_sampling import RandomUnderSampler\n\nfrom collections import Counter","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# OverSampling"},{"metadata":{},"cell_type":"markdown","source":"__SMOTE__"},{"metadata":{"trusted":true},"cell_type":"code","source":"n_folds = 5\npreds_xg = []\nmean_recall = []\nskf = StratifiedKFold(n_splits = n_folds)\n\nprint(f\"Original Dataset class count: {Counter(y)}\")\nprint('OverSampling...')\nsmote = SMOTE(random_state = 2021)\nX_sm, y_sm = smote.fit_resample(X, y)\nprint(X_sm.shape, y_sm.shape)\nprint(f\"OverSampled Dataset class count: {Counter(y_sm)}\")\n    \nfor i, (trn_idx, val_idx) in enumerate(skf.split(X_sm, y_sm)):\n    print(f\"Fold: {i + 1}\")\n    Xtrain, ytrain = X_sm.iloc[trn_idx], y_sm[trn_idx]\n    Xvalid, yvalid = X_sm.iloc[val_idx], y_sm[val_idx]\n    print(Xtrain.shape, ytrain.shape, Xvalid.shape, yvalid.shape)\n    #print(f\"Original Dataset class count: {Counter(ytrain)}\")\n    \n    \n    xg_train = xgb.DMatrix(Xtrain, label = ytrain)\n    xg_valid = xgb.DMatrix(Xvalid, label = yvalid)\n\n    xgboost = xgb.train(xgb_params,\n                              xg_train,\n                              10000,\n                              verbose_eval = 200,\n                              evals = [(xg_train, 'train'), (xg_valid, 'valid')],\n                              early_stopping_rounds = 100)\n\n    valid_preds = xgboost.predict(xg_valid)\n    print('XGBOOST ROC_AUC_SCORE - OverSampled: ', roc_auc_score(yvalid, valid_preds))\n    print('XGBOOST RECALL SCORE - OverSampled: ', recall_score(yvalid, valid_preds > 0.5))\n    mean_recall.append(recall_score(yvalid, valid_preds > 0.5))\n    conf_mat = confusion_matrix(yvalid, valid_preds > 0.5)\n    plot_confusion(conf_mat)\n    \n    preds_xg.append(valid_preds)\n    print()\nprint(f\"Mean Recall Score: {round(np.mean(mean_recall), 4)}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Importance Using SHAP"},{"metadata":{"trusted":true},"cell_type":"code","source":"import shap\n\nshap.initjs()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"explainer = shap.TreeExplainer(xgboost_sim)\nshap_values = explainer.shap_values(Xvalid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shap.summary_plot(shap_values, Xvalid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shap.force_plot(explainer.expected_value, shap_values[1], Xvalid.iloc[0, :])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Features in red color influence positively, i.e. drag the prediction value closer to 1, features in blue color - the opposite\n- Bigger Total_Trans_Ct, Total_Trans_Amt leads to prediction towards '0' - which we can see from the plotly plots for the same\n- Each arrow‚Äôs size represents the magnitude of the corresponding feature‚Äôs effect\n- The ‚Äúbase value‚Äù marks the model‚Äôs average prediction over the training set"},{"metadata":{"trusted":true},"cell_type":"code","source":"finish = time()\nprint(strftime(\"%H:%M:%S\", gmtime(finish - start)))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}