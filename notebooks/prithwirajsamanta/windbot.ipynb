{"cells":[{"metadata":{},"cell_type":"markdown","source":"This Notebook uses LSTM model to predict energy output for next hours","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from math import sqrt\nfrom numpy import concatenate\nfrom matplotlib import pyplot\nfrom pandas import read_csv\nfrom pandas import DataFrame\nfrom pandas import concat\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import mean_squared_error\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.models import load_model\nimport types\nimport os\nfrom contextlib import suppress","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert series to supervised learning\ndef series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n\tn_vars = 1 if type(data) is list else data.shape[1]\n\tdf = DataFrame(data)\n\tcols, names = list(), list()\n    \n\t# input sequence (t-n, ... t-1)\n\tfor i in range(n_in, 0, -1):\n\t\tcols.append(df.shift(i))\n\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n        \n\t# forecast sequence (t, t+1, ... t+n)\n\tfor i in range(0, n_out):\n\t\tcols.append(df.shift(-i))\n\t\tif i == 0:\n\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n\t\telse:\n\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n            \n\t# put it all together\n\tagg = concat(cols, axis=1)\n\tagg.columns = names\n    \n\t# drop rows with NaN values\n\tif dropnan:\n\t\tagg.dropna(inplace=True)\n\treturn agg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/wind-turbine-scada-dataset/T1.csv', header=0, index_col=0)\ncolumnsTitles=['LV ActivePower (kW)','Wind Speed (m/s)',\"Wind Direction (°)\",\"Theoretical_Power_Curve (KWh)\"]\ndf=df.reindex(columns=columnsTitles)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load dataset\ndf['LV ActivePower (kW)']=df['LV ActivePower (kW)'].div(5000)\ndf['Wind Speed (m/s)']=df['Wind Speed (m/s)'].div(30)\ndf['Theoretical_Power_Curve (KWh)']=df['Theoretical_Power_Curve (KWh)'].div(5000)\ndf['Wind Direction (°)']=df['Wind Direction (°)'].div(360)\ndataset = df\nvalues = dataset.values\n#print(values)\n\n# specify the number of lag and ahead hours\nn_hours = 24\nn_ahead = 1\nn_features = 4\n\n# integer encode direction\n#encoder = LabelEncoder()\n#values[:,n_features-1] = encoder.fit_transform(values[:,n_features-1])\n\n# ensure all data is float\nvalues = values.astype('float32')\n#print(df)\n\n# normalize features\n#scaler = MinMaxScaler(feature_range=(0, 1))\n#scaled = scaler.fit_transform(values)\n#print(scaled[0:30])\n\n# frame as supervised learning\nreframed = series_to_supervised(values, n_hours,n_ahead, 1)\n#print(reframed[0:24])\nprint(reframed.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# split into train and test sets\nvalues = reframed.values\nn_train_hours = (int)(len(dataset)*0.999)\ntrain = values[:n_train_hours, :]\ntest = values[n_train_hours:, :]\n\n#print(train)\n\n# split into input and outputs\nn_obs = n_hours * n_features\ntrain_X, train_y = train[:, :n_obs], train[:, -n_features]\ntest_X, test_y = test[:, :n_obs], test[:, -n_features]\nprint(train_X.shape, len(train_X), train_y.shape)\n\n#print(train_X)\n#print(train_y)\n\n# reshape input to be 3D [samples, timesteps, features]\ntrain_X = train_X.reshape((train_X.shape[0], n_hours, n_features))\ntest_X = test_X.reshape((test_X.shape[0], n_hours, n_features))\nprint(train_X.shape, train_y.shape, test_X.shape, test_y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(LSTM(5, input_shape=(train_X.shape[1], train_X.shape[2])))\nmodel.add(Dense(1))\nmodel.compile(loss='mae', optimizer='adam')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fit network\nhistory = model.fit(train_X, train_y, epochs=150, batch_size=24, validation_data=(test_X, test_y), verbose=2, shuffle=False)\nmodel.save(\"WindBot.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filename = 'WindBot'\n# Delete a duplicate file if exists.\nwith suppress(OSError):\n    os.remove(filename)\nmodel.save(filename+\".h5\",overwrite=True)\n\n#compress keras model\ntar_filename = filename + '.tgz'\ncmdstring = 'tar -zcvf ' + tar_filename + ' ' + filename+\".h5\"\nprint(cmdstring)\nos.system(cmdstring)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = load_model('WindBot.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot history\npyplot.plot(history.history['loss'], label='train')\npyplot.plot(history.history['val_loss'], label='test')\npyplot.legend()\npyplot.show()\n\n#Copying test data\ntest_C=test_X\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_X=test_C\n#yhat = model.predict(test_X)\n#test_X = test_X.reshape((test_X.shape[0], n_hours*n_features))\n#print(test_X)\n\n# invert scaling for forecast\n#inv_yhat = concatenate((yhat, test_X[:, -(n_features-1):]), axis=1)\n#inv_yhat = scaler.inverse_transform(inv_yhat)\n#inv_yhat = inv_yhat[:,0]\n\ninv_yhat=model.predict(test_X)\nfor i in range(len(inv_yhat)):\n    inv_yhat[i]=inv_yhat[i]*5000\n#print(inv_yhat)\n\n# invert scaling for actual\n#test_y = test_y.reshape((len(test_y), 1))\n#inv_y = concatenate((test_y, test_X[:, -(n_features-1):]), axis=1)\n#inv_y = scaler.inverse_transform(inv_y)\n#inv_y = inv_y[:,0]\n\ninv_y=test_y\nfor i in range(len(inv_y)):\n    inv_y[i]=inv_y[i]*5000\n#print(inv_y)\n\n# calculate RMSE\nrmse = sqrt(mean_squared_error(inv_y, inv_yhat))\nprint('Test RMSE: %.3f' % rmse)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot history\npyplot.plot(inv_yhat, label='predicted')\npyplot.plot(inv_y, label='true')\npyplot.legend()\npyplot.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}