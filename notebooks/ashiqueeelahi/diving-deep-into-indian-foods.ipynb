{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Let us import the libraries first**"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np;\nimport matplotlib.pyplot as plt;\nimport seaborn as sns;\nfrom sklearn.impute import SimpleImputer;\nfrom sklearn.compose import ColumnTransformer;\nfrom sklearn.pipeline import Pipeline;\nfrom sklearn.preprocessing import LabelEncoder;\nfrom sklearn.preprocessing import StandardScaler;\nfrom sklearn.preprocessing import MinMaxScaler;\nfrom sklearn.model_selection import train_test_split;\nfrom sklearn.linear_model import LinearRegression ;\nfrom sklearn.linear_model import Ridge, Lasso;\nfrom sklearn.metrics import mean_squared_error;\nfrom sklearn.metrics import r2_score;\nfrom sklearn.preprocessing import PolynomialFeatures;\nfrom sklearn.svm import SVR;\nfrom sklearn.svm import SVC;\nfrom sklearn.tree import DecisionTreeClassifier;\nfrom sklearn.ensemble import RandomForestClassifier;\nfrom sklearn.ensemble import RandomForestRegressor;\nfrom sklearn.neighbors import KNeighborsClassifier;\nfrom sklearn.naive_bayes import GaussianNB;\nimport pickle;","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Let us import the data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/indian-food-101/indian_food.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **How does the data look? Wanna Explore?**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head(30)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Hmm. Looks nice. Are there any null values? Let us check**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()/data.shape[0]*100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Haah!Very Few. We can easily drop them. It will not impact the datasets**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.dropna()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Nice. Let us look at our data again.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Wait! There are some -1 values. What to do? \n# \n# I guess we can replace them.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.replace(to_replace = '-1', method = 'ffill')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head(30)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **There are still some -1 values. But we just replaced them. Why they are still in our dataframe?\n# \n# Humm. Looks like we have only replaced the strings. We now need to replace the int values as well**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.replace(to_replace = -1, method = 'ffill')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head(30)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Now the data looks perfect. We can now start to visualize our data**"},{"metadata":{},"cell_type":"markdown","source":"# * **Let us start with the diet section**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['diet'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (16,9))\ndf_diet_type = data.diet.value_counts().reset_index()\nplt.pie(df_diet_type.diet, labels = df_diet_type['index'],autopct='%1.1f%%')\nplt.title(\"Vegetarian vs Non-Vegetarian recipes in dataset\")\nplt.show()\n\n#plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Haha HUge! Looks like everyone is becoming vegetarian these days. \n# \n# Next, let us explore the cuisine section**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['course'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (20,10))\n\ncourse = data.groupby('course').size().to_frame(name = \"count\").reset_index()\nsns.barplot(x = 'count', y='course', data = course )\n\nplt.title(\"Type of Course\")\nplt.ylabel(\"course\")\nplt.xlabel(\"Count\")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Great. People liking the main course pretty much. \n# \n# Let us have a look at the flavor section now**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['flavor_profile'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (16,9))\n\nflavor = data.groupby('flavor_profile').size().to_frame(name = \"count\").reset_index()\nsns.barplot(x = 'count', y='flavor_profile', data = flavor )\n#sub_index = np.arange(len(flavor))\n\nplt.title(\"Type of Flavors\")\nplt.ylabel(\"Flavor Profile\")\nplt.xlabel(\"Count\")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Yeah! Surely we like spices. Thats why, we really dont enjoy arab or traditional europian meals. ;) \n# \n# How about the regions?**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['region'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (16,9))\n\nregion = data.groupby('region').size().to_frame(name = \"count\").reset_index()\nsns.barplot(x = 'count', y='region', data = region )\n\nplt.title(\"Foods Belonging to Different Regions\")\nplt.ylabel(\"Region\")\nplt.xlabel(\"Count\")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **West is winning. :D\n# \n# How about the states? Which state seems to be more foody?**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['state'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (20,10))\n\nstate = data.groupby('state').size().to_frame(name = \"count\").reset_index()\nsns.barplot(x = 'count', y='state', data = state )\n\nplt.title(\"Foods Belonging to Different States\")\nplt.ylabel(\"State\")\nplt.xlabel(\"Count\")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Hah! PANJABIS! Balle balle!!\n# \n# We Indians spend an imense amount of time in cooking. But are all dishes like that? Let us check**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['cook_time'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (16,9))\n\ndf_cook_time = (data.prep_time + data.cook_time).to_frame('total_time').reset_index()\nplt.hist(df_cook_time['total_time'],np.arange(5,150,10), rwidth = 0.9)\n\nplt.title(\"Cooking time\")\nplt.ylabel(\"Number of recipes\")\nplt.xlabel(\"Time in minutes\")\n\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Nope. Thats not true. Surely some of our dishes take more time. But the average time limit is less than a hour. \n# \n# It was really nice exploruing the data. Specially when that is about this incredible region. Hope YOU enjoyed as well**"},{"metadata":{},"cell_type":"markdown","source":""}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}