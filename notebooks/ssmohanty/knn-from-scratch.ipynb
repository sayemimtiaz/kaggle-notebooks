{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport math\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-27T02:14:38.656809Z","iopub.execute_input":"2021-07-27T02:14:38.657461Z","iopub.status.idle":"2021-07-27T02:14:38.673415Z","shell.execute_reply.started":"2021-07-27T02:14:38.657408Z","shell.execute_reply":"2021-07-27T02:14:38.672271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Testing the major dimensionality reduction techniques on a new dataset - The malware classification dataset from the location :\nhttps://www.kaggle.com/saurabhshahane/classification-of-malwares","metadata":{}},{"cell_type":"code","source":"dataset = pd.read_csv(r\"../input/classification-of-malwares/ClaMP_Integrated-5184.csv\")\n\n#------------------------------------------------------------------------------------------------\n#Summary\nprint('Total Shape :',dataset.shape)\ndataset.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-27T02:10:02.098026Z","iopub.execute_input":"2021-07-27T02:10:02.098306Z","iopub.status.idle":"2021-07-27T02:10:02.198586Z","shell.execute_reply.started":"2021-07-27T02:10:02.098277Z","shell.execute_reply":"2021-07-27T02:10:02.197444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pre-Processing the data to enable one-hot encoding on the categorical columns","metadata":{}},{"cell_type":"code","source":"type_df = pd.DataFrame(dataset.dtypes).reset_index()\ntype_df.columns=['cols','type']\ntype_df[type_df['type']=='object']['cols'].unique()\n\n#------------------------------------------------------------------------------------\nprint('Total unique values in \"packer_type\":',dataset['packer_type'].nunique())\n#------------------------------------------------------------------------------------\n#Extracting the required levels only, based on value counts. \npacker_unique_df = pd.DataFrame(dataset['packer_type'].value_counts()).reset_index()\npacker_unique_df.columns = ['packer_type','unique_count']\ncatg = packer_unique_df[packer_unique_df['unique_count']>10]['packer_type'].unique()\n#------------------------------------------------------------------------------------\nencoded = pd.get_dummies(dataset['packer_type'])\nencoded = encoded[[col for col in list(encoded.columns) if col in catg]]\nprint('Shape of encode :',encoded.shape)\n#------------------------------------------------------------------------------------\n#Concatenating the encoded columns\nif set(catg).issubset(set(dataset.columns))==False: #Conditional automation \n    dataset = pd.concat([dataset,encoded],axis=1)\n    dataset.drop(columns='packer_type',inplace=True)\n\ndataset.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-27T02:10:02.200245Z","iopub.execute_input":"2021-07-27T02:10:02.200522Z","iopub.status.idle":"2021-07-27T02:10:02.271958Z","shell.execute_reply.started":"2021-07-27T02:10:02.200494Z","shell.execute_reply":"2021-07-27T02:10:02.270778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Separating the target column for our analysis (Since it is an dependent column in this use-case) and scaling the data (standard scaler)","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\n# Test Train Split for modelling purpose\nX = dataset.loc[:,[cols for cols in dataset.columns if ('class' not in cols)]] #Removing time since its a level column\ny = dataset.loc[:,[cols for cols in dataset.columns if 'class' in cols]]\n\n#----------------------------------------------------------------------------------------------------\n#Scaling the features\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\n\n#Splitting data into train-test\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33,random_state=100)\n\n#----------------------------------------------------------------------------------------------------\nprint('Total Shape of Train X:',X_train.shape)\nprint('Total Shape of Train Y:',y_train.shape)\nprint('Total Shape of Test X:',X_test.shape)\n\n#----------------------------------------------------------------------------------------------------\n\nX_arr = np.array(X_train)\nX_test_arr = np.array(X_test)\n\ny_arr = np.array(y_train).reshape(len(y_train),1)\ny_test_arr = np.array(y_test).reshape(len(y_test),1)\n\n#----------------------------------------------------------------------------------------------------\nprint(X_arr.shape)\nprint(X_test_arr.shape)\nprint(y_arr.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-27T02:10:02.274421Z","iopub.execute_input":"2021-07-27T02:10:02.275019Z","iopub.status.idle":"2021-07-27T02:10:03.454074Z","shell.execute_reply.started":"2021-07-27T02:10:02.274961Z","shell.execute_reply":"2021-07-27T02:10:03.453024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# KNN from scratch","metadata":{}},{"cell_type":"markdown","source":"## Utility UDF's regarding distance calculation","metadata":{}},{"cell_type":"code","source":"#distance calculation udf\ndef minkowski_(point_a,point_b,p=2):\n    \n    if p==1:\n        print('----> Manhattan')\n        dist = np.sum(abs(point_a-point_b))\n        print('Manual Distance :',dist)\n    elif p==2:\n        #print('----> Euclidean')\n        dist = np.sqrt(np.sum(np.square(point_a-point_b)))\n        #print('Manual Distance :',dist)\n        \n    return dist\n\n#------------------------------------------------------------------\n#Calculate distance from one point to all other points including itself\ndef distance_to_all(curr_vec,data,p_=2):\n\n    distance_list = []\n\n    for vec_idx in range(len(data)):\n        dist = minkowski_(point_a=curr_vec,point_b=data[vec_idx],p=p_)\n        distance_list.append(dist)\n\n    return distance_list","metadata":{"execution":{"iopub.status.busy":"2021-07-27T02:10:03.455495Z","iopub.execute_input":"2021-07-27T02:10:03.456114Z","iopub.status.idle":"2021-07-27T02:10:03.46411Z","shell.execute_reply.started":"2021-07-27T02:10:03.456062Z","shell.execute_reply":"2021-07-27T02:10:03.463267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## UDF for KNN operation","metadata":{}},{"cell_type":"code","source":"predictions = []\nprobabilities = []\n\ndef knn_model(data_x=X_arr,data_y=y_arr,k=10,curr_vec_=X_test_arr[34],mode='predict',threshold=0.5):\n\n    #print('#--------------------------------------------------------------------------------')\n    #Calculating distance of that point to every other point\n    distance_list = distance_to_all(curr_vec=curr_vec_,data=data_x,p_=2)\n    distance_list_reshaped = np.array(distance_list).reshape(len(distance_list),1)\n\n    #print('#--------------------------------------------------------------------------------')\n    #Creating a unified array for ease of indexing\n    array_final = data_x\n    array_final = np.append(array_final,data_y,axis=-1)\n    array_final = np.append(array_final,distance_list_reshaped,axis=-1) #Appending distances\n    \n    #Sorting the datapoints by the distance column\n    array_final_argsorted = array_final[array_final[:, -1].argsort()]\n\n    if mode=='train':\n\n        array_final_argsorted_top_k = array_final_argsorted[1:k+1,-2] #k+1 as the minimum distance is always 0 (with itself)\n        ratio_ = np.sum(array_final_argsorted_top_k)/k #Total density around the point\n\n        if ratio_>threshold:\n            predictions.append(1)\n        else:\n            predictions.append(0)\n            \n    elif mode=='predict':\n\n        array_final_argsorted_top_k = array_final_argsorted[0:k,-2] #Not k+1 since test data is not present in the training data (0 dist doesnt occur)\n        ratio_ = np.sum(array_final_argsorted_top_k)/k\n\n        if ratio_>threshold:\n            pred = 1\n        else:\n            pred = 0\n\n    return pred,ratio_    ","metadata":{"execution":{"iopub.status.busy":"2021-07-27T02:11:22.343321Z","iopub.execute_input":"2021-07-27T02:11:22.343651Z","iopub.status.idle":"2021-07-27T02:11:22.353432Z","shell.execute_reply.started":"2021-07-27T02:11:22.343618Z","shell.execute_reply":"2021-07-27T02:11:22.351997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Invoking the UDF for KNN for test data","metadata":{}},{"cell_type":"code","source":"predictions = [] #Initializing predictions tray for each test datapoint\nprobabilities = [] #Initializing prediction probability tray for each test datapoint\n\nfor idx in range(len(X_test)): #Iterating for datapoint in test data\n    #print('#-------------- ',idx,' --------------#')\n    pred,prob = knn_model(data_x=X_arr,data_y=y_arr,\n                          k=5,curr_vec_=X_test_arr[idx],\n                          mode='predict',threshold=0.5)\n    \n    predictions.append(pred) #Appending into the tray\n    probabilities.append(prob) #Appending into the tray\n    \n    \n#-----------------------------------------------\n#Evaluating the predictions from the KNN model\nscore = roc_auc_score(y_test_arr, predictions)\nprint('1. ROC AUC: %.3f' % score)\nprint('2. Accuracy :',accuracy_score(y_test_arr, predictions))\nprint('3. Classification Report -\\n',classification_report(y_test_arr, predictions))\nprint('4. Confusion Matrix - \\n',confusion_matrix(y_test_arr, predictions))","metadata":{"execution":{"iopub.status.busy":"2021-07-27T02:23:49.452446Z","iopub.execute_input":"2021-07-27T02:23:49.452915Z","iopub.status.idle":"2021-07-27T02:24:52.941969Z","shell.execute_reply.started":"2021-07-27T02:23:49.452879Z","shell.execute_reply":"2021-07-27T02:24:52.940282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Sklearn implementation for benchmarking","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier(n_neighbors=5)\nknn.fit(X_arr,y_arr)\nsklearn_preds = knn.predict(X_test_arr)\n\n#------------------------------------------------------------------------------------\nscore = roc_auc_score(y_test_arr, sklearn_preds)\nprint('1. ROC AUC: %.3f' % score)\nprint('2. Accuracy :',accuracy_score(y_test_arr, sklearn_preds))\nprint('3. Classification Report -\\n',classification_report(y_test_arr, sklearn_preds))\nprint('4. Confusion Matrix - \\n',confusion_matrix(y_test_arr, sklearn_preds))","metadata":{"execution":{"iopub.status.busy":"2021-07-27T02:15:19.065876Z","iopub.execute_input":"2021-07-27T02:15:19.066227Z","iopub.status.idle":"2021-07-27T02:15:19.335017Z","shell.execute_reply.started":"2021-07-27T02:15:19.066196Z","shell.execute_reply":"2021-07-27T02:15:19.33388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Insights : \n1. The manual implementation gives exact result as the sklearn implementation suggesting that the implementation is correct","metadata":{}},{"cell_type":"markdown","source":"# END","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}