{"cells":[{"metadata":{},"cell_type":"markdown","source":"## KEY NOTE\n\nThis notbook is complete guide to end to end machine learning problem from scratch. if you are beginner, it might hep you have an insight on how to start and how to approach a ML problem. Since the dataset is fairly simple it is very good to start your handson with.\n\nI followed the book by Aurelien Geron, The steps described by him are really detailed, so I decided to replicate it on my own and experiment with the concepts.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id='top'></a>\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\"  role=\"tab\" aria-controls=\"home\">Notebook Navigation</h3>\n\n[1. Project Skeleton](#1)   \n[2. Load the Data](#2)  \n[3. Take a Quick Look at Data Structures](#3)   \n[4. Create a Test Set](#4)    \n[5. Discover and Visualize Data to Gain Insights](#5)  \n&nbsp;&nbsp;&nbsp;&nbsp;[a. Visualizing Geographical Data](#5a)   \n&nbsp;&nbsp;&nbsp;&nbsp;[b. Looking for Correlations](#5b)       \n&nbsp;&nbsp;&nbsp;&nbsp;[c. Experimenting with Feature Combinations](#5c)     \n[6.Preparing Data for Machine Learning Algorithms](#6)     \n&nbsp;&nbsp;&nbsp;&nbsp;[a. Data Cleaning](#6a)     \n&nbsp;&nbsp;&nbsp;&nbsp;[b. Handling Text and Categorical Features](#6b)     \n&nbsp;&nbsp;&nbsp;&nbsp;[c. Column Transformers](#6c)     \n&nbsp;&nbsp;&nbsp;&nbsp;[d. Transformation Pipelines](#6d)     \n[7. Select and Train a Model](#7)     \n&nbsp;&nbsp;&nbsp;&nbsp;[a. Training and Evaluating on Training Set](#7a)     \n&nbsp;&nbsp;&nbsp;&nbsp;[b. Better Evaluation Using Cross Validation](#7b)     \n[8. Fine-Tune a Model](#8)  \n&nbsp;&nbsp;&nbsp;&nbsp;[a. Grid Search](#8a)     \n&nbsp;&nbsp;&nbsp;&nbsp;[b. Analyse the Best Models and Their Errors](#8b)       \n[9. Evaluate Your System on Test Set](#9)    \n[10. References](#10)   ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id=\"1\"></a>\n## 1. Project Skeleton\nBefore starting out any project, we must first plan our steps and have clarity on what type of problem we are tackling and what tools can be used and what cannot be used and why not?. This \"why not\" question will help you gain more insights on your ML journey. The following are key points I took into consideration.\n\nStaircase\n* What kind of ML problem statement is it? Try to define it\n* Understand the type of data?\n* Keep a test data aside for EDA\n* Relationships between various features, ie EDA \n* Try your intuition about the field: \n   * What can be important features that effect a house price? Bedrooms? Area? Population?\n* Data preprocessing: Building a pipeline for it\n* Applying models to predict\n* What must be the evaluation metric?\n* Evaluate the model on Test data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id=\"2\"></a>\n## 2. Load the Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# In book a function is defined to download data from Url and auto-extract it using tgz\n# but since we are using data directly from kaggle it is not required\n\nimport pandas as pd\nhousing = pd.read_csv(\"../input/california-housing-prices/housing.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"3\"></a>\n## 3. Take a Quick Look at Data Structures","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#housing = load_housing_data()\nhousing.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing[\"ocean_proximity\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing.describe() #all null values ignored","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#creating plots on dataset\n%matplotlib inline\nimport matplotlib.pyplot as plt\nhousing.hist(bins=50,figsize=(20,15))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"4\"></a>\n## 4. Create a Test Set","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nCreating shuffled testset with constant values in training and updated dataset values going to \ntest set in case dataset is updated, this done via hashlib\n\"\"\"\nimport hashlib\nimport numpy as np\n\ndef test_set_check(identifier,test_ratio,hash):\n    return hash(np.int64(identifier)).digest()[-1]<256*test_ratio\n    \ndef split_train_test(data,test_ratio,id_column,hash=hashlib.md5):\n    ids=data[id_column]\n    in_test_set=ids.apply(lambda id_:test_set_check(id_,test_ratio,hash))\n    return data.loc[~in_test_set],data.loc[in_test_set]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#combining latitude and longitude as new column id\n#housing_with_id[\"id\"]=housing[\"longitude\"]*1000+housing[\"latitude\"]\n#train_set1,test_set1 = split_train_test(housing_with_id,0.2,\"id\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#housing_with_id.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# or we can use sklearn function \n#from sklearn.model_selection import train_test_split\n#train_set,test_set = train_test_split(housing,test_size=0.2,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#understanding stratification\nhousing[\"median_income\"].hist(bins=40)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#creating hosusing income categories\nhousing[\"income_cat\"]=np.ceil(housing[\"median_income\"]/1.5)\nhousing[\"income_cat\"]=housing[\"income_cat\"].apply(lambda x: 5 if x>5 else x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing[\"income_cat\"].hist(bins=40)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#startified split\nfrom sklearn.model_selection import StratifiedShuffleSplit\n\nsplit= StratifiedShuffleSplit(n_splits=1,test_size=0.2,random_state=42)\nfor train_idx,test_idx in split.split(housing,housing[\"income_cat\"]):\n    strat_train_set=housing.loc[train_idx]\n    strat_test_set=housing.loc[test_idx]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dropping income category from test and train splits\na= (strat_train_set,strat_test_set)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in a:\n    i.drop([\"income_cat\"],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"5\"></a>\n## 5. Discover and Visualize Data to Gain Insights\n Do exploratory data analysis on test data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id=\"5a\"></a>\n### a. Visualizing Geographical Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data =strat_test_set.copy()\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# since there are latitude and longitudes, its good idea to have a scatter plot\n#set alpha =0.1 to clearly see dense points\ndata.plot(kind=\"scatter\",x=\"longitude\",y=\"latitude\",alpha=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#advanced scatter plot using median value of house\ndata.plot(kind=\"scatter\",x=\"longitude\",y=\"latitude\",alpha=0.4,\n         s=data[\"population\"]/100,label=\"population\",\n         c=\"median_house_value\",cmap=plt.get_cmap(\"jet\"),\n         colorbar=True)\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"5b\"></a>\n### b. Looking for Correlations","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate pearson's r coefficient\ncorr_matrix=data.corr()\ncorr_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_matrix[\"median_house_value\"].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#scatter matrix fom pandas\n\nfrom pandas.plotting import scatter_matrix\nattributes=[\"median_house_value\",\"median_income\",\"total_rooms\",\"housing_median_age\"]\nscatter_matrix(data[attributes],figsize=(12,8))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#exploring more on median income\ndata.plot(kind=\"scatter\",x=\"median_income\",y=\"median_house_value\",alpha=0.1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"5c\"></a>\n### c. Experimenting with Feature Combinations\nwe ll try to create new features that are more relevant","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"rooms_per_household\"]=data[\"total_rooms\"]/data[\"households\"]\ndata[\"bedrooms_per_room\"]=data[\"total_bedrooms\"]/data[\"total_rooms\"]\ndata[\"population_per_household\"]=data[\"population\"]/data[\"households\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets check co-relation matrix again\ncorr_matrix=data.corr()\ncorr_matrix[\"median_house_value\"].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"6\"></a>\n## 6. Preparing Data for Machine Learning Algorithms\n\nLets start by separating labels and predictors of our orignal train dataset into copies that we can use\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"housing=strat_train_set.drop(\"median_house_value\",axis=1)\nhousing_labels=strat_train_set[\"median_house_value\"].copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"6a\"></a>\n### a. Data Cleaning\nMissing values can be dealt in follwoing ways:\n1. Get rid of the corresponding values\n2. Get rid of whole features\n3. Set missing values to some value (zero, mean, median, etc)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# we will use SimpleImputer from sklearn.impute\nfrom sklearn.impute import SimpleImputer\nimputer=SimpleImputer(strategy=\"median\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# since imputer only works on numerical features we ll create a copy of data with only numerical features\nhousing_num=housing.drop(\"ocean_proximity\",axis=1)\nimputer.fit(housing_num)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# you can view these values\nimputer.statistics_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# use this imputer to transform\nX=imputer.transform(housing_num)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing_tr=pd.DataFrame(X,columns=housing_num.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing_tr.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"6b\"></a>\n### b. Handling Text and Categorical Features\nWe will handle the text feature \"ocean_proximity\" that we dropped earlier as it cannot be fed directly into any ML model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nencoder=LabelEncoder()\nhousing_cat=housing[\"ocean_proximity\"]\nhousing_cat_encoded=encoder.fit_transform(housing_cat)\nhousing_cat_encoded","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder.classes_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since classes are not ordinal, we will one-hot encode them","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\nencoder=OneHotEncoder()\nhousing_cat_1hot=encoder.fit_transform(housing_cat_encoded.reshape(-1,1))\nhousing_cat_1hot","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#converting the sparse matrix to array\nhousing_cat_1hot.toarray()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"6c\"></a>\n### c. Column Transformer\n\nFor regular transformation of columns as we did while experimention with features, we can define a column transformer","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.base import BaseEstimator,TransformerMixin\n\nrooms_ix,bedrooms_ix,population_ix,household_ix=3,4,5,6\n\nclass FeatureAdder(BaseEstimator, TransformerMixin):\n    def __init__(self,add_bedrooms_per_room=True):\n        self.add_bedrooms_per_room=add_bedrooms_per_room\n    def fit(self,X,y=None):\n        return self\n    def transform(self,X,y=None):\n        rooms_per_household=X[:,rooms_ix]/X[:,household_ix]\n        population_per_household=X[:,population_ix]/X[:,household_ix]\n        \n        if self.add_bedrooms_per_room:\n            bedrooms_per_room=X[:,bedrooms_ix]/X[:,rooms_ix]\n            return np.c_[X,rooms_per_household,population_per_household,bedrooms_per_room]\n        else:\n            return np.c_[X,rooms_per_household,population_per_household]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets instantiate our object\nadder= FeatureAdder(add_bedrooms_per_room=False)\nhousing_extra_features =adder.fit_transform(housing.values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"or we can use FunctionTransformer that easily defines above class based on your function","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import FunctionTransformer\n\nrooms_ix,bedrooms_ix,population_ix,household_ix=3,4,5,6\n\ndef extra_features(X,add_bedrooms_per_room=True):\n    rooms_per_household=X[:,rooms_ix]/X[:,household_ix]\n    population_per_household=X[:,population_ix]/X[:,household_ix]\n    if add_bedrooms_per_room:\n        bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n        return np.c_[X, rooms_per_household, population_per_household,\n                     bedrooms_per_room]\n    else:\n        return np.c_[X, rooms_per_household, population_per_household]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_adder =FunctionTransformer(extra_features,validate=False,\n                                  kw_args={\"add_bedrooms_per_room\":False})\nhousing_extra_features =feature_adder.fit_transform(housing.values)\n\nhousing_extra_feat = pd.DataFrame(\n    housing_extra_features,\n    columns=list(housing.columns)+[\"rooms_per_household\", \"population_per_household\"],\n    index=housing.index)\nhousing_extra_feat.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"6d\"></a>\n### d. Transformation Pipelines","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import Pipeline, FeatureUnion\nfrom sklearn.preprocessing import StandardScaler, LabelBinarizer\nfrom sklearn.compose import ColumnTransformer\n\nnum_attribs=list(housing_num)\ncat_attribs=[\"ocean_proximity\"]\n\nnum_pipeline=Pipeline([\n    (\"imputer\",SimpleImputer(strategy=\"median\")),\n    (\"feature_adder\",FeatureAdder()),\n    (\"std_scaler\",StandardScaler()),\n])\n\nfull_pipeline=ColumnTransformer([\n    (\"num\", num_pipeline, num_attribs),\n    (\"cat\", OneHotEncoder(), cat_attribs),\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing_prepared = full_pipeline.fit_transform(housing)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"7\"></a>\n## 7. Select and Train a Model","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id=\"7a\"></a>\n### a. Training and Evaluating on Training Set","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nlin_reg=LinearRegression()\nlin_reg.fit(housing_prepared,housing_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"some_data=housing.iloc[:5]\nsome_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing_labels.iloc[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"some_prepared_data = full_pipeline.transform(some_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lin_reg.predict(some_prepared_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#calculate mean squared error\nfrom sklearn.metrics import mean_squared_error\nhousing_predictions = lin_reg.predict(housing_prepared)\nlin_mse= mean_squared_error(housing_labels,housing_predictions)\nlin_rmse = np.sqrt(lin_mse)\nlin_rmse","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is underfitting model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# try another model\n\nfrom sklearn.tree import DecisionTreeRegressor\ntree_reg=DecisionTreeRegressor()\ntree_reg.fit(housing_prepared, housing_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing_predictions=tree_reg.predict(housing_prepared)\ntree_mse= mean_squared_error(housing_labels,housing_predictions)\ntree_rmse = np.sqrt(tree_mse)\ntree_rmse","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above model is highly overfitting, it recalls every value from the training set","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id=\"7b\"></a>\n### b. Better Evaluation Using Cross Validation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# using cross_val_score\n\nfrom sklearn.model_selection import cross_val_score\nscores=cross_val_score(tree_reg,housing_prepared,housing_labels,scoring=\"neg_mean_squared_error\",cv=10)\nrmse_scores=np.sqrt(-scores)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rmse_scores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets view all scores\ndef display_scores(scores):\n    print(\"Scores:\",scores)\n    print(\"Mean:\",scores.mean())\n    print(\"Standard Deviation:\",scores.std())\n\ndisplay_scores(rmse_scores)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lin_scores=cross_val_score(lin_reg,housing_prepared,housing_labels,scoring=\"neg_mean_squared_error\",cv=10)\nlin_rmse_scores=np.sqrt(-lin_scores)\ndisplay_scores(lin_rmse_scores)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# try with randomforest\nfrom sklearn.ensemble import RandomForestRegressor\nforest_reg = RandomForestRegressor()\nrf_scores=cross_val_score(forest_reg,housing_prepared,housing_labels,scoring=\"neg_mean_squared_error\",cv=5)\nrf_rmse_scores=np.sqrt(-rf_scores)\ndisplay_scores(rf_rmse_scores)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"8\"></a>\n## 8. Fine-Tune the Model","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id=\"8a\"></a>\n### a. Grid Search","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets use GridSearchCV for hyperparameter tuning\nfrom sklearn.model_selection import GridSearchCV\nparam_grid={\n    'n_estimators':[3,10,30],'max_features':[2,4,6,8],\n    'bootstrap':[False,True],'n_estimators':[3,10],'max_features':[2,3,4],\n}\n\nforest_reg=RandomForestRegressor()\ngrid_search=GridSearchCV(forest_reg,param_grid,cv=5,scoring=\"neg_mean_squared_error\")\ngrid_search.fit(housing_prepared,housing_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_search.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#getting the best model\ngrid_search.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#scores\ncvres=grid_search.cv_results_\nfor mean_score, params in zip(cvres[\"mean_test_score\"],cvres[\"params\"]):\n    print(np.sqrt(-mean_score), params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(grid_search.cv_results_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"8b\"></a>\n### b. Analyse the Best Models and Their Errors","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_importances = grid_search.best_estimator_.feature_importances_\nfeature_importances","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# display with feature names\nextra_features=[\"rooms_per_hhold\",\"population_per_hhold\",\"bedrooms_per_room\"]\ncat_encoder = full_pipeline.named_transformers_[\"cat\"] # calleing transformer named \"cat\" from full pipeline\ncat_one_hot_features = list(cat_encoder.categories_[0])\nfeatures = num_attribs + extra_features + cat_one_hot_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sorted(zip(feature_importances, features), reverse=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"9\"></a>\n## 9. Evaluate Your System on the Test Set","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"final_model= grid_search.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test= strat_test_set.drop(\"median_house_value\",axis=1)\ny_test= strat_test_set[\"median_house_value\"].copy()\n\nX_test_prepared = full_pipeline.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_predictions= final_model.predict(X_test_prepared)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_mse= mean_squared_error(y_test,final_predictions)\nfinal_rmse=np.sqrt(final_mse)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_rmse","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Thats the final Test Score","execution_count":null},{"metadata":{"trusted":false},"cell_type":"markdown","source":"<a id=\"10\"></a>\n## 10. References:\n\nLink to the book I followed: [Hands-On Machine Learning with Scikit-Learn and TensorFlow](https://www.amazon.in/Hands-Machine-Learning-Scikit-Learn-TensorFlow/dp/1491962291/ref=sr_1_1?dchild=1&keywords=handson+sklearn&qid=1599399632&sr=8-1) - *Aurélien Géron*\n    \nTop 5 Conceptual Books you might wanna see:\nhttps://www.kaggle.com/getting-started/171809\n    ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Do Upvote if you like :)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}