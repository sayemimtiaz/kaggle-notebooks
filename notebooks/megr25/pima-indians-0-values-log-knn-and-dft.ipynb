{"cells":[{"metadata":{},"cell_type":"markdown","source":"# 1.Introduction "},{"metadata":{},"cell_type":"markdown","source":"### In This Kernel I tried to fill those 0 values by using the correalation between variables, I also ask for some comment (doctor) to make sure about the relation between varaiable, these kernel is not that visual friendly because I had to find several intervals/ each columns , instead of using the mean / columns , I checked several kernel with 90% accurancy but i got 61 max, anyway it was a great challenge because it improved my pandas and numpy skills. Feel free to provide some feedback or a better way to find or replace the values "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#Basic library\nimport numpy as np \nimport pandas as pd \nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n\n#visualization \nimport seaborn as sns\nimport matplotlib.pyplot as plt \n%matplotlib inline \n\nsns.set_style(\"whitegrid\")\n\ndf= pd.read_csv('../input/pima-indians-diabetes-database/diabetes.csv')\ndf.tail(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1.1. Conclusion "},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import display\nfrom PIL import Image\npath=\"../input/conclusion/conclusion.png\"\ndisplay(Image.open(path))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    **From *LEFT* to *RIGHT***  BEST = \"Logistical Regression\" - Random Forest - KNN cluster"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()[1:6]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Scrub data** (filtering, extracting , replacing , handle missing values)"},{"metadata":{},"cell_type":"markdown","source":"### When I was analyzing this data frame I realized that there were many 0 values,then i was checking others kenerls and found out that many people was asking if theses 0 were set in purpose including myself,because I couldnt find any guidance , I decided to fill them out. \n1. I decided to fill out those value that has some kind of relation between variables\n2. I wrote a Funcion to easily chech how many Zeros are lefft to keep tracking "},{"metadata":{"trusted":true},"cell_type":"code","source":"def finding_zeros (frame):\n    columns = frame.columns[:8]\n    for i in columns:\n        zeros = len(frame.loc[frame[i]==0])\n        print(f'The numbers of 0 values in {i} = {zeros}')\n        \nfinding_zeros(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Finding Missing Values\nNAN_value = (df.isnull().sum() / len(df)) * 100\nMissing = NAN_value[NAN_value==0].index.sort_values(ascending=False)\nMissing_data = pd.DataFrame({'Missing Ratio' :NAN_value})\nMissing_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# \"--------  Section 2 ----------\"\n"},{"metadata":{},"cell_type":"markdown","source":"# 3. FINDING MISSING VALUES"},{"metadata":{},"cell_type":"markdown","source":"## In this section I want to drop all those rows which as 0 Values in all the columns\n1. Because later I want to find some relation between variable but 0 values might affect the final result\n2. I realized I can do this with dropna.(tresh=#), but I will have to create a new Dataframe and applya pd.join\n3. I check other forums and many user mentioned the highest accurancy was 60 % so I thought that the missing values might influence the final result "},{"metadata":{"trusted":true},"cell_type":"code","source":"def finding_zeros (frame):\n    columns = frame.columns[:8]\n    for i in columns:\n        zeros = len(frame.loc[frame[i]==0])\n        print(f'The numbers of 0 values in {i} = {zeros}')\n        \n# Let's Find all those Cells that have 0 Values\ncond1= df[(df['Insulin']==0) & (df['SkinThickness']==0) & (df['Pregnancies']==0) & (df['BloodPressure']==0) & (df['BMI']==0)].index\ncond2 = df[(df['Insulin']==0) & (df['SkinThickness']==0) & (df['Pregnancies']==0) & (df['BloodPressure']==0)].index\nZeros_values = cond2.append(cond1) \ndf.drop(Zeros_values,inplace=True)\n\nfinding_zeros(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.1. Finding the Relation Between Variable to fill out values 0\n1. By using a heatmap, I intended to find a relation between variable (Glucose-Skinthickness-BMI-Insulin), later I will use the relation with stronger coorelation to find the missing values\n2. Instead of using the group mean or Interpolate, I will sort the value by ranks I.e Find all People with Glucose btwn A-B, then extract the mean and use this value to fill the missing one "},{"metadata":{"trusted":true},"cell_type":"code","source":"f,ax = plt.subplots(figsize=(15,10))\nmask = np.triu(df.corr())\nsns.heatmap(df.corr(), annot=True, mask=mask,ax=ax,cmap='viridis')\nbottom,top = ax.get_ylim()\nax.set_ylim(bottom+ 0.5, top - 0.5)\nprint(\"variable relationship\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Conclusion:** Glucose -  Insulin , Skinthickness - BMI"},{"metadata":{},"cell_type":"markdown","source":"# \"--------  Section 3 ----------\""},{"metadata":{},"cell_type":"markdown","source":"## 4. Finding Insuline Values\n\n1.  Isuline has 364 \"0\" so I will try to fill them according to Glucose and Skinthickness, but first I will create some graph to have a general view of the data Behav.\n2.  Based on the Graph , We can notice that Insuline - Glucose has a better reationship \"it might seemed a linear regresion\" , the higher A is , B is as well,(please feel free to let any comment on this)\n3. Because Glucose is gonna be my parameter I have to create some Interval to limite the values (I.e People who has glucose btwn A and B and then Extract the mean)"},{"metadata":{"trusted":true},"cell_type":"code","source":"f,(ax1,ax2,ax3) =plt.subplots(1,3,figsize=(20,5))\ny='Insulin'\nsns.regplot(y=y,x='Glucose',data=df,order = 2,ax=ax1)\nsns.scatterplot(y=y,x='SkinThickness',data=df , ax=ax2,hue='Outcome')\nsns.boxplot(df.Glucose,ax=ax3)\nprint(\"This shows that the Higher Glucose. Higher Insuline\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Based on the Graph there is a better relation btwn Insulin-Glucose, so now I will fill them segmented by interval = 5"},{"metadata":{},"cell_type":"markdown","source":"### 4.1. Finding Mean of Insulin"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Defining Intervals\nlower = np.arange(26,236,5) #ax=ax Glucose we can see the min 20 , max 200\nupper= np.arange(30,205,5)\n\n#Finding the Insuline based on the Glucose/segmented \ndef find_insuline (name,down,top):\n    result = df.loc[(df['Insulin']>0)&(df['Glucose']>=down)&(df['Glucose']<=top)]['Insulin'].mean()\n    result=np.round(result)\n    Value.append(result)\n    #print(f'the Mean of {name} in range {down}, {top} is :{result}')  \n    \n#Insuline Mean value  \nValue= []\nfor i,j in zip(lower,upper):\n    find_insuline(\"Insulin\",i,j)\n    \nValue[1:9]  # <--- Here we have a lot of value but this way is more visualy friendly","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### The following Interval has Nan values so they will remain with 0 values \n1. The Mean of Insulin in range 31, 35 is :nan\n2. The Mean of Insulin in range 36, 40 is :nan\n3. The Mean of Insulin in range 41, 45 is :nan\n4. The Mean of Insulin in range 46, 50 is :nan\n5. The Mean of Insulin in range 51, 55 is :nan\n\n###### The Interval from 61,65 has nan value, but I can interpolate the value from rank 56-60 and 66-70"},{"metadata":{},"cell_type":"markdown","source":"### 4.2. Finding Index of Insulin == 0"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Finding Insulines zero value (based on gluose) _index by range\ndef find_insuline_index (name,down,top):\n    Index= df[(df['Insulin']==0) & (df['Glucose']>=down) & (df['Glucose']<=top)].index.values\n    Indexes.append(Index)\n    #print(f'the index in range {down}, {top} is :{Index}')\n    \n#Index\nIndexes =[]\nfor i , j in zip(lower,upper):\n    find_insuline_index(\"Index\",i,j)   \n\nIndexes[10:13] #It will show all the indexes with Insulin == 0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4.3. Replacing Values "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Total\nfor i,j in zip (np.arange(0,36,1),Value):\n    df.loc[Indexes[i],\"Insulin\"]=j\n# Values replace nan for 0    \nfor i in np.arange(0,4,1):\n    df.loc[Indexes[i],\"Insulin\"]=0\n#Interval from 61,65 with 42   \ndf.loc[Indexes[7],\"Insulin\"]=42\n\nfinding_zeros(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# \"--------  Section 4 ----------\""},{"metadata":{},"cell_type":"markdown","source":"## * 5. Finding Skin-Thickness*"},{"metadata":{"trusted":true},"cell_type":"code","source":"f,(ax1,ax2,ax3) =plt.subplots(1,3,figsize=(20,5))\ny='SkinThickness'\nsns.scatterplot(y=y,x='BMI',data=df,ax=ax1)\nsns.scatterplot(y=y,x='Glucose',data=df , ax=ax2,hue='Outcome')\nsns.boxplot(df.BMI,ax=ax3)\nprint(\"This shows that the greater BMI ,the greater SkinThickness (it maskes sense)\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 5.1. Creating Intervals\n### 5.2. Finding SlkinThickness Values (mean)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# I wont delete the oulier(except zero) because it is not wrong data, according to the Paper they are all girls 21>Age years old\ni_skin = np.arange(15,70,5)\nj_skin = np.arange(20,75,5)\n\n#Finding Value based on BMI\ndef finding_skin (name,down,top):\n    result = df.loc[(df['SkinThickness']>0)&(df['BMI']>=down)&(df['BMI']<=top)]['SkinThickness'].mean()\n    result=np.round(result,2)\n    Skin_values.append(result)\n    #print(f'the Mean of {name} in range {down}, {top} is :{result}')\n    \nSkin_values =[]\nfor i, j in zip (i_skin,j_skin):\n    finding_skin(\"Thickness\",i,j)\n    \nSkin_values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 5.3. Finding Skin-Thickness Index\n    \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def finding_skin_index (name,down,top):\n    Index = df.loc[(df['SkinThickness']==0)&(df['BMI']>=float(down))&(df['BMI']<=float(top))]['SkinThickness'].index.values\n    Skin_Index.append(Index)\n    #print(f'the index in range {down}, {top} is :{Index}')\n    \nSkin_Index = []\nfor i, j in zip (i_skin,j_skin):\n    finding_skin_index(\"Thickness\",i,j)\n    \nSkin_Index[0:2]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 5.4. Replacing Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"#replacing Values    \nfor i,j in zip (np.arange(0,10,1),j_skin):\n    df.loc[Skin_Index[i],\"SkinThickness\"]=j\n    \nfinding_zeros(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# \"--------  Section 5 ----------\""},{"metadata":{},"cell_type":"markdown","source":"## 6. Variable related with 0 Values  \n#### 6.1. Skinth Thickness ~ BMI"},{"metadata":{"trusted":true},"cell_type":"code","source":"SKIN_BMI_ZERO= df[(df['SkinThickness']==0)&(df['BMI']==0)]\nSKIN_BMI_ZERO","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 6.2.Glucose ~ Insulin"},{"metadata":{"trusted":true},"cell_type":"code","source":"BLOOD_INSULINE_ZERO= df[(df['Glucose']==0)&(df['Insulin']==0)]\nBLOOD_INSULINE_ZERO","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 6.3. Dropping Values\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Index\nBLOOD_INSULINE_ZERO=df[(df['Glucose']==0)&(df['Insulin']==0)].index.values\nSKIN_BMI_ZERO= df[(df['SkinThickness']==0)&(df['BMI']==0)].index.values\n\n#Droping VAlues\ndf.drop(BLOOD_INSULINE_ZERO, inplace=True)\ndf.drop(SKIN_BMI_ZERO ,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 7. Blood Pressure"},{"metadata":{"trusted":true},"cell_type":"code","source":"f,(ax1,ax2) =plt.subplots(1,2,figsize=(20,5))\nsns.scatterplot(x='BloodPressure',y='BMI',data=df, ax=ax1)\nsns.scatterplot(x='Age',y='BloodPressure',data=df, ax=ax2) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I can apply the same methodology to 'bloodpresurre' but after consulting with doctor (Friend of mine) He claims that blood pressure con not be associate with age , because it varies according several factors and that are not showed in the Data "},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(df[df['BloodPressure']==0].index.values,inplace=True)\n#Finding Missing Values\nNAN_value = (df.isnull().sum() / len(df)) * 100\nMissing = NAN_value[NAN_value==0].index.sort_values(ascending=False)\nMissing_data = pd.DataFrame({'Missing Ratio' :NAN_value})\nMissing_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# \"--------  Section 6 ----------\""},{"metadata":{},"cell_type":"markdown","source":"## 8. Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"def boxplot (frame1,frame2,frame3):\n    f,(ax1,ax2,ax3)=plt.subplots(1,3,figsize=(20,5))\n    sns.boxplot(frame1,ax=ax1)\n    sns.boxplot(frame2,ax=ax2)\n    sns.boxplot(frame3,ax=ax3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"boxplot(df.Pregnancies,df.Glucose,df.BloodPressure)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"boxplot(df.SkinThickness,df.Insulin,df.BMI)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"boxplot(df.DiabetesPedigreeFunction,df.Age,df.Outcome)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### **We can easealy notice that there are so many outliers**"},{"metadata":{},"cell_type":"markdown","source":"# \"--------  Section 7 ----------\""},{"metadata":{},"cell_type":"markdown","source":"## 9. Outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"preg = df.loc[df['Pregnancies']>=15]['Pregnancies'].count()\nglu = df.loc[df['Glucose']<40]['Glucose'].count()\nblood_1 =df[df['BloodPressure']<40]['BloodPressure'].count() \nblood_2 = df[df['BloodPressure']>100]['BloodPressure'].count()\nblood = blood_1 + blood_2\nskin = df[df['SkinThickness']>55]['SkinThickness'].count()\ninsu =df[df['Insulin']>380]['Insulin'].count()\nbmi = df[df['BMI']>50]['BMI'].count()\ndia = df[df['DiabetesPedigreeFunction']>1.2]['DiabetesPedigreeFunction'].count()\nage= df[df['Age']>63]['Age'].count()\noutliers = [preg,glu,blood,skin,insu,bmi,dia,age]\nOutliers = pd.DataFrame(data=outliers, index = df.columns[0:8], columns=['Outliers'])\nOutliers","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dropping Outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"preg_i = df.loc[df['Pregnancies']>=15]['Pregnancies'].index.values\nglu_i = df.loc[df['Glucose']<40]['Glucose'].index.values\nblood_1_i =df[df['BloodPressure']<40]['BloodPressure'].index.values \nblood_2_i= df[df['BloodPressure']>100]['BloodPressure'].index.values\nskin = df[df['SkinThickness']>55]['SkinThickness'].index.values\ninsu =df[df['Insulin']>380]['Insulin'].index.values\nbmi = df[df['BMI']>50]['BMI'].index.values\ndia = df[df['DiabetesPedigreeFunction']>1.2]['DiabetesPedigreeFunction'].index.values\nage= df[df['Age']>63]['Age'].index.values\n\nind_out = [preg_i,glu_i,blood_1_i,blood_2_i,skin,insu,bmi,dia,age]\nfor i in ind_out:\n    df_out= df.drop(i)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# \"--------  Section 8 ----------\""},{"metadata":{},"cell_type":"markdown","source":"## 10. Applying Machine Learning \n1. ##### Splitting Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix,classification_report,f1_score\n\nX=df_out.drop('Outcome',axis=1)\ny=df_out['Outcome']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=101)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 2. Applying Random Forest Tree"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nRFC = RandomForestClassifier(n_estimators=100)\nRFC_model =RFC.fit(X_train,y_train)\ny_pred_RFC= RFC.predict(X_test)\ny_pred_RFC\n\nprint(classification_report(y_test,y_pred_RFC))\nRFC_cm =confusion_matrix(y_test,y_pred_RFC)\nprint(f1_score(y_test,y_pred_RFC))\n#confusion_matrix(y_pred_RFC, y_test)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### 3. Applying Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nES=StandardScaler()\nES=ES.fit_transform(df_out.drop('Outcome',axis=1))\ndata= pd.DataFrame(ES , columns= df.columns[:-1])\ndata.head(4) # data_p = Data already Processed\n\nX_data=data\ny_data=df_out['Outcome']\n\nX_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.33, random_state=101)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlog=LogisticRegression()\nlog=log.fit(X_train,y_train)\ny_pred_log = log.predict(X_test)\n\nlog_m = confusion_matrix(y_test,y_pred_log )\n                         \nprint(classification_report(y_test,y_pred_log))\n#print(confusion_matrix(y_test,y_pred_log))\nprint(f1_score(y_test,y_pred_log))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### 4. Applying KNN "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\nError_Rate = []\nfor i in range (1,50):\n    \n    KNN_Error = KNeighborsClassifier(n_neighbors=i)\n    KNN_Error.fit(X_train,y_train)\n    pred_i = KNN_Error.predict(X_test)\n    Error_Rate.append(np.mean(pred_i != y_test))\n    \nplt.figure(figsize=(10,6))\nplt.plot(range(1,50), Error_Rate , color = 'blue', linestyle = 'dashed', marker = 'o')\nplt.title('Error rate vs K value')\nprint( \" K=3 is the most accurate rate because the error is closest to 0 \")    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"KNN=KNeighborsClassifier(n_neighbors=3)\nKNN=KNN.fit(X_train,y_train)\ny_pred_KNN= KNN.predict(X_test)\n\nKNN_cm =confusion_matrix(y_test,y_pred_KNN)\nprint(classification_report(y_test,y_pred_KNN))\n#print(confusion_matrix(y_test,y_pred_KNN))\nf1_score(y_test,y_pred_KNN)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f,(ax1,ax2,ax3) = plt.subplots(1,3,figsize=(20,5))\nmodel= [log_m,RFC_cm,KNN_cm]\naxes= [ax1,ax2,ax3]\n\nfor i,j in zip (model,axes):\n    group_names = ['True Neg','False Pos','False Neg','True Pos']\n        \n    group_counts = ['{0:0.0f}'.format(value) for value in\n                i.flatten()]\n        \n    group_percentages = ['{0:.2%}'.format(value) for value in\n                     i.flatten()/np.sum(i)]\n        \n    labels = [f'{v1}\\n{v2}\\n{v3}' for v1, v2, v3 in\n     zip(group_names,group_counts,group_percentages)]\n    labels = np.asarray(labels).reshape(2,2)\n        \n    ax =sns.heatmap(i, annot=labels, fmt='', cmap='plasma',ax=j)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"                                             **From *LEFT* to *RIGHT***  Logistical Regression - Random Forest - KNN cluster"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}