{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\nimport pandas as pd \nfrom collections import defaultdict\nfrom itertools import combinations\n\n\n#import csv\ntrump_insults = pd.read_csv(\"../input/all-trumps-twitter-insults-20152021/trump_insult_tweets_2014_to_2021.csv\")\n\n#create a list withing a list, where the inner-list is a tweet with individual words as items and the outer-list has each tweet as an item\nmaster_list = []\ninsult_list = []\nfor tweet in trump_insults.tweet:\n    insult_list.append(tweet)\nfor tweet in insult_list:\n    word_list = list(tweet.split(\" \"))\n    master_list.append(word_list)\n\n#show how first five tweets in the master_list are structured\nprint(master_list[:5])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We need to create a list of common words that we want to exclude from our pairs. To create this list, I ran the program with a high threshold and a min count, then I added words I felt had no significance (a, the, or, and) added them to this list to be excluded when I excecute the update_pair_counts function."},{"metadata":{"trusted":true},"cell_type":"code","source":"unsig_words =['in','and', '-', 'are', 'all', 'the', 'they', 'is', 'a', 'of', 'his', 'to', 'The', 'just', 'who', 'but', 'by', 'has', 'in', 'not',\n             'their','will', 'that', '&', 'was','been', 'have', 'than', 'would', 'should', 'be','said', 'If', 'would', 'him', 'for', 'did', 'I', 'my', 'he',\n              'He', 'on'] ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Define functions to make dictionaries of {word_pairs : count_of_word_pairs} and {word : occurence of word in item} for each tweet"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#write function to count n of times a specific set of words are together\ndef update_pair_counts (pair_counts, itemset):\n    assert type (pair_counts) is defaultdict\n\n    for a,b in combinations(itemset, 2):\n        pair_counts[a,b] +=1\n        pair_counts[b,a] +=1\n        \n#write a function to count n of times a word is used in all of the tweets\ndef update_item_counts(item_counts, itemset):\n    assert type(item_counts) is defaultdict\n    \n    for a in itemset:\n        item_counts[a] += 1\n        \n#write a function to filter rules by confidence\ndef filter_rules_by_confidence (pair_counts, item_counts, threshold):\n    conf_rules = {} \n    for (a,b) in pair_counts:\n        assert a in item_counts\n        if a in unsig_words or b in unsig_words:\n            continue\n        conf_ab = pair_counts[(a, b)]/ item_counts[a]\n        if conf_ab >= threshold:\n            conf_rules[(a,b)] = conf_ab\n    return conf_rules","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Apply functions to master_list to generate confident word pairing rules"},{"metadata":{"trusted":true},"cell_type":"code","source":"#set confidence filter\nconf_threshold = 0.50\n\n#define default dictionaries for the functions below\npair_counts = defaultdict(int)\nitem_counts = defaultdict(int)\n\nfor itemsets in master_list:\n    update_pair_counts(pair_counts, itemsets)\n    update_item_counts(item_counts, itemsets)\ntweet_word_rules = filter_rules_by_confidence(pair_counts, item_counts, conf_threshold)\n\n#if we don't also filter by a minimum count of the rule occuring, then we'll get word-pairs that are always found together but may only be seen once or twice\nhigh_freq_list = []\nmin_count = 150\n\nfor rule in tweet_word_rules.items():\n    if item_counts[rule[0][0]] >= min_count:\n        high_freq_list.append(rule)\n\n    \n\nhigh_freq_rules = dict(high_freq_list)\nprint('The function created',len(high_freq_rules),'rules with a confidence of', conf_threshold,'or higher and an occurrence requirement of', str(min_count)+'.')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Pretty print the code with the functions below."},{"metadata":{"trusted":true},"cell_type":"code","source":"def gen_rule_str(a, b, val=None, val_fmt='{:.2f}', sep=\" = \"):\n    text = \"{} => {}\".format(a, b)\n    if val:\n        text = \"confidence(\" + text + \")\"\n        text += sep + val_fmt.format(val)\n    return text\n\ndef print_rules(rules):\n    if type(rules) is dict or type(rules) is defaultdict:\n        from operator import itemgetter\n        ordered_rules = sorted(rules.items(), key=itemgetter(1), reverse=True)\n    else: # Assume rules is iterable\n        ordered_rules = [((a, b), None) for a, b in rules]\n    for (a, b), conf_ab in ordered_rules:\n        print(gen_rule_str(a, b, conf_ab))\n\n        \nprint_rules(high_freq_rules)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The variables to play with in this are the insiginifcant words list, the minimum pair count, and the confidence threshold. The program generally returns two proper nouns mentioned in the same tweet, as you can see. Using the insignificant list can definitely skew the results. If you want more colorful pairings, just turn the minimum count down to 10 or so."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}