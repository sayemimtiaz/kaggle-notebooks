{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"from datetime import datetime\ndeadline = datetime.strptime('2020-04-16 23:59:00','%Y-%m-%d %H:%M:%S')\nprint(deadline)\nprint(datetime.now())\nprint(deadline - datetime.now(), 'hours')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# imports\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom scipy import stats\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import interpolate\nimport json\nimport requests\nimport io\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom scipy.stats import lognorm\nfrom scipy.optimize import curve_fit\nimport string\nfrom scipy.integrate import quad\n\nfrom tqdm import tqdm\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import PolynomialFeatures, StandardScaler\nfrom sklearn.linear_model import SGDRegressor, LinearRegression, Lasso, Ridge, LogisticRegression\nfrom sklearn.base import clone\nfrom sklearn.pipeline import Pipeline, make_pipeline\nfrom sklearn.preprocessing import LabelEncoder \n\nfrom wordcloud import WordCloud\n\n# module settings\npd.set_option('display.max_colwidth', -1)\npd.set_option('display.max_rows', 1000)\nplt.rcParams['figure.figsize'] = [15, 8]\n\n# https://images.plot.ly/plotly-documentation/images/python_cheat_sheet.pdf\n# https://www.apsnet.org/edcenter/disimpactmngmnt/topc/EpidemiologyTemporal/Pages/ModellingProgress.aspx\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[CORD-19 Challenge](https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge/tasks?taskId=558)\n\n# What do we know about COVID-19 risk factors? What have we learned from epidemiological studies?\n\nSpecifically, we want to know what the literature reports about:\n\n* Data on potential risks factors\n* Smoking, pre-existing pulmonary disease\n* Co-infections (determine whether co-existing respiratory/viral infections make the virus more transmissible or virulent) and other co-morbidities\n* Neonates and pregnant women\n* Socio-economic and behavioral factors to understand the economic impact of the virus and whether there were differences.\n* Transmission dynamics of the virus, including the basic reproductive number, incubation period, serial interval, modes of transmission and environmental factors\n* Severity of disease, including risk of fatality among symptomatic hospitalized patients, and high-risk patient groups\n* Susceptibility of populations\n* Public health mitigation measures that could be effective for control\n\n# Evaluation\nSubmissions will be scored using the following grading rubric:\n\nAccuracy (5 points)\n* Did the participant accomplish the task?\n* Did the participant discuss the pros and cons of their approach?\n\nDocumentation (5 points)\n* Is the methodology well documented?\n* Is the code easy to read and reuse?\n\nPresentation (5 points)\n* Did the participant communicate their findings in an effective manner?\n* Did the participant make effective use of data visualizations?"},{"metadata":{},"cell_type":"markdown","source":"# Who are the most vulnerable?\n\n* *with rantes -28 cg and gg genotypes had a 3.28-fold (95%ci:2.32-4.64) and 3.06-fold (95%ci:1.47-6.39) increased risk of developing sars respectively (p < 0.0001).*  (source: antivirals for influenza-like illness?)\n* *presence in the room during fiberoptic intubation (or = 2.79, p = .004) or ecg (or = 3.52, p = .002), unprotected eye contact with secretions (or = 7.34, p = .001), patient apache ii score $20 (or = 17.05, p = .009) and patient pa0 2 /fi0 2 ratio #59 (or = 8.65, p = .001) were associated with increased risk of transmission of sars-cov.* (source: systematic review extreme water-related weather events and waterborne disease) \n* *groups seen as at 'high risk' of infection included the immune compromised (mentioned by 87% respondents), pig farmers (70%), elderly (57%), prostitutes/highly sexually active (53%), and the homeless (53%).* (source: development of a smartphone-based rapid dual fluorescent diagnostic system for the simultaneous detection of influenza a and h5 subtype in avian influenza a-infected patients)\n* [Males (80+ years old) are the most at risk of dying from COVID-19](https://www.kaggle.com/bitsnpieces/covid19-risk-factors/notebook#Males-(80+-years-old)-are-the-most-at-risk-of-dying-from-COVID-19)\n"},{"metadata":{},"cell_type":"markdown","source":"# Literature search\n\nThe literature search is conducted from the CORD-19 Research Challenge dataset. The information is therefore limited to only what is available in the dataset.\n\nThe method that I'll be using includes a simple bag of words overlap to fetch relevant documents. The documents retrieved will be based on which keywords are used. Keywords such as 'risk', 'lung', 'vulnerab', etc. are used to mark the paper as 'is_risk' while keywords such as 'gene', 'molecule' are for 'is_research'. For the preliminary version, only those papers marked 'is_risk' are analyzed. The advantage of this approach is that it's simple and easily understood.\n\nFuture improvements can include using more advanced NLP techniques such as sentence similarity using word and character embeddings which will require more resources. Analyze full text documents using summary tools like [summy](https://pypi.org/project/sumy/). The chosen words were manually selected based on experience however, other synonymous words or words from experts can increase the specificity and accuracy of the results.\n\nA couple of hand-picked results:\n>==========/kaggle/input/CORD-19-research-challenge/noncomm_use_subset/noncomm_use_subset/pdf_json/6c7341f17bfd790cdc05b6d1010c63f4f8eb5890.json==========\nantivirals for influenza-like illness? protocol for a randomized controlled trial of clinical and cost effectiveness in primary care (alic 4 e) antivirals for influenza-like illness? a randomized controlled trial of clinical and cost effectiveness in primary care (alic4e): the alic4e protocol antivirals for influenza-like illness? a randomized controlled trial of clinical and cost effectiveness in primary care (alic 4 e): the alic 4 e protocol antivirals for influenza-like illness? a randomized controlled trial of clinical and cost effectiveness in primary care (alic4e): the alic4e protocol antivirals for influenza-like illness? a randomized controlled trial of clinical and cost effectiveness in primary care (alic 4 e): the alic 4 e protocol\nindividuals with rantes -28 cg and gg genotypes had a 3.28-fold (95%ci:2.32-4.64) and 3.06-fold (95%ci:1.47-6.39) increased risk of developing sars respectively (p < 0.0001).\n\n>==========/kaggle/input/CORD-19-research-challenge/custom_license/custom_license/pmc_json/PMC7100800.xml.json==========\nsystematic review extreme water-related weather events and waterborne disease\nin multivariate gee logistic regression models, presence in the room during fiberoptic intubation (or = 2.79, p = .004) or ecg (or = 3.52, p = .002), unprotected eye contact with secretions (or = 7.34, p = .001), patient apache ii score $20 (or = 17.05, p = .009) and patient pa0 2 /fi0 2 ratio #59 (or = 8.65, p = .001) were associated with increased risk of transmission of sars-cov.\n\n>==========/kaggle/input/CORD-19-research-challenge/noncomm_use_subset/noncomm_use_subset/pdf_json/6c7341f17bfd790cdc05b6d1010c63f4f8eb5890.json==========\nantivirals for influenza-like illness? protocol for a randomized controlled trial of clinical and cost effectiveness in primary care (alic 4 e) antivirals for influenza-like illness? a randomized controlled trial of clinical and cost effectiveness in primary care (alic4e): the alic4e protocol antivirals for influenza-like illness? a randomized controlled trial of clinical and cost effectiveness in primary care (alic 4 e): the alic 4 e protocol antivirals for influenza-like illness? a randomized controlled trial of clinical and cost effectiveness in primary care (alic4e): the alic4e protocol antivirals for influenza-like illness? a randomized controlled trial of clinical and cost effectiveness in primary care (alic 4 e): the alic 4 e protocol\ncoronaviruses (covs) are found in a wide variety of wild and domestic animals, and constitute a risk for zoonotic and emerging infectious disease.\n\n> ==========/kaggle/input/CORD-19-research-challenge/noncomm_use_subset/noncomm_use_subset/pdf_json/f2948dc01fd28774bb06b6c6995bec2a2f466f2a.json==========\ntitle: household emergency preparedness in china: a cross-sectional survey author names and affiliations\npartially ecologic study based on short-term exposure demonstrated that sars patients from regions with moderate apis had an 84% increased risk of dying from sars compared to those from regions with low apis (rr = 1.84, 95% ci: 1.41-2.40).\n\n> ==========/kaggle/input/CORD-19-research-challenge/custom_license/custom_license/pmc_json/PMC7100800.xml.json==========\ndevelopment of a smartphone-based rapid dual fluorescent diagnostic system for the simultaneous detection of influenza a and h5 subtype in avian influenza a-infected patients\ngroups seen as at 'high risk' of infection included the immune compromised (mentioned by 87% respondents), pig farmers (70%), elderly (57%), prostitutes/highly sexually active (53%), and the homeless (53%).\n\n> ==========/kaggle/input/CORD-19-research-challenge/noncomm_use_subset/noncomm_use_subset/pdf_json/f2948dc01fd28774bb06b6c6995bec2a2f466f2a.json==========\ntitle: household emergency preparedness in china: a cross-sectional survey author names and affiliations\nfor patients at risk for asthma, or with existing asthma, viral respiratory tract infections can have a profound effect on the expression of disease or loss of control.\n\n> ==========/kaggle/input/CORD-19-research-challenge/noncomm_use_subset/noncomm_use_subset/pdf_json/f2948dc01fd28774bb06b6c6995bec2a2f466f2a.json==========\ntitle: household emergency preparedness in china: a cross-sectional survey author names and affiliations\nan elevated level of viral diversity was found in some sars-cov-2 infected patients, indicating the risk of rapid evolution of the virus.\n\n> ==========/kaggle/input/CORD-19-research-challenge/noncomm_use_subset/noncomm_use_subset/pdf_json/f2948dc01fd28774bb06b6c6995bec2a2f466f2a.json==========\ntitle: household emergency preparedness in china: a cross-sectional survey author names and affiliations\nalthough people at the extremes of age have a greater risk of complications, influenza has been more frequently investigated in the elderly than in children, and inpatients than outpatients.\n\n> ==========/kaggle/input/CORD-19-research-challenge/noncomm_use_subset/noncomm_use_subset/pdf_json/138e18baf12e4e92b67ab7dee321d2b149f236ed.json==========\ntitle: the changes of prevalence and etiology of pediatric pneumonia from national emergency department information system in korea, between 2007 and 2014\nby multivariate logistic regression, male, older age and comorbidity with diabetes were three important independent risk factors predicting aki among covid-19 patients.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"meta = pd.read_csv('/kaggle/input/CORD-19-research-challenge/metadata.csv')\nmeta","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# extracing title from json files\ndef parse_json(fn):\n    with open(fn, 'r') as f:\n        data = json.loads(f.read())\n#     print(data)\n    source = fn.split('/')[4]\n#     print('source=',source)\n    return([data['paper_id'], data['metadata']['title'], source, fn])\n\n# parse_json('/kaggle/input/CORD-19-research-challenge/biorxiv_medrxiv/biorxiv_medrxiv/pdf_json/2c006d09b6fccc527bf5ee3de0f165b018c39e73.json')\n\ndef load_data():\n    papers = []\n    import os\n    import json\n    for dirname, _, filenames in os.walk('/kaggle/input'):\n        for filename in tqdm(filenames):\n            if '.json' not in filename:\n                continue\n            try:\n                fn = os.path.join(dirname, filename)\n#                 print(fn)\n                papers.append(parse_json(fn))\n            except Exception as e:\n                print(e)\n                continue\n    return papers\n            \npapers = load_data()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"papers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# to data frame\ndf = pd.DataFrame(papers,columns=['pmcid','title','source', 'file'])\ndf = df.drop_duplicates()\ndf = pd.merge(df, meta, on='pmcid', how='left').reset_index().rename(columns={'title_x':'title'})\ndel df['title_y']\n\n# cleaning titles\ntitles = df['title']\ntitles_clean = []\nfor t in tqdm(titles):\n    titles_clean.append(t.replace('\"','').lower().strip())\n#     for p in parts:\n\ndf['title_clean'] = titles_clean\n\n\n# df = pd.read_csv('/kaggle/input/covid19-uncover-paper-titles/covid19_uncover_paper_titles.csv')\ndf['title'] = df['title'].astype('str')\ndf['title_clean'] = df['title_clean'].astype('str')\n\n# text associated that we are interested in\ninclusion = ('vulnerab epidem suscept copd male clinical illness female diabetes comorbid mortal prognosis hypertension blood heart liver lung kidney renal brain bladder tuberc drink alcohol mental psychi nerv smoking age stroke cardio cerebr cancer respira chronic factor risk population sex gender hospital health age population ethnic flu death mortality respir disease child pediat adult infant lung resp smok person patient old senior elderly infected individual').split(' ')\n\n# text associated with more research\nexclusion = ('pig rat mouse chicken horse mice dog monkey cat cations simulation bird gene cell tissue organism glia phagocy microbiology bacteria eukaryotic assay apoptosis signal protein pathway molecul rna dna monocytes chemokine').split(' ')\n\nrelevant_docs = set()\nresearch_docs = set()\ndf['is_risk'] = 0\ndf['is_research'] = 0\nfor i in tqdm(df.index):\n    t = df.loc[i,'title_clean']\n    if np.nan == t or pd.isna(t):\n        continue\n    for w in inclusion:\n#         print(f't={t}, w={w}')\n        if w in t:\n            df.loc[i, 'is_risk'] = 1\n            relevant_docs.add(t)\n            break\n    for w in exclusion:\n        if w in t:\n            df.loc[i, 'is_research'] = 1\n            research_docs.add(t)\n            break\n\n\ndf.to_csv('paper_titles_is_risk.csv', index=False)\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[['source','is_risk','is_research']].groupby('source').sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"meta","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Title enrichment and filtering"},{"metadata":{"trusted":true},"cell_type":"code","source":"# text associated that we are interested in\n# inclusion = ('vulnerab suscept factor risk population sex gender hospital health age population ethnic flu death mortality respir disease child pediat adult infant lung resp smok person patient old senior elderly infected individual').split(' ')\n\n# text associated with more research\n# exclusion = ('pig', 'rat', 'mouse', 'mice', 'monkey', 'cations', 'gene', 'cell', 'tissue', 'glia', 'phagocy', 'microbiology', 'bacteria', 'eukaryotic', 'apoptosis', 'signal', 'protein', 'pathway', 'molecul', 'rna', 'dna', 'monocytes', 'chemokine')\n\n# relevant_docs = set()\n# research_docs = set()\n# df['is_risk'] = 0\n# df['is_research'] = 0\n# for i in tqdm(range(df.shape[0])):\n#     t = df.loc[i,'title_clean']\n#     for w in inclusion:\n#         if w in t:\n#             df.loc[i, 'is_risk'] = 1\n#             relevant_docs.add(t)\n#     for w in exclusion:\n#         if w in t:\n#             df.loc[i, 'is_research'] = 1\n#             research_docs.add(t)\n\n# relevant_docs = list(relevant_docs)\n# research_docs = list(research_docs)\n# df.to_csv('paper_titles.csv', index=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Word cloud of \"risk\" paper titles"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.query('is_risk == 1 & is_research == 0')\nrelevant_docs = df['title'].values\n\ntext = ' '.join(relevant_docs)\nfrom wordcloud import WordCloud\n\n# # Build word frequencies on filtered tokens\n# freqs = pd.Series(np.concatenate([tokenize(x) for x in articles.Title])).value_counts()\n# wordcloud(freqs, \"Most frequent words in article titles tagged as COVID-19\")\n\n# Generate a word cloud image\nwordcloud = WordCloud().generate(text)\n\n# Display the generated image:\n# the matplotlib way:\nimport matplotlib.pyplot as plt\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\n\n# lower max_font_size\n# wordcloud = WordCloud(max_font_size=40).generate(text)\n# plt.figure()\n# plt.imshow(wordcloud, interpolation=\"bilinear\")\n# plt.axis(\"off\")\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fetch full text for 'risk' related papers  \ndef fetch_abstract(path):\n    ret = []\n    try:\n        \n        with open(path, 'r') as f:\n            data = json.loads(f.read())\n    #     print(data)\n    #     for a in data['body_text']:\n\n        for a in data['abstract']:\n            ret.append(a['text'])\n    except:\n        pass\n    return (' '.join(ret)).lower().strip()\n\n# fetch_abstract('/kaggle/input/CORD-19-research-challenge/noncomm_use_subset/noncomm_use_subset/pdf_json/26aec9a28a4345276498c14e302ead7d96c7feee.json')\n\n# full_text = dict()\ndf['abstract'] = ''\nfor i in tqdm(df.index):\n    fn = df.loc[i, 'file']\n    df.loc[i, 'abstract'] = fetch_abstract(fn)\n    \ndf.to_csv('paper_titles.csv', index=False)\ndf\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Abstract sentences WordCloud"},{"metadata":{"trusted":true},"cell_type":"code","source":"abstract_text = ' '.join(df['abstract'].values)\nabstract_text\n\n# remove stop words\nwords = []\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize \nstop_words = set(stopwords.words('english'))\nabstract_text = ' '.join([w for w in word_tokenize(abstract_text) if w not in stop_words])\n\n# Generate a word cloud image for the abstract\nwordcloud = WordCloud().generate(abstract_text)\n\n# Display the generated image:\n# the matplotlib way:\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_colwidth', -1)\nprint(df['title'].head(10))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Paper titles that with abstracts that contains *corona, covid, sars, mers, h1n1* and *risk*"},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.tokenize import sent_tokenize\n\nresults = []\nLIMIT = 2000\n\nprev_s = ''\nfor i in tqdm(df.index):\n    a = df.loc[i,'abstract']\n    for s in sent_tokenize(a):\n#             if 'patient' in s and 'risk' in s:\n        prev_s = s.strip()\n        if ('covid' is s or 'corona' in s or 'sars' in s or 'mers' in s or 'h1n1' in s) and 'risk' in s:\n            f = df.loc[i, 'file']\n            title = df.loc[i, 'title']\n            pid = df.loc[i, 'pmcid']\n            results.append((pid, f,title, prev_s + ' ' + s.strip()))\n#                 print(results)\n#             print()\n#             print('='*10 + fn + '='*10)\n#             print(title)\n#             print(s.strip())\n            if len(results) > LIMIT:\n                break\n    if len(results) > LIMIT:\n        break\n\n\nwith open('results_patient_risk.csv','w') as f:\n    for pid,fn,title,s in results:\n#         print()\n#         print('='*10 + fn + '='*10)\n#         print(title)\n#         print(s.strip())\n        f.write(fn + '\\t' + title + '\\t' + s.strip() + '\\n')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# number of abstract sentences that matched grouped by paper titles\ndf_results = pd.DataFrame(results, columns=['pmcid', 'file','title','sentence'])\ndf_results.to_csv('results.csv')\nprint(df_results.shape)\ndf_results.groupby(['title']).count()[['pmcid']].sort_values(by='pmcid',ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Abstract sentences matched *corona, covid, sars, mers, h1n1* and *risk*"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_results[['pmcid', 'title','sentence']].head(1000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results_text = ' '.join(df_results['sentence'].values)\n\n# Generate a word cloud image for the abstract\nwordcloud = WordCloud().generate(results_text)\n\n# Display the generated image:\n# the matplotlib way:\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Males (80+ years old) are the most at risk of dying from COVID-19\n\nAs shown below, most of the fatalities are Males (80+) with 6,825 fatalities vs Females (80+) 5,322. On the other hand, there were 7,379 Female (80+) survivors vs 4,185 Male (80+) survivors."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cases = pd.read_csv('/kaggle/input/covid19-european-enhanced-surveillance/covid19_enhanced_surveillance.csv')\ndf_cases.head(50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_rows', 1000)\ndf_cases['cases'] = [ int(str(x).replace('<=5','5')) for x in df_cases['Cases'] ]\ndf_cases['deaths'] = [ int(str(x).replace('<=5','5')) for x in df_cases['Deaths'] ]\ndf_cases.groupby(['Outcome', 'Gender','Age group']).sum()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}