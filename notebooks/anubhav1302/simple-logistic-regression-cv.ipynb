{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Load Libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split,StratifiedKFold,GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.linear_model import LogisticRegression\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Read Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv('../input/heart-disease-uci/heart.csv')\nprint(df.shape)\ndf.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Divide Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df,test_df=train_test_split(df,test_size=0.15)\nprint(train_df.shape)\nprint(test_df.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Basic Preprocessing\n\n* Treat Outliers\n* Scale data"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Outlier Correction,Missing values,Scaling\ncolumns=['age','trestbps','chol','thalach','oldpeak'] #take only numerical columns\nss=StandardScaler() \n\ndef outlier_(X):\n    tmp=[]\n    Q3=train_df[X].quantile(0.75)\n    Q1=train_df[X].quantile(0.25)\n    IQR=Q3-Q1\n    lower=train_df[X][train_df[X]<Q1-1.5*IQR].values\n    upper=train_df[X][train_df[X]>Q3+1.5*IQR].values\n    return lower,upper   \n\noutlier_col=[] #Store column names that have outliers.\nfor i in columns:\n    l,u=outlier_(i)\n    if len(l)>0 or len(u)>0:\n        print('>>Feature {} contain outliers'.format(i))\n        outlier_col.append(i)\n    else:\n        print('Feature {} contain no outliers'.format(i))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"iqr_values={} #To treat values in test data\ndef outlier_treatment(X):\n    Q3=train_df[X].quantile(0.75)\n    Q1=train_df[X].quantile(0.25)\n    IQR=Q3-Q1\n    lb=Q1-1.5*IQR\n    ub=Q1+1.5*IQR\n    train_df[X][train_df[X]<lb]=lb\n    train_df[X][train_df[X]>ub]=ub\n    iqr_values[X]=[lb,ub]\n\nfor i in outlier_col:\n    outlier_treatment(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=train_df.drop('target',axis=1)\n\n#Rescale\nX[columns]=ss.fit_transform(X[columns])\nX=X.values\n\ny=train_df['target'].values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Stratified_KFold + GridSearch\n* With each fold, we will tune the model and save it\n* Use all saved models from the K folds to make averaging classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nparams={'C':[i for i in range(1,150,5)],\n       'penalty':['l1','l2','elasticnet']}\n\nsplits=5\nkf=StratifiedKFold(n_splits=splits)\n\nmodel_dict={}\nmodel_ix=0\n\nfor train_ix,test_ix in kf.split(X,y):\n    print('Fold: {}/{}'.format(model_ix+1,splits))\n    train_data_X,train_data_y=X[train_ix],y[train_ix]\n    test_data_X,test_data_y=X[test_ix],y[test_ix]\n    \n    lr=LogisticRegression(class_weight='balanced')\n    gs=GridSearchCV(LogisticRegression(class_weight='balanced'),param_grid=params)\n    gs.fit(train_data_X,train_data_y)\n    best_model=gs.best_estimator_\n    \n    print('Validation Score: {:.3f}'.format(roc_auc_score(test_data_y,best_model.predict(test_data_X))))\n    print('-------------------------------------')\n    \n    #Save Model\n    model_dict['LogReg'+str(model_ix)]=best_model\n    model_ix+=1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocess Test Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_X=test_df.drop('target',axis=1)\ntest_y=test_df['target']\n\nfor col in outlier_col:\n    test_X[col][test_X[col]>iqr_values[col][1]]=iqr_values[col][1]\n    test_X[col][test_X[col]<iqr_values[col][0]]=iqr_values[col][1]\n    \ntest_X[columns]=ss.transform(test_X[columns])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Make Test Predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions=np.zeros((len(test_X),5))\nfor ix,k in enumerate(model_dict):\n    p=model_dict[k].predict(test_X)\n    predictions[:,ix]=p\n\npredictions=[1 if p>=0.5 else 0 for p in predictions.mean(axis=1)]\nprint('Test Score: {:.3f}'.format(roc_auc_score(test_y,predictions)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Nothing Fancy and technical done in this notebook, we just used 3 things:\n  * > Cross Validation\n  * > Grid Search\n  * > Averaging\n\n**Fin**"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}