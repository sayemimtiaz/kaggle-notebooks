{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Predicting the presence of heart disease using ML classification models.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The dataset given has 14 features(columns) and 303 rows. There are 303 training examples. Let's look at what the columns exactly represent since they are all abbreviated. I always find it easier to work on data that I am familiar with so lets understand what exactly the columns represent.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The heart disease dataset contains the following features:\n1. Age of the person \n2. Sex or the gender of the person \n3. Type of chest pain-represented by 4 values(0,1,2 and 3)\n4. Resting blood pressure\n5. Serum cholesterol which is the combined measurement of HDL and LDL (high and low density lipo-proteins). HDL is often deemed as good cholesterol and indicates lower risk of heart disease whereas LDL is seen as bad cholesterol which indicates a higher risk of heart disease and increased plaque formation in your blood vessels and arteries. \n6. Fasting blood sugar which indicates the level of diabetes and is considered to be a risk factor if found to be above 120 mg/dl.\n7. Resting electrocardiographic results which measure the electrical activity of the heart. It can diagnose the irregular heart rhythms, abnormally slow heart rhythms, evidence of an evolving/acute heart attack possibilities etc. \n8. Maximum heart rate achieved is the average maximum number of times our heart beats per minute. It is calculates as (220-age of the person).\n9. Exercise induced angina(AP) is a common concern among cardiac patients. Angina is usually stable but is triggered when we do physical activity especially in cold conditions.\n10. Oldpeak is described as the ST depression induced by exercise relative to rest. ST depression occurs when the J point is displaced below baseline. Not all ST depressions represents an emergency condition.\n11. The slope of the peak exercise ST segment\n12. The number of major vessels\n13. Thalach: 3 = normal; 6 = fixed defect; 7 = reversible defect\n14. Target-tells us whether the person has heart disease(1) or not(0).","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Import the various necessary modules and read/display the data","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import svm\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nimport seaborn as sns\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score,classification_report,confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv('../input/heart-disease-uci/heart.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The shape of the dataset is nothing but the rows x columns so lets see the dimensions of our dataset. Also lets check the presence of any NA or null values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data visualization using in-built python libraries","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The heatmap tells us the relation between various variables in our dataset by indicating how they affect each other using a color scheme as well as numerical data. Negative values indicate the relatively less correlation between the 2 specific variables whereas values closer to 1 are highly correlated. df.corr() is used to find the pairwise correlation of all columns in the dataframe.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,10))\nsns.heatmap(df.corr(),annot=True,linewidth=0.2,cmap='coolwarm')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The 8 plots below (countplots) represent the relations between the categorical values and the target variable(0 or 1) and is supposed to show the count of the categorical values.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,15))\nplt.subplot(4,4,1)\nsns.countplot(data=df,x='sex',hue='target',palette='Set2')\nplt.subplot(4,4,2)\nsns.countplot(data=df,x='cp',hue='target',palette='Set2')\nplt.subplot(4,4,3)\nsns.countplot(data=df,x='fbs',hue='target',palette='Set2')\nplt.subplot(4,4,4)\nsns.countplot(data=df,x='restecg',hue='target',palette='Set2')\nplt.subplot(4,4,5)\nsns.countplot(data=df,x='exang',hue='target',palette='Set1')\nplt.subplot(4,4,6)\nsns.countplot(data=df,x='slope',hue='target',palette='Set1')\nplt.subplot(4,4,7)\nsns.countplot(data=df,x='ca',hue='target',palette='Set1')\nplt.subplot(4,4,8)\nsns.countplot(data=df,x='thal',hue='target',palette='Set1')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The 4 plots (distplots) below are the histograms that represent the range of values that the continuous values posses.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,15))\nplt.subplot(4,4,1)\nsns.distplot(a=df['age'],bins=30)\nplt.subplot(4,4,2)\nsns.distplot(a=df['trestbps'],bins=40,color='red')\nplt.subplot(4,4,3)\nsns.distplot(a=df['chol'],bins=50,color='green')\nplt.subplot(4,4,4)\nsns.distplot(a=df['oldpeak'],bins=30,color='purple')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The following 4 plots depict the status of correlations between 3 different variables i.e. target, gender and 1 of 4 variables that contain continous numerical values. It is depicted using the boxplot where the green box indicates no heart disease and orange box represents the presence of heart disease. The X-axis represents age, resting blood pressure, cholesterol and oldpeak values. The 2 plots are further classified based on gender and the y-axis represents the target(0 or 1).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.catplot(x=\"age\", y=\"target\", row=\"sex\",kind=\"box\", orient=\"h\", height=1.5, aspect=4,data=df,palette='Set2')\ng.set(xscale='log')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.catplot(x=\"trestbps\", y=\"target\", row=\"sex\",kind=\"box\", orient=\"h\", height=1.5, aspect=4,data=df,palette='Set2')\ng.set(xscale='log')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.catplot(x=\"chol\", y=\"target\", row=\"sex\",kind=\"box\", orient=\"h\", height=1.5, aspect=4,data=df,palette='Set2')\ng.set(xscale='log')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.catplot(x=\"oldpeak\", y=\"target\", row=\"sex\",kind=\"box\", orient=\"h\", height=1.5, aspect=4,data=df,palette='Set2')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data manipulation","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The values of few categorical variables cause ambiguity while fitting our model and training it. So let's make them all binary and convert ranges of 0-3 or 0-4 to 1's and 0's by adding columns. We do this using pandas by specifying which columns need to be encoded and thus we get a dataframe with original columns replaced by our encoded variables.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"d1=pd.get_dummies(df['cp'],drop_first=True,prefix='cp')\nd2=pd.get_dummies(df['thal'],drop_first=True,prefix='thal')\nd3=pd.get_dummies(df['slope'],drop_first=True,prefix='slope')\ndf=pd.concat([df,d1,d2,d3],axis=1)\ndf.drop(['cp','thal','slope'],axis=1,inplace=True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creating an extra feature","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Lets just perform some extremely simple feature engineering using the age column. A well known fact is that adults over the age of 60 are more likely to suffer from heart diseases than younger adults. So, we create a separate column to filter the entries in which the person is either 60 years or older. We can do this by assigning 0's to those below 60 years of age and 1's to people over 60. We name the column 'seniors' which means senior citizens.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['age'].min()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['age'].max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['seniors'] = df['age'].map(lambda s: 1 if s >= 60 else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train-test split","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Now that our dataframe is ready, lets split the data into training and testing sets.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X=df.drop('target',axis=1)\ny=df['target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtrain,xtest,ytrain,ytest=train_test_split(X,y,test_size=0.2,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Scaling the data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"scale=StandardScaler()\nxtrain=scale.fit_transform(xtrain)\nxtest=scale.transform(xtest)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let us create a list called scores so that we can finally compare the performances of 5 different classification models based on their accuracy score.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"scores=[]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Classification","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"1. Logistic Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"clf1=LogisticRegression()\nclf1.fit(xtrain,ytrain)\npred1=clf1.predict(xtest)\ns1=accuracy_score(ytest,pred1)\nscores.append(s1*100)\nprint(s1*100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2. Random Forest","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"clf2=RandomForestClassifier(max_depth=2,random_state=0)\nclf2.fit(xtrain,ytrain)\npred2=clf2.predict(xtest)\ns2=accuracy_score(ytest,pred2)\nscores.append(s2*100)\nprint(s2*100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3. K nearest neighbors","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"clf3=KNeighborsClassifier()\nclf3.fit(xtrain,ytrain)\npred3=clf3.predict(xtest)\ns3=accuracy_score(ytest,pred3)\nscores.append(s3*100)\nprint(s3*100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"4. Support Vector Machine","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"clf4=svm.SVC(kernel='rbf',C=1)\nclf4.fit(xtrain,ytrain)\npred4=clf4.predict(xtest)\ns4=accuracy_score(ytest,pred4)\nscores.append(s4*100)\nprint(s4*100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"5. Decision Tree","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"clf5=DecisionTreeClassifier(max_depth=3,random_state=0)\nclf5.fit(xtrain,ytrain)\npred5=clf5.predict(xtest)\ns5=accuracy_score(ytest,pred5)\nscores.append(s5*100)\nprint(s5*100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Viewing the scores list, we can see how different models perform.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(scores)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"names=['LogisticRegression','RandomForest','KNN','SVM','Decision Tree']\nclassifier=pd.Series(data=scores,index=names)\nprint(classifier)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,7))\nclassifier.sort_index().plot.bar()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that we get the highest accuracy of 90.16% with the logistic regression classifier. So lets check it's classification report and confusion matrix to better understand our results from the predictions.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(confusion_matrix(ytest,pred1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Our classifier has predicted 27+28 outcomes correctly and 2+4 outcomes wrongly","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(ytest,pred1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thanks for viewing my kernel. Do upvote :)","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}