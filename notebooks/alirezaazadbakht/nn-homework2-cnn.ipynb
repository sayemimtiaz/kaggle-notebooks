{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Imports"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom albumentations import Compose, ShiftScaleRotate, Blur\nfrom albumentations.pytorch import ToTensor\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom mlxtend.plotting import plot_confusion_matrix\nfrom sklearn.metrics import confusion_matrix, classification_report\ndef make_report(y_pred , y_true, fig_size = (20,20)):\n    print (\"\")\n    print (\"Classification Report: \")\n    print (classification_report(y_true, y_pred))\n    cm = confusion_matrix(y_true, y_pred)\n    fig, ax = plot_confusion_matrix(figsize=fig_size, conf_mat=cm)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading data"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_pickle('/kaggle/input/traffic-signs-preprocessed/data0.pickle')\nprint('keys:', data.keys())\nprint('train shape:', data['x_train'].shape)\nprint('test shape:', data['x_test'].shape)\nprint('validation shape:', data['x_validation'].shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(2):\n    img = data['x_train'][i].T\n    plt.imshow(img)\n    plt.axis('off')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class MyDataset(torch.utils.data.Dataset):\n    def __init__(self, x, y, num_classes):\n        self.x = x\n        self.y = y\n        self.n_class = num_classes\n\n    def __len__(self):\n        return len(self.x)\n\n    def __getitem__(self, idx):\n        x=torchvision.transforms.functional.to_tensor(self.x[idx].astype(np.uint8).reshape((32, 32, 3)))\n        \n        label_idx = self.y[idx]\n        label = np.zeros(self.n_class)\n        label[label_idx] = 1\n        label = torch.tensor(label)\n#         return {'x': self.x[idx], 'y': label}\n        return {'x': x, 'y': label}\n    \nBATCH_SIZE = 256    \ntrain_dataset = MyDataset(data['x_train'], data['y_train'], 43)\ndataLoader_train = torch.utils.data.DataLoader(train_dataset,\n                                               batch_size=BATCH_SIZE,\n                                               shuffle=True)\n\ntest_dataset = MyDataset(data['x_test'], data['y_test'], 43)\ndataLoader_test = torch.utils.data.DataLoader(test_dataset,\n                                              batch_size=BATCH_SIZE,\n                                              shuffle=True)\n\nvalidation_dataset = MyDataset(data['x_validation'], data['y_validation'], 43)\ndataLoader_validation = torch.utils.data.DataLoader(validation_dataset,\n                                                    batch_size=BATCH_SIZE,\n                                                    shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(data['y_train'], bins = 43)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"so the classes are balanced"},{"metadata":{},"cell_type":"markdown","source":"# Modeling"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Model(torch.nn.Module):\n    \n    def __init__(self, num_classes):\n        super().__init__()\n        \n        self.conv = torch.nn.Sequential(\n            torch.nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3, 3)),\n            torch.nn.ReLU(),\n            torch.nn.BatchNorm2d(32),\n            torch.nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(3, 3)),\n            torch.nn.ReLU(),\n            torch.nn.BatchNorm2d(32),\n            torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3)),\n            torch.nn.ReLU(),\n            torch.nn.BatchNorm2d(64),\n        )\n        \n        self.flatten = torch.nn.Sequential(torch.nn.AdaptiveMaxPool2d(1), torch.nn.Flatten())\n        \n        self.fc = torch.nn.Sequential(\n            torch.nn.Linear(64, 512),\n            torch.nn.ReLU(),\n            torch.nn.Linear(512, num_classes)\n        )\n        \n    def forward(self, x):\n        x = self.conv(x)\n        x = self.flatten(x) \n        x = self.fc(x)\n        return x\n    \nmodel = Model(43)\nprint(model)\ncriterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=5e-4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nn_epochs = 3\nprint('started!')\nfor epoch in range(n_epochs):\n    train_batch_loss = 0\n    model.train()\n    for step, batch in enumerate(dataLoader_train):\n        x = batch[\"x\"]\n        y = batch[\"y\"]\n\n        optimizer.zero_grad()\n        outputs = model(x)\n        loss = criterion(outputs, torch.max(y, 1)[1])\n        loss.backward()\n        optimizer.step()\n        train_batch_loss += loss.item()\n        optimizer.step()\n        optimizer.zero_grad()\n\n    test_batch_loss = 0\n    model.eval()\n    with torch.no_grad():\n        for step, batch in enumerate(dataLoader_test):\n            x = batch[\"x\"]\n            y = batch[\"y\"]\n            outputs = model(x)\n            loss = criterion(outputs, torch.max(y, 1)[1])\n            test_batch_loss += loss.item()\n\n    print('epoch {}/{} finished with train loss: {} and test loss: {}'.format(epoch+1, n_epochs,\n                                                                              train_batch_loss / len(dataLoader_train),\n                                                                              test_batch_loss / len(dataLoader_test)))\n    \ntorch.save(model.state_dict(), './model_RGB')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def res(dataLoader):  \n    trues = []\n    preds = []\n    model.eval()\n    with torch.no_grad():\n        for step, batch in enumerate(dataLoader):\n            x = batch[\"x\"]\n            y = batch[\"y\"]\n\n            outputs = model(x)\n\n            true_labels = torch.max(y, 1)[1]\n            trues = trues + true_labels.tolist()\n            pred_labels = torch.max(outputs, 1)[1]\n            preds = preds + pred_labels.tolist()\n\n\n    make_report(y_pred = preds, y_true = trues)\n\nprint('Test')\nres(dataLoader_test)\nprint('validation')\nres(dataLoader_validation)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Gray scale "},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_pickle('/kaggle/input/traffic-signs-preprocessed/data4.pickle')\nprint('keys:', data.keys())\nprint('train shape:', data['x_train'].shape)\nprint('test shape:', data['x_test'].shape)\nprint('validation shape:', data['x_validation'].shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(2):\n    img = data['x_train'][i].T\n    plt.imshow(img, cmap='gray', vmin=0, vmax=255)\n    plt.axis('off')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class MyDataset(torch.utils.data.Dataset):\n    def __init__(self, x, y, num_classes):\n        self.x = x\n        self.y = y\n        self.n_class = num_classes\n\n    def __len__(self):\n        return len(self.x)\n\n    def __getitem__(self, idx):\n        x=torchvision.transforms.functional.to_tensor(self.x[idx].astype(np.uint8).reshape((32, 32, 1)))\n        \n        label_idx = self.y[idx]\n        label = np.zeros(self.n_class)\n        label[label_idx] = 1\n        label = torch.tensor(label)\n#         return {'x': self.x[idx], 'y': label}\n        return {'x': x, 'y': label}\n    \nBATCH_SIZE = 256    \ntrain_dataset = MyDataset(data['x_train'], data['y_train'], 43)\ndataLoader_train = torch.utils.data.DataLoader(train_dataset,\n                                               batch_size=BATCH_SIZE,\n                                               shuffle=True)\n\ntest_dataset = MyDataset(data['x_test'], data['y_test'], 43)\ndataLoader_test = torch.utils.data.DataLoader(test_dataset,\n                                              batch_size=BATCH_SIZE,\n                                              shuffle=True)\n\nvalidation_dataset = MyDataset(data['x_validation'], data['y_validation'], 43)\ndataLoader_validation = torch.utils.data.DataLoader(validation_dataset,\n                                                    batch_size=BATCH_SIZE,\n                                                    shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #68 percent\n# class Model(torch.nn.Module):\n    \n#     def __init__(self, num_classes):\n#         super().__init__()\n        \n#         self.conv = torch.nn.Sequential(\n#             torch.nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3, 3)),\n#             torch.nn.ReLU(),\n#             torch.nn.BatchNorm2d(32),\n#             torch.nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(3, 3)),\n#             torch.nn.ReLU(),\n#             torch.nn.BatchNorm2d(32),\n#         )\n        \n#         self.flatten = torch.nn.Sequential(torch.nn.AdaptiveMaxPool2d(1), torch.nn.Flatten())\n        \n#         self.fc = torch.nn.Sequential(\n#             torch.nn.Linear(32, 256),\n#             torch.nn.ReLU(),\n#             torch.nn.Dropout(0.3),\n#             torch.nn.Linear(256, num_classes)\n#         )\n        \n#     def forward(self, x):\n#         x = self.conv(x)\n#         x = self.flatten(x) \n#         x = self.fc(x)\n#         return x\n    \n# model = Model(43)\n# print(model)\n# criterion = torch.nn.CrossEntropyLoss()\n# optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #81\n# class Model(torch.nn.Module):\n    \n#     def __init__(self, num_classes):\n#         super().__init__()\n        \n#         self.conv = torch.nn.Sequential(\n#             torch.nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3, 3)),\n#             torch.nn.ReLU(),\n#             torch.nn.BatchNorm2d(32),\n#             torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3)),\n#             torch.nn.ReLU(),\n#             torch.nn.BatchNorm2d(64),\n#         )\n        \n#         self.flatten = torch.nn.Sequential(torch.nn.AdaptiveMaxPool2d(1), torch.nn.Flatten())\n        \n#         self.fc = torch.nn.Sequential(\n#             torch.nn.Linear(64, 512),\n#             torch.nn.ReLU(),\n#             torch.nn.Linear(512, num_classes)\n#         )\n        \n#     def forward(self, x):\n#         x = self.conv(x)\n#         x = self.flatten(x) \n#         x = self.fc(x)\n#         return x\n    \n# model = Model(43)\n# print(model)\n# criterion = torch.nn.CrossEntropyLoss()\n# optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#90\nclass Model(torch.nn.Module):\n    \n    def __init__(self, num_classes):\n        super().__init__()\n        \n        self.conv = torch.nn.Sequential(\n            torch.nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3, 3)),\n            torch.nn.ReLU(),\n            torch.nn.BatchNorm2d(32),\n            torch.nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(3, 3)),\n            torch.nn.ReLU(),\n            torch.nn.BatchNorm2d(32),\n            torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3)),\n            torch.nn.ReLU(),\n            torch.nn.BatchNorm2d(64),\n        )\n        \n        self.flatten = torch.nn.Sequential(torch.nn.AdaptiveMaxPool2d(1), torch.nn.Flatten())\n        \n        self.fc = torch.nn.Sequential(\n            torch.nn.Linear(64, 512),\n            torch.nn.ReLU(),\n            torch.nn.Linear(512, num_classes)\n        )\n        \n    def forward(self, x):\n        x = self.conv(x)\n        x = self.flatten(x) \n        x = self.fc(x)\n        return x\n    \nmodel = Model(43)\nprint(model)\ncriterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=5e-4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nn_epochs = 3\nprint('started!')\nfor epoch in range(n_epochs):\n    train_batch_loss = 0\n    model.train()\n    for step, batch in enumerate(dataLoader_train):\n        x = batch[\"x\"]\n        y = batch[\"y\"]\n\n        optimizer.zero_grad()\n        outputs = model(x)\n        loss = criterion(outputs, torch.max(y, 1)[1])\n        loss.backward()\n        optimizer.step()\n        train_batch_loss += loss.item()\n        optimizer.step()\n        optimizer.zero_grad()\n\n    test_batch_loss = 0\n    model.eval()\n    with torch.no_grad():\n        for step, batch in enumerate(dataLoader_test):\n            x = batch[\"x\"]\n            y = batch[\"y\"]\n            outputs = model(x)\n            loss = criterion(outputs, torch.max(y, 1)[1])\n            test_batch_loss += loss.item()\n\n    print('epoch {}/{} finished with train loss: {} and test loss: {}'.format(epoch+1, n_epochs,\n                                                                              train_batch_loss / len(dataLoader_train),\n                                                                              test_batch_loss / len(dataLoader_test)))\n    \ntorch.save(model.state_dict(), './model_gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def res(dataLoader):  \n    trues = []\n    preds = []\n    model.eval()\n    with torch.no_grad():\n        for step, batch in enumerate(dataLoader):\n            x = batch[\"x\"]\n            y = batch[\"y\"]\n\n            outputs = model(x)\n\n            true_labels = torch.max(y, 1)[1]\n            trues = trues + true_labels.tolist()\n            pred_labels = torch.max(outputs, 1)[1]\n            preds = preds + pred_labels.tolist()\n\n\n    make_report(y_pred = preds, y_true = trues)\n\nprint('Test')\nres(dataLoader_test)\nprint('validation')\nres(dataLoader_validation)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualization of filters and outputs"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Model(43)\nmodel.load_state_dict(torch.load('./model_gray'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.conv[0]\ndef imshow_filter(img,row,col):\n    print('-------------------------------------------------------------')\n    plt.figure()\n    for i in range(len(filters)):\n        img = filters[i]\n        img = np.transpose(img, (1, 2, 0))\n        img = img/(img.max()-img.min())\n        plt.subplot(row,col,i+1)\n        plt.imshow(img,cmap= 'gray')\n        plt.xticks([])\n        plt.yticks([])\n    plt.show()\n\nprint('layer1')\nfilters = model.conv[0].weight.data.cpu().numpy()\nimshow_filter(filters,8, 4)\n\nprint('layer2')\nfilters = model.conv[3].weight.data.cpu().numpy()[:,0:1,:,:]\nimshow_filter(filters,8, 4)\n\nprint('layer3')\nfilters = model.conv[6].weight.data.cpu().numpy()[:,0:1,:,:]\nimshow_filter(filters,8, 8)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## outputs "},{"metadata":{"trusted":true},"cell_type":"code","source":"#90\nclass VizModel(torch.nn.Module):\n    \n    def __init__(self, num_classes):\n        super().__init__()\n        \n        self.conv = torch.nn.Sequential(\n            torch.nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3, 3)),\n            torch.nn.ReLU(),\n            torch.nn.BatchNorm2d(32),\n            torch.nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(3, 3)),\n            torch.nn.ReLU(),\n            torch.nn.BatchNorm2d(32),\n            torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3)),\n            torch.nn.ReLU(),\n            torch.nn.BatchNorm2d(64),\n        )\n        \n        self.flatten = torch.nn.Sequential(torch.nn.AdaptiveMaxPool2d(1), torch.nn.Flatten())\n        \n        self.fc = torch.nn.Sequential(\n            torch.nn.Linear(64, 512),\n            torch.nn.ReLU(),\n            torch.nn.Linear(512, num_classes)\n        )\n        \n    def forward(self, x):\n        for layer in self.conv:\n            x = layer(x)\n            for i in range(16):\n                img = x.detach().numpy()[0,i:i+1,:,:]\n                img = np.transpose(img, (1, 2, 0))\n                img = img/(img.max()-img.min())+0.001\n                plt.subplot(8,4,i+1)\n                plt.imshow(img,cmap= 'gray')\n                plt.xticks([])\n                plt.yticks([])\n            plt.savefig('./{}.jpg'.format(layer))\n            plt.show()\n\n        x = self.flatten(x) \n        x = self.fc(x)\n        return x\n\nmodel = VizModel(43)\nmodel.load_state_dict(torch.load('./model_gray'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = next(iter(dataLoader_train))\nx = a['x'][4:5,:,:,:]\nmodel(x)\n\nimg = x[0,:,:,:].T\nplt.imshow(img, cmap='gray', vmin=0, vmax=1)\nplt.axis('off')\nplt.savefig('./sign.jpg')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# data Augmentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_pickle('/kaggle/input/traffic-signs-preprocessed/data4.pickle')\nprint('keys:', data.keys())\nprint('train shape:', data['x_train'].shape)\nprint('test shape:', data['x_test'].shape)\nprint('validation shape:', data['x_validation'].shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class MyDataset(torch.utils.data.Dataset):\n    def __init__(self, x, y, num_classes, transform = None):\n        self.x = x\n        self.y = y\n        self.n_class = num_classes\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.x)\n\n    def __getitem__(self, idx):\n#         x=torchvision.transforms.functional.to_tensor(self.x.astype(np.uint8).reshape((32, 32, 1)))\n        \n        augmented = self.transform(image=self.x[idx].reshape((32, 32, 1)))\n        x = augmented['image']\n#         print(x.shape)\n        label_idx = self.y[idx]\n        label = np.zeros(self.n_class)\n        label[label_idx] = 1\n        label = torch.tensor(label)\n#         return {'x': self.x[idx], 'y': label}\n        return {'x': x, 'y': label}\n\ntransform_train = Compose([\n    Blur(blur_limit=3, p=0.1),\n    ShiftScaleRotate(rotate_limit=45, p=0.3),\n    ToTensor()\n])\n\ntransform_test = Compose([\n    ToTensor()\n])\n    \nBATCH_SIZE = 256    \ntrain_dataset = MyDataset(data['x_train'], data['y_train'], 43, transform = transform_train)\ndataLoader_train = torch.utils.data.DataLoader(train_dataset,\n                                               batch_size=BATCH_SIZE,\n                                               shuffle=True)\n\ntest_dataset = MyDataset(data['x_test'], data['y_test'], 43, transform = transform_test)\ndataLoader_test = torch.utils.data.DataLoader(test_dataset,\n                                              batch_size=BATCH_SIZE,\n                                              shuffle=True)\n\nvalidation_dataset = MyDataset(data['x_validation'], data['y_validation'], 43,transform = transform_test)\ndataLoader_validation = torch.utils.data.DataLoader(validation_dataset,\n                                                    batch_size=BATCH_SIZE,\n                                                    shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#90\nclass Model(torch.nn.Module):\n    \n    def __init__(self, num_classes):\n        super().__init__()\n        \n        self.conv = torch.nn.Sequential(\n            torch.nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3, 3)),\n            torch.nn.ReLU(),\n            torch.nn.BatchNorm2d(32),\n            torch.nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(3, 3)),\n            torch.nn.ReLU(),\n            torch.nn.BatchNorm2d(32),\n            torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3)),\n            torch.nn.ReLU(),\n            torch.nn.BatchNorm2d(64),\n        )\n        \n        self.flatten = torch.nn.Sequential(torch.nn.AdaptiveMaxPool2d(1), torch.nn.Flatten())\n        \n        self.fc = torch.nn.Sequential(\n            torch.nn.Linear(64, 512),\n            torch.nn.ReLU(),\n            torch.nn.Linear(512, num_classes)\n        )\n        \n    def forward(self, x):\n        x = self.conv(x)\n        x = self.flatten(x) \n        x = self.fc(x)\n        return x\n    \nmodel = Model(43)\nprint(model)\ncriterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=5e-4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nn_epochs = 3\nprint('started!')\nfor epoch in range(n_epochs):\n    train_batch_loss = 0\n    model.train()\n    for step, batch in enumerate(dataLoader_train):\n        x = batch[\"x\"]\n        y = batch[\"y\"]\n\n        optimizer.zero_grad()\n        outputs = model(x)\n        loss = criterion(outputs, torch.max(y, 1)[1])\n        loss.backward()\n        optimizer.step()\n        train_batch_loss += loss.item()\n        optimizer.step()\n        optimizer.zero_grad()\n\n    test_batch_loss = 0\n    model.eval()\n    with torch.no_grad():\n        for step, batch in enumerate(dataLoader_test):\n            x = batch[\"x\"]\n            y = batch[\"y\"]\n            outputs = model(x)\n            loss = criterion(outputs, torch.max(y, 1)[1])\n            test_batch_loss += loss.item()\n\n    print('epoch {}/{} finished with train loss: {} and test loss: {}'.format(epoch+1, n_epochs,\n                                                                              train_batch_loss / len(dataLoader_train),\n                                                                              test_batch_loss / len(dataLoader_test)))\n    \ntorch.save(model.state_dict(), './model_aug')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def res(dataLoader):  \n    trues = []\n    preds = []\n    model.eval()\n    with torch.no_grad():\n        for step, batch in enumerate(dataLoader):\n            x = batch[\"x\"]\n            y = batch[\"y\"]\n\n            outputs = model(x)\n\n            true_labels = torch.max(y, 1)[1]\n            trues = trues + true_labels.tolist()\n            pred_labels = torch.max(outputs, 1)[1]\n            preds = preds + pred_labels.tolist()\n\n\n    make_report(y_pred = preds, y_true = trues)\n\nprint('Test')\nres(dataLoader_test)\nprint('validation')\nres(dataLoader_validation)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}