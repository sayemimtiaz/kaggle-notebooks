{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Caravan Insurance Challenge  using Random Forest\n#### Author : Rohini Garg","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"-----------------------------------------------------------------------------------------------------","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### *First of all we will have a small introduction about Random Forest*   \n#### What is Random Forest?\n\n *Credit : https://towardsdatascience.com *\n####   It is also called  *random descision forests *. Random forest, like its name implies, consists of a large number of individual decision trees that operate as an ensemble. Each individual tree in the random forest spits out a class prediction and the class with the most votes becomes our model’s prediction\n* **A large number of relatively uncorrelated models (trees) operating as a committee will outperform any of the individual constituent models.**\n* **There needs to be some actual signal in our features so that models built using those features do better than random guessing.**\n\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"*********************************************************************************************","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Objective of  Caravan Insurance Challenge?\n#### Identify potential purchasers of caravan insurance policies","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### About Data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The data file contains the following fields:\n\n* **ORIGIN**: train or test, as described above\n* **MOSTYPE**: Customer Subtype; see L0\n* **MAANTHUI**: Number of houses 1 - 10\n* **MGEMOMV**: Avg size household 1 - 6\n* **MGEMLEEF**: Avg age; see L1\n* **MOSHOOFD**: Customer main type; see L2\n\n************************************************************************\n* ** Percentages in each group, per postal code (see L3)**:\n\n* **MGODRK**: Roman catholic\n* **MGODPR**: Protestant …\n* **MGODOV**: Other religion\n* **MGODGE**: No religion\n* **MRELGE**: Married\n* **MRELSA**: Living together\n* **MRELOV**: Other relation\n* **MFALLEEN**: Singles\n* **MFGEKIND**: Household without children\n* **MFWEKIND**: Household with children\n* **MOPLHOOG**: High level education\n* **MOPLMIDD**: Medium level education\n* **MOPLLAAG**: Lower level education\n* **MBERHOOG**: High status\n* **MBERZELF**: Entrepreneur\n* **MBERBOER**: Farmer\n* **MBERMIDD**: Middle management\n* **MBERARBG**: Skilled labourers\n* **MBERARBO**: Unskilled labourers\n* **MSKA**: Social class A\n* **MSKB1**: Social class B1\n* **MSKB2**: Social class B2\n* **MSKC**: Social class C\n* **MSKD**: Social class D\n* **MHHUUR**: Rented house\n* **MHKOOP**: Home owners\n* **MAUT1**: 1 car\n* **MAUT2**: 2 cars\n* **MAUT0**: No car\n* **MZFONDS**: National Health Service\n* **MZPART**: Private health insurance\n* **MINKM30**: Income < 30.000\n* **MINK3045**: Income 30-45.000\n* **MINK4575**: Income 45-75.000\n* **MINK7512**: Income 75-122.000\n* **MINK123M**: Income >123.000\n* **MINKGEM**: Average income\n* **MKOOPKLA**: Purchasing power class\n************************************************************************\n* ** Total number of variable in postal code (see L4)**:\n\n* **PWAPART**: Contribution private third party insurance\n* **PWABEDR**: Contribution third party insurance (firms) …\n* **PWALAND**: Contribution third party insurane (agriculture)\n* **PPERSAUT**: Contribution car policies\n* **PBESAUT**: Contribution delivery van policies\n* **PMOTSCO**: Contribution motorcycle/scooter policies\n* **PVRAAUT**: Contribution lorry policies\n* **PAANHANG**: Contribution trailer policies\n* **PTRACTOR**: Contribution tractor policies\n* **PWERKT**: Contribution agricultural machines policies\n* **PBROM**: Contribution moped policies\n* **PLEVEN**: Contribution life insurances\n* **PPERSONG**: Contribution private accident insurance policies\n* **PGEZONG**: Contribution family accidents insurance policies\n* **PWAOREG**: Contribution disability insurance policies\n* **PBRAND**: Contribution fire policies\n* **PZEILPL**: Contribution surfboard policies\n* **PPLEZIER**: Contribution boat policies\n* **PFIETS**: Contribution bicycle policies\n* **PINBOED**: Contribution property insurance policies\n* **PBYSTAND**: Contribution social security insurance policies\n* **AWAPART**: Number of private third party insurance 1 - 12\n* **AWABEDR**: Number of third party insurance (firms) …\n* **AWALAND**: Number of third party insurance (agriculture)\n* **APERSAUT**: Number of car policies\n* **ABESAUT**: Number of delivery van policies\n* **AMOTSCO**: Number of motorcycle/scooter policies\n* **AVRAAUT**: Number of lorry policies\n* **AAANHANG**: Number of trailer policies\n* **ATRACTOR**: Number of tractor policies\n* **AWERKT**: Number of agricultural machines policies\n* **ABROM**: Number of moped policies\n* **ALEVEN**: Number of life insurances\n* **APERSONG**: Number of private accident insurance policies\n* **AGEZONG**: Number of family accidents insurance policies\n* **AWAOREG**: Number of disability insurance policies\n* **ABRAND**: Number of fire policies\n* **AZEILPL**: Number of surfboard policies\n* **APLEZIER**: Number of boat policies\n* **AFIETS**: Number of bicycle policies\n* **AINBOED**: Number of property insurance policies\n* **ABYSTAND**: Number of social security insurance policies\n* **CARAVAN**: Number of mobile home policies 0 - 1","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Call libraries","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#1.0 Clear memory\n%reset -f\n\n# 1.1 Call data manipulation libraries\nimport pandas as pd\nimport numpy as np\nfrom scipy.stats import kurtosis, skew\n\n# 1.2 Feature creation Classes\nfrom sklearn.preprocessing import PolynomialFeatures            # Interaction features\nfrom sklearn.preprocessing import KBinsDiscretizer  \n\n\n# 1.3 Data transformation classes\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import LabelEncoder\n\n# Construct a transformer from an arbitrary callable.\nfrom sklearn.preprocessing import FunctionTransformer\n\n# 1.4 Fill missing values\nfrom sklearn.impute import SimpleImputer\n\n\n# 1.5  Pipelines\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\n\n# 1.6 RandomForest modeling\nfrom sklearn.ensemble import RandomForestClassifier \n\n# 1.7 Misc\nimport os, gc\n\n#Graphing\nimport matplotlib.pyplot as plt\nimport plotly.graph_objects as go \nimport plotly.express as px\nfrom matplotlib.colors import LogNorm\nimport seaborn as sns\n\n# to display all outputs of one cell\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\n\n#hide warning\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Set Directory","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"os.chdir('/kaggle/input')\nos.listdir()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfci=pd.read_csv('caravan-insurance-challenge/caravan-insurance-challenge.csv')\ndfci.head()\nprint(\"No of Observatios:\",dfci.shape[0])\nprint(\"No of Features:\",dfci.shape[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfci.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfci.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Check if any NULL value","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dfci.columns[dfci.isnull().any()]\n#no column has null value so need to fix null values\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Check column type","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dfci.dtypes.value_counts()\n#All columns are int 64 except one ,\n\nstr_features = dfci.select_dtypes(include='object').columns\nstr_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets check the unique values of ORIGIN \ndfci['ORIGIN'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#check summary\ndfci.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **split data according to origin**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fetch Train Data\ntrain_data= dfci[dfci['ORIGIN']=='train']\n#drop ORIGIN col from train_data\ntrain_data.drop(['ORIGIN'],axis=1,inplace=True)\n\ntest_data=dfci[dfci['ORIGIN']=='test']\n#drop ORIGIN col from test_data\ntest_data.drop(['ORIGIN'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['CARAVAN'].value_counts().plot(kind='bar', title='CARAVAN Classification Train Data', grid=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data['CARAVAN'].value_counts().plot(kind='bar', title='CARAVAN Classification Test Data', grid=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **Observation**: Number of records are more in train and test data where CARVAN is zero","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Fetch target column values in variable and delete this column from train data ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y = train_data.pop('CARAVAN')\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#check standard deviation.if std() is zero drop that columns\ns= []\ns = [col for col in train_data.columns if train_data[col].std() == 0]\ns\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### we will seperate num and cat columns.Check unique values and seperate accordingly.Set  cat cols unique values < 5","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dg=(train_data.nunique() < 5)\ncat_columns = dg[dg == True].index.tolist()\nnum_columns = dg[dg == False].index.tolist()\nprint(\"No of cat cols\",len(cat_columns))\nprint(\"No of num cols\",len(num_columns))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### let us find out which preprocessing method will be used on numerical data. StandardScaler or RobustScaler???.Draw distplot","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import math\nplt.figure(figsize=(15,18))\nnoofrows= math.ceil(len(num_columns)/3)\nnoofrows\n#set false.Other wise error if  bandwidth =0 \nsns.distributions._has_statsmodels=False\n\nfor i in range(len(num_columns)):\n    plt.subplot(noofrows,3,i+1)\n    out=sns.distplot(train_data[num_columns[i]])\n    \nplt.tight_layout()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*  **There are outliers for most of columns so we will use RobustScaler for num_columns** \n* **OneHotEncoder for cat_columns**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Create Column Transformer\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\nct=ColumnTransformer([\n    ('rs',RobustScaler(),num_columns),\n    ('ohe',OneHotEncoder(),cat_columns),\n    ],\n    remainder=\"passthrough\"\n    )\nct.fit_transform(train_data)\nX=train_data\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### split data in 7:3 ratio so set test size=30","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=.30)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### create Pipeline and fit data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"rf= RandomForestClassifier(oob_score = True,bootstrap=True)\npipe =Pipeline(\n    [\n     ('ct',ct),\n     ('rf',rf)\n    ]\n    )\nrf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Check acuracy","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\npredicted = rf.predict(X_test)\naccuracy = accuracy_score(y_test, predicted)\nprint(\"Accuracy is:\",accuracy)\nprint(\"out-of-bag score computed by sklearn is an estimate of the classification accuracy we might expect to observe on new data\")\nprint(\"Out-of-bag score estimation::\",rf.oob_score_)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### We have good accuracy  but  it does not show us  anything about where we’re doing well.Performance can be  visualising by confusion matrix.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ncm = pd.DataFrame(confusion_matrix(y_test, predicted))\nsns.heatmap(cm, annot=True)\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.title('Predicted vs Actual')\ncm","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"from sklearn.tree import export_graphviz\nimport graphviz\n\nfeature_list=train_data.columns\ntree = rf.estimators_[5]\n# Export  to a dot_data\ndot_data = export_graphviz(tree, out_file=None,\n                     feature_names=train_data.columns,\n                     filled=True, rounded=True,\n                     special_characters=True)\n# Set graph and plot\ngraph = graphviz.Source(dot_data)\ngraph\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Get Feature importance","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimportances = list(rf.feature_importances_)\n\ndffeature_importance=pd.DataFrame({'Feature_Name':feature_list, 'Imporatance':importances})\n\n\n\n# Get which feature has max importance\ndffeature_importance[dffeature_importance['Imporatance'] == dffeature_importance['Imporatance'].max()]\n# Get which feature has max importance\ndffeature_importance[dffeature_importance['Imporatance'] == dffeature_importance['Imporatance'].min()]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" #### Plot Feature importance","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,18))\n\n# list of x locations for plotting\nx_values = list(range(len(importances)))\nplt.tick_params(axis='both', left='off', top='off', right='off', bottom='off', labelleft='off', labeltop='off', labelright='off', labelbottom='off')\n# Make a bar chart\nout=plt.bar(x_values, importances, orientation = 'vertical')\n\n# Tick labels for x axis\nplt.xticks(x_values, feature_list, rotation='vertical')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* * **Observation**:Most important features : PBRAND,PPERSAUT and MOSTYPE,APERSAUT","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}