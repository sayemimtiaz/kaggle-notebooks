{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. Introduction\n\n## 1.1 Premise\n\nA manager at a bank is concerned that more and more customers are leaving the bank's credit card services. \n\nThe bank would really appreciate it if someone could help it predict who is going to churn, so that it can proactively approach such customers to offer better services, and turn them back.\n\n## 1.2 Plan\n\n- Perform **exploratory data analysis** to learn the *properties/characteristics* of the features present.\n- Fit several **classification models** to predict whether a customer will churn or not.\n- Apply *hyper-parameter optimization* techniques.\n- **Evaluate performance** of fitted models.","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nfrom scipy import stats\n\n# Plotting\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\nplt.rc('font', family='serif')\n\n# Preprocessing\nfrom imblearn.over_sampling import RandomOverSampler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder, QuantileTransformer, StandardScaler\n\n# Modelling\nfrom shutil import rmtree\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, roc_auc_score\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.svm import SVC\nfrom tempfile import mkdtemp\nfrom xgboost import XGBClassifier","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-25T12:30:50.056101Z","iopub.execute_input":"2021-08-25T12:30:50.056637Z","iopub.status.idle":"2021-08-25T12:30:52.65766Z","shell.execute_reply.started":"2021-08-25T12:30:50.056594Z","shell.execute_reply":"2021-08-25T12:30:52.656675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the data\ndata = pd.read_csv(\n    '/kaggle/input/credit-card-customers/BankChurners.csv',\n    index_col='CLIENTNUM',\n    na_values=['Unknown']  # interpret \"Unknown\" as missing \n)\ndata.head()","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2021-08-25T12:30:52.659745Z","iopub.execute_input":"2021-08-25T12:30:52.66014Z","iopub.status.idle":"2021-08-25T12:30:52.785182Z","shell.execute_reply.started":"2021-08-25T12:30:52.660106Z","shell.execute_reply":"2021-08-25T12:30:52.784471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Exploratory Data Analysis\n\nThe dataset consists of 10,127 rows and 20 columns.","metadata":{}},{"cell_type":"code","source":"# Drop the last 2 columns as advised in the dataset's description\n# See https://www.kaggle.com/sakshigoyal7/credit-card-customers\ndata = data.iloc[:, :-2]\ndata.info()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-25T12:30:52.786284Z","iopub.execute_input":"2021-08-25T12:30:52.786736Z","iopub.status.idle":"2021-08-25T12:30:52.813878Z","shell.execute_reply.started":"2021-08-25T12:30:52.786698Z","shell.execute_reply":"2021-08-25T12:30:52.812675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.1 Missing Values\n\n`Education_Level`, `Marital_Status` and `Income_Category` have missing values. ","metadata":{}},{"cell_type":"code","source":"# Check for missing values\nmissing = data.isna().sum()\npd.DataFrame({\n    'No. of missing values': missing,\n    '% missing': missing.apply(lambda x: f'{x/len(data):.2%}')\n}).style.bar()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-25T12:30:52.815651Z","iopub.execute_input":"2021-08-25T12:30:52.815978Z","iopub.status.idle":"2021-08-25T12:30:52.966625Z","shell.execute_reply.started":"2021-08-25T12:30:52.815947Z","shell.execute_reply":"2021-08-25T12:30:52.965552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Strategy for Handling Missing Values\n\nA common and straight-forward way of dealing with missing values is to *drop affected rows or columns*. The advantage of this is that you'll be left with genuine, unaltered data. The disadvantage is that you lose some data; which is especially undesirable if the dataset is small, or large proportions of its values are missing.\n\nAnother common tactic is *imputation*, which involves determining values to fill in the blanks. The advantage here is that no data is thrown out. But then, depending on the method used, the imputed values might be misleading.\n\nRemoving rows with missing values would in this case leave only 7,081 rows for modelling. That is rather small, so we'll use imputation to get as much of the data as possible. This will be implemented as a component in the model fitting pipeline.","metadata":{}},{"cell_type":"markdown","source":"## 2.2 Numeric Features\n\nThere are 14 numeric features.","metadata":{}},{"cell_type":"code","source":"numeric_cols = data.select_dtypes(include=\"number\")\nnumeric_cols.describe()","metadata":{"execution":{"iopub.status.busy":"2021-08-25T12:30:52.971493Z","iopub.execute_input":"2021-08-25T12:30:52.971814Z","iopub.status.idle":"2021-08-25T12:30:53.038208Z","shell.execute_reply.started":"2021-08-25T12:30:52.97178Z","shell.execute_reply":"2021-08-25T12:30:53.036825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.2.1 Histograms","metadata":{}},{"cell_type":"code","source":"# Plot histograms of the numeric columns\nhistograms = numeric_cols.hist(figsize=(14, 12))","metadata":{"_kg_hide-output":false,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-25T12:30:53.040401Z","iopub.execute_input":"2021-08-25T12:30:53.040831Z","iopub.status.idle":"2021-08-25T12:30:56.594114Z","shell.execute_reply.started":"2021-08-25T12:30:53.040785Z","shell.execute_reply":"2021-08-25T12:30:56.592793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":">`Credit_Limit`, `Avg_Open_To_Buy`, `Total_Amt_Chng_Q4_Q1`, `Total_Trans_Amt`, `Total_Ct_Chng_Q4_Q1` and `Avg_Utilization_Ratio` are skewed to the right (positively skewed).\n\n>`Total_Revolving_Bal` has a curious peak close to the origin, which is investigated below:","metadata":{}},{"cell_type":"code","source":"total_rev_bal = data['Total_Revolving_Bal'].value_counts()\nprint(\n    f'A very large number of customers ({total_rev_bal[0]:,}) have '\n    '\"Total_Revolving_Bal\" == 0.',\n    total_rev_bal.nlargest(5),  # top 5 frequencies\n    '\\nFrequencies of the first 5 values confirm that the peak is specifically at 0:',\n    total_rev_bal.sort_index().head(),\n    sep=\"\\n\"\n)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-25T12:30:56.596218Z","iopub.execute_input":"2021-08-25T12:30:56.596863Z","iopub.status.idle":"2021-08-25T12:30:56.61628Z","shell.execute_reply.started":"2021-08-25T12:30:56.596817Z","shell.execute_reply":"2021-08-25T12:30:56.615215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.2.2 Box-plots","metadata":{}},{"cell_type":"code","source":"_ = numeric_cols.plot(kind=\"box\", subplots=True, layout=(5, 3), figsize=(12, 20))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-25T12:30:56.617821Z","iopub.execute_input":"2021-08-25T12:30:56.61825Z","iopub.status.idle":"2021-08-25T12:30:58.38891Z","shell.execute_reply.started":"2021-08-25T12:30:56.618215Z","shell.execute_reply":"2021-08-25T12:30:58.387965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> `Credit_Limit`, `Avg_Open_To_Buy`, `Total_Amt_Chng_Q4_Q1`, `Total_Trans_Amt` and `Total_Ct_Chng_Q4_Q1` have a very large number of outliers.\n>\n> The `QuantileTransformer` can be used to normalize them.","metadata":{}},{"cell_type":"markdown","source":"### 2.2.3 Normal Probability Plots","metadata":{}},{"cell_type":"code","source":"# Plot probability plots (qq-plots)\nfig, axes = plt.subplots(nrows=5, ncols=3, figsize=(12, 18))\n\nfig.tight_layout(h_pad=5)  # Add padding to sub-plots\n\nfor col, ax in zip(numeric_cols.columns, axes.flatten()):\n    stats.probplot(numeric_cols[col], dist='norm', plot=ax)\n    ax.set_title(col)\n\nfig.delaxes(axes[-1, -1])  # Remove 15th (last) axes which has no content","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-25T12:30:58.390518Z","iopub.execute_input":"2021-08-25T12:30:58.390825Z","iopub.status.idle":"2021-08-25T12:31:03.199017Z","shell.execute_reply.started":"2021-08-25T12:30:58.390794Z","shell.execute_reply":"2021-08-25T12:31:03.197622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- `Customer_Age`, `Dependent_count`, `Months_on_book` and `Total_Trans_Ct` are somewhat normally distributed, which is good.","metadata":{}},{"cell_type":"markdown","source":"## 2.3 Categorical Features\n\nThere are 5 categorical features. The target variable `Attrition_Flag` is also categorical.","metadata":{}},{"cell_type":"code","source":"categorical_cols = data.select_dtypes(include='O')\ncategorical_cols.describe()","metadata":{"execution":{"iopub.status.busy":"2021-08-25T12:31:03.201164Z","iopub.execute_input":"2021-08-25T12:31:03.201699Z","iopub.status.idle":"2021-08-25T12:31:03.261799Z","shell.execute_reply.started":"2021-08-25T12:31:03.201647Z","shell.execute_reply":"2021-08-25T12:31:03.260523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.3.1 Count-plots","metadata":{}},{"cell_type":"code","source":"# Plot countplots of categorical columns\nfig, axes = plt.subplots(nrows=3, ncols=2, figsize=(12, 14))\n\nfor col, ax in zip(categorical_cols.drop('Attrition_Flag', 1), axes.flatten()):\n    sns.countplot(data=categorical_cols, x=col, hue='Attrition_Flag', ax=ax)\n    ax.tick_params(axis='x', rotation=45)\n    ax.set_title(col, size=14)\n    \nfig.delaxes(axes[-1, -1])  # Drop 6th (last) axes as it has no content\nplt.tight_layout()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-25T12:31:03.263828Z","iopub.execute_input":"2021-08-25T12:31:03.26433Z","iopub.status.idle":"2021-08-25T12:31:04.737286Z","shell.execute_reply.started":"2021-08-25T12:31:03.264277Z","shell.execute_reply":"2021-08-25T12:31:04.736425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Modelling & Prediction\n\nLet's now attempt to fit several classification models to predict whether a customer will leave.\n\nThe target variable - `Attrition_Flag` - is heavily imbalanced, with one class having significantly higher occurences than the rest.","metadata":{}},{"cell_type":"code","source":"_ = sns.countplot(x=categorical_cols['Attrition_Flag'])","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-25T12:31:04.738761Z","iopub.execute_input":"2021-08-25T12:31:04.739303Z","iopub.status.idle":"2021-08-25T12:31:04.884375Z","shell.execute_reply.started":"2021-08-25T12:31:04.739261Z","shell.execute_reply":"2021-08-25T12:31:04.88316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> There exist strategies for handling such situations, some of which can be implemented using the [imbalanced-learn][1] package.\n\n> In this case, we'll use [Randomized over-sampling][2].\n\n[1]: https://imbalanced-learn.org/stable/user_guide.html\n[2]: https://imbalanced-learn.org/stable/over_sampling.html#naive-random-over-sampling","metadata":{}},{"cell_type":"code","source":"# Select the features and target\nX = data.drop('Attrition_Flag', axis=1)\ny = data['Attrition_Flag']\n\n# Prepare a training and a test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n\n\n# Preprocessing pipeline for numeric cols\nnumeric_pipe = Pipeline([\n    ('normalize', QuantileTransformer(output_distribution='normal')),\n    ('rescale', StandardScaler())\n])\n\n# Preprocessing pipeline for categorical cols\ncategorical_pipe = Pipeline([\n    ('impute', SimpleImputer(strategy='most_frequent')),\n    ('encode', OneHotEncoder())\n])\n\n# Combined preprocessing pipeline\nextract_features = ColumnTransformer([\n    ('numeric', numeric_pipe, numeric_cols.columns),\n    ('categorical', categorical_pipe, categorical_cols.columns.drop('Attrition_Flag'))\n])\n\n# Apply random oversampling to training data to counteract target class imbalance\nrandom_oversampler = RandomOverSampler(random_state=0)\nX_resampled, y_resampled = random_oversampler.fit_resample(X_train, y_train)\n\n\ndef fit_and_evaluate(classifier, params=None):\n    \"\"\"Fit a classification model and print metrics.\n    \n    Parameters\n    ----------\n    classifier: sklearn predictor instance\n        The model to fit.\n    params: dict\n        A dictionary of hyper-parameter values to pass to GridSearchCV \n        for model tuning.\n    \n    Returns\n    -------\n    sklearn predictor\n        The model with hyper-parameters yielding the highest cross-validated score.\n    \"\"\"\n    cache_dir = mkdtemp()\n    pipe = Pipeline(\n        [('features', extract_features), ('classifier', classifier)],\n        memory=cache_dir\n    )\n    \n    params = params or {} # use empty dict if params not provided\n    \n    model = GridSearchCV(estimator=pipe, param_grid=params, scoring='roc_auc',\n                         n_jobs=2, cv=4, verbose=1)\n    model.fit(X_resampled, y_resampled)\n\n    rmtree(cache_dir)\n    print(\n        f'\\nCross Validation AUC: {model.best_score_:.4f}',\n        '\\nClassification Report (on test data):\\n' + '-'*58,\n        classification_report(model.predict(X_test), y_test),\n        sep='\\n'\n    )\n    \n    return model.best_estimator_","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-25T12:39:26.868729Z","iopub.execute_input":"2021-08-25T12:39:26.869371Z","iopub.status.idle":"2021-08-25T12:39:26.955098Z","shell.execute_reply.started":"2021-08-25T12:39:26.8693Z","shell.execute_reply":"2021-08-25T12:39:26.953813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.1 Random Forest Classifier","metadata":{}},{"cell_type":"code","source":"clf = RandomForestClassifier(random_state=7)\nparams = {'classifier__max_depth': range(3, 8),\n          'classifier__n_estimators': [100, 200],\n          'classifier__class_weight': [\"balanced\", \"balanced_subsample\"]}\n\nrf_model = fit_and_evaluate(clf, params)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T12:31:04.984873Z","iopub.execute_input":"2021-08-25T12:31:04.98516Z","iopub.status.idle":"2021-08-25T12:32:32.389919Z","shell.execute_reply.started":"2021-08-25T12:31:04.985132Z","shell.execute_reply":"2021-08-25T12:32:32.388434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.2 Gradient Boosting Classifier","metadata":{}},{"cell_type":"code","source":"clf = XGBClassifier(learning_rate=0.02, random_state=0, subsample=0.8)\nparams = {'classifier__max_depth': range(3, 7),\n          'classifier__reg_lambda': np.logspace(0, 3, 4),\n          'classifier__n_estimators': [100, 250]}\n\ngb_model = fit_and_evaluate(clf, params)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T12:32:32.391931Z","iopub.execute_input":"2021-08-25T12:32:32.392307Z","iopub.status.idle":"2021-08-25T12:36:04.003478Z","shell.execute_reply.started":"2021-08-25T12:32:32.39227Z","shell.execute_reply":"2021-08-25T12:36:04.002284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.3 Support Vector Classifier","metadata":{}},{"cell_type":"code","source":"clf = SVC(class_weight='balanced', random_state=0)\nparams = {'classifier__C': np.logspace(0, 4, 10)}\n\nsvc_model = fit_and_evaluate(clf, params)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T12:36:04.008718Z","iopub.execute_input":"2021-08-25T12:36:04.009262Z","iopub.status.idle":"2021-08-25T12:37:34.024961Z","shell.execute_reply.started":"2021-08-25T12:36:04.009215Z","shell.execute_reply":"2021-08-25T12:37:34.023367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.4 Logistic Regression","metadata":{}},{"cell_type":"code","source":"clf = LogisticRegression(random_state=2, class_weight='balanced')\nparams = {'classifier__C': np.logspace(0, 4, 10)}\n\nlr_model = fit_and_evaluate(clf, params)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T12:39:35.583595Z","iopub.execute_input":"2021-08-25T12:39:35.583953Z","iopub.status.idle":"2021-08-25T12:39:51.71943Z","shell.execute_reply.started":"2021-08-25T12:39:35.583923Z","shell.execute_reply":"2021-08-25T12:39:51.718008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Conclusion\n\nAmong the models tested above, the `XGBClassifier` seems the most promising.\n\nLet's visualise sample predictions to check if the predictions from the various models are consistent:","metadata":{}},{"cell_type":"code","source":"sample = X.sample(25, random_state=5)\n\nresults = pd.DataFrame({\n    'Random Forest Classifier': rf_model.predict(sample),\n    'Gradient Boosting Classifier': gb_model.predict(sample),\n    'Support Vector Classifier': svc_model.predict(sample),\n    'Logistic Regression': lr_model.predict(sample)\n})\n\n\ndef color_code(cell):\n    \"\"\"Set a DataFrame cell's background color according to its value.\"\"\"\n    if cell == 'Existing Customer':\n        color = 'aqua'\n    elif cell == 'Attrited Customer':\n        color = 'orangered'\n    return f'background-color: {color}'\n\nresults.style.applymap(color_code)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-25T12:37:50.642753Z","iopub.execute_input":"2021-08-25T12:37:50.643164Z","iopub.status.idle":"2021-08-25T12:37:50.786535Z","shell.execute_reply.started":"2021-08-25T12:37:50.643133Z","shell.execute_reply":"2021-08-25T12:37:50.785521Z"},"trusted":true},"execution_count":null,"outputs":[]}]}