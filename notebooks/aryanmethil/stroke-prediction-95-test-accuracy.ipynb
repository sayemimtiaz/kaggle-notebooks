{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing Libraries","metadata":{}},{"cell_type":"code","source":"import joblib\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\nimport numpy as np\nfrom sklearn import metrics\nfrom sklearn import tree\nfrom xgboost import XGBClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nimport warnings\nwarnings.filterwarnings('ignore')\nwarnings.simplefilter('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating 5 <b>Stratified K Fold cross validation</b> sets for better testing","metadata":{}},{"cell_type":"code","source":"TRAINING_PATH='../input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv'\n\ndf=pd.read_csv(TRAINING_PATH)\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAINING_FOLDS_PATH='./'\n\nimport pandas as pd\n\ndf_train=pd.read_csv(TRAINING_PATH)\ndf_train.head()\n\ndf_train['stroke'].value_counts()\n\ndf_train['kfolds']=-1\ndf_train=df_train.sample(frac=1).reset_index(drop=True)\ndf_train.head()\n\nfrom sklearn import model_selection\n\nstrat_kf=model_selection.StratifiedKFold(n_splits=5)\n\nfor fold,(trn_,val_) in enumerate(strat_kf.split(X=df_train,y=df_train['stroke'])):\n  df_train.loc[val_,'kfolds']=fold\ndf_train.head()\n\ndf_train.to_csv(TRAINING_FOLDS_PATH+'train_folds.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ðŸ“‹<b>Data Exploration</b>\n","metadata":{}},{"cell_type":"code","source":"TRAINING_PATH='./train_folds.csv'\nMODEL_PATH='./'\nSUBMISSION_FILES_PATH='./Submissions/'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv(TRAINING_PATH)\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Handling Null Values","metadata":{}},{"cell_type":"code","source":"df.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### As we can see that BMI has 201 null values out of a total of 5110 which need to be handled. Null values can be handled by either dropping those rows entirely or by replacing them with a constant value like mean, median or mode. I proceeded with replacing the NaNs with the mean value.","metadata":{}},{"cell_type":"code","source":"df['bmi'].fillna(int(df['bmi'].mean()),inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.drop(['Unnamed: 0'],axis=1)\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Total number of unique values in each column\ndf.nunique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Scaling the Continuous Variables using <b>MinMaxScaler</b>","metadata":{}},{"cell_type":"code","source":"# Checking for any numerical data. If present, it has to be scaled etc.\n\ncolumns = df.columns\nnumerical_columns = df._get_numeric_data().columns\nnumerical_columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler=MinMaxScaler()\ndf_2 = df.loc[:,['age','avg_glucose_level','bmi']]\ndf.loc[:,df_2.columns] = pd.DataFrame(scaler.fit_transform(df_2),index=df.index,columns=df_2.columns)\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nsns.set_theme(style=\"darkgrid\")\nax = sns.countplot(x=\"smoking_status\", data=df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Handling the Categorical Features\n\n### 1. Features like smoking_status, gender, work_type and Residence_type have to be <b>One Hot Encoded</b> since they don't denote any Ordinal data (ie. the values don't denote any rank)\n### 2. The ever_married feature can be <b>Label Encoded</b> as the value is either Yes or No so we can encode them as 1 and 0 respectively.","metadata":{}},{"cell_type":"code","source":"# One hot encode the categorical columns - smoking_status\n\ndf=pd.get_dummies(data=df,columns=['smoking_status','gender','work_type','Residence_type'])\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Move the target and kfolds column to the last\n\ndf=df[[column for column in df if column not in['stroke','kfolds']]+['stroke','kfolds']]\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['ever_married'] = df['ever_married'].replace({'No':0,'Yes':1})\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# âœ… Let's choose the optimal features from the dataset using some <b>Feature Selection</b> techniques","metadata":{}},{"cell_type":"markdown","source":"### <b>Greedy Feature Selection</b> - After choosing a model and scoring function (here, accuracy); we take a feature iteratively and if that feature improves the score then only it is kept in our optimal feature dataset. Hence, the optimal dataset can be different for different models.\n\n### <b>Models Considered:</b>\n### 1. XGBoost Classifier\n### 2. Random Forest Classifier\n### 3. Decision Tree Classifier\n#### Note: SVM Classifier was taking time for feature Selection so the entire dataset was considered the optimal dataset for SVM","metadata":{}},{"cell_type":"code","source":"def run(fold,df,models,target_name, save_model, print_details=False):\n  \n  # print(df.head())\n  # Training and validation sets\n  df_train=df[df['kfolds']!=fold].reset_index(drop=True)\n  df_valid=df[df['kfolds']==fold].reset_index(drop=True)\n\n\n  # x and y of training dataset\n  x_train=df_train.drop(target_name,axis=1).values\n  y_train=df_train[target_name].values\n\n  # x and y of validation dataset\n  x_valid=df_valid.drop(target_name,axis=1).values\n  y_valid=df_valid[target_name].values\n\n  # accuracy => will store accuracies of the models  (same for confusion_matrices)\n  accuracy=[]\n  confusion_matrices=[]\n  classification_report=[]\n\n  for model_name,model_constructor in list(models.items()):\n    clf=model_constructor\n    clf.fit(x_train,y_train)\n\n    # preds_train, preds_valid => predictions when training and validation x are fed into the trained model\n    preds_train=clf.predict(x_train)\n    preds_valid=clf.predict(x_valid)\n\n    acc_train=metrics.accuracy_score(y_train,preds_train)\n    acc_valid=metrics.accuracy_score(y_valid,preds_valid)\n\n    f1_train = metrics.f1_score(y_train,preds_train)\n    f1_valid = metrics.f1_score(y_valid,preds_valid)\n\n    conf_matrix=metrics.confusion_matrix(y_valid,preds_valid)\n    class_report=metrics.classification_report(y_valid,preds_valid)\n\n    accuracy.append(acc_valid)\n    confusion_matrices.append(conf_matrix)\n    classification_report.append(class_report)\n\n    if(print_details==True):\n      print(f'Model => {model_name} => Fold = {fold} => Training Accuracy = {acc_train} => Validation Accuracy = {acc_valid}')\n\n    if(save_model==True):\n      joblib.dump(clf, f\"{MODEL_PATH}{model_name}_F1_{f1_valid}_ACC_{acc_valid}_FOLD_{fold}.bin\")\n\n  if(print_details==True):\n    print('\\n--------------------------------------------------------------------------------------------\\n')\n    \n  return accuracy,confusion_matrices,classification_report","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def greedy_feature_selection(fold,df,models,target_name):\n\n  # target_index => stores the index of the target variable in the dataset\n  # kfolds_index => stores the index of kfolds column in the dataset\n\n  target_index=df.columns.get_loc(target_name)\n  kfolds_index=df.columns.get_loc('kfolds')\n\n  # good_features => stores the indices of all the optimal features\n  # best_scores => keeps track of the best scores \n  good_features=[]\n  best_scores=[]\n\n  # df has X and y and a kfolds column. \n  # no of features (no of columns in X) => total columns in df - 1 (there's 1 y) - 1 (there's 1 kfolds)\n  num_features=df.shape[1]-2\n\n  while True:\n\n    # this_feature => the feature added to the already selected features to measure the effect of the former on the model\n    # best_score => keeps track of the best score achieved while selecting features 1 at a time and checking its effect on the model\n    this_feature=None\n    best_score=0\n\n\n    for feature in range(num_features):\n\n      # if the feature is already in the good_features list, ignore and move ahead\n      if feature in good_features:\n        continue\n      \n      # add the currently selected feature to the already discovered good features\n      selected_features=good_features+[feature]\n\n      # all the selected features + target and kfolds column\n      df_train=df.iloc[:, selected_features + [target_index,kfolds_index]]\n\n      # fit the selected dataset to a model \n      accuracy,confusion_matrices,classification_report=run(fold,df_train,models,save_model= False, target_name=target_name)\n\n      # if any improvement is observed over the previous set of features\n      if(accuracy[0]>best_score):\n        this_feature=feature\n        best_score=accuracy[0]\n      \n    if(this_feature!=None):\n      good_features.append(this_feature)\n      best_scores.append(best_score)\n    \n    if(len(best_scores)>2):\n      if(best_scores[-1]<best_scores[-2]):\n        break\n    \n  return best_scores[:-1] , df.iloc[:, good_features[:-1] + [target_index,kfolds_index]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1. XGBoost Classifier","metadata":{}},{"cell_type":"code","source":"print('Greedy Feature Selection : ')\nprint('\\n')\nmodels={'XGB': XGBClassifier()}\nbest_scores,df_optimal_XGB=greedy_feature_selection(fold=4,df=df,models=models,target_name='stroke')\nprint(df_optimal_XGB.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2. Random Forest Classifier","metadata":{}},{"cell_type":"code","source":"models={'RFC' : RandomForestClassifier()}\nbest_scores,df_optimal_RFC=greedy_feature_selection(fold=4,df=df,models=models,target_name='stroke')\nprint(df_optimal_RFC.head())\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3. Decision Tree Classifier","metadata":{}},{"cell_type":"code","source":"models={'DT' : DecisionTreeClassifier()}\nbest_scores,df_optimal_DT=greedy_feature_selection(fold=4,df=df,models=models,target_name='stroke')\nprint(df_optimal_DT.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ðŸ”Ž Finding the best hyperparameters for the models using Optuna Library for <b>Hyperparameter Tuning</b>\n\n### <b>Models Considered:</b>\n### 1. XGBoost Classifier\n### 2. Random Forest Classifier\n### 3. Decision Tree Classifier\n### 4. SVM Classifier\n### -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------","metadata":{}},{"cell_type":"markdown","source":"### 1. Random Forest Classifier","metadata":{}},{"cell_type":"code","source":"import optuna\nfrom functools import partial\n\ndef optimize_rfc(trial,df,total_folds,target_name):\n    criterion = trial.suggest_categorical(\"criterion\", ['gini','entropy'])\n    n_estimators = trial.suggest_int('n_estimators', 100, 1500)\n    max_depth = trial.suggest_int(\"max_depth\", 3, 30)\n    max_features = trial.suggest_uniform(\"max_features\", 0.01, 1.0)\n    min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 10)\n    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 100)\n    \n    model = RandomForestClassifier(\n        n_estimators = n_estimators, \n        max_depth = max_depth, \n        max_features = max_features, \n        min_samples_leaf = min_samples_leaf,\n        min_samples_split = min_samples_split,\n        criterion = criterion\n    )\n    \n    accuracies = []\n    \n    for fold in range(total_folds):\n        \n        df_train=df[df['kfolds']!=fold].reset_index(drop=True)\n        df_valid=df[df['kfolds']==fold].reset_index(drop=True)\n\n\n        # x and y of training dataset\n        x_train=df_train.drop(target_name,axis=1).values\n        y_train=df_train[target_name].values\n\n        # x and y of validation dataset\n        x_valid=df_valid.drop(target_name,axis=1).values\n        y_valid=df_valid[target_name].values\n        \n        model.fit(x_train, y_train)\n        preds= model.predict(x_valid)\n        \n        fold_acc = metrics.accuracy_score(y_valid, preds)\n        accuracies.append(fold_acc)\n        \n    return np.mean(accuracies)\n\noptimization_function_rfc = partial(optimize_rfc, df = df_optimal_RFC, total_folds = 5,target_name = 'stroke')\nstudy_rfc = optuna.create_study(direction = 'maximize')\nstudy_rfc.optimize(optimization_function_rfc, n_trials=15)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rfc_best_params = study_rfc.best_trial.params\nrfc_best_params","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2. XGBoost Classifier","metadata":{}},{"cell_type":"code","source":"def optimize_xgb(trial,df,total_folds,target_name):\n    \n    learning_rate = trial.suggest_uniform(\"learning_rate\", 0.01, 1.0)\n    gamma = trial.suggest_uniform(\"gamma\", 0.05, 1.0)\n    max_depth = trial.suggest_int(\"max_depth\", 3, 30)\n    min_child_weight = trial.suggest_int(\"min_child_weight\", 1, 10)\n    subsample = trial.suggest_uniform(\"subsample\", 0.5, 1.0)\n    colsample_bytree = trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0)\n    reg_lambda = trial.suggest_uniform(\"reg_lambda\", 0.01, 1.0)\n    reg_alpha = trial.suggest_uniform(\"reg_alpha\", 0.01, 1.0)\n    \n    model = XGBClassifier(\n        learning_rate = learning_rate,\n        gamma = gamma,\n        max_depth = max_depth,\n        min_child_weight = min_child_weight,\n        subsample = subsample,\n        colsample_bytree = colsample_bytree,\n        reg_lambda = reg_lambda,\n        reg_alpha = reg_alpha\n    )\n    \n    accuracies = []\n    \n    for fold in range(total_folds):\n        \n        df_train=df[df['kfolds']!=fold].reset_index(drop=True)\n        df_valid=df[df['kfolds']==fold].reset_index(drop=True)\n\n\n        # x and y of training dataset\n        x_train=df_train.drop(target_name,axis=1).values\n        y_train=df_train[target_name].values\n\n        # x and y of validation dataset\n        x_valid=df_valid.drop(target_name,axis=1).values\n        y_valid=df_valid[target_name].values\n        \n        model.fit(x_train, y_train)\n        preds= model.predict(x_valid)\n        \n        fold_acc = metrics.accuracy_score(y_valid, preds)\n        accuracies.append(fold_acc)\n        \n    return np.mean(accuracies)\n\noptimization_function_xgb = partial(optimize_xgb, df = df_optimal_XGB, total_folds = 5,target_name = 'stroke')\nstudy_xgb = optuna.create_study(direction = 'maximize')\nstudy_xgb.optimize(optimization_function_xgb, n_trials=15)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_best_params = study_xgb.best_trial.params\nxgb_best_params","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3. SVM Classifier","metadata":{}},{"cell_type":"code","source":"def optimize_svc(trial,df,total_folds,target_name):\n    \n    C = trial.suggest_uniform(\"C\", 0.001, 1000)\n    gamma = trial.suggest_categorical(\"gamma\", ['auto'])\n    class_weight = trial.suggest_categorical(\"class_weight\", ['balanced'])\n    \n    model = SVC(\n        C = C,\n        gamma = gamma,\n        class_weight = class_weight\n    )\n    \n    accuracies = []\n    \n    for fold in range(total_folds):\n        \n        df_train=df[df['kfolds']!=fold].reset_index(drop=True)\n        df_valid=df[df['kfolds']==fold].reset_index(drop=True)\n\n\n        # x and y of training dataset\n        x_train=df_train.drop(target_name,axis=1).values\n        y_train=df_train[target_name].values\n\n        # x and y of validation dataset\n        x_valid=df_valid.drop(target_name,axis=1).values\n        y_valid=df_valid[target_name].values\n        \n        model.fit(x_train, y_train)\n        preds= model.predict(x_valid)\n        \n        fold_acc = metrics.accuracy_score(y_valid, preds)\n        accuracies.append(fold_acc)\n        \n    return np.mean(accuracies)\n\noptimization_function_svc = partial(optimize_svc, df = df, total_folds = 5,target_name = 'stroke')\nstudy_svc = optuna.create_study(direction = 'maximize')\nstudy_svc.optimize(optimization_function_svc, n_trials=15)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"svc_best_params = study_svc.best_trial.params\nsvc_best_params","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4. Decision Tree Classifier","metadata":{}},{"cell_type":"code","source":"def optimize_dt(trial,df,total_folds,target_name):\n    criterion = trial.suggest_categorical(\"criterion\", ['gini','entropy'])\n    max_depth = trial.suggest_int(\"max_depth\", 3, 30)\n    max_features = trial.suggest_uniform(\"max_features\", 0.01, 1.0)\n    min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 10)\n    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 100)\n    \n    model = DecisionTreeClassifier(\n        max_depth = max_depth, \n        max_features = max_features, \n        min_samples_leaf = min_samples_leaf,\n        min_samples_split = min_samples_split,\n        criterion = criterion\n    )\n    \n    accuracies = []\n    \n    for fold in range(total_folds):\n        \n        df_train=df[df['kfolds']!=fold].reset_index(drop=True)\n        df_valid=df[df['kfolds']==fold].reset_index(drop=True)\n\n\n        # x and y of training dataset\n        x_train=df_train.drop(target_name,axis=1).values\n        y_train=df_train[target_name].values\n\n        # x and y of validation dataset\n        x_valid=df_valid.drop(target_name,axis=1).values\n        y_valid=df_valid[target_name].values\n        \n        model.fit(x_train, y_train)\n        preds= model.predict(x_valid)\n        \n        fold_acc = metrics.accuracy_score(y_valid, preds)\n        accuracies.append(fold_acc)\n        \n    return np.mean(accuracies)\n\noptimization_function_dt = partial(optimize_dt, df = df_optimal_DT, total_folds = 5,target_name = 'stroke')\nstudy_dt = optuna.create_study(direction = 'maximize')\nstudy_dt.optimize(optimization_function_dt, n_trials=15)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dt_best_params = study_dt.best_trial.params\ndt_best_params","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Now its time to Run the Models with their best hyperparameters!","metadata":{}},{"cell_type":"code","source":"XGB_model=XGBClassifier(**xgb_best_params)\nSVM_model=SVC(**svc_best_params)\nRFC_model=RandomForestClassifier(**rfc_best_params)\nDT_model=DecisionTreeClassifier(**dt_best_params)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models={\n    'Random Forest Classifier' : RFC_model\n    }\n\naccuracies,confusion_matrices,classification_reports=[],[],[]\nfor f in range(5):\n  accuracy,confusion_matrix,classification_report=run(f,df_optimal_RFC,models=models,target_name='stroke', save_model= True, print_details=True)\n  accuracies.append(accuracy)\n  confusion_matrices.append(confusion_matrix)\n  classification_reports.append(classification_report)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models={\n    'Decision Tree Classifier' : DT_model\n    }\n\naccuracies,confusion_matrices,classification_reports=[],[],[]\nfor f in range(5):\n  accuracy,confusion_matrix,classification_report=run(f,df_optimal_DT,models=models,target_name='stroke', save_model= True, print_details=True)\n  accuracies.append(accuracy)\n  confusion_matrices.append(confusion_matrix)\n  classification_reports.append(classification_report)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models={\n    'SVM Classifier' : SVM_model\n    }\n\naccuracies,confusion_matrices,classification_reports=[],[],[]\nfor f in range(5):\n  accuracy,confusion_matrix,classification_report=run(f,df,models=models,target_name='stroke', save_model= True, print_details=True)\n  accuracies.append(accuracy)\n  confusion_matrices.append(confusion_matrix)\n  classification_reports.append(classification_report)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models={\n    'XGB Classifier' : XGB_model\n    }\n\naccuracies,confusion_matrices,classification_reports=[],[],[]\nfor f in range(5):\n  accuracy,confusion_matrix,classification_report=run(f,df_optimal_XGB,models=models,target_name='stroke', save_model= True, print_details=True)\n  accuracies.append(accuracy)\n  confusion_matrices.append(confusion_matrix)\n  classification_reports.append(classification_report)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion:\n\n## Random Forest, Decision Tree and XGBoost Classifier all performed relatively same with their accuracies being 95% for both train and validation set. Hence no overfitting was observed.\n## SVM had an accuracy of 94% on the validation set. This (slightly lower accuracy than the other 3 models) could be attributed to the fact that feature selection could not be applied because of time constraint. However, an important thing to note is that there was a bit of overfitting here as training accuracy was surprisingly 100% but validation accuracy was 94%. ","metadata":{}},{"cell_type":"markdown","source":"## If you like my work, an upvote would be great!","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}