{"cells":[{"metadata":{},"cell_type":"markdown","source":"Since the beging of the Covid-19 pandemic a large number of people from different locations around the world have tweeted about it.\nThese tweets were collected using Twitter API and a Python script.In this kernel let's try to understand the pattern of tweets from different locations around the world.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F769452%2F35db2dd68238bfd958efdabebc9fef8f%2Fcovid-19-4961257_1280-e1586986896105.jpg?generation=1595760042647275&alt=media)","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"!pip install https://github.com/elyase/geotext/archive/master.zip\n!pip install topojson\n    ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"!pip install country_converter --upgrade\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Import Required Libraries","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nfrom geotext import GeoText\nimport json\nimport topojson\nimport country_converter as coco\nfrom nltk.stem import LancasterStemmer, SnowballStemmer, RegexpStemmer, WordNetLemmatizer \n#this was part of the NLP notebook\nimport nltk\nnltk.download('punkt')\n#import sentence tokenizer\nfrom nltk import sent_tokenize\n#import word tokenizer\nfrom nltk import word_tokenize\n#list of stopwords\nfrom nltk.corpus import stopwords\nimport string\n#import geograpy\nimport emoji\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nfrom wordcloud import WordCloud,STOPWORDS","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"covid_df=pd.read_csv('../input/covid19-tweets/covid19_tweets.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Location Analysis","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"covid_df.head(\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"covid_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"Location_count=pd.DataFrame(covid_df['user_location'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets take a look at the number of twwets from different locations around the world","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"Location_count.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"Location_count.reset_index(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"Location_count.rename(columns={'index':'Location','user_location':'count'},inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"Location_count.sort_values(by='count',inplace=True,ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#Location_count","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The information is a bit confusing since the locations treat countries and cities similarly","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"Count_graph=px.bar(x='count',y='Location',data_frame=Location_count[:15],color='Location')\nCount_graph.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Location_count.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"location=Location_count.loc[2]['Location']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We'll use GeoText to extract the country which city belongs to , so that we can get a picture of number of tweets from each countries","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"print(GeoText(location).countries)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"Location_country=Location_count.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"Location_country['Location']=Location_country['Location'].apply(lambda x:x.replace(',',' '))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#Location_country","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"Location_country['Location']=Location_country['Location'].apply(lambda x:(GeoText(x).country_mentions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"Location_country.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"Location_country.drop(Location_country[Location_country['Location']=='[]'].index,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"Location_country['Location']=Location_country['Location'].apply(lambda x:(x.keys()))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"Location_country['Location']=Location_country['Location'].apply(lambda x:list(x))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"Location_country.drop(Location_country.index[Location_country.Location.map(len)==0],inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#Location_country","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"Location_country['Location']=Location_country['Location'].apply(lambda x:str(x[0]))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#Location_country","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"agg_func={'count':'sum'}\nLocation_country=Location_country.groupby(['Location']).aggregate(agg_func)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is how the dataframe looks after aggregating the count(after factoring in the cities) for each country","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"Location_country.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"Location_country.sort_values(by=['count'],ascending=False,inplace=True)\nLocation_country.reset_index(inplace=True)\nLocation_country.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#Location_country['Location']=Location_country['Location'].apply(lambda x:x[2:-2])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The count for each country has changed after the values for all cities in countries is aggregated","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"Count_graph=px.bar(x='Location',y='count',data_frame=Location_country[:15],color='Location')\nCount_graph.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"cc = coco.CountryConverter()\nLocation_country['Location']=Location_country['Location'].apply(lambda x:cc.convert(names=x,to='ISO3'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"Location_country","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The below map shows number of tweets from each countries.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"india_states = json.load(open(\"../input/country-state-geo-location/countries.geo.json\", \"r\"))\nfig = px.choropleth(\n    Location_country,\n    locations=\"Location\",\n    geojson=india_states,\n    color=\"count\",\n    #hover_name=\"State or union territory\",\n    hover_data=[\"count\"],\n    title=\"number of tweets from each country\",\n)\nfig.update_geos(fitbounds=\"locations\", visible=False)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets=pd.DataFrame(covid_df['text'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Sentiment Analysis","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Let's try to understand the sentiment of tweets. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Before we try to do our analysis some pre-processing is required on these tweets. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"fuctions to remove emojis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\ndef char_is_emoji(character):\n    return character in emoji.UNICODE_EMOJI\n#does the text contain an emoji?\ndef text_has_emoji(text):\n    for character in text:\n        if character in emoji.UNICODE_EMOJI:\n            return True\n    return False\n#remove the emoji\ndef deEmojify(inputString):\n    return inputString.encode('ascii', 'ignore').decode('ascii')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Function to remove punctuations.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"punct =[]\npunct += list(string.punctuation)\npunct += 'â€™'\npunct.remove(\"'\")\ndef remove_punctuations(text):\n    for punctuation in punct:\n        text = text.replace(punctuation, ' ')\n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def nlp(df):\n    # lowercase everything\n    # get rid of '\\n' from whitespace\n    # regex remove hyperlinks\n    # removing '&gt;'\n    # check for emojis\n    # remov\n        # lowercase everything\n    df['token'] = df['text'].apply(lambda x: x.lower())\n    # get rid of '\\n' from whitespace \n    df['token'] = df['token'].apply(lambda x: x.replace('\\n', ' '))\n    # regex remove hyperlinks\n    df['token'] = df['token'].str.replace('http\\S+|www.\\S+', '', case=False)\n    # removing '&gt;'\n    df['token'] = df['token'].apply(lambda x: x.replace('&gt;', ''))\n    # Checking if emoji in tokens column, use for EDA purposes otherwise not necessary to keep this column\n    df['emoji'] = df['token'].apply(lambda x: text_has_emoji(x))\n    # Removing Emojis from tokens\n    #df['token'] = df['token'].apply(lambda x: deEmojify(x))\n    # remove punctuations\n    #df['token'] = df['token'].apply(remove_punctuations)\n    # remove ' s ' that was created after removing punctuations\n    df['token'] = df['token'].apply(lambda x: str(x).replace(\" s \", \" \"))\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"tweets1=(nlp(tweets))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"(tweets1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### WordCloud","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"comment_words=''\nfor val in tweets1.token: \n      \n    # typecaste each val to string \n    val = str(val) \n  \n    # split the value \n    tokens = val.split() \n      \n    # Converts each token into lowercase \n    for i in range(len(tokens)): \n        tokens[i] = tokens[i].lower() \n      \n    comment_words += \" \".join(tokens)+\" \"\n  \nwordcloud1 = WordCloud(width = 800, height = 800, \n                background_color ='white', \n                stopwords = STOPWORDS, \n                min_font_size = 10).generate(comment_words)\nplt.figure(figsize = (10,10), facecolor = None) \nplt.imshow(wordcloud1) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0) \n  \nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def categoriser(diction):\n    if(diction['neg']>0):\n        return(\"Negative\")\n    elif(diction['pos']>0):\n        return('Positive')\n    else:\n        return('Neutral')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def SentiAnlyser(df):\n    analyser= SentimentIntensityAnalyzer()\n    df['sentiment']=df['token'].apply(lambda x: analyser.polarity_scores(x))\n    df['sentiment']=df['sentiment'].apply(lambda x:categoriser(x))\n    return df","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"tweets2=SentiAnlyser(tweets1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets2.to_csv('./sentiment.csv')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"tweets2.iloc[22]","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"tweet_sentiments=pd.DataFrame(tweets2['sentiment'].value_counts())\ntweet_sentiments.reset_index(inplace=True)\ntweet_sentiments.rename(columns={'index':'Sentiment','sentiment':'count'},inplace=True)\nfig=px.pie(tweet_sentiments,values='count',names='Sentiment',title=\"Sentiments of Tweets\")","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}