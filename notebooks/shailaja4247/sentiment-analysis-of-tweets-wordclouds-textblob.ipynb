{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Aim of this notebook\n\n- How to analyse tweets\n- How to do sentiment analysis\n- How to make a wordcloud\n\n# About the data\n\nDataset consists of tweets on Trump.\n\n\n# About this Notebook\n\n- <a href =#1> 1. Importing packages and libraries  </a>\n- <a href =#2> 2. Reading the data </a>\n- <a href =#3> 3. Handling null values </a>\n- <a href =#4> 4. Exploratory data analysis </a>\n- <a href =#5> 5. Cleaning the data </a>\n- <a href =#6> 6. Applying data cleaning steps to data</a>\n- <a href =#7> 7. Finding the most Common words in our Text</a>\n- <a href =#8> 8.  Finding Most common words Sentiments Wise  </a>\n    - <a href =#8.1> 8.1.  Finding the tweet sentiment</a>\n    - <a href =#8.2> 8.2. Finding common words for positive sentiment tweets </a>\n    - <a href =#8.3> 8.3. Finding the common words for negative sentiment tweets  </a>\n    - <a href =#8.4> 8.4. Finding the common words for neutral sentiment tweets </a>\n- <a href =#9> 9. Number of Unique Words in tweets of each type of sentiment  </a>\n    - <a href =#9.1> 9.1. Number of unique words in tweets with positive sentiment </a>\n    - <a href =#9.2> 9.2. Number of unique words in tweets with negative sentimen </a>\n    - <a href =#9.3> 9.3. Number of unique words in tweets with neutral sentimen </a>\n- <a href =#10> 10. Wordclouds  </a>\n    - <a href =#10.1> 10.1.  WordCloud for neutral sentiment</a>\n    - <a href =#10.2> 10.2.  WordCloud for positive sentiment</a>\n    - <a href =#10.3> 10.3.  WordCloud for negative sentiment</a>\n\n<br><br>\nIn case you are just starting with NLP here is a guide to Approach almost any NLP Problem by Grandmaster @Abhishek Thakur\nhttps://www.slideshare.net/abhishekkrthakur/approaching-almost-any-nlp-problem\n\n\n<b> This kernel is a work in Progress,and I will keep on updating it as I learn more and more</b>\n\n**<span style=\"color:Red\">If you find this kernel useful, Please Upvote it , it motivates me to write more Quality content**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<div id=1> <h2>  1. Importing packages and libraries  </h2> </div> ","execution_count":null},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import re\nimport string\nimport numpy as np \nimport random\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom plotly import graph_objs as go\nimport plotly.express as px\nimport plotly.figure_factory as ff\nfrom collections import Counter\n\nfrom PIL import Image\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n\n\nimport nltk\nfrom nltk.corpus import stopwords\n\nfrom tqdm import tqdm\nimport os\nimport nltk\nimport spacy\nimport random\nfrom spacy.util import compounding\nfrom spacy.util import minibatch\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Below is a helper Function which generates random colors which can be used to give different colors to your plots.Feel free to use it**","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def random_colours(number_of_colors):\n    '''\n    Simple function for random colours generation.\n    Input:\n        number_of_colors - integer value indicating the number of colours which are going to be generated.\n    Output:\n        Color in the following format: ['#E86DA4'] .\n    '''\n    colors = []\n    for i in range(number_of_colors):\n        colors.append(\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]))\n    return colors","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div id=2> <h2> 2. Reading the Data  </h2></div> ","execution_count":null},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_kg_hide-input":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\ntrain=pd.read_csv('/kaggle/input/trump-tweets/trumptweets.csv')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"print(train.shape)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So We have 27486 tweets in the train set and 3535 tweets in the test set","execution_count":null},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Geo column has all values as nulls, hashtags have lot of null values, mentions also have lot of null values.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<div id=3> <h2> 3. Handling null values </h2> </div>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train['hashtags'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['mentions'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. hashtags: This column does not have something very significant for us to analyse. We have mostly words like #ixzz4 etc which make no sense and we wont be able to analyse their sentiment. So we can get rid of this column\n2. mentions  too does not have anything siginificant for us to analyse. Hence we can do away with that too. Let us drop columns which dont have any siginificantly useful information.\n3. geo anyways does not have any value, all values are null\n4. mentions usually mention another person and we wont really get any sentiment by analysing that","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train=train.drop(['link','mentions','hashtags','geo'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div id=4> <h2> 4. EDA  </h2></div>","execution_count":null},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets look at the distribution of reviews in the train set","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<div id=5> <h2>5. Cleaning the data </h2> </div>\n\nLet's first clean the data, remove stopwords etc and perform basic pre-processing","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Removing weird spaces**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_spaces(text):\n    text=text.strip()\n    text=text.split()\n    return ' '.join(text)\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b> Spelling Correction </b>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def edits1(word):\n    letters='abcdefghijklmnopqrstuvwxyz'\n    splits=[(word[:i], word[i:]) for i in range(len(word)+1)]\n    deletes=[L+R[1:] for L,R in splits if R]\n    transposes=[L+R[1] +R[0] + R[2:] for L,R in splits if len(R)>1]\n    replaces = [L+c+R[1:] for L,R in splits if R for c in letters]\n    inserts = [L+c+ R for L,R in splits for c in letters]\n    return set(deletes+transposes+replaces+inserts)\ndef edits2(word):\n    return(e2 for e1 in edits1(word) for e2 in edits1(e1))\n            ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b> Contraction </b>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"contraction = {'cause':'because',\n              'aint': 'am not',\n              'aren\\'t': 'are not'}\n\ndef mapping_replacer(x,dic):\n    for words in dic.keys():\n        if ' ' + words + ' ' in x:\n            x=x.replace(' '+ words +' ' ,' '+dic[words]+' ' )\n    return x\n\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b> Stemming, lemmetisation and tokenisation\n</b>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk\nnltk.download('punkit')\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem.wordnet import WordNetLemmatizer\nfrom nltk.stem.lancaster import LancasterStemmer\n\nnltk.LancasterStemmer\nls = LancasterStemmer()\nlem = WordNetLemmatizer()\ndef lexicon_normalization(text):\n    words = word_tokenize(text) \n    \n    \n    # 1- Stemming\n    words_stem = [ls.stem(w) for w in words]\n    \n    # 2- Lemmatization\n    words_lem = [lem.lemmatize(w) for w in words_stem]\n    return words_lem\n\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b> Handling emojis </b>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import emoji\nimport re \n#from emot.emo_unicode import UNICODE_EMO\ndef convert_emojis(text):\n    for emot in emoji.UNICODE_EMOJI:\n        text = re.sub(r'('+emot+')', \"_\".join(emoji.UNICODE_EMOJI[emot].replace(\",\",\"\").replace(\":\",\"\").split()), text)\n    return text","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>Removing links, brackets, numbers, punctuations etc. </b>\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_text(text):\n    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n    and remove words containing numbers.'''\n    text = str(text).lower()\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    text = re.sub('\\'','', text)\n    \n    return text","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b> Handling stopwords </b>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import Counter\ndef remove_stopword(text):\n    stop_words = stopwords.words('english')\n    stopwords_dict = Counter(stop_words)\n    text = ' '.join([word for word in text.split() if word not in stopwords_dict])\n    return text","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b> Tokenisation </b>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def tokenise(text):\n    words = word_tokenize(text) \n    return words\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div id = 6> <h2> 6. Applying data cleaning steps to data </h2> </div>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Cleaning Regex Expressions from data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\ntrain['content'] = train['content'].map(lambda x: re.sub(r'\\W+', ' ', x))\ntrain['content'] = train['content'].replace(r'\\W+', ' ', regex=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['content']=train['content'].apply(lambda x: mapping_replacer(x, contraction))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['content'] = train['content'].apply(lambda x:clean_text(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['content']=train['content'].apply(lambda x: remove_stopword(x))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['content']=train['content'].apply(lambda x: lexicon_normalization(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div id=7><h2>7. Finding the most Common words in our Text </h2></div>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"top = Counter([item for sublist in train['content'] for item in sublist])\ntemp = pd.DataFrame(top.most_common(20))\ntemp.columns = ['Common_words','count']\ntemp.style.background_gradient(cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"blacklist = ['http','https','www','com', 'ev','u','ly','pic','would']\n\ndef remove_words(text):\n    text = [i for i in text if (i not in blacklist)]\n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train['content']=remove_words(train['content'])\n\ntrain['content'] = train['content'].apply(lambda x: [i for i in x if i not in blacklist])","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = px.bar(temp, x=\"count\", y=\"Common_words\", title='Commmon Words in Selected Text', orientation='h', \n             width=700, height=700,color='Common_words')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"top = Counter([item for sublist in train['content'] for item in sublist])\ntemp = pd.DataFrame(top.most_common(20))\ntemp = temp.iloc[1:,:]\ntemp.columns = ['Common_words','count']\ntemp.style.background_gradient(cmap='Purples')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = px.treemap(temp, path=['Common_words'], values='count',title='Tree of Most Common Words')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div id = 8><h2>8. Finding Most common words Sentiments Wise</h2></div>\n\nLet's look at the most common words in different sentiments","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<div id=8.1><h3>8.1 Finding the tweet sentiment </div></h3>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud, STOPWORDS , ImageColorGenerator\n\nfrom textblob import TextBlob\n\ndef get_tweet_sentiment(tweet): \n    ''' \n    Utility function to classify sentiment of passed tweet \n    using textblob's sentiment method \n    '''\n    # create TextBlob object of passed tweet text \n    analysis = TextBlob(tweet) \n    \n    # set sentiment \n    if analysis.sentiment.polarity > 0:\n        return 'positive'\n    elif analysis.sentiment.polarity == 0: \n        return 'neutral'\n    else: \n        return 'negative'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['sentiment']=train['content'].apply(lambda x: get_tweet_sentiment(' '.join(x)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Positive_sent = train[train['sentiment']=='positive']\nNegative_sent = train[train['sentiment']=='negative']\nNeutral_sent = train[train['sentiment']=='neutral']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b> Overall tweet sentiment </b>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Number of tweets with positive sentiment', Positive_sent['sentiment'].count())\nprint('Number of tweets with negative sentiment', Negative_sent['sentiment'].count())\nprint('Number of tweets with neutral sentiment', Neutral_sent['sentiment'].count())\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b><i>So we see that overall the tweets are neutral in nature, followed by positive sentiment for the time in which they are analysed.</i></b>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<div id=8.2><h3>8.2 Finding common words for positive sentiment tweets</div></h3>","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#MosT common positive words\ntop = Counter([item for sublist in Positive_sent['content'] for item in sublist])\ntemp_positive = pd.DataFrame(top.most_common(20))\ntemp_positive.columns = ['Common_words','count']\ntemp_positive.style.background_gradient(cmap='Greens')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since we have words like 's', 'gre' which do not really mean anything, we will remove them and find the most common words","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\ntop = Counter([item for sublist in Positive_sent['content'] for item in sublist])\ntemp_positive = pd.DataFrame(top.most_common(23))\ntemp_positive.columns = ['Common_words','count']\ntemp_positive['Common_words'] = temp_positive['Common_words'].map(lambda x: re.sub(r'\\W+', '', x))\ntemp_positive['Common_words'] = temp_positive['Common_words'].replace(r'\\W+', '', regex=True)\ntemp_positive['Common_words'] = temp_positive['Common_words'].apply(lambda x:remove_spaces(x))\ntemp_positive=temp_positive[~temp_positive['Common_words'].isin(['s','gre','“',' * '])] #new line removing meaningless words\nmask1 = temp_positive.Common_words.str.contains('[a-zA-Z]')\nmask2 = temp_positive.Common_words.notna()\ntemp_positive = temp_positive[mask1 | mask2]\ntemp_positive.Common_words =  temp_positive.Common_words.str.replace(r\"\\s+\", \"\").replace(\"\", np.NaN)\ntemp_positive=temp_positive.dropna()\n\n\ntemp_positive.style.background_gradient(cmap='Greens')\n","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = px.bar(temp_positive, x=\"count\", y=\"Common_words\", title='Most Commmon Words in Positive Sentiment tweets', orientation='h', \n             width=700, height=700,color='Common_words')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div id=8.3><h3>8.3 Finding the common words for negative sentiment tweets </div></h3>","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#MosT common negative words\ntop = Counter([item for sublist in Negative_sent['content'] for item in sublist])\ntemp_negative = pd.DataFrame(top.most_common(20))\ntemp_negative = temp_negative.iloc[1:,:]\ntemp_negative.columns = ['Common_words','count']\ntemp_negative.style.background_gradient(cmap='Reds')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#MosT common negative words\ntop = Counter([item for sublist in Negative_sent['content'] for item in sublist])\ntemp_negative = pd.DataFrame(top.most_common(22))\ntemp_negative = temp_negative.iloc[1:,:]\ntemp_negative.columns = ['Common_words','count']\n\n#Data cleaning\ntemp_negative['Common_words'] = temp_negative['Common_words'].map(lambda x: re.sub(r'\\W+', '', x))\ntemp_negative['Common_words'] = temp_negative['Common_words'].replace(r'\\W+', '', regex=True)\ntemp_negative=temp_negative[~temp_negative['Common_words'].isin(['s','t'])] #new line removing meaningless words from above\n#mask1 = temp_negative.Common_words.str.contains('[a-zA-Z]')\n#mask2 = temp_negative.Common_words.notna()\n#temp_negative = temp_negative[mask1 | mask2]\n\ntemp_negative.Common_words =  temp_negative.Common_words.replace(\"\", np.nan)\ntemp_negative = temp_negative.dropna(subset=['Common_words'])\n\ntemp_negative.style.background_gradient(cmap='Reds')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = px.treemap(temp_negative, path=['Common_words'], values='count',title='Tree Of Most Common Words in Negative Tweets')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div id=8.4><h3>8.4 Finding the common words for neutral sentiment tweets </div></h3>","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#MosT common Neutral words\ntop = Counter([item for sublist in Neutral_sent['content'] for item in sublist])\ntemp_neutral = pd.DataFrame(top.most_common(20))\ntemp_neutral = temp_neutral.loc[1:,:]\ntemp_neutral.columns = ['Common_words','count']\ntemp_neutral.style.background_gradient(cmap='Reds')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntop = Counter([item for sublist in Neutral_sent['content'] for item in sublist])\ntemp_neutral = pd.DataFrame(top.most_common(20))\ntemp_neutral = temp_neutral.loc[1:,:]\ntemp_neutral.columns = ['Common_words','count']\n\n#Data cleaning\ntemp_neutral['Common_words'] = temp_neutral['Common_words'].map(lambda x: re.sub(r'\\W+', '', x))\ntemp_neutral['Common_words'] = temp_neutral['Common_words'].replace(r'\\W+', '', regex=True)\ntemp_neutral=temp_neutral[~temp_neutral['Common_words'].isin(['s'])] #new line removing meaningless words from above\n\ntemp_neutral.Common_words =  temp_neutral.Common_words.replace(\"\", np.nan)\ntemp_neutral = temp_neutral.dropna(subset=['Common_words'])\n\ntemp_neutral.style.background_gradient(cmap='Reds')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = px.bar(temp_neutral, x=\"count\", y=\"Common_words\", title='Most Commmon Neutral Words', orientation='h', \n             width=700, height=700,color='Common_words')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = px.treemap(temp_neutral, path=['Common_words'], values='count',title='Tree Of Most Common Neutral Words')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div id=9><h2>9. Number of Unique Words in tweets of each type of sentiment </h2> </div>\n\nWe will look at number of unique words in each type of tweet with different sentiments:\n* Positive\n* Negative\n* Neutral","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_text = [word for word_list in train['content'] for word in word_list]","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def words_unique(sentiment,numwords,raw_words):\n    '''\n    Input:\n        segment - Segment category (ex. 'Neutral');\n        numwords - how many specific words do you want to see in the final result; \n        raw_words - list  for item in train_data[train_data.segments == segments]['temp_list1']:\n    Output: \n        dataframe giving information about the name of the specific ingredient and how many times it occurs in the chosen cuisine (in descending order based on their counts)..\n\n    '''\n    allother = []\n    for item in train[train.sentiment != sentiment]['content']:\n        for word in item:\n            allother .append(word)\n    allother  = list(set(allother ))\n    \n    specificnonly = [x for x in raw_text if x not in allother]\n    \n    mycounter = Counter()\n    \n    for item in train[train.sentiment == sentiment]['content']:\n        for word in item:\n            mycounter[word] += 1\n    keep = list(specificnonly)\n    \n    for word in list(mycounter):\n        if word not in keep:\n            del mycounter[word]\n    \n    Unique_words = pd.DataFrame(mycounter.most_common(numwords), columns = ['words','count'])\n    \n    return Unique_words","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"  <div id=9.1><h2>9.1. Number of unique words in tweets with positive sentiment  </h2> </div>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Unique_Positive= words_unique('positive', 20, raw_text)\nprint(\"The top 20 unique words in Positive Tweets are:\")\nUnique_Positive.style.background_gradient(cmap='Greens')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Unique_Positive","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.treemap(Unique_Positive, path=['words'], values='count',title='Tree Of Unique Words in Positive sentiment tweets')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"scrolled":true,"trusted":true},"cell_type":"code","source":"import \nfrom palettable.colorbrewer.qualitative import Pastel1_7\nplt.figure(figsize=(16,10))\nmy_circle=plt.Circle((0,0), 0.7, color='white')\nplt.pie(Unique_Positive['count'], labels=Unique_Positive.words, colors=Pastel1_7.hex_colors)\np=plt.gcf()\np.gca().add_artist(my_circle)\nplt.title('DoNut Plot Of Unique words in Positive sentiment tweets')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"  <div id=9.2><h2>9.2. Number of unique words in tweets with negative sentiment  </h2> </div>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Unique_Negative= words_unique('negative', 10, raw_text)\nprint(\"The top 10 unique words in Negative Tweets are:\")\nUnique_Negative.style.background_gradient(cmap='Reds')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"from palettable.colorbrewer.qualitative import Pastel1_7\nplt.figure(figsize=(16,10))\nmy_circle=plt.Circle((0,0), 0.7, color='white')\nplt.rcParams['text.color'] = 'black'\nplt.pie(Unique_Negative['count'], labels=Unique_Negative.words, colors=Pastel1_7.hex_colors)\np=plt.gcf()\np.gca().add_artist(my_circle)\nplt.title('DoNut Plot Of Unique words in Negative sentiment tweets')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"  <div id=9.3><h2>9.3. Number of unique words in tweets with neutral sentiments  </h2> </div>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Unique_Neutral= words_unique('neutral', 10, raw_text)\nprint(\"The top 10 unique words in Neutral Tweets are:\")\nUnique_Neutral.style.background_gradient(cmap='Oranges')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since the count for positive, negative and neutral sentiments is so less, there is no use of creating word clouds with unique words. So we will create a wordcloud with all the words combined.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Data cleaning\nUnique_Neutral= words_unique('neutral', 14, raw_text)\nUnique_Neutral['words'] = Unique_Neutral['words'].map(lambda x: re.sub(r'\\W+', '', x))\nUnique_Neutral['words'] = Unique_Neutral['words'].replace(r'\\W+', '', regex=True)\nUnique_Neutral['words']=Unique_Neutral[~Unique_Neutral['words'].isin(['به','را','ایران','و'])] #new line removing meaningless words from above\n\nUnique_Neutral['words'] =  Unique_Neutral['words'].replace(\"\", np.nan)\nUnique_Neutral= Unique_Neutral.dropna(subset=['words'])\n\nUnique_Neutral.style.background_gradient(cmap='Reds')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"from palettable.colorbrewer.qualitative import Pastel1_7\nplt.figure(figsize=(16,10))\nmy_circle=plt.Circle((0,0), 0.7, color='white')\nplt.pie(Unique_Neutral['count'], labels=Unique_Neutral.words, colors=Pastel1_7.hex_colors)\np=plt.gcf()\np.gca().add_artist(my_circle)\nplt.title('DoNut Plot Of Unique words in Neutral sentiment tweets')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**By Looking at the Unique Words of each sentiment,we now have much more clarity about the data**\n\nWe shall now proceed to create word clouds, but we shall make word cloud of all words and not just existing words since unique words are very less in number for many sentiments (10,7,9 etc.) , so an effective word cloud can be only made by considering all the words in different sentiment tweets","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<div id=10><h2>10. WordClouds</h2> </div>\n\n\nWe will be building three types of wordclouds:\n\n* WordCloud of Neutral Tweets\n* WordCloud of Positive Tweets\n* WordCloud of Negative Tweets","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def plot_wordcloud(text, mask=None, max_words=200, max_font_size=100, figure_size=(24.0,16.0), color = 'white',\n                   title = None, title_size=40, image_color=False):\n    \n    wordcloud = WordCloud(background_color=color,\n                    max_words = max_words,\n                    max_font_size = max_font_size, \n                    random_state = 42,\n                    width=400, \n                    height=200,\n                    mask = mask)\n    wordcloud.generate(str(text))\n    \n    plt.figure(figsize=figure_size)\n    if image_color:\n        image_colors = ImageColorGenerator(mask);\n        plt.imshow(wordcloud.recolor(color_func=image_colors), interpolation=\"bilinear\");\n        plt.title(title, fontdict={'size': title_size,  \n                                  'verticalalignment': 'bottom'})\n    else:\n        plt.imshow(wordcloud);\n        plt.title(title, fontdict={'size': title_size, 'color': 'black', \n                                  'verticalalignment': 'bottom'})\n    plt.axis('off');\n    plt.tight_layout()  \nd = '/kaggle/input/trump-tweets/'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div id=10><h2>10.1. WordCloud for neutral sentiment</h2> </div>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Neutral_sent","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"pos_mask = np.array(Image.open('/kaggle/input/tweet-mask/tweet_mask.png'))\nplot_wordcloud(Neutral_sent.content,mask=pos_mask,color='white',max_font_size=100,title_size=30,title=\"WordCloud of Neutral Tweets\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div id=10.2><h2>10.2 WordCloud for positive sentiment</h2> </div>\n","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plot_wordcloud(Positive_sent.content,mask=pos_mask,title=\"Word Cloud Of Positive tweets\",title_size=30)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div id=10.3><h2>10.3 WordCloud for Tweets with negative sentiment</h2> </div>","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plot_wordcloud(Negative_sent.content,mask=pos_mask,title=\"Word Cloud of Negative Tweets\",color='white',title_size=30)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h4>If you liked my kernel, please be kind to upvote it :). It will help my efforts :)</h4>","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}