{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n\nfrom xgboost import XGBRegressor\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\nimport lightgbm as lgb\n\ndata=pd.read_csv('/kaggle/input/SolarEnergy/SolarPrediction.csv')\ncol_names=data.columns\nprint(col_names)\ndata=data.rename({'Data':'Date'}, axis=1)\ndata['date']=data['Date'].str.split(' ').str.get(0)\ndata['Datetime'] = pd.to_datetime(data['date'].apply(str)+' '+data['Time']) #Datetime column is of type datetime64\ndata['Hour_Minute'] = data['Datetime'].dt.strftime('%H:%M')\ndata['Hour'] = data['Datetime'].dt.strftime('%H')\ndata['Datetime']=sorted(data['Datetime']) ## date column was not sorted\n\ndata=data.drop(columns=['UNIXTime', 'Date', 'date', 'Time'])\ndata=data.set_index('Datetime')\n#print(data.head())\n\ndata['TimeSunSet']=pd.to_datetime(data['TimeSunSet'], format = \"%H:%M:%S\")\ndata['TimeSunRise']=pd.to_datetime(data['TimeSunRise'], format = \"%H:%M:%S\")\ndata['DayLength'] = data['TimeSunSet'] - data['TimeSunRise']\ndata['DayLength'] = data['DayLength'].dt.total_seconds().floordiv(60)\ndata['month']=data.index.month","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now the dataframe 'data' is ready for EDA which is done in next step.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"########################################## Exploratory Data Analysis ###################################################\nplt.figure(figsize=(12,8))\nsns.barplot(x=data['Temperature'],y=data['Radiation'])\nplt.xlabel('Temperature (F)')\nplt.ylabel('Radiation (W/m2)')\nplt.title('Radiation versus Temperature')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As it can be seen increasing temperature almost always results in increasing of the Radiation.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nsns.barplot(x=data['Humidity'],y=data['Radiation'])\nplt.xlabel('Humidity')\nplt.ylabel('Radiation (W/m2)')\nplt.title('Radiation versus Humidity')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the figure above we can see that there is no linear relationship between Radiation and Humidity."},{"metadata":{},"cell_type":"markdown","source":"Now we want to know how Radiation changes per month:"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (16,8)\nmonths = np.arange(9,13)\nrad_vs_month=data.loc[:, ['Radiation', 'month']].groupby('month').sum()\nrad_vs_month.plot()\nplt.xticks(months,['September', 'October', 'November', 'December'], rotation=30)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In October Radiation is highest and in December it i slowest which is logical!"},{"metadata":{},"cell_type":"markdown","source":"Now let's check the distribution of Radiation during the day time:"},{"metadata":{"trusted":true},"cell_type":"code","source":"rad_vs_hour=data.loc[:, ['Radiation', 'Hour']].groupby('Hour').mean()\nrad_vs_hour.plot(kind='bar')\nplt.xlabel('Time of the day (hour)')\nplt.ylabel('Radiation(W/m2)')\nplt.title('Total Radiation per time of the day')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As it can be seen, around noon is the maximum Radiation which makes sense."},{"metadata":{},"cell_type":"markdown","source":"Since we have the dey length for everyday, we can see how Radiation varies by daylength:"},{"metadata":{"trusted":true},"cell_type":"code","source":"rad_vs_time=data.loc[:, ['Radiation', 'DayLength']].groupby('DayLength').mean()\nrad_vs_time.plot()\nplt.title('Average Radiation versus day length')\nplt.xlabel('Day length (minutes)')\nplt.ylabel('Radiation(W/m2)')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is no strong correlation between daylength and Radiation, we can maybe ignore this feature while predicting Radiation. Now, to better understand the correlation between different features and Radiation we plot heatmap:"},{"metadata":{"trusted":true},"cell_type":"code","source":"## correlation matrix and heatmap\ncols_heatmap=['Temperature', 'Radiation', 'Pressure', 'Humidity', 'WindDirection(Degrees)', 'Speed', 'DayLength']\ncorr_mat = data.loc[:, cols_heatmap].corr(method='pearson')\nf, ax = plt.subplots(figsize=(12, 8))\nsns.heatmap(corr_mat, annot=True) # plot heatmap; annot=True shows the number, without it, there is no correlation value, just colors!\nplt.xticks(rotation=30)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It can be seen from heatmap that there is high correlation between temperature and Radiation, a low correlation between pressure and Radiation."},{"metadata":{},"cell_type":"markdown","source":"Now we split our data to train and validation. We want to use all the data from September to 2016-12-29 for training our models and use the data from 30 and 31 December 2016 as validation. \nAfter we predict Radiation values for 30 and 31 December, we can compare the result with the observed data (validation). \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"######################################### Specify Tain, test and validation data #######################################\n# Validation data is unseen data by model\ndata_usefulcols=data.drop(columns=['month', 'Hour', 'Hour_Minute', 'TimeSunSet', 'TimeSunRise', 'WindDirection(Degrees)', 'Speed'])\ntrain=data_usefulcols.loc[:'2016-12-29', data_usefulcols.columns]\nprint(train.tail())\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation=data_usefulcols.loc['2016-12-30':, data_usefulcols.columns]\nprint(validation.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now prepare X and y for our models:"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_validation=validation.drop(columns='Radiation')\ny_validation=validation[['Radiation']]\nResult=y_validation.copy()\nX=train.drop(columns='Radiation')\ny=train[['Radiation']] # used for XGBoost\ny_lgb=train['Radiation'] # used for LGBM","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We use Random Forest, XGBoost and LightGBM for prediction: "},{"metadata":{"trusted":true},"cell_type":"code","source":"############################################ Building Random Forest model  #############################################\nrf=RandomForestRegressor()\n\n# finding the best parameters by RandomizedSearchCV\nparam_rf = {'bootstrap':['False'], 'n_estimators': [500], \"max_depth\": [20], \"max_features\": np.arange(3,5).tolist(), \"min_samples_leaf\": np.arange(80,100).tolist(), \"criterion\": [\"mse\"]}\nrf_cv=RandomizedSearchCV(rf, param_rf, cv=2)\n\n# Extract the best estimator\nrf_cv.fit(X, np.ravel(y))\n\nbest_model = rf_cv.best_estimator_\nprint(best_model)\ny_pred_rf=best_model.predict(X_validation)\nResult['Predicted_Radiation_RF']=y_pred_rf\nrmse = np.sqrt(mean_squared_error(y_validation, y_pred_rf))\nprint(\"Root Mean Squared Error RF: {}\".format(rmse))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"################################################ Build XGBoost model ###################################################\n\nxgb = XGBRegressor(max_depth=35, random_state=42, n_estimators=1500, learning_rate=0.005, booster='gbtree', objective='reg:squarederror', min_child_weight=0.1, silent=1, n_jobs=10)\n\nxgb.fit(X, y.values.ravel())\ny_pred=xgb.predict(X_validation)\n\npredicted=pd.DataFrame(y_pred)\nResult['Predicted_Radiation_XGBoost']=y_pred\n\nrmse = np.sqrt(mean_squared_error(y_validation, y_pred))\nprint(\"Root Mean Squared Error XGBoost: {}\".format(rmse))\n\nfeat_imp = pd.Series(xgb.feature_importances_, index= X.columns).sort_values(ascending=True)\nfeat_imp.plot(kind='barh', title='Feature Importances XGBoost') # note: there in no feature importance for lgbm\nplt.ylabel('Feature Importance Score')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see from the figure above that Temperature and the length of the day are the most important features for this problem."},{"metadata":{"trusted":true},"cell_type":"code","source":"######################################### Build lightGB model ####################################################\nX_lgb = X.values\n\nparams = {\n      'num_leaves': 700,\n      'min_child_weight': 0.34,\n      'feature_fraction': 0.979,\n      'bagging_fraction': 0.818,\n      'min_data_in_leaf': 700,\n      'objective': 'regression',\n      'max_depth': 40,\n      'learning_rate': 0.1,\n      \"boosting_type\": \"gbdt\",\n      \"bagging_seed\": 11,\n      \"metric\": 'rmse',\n      \"verbosity\": -1,\n      'reg_alpha': 0.0001,\n      'reg_lambda': 2.9,\n      'random_state': 666,\n    }\n\nlgb_train = lgb.Dataset(X.values, label=y_lgb.values)\n# Train LightGBM model\nm_lgb = lgb.train(params, lgb_train, 400)\ny_pred_lgb=m_lgb.predict(X_validation)\n#print(np.round(y_pred_lgb[0], 6))\n\nResult['Predicted_Radiation_LGB']=y_pred_lgb\nprint(Result.loc[:, ['Predicted_Radiation_XGBoost', 'Radiation']].head())\n\nrmse_lgb = np.sqrt(mean_squared_error(y_validation, y_pred_lgb))\nprint(\"Root Mean Squared Error LGBM: {}\".format(rmse_lgb))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we plot the results to get a better insight about the predictions:"},{"metadata":{"trusted":true},"cell_type":"code","source":"######################################### Performance comparison #######################################################\nResult=Result.rename({'Radiation':'Radiation_observed'}, axis=1)\nResult.plot(figsize=(20,12))\nplt.ylabel('Radiation(W/m2)')\nplt.title('Performance of different models in prediction of Radiation for 30 and 31 December 2016')\nplt.xlabel('Date and Time')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looking at the RMS error we conclude that LightGBM has the best prediction here, however by looking at the figure above, we can see that XGBoost predictions of 31 December are more match with the observed data. All the models have considerable error between noon 30 December and morning 31 December. \nAlthough the train data is really small, the results are reasonable! \n"},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}