{"cells":[{"metadata":{},"cell_type":"markdown","source":"> ### <font color=blue>**Problem Statement**\n\nA Chinese automobile company Geely Auto aspires to enter the US market by setting up their manufacturing unit there and producing cars locally to give competition to their US and European counterparts.\n\nThey have contracted an automobile consulting company to understand the factors on which the pricing of cars depends. Specifically, they want to understand the factors affecting the pricing of cars in the American market, since those may be very different from the Chinese market. The company wants to know:Which variables are significant in predicting the price of a car How well those variables describe the price of a car Based on various market surveys, the consulting firm has gathered a large dataset of different types of cars across the Americal market.\n\n> ### <font color=blue>Business Goal\n\nYou are required to model the price of cars with the available independent variables. It will be used by the management to understand how exactly the prices vary with the independent variables. They can accordingly manipulate the design of the cars, the business strategy etc. to meet certain price levels. Further, the model will be a good way for management to understand the pricing dynamics of a new market.\n\n> ### <font color=blue>Data Preparation\n\nThere is a variable named CarName which is comprised of two parts - the first word is the name of 'car company' and the second is the 'car model'. For example, chevrolet impala has 'chevrolet' as the car company name and 'impala' as the car model name. You need to consider only company name as the independent variable for model building.\n\n> ### <font color=blue>Model Evaluation:\n\nWhen you're done with model building and residual analysis, and have made predictions on the test set, just make sure you use the following two lines of code to calculate the R-squared score on the test set.\n\nfrom sklearn.metrics import r2_score r2_score(y_test, y_pred) where y_test is the test data set for the target variable, and y_pred is the variable containing the predicted values of the target variable on the test set.\n\nPlease don't forget to perform this step as the R-squared score on the test set holds some marks. The variable names inside the 'r2_score' function can be different based on the variable names you have chosen.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n#import the packages\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# reading the csv file and set index to carid\ndf=pd.read_csv(\"../input/car-price-prediction/CarPrice_Assignment.csv\").set_index(\"car_ID\")\n#display rowsa and columns\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# to check the shape of the dataframe\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# to check the information of the data frame\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### <font color=red>No null values ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#to check the statistics of the data frame\ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# to check the columns of the data frame\ndf.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#to convert int to object \ndf[\"symboling\"]=df[\"symboling\"].map({-3:\"safe\",-2:\"safe\",-1:\"safe\",0:\"moderate\",1:\"moderate\",2:\"risk\",3:\"risk\"})\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# to split carname to company name\ndf[\"CompanyName\"]=df[\"CarName\"].str.split(\" \").str[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# to count the company names\ndf[\"CompanyName\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### <font color=red>company names  spellings are  wrong","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# replacing to proper company  spelling names\ndf[\"CompanyName\"].replace({'maxda':'mazda','vw':'volkswagen','porcshce':'porsche','Nissan':'nissan','vokswagen':'volkswagen',\n                             'toyouta':'toyota','alfa-romero':'alfa-romeo'},inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#scatter plot for numerical variable\ncol=(\"wheelbase\",\"carlength\",\"carwidth\",\"carheight\",\"curbweight\",\"enginesize\",\"fuelsystem\",\"boreratio\",\"stroke\",\"compressionratio\",\"horsepower\",\"peakrpm\",\"citympg\",\"highwaympg\")\nplt.figure(figsize=(20,15))\nfor i in range(0,len(col)):\n    plt.subplot(4,4,i+1)\n    sns.scatterplot(x=col[i],\n            y=\"price\",data=df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# categoricalvalue by using box plot\nplt.figure(figsize=(20,15))\ncol=(\"symboling\",\"fueltype\",\"aspiration\",\"doornumber\",\"carbody\",\"drivewheel\",\"enginelocation\",\"enginetype\",\"cylindernumber\",\"fuelsystem\")\nfor i in range(0,len(col)):\n    plt.subplot(4,4,(i+1))\n    sns.boxplot(x=col[i],y=\"price\",data=df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### <font color=red>we can clearly see there is clear relation between engine location and price","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(25,15))\nsns.boxplot(x=\"CompanyName\",y=\"price\",data=df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert categorical values to numerical values\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ndf[\"fueltype\"]=le.fit_transform(df['fueltype'])\ndf[\"aspiration\"]=le.fit_transform(df['aspiration'])\ndf[\"doornumber\"]=le.fit_transform(df['doornumber'])\ndf[\"enginelocation\"]=le.fit_transform(df['enginelocation'])\ndf.head()\ndf.drop([\"CarName\",'CompanyName'],axis=1,inplace=True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# converting categorical variables to dummy variables \ndf = pd.get_dummies(df)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# after dummy variable convertion from object variables to integer variable\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Splitting data into train and test data set","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n#creation of train and test data set  as 70:30\ndf_train,df_test=train_test_split(df,train_size=0.7,test_size=.3,random_state=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_train.shape)\nprint(df_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking the train head data set\ndf_train.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking statistical train datframe\ndf_train.describe()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#scaling by using min max scaler\nfrom sklearn.preprocessing import MinMaxScaler\nscaler=MinMaxScaler()\n# Some variable are out of scale\nli=[\"wheelbase\",\"carlength\",'carwidth','carheight',\"curbweight\",'enginesize','boreratio','stroke','compressionratio','horsepower','peakrpm','citympg','highwaympg','price']\ndf_train[li]=scaler.fit_transform(df_train[li])\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# to cjeck the statstical dataa of the train data\ndf_train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# to find co-relation on train set\nplt.figure(figsize=(40,40))\nsns.heatmap(df_train.corr(),cmap='YlGnBu')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#finding the corelation with respect to price\ncor=df_train.corr().iloc[[17]]\ncor","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Buliding the model","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Using RFE method","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train=df_train.pop(\"price\")\nX_train=df_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import the sklearn\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LinearRegression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating object for linear regression\nlm=LinearRegression()\n# fitting data to X and y train\nlm.fit(X_train,y_train)\n#selecting the top 15 features\nrfe=RFE(lm,15)\nrfe=rfe.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#listing the raking\nlist(zip(X_train.columns,rfe.support_,rfe.ranking_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#listing the top 15 features\ncol=X_train.columns[rfe.support_]\ncol","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Building using stats","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm\n#Creating X_train_rfe which will contain only the top 15 selected columns from the X_train dataset.\nX_train_rfe=X_train[col]\n# training the model\nX_train_rfe=sm.add_constant(X_train_rfe)\n#Applying the linearRegression model on the X_train_rfe and fitting the training dataset.\nlr_1=sm.OLS(y_train,X_train_rfe).fit()\nlr_1.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### <font color=red>highwaympg p-value is high so drop from train data frame.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_new = X_train_rfe.drop(columns=['highwaympg'])\nX_train_lm = sm.add_constant(X_train_new)\n\nlr_2 = sm.OLS(y_train, X_train_lm).fit()\nlr_2.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### <font color=red>All features are acceptable for p-value, so calculate VIF","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.stats.outliers_influence import variance_inflation_factor\nX_train_new = X_train_new.drop(columns=['const'])\nvif = pd.DataFrame()\nX = X_train_new\nvif['Features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### <font color=red>High VIF so remove \"enginetype_rotor\"","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_new = X_train_new.drop(columns=['enginetype_rotor'])\n\nX_train_lm = sm.add_constant(X_train_new)\n\nlr_3 = sm.OLS(y_train, X_train_lm).fit()\nlr_3.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.stats.outliers_influence import variance_inflation_factor\n\nvif = pd.DataFrame()\nX = X_train_new\nvif['Features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### <font color=red>drop curbweight as high VIf value","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_new = X_train_new.drop(columns=['curbweight'])\n\nX_train_lm = sm.add_constant(X_train_new)\nlr_4 = sm.OLS(y_train, X_train_lm).fit()\nlr_4.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.stats.outliers_influence import variance_inflation_factor\n\nvif = pd.DataFrame()\nX = X_train_new\nvif['Features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### <font color=red>Do not drop engine size, as value of R_square reduces very high, we are considering next VIF value i.e. carwidth","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_new = X_train_new.drop(columns=['carwidth'])\n\nX_train_lm = sm.add_constant(X_train_new)\n\nlr_5 = sm.OLS(y_train, X_train_lm).fit()\nlr_5.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### <font color=red>carbody_convertible has high p-value, so droping the carbody_conertible","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_new = X_train_new.drop(columns=['carbody_convertible'])\n\nX_train_lm = sm.add_constant(X_train_new)\n\nlr_6 = sm.OLS(y_train, X_train_lm).fit()\nlr_6.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### <font color=red>Drop the engine location from train data set as it has high p value","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_new = X_train_new.drop(columns=['enginelocation'])\n\nX_train_lm = sm.add_constant(X_train_new)\n\nlr_7 = sm.OLS(y_train, X_train_lm).fit()\nlr_7.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### <font color=red>No high pvalues so checking VIF value","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.stats.outliers_influence import variance_inflation_factor\n\nvif = pd.DataFrame()\nX = X_train_new\nvif['Features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### <font color=red>drop the stroke as high VIF value","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_new = X_train_new.drop(columns=['stroke'])\n\nX_train_lm = sm.add_constant(X_train_new)\n\nlr_8 = sm.OLS(y_train, X_train_lm).fit()\nlr_8.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### <font color=red>Drop the boreratio as high p value","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_new = X_train_new.drop(columns=['boreratio'])\n\nX_train_lm = sm.add_constant(X_train_new)\n\nlr_9 = sm.OLS(y_train, X_train_lm).fit()\nlr_9.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### <font color=red>Drop the cylindernumber_three as high p value","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_new = X_train_new.drop(columns=['cylindernumber_three'])\n\nX_train_lm = sm.add_constant(X_train_new)\n\nlr_10 = sm.OLS(y_train, X_train_lm).fit()\nlr_10.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Drop enginetype_ohc as p -value is greater than 5%","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_new = X_train_new.drop(columns=['enginetype_ohc'])\n\nX_train_lm = sm.add_constant(X_train_new)\n\nlr_11 = sm.OLS(y_train, X_train_lm).fit()\nlr_11.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### <font color=red>As no values are high p-values, so checeking VIF","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.stats.outliers_influence import variance_inflation_factor\n\nvif = pd.DataFrame()\nX = X_train_new\nvif['Features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### <font color=red>The value of VIF of horsepower is high so drop it","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_new = X_train_new.drop(columns=['horsepower'])\n\nX_train_lm = sm.add_constant(X_train_new)\n\nlr_12 = sm.OLS(y_train, X_train_lm).fit()\nlr_12.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.stats.outliers_influence import variance_inflation_factor\n\nvif = pd.DataFrame()\nX = X_train_new\nvif['Features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### <font color=red>All p valueslessthan 5% and VIF values less than 5%","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Residual analysis on train data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Checking if the error terms are also normally distributed. We will plot the histogram of the error terms and check whether it is normally distributed or not.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_lm.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_price=lr_12.predict(X_train_lm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting histogram of the error terms\nfig = plt.figure(figsize=(5,5))\nsns.distplot((y_train - y_train_price))\nfig.suptitle('Error Terms')\nplt.xlabel('Errors')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### <font color=red>As you can see the distribution is similar to normal distribution and the mean of the distribution is 0.\n\n> ### <font color=red>Predection on train and test data set","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#creating a list which will contain all the variables which are out of scale.\nli = ['wheelbase','carlength','carwidth','carheight','curbweight','enginesize','boreratio','stroke',\n     'compressionratio','horsepower','peakrpm','citympg','highwaympg','price']\n\n#performing fit_transform() on the columns present in the above list.\ndf_test[li] = scaler.transform(df_test[li])\ndf_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#creating X and ytest\nX_test=df_test\ny_test=df_test.pop(\"price\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# making predection on lr_12 model\nX_test_new=X_test[X_train_new.columns]\n# adding constant\nX_test_new=sm.add_constant(X_test_new)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# making predection\ny_pred=lr_12.predict(X_test_new)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Evaluation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,10))\nplt.scatter(y_test,y_pred)\nfig.suptitle('y_test vs y_pred', fontsize=20)              # Plot heading \nplt.xlabel('y_test', fontsize=18)                          # X-label\nplt.ylabel('y_pred', fontsize=16)   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import r2_score\nr2_score(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### <font color=red>As the R_squared value on test set is 80%, it is a pretty good LinearRegression model and we can use this to predict the car price for Geely motors.\n\n> ### <font color=red>Therefore our model is ğ‘ğ‘Ÿğ‘–ğ‘ğ‘’= -0.1286 + 1.4493enginesize - 0.1181enginetype_ohcv - 0.3495#ofCylinder_twelve + 0.2840#ofCylinder_two","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}