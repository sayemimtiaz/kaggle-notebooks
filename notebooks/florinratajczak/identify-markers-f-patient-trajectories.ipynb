{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Identification of relevant markers for predicting the patient trajectories\n\nThis Notebook investigates the differences in blood markers between patients which were hospitalized, sent to the ICU or could go home after testing Covid-19-positive. To do this, we stratify the patients into groups and succesfully check for statistically significant differences between the groups in various markers via ANOVA.\n\n# Data:\n\nThe Notebook uses the Einstein Dataset from the UNCOVER Covid-19 Challenge.\n\n# Results: \n\nSix markers are identified which vary significantly between the groups and therefore are plausible markers for patient trajectories.","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport scipy as sp\n\ndata = pd.read_csv(\"../input/uncover/UNCOVER/einstein/diagnosis-of-covid-19-and-its-clinical-spectrum.csv\",\n                  header = 0)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since we are interested in patient trajectories, we first subset the dataset for the actual patients, meaning that they must have tested positive for covid:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"positives = data[data.sars_cov_2_exam_result.eq(\"positive\")]\npositives.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Great, we still have 558 patients left, enough to do analysis on.\nNow the dataset has to be cleaned. Since we expect a lot of missing values, let's look at the percentage of missing values in the dataset:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_pos = pd.DataFrame(positives.isnull().mean() * 100)\npd.set_option('display.max_rows',len(missing_pos))\nmissing_pos","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see, most of the columns contain mostly missing values. Some, such as \"d_dimer\" and \"albumin\", contain not one actual value. Let's discard all colums that have mostly (> 95%) missing values.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for rowname, missingness in zip(missing_pos.index, missing_pos.values):\n    if  missingness[0] > 95:\n        positives.drop(str(rowname), inplace=True, axis = 1)\n        print(\"Dropped \" + rowname)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see, we just lost a lot of columns. But hey, they were (almost) entirely empty, anyway! Let's see how much is left:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"positives.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"558 patients with 53 columns each. This does not mean that every patient has a value in each of the columns, but we can look at this subset as the actual heart of the dataset.\n\nNow, there are three columns that indicate if a patient got admitted\n\n1. to the regular floor,\n2. to a semi-intensive care or\n3. to the intensive care unit. \n\nWe can safely assume that the patients that do not match either of these criteria have been\n\n4. sent home. \n\nSo, let's split up our dataset into these 4 groups:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"regular = positives[positives.patient_addmited_to_regular_ward_1_yes_0_no.eq(\"t\")]\nsemi = positives[positives.patient_addmited_to_semi_intensive_unit_1_yes_0_no.eq(\"t\")]\nintensive = positives[positives.patient_addmited_to_intensive_care_unit_1_yes_0_no.eq(\"t\")]\n\nhome = positives.drop(list(regular.index) + list(semi.index) + list(intensive.index), axis=0, inplace=False)\n\nprint(len(regular), len(semi), len(intensive), len(home))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, from out Covid-19 positive patients, 36 got sent to the regular floor, 8 got sent into semi intensive care, another 8 got sent into intensive care and 506 were sent home.\nThis is definitely unbalanced, but it is the best we can do. Additionally, this doesnt mean that the homegoers have far more values, since this group seems to have much sparser information:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.concat([\n           pd.DataFrame(home.isnull().mean() * 100).rename(columns={0:\"Home\"}),\n           pd.DataFrame(regular.isnull().mean() * 100).rename(columns={0:\"Regular\"}),\n           pd.DataFrame(semi.isnull().mean() * 100).rename(columns={0:\"Semi\"}),\n           pd.DataFrame(intensive.isnull().mean() * 100).rename(columns={0:\"Intensive\"}),\n          ],\n           axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you can see, the missingness is by far the highest among the homegoers. That is not a problem, since this group makes up for it in numbers.\n\nNow, lets see if we can find differences in the 4 different groups, or \"strata\", in some of these parameters. First, lets get some helpers on the way:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def select_columns(column):\n    # returns a list of lists for the specified column for each stratum\n    return [np.array(stratum[column].dropna()) for stratum in [home,regular,semi,intensive]]\n\nfrom scipy.stats import f_oneway\n\ndef analyze(df,blacklist):\n    # run a oneway-anova between the for groups for each column and return the results\n    res = {}\n    for column in df.columns:\n        if column not in blacklist:\n            print(column + \":\")\n            try:\n                f, p = f_oneway(*select_columns(column))\n                print(\"p-Value: \" + str(p))\n                res.update({column : (f,p)})\n            except ValueError as e:\n                print(e)\n            \n    return res\n\n# we are not interested in the following columns:\n\nblacklist= ['patient_id', 'patient_age_quantile', 'sars_cov_2_exam_result',\n       'patient_addmited_to_regular_ward_1_yes_0_no',\n       'patient_addmited_to_semi_intensive_unit_1_yes_0_no',\n       'patient_addmited_to_intensive_care_unit_1_yes_0_no']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"analysis = analyze(positives,blacklist)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see, there are many low p-values. There also are some errors concerning the categorical columns, but we will handle them later on. Let's continue with our continous variables and conduct a p-value adjustment with False Discovery Rate. Since we have run many tests, some of them might be positive just by chance. To avoid that, we need a p-value-adjustment for multiple testing:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def fdr(p_vals):\n\n    from scipy.stats import rankdata\n    ranked_p_values = rankdata(p_vals)\n    fdr = p_vals * len(p_vals) / ranked_p_values\n    fdr[fdr > 1] = 1\n\n    return fdr","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"p_values = [x[1] for x in list(analysis.values())]\np_values= np.array(p_values)\n\nfdr(p_values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Even after correction, there are still some significant p-values! Lets see how many variables differ significantly between at least two of our groups:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"adj_p_values = fdr(p_values)\n\nprint(np.sum(adj_p_values < 0.05))\n\nsignificant_columns = list(map(list(analysis.keys()).__getitem__,list(np.where(adj_p_values < 0.05)[0])))\n\nprint(significant_columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The difference of six columns is statistically significant between the groups. It doesnt surprise us that most of these columns have something to do with the immune system! This indicates that we are on the right track.\n\nNext, lets take deeper look into each of these six columns and how exactly they differ between the groups:\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def column_generator(columns_of_interest):\n    \n    for column in columns_of_interest:\n        \n        values = np.array([stratum[column].dropna() for stratum in [home,regular,semi,intensive]])\n        treatments = np.repeat([\"Home\",\"Regular\",\"Semi\",\"Intensive\"], repeats= [len(x) for x in values])\n         \n        values = np.hstack(values)\n        # Stack the data (and rename columns):\n\n        value_df = pd.DataFrame(values.T,columns=[\"Values\"])\n        treatments_df = pd.DataFrame(treatments.T,columns=[\"Treatments\"])\n\n        stacked_data = pd.concat([treatments_df,value_df],axis=1)\n        stacked_data.name = column\n        \n        yield stacked_data\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.stats.multicomp import (pairwise_tukeyhsd,\n                                         MultiComparison)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set up the data for comparison (creates a specialised object)\nfor stacked_data in column_generator(significant_columns):\n    MultiComp = MultiComparison(stacked_data['Values'],\n                                stacked_data['Treatments'])\n\n    # Show all pair-wise comparisons:\n    \n    # Print the comparisons\n    print(\"Variable: \" + stacked_data.name)\n    print(MultiComp.tukeyhsd(alpha=0.05/len(significant_columns)).summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# interim result\npd.DataFrame(list(map(list(analysis.keys()).__getitem__,list(np.where(adj_p_values < 0.05)[0])))).to_csv(\"submission.csv\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}