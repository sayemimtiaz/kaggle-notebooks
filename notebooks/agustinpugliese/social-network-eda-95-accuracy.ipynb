{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Social network product purchase","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Hi I'm new to ML so I'd be glad to receive your feedback!","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**The objective of this analysis is to predict whether a person will buy a product displayed on a social network ad or not, given their age, gender and salary and to compare the accuracy of different classification algorithms.**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"*Importing Modules*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingRegressor, AdaBoostClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import roc_curve, auc\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nsns.set()\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Loading and getting to know the dataset**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = pd.read_csv('../input/social-network-ads/Social_Network_Ads.csv')\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**The set has:**\n\n   - Id column\n   - Gender: Categorical column (Male/Female)\n   - Numerical features: Age and Estimated Salary","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.describe().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- There are 400 people analyzed.\n- The age goes from 18 to 60 years.\n- The salary goes from 15000 USD to 150000 USD per year.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Are there any missing values?**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(pd.isnull(dataset).sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*There are no missing values*","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Let's see how gender, salary and age are distributed**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"*Gender*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['Gender'].value_counts().plot.pie(autopct='%1.1f%%',shadow=True,figsize=(6,6))\nplt.title('Gender percentages', fontsize = 20)\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(dataset['Gender'], palette = 'Set2')\nplt.title ('Gender vs. quantity', fontsize = 20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Age*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(dataset['Age'], bins = 5, color = 'orange', label = 'KDE')\nplt.legend()\nplt.gcf().set_size_inches(12, 5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Conclusion:**\n- Age is normally distributed around 37 years, and most of the people studied are from 35 to 45 years.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Let's see how age is distributed per gender**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (22,10))\nsns.countplot(x = 'Age',data = dataset , hue='Gender', palette = 'Set2')\nplt.legend(loc='upper center')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There seems to be equal analyzed people per gender per age, seeing only more men of 35 years.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"tag1 = 'Male'\ntag2 = 'Female'\nMale = dataset[dataset[\"Gender\"] == tag1][['Age','EstimatedSalary']]\nFemale = dataset[dataset[\"Gender\"] == tag2][['Age','EstimatedSalary']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, (ax1, ax2) = plt.subplots(1, 2, sharey = True)\n\nax1.scatter(Male.Age, Male.EstimatedSalary, c = 'green', s = 15, alpha = 0.7)\nax1.set_title('Male age vs. Estimated Salary', c = 'green')\nax2.scatter(Female.Age, Female.EstimatedSalary, c='red', s = 15, alpha = 0.7)\nax2.set_title('Female age vs. Estimated Salary', c ='red')\nplt.gcf().set_size_inches(15, 7)\n\nplt.ylabel('Estimated Salary', fontsize = 20)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Conclusion:** There is no correlation between the estimated salary of a male or female with their age.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Statistics for purchased column**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x=\"Age\", col = 'Purchased', data=dataset, kind = 'count', palette='pastel')\nplt.gcf().set_size_inches(20, 10)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x=\"Gender\", col = 'Purchased', data=dataset, kind = 'count', palette='pastel')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Conclusions:**\n- The product seem to be intended for people within the range of 50 - 60 years, and it also seems to be intended both for male and Female gender.\n- As we saw on the Age vs Salary plots, it seems that the women analyzed have higher income than men, so this might be a reason for the slight difference between gender in purchased or not terms.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Feature Engineering**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"First let´s drop the ID column as it doesn't give any information.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset2 = dataset.copy()\ndataset2 = dataset2.drop(['User ID'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Splitting features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = dataset2.iloc[:, 0:3]\ny = dataset2.iloc[:, -1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = pd.get_dummies(X)\nX = X[['Gender_Male','Gender_Female','Age','EstimatedSalary']]\nX = X.drop(['Gender_Male'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Splitting train - test","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Scaling data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# sc_X = MinMaxScaler()\n# X_train = sc_X.fit_transform(X_train)\n# X_test = sc_X.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Logistic regression modeling**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier = LogisticRegression(random_state = 0)\nclassifier.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Predictions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = classifier.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Accuracy with confusion matrix**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(y_test, y_pred)\n\ngroup_names = ['True Neg','False Pos','False Neg','True Pos']\ngroup_counts = ['{0:0.0f}'.format(value) for value in\n                cm.flatten()]\ngroup_percentages = ['{0:.2%}'.format(value) for value in\n                     cm.flatten()/np.sum(cm)]\n\nlabels = [f'{v1}\\n{v2}\\n{v3}' for v1, v2, v3 in\n          zip(group_names,group_counts,group_percentages)]\n\nlabels = np.asarray(labels).reshape(2,2)\n\nsns.heatmap(cm, annot = labels, fmt = '', cmap = 'Blues', cbar = False)\nplt.gcf().set_size_inches(5, 5)\nplt.title('Confusion Matrix Logistic Regression', fontsize = 20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**As we didn't scale the data, the results and accuracy are pretty low, let's see what happens with other models**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Accuracy of the regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_LR = accuracy_score(y_test,y_pred) *100\nprint('The accuracy of the logistic regression is: ' +str(accuracy_LR) + ' %.')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Parameters of the regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"parameters_LR = classifier.coef_\nparameters_LR","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Comparing classifier algorithms: Random Forest Classifier, K-NN, Naive Bayes, and Ensambled models**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def clf_model(model):\n    clf = model\n    clf.fit(X_train, y_train)\n    accuracy = accuracy_score(y_test, clf.predict(X_test).round())\n    return clf, accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_performance = pd.DataFrame(columns = [\"Model\", \"Accuracy\"])\n\nmodels_to_evaluate = [RandomForestClassifier(n_estimators=1000), KNeighborsClassifier(n_neighbors = 7, metric = \"minkowski\", p = 2),\n                      SVC(kernel = 'rbf'), GaussianNB(), GradientBoostingRegressor(n_estimators=300, learning_rate=0.01), \n                     AdaBoostClassifier(n_estimators=300, learning_rate=0.01), XGBClassifier(n_estimators=300, learning_rate=0.01)]\n\nfor model in models_to_evaluate:\n    clf, accuracy = clf_model(model)\n    model_performance = model_performance.append({\"Model\": model, \"Accuracy\": accuracy}, ignore_index=True)\n\nmodel_performance","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Conclusion:** \n- Random Forest classifier, K-NN, SVC and Naive Bayes all reach a better accuracy than logistic regression even without scaling the data.\n- Scaling the data with MinMaxScaler (commented above) made all the models reach an accuracy of 92.5%\n- Ensambled models reached a better accuracy > 93%.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**CAP curve for model evaluation**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Cumulative Cccuracy Profile curve is a tool that will help evaluate the performance and accuracy of the classification model. I'm going to compare three models (SVC, K-NN and XGBoost) which all have different accuracy score. To do this, I'll compare how CAP curves for these algorithms relate to a random model and to an ideal model.\n\nAs the CAP curve gets more and more similar to the ideal model, the accuracy of the algorithm improves. We might expect that area under the plots increase as the accuracy improves. (Ideal model > XGClassifier > K-NN > SVC > Random model)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**XGClassifier**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"XGclassifier = XGBClassifier(n_estimators=300, learning_rate=0.01)\nXGclassifier.fit(X_train, y_train)\ny_pred_xg = XGclassifier.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**K-NN**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"KNN = KNeighborsClassifier(n_neighbors = 7, metric = \"minkowski\", p = 2)\nKNN.fit(X_train, y_train)\ny_pred_knn = KNN.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**SVC**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"SVC_clf = SVC(kernel = 'rbf')\nSVC_clf.fit(X_train, y_train)\ny_pred_SVC = SVC_clf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Plotting CAP**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# length of the test data \ntotal = len(y_test) \n  \n# Counting '1' labels in test data \none_count = np.sum(y_test) \n  \n# counting '0' lables in test data  \nzero_count = total - one_count \n\nplt.figure(figsize = (10, 6)) \n  \n# x-axis ranges from 0 to total people on y_test  \n# y-axis ranges from 0 to the total positive outcomes. \n\n# K-NN plot\n\nK = [y for _, y in sorted(zip(y_pred_knn, y_test), reverse = True)] \n\nx = np.arange(0, total + 1) # Shape of Y_test\ny = np.append([0], np.cumsum(K)) # Y values\n\nplt.plot(x, y, c = 'green', label = 'K-NN', linewidth = 2)\n\n# SVC Plot\n\nS = [y for _, y in sorted(zip(y_pred_SVC, y_test), reverse = True)] \n\nx2 = np.arange(0, total + 1) # Shape of Y_test\ny2 = np.append([0], np.cumsum(S)) # Y values\n\nplt.plot(x2, y2, c = 'orange', label = 'SVC', linewidth = 2)\n\n\n# XGClassifier plot \n\nXG = [y for _, y in sorted(zip(y_pred_xg, y_test), reverse = True)] \n\nx3 = np.arange(0, total + 1) # Shape of Y_test\ny3 = np.append([0], np.cumsum(XG)) # Y values\n\nplt.plot(x3, y3, c = 'red', label = 'XGClassifier', linewidth = 2)\n\n\n# Random Model plot\n  \nplt.plot([0, total], [0, one_count], c = 'blue',  \n         linestyle = '--', label = 'Random Model') \n\n# Perfect model plot\n\nplt.plot([0, one_count, total], [0, one_count, one_count], \n         c = 'grey', linewidth = 2, label = 'Perfect Model') \n\nplt.title('Cumulative Accuracy Profile of different models', fontsize = 20)\nplt.xlabel('Total y_test observations', fontsize = 15)\nplt.ylabel('N° class 1 scores', fontsize = 15)\nplt.legend() \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Area analysis (AUC)**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Area under Random Model\na = auc([0, total], [0, one_count])\n\n# Area between Perfect and Random Model\naP = auc([0, one_count, total], [0, one_count, one_count]) - a\n\n# Area K-NN\n\naKNN = auc(x, y) - a\nprint(\"Accuracy Rate for K-NN: {}\".format(aKNN / aP))\n\n# Area SVC\n\naSVC = auc(x2, y2) - a\nprint(\"Accuracy Rate for Support Vector Classifier: {}\".format(aSVC / aP))\n\n# Area XGClassifier\n\naXG = auc(x3, y3) - a\nprint(\"Accuracy Rate for XGClassifier: {}\".format(aXG / aP))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Conclusion:** \n- As expected, XGclassifier with an accuracy of 0.95 has almost the same area under the curve as the ideal model.\n- SVC and K-NN have the same Accuracy rate from the AUC although they don't have the same accuracy score. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Plotting ROC**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Receiver Operating Characteristic curve is another way to evaluate the accuracy of classification models and also to compare between them.\n\nIt plots the True Positive Rate in the Y-axis and False Positive Rate in the X-axis. It is a way to summarize information that could be obtained from many confusion matrices.\n\nAs the AUC gets bigger, the model is better at classifying.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fpr, tpr, thresholds = roc_curve(y_test, y_pred_knn)\n\nfpr2, tpr2, thresholds2 = roc_curve(y_test, y_pred_SVC)\n\nfpr3, tpr3, thresholds3 = roc_curve(y_test, y_pred_xg)\n\nroc_auc = auc(fpr, tpr)\nroc_auc2 = auc(fpr2, tpr2)\nroc_auc3 = auc(fpr3, tpr3)\n\nplt.figure(figsize = (10, 6)) \n\nplt.plot(fpr, tpr, c = 'green', linewidth = 2, label = 'K-NN AUC:' + ' {0:.2f}'.format(roc_auc))\nplt.plot(fpr2, tpr2, c = 'orange', linewidth = 2, label = 'Support Vector Classifier AUC:' + ' {0:.2f}'.format(roc_auc2))\nplt.plot(fpr3, tpr3, c = 'red', linewidth = 2, label = 'XGClassifier AUC:' + ' {0:.2f}'.format(roc_auc3))\nplt.plot([0,1], [0,1], c = 'blue', linestyle = '--')\n\nplt.xlabel('False Positive Rate', fontsize = 15)\nplt.ylabel('True Positive Rate', fontsize = 15)\nplt.title('ROC', fontsize = 20)\nplt.legend(loc = 'lower right', fontsize = 13)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Conclusion:**\n- Having calculated the accuracy score, ROC and CAP, we can certainly say that the XGClassifier ensembled model is the best one yet at classifying this dataset.\n- Logistic regression might have been improved scaling data, but as more robust models where used, there was no imperative need.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Thanks for reaching the end! Upvote if you liked it!","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}