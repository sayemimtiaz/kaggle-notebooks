{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Semantic Segmentation Exercise - I\nData Set: https://www.kaggle.com/bulentsiyah/semantic-drone-dataset\nGenerate the mask images for Original images. Labeled mask images are available in labeled_images_semantic. \nHints: \nNeed to choose the proper activation function. \nFeel free to add additional layers.\nTake 10% test data\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images_fpath='/kaggle/input/semantic-drone-dataset/dataset/semantic_drone_dataset/original_images/'\nmasks_fpath='/kaggle/input/semantic-drone-dataset/RGB_color_image_masks/RGB_color_image_masks/'\n#masks_fpath= '/kaggle/input/semantic-drone-dataset/dataset/semantic_drone_dataset/label_images_semantic/'\n\n#test_fpath='../input/3d_images/'\n#test_masks_fpath='../input/3d_masks/'\nprint(os.listdir('/kaggle/input/semantic-drone-dataset/dataset/semantic_drone_dataset/original_images/'))\nprint(os.listdir('/kaggle/input/semantic-drone-dataset/RGB_color_image_masks/RGB_color_image_masks/'))\n#print(os.listdir('/kaggle/input/semantic-drone-dataset/dataset/semantic_drone_dataset/label_images_semantic/'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Start your code here...."},{"metadata":{"trusted":true},"cell_type":"code","source":"from PIL import Image\nimport cv2\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\n#for building and training the U-Net model\nfrom tensorflow.keras.layers import Conv2D, Input, Concatenate, MaxPooling2D, Conv2DTranspose\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.models import Model\n\nprint(\"Loaded all libraries\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\ndef load_images_masks(path_images,path_masks):\n    images = os.listdir(path_images)\n    masks = os.listdir(path_masks)\n    images_list = []\n    mask_list = []\n\n    for i in images:\n        im = Image.open(path_images + i)\n        im1 = np.array(im.resize((128,128)))/255\n        images_list.append(im1)\n    del im,im1\n    for i in masks:\n        mask = Image.open(path_masks + i)\n        mask1 = np.array(mask.resize((128,128)))/255\n        mask_list.append(mask1)\n    del mask,mask1\n    return images_list,mask_list"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"No. of images =\",len(os.listdir(images_fpath)))\nprint(\"No. of image masks =\",len(os.listdir(masks_fpath)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#1 example let's pick image id '000'\ndef plot_img_and_mask(id):\n    img = cv2.imread(images_fpath + id + '.jpg')\n    img_mask = cv2.imread(masks_fpath + id + '.png')\n    plt.figure(figsize=(10,10))\n    plt.subplot(1,3,1,title='Actual image')\n    plt.imshow(img,cmap='gray')\n    plt.subplot(1,3,3,title='Image mask')\n    plt.imshow(img_mask,cmap='gray')\n    \nplot_img_and_mask('000')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_img_and_mask('140')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_img_and_mask('160')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"def initialize_img_data(folder):\n    lst=[] \n    for image in os.listdir(folder):\n        #load image in grayscale\n        img= cv2.imread(folder+\"/\"+image)\n        #convert to array\n        img_array=Image.fromarray(img)\n        #resize image\n        resize_img = img_array.resize((128 , 128))\n        #divide by 255 -> scaling data\n        norm_img=np.array(resize_img)/255\n        #expand dimensions\n        img_array = norm_img.reshape((128,128))#np.expand_dims(norm_img,axis=3)\n        lst.append(img_array)\n        del img, img_array,resize_img,norm_img\n        lst.sort()\n    return lst\n    \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\ndef sorted_alphanum(data):\n    convert = lambda text: int(text) if text.isdigit() else text.lower()\n    alphanum_key = lambda key: [ convert(c) for c in re.split('([0-9]+)', key) ] \n    return sorted(data, key=alphanum_key)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_images_masks(path_images,path_masks):\n    images = os.listdir(path_images)\n    masks = os.listdir(path_masks)\n    images_list = []\n    masks_list = []\n    print(len(images))\n\n    \n    images2 = sorted_alphanum(images)\n    masks2 = sorted_alphanum(masks)\n    \n    \n    for i in images2:\n        im = Image.open(path_images + i)\n        im1 = np.array(im.resize((128,128)))/255\n        images_list.append(im1)\n \n    for i in masks2:\n        mask = Image.open(path_masks + i)\n        mask1 = np.array(mask.resize((128,128)))/255\n        masks_list.append(mask1)\n        \n    return images_list,masks_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X,y=load_images_masks(images_fpath,masks_fpath)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#quick verification whether all the data is initialized or not\nprint(len(os.listdir(images_fpath)),len(X),len(y))\nprint(X[0].shape,y[0].shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#check data once they are loaded\nplt.figure(figsize=(10,10))\nplt.subplot(1,3,1,title='Original image')\nplt.imshow(X[100],cmap='viridis')\n\nplt.subplot(1,3,3,title='Image mask')\nplt.imshow(y[100],cmap='viridis')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Start your code here...."},{"metadata":{"trusted":true},"cell_type":"code","source":"X = np.array(X)\ny = np.array(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X.shape)\nprint(y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import all libraries for UNET model\nfrom tensorflow.keras.layers import Conv2D, Input, Concatenate, MaxPooling2D, Conv2DTranspose\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.models import Model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build U-Net model - Define layers\ninputs = Input(shape=(128, 128, 3))\n\nc1 = Conv2D(8, (3, 3), activation='relu', padding='same') (inputs)\nc1 = Conv2D(8, (3, 3), activation='relu', padding='same') (c1)\np1 = MaxPooling2D((2, 2)) (c1)\n\nc2 = Conv2D(16, (3, 3), activation='relu', padding='same') (p1)\nc2 = Conv2D(16, (3, 3), activation='relu', padding='same') (c2)\np2 = MaxPooling2D((2, 2)) (c2)\n\nc3 = Conv2D(32, (3, 3), activation='relu', padding='same') (p2)\nc3 = Conv2D(32, (3, 3), activation='relu', padding='same') (c3)\np3 = MaxPooling2D((2, 2)) (c3)\n\nc4 = Conv2D(64, (3, 3), activation='relu', padding='same') (p3)\nc4 = Conv2D(64, (3, 3), activation='relu', padding='same') (c4)\np4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n\nc5 = Conv2D(128, (3, 3), activation='relu', padding='same') (p4)\nc5 = Conv2D(128, (3, 3), activation='relu', padding='same') (c5)\n\nu6 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c5)\nu6 = Concatenate()([u6, c4])\nc6 = Conv2D(64, (3, 3), activation='relu', padding='same') (u6)\nc6 = Conv2D(64, (3, 3), activation='relu', padding='same') (c6)\n\nu7 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c6)\nu7 = Concatenate()([u7, c3])\nc7 = Conv2D(32, (3, 3), activation='relu', padding='same') (u7)\nc7 = Conv2D(32, (3, 3), activation='relu', padding='same') (c7)\n\nu8 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c7)\nu8 = Concatenate()([u8, c2])\nc8 = Conv2D(16, (3, 3), activation='relu', padding='same') (u8)\nc8 = Conv2D(16, (3, 3), activation='relu', padding='same') (c8)\n\nu9 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (c8)\nu9 = Concatenate()([u9, c1]) #removed ,axis=3\nc9 = Conv2D(8, (3, 3), activation='relu', padding='same') (u9)\nc9 = Conv2D(8, (3, 3), activation='relu', padding='same') (c9)\n\noutputs = Conv2D(3, (1, 1), activation='relu') (c9)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Model(inputs=[inputs], outputs=[outputs])\nmodel.compile(optimizer='adam', loss='binary_crossentropy')\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#early_stop = EarlyStopping(patience=5)\n#check_point = ModelCheckpoint('model.hdf5',save_best_only=True)\n#model.fit(x_train, y_train, epochs=20, callbacks=[early_stop,check_point])\nmodel.fit(x_train, y_train, epochs=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils import plot_model\nplot_model(model,to_file='model.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_test = model.predict(x_test, verbose=1)\n#print(y_train[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# End your code here..."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(1 , figsize = (15, 9))\nn = 0 \nfor i in range(4):\n    n += 1 \n    #r = np.random.randint(0, x_test.shape[0], 1)\n    r=[i]\n    plt.subplot(2, 2, n)\n    plt.subplots_adjust(hspace = 0.5, wspace = 0.5)\n    plt.imshow(x_test[r[0]])\n    plt.imshow(pred_test[r[0]], alpha=0.5)\n    \n\nplt.suptitle(\"Annotated images...\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(1 , figsize = (15, 9))\nn = 0 \nfor i in range(6):\n    n += 1 \n    #r = np.random.randint(0, x_test.shape[0], 1)\n    r=[i]\n    plt.subplot(3, 2, n)\n    plt.subplots_adjust(hspace = 0.5, wspace = 0.5)\n    plt.imshow(x_test[r[0]])\n    plt.imshow(y_test[r[0]], alpha=0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}