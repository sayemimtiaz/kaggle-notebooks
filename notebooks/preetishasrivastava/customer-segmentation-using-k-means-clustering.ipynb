{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Problem Statement:","metadata":{}},{"cell_type":"markdown","source":"Customer Segmentation is a popular application of unsupervised learning. Using clustering, identify segments of customers to target the potential user base. They divide customers into groups according to common characteristics like gender, age, interests, and spending habits so they can market to each group effectively.\n\nUse K-means clustering and also visualize the gender and age distributions. Then analyze their annual incomes and spending scores.","metadata":{}},{"cell_type":"markdown","source":"### -------------------------------------------------------------------------------------------------------------------------------------","metadata":{}},{"cell_type":"markdown","source":"**Data Set Information**\nThe dataset can be downloaded from: https://drive.google.com/file/d/19BOhwz52NUY3dg8XErVYglctpr5sjTy4/view\n\nThe information of various columns of the dataset are:-\n\n**Features**\n\n|Column Name |Data Type|Description|\n|-----|-----|-----|\n|CustomerID|Numerical|It contains the ID of the customers, used for model building|\n|Gender|Categorical|It has 2 categories, i.e., 'Male' and 'Female'|\n|Age|Numerical|It contains the age of the customers(in yrs.)|\n|Annual Income|Numerical|It contains annual income of a customer(in Dollar)|\n|Spending Score (1-100)|Numerical|This contains the score between 1-100 for a customer, known as spending score|","metadata":{}},{"cell_type":"markdown","source":"### ------------------------------------------------------------------------------------------------------------------------------------","metadata":{}},{"cell_type":"markdown","source":"###  Importing necessary libraries\n\nThe following code is written in Python 3.x. Libraries provide pre-written functionality to perform necessary tasks.","metadata":{}},{"cell_type":"code","source":"import pandas as pd                 #Importing Pandas\nimport numpy as np                  #Importing NumPy\nimport matplotlib.pyplot as plt     #Importing Matplotlib \nimport seaborn as sns               #Importing Seaborn\nfrom sklearn.cluster import KMeans  #Importing the K-Means Clustering Algorithm\n%matplotlib inline                  \n\n#It allows us to add plots to the browser interface, instead of showing a new terminal.","metadata":{"execution":{"iopub.status.busy":"2021-06-10T11:18:45.194827Z","iopub.execute_input":"2021-06-10T11:18:45.195227Z","iopub.status.idle":"2021-06-10T11:18:46.786308Z","shell.execute_reply.started":"2021-06-10T11:18:45.195143Z","shell.execute_reply":"2021-06-10T11:18:46.78526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# loading the dataset in the variable called 'df'\n\ndf= pd.read_csv('../input/customer-segmentation-tutorial-in-python/Mall_Customers.csv')\n\ndf.head()          # To view top 5 entries in the dataset.\n\n# in order to view bottom 5 entries, we can do\n#df.tail()\n\n#in order to view more than 5 entries, we can enter any integer value into '()'.\n#Ex: df.head(10) or df.tail(15), etc","metadata":{"execution":{"iopub.status.busy":"2021-06-10T11:18:46.788781Z","iopub.execute_input":"2021-06-10T11:18:46.78922Z","iopub.status.idle":"2021-06-10T11:18:46.859586Z","shell.execute_reply.started":"2021-06-10T11:18:46.789176Z","shell.execute_reply":"2021-06-10T11:18:46.858314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Renaming the columns as per our convenience!!\n\ndf.rename(columns={'Annual Income (k$)':'Annual Income', 'Spending Score (1-100)':'Spending Score'},inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T11:18:46.861333Z","iopub.execute_input":"2021-06-10T11:18:46.861776Z","iopub.status.idle":"2021-06-10T11:18:46.86865Z","shell.execute_reply.started":"2021-06-10T11:18:46.861712Z","shell.execute_reply":"2021-06-10T11:18:46.867172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now, we let us see all the column names.\n\ndf.columns","metadata":{"execution":{"iopub.status.busy":"2021-06-10T11:18:46.870688Z","iopub.execute_input":"2021-06-10T11:18:46.871289Z","iopub.status.idle":"2021-06-10T11:18:46.885679Z","shell.execute_reply.started":"2021-06-10T11:18:46.87124Z","shell.execute_reply":"2021-06-10T11:18:46.884431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We can see that the column named 'CustomerID' can be removed from the dataset as it is unique for each customer and cannot be\n#used further for any predictions.\n\ndf.drop(['CustomerID'],axis=1,inplace=True)\n\n# If axis=0, it consitutes row operation. Since we have to remove the column, we do axis=1","metadata":{"execution":{"iopub.status.busy":"2021-06-10T11:18:46.889132Z","iopub.execute_input":"2021-06-10T11:18:46.889443Z","iopub.status.idle":"2021-06-10T11:18:46.900963Z","shell.execute_reply.started":"2021-06-10T11:18:46.889414Z","shell.execute_reply":"2021-06-10T11:18:46.900074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info() # This gives the information like no. of non- null values and data types of the columns.","metadata":{"execution":{"iopub.status.busy":"2021-06-10T11:18:46.904513Z","iopub.execute_input":"2021-06-10T11:18:46.905281Z","iopub.status.idle":"2021-06-10T11:18:46.932774Z","shell.execute_reply.started":"2021-06-10T11:18:46.905231Z","shell.execute_reply":"2021-06-10T11:18:46.930947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe() # To obtain the descriptive analysis of the numerical columns in the dataset","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-06-10T11:18:46.934252Z","iopub.execute_input":"2021-06-10T11:18:46.934829Z","iopub.status.idle":"2021-06-10T11:18:46.967855Z","shell.execute_reply.started":"2021-06-10T11:18:46.934781Z","shell.execute_reply":"2021-06-10T11:18:46.96675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now let us check for the shape of the dataset and also that are any null values present in our dataset.\n# For that,\n\nprint('shape of the dataset=', df.shape)\n\nprint(' \\nThe null count of each column of the dataset are as follows:')\ndf.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-06-10T11:18:46.969199Z","iopub.execute_input":"2021-06-10T11:18:46.969511Z","iopub.status.idle":"2021-06-10T11:18:46.979443Z","shell.execute_reply.started":"2021-06-10T11:18:46.96948Z","shell.execute_reply":"2021-06-10T11:18:46.978215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Observation:\n- From the above cell, we can see that there are no null values present in the dataset.","metadata":{}},{"cell_type":"code","source":"# Function to identify numeric features:\ndef numeric_features(dataset):\n    numeric_col = dataset.select_dtypes(include=np.number).columns.tolist()\n    return dataset[numeric_col].head()\n    \nnumeric_columns = numeric_features(df)\nprint(\"Numerical Features:\")\nprint(numeric_columns)\n\nprint(\"====\"*20)\n\n# Function to identify categorical features:\ndef categorical_features(dataset):\n    categorical_col = dataset.select_dtypes(exclude=np.number).columns.tolist()\n    return dataset[categorical_col].head()\n\ncategorical_columns = categorical_features(df)\nprint(\"Categorical Features:\")\nprint(categorical_columns)\n\nprint(\"====\"*20)\n\n# Function to check the datatypes of all the columns:\ndef check_datatypes(dataset):\n    return dataset.dtypes\n\nprint(\"Datatypes of all the columns:\")\ncheck_datatypes(df)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T11:18:46.980876Z","iopub.execute_input":"2021-06-10T11:18:46.981177Z","iopub.status.idle":"2021-06-10T11:18:47.007251Z","shell.execute_reply.started":"2021-06-10T11:18:46.981149Z","shell.execute_reply":"2021-06-10T11:18:47.005953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Detect outliers in the continuous columns\n\nOutliers are observations that lie far away from majority of observations in the dataset and can be represented mathematically in different ways.\n\nOne method of defining outliers are: outliers are data points lying beyond **(third quartile + 1.5xIQR)** and below **(first quartile - 1.5xIQR)**. \n\n- The function below takes a dataframe and outputs the number of outliers in every numeric feature based on the above rule of *IQR* \n\nYou can even modify the function below to capture the outliers as per their other definitions. ","metadata":{}},{"cell_type":"code","source":"# Function to detect outliers in every feature\ndef detect_outliers(df):\n    cols = list(df)\n    outliers = pd.DataFrame(columns = ['Feature', 'Number of Outliers'])\n    for column in cols:\n        if column in df.select_dtypes(include=np.number).columns:\n            q1 = df[column].quantile(0.25)\n            q3 = df[column].quantile(0.75)\n            iqr = q3 - q1\n            fence_low = q1 - (1.5*iqr)\n            fence_high = q3 + (1.5*iqr)\n            outliers = outliers.append({'Feature':column, \n                            'Number of Outliers':df.loc[(df[column] < fence_low)|(df[column] > fence_high)].shape[0]},\n                             ignore_index=True)\n    return outliers\n\ndetect_outliers(df)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T11:18:47.009501Z","iopub.execute_input":"2021-06-10T11:18:47.009988Z","iopub.status.idle":"2021-06-10T11:18:47.071001Z","shell.execute_reply.started":"2021-06-10T11:18:47.009937Z","shell.execute_reply":"2021-06-10T11:18:47.069805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#####  Observation:\n- From the above output, it is clear that almost there is no outlier data present in the dataset","metadata":{}},{"cell_type":"markdown","source":"### ------------------------------------------------------------------------------------------------------------------------------------","metadata":{}},{"cell_type":"markdown","source":"## EDA & Data Visualizations\n\nExploratory data analysis is an approach to analyzing data sets by summarizing their main characteristics with visualizations. The EDA process is a crucial step prior to building a model in order to unravel various insights that later become important in developing a robust algorithmic model.","metadata":{}},{"cell_type":"markdown","source":"### Univariate analysis\n\nUnivariate analysis means analysis of a single variable. Itâ€™s mainly describes the characteristics of the variable.","metadata":{}},{"cell_type":"code","source":"sns.countplot(df['Gender'])","metadata":{"execution":{"iopub.status.busy":"2021-06-10T11:18:47.072496Z","iopub.execute_input":"2021-06-10T11:18:47.072914Z","iopub.status.idle":"2021-06-10T11:18:47.225861Z","shell.execute_reply.started":"2021-06-10T11:18:47.07287Z","shell.execute_reply":"2021-06-10T11:18:47.224713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Observation:\n- From the above countplot, we can say that there are more female entries in the dataset when compared to male.","metadata":{}},{"cell_type":"code","source":"sns.distplot(df['Age'], bins=30)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T11:18:47.227312Z","iopub.execute_input":"2021-06-10T11:18:47.227725Z","iopub.status.idle":"2021-06-10T11:18:47.488843Z","shell.execute_reply.started":"2021-06-10T11:18:47.227679Z","shell.execute_reply":"2021-06-10T11:18:47.487595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Observation:\n- From the distplot and the descriptive analysis run on the dataset, it is visible that the age column contains values that are almost normally distributed. The kde on the distplot looks like a bell-curve.","metadata":{}},{"cell_type":"markdown","source":"### Bivariate Analysis \n\nBivariate analysis involves checking the relationship between two variables simultaneously.","metadata":{}},{"cell_type":"code","source":"sns.boxplot(df['Gender'], df['Age'])","metadata":{"execution":{"iopub.status.busy":"2021-06-10T11:18:47.490574Z","iopub.execute_input":"2021-06-10T11:18:47.491047Z","iopub.status.idle":"2021-06-10T11:18:47.637259Z","shell.execute_reply.started":"2021-06-10T11:18:47.491005Z","shell.execute_reply":"2021-06-10T11:18:47.636288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Observation:\n- From the boxplot we can see that the average age of females in the dataset is more than the male in the dataset. Also, there is no outlier present in the dataset","metadata":{}},{"cell_type":"markdown","source":"**Seaborn Pairplot**\n\nSeaborn Pairplot uses to get the relation between each and every variable present in Pandas DataFrame. It works like a seaborn scatter plot but it plot only two variables plot and sns paiplot plot the pairwise plot of multiple features/variable in a grid format","metadata":{}},{"cell_type":"code","source":"sns.pairplot(df)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T11:18:47.63838Z","iopub.execute_input":"2021-06-10T11:18:47.638651Z","iopub.status.idle":"2021-06-10T11:18:49.655002Z","shell.execute_reply.started":"2021-06-10T11:18:47.638625Z","shell.execute_reply":"2021-06-10T11:18:49.65394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-10T11:18:49.656179Z","iopub.execute_input":"2021-06-10T11:18:49.656459Z","iopub.status.idle":"2021-06-10T11:18:49.668702Z","shell.execute_reply.started":"2021-06-10T11:18:49.656431Z","shell.execute_reply":"2021-06-10T11:18:49.667217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### --------------------------------------------------------------------------------------------------------------------------------------","metadata":{}},{"cell_type":"markdown","source":"## Treating the categorical feature:\n- As we all know that ML algorithms do not work with alphabetical values, we need to convert these values to numerical data.\n- In this dataset, the only alphabetical column is the categorical column, called `Gender`.\n- It contains the gender of the customer as **Male** or **Female**.\n- So, we can assign or `map` the values of male and female entries in the given dataset as shown below.","metadata":{}},{"cell_type":"code","source":"gender= {'Male':0, 'Female':1}\ndf['Gender']= df['Gender'].map(gender)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T11:18:49.670028Z","iopub.execute_input":"2021-06-10T11:18:49.670315Z","iopub.status.idle":"2021-06-10T11:18:49.680873Z","shell.execute_reply.started":"2021-06-10T11:18:49.670288Z","shell.execute_reply":"2021-06-10T11:18:49.679867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Looking at the head of the dataset to see if the maping works!\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-10T11:18:49.682156Z","iopub.execute_input":"2021-06-10T11:18:49.682456Z","iopub.status.idle":"2021-06-10T11:18:49.697259Z","shell.execute_reply.started":"2021-06-10T11:18:49.682428Z","shell.execute_reply":"2021-06-10T11:18:49.696178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Checking the correlation of the features with the help of 'Heatmap'","metadata":{}},{"cell_type":"markdown","source":"A **correlation** between two random vairables describes a statistical association, which basically means how close these two random variables are to having a linear relation ship. The correlation can range between -1 and 1:\n\n- A correlation of 1 means the variables are perfectly correlated.\n- A correlation of 0 means there is no corerlation between teh variables.\n- A corerlation of -1 means the variabels are prefectly negatively corerlated","metadata":{}},{"cell_type":"code","source":"sns.heatmap(df.corr(), annot=True, cmap='magma')","metadata":{"execution":{"iopub.status.busy":"2021-06-10T11:18:49.698417Z","iopub.execute_input":"2021-06-10T11:18:49.698708Z","iopub.status.idle":"2021-06-10T11:18:50.013185Z","shell.execute_reply.started":"2021-06-10T11:18:49.69868Z","shell.execute_reply":"2021-06-10T11:18:50.012279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Observation:\n\n- From the above heatmap, we can find that 'Age' is negatively correlated with the 'Annual Income' and 'Spending Score'. \n- 'Annual Income' is very very less correlated 'Spending Score'.\n- 'Gender' is very less correlated with 'Spending Score' but more correlated, when compared to 'Annual Income'!","metadata":{}},{"cell_type":"markdown","source":"### ------------------------------------------------------------------------------------------------------------------------------------","metadata":{}},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2021-06-10T11:18:50.014581Z","iopub.execute_input":"2021-06-10T11:18:50.015254Z","iopub.status.idle":"2021-06-10T11:18:50.022414Z","shell.execute_reply.started":"2021-06-10T11:18:50.015204Z","shell.execute_reply":"2021-06-10T11:18:50.021199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Separating the dataset variables as feature and target variables.\n\nx= df['Annual Income'] # Feature\ny= df['Spending Score'] #Label/ Target","metadata":{"execution":{"iopub.status.busy":"2021-06-10T11:18:50.023606Z","iopub.execute_input":"2021-06-10T11:18:50.023898Z","iopub.status.idle":"2021-06-10T11:18:50.037555Z","shell.execute_reply.started":"2021-06-10T11:18:50.023871Z","shell.execute_reply":"2021-06-10T11:18:50.036321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop('Spending Score', axis=1, inplace=True)  # Dropping the target variable as that will be used in prediction!\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-10T11:18:50.039297Z","iopub.execute_input":"2021-06-10T11:18:50.039956Z","iopub.status.idle":"2021-06-10T11:18:50.060461Z","shell.execute_reply.started":"2021-06-10T11:18:50.039919Z","shell.execute_reply":"2021-06-10T11:18:50.05929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model training:\n### Model used: **KMeans Clustering**\n\n- K Means Clustering is an unsupervised learning algorithm that tries to cluster data based on their similarity. Unsupervised learning means that there is no outcome to be predicted, and the algorithm just tries to find patterns in the data. \n- In k means clustering, we have the specify the number of clusters we want the data to be grouped into. \n- The algorithm randomly assigns each observation to a cluster, and finds the centroid of each cluster. Then, the algorithm iterates through two steps:\n    1. Reassign data points to the cluster whose centroid is closest. \n    2. Calculate new centroid of each cluster. \n\n\n- These two steps are repeated till the within cluster variation cannot be reduced any further. \n- The within cluster variation is calculated as the sum of the euclidean distance between the data points and their respective cluster centroids.","metadata":{}},{"cell_type":"code","source":"# Let us Randomly assume that the number of clusters or groups in with the customers can be divided are 2.\n\nkm= KMeans(n_clusters=2)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T11:18:50.061708Z","iopub.execute_input":"2021-06-10T11:18:50.062013Z","iopub.status.idle":"2021-06-10T11:18:50.076699Z","shell.execute_reply.started":"2021-06-10T11:18:50.061985Z","shell.execute_reply":"2021-06-10T11:18:50.075563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=pd.DataFrame({'x1':df['Annual Income'],'x2':df['Gender'],'y': y})","metadata":{"execution":{"iopub.status.busy":"2021-06-10T11:18:50.078518Z","iopub.execute_input":"2021-06-10T11:18:50.078987Z","iopub.status.idle":"2021-06-10T11:18:50.092258Z","shell.execute_reply.started":"2021-06-10T11:18:50.078943Z","shell.execute_reply":"2021-06-10T11:18:50.091057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"km.fit(data)    # Fitting the K-Means algorithm on the dataset.","metadata":{"execution":{"iopub.status.busy":"2021-06-10T11:18:50.096094Z","iopub.execute_input":"2021-06-10T11:18:50.096487Z","iopub.status.idle":"2021-06-10T11:18:50.134191Z","shell.execute_reply.started":"2021-06-10T11:18:50.096452Z","shell.execute_reply":"2021-06-10T11:18:50.133355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yp=km.predict(data)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T11:18:50.135164Z","iopub.execute_input":"2021-06-10T11:18:50.135476Z","iopub.status.idle":"2021-06-10T11:18:50.146837Z","shell.execute_reply.started":"2021-06-10T11:18:50.135447Z","shell.execute_reply":"2021-06-10T11:18:50.145545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Let us plot the `Scatter Plot` to view the 2 clusters obtained.","metadata":{}},{"cell_type":"code","source":"plt.scatter(x,y,c=yp)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T11:18:50.148696Z","iopub.execute_input":"2021-06-10T11:18:50.149194Z","iopub.status.idle":"2021-06-10T11:18:50.302623Z","shell.execute_reply.started":"2021-06-10T11:18:50.149146Z","shell.execute_reply":"2021-06-10T11:18:50.301599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ------------------------------------------------------------------------------------------------------------------------","metadata":{}},{"cell_type":"markdown","source":"## Finding correct number of clusters:\n\n### `The Elbow Method`\n\n- The Elbow Method is one of the most popular methods to determine this optimal value of k.  \n- From the above visualization, we can see that the optimal number of clusters should be around 2\n- The below function will calculate the correct value of 'K', i.e., the number of clusters present in our dataset.","metadata":{}},{"cell_type":"code","source":"wcss=[]\n\nfor i in range(1, 11):\n    kmeans = KMeans(n_clusters = i, init = 'k-means++', \n                    max_iter = 300, n_init = 10, random_state = 42)\n    kmeans.fit(data)\n    wcss.append(kmeans.inertia_)\n    \n# Plotting the results onto a line graph, \n# allowing us to observe 'The elbow'\nplt.figure(figsize=(10,5))\nplt.plot(range(1, 11), wcss)\nplt.title('The elbow method', fontweight=\"bold\")\nplt.xlabel('Number of clusters(K)')\nplt.ylabel('within Clusters Sum of Squares(WCSS)') # Within cluster sum of squares","metadata":{"execution":{"iopub.status.busy":"2021-06-10T11:18:50.303927Z","iopub.execute_input":"2021-06-10T11:18:50.304221Z","iopub.status.idle":"2021-06-10T11:18:50.939591Z","shell.execute_reply.started":"2021-06-10T11:18:50.304193Z","shell.execute_reply":"2021-06-10T11:18:50.938271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Observation:\n\n- From the above graph, we can say that the best classification or clustering of data can be done into 5 groups. ","metadata":{}},{"cell_type":"code","source":"# Applying K-Means to the dataset / Creating the K-Means classifier, with 5 number of clusters.\nkm= KMeans(n_clusters=5)\nkm.fit(data)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T11:18:50.941418Z","iopub.execute_input":"2021-06-10T11:18:50.941866Z","iopub.status.idle":"2021-06-10T11:18:50.982411Z","shell.execute_reply.started":"2021-06-10T11:18:50.941832Z","shell.execute_reply":"2021-06-10T11:18:50.981611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yp=km.predict(data)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T11:18:50.983503Z","iopub.execute_input":"2021-06-10T11:18:50.983988Z","iopub.status.idle":"2021-06-10T11:18:50.990592Z","shell.execute_reply.started":"2021-06-10T11:18:50.98394Z","shell.execute_reply":"2021-06-10T11:18:50.989601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.scatter(data['x1'],data['y'],c=yp)\nplt.title(\"Clustering customers based on Annual Income and Spending score\", fontsize=15,fontweight=\"bold\")\nplt.xlabel(\"Annual Income\")\nplt.ylabel(\"Spending Score\")","metadata":{"execution":{"iopub.status.busy":"2021-06-10T11:18:50.992069Z","iopub.execute_input":"2021-06-10T11:18:50.992411Z","iopub.status.idle":"2021-06-10T11:18:51.174056Z","shell.execute_reply.started":"2021-06-10T11:18:50.992379Z","shell.execute_reply":"2021-06-10T11:18:51.173178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Observation:\n\n- On the basis of the above graph, we can say that the clusters represent the following groups:\n    1. HI----HS (High annual income, High Spending score)\n    2. LI----HS (Low annual income, High spending score)\n    3. HI----LS (High annual income, Low spending score)\n    4. LI----LS (Low annual income, Low spending score)\n    5. II----IS (Intermediate annual income, Intermediate spending score)\n    \n            where, S: spending and I: income and\n                   H: high, \n                   L: low \n                   I:intermediate","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}