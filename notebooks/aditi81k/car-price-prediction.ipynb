{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import linear_model\nfrom sklearn.linear_model import LinearRegression\n\n# reading the dataset\ncars = pd.read_csv(\"/kaggle/input/car-price-prediction/CarPrice_Assignment.csv\")\ncars.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cars.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cars.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cars.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Splitting company name from CarName column\nCompanyName = cars['CarName'].apply(lambda a : a.split(' ')[0])\ncars.insert(3,\"CompanyName\",CompanyName)\ncars.drop(['CarName'],axis=1,inplace=True)\nprint(cars.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cars.CompanyName.unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Fixing invalid values\nThere seems to be some spelling error in the CompanyName column.\n\n* maxda = mazda\n* Nissan = nissan\n* porsche = porcshce\n* toyota = toyouta\n* vokswagen = volkswagen = vw","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cars.CompanyName = cars.CompanyName.str.lower()\n\ndef replace_name(a,b):\n    cars.CompanyName.replace(a,b,inplace=True)\n\nreplace_name('maxda','mazda')\nreplace_name('porcshce','porsche')\nreplace_name('toyouta','toyota')\nreplace_name('vokswagen','volkswagen')\nreplace_name('vw','volkswagen')\n\ncars.CompanyName.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking for duplicates\ncars.loc[cars.duplicated()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cars.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,8))\n\nplt.subplot(1,2,1)\nplt.title('Car Price Distribution Plot')\nsns.distplot(cars.price)\n\nplt.subplot(1,2,2)\nplt.title('Car Price Spread')\nsns.boxplot(y=cars.price)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(cars.price.describe(percentiles = [0.25,0.50,0.75,0.85,0.90,1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Inference :\n1. The plot seemed to be right-skewed, meaning that the most prices in the dataset are low(Below 15,000).\n2. There is a significant difference between the mean and the median of the price distribution.\n3. The data points are far spread out from the mean, which indicates a high variance in the car prices.(85% of the prices are below 18,500,    whereas the remaining 15% are between 18,500 and 45,400.)\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":" Visualising Categorical Data\n \n - CompanyName\n- Symboling\n- fueltype\n- enginetype\n- carbody\n- doornumber\n- enginelocation\n- fuelsystem\n- cylindernumber\n- aspiration\n- drivewheel","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(25, 6))\n\nplt.subplot(1,3,1)\nplt1 = cars.CompanyName.value_counts().plot('bar')\nplt.title('Companies Histogram')\nplt1.set(xlabel = 'Car company', ylabel='Frequency of company')\n\nplt.subplot(1,3,2)\nplt1 = cars.fueltype.value_counts().plot('bar')\nplt.title('Fuel Type Histogram')\nplt1.set(xlabel = 'Fuel Type', ylabel='Frequency of fuel type')\n\nplt.subplot(1,3,3)\nplt1 = cars.carbody.value_counts().plot('bar')\nplt.title('Car Type Histogram')\nplt1.set(xlabel = 'Car Type', ylabel='Frequency of Car type')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Inference :\n* Toyota seemed to be favored car company.\n* Number of gas fueled cars are more than diesel.\n* sedan is the top car type prefered.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,8))\n\nplt.subplot(1,2,1)\nplt.title('Symboling Histogram')\nsns.countplot(cars.symboling, palette=(\"cubehelix\"))\n\nplt.subplot(1,2,2)\nplt.title('Symboling vs Price')\nsns.boxplot(x=cars.symboling, y=cars.price, palette=(\"cubehelix\"))\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Inference :\n* It seems that the symboling with 0 and 1 values have high number of rows (i.e. They are most sold.)\n* The cars with -1 symboling seems to be high priced (as it makes sense too, insurance risk rating -1 is quite good). But it seems that       symboling with 3 value has the price range similar to -2 value. There is a dip in price at symboling 1.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,8))\n\nplt.subplot(1,2,1)\nplt.title('Engine Type Histogram')\nsns.countplot(cars.enginetype, palette=(\"Blues_d\"))\n\nplt.subplot(1,2,2)\nplt.title('Engine Type vs Price')\nsns.boxplot(x=cars.enginetype, y=cars.price, palette=(\"PuBuGn\"))\n\nplt.show()\n\ndf = pd.DataFrame(cars.groupby(['enginetype'])['price'].mean().sort_values(ascending = False))\ndf.plot.bar(figsize=(8,6))\nplt.title('Engine Type vs Average Price')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Inference :¶\n* ohc Engine type seems to be most favored type.\n* ohcv has the highest price range (While dohcv has only one row), ohc and ohcf have the low price range.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(25, 6))\n\ndf = pd.DataFrame(cars.groupby(['CompanyName'])['price'].mean().sort_values(ascending = False))\ndf.plot.bar()\nplt.title('Company Name vs Average Price')\nplt.show()\n\ndf = pd.DataFrame(cars.groupby(['fueltype'])['price'].mean().sort_values(ascending = False))\ndf.plot.bar()\nplt.title('Fuel Type vs Average Price')\nplt.show()\n\ndf = pd.DataFrame(cars.groupby(['carbody'])['price'].mean().sort_values(ascending = False))\ndf.plot.bar()\nplt.title('Car Type vs Average Price')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Inference :\n* Jaguar and Buick seem to have highest average price.\n* diesel has higher average price than gas.\n* hardtop and convertible have higher average price.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,5))\n\nplt.subplot(1,2,1)\nplt.title('Door Number Histogram')\nsns.countplot(cars.doornumber, palette=(\"plasma\"))\n\nplt.subplot(1,2,2)\nplt.title('Door Number vs Price')\nsns.boxplot(x=cars.doornumber, y=cars.price, palette=(\"plasma\"))\n\nplt.show()\n\nplt.figure(figsize=(15,5))\n\nplt.subplot(1,2,1)\nplt.title('Aspiration Histogram')\nsns.countplot(cars.aspiration, palette=(\"plasma\"))\n\nplt.subplot(1,2,2)\nplt.title('Aspiration vs Price')\nsns.boxplot(x=cars.aspiration, y=cars.price, palette=(\"plasma\"))\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Inference :\n* doornumber variable is not affacting the price much. There is no sugnificant difference between the categories in it.\n* It seems aspiration with turbo have higher price range than the std(though it has some high values outside the whiskers.)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_count(x,fig):\n    plt.subplot(4,2,fig)\n    plt.title(x+' Histogram')\n    sns.countplot(cars[x],palette=(\"magma\"))\n    plt.subplot(4,2,(fig+1))\n    plt.title(x+' vs Price')\n    sns.boxplot(x=cars[x], y=cars.price, palette=(\"magma\"))\n    \nplt.figure(figsize=(15,20))\n\nplot_count('enginelocation', 1)\nplot_count('cylindernumber', 3)\nplot_count('fuelsystem', 5)\nplot_count('drivewheel', 7)\n\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Inference :\n* Very few datapoints for enginelocation categories to make an inference.\n* Most common number of cylinders are four, six and five. Though eight cylinders have the highest price range.\n* mpfi and 2bbl are most common type of fuel systems. mpfi and idi having the highest price range. But there are few data for other categories to derive any meaningful inference\n* A very significant difference in drivewheel category. Most high ranged cars seeme to prefer rwd drivewheel.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def scatter(x,fig):\n    plt.subplot(5,2,fig)\n    plt.scatter(cars[x],cars['price'])\n    plt.title(x+' vs Price')\n    plt.ylabel('Price')\n    plt.xlabel(x)\n\nplt.figure(figsize=(10,20))\n\nscatter('carlength', 1)\nscatter('carwidth', 2)\nscatter('carheight', 3)\nscatter('curbweight', 4)\n\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Inference :\n* carwidth, carlength and curbweight seems to have a poitive correlation with price.\n* carheight doesn't show any significant trend with price.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def pp(x,y,z):\n    sns.pairplot(cars, x_vars=[x,y,z], y_vars='price',size=4, aspect=1, kind='scatter')\n    plt.show()\n\npp('enginesize', 'boreratio', 'stroke')\npp('compressionratio', 'horsepower', 'peakrpm')\npp('wheelbase', 'citympg', 'highwaympg')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Inference :\n* enginesize, boreratio, horsepower, wheelbase - seem to have a significant positive correlation with price.\n* citympg, highwaympg - seem to have a significant negative correlation with price.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"np.corrcoef(cars['carlength'], cars['carwidth'])[0, 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fuel economy\ncars['fueleconomy'] = (0.55 * cars['citympg']) + (0.45 * cars['highwaympg'])\ncars['fueleconomy']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Binning the Car Companies based on avg prices of each Company.\ncars['price'] = cars['price'].astype('int')\ntemp = cars.copy()\ntable = temp.groupby(['CompanyName'])['price'].mean()\ntemp = temp.merge(table.reset_index(), how='left',on='CompanyName')\nbins = [0,10000,20000,40000]\ncars_bin=['Budget','Medium','Highend']\ncars['carsrange'] = pd.cut(temp['price_y'],bins,right=False,labels=cars_bin)\ncars.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,6))\n\nplt.title('Fuel economy vs Price')\nsns.scatterplot(x=cars['fueleconomy'],y=cars['price'],hue=cars['drivewheel'])\nplt.xlabel('Fuel Economy')\nplt.ylabel('Price')\n\nplt.show()\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Inference :\n* fueleconomy has an obvios negative correlation with price and is significant.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(25, 6))\n\ndf = pd.DataFrame(cars.groupby(['fuelsystem','drivewheel','carsrange'])['price'].mean().unstack(fill_value=0))\ndf\ndf.plot.bar()\nplt.title('Car Range vs Average Price')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Inference :\n* High ranged cars prefer rwd drivewheel with idi or mpfi fuelsystem.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"List of significant variables after Visual analysis :\n- Car Range \n- Engine Type \n- Fuel type \n- Car Body \n- Aspiration \n- Cylinder Number \n- Drivewheel \n- Curbweight \n- Car Length\n- Car width\n- Engine Size \n- Boreratio \n- Horse Power \n- Wheel base \n- Fuel Economy ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cars_lr = cars[['price','fueltype', 'aspiration','carbody', 'drivewheel','wheelbase','curbweight', 'enginetype', 'cylindernumber', 'enginesize', 'boreratio','horsepower','fueleconomy', 'carlength','carwidth', 'carsrange']]\ncars_lr.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(cars_lr)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Defining the map function\ndef dummies(x,df):\n    temp = pd.get_dummies(df[x], drop_first = True)\n    df = pd.concat([df, temp], axis = 1)\n    df.drop([x], axis = 1, inplace = True)\n    return df\n# Applying the function to the cars_lr\n\ncars_lr = dummies('fueltype',cars_lr)\ncars_lr = dummies('aspiration',cars_lr)\ncars_lr = dummies('carbody',cars_lr)\ncars_lr = dummies('drivewheel',cars_lr)\ncars_lr = dummies('enginetype',cars_lr)\ncars_lr = dummies('cylindernumber',cars_lr)\ncars_lr = dummies('carsrange',cars_lr)\ncars_lr.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cars_lr.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Train-Test Split and feature scaling","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nnp.random.seed(0)\ndf_train, df_test = train_test_split(cars_lr, train_size = 0.7, test_size = 0.3, random_state = 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\nnum_vars = ['wheelbase', 'curbweight', 'enginesize', 'boreratio', 'horsepower','fueleconomy','carlength','carwidth','price']\ndf_train[num_vars] = scaler.fit_transform(df_train[num_vars])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Correlation using heatmap\nplt.figure(figsize = (30, 25))\nsns.heatmap(df_train.corr(), annot = True, cmap=\"YlGnBu\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Highly correlated variables to price are - curbweight, enginesize, horsepower,carwidth and highend.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dividing data into X and y variables\ny_train = df_train.pop('price')\nX_train = df_train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Model Building","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LinearRegression\nimport statsmodels.api as sm \nfrom statsmodels.stats.outliers_influence import variance_inflation_factor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lm = LinearRegression()\nlm.fit(X_train,y_train)\nrfe = RFE(lm, 10)\nrfe = rfe.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list(zip(X_train.columns,rfe.support_,rfe.ranking_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.columns[rfe.support_]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Building model using statsmodel, for the detailed statistics","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_rfe = X_train[X_train.columns[rfe.support_]]\nX_train_rfe.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model(X,y):\n    X = sm.add_constant(X) #Adding the constant\n    lm = sm.OLS(y,X).fit() # fitting the model\n    print(lm.summary()) # model summary\n    return X\n    \ndef checkVIF(X):\n    vif = pd.DataFrame()\n    vif['Features'] = X.columns\n    vif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n    vif['VIF'] = round(vif['VIF'], 2)\n    vif = vif.sort_values(by = \"VIF\", ascending = False)\n    return(vif)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"MODEL 1","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_new = build_model(X_train_rfe,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"p-vale of twelve seems to be higher than the significance value of 0.05, hence dropping it as it is insignificant in presence of other variables.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_new = X_train_rfe.drop([\"twelve\"], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_newX_train_new = build_model(X_train_new,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_new = X_train_new.drop([\"fueleconomy\"], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_new = build_model(X_train_new,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_new = build_model(X_train_new,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Calculating the Variance Inflation Factor\ncheckVIF(X_train_new)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"dropping curbweight because of high VIF value. (shows that curbweight has high multicollinearity.)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_new = X_train_new.drop([\"curbweight\"], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_new = build_model(X_train_new,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"checkVIF(X_train_new)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"dropping sedan because of high VIF value.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_new = X_train_new.drop([\"sedan\"], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_new = build_model(X_train_new,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"checkVIF(X_train_new)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"dropping wagon because of high p-value.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_new = build_model(X_train_new,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"checkVIF(X_train_new)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dropping dohcv to see the changes in model statistics\nX_train_new = X_train_new.drop([\"dohcv\"], axis = 1)\nX_train_new = build_model(X_train_new,y_train)\ncheckVIF(X_train_new)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lm = sm.OLS(y_train,X_train_new).fit()\ny_train_price = lm.predict(X_train_new)\n# Plot the histogram of the error terms\nfig = plt.figure()\nsns.distplot((y_train - y_train_price), bins = 20)\nfig.suptitle('Error Terms', fontsize = 20)                  # Plot heading \nplt.xlabel('Errors', fontsize = 18)   ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Error terms seem to be approximately normally distributed, so the assumption on the linear modeling seems to be fulfilled.\n\n**Prediction and Evaluation**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Scaling the test set\nnum_vars = ['wheelbase', 'curbweight', 'enginesize', 'boreratio', 'horsepower','fueleconomy','carlength','carwidth','price']\ndf_test[num_vars] = scaler.fit_transform(df_test[num_vars])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dividing into X and y\ny_test = df_test.pop('price')\nX_test = df_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now let's use our model to make predictions.\nX_train_new = X_train_new.drop('const',axis=1)\n# Creating X_test_new dataframe by dropping variables from X_test\nX_test_new = X_test[X_train_new.columns]\n\n# Adding a constant variable \nX_test_new = sm.add_constant(X_test_new)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making predictions\ny_pred = lm.predict(X_test_new)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Evaluation of test via comparison of y_pred and y_test¶","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import r2_score \nr2_score(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#EVALUATION OF THE MODEL\n# Plotting y_test and y_pred to understand the spread.\nfig = plt.figure()\nplt.scatter(y_test,y_pred)\nfig.suptitle('y_test vs y_pred', fontsize=20)              # Plot heading \nplt.xlabel('y_test', fontsize=18)                          # X-label\nplt.ylabel('y_pred', fontsize=16) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Evaluation of the model using Statistics","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(lm.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Inference :\n* R-sqaured and Adjusted R-squared (extent of fit) - 0.899 and 0.896 - 90% variance explained.\n* F-stats and Prob(F-stats) (overall model fit) - 308.0 and 1.04e-67(approx. 0.0) - Model fir is significant and explained 90% variance is just not by chance.\n* p-values - p-values for all the coefficients seem to be less than the significance level of 0.05. - meaning that all the predictors are statistically significant.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}