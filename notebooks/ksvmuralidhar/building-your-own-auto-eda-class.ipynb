{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h1>HR Analytics: Job Change of Data Scientists"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport scipy.stats as stats\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom IPython.display import display\nfrom scipy.stats import chi2_contingency\nfrom sklearn.preprocessing import OrdinalEncoder, MinMaxScaler, OneHotEncoder, MaxAbsScaler, LabelEncoder\nfrom sklearn.decomposition import PCA, TruncatedSVD\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.feature_selection import mutual_info_classif","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2>The hidden cell below defines a class named 'AutoEdaBinaryClassif' to perform auto EDA for any binary classification problem."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"class AutoEdaBinaryClassif():\n    def __init__(self):\n        pass\n    \n    \n    def primary_eda(self,data):\n        '''\n        This method returns head, shape,data types of variables \n        and summary statistics of input data frame.\n        \n        params:\n        data: input data frame.\n        \n        Returns: None.\n        \n        '''\n        data = data.copy()\n        print(\"First few records\")\n        display(data.head().T)\n        shape = data.shape\n        print(f'Dataset has {shape[0]} records/rows and {shape[1]} features/columns\\n')\n        data_types = data.dtypes\n        data_types = [f'{i}: {j}' for i, j in zip(list(data_types.index), list(data_types.astype('str')))]\n        print(f'Data types: {data_types}\\n\\n\\nSummary of numeric variables:')\n        display(data.describe().T)\n        print(f'Summary of categorical variables:')\n        display(data.describe(include='object').T)\n    \n    \n    def missing_value_summary(self, data, show_plot=True, plot_width=8, plot_height=8):\n        '''\n        This method returns missing value summary of an input data frame and also\n        plots a heatmap of the missing values across columns and indices.\n        \n        params:\n        data: input data frame.\n        show_plot: boolean to disply the missing value plot, default value = True\n        plot_width: width of the heatmap, default value = 8.\n        plot_height: height of the heatmap, default value = 8.\n        \n        Returns: Data frame with missing value summary.\n        \n        '''\n        data = data.copy()\n        miss_val_cnt = data.isnull().sum().astype('int')\n        miss_val_per = np.round((miss_val_cnt / len(data)) * 100,2)\n        missing_value_summary = pd.concat([miss_val_cnt,miss_val_per],axis=1).reset_index()\n        missing_value_summary.columns = ['column', 'missing_count', 'missing_percent']\n        miss_str = missing_value_summary.copy()\n        miss_str['column'] = miss_str['column'] + ':'\n        miss_str['missing_percent'] = '(' + miss_str['missing_percent'].astype('str') + '%)'\n        miss_str = \"; \".join(miss_str.apply(lambda x: ''.join([str(i) for i in list(x)]),axis=1))\n        print(f'Missing values: Format- column:count(percent)\\n\\n{miss_str}')\n        if show_plot == True:\n            miss_val_mark = data.isnull()\n            fig = plt.figure(figsize=(plot_width, plot_height))\n            sns.heatmap(miss_val_mark,cbar=False)\n            plt.title('Missing values')\n            plt.show()\n        return missing_value_summary\n    \n    \n    def class_separation(self, data, categorical_variables, method='pca', plot_alpha=0.5):\n        '''\n        This method uses 2-D scatter plot to visualize the class separation \n        by reducing the data dimensions to 2, using PCA/SVD.\n        \n        params:\n        data: input data frame.\n        categorical_variables: list containing categorical variable/column names of 'data'.\n        method: technique to be used for dimensionality reduction. Takes two values 'pca' or 'svd'.\n        default value = 'pca'\n        plot_alpha: specifies the transparency of the markers in the scatter plot.\n        default value = 0.5.\n        \n        Returns: None.\n        \n        '''\n        categorical_variables = categorical_variables.copy()\n        data = data.copy()\n        data = data.dropna().copy()\n        print(f'{len(data)} examples remaining after dropping examples with NaN')\n        X = data.iloc[:,:-1].copy()\n        y = LabelEncoder().fit_transform(data['target']).copy()\n        \n        if method == 'pca':\n            col_transform = ColumnTransformer(transformers=[['ordinal_encoder',\n                                                             OrdinalEncoder(),\n                                                             categorical_variables]],\n                                              remainder='passthrough')\n\n            X = col_transform.fit_transform(X).copy()\n            min_max = MinMaxScaler()\n            X = min_max.fit_transform(X).copy()\n\n            pca = PCA(n_components=2,random_state=11)\n            X_pca = pca.fit_transform(X).copy()\n            X_pca = pd.DataFrame(X_pca,columns=[\"component_1\",\"component_2\"])\n            X_pca['y'] = y\n\n            print(f'Total explained variance ratio: {np.cumsum(pca.explained_variance_ratio_)[-1]}\\nTotal explained variance ratio less than 0.6 may not be reliable')\n            \n            fig = plt.figure(figsize=(8,8))\n            sns.scatterplot(data=X_pca,x='component_1',y=\"component_2\",hue='y',alpha=plot_alpha);\n        else:\n            col_transform = ColumnTransformer(transformers=[['ohe',\n                                                             OneHotEncoder(),\n                                                             categorical_variables]],\n                                              remainder='passthrough')\n\n            X = col_transform.fit_transform(X).copy()\n            max_abs = MaxAbsScaler()\n            X = max_abs.fit_transform(X).copy()\n\n            tsvd = TruncatedSVD(n_components=2,random_state=11)\n            X_svd = tsvd.fit_transform(X).copy()\n            X_svd = pd.DataFrame(X_svd,columns=[\"component_1\",\"component_2\"])\n            X_svd['y'] = y\n\n            print(f'Total explained variance ratio: {np.cumsum(tsvd.explained_variance_ratio_)[-1]}\\nTotal explained variance ratio less than 0.6 may not be reliable')\n            \n            fig = plt.figure(figsize=(8,8))\n            sns.scatterplot(data=X_svd,x='component_1',y=\"component_2\",hue='y',alpha=plot_alpha);\n\n            \n    def density_plots(self, data, numeric_variables, plot_width = 15, plot_height = 20):\n        '''\n        This method displays the KDE plots of the numeric variables in a data frame.\n        \n        params:\n        data: input data frame.\n        numeric_variables: list containing numeric variable/column names of 'data'.\n        plot_width: width of the plot, default value = 15.\n        plot_height: height of the plot, default value = 20.\n        \n        Returns: None\n        \n        '''\n        numeric_variables = numeric_variables.copy()\n        data = data.copy()\n        numeric_variables_length = len(numeric_variables)\n        rows_in_plot = int(numeric_variables_length / 2) if (numeric_variables_length % 2 == 0) else (int(numeric_variables_length / 2) + 1)\n        data[numeric_variables].plot(kind='kde', figsize=(plot_width, plot_height), subplots=True, layout=(rows_in_plot,2),sharex = False, sharey = False, color='black');\n        \n    \n    def cdf(self, data, numeric_variables, plot_width=15, plot_height=20):\n        data = data.copy()\n        numeric_variables = numeric_variables.copy()\n            \n        r = c = 0\n        numeric_variables_length = len(numeric_variables)\n        rows_in_plot = int(numeric_variables_length / 2) if (numeric_variables_length % 2 == 0) else (int(numeric_variables_length / 2) + 1)\n        fig,ax = plt.subplots(rows_in_plot,2,figsize=(plot_width, plot_height))\n        \n        if rows_in_plot > 1:\n            for n,i in enumerate(numeric_variables):\n                val_cnts = np.round(data[i].value_counts(normalize=True),3).sort_index().copy()\n                val_cnts = val_cnts.cumsum().copy()\n                val_cnts.plot(kind='line',ax=ax[r,c],title=f'CDF of {i}',color='black',xlabel=i,ylabel='cdf')\n                ax[r,c].yaxis.grid(color='lightgray', linestyle='dashed')\n                ax[r,c].xaxis.grid(color='lightgray', linestyle='dashed')\n                c+=1\n                if (n+1)%2==0:\n                    r+=1\n                    c=0\n            if (numeric_variables_length % 2) != 0:\n                ax[r,c].axis(\"off\")\n        else:\n            for n,i in enumerate(numeric_variables):\n                val_cnts = np.round(data[i].value_counts(normalize=True),3).sort_index().copy()\n                val_cnts = val_cnts.cumsum().copy()\n                val_cnts.plot(kind='line',ax=ax[n],title=f'CDF of {i}',color='black',xlabel=i,ylabel='cdf')\n                ax[n].yaxis.grid(color='lightgray', linestyle='dashed')\n                ax[n].xaxis.grid(color='lightgray', linestyle='dashed')\n                c+=1\n                if (n+1)%2==0:\n                    r+=1\n                    c=0\n            if numeric_variables_length == 1:\n                ax[1].axis('off')\n        plt.show()\n        \n        \n    \n    \n    def normality_test(self, data, numeric_variables):\n        '''\n        This method performs a test for normality using 'normaltest' function of scipy.stats module.\n        \n        params:\n        data: input data frame.\n        numeric_variables: list containing numeric variable/column names of 'data'.\n        \n        Returns: None\n        \n        '''\n        numeric_variables = numeric_variables.copy()\n        data = data.copy()\n        print(\"The test for normality is performed using 'normaltest' function of scipy.stats\\n\\nSignificance Level (alpha) : 0.05\\n\\n\" +\n        \"h0:Sample comes from a normal distribution\\nh1:Sample doesn't come from a normal distribution\\n\\n\")\n        for i in numeric_variables:\n            print(f\"{i}: {'Non-Gaussian' if (stats.normaltest(data[i])[1])<0.05 else 'Gaussian'}  {stats.normaltest(data[i])}\")\n       \n    \n    def qqplots(self, data, numeric_variables):\n        '''\n        This method displays the Q-Q plots of the specified numeric variables in the input data frame.\n        \n        params:\n        data: input data frame.\n        numeric_variables: list containing numeric variable/column names of 'data'.\n        \n        Returns: None.\n        \n        '''\n        numeric_variables = numeric_variables.copy()\n        data = data.copy()\n        for n,i in enumerate(numeric_variables):\n            stats.probplot(data[i],plot=plt)\n            plt.title(i)\n            plt.show()\n           \n        \n    def boxplots(self, data, numeric_variables, plot_width=15, plot_height=20):\n        '''\n        This method displays the box plots of the specified numeric variables in a data frame.\n        \n        params:\n        data: input data frame.\n        numeric_variables: list containing numeric variable/column names of 'data'.\n        plot_width: width of the plot, default value = 15.\n        plot_height: height of the plot, default value = 20.\n        \n        Returns: None.\n        \n        '''\n        numeric_variables = numeric_variables.copy()\n        data = data.copy()\n        numeric_variables_length = len(numeric_variables)\n        rows_in_plot = int(numeric_variables_length / 2) if (numeric_variables_length % 2 == 0) else (int(numeric_variables_length / 2) + 1)\n        data[numeric_variables].plot(kind='box',subplots=True,layout=(rows_in_plot,2),figsize=(plot_width, plot_height), color='black');\n        \n        \n    def skewness_test(self, data, numeric_variables):\n        '''\n        This method performs a test for skewness and also displays the skewness value.\n        \n        params:\n        data: input data frame.\n        numeric_variables: list containing numeric variable/column names of 'data'.\n        \n        Returns: None\n        \n        '''\n        numeric_variables = numeric_variables.copy()\n        data = data.copy()\n        for i in numeric_variables:\n            print(f\"{i}: {'Skewed' if (stats.skewtest(data[i])[1])<0.05 else 'Not Skewed'}  {stats.skew(data[i])}\")\n            \n    \n    def feature_correlation(self, data, numeric_variables, corr_matrix_width = 10, corr_matrix_height = 10, plot = True, plot_width = 10, plot_height = 10):\n        '''\n        This method displays the Pearson & Kendall rank correlation coefficients of the specified\n        numeric features of the input data frame. The correlation coefficients are displayed using \n        seaborn' heatmap.\n        \n        params:\n        data: input data frame.\n        numeric_variables: list containing numeric variable/column names of 'data'.\n        corr_matrix_width: width of correlation heatmaps, default value = 10.\n        corr_matrix_height: height of correlation heatmaps, default value = 10.\n        plot: boolean to control the display of pairplots, default value = True.\n        plot_width: width of pair plot, default value = 10.\n        plot_height: height of pair plot, default value = 10.\n        \n        Returns: None.\n        \n        '''\n        numeric_variables = numeric_variables.copy()\n        data = data.copy()\n        fig = plt.figure(figsize=(corr_matrix_width, corr_matrix_height))\n        sns.heatmap(data[numeric_variables].corr(method='pearson'),mask=np.triu(data[numeric_variables].corr()),\n                    annot=True,fmt='.2f',\n                    cbar=False,cmap=['white'],linewidths=0.01,linecolor='black',square=True)\n        plt.title('Pearson correlation')\n        plt.show();\n        \n        fig = plt.figure(figsize=(corr_matrix_width, corr_matrix_height))\n        sns.heatmap(data[numeric_variables].corr(method='kendall'),mask=np.triu(data[numeric_variables].corr()),\n                    annot=True,fmt='.2f',\n                    cbar=False,cmap=['white'],linewidths=0.01,linecolor='black',square=True)\n        plt.title('Kendall rank correlation')\n        plt.show();\n        \n        if plot == True:\n            fig = plt.figure(figsize=(plot_width, plot_height))\n            sns.pairplot(data[numeric_variables])\n            plt.show();\n            \n        \n    \n    def numeric_variables_vs_target(self, data, numeric_variables, target, plot_width=15, plot_height=20):\n        '''\n        This method plots violin plots of specified numeric variables vs target variable.\n        \n        params:\n        data: input data frame.\n        numeric_variables: list containing numeric variable/column names of 'data'.\n        target: string specifying the name of target variable.\n        plot_width: width of pair plot, default value = 15.\n        plot_height: height of pair plot, default value = 20.\n        \n        Returns: None.\n        \n        '''\n        numeric_variables = numeric_variables.copy()\n        data = data.copy()\n        r = c = 0\n        numeric_variables_length = len(numeric_variables)\n        rows_in_plot = int(numeric_variables_length / 2) if (numeric_variables_length % 2 == 0) else (int(numeric_variables_length / 2) + 1)\n        fig,ax = plt.subplots(rows_in_plot,2,figsize=(plot_width, plot_height))\n        \n        if rows_in_plot > 1:\n            for n,i in enumerate(numeric_variables):\n                med = data[[i,target]].groupby(target).median().copy()\n                sns.violinplot(x=target,y=i,data=data,ax=ax[r,c],palette=[\"gray\",\"lightgray\"])\n                med.plot(ax=ax[r,c],color='black',linewidth=3,linestyle=\"--\",legend=False)\n                for x,y in zip(list(med.index),med[i]):\n                    ax[r,c].text(x=x+0.05,y=y+0.01,s=np.round(y,2),fontsize=10,color='white',backgroundcolor='black')\n                ax[r,c].set_title(i.upper()+\" by \"+target)\n                c+=1\n                if (n+1)%2==0:\n                    r+=1\n                    c=0\n            if (numeric_variables_length % 2) != 0:\n                ax[r,c].axis(\"off\")\n        else:\n            for n,i in enumerate(numeric_variables):\n                med = data[[i,target]].groupby(target).median().copy()\n                sns.violinplot(x=target,y=i,data=data,ax=ax[c],palette=[\"gray\",\"lightgray\"])\n                med.plot(ax=ax[c],color='black',linewidth=3,linestyle=\"--\",legend=False)\n                for x,y in zip(list(med.index),med[i]):\n                    ax[c].text(x=x+0.05,y=y+0.01,s=np.round(y,2),fontsize=10,color='white',backgroundcolor='black')\n                ax[c].set_title(i.upper()+\" by \"+target)\n                c+=1\n                if (n+1)%2==0:\n                    r+=1\n                    c=0\n            if numeric_variables_length == 1:\n                ax[1].axis('off')\n        plt.show()\n        \n        \n    def categorical_variable_distribution(self, data, categorical_variables, plot=True, vars_to_exclude_from_plots=[], plot_width=10, plot_height=10):\n        categorical_variables = categorical_variables.copy()\n        data = data.copy()\n        data = data.fillna('NaN/Missing').copy()\n        for i in categorical_variables:\n            val_cnt = pd.DataFrame(np.round(data[i].value_counts(normalize=True)*100,2))\n            val_cnt.columns = ['Proportion']\n            n_unique = data[i].nunique()\n            excl_str = \"\"\n            if 'NaN/Missing' in list(val_cnt.index):\n                n_unique -= 1\n                excl_str = \"(excluding 'NaN/Missing')\"\n            print(f\"{i}: {n_unique} unique categories{excl_str}\\n{val_cnt}\\n\\n\")\n            \n            \n        if plot == True:\n            categorical_variables = categorical_variables.copy()\n            data = data.copy()\n            for rem in vars_to_exclude_from_plots:\n                categorical_variables.remove(rem)\n            r = c = 0\n            variables_length = len(categorical_variables)\n            rows_in_plot = int(variables_length / 2) if (variables_length % 2 == 0) else (int(variables_length / 2) + 1)\n            fig,ax = plt.subplots(rows_in_plot,2,figsize=(plot_width, plot_height))\n\n            if rows_in_plot > 1:\n                for n,i in enumerate(categorical_variables):\n                    cat_dist = data[i].value_counts().sort_values().copy()\n                    cat_dist = np.round((cat_dist / cat_dist.sum()) * 100,1).copy()\n                    cat_dist.plot(kind=\"barh\",ax=ax[r,c],sharey=False,title=i,color='black')\n                    for x,y in enumerate(list(cat_dist.index)):\n                        ax[r,c].text(y=x-0.02,x=cat_dist[y],s=f'{np.round(cat_dist[y],2)}%')\n                    ax[r,c].set_title(i)\n                    c+=1\n                    if (n+1)%2==0:\n                        r+=1\n                        c=0\n                if (variables_length % 2) != 0:\n                    ax[r,c].axis(\"off\")\n            else:\n                for n,i in enumerate(categorical_variables):\n                    cat_dist = data[i].value_counts().sort_values().copy()\n                    cat_dist = np.round((cat_dist / cat_dist.sum()) * 100,1).copy()\n                    cat_dist.plot(kind=\"barh\",ax=ax[n],sharey=False,title=i,color='black')\n                    for x,y in enumerate(list(cat_dist.index)):\n                        ax[n].text(y=x-0.02,x=cat_dist[y],s=f'{np.round(cat_dist[y],2)}%')\n                    ax[n].set_title(i)\n                    c+=1\n                    if (n+1)%2==0:\n                        r+=1\n                        c=0\n                if variables_length == 1:\n                    ax[1].axis('off')\n            plt.show()\n            \n            \n    def categorical_variables_vs_target(self, data, categorical_variables, target, crosstabs=True, crosstab_show_missing=False, crosstab_proportion=True, col_proportion=True, plots=True, vars_to_exclude_from_plots=[],plot_width=15,plot_height=20):\n        categorical_variables = categorical_variables.copy()\n        data = data.copy()\n        categorical_variables = categorical_variables.copy()\n        for i in categorical_variables:\n            ct = pd.crosstab(columns=data[i],index=data[target])\n            stat, p, dof, expected = chi2_contingency(ct) \n            print(f\"\\n{'-'*len(f'Chi-Square test between {i} & {target}')}\")\n            print(f'Chi-Square test between {i} & {target}')\n            print(f\"{'-'*len(f'Chi-Square test between {i} & {target}')}\")\n            print(f\"\\nH0: THERE IS NO RELATIONSHIP BETWEEN {target.upper()} & {i.upper()}\\nH1: THERE IS RELATIONSHIP BETWEEN {target.upper()} & {i.upper()}\")\n            print(f\"\\nP-VALUE: {p}\")\n            print(\"REJECT H0\" if p<0.05 else \"FAILED TO REJECT H0\")\n        \n        \n        if plots == True:\n            for rem in vars_to_exclude_from_plots:\n                categorical_variables.remove(rem)\n            cat_variables_length = len(categorical_variables)\n            rows_in_plot = int(cat_variables_length / 2) if (cat_variables_length % 2 == 0) else (int(cat_variables_length / 2) + 1)\n            r = c = 0\n            fig,ax = plt.subplots(rows_in_plot,2,figsize=(plot_width,plot_height))\n        \n    \n            if rows_in_plot > 1:\n                for n,i in enumerate(categorical_variables):\n                        ct = pd.crosstab(columns=data[i],index=data[target],normalize=\"columns\")\n                        ct.T.plot(kind=\"bar\",stacked=True,color=[\"black\",\"gray\"],ax=ax[r,c])\n                        ax[r,c].set_ylabel(\"% of observations\")\n                        ax[r,c].set_xlabel(\"\")\n                        ax[r,c].set_title(f'{i} vs {target}')\n                        c+=1\n                        if (n+1)%2==0:\n                            r+=1\n                            c=0\n                if (cat_variables_length % 2) != 0:\n                    ax[r,c].axis(\"off\")\n            else:\n                for n,i in enumerate(categorical_variables):\n                        ct = pd.crosstab(columns=data[i],index=data[target],normalize=\"columns\")\n                        ct.T.plot(kind=\"bar\",stacked=True,color=[\"black\",\"gray\"],ax=ax[c])\n                        ax[c].set_ylabel(\"% of observations\")\n                        ax[c].set_xlabel(\"\")\n                        ax[c].set_title(f'{i} vs {target}')\n                        c+=1\n                        if (n+1)%2==0:\n                            r+=1\n                            c=0\n                if cat_variables_length == 1:\n                    ax[1].axis('off')\n\n\n            plt.show()\n            \n            \n        if crosstabs == True:\n            for i in categorical_variables:\n                \n                if crosstab_proportion == True:\n                    if col_proportion == True:\n                        print(f\"\\n{'-'*len(f'Crosstab (Column-wise Proportion) between {i} & {target}')}\")\n                        print(f'Crosstab (Column-wise Proportion) between {i} & {target}')\n                        if crosstab_show_missing == True:\n                            data_1 = data.copy()\n                            data_1.fillna('NaN/Missing',inplace=True)\n                            ct = np.round(pd.crosstab(index=data_1[i],columns=data_1[target],normalize='columns') * 100, 2)\n                        else:\n                            ct = np.round(pd.crosstab(index=data[i],columns=data[target],normalize='columns') * 100, 2)\n                        print(f\"{'-'*len(f'Crosstab (Column-wise Proportion) between {i} & {target}')}\")\n                    else:\n                        print(f\"\\n{'-'*len(f'Crosstab (Row-wise Proportion) between {i} & {target}')}\")\n                        print(f'Crosstab (Row-wise Proportion) between {i} & {target}')\n                        if crosstab_show_missing == True:\n                            data_1 = data.copy()\n                            data_1.fillna('NaN/Missing',inplace=True)\n                            ct = np.round(pd.crosstab(index=data_1[i],columns=data_1[target],normalize='index') * 100, 2)\n                        else:\n                            ct = np.round(pd.crosstab(index=data[i],columns=data[target],normalize='index') * 100, 2)\n                        print(f\"{'-'*len(f'Crosstab (Row-wise Proportion) between {i} & {target}')}\")\n                else:\n                    print(f\"\\n{'-'*len(f'Crosstab between {i} & {target}')}\")\n                    print(f'Crosstab between {i} & {target}')\n                    print(f\"{'-'*len(f'Crosstab between {i} & {target}')}\")\n                    if crosstab_show_missing == True:\n                            data_1 = data.copy()\n                            data_1.fillna('NaN/Missing',inplace=True)\n                            ct = pd.crosstab(index=data_1[i],columns=data_1[target])\n                    else:\n                        ct = pd.crosstab(index=data[i],columns=data[target])\n                print(ct)\n                \n                \n    def target_distribution(self, data, target):\n        data = data.copy()\n        sns.countplot(data=data,x=target,palette=['black','gray']);\n        tgt_cnt = data[target].value_counts()\n        tgt_prop = np.round(data[target].value_counts(normalize=True)*100,1)\n        plt.text(x=-0.2,y=tgt_cnt[0]/2,s=f'{tgt_cnt[0]:,} ({tgt_prop[0]}%)',backgroundcolor='white')\n        plt.text(x=0.8,y=tgt_cnt[1]/2,s=f'{tgt_cnt[1]:,} ({tgt_prop[1]}%)',backgroundcolor='white')\n        plt.title('Target Distribution')\n        \n        \n    def mutual_info(self, data, categorical_variables, target, plot_width=15, plot_height=10):\n        df = data.copy()\n\n        X = df.drop(columns=[target]).copy()\n        y = df[target].values.copy()\n\n        for i in categorical_variables:\n            le = LabelEncoder()\n            X[i] = le.fit_transform(X[i])\n\n        mutual_info = mutual_info_classif(X=X,y=y,discrete_features=(X.dtypes == np.int64),random_state=11)\n        mutual_info_df = pd.DataFrame({'feature':X.columns,'MI':mutual_info}).sort_values(by='MI',ascending=False)\n        mutual_info_df.sort_values(by='MI').plot(x='feature',y='MI',kind='barh',figsize=(plot_width,plot_height),color='black',title='Mutual information')\n        for n,k in enumerate(range((len(mutual_info_df)-1),-1,-1)):\n            plt.text(y=n-0.01,x=mutual_info_df.iloc[k,1],s=np.round(mutual_info_df.iloc[k,1],4))\n        plt.show()\n\n        return mutual_info_df\n    \n    def missing_value_analysis(self, data, col_to_analyze, cols_to_use, target):\n        main_df = pd.DataFrame()\n        for col in cols_to_use:\n            df = data.copy()\n            df = df.set_index(col).copy()\n            df.fillna('missing',inplace=True)\n            df[df!='missing'] = np.nan\n            df = df.groupby(col).count().copy()\n            vc = data[col].value_counts().copy()\n            df = df.merge(vc,left_index=True,right_index=True,how='left').copy()\n            df = np.round(df.apply(lambda x: x/df.iloc[:,-1]) * 100, 2).copy()\n            df.drop(columns=df.columns[-1], inplace=True)\n            df.index = col + \": \" + pd.Series(df.index)\n            main_df = main_df.append(df).copy()\n\n        df = main_df[[col_to_analyze]].sort_values(by=col_to_analyze,ascending=False)\n        fig = plt.figure(figsize=(20,2))\n        plt.title(f'Missing Values Analysis of {col_to_analyze}')\n        n = int(np.ceil((len(df)/2)))\n        sns.heatmap(df.iloc[:n,:].T,annot=True,cbar=False,linewidths=0.01,fmt='.1f',cmap=['white'],linecolor='black',square=True)\n        plt.show()\n        fig = plt.figure(figsize=(20,2))\n        plt.title(f'Missing Values Analysis of {col_to_analyze}')\n        sns.heatmap(df.iloc[n:,:].T,annot=True,cbar=False,linewidths=0.01,fmt='.1f',cmap=['white'],linecolor='black',square=True)\n        plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/hr-analytics-job-change-of-data-scientists/aug_train.csv')\ndata.drop(columns=['enrollee_id'],inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2>Creating an instance of EdaBinaryClassif class"},{"metadata":{"trusted":true},"cell_type":"code","source":"eda = AutoEdaBinaryClassif()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2>Preliminary EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(eda.primary_eda.__doc__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eda.primary_eda(data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>Data type of all the variables looks good. 'city' and 'experience' have high cardinality. Both the numeric variables have no missing values. But we can see that the count of categorical variables shows missing values."},{"metadata":{},"cell_type":"markdown","source":"<h2>Missing Values Summary"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(eda.missing_value_summary.__doc__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_data = eda.missing_value_summary(data,plot_width=10,plot_height=12)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>'company_type', 'company_size', 'gender' and 'major_discipline' have lot of missing values."},{"metadata":{},"cell_type":"markdown","source":"<h2>Storing Categorical & Numeric Features in Separate Variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_variables = list(data.select_dtypes('object').columns)\n\nnumeric_variables = list(data.select_dtypes(['float64','int64']).columns)\nnumeric_variables.remove('target')\n\ntarget = 'target'\n\nprint(f'Categorical Variables ({len(categorical_variables)}):\\n{categorical_variables}\\n\\nNumeric Variables ({len(numeric_variables)}):\\n{numeric_variables}\\n\\nTarget:\\n{target}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2>Missing value analysis to find out MAR and NMAR cases, where missing value % is high"},{"metadata":{"trusted":true},"cell_type":"code","source":"eda.missing_value_analysis(data=data,\n                       col_to_analyze='major_discipline',\n                       cols_to_use=['gender','relevent_experience','enrolled_university',\n                                    'education_level','experience',\n                                    'company_size','company_type','last_new_job'],\n                       target=target)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>In the above heatmap, we analyzed the missing values for 'major_discipline' variable. We find that 100% of the values are missing in 'major_discipline', where 'education_level' is High school and primary school. This is fine, as people who have primary school as their highest education can't have a major discipline. So this case must be marked separately."},{"metadata":{"trusted":true},"cell_type":"code","source":"eda.missing_value_analysis(data=data,\n                       col_to_analyze='gender',\n                       cols_to_use=['relevent_experience','enrolled_university',\n                                    'education_level','experience','major_discipline',\n                                    'company_size','company_type','last_new_job'],\n                       target=target)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>People with 'experience' less than or equal to 2 haven't disclosed their gender. We can't find any reason behind it."},{"metadata":{"trusted":true},"cell_type":"code","source":"eda.missing_value_analysis(data=data,\n                       col_to_analyze='company_type',\n                       cols_to_use=['gender','relevent_experience','enrolled_university',\n                                    'education_level','experience','major_discipline',\n                                    'company_size','last_new_job'],\n                       target=target)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2>Visualizing Class Separation"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(eda.class_separation.__doc__)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>Class Separation Using PCA"},{"metadata":{"trusted":true},"cell_type":"code","source":"eda.class_separation(data=data,\n                 categorical_variables=categorical_variables,\n                 method='pca',\n                 plot_alpha=0.5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>Class Separation With SVD"},{"metadata":{"trusted":true},"cell_type":"code","source":"eda.class_separation(data=data,\n                 categorical_variables=categorical_variables,\n                 method='svd',\n                 plot_alpha=0.5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2>Distribution of Numeric Variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(eda.density_plots.__doc__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eda.density_plots(data=data,\n                  numeric_variables=numeric_variables,\n                  plot_width = 12,\n                  plot_height = 5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2>Cumulative distribution Function (CDF) of Numeric Variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"eda.cdf(data=data,\n        numeric_variables=numeric_variables,\n        plot_height=5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>The above CDF shows ~50% of 'city_development_index' is less than 0.9. While, 80% of 'training_hours' are less that 100."},{"metadata":{},"cell_type":"markdown","source":"<h2>Normality Tests"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(eda.normality_test.__doc__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eda.normality_test(data=data,\n                   numeric_variables=numeric_variables)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2>Q-Q Plots"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(eda.qqplots.__doc__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eda.qqplots(data=data,\n           numeric_variables=numeric_variables)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2>Box Plots To Detect Outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(eda.boxplots.__doc__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eda.boxplots(data=data,\n            numeric_variables=numeric_variables,\n            plot_width=10,\n            plot_height=4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2>Skewness Test"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(eda.skewness_test.__doc__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eda.skewness_test(data=data,\n           numeric_variables=numeric_variables)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2>Correlation Between Features"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(eda.feature_correlation.__doc__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eda.feature_correlation(data=data,\n           numeric_variables=numeric_variables,\n           corr_matrix_width=3,\n           corr_matrix_height=3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>We can see no relation between 'city_development_index' and 'training_hours'"},{"metadata":{},"cell_type":"markdown","source":"<h2>Numeric Variables Vs Target"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(eda.numeric_variables_vs_target.__doc__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eda.numeric_variables_vs_target(data=data,\n                                numeric_variables=numeric_variables,\n                                target=target,\n                                plot_width=12,\n                                plot_height=5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3><ol><li>Relatively more employees stay with the companies located in cities with higher development index.</li>\n    <li>Training hours have no major impact on the target variable. People staying with and leaving the company have a similar distribution of training hours.</li></ol></h3>"},{"metadata":{},"cell_type":"markdown","source":"<h2>Categorical Variable Distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"eda.categorical_variable_distribution(data=data,\n                                     categorical_variables=categorical_variables,\n                                     plot_width=20,\n                                     plot_height=35,\n                                     vars_to_exclude_from_plots=['city'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2>Categorical Variables Vs Target"},{"metadata":{"trusted":true},"cell_type":"code","source":"eda.categorical_variables_vs_target(data=data,\n                                    categorical_variables=categorical_variables,\n                                    target=target,\n                                    vars_to_exclude_from_plots=['city'],\n                                    plot_width=20,\n                                    plot_height=35,\n                                    col_proportion=False,\n                                    crosstab_show_missing=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3><ol><li>No strong relationship between target and gender.</li>\n    <li>People with relevant experience are more likely to stay with their current company</li>\n    <li>People with higher 'experience' are likely to stay with their current company.</li>\n    <li>People enrolled in a full time course are more likely to leave.</li>\n    <li>Graduates and people with masters are more likely to leave.</li></ol></h3>"},{"metadata":{},"cell_type":"markdown","source":"<h2>Target Distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"eda.target_distribution(data=data,\n                       target=target)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>The class is imbalanced"},{"metadata":{"trusted":true},"cell_type":"code","source":"mutual_info = eda.mutual_info(data=data,\n               categorical_variables=categorical_variables,\n               target=target,\n               plot_height=7)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>WORK IN PROGRESS"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}