{"cells":[{"metadata":{},"cell_type":"markdown","source":" # Import Packages and Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import libraries \nimport os\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset,DataLoader\nfrom sklearn.metrics import f1_score,precision_score\nfrom PIL import Image\nfrom torchvision.transforms import transforms \nfrom matplotlib import pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom pathlib import Path\nimport math\nimport copy","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Get Dataset\nimage_path='../input/celeba-dataset/img_align_celeba/img_align_celeba'\ndf_attr=pd.read_csv('../input/celeba-dataset/list_attr_celeba.csv')\ndf_landmarks=pd.read_csv('../input/celeba-dataset/list_landmarks_align_celeba.csv')\ndf_bbox=pd.read_csv('../input/celeba-dataset/list_bbox_celeba.csv')\ndf_attr.head()\ndf_attr.replace(-1,0,inplace=True)\ndf_attr.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualize Label count of Dataset and check for imbalance\narr=pd.DataFrame(df_attr.iloc[:,1:].sum(axis=0))\narr.columns=['labels']\narr.sort_values(by='labels',ascending=False)\nplt.figure(figsize=(16,8))\nplt.bar(arr.index,arr['labels'])\nplt.xticks(rotation=90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Look for correlation between labels\nimport seaborn as sns\nplt.figure(figsize=(16,12))\nsns.heatmap(df_attr.iloc[:,1:].corr(), cmap=\"RdYlBu\", vmin=-1, vmax=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# DataLoader "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Class to get data in specific format and preprocessing.\nclass CelebDataset(Dataset):\n    def __init__(self,df_1,image_path,transform=None,mode='train'):\n        super().__init__()\n        self.attr=df_1.drop(['image_id'],axis=1)\n        self.path=image_path\n        self.image_id=df_1['image_id']\n        self.transform=transform\n        self.mode=mode\n    def __len__(self):\n        return self.image_id.shape[0]\n    def __getitem__(self,idx:int):\n        image_name=self.image_id.iloc[idx]\n        image=Image.open(os.path.join(image_path,image_name))\n        attributes=np.asarray(self.attr.iloc[idx].T,dtype=np.float32)\n        if self.transform:\n            image=self.transform(image)\n        return image,attributes    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split Dataset into train,test and valid\nfrom sklearn.model_selection import train_test_split\ntrain_df,test=train_test_split(df_attr,test_size=0.1,shuffle=True,random_state=212)\nvalid_df,test_df=train_test_split(test,test_size=0.5,random_state=212)\ntrain_df.shape,valid_df.shape,test_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Apply Data augmentation and different type of transforms on train data.\ntrain_transform=transforms.Compose([transforms.Resize((224,224)),transforms.RandomVerticalFlip(p=0.5),\n                                    transforms.RandomHorizontalFlip(p=0.5),transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.2),\n                                    transforms.ToTensor(),\n                                    transforms.Normalize(mean=[0.5063, 0.4258, 0.3832],std=[0.2644, 0.2436, 0.2397])])\n# Apply Data augmentation and different type of transforms on test and validation data.\nvalid_transform=transforms.Compose([transforms.Resize((224,224)),\n                              transforms.ToTensor(),\n                              transforms.Normalize(mean=[0.5063, 0.4258, 0.3832],std=[0.2644, 0.2436, 0.2397])])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create Dataset Object and DataLoader for train and validation set \ntrain_data=CelebDataset(train_df,image_path,train_transform)\ntrain_loader=DataLoader(train_data,batch_size=64,shuffle=True,num_workers=4)\nvalid_data=CelebDataset(valid_df,image_path,valid_transform)\nvalid_loader=DataLoader(valid_data,batch_size=64,num_workers=4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualizing Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# function to visualize dataset\ndef imshow(images,attr,idx:int):\n    images=images.cpu().numpy().transpose((0,2,3,1))\n    plt.imshow(images[idx]*[0.2644, 0.2436, 0.2397]+[0.5063, 0.4258, 0.3832])\n    labels=df_attr.columns.tolist()\n    labels=labels[1:]\n    att=attr[idx].numpy()\n    labels=[label for label,a in list(zip(labels,att)) if a==1]\n    plt.xlabel(\"\\n\".join(labels))\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualizing Data\nimages,attr=next(iter(train_loader))\nimshow(images,attr,0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creating Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Defining Class for Single Layer. \nclass Layer(nn.Module):\n    def __init__(self,in_ch,out_ch,kernel_size=3,stride=1,padding=1):\n        super(Layer,self).__init__()\n        self.conv=nn.Conv2d(in_ch,out_ch,kernel_size,stride,padding)\n        self.bn=nn.BatchNorm2d(out_ch)\n        self.relu=nn.ReLU()\n        nn.init.xavier_uniform_(self.conv.weight)\n    def forward(self,Input):\n        output=self.conv(Input)\n        output=self.bn(output)\n        output=self.relu(output)\n        return output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Complete model\nclass CelebModel(nn.Module):\n    def __init__(self,num_classes=40):\n        super(CelebModel,self).__init__()\n        \n        self.unit1=Layer(in_ch=3,out_ch=32)        \n        self.unit2=Layer(in_ch=32,out_ch=32)\n        self.pool1=nn.MaxPool2d(kernel_size=2)\n        \n        self.unit3=Layer(in_ch=32,out_ch=64)\n        self.unit4=Layer(in_ch=64,out_ch=64)\n        self.pool2=nn.MaxPool2d(kernel_size=2)\n        \n        self.unit5=Layer(in_ch=64,out_ch=128)\n        self.unit6=Layer(in_ch=128,out_ch=128)\n        self.unit7=Layer(in_ch=128,out_ch=128)\n        self.pool3=nn.MaxPool2d(kernel_size=2)\n        \n        self.unit8=Layer(in_ch=128,out_ch=256,kernel_size=5,padding=0)\n        self.unit9=Layer(in_ch=256,out_ch=256,kernel_size=5,padding=0)\n        self.unit10=Layer(in_ch=256,out_ch=256,kernel_size=5,padding=0)\n        self.pool4=nn.MaxPool2d(kernel_size=2)\n        \n        self.drop2=nn.Dropout(0.5)   \n        \n        self.unit11=Layer(in_ch=256,out_ch=512,kernel_size=3,padding=0)\n        self.unit12=Layer(in_ch=512,out_ch=512,kernel_size=3,padding=0)\n        self.unit13=Layer(in_ch=512,out_ch=512,kernel_size=3,padding=0)\n        \n        self.pool5=nn.AvgPool2d(kernel_size=2)\n        \n        self.drop3=nn.Dropout(0.5)\n        \n        self.model=nn.Sequential(self.unit1,self.unit2,self.pool1,self.unit3,\n                                 self.unit4,self.pool2,self.unit5,self.unit6,\n                                 self.unit7,self.pool3,self.unit8,self.unit9,\n                                 self.unit10,self.pool4,self.drop2,self.unit11,\n                                 self.unit12,self.unit13,self.pool5,self.drop3)\n        \n        self.fc=nn.Linear(in_features=512,out_features=num_classes)\n        \n    def forward(self,Input):\n        \n        output=self.model(Input)\n        output=output.view(-1,512)\n        output=self.fc(output)\n        \n        return output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# setting environment \ndevice=torch.device('cuda' if torch.cuda.is_available() else 'cpu')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating Model Object,loss function,optimizer and scheduler\nmodel=CelebModel().to(device)\ncriterion=nn.BCEWithLogitsLoss()\noptimizer=optim.SGD(model.parameters(),lr=0.1,momentum=0.9)\nscheduler=optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.0000001, max_lr=1,mode='exp_range')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training and Validating Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating a Checkpoint to Save model\ndef Save_model(model,cur_acc,best_acc,filename):\n    if cur_acc>best_acc:\n        best_acc=cur_acc\n        best_model=copy.deepcopy(model)\n        torch.save(best_model.state_dict(),filename)\n    return best_acc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create validation loop \ndef val_model():\n    model.eval()\n    epoch_loss=0\n    acc=0\n    with torch.no_grad():\n        val_pred=[]\n        val_lbl=[]\n        for images,attr in valid_loader:\n            \n            if torch.cuda.is_available():\n                images=images.to(device)\n                attr=attr.to(device)\n            \n            output=model(images)\n            \n            loss=criterion(output,attr)\n            \n            prediction=torch.round(torch.sigmoid(output))\n            \n            epoch_loss+=loss.item()*images.size(0)\n            \n            val_lbl.append(attr.detach().cpu())\n            \n            val_pred.append(prediction.detach().cpu()) \n            \n        epoch_loss/=len(valid_data)\n        \n        acc=f1_score(torch.cat(val_lbl,dim=0).numpy(),torch.cat(val_pred,dim=0).numpy(),average='samples')\n        \n        return epoch_loss,acc    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create Training loop \ndef train_model(num_epochs):\n    train_loss=[]\n    best_acc=0.0\n    for i in range(num_epochs):\n        epoch_loss=0\n        acc=0\n        j=0\n        epoch_pred=[]\n        epoch_lbl=[]\n        model.train()\n        for images,attr in train_loader:\n            j+=1 \n            if torch.cuda.is_available():\n                images=images.to(device)\n                attr=attr.to(device)\n            \n            optimizer.zero_grad()\n            \n            output=model(images)\n            \n            loss=criterion(output,attr)\n            \n            loss.backward()\n            \n            optimizer.step()\n            \n            prediction=torch.round(torch.sigmoid(output))\n            \n            epoch_loss+=loss.item()*images.size(0)\n            \n            epoch_lbl.append(attr.detach().cpu())\n            \n            epoch_pred.append(prediction.detach().cpu()) \n            \n            torch.cuda.empty_cache()\n            \n            if (j+1)%500==0:\n                print(f'Loss #{(j+1)//500}:{loss.item()}')\n            \n            scheduler.step()\n            \n        epoch_loss/=len(train_data)\n        \n        acc=f1_score(torch.cat(epoch_lbl,dim=0).numpy(),torch.cat(epoch_pred,dim=0).numpy(),average='samples')\n        \n        train_loss.append(epoch_loss)\n        \n        val_loss,val_acc=val_model()\n        \n        best_acc=Save_model(model,val_acc,best_acc,'model.pth')   # save model\n        \n        print(f'Epoch : {i+1} , Training loss:{epoch_loss} , Training f1_score:{acc} , Validation loss:{val_loss} , Validation f1_score:{val_acc}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training model\nnum_epochs=7\nif __name__=='__main__':\n    train_model(num_epochs)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Testing Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create Dataset Object and DataLoader for train and validation set\ntest_data=CelebDataset(test_df,image_path,valid_transform)\ntest_loader=DataLoader(test_data,batch_size=64,shuffle=False,num_workers=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to predict Labels\ndef Predict(images,model,idx:int):\n    pred=model(images)\n    images=images.cpu().numpy().transpose((0,2,3,1))\n    fig = plt.figure(figsize=(15,5))\n    plt.subplot(1,2, 1)\n    plt.imshow(images[idx])\n    labels=df_attr.columns.tolist()\n    labels=labels[1:]\n    attr=torch.round(torch.sigmoid(pred)).cpu().detach()\n    prd=torch.sigmoid(pred[idx]).cpu().detach().numpy()\n    att=attr[idx].numpy()\n    labels=[label for label,a in list(zip(labels,att)) if a==1]\n    pred_list=[p for p,a in list(zip(prd,att)) if a==1]\n    plt.subplot(1,2,2)\n    plt.barh(labels,pred_list)\n    plt.show()\n    return labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loading Save model\nmodel.load_state_dict(torch.load('model.pth',map_location=torch.device('cpu')))\nmodel.eval()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Testing Model\nimages,attr=next(iter(test_loader))\n\n# Getting actual labels\nlabels=df_attr.columns.tolist()\nlabels=labels[1:]\nact_labels=[l for l,a in zip(labels,attr[20].numpy()) if a==1]\n\n\n# Making prediction on test dataset\npred_labels=Predict(images,model,12)\n\n# comparing labels and predictions\nprint('Actual labels:',act_labels)\nprint('Predictions',pred_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# You can find Live Running app at [AttributePredictionapp](https://attributepredictionapp.herokuapp.com/)"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}