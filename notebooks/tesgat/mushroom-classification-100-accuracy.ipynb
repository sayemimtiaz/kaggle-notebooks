{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"#Importing dependencies\n\n# Standard Python Imports\nfrom timeit import default_timer as timer\nimport time, datetime\nimport os\n\n# Data Manipulation\nimport numpy as np\nimport pandas as pd\n\n# Data Visualization \nimport matplotlib.pyplot as plt\nimport missingno as msno\nimport seaborn as sns\nplt.style.use('seaborn-whitegrid')\n\n# For Data Preprocessing\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder, LabelBinarizer\nfrom sklearn.preprocessing import Imputer\nfrom sklearn.pipeline import Pipeline\ntry:\n    from sklearn.impute import SimpleImputer # Scikit-Learn 0.20+\nexcept ImportError:\n    from sklearn.preprocessing import Imputer as SimpleImputer\n\n# Machine Learning\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn import model_selection, tree, preprocessing, metrics, linear_model\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.pipeline import FeatureUnion\n# Algorithms\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.svm import LinearSVC\nfrom sklearn import svm\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost.sklearn import XGBClassifier\n# Validation & Scoring\nfrom sklearn.model_selection import cross_val_score, GridSearchCV, KFold\n# Ignoring the warnings that we will see in this notebook\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing Data\ndef fetch_data():\n    data = pd.read_csv(\"./../input/mushrooms.csv\")\n    return data\ndata = fetch_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"msno.matrix(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.get_dtype_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All features are categorical"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedShuffleSplit\nsplit = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\nfor train_index, test_index in split.split(data, data[\"class\"]):\n    train = data.loc[train_index]\n    test = data.loc[test_index]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(y=\"class\", data=data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(y=\"class\", data=train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(y=\"class\", data=test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_train = train[\"class\"]\nX_train = train.iloc[:,1:]\n\nY_test = test[\"class\"]\nX_test = test.iloc[:,1:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DropColumns(BaseEstimator, TransformerMixin):\n    def __init__(self, column_names=[]):\n        self.column_names = column_names\n    def transform(self, df, y=None):\n        return df.drop(self.column_names, axis=1)\n    def fit(self, df, y=None):\n        return self","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ColumnExtractor(BaseEstimator, TransformerMixin):\n    def __init__(self, column_names=[]):\n        self.column_names = column_names\n    def transform(self, df, y=None):\n        return df.loc[:, self.column_names]\n    def fit(self, df, y=None):\n        return self","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class FeatureNormalizer(BaseEstimator, TransformerMixin):\n    def __init__(self, column_names=[]):\n        self.column_names = column_names\n        self.min_max_scalar = MinMaxScaler()\n    def fit(self, X, y=None):\n        self.min_max_scalar.fit(X[self.column_names])\n        return self\n    def transform(self, X, y=None):\n        X[self.column_names] = self.min_max_scalar.transform(X[self.column_names])\n        return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class MissingStalkRoots(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        pass\n    def fit(self, X, y=None):\n        X[\"stalk-root\"] = X[\"stalk-root\"].replace(['?'], 'm')\n        return self\n    def transform(self, X, y=None):\n        return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ReplacingVeilColor(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        pass\n    def fit(self, X, y=None):\n        X[\"veil-color\"] = X[\"veil-color\"].replace(['n', 'o'], 'nw')\n        return self\n    def transform(self, X, y=None):\n        return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class MyLabelBinarizer(TransformerMixin):\n    def __init__(self):\n        self.encoder = LabelBinarizer()\n    def fit(self, x, y=0):\n        self.encoder.fit(x)\n        return self\n    def transform(self, x, y=0):\n        return self.encoder.transform(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(y=\"cap-shape\", data=train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(y=\"cap-surface\", data=train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(y=\"cap-color\", data=train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(y=\"bruises\", data=train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(y=\"odor\", data=train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(y=\"gill-spacing\", data=train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(y=\"gill-size\", data=train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(y=\"stalk-shape\", data=train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(y=\"stalk-root\", data=train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(y=\"stalk-surface-above-ring\", data=train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(y=\"stalk-surface-below-ring\", data=train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(y=\"stalk-color-above-ring\", data=train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(y=\"stalk-color-below-ring\", data=train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(y=\"veil-color\", data=train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(y=\"ring-number\", data=train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"counter = train[train[\"ring-number\"] == \"n\"]\nprint(\"There are {} ring-numbers with value \\'n\\'\".format(len(counter)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(y=\"ring-type\", data=train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_preprocessing = Pipeline([\n        (\"drop_veil_tape\", DropColumns([\"veil-type\"])),\n        (\"replacing_stalk_roots\", MissingStalkRoots()),\n        (\"repalcing_veil_color\", ReplacingVeilColor()),\n        #(\"one_hot_encoding\", OneHotEncoder(sparse=False))\n    ])\n\nlabels_preprocessing = Pipeline([\n        (\"one_hot_encoding\", MyLabelBinarizer())\n    ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = data_preprocessing.fit_transform(X_train)\nX_test = data_preprocessing.fit_transform(X_test)\nY_train = labels_preprocessing.fit_transform(Y_train)\nY_test = labels_preprocessing.fit_transform(Y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"combinedsets = pd.concat([X_train, X_test])\nenc = OneHotEncoder(sparse=False)\nenc.fit(combinedsets)\nX_train = enc.transform(X_train)\nX_test = enc.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function that runs the requested algorithm and returns the accuracy metrics\ndef fit_ml_algo(algo, x_train, y_train, cv):\n    # One Pass\n    model = algo.fit(x_train, y_train)\n    acc = round(model.score(x_train, y_train) * 100, 2)\n    \n    # Cross Validation \n    train_pred = model_selection.cross_val_predict(algo, \n                                                  x_train, \n                                                  y_train, \n                                                  cv=cv, \n                                                  n_jobs = -1)\n    # Cross-validation accuracy metric\n    acc_cv = round(metrics.accuracy_score(y_train, train_pred) * 100, 2)\n    \n    #print(\"Model used :\", algo.best_estimator_)\n    return train_pred, acc, acc_cv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class MachineLearningClassification(TransformerMixin):\n    def __init__(self, x_train, y_train):\n        self.x_train = x_train\n        self.y_train = y_train\n    def fit(self, x_train, y_train):\n        \"\"\"knn_params = {'n_neighbors':list(range(1,100)), 'weights': ['distance', 'uniform']}\n        knn_grid_search_cv = GridSearchCV(KNeighborsClassifier(), knn_params, cv=5)\n        knn_grid_search_cv.fit(self.x_train, self.y_train)\n        knn = knn_grid_search_cv.best_estimator_\n        \n        Cs = [0.001, 0.01, 0.1, 1, 10]\n        gammas = [0.001, 0.01, 0.1, 1]\n        kernels = ['rbf', 'linear']\n        param_grid = {'C': Cs, 'gamma' : gammas, 'kernel': kernels}\n        svm_grid_search = GridSearchCV(svm.SVC(), param_grid, cv=10)\n        svm_grid_search.fit(self.x_train, self.y_train)\n        svmc = svm_grid_search.best_estimator_\n        \n        rf_params = {'n_estimators': list(range(1,100))}\n        rf_grid_search = GridSearchCV(RandomForestClassifier(), rf_params, cv=10)\n        rf_grid_search.fit(self.x_train, self.y_train)\n        rfc = rf_grid_search.best_estimator_\"\"\"\n        \n        sgdc_params = {\"loss\": [\"hinge\", \"log\"], \"penalty\": [\"l1\", \"l2\"], \"max_iter\": [1,2,3,4,5]}\n        sgdc_grid_search = GridSearchCV(SGDClassifier(), sgdc_params, cv=5)\n        sgdc_grid_search.fit(self.x_train, self.y_train)\n        sgdc = sgdc_grid_search.best_estimator_\n                       \n        gbc_params = {\"loss\": [\"deviance\", \"exponential\"],\"learning_rate\": [1,0.6 ,0.5,0.4,0.3, 0.25, 0.1, 0.05, 0.01],\"n_estimators\": [10,50,100]}\n        gbc_grid_search = GridSearchCV(GradientBoostingClassifier(), gbc_params, cv=5)\n        gbc_grid_search.fit(self.x_train, self.y_train)\n        gbc = gbc_grid_search.best_estimator_\n                       \n        \"\"\" lsvc_params = {\"penalty\": [\"l2\"],\"loss\": [\"hinge\", \"squared_hinge\"],\"dual\": [True],\"C\": [0.001,0.01,0.1,1,10]}     \n        lsvc_grid_search = GridSearchCV(LinearSVC(), lsvc_params, cv=5)\n        lsvc_grid_search.fit(self.x_train, self.y_train)\n        lsvc = lsvc_grid_search.best_estimator_\n                       \n        xgb_params = {\"early_stopping_rounds\": [1,2,5],\"n_estimators\": [5,10,15],\"learning_rate\": [0.001,0.03,0.05],\"n_jobs\": [0,1,2,5]}\n        xgb_grid_search = GridSearchCV(XGBClassifier(), xgb_params, cv=5)\n        xgb_grid_search.fit(self.x_train, self.y_train)\n        xgb = xgb_grid_search.best_estimator_\n        \"\"\"\n                       \n        classifiers_array = [LogisticRegression(),\n                             #knn,\n                             #svmc,\n                             DecisionTreeClassifier(),\n                             #rfc,\n                             sgdc,\n                             gbc,\n                             #lsvc,\n                             #xgb\n                            ]          \n        \n        best_cls = None\n        best_acc = None\n        best_acc_cv = None\n        accs = []\n        accs_cv = []\n        \n        for clf in classifiers_array:\n            train_pred, clf_acc, clf_acc_cv = fit_ml_algo(clf,self.x_train,self.y_train,5)\n            accs.append(clf_acc)\n            accs_cv.append(clf_acc_cv)\n            \n        best_acc = max(accs)\n        best_acc_cv = max(accs_cv)\n        best_cls = classifiers_array[accs_cv.index(best_acc_cv)]\n        return best_acc, best_acc_cv, best_cls\n    def transform(self, x_train, y_train):\n        return best_acc, best_acc_cv, best_cls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def classify(x_train, y_train):\n    \"\"\"knn_params = {'n_neighbors':list(range(1,100)), 'weights': ['distance', 'uniform']}\n    knn_grid_search_cv = GridSearchCV(KNeighborsClassifier(), knn_params, cv=5)\n    knn_grid_search_cv.fit(x_train, y_train)\n    knn = knn_grid_search_cv.best_estimator_\n        \n    Cs = [0.001, 0.01, 0.1, 1, 10]\n    gammas = [0.001, 0.01, 0.1, 1]\n    kernels = ['rbf', 'linear']\n    param_grid = {'C': Cs, 'gamma' : gammas, 'kernel': kernels}\n    svm_grid_search = GridSearchCV(svm.SVC(), param_grid, cv=5)\n    svm_grid_search.fit(x_train, y_train)\n    svmc = svm_grid_search.best_estimator_\n        \n    rf_params = {'n_estimators': list(range(1,100))}\n    rf_grid_search = GridSearchCV(RandomForestClassifier(), rf_params, cv=5)\n    rf_grid_search.fit(x_train, y_train)\n    rfc = rf_grid_search.best_estimator_\"\"\"\n        \n    sgdc_params = {\"loss\": [\"hinge\", \"log\"], \"penalty\": [\"l1\", \"l2\"], \"max_iter\": [1,2,3,4,5]}\n    sgdc_grid_search = GridSearchCV(SGDClassifier(), sgdc_params, cv=5)\n    sgdc_grid_search.fit(x_train, y_train)\n    sgdc = sgdc_grid_search.best_estimator_\n                       \n    gbc_params = {\"loss\": [\"deviance\", \"exponential\"],\"learning_rate\": [1,0.6 ,0.5,0.4,0.3, 0.25, 0.1, 0.05, 0.01],\"n_estimators\": [10,50,100]}\n    gbc_grid_search = GridSearchCV(GradientBoostingClassifier(), gbc_params, cv=5)\n    gbc_grid_search.fit(x_train, y_train)\n    gbc = gbc_grid_search.best_estimator_\n                       \n    \"\"\" lsvc_params = {\"penalty\": [\"l2\"],\"loss\": [\"hinge\", \"squared_hinge\"],\"dual\": [True],\"C\": [0.001,0.01,0.1,1,10]}     \n    lsvc_grid_search = GridSearchCV(LinearSVC(), lsvc_params, cv=5)\n    lsvc_grid_search.fit(x_train, y_train)\n    lsvc = lsvc_grid_search.best_estimator_\n                       \n    xgb_params = {\"early_stopping_rounds\": [1,2,5],\"n_estimators\": [5,10,15],\"learning_rate\": [0.001,0.03,0.05],\"n_jobs\": [0,1,2,5]}\n    xgb_grid_search = GridSearchCV(XGBClassifier(), xgb_params, cv=5)\n    xgb_grid_search.fit(x_train, y_train)\n    xgb = xgb_grid_search.best_estimator_\n    \"\"\"\n                       \n    classifiers_array = [LogisticRegression(),\n                        #knn,\n                        #svmc,\n                        DecisionTreeClassifier(),\n                        #rfc,\n                        sgdc,\n                        gbc,\n                        #lsvc,\n                        #xgb\n                        ]          \n        \n    best_cls = None\n    best_acc = None\n    best_acc_cv = None\n    accs = []\n    accs_cv = []\n        \n    for clf in classifiers_array:\n        train_pred, clf_acc, clf_acc_cv = fit_ml_algo(clf,x_train,y_train,5)\n        accs.append(clf_acc)\n        accs_cv.append(clf_acc_cv)\n            \n    best_acc = max(accs)\n    best_acc_cv = max(accs_cv)\n    best_cls = classifiers_array[accs_cv.index(best_acc_cv)]\n    return best_acc, best_acc_cv, best_cls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classification = Pipeline([\n        (\"classification_best\", MachineLearningClassification(X_train, Y_train))\n    ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_classifier,best_acc_cv, best_acc = classify(X_train, Y_train)\nprint(\"Best Classifier : \", best_classifier)\nprint(\"Best Acc, CV : \", best_acc_cv)\nprint(\"Best Acc : \", best_acc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n            max_features=None, max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=1, min_samples_split=2,\n            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n            splitter='best')\nmodel.fit(X_train, Y_train)\npred = model.predict(X_test)\nprint(\"Test accuracy :\", round(metrics.accuracy_score(Y_test, pred) * 100, 2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score, f1_score\nprint(\"Precision : \", precision_score(Y_test, pred))\nprint(\"Recall : \", recall_score(Y_test, pred))\nprint(\"F1 : \", f1_score(Y_test, pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"nbformat":4,"nbformat_minor":1}